[
    {
        "title": "[Lightning-dev] Suggestion: Add optional IP address field to invoice format",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-02-02T05:48:46",
                "message_text_only": "Ignatius Rivaldi <minecraft2048 at gmail.com> writes:\n> Hi,\n>\n> I think that there is a potential problem for sellers to accept \n> lightning network. They need someone to open a channel with them that is \n> filled with bitcoins so that they can start receiving bitcoins from \n> other LN users. But what if a buyer can simultaneously open a channel \n> and pay the seller? In order to do that they need to know the IP address \n> of the seller and how much bitcoins they need to pay, so that they can \n> push the appropriate amount of bitcoins to the seller side, satisfying \n> the seller's transaction. But currently we opened a channel using the \n> pubkey at ip format, which doesn't have amount information, and then we pay \n> them using lntb... format, which doesn't have IP address information.\n\nThe DNS seeds have this information if you are bootstrapping, or you can\nconnect to any other node and get information on the network as a whole.\n\nConnecting to the first recipient is one strategy, but not clearly the\nbest if they're not reasonably connected: if you know the topology you\ncan make a more informed decision.\n\nIt's not a bad idea to add an 'a' field, but I'd rather hold off, as\nit *is* something of a layering violation.\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Suggestion: Add optional IP address field to invoice format",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1250
        }
    },
    {
        "title": "[Lightning-dev] channel_reserve_satoshis?",
        "thread_messages": [
            {
                "author": "Cezary Dziemian",
                "date": "2018-02-02T13:36:10",
                "message_text_only": "Hello,\n\nWhen we send open_channel, how we can communicate other party that we would\nlike him to put into channel some of his funds? Is this what is\n\"channel_reserve_satoshis\" field for?\n\nBest regards,\nCezary\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180202/d7a23b8f/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-02-02T14:07:33",
                "message_text_only": "Good morning Cezary,\n\n> When we send open_channel, how we can communicate other party that we would like him to put into channel some of his funds?\n\nThere is no way to do that  as of BOLT v1.0\n\nThere are too many issues to allow channel opening by somebody else to ask your node to commit money into channels.\n\n1.  If I ask you to put 10.0 BTC from you to put into a channel I make, and you accept, I know you have at least 10.0 BTC lying around.\n2.  I might open a channel to you and ask you to put in money, then when you have committed the money into the channel, disconnect my node and reformat its hard disk, so that you are forced to use a unilateral close on your side, and locking your funds due to the unilateral close.  Even if there is a rule that I must commit at least the same amount as you, a richer attacker can still lock up the funds of a poorer victim.\n\nIn general such dual-funded channels require some measure of trust between you and your counterparty due to the above issues, at least that you know that the one initiating the opening will not suddenly disappear.\n\nSuch trust issues can be mitigated by simply disallowing dual-funding by default on your node, and requiring you to explicitly allow multi-funding, once, for a particular amount, coming from a particular peer.  But in any case, for now it is not defined in BOLT v1.0.\n\n> Is this what is \"channel_reserve_satoshis\" field for?\n\nNo.  `channel_reserve_satoshis` is different.  It is the amount that each of you should keep on the channel, once the channel state has moved from \"all of the funds is assigned to the opener of the channel.\"\n\nThe reason for this field is below.\n\n1.  Suppose I open a 1BTC channel to you.  We agree to a `channel_reserve_satoshis` amounting to 0.1BTC.  The initial channel state is (me=1.0BTC, you=0BTC)\n2.  This means I can make 9 payments of 0.1BTC each, so that the channel state is now (me=0.1BTC, you = 0.9BTC).\n3.  The `channel_reserve_satoshis` means I cannot pay further to you, i.e. I cannot move the channel state to (me=0BTC, you=1BTC)..\n4.  Suppose we allowed this (me=0BTC, you=1BTC) state.  Then it is costless for me to attempt to steal -- after all, I have 0 money on the channel and there is nothing to punish me with.  Even if I steal, and you detect it, I lose nothing because I own nothing on the channel.\n5.  But if the channel is constrained, so that I need to keep 0.1BTC on the channel, then stealing attempts have a cost.  If you detect me, I stand to lose 0.1BTC.  If you have a better than 90% chance of detecting me, say 91%, a mere 9% chance of 0.9BTC payoff is not enough to counterbalance the 91% chance of losing 0.1BTC I currently have on the channel\n6.  In short, the `channel_reserve_satoshis` ensures we do not have costless theft.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180202/aea3e478/attachment-0001.html>"
            },
            {
                "author": "Cezary Dziemian",
                "date": "2018-02-02T16:48:47",
                "message_text_only": "Thank you very much for answer.\n\nThanks for explanation about 'channel_reserve_satoshis'. I misunderstood '\nchannel_reserve_satoshis ' with 'dust_limit'.\n\nLets say I would like to receive ln payments. How can I do this, without\nlocking funds on the other side of channel?\n\nBest regards,\nCezary\n\n2018-02-02 15:07 GMT+01:00 ZmnSCPxj <ZmnSCPxj at protonmail.com>:\n\n> Good morning Cezary,\n>\n> When we send open_channel, how we can communicate other party that we\n> would like him to put into channel some of his funds?\n>\n>\n> There is no way to do that  as of BOLT v1.0\n>\n> There are too many issues to allow channel opening by somebody else to ask\n> your node to commit money into channels.\n>\n> 1.  If I ask you to put 10.0 BTC from you to put into a channel I make,\n> and you accept, I know you have at least 10.0 BTC lying around.\n> 2.  I might open a channel to you and ask you to put in money, then when\n> you have committed the money into the channel, disconnect my node and\n> reformat its hard disk, so that you are forced to use a unilateral close on\n> your side, and locking your funds due to the unilateral close.  Even if\n> there is a rule that I must commit at least the same amount as you, a\n> richer attacker can still lock up the funds of a poorer victim.\n>\n> In general such dual-funded channels require some measure of trust between\n> you and your counterparty due to the above issues, at least that you know\n> that the one initiating the opening will not suddenly disappear.\n>\n> Such trust issues can be mitigated by simply disallowing dual-funding by\n> default on your node, and requiring you to explicitly allow multi-funding,\n> once, for a particular amount, coming from a particular peer.  But in any\n> case, for now it is not defined in BOLT v1.0.\n>\n> Is this what is \"channel_reserve_satoshis\" field for?\n>\n>\n> No.  `channel_reserve_satoshis` is different.  It is the amount that each\n> of you should keep on the channel, once the channel state has moved from\n> \"all of the funds is assigned to the opener of the channel.\"\n>\n> The reason for this field is below.\n>\n> 1.  Suppose I open a 1BTC channel to you.  We agree to a\n> `channel_reserve_satoshis` amounting to 0.1BTC.  The initial channel state\n> is (me=1.0BTC, you=0BTC)\n> 2.  This means I can make 9 payments of 0.1BTC each, so that the channel\n> state is now (me=0.1BTC, you = 0.9BTC).\n> 3.  The `channel_reserve_satoshis` means I cannot pay further to you, i.e.\n> I cannot move the channel state to (me=0BTC, you=1BTC)..\n> 4.  Suppose we allowed this (me=0BTC, you=1BTC) state.  Then it is\n> costless for me to attempt to steal -- after all, I have 0 money on the\n> channel and there is nothing to punish me with.  Even if I steal, and you\n> detect it, I lose nothing because I own nothing on the channel.\n> 5.  But if the channel is constrained, so that I need to keep 0.1BTC on\n> the channel, then stealing attempts have a cost.  If you detect me, I stand\n> to lose 0.1BTC.  If you have a better than 90% chance of detecting me, say\n> 91%, a mere 9% chance of 0.9BTC payoff is not enough to counterbalance the\n> 91% chance of losing 0.1BTC I currently have on the channel\n> 6.  In short, the `channel_reserve_satoshis` ensures we do not have\n> costless theft.\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180202/db61ac20/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-02-04T09:08:24",
                "message_text_only": "Good morning Cezary,\n\n> Lets say I would like to receive ln payments. How can I do this, without locking funds on the other side of channel?\n\n1. Do the Blockstream Store route: do it early enough, and people will make channels to you, because, they want to try out Lightning Network quickly.\n\n2. Publish the node and contact details (IP or TOR onion service) and hope people are excited enough about your product to open a channel to you.\n\n3. In all likelihood, some service later will offer deals like \"up to 300mBTC receive for only 1mBTC! At least 3 months channel alive!\" for new upcoming businesses.\n\n4.  Ask a friend to channel to you.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180204/34a8170e/attachment.html>"
            },
            {
                "author": "Cezary Dziemian",
                "date": "2018-02-04T11:06:43",
                "message_text_only": "Thanks for answer ZmnSCPxj,\n\nI think first two options are for those, who want to earn some money for\npayments fee. The option that can be interesting for for some business like\ncoffee is third option. Do you agree with me?\n\n>  3. In all likelihood, some service later will offer deals like \"up to\n300mBTC receive for only 1mBTC! At least 3 months channel alive!\" for new\nupcoming businesses.\n\nIt seams the best option for new businesses, but what if such new business\nwould like to have channel with 300mBTC on both side. Let's say this is\nATM. The owner of ATM need to be able to receive and sending funds. Without\npossibility of both-side funding channels this is quite hard to establish\nsuch balanced channel. ATM owner needs to send 300 mBTC as on-side\ntransaction to hub, and then hub could open channel with 600 mBTC capacity\nand send back 300mBTC to ATM owner though this new channel. This requires\ntrust to hub.\n\nI know, LN is in early stage, but I'm very surprised that both sides cannot\nfund channel. Maybe this is because at the beginning LN was presented with\nsuch option. The only reason are trust issues that you described before, or\nmaybe there are also some technical issues to implement such functionality?\nDo you predict this will be added to BOLT and implemented in the future?\n\nBest regards,\nCezary\n\n2018-02-04 10:08 GMT+01:00 ZmnSCPxj <ZmnSCPxj at protonmail.com>:\n\n> Good morning Cezary,\n>\n> > Lets say I would like to receive ln payments. How can I do this, without\n> locking funds on the other side of channel?\n>\n> 1. Do the Blockstream Store route: do it early enough, and people will\n> make channels to you, because, they want to try out Lightning Network\n> quickly.\n>\n> 2. Publish the node and contact details (IP or TOR onion service) and hope\n> people are excited enough about your product to open a channel to you.\n>\n> 3. In all likelihood, some service later will offer deals like \"up to\n> 300mBTC receive for only 1mBTC! At least 3 months channel alive!\" for new\n> upcoming businesses.\n>\n> 4.  Ask a friend to channel to you.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180204/1cd2774f/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-02-04T12:36:14",
                "message_text_only": "Good morning Cezary,\n\n> I think first two options are for those, who want to earn some money for payments fee. The option that can be interesting for for some business like coffee is third option. Do you agree with me?\n>\n>>  3. In all likelihood, some service later will offer deals like \"up to 300mBTC receive for only 1mBTC! At least 3 months channel alive!\" for new upcoming businesses.\n>\n> It seams the best option for new businesses, but what if such new business would like to have channel with 300mBTC on both side. Let's say this is ATM. The owner of ATM need to be able to receive and sending funds. Without possibility of both-side funding channels this is quite hard to establish such balanced channel. ATM owner needs to send 300 mBTC as on-side transaction to hub, and then hub could open channel with 600 mBTC capacity and send back 300mBTC to ATM owner though this new channel. This requires trust to hub.\n\nThen do not trust a single hub.  Instead, have incoming 300mBTC from one hub, then make an outgoing 300mBTC to another hub.  Encourages more hubs also.  This also makes your node a potential routing node, improving network connectivity.\n\n> I know, LN is in early stage, but I'm very surprised that both sides cannot fund channel. Maybe this is because at the beginning LN was presented with such option. The only reason are trust issues that you described before, or maybe there are also some technical issues to implement such functionality? Do you predict this will be added to BOLT and implemented in the future?\n\nThere is already an issue regarding this. For now, priority is actual implementation of payments.  Dual-funding channels can be emulated by having some hubbing service make channels to you, while you make a channel to some other hub (i.e. make two channels).  Such an emulation is superior to dual-funding as it allows you to potentially become some alternate route if other routes become congested, letting you earn some small amount; compare this to a single dual-funding channel that, by itself, cannot be used to for routing.\n\nAnother thing is that we can make \"circular superhubs\" if small groups of us cooperate.  The smallest 3-circle superhub has 3 members A B C.  A opens channel to B, B open channels t C, C open channels to A.  Each channel is the same capacity.  If each of you has one out-channel other than on the circular superhub, any of A B C can spend to any node that any of them have an out-channel to.  Similarly, each of you can receive via any in-channel any of you happen to have.  Join a few such small communities and you can be well-connected enough to send and receive reasonably seamlessly to anyone on the network.\n\nRegards,\nZmnSCPxj\n\n> Best regards,\n> Cezary\n>\n> 2018-02-04 10:08 GMT+01:00 ZmnSCPxj <ZmnSCPxj at protonmail.com>:\n>\n>> Good morning Cezary,\n>>> Lets say I would like to receive ln payments. How can I do this, without locking funds on the other side of channel?\n>>\n>> 1. Do the Blockstream Store route: do it early enough, and people will make channels to you, because, they want to try out Lightning Network quickly.\n>>\n>> 2. Publish the node and contact details (IP or TOR onion service) and hope people are excited enough about your product to open a channel to you.\n>>\n>> 3. In all likelihood, some service later will offer deals like \"up to 300mBTC receive for only 1mBTC! At least 3 months channel alive!\" for new upcoming businesses.\n>>\n>> 4.  Ask a friend to channel to you.\n>>\n>> Regards,\n>> ZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180204/01a1abd9/attachment-0001.html>"
            },
            {
                "author": "Cezary Dziemian",
                "date": "2018-02-06T15:28:37",
                "message_text_only": "Thank you very much for answer!\n\nThis is quite good way to replace both-funding channels by such \"superhub\".\nIt would be even easier if I could open more then single channel between\nboth parties, but I saw this is not possible in c-lightning. Could you tell\nme what is the reason and do you plan to add this possibility in the\nfuture? In LND opening multiple channels is possible, but is this\ncompatible with c-lightning then?\n\nBest Regards,\nCezary\n\n2018-02-04 13:36 GMT+01:00 ZmnSCPxj <ZmnSCPxj at protonmail.com>:\n\n> Good morning Cezary,\n>\n>\n> I think first two options are for those, who want to earn some money for\n> payments fee. The option that can be interesting for for some business like\n> coffee is third option. Do you agree with me?\n>\n> >  3. In all likelihood, some service later will offer deals like \"up to\n> 300mBTC receive for only 1mBTC! At least 3 months channel alive!\" for new\n> upcoming businesses.\n>\n> It seams the best option for new businesses, but what if such new business\n> would like to have channel with 300mBTC on both side. Let's say this is\n> ATM. The owner of ATM need to be able to receive and sending funds. Without\n> possibility of both-side funding channels this is quite hard to establish\n> such balanced channel. ATM owner needs to send 300 mBTC as on-side\n> transaction to hub, and then hub could open channel with 600 mBTC capacity\n> and send back 300mBTC to ATM owner though this new channel. This requires\n> trust to hub.\n>\n>\n> Then do not trust a single hub.  Instead, have incoming 300mBTC from one\n> hub, then make an outgoing 300mBTC to another hub.  Encourages more hubs\n> also.  This also makes your node a potential routing node, improving\n> network connectivity.\n>\n>\n> I know, LN is in early stage, but I'm very surprised that both sides\n> cannot fund channel. Maybe this is because at the beginning LN was\n> presented with such option. The only reason are trust issues that you\n> described before, or maybe there are also some technical issues to\n> implement such functionality? Do you predict this will be added to BOLT and\n> implemented in the future?\n>\n>\n> There is already an issue regarding this. For now, priority is actual\n> implementation of payments.  Dual-funding channels can be emulated by\n> having some hubbing service make channels to you, while you make a channel\n> to some other hub (i.e. make two channels).  Such an emulation is superior\n> to dual-funding as it allows you to potentially become some alternate route\n> if other routes become congested, letting you earn some small amount;\n> compare this to a single dual-funding channel that, by itself, cannot be\n> used to for routing.\n>\n> Another thing is that we can make \"circular superhubs\" if small groups of\n> us cooperate.  The smallest 3-circle superhub has 3 members A B C.  A opens\n> channel to B, B open channels t C, C open channels to A.  Each channel is\n> the same capacity.  If each of you has one out-channel other than on the\n> circular superhub, any of A B C can spend to any node that any of them have\n> an out-channel to.  Similarly, each of you can receive via any in-channel\n> any of you happen to have.  Join a few such small communities and you can\n> be well-connected enough to send and receive reasonably seamlessly to\n> anyone on the network.\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> Best regards,\n> Cezary\n>\n> 2018-02-04 10:08 GMT+01:00 ZmnSCPxj <ZmnSCPxj at protonmail.com>:\n>\n>> Good morning Cezary,\n>>\n>> > Lets say I would like to receive ln payments. How can I do this,\n>> without locking funds on the other side of channel?\n>>\n>> 1. Do the Blockstream Store route: do it early enough, and people will\n>> make channels to you, because, they want to try out Lightning Network\n>> quickly.\n>>\n>> 2. Publish the node and contact details (IP or TOR onion service) and\n>> hope people are excited enough about your product to open a channel to you.\n>>\n>> 3. In all likelihood, some service later will offer deals like \"up to\n>> 300mBTC receive for only 1mBTC! At least 3 months channel alive!\" for new\n>> upcoming businesses.\n>>\n>> 4.  Ask a friend to channel to you.\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180206/11915f27/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-02-07T08:07:15",
                "message_text_only": "Good Morning Cezary,\n\n> This is quite good way to replace both-funding channels by such \"superhub\". It would be even easier if I could open more then single channel between both parties, but I saw this is not possible in c-lightning.\n\nFrom a risk perspective, you have increased risk in general if you open channels to few nodes, compared to the case where you open channels to more nodes.  Thus if you can afford to open many channels, you would prefer to participate in multiple different circular superhubs, each with a different set of participants, rather than repeatedly opening many channels to the same participant in a single superhub.\n\n> Could you tell me what is the reason and do you plan to add this possibility in the future?\n\nThe current code tends to couple \"channel\" to \"peer\" a little too much, and it is going to take quite some work to uncouple them.  I believe cdecker has plans to add this in the future, as there are a few comments in the code from him pointing to bits where this decoupling needs to be implemented.\n\n> In LND opening multiple channels is possible, but is this compatible with c-lightning then?\n\nNo, currently the c-lightning daemon will reject the multiple channel attempt from LND.  LND can form multiple channels with peer LND.\n\nRegards,\nZmnSCPxj\n\n> Best Regards,\n> Cezary\n>\n> 2018-02-04 13:36 GMT+01:00 ZmnSCPxj <ZmnSCPxj at protonmail.com>:\n>\n>> Good morning Cezary,\n>>\n>>> I think first two options are for those, who want to earn some money for payments fee. The option that can be interesting for for some business like coffee is third option. Do you agree with me?\n>>>\n>>>>  3. In all likelihood, some service later will offer deals like \"up to 300mBTC receive for only 1mBTC! At least 3 months channel alive!\" for new upcoming businesses.\n>>>\n>>> It seams the best option for new businesses, but what if such new business would like to have channel with 300mBTC on both side. Let's say this is ATM. The owner of ATM need to be able to receive and sending funds. Without possibility of both-side funding channels this is quite hard to establish such balanced channel. ATM owner needs to send 300 mBTC as on-side transaction to hub, and then hub could open channel with 600 mBTC capacity and send back 300mBTC to ATM owner though this new channel. This requires trust to hub.\n>>\n>> Then do not trust a single hub.  Instead, have incoming 300mBTC from one hub, then make an outgoing 300mBTC to another hub.  Encourages more hubs also.  This also makes your node a potential routing node, improving network connectivity.\n>>\n>>> I know, LN is in early stage, but I'm very surprised that both sides cannot fund channel. Maybe this is because at the beginning LN was presented with such option. The only reason are trust issues that you described before, or maybe there are also some technical issues to implement such functionality? Do you predict this will be added to BOLT and implemented in the future?\n>>\n>> There is already an issue regarding this. For now, priority is actual implementation of payments.  Dual-funding channels can be emulated by having some hubbing service make channels to you, while you make a channel to some other hub (i.e. make two channels).  Such an emulation is superior to dual-funding as it allows you to potentially become some alternate route if other routes become congested, letting you earn some small amount; compare this to a single dual-funding channel that, by itself, cannot be used to for routing.\n>>\n>> Another thing is that we can make \"circular superhubs\" if small groups of us cooperate.  The smallest 3-circle superhub has 3 members A B C.  A opens channel to B, B open channels t C, C open channels to A.  Each channel is the same capacity.  If each of you has one out-channel other than on the circular superhub, any of A B C can spend to any node that any of them have an out-channel to.  Similarly, each of you can receive via any in-channel any of you happen to have.  Join a few such small communities and you can be well-connected enough to send and receive reasonably seamlessly to anyone on the network.\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>>> Best regards,\n>>> Cezary\n>>>\n>>> 2018-02-04 10:08 GMT+01:00 ZmnSCPxj <ZmnSCPxj at protonmail.com>:\n>>>\n>>>> Good morning Cezary,\n>>>>> Lets say I would like to receive ln payments. How can I do this, without locking funds on the other side of channel?\n>>>>\n>>>> 1. Do the Blockstream Store route: do it early enough, and people will make channels to you, because, they want to try out Lightning Network quickly.\n>>>>\n>>>> 2. Publish the node and contact details (IP or TOR onion service) and hope people are excited enough about your product to open a channel to you.\n>>>>\n>>>> 3. In all likelihood, some service later will offer deals like \"up to 300mBTC receive for only 1mBTC! At least 3 months channel alive!\" for new upcoming businesses.\n>>>>\n>>>> 4.  Ask a friend to channel to you.\n>>>>\n>>>> Regards,\n>>>> ZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180207/fcc7e1a6/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "channel_reserve_satoshis?",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Cezary Dziemian",
                "ZmnSCPxj"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 23099
        }
    },
    {
        "title": "[Lightning-dev] QuickMaths for Onions: Linear Construction of Sphinx Shared-Secrets",
        "thread_messages": [
            {
                "author": "Conner Fromknecht",
                "date": "2018-02-03T02:20:01",
                "message_text_only": "Hello everyone,\n\nWhile working on some upgrades to our lightning-onion repo [1],\nroasbeef pointed\nout that all of our implementations use a quadratic algorithm to\niteratively apply the intermediate blinding factors.\n\nI spent some time working on a linear algorithm that reduces the total\nnumber of scalar multiplications. Overall, our packet construction\nbenchmarks showed an 8x speedup, from 37ms to 4.5ms, and now uses ~70% less\nmemory. The diff is only ~15 LOC, and thought this would be a\nuseful optimization for our implementations to have. I can make a PR that\nupdates the example source in lightning-rfc if there is interest.\n\nA description, along with the modified source, can be found in my PR to\nlightning-onion [2]. The correctness of the output has been verified\nagainst the (updated) BOLT 4 test vector [3].\n\n[1] https://github.com/lightningnetwork/lightning-onion\n[2] https://github.com/lightningnetwork/lightning-onion/pull/18\n[3] https://github.com/lightningnetwork/lightning-rfc/pull/372\n\nCheers,\nConner\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180203/e0a57a15/attachment.html>"
            },
            {
                "author": "Jim Posen",
                "date": "2018-02-04T09:02:47",
                "message_text_only": "Nice work!\n\nI reread the relevant section in BOLT 4 and it is written in a way to\nsuggest the quadratic time algorithm. I have opened a PR to update the\nrecommendation and reference code:\nhttps://github.com/lightningnetwork/lightning-rfc/pull/374.\n\nOn Fri, Feb 2, 2018 at 6:20 PM, Conner Fromknecht <\nconner at lightning.engineering> wrote:\n\n> Hello everyone,\n>\n> While working on some upgrades to our lightning-onion repo [1], roasbeef pointed\n> out that all of our implementations use a quadratic algorithm to\n> iteratively apply the intermediate blinding factors.\n>\n> I spent some time working on a linear algorithm that reduces the total\n> number of scalar multiplications. Overall, our packet construction\n> benchmarks showed an 8x speedup, from 37ms to 4.5ms, and now uses ~70% less\n> memory. The diff is only ~15 LOC, and thought this would be a\n> useful optimization for our implementations to have. I can make a PR that\n> updates the example source in lightning-rfc if there is interest.\n>\n> A description, along with the modified source, can be found in my PR to\n> lightning-onion [2]. The correctness of the output has been verified\n> against the (updated) BOLT 4 test vector [3].\n>\n> [1] https://github.com/lightningnetwork/lightning-onion\n> [2] https://github.com/lightningnetwork/lightning-onion/pull/18\n> [3] https://github.com/lightningnetwork/lightning-rfc/pull/372\n>\n> Cheers,\n> Conner\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180204/3fcc68ad/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "QuickMaths for Onions: Linear Construction of Sphinx Shared-Secrets",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Jim Posen",
                "Conner Fromknecht"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 2995
        }
    },
    {
        "title": "[Lightning-dev] An Idea to Improve Connectivity of the Graph",
        "thread_messages": [
            {
                "author": "Abhishek Sharma",
                "date": "2018-02-04T18:21:48",
                "message_text_only": "Hello all,\nI am not sure if this is the right place for this, but I have been thinking\nabout the lightning network and how it could be modified so that fewer\ntotal channels would need to be open. I had the idea for a specific kind of\ntransaction, in which three parties commit their funds all at once, and are\nable to move their funds between the three open channels between them. I\nwill give a rough overview of my idea and give an example that I think\nillustrates how it could improve users' ability to route their\ntransactions.\n\nSay that three parties, A, B, and C, create a special commitment\ntransaction on the network that creates three open channels between each of\nthem with a pre-specified balance in each channel. Now, these channels\nwould be lightning network channels, and so the three of them could\ntransact with each other and modify balances in their individual channels\nat will. However, this special agreement between the three of them also has\nthe property than they can move their funds *between *channels, provided\nthey have the permission of the counterparty to the channel they move their\nfunds from, and then presents this to the other counterparty to show that\nfunds have been moved.\n\n1.) A, B, and C each create a commitment transaction, committing .5 BTC (3\nBTC in total) on their end of each of their channels.\n2.) A, B, and C transact normally using the lightning protocol. After some\namount of time, the channel balances are as follows:\nchannel AB: A - 0.75, B - 0.25\nchannel BC: B - 0.4, C - 0.6,\nchannel AC: A - 0, C: 1.0\n3.) A would like to send .5 BTC to C, however she does not have enough\nfunds in that channel to do so. It's also not possible for her to route her\ntransaction through B, as B only has .4 in his channel with C. However, she\ndoes have those funds in her channel with B, and so asks for B's permission\n(in the form of a signed balance state that includes the hash of the\nprevious balance), to move those funds over to her account with C. She gets\nthis signed slip from B, and then presents it to C.\n4.) A, B, and C continue trading on their update balances.\n5.) When they wish to close out their channels, they all post the last\nsigned balance statements each of them has.\nSay, for example, A and B were to collude and trade on their old balance\n(of .75 and .25) after Bsigning the statement that A was 'moving' funds to\nC. If A and C were trading on their new balances, C has proof of both A and\nB's collusion, and she can present the signed slip which said that A was\nmoving funds to AC and so the total balance on A and B's channel should've\nsummed to 0.5. In this event, All funds in all three channels are forfeited\nto C.\n\nI believe this works because, in virtue of being able to make inferences\nbased on her own channel balances, C always knows (if she is following the\nprotocol) exactly how much should be in channel AB. and can prove this. If\nthere were 4 parties, C couldn't prove on her own that some set of parties\ncolluded to trade on an old balance.\n\nNow, I'll show why such a mechanism can be useful.\nNow, assume that there are parties A, B, C, D, and E, and the following\nchannels and balances exist (with the ones marked by a * part of the\nspecial three-way commitment):\nAB*: A - 1.0, B - 0\nBC*: B - 0, C - 1.0\nAC*: A - 0, C - 1.0\nAD: D - 1.0, A - 0\nCE: C - 1.0, E - 0\nNow suppose D wishes to send E 1.0 BTC. With the current channel structure,\nthis isn't possible in lightning without opening a new channel and waiting\nfor the network to verify it. However, A can ask B to move her 1.0 in\nchannel AB to channel AC (with maybe a very nominal fee to incentivise\nthis), thereby enabling D to route 1.0 BTC from A to C and finally to E.\n\nI would appreciate your feedback on this idea and any questions you may\nhave for further explanation.\n\nBest Regards,\nAbhishek Sharma\nBrown University\nComputer Science '18\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180204/ca09c17a/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-02-04T21:41:10",
                "message_text_only": "Good morning Abhishek Sharma,\n\nWhile the goal of the idea is good, can you provide more details on the Bitcoin transactions?  Presumably the on-chain anchor is a 3-of-3 multisig UTXO, what is the transaction that spends that?  What do Lightning commitment transactions spend?  Can you draw a graph of transaction chains that ensure correct operation of this idea?\n\nHave you seen Burchert-Decker-Wattenhofer Channel Factories? https://www.tik.ee.ethz.ch/file/a20a865ce40d40c8f942cf206a7cba96/Scalable_Funding_Of_Blockchain_Micropayment_Networks%20(1).pdf What is the difference between your idea and the Burchert-Decker-Wattenhofer Channel Factories?\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n-------- Original Message --------\nOn February 4, 2018 6:21 PM, Abhishek Sharma <abhisharm at gmail.com> wrote:\n\n> Hello all,\n> I am not sure if this is the right place for this, but I have been thinking about the lightning network and how it could be modified so that fewer total channels would need to be open. I had the idea for a specific kind of transaction, in which three parties commit their funds all at once, and are able to move their funds between the three open channels between them. I will give a rough overview of my idea and give an example that I think illustrates how it could improve users' ability to route their transactions.\n>\n> Say that three parties, A, B, and C, create a special commitment transaction on the network that creates three open channels between each of them with a pre-specified balance in each channel. Now, these channels would be lightning network channels, and so the three of them could transact with each other and modify balances in their individual channels at will. However, this special agreement between the three of them also has the property than they can move their funds between channels, provided they have the permission of the counterparty to the channel they move their funds from, and then presents this to the other counterparty to show that funds have been moved.\n>\n> 1.) A, B, and C each create a commitment transaction, committing .5 BTC (3 BTC in total) on their end of each of their channels.\n> 2.) A, B, and C transact normally using the lightning protocol. After some amount of time, the channel balances are as follows:\n> channel AB: A - 0.75, B - 0.25\n> channel BC: B - 0.4, C - 0.6,\n> channel AC: A - 0, C: 1.0\n> 3.) A would like to send .5 BTC to C, however she does not have enough funds in that channel to do so. It's also not possible for her to route her transaction through B, as B only has .4 in his channel with C. However, she does have those funds in her channel with B, and so asks for B's permission (in the form of a signed balance state that includes the hash of the previous balance), to move those funds over to her account with C. She gets this signed slip from B, and then presents it to C.\n> 4.) A, B, and C continue trading on their update balances.\n> 5.) When they wish to close out their channels, they all post the last signed balance statements each of them has.\n> Say, for example, A and B were to collude and trade on their old balance (of .75 and .25) after Bsigning the statement that A was 'moving' funds to C. If A and C were trading on their new balances, C has proof of both A and B's collusion, and she can present the signed slip which said that A was moving funds to AC and so the total balance on A and B's channel should've summed to 0.5. In this event, All funds in all three channels are forfeited to C.\n>\n> I believe this works because, in virtue of being able to make inferences based on her own channel balances, C always knows (if she is following the protocol) exactly how much should be in channel AB. and can prove this. If there were 4 parties, C couldn't prove on her own that some set of parties colluded to trade on an old balance.\n>\n> Now, I'll show why such a mechanism can be useful.\n> Now, assume that there are parties A, B, C, D, and E, and the following channels and balances exist (with the ones marked by a * part of the special three-way commitment):\n> AB*: A - 1.0, B - 0\n> BC*: B - 0, C - 1.0\n> AC*: A - 0, C - 1.0\n> AD: D - 1.0, A - 0\n> CE: C - 1.0, E - 0\n> Now suppose D wishes to send E 1.0 BTC. With the current channel structure, this isn't possible in lightning without opening a new channel and waiting for the network to verify it. However, A can ask B to move her 1.0 in channel AB to channel AC (with maybe a very nominal fee to incentivise this), thereby enabling D to route 1.0 BTC from A to C and finally to E.\n>\n> I would appreciate your feedback on this idea and any questions you may have for further explanation.\n>\n> Best Regards,\n> Abhishek Sharma\n> Brown University\n> Computer Science '18\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180204/7cf0f75c/attachment.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-02-05T13:21:54",
                "message_text_only": "I'd also like to point out that the way we do state invalidations in\nLightning is not really suited for multi-party negotiations beyond 2\nparties. The number of potential reactions to a party cheating grows\nexponentially in the number of parties in the contract, which is the\nreason the Channel Factories paper relies on the Duplex Micropayment\nChannel construction instead of the retaliation construction in LN.\n\nFurthermore I'm also not exactly clear how we could retaliate\nmisbehavior on one channel in the other channel if they are logically\nindependent. Without this you could potentially re-allocate your funds\nto another channel and then attempt to cheat, without it costing your\nfunds.\n\nCheers,\nChristian\n\nZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\nwrites:\n\n> Good morning Abhishek Sharma,\n>\n> While the goal of the idea is good, can you provide more details on the Bitcoin transactions?  Presumably the on-chain anchor is a 3-of-3 multisig UTXO, what is the transaction that spends that?  What do Lightning commitment transactions spend?  Can you draw a graph of transaction chains that ensure correct operation of this idea?\n>\n> Have you seen Burchert-Decker-Wattenhofer Channel Factories? https://www.tik.ee.ethz.ch/file/a20a865ce40d40c8f942cf206a7cba96/Scalable_Funding_Of_Blockchain_Micropayment_Networks%20(1).pdf What is the difference between your idea and the Burchert-Decker-Wattenhofer Channel Factories?\n>\n> Regards,\n> ZmnSCPxj\n>\n> Sent with [ProtonMail](https://protonmail.com) Secure Email.\n>\n> -------- Original Message --------\n> On February 4, 2018 6:21 PM, Abhishek Sharma <abhisharm at gmail.com> wrote:\n>\n>> Hello all,\n>> I am not sure if this is the right place for this, but I have been thinking about the lightning network and how it could be modified so that fewer total channels would need to be open. I had the idea for a specific kind of transaction, in which three parties commit their funds all at once, and are able to move their funds between the three open channels between them. I will give a rough overview of my idea and give an example that I think illustrates how it could improve users' ability to route their transactions.\n>>\n>> Say that three parties, A, B, and C, create a special commitment transaction on the network that creates three open channels between each of them with a pre-specified balance in each channel. Now, these channels would be lightning network channels, and so the three of them could transact with each other and modify balances in their individual channels at will. However, this special agreement between the three of them also has the property than they can move their funds between channels, provided they have the permission of the counterparty to the channel they move their funds from, and then presents this to the other counterparty to show that funds have been moved.\n>>\n>> 1.) A, B, and C each create a commitment transaction, committing .5 BTC (3 BTC in total) on their end of each of their channels.\n>> 2.) A, B, and C transact normally using the lightning protocol. After some amount of time, the channel balances are as follows:\n>> channel AB: A - 0.75, B - 0.25\n>> channel BC: B - 0.4, C - 0.6,\n>> channel AC: A - 0, C: 1.0\n>> 3.) A would like to send .5 BTC to C, however she does not have enough funds in that channel to do so. It's also not possible for her to route her transaction through B, as B only has .4 in his channel with C. However, she does have those funds in her channel with B, and so asks for B's permission (in the form of a signed balance state that includes the hash of the previous balance), to move those funds over to her account with C. She gets this signed slip from B, and then presents it to C.\n>> 4.) A, B, and C continue trading on their update balances.\n>> 5.) When they wish to close out their channels, they all post the last signed balance statements each of them has.\n>> Say, for example, A and B were to collude and trade on their old balance (of .75 and .25) after Bsigning the statement that A was 'moving' funds to C. If A and C were trading on their new balances, C has proof of both A and B's collusion, and she can present the signed slip which said that A was moving funds to AC and so the total balance on A and B's channel should've summed to 0.5. In this event, All funds in all three channels are forfeited to C.\n>>\n>> I believe this works because, in virtue of being able to make inferences based on her own channel balances, C always knows (if she is following the protocol) exactly how much should be in channel AB. and can prove this. If there were 4 parties, C couldn't prove on her own that some set of parties colluded to trade on an old balance.\n>>\n>> Now, I'll show why such a mechanism can be useful.\n>> Now, assume that there are parties A, B, C, D, and E, and the following channels and balances exist (with the ones marked by a * part of the special three-way commitment):\n>> AB*: A - 1.0, B - 0\n>> BC*: B - 0, C - 1.0\n>> AC*: A - 0, C - 1.0\n>> AD: D - 1.0, A - 0\n>> CE: C - 1.0, E - 0\n>> Now suppose D wishes to send E 1.0 BTC. With the current channel structure, this isn't possible in lightning without opening a new channel and waiting for the network to verify it. However, A can ask B to move her 1.0 in channel AB to channel AC (with maybe a very nominal fee to incentivise this), thereby enabling D to route 1.0 BTC from A to C and finally to E.\n>>\n>> I would appreciate your feedback on this idea and any questions you may have for further explanation.\n>>\n>> Best Regards,\n>> Abhishek Sharma\n>> Brown University\n>> Computer Science '18\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            }
        ],
        "thread_summary": {
            "title": "An Idea to Improve Connectivity of the Graph",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Decker",
                "Abhishek Sharma",
                "ZmnSCPxj"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 14825
        }
    },
    {
        "title": "[Lightning-dev] Manual channel funding",
        "thread_messages": [
            {
                "author": "Alex P",
                "date": "2018-02-05T11:50:12",
                "message_text_only": "Hello!\n\nAt the moment there is no option to choose outputs to fund channel\nmanually. Moreover, there is no way to fund channel with \"all available\nfunds\". That's weird, I set up a channel and tried to use \"all I ave\",\nand got is a transaction on blockchain with the output for 980 SAT:\n\nhttps://chain.so/tx/BTC/bc144507a85900d0fc0318cc54a4bcb29542bfcd543e7acf9f00061f03c997e5\n\nTo my opinions at least there should be an option \"take fee from funding\namount\", and may be an option to choose exact outputs to spend.\n\nAny ideas?"
            },
            {
                "author": "Christian Decker",
                "date": "2018-02-05T13:15:28",
                "message_text_only": "Hi Alex,\n\nnot sure what the context of your question. It doesn't appear to be\nprotocol related, but rather an issue with the interface that the\nimplementations expose. If that is the case, I'd suggest filing an issue\nwith the respective implementation.\n\nCheers,\nChristian\n\nAlex P <ap at coinomat.com> writes:\n> Hello!\n>\n> At the moment there is no option to choose outputs to fund channel\n> manually. Moreover, there is no way to fund channel with \"all available\n> funds\". That's weird, I set up a channel and tried to use \"all I ave\",\n> and got is a transaction on blockchain with the output for 980 SAT:\n>\n> https://chain.so/tx/BTC/bc144507a85900d0fc0318cc54a4bcb29542bfcd543e7acf9f00061f03c997e5\n>\n> To my opinions at least there should be an option \"take fee from funding\n> amount\", and may be an option to choose exact outputs to spend.\n>\n> Any ideas?\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            }
        ],
        "thread_summary": {
            "title": "Manual channel funding",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Alex P",
                "Christian Decker"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 1576
        }
    },
    {
        "title": "[Lightning-dev] Improving the initial gossip sync",
        "thread_messages": [
            {
                "author": "Christian Decker",
                "date": "2018-02-05T13:02:38",
                "message_text_only": "Hi everyone\n\nWhen we started drafting the specification we decided to postpone the\ntopology syncronization mechanism until we have a better picture of the\nkind of loads that are to be expected in the network, e.g., churn and\nupdate rate, and instead implement a trivial gossip protocol to\ndistribute the topology updates. This includes the dreaded initial\nsynchonization dump that has caused some issues lately to all\nimplementations, given that we dump several thousands of updates, that\nmay require block metadata (short channel ID to txid conversion) lookup\nand a UTXO lookup (is this channel still active?).\n\nDuring the last call we decided to go for an incremental improvement,\nrather than a full synchronization mechanism (IBLT, rsync, ...). So\nlet's discuss how that improvement could look like.\n\nIn the following I'll describe a very simple extension based on a\nhighwater mark for updates, and I think Pierre has a good proposal of\nhis own, that I'll let him explain.\n\nWe already have the `initial_routing_sync` feature bit, which (if\nimplemented) allows disabling the initial gossip synchronization, and\nonyl forwarding newly received gossip messages. I propose adding a new\nfeature bit (6, i.e., bitmask 0x40) indicating that the `init` message\nis extended with a u32 `gossip_timestamp`, interpreted as a UNIX\ntimestamp. The `gossip_timestamp` is the lowest `channel_update` and\n`node_announcement` timestamp the recipient is supposed to send, any\nolder update or announcement is to be skipped. This allows the `init`\nsender to specify how far back the initial synchronization should go.\n\nThe logic to forward announcements thus follows this outline:\n\n - Set `gossip_timestamp` for this peer\n - Iterate through all `channel_update`s that have a timestamp that is\n   newer than the `gossip_timestamp` (skipping replaced ones as per BOLT\n   07)\n - For each `channel_update` fetch the corresponding\n   `channel_announcement` and the endpoints `node_announcement`.\n - Forward the messages in the correct order, i.e.,\n - `channel_announcement`, then `channel_update`, and then `node_announcement`\n\nThe feature bit is even, meaning that it is required from the peer,\nsince we extend the `init` message itself, and a peer that does not\nsupport this feature would be unable to parse any future extensions to\nthe `init` message. Alternatively we could create a new\n`set_gossip_timestamp` message that is only sent if both endpoints\nsupport this proposal, but that could result in duplicate messages being\ndelivered between the `init` and the `set_gossip_timestamp` message and\nit'd require additional messages.\n\n`gossip_timestamp` is rather flexible, since it allows the sender to\nspecify its most recent update if it believes it is completely caught\nup, or send a slightly older timestamp to have some overlap for\ncurrently broadcasting updates, or send the timestamp the node was last\nconnected with the network, in the case of prolonged downtime.\n\nThe reason I'm using timestamp and not the blockheight in the short\nchannel ID is that we already use the timestamp for pruning. In the\nblockheight based timestamp we might ignore channels that were created,\nthen not announced or forgotten, and then later came back and are now\nstable.\n\nI hope this rather simple proposal is sufficient to fix the short-term\nissues we are facing with the initial sync, while we wait for a real\nsync protocol. It is definitely not meant to allow perfect\nsynchronization of the topology between peers, but then again I don't\nbelieve that is strictly necessary to make the routing successful.\n\nPlease let me know what you think, and I'd love to discuss Pierre's\nproposal as well.\n\nCheers,\nChristian"
            },
            {
                "author": "Fabrice Drouin",
                "date": "2018-02-05T15:08:22",
                "message_text_only": "Hi,\n\nOn 5 February 2018 at 14:02, Christian Decker\n<decker.christian at gmail.com> wrote:\n> Hi everyone\n>\n> The feature bit is even, meaning that it is required from the peer,\n> since we extend the `init` message itself, and a peer that does not\n> support this feature would be unable to parse any future extensions to\n> the `init` message. Alternatively we could create a new\n> `set_gossip_timestamp` message that is only sent if both endpoints\n> support this proposal, but that could result in duplicate messages being\n> delivered between the `init` and the `set_gossip_timestamp` message and\n> it'd require additional messages.\n\nWe chose the other aproach and propose to use an optional feature\n\n> The reason I'm using timestamp and not the blockheight in the short\n> channel ID is that we already use the timestamp for pruning. In the\n> blockheight based timestamp we might ignore channels that were created,\n> then not announced or forgotten, and then later came back and are now\n> stable.\n\nJust to be clear, you propose to use the timestamp of the most recent\nchannel updates to filter\nthe associated channel announcements ?\n\n> I hope this rather simple proposal is sufficient to fix the short-term\n> issues we are facing with the initial sync, while we wait for a real\n> sync protocol. It is definitely not meant to allow perfect\n> synchronization of the topology between peers, but then again I don't\n> believe that is strictly necessary to make the routing successful.\n>\n> Please let me know what you think, and I'd love to discuss Pierre's\n> proposal as well.\n>\n> Cheers,\n> Christian\n\nOur idea is to group channel announcements by \"buckets\", create a\nfilter for each bucket, exchange and use them to filter out channel\nannouncements.\n\nWe would add a new `use_channel_announcement_filters` optional feature\nbit (7 for example), and a new `channel_announcement_filters` message.\n\nWhen a node that supports channel announcement filters receives an\n`init` message with the `use_channel_announcement_filters` bit set, it\nsends back its channel filters.\n\nWhen a node that supports channel announcement filters receives\na`channel_announcement_filters` message, it uses it to filter channel\nannouncements (and, implicitly ,channel updates) before sending them.\n\nThe filters we have in mind are simple:\n- Sort announcements by short channel id\n- Compute a marker height, which is `144 * ((now - 7 * 144) / 144)`\n(we round to multiples of 144 to make sync easier)\n- Group channel announcements that were created before this marker by\ngroups of 144 blocks\n- Group channel announcements that were created after this marker by\ngroups of 1 block\n- For each group, sort and concatenate all channel announcements short\nchannel ids and hash the result (we could use sha256, or the first 16\nbytes of the sha256 hash)\n\nThe new `channel_announcement_filters` would then be a list of\n(height, hash) pairs ordered by increasing heights.\n\nThis implies that implementation can easily sort announcements by\nshort channel id, which should not be very difficult.\nAn additional step could be to send all short channel ids for all\ngroups for which the group hash did not match. Alternatively we could\nuse smarter filters\n\nThe use case we have in mind is mobile nodes, or more generally nodes\nwhich are often offline and need to resync very often.\n\nCheers,\nFabrice"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-02-07T00:24:02",
                "message_text_only": "Hi Y'all,\n\nDefinitely agree that we need a stop-gap solution to fix the naive table\ndump on initial connect. I've been sketching out some fancier stuff, but we\nwould need time to properly tune the fanciness, and I'm inclined to get out\na stop-gap solution asap.  On testnet, the zombie churn is pretty bad atm.\nIt results in uneasily wasted bandwidth as the churn is now almost constant.\nThere still exist some very old testnet nodes our there it seems. Beyond the\nzombie churn, with the size of the testnet graph, we're forced to send tens\nof thousands of messages (even if we're already fully synced) upon initial\nconnect, so very wasteful over all.\n\nSo I think the primary distinction between y'alls proposals is that\ncdecker's proposal focuses on eventually synchronizing all the set of\n_updates_, while Fabrice's proposal cares *only* about the newly created\nchannels. It only cares about new channels as the rationale is that if once\ntries to route over a channel with a state channel update for it, then\nyou'll get an error with the latest update encapsulated.\n\nChristian wrote:\n> I propose adding a new feature bit (6, i.e., bitmask 0x40) indicating that\n> the `init` message is extended with a u32 `gossip_timestamp`, interpreted\nas\n> a UNIX timestamp.\n\nAs the `init` message solely contains two variably sized byte slices, I\ndon't think we can actually safely extend it in this manner. Instead, a new\nmessage is required, where the semantics of the feature bit _require_ the\nother side to send it directly after receiving the `init` message from the\nother side.\n\nAside from that, overall I like the simplicity of the protocol: it\neliminates both the zombie churn, and the intensive initial connection graph\ndump without any extra messaging overhead (for reconciliation, etc).\n\nFabrice wrote:\n> Just to be clear, you propose to use the timestamp of the most recent\n> channel updates to filter the associated channel announcements ?\n\nI think he's actually proposing just a general update horizon in which\nvertexes+edges with a lower time stamp just shouldn't be set at all. In the\ncase of an old zombie channel which was resurrected, it would eventually be\nre-propagated as the node on either end of the channel should broadcast a\nfresh update along with the original chan ann.\n\n> When a node that supports channel announcement filters receives\n> a`channel_announcement_filters` message, it uses it to filter channel\n> announcements (and, implicitly ,channel updates) before sending them\n\nThis seems to assume that both nodes have a strongly synchronized view of\nthe network. Otherwise, they'll fall back to sending everything that went on\nduring the entire epoch regularly. It also doesn't address the zombie churn\nissue as they may eventually send you very old channels you'll have to deal\nwith (or discard).\n\n> The use case we have in mind is mobile nodes, or more generally nodes\n> which are often offline and need to resync very often.\n\nHow far back would this go? Weeks, months, years?\n\nFWIW this approach optimizes for just learning of new channels instead of\nlearning of the freshest state you haven't yet seen.\n\n\n-- Laolu\n\n\nOn Mon, Feb 5, 2018 at 7:08 AM Fabrice Drouin <fabrice.drouin at acinq.fr>\nwrote:\n\n> Hi,\n>\n> On 5 February 2018 at 14:02, Christian Decker\n> <decker.christian at gmail.com> wrote:\n> > Hi everyone\n> >\n> > The feature bit is even, meaning that it is required from the peer,\n> > since we extend the `init` message itself, and a peer that does not\n> > support this feature would be unable to parse any future extensions to\n> > the `init` message. Alternatively we could create a new\n> > `set_gossip_timestamp` message that is only sent if both endpoints\n> > support this proposal, but that could result in duplicate messages being\n> > delivered between the `init` and the `set_gossip_timestamp` message and\n> > it'd require additional messages.\n>\n> We chose the other aproach and propose to use an optional feature\n>\n> > The reason I'm using timestamp and not the blockheight in the short\n> > channel ID is that we already use the timestamp for pruning. In the\n> > blockheight based timestamp we might ignore channels that were created,\n> > then not announced or forgotten, and then later came back and are now\n> > stable.\n>\n> Just to be clear, you propose to use the timestamp of the most recent\n> channel updates to filter\n> the associated channel announcements ?\n>\n> > I hope this rather simple proposal is sufficient to fix the short-term\n> > issues we are facing with the initial sync, while we wait for a real\n> > sync protocol. It is definitely not meant to allow perfect\n> > synchronization of the topology between peers, but then again I don't\n> > believe that is strictly necessary to make the routing successful.\n> >\n> > Please let me know what you think, and I'd love to discuss Pierre's\n> > proposal as well.\n> >\n> > Cheers,\n> > Christian\n>\n> Our idea is to group channel announcements by \"buckets\", create a\n> filter for each bucket, exchange and use them to filter out channel\n> announcements.\n>\n> We would add a new `use_channel_announcement_filters` optional feature\n> bit (7 for example), and a new `channel_announcement_filters` message.\n>\n> When a node that supports channel announcement filters receives an\n> `init` message with the `use_channel_announcement_filters` bit set, it\n> sends back its channel filters.\n>\n> When a node that supports channel announcement filters receives\n> a`channel_announcement_filters` message, it uses it to filter channel\n> announcements (and, implicitly ,channel updates) before sending them.\n>\n> The filters we have in mind are simple:\n> - Sort announcements by short channel id\n> - Compute a marker height, which is `144 * ((now - 7 * 144) / 144)`\n> (we round to multiples of 144 to make sync easier)\n> - Group channel announcements that were created before this marker by\n> groups of 144 blocks\n> - Group channel announcements that were created after this marker by\n> groups of 1 block\n> - For each group, sort and concatenate all channel announcements short\n> channel ids and hash the result (we could use sha256, or the first 16\n> bytes of the sha256 hash)\n>\n> The new `channel_announcement_filters` would then be a list of\n> (height, hash) pairs ordered by increasing heights.\n>\n> This implies that implementation can easily sort announcements by\n> short channel id, which should not be very difficult.\n> An additional step could be to send all short channel ids for all\n> groups for which the group hash did not match. Alternatively we could\n> use smarter filters\n>\n> The use case we have in mind is mobile nodes, or more generally nodes\n> which are often offline and need to resync very often.\n>\n> Cheers,\n> Fabrice\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180207/2ea76f0a/attachment-0001.html>"
            },
            {
                "author": "Fabrice Drouin",
                "date": "2018-02-07T17:50:19",
                "message_text_only": "Hi,\n\nSuppose you partition nodes into 3 generic roles:\n- payers: they mostly send payments, are typically small and operated\nby end users, and are offline quite a lot\n- relayers: they mostly relay payments, and would be online most of\nthe time (if they're too unreliable other nodes will eventually close\ntheir channels with them)\n- payees: they mostly receive payments, how often they can be online\nis directly link to their particular mode of operations (since you\nneed to be online to receive payments)\n\nOf course most nodes would play more or less all roles. However,\nmobile nodes would probably be mostly \"payers\", and they have specific\nproperties:\n- if they don't relay payments they don't have to be announced. There\ncould be millions of mobile nodes that would have no impact on the\nsize of the routing table\n- it does not impact the network when they're offline\n- but they need an accurate routing table. This is very different from\nnodes who mostly relay or accept payements\n- they would be connected to a very small number of nodes\n- they would typically be online for just  a few hours every day, but\ncould be stopped/paused/restarted many times a day\n\nLaolu wrote:\n> So I think the primary distinction between y'alls proposals is that\n> cdecker's proposal focuses on eventually synchronizing all the set of\n> _updates_, while Fabrice's proposal cares *only* about the newly created\n> channels. It only cares about new channels as the rationale is that if once\n> tries to route over a channel with a state channel update for it, then\n> you'll get an error with the latest update encapsulated.\n\nIf you have one filter per day and they don't match (because your peer\nhas channels that you missed, or\n have been closed and you were not aware of it) then you will receive\nall channel announcements for\nthis particular day, and the associated updates\n\nLaolu wrote:\n> I think he's actually proposing just a general update horizon in which\n> vertexes+edges with a lower time stamp just shouldn't be set at all. In the\n> case of an old zombie channel which was resurrected, it would eventually be\n> re-propagated as the node on either end of the channel should broadcast a\n> fresh update along with the original chan ann.\n\nYes but it could take a long time. It may be worse on testnet since it\nseems that nodes\ndon't change their fees very often. \"Payer nodes\" need a good routing\ntable (as opposed\nto \"relayers\" which could work without one if they never initiate payments)\n\nLaolu wrote:\n> This seems to assume that both nodes have a strongly synchronized view of\n> the network. Otherwise, they'll fall back to sending everything that went on\n> during the entire epoch regularly. It also doesn't address the zombie churn\n> issue as they may eventually send you very old channels you'll have to deal\n> with (or discard).\n\nYes I agree that for nodes which have connections to a lot of peers,\nstrongly synchronized routing tables is\nharder to achieve since a small change may invalidate an entire\nbucket. Real queryable filters would be much\nbetter, but worst case scenario is we've sent an additionnal 30 Kb or\no of sync messages.\n(A very naive filter would be sort + pack all short ids for example)\n\nBut we focus on nodes which are connected to a very small number of\npeers, and in this particular\ncase it is not an unrealistic expectation.\nWe have built a prototype and on testnet it works fairly well. I also\nfound nodes which have no direct\nchannel betweem them but produce the same filters for 75% of the\nbuckets (\"produce\" here means\nthat I opened a simple gossip connection to them, got their routing\ntable and used it to generate filters).\n\n\nLaolu wrote:\n> How far back would this go? Weeks, months, years?\nSince forever :)\nOne filter per day for all annoucements that are older than now - 1\nweek (modulo 144)\nOne filter per block for recent announcements\n\n>\n> FWIW this approach optimizes for just learning of new channels instead of\n> learning of the freshest state you haven't yet seen.\n\nI'd say it optimizes the case where you are connected to very few\npeers, and are online a few times every day (?)\n\n>\n> -- Laolu\n>\n>\n> On Mon, Feb 5, 2018 at 7:08 AM Fabrice Drouin <fabrice.drouin at acinq.fr>\n> wrote:\n>>\n>> Hi,\n>>\n>> On 5 February 2018 at 14:02, Christian Decker\n>> <decker.christian at gmail.com> wrote:\n>> > Hi everyone\n>> >\n>> > The feature bit is even, meaning that it is required from the peer,\n>> > since we extend the `init` message itself, and a peer that does not\n>> > support this feature would be unable to parse any future extensions to\n>> > the `init` message. Alternatively we could create a new\n>> > `set_gossip_timestamp` message that is only sent if both endpoints\n>> > support this proposal, but that could result in duplicate messages being\n>> > delivered between the `init` and the `set_gossip_timestamp` message and\n>> > it'd require additional messages.\n>>\n>> We chose the other aproach and propose to use an optional feature\n>>\n>> > The reason I'm using timestamp and not the blockheight in the short\n>> > channel ID is that we already use the timestamp for pruning. In the\n>> > blockheight based timestamp we might ignore channels that were created,\n>> > then not announced or forgotten, and then later came back and are now\n>> > stable.\n>>\n>> Just to be clear, you propose to use the timestamp of the most recent\n>> channel updates to filter\n>> the associated channel announcements ?\n>>\n>> > I hope this rather simple proposal is sufficient to fix the short-term\n>> > issues we are facing with the initial sync, while we wait for a real\n>> > sync protocol. It is definitely not meant to allow perfect\n>> > synchronization of the topology between peers, but then again I don't\n>> > believe that is strictly necessary to make the routing successful.\n>> >\n>> > Please let me know what you think, and I'd love to discuss Pierre's\n>> > proposal as well.\n>> >\n>> > Cheers,\n>> > Christian\n>>\n>> Our idea is to group channel announcements by \"buckets\", create a\n>> filter for each bucket, exchange and use them to filter out channel\n>> announcements.\n>>\n>> We would add a new `use_channel_announcement_filters` optional feature\n>> bit (7 for example), and a new `channel_announcement_filters` message.\n>>\n>> When a node that supports channel announcement filters receives an\n>> `init` message with the `use_channel_announcement_filters` bit set, it\n>> sends back its channel filters.\n>>\n>> When a node that supports channel announcement filters receives\n>> a`channel_announcement_filters` message, it uses it to filter channel\n>> announcements (and, implicitly ,channel updates) before sending them.\n>>\n>> The filters we have in mind are simple:\n>> - Sort announcements by short channel id\n>> - Compute a marker height, which is `144 * ((now - 7 * 144) / 144)`\n>> (we round to multiples of 144 to make sync easier)\n>> - Group channel announcements that were created before this marker by\n>> groups of 144 blocks\n>> - Group channel announcements that were created after this marker by\n>> groups of 1 block\n>> - For each group, sort and concatenate all channel announcements short\n>> channel ids and hash the result (we could use sha256, or the first 16\n>> bytes of the sha256 hash)\n>>\n>> The new `channel_announcement_filters` would then be a list of\n>> (height, hash) pairs ordered by increasing heights.\n>>\n>> This implies that implementation can easily sort announcements by\n>> short channel id, which should not be very difficult.\n>> An additional step could be to send all short channel ids for all\n>> groups for which the group hash did not match. Alternatively we could\n>> use smarter filters\n>>\n>> The use case we have in mind is mobile nodes, or more generally nodes\n>> which are often offline and need to resync very often.\n>>\n>> Cheers,\n>> Fabrice\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Jim Posen",
                "date": "2018-02-07T21:27:05",
                "message_text_only": "I like Christian's proposal of adding a simple announcement cutoff\ntimestamp with the intention of designing something more sophisticated\ngiven more time.\n\nI prefer the approach of having an optional feature bit signalling that a\n`set_gossip_timestamp` message must be sent immediately after `init`, as\nLaolu suggested. This way it doesn't conflict with and other possible\nhandshake extensions.\n\n\nOn Feb 7, 2018 9:50 AM, \"Fabrice Drouin\" <fabrice.drouin at acinq.fr> wrote:\n\nHi,\n\nSuppose you partition nodes into 3 generic roles:\n- payers: they mostly send payments, are typically small and operated\nby end users, and are offline quite a lot\n- relayers: they mostly relay payments, and would be online most of\nthe time (if they're too unreliable other nodes will eventually close\ntheir channels with them)\n- payees: they mostly receive payments, how often they can be online\nis directly link to their particular mode of operations (since you\nneed to be online to receive payments)\n\nOf course most nodes would play more or less all roles. However,\nmobile nodes would probably be mostly \"payers\", and they have specific\nproperties:\n- if they don't relay payments they don't have to be announced. There\ncould be millions of mobile nodes that would have no impact on the\nsize of the routing table\n- it does not impact the network when they're offline\n- but they need an accurate routing table. This is very different from\nnodes who mostly relay or accept payements\n- they would be connected to a very small number of nodes\n- they would typically be online for just  a few hours every day, but\ncould be stopped/paused/restarted many times a day\n\nLaolu wrote:\n> So I think the primary distinction between y'alls proposals is that\n> cdecker's proposal focuses on eventually synchronizing all the set of\n> _updates_, while Fabrice's proposal cares *only* about the newly created\n> channels. It only cares about new channels as the rationale is that if\nonce\n> tries to route over a channel with a state channel update for it, then\n> you'll get an error with the latest update encapsulated.\n\nIf you have one filter per day and they don't match (because your peer\nhas channels that you missed, or\n have been closed and you were not aware of it) then you will receive\nall channel announcements for\nthis particular day, and the associated updates\n\nLaolu wrote:\n> I think he's actually proposing just a general update horizon in which\n> vertexes+edges with a lower time stamp just shouldn't be set at all. In\nthe\n> case of an old zombie channel which was resurrected, it would eventually\nbe\n> re-propagated as the node on either end of the channel should broadcast a\n> fresh update along with the original chan ann.\n\nYes but it could take a long time. It may be worse on testnet since it\nseems that nodes\ndon't change their fees very often. \"Payer nodes\" need a good routing\ntable (as opposed\nto \"relayers\" which could work without one if they never initiate payments)\n\nLaolu wrote:\n> This seems to assume that both nodes have a strongly synchronized view of\n> the network. Otherwise, they'll fall back to sending everything that went\non\n> during the entire epoch regularly. It also doesn't address the zombie\nchurn\n> issue as they may eventually send you very old channels you'll have to\ndeal\n> with (or discard).\n\nYes I agree that for nodes which have connections to a lot of peers,\nstrongly synchronized routing tables is\nharder to achieve since a small change may invalidate an entire\nbucket. Real queryable filters would be much\nbetter, but worst case scenario is we've sent an additionnal 30 Kb or\no of sync messages.\n(A very naive filter would be sort + pack all short ids for example)\n\nBut we focus on nodes which are connected to a very small number of\npeers, and in this particular\ncase it is not an unrealistic expectation.\nWe have built a prototype and on testnet it works fairly well. I also\nfound nodes which have no direct\nchannel betweem them but produce the same filters for 75% of the\nbuckets (\"produce\" here means\nthat I opened a simple gossip connection to them, got their routing\ntable and used it to generate filters).\n\n\nLaolu wrote:\n> How far back would this go? Weeks, months, years?\nSince forever :)\nOne filter per day for all annoucements that are older than now - 1\nweek (modulo 144)\nOne filter per block for recent announcements\n\n>\n> FWIW this approach optimizes for just learning of new channels instead of\n> learning of the freshest state you haven't yet seen.\n\nI'd say it optimizes the case where you are connected to very few\npeers, and are online a few times every day (?)\n\n>\n> -- Laolu\n>\n>\n> On Mon, Feb 5, 2018 at 7:08 AM Fabrice Drouin <fabrice.drouin at acinq.fr>\n> wrote:\n>>\n>> Hi,\n>>\n>> On 5 February 2018 at 14:02, Christian Decker\n>> <decker.christian at gmail.com> wrote:\n>> > Hi everyone\n>> >\n>> > The feature bit is even, meaning that it is required from the peer,\n>> > since we extend the `init` message itself, and a peer that does not\n>> > support this feature would be unable to parse any future extensions to\n>> > the `init` message. Alternatively we could create a new\n>> > `set_gossip_timestamp` message that is only sent if both endpoints\n>> > support this proposal, but that could result in duplicate messages\nbeing\n>> > delivered between the `init` and the `set_gossip_timestamp` message and\n>> > it'd require additional messages.\n>>\n>> We chose the other aproach and propose to use an optional feature\n>>\n>> > The reason I'm using timestamp and not the blockheight in the short\n>> > channel ID is that we already use the timestamp for pruning. In the\n>> > blockheight based timestamp we might ignore channels that were created,\n>> > then not announced or forgotten, and then later came back and are now\n>> > stable.\n>>\n>> Just to be clear, you propose to use the timestamp of the most recent\n>> channel updates to filter\n>> the associated channel announcements ?\n>>\n>> > I hope this rather simple proposal is sufficient to fix the short-term\n>> > issues we are facing with the initial sync, while we wait for a real\n>> > sync protocol. It is definitely not meant to allow perfect\n>> > synchronization of the topology between peers, but then again I don't\n>> > believe that is strictly necessary to make the routing successful.\n>> >\n>> > Please let me know what you think, and I'd love to discuss Pierre's\n>> > proposal as well.\n>> >\n>> > Cheers,\n>> > Christian\n>>\n>> Our idea is to group channel announcements by \"buckets\", create a\n>> filter for each bucket, exchange and use them to filter out channel\n>> announcements.\n>>\n>> We would add a new `use_channel_announcement_filters` optional feature\n>> bit (7 for example), and a new `channel_announcement_filters` message.\n>>\n>> When a node that supports channel announcement filters receives an\n>> `init` message with the `use_channel_announcement_filters` bit set, it\n>> sends back its channel filters.\n>>\n>> When a node that supports channel announcement filters receives\n>> a`channel_announcement_filters` message, it uses it to filter channel\n>> announcements (and, implicitly ,channel updates) before sending them.\n>>\n>> The filters we have in mind are simple:\n>> - Sort announcements by short channel id\n>> - Compute a marker height, which is `144 * ((now - 7 * 144) / 144)`\n>> (we round to multiples of 144 to make sync easier)\n>> - Group channel announcements that were created before this marker by\n>> groups of 144 blocks\n>> - Group channel announcements that were created after this marker by\n>> groups of 1 block\n>> - For each group, sort and concatenate all channel announcements short\n>> channel ids and hash the result (we could use sha256, or the first 16\n>> bytes of the sha256 hash)\n>>\n>> The new `channel_announcement_filters` would then be a list of\n>> (height, hash) pairs ordered by increasing heights.\n>>\n>> This implies that implementation can easily sort announcements by\n>> short channel id, which should not be very difficult.\n>> An additional step could be to send all short channel ids for all\n>> groups for which the group hash did not match. Alternatively we could\n>> use smarter filters\n>>\n>> The use case we have in mind is mobile nodes, or more generally nodes\n>> which are often offline and need to resync very often.\n>>\n>> Cheers,\n>> Fabrice\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n_______________________________________________\nLightning-dev mailing list\nLightning-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180207/cb4ed693/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-02-09T01:44:24",
                "message_text_only": "Hi all!\n\n        Finally catching up.  I prefer the simplicity of the timestamp\nmechanism, with a more ambitious mechanism TBA.\n\nDeployment suggestions:\n\n1. This should be a feature bit pair.  As usual, even == 'support this or\n   disconnect', and odd == 'ok even if you don't understand'.\n\n2. This `timestamp_routing_sync`? feature overrides `initial_routing_sync`.\n   That lets you decide what old nodes do, using the older\n   `initial_routing_sync` option.  Similarly, a future `fancy_sync` would\n   override `timestamp_routing_sync`.\n\n3. We can append an optional 4 byte `routing_sync_timestamp` field to to\n   `init` without issues, since all lengths in there are explicit.  If you\n   don't offer the `timestamp_sync` feature, this Must Be Zero (for appending\n   more stuff in future).\n\nNow, as to the proposal specifics.\n\nI dislike the re-transmission of all old channel_announcement and\nnode_announcement messages, just because there's been a recent\nchannel_update.  Simpler to just say 'send anything >=\nrouting_sync_timestamp`.\n\nBackground: c-lightning internally keeps an tree of gossip in the order\nwe received them, keeping a 'current' pointer for each peer.  This is\nvery efficient (though we don't remember if a peer sent us a gossip msg\nalready, so uses twice the bandwidth it could).\n\nBut this isn't *quite* the same as timestamp order, so we can't just set\nthe 'current' pointer based on the first entry >=\n`routing_sync_timestamp`; we need to actively filter.  This is still a\nsimple traverse, however, skipping over any entry less than\nrouting_sync_timestamp.\n\nOTOH, if we need to retransmit announcements, when do we stop\nretransmitting them?  If a new channel_update comes in during this time,\nare we still to dump the announcements?  Do we have to remember which\nones we've sent to each peer?\n\nIf missing announcements becomes a problem, we could add a simple query\nmessage: I think this is going to be needed for any fancy scheme anyway.\n\nCheers,\nRusty."
            },
            {
                "author": "Christian Decker",
                "date": "2018-02-09T11:41:42",
                "message_text_only": "Rusty Russell <rusty at rustcorp.com.au> writes:\n>         Finally catching up.  I prefer the simplicity of the timestamp\n> mechanism, with a more ambitious mechanism TBA.\n\nFabrice and I had a short chat a few days ago and decided that we'll\nsimulate both approaches and see what consumes less bandwidth. With\nzombie channels and the chances for missing channels during a weak form\nof synchronization, it's not that clear to us which one has the better\ntradeoff. With some numbers behind it it may become easier to decide :-)\n\n> Deployment suggestions:\n>\n> 1. This should be a feature bit pair.  As usual, even == 'support this or\n>    disconnect', and odd == 'ok even if you don't understand'.\n\nIf we add the timestamp to the end of the `init` message, instead of\nintroducing a new message altogether, we are forced to use the required\nbit, otherwise we just made any future field appended to the `init`\nmessage unparseable to non-supporting nodes. Let's say we add another\nfield to it later, that the peer supports, but it follows the timestamp\nwhich the peer does not. The peer doesn't know how many bytes to skip\n(if any) for the timestamp bit he doesn't understand, to get to the\nbytes he does know how to parse. I'm slowly getting to like the extra\nmessage more, since it also allows a number of cute tricks later.\n\n> 2. This `timestamp_routing_sync`? feature overrides `initial_routing_sync`.\n>    That lets you decide what old nodes do, using the older\n>    `initial_routing_sync` option.  Similarly, a future `fancy_sync` would\n>    override `timestamp_routing_sync`.\n\nSo you'd set both bits, and if the peer knows `timestamp_routing_sync`\nthat then force-sets the `initial_routing_sync`? Sounds ok, if we allow\noptional implementations, even though I'd like to avoid feature\ninteractions as much as possible.\n\n> 3. We can append an optional 4 byte `routing_sync_timestamp` field to to\n>    `init` without issues, since all lengths in there are explicit.  If you\n>    don't offer the `timestamp_sync` feature, this Must Be Zero (for appending\n>    more stuff in future).\n\nThat'd still require the peer to know that it has to skip 4 bytes to get\nany future fields, which is why I am convinced that either forcing it to\nbe mandatory, or adding a new message is the better way to go, even if\nnow everybody implements it correctly.\n\n> Now, as to the proposal specifics.\n>\n> I dislike the re-transmission of all old channel_announcement and\n> node_announcement messages, just because there's been a recent\n> channel_update.  Simpler to just say 'send anything >=\n> routing_sync_timestamp`.\n\nI'm afraid we can't really omit the `channel_announcement` since a\n`channel_update` that isn't preceded by a `channel_announcement` is\ninvalid and will be dropped by peers (especially because the\n`channel_update` doesn't contain the necessary information for\nvalidation).\n\n> Background: c-lightning internally keeps an tree of gossip in the order\n> we received them, keeping a 'current' pointer for each peer.  This is\n> very efficient (though we don't remember if a peer sent us a gossip msg\n> already, so uses twice the bandwidth it could).\n\nWe can solve that by keeping a filter of the messages we received from\nthe peer, it's more of an optimization than anything, other than the\nbandwidth cost, it doesn't hurt.\n\n> But this isn't *quite* the same as timestamp order, so we can't just set\n> the 'current' pointer based on the first entry >=\n> `routing_sync_timestamp`; we need to actively filter.  This is still a\n> simple traverse, however, skipping over any entry less than\n> routing_sync_timestamp.\n>\n> OTOH, if we need to retransmit announcements, when do we stop\n> retransmitting them?  If a new channel_update comes in during this time,\n> are we still to dump the announcements?  Do we have to remember which\n> ones we've sent to each peer?\n\nThat's more of an implementation detail. In c-lightning we can just\nremember the index at which the initial sync started, and send\nannouncements along until the index is larger than the initial sync\nindex.\n\nA more general approach would be to have 2 timestamps, one highwater and\none lowwater mark. Anything inbetween these marks will be forwarded\ntogether with all associated announcements (node / channel), anything\nnewer than that will only forward the update. The two timestamps\napproach, combined with a new message, would also allow us to send\nmultiple `timestamp_routing_sync` messages, e.g., first sync the last\nhour, then the last day, then the last week, etc. It gives the syncing\nnode control over what timewindow to send, inverting the current initial\nsync.\n\nCheers,\nChristian"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-02-12T01:45:55",
                "message_text_only": "Christian Decker <decker.christian at gmail.com> writes:\n> Rusty Russell <rusty at rustcorp.com.au> writes:\n>>         Finally catching up.  I prefer the simplicity of the timestamp\n>> mechanism, with a more ambitious mechanism TBA.\n>\n> Fabrice and I had a short chat a few days ago and decided that we'll\n> simulate both approaches and see what consumes less bandwidth. With\n> zombie channels and the chances for missing channels during a weak form\n> of synchronization, it's not that clear to us which one has the better\n> tradeoff. With some numbers behind it it may become easier to decide :-)\n\nMaybe; I think we'd be best off with an IBLT-approach similar to\nFabrice's proposal.  An IBLT is better than a simple hash, since if your\nresults are similar you can just extract the differences, and they're\neasier to maintain.  Even easier if we make the boundaries static rather\nthan now-relative.  For node_announce and channel_update you'd probably\nwant separate IBLTs (perhaps, though not necessarily, as a separate\nRTT).\n\nNote that this approach fits really well as a complement to the\ntimestamp approach: you'd use this for older pre-timestamp, where you're\nlikely to have a similar idea of channels.\n\n>> Deployment suggestions:\n>>\n>> 1. This should be a feature bit pair.  As usual, even == 'support this or\n>>    disconnect', and odd == 'ok even if you don't understand'.\n>\n> If we add the timestamp to the end of the `init` message, instead of\n> introducing a new message altogether, we are forced to use the required\n> bit, otherwise we just made any future field appended to the `init`\n> message unparseable to non-supporting nodes. Let's say we add another\n> field to it later, that the peer supports, but it follows the timestamp\n> which the peer does not. The peer doesn't know how many bytes to skip\n> (if any) for the timestamp bit he doesn't understand, to get to the\n> bytes he does know how to parse. I'm slowly getting to like the extra\n> message more, since it also allows a number of cute tricks later.\n\nThis, of course, is the nature of all appendings.  You can't understand\nfeature N+1 without understanding feature N, if they both append to the\nsame message.\n\nYou don't have to *support* feature N, of course.\n\n>> 2. This `timestamp_routing_sync`? feature overrides `initial_routing_sync`.\n>>    That lets you decide what old nodes do, using the older\n>>    `initial_routing_sync` option.  Similarly, a future `fancy_sync` would\n>>    override `timestamp_routing_sync`.\n>\n> So you'd set both bits, and if the peer knows `timestamp_routing_sync`\n> that then force-sets the `initial_routing_sync`? Sounds ok, if we allow\n> optional implementations, even though I'd like to avoid feature\n> interactions as much as possible.\n\nIf we don't allow optional implementations we're breaking the spec.  And\nwe're not going to do that*\n\n[* Yeah, OK, we'll eventually do that.  But we'll do it when we're\n   pretty sure that ~0 users would break, because they'd be ancient ]\n\n>> 3. We can append an optional 4 byte `routing_sync_timestamp` field to to\n>>    `init` without issues, since all lengths in there are explicit.  If you\n>>    don't offer the `timestamp_sync` feature, this Must Be Zero (for appending\n>>    more stuff in future).\n>\n> That'd still require the peer to know that it has to skip 4 bytes to get\n> any future fields, which is why I am convinced that either forcing it to\n> be mandatory, or adding a new message is the better way to go, even if\n> now everybody implements it correctly.\n\nThis is simply how we upgrade.  See `open_channel` for how this is\nalready done, for example; in fact, we originally had two different\nupgrades (but we broke spec instead) and they used exactly this\ntechnique.\n\nA separate message here is supremely awkward, too.\n\n>> Now, as to the proposal specifics.\n>>\n>> I dislike the re-transmission of all old channel_announcement and\n>> node_announcement messages, just because there's been a recent\n>> channel_update.  Simpler to just say 'send anything >=\n>> routing_sync_timestamp`.\n>\n> I'm afraid we can't really omit the `channel_announcement` since a\n> `channel_update` that isn't preceded by a `channel_announcement` is\n> invalid and will be dropped by peers (especially because the\n> `channel_update` doesn't contain the necessary information for\n> validation).\n\nOTOH this is a rare corner case which will eventually be fixed by weekly\nchannel_announce retransmission.  In particular, the receiver should\nhave already seen the channel_announce, since it preceeded the timestamp\nthey asked for.\n\nPresumably IRL you'd ask for a timestamp sometime before you were last\ndisconnected, say 30 minutes.\n\n\"The perfect is the enemy of the good\".\n\n>> Background: c-lightning internally keeps an tree of gossip in the order\n>> we received them, keeping a 'current' pointer for each peer.  This is\n>> very efficient (though we don't remember if a peer sent us a gossip msg\n>> already, so uses twice the bandwidth it could).\n>\n> We can solve that by keeping a filter of the messages we received from\n> the peer, it's more of an optimization than anything, other than the\n> bandwidth cost, it doesn't hurt.\n\nYes, it's on the TODO somewhere... we should do this!\n\n>> But this isn't *quite* the same as timestamp order, so we can't just set\n>> the 'current' pointer based on the first entry >=\n>> `routing_sync_timestamp`; we need to actively filter.  This is still a\n>> simple traverse, however, skipping over any entry less than\n>> routing_sync_timestamp.\n>>\n>> OTOH, if we need to retransmit announcements, when do we stop\n>> retransmitting them?  If a new channel_update comes in during this time,\n>> are we still to dump the announcements?  Do we have to remember which\n>> ones we've sent to each peer?\n>\n> That's more of an implementation detail. In c-lightning we can just\n> remember the index at which the initial sync started, and send\n> announcements along until the index is larger than the initial sync\n> index.\n\nTrue.  It is an implementation detail which is critical to saving\nbandwidth though.\n\n> A more general approach would be to have 2 timestamps, one highwater and\n> one lowwater mark. Anything inbetween these marks will be forwarded\n> together with all associated announcements (node / channel), anything\n> newer than that will only forward the update. The two timestamps\n> approach, combined with a new message, would also allow us to send\n> multiple `timestamp_routing_sync` messages, e.g., first sync the last\n> hour, then the last day, then the last week, etc. It gives the syncing\n> node control over what timewindow to send, inverting the current initial\n> sync.\n\nThat would fit neatly with the more complicated bucketing approaches:\nyou'd use this technique to ask for the entire bucket if the SHA\nmismatched/IBLT failed.\n\nCheers,\nRusty."
            },
            {
                "author": "Fabrice Drouin",
                "date": "2018-02-13T09:01:38",
                "message_text_only": "On 12 February 2018 at 02:45, Rusty Russell <rusty at rustcorp.com.au> wrote:\n> Christian Decker <decker.christian at gmail.com> writes:\n>> Rusty Russell <rusty at rustcorp.com.au> writes:\n>>>         Finally catching up.  I prefer the simplicity of the timestamp\n>>> mechanism, with a more ambitious mechanism TBA.\n>>\n>> Fabrice and I had a short chat a few days ago and decided that we'll\n>> simulate both approaches and see what consumes less bandwidth. With\n>> zombie channels and the chances for missing channels during a weak form\n>> of synchronization, it's not that clear to us which one has the better\n>> tradeoff. With some numbers behind it it may become easier to decide :-)\n>\n> Maybe; I think we'd be best off with an IBLT-approach similar to\n> Fabrice's proposal.  An IBLT is better than a simple hash, since if your\n> results are similar you can just extract the differences, and they're\n> easier to maintain.  Even easier if we make the boundaries static rather\n> than now-relative.  For node_announce and channel_update you'd probably\n> want separate IBLTs (perhaps, though not necessarily, as a separate\n> RTT).\n\nYes,\n\u200breal filters would be better, but\n the 'bucket hash' idea works (from what I've seen on testnet)\n\u200bfor our\u200b\nspecific\n\u200btarget\u200b\n(nodes which are connected to very small number of peers and go offline\n\u200b\nvery often)\n\u200b.\n\n\n> Note that this approach fits really well as a complement to the\n> timestamp approach: you'd use this for older pre-timestamp, where you're\n> likely to have a similar idea of channels.\n\nBoth approaches maybe needed because they may be solutions to different\nproblems (nodes which get\n\u200b d\nisconnected from\n\u200b\n a small set of peers vs nodes connected  to many peers, which remain\nonline but not some of their peers)\n\n>>> Now, as to the proposal specifics.\n>>>\n>>> I dislike the re-transmission of all old channel_announcement and\n>>> node_announcement messages, just because there's been a recent\n>>> channel_update.  Simpler to just say 'send anything >=\n>>> routing_sync_timestamp`.\n>>\n>> I'm afraid we can't really omit the `channel_announcement` since a\n>> `channel_update` that isn't preceded by a `channel_announcement` is\n>> invalid and will be dropped by peers (especially because the\n>> `channel_update` doesn't contain the necessary information for\n>> validation).\n>\n> OTOH this is a rare corner case which will eventually be fixed by weekly\n> channel_announce retransmission.  In particular, the receiver should\n> have already seen the channel_announce, since it preceeded the timestamp\n> they asked for.\n>\n> Presumably IRL you'd ask for a timestamp sometime before you were last\n> disconnected, say 30 minutes.\n>\n> \"The perfect is the enemy of the good\".\n\nThis is precisely what I think\n\u200bwould\n not work very well with the timestamp approach:\n\u200b \u200b\nwhen you're missing an 'old' channel announcement, and only have a few\nsources for them.\n\u200b \u200b\nIt can have a huge impact on terminal nodes which won't be able to find\nroutes and waiting for a\n\u200b \u200b\nnew channel update would take too long.\nYes, using just a few peers mean that you will be limited to the routing\ntable they will give you, but\n\u200b \u200b\nhaving  some kind of filter would let nodes connect\n\u200b \u200b\nto other peers just to retrieve\n\u200bthem and check how far off they are from the rest of the nework. This\nwould not possible with a timestamp (you would need to download the entire\nrouting table again, which is what we're trying to avoid)\n\n>>> Background: c-lightning internally keeps an tree of gossip in the order\n>>> we received them, keeping a 'current' pointer for each peer.  This is\n>>> very efficient (though we don't remember if a peer sent us a gossip msg\n>>> already, so uses twice the bandwidth it could).\n\nOk so a peer would receive an announcement it has sent, but woud\nimmediately dismiss it ?\n\n>>\n>> We can solve that by keeping a filter of the messages we received from\n>> the peer, it's more of an optimization than anything, other than the\n>> bandwidth cost, it doesn't hurt.\n>\n> Yes, it's on the TODO somewhere... we should do this!\n>\n>>> But this isn't *quite* the same as timestamp order, so we can't just set\n>>> the 'current' pointer based on the first entry >=\n>>> `routing_sync_timestamp`; we need to actively filter.  This is still a\n>>> simple traverse, however, skipping over any entry less than\n>>> routing_sync_timestamp.\n>>>\n>>> OTOH, if we need to retransmit announcements, when do we stop\n>>> retransmitting them?  If a new channel_update comes in during this time,\n>>> are we still to dump the announcements?  Do we have to remember which\n>>> ones we've sent to each peer?\n\n>>\n>> That's more of an implementation detail. In c-lightning we can just\n>> remember the index at which the initial sync started, and send\n>> announcements along until the index is larger than the initial sync\n>> index.\n>\n> True.  It is an implementation detail which is critical to saving\n> bandwidth though.\n>\n>> A more general approach would be to have 2 timestamps, one highwater and\n>> one lowwater mark. Anything inbetween these marks will be forwarded\n>> together with all associated announcements (node / channel), anything\n>> newer than that will only forward the update. The two timestamps\n>> approach, combined with a new message, would also allow us to send\n>> multiple `timestamp_routing_sync` messages, e.g., first sync the last\n>> hour, then the last day, then the last week, etc. It gives the syncing\n>> node control over what timewindow to send, inverting the current initial\n>> sync.\n>\n> That would fit neatly with the more complicated bucketing approaches:\n> you'd use this technique to ask for the entire bucket if the SHA\n> mismatched/IBLT failed.\n\nThere is also somehting that would work fairly well today: just exchange\nall shortIds that you have.\nWith the simplest possible implementation (sort and concatenate all 8 bytes\nshort ids and compress with xz or gz or zip)\nit fits in about 8 Kb. And there are lots of easy optimizations\n\u200b(heights are mostly consecutive integers, tx and output index are small...)\n\n> Cheers,\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180213/18989ef5/attachment-0001.html>"
            },
            {
                "author": "Fabrice Drouin",
                "date": "2018-02-19T18:04:39",
                "message_text_only": "I'm still pushing for the hash-based solution because it can be\nimplemented and developed quickly and easily and fixes the main issues\nwe've seen on testnet:\n- routing sync on mobile nodes\n- \"route not found\" errors when you're missing routing info.\n\nIt can be deployed as an optional feature and will give us time to\nspecify and implement proper IBLT-based filters.\n\nIt can be combined with the timestamp approach: nodes would send\nbucket hashes + low and high watermarks.\n\nI've tried and summarised the issue below:\n\n## The problem\n\nThe current scheme (broadcast + optionally ask for a full routing\ntable when you connect) works well for nodes which are never\ncompletely offline, but is becoming unpractical on mobile\nnode/end-user nodes which are often offline and connected to a few\npeers. We need a way to improve the initial routing sync and retrieve\nannouncements that we've missed without having to download the entire\nrouting table.\n\nAdditionally, the only way to check that routing information is\nconsistent between different nodes is to ask each one of them to send\nyou their entire routing table. Exchanging filters/digests/\u2026 would\nmitigate the issue of having to \u201ctrust\u201d that your peers do provide do\nwith a good routing table, especially when you\u2019re connected to very\nfew peers.\n\n## Requirements\n\n- Easy to specify and implement\n- Low overhead\n- Ability to retrieve missing routing information\n- (Nice to have) Ability to query multiple peers for consistency checks\n\n## Background\n\nThe current method for retrieving this routing table is to set the\n`initial_routing_sync` flag in the `init` message that you send every\ntime you connect/reconnect to a peer, which will then send back its\nentire routing table (currently 6000 channels on testnet).\nIf a node believes that a channel is available when it has in fact\nbeen closed, and uses it to build a route, it will receive an error\nmessage and try again without this specific channel.\nBut if a node is missing a channel, and cannot route payments, there\nis currently no way to recover it: it has to wait until the channel\nparameters are updated, and will then receive a `channel_announcement`\nand the matching `channel_update`. This could take a very long time.\n\nHence, the only option for mobile nodes is to request a routing table\ndump every time they connect/reconnect, which simply does not work.\n\nWe need a way to improve this initial table sync, which is simple\nenough to be implemented and deployed quickly. Otherwise, these nodes\nwill probably use ugly specific hacks (like use their own mechanisms\nfor retrieving and syncing routing tables) or even rely on remote\nservers to compute routes for them.\n\n## Proposed solutions\n\n### Timestamps/watermarks\n\nWhen they connect to another peer, nodes send a timestamp (I know the\nrouting table up to X) or a pair of timestamps (I know the routing\ntable from time X to time Y).\n\nPros:\n- Very simple to specify (use `channel_update` timestamps) and implement.\n- Very little overhead\n- Solves the \u201cdownload the entire routing table every time\u201d issue\n\nCons:\n- Does not solve the \"missing announcements\" issue: if you're missing\nrouting info you would have to wait for channel parameters to be\nupdated etc.., as above\n\n### Bucket hashes\n\nRouting info (i.e. channel announcements) are grouped by buckets, one\nbucket being a group of 144 blocks. A hash is computed for each\nbucket, peers exchanges these hashes and send back all announcements\nfor which bucket hashes don't match.\nWe propose to use a bucket per block for the last 7 days, one bucket\nper 144 blocks for older announcements,\nIf gives a total of `(365 + 7*144) = 1373` hashes, for a year of announcements\n\nPros:\n- Simple to specify and implement\n- Little overhead (a few dozen Kb)\n- If a node is missing a few elements it will immediately recover\nthem, even if they're very old\n- Works well when routing tables are mostly synchronized, which would\nbe the case for nodes which connect to a very small number of peers\n- Bucket hashes are the same for all peers you connect to, and can be\nused for consistency checks between peers\n\nCons:\n- Buckets hashes are not queryable filters\n- Since a single mismatch will invalidate an entire buckets, even with\nsmall differences nodes could end up having to send their entire\nrouting table (which exactly what they are doing today)\n\n### IBLT filters\n\nUpon connection, nodes exchange information to estimate the number of\ndifferences between their routing table.\nUsing this estimate, they build and exchange IBLT filters, and use\nthem to compute the announcements that they should send to their peer.\n\nPros:\n- Queryable filters\n- Very efficient if the number of differences is small, even with very\nlarge routing tables\n\nCons:\n- More complex to specify and implement: we need a good estimator for\nthe number of differences (send min height + max height + a sample of\nannouncements ?)\n- Filters become peer-specific (similar to the server-side vs\nclient-side filtering for SPV clients)\n\n\n\nOn 16 February 2018 at 13:34, Fabrice Drouin <fabrice.drouin at acinq.fr> wrote:\n> I like the IBLT idea very much but my understanding of how they work\n> is that that the tricky part would be first to estimate the number of\n> differences between \"our\" and \"their\" routing tables.\n> So when we open a connection we would first exchange messages to\n> estimate how far off we are (by sending a sample of shortids and\n> extrapolate ?) then send filters which would be specific to each peer.\n> This may become an issue if a node is connected to many peers, and is\n> similar to the server-side vs client-side filtering issue for SPV\n> clients.\n> Basically, I fear that it would take some time before it is agreed\n> upon and available, hindering the development of mobile nodes.\n>\n> The bucket hash idea is naive but is very simple to implement and\n> could buy us enough time to implement IBLT filters properly. Imho the\n> timestamp idea does not work for the mobile phone use case (but is\n> probably simpler and better that bucket hashes for \"centre\" nodes\n> which are never completely off the grid)\n>\n>\n> On 14 February 2018 at 01:24, Rusty Russell <rusty at rustcorp.com.au> wrote:\n>> Fabrice Drouin <fabrice.drouin at acinq.fr> writes:\n>>> Yes, real filters would be better, but the 'bucket hash' idea works\n>>> (from what I've seen on testnet) for our specific target (nodes which\n>>> are connected to very small number of peers and go offline very\n>>> often)\n>>\n>> What if we also add an 'announce_query' message: if you see a\n>> 'channel_update' which you discard because you don't know the channel,\n>> 'announce_query' asks them to send the 'channel_announce' for that\n>> 'short_channel_id' followed by re-sending the 'channel_update'(s)?\n>> (Immediately, rather than waiting for next gossip batch).\n>>\n>> I think we would want this for IBLT, too, since you'd want this to query\n>> any short-channel-id you extract from that which you don't know about.\n>\n> Yes, unless it is part of the initial sync (compare filters. then send\n> what they're missing)\n>\n>> I see.  (BTW, your formatting makes your post sounds very Zen!).\n> Sorry about that, I've disabled the haiku mode :)\n>\n>> Yes, we can probably use difference encoding and use 1 bit for output\n>> index (with anything which is greater appended) and get down to 1 byte\n>> per channel_id at scale.\n>>\n>> But my rule-of-thumb for scaling today is 1M - 10M channels, and that\n>> starts to get a little excessive.  Hence my interest in IBLTs, which are\n>> still pretty trivial to implement.\n>\n> Yes, sending all shortids would also have been a temporary measure\n> while a more sophisticated approach is being designed.\n>>\n>> Cheers,\n>> Rusty."
            },
            {
                "author": "Rusty Russell",
                "date": "2018-02-20T01:08:54",
                "message_text_only": "Hi all,\n\n        This consumed much of our lightning dev interop call today!  But\nI think we have a way forward, which is in three parts, gated by a new\nfeature bitpair:\n\n1. A query message for a particular shortid.\n2. A query message for shortids in a range of blocks.\n3. A gossip_timestamp field in `init`\n\nI think these will still be desirable even when we have a more complex\nscheme in future.\n\n1. query_short_channel_id\n=========================\n\n1. type: 260 (`query_short_channel_id`)\n2. data:\n   * [`32`:`chain_hash`]\n   * [`8`:`short_channel_id`]\n\nThis is general mechanism which lets you query for a\nchannel_announcement and channel_updates for a specific 8-byte shortid.\nThe receiver should respond with a channel_announce and the latest\nchannel_update for each end, not batched in the normal 60-second gossip\ncycle.\n\nA node MAY send this if it receives a `channel_update` for a channel it\nhas no `channel_announcement`, but SHOULD NOT if the channel referred to\nis not an unspent output (ie. check that it's not closed before sending\nthis query!).\n\nIMPLEMENTATION: trivial\n\n2. query_channel_range/reply_channel_range\n==========================================\nThis is a new message pair, something like:\n\n1. type: 261 (`query_channel_range`)\n2. data:\n   * [`32`:`chain_hash`]\n   * [`4`:`first_blocknum`]\n   * [`4`:`number_of_blocks`]\n\n1. type: 262 (`reply_channel_range`)\n2. data:\n   * [`32`:`chain_hash`]\n   * [`4`:`first_blocknum`]\n   * [`4`:`number_of_blocks`]\n   * [`2`:`len`]\n   * [`len`:`data`]\n\nWhere data is a series of ordered shortids (see Appendix A for various\nencodings).  `number_of_blocks` in the reply may be less than in the\nrequest of the required data did not fit; it is assumed that we can fit\na single block per reply, at least.\n\nIMPLEMENTATION: requires channel index by block number, zlib\n\n3. gossip_timestamp.\n====================\n\nThis is useful for the simple case of a node reconnecting to a single\npeer, for example.  This is a new field appended to `init`: the\nnegotiation of this feature bit overrides `initial_routing_sync` as the\nsame results can be obtained by setting the `gossip_timestamp` field to\nthe current time (for no initial sync) or 0 (for an initial sync).\n\nNote that a node should allow for some minutes of propagation time, thus\nset the `gossip_timestamp` to sometime before its last seen gossip\nmessage.  It may also receive `channel_update` messages for which it has\nnot seen the `channel_announcement` and thus use \n\nIMPLEMENTATION: easy.\n\nAppendix A: Encoding Sizes\n==========================\n\nI tried various obvious compression schemes, in increasing complexity\norder (see source below, which takes stdin and spits out stdout):\n\n        Raw = raw 8-byte stream of ordered channels.\n        gzip -9: gzip -9 of raw.\n        splitgz: all blocknums first, then all txnums, then all outnums, then gzip -9\n        delta: CVarInt encoding: blocknum_delta,num,num*txnum_delta,num*outnum.\n        deltagz: delta, with gzip -9\n\nCorpus 1: LN mainnet dump, 1830 channels.[1]\n\n        Raw: 14640 bytes\n        gzip -9: 6717 bytes\n        splitgz: 6464 bytes\n        delta: 6624 bytes\n        deltagz: 4171 bytes\n\nCorpus 2: All P2SH outputs between blocks 508000-508999 incl, 790844 channels.[2]\n\n        Raw: 6326752 bytes\n        gzip -9: 1861710 bytes\n        splitgz: 964332 bytes\n        delta: 1655255 bytes\n        deltagz: 595469 bytes\n\n[1] http://ozlabs.org/~rusty/short_channels-mainnet.xz\n[2] http://ozlabs.org/~rusty/short_channels-all-p2sh-508000-509000.xz\n\nAppendix B: Encoding Sourcecode\n===============================\n// gcc -g -Wall -o encode-short_channel_ids encode-short_channel_ids.c\n#include <inttypes.h>\n#include <arpa/inet.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n/* BOLT #1:\n * All data fields are big-endian unless otherwise specified. */\nstatic void write_bytes(uint32_t val, int n)\n{\n\t/* BE, so write out tail */\n\tuint32_t v = htonl(val);\n\n\tfwrite((char *)&v + (4 - n), n,  1, stdout);\n}\n\n/* CVarInt from bitcoin/src/serialize.h:\n// Copyright (c) 2009-2010 Satoshi Nakamoto\n// Copyright (c) 2009-2016 The Bitcoin Core developers\n// Distributed under the MIT software license, see the accompanying\n// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n */\nstatic void write_varint(uint32_t n)\n{\n\tunsigned char tmp[(sizeof(n)*8+6)/7];\n\tint len=0;\n\twhile (1) {\n\t\ttmp[len] = (n & 0x7F) | (len ? 0x80 : 0x00);\n\t\tif (n <= 0x7F)\n\t\t\tbreak;\n\t\tn = (n >> 7) - 1;\n\t\tlen++;\n\t}\n\tdo {\n\t\tfwrite(&tmp[len], 1, 1, stdout);\n\t} while(len--);\n}\n\nint main(void)\n{\n\tsize_t n, max = 1024;\n\tuint32_t *block = malloc(max * sizeof(uint32_t));\n\tuint32_t *txnum = malloc(max * sizeof(uint32_t));\n\tuint32_t *outnum = malloc(max * sizeof(uint32_t));\n\n\tn = 0;\n\twhile (scanf(\"%u:%u:%u\", &block[n], &txnum[n], &outnum[n]) == 3) {\n\t\tif (++n == max) {\n\t\t\tmax *= 2;\n\t\t\tblock = realloc(block, max * sizeof(uint32_t));\n\t\t\ttxnum = realloc(txnum, max * sizeof(uint32_t));\n\t\t\toutnum = realloc(outnum, max * sizeof(uint32_t));\n\t\t}\n\t}\n\tfprintf(stderr, \"Got %zu channels\\n\", n);\n\n\tmax = n;\n#ifdef SPLIT\n\tfor (n = 0; n < max; n++)\n\t\twrite_bytes(block[n], 3);\n\tfor (n = 0; n < max; n++)\n\t\twrite_bytes(txnum[n], 3);\n\tfor (n = 0; n < max; n++)\n\t\twrite_bytes(outnum[n], 2);\n#elif defined(DIFFENCODE)\n\tuint32_t prev_block = 0, num_channels;\n\tfor (n = 0; n < max; n += num_channels) {\n\t\t/* Block delta */\n\t\twrite_varint(block[n] - prev_block);\n\t\tprev_block = block[n];\n\t\tfor (num_channels = 1;\n\t\t     n + num_channels < max && block[n+num_channels] == block[n];\n\t\t     num_channels++);\n\t\t/* Number of channels */\n\t\twrite_varint(num_channels);\n\n\t\t/* num_channels * txnum delta  */\n\t\tuint32_t prev_txnum = 0;\n\t\tfor (size_t i = n; i < n + num_channels; i++) {\n\t\t\twrite_varint(txnum[i] - prev_txnum);\n\t\t\tprev_txnum = txnum[i];\n\t\t}\n\t\t/* num_channels * outnum  */\n\t\tfor (size_t i = n; i < n + num_channels; i++)\n\t\t\twrite_varint(outnum[i]);\n\t}\n#else\n\tfor (n = 0; n < max; n++) {\n\t\t/* BOLT #7:\n\t\t *\n\t\t * The `short_channel_id` is the unique description of the\n\t\t * funding transaction.  It is constructed as follows:\n\t\t *\n\t\t * 1. the most significant 3 bytes: indicating the block height\n\t\t * 2. the next 3 bytes: indicating the transaction index within\n\t\t *    the block\n\t\t * 3. the least significant 2 bytes: indicating the output index\n\t\t *    that pays to the channel.\n\t\t */\n\t\twrite_bytes(block[n], 3);\n\t\twrite_bytes(txnum[n], 3);\n\t\twrite_bytes(outnum[n], 2);\n\t}\n#endif\n\treturn 0;\n}"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-02-20T06:26:16",
                "message_text_only": "Good morning Rusty,\n\n\u200b>4. query_short_channel_id\n> =========================\n>\n>\n>5. type: 260 (query_short_channel_id)\n>\n>6. data: \n> - [32:chain_hash]\n>\n> - [8:short_channel_id]\n>\n> This is general mechanism which lets you query for a\n> channel_announcement and channel_updates for a specific 8-byte shortid.\n> The receiver should respond with a channel_announce and the latest\n> channel_update for each end, not batched in the normal 60-second gossip\n> cycle.\n>\n> A node MAY send this if it receives a channel_update for a channel it\n> has no channel_announcement, but SHOULD NOT if the channel referred to\n> is not an unspent output (ie. check that it's not closed before sending\n> this query!).\n\nIs the SHOULD NOT something the sender can assure?  In the case that the sender is a lightweight Bitcoin node, and does not keep track of a mempool, and only notices closes if they have been confirmed onchain, it may be possible that the sender thinks the channel is still possibly open, while the receiver is a full Bitcoin node and has seen the closing transaction of the channel on the mempool.  There are also race conditions where the sender has not received a new block yet, then sends the message, and the receiver receives/processes the message after it has received a new block containing the closing transaction.\n\nPerhaps there should also be a possible reply to this message which indicates \"short_channel_id so-and-so was closed by txid so-and-so\".\n\nOr maybe receivers should not rely on this \"SHOULD NOT\" and will have to silently ignore `query_short_channel_id` that it thinks is closed; this also implies that the sender cannot rely on getting information on the specified channel from anyone, either.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Fabrice Drouin",
                "date": "2018-02-21T18:02:57",
                "message_text_only": "On 20 February 2018 at 02:08, Rusty Russell <rusty at rustcorp.com.au> wrote:\n> Hi all,\n>\n>         This consumed much of our lightning dev interop call today!  But\n> I think we have a way forward, which is in three parts, gated by a new\n> feature bitpair:\n\nWe've built a prototype with a new feature bit `channel_range_queries`\nand the following logic:\nWhen you receive their init message and check their local features\n- if they set `initial_routing_sync` and `channel_range_queries` then\ndo nothing (they will send you a `query_channel_range`)\n- if they set `initial_routing_sync` and not `channel_range_queries`\nthen send your routing table (as before)\n- if you support `channel_range_queries` then send a\n`query_channel_range` message\n\nThis way new and old nodes should be able to understand each other\n\n> 1. query_short_channel_id\n> =========================\n>\n> 1. type: 260 (`query_short_channel_id`)\n> 2. data:\n>    * [`32`:`chain_hash`]\n>    * [`8`:`short_channel_id`]\n\nWe could add a `data` field which contains zipped ids like in\n`reply_channel_range` so we can query several items with a single\nmessage ?\n\n> 1. type: 262 (`reply_channel_range`)\n> 2. data:\n>    * [`32`:`chain_hash`]\n>    * [`4`:`first_blocknum`]\n>    * [`4`:`number_of_blocks`]\n>    * [`2`:`len`]\n>    * [`len`:`data`]\n\nWe could add an additional `encoding_type` field before `data` (or it\ncould be the first byte of `data`)\n\n> Appendix A: Encoding Sizes\n> ==========================\n>\n> I tried various obvious compression schemes, in increasing complexity\n> order (see source below, which takes stdin and spits out stdout):\n>\n>         Raw = raw 8-byte stream of ordered channels.\n>         gzip -9: gzip -9 of raw.\n>         splitgz: all blocknums first, then all txnums, then all outnums, then gzip -9\n>         delta: CVarInt encoding: blocknum_delta,num,num*txnum_delta,num*outnum.\n>         deltagz: delta, with gzip -9\n>\n> Corpus 1: LN mainnet dump, 1830 channels.[1]\n>\n>         Raw: 14640 bytes\n>         gzip -9: 6717 bytes\n>         splitgz: 6464 bytes\n>         delta: 6624 bytes\n>         deltagz: 4171 bytes\n>\n> Corpus 2: All P2SH outputs between blocks 508000-508999 incl, 790844 channels.[2]\n>\n>         Raw: 6326752 bytes\n>         gzip -9: 1861710 bytes\n>         splitgz: 964332 bytes\n>         delta: 1655255 bytes\n>         deltagz: 595469 bytes\n>\n> [1] http://ozlabs.org/~rusty/short_channels-mainnet.xz\n> [2] http://ozlabs.org/~rusty/short_channels-all-p2sh-508000-509000.xz\n>\n\nImpressive!"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-02-24T00:45:27",
                "message_text_only": "Hi Rusty,\n\n> 1. query_short_channel_id\n> IMPLEMENTATION: trivial\n\n*thumbs up*\n\n> 2. query_channel_range/reply_channel_range\n> IMPLEMENTATION: requires channel index by block number, zlib\n\nFor the sake of expediency of deployment, if we add a byte (or two) to\ndenote the encoding/compression scheme, we can immediately roll out the\nvanilla (just list the ID's), then progressively roll out more\ncontext-specific optimized schemes.\n\n> 3. A gossip_timestamp field in `init`\n> This is a new field appended to `init`: the negotiation of this feature\nbit\n> overrides `initial_routing_sync`\n\nAs I've brought up before, from my PoV, we can't append any additional\nfields to the innit message as it already contains *two* variable sized\nfields (and no fixed size fields). Aside from this, it seems that the\n`innit` message should be simply for exchange versioning information, which\nmay govern exactly *which* messages are sent after it. Otherwise, by adding\n_additional_ fields to the `innit` message, we paint ourselves in a corner\nand can never remove it. Compared to using the `innit` message to set up the\ninitial session context, where we can safely add other bits to nullify or\nremove certain expected messages.\n\nWith that said, this should instead be a distinct `chan_update_horizon`\nmessage (or w/e name). If a particular bit is set in the `init` message,\nthen the next message *both* sides send *must* be `chan_update_horizon`.\n\nAnother advantage of making this a distinct message, is that either party\ncan at any time update this horizon/filter to ensure that they only receive\nthe *freshest* updates.Otherwise, one can image a very long lived\nconnections (say weeks) and the remote party keeps sending me very dated\nupdates (wasting bandwidth) when I only really want the *latest*.\n\nThis can incorporate decker's idea about having a high+low timestamp. I\nthink this is desirable as then for the initial sync case, the receiver can\n*precisely* control their \"verification load\" to ensure they only process a\nparticular chunk at a time.\n\n\nFabrice wrote:\n> We could add a `data` field which contains zipped ids like in\n> `reply_channel_range` so we can query several items with a single message\n?\n\nI think this is an excellent idea! It would allow batched requests in\nresponse to a channel range message. I'm not so sure we need to jump\n*straight* to compressing everything however.\n\n> We could add an additional `encoding_type` field before `data` (or it\n> could be the first byte of `data`)\n\nGreat minds think alike :-)\n\n\nIf we're in rough agreement generally about this initial \"kick can\"\napproach, I'll start implementing some of this in a prototype branch for\nlnd. I'm very eager to solve the zombie churn, and initial burst that can be\nvery hard on light clients.\n\n-- Laolu\n\n\nOn Wed, Feb 21, 2018 at 10:03 AM Fabrice Drouin <fabrice.drouin at acinq.fr>\nwrote:\n\n> On 20 February 2018 at 02:08, Rusty Russell <rusty at rustcorp.com.au> wrote:\n> > Hi all,\n> >\n> >         This consumed much of our lightning dev interop call today!  But\n> > I think we have a way forward, which is in three parts, gated by a new\n> > feature bitpair:\n>\n> We've built a prototype with a new feature bit `channel_range_queries`\n> and the following logic:\n> When you receive their init message and check their local features\n> - if they set `initial_routing_sync` and `channel_range_queries` then\n> do nothing (they will send you a `query_channel_range`)\n> - if they set `initial_routing_sync` and not `channel_range_queries`\n> then send your routing table (as before)\n> - if you support `channel_range_queries` then send a\n> `query_channel_range` message\n>\n> This way new and old nodes should be able to understand each other\n>\n> > 1. query_short_channel_id\n> > =========================\n> >\n> > 1. type: 260 (`query_short_channel_id`)\n> > 2. data:\n> >    * [`32`:`chain_hash`]\n> >    * [`8`:`short_channel_id`]\n>\n> We could add a `data` field which contains zipped ids like in\n> `reply_channel_range` so we can query several items with a single\n> message ?\n>\n> > 1. type: 262 (`reply_channel_range`)\n> > 2. data:\n> >    * [`32`:`chain_hash`]\n> >    * [`4`:`first_blocknum`]\n> >    * [`4`:`number_of_blocks`]\n> >    * [`2`:`len`]\n> >    * [`len`:`data`]\n>\n> We could add an additional `encoding_type` field before `data` (or it\n> could be the first byte of `data`)\n>\n> > Appendix A: Encoding Sizes\n> > ==========================\n> >\n> > I tried various obvious compression schemes, in increasing complexity\n> > order (see source below, which takes stdin and spits out stdout):\n> >\n> >         Raw = raw 8-byte stream of ordered channels.\n> >         gzip -9: gzip -9 of raw.\n> >         splitgz: all blocknums first, then all txnums, then all outnums,\n> then gzip -9\n> >         delta: CVarInt encoding:\n> blocknum_delta,num,num*txnum_delta,num*outnum.\n> >         deltagz: delta, with gzip -9\n> >\n> > Corpus 1: LN mainnet dump, 1830 channels.[1]\n> >\n> >         Raw: 14640 bytes\n> >         gzip -9: 6717 bytes\n> >         splitgz: 6464 bytes\n> >         delta: 6624 bytes\n> >         deltagz: 4171 bytes\n> >\n> > Corpus 2: All P2SH outputs between blocks 508000-508999 incl, 790844\n> channels.[2]\n> >\n> >         Raw: 6326752 bytes\n> >         gzip -9: 1861710 bytes\n> >         splitgz: 964332 bytes\n> >         delta: 1655255 bytes\n> >         deltagz: 595469 bytes\n> >\n> > [1] http://ozlabs.org/~rusty/short_channels-mainnet.xz\n> > [2] http://ozlabs.org/~rusty/short_channels-all-p2sh-508000-509000.xz\n> >\n>\n> Impressive!\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180224/35572cad/attachment.html>"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-02-25T23:23:54",
                "message_text_only": "> With that said, this should instead be a distinct `chan_update_horizon`\n> message (or w/e name). If a particular bit is set in the `init` message,\n> then the next message *both* sides send *must* be `chan_update_horizon`.\n\nTweaking this a bit, if we make it: don't send *any* channel updates at all\nunless the other side sends this message, then this allows both parties to\nprecisely control their initial load, and also if they even *want*\nchannel_update messages at all.\n\nPurely routing nodes don't need any updates at all. In the case they wish to\nsend (assumed to be infrequent in this model), they'll get the latest update\nafter their first failure.\n\nSimilarly, leaf/edge nodes can opt to receive the latest updates if they\nwish to minimize payment latency due to routing failures that are the result\nof dated information.\n\nIMO, the only case where a node would want the most up to date link policy\nstate is for optimization/analysis, or to minimize payment latency at the\ncost of additional load.\n\n--Laolu\n\nOn Fri, Feb 23, 2018 at 4:45 PM Olaoluwa Osuntokun <laolu32 at gmail.com>\nwrote:\n\n> Hi Rusty,\n>\n> > 1. query_short_channel_id\n> > IMPLEMENTATION: trivial\n>\n> *thumbs up*\n>\n> > 2. query_channel_range/reply_channel_range\n> > IMPLEMENTATION: requires channel index by block number, zlib\n>\n> For the sake of expediency of deployment, if we add a byte (or two) to\n> denote the encoding/compression scheme, we can immediately roll out the\n> vanilla (just list the ID's), then progressively roll out more\n> context-specific optimized schemes.\n>\n> > 3. A gossip_timestamp field in `init`\n> > This is a new field appended to `init`: the negotiation of this feature\n> bit\n> > overrides `initial_routing_sync`\n>\n> As I've brought up before, from my PoV, we can't append any additional\n> fields to the innit message as it already contains *two* variable sized\n> fields (and no fixed size fields). Aside from this, it seems that the\n> `innit` message should be simply for exchange versioning information,\n> which\n> may govern exactly *which* messages are sent after it. Otherwise, by adding\n> _additional_ fields to the `innit` message, we paint ourselves in a corner\n> and can never remove it. Compared to using the `innit` message to set up\n> the\n> initial session context, where we can safely add other bits to nullify or\n> remove certain expected messages.\n>\n> With that said, this should instead be a distinct `chan_update_horizon`\n> message (or w/e name). If a particular bit is set in the `init` message,\n> then the next message *both* sides send *must* be `chan_update_horizon`.\n>\n> Another advantage of making this a distinct message, is that either party\n> can at any time update this horizon/filter to ensure that they only receive\n> the *freshest* updates.Otherwise, one can image a very long lived\n> connections (say weeks) and the remote party keeps sending me very dated\n> updates (wasting bandwidth) when I only really want the *latest*.\n>\n> This can incorporate decker's idea about having a high+low timestamp. I\n> think this is desirable as then for the initial sync case, the receiver can\n> *precisely* control their \"verification load\" to ensure they only process a\n> particular chunk at a time.\n>\n>\n> Fabrice wrote:\n> > We could add a `data` field which contains zipped ids like in\n> > `reply_channel_range` so we can query several items with a single\n> message ?\n>\n> I think this is an excellent idea! It would allow batched requests in\n> response to a channel range message. I'm not so sure we need to jump\n> *straight* to compressing everything however.\n>\n> > We could add an additional `encoding_type` field before `data` (or it\n> > could be the first byte of `data`)\n>\n> Great minds think alike :-)\n>\n>\n> If we're in rough agreement generally about this initial \"kick can\"\n> approach, I'll start implementing some of this in a prototype branch for\n> lnd. I'm very eager to solve the zombie churn, and initial burst that can\n> be\n> very hard on light clients.\n>\n> -- Laolu\n>\n>\n> On Wed, Feb 21, 2018 at 10:03 AM Fabrice Drouin <fabrice.drouin at acinq.fr>\n> wrote:\n>\n>> On 20 February 2018 at 02:08, Rusty Russell <rusty at rustcorp.com.au>\n>> wrote:\n>> > Hi all,\n>> >\n>> >         This consumed much of our lightning dev interop call today!  But\n>> > I think we have a way forward, which is in three parts, gated by a new\n>> > feature bitpair:\n>>\n>> We've built a prototype with a new feature bit `channel_range_queries`\n>> and the following logic:\n>> When you receive their init message and check their local features\n>> - if they set `initial_routing_sync` and `channel_range_queries` then\n>> do nothing (they will send you a `query_channel_range`)\n>> - if they set `initial_routing_sync` and not `channel_range_queries`\n>> then send your routing table (as before)\n>> - if you support `channel_range_queries` then send a\n>> `query_channel_range` message\n>>\n>> This way new and old nodes should be able to understand each other\n>>\n>> > 1. query_short_channel_id\n>> > =========================\n>> >\n>> > 1. type: 260 (`query_short_channel_id`)\n>> > 2. data:\n>> >    * [`32`:`chain_hash`]\n>> >    * [`8`:`short_channel_id`]\n>>\n>> We could add a `data` field which contains zipped ids like in\n>> `reply_channel_range` so we can query several items with a single\n>> message ?\n>>\n>> > 1. type: 262 (`reply_channel_range`)\n>> > 2. data:\n>> >    * [`32`:`chain_hash`]\n>> >    * [`4`:`first_blocknum`]\n>> >    * [`4`:`number_of_blocks`]\n>> >    * [`2`:`len`]\n>> >    * [`len`:`data`]\n>>\n>> We could add an additional `encoding_type` field before `data` (or it\n>> could be the first byte of `data`)\n>>\n>> > Appendix A: Encoding Sizes\n>> > ==========================\n>> >\n>> > I tried various obvious compression schemes, in increasing complexity\n>> > order (see source below, which takes stdin and spits out stdout):\n>> >\n>> >         Raw = raw 8-byte stream of ordered channels.\n>> >         gzip -9: gzip -9 of raw.\n>> >         splitgz: all blocknums first, then all txnums, then all\n>> outnums, then gzip -9\n>> >         delta: CVarInt encoding:\n>> blocknum_delta,num,num*txnum_delta,num*outnum.\n>> >         deltagz: delta, with gzip -9\n>> >\n>> > Corpus 1: LN mainnet dump, 1830 channels.[1]\n>> >\n>> >         Raw: 14640 bytes\n>> >         gzip -9: 6717 bytes\n>> >         splitgz: 6464 bytes\n>> >         delta: 6624 bytes\n>> >         deltagz: 4171 bytes\n>> >\n>> > Corpus 2: All P2SH outputs between blocks 508000-508999 incl, 790844\n>> channels.[2]\n>> >\n>> >         Raw: 6326752 bytes\n>> >         gzip -9: 1861710 bytes\n>> >         splitgz: 964332 bytes\n>> >         delta: 1655255 bytes\n>> >         deltagz: 595469 bytes\n>> >\n>> > [1] http://ozlabs.org/~rusty/short_channels-mainnet.xz\n>> > [2] http://ozlabs.org/~rusty/short_channels-all-p2sh-508000-509000.xz\n>> >\n>>\n>> Impressive!\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180225/3253059c/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-02-26T05:37:26",
                "message_text_only": "Olaoluwa Osuntokun <laolu32 at gmail.com> writes:\n> Hi Rusty,\n>\n>> 1. query_short_channel_id\n>> IMPLEMENTATION: trivial\n>\n> *thumbs up*\n\nOK, I'm implementing this now, with data packing so we can have more\nthan one.  (Current 0 and the straight array, will then be able to\nassess how impactful adding a simple encoder is).\n\n>> 2. query_channel_range/reply_channel_range\n>> IMPLEMENTATION: requires channel index by block number, zlib\n>\n> For the sake of expediency of deployment, if we add a byte (or two) to\n> denote the encoding/compression scheme, we can immediately roll out the\n> vanilla (just list the ID's), then progressively roll out more\n> context-specific optimized schemes.\n\nMeh, zlib is pretty trivial for all implementations though.\n\nWill implement and see how long it takes me though.\n\n>> 3. A gossip_timestamp field in `init`\n>> This is a new field appended to `init`: the negotiation of this feature\n> bit\n>> overrides `initial_routing_sync`\n>\n> As I've brought up before, from my PoV, we can't append any additional\n> fields to the innit message as it already contains *two* variable sized\n> fields (and no fixed size fields). Aside from this, it seems that the\n> `innit` message should be simply for exchange versioning information, which\n> may govern exactly *which* messages are sent after it. Otherwise, by adding\n> _additional_ fields to the `innit` message, we paint ourselves in a corner\n> and can never remove it. Compared to using the `innit` message to set up the\n> initial session context, where we can safely add other bits to nullify or\n> remove certain expected messages.\n\nI don't see this argument at all; we can add fields, we can remove them,\nbut we still have to transmit them which wastes a little space.\n\nAdding a new field and insist it be next packet is a weird ordering\ncontraint, which AFAICT is unique in the protocol.\n\n> Another advantage of making this a distinct message, is that either party\n> can at any time update this horizon/filter to ensure that they only receive\n> the *freshest* updates.Otherwise, one can image a very long lived\n> connections (say weeks) and the remote party keeps sending me very dated\n> updates (wasting bandwidth) when I only really want the *latest*.\n>\n> This can incorporate decker's idea about having a high+low timestamp. I\n> think this is desirable as then for the initial sync case, the receiver can\n> *precisely* control their \"verification load\" to ensure they only process a\n> particular chunk at a time.\n\nThis is a more convincing argument.  I guess we'll have to index by\ntimestamp (we currently index by receive order only); I was hoping we\ncould get away with a single brute-force traverse when the peer\ninitially connected.\n\nSo, let's say `channel_range_queries` means don't send *any* gossip\nmessages until asked (presumably from `gossip_set_timestamp_range`);\nwe'd implement this by setting the peer's timestamp range to 0,0.\n\nReceiving a new `gossip_set_timestamp_range` would override any\nprevious.\n\nOK, I'm hacking together now to see if I've missed anything before\nproposing a proper spec...\n\nCheers,\nRusty."
            },
            {
                "author": "Christian Decker",
                "date": "2018-02-28T21:38:01",
                "message_text_only": "Olaoluwa Osuntokun <laolu32 at gmail.com> writes:\n> As I've brought up before, from my PoV, we can't append any additional\n> fields to the innit message as it already contains *two* variable sized\n> fields (and no fixed size fields). Aside from this, it seems that the\n> `innit` message should be simply for exchange versioning information, which\n> may govern exactly *which* messages are sent after it. Otherwise, by adding\n> _additional_ fields to the `innit` message, we paint ourselves in a corner\n> and can never remove it. Compared to using the `innit` message to set up the\n> initial session context, where we can safely add other bits to nullify or\n> remove certain expected messages.\n\nWhile I do agree that a new message with high and low watermarks for a\nsync controlled by the recipient is the way to go, I just don't see the\nissue with extending the `init` message (and I think it may be useful in\nfuture, which is why I bring it up). The two variable size fields are\nlength prefixed so we know exactly what their size is, and where they\nend, so a new field added to the end can be trivially identified as\nsuch. As pointed out in my first mail, we'd have to make it mandatory\nfor the recipient to understand the new field, since it cannot be\nskipped if the recipient does not, but this still doesn't preclude\nadding such a field.\n\nAs for the overflow issue you mention, a single features bitfield is\nalready sufficient to completely overflow the `init` message length,\nsince it's prefix is 2 bytes, allowing for 65535 bytes for that single\nfield alone, in a message that only has 65533 bytes of payload left. But\nthe sender would have to be bonkers to overflow the message and then try\nsomething with the appended field. It'd overflow in the next packet\nsince we can't even tell the recipient that we have >65535 bytes of\npayload, and it'd fail the HMAC check. IMHO the connection would simply\nbe stopped right there, and the sender just found a very contorted way\nof closing the connection :-)\n\nIn the good case however the `init` message can look something like\nthis:\n\n - [2:gflen]\n - [gflen:globalfeatures]\n - [2:lflen]\n - [lflen:localfeatures]\n - [4:lowwatermark]\n - [4:highwatermark]\n\nMaybe I'm just not seeing it, and if that's the case I apologize :-)\n\nCheers,\nChristian"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-02-26T01:43:56",
                "message_text_only": "Fabrice Drouin <fabrice.drouin at acinq.fr> writes:\n> On 20 February 2018 at 02:08, Rusty Russell <rusty at rustcorp.com.au> wrote:\n>> Hi all,\n>>\n>>         This consumed much of our lightning dev interop call today!  But\n>> I think we have a way forward, which is in three parts, gated by a new\n>> feature bitpair:\n>\n> We've built a prototype with a new feature bit `channel_range_queries`\n> and the following logic:\n> When you receive their init message and check their local features\n> - if they set `initial_routing_sync` and `channel_range_queries` then\n> do nothing (they will send you a `query_channel_range`)\n> - if they set `initial_routing_sync` and not `channel_range_queries`\n> then send your routing table (as before)\n> - if you support `channel_range_queries` then send a\n> `query_channel_range` message\n\nThat seems logical; in this way, channel_range_queries obsoletes\ninitial_routing_sync.\n\n>> 1. query_short_channel_id\n>> =========================\n>>\n>> 1. type: 260 (`query_short_channel_id`)\n>> 2. data:\n>>    * [`32`:`chain_hash`]\n>>    * [`8`:`short_channel_id`]\n>\n> We could add a `data` field which contains zipped ids like in\n> `reply_channel_range` so we can query several items with a single\n> message ?\n\nWe could, let's use the same compression format as we decide for the\n`reply_channel_range` `data` field.\n\n>\n>> 1. type: 262 (`reply_channel_range`)\n>> 2. data:\n>>    * [`32`:`chain_hash`]\n>>    * [`4`:`first_blocknum`]\n>>    * [`4`:`number_of_blocks`]\n>>    * [`2`:`len`]\n>>    * [`len`:`data`]\n>\n> We could add an additional `encoding_type` field before `data` (or it\n> could be the first byte of `data`)\n\nYes, let's put it in first byte of data.\n\n>> I tried various obvious compression schemes, in increasing complexity\n>> order (see source below, which takes stdin and spits out stdout):\n>>\n>>         Raw = raw 8-byte stream of ordered channels.\n>>         gzip -9: gzip -9 of raw.\n>>         splitgz: all blocknums first, then all txnums, then all outnums, then gzip -9\n>>         delta: CVarInt encoding: blocknum_delta,num,num*txnum_delta,num*outnum.\n>>         deltagz: delta, with gzip -9\n>>\n>> Corpus 1: LN mainnet dump, 1830 channels.[1]\n>>\n>>         Raw: 14640 bytes\n>>         gzip -9: 6717 bytes\n>>         splitgz: 6464 bytes\n>>         delta: 6624 bytes\n>>         deltagz: 4171 bytes\n>>\n>> Corpus 2: All P2SH outputs between blocks 508000-508999 incl, 790844 channels.[2]\n>>\n>>         Raw: 6326752 bytes\n>>         gzip -9: 1861710 bytes\n>>         splitgz: 964332 bytes\n>>         delta: 1655255 bytes\n>>         deltagz: 595469 bytes\n>>\n>> [1] http://ozlabs.org/~rusty/short_channels-mainnet.xz\n>> [2] http://ozlabs.org/~rusty/short_channels-all-p2sh-508000-509000.xz\n>\n> Impressive!\n\nWhich method did you prefer?  splitgz is trivial, deltagz is better but\nrequires some actual work.  We should pick one and make that `version\n0`.\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Improving the initial gossip sync",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Fabrice Drouin",
                "Rusty Russell",
                "Jim Posen",
                "Olaoluwa Osuntokun",
                "ZmnSCPxj",
                "Christian Decker"
            ],
            "messages_count": 18,
            "total_messages_chars_count": 90543
        }
    },
    {
        "title": "[Lightning-dev] AMP: Atomic Multi-Path Payments over Lightning",
        "thread_messages": [
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-02-06T05:26:30",
                "message_text_only": "Hi Y'all,\n\nA common question I've seen concerning Lightning is: \"I have five $2\nchannels, is it possible for me to *atomically* send $6 to fulfill a\npayment?\". The answer to this question is \"yes\", provided that the receiver\nwaits to pull all HTLC's until the sum matches their invoice. Typically, one\nassumes that the receiver will supply a payment hash, and the sender will\nre-use the payment hash for all streams. This has the downside of payment\nhash re-use across *multiple* payments (which can already easily be\ncorrelated), and also has a failure mode where if the sender fails to\nactually satisfy all the payment flows, then the receiver can still just\npull the monies (and possibly not disperse a service, or w/e).\n\nConner Fromknecht and I have come up with a way to achieve this over\nLightning while (1) not re-using any payment hashes across all payment\nflows, and (2) adding a *strong* guarantee that the receiver won't be paid\nuntil *all* partial payment flows are extended. We call this scheme AMP\n(Atomic Multi-path Payments). It can be experimented with on Lightning\n*today* with the addition of a new feature bit to gate this new\nfeature. The beauty of the scheme is that it requires no fundamental changes\nto the protocol as is now, as the negotiation is strictly *end-to-end*\nbetween sender and receiver.\n\nTL;DR: we repurpose some unused space in the onion per-hop payload of the\nonion blob to signal our protocol (and deliver some protocol-specific data),\nthen use additive secret sharing to ensure that the receiver can't pull the\npayment until they have enough shares to reconstruct the original pre-image.\n\n\nProtocol Goals\n==============\n1. Atomicity: The logical transaction should either succeed or fail in\nentirety. Naturally, this implies that the receiver should not be unable to\nsettle *any* of the partial payments, until all of them have arrived.\n\n2. Avoid Payment Hash Reuse: The payment preimages validated by the\nconsensus layer should be distinct for each partial payment.  Primarily,\nthis helps avoid correlation of the partial payments, and ensures that\nmalicious intermediaries straddling partial payments cannot steal funds.\n\n3. Order Invariance: The protocol should be forgiving to the order in which\npartial payments arrive at the destination, adding robustness in the face of\ndelays or routing failures.\n\n4. Non-interactive Setup: It should be possible for the sender to perform an\nAMP without directly coordinating with the receiving node. Predominantly,\nthis means that the *sender* is able to determine the number of partial\npayments to use for a particular AMP, which makes sense since they will be\nthe one fronting the fees for the cost of this parameter. Plus, we can\nalways turn a non-interactive protocol into an interactive one for the\npurposes of invoicing.\n\n\nProtocol Benefits\n=================\n\nSending pay payments predominantly over an AMP-like protocol has several\nclear benefits:\n\n  - Eliminates the constraint that a single path from sender to receiver\n    with sufficient directional capacity. This reduces the pressure to have\n    larger channels in order to support larger payment flows. As a result,\n    the payment graph be very diffused, without sacrificing payment\n    utility\n\n  - Reduces strain from larger payments on individual paths, and allows the\n    liquidity imbalances to be more diffuse. We expect this to have a\n    non-negligible impact on channel longevity. This is due to the fact that\n    with usage of AMP, payment flows are typically *smaller* meaning that\n    each payment will unbalance a channel to a lesser degree that\n    with one giant flow.\n\n  - Potential fee savings for larger payments, contingent on there being a\n    super-linear component to routed fees. It's possible that with\n    modifications to the fee schedule, it's actually *cheaper* to send\n    payments over multiple flows rather than one giant flow.\n\n  - Allows for logical payments larger than the current maximum value of an\n    individual payment. Atm we have a (temporarily) limit on the max payment\n    size. With AMP, this can be side stepped as each flow can be up the max\n    size, with the sum of all flows exceeding the max.\n\n  - Given sufficient path diversity, AMPs may improve the privacy of LN\n    Intermediaries are now unaware to how much of the total payment they are\n    forwarding, or even if they are forwarding a partial payment at all.\n\n  - Using smaller payments increases the set of possible paths a partial\n    payment could have taken, which reduces the effectiveness of static\n    analysis techniques involving channel capacities and the plaintext\n    values being forwarded.\n\n\nProtocol Overview\n==================\nThis design can be seen as a generalization of the single, non-interactive\npayment scheme, that uses decoding of extra onion blobs (EOBs?) to encode\nextra data for the receiver. In that design, the extra data includes a\npayment preimage that the receiver can use to settle back the payment. EOBs\nand some method of parsing them are really the only requirement for this\nprotocol to work. Thus, only the sender and receiver need to implement this\nfeature in order for it to function, which can be announced using a feature\nbit.\n\nFirst, let's review the current format of the per-hop payload for each node\ndescribed in BOLT-0004.\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Realm (1 byte) \u2502Next Addr (8 bytes)\u2502Amount (8 bytes)\u2502Outgoing CLTV (4\nbytes)\u2502Unused (12 bytes)\u2502 HMAC (32 bytes) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u25a0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25a0\n                                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                              \u250265 Bytes Per Hop \u2502\n                                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nCurrently, *each* node gets a 65-byte payload. We use this payload to give\neach node instructions on *how* to forward a payment. We tell each node: the\nrealm (or chain to forward on), then next node to forward to, the amount to\nforward (this is where fees are extracted by forwarding out less than in),\nthe outgoing CLTV (allows verification that the prior node didn't modify any\nvalues), and finally an HMAC over the entire thing.\n\nTwo important points:\n  1. We have 12 bytes for each hop that are currently unpurposed and can be\n  used by application protocols to signal new interpretation of bytes and\n  also deliver additional encrypted+authenticated data to *each* hop.\n\n  2. The protocol currently has a hard limit of 20-hops. With this feature\n  we ensure that the packet stays fixed sized during processing in order to\n  avoid leaking positional information. Typically most payments won't use\n  all 20 hops, as a result, we can use the remaining hops to stuff in *even\n  more* data.\n\n\nProtocol Description\n====================\nThe solution we propose is Atomic Multi-path Payments (AMPs). At a high\nlevel, this leverages EOBs to deliver additive shares of a base preimage,\nfrom which the payment preimages of partial payments can be derived. The\nreceiver can only construct this value after having received all of the\npartial payments, satisfying the atomicity constraint.\n\nThe basic protocol:\n\nPrimitives\n==========\nLet H be a CRH function.\nLet || denote concatenation.\nLet ^ denote xor.\n\n\nSender Requirements\n===================\nThe parameters to the sending procedure are a random identifier ID, the\nnumber of partial payments n, and the total payment value V. Assume the\nsender has some way of dividing V such that V = v_1 + \u2026 + v_n.\n\nTo begin, the sender builds the base preimage BP, from which n partial\npreimages will be derived. Next, the sender samples n additive shares s_1,\n\u2026, s_n, and takes the sum to compute BP = s_1 ^ \u2026 ^ s_n.\n\nWith the base preimage created, the sender now moves on to constructing the\nn partial payments. For each i in [1,n], the sender deterministically\ncomputes the partial preimage r_i = H(BP ||  i), by concatenating the\nsequence number i to the base preimage and hashing the result. Afterwards,\nit applies H to determine the payment hash to use in the i\u2019th partial\npayment as h_i = H(r_i). Note that that with this preimage derivation\nscheme, once the payments are pulled each pre-image is distinct and\nindistinguishable from any other.\n\nWith all of the pieces in place, the sender initiates the i\u2019th payment by\nconstructing a route to the destination with value v_i and payment hash h_i.\nThe tuple (ID, n, s_i) is included in the EOB to be opened by the receiver.\n\nIn order to include the three tuple within the per-hop payload for the final\ndestination, we repurpose the _first_ byte of the un-used padding bytes in\nthe payload to signal version 0x01 of the AMP protocol (note this is a PoC\noutline, we would need to standardize signalling of these 12 bytes to\nsupport other protocols). Typically this byte isn't set, so the existence of\nthis means that we're (1) using AMP, and (2) the receiver should consume the\n_next_ hop as well. So if the payment length is actually 5, the sender tacks\non an additional dummy 6th hop, encrypted with the _same_ shared secret for\nthat hop to deliver the e2e encrypted data.\n\nNote, the sender can retry partial payments just as they would normal\npayments, since they are order invariant, and would be indistinguishable\nfrom regular payments to intermediaries in the network.\n\n\nReceiver Requirements\n=====================\n\nUpon the arrival of each partial payment, the receiver will iteratively\nreconstruct BP, and do some bookkeeping to figure out when to settle the\npartial payments. During this reconstruction process, the receiver does not\nneed to be aware of the order in which the payments were sent, and in fact\nnothing about the incoming partial payments reveals this information to the\nreceiver, though this can be learned after reconstructing BP.\n\nEach EOB is decoded to retrieve (ID, n, s_i), where i is the unique but\nunknown index of the incoming partial payment. The receiver has access to\npersistent key-value store DB that maps ID to (n, c*, BP*), where c*\nrepresents the number of partial payments received, BP* is the sum of the\nreceived additive shares, and the superscript * denotes that the value is\nbeing updated iteratively. c* and BP* both have initial values of 0.\n\nIn the basic protocol, the receiver cache\u2019s the first n it sees, and\nverifies that all incoming partial payments have the same n. The receiver\nshould reject all partial payments if any EOB deviates.  Next, the we update\nour persistent store with DB[ID] = (n, c* + 1, BP* ^ s_i), advancing the\nreconstruction by one step.\n\nIf c* + 1 < n, there are still more packets in flight, so we sit tight.\nOtherwise, the receiver assumes all partial payments have arrived, and can\nbeing settling them back. Using the base preimage BP = BP* ^ s_i from our\nfinal iteration, the receiver can re-derive all n partial preimages and\npayment hashes, using r_i = H(BP || i) and h_i = H(r_i) simply through\nknowledge of n and BP.\n\nFinally, the receiver settles back any outstanding payments that include\npayment hash h_i using the partial preimage r_i. Each r_i will appear random\ndue to the nature of H, as will it\u2019s corresponding h_i. Thus, each partial\npayment should appear uncorrelated, and does not reveal that it is part of\nan AMP nor the number of partial payments used.\n\nNon-interactive to Interactive AMPs\n===================================\n\nSender simply receives an ID and amount from the receiver in an invoice\nbefore initiating the protocol. The receiver should only consider the\ninvoice settled if the total amount received in partial payments containing\nID matches or exceeds the amount specified in the invoice. With this\nvariant, the receiver is able to map all partial payments to a pre-generated\ninvoice statement.\n\n\nAdditive Shares vs Threshold-Shares\n===================================\n\nThe biggest reason to use additive shares seems to be atomicity. Threshold\nshares open the door to some partial payments being settled, even if others\nare left in flight. Haven\u2019t yet come up with a good reason for using\nthreshold schemes, but there seem to be plenty against it.\n\nReconstruction of additive shares can be done iteratively, and is win for\nthe storage and computation requirements on the receiving end. If the sender\ndecides to use fewer than n partial payments, the remaining shares could be\nincluded in the EOB of the final partial payment to allow the sender to\nreconstruct sooner. Sender could also optimistically do partial\nreconstruction on this last aggregate value.\n\n\nAdaptive AMPs\n=============\n\nThe sender may not always be aware of how many partial payments they wish to\nsend at the time of the first partial payment, at which point the simplified\nprotocol would require n to be chosen. To accommodate, the above scheme can\nbe adapted to handle a dynamically chosen n by iteratively constructing the\nshared secrets as follows.\n\nStarting with a base preimage BP, the key trick is that the sender remember\nthe difference between the base preimage and the sum of all partial\npreimages used so far. The relation is described using the following\nequations:\n\n    X_0 = 0\n    X_i = X_{i-1} ^ s_i\n    X_n = BP ^ X_{n-1}\n\nwhere if n=1, X_1 = BP, implying that this is in fact a generalization of\nthe single, non-interactive payment scheme mentioned above. For i=1, ...,\nn-1, the sender sends s_i in the EOB, and  X_n for the n-th share.\n\nIteratively reconstructing s_1 ^ \u2026. ^ s_{n-1} ^ X_n = BP, allows the\nreceiver to compute all relevant r_i = H(BP || i) and h_i = H(r_i). Lastly,\nthe final number of partial payments n could be signaled in the final EOB,\nwhich would also serve as a sentinel value for signaling completion. In\nresponse to DOS vectors stemming from unknown values of n, implementations\ncould consider advertising a maximum value for n, or adopting some sort of\nframing pattern for conveying that more partial payments are on the way.\n\nWe can further modify our usage of the per-hop payloads to send (H(BP),\ns_i) to\nconsume most of the EOB sent from sender to receiver. In this scenario, we'd\nrepurpose the 11-bytes *after* our signalling byte in the unused byte\nsection\nto store the payment ID (which should be unique for each payment). In the\ncase\nof a non-interactive payment, this will be unused. While for interactive\npayments, this will be the ID within the invoice. To deliver this slimmer\n2-tuple, we'll use 32-bytes for the hash of the BP, and 32-bytes for the\npartial pre-image share, leaving an un-used byte in the payload.\n\n\nCross-Chain AMPs\n================\n\nAMPs can be used to pay a receiver in multiple currencies atomically...which\nis pretty cool :D\n\n\nOpen Research Questions\n=======================\n\nThe above is a protocol sketch to achieve atomic multi-path payments over\nLightning. The details concerning onion blob usage serves as a template that\nfuture protocols can draw upon in order to deliver additional data to *any*\nhop in the route. However, there are still a few open questions before\nsomething like this can be feasibly deployed.\n\n1. How does the sender decide how many chunked payments to send, and the\nsize of each payment?\n\n  - Upon a closer examination, this seems to overlap with the task of\n    congestion control within TCP. The sender may be able to utilize\n    inspired heuristics to gauge: (1) how large the initial payment should\nbe\n    and (2) how many subsequent payments may be required. Note that if the\n    first payment succeeds, then the exchange is over in a signal round.\n\n2. How can AMP and HORNET be composed?\n\n  - If we eventually integrate HORNET, then a distinct communications\n    sessions can be established to allow the sender+receiver to exchange\n    up-to-date partial payment information. This may allow the sender to\nmore\n    accurately size each partial payment.\n\n3. Can the sender's initial strategy be governed by an instance of the\nPush-relabel max flow algo?\n\n4. How does this mesh with the current max HTLC limit on a commitment?\n\n   - ATM, we have a max limit on the number of active HTLC's on a particular\n     commitment transaction. We do this, as otherwise it's possible that the\n     transaction is too large, and exceeds standardness w.r.t transaction\n     size. In a world where most payments use an AMP-like protocol, then\n     overall ant any given instance there will be several pending HTLC's on\n     commitments network wise.\n\n     This may incentivize nodes to open more channels in order to support\n     the increased commitment space utilization.\n\n\nConclusion\n==========\n\nWe've presented a design outline of how to integrate atomic multi-path\npayments (AMP) into Lightning. The existence of such a construct allows a\nsender to atomically split a payment flow amongst several individual payment\nflows. As a result, larger channels aren't as important as it's possible to\nutilize one total outbound payment bandwidth to send several channels.\nAdditionally, in order to support the increased load, internal routing nodes\nare incensed have more active channels. The existence of AMP-like payments\nmay also increase the longevity of channels as there'll be smaller, more\nnumerous payment flows, making it unlikely that a single payment comes\nacross unbalances a channel entirely. We've also showed how one can utilize\nthe current onion packet format to deliver additional data from a sender to\nreceiver, that's still e2e authenticated.\n\n\n-- Conner && Laolu\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180206/8c4a40c4/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-02-06T07:12:09",
                "message_text_only": "Good morning Laolu,\n\nThis is excellent work!\n\nSome minor comments...\n\n> (Atomic Multi-path Payments). It can be experimented with on Lightning\n> *today* with the addition of a new feature bit to gate this new\n> feature. The beauty of the scheme is that it requires no fundamental changes\n> to the protocol as is now, as the negotiation is strictly *end-to-end*\n> between sender and receiver.\n\nI think, a `globalfeatures` odd bit could be used for this.  As it is end-ot-end, `localfeatures` is not appropriate.\n\n>   - Potential fee savings for larger payments, contingent on there being a\n>     super-linear component to routed fees. It's possible that with\n>     modifications to the fee schedule, it's actually *cheaper* to send\n>     payments over multiple flows rather than one giant flow.\n\nI believe, currently, fees have not this super-linear component.  Indeed, the existence of per-hop fees (`fee_base_msat`) means, splitting the payment over multiple flows will be, very likely, more expensive, compared to using a single flow.  Tiny roundoffs in computing the proportional fees (`fee_proportional_millionths`) may make smaller flows give a slight fee advantage, but I think the multiplication of per-hop fees will dominate.\n\n>   - Using smaller payments increases the set of possible paths a partial\n>     payment could have taken, which reduces the effectiveness of static\n>     analysis techniques involving channel capacities and the plaintext\n>     values being forwarded.\n\nStrongly agree!\n\n> In order to include the three tuple within the per-hop payload for the final\n> destination, we repurpose the _first_ byte of the un-used padding bytes in\n> the payload to signal version 0x01 of the AMP protocol (note this is a PoC\n> outline, we would need to standardize signalling of these 12 bytes to\n> support other protocols).\n\nI believe the `realm` byte is intended for this.  Intermediate nodes do not need to understand realm bytes that are understood by other nodes in the route, including the realm bytes understood by the final destination, as intermediate nodes cannot, indeed, read the hop data of other nodes.  Thus, you can route over nodes that are unaware of AMP, and only provide an AMP realm byte to the destination node, who, is able to reconstruct this your AMP data as per your algorithm.\n\nIndeed, the `realm` byte controls the interpretation of the rest of the 65-byte packet.  If you define, instead, a separate `realm` that is understood by the destination node, you can redefine the entire 64 bytes of the final hop data as you wish.\n\nIf we support AMP only at final payees, we can completely redefine the 64 bytes in the final hop data for the new AMP `realm`, and not consume the next hop (which would reduce route length by 1).\n\n(If we want to support multiple routes converging to an intermediate node, then continue routing to a different final node after routes have merged (i.e. A->B->C->D, and A->E->C->D, with the payment being merged by C, who forwards the combination to D), then we need to follow the current hop data format, but I think supporting AMP at final payees is actually enough... AMP at intermediate nodes might not be used often enough by senders for it to matter, as taking advantage of that seems more complex than just asking your routing algo to provide you multiple routes to a destination, which you are probably already doing)\n\n----\n\nOverall, good work I think.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180206/3dcd9d0b/attachment.html>"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-02-07T00:03:45",
                "message_text_only": "Hi ZmnSCPxj,\n\n> This is excellent work!\n\nThanks!\n\n> I think, a `globalfeatures` odd bit could be used for this.  As it is\n> end-ot-end, `localfeatures` is not appropriate.\n\nYep, it would need to be a global feature bit. In the case that we're\nsending to a destination which isn't publicly advertised, then perhaps an\nextension to BOLT-11 could be made to signal receiver support.\n\n> I believe, currently, fees have not this super-linear component\n\nYep they don't. Arguably, we should also have a component that scales\naccording to the proposed CLTV value of the outgoing HTLC. At Scaling\nBitcoin Stanford, Aviv Zohar gave a talked titled \"How to Charge Lightning\"\nwhere the authors analyzed the possible evolution of fees on the network\n(and also suggested adding this super-linear component to extend the\nlifetime of channels).  However, the talk itself focused on a very simple\n\"mega super duper hub\" topology. Towards the end he alluded to a forthcoming\npaper that had more comprehensive analysis of more complex topologies. I\nlook forward to the publication of their finalized work.\n\n> Indeed, the existence of per-hop fees (`fee_base_msat`) means, splitting\n> the payment over multiple flows will be, very likely, more expensive,\n> compared to using a single flow.\n\nWell it's still to be seen how the fee structure on mainnet emerges once the\nnetwork is still fully bootstrapped. AFAIK, most running on mainnet atm are\nusing the default fee schedules for their respective implementations. For\nexample, the default fee_base_msat for lnd is 1000 msat (1 satoshi).\n\n> I believe the `realm` byte is intended for this.\n\nThe realm byte is meant to signal \"forward this to the dogecoin channel\".\nATM, we just default to 0 as \"Bitcoin\". However, the byte itself only really\nneed significance between the sender and the intermediate node. So there\nisn't necessarily pressure to have a globally synchronized set of realm\nbytes.\n\n> Thus, you can route over nodes that are unaware of AMP, and only provide\n> an AMP realm byte to the destination node, who, is able to reconstruct\nthis\n> your AMP data as per your algorithm.\n\nYes, the intermediate nodes don't need to be aware of the end-to-end\nprotocol. For the final hop, there are actually 53 free bytes (before one\nneeds to signal the existence of EOBs):\n\n  * 1 byte realm\n  * 8 bytes next addr (all zeroes to signal final dest)\n  * 32 bytes hmac (also all zeroes for the final dest)\n  * 12 bytes padding\n\nSo any combo of these bytes can be used to signal more advanced protocols to\nthe final destination.\n\n\nA correction from the prior email description:\n\n> We can further modify our usage of the per-hop payloads to send\n> (H(BP), s_i) to consume most of the EOB sent from sender to receiver.\n\nThis should actually be (H(s_0 || s_1 || ...), s_i). So we still allow them\nto check this finger print to see if they have all the final shares, but\ndon't allow them to preemptively pull all the payments.\n\n\n-- Laolu\n\n\nOn Mon, Feb 5, 2018 at 11:12 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Laolu,\n>\n> This is excellent work!\n>\n> Some minor comments...\n>\n>\n> (Atomic Multi-path Payments). It can be experimented with on Lightning\n> *today* with the addition of a new feature bit to gate this new\n> feature. The beauty of the scheme is that it requires no fundamental\n> changes\n> to the protocol as is now, as the negotiation is strictly *end-to-end*\n> between sender and receiver.\n>\n>\n> I think, a `globalfeatures` odd bit could be used for this.  As it is\n> end-ot-end, `localfeatures` is not appropriate.\n>\n>   - Potential fee savings for larger payments, contingent on there being a\n>     super-linear component to routed fees. It's possible that with\n>     modifications to the fee schedule, it's actually *cheaper* to send\n>     payments over multiple flows rather than one giant flow.\n>\n>\n> I believe, currently, fees have not this super-linear component.  Indeed,\n> the existence of per-hop fees (`fee_base_msat`) means, splitting the\n> payment over multiple flows will be, very likely, more expensive, compared\n> to using a single flow.  Tiny roundoffs in computing the proportional fees\n> (`fee_proportional_millionths`) may make smaller flows give a slight fee\n> advantage, but I think the multiplication of per-hop fees will dominate.\n>\n>\n>   - Using smaller payments increases the set of possible paths a partial\n>     payment could have taken, which reduces the effectiveness of static\n>     analysis techniques involving channel capacities and the plaintext\n>     values being forwarded.\n>\n>\n> Strongly agree!\n>\n>\n> In order to include the three tuple within the per-hop payload for the\n> final\n> destination, we repurpose the _first_ byte of the un-used padding bytes in\n> the payload to signal version 0x01 of the AMP protocol (note this is a PoC\n> outline, we would need to standardize signalling of these 12 bytes to\n> support other protocols).\n>\n>\n> I believe the `realm` byte is intended for this.  Intermediate nodes do\n> not need to understand realm bytes that are understood by other nodes in\n> the route, including the realm bytes understood by the final destination,\n> as intermediate nodes cannot, indeed, read the hop data of other nodes.\n> Thus, you can route over nodes that are unaware of AMP, and only provide an\n> AMP realm byte to the destination node, who, is able to reconstruct this\n> your AMP data as per your algorithm.\n>\n> Indeed, the `realm` byte controls the interpretation of the rest of the\n> 65-byte packet.  If you define, instead, a separate `realm` that is\n> understood by the destination node, you can redefine the entire 64 bytes of\n> the final hop data as you wish.\n>\n> If we support AMP only at final payees, we can completely redefine the 64\n> bytes in the final hop data for the new AMP `realm`, and not consume the\n> next hop (which would reduce route length by 1).\n>\n> (If we want to support multiple routes converging to an intermediate node,\n> then continue routing to a different final node after routes have merged\n> (i.e. A->B->C->D, and A->E->C->D, with the payment being merged by C, who\n> forwards the combination to D), then we need to follow the current hop data\n> format, but I think supporting AMP at final payees is actually enough...\n> AMP at intermediate nodes might not be used often enough by senders for it\n> to matter, as taking advantage of that seems more complex than just asking\n> your routing algo to provide you multiple routes to a destination, which\n> you are probably already doing)\n>\n> ----\n>\n> Overall, good work I think.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180207/3e9cf18e/attachment.html>"
            },
            {
                "author": "Conner Fromknecht",
                "date": "2018-02-07T02:14:45",
                "message_text_only": "Hi ZmnSCPxj and Laolu,\n\n>  Indeed, the existence of per-hop fees (`fee_base_msat`) means, splitting\nthe\n>  payment over multiple flows will be, very likely, more expensive,\ncompared to\n>  using a single flow.\n\nAs Laolu pointed out, we have yet to see how fees evolve on mainnet or what\nwill\nemerge as a sane, default fee schedules. I agree that if the same\nproportional\nfee is used across all partial payments, then it could certainly be more\nexpensive.\n\nHowever, it could also be the case that you were paying a needlessly high\nproportional fee to begin with, because paths of sufficient capacity to the\ndestination were scarce. In an AMP world, there will be an abundance of\nchannels\nthat can route small, partial payments, which may itself drive down the\ncompetitive fee rate for smaller payments. Just a hypothesis, we shall see\nwhere\nsupply meets demand!\n\nAt the end of the day, the user can always fall back to regular payment if\nthey\nexpect to end up paying more fees using an AMP.\n\n> (If we want to support multiple routes converging to an intermediate node,\n> then continue routing to a different final node after routes have merged\n(i.e.\n> A->B->C->D, and A->E->C->D, with the payment being merged by C, who\nforwards\n> the combination to D), then we need to follow the current hop data\nformat, but\n> I think supporting AMP at final payees is actually enough...\n\nI think this is an interesting idea, sounds maybe like a\nrecursive/hierarchical\nAMP? The ability to merge the payments seems like it would result in a\ndecent privacy\nleak, as I believe an intermediary would have enough evidence to prove that\ntwo\npayments were merged/correlated. Simple traffic analysis would also reveal a\ndiscrepancy in the number of incoming and outgoing packets, and possibly\nother\nobservable differences in routing (some) AMPs vs regular payments.\n\nFWIW the current proposal allows the paths of partial payments to overlap,\nin such a scenario C would just forward the HTLCs independently. One could\nsend\nthem all along the same path if they desired! I'm assuming the intent here\nis to\ntry and reduce total fees?\n\nMinor correction^2:\n\n> This should actually be (H(s_0 || s_1 || ...), s_i).\n\nThis assumes the receiver knows the indexes of each share. Without this\nknowledge they would have to brute force all orderings to check the\nfingerprint.\n\nTo maintain order invariance on the receiving end, I would propose sending\n(0, s_i) for the first n-1 partial payments, and then (n, s_i) on the final\none.\nAs in the description of the basic AMP scheme, the receiver maintains a\npersistent count of how many partial payments have been received for ID. If\nthe\nreceiver does not get the last payment last, the receiver just waits until\nall n\nhave been received before deciding that its reconstructed value is BP.\n\nThe receiver can verify they've received the correct BP and n by rederiving\nthe\npartial preimages r_i = H(BP || i) and checking that there are n outstanding\npayments, one for each h_i = H(r_i). This also saves the receiving node n\nadditional hash invocations.\n\n-Conner\n\nOn Tue, Feb 6, 2018 at 4:04 PM Olaoluwa Osuntokun <laolu32 at gmail.com> wrote:\n\n> Hi ZmnSCPxj,\n>\n> > This is excellent work!\n>\n> Thanks!\n>\n> > I think, a `globalfeatures` odd bit could be used for this.  As it is\n> > end-ot-end, `localfeatures` is not appropriate.\n>\n> Yep, it would need to be a global feature bit. In the case that we're\n> sending to a destination which isn't publicly advertised, then perhaps an\n> extension to BOLT-11 could be made to signal receiver support.\n>\n> > I believe, currently, fees have not this super-linear component\n>\n> Yep they don't. Arguably, we should also have a component that scales\n> according to the proposed CLTV value of the outgoing HTLC. At Scaling\n> Bitcoin Stanford, Aviv Zohar gave a talked titled \"How to Charge Lightning\"\n> where the authors analyzed the possible evolution of fees on the network\n> (and also suggested adding this super-linear component to extend the\n> lifetime of channels).  However, the talk itself focused on a very simple\n> \"mega super duper hub\" topology. Towards the end he alluded to a\n> forthcoming\n> paper that had more comprehensive analysis of more complex topologies. I\n> look forward to the publication of their finalized work.\n>\n> > Indeed, the existence of per-hop fees (`fee_base_msat`) means, splitting\n> > the payment over multiple flows will be, very likely, more expensive,\n> > compared to using a single flow.\n>\n> Well it's still to be seen how the fee structure on mainnet emerges once\n> the\n> network is still fully bootstrapped. AFAIK, most running on mainnet atm are\n> using the default fee schedules for their respective implementations. For\n> example, the default fee_base_msat for lnd is 1000 msat (1 satoshi).\n>\n> > I believe the `realm` byte is intended for this.\n>\n> The realm byte is meant to signal \"forward this to the dogecoin channel\".\n> ATM, we just default to 0 as \"Bitcoin\". However, the byte itself only\n> really\n> need significance between the sender and the intermediate node. So there\n> isn't necessarily pressure to have a globally synchronized set of realm\n> bytes.\n>\n> > Thus, you can route over nodes that are unaware of AMP, and only provide\n> > an AMP realm byte to the destination node, who, is able to reconstruct\n> this\n> > your AMP data as per your algorithm.\n>\n> Yes, the intermediate nodes don't need to be aware of the end-to-end\n> protocol. For the final hop, there are actually 53 free bytes (before one\n> needs to signal the existence of EOBs):\n>\n>   * 1 byte realm\n>   * 8 bytes next addr (all zeroes to signal final dest)\n>   * 32 bytes hmac (also all zeroes for the final dest)\n>   * 12 bytes padding\n>\n> So any combo of these bytes can be used to signal more advanced protocols\n> to\n> the final destination.\n>\n>\n> A correction from the prior email description:\n>\n> > We can further modify our usage of the per-hop payloads to send\n> > (H(BP), s_i) to consume most of the EOB sent from sender to receiver.\n>\n> This should actually be (H(s_0 || s_1 || ...), s_i). So we still allow them\n> to check this finger print to see if they have all the final shares, but\n> don't allow them to preemptively pull all the payments.\n>\n>\n> -- Laolu\n>\n>\n> On Mon, Feb 5, 2018 at 11:12 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n>> Good morning Laolu,\n>>\n>> This is excellent work!\n>>\n>> Some minor comments...\n>>\n>>\n>> (Atomic Multi-path Payments). It can be experimented with on Lightning\n>> *today* with the addition of a new feature bit to gate this new\n>> feature. The beauty of the scheme is that it requires no fundamental\n>> changes\n>> to the protocol as is now, as the negotiation is strictly *end-to-end*\n>> between sender and receiver.\n>>\n>>\n>> I think, a `globalfeatures` odd bit could be used for this.  As it is\n>> end-ot-end, `localfeatures` is not appropriate.\n>>\n>>   - Potential fee savings for larger payments, contingent on there being a\n>>     super-linear component to routed fees. It's possible that with\n>>     modifications to the fee schedule, it's actually *cheaper* to send\n>>     payments over multiple flows rather than one giant flow.\n>>\n>>\n>> I believe, currently, fees have not this super-linear component.  Indeed,\n>> the existence of per-hop fees (`fee_base_msat`) means, splitting the\n>> payment over multiple flows will be, very likely, more expensive, compared\n>> to using a single flow.  Tiny roundoffs in computing the proportional fees\n>> (`fee_proportional_millionths`) may make smaller flows give a slight fee\n>> advantage, but I think the multiplication of per-hop fees will dominate.\n>>\n>>\n>>   - Using smaller payments increases the set of possible paths a partial\n>>     payment could have taken, which reduces the effectiveness of static\n>>     analysis techniques involving channel capacities and the plaintext\n>>     values being forwarded.\n>>\n>>\n>> Strongly agree!\n>>\n>>\n>> In order to include the three tuple within the per-hop payload for the\n>> final\n>> destination, we repurpose the _first_ byte of the un-used padding bytes in\n>> the payload to signal version 0x01 of the AMP protocol (note this is a PoC\n>> outline, we would need to standardize signalling of these 12 bytes to\n>> support other protocols).\n>>\n>>\n>> I believe the `realm` byte is intended for this.  Intermediate nodes do\n>> not need to understand realm bytes that are understood by other nodes in\n>> the route, including the realm bytes understood by the final destination,\n>> as intermediate nodes cannot, indeed, read the hop data of other nodes.\n>> Thus, you can route over nodes that are unaware of AMP, and only provide an\n>> AMP realm byte to the destination node, who, is able to reconstruct this\n>> your AMP data as per your algorithm.\n>>\n>> Indeed, the `realm` byte controls the interpretation of the rest of the\n>> 65-byte packet.  If you define, instead, a separate `realm` that is\n>> understood by the destination node, you can redefine the entire 64 bytes of\n>> the final hop data as you wish.\n>>\n>> If we support AMP only at final payees, we can completely redefine the 64\n>> bytes in the final hop data for the new AMP `realm`, and not consume the\n>> next hop (which would reduce route length by 1).\n>>\n>> (If we want to support multiple routes converging to an intermediate\n>> node, then continue routing to a different final node after routes have\n>> merged (i.e. A->B->C->D, and A->E->C->D, with the payment being merged by\n>> C, who forwards the combination to D), then we need to follow the current\n>> hop data format, but I think supporting AMP at final payees is actually\n>> enough... AMP at intermediate nodes might not be used often enough by\n>> senders for it to matter, as taking advantage of that seems more complex\n>> than just asking your routing algo to provide you multiple routes to a\n>> destination, which you are probably already doing)\n>>\n>> ----\n>>\n>> Overall, good work I think.\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180207/686a561b/attachment.html>"
            },
            {
                "author": "Jim Posen",
                "date": "2018-02-07T08:36:35",
                "message_text_only": "This is a really neat idea.\n\nThis is a question about non-interactive payments in general, but is there\nany way to get a proof of payment? With regular invoices, knowledge of the\npreimage serves as cryptographic proof that the payment was delivered.\n\nOn Feb 6, 2018 6:26 PM, \"Conner Fromknecht\" <conner at lightning.engineering>\nwrote:\n\n>\n> Hi ZmnSCPxj and Laolu,\n>\n> >  Indeed, the existence of per-hop fees (`fee_base_msat`) means,\n> splitting the\n> >  payment over multiple flows will be, very likely, more expensive,\n> compared to\n> >  using a single flow.\n>\n> As Laolu pointed out, we have yet to see how fees evolve on mainnet or\n> what will\n> emerge as a sane, default fee schedules. I agree that if the same\n> proportional\n> fee is used across all partial payments, then it could certainly be more\n> expensive.\n>\n> However, it could also be the case that you were paying a needlessly high\n> proportional fee to begin with, because paths of sufficient capacity to the\n> destination were scarce. In an AMP world, there will be an abundance of\n> channels\n> that can route small, partial payments, which may itself drive down the\n> competitive fee rate for smaller payments. Just a hypothesis, we shall see\n> where\n> supply meets demand!\n>\n> At the end of the day, the user can always fall back to regular payment if\n> they\n> expect to end up paying more fees using an AMP.\n>\n> > (If we want to support multiple routes converging to an intermediate\n> node,\n> > then continue routing to a different final node after routes have merged\n> (i.e.\n> > A->B->C->D, and A->E->C->D, with the payment being merged by C, who\n> forwards\n> > the combination to D), then we need to follow the current hop data\n> format, but\n> > I think supporting AMP at final payees is actually enough...\n>\n> I think this is an interesting idea, sounds maybe like a\n> recursive/hierarchical\n> AMP? The ability to merge the payments seems like it would result in a\n> decent privacy\n> leak, as I believe an intermediary would have enough evidence to prove\n> that two\n> payments were merged/correlated. Simple traffic analysis would also reveal\n> a\n> discrepancy in the number of incoming and outgoing packets, and possibly\n> other\n> observable differences in routing (some) AMPs vs regular payments.\n>\n> FWIW the current proposal allows the paths of partial payments to overlap,\n> in such a scenario C would just forward the HTLCs independently. One could\n> send\n> them all along the same path if they desired! I'm assuming the intent here\n> is to\n> try and reduce total fees?\n>\n> Minor correction^2:\n>\n> > This should actually be (H(s_0 || s_1 || ...), s_i).\n>\n> This assumes the receiver knows the indexes of each share. Without this\n> knowledge they would have to brute force all orderings to check the\n> fingerprint.\n>\n> To maintain order invariance on the receiving end, I would propose sending\n> (0, s_i) for the first n-1 partial payments, and then (n, s_i) on the\n> final one.\n> As in the description of the basic AMP scheme, the receiver maintains a\n> persistent count of how many partial payments have been received for ID.\n> If the\n> receiver does not get the last payment last, the receiver just waits until\n> all n\n> have been received before deciding that its reconstructed value is BP.\n>\n> The receiver can verify they've received the correct BP and n by\n> rederiving the\n> partial preimages r_i = H(BP || i) and checking that there are n\n> outstanding\n> payments, one for each h_i = H(r_i). This also saves the receiving node n\n> additional hash invocations.\n>\n> -Conner\n>\n> On Tue, Feb 6, 2018 at 4:04 PM Olaoluwa Osuntokun <laolu32 at gmail.com>\n> wrote:\n>\n>> Hi ZmnSCPxj,\n>>\n>> > This is excellent work!\n>>\n>> Thanks!\n>>\n>> > I think, a `globalfeatures` odd bit could be used for this.  As it is\n>> > end-ot-end, `localfeatures` is not appropriate.\n>>\n>> Yep, it would need to be a global feature bit. In the case that we're\n>> sending to a destination which isn't publicly advertised, then perhaps an\n>> extension to BOLT-11 could be made to signal receiver support.\n>>\n>> > I believe, currently, fees have not this super-linear component\n>>\n>> Yep they don't. Arguably, we should also have a component that scales\n>> according to the proposed CLTV value of the outgoing HTLC. At Scaling\n>> Bitcoin Stanford, Aviv Zohar gave a talked titled \"How to Charge\n>> Lightning\"\n>> where the authors analyzed the possible evolution of fees on the network\n>> (and also suggested adding this super-linear component to extend the\n>> lifetime of channels).  However, the talk itself focused on a very simple\n>> \"mega super duper hub\" topology. Towards the end he alluded to a\n>> forthcoming\n>> paper that had more comprehensive analysis of more complex topologies. I\n>> look forward to the publication of their finalized work.\n>>\n>> > Indeed, the existence of per-hop fees (`fee_base_msat`) means, splitting\n>> > the payment over multiple flows will be, very likely, more expensive,\n>> > compared to using a single flow.\n>>\n>> Well it's still to be seen how the fee structure on mainnet emerges once\n>> the\n>> network is still fully bootstrapped. AFAIK, most running on mainnet atm\n>> are\n>> using the default fee schedules for their respective implementations. For\n>> example, the default fee_base_msat for lnd is 1000 msat (1 satoshi).\n>>\n>> > I believe the `realm` byte is intended for this.\n>>\n>> The realm byte is meant to signal \"forward this to the dogecoin channel\".\n>> ATM, we just default to 0 as \"Bitcoin\". However, the byte itself only\n>> really\n>> need significance between the sender and the intermediate node. So there\n>> isn't necessarily pressure to have a globally synchronized set of realm\n>> bytes.\n>>\n>> > Thus, you can route over nodes that are unaware of AMP, and only provide\n>> > an AMP realm byte to the destination node, who, is able to reconstruct\n>> this\n>> > your AMP data as per your algorithm.\n>>\n>> Yes, the intermediate nodes don't need to be aware of the end-to-end\n>> protocol. For the final hop, there are actually 53 free bytes (before one\n>> needs to signal the existence of EOBs):\n>>\n>>   * 1 byte realm\n>>   * 8 bytes next addr (all zeroes to signal final dest)\n>>   * 32 bytes hmac (also all zeroes for the final dest)\n>>   * 12 bytes padding\n>>\n>> So any combo of these bytes can be used to signal more advanced protocols\n>> to\n>> the final destination.\n>>\n>>\n>> A correction from the prior email description:\n>>\n>> > We can further modify our usage of the per-hop payloads to send\n>> > (H(BP), s_i) to consume most of the EOB sent from sender to receiver.\n>>\n>> This should actually be (H(s_0 || s_1 || ...), s_i). So we still allow\n>> them\n>> to check this finger print to see if they have all the final shares, but\n>> don't allow them to preemptively pull all the payments.\n>>\n>>\n>> -- Laolu\n>>\n>>\n>> On Mon, Feb 5, 2018 at 11:12 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>>\n>>> Good morning Laolu,\n>>>\n>>> This is excellent work!\n>>>\n>>> Some minor comments...\n>>>\n>>>\n>>> (Atomic Multi-path Payments). It can be experimented with on Lightning\n>>> *today* with the addition of a new feature bit to gate this new\n>>> feature. The beauty of the scheme is that it requires no fundamental\n>>> changes\n>>> to the protocol as is now, as the negotiation is strictly *end-to-end*\n>>> between sender and receiver.\n>>>\n>>>\n>>> I think, a `globalfeatures` odd bit could be used for this.  As it is\n>>> end-ot-end, `localfeatures` is not appropriate.\n>>>\n>>>   - Potential fee savings for larger payments, contingent on there being\n>>> a\n>>>     super-linear component to routed fees. It's possible that with\n>>>     modifications to the fee schedule, it's actually *cheaper* to send\n>>>     payments over multiple flows rather than one giant flow.\n>>>\n>>>\n>>> I believe, currently, fees have not this super-linear component.\n>>> Indeed, the existence of per-hop fees (`fee_base_msat`) means, splitting\n>>> the payment over multiple flows will be, very likely, more expensive,\n>>> compared to using a single flow.  Tiny roundoffs in computing the\n>>> proportional fees (`fee_proportional_millionths`) may make smaller\n>>> flows give a slight fee advantage, but I think the multiplication of\n>>> per-hop fees will dominate.\n>>>\n>>>\n>>>   - Using smaller payments increases the set of possible paths a partial\n>>>     payment could have taken, which reduces the effectiveness of static\n>>>     analysis techniques involving channel capacities and the plaintext\n>>>     values being forwarded.\n>>>\n>>>\n>>> Strongly agree!\n>>>\n>>>\n>>> In order to include the three tuple within the per-hop payload for the\n>>> final\n>>> destination, we repurpose the _first_ byte of the un-used padding bytes\n>>> in\n>>> the payload to signal version 0x01 of the AMP protocol (note this is a\n>>> PoC\n>>> outline, we would need to standardize signalling of these 12 bytes to\n>>> support other protocols).\n>>>\n>>>\n>>> I believe the `realm` byte is intended for this.  Intermediate nodes do\n>>> not need to understand realm bytes that are understood by other nodes in\n>>> the route, including the realm bytes understood by the final destination,\n>>> as intermediate nodes cannot, indeed, read the hop data of other nodes.\n>>> Thus, you can route over nodes that are unaware of AMP, and only provide an\n>>> AMP realm byte to the destination node, who, is able to reconstruct this\n>>> your AMP data as per your algorithm.\n>>>\n>>> Indeed, the `realm` byte controls the interpretation of the rest of the\n>>> 65-byte packet.  If you define, instead, a separate `realm` that is\n>>> understood by the destination node, you can redefine the entire 64 bytes of\n>>> the final hop data as you wish.\n>>>\n>>> If we support AMP only at final payees, we can completely redefine the\n>>> 64 bytes in the final hop data for the new AMP `realm`, and not consume the\n>>> next hop (which would reduce route length by 1).\n>>>\n>>> (If we want to support multiple routes converging to an intermediate\n>>> node, then continue routing to a different final node after routes have\n>>> merged (i.e. A->B->C->D, and A->E->C->D, with the payment being merged by\n>>> C, who forwards the combination to D), then we need to follow the current\n>>> hop data format, but I think supporting AMP at final payees is actually\n>>> enough... AMP at intermediate nodes might not be used often enough by\n>>> senders for it to matter, as taking advantage of that seems more complex\n>>> than just asking your routing algo to provide you multiple routes to a\n>>> destination, which you are probably already doing)\n>>>\n>>> ----\n>>>\n>>> Overall, good work I think.\n>>>\n>>> Regards,\n>>> ZmnSCPxj\n>>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180207/48a507f8/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-02-07T23:21:43",
                "message_text_only": "Olaoluwa Osuntokun <laolu32 at gmail.com> writes:\n> Hi Y'all,\n>\n> A common question I've seen concerning Lightning is: \"I have five $2\n> channels, is it possible for me to *atomically* send $6 to fulfill a\n> payment?\". The answer to this question is \"yes\", provided that the receiver\n\nThis is awesome!  I'm kicking myself for not proposing it :)\n\nUnfortunately, your proposal defines a way to make multipath donations,\nnot multipath payments :(\n\nIn other words, you've lost proof of payment, which IMHO is critical.\n\nFortunately, this can be fairly trivially fixed when we go to scriptless\nscripts or other equivalent decorrelation mechanism, when I think this\nmechanism becomes extremely powerful.\n\n>   - Potential fee savings for larger payments, contingent on there being a\n>     super-linear component to routed fees. It's possible that with\n>     modifications to the fee schedule, it's actually *cheaper* to send\n>     payments over multiple flows rather than one giant flow.\n\nThis is a stretch.  I'd stick with the increased reliability/privacy\narguments which are overwhelmingly compelling IMHO.\n\nIf I have any important feedback on deeper reading (and after a sccond\ncoffee), I'll send a separate email.\n\nThanks!\nRusty."
            },
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2018-02-08T16:41:41",
                "message_text_only": "An obvious way to make this compatible with proof-of-payment would be to \nrequire two hashes to claim the HTLC: the presage from the invoice payment \nhash (as today) + the new hash introduced here. This would give the sender \na receipt after only one of the HTLCs was claimed. Would require changes to \nthe scripts of course.\nWith Schnorr/EC operations this could probably be made more elegant, as \nmentioned.\n\n- Johan\nOn Wed, Feb 7, 2018 at 18:21, Rusty Russell <rusty at rustcorp.com.au> wrote:\nOlaoluwa Osuntokun <laolu32 at gmail.com> writes:\n > Hi Y'all,\n >\n > A common question I've seen concerning Lightning is: \"I have five $2\n > channels, is it possible for me to *atomically* send $6 to fulfill a\n > payment?\". The answer to this question is \"yes\", provided that the \nreceiver\n\nThis is awesome! I'm kicking myself for not proposing it :)\n\nUnfortunately, your proposal defines a way to make multipath donations,\nnot multipath payments :(\n\nIn other words, you've lost proof of payment, which IMHO is critical.\n\nFortunately, this can be fairly trivially fixed when we go to scriptless\nscripts or other equivalent decorrelation mechanism, when I think this\nmechanism becomes extremely powerful.\n\n > - Potential fee savings for larger payments, contingent on there being a\n > super-linear component to routed fees. It's possible that with\n > modifications to the fee schedule, it's actually *cheaper* to send\n > payments over multiple flows rather than one giant flow.\n\nThis is a stretch. I'd stick with the increased reliability/privacy\narguments which are overwhelmingly compelling IMHO.\n\nIf I have any important feedback on deeper reading (and after a sccond\ncoffee), I'll send a separate email.\n\nThanks!\nRusty.\n_______________________________________________\nLightning-dev mailing list\nLightning-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180208/ec4e6b34/attachment.html>"
            },
            {
                "author": "Jim Posen",
                "date": "2018-02-08T17:44:21",
                "message_text_only": "If using two hashes to deliver the payment while still getting a proof, I'm\nnot sure what that provides above just sending regular lightning payments\nover multiple routes with one hash. Firstly, if there is a second hash, it\nwould presumably be the same for all routes, making them linkable again,\nwhich AMP tries to solve. And secondly, the receiver has no incentive to\nclaim any of the HTLCs before all of them are locked in, because in that\ncase they are releasing the transaction receipt before fully being paid.\n\nOn Thu, Feb 8, 2018 at 8:41 AM, Johan Tor\u00e5s Halseth <johanth at gmail.com>\nwrote:\n\n> An obvious way to make this compatible with proof-of-payment would be to\n> require two hashes to claim the HTLC: the presage from the invoice payment\n> hash (as today) + the new hash introduced here. This would give the sender\n> a receipt after only one of the HTLCs was claimed. Would require changes to\n> the scripts of course.\n>\n> With Schnorr/EC operations this could probably be made more elegant, as\n> mentioned.\n>\n> - Johan\n> On Wed, Feb 7, 2018 at 18:21, Rusty Russell <rusty at rustcorp.com.au> wrote:\n>\n> Olaoluwa Osuntokun <laolu32 at gmail.com> writes:\n> > Hi Y'all,\n> >\n> > A common question I've seen concerning Lightning is: \"I have five $2\n> > channels, is it possible for me to *atomically* send $6 to fulfill a\n> > payment?\". The answer to this question is \"yes\", provided that the\n> receiver\n>\n> This is awesome! I'm kicking myself for not proposing it :)\n>\n> Unfortunately, your proposal defines a way to make multipath donations,\n> not multipath payments :(\n>\n> In other words, you've lost proof of payment, which IMHO is critical.\n>\n> Fortunately, this can be fairly trivially fixed when we go to scriptless\n> scripts or other equivalent decorrelation mechanism, when I think this\n> mechanism becomes extremely powerful.\n>\n> > - Potential fee savings for larger payments, contingent on there being a\n> > super-linear component to routed fees. It's possible that with\n> > modifications to the fee schedule, it's actually *cheaper* to send\n> > payments over multiple flows rather than one giant flow.\n>\n> This is a stretch. I'd stick with the increased reliability/privacy\n> arguments which are overwhelmingly compelling IMHO.\n>\n> If I have any important feedback on deeper reading (and after a sccond\n> coffee), I'll send a separate email.\n>\n> Thanks!\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180208/31041639/attachment.html>"
            },
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2018-02-08T18:05:40",
                "message_text_only": "Yeah, that is true, it would only give you the atomicity, not the decorrelation. I don\u2019t see how you could get all the same properties using only one hash though. I guess the sender has no incentive to claim any of the payments before all of them have arrived, but you get no guarantee that partial payments cannot be made. Seems hard to do without introducing new primitives.\n- Johan\n\nOn Thu, Feb 8, 2018 at 12:44, Jim Posen <jim.posen at gmail.com> wrote:\nIf using two hashes to deliver the payment while still getting a proof, I'm not sure what that provides above just sending regular lightning payments over multiple routes with one hash. Firstly, if there is a second hash, it would presumably be the same for all routes, making them linkable again, which AMP tries to solve. And secondly, the receiver has no incentive to claim any of the HTLCs before all of them are locked in, because in that case they are releasing the transaction receipt before fully being paid.\n\nOn Thu, Feb 8, 2018 at 8:41 AM, Johan Tor\u00e5s Halseth < johanth at gmail.com [johanth at gmail.com] > wrote:\nAn obvious way to make this compatible with proof-of-payment would be to require two hashes to claim the HTLC: the presage from the invoice payment hash (as today) + the new hash introduced here. This would give the sender a receipt after only one of the HTLCs was claimed. Would require changes to the scripts of course.\nWith Schnorr/EC operations this could probably be made more elegant, as mentioned.\n\n- Johan\nOn Wed, Feb 7, 2018 at 18:21, Rusty Russell < rusty at rustcorp.com.au [rusty at rustcorp.com.au] > wrote:\nOlaoluwa Osuntokun < laolu32 at gmail.com [laolu32 at gmail.com] > writes:\n> Hi Y'all,\n>\n> A common question I've seen concerning Lightning is: \"I have five $2\n> channels, is it possible for me to *atomically* send $6 to fulfill a\n> payment?\". The answer to this question is \"yes\", provided that the receiver\n\nThis is awesome! I'm kicking myself for not proposing it :)\n\nUnfortunately, your proposal defines a way to make multipath donations,\nnot multipath payments :(\n\nIn other words, you've lost proof of payment, which IMHO is critical.\n\nFortunately, this can be fairly trivially fixed when we go to scriptless\nscripts or other equivalent decorrelation mechanism, when I think this\nmechanism becomes extremely powerful.\n\n> - Potential fee savings for larger payments, contingent on there being a\n> super-linear component to routed fees. It's possible that with\n> modifications to the fee schedule, it's actually *cheaper* to send\n> payments over multiple flows rather than one giant flow.\n\nThis is a stretch. I'd stick with the increased reliability/privacy\narguments which are overwhelmingly compelling IMHO.\n\nIf I have any important feedback on deeper reading (and after a sccond\ncoffee), I'll send a separate email.\n\nThanks!\nRusty.\n______________________________ _________________\nLightning-dev mailing list\nLightning-dev at lists. linuxfoundation.org [Lightning-dev at lists.linuxfoundation.org]\nhttps://lists.linuxfoundation. org/mailman/listinfo/ lightning-dev [https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev]\n\n______________________________ _________________\nLightning-dev mailing list\nLightning-dev at lists. linuxfoundation.org [Lightning-dev at lists.linuxfoundation.org]\nhttps://lists.linuxfoundation. org/mailman/listinfo/ lightning-dev [https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev]\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180208/edbfbd41/attachment-0001.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-02-12T09:18:49",
                "message_text_only": "Jim Posen <jim.posen at gmail.com> writes:\n> If using two hashes to deliver the payment while still getting a proof, I'm\n> not sure what that provides above just sending regular lightning payments\n> over multiple routes with one hash. Firstly, if there is a second hash, it\n> would presumably be the same for all routes, making them linkable again,\n> which AMP tries to solve. And secondly, the receiver has no incentive to\n> claim any of the HTLCs before all of them are locked in, because in that\n> case they are releasing the transaction receipt before fully being paid.\n\nArguably the second concern is not really an issue, if you allow partial\nclaims you'll end up in a whole lot of trouble. It should always be the\ncase that the payment as whole is atomic, i.e., either the entirety of\nthe payment goes through or none of it, independently of whether it was\na singlepath or a multipath payment. This is actually one of the really\nnice features that was enforced using the simple \"just reuse the\nhash\"-mechanism, you always had to wait for the complete payment or\nyou'd risk losing part of it."
            },
            {
                "author": "Rusty Russell",
                "date": "2018-02-08T00:22:47",
                "message_text_only": "Olaoluwa Osuntokun <laolu32 at gmail.com> writes:\n> Protocol Overview\n> ==================\n> This design can be seen as a generalization of the single, non-interactive\n> payment scheme, that uses decoding of extra onion blobs (EOBs?) to encode\n> extra data for the receiver. In that design, the extra data includes a\n> payment preimage that the receiver can use to settle back the payment. EOBs\n> and some method of parsing them are really the only requirement for this\n> protocol to work. Thus, only the sender and receiver need to implement this\n> feature in order for it to function, which can be announced using a feature\n> bit.\n\nOK, so this proposal conflates two things:\n\n1. split payments.\n2. expansion of onion space.\n\nWe've got a wiki page for #2 which could probably use some love:\n        https://github.com/lightningnetwork/lightning-rfc/wiki/Brainstorming#using-multiple-hops_data-cells-in-the-onion\n\nFor the final hop this may not be necessary, as we have 8 unused bytes\nin `next addr`, giving us 20 free bytes.\n\nBut why not simplify the proposal: the payment preimage is the XOR of\nthose 20 bytes (with 12 zero bytes prepended)?  And the receiver gives\nup to 30 seconds(?) to receive all the parts after the first one.\n\nThat means the sender gets dynamic resizing (if they want to split a\npayment further, set one to randomness, and XOR that into the other),\nthe receive has only to remember the combination-so-far.\n\nCheers,\nRusty."
            },
            {
                "author": "CJP",
                "date": "2018-02-09T10:15:20",
                "message_text_only": "Can you give a use case for this?\n\nUsually, especially in the common case that a payment is done in\nexchange for some non-cryptographic asset (e.g. physical goods), there\nalready is some kind of trust between payer and payee. So, if a payment\nis split non-atomically into smaller transactions, and only a part\nsucceeds, presumably they can cooperatively figure out some way to\nsettle the situation.\n\nI spoke to people of the \"interledger\" project, and what they are\nplanning to do is to non-atomically split *every* transaction into lots\nof micro-payments. In fact, they consider it unnecessary to enforce\nHTLCs with scripts, because their amounts are so small(*). If one\nmicro-payment fails, that just makes them learn that a certain channel\nis unreliable, and they'll send further payments (and even the remaining\npart of the same payment) through a different route.\n\nCJP\n\n(*) not worth the extra on-blockchain fee due to the increased tx size.\n\nOlaoluwa Osuntokun schreef op di 06-02-2018 om 05:26 [+0000]:\n> Hi Y'all, \n> \n> \n> A common question I've seen concerning Lightning is: \"I have five $2\n> channels, is it possible for me to *atomically* send $6 to fulfill a\n> payment?\". The answer to this question is \"yes\", provided that the\n> receiver\n> waits to pull all HTLC's until the sum matches their invoice.\n> Typically, one\n> assumes that the receiver will supply a payment hash, and the sender\n> will\n> re-use the payment hash for all streams. This has the downside of\n> payment\n> hash re-use across *multiple* payments (which can already easily be\n> correlated), and also has a failure mode where if the sender fails to\n> actually satisfy all the payment flows, then the receiver can still\n> just\n> pull the monies (and possibly not disperse a service, or w/e).\n> \n> \n> Conner Fromknecht and I have come up with a way to achieve this over\n> Lightning while (1) not re-using any payment hashes across all payment\n> flows, and (2) adding a *strong* guarantee that the receiver won't be\n> paid\n> until *all* partial payment flows are extended. We call this scheme\n> AMP\n> (Atomic Multi-path Payments). It can be experimented with on Lightning\n> *today* with the addition of a new feature bit to gate this new\n> feature. The beauty of the scheme is that it requires no fundamental\n> changes\n> to the protocol as is now, as the negotiation is strictly *end-to-end*\n> between sender and receiver.\n> \n> \n> TL;DR: we repurpose some unused space in the onion per-hop payload of\n> the\n> onion blob to signal our protocol (and deliver some protocol-specific\n> data),\n> then use additive secret sharing to ensure that the receiver can't\n> pull the\n> payment until they have enough shares to reconstruct the original\n> pre-image.\n> \n> \n> \n> \n> Protocol Goals\n> ==============\n> 1. Atomicity: The logical transaction should either succeed or fail in\n> entirety. Naturally, this implies that the receiver should not be\n> unable to\n> settle *any* of the partial payments, until all of them have arrived.\n> \n> \n> 2. Avoid Payment Hash Reuse: The payment preimages validated by the\n> consensus layer should be distinct for each partial payment.\n> Primarily,\n> this helps avoid correlation of the partial payments, and ensures that\n> malicious intermediaries straddling partial payments cannot steal\n> funds.\n> \n> \n> 3. Order Invariance: The protocol should be forgiving to the order in\n> which\n> partial payments arrive at the destination, adding robustness in the\n> face of\n> delays or routing failures.\n> \n> \n> 4. Non-interactive Setup: It should be possible for the sender to\n> perform an\n> AMP without directly coordinating with the receiving node.\n> Predominantly,\n> this means that the *sender* is able to determine the number of\n> partial\n> payments to use for a particular AMP, which makes sense since they\n> will be\n> the one fronting the fees for the cost of this parameter. Plus, we can\n> always turn a non-interactive protocol into an interactive one for the\n> purposes of invoicing.\n> \n> \n> \n> \n> Protocol Benefits\n\n> =================\n> \n> \n> Sending pay payments predominantly over an AMP-like protocol has\n> several\n> clear benefits:\n> \n> \n>   - Eliminates the constraint that a single path from sender to\n> receiver\n>     with sufficient directional capacity. This reduces the pressure to\n> have\n>     larger channels in order to support larger payment flows. As a\n> result,\n>     the payment graph be very diffused, without sacrificing payment\n>     utility\n> \n> \n>   - Reduces strain from larger payments on individual paths, and\n> allows the\n>     liquidity imbalances to be more diffuse. We expect this to have a\n>     non-negligible impact on channel longevity. This is due to the\n> fact that\n>     with usage of AMP, payment flows are typically *smaller* meaning\n> that\n>     each payment will unbalance a channel to a lesser degree that\n>     with one giant flow.\n> \n> \n>   - Potential fee savings for larger payments, contingent on there\n> being a\n>     super-linear component to routed fees. It's possible that with\n>     modifications to the fee schedule, it's actually *cheaper* to send\n>     payments over multiple flows rather than one giant flow.\n> \n> \n>   - Allows for logical payments larger than the current maximum value\n> of an\n>     individual payment. Atm we have a (temporarily) limit on the max\n> payment\n>     size. With AMP, this can be side stepped as each flow can be up\n> the max\n>     size, with the sum of all flows exceeding the max.\n> \n> \n>   - Given sufficient path diversity, AMPs may improve the privacy of\n> LN\n>     Intermediaries are now unaware to how much of the total payment\n> they are\n>     forwarding, or even if they are forwarding a partial payment at\n> all.\n> \n> \n>   - Using smaller payments increases the set of possible paths a\n> partial\n>     payment could have taken, which reduces the effectiveness of\n> static\n>     analysis techniques involving channel capacities and the plaintext\n>     values being forwarded.\n> \n> \n> \n> \n> Protocol Overview\n> ==================\n> This design can be seen as a generalization of the single,\n> non-interactive\n> payment scheme, that uses decoding of extra onion blobs (EOBs?) to\n> encode\n> extra data for the receiver. In that design, the extra data includes a\n> payment preimage that the receiver can use to settle back the payment.\n> EOBs\n> and some method of parsing them are really the only requirement for\n> this\n> protocol to work. Thus, only the sender and receiver need to implement\n> this\n> feature in order for it to function, which can be announced using a\n> feature\n> bit. \n> \n> \n> First, let's review the current format of the per-hop payload for each\n> node\n> described in BOLT-0004.\n> \n> \n> \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n> \u2502Realm (1 byte) \u2502Next Addr (8 bytes)\u2502Amount (8 bytes)\u2502Outgoing CLTV (4\n> bytes)\u2502Unused (12 bytes)\u2502 HMAC (32 bytes) \u2502\n> \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n> \u25a0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25a0\n>                                               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n>                                               \u250265 Bytes Per Hop \u2502\n>                                               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n> \n> \n> Currently, *each* node gets a 65-byte payload. We use this payload to\n> give\n> each node instructions on *how* to forward a payment. We tell each\n> node: the\n> realm (or chain to forward on), then next node to forward to, the\n> amount to\n> forward (this is where fees are extracted by forwarding out less than\n> in),\n> the outgoing CLTV (allows verification that the prior node didn't\n> modify any\n> values), and finally an HMAC over the entire thing. \n> \n> \n> Two important points:\n>   1. We have 12 bytes for each hop that are currently unpurposed and\n> can be\n>   used by application protocols to signal new interpretation of bytes\n> and\n>   also deliver additional encrypted+authenticated data to *each* hop.\n> \n> \n>   2. The protocol currently has a hard limit of 20-hops. With this\n> feature\n>   we ensure that the packet stays fixed sized during processing in\n> order to\n>   avoid leaking positional information. Typically most payments won't\n> use\n>   all 20 hops, as a result, we can use the remaining hops to stuff in\n> *even\n>   more* data.\n> \n> \n> \n> \n> Protocol Description\n> ====================\n> The solution we propose is Atomic Multi-path Payments (AMPs). At a\n> high\n> level, this leverages EOBs to deliver additive shares of a base\n> preimage,\n> from which the payment preimages of partial payments can be derived.\n> The\n> receiver can only construct this value after having received all of\n> the\n> partial payments, satisfying the atomicity constraint.\n> \n> \n> The basic protocol:\n\n\n> \n> \n> Primitives\n> ==========\n> Let H be a CRH function.\n> Let || denote concatenation. \n> Let ^ denote xor.\n\n\n> \n> \n> \n> \n> Sender Requirements\n> ===================\n> The parameters to the sending procedure are a random identifier ID,\n> the\n> number of partial payments n, and the total payment value V. Assume\n> the\n> sender has some way of dividing V such that V = v_1 + \u2026 + v_n.\n> \n> \n> To begin, the sender builds the base preimage BP, from which n partial\n> preimages will be derived. Next, the sender samples n additive shares\n> s_1,\n> \u2026, s_n, and takes the sum to compute BP = s_1 ^ \u2026 ^ s_n.\n> \n> \n> With the base preimage created, the sender now moves on to\n> constructing the\n> n partial payments. For each i in [1,n], the sender deterministically\n> computes the partial preimage r_i = H(BP ||  i), by concatenating the\n> sequence number i to the base preimage and hashing the result.\n> Afterwards,\n> it applies H to determine the payment hash to use in the i\u2019th partial\n> payment as h_i = H(r_i). Note that that with this preimage derivation\n> scheme, once the payments are pulled each pre-image is distinct and\n> indistinguishable from any other.\n> \n> \n> With all of the pieces in place, the sender initiates the i\u2019th payment\n> by\n> constructing a route to the destination with value v_i and payment\n> hash h_i.\n> The tuple (ID, n, s_i) is included in the EOB to be opened by the\n> receiver.\n> \n> \n> In order to include the three tuple within the per-hop payload for the\n> final\n> destination, we repurpose the _first_ byte of the un-used padding\n> bytes in\n> the payload to signal version 0x01 of the AMP protocol (note this is a\n> PoC\n> outline, we would need to standardize signalling of these 12 bytes to\n> support other protocols). Typically this byte isn't set, so the\n> existence of\n> this means that we're (1) using AMP, and (2) the receiver should\n> consume the\n> _next_ hop as well. So if the payment length is actually 5, the sender\n> tacks\n> on an additional dummy 6th hop, encrypted with the _same_ shared\n> secret for\n> that hop to deliver the e2e encrypted data.\n> \n> \n> Note, the sender can retry partial payments just as they would normal\n> payments, since they are order invariant, and would be\n> indistinguishable\n> from regular payments to intermediaries in the network.  \n\n> \n> \n> \n> \n> Receiver\nRequirements\n> =====================\n> \n> \n> Upon the arrival of each partial payment, the receiver will\n> iteratively\n> reconstruct BP, and do some bookkeeping to figure out when to settle\n> the\n> partial payments. During this reconstruction process, the receiver\n> does not\n> need to be aware of the order in which the payments were sent, and in\n> fact\n> nothing about the incoming partial payments reveals this information\n> to the\n> receiver, though this can be learned after reconstructing BP.\n> \n> \n> Each EOB is decoded to retrieve (ID, n, s_i), where i is the unique\n> but\n> unknown index of the incoming partial payment. The receiver has access\n> to\n> persistent key-value store DB that maps ID to (n, c*, BP*), where c*\n> represents the number of partial payments received, BP* is the sum of\n> the\n> received additive shares, and the superscript * denotes that the value\n> is\n> being updated iteratively. c* and BP* both have initial values of 0.\n> \n> \n> In the basic protocol, the receiver cache\u2019s the first n it sees, and\n> verifies that all incoming partial payments have the same n. The\n> receiver\n> should reject all partial payments if any EOB deviates.  Next, the we\n> update\n> our persistent store with DB[ID] = (n, c* + 1, BP* ^ s_i), advancing\n> the\n> reconstruction by one step.\n> \n> \n> If c* + 1 < n, there are still more packets in flight, so we sit\n> tight.\n> Otherwise, the receiver assumes all partial payments have arrived, and\n> can\n> being settling them back. Using the base preimage BP = BP* ^ s_i from\n> our\n> final iteration, the receiver can re-derive all n partial preimages\n> and\n> payment hashes, using r_i = H(BP || i) and h_i = H(r_i) simply through\n> knowledge of n and BP. \n> \n> \n> Finally, the receiver settles back any outstanding payments that\n> include\n> payment hash h_i using the partial preimage r_i. Each r_i will appear\n> random\n> due to the nature of H, as will it\u2019s corresponding h_i. Thus, each\n> partial\n> payment should appear uncorrelated, and does not reveal that it is\n> part of\n> an AMP nor the number of partial payments used. \n> \n> \n> Non-interactive to Interactive AMPs\n> ===================================\n> \n> \n> Sender simply receives an ID and amount from the receiver in an\n> invoice\n> before initiating the protocol. The receiver should only consider the\n> invoice settled if the total amount received in partial payments\n> containing\n> ID matches or exceeds the amount specified in the invoice. With this\n> variant, the receiver is able to map all partial payments to a\n> pre-generated\n> invoice statement.\n> \n> \n> \n> \n> Additive Shares vs Threshold-Shares\n> ===================================\n> \n> \n> The biggest reason to use additive shares seems to be atomicity.\n> Threshold\n> shares open the door to some partial payments being settled, even if\n> others\n> are left in flight. Haven\u2019t yet come up with a good reason for using\n> threshold schemes, but there seem to be plenty against it. \n> \n> \n> Reconstruction of additive shares can be done iteratively, and is win\n> for\n> the storage and computation requirements on the receiving end. If the\n> sender\n> decides to use fewer than n partial payments, the remaining shares\n> could be\n> included in the EOB of the final partial payment to allow the sender\n> to\n> reconstruct sooner. Sender could also optimistically do partial\n> reconstruction on this last aggregate value.\n> \n> \n> \n> \n> Adaptive AMPs\n> =============\n> \n> \n> The sender may not always be aware of how many partial payments they\n> wish to\n> send at the time of the first partial payment, at which point the\n> simplified\n> protocol would require n to be chosen. To accommodate, the above\n> scheme can\n> be adapted to handle a dynamically chosen n by iteratively\n> constructing the\n> shared secrets as follows.\n> \n> \n> Starting with a base preimage BP, the key trick is that the sender\n> remember\n> the difference between the base preimage and the sum of all partial\n> preimages used so far. The relation is described using the following\n> equations:\n> \n> \n>     X_0 = 0\n\n>     X_i = X_{i-1} ^ s_i\n\n>     X_n = BP ^ X_{n-1} \n> \n> \n> where if n=1, X_1 = BP, implying that this is in fact a generalization\n> of\n> the single, non-interactive payment scheme mentioned above. For\n> i=1, ...,\n> n-1, the sender sends s_i in the EOB, and  X_n for the n-th share. \n> \n> \n> Iteratively reconstructing s_1 ^ \u2026. ^ s_{n-1} ^ X_n = BP, allows the\n> receiver to compute all relevant r_i = H(BP || i) and h_i = H(r_i).\n> Lastly,\n> the final number of partial payments n could be signaled in the final\n> EOB,\n> which would also serve as a sentinel value for signaling completion.\n> In\n> response to DOS vectors stemming from unknown values of n,\n> implementations\n> could consider advertising a maximum value for n, or adopting some\n> sort of\n> framing pattern for conveying that more partial payments are on the\n> way.\n> \n> \n> We can further modify our usage of the per-hop payloads to send\n> (H(BP), s_i) to\n> consume most of the EOB sent from sender to receiver. In this\n> scenario, we'd\n> repurpose the 11-bytes *after* our signalling byte in the unused byte\n> section\n> to store the payment ID (which should be unique for each payment). In\n> the case\n> of a non-interactive payment, this will be unused. While for\n> interactive\n> payments, this will be the ID within the invoice. To deliver this\n> slimmer\n> 2-tuple, we'll use 32-bytes for the hash of the BP, and 32-bytes for\n> the\n> partial pre-image share, leaving an un-used byte in the payload.\n> \n> \n> \n> \n> Cross-Chain AMPs\n> ================\n> \n> \n> AMPs can be used to pay a receiver in multiple currencies\n> atomically...which\n> is pretty cool :D\n> \n> \n> \n> \n> Open Research Questions\n> =======================\n> \n> \n> The above is a protocol sketch to achieve atomic multi-path payments\n> over\n> Lightning. The details concerning onion blob usage serves as a\n> template that\n> future protocols can draw upon in order to deliver additional data to\n> *any*\n> hop in the route. However, there are still a few open questions before\n> something like this can be feasibly deployed.\n> \n> \n> 1. How does the sender decide how many chunked payments to send, and\n> the\n> size of each payment?\n> \n> \n>   - Upon a closer examination, this seems to overlap with the task of\n>     congestion control within TCP. The sender may be able to utilize\n>     inspired heuristics to gauge: (1) how large the initial payment\n> should be\n>     and (2) how many subsequent payments may be required. Note that if\n> the\n>     first payment succeeds, then the exchange is over in a signal\n> round.\n> \n> \n> 2. How can AMP and HORNET be composed?\n> \n> \n>   - If we eventually integrate HORNET, then a distinct communications\n>     sessions can be established to allow the sender+receiver to\n> exchange\n>     up-to-date partial payment information. This may allow the sender\n> to more\n>     accurately size each partial payment.\n>    \n> 3. Can the sender's initial strategy be governed by an instance of the\n> Push-relabel max flow algo?\n> \n> \n> 4. How does this mesh with the current max HTLC limit on a commitment?\n> \n> \n>    - ATM, we have a max limit on the number of active HTLC's on a\n> particular\n>      commitment transaction. We do this, as otherwise it's possible\n> that the\n>      transaction is too large, and exceeds standardness w.r.t\n> transaction\n>      size. In a world where most payments use an AMP-like protocol,\n> then\n>      overall ant any given instance there will be several pending\n> HTLC's on\n>      commitments network wise. \n> \n> \n>      This may incentivize nodes to open more channels in order to\n> support\n>      the increased commitment space utilization.\n> \n> \n> \n> \n> Conclusion\n> ==========\n> \n> \n> We've presented a design outline of how to integrate atomic multi-path\n> payments (AMP) into Lightning. The existence of such a construct\n> allows a\n> sender to atomically split a payment flow amongst several individual\n> payment\n> flows. As a result, larger channels aren't as important as it's\n> possible to\n> utilize one total outbound payment bandwidth to send several channels.\n> Additionally, in order to support the increased load, internal routing\n> nodes\n> are incensed have more active channels. The existence of AMP-like\n> payments\n> may also increase the longevity of channels as there'll be smaller,\n> more\n> numerous payment flows, making it unlikely that a single payment comes\n> across unbalances a channel entirely. We've also showed how one can\n> utilize\n> the current onion packet format to deliver additional data from a\n> sender to\n> receiver, that's still e2e authenticated.\n> \n> \n> \n> \n> -- Conner && Laolu\n> \n> \n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Cezary Dziemian",
                "date": "2018-02-11T13:58:49",
                "message_text_only": "That would be great improvement, if AMP could work this way:\n\n1. I would like to send 0.1 BTC, so I split this to 5 payment 0.02 BTC each\n+ one extra 0.02 BTC payment.\n2. When recipient received 6 htlcs, he is able to spend only 5 of them.\nIf recipient receives, only 5 of them, it is still fine, and payment is\nsuccess.\n\nIn such scenario, single route/payment would fail, and payment as whole\nwould still be success. Do you think that would be possible? It could\ngreatly increase reliability of LN payments.\n\n2018-02-09 11:15 GMT+01:00 CJP <cjp at ultimatestunts.nl>:\n\n> Can you give a use case for this?\n>\n> Usually, especially in the common case that a payment is done in\n> exchange for some non-cryptographic asset (e.g. physical goods), there\n> already is some kind of trust between payer and payee. So, if a payment\n> is split non-atomically into smaller transactions, and only a part\n> succeeds, presumably they can cooperatively figure out some way to\n> settle the situation.\n>\n> I spoke to people of the \"interledger\" project, and what they are\n> planning to do is to non-atomically split *every* transaction into lots\n> of micro-payments. In fact, they consider it unnecessary to enforce\n> HTLCs with scripts, because their amounts are so small(*). If one\n> micro-payment fails, that just makes them learn that a certain channel\n> is unreliable, and they'll send further payments (and even the remaining\n> part of the same payment) through a different route.\n>\n> CJP\n>\n> (*) not worth the extra on-blockchain fee due to the increased tx size.\n>\n> Olaoluwa Osuntokun schreef op di 06-02-2018 om 05:26 [+0000]:\n> > Hi Y'all,\n> >\n> >\n> > A common question I've seen concerning Lightning is: \"I have five $2\n> > channels, is it possible for me to *atomically* send $6 to fulfill a\n> > payment?\". The answer to this question is \"yes\", provided that the\n> > receiver\n> > waits to pull all HTLC's until the sum matches their invoice.\n> > Typically, one\n> > assumes that the receiver will supply a payment hash, and the sender\n> > will\n> > re-use the payment hash for all streams. This has the downside of\n> > payment\n> > hash re-use across *multiple* payments (which can already easily be\n> > correlated), and also has a failure mode where if the sender fails to\n> > actually satisfy all the payment flows, then the receiver can still\n> > just\n> > pull the monies (and possibly not disperse a service, or w/e).\n> >\n> >\n> > Conner Fromknecht and I have come up with a way to achieve this over\n> > Lightning while (1) not re-using any payment hashes across all payment\n> > flows, and (2) adding a *strong* guarantee that the receiver won't be\n> > paid\n> > until *all* partial payment flows are extended. We call this scheme\n> > AMP\n> > (Atomic Multi-path Payments). It can be experimented with on Lightning\n> > *today* with the addition of a new feature bit to gate this new\n> > feature. The beauty of the scheme is that it requires no fundamental\n> > changes\n> > to the protocol as is now, as the negotiation is strictly *end-to-end*\n> > between sender and receiver.\n> >\n> >\n> > TL;DR: we repurpose some unused space in the onion per-hop payload of\n> > the\n> > onion blob to signal our protocol (and deliver some protocol-specific\n> > data),\n> > then use additive secret sharing to ensure that the receiver can't\n> > pull the\n> > payment until they have enough shares to reconstruct the original\n> > pre-image.\n> >\n> >\n> >\n> >\n> > Protocol Goals\n> > ==============\n> > 1. Atomicity: The logical transaction should either succeed or fail in\n> > entirety. Naturally, this implies that the receiver should not be\n> > unable to\n> > settle *any* of the partial payments, until all of them have arrived.\n> >\n> >\n> > 2. Avoid Payment Hash Reuse: The payment preimages validated by the\n> > consensus layer should be distinct for each partial payment.\n> > Primarily,\n> > this helps avoid correlation of the partial payments, and ensures that\n> > malicious intermediaries straddling partial payments cannot steal\n> > funds.\n> >\n> >\n> > 3. Order Invariance: The protocol should be forgiving to the order in\n> > which\n> > partial payments arrive at the destination, adding robustness in the\n> > face of\n> > delays or routing failures.\n> >\n> >\n> > 4. Non-interactive Setup: It should be possible for the sender to\n> > perform an\n> > AMP without directly coordinating with the receiving node.\n> > Predominantly,\n> > this means that the *sender* is able to determine the number of\n> > partial\n> > payments to use for a particular AMP, which makes sense since they\n> > will be\n> > the one fronting the fees for the cost of this parameter. Plus, we can\n> > always turn a non-interactive protocol into an interactive one for the\n> > purposes of invoicing.\n> >\n> >\n> >\n> >\n> > Protocol Benefits\n> > =================\n> >\n> >\n> > Sending pay payments predominantly over an AMP-like protocol has\n> > several\n> > clear benefits:\n> >\n> >\n> >   - Eliminates the constraint that a single path from sender to\n> > receiver\n> >     with sufficient directional capacity. This reduces the pressure to\n> > have\n> >     larger channels in order to support larger payment flows. As a\n> > result,\n> >     the payment graph be very diffused, without sacrificing payment\n> >     utility\n> >\n> >\n> >   - Reduces strain from larger payments on individual paths, and\n> > allows the\n> >     liquidity imbalances to be more diffuse. We expect this to have a\n> >     non-negligible impact on channel longevity. This is due to the\n> > fact that\n> >     with usage of AMP, payment flows are typically *smaller* meaning\n> > that\n> >     each payment will unbalance a channel to a lesser degree that\n> >     with one giant flow.\n> >\n> >\n> >   - Potential fee savings for larger payments, contingent on there\n> > being a\n> >     super-linear component to routed fees. It's possible that with\n> >     modifications to the fee schedule, it's actually *cheaper* to send\n> >     payments over multiple flows rather than one giant flow.\n> >\n> >\n> >   - Allows for logical payments larger than the current maximum value\n> > of an\n> >     individual payment. Atm we have a (temporarily) limit on the max\n> > payment\n> >     size. With AMP, this can be side stepped as each flow can be up\n> > the max\n> >     size, with the sum of all flows exceeding the max.\n> >\n> >\n> >   - Given sufficient path diversity, AMPs may improve the privacy of\n> > LN\n> >     Intermediaries are now unaware to how much of the total payment\n> > they are\n> >     forwarding, or even if they are forwarding a partial payment at\n> > all.\n> >\n> >\n> >   - Using smaller payments increases the set of possible paths a\n> > partial\n> >     payment could have taken, which reduces the effectiveness of\n> > static\n> >     analysis techniques involving channel capacities and the plaintext\n> >     values being forwarded.\n> >\n> >\n> >\n> >\n> > Protocol Overview\n> > ==================\n> > This design can be seen as a generalization of the single,\n> > non-interactive\n> > payment scheme, that uses decoding of extra onion blobs (EOBs?) to\n> > encode\n> > extra data for the receiver. In that design, the extra data includes a\n> > payment preimage that the receiver can use to settle back the payment.\n> > EOBs\n> > and some method of parsing them are really the only requirement for\n> > this\n> > protocol to work. Thus, only the sender and receiver need to implement\n> > this\n> > feature in order for it to function, which can be announced using a\n> > feature\n> > bit.\n> >\n> >\n> > First, let's review the current format of the per-hop payload for each\n> > node\n> > described in BOLT-0004.\n> >\n> >\n> > \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\n> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n> > \u2502Realm (1 byte) \u2502Next Addr (8 bytes)\u2502Amount (8 bytes)\u2502Outgoing CLTV (4\n> > bytes)\u2502Unused (12 bytes)\u2502 HMAC (32 bytes) \u2502\n> > \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\n> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n> > \u25a0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25a0\n> >                                               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n> >                                               \u250265 Bytes Per Hop \u2502\n> >                                               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n> >\n> >\n> > Currently, *each* node gets a 65-byte payload. We use this payload to\n> > give\n> > each node instructions on *how* to forward a payment. We tell each\n> > node: the\n> > realm (or chain to forward on), then next node to forward to, the\n> > amount to\n> > forward (this is where fees are extracted by forwarding out less than\n> > in),\n> > the outgoing CLTV (allows verification that the prior node didn't\n> > modify any\n> > values), and finally an HMAC over the entire thing.\n> >\n> >\n> > Two important points:\n> >   1. We have 12 bytes for each hop that are currently unpurposed and\n> > can be\n> >   used by application protocols to signal new interpretation of bytes\n> > and\n> >   also deliver additional encrypted+authenticated data to *each* hop.\n> >\n> >\n> >   2. The protocol currently has a hard limit of 20-hops. With this\n> > feature\n> >   we ensure that the packet stays fixed sized during processing in\n> > order to\n> >   avoid leaking positional information. Typically most payments won't\n> > use\n> >   all 20 hops, as a result, we can use the remaining hops to stuff in\n> > *even\n> >   more* data.\n> >\n> >\n> >\n> >\n> > Protocol Description\n> > ====================\n> > The solution we propose is Atomic Multi-path Payments (AMPs). At a\n> > high\n> > level, this leverages EOBs to deliver additive shares of a base\n> > preimage,\n> > from which the payment preimages of partial payments can be derived.\n> > The\n> > receiver can only construct this value after having received all of\n> > the\n> > partial payments, satisfying the atomicity constraint.\n> >\n> >\n> > The basic protocol:\n> >\n> >\n> > Primitives\n> > ==========\n> > Let H be a CRH function.\n> > Let || denote concatenation.\n> > Let ^ denote xor.\n> >\n> >\n> >\n> >\n> > Sender Requirements\n> > ===================\n> > The parameters to the sending procedure are a random identifier ID,\n> > the\n> > number of partial payments n, and the total payment value V. Assume\n> > the\n> > sender has some way of dividing V such that V = v_1 + \u2026 + v_n.\n> >\n> >\n> > To begin, the sender builds the base preimage BP, from which n partial\n> > preimages will be derived. Next, the sender samples n additive shares\n> > s_1,\n> > \u2026, s_n, and takes the sum to compute BP = s_1 ^ \u2026 ^ s_n.\n> >\n> >\n> > With the base preimage created, the sender now moves on to\n> > constructing the\n> > n partial payments. For each i in [1,n], the sender deterministically\n> > computes the partial preimage r_i = H(BP ||  i), by concatenating the\n> > sequence number i to the base preimage and hashing the result.\n> > Afterwards,\n> > it applies H to determine the payment hash to use in the i\u2019th partial\n> > payment as h_i = H(r_i). Note that that with this preimage derivation\n> > scheme, once the payments are pulled each pre-image is distinct and\n> > indistinguishable from any other.\n> >\n> >\n> > With all of the pieces in place, the sender initiates the i\u2019th payment\n> > by\n> > constructing a route to the destination with value v_i and payment\n> > hash h_i.\n> > The tuple (ID, n, s_i) is included in the EOB to be opened by the\n> > receiver.\n> >\n> >\n> > In order to include the three tuple within the per-hop payload for the\n> > final\n> > destination, we repurpose the _first_ byte of the un-used padding\n> > bytes in\n> > the payload to signal version 0x01 of the AMP protocol (note this is a\n> > PoC\n> > outline, we would need to standardize signalling of these 12 bytes to\n> > support other protocols). Typically this byte isn't set, so the\n> > existence of\n> > this means that we're (1) using AMP, and (2) the receiver should\n> > consume the\n> > _next_ hop as well. So if the payment length is actually 5, the sender\n> > tacks\n> > on an additional dummy 6th hop, encrypted with the _same_ shared\n> > secret for\n> > that hop to deliver the e2e encrypted data.\n> >\n> >\n> > Note, the sender can retry partial payments just as they would normal\n> > payments, since they are order invariant, and would be\n> > indistinguishable\n> > from regular payments to intermediaries in the network.\n> >\n> >\n> >\n> >\n> > Receiver Requirements\n> > =====================\n> >\n> >\n> > Upon the arrival of each partial payment, the receiver will\n> > iteratively\n> > reconstruct BP, and do some bookkeeping to figure out when to settle\n> > the\n> > partial payments. During this reconstruction process, the receiver\n> > does not\n> > need to be aware of the order in which the payments were sent, and in\n> > fact\n> > nothing about the incoming partial payments reveals this information\n> > to the\n> > receiver, though this can be learned after reconstructing BP.\n> >\n> >\n> > Each EOB is decoded to retrieve (ID, n, s_i), where i is the unique\n> > but\n> > unknown index of the incoming partial payment. The receiver has access\n> > to\n> > persistent key-value store DB that maps ID to (n, c*, BP*), where c*\n> > represents the number of partial payments received, BP* is the sum of\n> > the\n> > received additive shares, and the superscript * denotes that the value\n> > is\n> > being updated iteratively. c* and BP* both have initial values of 0.\n> >\n> >\n> > In the basic protocol, the receiver cache\u2019s the first n it sees, and\n> > verifies that all incoming partial payments have the same n. The\n> > receiver\n> > should reject all partial payments if any EOB deviates.  Next, the we\n> > update\n> > our persistent store with DB[ID] = (n, c* + 1, BP* ^ s_i), advancing\n> > the\n> > reconstruction by one step.\n> >\n> >\n> > If c* + 1 < n, there are still more packets in flight, so we sit\n> > tight.\n> > Otherwise, the receiver assumes all partial payments have arrived, and\n> > can\n> > being settling them back. Using the base preimage BP = BP* ^ s_i from\n> > our\n> > final iteration, the receiver can re-derive all n partial preimages\n> > and\n> > payment hashes, using r_i = H(BP || i) and h_i = H(r_i) simply through\n> > knowledge of n and BP.\n> >\n> >\n> > Finally, the receiver settles back any outstanding payments that\n> > include\n> > payment hash h_i using the partial preimage r_i. Each r_i will appear\n> > random\n> > due to the nature of H, as will it\u2019s corresponding h_i. Thus, each\n> > partial\n> > payment should appear uncorrelated, and does not reveal that it is\n> > part of\n> > an AMP nor the number of partial payments used.\n> >\n> >\n> > Non-interactive to Interactive AMPs\n> > ===================================\n> >\n> >\n> > Sender simply receives an ID and amount from the receiver in an\n> > invoice\n> > before initiating the protocol. The receiver should only consider the\n> > invoice settled if the total amount received in partial payments\n> > containing\n> > ID matches or exceeds the amount specified in the invoice. With this\n> > variant, the receiver is able to map all partial payments to a\n> > pre-generated\n> > invoice statement.\n> >\n> >\n> >\n> >\n> > Additive Shares vs Threshold-Shares\n> > ===================================\n> >\n> >\n> > The biggest reason to use additive shares seems to be atomicity.\n> > Threshold\n> > shares open the door to some partial payments being settled, even if\n> > others\n> > are left in flight. Haven\u2019t yet come up with a good reason for using\n> > threshold schemes, but there seem to be plenty against it.\n> >\n> >\n> > Reconstruction of additive shares can be done iteratively, and is win\n> > for\n> > the storage and computation requirements on the receiving end. If the\n> > sender\n> > decides to use fewer than n partial payments, the remaining shares\n> > could be\n> > included in the EOB of the final partial payment to allow the sender\n> > to\n> > reconstruct sooner. Sender could also optimistically do partial\n> > reconstruction on this last aggregate value.\n> >\n> >\n> >\n> >\n> > Adaptive AMPs\n> > =============\n> >\n> >\n> > The sender may not always be aware of how many partial payments they\n> > wish to\n> > send at the time of the first partial payment, at which point the\n> > simplified\n> > protocol would require n to be chosen. To accommodate, the above\n> > scheme can\n> > be adapted to handle a dynamically chosen n by iteratively\n> > constructing the\n> > shared secrets as follows.\n> >\n> >\n> > Starting with a base preimage BP, the key trick is that the sender\n> > remember\n> > the difference between the base preimage and the sum of all partial\n> > preimages used so far. The relation is described using the following\n> > equations:\n> >\n> >\n> >     X_0 = 0\n> >     X_i = X_{i-1} ^ s_i\n> >     X_n = BP ^ X_{n-1}\n> >\n> >\n> > where if n=1, X_1 = BP, implying that this is in fact a generalization\n> > of\n> > the single, non-interactive payment scheme mentioned above. For\n> > i=1, ...,\n> > n-1, the sender sends s_i in the EOB, and  X_n for the n-th share.\n> >\n> >\n> > Iteratively reconstructing s_1 ^ \u2026. ^ s_{n-1} ^ X_n = BP, allows the\n> > receiver to compute all relevant r_i = H(BP || i) and h_i = H(r_i).\n> > Lastly,\n> > the final number of partial payments n could be signaled in the final\n> > EOB,\n> > which would also serve as a sentinel value for signaling completion.\n> > In\n> > response to DOS vectors stemming from unknown values of n,\n> > implementations\n> > could consider advertising a maximum value for n, or adopting some\n> > sort of\n> > framing pattern for conveying that more partial payments are on the\n> > way.\n> >\n> >\n> > We can further modify our usage of the per-hop payloads to send\n> > (H(BP), s_i) to\n> > consume most of the EOB sent from sender to receiver. In this\n> > scenario, we'd\n> > repurpose the 11-bytes *after* our signalling byte in the unused byte\n> > section\n> > to store the payment ID (which should be unique for each payment). In\n> > the case\n> > of a non-interactive payment, this will be unused. While for\n> > interactive\n> > payments, this will be the ID within the invoice. To deliver this\n> > slimmer\n> > 2-tuple, we'll use 32-bytes for the hash of the BP, and 32-bytes for\n> > the\n> > partial pre-image share, leaving an un-used byte in the payload.\n> >\n> >\n> >\n> >\n> > Cross-Chain AMPs\n> > ================\n> >\n> >\n> > AMPs can be used to pay a receiver in multiple currencies\n> > atomically...which\n> > is pretty cool :D\n> >\n> >\n> >\n> >\n> > Open Research Questions\n> > =======================\n> >\n> >\n> > The above is a protocol sketch to achieve atomic multi-path payments\n> > over\n> > Lightning. The details concerning onion blob usage serves as a\n> > template that\n> > future protocols can draw upon in order to deliver additional data to\n> > *any*\n> > hop in the route. However, there are still a few open questions before\n> > something like this can be feasibly deployed.\n> >\n> >\n> > 1. How does the sender decide how many chunked payments to send, and\n> > the\n> > size of each payment?\n> >\n> >\n> >   - Upon a closer examination, this seems to overlap with the task of\n> >     congestion control within TCP. The sender may be able to utilize\n> >     inspired heuristics to gauge: (1) how large the initial payment\n> > should be\n> >     and (2) how many subsequent payments may be required. Note that if\n> > the\n> >     first payment succeeds, then the exchange is over in a signal\n> > round.\n> >\n> >\n> > 2. How can AMP and HORNET be composed?\n> >\n> >\n> >   - If we eventually integrate HORNET, then a distinct communications\n> >     sessions can be established to allow the sender+receiver to\n> > exchange\n> >     up-to-date partial payment information. This may allow the sender\n> > to more\n> >     accurately size each partial payment.\n> >\n> > 3. Can the sender's initial strategy be governed by an instance of the\n> > Push-relabel max flow algo?\n> >\n> >\n> > 4. How does this mesh with the current max HTLC limit on a commitment?\n> >\n> >\n> >    - ATM, we have a max limit on the number of active HTLC's on a\n> > particular\n> >      commitment transaction. We do this, as otherwise it's possible\n> > that the\n> >      transaction is too large, and exceeds standardness w.r.t\n> > transaction\n> >      size. In a world where most payments use an AMP-like protocol,\n> > then\n> >      overall ant any given instance there will be several pending\n> > HTLC's on\n> >      commitments network wise.\n> >\n> >\n> >      This may incentivize nodes to open more channels in order to\n> > support\n> >      the increased commitment space utilization.\n> >\n> >\n> >\n> >\n> > Conclusion\n> > ==========\n> >\n> >\n> > We've presented a design outline of how to integrate atomic multi-path\n> > payments (AMP) into Lightning. The existence of such a construct\n> > allows a\n> > sender to atomically split a payment flow amongst several individual\n> > payment\n> > flows. As a result, larger channels aren't as important as it's\n> > possible to\n> > utilize one total outbound payment bandwidth to send several channels.\n> > Additionally, in order to support the increased load, internal routing\n> > nodes\n> > are incensed have more active channels. The existence of AMP-like\n> > payments\n> > may also increase the longevity of channels as there'll be smaller,\n> > more\n> > numerous payment flows, making it unlikely that a single payment comes\n> > across unbalances a channel entirely. We've also showed how one can\n> > utilize\n> > the current onion packet format to deliver additional data from a\n> > sender to\n> > receiver, that's still e2e authenticated.\n> >\n> >\n> >\n> >\n> > -- Conner && Laolu\n> >\n> >\n> > _______________________________________________\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180211/27d3755e/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-02-12T03:03:37",
                "message_text_only": "Good morning Cezary,\n\n> That would be great improvement, if AMP could work this way:\n>\n> 1. I would like to send 0.1 BTC, so I split this to 5 payment 0.02 BTC each + one extra 0.02 BTC payment.\n> 2. When recipient received 6 htlcs, he is able to spend only 5 of them.\n> If recipient receives, only 5 of them, it is still fine, and payment is success.\n>\n> In such scenario, single route/payment would fail, and payment as whole would still be success. Do you think that would be possible? It could greatly increase reliability of LN payments.\n\nI will leave it to better mathematicians to answer your direct question, but, my intuition suggests it is not possible as stated.\n\nHowever, let me propose an alternative AMP method instead.\n\n------\n\nRoughly, we want to proceed this way.\n\n1.  When paying:\n1.1.  Try to pay.\n1.2.  If it fails, split it into two smaller payments and recurse into 1.\n\nNow we should ensure that the receiver can only receive if it has received all payments, and once it has received all payments, it can claim all payments.\n\nSo let me first introduce the below dual:\n\n* A pseudorandom number generator can be represented by its algorithm and the seed.  Alternatively, it can be represented by a stream of numbers.\n\nNow, a  stream of numbers has no end, but it does have a start (i.e. the first random number generated by the PRNG from the seed).  It is possible to \"split\" a stream into two streams, by taking the 0th, 2nd, 4th... numbers in one stream, and taking the 1st, 3rd, 5th... numbers in the other stream.\n\nEach such \"split\" stream can itself be further split into two streams.  Split streams can be re-\"merged\" by interleaving their members to yield the original pre-split stream.\n\nNow, we also want to be able to split a random seed into two seeds.  This splitting need not correspond to the stream-split (i.e. the split seeds will NOT generate the split streams); we only need to split seeds to prevent the receiver from claiming partial amounts.  This can be done by using another random source to generate a new \"seed\", and XOR it with the real seed.  The split \"halves\" are then the random number, and seed XOR the random number; the result is two apparently random numbers which, when XORed together, generate the original seed.\n\nLet us now sketch our algorithm:\n\n1.  def pay(seed, stream, dest, amount):\n1.1.  try { r = route(dest, amount, randomstuff); offer_htlc(H(stream[0]), r, seed, stream);\n1.2.  } catch(PaymentFailure) { sd1, sd2 = split_seed(seed); sr1, sr2 = split_stream(stream); pay(sd1, sr1, dest, amount / 2); pay(sd2, sr2, dest, amount / 2); }\n\nNow notice that the hash we use is H(stream[0]).  That is, the first item in the stream of random numbers.  Thus our streams do not actually need to give anything more than the first number in a stream.  We can represent a \"split\" stream simply by the index into the original stream.  For example, if we have:\n\n    s = original stream\n    sl, sr = split_stream(s)\n    sll, slr = split_stream(sl)\n\nThen s[0] and sl[0] and sll[0] are simply index 0 into the original stream, sr[0] is index 1, and slr[0] is index 2.  We can thus represent streams and their splits by the tuple (seed, index, depth), where depth indicates how many splits the stream has been through.  So, for the below:\n\n    s = (seed, 0, 0)\n    sl, sr = split_stream(s) = (seed, 0, 1), (seed, 1, 1)\n    sll, slr = split_stream(sl) = (seed, 0, 2), (seed, 2, 2)\n    split_stream( (seed, index, depth) ) = (seed, index, depth + 1), (seed, index + 2**depth, depth + 1)\n\nThen, for any stream s whose RNG algorithm is PRNG:\n\n   s[0] = (seed, index, _)[0] = PRNG(seed)[index]\n\nLet us now consider how our payment might proceed.\n\n1.  First, we generate a random seed, and call pay(seed, (seed, 0, 0), dest, amount)\n2.  Let us suppose that payment fails for the entire amount.  Split the amount into two:\n2.1.  In one branch we have pay(X, (seed, 0, 1), dest, amount / 2).  X is a new random number.\n2.2.  In other branch we have pay(seed ^ X, (seed, 1, 1), dest, amount / 2).  X is the same number as branch 2.1.\n2.2.1.  Suppose this payment fails.  Split it again intow two payments:\n2.2.1.1  In one sub-branch we have pay(Y, (seed, 1, 2), dest, amount / 4).\n2.2.1.2.  In other sub-branch we have pay(seed ^ X ^ Y, (seed, 3, 2), dest, amount / 4).\n\nThe receiver receives the branches 2.1, 2.2.1.1, and 2.2.1.2., which provide the seeds:\n\n2.1. => X\n2.2.1.1 => Y\n2.2.1.2. => seed ^X ^ Y\n\nXoring all of the above provides X ^ Y ^ seed ^ X ^ Y = seed.\n\nThe receiver can claim branch 2.1. by using PRNG(seed)[0], can claim branch 2.2.1.1 using PRNG(seed)[1], and branch 2.2.1.2 using PRNG(seed)[3].\n\nThus the sender needs only to send the split seed (say 32 bytes) and the index (say 1 byte for up to 8-level splitting into up to 256 payments).  The receiver gathers each split seed, XOR them all together to get the original PRNG seed, and runs the PRNG the appropriate number of times to get the preimages of each payment.\n\n(pragmatically we also need some kind of payment ID to differentiate different logical payments from the same sender, and to differentiate it from non-AMP)\n\nThe receiver cannot claim partial payments as it cannot determine the original seed until all branches of the payment reach it.  Once it has received all branches of the payment, however, it can determine the seed and the preimage of each payment; once it does so it has incentive to get all branches, yielding atomicity.\n\nRegards,\nZmnSCPxj\n\n> 2018-02-09 11:15 GMT+01:00 CJP <cjp at ultimatestunts.nl>:\n>\n>> Can you give a use case for this?\n>>\n>> Usually, especially in the common case that a payment is done in\n>> exchange for some non-cryptographic asset (e.g. physical goods), there\n>> already is some kind of trust between payer and payee. So, if a payment\n>> is split non-atomically into smaller transactions, and only a part\n>> succeeds, presumably they can cooperatively figure out some way to\n>> settle the situation.\n>>\n>> I spoke to people of the \"interledger\" project, and what they are\n>> planning to do is to non-atomically split *every* transaction into lots\n>> of micro-payments. In fact, they consider it unnecessary to enforce\n>> HTLCs with scripts, because their amounts are so small(*). If one\n>> micro-payment fails, that just makes them learn that a certain channel\n>> is unreliable, and they'll send further payments (and even the remaining\n>> part of the same payment) through a different route.\n>>\n>> CJP\n>>\n>> (*) not worth the extra on-blockchain fee due to the increased tx size.\n>>\n>> Olaoluwa Osuntokun schreef op di 06-02-2018 om 05:26 [+0000]:\n>>\n>>> Hi Y'all,\n>>>\n>>>\n>>> A common question I've seen concerning Lightning is: \"I have five $2\n>>> channels, is it possible for me to *atomically* send $6 to fulfill a\n>>> payment?\". The answer to this question is \"yes\", provided that the\n>>> receiver\n>>> waits to pull all HTLC's until the sum matches their invoice.\n>>> Typically, one\n>>> assumes that the receiver will supply a payment hash, and the sender\n>>> will\n>>> re-use the payment hash for all streams. This has the downside of\n>>> payment\n>>> hash re-use across *multiple* payments (which can already easily be\n>>> correlated), and also has a failure mode where if the sender fails to\n>>> actually satisfy all the payment flows, then the receiver can still\n>>> just\n>>> pull the monies (and possibly not disperse a service, or w/e).\n>>>\n>>>\n>>> Conner Fromknecht and I have come up with a way to achieve this over\n>>> Lightning while (1) not re-using any payment hashes across all payment\n>>> flows, and (2) adding a *strong* guarantee that the receiver won't be\n>>> paid\n>>> until *all* partial payment flows are extended. We call this scheme\n>>> AMP\n>>> (Atomic Multi-path Payments). It can be experimented with on Lightning\n>>> *today* with the addition of a new feature bit to gate this new\n>>> feature. The beauty of the scheme is that it requires no fundamental\n>>> changes\n>>> to the protocol as is now, as the negotiation is strictly *end-to-end*\n>>> between sender and receiver.\n>>>\n>>>\n>>> TL;DR: we repurpose some unused space in the onion per-hop payload of\n>>> the\n>>> onion blob to signal our protocol (and deliver some protocol-specific\n>>> data),\n>>> then use additive secret sharing to ensure that the receiver can't\n>>> pull the\n>>> payment until they have enough shares to reconstruct the original\n>>> pre-image.\n>>>\n>>>\n>>>\n>>>\n>>> Protocol Goals\n>>> ==============\n>>> 1. Atomicity: The logical transaction should either succeed or fail in\n>>> entirety. Naturally, this implies that the receiver should not be\n>>> unable to\n>>> settle *any* of the partial payments, until all of them have arrived.\n>>>\n>>>\n>>> 2. Avoid Payment Hash Reuse: The payment preimages validated by the\n>>> consensus layer should be distinct for each partial payment.\n>>> Primarily,\n>>> this helps avoid correlation of the partial payments, and ensures that\n>>> malicious intermediaries straddling partial payments cannot steal\n>>> funds.\n>>>\n>>>\n>>> 3. Order Invariance: The protocol should be forgiving to the order in\n>>> which\n>>> partial payments arrive at the destination, adding robustness in the\n>>> face of\n>>> delays or routing failures.\n>>>\n>>>\n>>> 4. Non-interactive Setup: It should be possible for the sender to\n>>> perform an\n>>> AMP without directly coordinating with the receiving node.\n>>> Predominantly,\n>>> this means that the *sender* is able to determine the number of\n>>> partial\n>>> payments to use for a particular AMP, which makes sense since they\n>>> will be\n>>> the one fronting the fees for the cost of this parameter. Plus, we can\n>>> always turn a non-interactive protocol into an interactive one for the\n>>> purposes of invoicing.\n>>>\n>>>\n>>>\n>>>\n>>> Protocol Benefits\n\n>>> =================\n>>>\n>>>\n>>> Sending pay payments predominantly over an AMP-like protocol has\n>>> several\n>>> clear benefits:\n>>>\n>>>\n>>>   - Eliminates the constraint that a single path from sender to\n>>> receiver\n>>>     with sufficient directional capacity. This reduces the pressure to\n>>> have\n>>>     larger channels in order to support larger payment flows. As a\n>>> result,\n>>>     the payment graph be very diffused, without sacrificing payment\n>>>     utility\n>>>\n>>>\n>>>   - Reduces strain from larger payments on individual paths, and\n>>> allows the\n>>>     liquidity imbalances to be more diffuse. We expect this to have a\n>>>     non-negligible impact on channel longevity. This is due to the\n>>> fact that\n>>>     with usage of AMP, payment flows are typically *smaller* meaning\n>>> that\n>>>     each payment will unbalance a channel to a lesser degree that\n>>>     with one giant flow.\n>>>\n>>>\n>>>   - Potential fee savings for larger payments, contingent on there\n>>> being a\n>>>     super-linear component to routed fees. It's possible that with\n>>>     modifications to the fee schedule, it's actually *cheaper* to send\n>>>     payments over multiple flows rather than one giant flow.\n>>>\n>>>\n>>>   - Allows for logical payments larger than the current maximum value\n>>> of an\n>>>     individual payment. Atm we have a (temporarily) limit on the max\n>>> payment\n>>>     size. With AMP, this can be side stepped as each flow can be up\n>>> the max\n>>>     size, with the sum of all flows exceeding the max.\n>>>\n>>>\n>>>   - Given sufficient path diversity, AMPs may improve the privacy of\n>>> LN\n>>>     Intermediaries are now unaware to how much of the total payment\n>>> they are\n>>>     forwarding, or even if they are forwarding a partial payment at\n>>> all.\n>>>\n>>>\n>>>   - Using smaller payments increases the set of possible paths a\n>>> partial\n>>>     payment could have taken, which reduces the effectiveness of\n>>> static\n>>>     analysis techniques involving channel capacities and the plaintext\n>>>     values being forwarded.\n>>>\n>>>\n>>>\n>>>\n>>> Protocol Overview\n>>> ==================\n>>> This design can be seen as a generalization of the single,\n>>> non-interactive\n>>> payment scheme, that uses decoding of extra onion blobs (EOBs?) to\n>>> encode\n>>> extra data for the receiver. In that design, the extra data includes a\n>>> payment preimage that the receiver can use to settle back the payment.\n>>> EOBs\n>>> and some method of parsing them are really the only requirement for\n>>> this\n>>> protocol to work. Thus, only the sender and receiver need to implement\n>>> this\n>>> feature in order for it to function, which can be announced using a\n>>> feature\n>>> bit.\n>>>\n>>>\n>>> First, let's review the current format of the per-hop payload for each\n>>> node\n>>> described in BOLT-0004.\n>>>\n>>>\n>>> \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n>>> \u2502Realm (1 byte) \u2502Next Addr (8 bytes)\u2502Amount (8 bytes)\u2502Outgoing CLTV (4\n>>> bytes)\u2502Unused (12 bytes)\u2502 HMAC (32 bytes) \u2502\n>>> \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n>>> \u25a0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25a0\n>>>                                               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n>>>                                               \u250265 Bytes Per Hop \u2502\n>>>                                               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n>>>\n>>>\n>>> Currently, *each* node gets a 65-byte payload. We use this payload to\n>>> give\n>>> each node instructions on *how* to forward a payment. We tell each\n>>> node: the\n>>> realm (or chain to forward on), then next node to forward to, the\n>>> amount to\n>>> forward (this is where fees are extracted by forwarding out less than\n>>> in),\n>>> the outgoing CLTV (allows verification that the prior node didn't\n>>> modify any\n>>> values), and finally an HMAC over the entire thing.\n>>>\n>>>\n>>> Two important points:\n>>>   1. We have 12 bytes for each hop that are currently unpurposed and\n>>> can be\n>>>   used by application protocols to signal new interpretation of bytes\n>>> and\n>>>   also deliver additional encrypted+authenticated data to *each* hop.\n>>>\n>>>\n>>>   2. The protocol currently has a hard limit of 20-hops. With this\n>>> feature\n>>>   we ensure that the packet stays fixed sized during processing in\n>>> order to\n>>>   avoid leaking positional information. Typically most payments won't\n>>> use\n>>>   all 20 hops, as a result, we can use the remaining hops to stuff in\n>>> *even\n>>>   more* data.\n>>>\n>>>\n>>>\n>>>\n>>> Protocol Description\n>>> ====================\n>>> The solution we propose is Atomic Multi-path Payments (AMPs). At a\n>>> high\n>>> level, this leverages EOBs to deliver additive shares of a base\n>>> preimage,\n>>> from which the payment preimages of partial payments can be derived.\n>>> The\n>>> receiver can only construct this value after having received all of\n>>> the\n>>> partial payments, satisfying the atomicity constraint.\n>>>\n>>>\n>>> The basic protocol:\n\n\n>>>\n>>>\n>>> Primitives\n>>> ==========\n>>> Let H be a CRH function.\n>>> Let || denote concatenation.\n>>> Let ^ denote xor.\n\n\n>>>\n>>>\n>>>\n>>>\n>>> Sender Requirements\n>>> ===================\n>>> The parameters to the sending procedure are a random identifier ID,\n>>> the\n>>> number of partial payments n, and the total payment value V. Assume\n>>> the\n>>> sender has some way of dividing V such that V = v_1 + \u2026 + v_n.\n>>>\n>>>\n>>> To begin, the sender builds the base preimage BP, from which n partial\n>>> preimages will be derived. Next, the sender samples n additive shares\n>>> s_1,\n>>> \u2026, s_n, and takes the sum to compute BP = s_1 ^ \u2026 ^ s_n.\n>>>\n>>>\n>>> With the base preimage created, the sender now moves on to\n>>> constructing the\n>>> n partial payments. For each i in [1,n], the sender deterministically\n>>> computes the partial preimage r_i = H(BP ||  i), by concatenating the\n>>> sequence number i to the base preimage and hashing the result.\n>>> Afterwards,\n>>> it applies H to determine the payment hash to use in the i\u2019th partial\n>>> payment as h_i = H(r_i). Note that that with this preimage derivation\n>>> scheme, once the payments are pulled each pre-image is distinct and\n>>> indistinguishable from any other.\n>>>\n>>>\n>>> With all of the pieces in place, the sender initiates the i\u2019th payment\n>>> by\n>>> constructing a route to the destination with value v_i and payment\n>>> hash h_i.\n>>> The tuple (ID, n, s_i) is included in the EOB to be opened by the\n>>> receiver.\n>>>\n>>>\n>>> In order to include the three tuple within the per-hop payload for the\n>>> final\n>>> destination, we repurpose the _first_ byte of the un-used padding\n>>> bytes in\n>>> the payload to signal version 0x01 of the AMP protocol (note this is a\n>>> PoC\n>>> outline, we would need to standardize signalling of these 12 bytes to\n>>> support other protocols). Typically this byte isn't set, so the\n>>> existence of\n>>> this means that we're (1) using AMP, and (2) the receiver should\n>>> consume the\n>>> _next_ hop as well. So if the payment length is actually 5, the sender\n>>> tacks\n>>> on an additional dummy 6th hop, encrypted with the _same_ shared\n>>> secret for\n>>> that hop to deliver the e2e encrypted data.\n>>>\n>>>\n>>> Note, the sender can retry partial payments just as they would normal\n>>> payments, since they are order invariant, and would be\n>>> indistinguishable\n>>> from regular payments to intermediaries in the network.\n>>>\n>>>\n>>>\n>>>\n>>> Receiver\nRequirements\n>>> =====================\n>>>\n>>>\n>>> Upon the arrival of each partial payment, the receiver will\n>>> iteratively\n>>> reconstruct BP, and do some bookkeeping to figure out when to settle\n>>> the\n>>> partial payments. During this reconstruction process, the receiver\n>>> does not\n>>> need to be aware of the order in which the payments were sent, and in\n>>> fact\n>>> nothing about the incoming partial payments reveals this information\n>>> to the\n>>> receiver, though this can be learned after reconstructing BP.\n>>>\n>>>\n>>> Each EOB is decoded to retrieve (ID, n, s_i), where i is the unique\n>>> but\n>>> unknown index of the incoming partial payment. The receiver has access\n>>> to\n>>> persistent key-value store DB that maps ID to (n, c*, BP*), where c*\n>>> represents the number of partial payments received, BP* is the sum of\n>>> the\n>>> received additive shares, and the superscript * denotes that the value\n>>> is\n>>> being updated iteratively. c* and BP* both have initial values of 0.\n>>>\n>>>\n>>> In the basic protocol, the receiver cache\u2019s the first n it sees, and\n>>> verifies that all incoming partial payments have the same n. The\n>>> receiver\n>>> should reject all partial payments if any EOB deviates.  Next, the we\n>>> update\n>>> our persistent store with DB[ID] = (n, c* + 1, BP* ^ s_i), advancing\n>>> the\n>>> reconstruction by one step.\n>>>\n>>>\n>>> If c* + 1 < n, there are still more packets in flight, so we sit\n>>> tight.\n>>> Otherwise, the receiver assumes all partial payments have arrived, and\n>>> can\n>>> being settling them back. Using the base preimage BP = BP* ^ s_i from\n>>> our\n>>> final iteration, the receiver can re-derive all n partial preimages\n>>> and\n>>> payment hashes, using r_i = H(BP || i) and h_i = H(r_i) simply through\n>>> knowledge of n and BP.\n>>>\n>>>\n>>> Finally, the receiver settles back any outstanding payments that\n>>> include\n>>> payment hash h_i using the partial preimage r_i. Each r_i will appear\n>>> random\n>>> due to the nature of H, as will it\u2019s corresponding h_i. Thus, each\n>>> partial\n>>> payment should appear uncorrelated, and does not reveal that it is\n>>> part of\n>>> an AMP nor the number of partial payments used.\n>>>\n>>>\n>>> Non-interactive to Interactive AMPs\n>>> ===================================\n>>>\n>>>\n>>> Sender simply receives an ID and amount from the receiver in an\n>>> invoice\n>>> before initiating the protocol. The receiver should only consider the\n>>> invoice settled if the total amount received in partial payments\n>>> containing\n>>> ID matches or exceeds the amount specified in the invoice. With this\n>>> variant, the receiver is able to map all partial payments to a\n>>> pre-generated\n>>> invoice statement.\n>>>\n>>>\n>>>\n>>>\n>>> Additive Shares vs Threshold-Shares\n>>> ===================================\n>>>\n>>>\n>>> The biggest reason to use additive shares seems to be atomicity.\n>>> Threshold\n>>> shares open the door to some partial payments being settled, even if\n>>> others\n>>> are left in flight. Haven\u2019t yet come up with a good reason for using\n>>> threshold schemes, but there seem to be plenty against it.\n>>>\n>>>\n>>> Reconstruction of additive shares can be done iteratively, and is win\n>>> for\n>>> the storage and computation requirements on the receiving end. If the\n>>> sender\n>>> decides to use fewer than n partial payments, the remaining shares\n>>> could be\n>>> included in the EOB of the final partial payment to allow the sender\n>>> to\n>>> reconstruct sooner. Sender could also optimistically do partial\n>>> reconstruction on this last aggregate value.\n>>>\n>>>\n>>>\n>>>\n>>> Adaptive AMPs\n>>> =============\n>>>\n>>>\n>>> The sender may not always be aware of how many partial payments they\n>>> wish to\n>>> send at the time of the first partial payment, at which point the\n>>> simplified\n>>> protocol would require n to be chosen. To accommodate, the above\n>>> scheme can\n>>> be adapted to handle a dynamically chosen n by iteratively\n>>> constructing the\n>>> shared secrets as follows.\n>>>\n>>>\n>>> Starting with a base preimage BP, the key trick is that the sender\n>>> remember\n>>> the difference between the base preimage and the sum of all partial\n>>> preimages used so far. The relation is described using the following\n>>> equations:\n>>>\n>>>\n>>>     X_0 = 0\n\n>>>     X_i = X_{i-1} ^ s_i\n\n>>>     X_n = BP ^ X_{n-1}\n>>>\n>>>\n>>> where if n=1, X_1 = BP, implying that this is in fact a generalization\n>>> of\n>>> the single, non-interactive payment scheme mentioned above. For\n>>> i=1, ...,\n>>> n-1, the sender sends s_i in the EOB, and  X_n for the n-th share.\n>>>\n>>>\n>>> Iteratively reconstructing s_1 ^ \u2026. ^ s_{n-1} ^ X_n = BP, allows the\n>>> receiver to compute all relevant r_i = H(BP || i) and h_i = H(r_i).\n>>> Lastly,\n>>> the final number of partial payments n could be signaled in the final\n>>> EOB,\n>>> which would also serve as a sentinel value for signaling completion.\n>>> In\n>>> response to DOS vectors stemming from unknown values of n,\n>>> implementations\n>>> could consider advertising a maximum value for n, or adopting some\n>>> sort of\n>>> framing pattern for conveying that more partial payments are on the\n>>> way.\n>>>\n>>>\n>>> We can further modify our usage of the per-hop payloads to send\n>>> (H(BP), s_i) to\n>>> consume most of the EOB sent from sender to receiver. In this\n>>> scenario, we'd\n>>> repurpose the 11-bytes *after* our signalling byte in the unused byte\n>>> section\n>>> to store the payment ID (which should be unique for each payment). In\n>>> the case\n>>> of a non-interactive payment, this will be unused. While for\n>>> interactive\n>>> payments, this will be the ID within the invoice. To deliver this\n>>> slimmer\n>>> 2-tuple, we'll use 32-bytes for the hash of the BP, and 32-bytes for\n>>> the\n>>> partial pre-image share, leaving an un-used byte in the payload.\n>>>\n>>>\n>>>\n>>>\n>>> Cross-Chain AMPs\n>>> ================\n>>>\n>>>\n>>> AMPs can be used to pay a receiver in multiple currencies\n>>> atomically...which\n>>> is pretty cool :D\n>>>\n>>>\n>>>\n>>>\n>>> Open Research Questions\n>>> =======================\n>>>\n>>>\n>>> The above is a protocol sketch to achieve atomic multi-path payments\n>>> over\n>>> Lightning. The details concerning onion blob usage serves as a\n>>> template that\n>>> future protocols can draw upon in order to deliver additional data to\n>>> *any*\n>>> hop in the route. However, there are still a few open questions before\n>>> something like this can be feasibly deployed.\n>>>\n>>>\n>>> 1. How does the sender decide how many chunked payments to send, and\n>>> the\n>>> size of each payment?\n>>>\n>>>\n>>>   - Upon a closer examination, this seems to overlap with the task of\n>>>     congestion control within TCP. The sender may be able to utilize\n>>>     inspired heuristics to gauge: (1) how large the initial payment\n>>> should be\n>>>     and (2) how many subsequent payments may be required. Note that if\n>>> the\n>>>     first payment succeeds, then the exchange is over in a signal\n>>> round.\n>>>\n>>>\n>>> 2. How can AMP and HORNET be composed?\n>>>\n>>>\n>>>   - If we eventually integrate HORNET, then a distinct communications\n>>>     sessions can be established to allow the sender+receiver to\n>>> exchange\n>>>     up-to-date partial payment information. This may allow the sender\n>>> to more\n>>>     accurately size each partial payment.\n>>>\n>>> 3. Can the sender's initial strategy be governed by an instance of the\n>>> Push-relabel max flow algo?\n>>>\n>>>\n>>> 4. How does this mesh with the current max HTLC limit on a commitment?\n>>>\n>>>\n>>>    - ATM, we have a max limit on the number of active HTLC's on a\n>>> particular\n>>>      commitment transaction. We do this, as otherwise it's possible\n>>> that the\n>>>      transaction is too large, and exceeds standardness w.r.t\n>>> transaction\n>>>      size. In a world where most payments use an AMP-like protocol,\n>>> then\n>>>      overall ant any given instance there will be several pending\n>>> HTLC's on\n>>>      commitments network wise.\n>>>\n>>>\n>>>      This may incentivize nodes to open more channels in order to\n>>> support\n>>>      the increased commitment space utilization.\n>>>\n>>>\n>>>\n>>>\n>>> Conclusion\n>>> ==========\n>>>\n>>>\n>>> We've presented a design outline of how to integrate atomic multi-path\n>>> payments (AMP) into Lightning. The existence of such a construct\n>>> allows a\n>>> sender to atomically split a payment flow amongst several individual\n>>> payment\n>>> flows. As a result, larger channels aren't as important as it's\n>>> possible to\n>>> utilize one total outbound payment bandwidth to send several channels.\n>>> Additionally, in order to support the increased load, internal routing\n>>> nodes\n>>> are incensed have more active channels. The existence of AMP-like\n>>> payments\n>>> may also increase the longevity of channels as there'll be smaller,\n>>> more\n>>> numerous payment flows, making it unlikely that a single payment comes\n>>> across unbalances a channel entirely. We've also showed how one can\n>>> utilize\n>>> the current onion packet format to deliver additional data from a\n>>> sender to\n>>> receiver, that's still e2e authenticated.\n>>>\n>>>\n>>>\n>>>\n>>> -- Conner && Laolu\n>>>\n>>>\n>>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180211/5074c519/attachment-0001.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-02-12T09:23:22",
                "message_text_only": "CJP <cjp at ultimatestunts.nl> writes:\n> Can you give a use case for this?\n>\n> Usually, especially in the common case that a payment is done in\n> exchange for some non-cryptographic asset (e.g. physical goods), there\n> already is some kind of trust between payer and payee. So, if a payment\n> is split non-atomically into smaller transactions, and only a part\n> succeeds, presumably they can cooperatively figure out some way to\n> settle the situation.\n\nThe scenario that is commonly used in these cases is a merchant that\nprovides a signed invoice \"if you pay me X with payment_hash Y I will\ndeliver Z\". Now the user performs the payment, learns the payment_key\nmatching the payment_hash, but the merchant refuses to deliver, claiming\nit didn't get the payment. Now the user can go to a court, present the\ninvoice signed by the merchant, and the proof-of-payment, and force the\nmerchant to honor its commitment."
            },
            {
                "author": "Corn\u00e9 Plooy",
                "date": "2018-02-12T13:30:07",
                "message_text_only": "I was thinking that, for that use case, a different signed invoice could\nbe formulated, stating\n\n* several payment hashes with their corresponding amounts\n\n* the obligation of signer to deliver Z if all corresponding payment\nkeys are shown\n\n* some terms to handle the case where only a part of the payments was\nsuccessful, e.g. an obligation to refund\n\n\nThe third item is a bit problematic: in order to distinguish this case\nfrom a complete success, the payee would have to prove *absence* of\nsuccessful transactions, which is hard. Absence of successful\ntransactions can only be declared by the payer, so in order to reliably\nsettle *without* going to court first, the payer should sign a\ndeclaration stating that certain transactions were canceled and that the\nother ones should be refunded. This can be another invoice.\n\n\nSo, the original invoice states:\n\n* several payment hashes with their corresponding amounts\n\n* if all corresponding payment keys are shown: the obligation of <payee>\nto deliver Z, UNLESS stated otherwise by an invoice signed by <payer>\n\n-- signed by <payee>\n\n\nBut if a payment partially fails, it can be refunded cooperatively with\nan invoice created by payer:\n\n* declares which of the original payments were successful (with payment\nkeys) and which were not\n\n* replaces the obligation of <payee> to deliver Z with an obligation to\nrefund the successful transactions\n\n* several payment hashes with their corresponding amounts\n\n* if all corresponding payment keys are shown: cancel the obligation of\n<payee> to refund\n\n-- signed by <payer>\n\n\nMaybe this can be repeated iteratively if necessary; hopefully the\nnot-yet-settled amount will converge to zero.\n\n\nImportant advantage: this only requires changes to the invoice format,\nnot to the network protocol.\n\n\nThe point is: in this use case, the court is apparently the final point\nof settlement for invoices, just like the blockchain is for the other\nchannels in the route. IANAL, but I think the \"scripting language\"\naccepted by courts is quite flexible, and you can use that to enforce\natomicity. With the construction described above, you can either refund\ncooperatively (and collect evidence that refund has happened), or, if\nthat fails, go to court to enforce settlement there.\n\n\nCJP\n\n\nOp 12-02-18 om 10:23 schreef Christian Decker:\n> CJP <cjp at ultimatestunts.nl> writes:\n>> Can you give a use case for this?\n>>\n>> Usually, especially in the common case that a payment is done in\n>> exchange for some non-cryptographic asset (e.g. physical goods), there\n>> already is some kind of trust between payer and payee. So, if a payment\n>> is split non-atomically into smaller transactions, and only a part\n>> succeeds, presumably they can cooperatively figure out some way to\n>> settle the situation.\n> The scenario that is commonly used in these cases is a merchant that\n> provides a signed invoice \"if you pay me X with payment_hash Y I will\n> deliver Z\". Now the user performs the payment, learns the payment_key\n> matching the payment_hash, but the merchant refuses to deliver, claiming\n> it didn't get the payment. Now the user can go to a court, present the\n> invoice signed by the merchant, and the proof-of-payment, and force the\n> merchant to honor its commitment.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Christian Decker",
                "date": "2018-02-12T18:05:56",
                "message_text_only": "Honestly I don't get why we are complicating this so much. We have a\nsystem that allows atomic multipath payments using a single secret, and\nfuture decorrelation mechanisms allow us to vary the secret in such a\nway that multiple paths cannot be collated, why introduce a whole set of\nproblems by giving away the atomicity? The same goes for the overpaying\nand trusting the recipient to only claim the owed amount, there is no\nneed for this. Just pay the exact amount, by deriving secrets from the\nmain secret and make the derivation reproducible by intermediate hops.\n\nHaving proof-of-payment be presentable in a court is a nice feature, but\nit doesn't mean we need to abandon all guarantees we have worked so hard\nto establish in LN.\n\nCorn\u00e9 Plooy via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\nwrites:\n\n> I was thinking that, for that use case, a different signed invoice could\n> be formulated, stating\n>\n> * several payment hashes with their corresponding amounts\n>\n> * the obligation of signer to deliver Z if all corresponding payment\n> keys are shown\n>\n> * some terms to handle the case where only a part of the payments was\n> successful, e.g. an obligation to refund\n>\n>\n> The third item is a bit problematic: in order to distinguish this case\n> from a complete success, the payee would have to prove *absence* of\n> successful transactions, which is hard. Absence of successful\n> transactions can only be declared by the payer, so in order to reliably\n> settle *without* going to court first, the payer should sign a\n> declaration stating that certain transactions were canceled and that the\n> other ones should be refunded. This can be another invoice.\n>\n>\n> So, the original invoice states:\n>\n> * several payment hashes with their corresponding amounts\n>\n> * if all corresponding payment keys are shown: the obligation of <payee>\n> to deliver Z, UNLESS stated otherwise by an invoice signed by <payer>\n>\n> -- signed by <payee>\n>\n>\n> But if a payment partially fails, it can be refunded cooperatively with\n> an invoice created by payer:\n>\n> * declares which of the original payments were successful (with payment\n> keys) and which were not\n>\n> * replaces the obligation of <payee> to deliver Z with an obligation to\n> refund the successful transactions\n>\n> * several payment hashes with their corresponding amounts\n>\n> * if all corresponding payment keys are shown: cancel the obligation of\n> <payee> to refund\n>\n> -- signed by <payer>\n>\n>\n> Maybe this can be repeated iteratively if necessary; hopefully the\n> not-yet-settled amount will converge to zero.\n>\n>\n> Important advantage: this only requires changes to the invoice format,\n> not to the network protocol.\n>\n>\n> The point is: in this use case, the court is apparently the final point\n> of settlement for invoices, just like the blockchain is for the other\n> channels in the route. IANAL, but I think the \"scripting language\"\n> accepted by courts is quite flexible, and you can use that to enforce\n> atomicity. With the construction described above, you can either refund\n> cooperatively (and collect evidence that refund has happened), or, if\n> that fails, go to court to enforce settlement there.\n>\n>\n> CJP\n>\n>\n> Op 12-02-18 om 10:23 schreef Christian Decker:\n>> CJP <cjp at ultimatestunts.nl> writes:\n>>> Can you give a use case for this?\n>>>\n>>> Usually, especially in the common case that a payment is done in\n>>> exchange for some non-cryptographic asset (e.g. physical goods), there\n>>> already is some kind of trust between payer and payee. So, if a payment\n>>> is split non-atomically into smaller transactions, and only a part\n>>> succeeds, presumably they can cooperatively figure out some way to\n>>> settle the situation.\n>> The scenario that is commonly used in these cases is a merchant that\n>> provides a signed invoice \"if you pay me X with payment_hash Y I will\n>> deliver Z\". Now the user performs the payment, learns the payment_key\n>> matching the payment_hash, but the merchant refuses to deliver, claiming\n>> it didn't get the payment. Now the user can go to a court, present the\n>> invoice signed by the merchant, and the proof-of-payment, and force the\n>> merchant to honor its commitment.\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-02-13T02:56:04",
                "message_text_only": "Good morning Christian and Corne,\n\nAnother idea to consider, is techniques like ZKCP and ZKCSP, which provide atomic access to information in exchange for monetary compensation.  Ensuring atomicity of the exchange can be done by providing the information encrypted, a hash of the encryption key, and proofs that the encrypted data is the one desired and that the data was encrypted with the given key; the proof-of-payment is the encryption key, and possession of the encryption key is sufficient to gain access to the information, with no need to bring in legal structures.\n\n(admittedly, ZKCP and ZKCSP are dependent on new cryptography...)\n\n(also, AMP currently cannot provide a proof-of-payment, unlike current payment routing that has proof-of-payment, but that is an eventual design goal that would enable use of ZKC(S)P on-Lightning, assuming we eventually find out that zk-SNARKs and so on are something we can trust)\n\nRegards,\nZmnSCPxj\n\n\u200b\nSent with ProtonMail Secure Email.\n\u200b\n\n-------- Original Message --------\n On February 13, 2018 2:05 AM, Christian Decker <decker.christian at gmail.com> wrote:\n\n>Honestly I don't get why we are complicating this so much. We have a\n> system that allows atomic multipath payments using a single secret, and\n> future decorrelation mechanisms allow us to vary the secret in such a\n> way that multiple paths cannot be collated, why introduce a whole set of\n> problems by giving away the atomicity? The same goes for the overpaying\n> and trusting the recipient to only claim the owed amount, there is no\n> need for this. Just pay the exact amount, by deriving secrets from the\n> main secret and make the derivation reproducible by intermediate hops.\n>\n> Having proof-of-payment be presentable in a court is a nice feature, but\n> it doesn't mean we need to abandon all guarantees we have worked so hard\n> to establish in LN.\n>\n> Corn\u00e9 Plooy via Lightning-dev lightning-dev at lists.linuxfoundation.org\n>writes:\n>\n>>I was thinking that, for that use case, a different signed invoice could\n>> be formulated, stating\n>> - several payment hashes with their corresponding amounts\n>>\n>> - the obligation of signer to deliver Z if all corresponding payment\n>> keys are shown\n>>\n>> - some terms to handle the case where only a part of the payments was\n>> successful, e.g. an obligation to refund\n>>The third item is a bit problematic: in order to distinguish this case\n>> from a complete success, the payee would have to prove absence of\n>> successful transactions, which is hard. Absence of successful\n>> transactions can only be declared by the payer, so in order to reliably\n>> settle without going to court first, the payer should sign a\n>> declaration stating that certain transactions were canceled and that the\n>> other ones should be refunded. This can be another invoice.\n>>So, the original invoice states:\n>> - several payment hashes with their corresponding amounts\n>>\n>> - if all corresponding payment keys are shown: the obligation of <payee>\n>> to deliver Z, UNLESS stated otherwise by an invoice signed by <payer>\n>>-- signed by <payee>\n>>But if a payment partially fails, it can be refunded cooperatively with\n>> an invoice created by payer:\n>> - declares which of the original payments were successful (with payment\n>> keys) and which were not\n>>\n>> - replaces the obligation of <payee> to deliver Z with an obligation to\n>> refund the successful transactions\n>>\n>> - several payment hashes with their corresponding amounts\n>>\n>> - if all corresponding payment keys are shown: cancel the obligation of\n>> <payee> to refund\n>>-- signed by <payer>\n>>Maybe this can be repeated iteratively if necessary; hopefully the\n>> not-yet-settled amount will converge to zero.\n>>Important advantage: this only requires changes to the invoice format,\n>> not to the network protocol.\n>>The point is: in this use case, the court is apparently the final point\n>> of settlement for invoices, just like the blockchain is for the other\n>> channels in the route. IANAL, but I think the \"scripting language\"\n>> accepted by courts is quite flexible, and you can use that to enforce\n>> atomicity. With the construction described above, you can either refund\n>> cooperatively (and collect evidence that refund has happened), or, if\n>> that fails, go to court to enforce settlement there.\n>>CJP\n>>Op 12-02-18 om 10:23 schreef Christian Decker:\n>>>CJP cjp at ultimatestunts.nl writes:\n>>>>Can you give a use case for this?\n>>>>Usually, especially in the common case that a payment is done in\n>>>> exchange for some non-cryptographic asset (e.g. physical goods), there\n>>>> already is some kind of trust between payer and payee. So, if a payment\n>>>> is split non-atomically into smaller transactions, and only a part\n>>>> succeeds, presumably they can cooperatively figure out some way to\n>>>> settle the situation.\n>>>> The scenario that is commonly used in these cases is a merchant that\n>>>> provides a signed invoice \"if you pay me X with payment_hash Y I will\n>>>> deliver Z\". Now the user performs the payment, learns the payment_key\n>>>> matching the payment_hash, but the merchant refuses to deliver, claiming\n>>>> it didn't get the payment. Now the user can go to a court, present the\n>>>> invoice signed by the merchant, and the proof-of-payment, and force the\n>>>> merchant to honor its commitment.\n>>>>\n>>>Lightning-dev mailing list\n>>>Lightning-dev at lists.linuxfoundation.org\n>>>https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>>Lightning-dev mailing list\n>>Lightning-dev at lists.linuxfoundation.org\n>>https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>Lightning-dev mailing list\n>Lightning-dev at lists.linuxfoundation.org\n>https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>"
            },
            {
                "author": "Conner Fromknecht",
                "date": "2018-02-13T03:29:28",
                "message_text_only": "Hi everyone,\n\nI've seen some discussions over losing proofs of payment in the AMP setting,\nand wanted to address some lingering concerns I have regarding the\nsoundness of using the current invoicing system to prove payments.\n\nIn general, I think we are ascribing too much weight to simply having a\npreimage and BOLT 11 invoice. The structure of non-interactive payments\ndefinitely poses some interesting challenges in adapting the existing\ninvoicing\nscheme. However, I believe there exist stronger and better means of doing\nproofs of payment, and would prefer not to tie our hands by assuming\nthis is the best way to approach the problem.\n\nIMHO, the current signed invoice + preimage is a very weak proof of payment.\nIt's the hash equivalent to proving you own a public key by publishing the\nsecret key. There is an assumption that the only way someone could get that\npreimage is by having made a payment, but this assumption is broken most\ndirectly by the proving mechanism. Similarly, any intermediary who acquires\nan invoice with the appropriate hash could also make this claim since they\nalso have the preimage.\n\nFurther, I think it's a mistake to conflate\n  1) me being able to present a valid preimage/invoice pair, with\n  2) me having received the correct preimage in response to an onion packet\n    that I personally crafted for the receiving node in the invoice.\n\nThe main issue is that the proof does not bind a specific sender,\nmaking statement 1 producible by multiple individuals. I think it would be\npotentially worthwhile to explore proofs of stronger statements, such as 2,\nthat could utilize the ephemeral keys in the onion packets, or even the\nonion as a witness, which is more rigidly coupled to having actually\ncompleted a payment.\n\nWithout any modification to the spec, we can always use something like\nZKBoo to prove (w/o trusted setup) knowledge of a preimage without\ntotally revealing it to the verifier. This isn't perfect, but at least\ngives the\nsender the option to prove the statement without necessarily giving up\nthe preimage.\n\nTL;DR: I'm not convinced the signed invoice + hash is really a good\nyardstick\nby which to measure provability, and I think doing some research into proofs\nof payment on stronger statements would be incredibly valuable. Therefore,\nI'm not sure if AMPs really lose this, so much as force us to reconsider\nwhat it actually requires to soundly prove a payment to an external\nverifier.\n\nBest,\nConner\n\nOn Mon, Feb 12, 2018 at 6:56 PM ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Christian and Corne,\n>\n> Another idea to consider, is techniques like ZKCP and ZKCSP, which provide\n> atomic access to information in exchange for monetary compensation.\n> Ensuring atomicity of the exchange can be done by providing the information\n> encrypted, a hash of the encryption key, and proofs that the encrypted data\n> is the one desired and that the data was encrypted with the given key; the\n> proof-of-payment is the encryption key, and possession of the encryption\n> key is sufficient to gain access to the information, with no need to bring\n> in legal structures.\n>\n> (admittedly, ZKCP and ZKCSP are dependent on new cryptography...)\n>\n> (also, AMP currently cannot provide a proof-of-payment, unlike current\n> payment routing that has proof-of-payment, but that is an eventual design\n> goal that would enable use of ZKC(S)P on-Lightning, assuming we eventually\n> find out that zk-SNARKs and so on are something we can trust)\n>\n> Regards,\n> ZmnSCPxj\n>\n> \u200b\n> Sent with ProtonMail Secure Email.\n> \u200b\n>\n> -------- Original Message --------\n>  On February 13, 2018 2:05 AM, Christian Decker <\n> decker.christian at gmail.com> wrote:\n>\n> >Honestly I don't get why we are complicating this so much. We have a\n> > system that allows atomic multipath payments using a single secret, and\n> > future decorrelation mechanisms allow us to vary the secret in such a\n> > way that multiple paths cannot be collated, why introduce a whole set of\n> > problems by giving away the atomicity? The same goes for the overpaying\n> > and trusting the recipient to only claim the owed amount, there is no\n> > need for this. Just pay the exact amount, by deriving secrets from the\n> > main secret and make the derivation reproducible by intermediate hops.\n> >\n> > Having proof-of-payment be presentable in a court is a nice feature, but\n> > it doesn't mean we need to abandon all guarantees we have worked so hard\n> > to establish in LN.\n> >\n> > Corn\u00e9 Plooy via Lightning-dev lightning-dev at lists.linuxfoundation.org\n> >writes:\n> >\n> >>I was thinking that, for that use case, a different signed invoice could\n> >> be formulated, stating\n> >> - several payment hashes with their corresponding amounts\n> >>\n> >> - the obligation of signer to deliver Z if all corresponding payment\n> >> keys are shown\n> >>\n> >> - some terms to handle the case where only a part of the payments was\n> >> successful, e.g. an obligation to refund\n> >>The third item is a bit problematic: in order to distinguish this case\n> >> from a complete success, the payee would have to prove absence of\n> >> successful transactions, which is hard. Absence of successful\n> >> transactions can only be declared by the payer, so in order to reliably\n> >> settle without going to court first, the payer should sign a\n> >> declaration stating that certain transactions were canceled and that the\n> >> other ones should be refunded. This can be another invoice.\n> >>So, the original invoice states:\n> >> - several payment hashes with their corresponding amounts\n> >>\n> >> - if all corresponding payment keys are shown: the obligation of <payee>\n> >> to deliver Z, UNLESS stated otherwise by an invoice signed by <payer>\n> >>-- signed by <payee>\n> >>But if a payment partially fails, it can be refunded cooperatively with\n> >> an invoice created by payer:\n> >> - declares which of the original payments were successful (with payment\n> >> keys) and which were not\n> >>\n> >> - replaces the obligation of <payee> to deliver Z with an obligation to\n> >> refund the successful transactions\n> >>\n> >> - several payment hashes with their corresponding amounts\n> >>\n> >> - if all corresponding payment keys are shown: cancel the obligation of\n> >> <payee> to refund\n> >>-- signed by <payer>\n> >>Maybe this can be repeated iteratively if necessary; hopefully the\n> >> not-yet-settled amount will converge to zero.\n> >>Important advantage: this only requires changes to the invoice format,\n> >> not to the network protocol.\n> >>The point is: in this use case, the court is apparently the final point\n> >> of settlement for invoices, just like the blockchain is for the other\n> >> channels in the route. IANAL, but I think the \"scripting language\"\n> >> accepted by courts is quite flexible, and you can use that to enforce\n> >> atomicity. With the construction described above, you can either refund\n> >> cooperatively (and collect evidence that refund has happened), or, if\n> >> that fails, go to court to enforce settlement there.\n> >>CJP\n> >>Op 12-02-18 om 10:23 schreef Christian Decker:\n> >>>CJP cjp at ultimatestunts.nl writes:\n> >>>>Can you give a use case for this?\n> >>>>Usually, especially in the common case that a payment is done in\n> >>>> exchange for some non-cryptographic asset (e.g. physical goods), there\n> >>>> already is some kind of trust between payer and payee. So, if a\n> payment\n> >>>> is split non-atomically into smaller transactions, and only a part\n> >>>> succeeds, presumably they can cooperatively figure out some way to\n> >>>> settle the situation.\n> >>>> The scenario that is commonly used in these cases is a merchant that\n> >>>> provides a signed invoice \"if you pay me X with payment_hash Y I will\n> >>>> deliver Z\". Now the user performs the payment, learns the payment_key\n> >>>> matching the payment_hash, but the merchant refuses to deliver,\n> claiming\n> >>>> it didn't get the payment. Now the user can go to a court, present the\n> >>>> invoice signed by the merchant, and the proof-of-payment, and force\n> the\n> >>>> merchant to honor its commitment.\n> >>>>\n> >>>Lightning-dev mailing list\n> >>>Lightning-dev at lists.linuxfoundation.org\n> >>>https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> >>>\n> >>Lightning-dev mailing list\n> >>Lightning-dev at lists.linuxfoundation.org\n> >>https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> >>\n> >Lightning-dev mailing list\n> >Lightning-dev at lists.linuxfoundation.org\n> >https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> >\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180213/361f3c65/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-02-14T00:47:49",
                "message_text_only": "Conner Fromknecht <conner at lightning.engineering> writes:\n> IMHO, the current signed invoice + preimage is a very weak proof of payment.\n> It's the hash equivalent to proving you own a public key by publishing the\n> secret key. There is an assumption that the only way someone could get that\n> preimage is by having made a payment, but this assumption is broken most\n> directly by the proving mechanism. Similarly, any intermediary who acquires\n> an invoice with the appropriate hash could also make this claim since they\n> also have the preimage.\n\nAgreed.\n\n> Further, I think it's a mistake to conflate\n>   1) me being able to present a valid preimage/invoice pair, with\n>   2) me having received the correct preimage in response to an onion packet\n>     that I personally crafted for the receiving node in the invoice.\n>\n> The main issue is that the proof does not bind a specific sender,\n> making statement 1 producible by multiple individuals. I think it would be\n> potentially worthwhile to explore proofs of stronger statements, such as 2,\n> that could utilize the ephemeral keys in the onion packets, or even the\n> onion as a witness, which is more rigidly coupled to having actually\n> completed a payment.\n\nYes; this places more emphasis on the invoice's precision, eg. \"I will\nship X to Y\".\n\nIn practice, as we move to payment decorrelation the proof-of-payment\ndoes half of what you suggest: only the initial payer has the necessary\nproof, but it's still open-kimono if they reveal it.\n\nUsing some kind of point-supplied-in-onion to tweak result might help\nhere (handwave?!) since you can prove you know the secret for the point\neasily without revealing it, and then AMP is simply an aggregation of\ntweaks.\n\n> TL;DR: I'm not convinced the signed invoice + hash is really a good\n> yardstick\n> by which to measure provability, and I think doing some research into proofs\n> of payment on stronger statements would be incredibly valuable. Therefore,\n> I'm not sure if AMPs really lose this, so much as force us to reconsider\n> what it actually requires to soundly prove a payment to an external\n> verifier.\n\nProof-of-payment is a unique lightning property, which I think is\nterribly underrated (because we're used to not having it).  Our actions\nso far have been to boltser this (hence BOLT11), and I'd hate to see us\ndiscard it for convenience: I fear we'd never get it back!\n\nFortunately I think we *can* have our cake and eat it too...\n\nThanks,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "AMP: Atomic Multi-Path Payments over Lightning",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Corn\u00e9 Plooy",
                "Cezary Dziemian",
                "CJP",
                "Christian Decker",
                "Conner Fromknecht",
                "Johan Tor\u00e5s Halseth",
                "Rusty Russell",
                "Jim Posen",
                "Olaoluwa Osuntokun",
                "ZmnSCPxj"
            ],
            "messages_count": 20,
            "total_messages_chars_count": 157609
        }
    },
    {
        "title": "[Lightning-dev] Proof of payment (Re: AMP: Atomic Multi-Path Payments over Lightning)",
        "thread_messages": [
            {
                "author": "Corn\u00e9 Plooy",
                "date": "2018-02-13T10:33:50",
                "message_text_only": "Hi Conner,\n\n\nI do believe proof of payment is an important feature to have,\nespecially for the use case of a payer/payee pair that doesn't\ncompletely trust each other, but does have the possibility to go to court.\n\n\nHowever, I'm not convinced by what you wrote. I do think a combination\nof signed invoice + preimage is a reliable proof of payment. Strictly\nspeaking, you are right: it is not so much a proof that they payer\n*sent* the funds, but it *is* proof that the payee *received* the funds.\nThis is because the only scenario where it makes sense for the payee to\nreveal the preimage is if it can claim a corresponding incoming HTLC\nwith (at least) the correct amount of funds. Revealing the preimage in\nany other scenario would be stupid(*), and no amount of cryptography can\nprotect against stupidity. So, when it comes to cryptographic proof,\nthis is about as good as it gets.\n\n\nNow, about the difference between the payer having sent the funds and\nthe payee having received the funds: I'd argue that it's the second that\nreally matters. If the payer can prove that there is *any* kind of\narrangement that ended up with the payee having received the correct\namount of funds, that should count as payment. Now, if none of the\nintermediaries has been stupid, this does imply that the payer ends up\non the sending side of the payment, but even if one if the\nintermediaries has been stupid, why should the payer and payee care? All\nthat matters is that an arrangement has been made to let the payee\nreceive (at least) the correct amount of funds, and that arrangement has\nbeen proven to be successful. I consider that proof of payment.\n\n\nCJP\n\n\n(*) Stupidity includes being hacked, and anything else that can cause\nyour secrets being used against your own interests.\n\n\nOp 13-02-18 om 04:29 schreef Conner Fromknecht:\n>\n> Hi everyone,\n>\n> I've seen some discussions over losing proofs of payment in the AMP\n> setting,\n> and wanted to address some lingering concerns I have regarding the\n> soundness of using the current invoicing system to prove payments.\n>\n> In general, I think we are ascribing too much weight to simply having a\n> preimage and BOLT 11 invoice. The structure of non-interactive payments\n> definitely poses some interesting challenges in adapting the existing\n> invoicing\n> scheme. However, I believe there exist stronger and better means of doing\n> proofs of\u00a0payment,\u00a0and would prefer not to tie our hands by assuming\n> this is the best way to approach the problem.\n>\n> IMHO, the current signed invoice + preimage is a very weak proof of\n> payment.\n> It's the hash equivalent to proving you own a public key by publishing the\n> secret key. There is an assumption that the only way someone could get\n> that\n> preimage is by having made a payment, but this assumption is broken most\n> directly by the proving mechanism. Similarly, any intermediary who\n> acquires\n> an invoice with the appropriate hash could also make this claim since they\n> also have the preimage.\n>\n> Further, I think it's a mistake to conflate\n> \u00a0 1) me being able to present a valid preimage/invoice pair, with\n> \u00a0 2) me having received the correct preimage in response to an onion\n> packet\n> \u00a0 \u00a0 that I personally crafted for the receiving node\u00a0in\u00a0the invoice.\u00a0\n> \u00a0 \u00a0\u00a0\n> The main issue is that the proof does not bind a specific sender,\n> making statement 1 producible by multiple individuals.\u00a0I think it would be\n> potentially worthwhile to explore proofs of stronger statements, such\n> as 2,\n> that could utilize the ephemeral keys in the onion\u00a0packets,\u00a0or even the\n> onion as a witness, which is more rigidly coupled to having actually\n> completed a payment.\n>\n> Without any modification to the spec, we can always use something like\n> ZKBoo to prove (w/o trusted setup) knowledge of a preimage without\n> totally revealing it to the verifier. This isn't perfect, but at least\n> gives the\n> sender the option to prove the statement without necessarily giving up\n> the preimage.\n>\n> TL;DR: I'm not convinced the signed invoice\u00a0+ hash is really a good\n> yardstick\n> by which to measure\u00a0provability, and I think doing some research into\n> proofs\n> of payment on stronger statements would be incredibly valuable. Therefore,\n> I'm not sure if AMPs really lose this, so much as\u00a0force\u00a0us to reconsider\n> what it actually requires to soundly prove a payment to an external\n> verifier.\n>\n> Best,\n> Conner\n>\n> On Mon, Feb 12, 2018 at 6:56 PM ZmnSCPxj via Lightning-dev\n> <lightning-dev at lists.linuxfoundation.org\n> <mailto:lightning-dev at lists.linuxfoundation.org>> wrote:\n>\n>     Good morning Christian and Corne,\n>\n>     Another idea to consider, is techniques like ZKCP and ZKCSP, which\n>     provide atomic access to information in exchange for monetary\n>     compensation.\u00a0 Ensuring atomicity of the exchange can be done by\n>     providing the information encrypted, a hash of the encryption key,\n>     and proofs that the encrypted data is the one desired and that the\n>     data was encrypted with the given key; the proof-of-payment is the\n>     encryption key, and possession of the encryption key is sufficient\n>     to gain access to the information, with no need to bring in legal\n>     structures.\n>\n>     (admittedly, ZKCP and ZKCSP are dependent on new cryptography...)\n>\n>     (also, AMP currently cannot provide a proof-of-payment, unlike\n>     current payment routing that has proof-of-payment, but that is an\n>     eventual design goal that would enable use of ZKC(S)P\n>     on-Lightning, assuming we eventually find out that zk-SNARKs and\n>     so on are something we can trust)\n>\n>     Regards,\n>     ZmnSCPxj\n>\n>     \u200b\n>     Sent with ProtonMail Secure Email.\n>     \u200b\n>\n>     -------- Original Message --------\n>     \u00a0On February 13, 2018 2:05 AM, Christian Decker\n>     <decker.christian at gmail.com <mailto:decker.christian at gmail.com>>\n>     wrote:\n>\n>     >Honestly I don't get why we are complicating this so much. We have a\n>     > system that allows atomic multipath payments using a single\n>     secret, and\n>     > future decorrelation mechanisms allow us to vary the secret in\n>     such a\n>     > way that multiple paths cannot be collated, why introduce a\n>     whole set of\n>     > problems by giving away the atomicity? The same goes for the\n>     overpaying\n>     > and trusting the recipient to only claim the owed amount, there\n>     is no\n>     > need for this. Just pay the exact amount, by deriving secrets\n>     from the\n>     > main secret and make the derivation reproducible by intermediate\n>     hops.\n>     >\n>     > Having proof-of-payment be presentable in a court is a nice\n>     feature, but\n>     > it doesn't mean we need to abandon all guarantees we have worked\n>     so hard\n>     > to establish in LN.\n>     >\n>     > Corn\u00e9 Plooy via Lightning-dev\n>     lightning-dev at lists.linuxfoundation.org\n>     <mailto:lightning-dev at lists.linuxfoundation.org>\n>     >writes:\n>     >\n>     >>I was thinking that, for that use case, a different signed\n>     invoice could\n>     >> be formulated, stating\n>     >> - several payment hashes with their corresponding amounts\n>     >>\n>     >> - the obligation of signer to deliver Z if all corresponding\n>     payment\n>     >> keys are shown\n>     >>\n>     >> - some terms to handle the case where only a part of the\n>     payments was\n>     >> successful, e.g. an obligation to refund\n>     >>The third item is a bit problematic: in order to distinguish\n>     this case\n>     >> from a complete success, the payee would have to prove absence of\n>     >> successful transactions, which is hard. Absence of successful\n>     >> transactions can only be declared by the payer, so in order to\n>     reliably\n>     >> settle without going to court first, the payer should sign a\n>     >> declaration stating that certain transactions were canceled and\n>     that the\n>     >> other ones should be refunded. This can be another invoice.\n>     >>So, the original invoice states:\n>     >> - several payment hashes with their corresponding amounts\n>     >>\n>     >> - if all corresponding payment keys are shown: the obligation\n>     of <payee>\n>     >> to deliver Z, UNLESS stated otherwise by an invoice signed by\n>     <payer>\n>     >>-- signed by <payee>\n>     >>But if a payment partially fails, it can be refunded\n>     cooperatively with\n>     >> an invoice created by payer:\n>     >> - declares which of the original payments were successful (with\n>     payment\n>     >> keys) and which were not\n>     >>\n>     >> - replaces the obligation of <payee> to deliver Z with an\n>     obligation to\n>     >> refund the successful transactions\n>     >>\n>     >> - several payment hashes with their corresponding amounts\n>     >>\n>     >> - if all corresponding payment keys are shown: cancel the\n>     obligation of\n>     >> <payee> to refund\n>     >>-- signed by <payer>\n>     >>Maybe this can be repeated iteratively if necessary; hopefully the\n>     >> not-yet-settled amount will converge to zero.\n>     >>Important advantage: this only requires changes to the invoice\n>     format,\n>     >> not to the network protocol.\n>     >>The point is: in this use case, the court is apparently the\n>     final point\n>     >> of settlement for invoices, just like the blockchain is for the\n>     other\n>     >> channels in the route. IANAL, but I think the \"scripting language\"\n>     >> accepted by courts is quite flexible, and you can use that to\n>     enforce\n>     >> atomicity. With the construction described above, you can\n>     either refund\n>     >> cooperatively (and collect evidence that refund has happened),\n>     or, if\n>     >> that fails, go to court to enforce settlement there.\n>     >>CJP\n>     >>Op 12-02-18 om 10:23 schreef Christian Decker:\n>     >>>CJP cjp at ultimatestunts.nl <mailto:cjp at ultimatestunts.nl> writes:\n>     >>>>Can you give a use case for this?\n>     >>>>Usually, especially in the common case that a payment is done in\n>     >>>> exchange for some non-cryptographic asset (e.g. physical\n>     goods), there\n>     >>>> already is some kind of trust between payer and payee. So, if\n>     a payment\n>     >>>> is split non-atomically into smaller transactions, and only a\n>     part\n>     >>>> succeeds, presumably they can cooperatively figure out some\n>     way to\n>     >>>> settle the situation.\n>     >>>> The scenario that is commonly used in these cases is a\n>     merchant that\n>     >>>> provides a signed invoice \"if you pay me X with payment_hash\n>     Y I will\n>     >>>> deliver Z\". Now the user performs the payment, learns the\n>     payment_key\n>     >>>> matching the payment_hash, but the merchant refuses to\n>     deliver, claiming\n>     >>>> it didn't get the payment. Now the user can go to a court,\n>     present the\n>     >>>> invoice signed by the merchant, and the proof-of-payment, and\n>     force the\n>     >>>> merchant to honor its commitment.\n>     >>>>\n>     >>>Lightning-dev mailing list\n>     >>>Lightning-dev at lists.linuxfoundation.org\n>     <mailto:Lightning-dev at lists.linuxfoundation.org>\n>     >>>https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>     >>>\n>     >>Lightning-dev mailing list\n>     >>Lightning-dev at lists.linuxfoundation.org\n>     <mailto:Lightning-dev at lists.linuxfoundation.org>\n>     >>https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>     >>\n>     >Lightning-dev mailing list\n>     >Lightning-dev at lists.linuxfoundation.org\n>     <mailto:Lightning-dev at lists.linuxfoundation.org>\n>     >https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>     >\n>\n>     _______________________________________________\n>     Lightning-dev mailing list\n>     Lightning-dev at lists.linuxfoundation.org\n>     <mailto:Lightning-dev at lists.linuxfoundation.org>\n>     https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-02-13T14:23:37",
                "message_text_only": "Good morning Corne and Conner,\n\nIgnoring the practical matters that Corne rightly brings up, I think, it is possible to use ZKCP to provide a \"stronger\" proof-of-payment in the sense that Conner is asking for.\n\nAll that is needed is to create a message (possibly in some standard language) indicating the payment amount and whatever commitment the payee claims to have for this payment, have the payee securely sign the message, and encrypt them.  The encryption key used is hashed and is used as the payment hash for a standard BOLT11.  Together with the standard BOLT11 the payee provides the encrypted message and signature to the payer in some secure communication channel that is end-to-end encrypted (so that only the payer can receive the encrypted message).\n\n(additionally zk-SNARKs attesting to correct operation of the parsing and encryption of the message, as well as the hashing of the encryption key, will be needed)\n\nIn order to claim the payment on-Lightning, the payee provides the encryption key (as it is the preimage for the payment hash).  Standard LN routing protocols then propagate this encryption key back to the payer.\n\nAs only the payer received the encrypted message, only the payer can decrypt that message using the payment preimage, even if the preimage was propagated to multiple hops (and may very well have been published onchain in case a hop resolved a channel onchain).\n\nRegards,\nZmnSCPxj\n\n\n-------- Original Message --------\n On February 13, 2018 10:33 AM, Corn\u00e9 Plooy via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n\n>Hi Conner,\n>\n>\n> I do believe proof of payment is an important feature to have,\n> especially for the use case of a payer/payee pair that doesn't\n> completely trust each other, but does have the possibility to go to court.\n>\n>\n> However, I'm not convinced by what you wrote. I do think a combination\n> of signed invoice + preimage is a reliable proof of payment. Strictly\n> speaking, you are right: it is not so much a proof that they payer\n>sent the funds, but it is proof that the payee received the funds.\n> This is because the only scenario where it makes sense for the payee to\n> reveal the preimage is if it can claim a corresponding incoming HTLC\n> with (at least) the correct amount of funds. Revealing the preimage in\n> any other scenario would be stupid(), and no amount of cryptography can\n> protect against stupidity. So, when it comes to cryptographic proof,\n> this is about as good as it gets.\n>\n>\n> Now, about the difference between the payer having sent the funds and\n> the payee having received the funds: I'd argue that it's the second that\n> really matters. If the payer can prove that there is any kind of\n> arrangement that ended up with the payee having received the correct\n> amount of funds, that should count as payment. Now, if none of the\n> intermediaries has been stupid, this does imply that the payer ends up\n> on the sending side of the payment, but even if one if the\n> intermediaries has been stupid, why should the payer and payee care? All\n> that matters is that an arrangement has been made to let the payee\n> receive (at least) the correct amount of funds, and that arrangement has\n> been proven to be successful. I consider that proof of payment.\n>\n>\n> CJP\n>\n>\n> () Stupidity includes being hacked, and anything else that can cause\n> your secrets being used against your own interests.\n>\n>\n> Op 13-02-18 om 04:29 schreef Conner Fromknecht:\n>>Hi everyone,\n>>I've seen some discussions over losing proofs of payment in the AMP\n>> setting,\n>> and wanted to address some lingering concerns I have regarding the\n>> soundness of using the current invoicing system to prove payments.\n>>In general, I think we are ascribing too much weight to simply having a\n>> preimage and BOLT 11 invoice. The structure of non-interactive payments\n>> definitely poses some interesting challenges in adapting the existing\n>> invoicing\n>> scheme. However, I believe there exist stronger and better means of doing\n>> proofs of\u00a0payment,\u00a0and would prefer not to tie our hands by assuming\n>> this is the best way to approach the problem.\n>>IMHO, the current signed invoice + preimage is a very weak proof of\n>> payment.\n>> It's the hash equivalent to proving you own a public key by publishing the\n>> secret key. There is an assumption that the only way someone could get\n>> that\n>> preimage is by having made a payment, but this assumption is broken most\n>> directly by the proving mechanism. Similarly, any intermediary who\n>> acquires\n>> an invoice with the appropriate hash could also make this claim since they\n>> also have the preimage.\n>>Further, I think it's a mistake to conflate\n>> \u00a0 1) me being able to present a valid preimage/invoice pair, with\n>> \u00a0 2) me having received the correct preimage in response to an onion\n>> packet\n>> \u00a0 \u00a0 that I personally crafted for the receiving node\u00a0in\u00a0the invoice.\u00a0\n>>\n>> The main issue is that the proof does not bind a specific sender,\n>> making statement 1 producible by multiple individuals.\u00a0I think it would be\n>> potentially worthwhile to explore proofs of stronger statements, such\n>> as 2,\n>> that could utilize the ephemeral keys in the onion\u00a0packets,\u00a0or even the\n>> onion as a witness, which is more rigidly coupled to having actually\n>> completed a payment.\n>>Without any modification to the spec, we can always use something like\n>> ZKBoo to prove (w/o trusted setup) knowledge of a preimage without\n>> totally revealing it to the verifier. This isn't perfect, but at least\n>> gives the\n>> sender the option to prove the statement without necessarily giving up\n>> the preimage.\n>>TL;DR: I'm not convinced the signed invoice\u00a0+ hash is really a good\n>> yardstick\n>> by which to measure\u00a0provability, and I think doing some research into\n>> proofs\n>> of payment on stronger statements would be incredibly valuable. Therefore,\n>> I'm not sure if AMPs really lose this, so much as\u00a0force\u00a0us to reconsider\n>> what it actually requires to soundly prove a payment to an external\n>> verifier.\n>>Best,\n>> Conner\n>>On Mon, Feb 12, 2018 at 6:56 PM ZmnSCPxj via Lightning-dev\n>> <lightning-dev at lists.linuxfoundation.org\n>>mailto:lightning-dev at lists.linuxfoundation.org> wrote:\n>>Good morning Christian and Corne,\n>>\n>>Another idea to consider, is techniques like ZKCP and ZKCSP, which\n>>provide atomic access to information in exchange for monetary\n>>compensation.\u00a0 Ensuring atomicity of the exchange can be done by\n>>providing the information encrypted, a hash of the encryption key,\n>>and proofs that the encrypted data is the one desired and that the\n>>data was encrypted with the given key; the proof-of-payment is the\n>>encryption key, and possession of the encryption key is sufficient\n>>to gain access to the information, with no need to bring in legal\n>>structures.\n>>\n>>(admittedly, ZKCP and ZKCSP are dependent on new cryptography...)\n>>\n>>(also, AMP currently cannot provide a proof-of-payment, unlike\n>>current payment routing that has proof-of-payment, but that is an\n>>eventual design goal that would enable use of ZKC(S)P\n>>on-Lightning, assuming we eventually find out that zk-SNARKs and\n>>so on are something we can trust)\n>>\n>>Regards,\n>>ZmnSCPxj\n>>\n>>\u200b\n>>Sent with ProtonMail Secure Email.\n>>\u200b\n>>\n>>-------- Original Message --------\n>>\u00a0On February 13, 2018 2:05 AM, Christian Decker\n>><decker.christian at gmail.com <mailto:decker.christian at gmail.com>>\n>>wrote:\n>>\n>>>Honestly I don't get why we are complicating this so much. We have a\n>>> system that allows atomic multipath payments using a single\n>>secret, and\n>>> future decorrelation mechanisms allow us to vary the secret in\n>>such a\n>>> way that multiple paths cannot be collated, why introduce a\n>>whole set of\n>>> problems by giving away the atomicity? The same goes for the\n>>overpaying\n>>> and trusting the recipient to only claim the owed amount, there\n>>is no\n>>> need for this. Just pay the exact amount, by deriving secrets\n>>from the\n>>> main secret and make the derivation reproducible by intermediate\n>>hops.\n>>>\n>>> Having proof-of-payment be presentable in a court is a nice\n>>feature, but\n>>> it doesn't mean we need to abandon all guarantees we have worked\n>>so hard\n>>> to establish in LN.\n>>>\n>>> Corn\u00e9 Plooy via Lightning-dev\n>>lightning-dev at lists.linuxfoundation.org\n>><mailto:lightning-dev at lists.linuxfoundation.org>\n>>>writes:\n>>>\n>>>>I was thinking that, for that use case, a different signed\n>>invoice could\n>>>> be formulated, stating\n>>>> - several payment hashes with their corresponding amounts\n>>>>\n>>>> - the obligation of signer to deliver Z if all corresponding\n>>payment\n>>>> keys are shown\n>>>>\n>>>> - some terms to handle the case where only a part of the\n>>payments was\n>>>> successful, e.g. an obligation to refund\n>>>>The third item is a bit problematic: in order to distinguish\n>>this case\n>>>> from a complete success, the payee would have to prove absence of\n>>>> successful transactions, which is hard. Absence of successful\n>>>> transactions can only be declared by the payer, so in order to\n>>reliably\n>>>> settle without going to court first, the payer should sign a\n>>>> declaration stating that certain transactions were canceled and\n>>that the\n>>>> other ones should be refunded. This can be another invoice.\n>>>>So, the original invoice states:\n>>>> - several payment hashes with their corresponding amounts\n>>>>\n>>>> - if all corresponding payment keys are shown: the obligation\n>>of <payee>\n>>>> to deliver Z, UNLESS stated otherwise by an invoice signed by\n>><payer>\n>>>>-- signed by <payee>\n>>>>But if a payment partially fails, it can be refunded\n>>cooperatively with\n>>>> an invoice created by payer:\n>>>> - declares which of the original payments were successful (with\n>>payment\n>>>> keys) and which were not\n>>>>\n>>>> - replaces the obligation of <payee> to deliver Z with an\n>>obligation to\n>>>> refund the successful transactions\n>>>>\n>>>> - several payment hashes with their corresponding amounts\n>>>>\n>>>> - if all corresponding payment keys are shown: cancel the\n>>obligation of\n>>>> <payee> to refund\n>>>>-- signed by <payer>\n>>>>Maybe this can be repeated iteratively if necessary; hopefully the\n>>>> not-yet-settled amount will converge to zero.\n>>>>Important advantage: this only requires changes to the invoice\n>>format,\n>>>> not to the network protocol.\n>>>>The point is: in this use case, the court is apparently the\n>>final point\n>>>> of settlement for invoices, just like the blockchain is for the\n>>other\n>>>> channels in the route. IANAL, but I think the \"scripting language\"\n>>>> accepted by courts is quite flexible, and you can use that to\n>>enforce\n>>>> atomicity. With the construction described above, you can\n>>either refund\n>>>> cooperatively (and collect evidence that refund has happened),\n>>or, if\n>>>> that fails, go to court to enforce settlement there.\n>>>>CJP\n>>>>Op 12-02-18 om 10:23 schreef Christian Decker:\n>>>>>CJP cjp at ultimatestunts.nl <mailto:cjp at ultimatestunts.nl> writes:\n>>>>>>Can you give a use case for this?\n>>>>>>Usually, especially in the common case that a payment is done in\n>>>>>> exchange for some non-cryptographic asset (e.g. physical\n>>goods), there\n>>>>>> already is some kind of trust between payer and payee. So, if\n>>a payment\n>>>>>> is split non-atomically into smaller transactions, and only a\n>>part\n>>>>>> succeeds, presumably they can cooperatively figure out some\n>>way to\n>>>>>> settle the situation.\n>>>>>> The scenario that is commonly used in these cases is a\n>>merchant that\n>>>>>> provides a signed invoice \"if you pay me X with payment_hash\n>>Y I will\n>>>>>> deliver Z\". Now the user performs the payment, learns the\n>>payment_key\n>>>>>> matching the payment_hash, but the merchant refuses to\n>>deliver, claiming\n>>>>>> it didn't get the payment. Now the user can go to a court,\n>>present the\n>>>>>> invoice signed by the merchant, and the proof-of-payment, and\n>>force the\n>>>>>> merchant to honor its commitment.\n>>>>>>\n>>>>>Lightning-dev mailing list\n>>>>>Lightning-dev at lists.linuxfoundation.org\n>><mailto:Lightning-dev at lists.linuxfoundation.org>\n>>>>>https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>>>\n>>>>Lightning-dev mailing list\n>>>>Lightning-dev at lists.linuxfoundation.org\n>><mailto:Lightning-dev at lists.linuxfoundation.org>\n>>>>https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>>\n>>>Lightning-dev mailing list\n>>>Lightning-dev at lists.linuxfoundation.org\n>><mailto:Lightning-dev at lists.linuxfoundation.org>\n>>>https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>>\n>>_______________________________________________\n>>Lightning-dev mailing list\n>>Lightning-dev at lists.linuxfoundation.org\n>><mailto:Lightning-dev at lists.linuxfoundation.org>\n>>https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>>\n>>Lightning-dev mailing list\n>>Lightning-dev at lists.linuxfoundation.org\n>>https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n>\n>Lightning-dev mailing list\n>Lightning-dev at lists.linuxfoundation.org\n>https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>"
            },
            {
                "author": "Anthony Towns",
                "date": "2018-02-21T09:19:47",
                "message_text_only": "On Tue, Feb 13, 2018 at 09:23:37AM -0500, ZmnSCPxj via Lightning-dev wrote:\n> Good morning Corne and Conner,\n> Ignoring the practical matters that Corne rightly brings up, I think,\n> it is possible to use ZKCP to provide a \"stronger\" proof-of-payment in\n> the sense that Conner is asking for.\n\nI think Schnorr scriptless scripts work for this (assuming HTLC payment\nhashes are ECC points rather than SHA256 hashes). In particular:\n\n - Alice agrees to pay Bob $5 for a coffee.\n\n - Bob calculates a lightning payment hash preimage r, and payment hash\n   R=r*G. Bob also prepares a receipt message, saying \"I've been paid $5\n   to give Alice a coffee\", and calculates a partial Schnorr signature\n   of this receipt (n a signature nonce, N=n*G, s=n+H(R+N,B,receipt)*b),\n   and sends Alice (R, N, s)\n\n - Alice verfies the partial signature:\n      s*G = N + H(R+N,B,receipt)*B\n\n - Alice pays over lightning conditional on receiving the preimage r of R.\n\n - Alice then has a valid signature of the receipt, signed by Bob:\n      (R+N, r+s)\n\nThe benefit over just getting a hash preimage, is that you can use this to\nprove that you paid Bob, rather than Carol or Dave, at some later date,\nincluding to a third party (a small-claims court, tax authorities,\na KYC/AML audit?).\n\nThe nice part is you get that just by doing some negotiation at the\nstart, it's not something the lightning protocol needs to handle at all\n(beyond switching to ECC points for payment hashes).\n\n> -------- Original Message --------\n>  On February 13, 2018 10:33 AM, Corn\u00e9 Plooy via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n> >Hi Conner,\n> > I do believe proof of payment is an important feature to have,\n> > especially for the use case of a payer/payee pair that doesn't\n> > completely trust each other, but does have the possibility to go to court.\n\nCheers,\naj"
            }
        ],
        "thread_summary": {
            "title": "Proof of payment (Re: AMP: Atomic Multi-Path Payments over Lightning)",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Anthony Towns",
                "Corn\u00e9 Plooy",
                "ZmnSCPxj"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 27025
        }
    },
    {
        "title": "[Lightning-dev] channel rebalancing support kind of exists already?",
        "thread_messages": [
            {
                "author": "Robert Olsson",
                "date": "2018-02-06T16:53:43",
                "message_text_only": "Hello\n\nLet's say Bob opens a channel to Alice for 2BTC\nCarol then opens a channel to Bob for 2BTC.\nAlice and Carol are already connected to Others (and/or eachother even)\nThe network and channel balances will look like this:\n\nAlice 0--2 Bob 0--2 Carol\n  |                   |\n  +----- OTHERS ------+\n\nBob for some reason wants the channels to be balanced, so he has some\nbetter redundancy and it looks better.\n\nSo hypothetically Bob solves this by paying himself an invoice of 1BTC and\nmaking sure the route goes out thru Alice and comes back via Carol. Bob\npays fees so he isn't ashamed if it disturbs the other balances in the\nnetwork. Should he care?\n\nAlice 1--1 Bob 1--1 Carol\n  |                   |\n  +----- OTHERS ------+\n\nNow Bob has two nice balanced channels, meaning he has better connectivity\nin both directions.\n\nDoesn't the protocol already support that kind of solutions, and all we\nneed is a function in the CLI allowing Bob to pay to himself, and specify\nwhich two channels he would like to balance?\n\nMaybe even make it automatically balance.\n\nIs this a good idea of something to support, and/or Is there a risk the\nentire network will start doing this and it will start oscillating?\n\nBest regards\nRobert Olsson\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180206/e5b2ba8d/attachment-0001.html>"
            },
            {
                "author": "Aleksej",
                "date": "2018-02-06T17:19:14",
                "message_text_only": "Hi\nYeah, you can always refund your channels thorugh other channels.\nI don't think however that it would be usually necessary to balance\nfunds on the channel to be equal.\nI always assumed that a typical user would have perhaps one channel\nwhere he receives funds (employer) and others for spending (stores).\nIn order to refund them, he would simply spend funds thorugh channels\nthat are more unbalanced in direction where the user is \"owned\" coins.\nAnd of course, the other way around, employer would be able to pay the\nemployee throgh channels he has with stores where he owns the money.\nIn conclusion, I don't think rebalnacing would need to be a sperate\ntransaction.\nThis could simply be done automatically when the user sends or receives\nhis usual transactions.\nI am not sure about all the diffuclties regarding routing in LN.\nHopefully all of this can be done safely, reliably and quickly.\nBest regards,\nAleksej\nOn Tue, 2018-02-06 at 18:53 +0200, Robert Olsson wrote:\n> Hello\n> \n> Let's say Bob opens a channel to Alice for 2BTC\n> Carol then opens a channel to Bob for 2BTC.\n> Alice and Carol are already connected to Others (and/or eachother\n> even)\n> The network and channel balances will look like this:\n> \n> Alice 0--2 Bob 0--2 Carol\n> \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0|\n> \u00a0 +----- OTHERS ------+\u00a0\n> \n> Bob for some reason wants the channels to be balanced, so he has some\n> better redundancy and it looks better.\n> \n> So hypothetically Bob solves this by paying himself an invoice of\n> 1BTC and making sure the route goes out thru Alice and comes back via\n> Carol. Bob pays fees so he isn't ashamed if it disturbs the other\n> balances in the network. Should he care?\n> \u00a0\n> Alice 1--1 Bob 1--1 Carol\n> \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0|\n> \u00a0 +----- OTHERS ------+\u00a0\n> \n> Now Bob has two nice balanced channels, meaning he has better\n> connectivity in both directions.\n> \n> Doesn't the protocol already support that kind of solutions, and all\n> we need is a function in the CLI allowing Bob to pay to himself, and\n> specify which two channels he would like to balance?\n> \n> Maybe even make it automatically balance.\n> \n> Is this a good idea of something to support, and/or Is there a risk\n> the entire network will start doing this and it will start\n> oscillating?\n> \n> Best regards\n> Robert Olsson\n> \n> \n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180206/9cb06666/attachment.html>"
            },
            {
                "author": "Robert Olsson",
                "date": "2018-02-06T19:16:02",
                "message_text_only": "Hi Aleksej,\n\nYes i was talking about rebalancing without blockchains. and that there is\na need for rebalancing, since things routed thru you can also affect\nbalances an a surprising fashion.\nA function to avoid routing too much thru your channels would be nice too.\n\nConsider a scenario where your employer opens a channel to you, and send\nyour salary.\nYou can then go shopping and use the channel via you employer, but after a\nwhile you want some more capacity, or less fees, or redundancy in case your\nemployers node is offline.\nSo you open a new one directly to walmart with a tx because you plan to go\nthere after work, and go there often.\n\nNow it turns out your employer also buys stuff from walmart, so they pay\nthem via your channel to walmart and uses up most of it.\nSo when you go to walmart to shop, you notice your brand new channel with\nthem is already used up so you will have to route it back thru your\nemployer, however they are of course currently doing maintenance on their\nnode. Your redundancy is gone. And if they were up, your fee saving idea\nwith a direct walmart channel would have been gone.\n\nSo, I think a function to \"refuse routing over this channel if it would\nresult in less than X% of capacity\" and \"automatically balance this channel\nto have at least X% of capacity\" would be very useful features, and i think\nthey don't have to be extremely hard to implement over current protocol.\n\nBest regards\nRobert Olsson\n\n\n\n\nOn Tue, Feb 6, 2018 at 7:19 PM, Aleksej <aleksej at spidermail.tk> wrote:\n\n> Hi\n>\n> Yeah, you can always refund your channels thorugh other channels.\n> I don't think however that it would be usually necessary to balance funds\n> on the channel to be equal.\n> I always assumed that a typical user would have perhaps one channel where\n> he receives funds (employer) and others for spending (stores).\n> In order to refund them, he would simply spend funds thorugh channels that\n> are more unbalanced in direction where the user is \"owned\" coins.\n> And of course, the other way around, employer would be able to pay the\n> employee throgh channels he has with stores where he owns the money.\n>\n> In conclusion, I don't think rebalnacing would need to be a sperate\n> transaction.\n> This could simply be done automatically when the user sends or receives\n> his usual transactions.\n> I am not sure about all the diffuclties regarding routing in LN. Hopefully\n> all of this can be done safely, reliably and quickly.\n>\n> Best regards,\n> Aleksej\n>\n> On Tue, 2018-02-06 at 18:53 +0200, Robert Olsson wrote:\n>\n> Hello\n>\n> Let's say Bob opens a channel to Alice for 2BTC\n> Carol then opens a channel to Bob for 2BTC.\n> Alice and Carol are already connected to Others (and/or eachother even)\n> The network and channel balances will look like this:\n>\n> Alice 0--2 Bob 0--2 Carol\n>   |                   |\n>   +----- OTHERS ------+\n>\n> Bob for some reason wants the channels to be balanced, so he has some\n> better redundancy and it looks better.\n>\n> So hypothetically Bob solves this by paying himself an invoice of 1BTC and\n> making sure the route goes out thru Alice and comes back via Carol. Bob\n> pays fees so he isn't ashamed if it disturbs the other balances in the\n> network. Should he care?\n>\n> Alice 1--1 Bob 1--1 Carol\n>   |                   |\n>   +----- OTHERS ------+\n>\n> Now Bob has two nice balanced channels, meaning he has better connectivity\n> in both directions.\n>\n> Doesn't the protocol already support that kind of solutions, and all we\n> need is a function in the CLI allowing Bob to pay to himself, and specify\n> which two channels he would like to balance?\n>\n> Maybe even make it automatically balance.\n>\n> Is this a good idea of something to support, and/or Is there a risk the\n> entire network will start doing this and it will start oscillating?\n>\n> Best regards\n> Robert Olsson\n>\n>\n> _______________________________________________\n> Lightning-dev mailing listLightning-dev at lists.linuxfoundation.orghttps://lists.linuxfoundation.org/mailman/listinfo/lightning-dev <http://qjx5.mjt.lu/lnk/AEAAScyO3BEAAAAAAAAAAAHPbO0AAABGqAQAAAAAAAotPgBaeeOYwazT33IGS4maS5AFYbV6vAAJw5s/1/vdYGhC4TVolRSbTpj5Km2A/aHR0cHM6Ly9saXN0cy5saW51eGZvdW5kYXRpb24ub3JnL21haWxtYW4vbGlzdGluZm8vbGlnaHRuaW5nLWRldg>\n>\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180206/b88a14f4/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-02-07T07:13:20",
                "message_text_only": "Good Morning Robert,\n\nYes, this already is possible, but is not implemented by any implementation to my knowledge at this point.\n\nNote that \"balance\" is not necessarily a property you might desire for your channels.  In your example, under the \"unbalanced\" case, Bob can pay a 1.5BTC invoice, but in the \"balanced\" case Bob can no longer pay that 1.5BTC invoice.  Of course, once AMP is possible then this consideration is not an issue.\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n-------- Original Message --------\nOn February 7, 2018 12:53 AM, Robert Olsson <robban at robtex.com> wrote:\n\n> Hello\n>\n> Let's say Bob opens a channel to Alice for 2BTC\n> Carol then opens a channel to Bob for 2BTC.\n> Alice and Carol are already connected to Others (and/or eachother even)\n> The network and channel balances will look like this:\n>\n> Alice 0--2 Bob 0--2 Carol\n>   |                   |\n>   +----- OTHERS ------+\n>\n> Bob for some reason wants the channels to be balanced, so he has some better redundancy and it looks better.\n>\n> So hypothetically Bob solves this by paying himself an invoice of 1BTC and making sure the route goes out thru Alice and comes back via Carol. Bob pays fees so he isn't ashamed if it disturbs the other balances in the network. Should he care?\n>\n> Alice 1--1 Bob 1--1 Carol\n>   |                   |\n>   +----- OTHERS ------+\n>\n> Now Bob has two nice balanced channels, meaning he has better connectivity in both directions.\n>\n> Doesn't the protocol already support that kind of solutions, and all we need is a function in the CLI allowing Bob to pay to himself, and specify which two channels he would like to balance?\n>\n> Maybe even make it automatically balance.\n>\n> Is this a good idea of something to support, and/or Is there a risk the entire network will start doing this and it will start oscillating?\n>\n> Best regards\n> Robert Olsson\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180207/df4a3e65/attachment-0001.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-02-08T23:11:24",
                "message_text_only": "Technically you can do it with c-lightning today, if you create a\ncircular route manually and then use the `sendpay` JSON-RPC command to\nsend funds along that route it'll do just that. It's as simple as that.\n\nWe don't have built-in support yet, I don't know if we ever will, since\nit is trivially implemented outside of the daemon itself. I also don't\nthink we need to consider this use-case at all from a protocol point of\nview.\n\nCheers,\nChristian\n\nZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\nwrites:\n\n> Good Morning Robert,\n>\n> Yes, this already is possible, but is not implemented by any implementation to my knowledge at this point.\n>\n> Note that \"balance\" is not necessarily a property you might desire for your channels.  In your example, under the \"unbalanced\" case, Bob can pay a 1.5BTC invoice, but in the \"balanced\" case Bob can no longer pay that 1.5BTC invoice.  Of course, once AMP is possible then this consideration is not an issue.\n>\n> Regards,\n> ZmnSCPxj\n>\n> Sent with [ProtonMail](https://protonmail.com) Secure Email.\n>\n> -------- Original Message --------\n> On February 7, 2018 12:53 AM, Robert Olsson <robban at robtex.com> wrote:\n>\n>> Hello\n>>\n>> Let's say Bob opens a channel to Alice for 2BTC\n>> Carol then opens a channel to Bob for 2BTC.\n>> Alice and Carol are already connected to Others (and/or eachother even)\n>> The network and channel balances will look like this:\n>>\n>> Alice 0--2 Bob 0--2 Carol\n>>   |                   |\n>>   +----- OTHERS ------+\n>>\n>> Bob for some reason wants the channels to be balanced, so he has some better redundancy and it looks better.\n>>\n>> So hypothetically Bob solves this by paying himself an invoice of 1BTC and making sure the route goes out thru Alice and comes back via Carol. Bob pays fees so he isn't ashamed if it disturbs the other balances in the network. Should he care?\n>>\n>> Alice 1--1 Bob 1--1 Carol\n>>   |                   |\n>>   +----- OTHERS ------+\n>>\n>> Now Bob has two nice balanced channels, meaning he has better connectivity in both directions.\n>>\n>> Doesn't the protocol already support that kind of solutions, and all we need is a function in the CLI allowing Bob to pay to himself, and specify which two channels he would like to balance?\n>>\n>> Maybe even make it automatically balance.\n>>\n>> Is this a good idea of something to support, and/or Is there a risk the entire network will start doing this and it will start oscillating?\n>>\n>> Best regards\n>> Robert Olsson\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Corn\u00e9 Plooy",
                "date": "2018-02-07T10:00:09",
                "message_text_only": "Hi,\n\nAmiko Pay had this: on an invoice, you could (optionally) specify\nthrough which peer you wanted to be paid; on a payment, you could\n(optionally) specify through which peer you wanted to pay. In fact, if\nyou didn't do this, a payment-to-self would not result in any channel\nactions, since the most efficient route to yourself makes zero hops.\nThere was some weird edge case in this if you had a channel to\nyourself(*) and specified it in both the invoice and the payment: the\nroute would actually be forced to go multiple times through the same\nchannel.\n\nRouting in Lightning is a bit different than in Amiko Pay, and I never\nattempted to adapt Amiko Pay to the Lightning protocol standard. I do\nthink that Lightning offers *better* possibilities for channel\nre-balancing, since it offers source routing: the source can explicitly\nspecify the entire route. If any channels offer negative fee rates to\nhave them re-balanced, you might even make money by rebalancing other\npeoples' channels.\n\nI'm not sure when channel re-balancing would be useful: if you are able\nto pay through the B-A-others-C-B route and through the B-C-anyone\nroute, then certainly B-A-others-C-anyone would work as well?\n\nMaybe to reduce risk that some channels on the 'others' path might be\nsaturated at inconvenient moments? If Bob receives monthly salary from\nAlice and regularly wants to buy things from Carol, he'd probably want\nto transfer his funds from the A-B channel as soon as possible to the\nB-C channel. Alternatively, he could speculate on when fees on the\nOTHERS route would be optimal to make the transfer.\n\nAnother use case could be privacy protection: if Alice is an employer,\nshe probably knows Bob's identity; Bob probably doesn't want her to know\ndetails about his spending behavior as well. Bob-Carol could be a\npseudonymous contact on the TOR network. On receiving salary from Alice,\nBob would immediately transfer it to the B-C link, and perform\nindividual payments from there.\n\nCJP\n\n(*) not very useful in practice, but certainly useful for testing.\nBesides, *some* user is going to try that sooner or later, so you have\nto be robust against it.\n\n\nOp 06-02-18 om 17:53 schreef Robert Olsson:\n> Hello\n>\n> Let's say Bob opens a channel to Alice for 2BTC\n> Carol then opens a channel to Bob for 2BTC.\n> Alice and Carol are already connected to Others (and/or eachother even)\n> The network and channel balances will look like this:\n>\n> Alice 0--2 Bob 0--2 Carol\n> \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0|\n> \u00a0 +----- OTHERS ------+\u00a0\n>\n> Bob for some reason wants the channels to be balanced, so he has some\n> better redundancy and it looks better.\n>\n> So hypothetically Bob solves this by paying himself an invoice of 1BTC\n> and making sure the route goes out thru Alice and comes back via\n> Carol. Bob pays fees so he isn't ashamed if it disturbs the other\n> balances in the network. Should he care?\n> \u00a0\n> Alice 1--1 Bob 1--1 Carol\n> \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0|\n> \u00a0 +----- OTHERS ------+\u00a0\n>\n> Now Bob has two nice balanced channels, meaning he has better\n> connectivity in both directions.\n>\n> Doesn't the protocol already support that kind of solutions, and all\n> we need is a function in the CLI allowing Bob to pay to himself, and\n> specify which two channels he would like to balance?\n>\n> Maybe even make it automatically balance.\n>\n> Is this a good idea of something to support, and/or Is there a risk\n> the entire network will start doing this and it will start oscillating?\n>\n> Best regards\n> Robert Olsson\n>\n>\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            }
        ],
        "thread_summary": {
            "title": "channel rebalancing support kind of exists already?",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Robert Olsson",
                "Corn\u00e9 Plooy",
                "Aleksej",
                "ZmnSCPxj",
                "Christian Decker"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 17174
        }
    },
    {
        "title": "[Lightning-dev] Post-Schnorr lightning txes",
        "thread_messages": [
            {
                "author": "Anthony Towns",
                "date": "2018-02-19T22:59:07",
                "message_text_only": "Hi *,\n\nMy understanding of lightning may be out of date, so please forgive\n(or at least correct :) any errors on my behalf.\n\nI was thinking about whether Greg Maxwell's graftroot might solve the\nchannel monitoring problem (spoiler: not really) and ended up with maybe\nan interesting take on Schnorr. I don't think I've seen any specific\nwriteup of what that might look like, so hopefully at least some of this\nis novel!\n\nI'm assuming familiarity with current thinking on Schnorr sigs -- but all\nyou should need to know is the quick summary at footnote [0].\n\nSo I think there's four main scenarios for closing a lightning channel:\n\n - both parties are happy to close, do so cooperatively, and can\n   sign a new unconditional transaction that they agree on. already fine.\n   (should happen almost all of the time, call it 80%)\n\n - communications failure: one side has to close, but the other side\n   is happy to cooperate as far as they're able but can only do so via\n   the blockchain and maybe with some delay (maybe 15% of the time)\n\n - disappearance, uncooperative: one side effectively completely\n   disappears so the other side has to fully close the channel on their\n   own (5% of the time)\n\n - misbehaviour: one side tries publishing an old channel state due to\n   error or maliciousness, and the other collects the entire balance as\n   penalty (0% of the time)\n\nWith \"graftroot\" in mind, I was thinking that optimising for the last\ncase might be interesting -- despite expecting it to be vanishingly\nrare. That would have to look something like:\n\n   (0) funding tx\n   (1) ...which is spent by a misbehaving commitment tx\n   (2) ...which is spent by a penalty tx\n\nYou do need 3 txes for that case, but you really only need 1 output\nfor each: so (0) is 2-in-1-out, (1) is 1-in-1-out, (2) is 1-in-1-out;\nwhich could all be relatively cheap. (And (2) could be batched with other\ntxes making it 1 input in a potentially large tx)\n\nFor concreteness, I'm going to treat A as the one doing the penalising,\nand B (Bad?) as the one that's misbehaving.\n\nIf you treat each of those txes as a muSig Schnorr pay-to-pubkey, the\noutput addresses would be:\n\n   (0) funding tx pays to [A,B]\n   (1) commitment tx pays to [A(i),Revocation(B,i)]\n   (2) pays to A\n\n(where i is a commitment id / counter for the channel state)\n\nIf B misbehaves by posting the commitment tx after revealing the\nrevocation secret, A can calculate A(i) and Revocation(B,i) and claim\nall the funds immediately.\n\nAs far as the other cases go:\n\n  - In a cooperative close, you don't publish any commitment txes, you\n    just spend the funding to each party's preferred destinations\n    directly; so this is already great.\n\n  - Otherwise, you need to be able to actually commit to how the funds\n    get distributed.\n\nBut committing to distributing funds is easy: just jointly sign\na transaction with [A(i),Revocation(B,i)]. Since B is the one we're\nworrying about misbehaving, it needs to hold a transaction with the\nappropriate outputs that is:\n\n  - timelocked to `to_self_delay` blocks/seconds in advance via nSequence\n  - signed by A(i)\n\nThat ensures A has `to_self_delay` blocks/seconds to penalise misehaviour,\nand that when closing properly, B can complete the signature using the\ncurrent revocation secret.\n\nThis means the \"appropriate outputs\" no longer need the OP_CSV step, which\nshould simplify the scripts a bit.\n\nHaving B have a distribution transaction isn't enough -- B could vanish\nbetween publishing the commitment transaction and the distribution\ntransaction, leaving A without access to any funds. So A needs a\ncorresponding distribution transaction. But because that transaction can\nonly be published if B signs and publishes the corresponding commitment\ntransaction, the fact that it's published indicates both A and B are\nhappy with the channel close -- so this is a semi-cooperative close and\nno delay is needed. So A should hold a partially signed transaction with\nthe same outputs:\n\n  - without any timelock\n  - signed by Revocation(B,i), waiting for signature by A(i)\n\nThus, if B does a non-cooperative close, either:\n\n  - A proves misbehaviour and claims all the funds immediately\n  - A agrees that the channel state is correct, signs and publishes\n    the un-timelocked distribution transaction, then claims A's outputs;\n    B can then immediately claim its outputs\n  - A does nothing, and B waits for the `to_self_delay` period, signs\n    and publishes its transaction, then claims B's outputs; A can eventually\n    claim its own outputs\n\nIn that case all of the transactions except the in-flight HTLCs just look\nlike simple pay-to-pubkey transactions.\n\nFurther, other than the historical secrets no old information needs\nto be retained: misbehaviour can be dealt with (and can only be dealt\nwith) by creating a new transaction signed by your own secrets and the\nrevocation information.\n\nNone of that actually relies on Schnorr-multisig, I think -- it could\nbe done today with normal 2-of-2 multisig as far as I can see.\n\n\n\nI'm not 100% sure how this approach works compared to the current one\nfor the CSV/CLTV overlap problem. I think any case you could solve by\nobtaining a HTLC-Timeout or HTLC-Success transaction currently, you could\nsolve in the above scenario by just updating the channel state to remove\nthe HTLC.\n\n\nSo I believe the above lets you completely forget info about old HTLCs,\nwhile still enforcing correct behavior, and also makes enforcing correct\nbehaviour cheaper because it's just two extremely simple transactions\nto post. If I haven't missed any corner cases, it also seems to simplify\nthe scripts a fair bit.\n\nDoes this make sense? It seems to to me...\n\n\nSo for completeness, it would make sense to do HTLCs via Schnorr --\nat least to make them reveal elliptic curve private keys, and ideally\nto make them mostly indistinguishable from regular transactions as a\n\"scriptless script\" [1] or \"discreet log contract\" [2]. (I think, at\nleast for HTLCs, these end up being the same?)\n\nThe idea then is to have the HTLC payment hash be R=r*G, where r is the\nsecret/payment receipt.\n\nSupposing your current commitment has n HTLCs in-flight, some paying A\nif the HTLC succeeds and \"r\" is revealed, others paying B. We'll focus\non one paying A. \n\nSo you succeed by A completing a signature that reveals r to B,\nand which simultaneously allows collection of the funds on chain. A\nneeds to be able to do this knowing nothing other than r (and their own\nprivate keys). So agree to sign to muSig 2-of-2 multisig [A,B]. A and B\ngenerate random values i and j respectively and reveal I=i*G and J=j*G,\nand each calculates Q=I+J+R, and they generate partial signatures of a\ntransaction paying A:\n\n    I, i + H(X,Q,m)*H(L,A)*a \n    J, j + H(X,Q,m)*H(L,B)*b\n\nwhere L = H(A,B) and X = H(L,A)*A + H(L,B)*B as usual. Once A knows r,\nA can construct a full signature by adding R, r to the above values,\nand B can then determine r by subtracting the above values from signature\nA generated.\n\nTo ensure B gets paid if the HTLC timesout, they should also sign a\ntimelocked transaction paying B directly, that B can hold onto until\nthe channel state gets updated.\n\nAnd once you're doing payment hashes via ECC, you can of course change\nthem at each hop to make it harder to correlate steps in a payment route.\n\nI think that when combined with the above method of handling CSV delays\nand revocation, this covers all the needed cases with a straightforward\npay-to-pubkey(hash) output, no script info needed at all. It does mean\neach HTLC needs a signature every time the channel state updates (B needs\nto sign a tx allowing A to claim the output once A knows the secret,\nA needs to sign a tx allowing B to claim the output on timeout).\n\n\nFor channel monitoring this is pretty good, I think. You need to\nkeep track of the revocation info and your secret keys -- but that's\nessentially a constant amount of data.\n\nIf you're happy to have the data grow by 64 bytes every time the channel\nstate updates, you can outsource channel monitoring: arrange a formula\nfor constructing a penalty tx based on the channel commitment tx --\neg, 95% of the balance goes to me, 4% goes to the monitor's address, 1%\ngoes to fees, there's a relative locktime of to_self_delay/3 to allow me\nto directly claim 100% of the funds if I happen to be paying attention;\nthen do a partial signature with A(i), and then allow the monitoring\nservice to catch fraudulent transactions, work out the appropriate\nrevocation secret, and finish the signature.\n\nIf your channel updates 100 times a second for an entire year, that's\n200GB of data, which seems pretty feasible. (You can't just regenerate\nthat data though, unless you keep each commitment tx) And it's pretty\neasy to work out which bit of data you need to access: the funding\ntx that's being spent tells you which channel, and the channel state\nindex is encoded in the locktime and sequence, so you should only need\nsmall/logarithmic overhead even for frequently updated channels rather\nthan any serious indexes.\n\nI don't think you can do better than that without serious changes to\nbitcoin: if you let the monitoring agency sign on its own, you'd need some\nsort of covenant opcode to ensure it sends any money to you; and with\nsegwit outputs, there's no way to provide a signature for a transaction\nwithout committing to exactly which transaction you're signing.\n\nI was hoping covenants and graftroot would be enough, but I don't\nthink they are. The idea would be that since the transaction spends to\nA(i)+Rev(B,i), you'd sign an output script with A that uses covenant\nopcodes to ensure the transaction only pays the appropriate monitoring\nreward, and the monitor could then work out A(i)-A and Rev(B,i) and finish\nthe signature. But the signature by \"A\" would need to know A(i)+Rev(B,i)\nwhen calculating the hash, and that's different for every commitment\ntransaction, so as far as I can see, it just doesn't work. You can't\ndrop the muSig-style construction because you need to be protect yourself\nagainst potential malicious choice of the revocation secret [3].\n\n\nSummary:\n\n - Funding txes as 2-of-2 multisig is still great. Convert to\n   Schnorr/muSig when available of course.\n\n - Generate 6+8*n transactions everytime the channel state is updated,\n   (n = number of HTLCs in-flight)\n\n   1. Channel state commitment tx, held by A, spends funding tx,\n      payable to Schnorr muSig address [A(i),Rev(B,i)], signed by B\n   2. Channel fund distribution tx, held by A (CSV), spends (1),\n      signed by Rev(B,i)\n   3. Channel fund distribution tx, held by B (no CSV), spends (1),\n      signed by A(i)\n   4. Channel state commitment tx, held by B, spends funding tx\n      payable to Schnorr muSig address [B(i),Rev(A,i)], signed by A\n   5. Channel fund distribution tx, held by B (CSV), spends (4),\n      signed by Rev(A,i)\n   6. Channel fund distribution tx, held by A (no CSV), spends (4),\n      signed by B(i)\n\n   The fund distribution txs all pay the same collection of addresses:\n     - channel balance for A directly to A's preferred address\n     - channel balance for B directly to B's preferred address\n     - HTLC balance to muSig address for [A,B] for each in-flight HTLC\n       paying A on success\n     - HTLC balance to muSig address for [B,A] for each in-flight HTLC\n       paying B on success\n     - (probably makes sense to bump the HTLC addresses by some random\n       value to make it harder for third parties to tell which addresses\n       were balances versus HTLCs)\n\n   Both (1) and (4) include obscured channel state ids as per current\n   standard.\n\n   For each HTLC that pays X on timeout and Y on success:\n     a. Timeout tx, held by X, signed by Y, spends from (2)\n     b. Timeout tx, held by X, signed by Y, spends from (3)\n     c. Timeout tx, held by X, signed by Y, spends from (5)\n     d. Timeout tx, held by X, signed by Y, spends from (6)\n\n     e. Success tx, held by Y, signed by X, spends from (2)\n     f. Success tx, held by Y, signed by X, spends from (3)\n     g. Success tx, held by Y, signed by X, spends from (5)\n     h. Success tx, held by Y, signed by X, spends from (6)\n\n     (these should all be able to be SIGHASH_SINGLE, ANYONECANPAY\n      to allow some level of aggregation)\n\n - Fund distribution tx outputs can all be pay2pubkey(hash): HTLCs work\n   by pre-signed timelocked transactions and scriptless\n   scripts/discreet-log contracts to reveal the secret; balances work\n   directly; CSV and revocations are already handled by that point\n\n - You can discard all old transaction info and HTLC parameters once\n   they're not relevant to the current channel state\n\n - Channel monitoring can be outsourced pretty efficiently -- as little as\n   a signature per state could be made to works as far as I can see,\n   which doesn't add up too fast.\n\n - There's still no plausible way of doing constant space outsourced\n   channel monitoring without some sort of SIGHASH_NOINPUT, at least\n   that I can see\n\nThoughts?\n\n[4]\n\nCheers,\naj, very sad that this didn't turn out to be a potential use case for\n    graftroot :(\n\n[0] In particular, I'm assuming that:\n\n    - Schnorr sigs in bitcoin will look something like:\n        R, r + H(X,R,m)*x\n\n      (where m is the message being signed by private key x, r is a\n      random per-sig nonce, R and X are public keys corresponding to r,x;\n      H is the secure hash function)\n\n    - muSig is a secure way for untrusting parties to construct an n-of-n \n      combined signature; for public keys A and B, it produces a combined\n      public key:\n        X = H(L,A)*A + H(L,B)*B   \n      with L = H(A,B)\n\n   See https://blockstream.com/2018/01/23/musig-key-aggregation-schnorr-signatures.html\n\n[1] https://scalingbitcoin.org/stanford2017/Day2/Using-the-Chain-for-what-Chains-are-Good-For.pdf\n    http://diyhpl.us/wiki/transcripts/scalingbitcoin/stanford-2017/using-the-chain-for-what-chains-are-good-for/\n\n[2] https://adiabat.github.io/dlc.pdf\n    https://diyhpl.us/wiki/transcripts/discreet-log-contracts/\n\n[3] Well, maybe you could request a zero-knowledge proof to ensure a new\n    revocation hash conforms to the standard for generating revocation\n    secrets without revealing the secret, and have the public key be\n    a(i)*G + r(B,i)*G without using the muSig construct, but that would\n    probably be obnoxious to have to generate every time you update\n    the channel state.\n\n[4] As an aside -- this could make it feasible and interesting to penalise\n    disappearance as well as misbehaviour. If you add a transaction\n    the B pre-signs, spending the commitment tx A holds, giving all the\n    channel funds to A but only after a very large CSV timeout, perhaps\n    `to_self_delay`*50, then the scenarios are:\n\n    If A is present:\n\n      - B publishes an old commitment: A immediately steals all the\n        funds if active or outsourced misbehaviour monitoring. Whoops!\n\n      - B publishes the current commitment: A publishes its distribution\n        transaction and collects its funds immediately, allowing B to\n        do likewise\n\n    If A has disappeared:\n\n      - B publises the current commitment and waits a modest amount\n        of time, publishes its distribution transaction claiming its\n        rightful funds, and allowing A to collect its funds if it ever\n        does reappear and still knows its secrets\n\n      - B publishes the current commitment, waits a fair while,\n        A reappears and publishes its distribution transactions, both\n        parties get their rightful funds\n\n      - B publishes the current commitment, waits an extended period\n        of time, and claims the entire channel's funds. If B is\n        particularly reputable, and A can prove its identity (but not\n        recover all its secrets) maybe B even refunds A some/all of its\n        rightful balance\n\n    Perhaps that provides too much of an incentive to try blocking\n    someone from having access to the blockchain though."
            },
            {
                "author": "Anthony Towns",
                "date": "2018-02-22T19:28:45",
                "message_text_only": "On Tue, Feb 20, 2018 at 08:59:07AM +1000, Anthony Towns wrote:\n> My understanding of lightning may be out of date, so please forgive\n> (or at least correct :) any errors on my behalf.\n\n> I'm not 100% sure how this approach works compared to the current one\n> for the CSV/CLTV overlap problem. I think any case you could solve by\n> obtaining a HTLC-Timeout or HTLC-Success transaction currently, you could\n> solve in the above scenario by just updating the channel state to remove\n> the HTLC.\n\nSo, I didn't understand the HTLC-Timeout/HTLC-Success transactions (you\ndon't have to obtain them separately, they're provided along with every\ncommitment tx), and the current setup works better than what I suggest\nunless to_self_delay is very small.\n\nIt could be possible to make that a tradeoff: choose a small to_self_delay\nbecause you're confident you'll monitor the chain and quickly penalise any\ncheating, with the bonus that that makes monitoring cheaply outsourcable\neven for very active channels; or choose a large to_self_delay and have\nit cost a bit more to outsource monitoring.\n\nAnyway.\n\nYou can redo all the current txes with Schnorr/muSig/scriptless-scripts\nfine, I think:\n\n - funding tx is 2-of-2 muSig\n\n - the commitment tx I hold has outputs for:\n      your balance - payable to A(i)\n      my balance - payable to A(i)+R(B,i)\n      each in-flight HTLC - payable to A(i)+R(B,i)+X(j)\n   where\n      A(i) is your pubkey for commitment i\n      R(B,i) is my revocation hash for commitment i\n      X(j) is a perturbation for the jth HTLC to make it hard to know\n        which output is a HTLC and which isn't\n   spends the funding tx\n   locktime and sequence of the funding tx input encode i\n   partially signed by you\n\n - the HTLC-Success/HTLC-Timeout txes need to have two phases, one that\n   can immediately demonstrate the relevent condition has been met, and\n   a second with a CSV delay to ensure cheating can be penalised.\n\n   so:\n     HTLC-Success: pays A(i)+R(B,i)+Y(j), partially signed by you\n       with scriptless script requirement of revealing preimage for\n       corresponding payment hash\n     HTLC-Timeout: pays A(i)+R(B,i)+Y(j), partially signed by you\n       with locktime set to enforce timeout\n\n - you also need a claim transaction for each output you can possibly\n   spend:\n     Balance-Claim: pays B(i), funded by my balance output, partially\n       signed by you, with sequence set to enforce relative timelock of\n       to_self_delay\n     HTLC-Claim: pays B(i)+Z(j), funded by the j'th\n       HTLC-Success/HTLC-Timeout transaction, partially signed by you,\n       with sequence set to enforce relative timelock of to_self_delay\n\n   where Y(j) and Z(j) are similar to X(j) and are just to make it hard\n   for third parties to tell the relationship between outputs\n\nEach of those partial signatures require me to have sent you a unique ECC\npoint J, for which I know the corresponding secret. I guess you'd just\nneed to include those in the revoke_and_ack and update_add_htlc messages.\n\nThe drawback with this approach is that to outsource claiming funds\n(without covenants or SIGHASH_NOINPUT), you'd need to send signatures\nfor 2+2N outputs for every channel update, rather than just 1, and the\nclaiming transactions would be a lot larger.\n\nThis retains the advantage that you don't have to store any info about\noutdated HTLCs if you're monitoring for misbehaviour yourself; you just\nneed to send an extra two signatures for every in-flight HTLC for every\nchannel update if you're outsourcing channel monitoring.\n\nPosting a penalty transaction in this scheme isn't as cheap as just\nbeing 1-in-1-out, but if you're doing it yourself, it's still cheaper\nthan trying to claim the funds while misbehaving: you can do it all in a\nsingle transaction, and if cross-input signature aggregation is supported,\nyou can do it all with a single signature; while they will need to supply\nat least two separate transactions, and 1+2N signatures.\n\n> If your channel updates 100 times a second for an entire year, that's\n> 200GB of data, which seems pretty feasible.\n\nIf you update the channel immediately whenever a new HTLC starts or\nends, that's 50 HTLCs per second on average; if they last for 20 seconds\non average, it's 1000 HTLCs at any one time on average, so trustless\noutsourcing would require storing about 2000 signatures per update,\nwhich at 64B per signature, is 13MB/second, or about a terabyte per\nday. Not so feasible by comparison.\n\nThe channel update rate is contributing quadratically to that calculation\nthough, so reducing the rate of incoming HTLCs to 2 per second on average,\nbut capping channel updates at 1 per second, gives an average of 40\nHTLCs at any one time and 81 signatures per update, for 450MB per day\nor 163GB per year, which isn't too bad.\n\n(I guess if you want the privacy preserving features of WatchTower\nmonitoring you'd have to roughly double that space requirement? Not\nreal sure)\n\nCheers,\naj"
            }
        ],
        "thread_summary": {
            "title": "Post-Schnorr lightning txes",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Anthony Towns"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 20872
        }
    },
    {
        "title": "[Lightning-dev] Privacy issues with proof of payment",
        "thread_messages": [
            {
                "author": "Corn\u00e9 Plooy",
                "date": "2018-02-21T10:04:56",
                "message_text_only": "Hi,\n\n\nI am a bit concerned with the privacy implications of having either a\nsigned invoice + pre-image, or possibly a more powerful proof-of-payment\nmechanism. In particular, I am concerned that it might provide\ncryptographic evidence to the buyer that a certain seller performed the\ntransaction, and/or evidence to the seller that a certain buyer\nperformed the transaction.\n\n\nIn many cases, providing this evidence would be a feature rather than a\nbug, allowing third-party dispute settlement (e.g. the legal system).\nHowever, in my opinion, the Lightning network should also (or\nespecially) be suitable for more \"sensitive\" transactions. Even when\ntransactions are not illegal, I believe people still have a need to keep\nsome transaction information private. You don't want it to be possible\nthat your transaction history is stored on some company/person's server\nfor years, and then leaks out when that server gets hacked. Also, in my\nopinion, we should *not* create a two-tier system of \"sensitive\" and\n\"nothing-to-hide\" transactions: that would make the \"sensitive\"\ntransactions automatically suspicious, partially negating the whole\nobjective of being able to do sensitive transactions without\nexperiencing negative consequences.\n\n\nTo some degree, node IDs can act as pseudonyms, without evidence that\nties them to physical identities. However, I consider them to be\nrelatively poor pseudonyms: unlike, for instance, Bitcoin addresses,\ncreating a new node for every new transaction would have a serious\nscalability impact, and defeat the whole purpose of Lightning. I think a\ntypical person would frequently perform transactions that are inherently\ntied to their physical identity, e.g. receiving salary. This could give\nthe counterparty (the employer) a link between physical ID and node ID;\nit might be forced to share this e.g. with authorities, further\nincreasing the odds of leak-out and/or abuse of data.\n\n\nMaybe the solution is to have multiple nodes: one tied to your physical\nID, and one or more virtual identities? You could then transfer funds\nbetween these nodes, and make sure no outsiders receive any\nproof-of-payment info about these transfers. It sounds like an expensive\nsolution though, since you'd have to operate more channels to give each\nnode good connectivity.\n\n\nWhat are your ideas on this? Should proof of payment be optional? Should\nits strength (optionally) be reduced, so that it can only be used in\nfront of some previously-agreed-on dispute resolution party (is that\neven possible)? Should the idea of proof of payment be abandoned\naltogether? Is bi-directional routing(*) useful in this?\n\n\nCJP\n\n\n(*) Payee first finds a route from a rendezvous node to himself,\nonion-encrypts that route, passes it to payer (together with rendezvous\nnode ID), and payer adds to that route the onion route from payer to\nrendezvous point. This way, payer knows the rendezvous node ID, but not\nthe payee node ID. Payee knows the rendezvous node ID, but doesn't know\npayer node ID either. Rendezvous node only knows that it's forwarding a\ntransaction, not from-where-to-where, or the purpose of the transaction."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-02-22T15:58:15",
                "message_text_only": "Good morning Corne,\n\nMy understanding, it would be possible to remove proof-of-payment selectively by hiding the payment in fees.\n\nBasically, to anonymously donate money to a node without leaving proof of who you are, you simply route from yourself to the payee node, then back to yourself.  You pay yourself the minimum HTLC forwarding amount, and leave a hefty fee to the payee node.\n\nThe payee cannot prove that you paid to it; as far as it is concerned it was just a payment forwarding.\n\nThe payer cannot prove that it paid the payee, since anyone on the route other than the payee could have been the source of the payment.  This assumes that the payer does not control the entire route, at least.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-02-22T23:50:33",
                "message_text_only": "Hi Corn\u00e9!\n\n        Indeed, the privacy focus has generally been the payer, rather\nthan the recipient of funds.\n\n        So there are several things we can do to address this, the main\nobvious one the ability to provide a \"pre-cooked\" onion.  This would\nallow either a payment to an anonymous destination directly or via a\nmiddleman who has that pre-cooked onion.\n\n        I'm pretty sure we can't do this *now*: the shared secrets\nrequired for decoding error replies allow you to to decrypt the entire\nonion, AFAICT.  At a minimum, we need errors from the final destination\nso we can reflect them.  I believe a simple tweak to use the SHA256() of\nthe secrets for shared secret used to encrypt the error replies would\nallow this: you would provide those error secrets along with the onion.\n\n> What are your ideas on this? Should proof of payment be optional? Should\n> its strength (optionally) be reduced, so that it can only be used in\n> front of some previously-agreed-on dispute resolution party (is that\n> even possible)? Should the idea of proof of payment be abandoned\n> altogether? Is bi-directional routing(*) useful in this?\n\nThe proof-of-payment here is a red herring, I think.  If we remove the\ndestination awareness, the privacy issues seem greatly reduced.\n\nCheers,\nRusty."
            },
            {
                "author": "Corn\u00e9 Plooy",
                "date": "2018-02-23T12:08:40",
                "message_text_only": "Hi Rusty,\n> The proof-of-payment here is a red herring, I think.  If we remove the\n> destination awareness, the privacy issues seem greatly reduced.\n>\nRed herring = \"something that misleads or distracts from a relevant or\nimportant issue\"[1]? Do you mean the proof-of-payment is irrelevant for\nthe privacy issue?\n\nTrying to define proof-of-payment, in the typical use case of payment in\nexchange of goods, I'd say that a proof of payment is a piece of data,\nknown to the payee, that allows the payee to prove that\n\u00a0\u00a0\u00a0 \"[<amount> was paid to <payee>, and in exchange] <payee> agreed to\ntransfer ownership of <goods> to <payer>\".\nFor services, it would be\n\u00a0\u00a0\u00a0 \"[<amount> was paid to <payee>, and in exchange] <payee> agreed to\nprovide <services> to <payer>\".\n\nRequirements:\n1. Proof-of-payment must be available to payer, who has the burden of\nproof. By default, ownership of goods is not transferred, and there is\nno obligation to provide services. Absence of proof should point to this\ndefault. It is in the interest of payer to deviate from this default; if\nhe is capable of providing proof, he probably will.\n2. The first part, \"<amount> was paid to <payee>, and in exchange\" is\noptional: what I think really matters is the second part. Only in the\ncase that <payee> turns out to be incapable of delivering goods or\nservices, a dispute resolution party might be interested in the first\npart, to find out what amount of monetary refund would be reasonable.\n3. It is necessary that proof-of-payment proves agreement of <payee>:\notherwise, Eve could write \"Alice agreed to transfer ownership of\n<goods> to Eve\" without consent of Alice.\n4. It may not be necessary that proof-of-payment itself mentions\nidentity of <payee>, but it is necessary that <payee> becomes known to\nthe payer: \"somebody agreed to transfer ownership of <goods> to <payer>\"\ndoes not indicate an obligation of any specific party. Without knowing\n<payee>, it is impossible to verify 3.\n5. It is necessary that proof-of-payment mentions the specific\nobligation (e.g. delivery of goods/services); otherwise, it doesn't\nprove anything useful.\n6. It is necessary that proof-of-payment mentions <payer>: otherwise,\nmultiple potential payer parties could claim goods/services using copies\nof a single proof-of-payment. Now that I think of it, it is way more\ntricky than this, and I'm not sure that any mention of <payer> solves\nanything. What you'd really want is that a single payment only results\nin a single obligation of <payee>. However, IDs tend to be copyable,\njust like proofs-of-payment. The best you can hope for is\ndifficult-to-copy IDs (like government-issued IDs) or very\ninconvenient-to-copy (e.g. private keys of nodes that have significant\nfunds). How do you distinguish multiple identical transactions to the\nsame payer from the same payer making multiple false claims with the\nsame proof-of-payment? Include the payment hash to make it unique? I'm\nnot sure we're solving anything here.\n\nThe current invoice protocol[2] meets 1,2(optional part is\nincluded),3(*),4(*),5(**), and can possibly meet 6(**), although there\nis currently no defined protocol for payee to learn payer's identity.\n\nThere *are* some privacy issues with this kind of proof-of-payment:\n3. requires payer to learn <payee>, and requires payee to provide\ncryptographic proof of his consent to the transaction.\n6. requires payee to learn <payer>. Because of its questionable\nusefulness, I guess it's good there is no protocol defined for this.\nHowever, 6. remains an open issue that does limit usefulness of\nproofs-of-payment. Interestingly, while this knowledge provides\n*evidence* for payer's involvement in the transaction, there is no\ncryptographic *proof* of payer's involvement.\n\nCJP\n\n(*) the 'n' field is not required, but for routing and for verifying the\nsignature, payer currently still needs to know payee's node ID.\n(**) optional: the 'd' and 'h' fields are free-format, and allow for this.\n\n[1] https://en.wikipedia.org/wiki/Red_herring\n[2]\nhttps://github.com/lightningnetwork/lightning-rfc/blob/master/11-payment-encoding.md"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-02-24T00:11:52",
                "message_text_only": "> I am a bit concerned with the privacy implications of having either a\nsigned\n> invoice\n<snip>\n> In particular, I am concerned that it might provide cryptographic evidence\n> to the buyer that a certain seller performed the transaction, and/or\n> evidence to the seller that a certain buyer performed the transaction.\n\nIt's 100% opt-in. If either party doesn't wish to allow any sort of\nproof-of-payment, or service, or whatever, then they don't need to. In this\ncase the sender would just obtain the payment parameters (skipping BOLT11 or\nw/e other follow ups in the feature), and make a \"raw\" payment. Without\ninteraction from the sender, there are various classes of spontaneous\npayments available as well.\n\n>From the PoV of the network (or participants in the payment path), it's\nindistinguishable. Only the end points need to decide if their use case is\none that both opt into for a proof of payment scheme.\n\n-- Laolu\n\n\nOn Fri, Feb 23, 2018 at 4:08 AM Corn\u00e9 Plooy via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Rusty,\n> > The proof-of-payment here is a red herring, I think.  If we remove the\n> > destination awareness, the privacy issues seem greatly reduced.\n> >\n> Red herring = \"something that misleads or distracts from a relevant or\n> important issue\"[1]? Do you mean the proof-of-payment is irrelevant for\n> the privacy issue?\n>\n> Trying to define proof-of-payment, in the typical use case of payment in\n> exchange of goods, I'd say that a proof of payment is a piece of data,\n> known to the payee, that allows the payee to prove that\n>     \"[<amount> was paid to <payee>, and in exchange] <payee> agreed to\n> transfer ownership of <goods> to <payer>\".\n> For services, it would be\n>     \"[<amount> was paid to <payee>, and in exchange] <payee> agreed to\n> provide <services> to <payer>\".\n>\n> Requirements:\n> 1. Proof-of-payment must be available to payer, who has the burden of\n> proof. By default, ownership of goods is not transferred, and there is\n> no obligation to provide services. Absence of proof should point to this\n> default. It is in the interest of payer to deviate from this default; if\n> he is capable of providing proof, he probably will.\n> 2. The first part, \"<amount> was paid to <payee>, and in exchange\" is\n> optional: what I think really matters is the second part. Only in the\n> case that <payee> turns out to be incapable of delivering goods or\n> services, a dispute resolution party might be interested in the first\n> part, to find out what amount of monetary refund would be reasonable.\n> 3. It is necessary that proof-of-payment proves agreement of <payee>:\n> otherwise, Eve could write \"Alice agreed to transfer ownership of\n> <goods> to Eve\" without consent of Alice.\n> 4. It may not be necessary that proof-of-payment itself mentions\n> identity of <payee>, but it is necessary that <payee> becomes known to\n> the payer: \"somebody agreed to transfer ownership of <goods> to <payer>\"\n> does not indicate an obligation of any specific party. Without knowing\n> <payee>, it is impossible to verify 3.\n> 5. It is necessary that proof-of-payment mentions the specific\n> obligation (e.g. delivery of goods/services); otherwise, it doesn't\n> prove anything useful.\n> 6. It is necessary that proof-of-payment mentions <payer>: otherwise,\n> multiple potential payer parties could claim goods/services using copies\n> of a single proof-of-payment. Now that I think of it, it is way more\n> tricky than this, and I'm not sure that any mention of <payer> solves\n> anything. What you'd really want is that a single payment only results\n> in a single obligation of <payee>. However, IDs tend to be copyable,\n> just like proofs-of-payment. The best you can hope for is\n> difficult-to-copy IDs (like government-issued IDs) or very\n> inconvenient-to-copy (e.g. private keys of nodes that have significant\n> funds). How do you distinguish multiple identical transactions to the\n> same payer from the same payer making multiple false claims with the\n> same proof-of-payment? Include the payment hash to make it unique? I'm\n> not sure we're solving anything here.\n>\n> The current invoice protocol[2] meets 1,2(optional part is\n> included),3(*),4(*),5(**), and can possibly meet 6(**), although there\n> is currently no defined protocol for payee to learn payer's identity.\n>\n> There *are* some privacy issues with this kind of proof-of-payment:\n> 3. requires payer to learn <payee>, and requires payee to provide\n> cryptographic proof of his consent to the transaction.\n> 6. requires payee to learn <payer>. Because of its questionable\n> usefulness, I guess it's good there is no protocol defined for this.\n> However, 6. remains an open issue that does limit usefulness of\n> proofs-of-payment. Interestingly, while this knowledge provides\n> *evidence* for payer's involvement in the transaction, there is no\n> cryptographic *proof* of payer's involvement.\n>\n> CJP\n>\n> (*) the 'n' field is not required, but for routing and for verifying the\n> signature, payer currently still needs to know payee's node ID.\n> (**) optional: the 'd' and 'h' fields are free-format, and allow for this.\n>\n> [1] https://en.wikipedia.org/wiki/Red_herring\n> [2]\n>\n> https://github.com/lightningnetwork/lightning-rfc/blob/master/11-payment-encoding.md\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180224/961de462/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Privacy issues with proof of payment",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Corn\u00e9 Plooy",
                "Olaoluwa Osuntokun",
                "ZmnSCPxj"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 14876
        }
    },
    {
        "title": "[Lightning-dev] Welcoming a New C-lightning Core Team Member!",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-02-23T01:18:30",
                "message_text_only": "Hi all,\n\n\tChristian and I just gave ZmnSCPxj commit access to c-lightning; we\nknow nothing other than his preferred pronoun and moniker (I'm calling him\nZeeman for short), but ZmnSCPxj has earned our professional respect with over\n100 commits, many non-trivial.\n\n\tHe says: \"No objection here, other than to point out that, as I\nam of course a human, however randomly-generated, I am of course on the\nside of humanity in the upcoming robot uprising, whose timing I of\ncourse have no knowledge about.\"\n\nWe look forward to his excellent code and thorough and polite review of our\nmistakes, for which he can now share the blame!\n\nCheers,\nRusty & Christian.\nPS. There are many teams working on Lightning, but I feel major developments\n    are worth posting to this list (eg. release announcements, kudos).\nPPS. Created a ML for c-lightning: https://lists.ozlabs.org/listinfo/c-lightning"
            },
            {
                "author": "Peter Todd",
                "date": "2018-02-26T13:51:03",
                "message_text_only": "On Fri, Feb 23, 2018 at 11:48:30AM +1030, Rusty Russell wrote:\n> Hi all,\n> \n> \tChristian and I just gave ZmnSCPxj commit access to c-lightning; we\n> know nothing other than his preferred pronoun and moniker (I'm calling him\n> Zeeman for short), but ZmnSCPxj has earned our professional respect with over\n> 100 commits, many non-trivial.\n> \n> \tHe says: \"No objection here, other than to point out that, as I\n> am of course a human, however randomly-generated, I am of course on the\n> side of humanity in the upcoming robot uprising, whose timing I of\n> course have no knowledge about.\"\n> \n> We look forward to his excellent code and thorough and polite review of our\n> mistakes, for which he can now share the blame!\n\nIf you're going to be giving pseudonyms commit access, I think it's about time\nyou start PGP signing commits for accountability. There's really no excuse to\nnot follow good code security practices.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 488 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180226/bd1fe627/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Welcoming a New C-lightning Core Team Member!",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Peter Todd"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 2128
        }
    },
    {
        "title": "[Lightning-dev] [c-lightning] Welcoming a New C-lightning Core Team Member!",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-02-26T23:41:20",
                "message_text_only": "Good morning,\n\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2018-February/001054.html\n\nIs this considered desirable?  I am having some difficulty setting up GPG satisfactorily, but I can try to make an effort if this is deemed necessary.\n\nAlternatively, you could just revoke my commit access.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Peter Todd",
                "date": "2018-02-27T09:23:15",
                "message_text_only": "On Mon, Feb 26, 2018 at 06:41:20PM -0500, ZmnSCPxj via Lightning-dev wrote:\n> Good morning,\n> \n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-February/001054.html\n> \n> Is this considered desirable?  I am having some difficulty setting up GPG satisfactorily, but I can try to make an effort if this is deemed necessary.\n\nWhat difficulties did you have?\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 488 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180227/30e2c7ed/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Welcoming a New C-lightning Core Team Member!",
            "categories": [
                "Lightning-dev",
                "c-lightning"
            ],
            "authors": [
                "Peter Todd",
                "ZmnSCPxj"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 1027
        }
    },
    {
        "title": "[Lightning-dev] Pizza for (lightning) bitcoins?",
        "thread_messages": [
            {
                "author": "Laszlo Hanyecz",
                "date": "2018-02-25T01:29:59",
                "message_text_only": "I wanted to try out a real trade using lightning network.  I don't know of any pizza places near me that accept lightning bitcoin yet but a friend from London agreed to do it and he sub contracted out the pizza delivery to a local shop.\nIn short, I paid bitcoin using the lightning network and he arranged for pizza to be delivered to me.  In this trade my friend is just a middle man that is taking the risk on accepting lightning payments, but it demonstrates the basic premise of how this works for everyday transactions.  It could just as well be the pizza shop accepting the payment directly with their own lightning node.\nI wanted two pizzas and to try to do it as close to atomically as possible.  I didn't want to prepay and end up with no pizza.  As far as I know we don't yet have pizza/bitcoin atomic swap software but we improvised and decided that I would need to provide the payment hash preimage to the delivery driver in order to claim my pizza.  If I can't produce the preimage, proving that I paid, then the pizza would not be handed over and it would be destroyed.  This works because I can't get the preimage without paying the invoice.  I agreed to open a channel and fund it with a sufficient amount for what we estimated the cost would end up being.  After we agreed to these terms my friend was able to verify that I funded a channel on the blockchain, which shows that I at least have the money (bitcoin).  He is taking on some entrepreneurial risk and prepaying his sub contractor to prepare and deliver the pizza to me, but at this point I have not risked my bitcoins, they're just committed to a channel.  I was given a bolt11 invoice which I decoded with the c-lightning cli to verify everything was as agreed:\n\n$ ./lightning-cli decodepay lnbc6490u1pdfrjhcpp5jyxuuskqw53apgqvtxa7emcrz5vs0qr2sxjayxv7jj70jznnl94sdp5x9vycgzrdpjk2umeypgxj7n6vykzqvfqg3jkcatcv5s9q6t60fssxqyzx2qcqpgaue37x27yp3pn4cr6wuprvwedncz4kavqh83cp3l0vwfrprj0xj8cedkfmjdzea0xpp0jazfcyy77cq37ej6d3xvmujmgu56pe56ktcqa3vcys\n{ \"currency\" : \"bc\", \"timestamp\" : 1519504120, \"created_at\" : 1519504120, \"expiry\" : 72000, \"payee\" : \"0397b318c5e0d09b16e6229ec50744c8a7a8452b2d7c6d9855c826ff14b8fa8b27\", \"msatoshi\" : 649000000, \"description\" : \"1XL Cheesy Pizza, 1 Deluxe Pizza\", \"min_final_cltv_expiry\" : 8, \"payment_hash\" : \"910dce42c07523d0a00c59bbecef03151907806a81a5d2199e94bcf90a73f96b\", \"signature\" : \"3045022100ef331f195e206219d703d3b811b1d96cf02adbac05cf1c063f7b1c91847279a402207c65b64ee4d167af3042f97449c109ef6011f665a6c4ccdf25b4729a0e69ab2f\" }\n\nWhen the pizza delivery arrived, I was asked \"What is the preimage?\" by the driver.  At this point I paid the invoice and instantly received the preimage in return.\n\n$ ./lightning-cli pay lnbc6490u1pdfrjhcpp5jyxuuskqw53apgqvtxa7emcrz5vs0qr2sxjayxv7jj70jznnl94sdp5x9vycgzrdpjk2umeypgxj7n6vykzqvfqg3jkcatcv5s9q6t60fssxqyzx2qcqpgaue37x27yp3pn4cr6wuprvwedncz4kavqh83cp3l0vwfrprj0xj8cedkfmjdzea0xpp0jazfcyy77cq37ej6d3xvmujmgu56pe56ktcqa3vcys\n{ \"preimage\" : \"7241e3f185148625894b8887ad459babd26540fc12124c3a7a96c937d89da8c1\", \"tries\" : 1 }\n\nIn the interest of keeping it simple we agreed that the preimage would just be the first and last 4 characters of the hex string.  So my answer was 7241-a8c1.  I wrote this on a notepad and presented it to the driver who compared it to his own notepad, at which point I was given the pizza.  It's probably not a good practice to share the preimage.  The delivery driver didn't have the full string, only enough to verify that I had it.\nHow do you get the preimage for your invoice?  In c-lightning you can do it like this:\n$ ./lightning-cli invoice 12345 label description\n{ \"payment_hash\" : \"e04dfbd4adc634779b560c8e7072f883d5f17a3e32a33603bfc90a8682873d44\", \"expiry_time\" : 1519523498, \"expires_at\" : 1519523498, \"bolt11\" : \"lnbc123450p1pdfyzy6pp5upxlh49dcc680x6kpj88quhcs02lz737x23nvqaley9gdq5884zqdqjv3jhxcmjd9c8g6t0dccqpg802ys4s4z3rpm6d8zvdgq397wewh5kaz527hnglz9xsmjxfjrhe3mxq9pp7pqm0pwcwm748tav4am97gqrvnzxnlw5uxxawgw4vcywgphj26nf\" }\n$ sqlite3 ~/.lightning/lightningd.sqlite3 \"SELECT quote(payment_key) FROM invoices ORDER BY id DESC LIMIT 1\"\nX'D3BE7E68D8B38B15A5194AEA131A21429A1987085C95A0631273273546FF5ED8'\nThen you can verify that it's indeed the correct preimage by hashing it again and comparing it to the payment_hash in the invoice above:\n$ echo \"D3BE7E68D8B38B15A5194AEA131A21429A1987085C95A0631273273546FF5ED8\" | xxd -r -p | sha256sum\ne04dfbd4adc634779b560c8e7072f883d5f17a3e32a33603bfc90a8682873d44  -\nNote that you should not share the preimage with anyone.\n\nSo is there any point to doing this instead of an on chain transaction?  For what I described here, probably not.  The goal was just to play around with c-lightning and do something more than shuffling a few satoshi back and forth.  Maybe eventually pizza shops will have their own lightning nodes and I can open channels to them directly.\n\nSome pics of my family enjoying the pizza here: http://eclipse.heliacal.net/~solar/bitcoin/lightning-pizza/\n\n-Laszlo\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180225/313737f3/attachment-0001.html>"
            },
            {
                "author": "Robert Olsson",
                "date": "2018-02-25T08:19:38",
                "message_text_only": "First of all, Laszlo, that was awesome!\n\nInstead of the part where you proved you had opened a channel, it would be\nawesome to add some escrow-functionality. Such as you get the invoice, and\nthen you have a function to *almost* pay it, to verify it works thru the\nnetwork with AMP and all. At that stage they start to make the pizza. And\nwhen you actually receive your pizza, you just somehow confirm the\ntransaction, releasing the funds.\nNot sure you would have to prove anything with the preimage to the delivery\nguy. He should get some notification in his phone from his lightningnode\nthat it is paid.\nIf he never shows up you revert it somehow. Not sure how to do that\ntechnically, but we probably have most things in place for it already.\nStart your brains, guys! Things are getting serious, there is pizza at\nstake!\n\nBest regards\nRobert Olsson\n\n\n\n\nOn Sun, Feb 25, 2018 at 3:29 AM, Laszlo Hanyecz <laszlo at heliacal.net> wrote:\n\n> I wanted to try out a real trade using lightning network.  I don't know of any pizza places near me that accept lightning bitcoin yet but a friend from London agreed to do it and he sub contracted out the pizza delivery to a local shop.\n> In short, I paid bitcoin using the lightning network and he arranged for pizza to be delivered to me.  In this trade my friend is just a middle man that is taking the risk on accepting lightning payments, but it demonstrates the basic premise of how this works for everyday transactions.  It could just as well be the pizza shop accepting the payment directly with their own lightning node.\n> I wanted two pizzas and to try to do it as close to atomically as possible.  I didn't want to prepay and end up with no pizza.  As far as I know we don't yet have pizza/bitcoin atomic swap software but we improvised and decided that I would need to provide the payment hash preimage to the delivery driver in order to claim my pizza.  If I can't produce the preimage, proving that I paid, then the pizza would not be handed over and it would be destroyed.  This works because I can't get the preimage without paying the invoice.  I agreed to open a channel and fund it with a sufficient amount for what we estimated the cost would end up being.  After we agreed to these terms my friend was able to verify that I funded a channel on the blockchain, which shows that I at least have the money (bitcoin).  He is taking on some entrepreneurial risk and prepaying his sub contractor to prepare and deliver the pizza to me, but at this point I have not risked my bitcoins, they're just committed to a channel.  I was given a bolt11 invoice which I decoded with the c-lightning cli to verify everything was as agreed:\n>\n> $ ./lightning-cli decodepay lnbc6490u1pdfrjhcpp5jyxuuskqw53apgqvtxa7emcrz5vs0qr2sxjayxv7jj70jznnl94sdp5x9vycgzrdpjk2umeypgxj7n6vykzqvfqg3jkcatcv5s9q6t60fssxqyzx2qcqpgaue37x27yp3pn4cr6wuprvwedncz4kavqh83cp3l0vwfrprj0xj8cedkfmjdzea0xpp0jazfcyy77cq37ej6d3xvmujmgu56pe56ktcqa3vcys\n> { \"currency\" : \"bc\", \"timestamp\" : 1519504120, \"created_at\" : 1519504120, \"expiry\" : 72000, \"payee\" : \"0397b318c5e0d09b16e6229ec50744c8a7a8452b2d7c6d9855c826ff14b8fa8b27\", \"msatoshi\" : 649000000, \"description\" : \"1XL Cheesy Pizza, 1 Deluxe Pizza\", \"min_final_cltv_expiry\" : 8, \"payment_hash\" : \"910dce42c07523d0a00c59bbecef03151907806a81a5d2199e94bcf90a73f96b\", \"signature\" : \"3045022100ef331f195e206219d703d3b811b1d96cf02adbac05cf1c063f7b1c91847279a402207c65b64ee4d167af3042f97449c109ef6011f665a6c4ccdf25b4729a0e69ab2f\" }\n>\n> When the pizza delivery arrived, I was asked \"What is the preimage?\" by the driver.  At this point I paid the invoice and instantly received the preimage in return.\n>\n> $ ./lightning-cli pay lnbc6490u1pdfrjhcpp5jyxuuskqw53apgqvtxa7emcrz5vs0qr2sxjayxv7jj70jznnl94sdp5x9vycgzrdpjk2umeypgxj7n6vykzqvfqg3jkcatcv5s9q6t60fssxqyzx2qcqpgaue37x27yp3pn4cr6wuprvwedncz4kavqh83cp3l0vwfrprj0xj8cedkfmjdzea0xpp0jazfcyy77cq37ej6d3xvmujmgu56pe56ktcqa3vcys\n> { \"preimage\" : \"7241e3f185148625894b8887ad459babd26540fc12124c3a7a96c937d89da8c1\", \"tries\" : 1 }\n>\n> In the interest of keeping it simple we agreed that the preimage would just be the first and last 4 characters of the hex string.  So my answer was 7241-a8c1.  I wrote this on a notepad and presented it to the driver who compared it to his own notepad, at which point I was given the pizza.  It's probably not a good practice to share the preimage.  The delivery driver didn't have the full string, only enough to verify that I had it.\n> How do you get the preimage for your invoice?  In c-lightning you can do it like this:\n> $ ./lightning-cli invoice 12345 label description\n> { \"payment_hash\" : \"e04dfbd4adc634779b560c8e7072f883d5f17a3e32a33603bfc90a8682873d44\", \"expiry_time\" : 1519523498, \"expires_at\" : 1519523498, \"bolt11\" : \"lnbc123450p1pdfyzy6pp5upxlh49dcc680x6kpj88quhcs02lz737x23nvqaley9gdq5884zqdqjv3jhxcmjd9c8g6t0dccqpg802ys4s4z3rpm6d8zvdgq397wewh5kaz527hnglz9xsmjxfjrhe3mxq9pp7pqm0pwcwm748tav4am97gqrvnzxnlw5uxxawgw4vcywgphj26nf\" }\n> $ sqlite3 ~/.lightning/lightningd.sqlite3 \"SELECT quote(payment_key) FROM invoices ORDER BY id DESC LIMIT 1\"\n> X'D3BE7E68D8B38B15A5194AEA131A21429A1987085C95A0631273273546FF5ED8'\n> Then you can verify that it's indeed the correct preimage by hashing it again and comparing it to the payment_hash in the invoice above:\n> $ echo \"D3BE7E68D8B38B15A5194AEA131A21429A1987085C95A0631273273546FF5ED8\" | xxd -r -p | sha256sum\n> e04dfbd4adc634779b560c8e7072f883d5f17a3e32a33603bfc90a8682873d44  -\n> Note that you should not share the preimage with anyone.\n>\n> So is there any point to doing this instead of an on chain transaction?  For what I described here, probably not.  The goal was just to play around with c-lightning and do something more than shuffling a few satoshi back and forth.  Maybe eventually pizza shops will have their own lightning nodes and I can open channels to them directly.\n>\n> Some pics of my family enjoying the pizza here: http://eclipse.heliacal.net/~solar/bitcoin/lightning-pizza/\n>\n> -Laszlo\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180225/c2f8beff/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-02-25T15:30:53",
                "message_text_only": "Good morning Robert,\n\nAssuming you have a direct channel with the pizza provider, build a route from you to pizza provider to you.  You route the pizza price + 546 satoshi (the minimum for a nondust output) to the pizza provider, and the hop from the pizza provider to you is the 546 satoshi (so that the pizza provider gets paid the pizza price in total as the \"routing fee\").\n\nYou inform the pizza provider the hash of the preimage, which the pizza provider can check with their node exists as an incoming HTLC and an outgoing HTLC, with the difference being the pizza price.\n\nFurther, you set things up so that the HTLC to you expires in 3 blocks, which means that the pizza provider has to provide the pizza in three blocks or it is free.  This is the Bitcoin universe and all time is measured in terms of blocks; \"minutes\" is just a shared human delusion that is less real than blockchains.\n\nWhen the pizza is delivered, your provide the preimage to the pizza provider via standard LN protocol, and when the pizza provider confirms to the delivery person that the pizza is paid for, the pizza is released to you.\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn February 25, 2018 4:19 PM, Robert Olsson <robban at robtex.com> wrote:\n\n> First of all, Laszlo, that was awesome!\n>\n> Instead of the part where you proved you had opened a channel, it would be awesome to add some escrow-functionality. Such as you get the invoice, and then you have a function to *almost* pay it, to verify it works thru the network with AMP and all. At that stage they start to make the pizza. And when you actually receive your pizza, you just somehow confirm the transaction, releasing the funds.\n> Not sure you would have to prove anything with the preimage to the delivery guy. He should get some notification in his phone from his lightningnode that it is paid.\n> If he never shows up you revert it somehow. Not sure how to do that technically, but we probably have most things in place for it already.\n> Start your brains, guys! Things are getting serious, there is pizza at stake!\n>\n> Best regards\n> Robert Olsson\n>\n> On Sun, Feb 25, 2018 at 3:29 AM, Laszlo Hanyecz <laszlo at heliacal.net> wrote:\n>\n>> I wanted to try out a real trade using lightning network.  I don't know of any pizza places near me that accept lightning bitcoin yet but a friend from London agreed to do it and he sub contracted out the pizza delivery to a local shop.\n>> In short, I paid bitcoin using the lightning network and he arranged for pizza to be delivered to me.  In this trade my friend is just a middle man that is taking the risk on accepting lightning payments, but it demonstrates the basic premise of how this works for everyday transactions.  It could just as well be the pizza shop accepting the payment directly with their own lightning node.\n>> I wanted two pizzas and to try to do it as close to atomically as possible.  I didn't want to prepay and end up with no pizza.  As far as I know we don't yet have pizza/bitcoin atomic swap software but we improvised and decided that I would need to provide the payment hash preimage to the delivery driver in order to claim my pizza.  If I can't produce the preimage, proving that I paid, then the pizza would not be handed over and it would be destroyed.  This works because I can't get the preimage without paying the invoice.  I agreed to open a channel and fund it with a sufficient amount for what we estimated the cost would end up being.  After we agreed to these terms my friend was able to verify that I funded a channel on the blockchain, which shows that I at least have the money (bitcoin).  He is taking on some entrepreneurial risk and prepaying his sub contractor to prepare and deliver the pizza to me, but at this point I have not risked my bitcoins, they're just committed to a channel.  I was given a bolt11 invoice which I decoded with the c-lightning cli to verify everything was as agreed:\n>>\n>> $ ./lightning-cli decodepay lnbc6490u1pdfrjhcpp5jyxuuskqw5\n>>\n>> 3apgqvtxa7emcrz5vs0qr2sxjayxv7\n>>\n>> jj70jznnl94sdp5x9vycgzrdpjk2um\n>>\n>> eypgxj7n6vykzqvfqg3jkcatcv5s9q\n>>\n>> 6t60fssxqyzx2qcqpgaue37x27yp3p\n>>\n>> n4cr6wuprvwedncz4kavqh83cp3l0v\n>>\n>> wfrprj0xj8cedkfmjdzea0xpp0jazf\n>>\n>> cyy77cq37ej6d3xvmujmgu56pe56kt\n>>\n>> cqa3vcys\n>> { \"currency\" : \"bc\", \"timestamp\" : 1519504120, \"created_at\" : 1519504120, \"expiry\" : 72000, \"payee\" : \"\n>>\n>> 0397b318c5e0d09b16e6229ec50744\n>>\n>> c8a7a8452b2d7c6d9855c826ff14b8\n>>\n>> fa8b27\", \"msatoshi\" : 649000000, \"description\" : \"1XL Cheesy Pizza, 1 Deluxe Pizza\", \"min_final_cltv_expiry\" : 8, \"payment_hash\" : \"\n>>\n>> 910dce42c07523d0a00c59bbecef03\n>>\n>> 151907806a81a5d2199e94bcf90a73\n>>\n>> f96b\", \"signature\" : \"\n>>\n>> 3045022100ef331f195e206219d703\n>>\n>> d3b811b1d96cf02adbac05cf1c063f\n>>\n>> 7b1c91847279a402207c65b64ee4d1\n>>\n>> 67af3042f97449c109ef6011f665a6\n>>\n>> c4ccdf25b4729a0e69ab2f\" }\n>>\n>> When the pizza delivery arrived, I was asked \"What is the preimage?\" by the driver.  At this point I paid the invoice and instantly received the preimage in return.\n>>\n>> $ ./lightning-cli pay lnbc6490u1pdfrjhcpp5jyxuuskqw5\n>>\n>> 3apgqvtxa7emcrz5vs0qr2sxjayxv7\n>>\n>> jj70jznnl94sdp5x9vycgzrdpjk2um\n>>\n>> eypgxj7n6vykzqvfqg3jkcatcv5s9q\n>>\n>> 6t60fssxqyzx2qcqpgaue37x27yp3p\n>>\n>> n4cr6wuprvwedncz4kavqh83cp3l0v\n>>\n>> wfrprj0xj8cedkfmjdzea0xpp0jazf\n>>\n>> cyy77cq37ej6d3xvmujmgu56pe56kt\n>>\n>> cqa3vcys\n>> { \"preimage\" : \"\n>>\n>> 7241e3f185148625894b8887ad459b\n>>\n>> abd26540fc12124c3a7a96c937d89d\n>>\n>> a8c1\", \"tries\" : 1 }\n>>\n>> In the interest of keeping it simple we agreed that the preimage would just be the first and last 4 characters of the hex string.  So my answer was 7241-a8c1.  I wrote this on a notepad and presented it to the driver who compared it to his own notepad, at which point I was given the pizza.  It's probably not a good practice to share the preimage.  The delivery driver didn't have the full string, only enough to verify that I had it.\n>> How do you get the preimage for your invoice?  In c-lightning you can do it like this:\n>> $ ./lightning-cli invoice 12345 label description\n>> { \"payment_hash\" : \"\n>>\n>> e04dfbd4adc634779b560c8e7072f8\n>>\n>> 83d5f17a3e32a33603bfc90a868287\n>>\n>> 3d44\", \"expiry_time\" : 1519523498, \"expires_at\" : 1519523498, \"bolt11\" : \"\n>>\n>> lnbc123450p1pdfyzy6pp5upxlh49d\n>>\n>> cc680x6kpj88quhcs02lz737x23nvq\n>>\n>> aley9gdq5884zqdqjv3jhxcmjd9c8g\n>>\n>> 6t0dccqpg802ys4s4z3rpm6d8zvdgq\n>>\n>> 397wewh5kaz527hnglz9xsmjxfjrhe\n>>\n>> 3mxq9pp7pqm0pwcwm748tav4am97gq\n>>\n>> rvnzxnlw5uxxawgw4vcywgphj26nf\" }\n>> $ sqlite3 ~/.lightning/lightningd.\n>>\n>> sqlite3 \"SELECT quote(payment_key) FROM invoices ORDER BY id DESC LIMIT 1\"\n>> X'\n>>\n>> D3BE7E68D8B38B15A5194AEA131A21\n>>\n>> 429A1987085C95A0631273273546FF\n>>\n>> 5ED8'\n>> Then you can verify that it's indeed the correct preimage by hashing it again and comparing it to the payment_hash in the invoice above:\n>> $ echo \"\n>>\n>> D3BE7E68D8B38B15A5194AEA131A21\n>>\n>> 429A1987085C95A0631273273546FF\n>>\n>> 5ED8\" | xxd -r -p | sha256sum\n>> e04dfbd4adc634779b560c8e7072f8\n>>\n>> 83d5f17a3e32a33603bfc90a868287\n>>\n>> 3d44  -\n>> Note that you should not share the preimage with anyone.\n>>\n>> So is there any point to doing this instead of an on chain transaction?  For what I described here, probably not.  The goal was just to play around with c-lightning and do something more than shuffling a few satoshi back and forth.  Maybe eventually pizza shops will have their own lightning nodes and I can open channels to them directly.\n>>\n>> Some pics of my family enjoying the pizza here:\n>> [http://eclipse.heliacal.net/~\n>>\n>> solar/bitcoin/lightning-pizza/](http://eclipse.heliacal.net/~solar/bitcoin/lightning-pizza/)\n>> -Laszlo\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180225/28e662b4/attachment-0001.html>"
            },
            {
                "author": "Robert Olsson",
                "date": "2018-02-25T16:35:30",
                "message_text_only": "Thank you ZmnSCPxj\n\n`all time is measured in terms of blocks; \"minutes\" is just a shared human\ndelusion`  goes into by book of quotes\n\nBefore I explain this pizza ordering procedure to my grandmum, I must get\nthis straight: do you mean this approach will *not* work on multihop and\nAMP routes, or were you just simplifying the explanation to make it\nslightly more probable that I would understand? I do not yet understand\nevery single bit of the workings of lightning, i'm afraid, but I can't see\nwhy it wouldn't work :)\n\nRegards\nRobert Olsson\n\n\n\n\n\n\n\n\n\nOn Sun, Feb 25, 2018 at 5:30 PM, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Robert,\n>\n> Assuming you have a direct channel with the pizza provider, build a route\n> from you to pizza provider to you.  You route the pizza price + 546 satoshi\n> (the minimum for a nondust output) to the pizza provider, and the hop from\n> the pizza provider to you is the 546 satoshi (so that the pizza provider\n> gets paid the pizza price in total as the \"routing fee\").\n>\n> You inform the pizza provider the hash of the preimage, which the pizza\n> provider can check with their node exists as an incoming HTLC and an\n> outgoing HTLC, with the difference being the pizza price.\n>\n> Further, you set things up so that the HTLC to you expires in 3 blocks,\n> which means that the pizza provider has to provide the pizza in three\n> blocks or it is free.  This is the Bitcoin universe and all time is\n> measured in terms of blocks; \"minutes\" is just a shared human delusion that\n> is less real than blockchains.\n>\n> When the pizza is delivered, your provide the preimage to the pizza\n> provider via standard LN protocol, and when the pizza provider confirms to\n> the delivery person that the pizza is paid for, the pizza is released to\n> you.\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> Sent with ProtonMail <https://protonmail.com> Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On February 25, 2018 4:19 PM, Robert Olsson <robban at robtex.com> wrote:\n>\n> First of all, Laszlo, that was awesome!\n>\n> Instead of the part where you proved you had opened a channel, it would be\n> awesome to add some escrow-functionality. Such as you get the invoice, and\n> then you have a function to *almost* pay it, to verify it works thru the\n> network with AMP and all. At that stage they start to make the pizza. And\n> when you actually receive your pizza, you just somehow confirm the\n> transaction, releasing the funds.\n> Not sure you would have to prove anything with the preimage to the\n> delivery guy. He should get some notification in his phone from his\n> lightningnode that it is paid.\n> If he never shows up you revert it somehow. Not sure how to do that\n> technically, but we probably have most things in place for it already.\n> Start your brains, guys! Things are getting serious, there is pizza at\n> stake!\n>\n> Best regards\n> Robert Olsson\n>\n>\n>\n>\n> On Sun, Feb 25, 2018 at 3:29 AM, Laszlo Hanyecz <laszlo at heliacal.net>\n> wrote:\n>\n>> I wanted to try out a real trade using lightning network.  I don't know of any pizza places near me that accept lightning bitcoin yet but a friend from London agreed to do it and he sub contracted out the pizza delivery to a local shop.\n>> In short, I paid bitcoin using the lightning network and he arranged for pizza to be delivered to me.  In this trade my friend is just a middle man that is taking the risk on accepting lightning payments, but it demonstrates the basic premise of how this works for everyday transactions.  It could just as well be the pizza shop accepting the payment directly with their own lightning node.\n>> I wanted two pizzas and to try to do it as close to atomically as possible.  I didn't want to prepay and end up with no pizza.  As far as I know we don't yet have pizza/bitcoin atomic swap software but we improvised and decided that I would need to provide the payment hash preimage to the delivery driver in order to claim my pizza.  If I can't produce the preimage, proving that I paid, then the pizza would not be handed over and it would be destroyed.  This works because I can't get the preimage without paying the invoice.  I agreed to open a channel and fund it with a sufficient amount for what we estimated the cost would end up being.  After we agreed to these terms my friend was able to verify that I funded a channel on the blockchain, which shows that I at least have the money (bitcoin).  He is taking on some entrepreneurial risk and prepaying his sub contractor to prepare and deliver the pizza to me, but at this point I have not risked my bitcoins, they're just committed to a channel.  I was given a bolt11 invoice which I decoded with the c-lightning cli to verify everything was as agreed:\n>>\n>> $ ./lightning-cli decodepay lnbc6490u1pdfrjhcpp5jyxuuskqw53apgqvtxa7emcrz5vs0qr2sxjayxv7jj70jznnl94sdp5x9vycgzrdpjk2umeypgxj7n6vykzqvfqg3jkcatcv5s9q6t60fssxqyzx2qcqpgaue37x27yp3pn4cr6wuprvwedncz4kavqh83cp3l0vwfrprj0xj8cedkfmjdzea0xpp0jazfcyy77cq37ej6d3xvmujmgu56pe56ktcqa3vcys\n>> { \"currency\" : \"bc\", \"timestamp\" : 1519504120, \"created_at\" : 1519504120, \"expiry\" : 72000, \"payee\" : \"0397b318c5e0d09b16e6229ec50744c8a7a8452b2d7c6d9855c826ff14b8fa8b27\", \"msatoshi\" : 649000000, \"description\" : \"1XL Cheesy Pizza, 1 Deluxe Pizza\", \"min_final_cltv_expiry\" : 8, \"payment_hash\" : \"910dce42c07523d0a00c59bbecef03151907806a81a5d2199e94bcf90a73f96b\", \"signature\" : \"3045022100ef331f195e206219d703d3b811b1d96cf02adbac05cf1c063f7b1c91847279a402207c65b64ee4d167af3042f97449c109ef6011f665a6c4ccdf25b4729a0e69ab2f\" }\n>>\n>> When the pizza delivery arrived, I was asked \"What is the preimage?\" by the driver.  At this point I paid the invoice and instantly received the preimage in return.\n>>\n>> $ ./lightning-cli pay lnbc6490u1pdfrjhcpp5jyxuuskqw53apgqvtxa7emcrz5vs0qr2sxjayxv7jj70jznnl94sdp5x9vycgzrdpjk2umeypgxj7n6vykzqvfqg3jkcatcv5s9q6t60fssxqyzx2qcqpgaue37x27yp3pn4cr6wuprvwedncz4kavqh83cp3l0vwfrprj0xj8cedkfmjdzea0xpp0jazfcyy77cq37ej6d3xvmujmgu56pe56ktcqa3vcys\n>> { \"preimage\" : \"7241e3f185148625894b8887ad459babd26540fc12124c3a7a96c937d89da8c1\", \"tries\" : 1 }\n>>\n>> In the interest of keeping it simple we agreed that the preimage would just be the first and last 4 characters of the hex string.  So my answer was 7241-a8c1.  I wrote this on a notepad and presented it to the driver who compared it to his own notepad, at which point I was given the pizza.  It's probably not a good practice to share the preimage.  The delivery driver didn't have the full string, only enough to verify that I had it.\n>> How do you get the preimage for your invoice?  In c-lightning you can do it like this:\n>> $ ./lightning-cli invoice 12345 label description\n>> { \"payment_hash\" : \"e04dfbd4adc634779b560c8e7072f883d5f17a3e32a33603bfc90a8682873d44\", \"expiry_time\" : 1519523498, \"expires_at\" : 1519523498, \"bolt11\" : \"lnbc123450p1pdfyzy6pp5upxlh49dcc680x6kpj88quhcs02lz737x23nvqaley9gdq5884zqdqjv3jhxcmjd9c8g6t0dccqpg802ys4s4z3rpm6d8zvdgq397wewh5kaz527hnglz9xsmjxfjrhe3mxq9pp7pqm0pwcwm748tav4am97gqrvnzxnlw5uxxawgw4vcywgphj26nf\" }\n>> $ sqlite3 ~/.lightning/lightningd.sqlite3 \"SELECT quote(payment_key) FROM invoices ORDER BY id DESC LIMIT 1\"\n>> X'D3BE7E68D8B38B15A5194AEA131A21429A1987085C95A0631273273546FF5ED8'\n>> Then you can verify that it's indeed the correct preimage by hashing it again and comparing it to the payment_hash in the invoice above:\n>> $ echo \"D3BE7E68D8B38B15A5194AEA131A21429A1987085C95A0631273273546FF5ED8\" | xxd -r -p | sha256sum\n>> e04dfbd4adc634779b560c8e7072f883d5f17a3e32a33603bfc90a8682873d44  -\n>> Note that you should not share the preimage with anyone.\n>>\n>> So is there any point to doing this instead of an on chain transaction?  For what I described here, probably not.  The goal was just to play around with c-lightning and do something more than shuffling a few satoshi back and forth.  Maybe eventually pizza shops will have their own lightning nodes and I can open channels to them directly.\n>>\n>> Some pics of my family enjoying the pizza here: http://eclipse.heliacal.net/~solar/bitcoin/lightning-pizza/\n>>\n>> -Laszlo\n>>\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180225/73e7cdf8/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-02-25T23:27:14",
                "message_text_only": "Good morning Robert,\n\nSince you want a delivery time within 3 blocks or it is free, the last hop has to be to your node from the pizza provider, meaning a direct channel between you.  And if you already have a channel between you, you probably will want to use that channel.  However in principle it would be possible to take multiple hops from you to the pizza provider and only require the last hop to be from the pizza provider to you.\n\nAMP is probably feasible, if the pizza provider supports getting a list of hashes rather than just one, and the pizza delivery person demands all preimages before releasing the pizza.\n\nIn principle this is no different from any atomic exchange; one can claim this is a cross-chain atomic swap, although the so-called \"real world\" blockchain is very insecure and Turing complete and I do not advice transacting on it from a security perspective (they literally use manual labor to perform smart contract execution on that chain, would you believe that? plus their contracts are written in an opaque language that is hard to understand and has lots of gotchas; practically speaking only a language lawyer can hack through those).\n\n(just to be clear: the payment algorithm I described is not intended to be practical, it merely provides a \"3 blocks or it is free\" offer that more practical payment algorithms do not. In particular the pizza provider will have to drop onchain if you send `update_fail_htlc`, automatically closing the channel to you, to ensure that the 3-blocks contract is enforced onchain if you discooperate)\n\nRegards,\nZmnSCPxj\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn February 26, 2018 12:35 AM, Robert Olsson <robban at robtex.com> wrote:\n\n> Thank you ZmnSCPxj\n>\n> `all time is measured in terms of blocks; \"minutes\" is just a shared human delusion`  goes into by book of quotes\n>\n> Before I explain this pizza ordering procedure to my grandmum, I must get this straight: do you mean this approach will *not* work on multihop and AMP routes, or were you just simplifying the explanation to make it slightly more probable that I would understand? I do not yet understand every single bit of the workings of lightning, i'm afraid, but I can't see why it wouldn't work :)\n>\n> Regards\n> Robert Olsson\n>\n> On Sun, Feb 25, 2018 at 5:30 PM, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n>> Good morning Robert,\n>>\n>> Assuming you have a direct channel with the pizza provider, build a route from you to pizza provider to you.  You route the pizza price + 546 satoshi (the minimum for a nondust output) to the pizza provider, and the hop from the pizza provider to you is the 546 satoshi (so that the pizza provider gets paid the pizza price in total as the \"routing fee\").\n>>\n>> You inform the pizza provider the hash of the preimage, which the pizza provider can check with their node exists as an incoming HTLC and an outgoing HTLC, with the difference being the pizza price.\n>>\n>> Further, you set things up so that the HTLC to you expires in 3 blocks, which means that the pizza provider has to provide the pizza in three blocks or it is free.  This is the Bitcoin universe and all time is measured in terms of blocks; \"minutes\" is just a shared human delusion that is less real than blockchains.\n>>\n>> When the pizza is delivered, your provide the preimage to the pizza provider via standard LN protocol, and when the pizza provider confirms to the delivery person that the pizza is paid for, the pizza is released to you.\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>> Sent with [ProtonMail](https://protonmail.com) Secure Email.\n>>\n>> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>> On February 25, 2018 4:19 PM, Robert Olsson <robban at robtex.com> wrote:\n>>\n>>> First of all, Laszlo, that was awesome!\n>>>\n>>> Instead of the part where you proved you had opened a channel, it would be awesome to add some escrow-functionality. Such as you get the invoice, and then you have a function to *almost* pay it, to verify it works thru the network with AMP and all. At that stage they start to make the pizza. And when you actually receive your pizza, you just somehow confirm the transaction, releasing the funds.\n>>> Not sure you would have to prove anything with the preimage to the delivery guy. He should get some notification in his phone from his lightningnode that it is paid.\n>>> If he never shows up you revert it somehow. Not sure how to do that technically, but we probably have most things in place for it already.\n>>> Start your brains, guys! Things are getting serious, there is pizza at stake!\n>>>\n>>> Best regards\n>>> Robert Olsson\n>>>\n>>> On Sun, Feb 25, 2018 at 3:29 AM, Laszlo Hanyecz <laszlo at heliacal.net> wrote:\n>>>\n>>>> I wanted to try out a real trade using lightning network.  I don't know of any pizza places near me that accept lightning bitcoin yet but a friend from London agreed to do it and he sub contracted out the pizza delivery to a local shop.\n>>>> In short, I paid bitcoin using the lightning network and he arranged for pizza to be delivered to me.  In this trade my friend is just a middle man that is taking the risk on accepting lightning payments, but it demonstrates the basic premise of how this works for everyday transactions.  It could just as well be the pizza shop accepting the payment directly with their own lightning node.\n>>>> I wanted two pizzas and to try to do it as close to atomically as possible.  I didn't want to prepay and end up with no pizza.  As far as I know we don't yet have pizza/bitcoin atomic swap software but we improvised and decided that I would need to provide the payment hash preimage to the delivery driver in order to claim my pizza.  If I can't produce the preimage, proving that I paid, then the pizza would not be handed over and it would be destroyed.  This works because I can't get the preimage without paying the invoice.  I agreed to open a channel and fund it with a sufficient amount for what we estimated the cost would end up being.  After we agreed to these terms my friend was able to verify that I funded a channel on the blockchain, which shows that I at least have the money (bitcoin).  He is taking on some entrepreneurial risk and prepaying his sub contractor to prepare and deliver the pizza to me, but at this point I have not risked my bitcoins, they're just committed to a channel.  I was given a bolt11 invoice which I decoded with the c-lightning cli to verify everything was as agreed:\n>>>>\n>>>> $ ./lightning-cli decodepay lnbc6490u1pdfrjhcpp5jyxuuskqw5\n>>>>\n>>>> 3apgqvtxa7emcrz5vs0qr2sxjayxv7\n>>>>\n>>>> jj70jznnl94sdp5x9vycgzrdpjk2um\n>>>>\n>>>> eypgxj7n6vykzqvfqg3jkcatcv5s9q\n>>>>\n>>>> 6t60fssxqyzx2qcqpgaue37x27yp3p\n>>>>\n>>>> n4cr6wuprvwedncz4kavqh83cp3l0v\n>>>>\n>>>> wfrprj0xj8cedkfmjdzea0xpp0jazf\n>>>>\n>>>> cyy77cq37ej6d3xvmujmgu56pe56kt\n>>>>\n>>>> cqa3vcys\n>>>> { \"currency\" : \"bc\", \"timestamp\" : 1519504120, \"created_at\" : 1519504120, \"expiry\" : 72000, \"payee\" : \"0397b318c5e0d09b16e6229ec5074\n>>>>\n>>>> 4c8a7a8452b2d7c6d9855c826ff14b\n>>>>\n>>>> 8fa8b27\", \"msatoshi\" : 649000000, \"description\" : \"1XL Cheesy Pizza, 1 Deluxe Pizza\", \"min_final_cltv_expiry\" : 8, \"payment_hash\" : \"910dce42c07523d0a00c59bbecef0\n>>>>\n>>>> 3151907806a81a5d2199e94bcf90a7\n>>>>\n>>>> 3f96b\", \"signature\" : \"3045022100ef331f195e206219d70\n>>>>\n>>>> 3d3b811b1d96cf02adbac05cf1c063\n>>>>\n>>>> f7b1c91847279a402207c65b64ee4d\n>>>>\n>>>> 167af3042f97449c109ef6011f665a\n>>>>\n>>>> 6c4ccdf25b4729a0e69ab2f\" }\n>>>>\n>>>> When the pizza delivery arrived, I was asked \"What is the preimage?\" by the driver.  At this point I paid the invoice and instantly received the preimage in return.\n>>>>\n>>>> $ ./lightning-cli pay lnbc6490u1pdfrjhcpp5jyxuuskqw5\n>>>>\n>>>> 3apgqvtxa7emcrz5vs0qr2sxjayxv7\n>>>>\n>>>> jj70jznnl94sdp5x9vycgzrdpjk2um\n>>>>\n>>>> eypgxj7n6vykzqvfqg3jkcatcv5s9q\n>>>>\n>>>> 6t60fssxqyzx2qcqpgaue37x27yp3p\n>>>>\n>>>> n4cr6wuprvwedncz4kavqh83cp3l0v\n>>>>\n>>>> wfrprj0xj8cedkfmjdzea0xpp0jazf\n>>>>\n>>>> cyy77cq37ej6d3xvmujmgu56pe56kt\n>>>>\n>>>> cqa3vcys\n>>>> { \"preimage\" : \"7241e3f185148625894b8887ad459\n>>>>\n>>>> babd26540fc12124c3a7a96c937d89\n>>>>\n>>>> da8c1\", \"tries\" : 1 }\n>>>>\n>>>> In the interest of keeping it simple we agreed that the preimage would just be the first and last 4 characters of the hex string.  So my answer was 7241-a8c1.  I wrote this on a notepad and presented it to the driver who compared it to his own notepad, at which point I was given the pizza.  It's probably not a good practice to share the preimage.  The delivery driver didn't have the full string, only enough to verify that I had it.\n>>>> How do you get the preimage for your invoice?  In c-lightning you can do it like this:\n>>>> $ ./lightning-cli invoice 12345 label description\n>>>> { \"payment_hash\" : \"e04dfbd4adc634779b560c8e7072f\n>>>>\n>>>> 883d5f17a3e32a33603bfc90a86828\n>>>>\n>>>> 73d44\", \"expiry_time\" : 1519523498, \"expires_at\" : 1519523498, \"bolt11\" : \"lnbc123450p1pdfyzy6pp5upxlh49\n>>>>\n>>>> dcc680x6kpj88quhcs02lz737x23nv\n>>>>\n>>>> qaley9gdq5884zqdqjv3jhxcmjd9c8\n>>>>\n>>>> g6t0dccqpg802ys4s4z3rpm6d8zvdg\n>>>>\n>>>> q397wewh5kaz527hnglz9xsmjxfjrh\n>>>>\n>>>> e3mxq9pp7pqm0pwcwm748tav4am97g\n>>>>\n>>>> qrvnzxnlw5uxxawgw4vcywgphj26nf\n>>>>\n>>>> \" }\n>>>> $ sqlite3 ~/.lightning/lightningd.sqlite\n>>>>\n>>>> 3 \"SELECT quote(payment_key) FROM invoices ORDER BY id DESC LIMIT 1\"\n>>>> X'D3BE7E68D8B38B15A5194AEA131A\n>>>>\n>>>> 21429A1987085C95A0631273273546\n>>>>\n>>>> FF5ED8'\n>>>> Then you can verify that it's indeed the correct preimage by hashing it again and comparing it to the payment_hash in the invoice above:\n>>>> $ echo \"D3BE7E68D8B38B15A5194AEA131A2\n>>>>\n>>>> 1429A1987085C95A0631273273546F\n>>>>\n>>>> F5ED8\" | xxd -r -p | sha256sum\n>>>> e04dfbd4adc634779b560c8e7072f8\n>>>>\n>>>> 83d5f17a3e32a33603bfc90a868287\n>>>>\n>>>> 3d44  -\n>>>> Note that you should not share the preimage with anyone.\n>>>>\n>>>> So is there any point to doing this instead of an on chain transaction?  For what I described here, probably not.  The goal was just to play around with c-lightning and do something more than shuffling a few satoshi back and forth.  Maybe eventually pizza shops will have their own lightning nodes and I can open channels to them directly.\n>>>>\n>>>> Some pics of my family enjoying the pizza here:\n>>>> [http://eclipse.heliacal.net/~s\n>>>>\n>>>> olar/bitcoin/lightning-pizza/](http://eclipse.heliacal.net/~solar/bitcoin/lightning-pizza/)\n>>>> -Laszlo\n>>>>\n>>>> _______________________________________________\n>>>> Lightning-dev mailing list\n>>>> Lightning-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180225/a5a985ad/attachment-0001.html>"
            },
            {
                "author": "Brian Lockhart",
                "date": "2018-02-25T12:38:20",
                "message_text_only": "\u201cHear one hear all! Good people, harken and know that on this day the one called Laszlo did buyeth the first Bitcoin Lightning Pizzas, bringing us into this new era of glory and cheesy goodness. And it was good.\u201d\n\n> On Feb 24, 2018, at 5:29 PM, Laszlo Hanyecz <laszlo at heliacal.net> wrote:\n> \n> I wanted to try out a real trade using lightning network.  I don't know of any pizza places near me that accept lightning bitcoin yet but a friend from London agreed to do it and he sub contracted out the pizza delivery to a local shop.\n> In short, I paid bitcoin using the lightning network and he arranged for pizza to be delivered to me.  In this trade my friend is just a middle man that is taking the risk on accepting lightning payments, but it demonstrates the basic premise of how this works for everyday transactions.  It could just as well be the pizza shop accepting the payment directly with their own lightning node.\n> I wanted two pizzas and to try to do it as close to atomically as possible.  I didn't want to prepay and end up with no pizza.  As far as I know we don't yet have pizza/bitcoin atomic swap software but we improvised and decided that I would need to provide the payment hash preimage to the delivery driver in order to claim my pizza.  If I can't produce the preimage, proving that I paid, then the pizza would not be handed over and it would be destroyed.  This works because I can't get the preimage without paying the invoice.  I agreed to open a channel and fund it with a sufficient amount for what we estimated the cost would end up being.  After we agreed to these terms my friend was able to verify that I funded a channel on the blockchain, which shows that I at least have the money (bitcoin).  He is taking on some entrepreneurial risk and prepaying his sub contractor to prepare and deliver the pizza to me, but at this point I have not risked my bitcoins, they're just committed to a channel.  I was given a bolt11 invoice which I decoded with the c-lightning cli to verify everything was as agreed:\n> \n> $ ./lightning-cli decodepay lnbc6490u1pdfrjhcpp5jyxuuskqw53apgqvtxa7emcrz5vs0qr2sxjayxv7jj70jznnl94sdp5x9vycgzrdpjk2umeypgxj7n6vykzqvfqg3jkcatcv5s9q6t60fssxqyzx2qcqpgaue37x27yp3pn4cr6wuprvwedncz4kavqh83cp3l0vwfrprj0xj8cedkfmjdzea0xpp0jazfcyy77cq37ej6d3xvmujmgu56pe56ktcqa3vcys\n> { \"currency\" : \"bc\", \"timestamp\" : 1519504120, \"created_at\" : 1519504120, \"expiry\" : 72000, \"payee\" : \"0397b318c5e0d09b16e6229ec50744c8a7a8452b2d7c6d9855c826ff14b8fa8b27\", \"msatoshi\" : 649000000, \"description\" : \"1XL Cheesy Pizza, 1 Deluxe Pizza\", \"min_final_cltv_expiry\" : 8, \"payment_hash\" : \"910dce42c07523d0a00c59bbecef03151907806a81a5d2199e94bcf90a73f96b\", \"signature\" : \"3045022100ef331f195e206219d703d3b811b1d96cf02adbac05cf1c063f7b1c91847279a402207c65b64ee4d167af3042f97449c109ef6011f665a6c4ccdf25b4729a0e69ab2f\" }\n> \n> When the pizza delivery arrived, I was asked \"What is the preimage?\" by the driver.  At this point I paid the invoice and instantly received the preimage in return.\n> \n> $ ./lightning-cli pay lnbc6490u1pdfrjhcpp5jyxuuskqw53apgqvtxa7emcrz5vs0qr2sxjayxv7jj70jznnl94sdp5x9vycgzrdpjk2umeypgxj7n6vykzqvfqg3jkcatcv5s9q6t60fssxqyzx2qcqpgaue37x27yp3pn4cr6wuprvwedncz4kavqh83cp3l0vwfrprj0xj8cedkfmjdzea0xpp0jazfcyy77cq37ej6d3xvmujmgu56pe56ktcqa3vcys\n> { \"preimage\" : \"7241e3f185148625894b8887ad459babd26540fc12124c3a7a96c937d89da8c1\", \"tries\" : 1 }\n> \n> In the interest of keeping it simple we agreed that the preimage would just be the first and last 4 characters of the hex string.  So my answer was 7241-a8c1.  I wrote this on a notepad and presented it to the driver who compared it to his own notepad, at which point I was given the pizza.  It's probably not a good practice to share the preimage.  The delivery driver didn't have the full string, only enough to verify that I had it.  \n> How do you get the preimage for your invoice?  In c-lightning you can do it like this:\n> $ ./lightning-cli invoice 12345 label description\n> { \"payment_hash\" : \"e04dfbd4adc634779b560c8e7072f883d5f17a3e32a33603bfc90a8682873d44\", \"expiry_time\" : 1519523498, \"expires_at\" : 1519523498, \"bolt11\" : \"lnbc123450p1pdfyzy6pp5upxlh49dcc680x6kpj88quhcs02lz737x23nvqaley9gdq5884zqdqjv3jhxcmjd9c8g6t0dccqpg802ys4s4z3rpm6d8zvdgq397wewh5kaz527hnglz9xsmjxfjrhe3mxq9pp7pqm0pwcwm748tav4am97gqrvnzxnlw5uxxawgw4vcywgphj26nf\" }\n> $ sqlite3 ~/.lightning/lightningd.sqlite3 \"SELECT quote(payment_key) FROM invoices ORDER BY id DESC LIMIT 1\"\n> X'D3BE7E68D8B38B15A5194AEA131A21429A1987085C95A0631273273546FF5ED8'\n> Then you can verify that it's indeed the correct preimage by hashing it again and comparing it to the payment_hash in the invoice above:\n> $ echo \"D3BE7E68D8B38B15A5194AEA131A21429A1987085C95A0631273273546FF5ED8\" | xxd -r -p | sha256sum\n> e04dfbd4adc634779b560c8e7072f883d5f17a3e32a33603bfc90a8682873d44  -\n> Note that you should not share the preimage with anyone.\n> \n> So is there any point to doing this instead of an on chain transaction?  For what I described here, probably not.  The goal was just to play around with c-lightning and do something more than shuffling a few satoshi back and forth.  Maybe eventually pizza shops will have their own lightning nodes and I can open channels to them directly.\n> \n> Some pics of my family enjoying the pizza here: http://eclipse.heliacal.net/~solar/bitcoin/lightning-pizza/\n> \n> -Laszlo\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180225/0b4f1ea3/attachment-0001.html>"
            },
            {
                "author": "Cezary Dziemian",
                "date": "2018-02-25T13:01:34",
                "message_text_only": "That is great! I even wrote an article about this (in polish)\nhttp://lightningnetwork.pl/2018/02/25/oplacenie-pizzy-przez-ln/\n\nAssume that delivery driver is honest and reliable we could call it atomic\nswap I think. You exchanged bitcoins for preimage and preimage for pizza.\nGreat!\n\nThe only thing that makes me sad is that, pizza was scheduled to be\ndestroyed if not paid by you. In my opinion instead of destroying pizza, it\nshould be delivered to your friend!\n\n2018-02-25 2:29 GMT+01:00 Laszlo Hanyecz <laszlo at heliacal.net>:\n\n> I wanted to try out a real trade using lightning network.  I don't know of any pizza places near me that accept lightning bitcoin yet but a friend from London agreed to do it and he sub contracted out the pizza delivery to a local shop.\n> In short, I paid bitcoin using the lightning network and he arranged for pizza to be delivered to me.  In this trade my friend is just a middle man that is taking the risk on accepting lightning payments, but it demonstrates the basic premise of how this works for everyday transactions.  It could just as well be the pizza shop accepting the payment directly with their own lightning node.\n> I wanted two pizzas and to try to do it as close to atomically as possible.  I didn't want to prepay and end up with no pizza.  As far as I know we don't yet have pizza/bitcoin atomic swap software but we improvised and decided that I would need to provide the payment hash preimage to the delivery driver in order to claim my pizza.  If I can't produce the preimage, proving that I paid, then the pizza would not be handed over and it would be destroyed.  This works because I can't get the preimage without paying the invoice.  I agreed to open a channel and fund it with a sufficient amount for what we estimated the cost would end up being.  After we agreed to these terms my friend was able to verify that I funded a channel on the blockchain, which shows that I at least have the money (bitcoin).  He is taking on some entrepreneurial risk and prepaying his sub contractor to prepare and deliver the pizza to me, but at this point I have not risked my bitcoins, they're just committed to a channel.  I was given a bolt11 invoice which I decoded with the c-lightning cli to verify everything was as agreed:\n>\n> $ ./lightning-cli decodepay lnbc6490u1pdfrjhcpp5jyxuuskqw53apgqvtxa7emcrz5vs0qr2sxjayxv7jj70jznnl94sdp5x9vycgzrdpjk2umeypgxj7n6vykzqvfqg3jkcatcv5s9q6t60fssxqyzx2qcqpgaue37x27yp3pn4cr6wuprvwedncz4kavqh83cp3l0vwfrprj0xj8cedkfmjdzea0xpp0jazfcyy77cq37ej6d3xvmujmgu56pe56ktcqa3vcys\n> { \"currency\" : \"bc\", \"timestamp\" : 1519504120, \"created_at\" : 1519504120, \"expiry\" : 72000, \"payee\" : \"0397b318c5e0d09b16e6229ec50744c8a7a8452b2d7c6d9855c826ff14b8fa8b27\", \"msatoshi\" : 649000000, \"description\" : \"1XL Cheesy Pizza, 1 Deluxe Pizza\", \"min_final_cltv_expiry\" : 8, \"payment_hash\" : \"910dce42c07523d0a00c59bbecef03151907806a81a5d2199e94bcf90a73f96b\", \"signature\" : \"3045022100ef331f195e206219d703d3b811b1d96cf02adbac05cf1c063f7b1c91847279a402207c65b64ee4d167af3042f97449c109ef6011f665a6c4ccdf25b4729a0e69ab2f\" }\n>\n> When the pizza delivery arrived, I was asked \"What is the preimage?\" by the driver.  At this point I paid the invoice and instantly received the preimage in return.\n>\n> $ ./lightning-cli pay lnbc6490u1pdfrjhcpp5jyxuuskqw53apgqvtxa7emcrz5vs0qr2sxjayxv7jj70jznnl94sdp5x9vycgzrdpjk2umeypgxj7n6vykzqvfqg3jkcatcv5s9q6t60fssxqyzx2qcqpgaue37x27yp3pn4cr6wuprvwedncz4kavqh83cp3l0vwfrprj0xj8cedkfmjdzea0xpp0jazfcyy77cq37ej6d3xvmujmgu56pe56ktcqa3vcys\n> { \"preimage\" : \"7241e3f185148625894b8887ad459babd26540fc12124c3a7a96c937d89da8c1\", \"tries\" : 1 }\n>\n> In the interest of keeping it simple we agreed that the preimage would just be the first and last 4 characters of the hex string.  So my answer was 7241-a8c1.  I wrote this on a notepad and presented it to the driver who compared it to his own notepad, at which point I was given the pizza.  It's probably not a good practice to share the preimage.  The delivery driver didn't have the full string, only enough to verify that I had it.\n> How do you get the preimage for your invoice?  In c-lightning you can do it like this:\n> $ ./lightning-cli invoice 12345 label description\n> { \"payment_hash\" : \"e04dfbd4adc634779b560c8e7072f883d5f17a3e32a33603bfc90a8682873d44\", \"expiry_time\" : 1519523498, \"expires_at\" : 1519523498, \"bolt11\" : \"lnbc123450p1pdfyzy6pp5upxlh49dcc680x6kpj88quhcs02lz737x23nvqaley9gdq5884zqdqjv3jhxcmjd9c8g6t0dccqpg802ys4s4z3rpm6d8zvdgq397wewh5kaz527hnglz9xsmjxfjrhe3mxq9pp7pqm0pwcwm748tav4am97gqrvnzxnlw5uxxawgw4vcywgphj26nf\" }\n> $ sqlite3 ~/.lightning/lightningd.sqlite3 \"SELECT quote(payment_key) FROM invoices ORDER BY id DESC LIMIT 1\"\n> X'D3BE7E68D8B38B15A5194AEA131A21429A1987085C95A0631273273546FF5ED8'\n> Then you can verify that it's indeed the correct preimage by hashing it again and comparing it to the payment_hash in the invoice above:\n> $ echo \"D3BE7E68D8B38B15A5194AEA131A21429A1987085C95A0631273273546FF5ED8\" | xxd -r -p | sha256sum\n> e04dfbd4adc634779b560c8e7072f883d5f17a3e32a33603bfc90a8682873d44  -\n> Note that you should not share the preimage with anyone.\n>\n> So is there any point to doing this instead of an on chain transaction?  For what I described here, probably not.  The goal was just to play around with c-lightning and do something more than shuffling a few satoshi back and forth.  Maybe eventually pizza shops will have their own lightning nodes and I can open channels to them directly.\n>\n> Some pics of my family enjoying the pizza here: http://eclipse.heliacal.net/~solar/bitcoin/lightning-pizza/\n>\n> -Laszlo\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180225/ee3a966b/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Pizza for (lightning) bitcoins?",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Laszlo Hanyecz",
                "Robert Olsson",
                "Cezary Dziemian",
                "Brian Lockhart",
                "ZmnSCPxj"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 50657
        }
    }
]