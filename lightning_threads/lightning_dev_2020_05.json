[
    {
        "title": "[Lightning-dev] [c-lightning] v0.8.2 Scaling the Ethereum Blockchain",
        "thread_messages": [
            {
                "author": "lisa neigut",
                "date": "2020-05-01T00:25:37",
                "message_text_only": "We're pleased to announce the 0.8.2 release of c-lightning, named by\n@arowser <https://github.com/arowser>.\n\nThis is a minor release and includes a few new and experimental features,\nas well as bug-fixes and performance wins.\nHighlights for Users\n\n   - New config option --large-channels (also known as 'wumbo') which\n   enables opening channels of any size. (Note that your peer must also\n   support large channels.)\n   - This release includes a keysend plugin, which will enable receiving\n   'keysend' payments, as first introduced by Lightning Labs\n   <https://github.com/lightningnetwork/lnd/pull/3795>. Note that the\n   included keysend plugin is receive only for this release. Nodes which do\n   not want the hassle of spontaneous unrequested payments should add\n   'disable-plugin=keysend' to their config!\n   - We'll now announce multiple connection endpoints for a single 'type',\n   e.g. multiple IPv4 addresses.\n   - A new FAQ\n   <https://github.com/ElementsProject/lightning/blob/master/doc/FAQ.md>!\n   - Big performance improvment in the pay command (~1s speedup on average)\n\nHighlights for the Network\n\n   - c-lightning nodes can now participate in creating larger channels\n   (with the --large-channel config option).\n   - We now wait until the first payment through a channel before updating\n   the feerate; this should help with some spurious closures at channel open\n   or re-connect that were occurring against older versions of other\n   implementations.\n\nHighlights for Developers\n\n   - A new command getsharedsecret for getting the BOLT-compliant shared\n   secret finding for a node and a point.\n   - The API for the 'Bitcoin backend' plugin infrastructure has been\n   documented!\n   - Facilities for building rendez-vous compatible onions has been added\n   to the onion devtool\n   - Plugin options will now respect the type they were given in the\n   manifest.\n   - Fixes with plugin cleanups and hangs.\n   - Python2 has been removed as a dependence.\n\nMore details can be found at\nhttps://github.com/ElementsProject/lightning/blob/v0.8.2/CHANGELOG.md\n\nThanks to everyone for their contributions and bug reports; please keep\nthem coming.\n\nSince 0.8.1, we've had 236 commits from 10 different authors, with 2 first\ntime contributors:\n\n   - Dr. Maxim Orlovsky @dr-orlovsky <https://github.com/dr-orlovsky>\n   - Dave Scotese @dscotese <https://github.com/dscotese>\n\nCheers,\n\nLisa, Christian, Rusty, and ZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200430/d91e2979/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "v0.8.2 Scaling the Ethereum Blockchain",
            "categories": [
                "Lightning-dev",
                "c-lightning"
            ],
            "authors": [
                "lisa neigut"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2611
        }
    },
    {
        "title": "[Lightning-dev] On the scalability issues of onboarding millions of LN mobile clients",
        "thread_messages": [
            {
                "author": "Antoine Riard",
                "date": "2020-05-05T10:17:37",
                "message_text_only": "Hi,\n\n(cross-posting as it's really both layers concerned)\n\nOngoing advancement of BIP 157 implementation in Core maybe the opportunity\nto reflect on the future of light client protocols and use this knowledge\nto make better-informed decisions about what kind of infrastructure is\nneeded to support mobile clients at large scale.\n\nTrust-minimization of Bitcoin security model has always relied first and\nabove on running a full-node. This current paradigm may be shifted by LN\nwhere fast, affordable, confidential, censorship-resistant payment services\nmay attract a lot of adoption without users running a full-node. Assuming a\nuser adoption path where a full-node is required to benefit for LN may\ndeprive a lot of users, especially those who are already denied a real\nfinancial infrastructure access. It doesn't mean we shouldn't foster node\nadoption when people are able to do so, and having a LN wallet maybe even a\nfirst-step to it.\n\nDesigning a mobile-first LN experience opens its own gap of challenges\nespecially in terms of security and privacy. The problem can be scoped as\nhow to build a scalable, secure, private chain access backend for millions\nof LN clients ?\n\nLight client protocols for LN exist (either BIP157 or Electrum are used),\nalthough their privacy and security guarantees with regards to\nimplementation on the client-side may still be an object of concern\n(aggressive tx-rebroadcast, sybillable outbound peer selection, trusted fee\nestimation). That said, one of the bottlenecks is likely the number of\nfull-nodes being willingly to dedicate resources to serve those clients.\nIt's not about _which_ protocol is deployed but more about _incentives_ for\nnode operators to dedicate long-term resources to client they have lower\nreasons to care about otherwise.\n\nEven with cheaper, more efficient protocols like BIP 157, you may have a\nhuge discrepancy between what is asked and what is offered. Assuming 10M\nlight clients [0] each of them consuming ~100MB/month for filters/headers,\nthat means you're asking 1PB/month of traffic to the backbone network. If\nyou assume 10K public nodes, like today, assuming _all_ of them opt-in to\nsignal BIP 157, that's an increase of 100GB/month for each. Which is\nconsequent with regards to the estimated cost of 350GB/month for running an\nactual public node. Widening full-node adoption, specially in term of\ngeographic distribution means as much as we can to bound its operational\ncost.\n\nObviously,  deployment of more efficient tx-relay protocol like Erlay will\nfree up some resources but it maybe wiser to dedicate them to increase\nhealth and security of the backbone network like deploying more outbound\nconnections.\n\nUnless your light client protocol is so ridiculous cheap to rely on\nniceness of a subset of node operators offering free resources, it won't\nscale. And it's likely you will always have a ratio disequilibrium between\nnumbers of clients and numbers of full-node, even worst their growth rate\nwon't be the same, first ones are so much easier to setup.\n\nIt doesn't mean servicing filters for free won't work for now, numbers of\nBIP157 clients is still pretty low, but what is worrying is  wallet vendors\nbuilding such chain access backend, hitting a bandwidth scalability wall\nfew years from now instead of pursuing better solutions. And if this\nhappen, maybe suddenly, isn't the quick fix going to be to rely on\ncentralized services, so much easier to deploy ?\n\nOf course, it may be brought that actually current full-node operators\ndon't get anything back from servicing blocks, transactions, addresses...\nIt may be replied that you have an indirect incentive to participate in\nnetwork relay and therefore guarantee censorship-resistance, instead of\ndirectly connecting to miners. You do have today ways to select your\nresources exposure like pruning, block-only or being private but the wider\npoint is the current (non?)-incentives model seems to work for the base\nlayer. For light clients data, are node operators going to be satisfied to\nserve this new *class* of traffic en masse ?\n\nThis doesn't mean you won't find BIP157 servers, ready to serve you with\nunlimited credit, but it's more likely their intentions maybe not aligned,\nlike spying on your transaction broadcast or block fetched. And you do want\npeer diversity to avoid every BIP157 servers being on few ASNs for\nfault-tolerance. Do people expect a scenario a la Cloudflare, where\neveryone connections is to far or less the same set of entities ?\n\nMoreover, the LN security model diverges hugely from basic on-chain\ntransactions. Worst-case attack on-chain a malicious light client server\nshowing a longest, invalid, PoW-signed chain to double-spend the user. On\nLN, the *liveliness* requirement means the entity owning your view of the\nchain can lie to you on whether your channel has been spent by a revoked\ncommitment, the real tip of the blockchain or even dry-up block\nannouncement to trigger unexpected behavior in the client logic. A\nmalicious light client server may just drop any filters/utxos spends, what\nyour LN client should do in this case ? [1]\n\nTherefore, you may want to introduce monetary compensation in exchange of\nservicing filters. Light client not dedicating resources to maintain the\nnetwork but free-riding on it, you may use their micro-payment capabilities\nto price chain access resources [3]. This proposition may suit within the\nwatchtower paradigm, where another entity is delegated some part of\nprotocol execution, alleviating client onliness requirement. It needs\nfurther analysis but how your funds may be compromised by a watchtower are\nlikely to be the same scenario that how a chain validation provider can\ncompromise you. That said, how do you avoid such \"chain access\" market\nturning as an oligopoly is an open question. You may \"bind\" them to\ninternet topology or ask for fidelity bonds and create some kind of\nscarcity but still...\n\nMaybe I'm completely wrong, missing some numbers, and it's maybe fine to\njust rely on few thousands of full-node operators being nice and servicing\nfriendly millions of LN mobiles clients. But just in case it may be good to\nconsider a reasonable alternative.\n\nThanks Gleb for many points exposed here but all mistakes are my own.\n\nCheers,\n\nAntoine\n\n[0] UTXO set size may be a bottleneck, but still if you have 2 channels by\nclients that's 20M utxos, just roughly ~x3 than today.\n\n[1] And committing filters as part of headers may not solve everything as\nan attacker can just delay or slow announcements to you, so you still need\nnetwork access to at least one honest node.\n\n[2]  It maybe argue that distinction client-vs-peer doesn't hold because\nyou may start as a client and start synchronizing the chain, relaying\nblocks, etc. AFAIK, there is no such hybrid implementation and that's not\nwhat you want to run in a mobile.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200505/bac9a893/attachment.html>"
            },
            {
                "author": "Andr\u00e9s G. Aragoneses",
                "date": "2020-05-05T10:28:22",
                "message_text_only": "Hey Antoine, just a small note, [3] is missing in your footnotes, can you\nadd it? Thanks\n\nOn Tue, 5 May 2020 at 18:17, Antoine Riard <antoine.riard at gmail.com> wrote:\n\n> Hi,\n>\n> (cross-posting as it's really both layers concerned)\n>\n> Ongoing advancement of BIP 157 implementation in Core maybe the\n> opportunity to reflect on the future of light client protocols and use this\n> knowledge to make better-informed decisions about what kind of\n> infrastructure is needed to support mobile clients at large scale.\n>\n> Trust-minimization of Bitcoin security model has always relied first and\n> above on running a full-node. This current paradigm may be shifted by LN\n> where fast, affordable, confidential, censorship-resistant payment services\n> may attract a lot of adoption without users running a full-node. Assuming a\n> user adoption path where a full-node is required to benefit for LN may\n> deprive a lot of users, especially those who are already denied a real\n> financial infrastructure access. It doesn't mean we shouldn't foster node\n> adoption when people are able to do so, and having a LN wallet maybe even a\n> first-step to it.\n>\n> Designing a mobile-first LN experience opens its own gap of challenges\n> especially in terms of security and privacy. The problem can be scoped as\n> how to build a scalable, secure, private chain access backend for millions\n> of LN clients ?\n>\n> Light client protocols for LN exist (either BIP157 or Electrum are used),\n> although their privacy and security guarantees with regards to\n> implementation on the client-side may still be an object of concern\n> (aggressive tx-rebroadcast, sybillable outbound peer selection, trusted fee\n> estimation). That said, one of the bottlenecks is likely the number of\n> full-nodes being willingly to dedicate resources to serve those clients.\n> It's not about _which_ protocol is deployed but more about _incentives_ for\n> node operators to dedicate long-term resources to client they have lower\n> reasons to care about otherwise.\n>\n> Even with cheaper, more efficient protocols like BIP 157, you may have a\n> huge discrepancy between what is asked and what is offered. Assuming 10M\n> light clients [0] each of them consuming ~100MB/month for filters/headers,\n> that means you're asking 1PB/month of traffic to the backbone network. If\n> you assume 10K public nodes, like today, assuming _all_ of them opt-in to\n> signal BIP 157, that's an increase of 100GB/month for each. Which is\n> consequent with regards to the estimated cost of 350GB/month for running an\n> actual public node. Widening full-node adoption, specially in term of\n> geographic distribution means as much as we can to bound its operational\n> cost.\n>\n> Obviously,  deployment of more efficient tx-relay protocol like Erlay will\n> free up some resources but it maybe wiser to dedicate them to increase\n> health and security of the backbone network like deploying more outbound\n> connections.\n>\n> Unless your light client protocol is so ridiculous cheap to rely on\n> niceness of a subset of node operators offering free resources, it won't\n> scale. And it's likely you will always have a ratio disequilibrium between\n> numbers of clients and numbers of full-node, even worst their growth rate\n> won't be the same, first ones are so much easier to setup.\n>\n> It doesn't mean servicing filters for free won't work for now, numbers of\n> BIP157 clients is still pretty low, but what is worrying is  wallet vendors\n> building such chain access backend, hitting a bandwidth scalability wall\n> few years from now instead of pursuing better solutions. And if this\n> happen, maybe suddenly, isn't the quick fix going to be to rely on\n> centralized services, so much easier to deploy ?\n>\n> Of course, it may be brought that actually current full-node operators\n> don't get anything back from servicing blocks, transactions, addresses...\n> It may be replied that you have an indirect incentive to participate in\n> network relay and therefore guarantee censorship-resistance, instead of\n> directly connecting to miners. You do have today ways to select your\n> resources exposure like pruning, block-only or being private but the wider\n> point is the current (non?)-incentives model seems to work for the base\n> layer. For light clients data, are node operators going to be satisfied to\n> serve this new *class* of traffic en masse ?\n>\n> This doesn't mean you won't find BIP157 servers, ready to serve you with\n> unlimited credit, but it's more likely their intentions maybe not aligned,\n> like spying on your transaction broadcast or block fetched. And you do want\n> peer diversity to avoid every BIP157 servers being on few ASNs for\n> fault-tolerance. Do people expect a scenario a la Cloudflare, where\n> everyone connections is to far or less the same set of entities ?\n>\n> Moreover, the LN security model diverges hugely from basic on-chain\n> transactions. Worst-case attack on-chain a malicious light client server\n> showing a longest, invalid, PoW-signed chain to double-spend the user. On\n> LN, the *liveliness* requirement means the entity owning your view of the\n> chain can lie to you on whether your channel has been spent by a revoked\n> commitment, the real tip of the blockchain or even dry-up block\n> announcement to trigger unexpected behavior in the client logic. A\n> malicious light client server may just drop any filters/utxos spends, what\n> your LN client should do in this case ? [1]\n>\n> Therefore, you may want to introduce monetary compensation in exchange of\n> servicing filters. Light client not dedicating resources to maintain the\n> network but free-riding on it, you may use their micro-payment capabilities\n> to price chain access resources [3]. This proposition may suit within the\n> watchtower paradigm, where another entity is delegated some part of\n> protocol execution, alleviating client onliness requirement. It needs\n> further analysis but how your funds may be compromised by a watchtower are\n> likely to be the same scenario that how a chain validation provider can\n> compromise you. That said, how do you avoid such \"chain access\" market\n> turning as an oligopoly is an open question. You may \"bind\" them to\n> internet topology or ask for fidelity bonds and create some kind of\n> scarcity but still...\n>\n> Maybe I'm completely wrong, missing some numbers, and it's maybe fine to\n> just rely on few thousands of full-node operators being nice and servicing\n> friendly millions of LN mobiles clients. But just in case it may be good to\n> consider a reasonable alternative.\n>\n> Thanks Gleb for many points exposed here but all mistakes are my own.\n>\n> Cheers,\n>\n> Antoine\n>\n> [0] UTXO set size may be a bottleneck, but still if you have 2 channels by\n> clients that's 20M utxos, just roughly ~x3 than today.\n>\n> [1] And committing filters as part of headers may not solve everything as\n> an attacker can just delay or slow announcements to you, so you still need\n> network access to at least one honest node.\n>\n> [2]  It maybe argue that distinction client-vs-peer doesn't hold because\n> you may start as a client and start synchronizing the chain, relaying\n> blocks, etc. AFAIK, there is no such hybrid implementation and that's not\n> what you want to run in a mobile.\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200505/15b6aaac/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-06T08:27:45",
                "message_text_only": "I didn't trust myself and verify. In fact the [3] is the real [2].\n\nLe mar. 5 mai 2020 \u00e0 06:28, Andr\u00e9s G. Aragoneses <knocte at gmail.com> a\n\u00e9crit :\n\n> Hey Antoine, just a small note, [3] is missing in your footnotes, can you\n> add it? Thanks\n>\n> On Tue, 5 May 2020 at 18:17, Antoine Riard <antoine.riard at gmail.com>\n> wrote:\n>\n>> Hi,\n>>\n>> (cross-posting as it's really both layers concerned)\n>>\n>> Ongoing advancement of BIP 157 implementation in Core maybe the\n>> opportunity to reflect on the future of light client protocols and use this\n>> knowledge to make better-informed decisions about what kind of\n>> infrastructure is needed to support mobile clients at large scale.\n>>\n>> Trust-minimization of Bitcoin security model has always relied first and\n>> above on running a full-node. This current paradigm may be shifted by LN\n>> where fast, affordable, confidential, censorship-resistant payment services\n>> may attract a lot of adoption without users running a full-node. Assuming a\n>> user adoption path where a full-node is required to benefit for LN may\n>> deprive a lot of users, especially those who are already denied a real\n>> financial infrastructure access. It doesn't mean we shouldn't foster node\n>> adoption when people are able to do so, and having a LN wallet maybe even a\n>> first-step to it.\n>>\n>> Designing a mobile-first LN experience opens its own gap of challenges\n>> especially in terms of security and privacy. The problem can be scoped as\n>> how to build a scalable, secure, private chain access backend for millions\n>> of LN clients ?\n>>\n>> Light client protocols for LN exist (either BIP157 or Electrum are used),\n>> although their privacy and security guarantees with regards to\n>> implementation on the client-side may still be an object of concern\n>> (aggressive tx-rebroadcast, sybillable outbound peer selection, trusted fee\n>> estimation). That said, one of the bottlenecks is likely the number of\n>> full-nodes being willingly to dedicate resources to serve those clients.\n>> It's not about _which_ protocol is deployed but more about _incentives_ for\n>> node operators to dedicate long-term resources to client they have lower\n>> reasons to care about otherwise.\n>>\n>> Even with cheaper, more efficient protocols like BIP 157, you may have a\n>> huge discrepancy between what is asked and what is offered. Assuming 10M\n>> light clients [0] each of them consuming ~100MB/month for filters/headers,\n>> that means you're asking 1PB/month of traffic to the backbone network. If\n>> you assume 10K public nodes, like today, assuming _all_ of them opt-in to\n>> signal BIP 157, that's an increase of 100GB/month for each. Which is\n>> consequent with regards to the estimated cost of 350GB/month for running an\n>> actual public node. Widening full-node adoption, specially in term of\n>> geographic distribution means as much as we can to bound its operational\n>> cost.\n>>\n>> Obviously,  deployment of more efficient tx-relay protocol like Erlay\n>> will free up some resources but it maybe wiser to dedicate them to increase\n>> health and security of the backbone network like deploying more outbound\n>> connections.\n>>\n>> Unless your light client protocol is so ridiculous cheap to rely on\n>> niceness of a subset of node operators offering free resources, it won't\n>> scale. And it's likely you will always have a ratio disequilibrium between\n>> numbers of clients and numbers of full-node, even worst their growth rate\n>> won't be the same, first ones are so much easier to setup.\n>>\n>> It doesn't mean servicing filters for free won't work for now, numbers of\n>> BIP157 clients is still pretty low, but what is worrying is  wallet vendors\n>> building such chain access backend, hitting a bandwidth scalability wall\n>> few years from now instead of pursuing better solutions. And if this\n>> happen, maybe suddenly, isn't the quick fix going to be to rely on\n>> centralized services, so much easier to deploy ?\n>>\n>> Of course, it may be brought that actually current full-node operators\n>> don't get anything back from servicing blocks, transactions, addresses...\n>> It may be replied that you have an indirect incentive to participate in\n>> network relay and therefore guarantee censorship-resistance, instead of\n>> directly connecting to miners. You do have today ways to select your\n>> resources exposure like pruning, block-only or being private but the wider\n>> point is the current (non?)-incentives model seems to work for the base\n>> layer. For light clients data, are node operators going to be satisfied to\n>> serve this new *class* of traffic en masse ?\n>>\n>> This doesn't mean you won't find BIP157 servers, ready to serve you with\n>> unlimited credit, but it's more likely their intentions maybe not aligned,\n>> like spying on your transaction broadcast or block fetched. And you do want\n>> peer diversity to avoid every BIP157 servers being on few ASNs for\n>> fault-tolerance. Do people expect a scenario a la Cloudflare, where\n>> everyone connections is to far or less the same set of entities ?\n>>\n>> Moreover, the LN security model diverges hugely from basic on-chain\n>> transactions. Worst-case attack on-chain a malicious light client server\n>> showing a longest, invalid, PoW-signed chain to double-spend the user. On\n>> LN, the *liveliness* requirement means the entity owning your view of the\n>> chain can lie to you on whether your channel has been spent by a revoked\n>> commitment, the real tip of the blockchain or even dry-up block\n>> announcement to trigger unexpected behavior in the client logic. A\n>> malicious light client server may just drop any filters/utxos spends, what\n>> your LN client should do in this case ? [1]\n>>\n>> Therefore, you may want to introduce monetary compensation in exchange of\n>> servicing filters. Light client not dedicating resources to maintain the\n>> network but free-riding on it, you may use their micro-payment capabilities\n>> to price chain access resources [3]. This proposition may suit within the\n>> watchtower paradigm, where another entity is delegated some part of\n>> protocol execution, alleviating client onliness requirement. It needs\n>> further analysis but how your funds may be compromised by a watchtower are\n>> likely to be the same scenario that how a chain validation provider can\n>> compromise you. That said, how do you avoid such \"chain access\" market\n>> turning as an oligopoly is an open question. You may \"bind\" them to\n>> internet topology or ask for fidelity bonds and create some kind of\n>> scarcity but still...\n>>\n>> Maybe I'm completely wrong, missing some numbers, and it's maybe fine to\n>> just rely on few thousands of full-node operators being nice and servicing\n>> friendly millions of LN mobiles clients. But just in case it may be good to\n>> consider a reasonable alternative.\n>>\n>> Thanks Gleb for many points exposed here but all mistakes are my own.\n>>\n>> Cheers,\n>>\n>> Antoine\n>>\n>> [0] UTXO set size may be a bottleneck, but still if you have 2 channels\n>> by clients that's 20M utxos, just roughly ~x3 than today.\n>>\n>> [1] And committing filters as part of headers may not solve everything as\n>> an attacker can just delay or slow announcements to you, so you still need\n>> network access to at least one honest node.\n>>\n>> [2]  It maybe argue that distinction client-vs-peer doesn't hold because\n>> you may start as a client and start synchronizing the chain, relaying\n>> blocks, etc. AFAIK, there is no such hybrid implementation and that's not\n>> what you want to run in a mobile.\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200506/7bc013c5/attachment-0001.html>"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2020-05-06T00:31:32",
                "message_text_only": "Hi Antoine,\n\n> Even with cheaper, more efficient protocols like BIP 157, you may have a\n> huge discrepancy between what is asked and what is offered. Assuming 10M\n> light clients [0] each of them consuming ~100MB/month for filters/headers,\n> that means you're asking 1PB/month of traffic to the backbone network. If\n> you assume 10K public nodes, like today, assuming _all_ of them opt-in to\n> signal BIP 157, that's an increase of 100GB/month for each. Which is\n> consequent with regards to the estimated cost of 350GB/month for running\n> an actual public node\n\nOne really dope thing about BIP 157+158, is that the protocol makes serving\nlight clients now _stateless_, since the full node doesn't need to perform\nany unique work for a given client. As a result, the entire protocol could\nbe served over something like HTTP, taking advantage of all the established\nCDNs and anycast serving infrastructure, which can reduce syncing time\n(less latency to\nfetch data) and also more widely distributed the load of light clients using\nthe existing web infrastructure. Going further, with HTTP/2's server-push\ncapabilities, those serving this data can still push out notifications for\nnew headers, etc.\n\n> Therefore, you may want to introduce monetary compensation in exchange of\n> servicing filters. Light client not dedicating resources to maintain the\n> network but free-riding on it, you may use their micro-payment\n> capabilities to price chain access resources [3]\n\nPiggy backing off the above idea, if the data starts being widely served\nover HTTP, then LSATs[1][2] can be used to add a lightweight payment\nmechanism by inserting a new proxy server in front of the filter/header\ninfrastructure. The minted tokens themselves may allow a user to purchase\naccess to a single header/filter, a range of them in the past, or N headers\npast the known chain tip, etc, etc.\n\n-- Laolu\n\n[1]: https://lsat.tech/\n[2]: https://lightning.engineering/posts/2020-03-30-lsat/\n\n\nOn Tue, May 5, 2020 at 3:17 AM Antoine Riard <antoine.riard at gmail.com>\nwrote:\n\n> Hi,\n>\n> (cross-posting as it's really both layers concerned)\n>\n> Ongoing advancement of BIP 157 implementation in Core maybe the\n> opportunity to reflect on the future of light client protocols and use this\n> knowledge to make better-informed decisions about what kind of\n> infrastructure is needed to support mobile clients at large scale.\n>\n> Trust-minimization of Bitcoin security model has always relied first and\n> above on running a full-node. This current paradigm may be shifted by LN\n> where fast, affordable, confidential, censorship-resistant payment services\n> may attract a lot of adoption without users running a full-node. Assuming a\n> user adoption path where a full-node is required to benefit for LN may\n> deprive a lot of users, especially those who are already denied a real\n> financial infrastructure access. It doesn't mean we shouldn't foster node\n> adoption when people are able to do so, and having a LN wallet maybe even a\n> first-step to it.\n>\n> Designing a mobile-first LN experience opens its own gap of challenges\n> especially in terms of security and privacy. The problem can be scoped as\n> how to build a scalable, secure, private chain access backend for millions\n> of LN clients ?\n>\n> Light client protocols for LN exist (either BIP157 or Electrum are used),\n> although their privacy and security guarantees with regards to\n> implementation on the client-side may still be an object of concern\n> (aggressive tx-rebroadcast, sybillable outbound peer selection, trusted fee\n> estimation). That said, one of the bottlenecks is likely the number of\n> full-nodes being willingly to dedicate resources to serve those clients.\n> It's not about _which_ protocol is deployed but more about _incentives_ for\n> node operators to dedicate long-term resources to client they have lower\n> reasons to care about otherwise.\n>\n> Even with cheaper, more efficient protocols like BIP 157, you may have a\n> huge discrepancy between what is asked and what is offered. Assuming 10M\n> light clients [0] each of them consuming ~100MB/month for filters/headers,\n> that means you're asking 1PB/month of traffic to the backbone network. If\n> you assume 10K public nodes, like today, assuming _all_ of them opt-in to\n> signal BIP 157, that's an increase of 100GB/month for each. Which is\n> consequent with regards to the estimated cost of 350GB/month for running an\n> actual public node. Widening full-node adoption, specially in term of\n> geographic distribution means as much as we can to bound its operational\n> cost.\n>\n> Obviously,  deployment of more efficient tx-relay protocol like Erlay will\n> free up some resources but it maybe wiser to dedicate them to increase\n> health and security of the backbone network like deploying more outbound\n> connections.\n>\n> Unless your light client protocol is so ridiculous cheap to rely on\n> niceness of a subset of node operators offering free resources, it won't\n> scale. And it's likely you will always have a ratio disequilibrium between\n> numbers of clients and numbers of full-node, even worst their growth rate\n> won't be the same, first ones are so much easier to setup.\n>\n> It doesn't mean servicing filters for free won't work for now, numbers of\n> BIP157 clients is still pretty low, but what is worrying is  wallet vendors\n> building such chain access backend, hitting a bandwidth scalability wall\n> few years from now instead of pursuing better solutions. And if this\n> happen, maybe suddenly, isn't the quick fix going to be to rely on\n> centralized services, so much easier to deploy ?\n>\n> Of course, it may be brought that actually current full-node operators\n> don't get anything back from servicing blocks, transactions, addresses...\n> It may be replied that you have an indirect incentive to participate in\n> network relay and therefore guarantee censorship-resistance, instead of\n> directly connecting to miners. You do have today ways to select your\n> resources exposure like pruning, block-only or being private but the wider\n> point is the current (non?)-incentives model seems to work for the base\n> layer. For light clients data, are node operators going to be satisfied to\n> serve this new *class* of traffic en masse ?\n>\n> This doesn't mean you won't find BIP157 servers, ready to serve you with\n> unlimited credit, but it's more likely their intentions maybe not aligned,\n> like spying on your transaction broadcast or block fetched. And you do want\n> peer diversity to avoid every BIP157 servers being on few ASNs for\n> fault-tolerance. Do people expect a scenario a la Cloudflare, where\n> everyone connections is to far or less the same set of entities ?\n>\n> Moreover, the LN security model diverges hugely from basic on-chain\n> transactions. Worst-case attack on-chain a malicious light client server\n> showing a longest, invalid, PoW-signed chain to double-spend the user. On\n> LN, the *liveliness* requirement means the entity owning your view of the\n> chain can lie to you on whether your channel has been spent by a revoked\n> commitment, the real tip of the blockchain or even dry-up block\n> announcement to trigger unexpected behavior in the client logic. A\n> malicious light client server may just drop any filters/utxos spends, what\n> your LN client should do in this case ? [1]\n>\n> Therefore, you may want to introduce monetary compensation in exchange of\n> servicing filters. Light client not dedicating resources to maintain the\n> network but free-riding on it, you may use their micro-payment capabilities\n> to price chain access resources [3]. This proposition may suit within the\n> watchtower paradigm, where another entity is delegated some part of\n> protocol execution, alleviating client onliness requirement. It needs\n> further analysis but how your funds may be compromised by a watchtower are\n> likely to be the same scenario that how a chain validation provider can\n> compromise you. That said, how do you avoid such \"chain access\" market\n> turning as an oligopoly is an open question. You may \"bind\" them to\n> internet topology or ask for fidelity bonds and create some kind of\n> scarcity but still...\n>\n> Maybe I'm completely wrong, missing some numbers, and it's maybe fine to\n> just rely on few thousands of full-node operators being nice and servicing\n> friendly millions of LN mobiles clients. But just in case it may be good to\n> consider a reasonable alternative.\n>\n> Thanks Gleb for many points exposed here but all mistakes are my own.\n>\n> Cheers,\n>\n> Antoine\n>\n> [0] UTXO set size may be a bottleneck, but still if you have 2 channels by\n> clients that's 20M utxos, just roughly ~x3 than today.\n>\n> [1] And committing filters as part of headers may not solve everything as\n> an attacker can just delay or slow announcements to you, so you still need\n> network access to at least one honest node.\n>\n> [2]  It maybe argue that distinction client-vs-peer doesn't hold because\n> you may start as a client and start synchronizing the chain, relaying\n> blocks, etc. AFAIK, there is no such hybrid implementation and that's not\n> what you want to run in a mobile.\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200505/f910aa3f/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-06T09:40:06",
                "message_text_only": "> As a result, the entire protocol could be served over something like\nHTTP, taking advantage of all the established CDNs and anycast serving\ninfrastructure,\n\nYes it's moving the issue of being a computation one to a distribution one.\nBut still you need the bandwidth capacities. What I'm concerned is the\ntrust model of relying on few-establish CDNs, you don't want to make it\neasy to have \"headers-routing\" hijack and therefore having massive channel\nclosure or time-locks interference due to LN clients not seeing the last\nfew block. So you may want to separate control/data plane, get filters from\nCDN and headers as check-and-control directly from the backbone network.\n\"Hybrid\" models should clearly be explored.\n\nWeb-of-trust style of deployments should be also envisioned, you may get\nhuge scaling improvement, assuming client may be peers between themselves\nand the ones belonging to the same social entity should be able to share\nthe same chain view without too much risk.\n\n> Piggy backing off the above idea, if the data starts being widely served\nover HTTP, then LSATs[1][2] can be used to add a lightweight payment\nmechanism by inserting a new proxy server in front of the filter/header\ninfrastructure.\n\nYeah, I hadn't time to read the spec yet but that was clearly something\nlike LSATs I meaned speaking about monetary compensation to price\nresources. I just hope it isn't too much tie to HTTP because you may want\nto read/write over other communication channels like\ntx-broadcast-over-radio to solve first-hop privacy.\n\nLe mar. 5 mai 2020 \u00e0 20:31, Olaoluwa Osuntokun <laolu32 at gmail.com> a \u00e9crit :\n\n> Hi Antoine,\n>\n> > Even with cheaper, more efficient protocols like BIP 157, you may have a\n> > huge discrepancy between what is asked and what is offered. Assuming 10M\n> > light clients [0] each of them consuming ~100MB/month for\n> filters/headers,\n> > that means you're asking 1PB/month of traffic to the backbone network. If\n> > you assume 10K public nodes, like today, assuming _all_ of them opt-in to\n> > signal BIP 157, that's an increase of 100GB/month for each. Which is\n> > consequent with regards to the estimated cost of 350GB/month for running\n> > an actual public node\n>\n> One really dope thing about BIP 157+158, is that the protocol makes serving\n> light clients now _stateless_, since the full node doesn't need to perform\n> any unique work for a given client. As a result, the entire protocol could\n> be served over something like HTTP, taking advantage of all the established\n> CDNs and anycast serving infrastructure, which can reduce syncing time\n> (less latency to\n> fetch data) and also more widely distributed the load of light clients\n> using\n> the existing web infrastructure. Going further, with HTTP/2's server-push\n> capabilities, those serving this data can still push out notifications for\n> new headers, etc.\n>\n> > Therefore, you may want to introduce monetary compensation in exchange of\n> > servicing filters. Light client not dedicating resources to maintain the\n> > network but free-riding on it, you may use their micro-payment\n> > capabilities to price chain access resources [3]\n>\n> Piggy backing off the above idea, if the data starts being widely served\n> over HTTP, then LSATs[1][2] can be used to add a lightweight payment\n> mechanism by inserting a new proxy server in front of the filter/header\n> infrastructure. The minted tokens themselves may allow a user to purchase\n> access to a single header/filter, a range of them in the past, or N headers\n> past the known chain tip, etc, etc.\n>\n> -- Laolu\n>\n> [1]: https://lsat.tech/\n> [2]: https://lightning.engineering/posts/2020-03-30-lsat/\n>\n>\n> On Tue, May 5, 2020 at 3:17 AM Antoine Riard <antoine.riard at gmail.com>\n> wrote:\n>\n>> Hi,\n>>\n>> (cross-posting as it's really both layers concerned)\n>>\n>> Ongoing advancement of BIP 157 implementation in Core maybe the\n>> opportunity to reflect on the future of light client protocols and use this\n>> knowledge to make better-informed decisions about what kind of\n>> infrastructure is needed to support mobile clients at large scale.\n>>\n>> Trust-minimization of Bitcoin security model has always relied first and\n>> above on running a full-node. This current paradigm may be shifted by LN\n>> where fast, affordable, confidential, censorship-resistant payment services\n>> may attract a lot of adoption without users running a full-node. Assuming a\n>> user adoption path where a full-node is required to benefit for LN may\n>> deprive a lot of users, especially those who are already denied a real\n>> financial infrastructure access. It doesn't mean we shouldn't foster node\n>> adoption when people are able to do so, and having a LN wallet maybe even a\n>> first-step to it.\n>>\n>> Designing a mobile-first LN experience opens its own gap of challenges\n>> especially in terms of security and privacy. The problem can be scoped as\n>> how to build a scalable, secure, private chain access backend for millions\n>> of LN clients ?\n>>\n>> Light client protocols for LN exist (either BIP157 or Electrum are used),\n>> although their privacy and security guarantees with regards to\n>> implementation on the client-side may still be an object of concern\n>> (aggressive tx-rebroadcast, sybillable outbound peer selection, trusted fee\n>> estimation). That said, one of the bottlenecks is likely the number of\n>> full-nodes being willingly to dedicate resources to serve those clients.\n>> It's not about _which_ protocol is deployed but more about _incentives_ for\n>> node operators to dedicate long-term resources to client they have lower\n>> reasons to care about otherwise.\n>>\n>> Even with cheaper, more efficient protocols like BIP 157, you may have a\n>> huge discrepancy between what is asked and what is offered. Assuming 10M\n>> light clients [0] each of them consuming ~100MB/month for filters/headers,\n>> that means you're asking 1PB/month of traffic to the backbone network. If\n>> you assume 10K public nodes, like today, assuming _all_ of them opt-in to\n>> signal BIP 157, that's an increase of 100GB/month for each. Which is\n>> consequent with regards to the estimated cost of 350GB/month for running an\n>> actual public node. Widening full-node adoption, specially in term of\n>> geographic distribution means as much as we can to bound its operational\n>> cost.\n>>\n>> Obviously,  deployment of more efficient tx-relay protocol like Erlay\n>> will free up some resources but it maybe wiser to dedicate them to increase\n>> health and security of the backbone network like deploying more outbound\n>> connections.\n>>\n>> Unless your light client protocol is so ridiculous cheap to rely on\n>> niceness of a subset of node operators offering free resources, it won't\n>> scale. And it's likely you will always have a ratio disequilibrium between\n>> numbers of clients and numbers of full-node, even worst their growth rate\n>> won't be the same, first ones are so much easier to setup.\n>>\n>> It doesn't mean servicing filters for free won't work for now, numbers of\n>> BIP157 clients is still pretty low, but what is worrying is  wallet vendors\n>> building such chain access backend, hitting a bandwidth scalability wall\n>> few years from now instead of pursuing better solutions. And if this\n>> happen, maybe suddenly, isn't the quick fix going to be to rely on\n>> centralized services, so much easier to deploy ?\n>>\n>> Of course, it may be brought that actually current full-node operators\n>> don't get anything back from servicing blocks, transactions, addresses...\n>> It may be replied that you have an indirect incentive to participate in\n>> network relay and therefore guarantee censorship-resistance, instead of\n>> directly connecting to miners. You do have today ways to select your\n>> resources exposure like pruning, block-only or being private but the wider\n>> point is the current (non?)-incentives model seems to work for the base\n>> layer. For light clients data, are node operators going to be satisfied to\n>> serve this new *class* of traffic en masse ?\n>>\n>> This doesn't mean you won't find BIP157 servers, ready to serve you with\n>> unlimited credit, but it's more likely their intentions maybe not aligned,\n>> like spying on your transaction broadcast or block fetched. And you do want\n>> peer diversity to avoid every BIP157 servers being on few ASNs for\n>> fault-tolerance. Do people expect a scenario a la Cloudflare, where\n>> everyone connections is to far or less the same set of entities ?\n>>\n>> Moreover, the LN security model diverges hugely from basic on-chain\n>> transactions. Worst-case attack on-chain a malicious light client server\n>> showing a longest, invalid, PoW-signed chain to double-spend the user. On\n>> LN, the *liveliness* requirement means the entity owning your view of the\n>> chain can lie to you on whether your channel has been spent by a revoked\n>> commitment, the real tip of the blockchain or even dry-up block\n>> announcement to trigger unexpected behavior in the client logic. A\n>> malicious light client server may just drop any filters/utxos spends, what\n>> your LN client should do in this case ? [1]\n>>\n>> Therefore, you may want to introduce monetary compensation in exchange of\n>> servicing filters. Light client not dedicating resources to maintain the\n>> network but free-riding on it, you may use their micro-payment capabilities\n>> to price chain access resources [3]. This proposition may suit within the\n>> watchtower paradigm, where another entity is delegated some part of\n>> protocol execution, alleviating client onliness requirement. It needs\n>> further analysis but how your funds may be compromised by a watchtower are\n>> likely to be the same scenario that how a chain validation provider can\n>> compromise you. That said, how do you avoid such \"chain access\" market\n>> turning as an oligopoly is an open question. You may \"bind\" them to\n>> internet topology or ask for fidelity bonds and create some kind of\n>> scarcity but still...\n>>\n>> Maybe I'm completely wrong, missing some numbers, and it's maybe fine to\n>> just rely on few thousands of full-node operators being nice and servicing\n>> friendly millions of LN mobiles clients. But just in case it may be good to\n>> consider a reasonable alternative.\n>>\n>> Thanks Gleb for many points exposed here but all mistakes are my own.\n>>\n>> Cheers,\n>>\n>> Antoine\n>>\n>> [0] UTXO set size may be a bottleneck, but still if you have 2 channels\n>> by clients that's 20M utxos, just roughly ~x3 than today.\n>>\n>> [1] And committing filters as part of headers may not solve everything as\n>> an attacker can just delay or slow announcements to you, so you still need\n>> network access to at least one honest node.\n>>\n>> [2]  It maybe argue that distinction client-vs-peer doesn't hold because\n>> you may start as a client and start synchronizing the chain, relaying\n>> blocks, etc. AFAIK, there is no such hybrid implementation and that's not\n>> what you want to run in a mobile.\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200506/b268d398/attachment-0001.html>"
            },
            {
                "author": "Richard Myers",
                "date": "2020-05-07T11:09:37",
                "message_text_only": "Thanks Antoine for starting this thread, I've also been curious about the\ncurrent thinking on light clients and incentivized full node services after\nseeing the LSAT work.\n\nOn Wed, May 6, 2020 at 11:40 AM Antoine Riard <antoine.riard at gmail.com>\nwrote:\n\n>\n> Yeah, I hadn't time to read the spec yet but that was clearly something\n> like LSATs I meaned speaking about monetary compensation to price\n> resources. I just hope it isn't too much tie to HTTP because you may want\n> to read/write over other communication channels like\n> tx-broadcast-over-radio to solve first-hop privacy.\n>\n\nI think we should consider alternative peer-to-peer communication channels\nboth in the context of supporting light client users and encouraging full\nnode diversity.\n\nBecause block headers and block filters can be cached and forwarded we can\nuse pure broadcast systems like geostationary satellites or radio systems\nwith various trade-offs between range and bandwidth such as amateur radio,\nunlicensed UHF and community WiFi.  Protocol features that support\nlow-bandwidth broadcast and local peer-to-peer networks add resilience to\nthe Bitcoin network because they can not be as easily sybilled, censored or\nsurveilled en mass, as centralized ISPs can be.\n\nBandwidth is the primary limitation of these alternative last-mile networks\ncompared to nodes using wired internet connections. We would like all\nBitcoin nodes to operate as equal peers (flat network), but the reality is\nthat potential Bitcoin users do not have equal access to affordable\nbandwidth from centralized providers. A system that lets light clients\naccess full nodes over local peer-to-peer networks could make self-custody\nmore accessible to light-client users and more local full nodes\nincentivized to provide services over local peer-to-peer networks could\nhelp increase the geographic diversity of full nodes.\n\nFor example, a light client could have inbound connections for block\nheaders and filters from 1) other light client peers via bluetooth, 2) an\nISP connected full node via a community WiFi network and 3) a blocksat\nconnected full node via a UHF mesh network.  These scenarios in more detail:\n\n1) two nearby light clients can exchange cached block headers, block\nfilters and full blocks over bluetooth or shared local WiFi - either tit\nfor tat or altruistically. Full blocks can be used to spot check block\nfilters and new block headers can help detect forks. There is no\ncommunication cost and when the local internet is censored or down can help\n(slowly) relay network state from any small set of operating links to the\noutside internet.\n\n2) a light client can query an ISP connected full node on the same\nunmetered local WiFi network and exchange differences in block headers\nopportunistically or pay for large missing ranges of headers, filters or\nfull blocks using a payment channel. Cost is reduced and privacy is\nenhanced for the light client by not using a centralized ISP. Bandwidth for\nrunning the full node can be amortized and subsidized by payments from\nlight clients who they resell data to.\n\n3) an off-grid validating full node can receive block information from the\nblocksat, but cross validate block headers from nearby full nodes connected\nto ISPs and light clients with cached information via low-bandwidth\nlong-range UHF mesh radio. This full node has no fixed bandwidth costs and\ncan also earn LN payments from light clients to help subsidize their\ninitial hardware purchase.\n\nI also believe a light-client could confirm specific transactions by\nquerying for Merkle proofs instead of full blocks when using a\nlow-bandwidth long distance and/or multi-hop radio link without the same\nprivacy linking concerns these queries would have if made using an internet\naddress tied to their identity or more specific physical location. I\nwouldn't argue to add this to the core protocol, but like Watchtowers it's\na service that can monetize and support the operation of a full node.\n\n  -- Richard\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200507/f6246a76/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-11T05:44:08",
                "message_text_only": "Good morning Richard, and all,\n\n\n> 2) a\u00a0light client can query an ISP connected full node on the same unmetered local WiFi network and exchange differences in block headers opportunistically or pay for large missing ranges of headers, filters or full blocks using a payment channel. Cost is reduced and privacy\u00a0is enhanced for the light client by not using a centralized ISP. Bandwidth for running the full node can be amortized\u00a0and subsidized by payments from light clients who they resell data to.\n\nA relatively pointless observation, but it seems to me that:\n\n* The light client is requesting for validation information, because...\n* ...its direct peers might be defrauding it, leading to...\n* ...the money it *thinks* it has in its channels being valueless.\n\nThus, if the light client opportunistically pays for validation information (whether full blocks, headers, or filters), the direct peers it has could just as easily not forward any payments, thus preventing the light client from paying for the validation information.\n\nIndeed, if the direct peer *is* defrauding the light client, the direct peer has no real incentive to actually forward *any* payments --- to do so would be to reduce the possible earnings it gets from defrauding the light client.\n(\"Simulating\" the payments so that the light client will not suspect anything runs the risk that the light client will be able to forward all its money out of the channel, and the cheating peer is still potentially liable for any funds it originally had in the channel if it gets caught.)\n\nWhat would work would be to use a system similar to watchtowers, wherein the validation-information-provider is prepaid and issues tokens that can be redeemed later.\nBut this is not suitable for opportunistic on-same-WiFi where, say, a laptop is running a validation-information-provider-for-payment program on the same WiFi as a light-client mobile phone, if we consider that the laptop and mobile may have never met before and may never meet again.\nIt would work if the laptop altruistically serves the blocks, but not if it were for (on-Lightning) payment.\n\n\nSo it seems to me that this kind of service is best ridden on top of watchtower service providers.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Richard Myers",
                "date": "2020-05-12T10:09:34",
                "message_text_only": "Thanks for sharing your thoughts ZmnSCPxj. I think I can summarize your\nconcern as: A node without direct internet connectivity can not rely on an\nopportunistically incentivized local network peer for blockchain\ninformation because the off-grid node's direct LN peers could collude to\nnot forward the payment.\n\nOn Mon, May 11, 2020 at 7:44 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> > 2) a light client can query an ISP connected full node on the same\n> unmetered local WiFi network and exchange differences in block headers\n> opportunistically or pay for large missing ranges of headers, filters or\n> full blocks using a payment channel. Cost is reduced and privacy is\n> enhanced for the light client by not using a centralized ISP. Bandwidth for\n> running the full node can be amortized and subsidized by payments from\n> light clients who they resell data to.\n>\n> A relatively pointless observation, but it seems to me that:\n>\n> * The light client is requesting for validation information, because...\n> * ...its direct peers might be defrauding it, leading to...\n> * ...the money it *thinks* it has in its channels being valueless.\n>\n> Thus, if the light client opportunistically pays for validation\n> information (whether full blocks, headers, or filters), the direct peers it\n> has could just as easily not forward any payments, thus preventing the\n> light client from paying for the validation information.\n>\n> Indeed, if the direct peer *is* defrauding the light client, the direct\n> peer has no real incentive to actually forward *any* payments --- to do so\n> would be to reduce the possible earnings it gets from defrauding the light\n> client.\n> (\"Simulating\" the payments so that the light client will not suspect\n> anything runs the risk that the light client will be able to forward all\n> its money out of the channel, and the cheating peer is still potentially\n> liable for any funds it originally had in the channel if it gets caught.)\n>\n\nOne question I had is: how can a malicious direct payment peer \"simulate\" a\nsuccessful payment made by an off-grid victim peer to an information\nsource?  The censoring peer wouldn't be able to return the preimage for a\npayment they failed to forward. Also, since the information provider and\noff-grid node can presumably communicate via their local network\nconnection, it would be obvious if all of the victims LN peers were failing\nto forward payments (whether maliciously or due to routing failures) to an\ninformation provider they could otherwise communicate with.\n\nAny LN payments not monitored by a watchtower that are received by the\neclipsed off-grid victim node would be at risk in this attack scenario.\nLikewise any layer 1 payments they received should be buried under\nsufficient valid block headers before being relied on.\n\nI don't see how a LN node one-step removed from a direct internet\nconnection is at more risk than an internet connected node eclipsed by\ntheir ISP, for example. In both cases, failure to get timely blockchain\ninfo should trigger warnings to stop accepting payments.\n\n\n> What would work would be to use a system similar to watchtowers, wherein\n> the validation-information-provider is prepaid and issues tokens that can\n> be redeemed later.\n> But this is not suitable for opportunistic on-same-WiFi where, say, a\n> laptop is running a validation-information-provider-for-payment program on\n> the same WiFi as a light-client mobile phone, if we consider that the\n> laptop and mobile may have never met before and may never meet again.\n> It would work if the laptop altruistically serves the blocks, but not if\n> it were for (on-Lightning) payment.\n>\n\nThere's another problem if we can't rely on a recurring relationship with\nan information provider besides not being able to prepay for validation\ninformation doesn't make sense. We don't want an information provider to\ncollect payments for serving invalid information. Maybe for very small\npayments this isn't a problem, but ideally validity could be coded into the\nHTLC.\n\nFor example, an alternative HTLC construct that only paid for valid 81 B\nheaders that hash to 32 B values with a number of leading zeros committed\nto by the HTLC. It would make more economic sense for an internet gateway\nnode to serve valid mined header to nodes on their local WiFi network than\nto create bogus ones with the same (high) amount of work.\n\n\n> So it seems to me that this kind of service is best ridden on top of\n> watchtower service providers.\n>\n\nPublic watchtowers or some sort of HTTP proxy data cache similar to a\nwatchtower makes the most sense to me because they would be expected to be\neconomically motivated and LN payment aware. Full nodes could potentially\nbe incentivized to exchange new data with other nodes in a tit-for-tat way,\nbut I don't expect them to be incentivized by light clients using LN\nmicropayments in a server-client arrangement.\n\nNetwork agents that monetize full node information services beyond channel\nmonitoring would be more than just a \"Watchtower\" for light clients. Would\nthey be more like incentivized Electrum servers? Are there still privacy\nconcerns when they serve generic/un-personalized headers/filters/blocks to\nlight clients? A personal, altruistic or friends and family watchtower is\nalso possible, but I'm thinking about how light clients without this\npossibility can be served.\n\nHappy new epoch,\n\n  -- Richard\n\n-- \nRichard Myers\nDecentralized Applications Engineer, goTenna\ngotenna.com\n@gotenna\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200512/ea1a456e/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-12T15:48:30",
                "message_text_only": "Good morning Richard,\n\n> Thanks for sharing your thoughts ZmnSCPxj. I think I can summarize your concern as: A node without direct internet connectivity can not rely on an opportunistically incentivized local network peer for blockchain information because the off-grid node's direct LN peers could collude to not forward the payment.\n\nCorrect.\n\n> > > 2) a\u00a0light client can query an ISP connected full node on the same unmetered local WiFi network and exchange differences in block headers opportunistically or pay for large missing ranges of headers, filters or full blocks using a payment channel. Cost is reduced and privacy\u00a0is enhanced for the light client by not using a centralized ISP. Bandwidth for running the full node can be amortized\u00a0and subsidized by payments from light clients who they resell data to.\n> >\n> > A relatively pointless observation, but it seems to me that:\n> >\n> > * The light client is requesting for validation information, because...\n> > * ...its direct peers might be defrauding it, leading to...\n> > * ...the money it *thinks* it has in its channels being valueless.\n> >\n> > Thus, if the light client opportunistically pays for validation information (whether full blocks, headers, or filters), the direct peers it has could just as easily not forward any payments, thus preventing the light client from paying for the validation information.\n> >\n> > Indeed, if the direct peer *is* defrauding the light client, the direct peer has no real incentive to actually forward *any* payments --- to do so would be to reduce the possible earnings it gets from defrauding the light client.\n> > (\"Simulating\" the payments so that the light client will not suspect anything runs the risk that the light client will be able to forward all its money out of the channel, and the cheating peer is still potentially liable for any funds it originally had in the channel if it gets caught.)\n>\n> One question I had is: how can a malicious direct payment peer \"simulate\" a successful payment made by an off-grid victim peer to an information source?\u00a0 The\u00a0censoring peer wouldn't be able to return the preimage for a payment they failed to forward. Also, since the information provider and off-grid node can presumably communicate via their local network connection, it would be obvious if all of the victims LN peers were failing to forward payments (whether maliciously or due to routing failures) to an information provider they could otherwise communicate with.\n\nPerhaps \"simulate\" is not quite the correct term.\nBasically, if the eclipsing peer(s) are reasonably sure they have eclipsed the light client, then all funds in those channels are semantically theirs (they \"0wn\" the eclipsed light client).\nThen anything the light node offers from those channels (which it thinks are its, but are now in reality owned by the eclipsing peer) has no value (the eclipsing node already 0wns the light node and all its funds, what can the light node offer to it?).\nThe eclipsing peer could still \"simulate\" what the light node expects of reality by pretending that the light node actually still owns funds in the channel (even though the eclipsing node has successfully stolen all those funds), and forward as normal to get the payment preimage/scalar.\n\n\n> > What would work would be to use a system similar to watchtowers, wherein the validation-information-provider is prepaid and issues tokens that can be redeemed later.\n> > But this is not suitable for opportunistic on-same-WiFi where, say, a laptop is running a validation-information-provider-for-payment program on the same WiFi as a light-client mobile phone, if we consider that the laptop and mobile may have never met before and may never meet again.\n> > It would work if the laptop altruistically serves the blocks, but not if it were for (on-Lightning) payment.\n>\n> There's another problem if we can't rely on a recurring relationship with an information provider besides not being able to prepay for validation information doesn't make sense. We don't want an information provider\u00a0to collect payments for serving invalid information. Maybe for very small payments this isn't a problem, but ideally validity could be coded into the HTLC.\n>\n> For example, an alternative HTLC construct that only paid for valid 81 B headers that hash to 32 B values with a number of leading zeros committed to by the HTLC. It would make more economic sense for an internet gateway node to serve valid mined header to nodes on their\u00a0local WiFi network than to create bogus ones with the same (high) amount of work.\n\nIf you are considering this for on-Lightning payments, do note that the alternative HTLC construct has to be known by every forwarding node, including the direct peer(s) of the light client, which are precisely the potential attackers on the light client.\n\nIt seems to be impractical for onchain payments: the provider can drop the data onchain to claim the funds, but it is precisely the blockchain data that the light client does not have direct access to, so ---\n\n\n> \u00a0\n>\n> > So it seems to me that this kind of service is best ridden on top of watchtower service providers.\n>\n> Public watchtowers or some sort of HTTP proxy data cache similar to\u00a0a watchtower makes the most sense to me because they would be expected to be economically motivated and LN payment aware. Full nodes could potentially be incentivized to exchange new data with other nodes in a tit-for-tat way, but I don't expect them to be incentivized by light clients using LN micropayments in a server-client arrangement.\n>\n> Network agents that monetize full node information services beyond channel monitoring would be more than just a \"Watchtower\" for light clients. Would they be more like incentivized Electrum servers?\n\nPossibly.\n\n> Are there still privacy concerns when they\u00a0serve generic/un-personalized headers/filters/blocks to light clients?\n\nIt marks the client as a light client, at least.\n\nSomeone who gets read-only access to the logs of such a public-service node now has a list of light clients.\nIf the light clients are in any way identifiable and locatable, the hacker can then attempt to hack the light client and redirect their understanding of what the public-service node is (e.g. DNS poisoning) and then start performing other attacks on the client once its view of the blockchain is eclipsed.\n\nThis would be helped if the light client, for example, always uses Tor to access the public-service node, if payments for services of that node are decorrelated (e.g. tokens issued by the node that will later be reclaimed for service are blinded), etc.\nSuch would make the light client harder to locate in the first place.\n\n(While a mobile client can certainly access the Internet over various access points, most people who own mobile devices have a home they go to at night, which often has Internet access, possibly with a stable identifiable location that can be attacked)\n\n>\u00a0A personal, altruistic or friends and family watchtower is also possible, but I'm thinking about how light clients without this possibility can be served.\n\nThis is probably something we can expect to see as well; though it should be noted, for those philosophically interested in such things, that these are the genesis of governments and states.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Igor Cota",
                "date": "2020-05-07T16:40:49",
                "message_text_only": "Hi Antoine et al,\n\nMaybe I'm completely wrong, missing some numbers, and it's maybe fine to\n> just rely on few thousands of full-node operators being nice and servicing\n> friendly millions of LN mobiles clients. But just in case it may be good to\n> consider a reasonable alternative.\n>\n\n\n> So you may want to separate control/data plane, get filters from CDN and\n> headers as check-and-control directly from the backbone network. \"Hybrid\"\n> models should clearly be explored.\n\n\nFor some months now I've been exploring the feasibility of running full\nnodes on everyday phones [1]. One of my first thoughts was how to avoid the\nphones mooching off the network. Obviously due to battery, storage and\nbandwidth constraints it is not reasonable to expect pocket full nodes to\nserve blocks during day time.\n\nHuge exception to this is the time we are asleep and our phones are\nconnected to wifi and charging. IMO this is a huge untapped resource that\nwould allow mobile nodes to earn their keep. If we limit full node\noperation to sleepy night time the only constraining resource is storage:\n512 gb of internal storage in phones is quite rare, probably about $100 for\nan SD card with full archival node capacity but phones with memory card\nslots rarer still - no one is going to bother.\n\nSo depending on their storage capacity phone nodes could decide to store\nand serve just a randomly selected range of blocks during their nighttime\noperation. With trivial changes to P2P they could advertise the blocks they\nare able to serve.\nIf there comes a time that normal full nodes feel DoS'ed they can challenge\nsuch nodes to produce the blocks they advertise and ban them as moochers if\nthey fail to do so. Others may elect to be more charitable and serve\neveryone.\n\nThese types of nodes would truly be part-timing since they only carry a\nsubset of the blockchain and work while their operator is asleep. Probably\nshould be called part-time or Sleeper Nodes\u2122.\n\nThey could be user friendly as well, with Assume UTXO they could be\nbootstrapped quickly and while they do the IBD in the background instead of\ntraditional pruning they can keep the randomly assigned bit of blockchain\nto later serve the network.\n\nSave for the elderly, all the people I know could run such a node, and I\ndon't live in a first world country.\n\nThere is also the feel-good kumbaya aspect of American phone nodes serving\nthe African continent while the Americans are asleep, Africans and\nEuropeans serving the Asians in kind. By plugging in our phones and going\nto sleep we could blanket the whole world in (somewhat) full nodes!\n\nCheers,\nIgor\n\n[1] https://icota.github.io/\n\nOn Tue, 5 May 2020 at 12:18, Antoine Riard <antoine.riard at gmail.com> wrote:\n\n> Hi,\n>\n> (cross-posting as it's really both layers concerned)\n>\n> Ongoing advancement of BIP 157 implementation in Core maybe the\n> opportunity to reflect on the future of light client protocols and use this\n> knowledge to make better-informed decisions about what kind of\n> infrastructure is needed to support mobile clients at large scale.\n>\n> Trust-minimization of Bitcoin security model has always relied first and\n> above on running a full-node. This current paradigm may be shifted by LN\n> where fast, affordable, confidential, censorship-resistant payment services\n> may attract a lot of adoption without users running a full-node. Assuming a\n> user adoption path where a full-node is required to benefit for LN may\n> deprive a lot of users, especially those who are already denied a real\n> financial infrastructure access. It doesn't mean we shouldn't foster node\n> adoption when people are able to do so, and having a LN wallet maybe even a\n> first-step to it.\n>\n> Designing a mobile-first LN experience opens its own gap of challenges\n> especially in terms of security and privacy. The problem can be scoped as\n> how to build a scalable, secure, private chain access backend for millions\n> of LN clients ?\n>\n> Light client protocols for LN exist (either BIP157 or Electrum are used),\n> although their privacy and security guarantees with regards to\n> implementation on the client-side may still be an object of concern\n> (aggressive tx-rebroadcast, sybillable outbound peer selection, trusted fee\n> estimation). That said, one of the bottlenecks is likely the number of\n> full-nodes being willingly to dedicate resources to serve those clients.\n> It's not about _which_ protocol is deployed but more about _incentives_ for\n> node operators to dedicate long-term resources to client they have lower\n> reasons to care about otherwise.\n>\n> Even with cheaper, more efficient protocols like BIP 157, you may have a\n> huge discrepancy between what is asked and what is offered. Assuming 10M\n> light clients [0] each of them consuming ~100MB/month for filters/headers,\n> that means you're asking 1PB/month of traffic to the backbone network. If\n> you assume 10K public nodes, like today, assuming _all_ of them opt-in to\n> signal BIP 157, that's an increase of 100GB/month for each. Which is\n> consequent with regards to the estimated cost of 350GB/month for running an\n> actual public node. Widening full-node adoption, specially in term of\n> geographic distribution means as much as we can to bound its operational\n> cost.\n>\n> Obviously,  deployment of more efficient tx-relay protocol like Erlay will\n> free up some resources but it maybe wiser to dedicate them to increase\n> health and security of the backbone network like deploying more outbound\n> connections.\n>\n> Unless your light client protocol is so ridiculous cheap to rely on\n> niceness of a subset of node operators offering free resources, it won't\n> scale. And it's likely you will always have a ratio disequilibrium between\n> numbers of clients and numbers of full-node, even worst their growth rate\n> won't be the same, first ones are so much easier to setup.\n>\n> It doesn't mean servicing filters for free won't work for now, numbers of\n> BIP157 clients is still pretty low, but what is worrying is  wallet vendors\n> building such chain access backend, hitting a bandwidth scalability wall\n> few years from now instead of pursuing better solutions. And if this\n> happen, maybe suddenly, isn't the quick fix going to be to rely on\n> centralized services, so much easier to deploy ?\n>\n> Of course, it may be brought that actually current full-node operators\n> don't get anything back from servicing blocks, transactions, addresses...\n> It may be replied that you have an indirect incentive to participate in\n> network relay and therefore guarantee censorship-resistance, instead of\n> directly connecting to miners. You do have today ways to select your\n> resources exposure like pruning, block-only or being private but the wider\n> point is the current (non?)-incentives model seems to work for the base\n> layer. For light clients data, are node operators going to be satisfied to\n> serve this new *class* of traffic en masse ?\n>\n> This doesn't mean you won't find BIP157 servers, ready to serve you with\n> unlimited credit, but it's more likely their intentions maybe not aligned,\n> like spying on your transaction broadcast or block fetched. And you do want\n> peer diversity to avoid every BIP157 servers being on few ASNs for\n> fault-tolerance. Do people expect a scenario a la Cloudflare, where\n> everyone connections is to far or less the same set of entities ?\n>\n> Moreover, the LN security model diverges hugely from basic on-chain\n> transactions. Worst-case attack on-chain a malicious light client server\n> showing a longest, invalid, PoW-signed chain to double-spend the user. On\n> LN, the *liveliness* requirement means the entity owning your view of the\n> chain can lie to you on whether your channel has been spent by a revoked\n> commitment, the real tip of the blockchain or even dry-up block\n> announcement to trigger unexpected behavior in the client logic. A\n> malicious light client server may just drop any filters/utxos spends, what\n> your LN client should do in this case ? [1]\n>\n> Therefore, you may want to introduce monetary compensation in exchange of\n> servicing filters. Light client not dedicating resources to maintain the\n> network but free-riding on it, you may use their micro-payment capabilities\n> to price chain access resources [3]. This proposition may suit within the\n> watchtower paradigm, where another entity is delegated some part of\n> protocol execution, alleviating client onliness requirement. It needs\n> further analysis but how your funds may be compromised by a watchtower are\n> likely to be the same scenario that how a chain validation provider can\n> compromise you. That said, how do you avoid such \"chain access\" market\n> turning as an oligopoly is an open question. You may \"bind\" them to\n> internet topology or ask for fidelity bonds and create some kind of\n> scarcity but still...\n>\n> Maybe I'm completely wrong, missing some numbers, and it's maybe fine to\n> just rely on few thousands of full-node operators being nice and servicing\n> friendly millions of LN mobiles clients. But just in case it may be good to\n> consider a reasonable alternative.\n>\n> Thanks Gleb for many points exposed here but all mistakes are my own.\n>\n> Cheers,\n>\n> Antoine\n>\n> [0] UTXO set size may be a bottleneck, but still if you have 2 channels by\n> clients that's 20M utxos, just roughly ~x3 than today.\n>\n> [1] And committing filters as part of headers may not solve everything as\n> an attacker can just delay or slow announcements to you, so you still need\n> network access to at least one honest node.\n>\n> [2]  It maybe argue that distinction client-vs-peer doesn't hold because\n> you may start as a client and start synchronizing the chain, relaying\n> blocks, etc. AFAIK, there is no such hybrid implementation and that's not\n> what you want to run in a mobile.\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n\n\n-- \n*Igor Cota*\nCodex Apertus Ltd\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200507/8b85d6e1/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-09T07:22:52",
                "message_text_only": "Hi Igor,\n\nThanks for sharing about what it's technically possible to do for a\nfull-node on phone, specially with regards to lower grade devices.\n\nI do see 2 limitations for sleeping nodes:\n- a lightning specific one, i.e you need to process block data real-time in\ncase of incoming HTLC you need to claim on chain or a HTLC timeout. There\nis a bunch of timelocks implications in LN,  with regards to CSV,\nCLTV_DELTA, incoming policy, outgoing policy, ... and you can't really\nafford to be late without loosing a payment. I don't see timelocks being\nincrease, that would hinder liquidity.\n- a p2p bandwidth concern, even if this new class of nodes turn as public\nones, they would still have a heavy sync period due to be fallen-behind\nduring the day, so you would have huge bandwidth spikes every a timezone\nfalls asleep and a risk of choking upload links of stable full-nodes.\n\nI think assume-utxo may be interesting in the future in case of long-fork\ndetection, you may be able to download a utxo-set on the fly, and fall-back\nto a full-node. But that would be only an emergency measure, not a regular\ncost on the backbone network.\n\nAntoine\n\n\nLe jeu. 7 mai 2020 \u00e0 12:41, Igor Cota <igor at codexapertus.com> a \u00e9crit :\n\n> Hi Antoine et al,\n>\n> Maybe I'm completely wrong, missing some numbers, and it's maybe fine to\n>> just rely on few thousands of full-node operators being nice and servicing\n>> friendly millions of LN mobiles clients. But just in case it may be good to\n>> consider a reasonable alternative.\n>>\n>\n>\n>> So you may want to separate control/data plane, get filters from CDN and\n>> headers as check-and-control directly from the backbone network. \"Hybrid\"\n>> models should clearly be explored.\n>\n>\n> For some months now I've been exploring the feasibility of running full\n> nodes on everyday phones [1]. One of my first thoughts was how to avoid the\n> phones mooching off the network. Obviously due to battery, storage and\n> bandwidth constraints it is not reasonable to expect pocket full nodes to\n> serve blocks during day time.\n>\n> Huge exception to this is the time we are asleep and our phones are\n> connected to wifi and charging. IMO this is a huge untapped resource that\n> would allow mobile nodes to earn their keep. If we limit full node\n> operation to sleepy night time the only constraining resource is storage:\n> 512 gb of internal storage in phones is quite rare, probably about $100 for\n> an SD card with full archival node capacity but phones with memory card\n> slots rarer still - no one is going to bother.\n>\n> So depending on their storage capacity phone nodes could decide to store\n> and serve just a randomly selected range of blocks during their nighttime\n> operation. With trivial changes to P2P they could advertise the blocks they\n> are able to serve.\n> If there comes a time that normal full nodes feel DoS'ed they can\n> challenge such nodes to produce the blocks they advertise and ban them as\n> moochers if they fail to do so. Others may elect to be more charitable and\n> serve everyone.\n>\n> These types of nodes would truly be part-timing since they only carry a\n> subset of the blockchain and work while their operator is asleep. Probably\n> should be called part-time or Sleeper Nodes\u2122.\n>\n> They could be user friendly as well, with Assume UTXO they could be\n> bootstrapped quickly and while they do the IBD in the background instead of\n> traditional pruning they can keep the randomly assigned bit of blockchain\n> to later serve the network.\n>\n> Save for the elderly, all the people I know could run such a node, and I\n> don't live in a first world country.\n>\n> There is also the feel-good kumbaya aspect of American phone nodes serving\n> the African continent while the Americans are asleep, Africans and\n> Europeans serving the Asians in kind. By plugging in our phones and going\n> to sleep we could blanket the whole world in (somewhat) full nodes!\n>\n> Cheers,\n> Igor\n>\n> [1] https://icota.github.io/\n>\n> On Tue, 5 May 2020 at 12:18, Antoine Riard <antoine.riard at gmail.com>\n> wrote:\n>\n>> Hi,\n>>\n>> (cross-posting as it's really both layers concerned)\n>>\n>> Ongoing advancement of BIP 157 implementation in Core maybe the\n>> opportunity to reflect on the future of light client protocols and use this\n>> knowledge to make better-informed decisions about what kind of\n>> infrastructure is needed to support mobile clients at large scale.\n>>\n>> Trust-minimization of Bitcoin security model has always relied first and\n>> above on running a full-node. This current paradigm may be shifted by LN\n>> where fast, affordable, confidential, censorship-resistant payment services\n>> may attract a lot of adoption without users running a full-node. Assuming a\n>> user adoption path where a full-node is required to benefit for LN may\n>> deprive a lot of users, especially those who are already denied a real\n>> financial infrastructure access. It doesn't mean we shouldn't foster node\n>> adoption when people are able to do so, and having a LN wallet maybe even a\n>> first-step to it.\n>>\n>> Designing a mobile-first LN experience opens its own gap of challenges\n>> especially in terms of security and privacy. The problem can be scoped as\n>> how to build a scalable, secure, private chain access backend for millions\n>> of LN clients ?\n>>\n>> Light client protocols for LN exist (either BIP157 or Electrum are used),\n>> although their privacy and security guarantees with regards to\n>> implementation on the client-side may still be an object of concern\n>> (aggressive tx-rebroadcast, sybillable outbound peer selection, trusted fee\n>> estimation). That said, one of the bottlenecks is likely the number of\n>> full-nodes being willingly to dedicate resources to serve those clients.\n>> It's not about _which_ protocol is deployed but more about _incentives_ for\n>> node operators to dedicate long-term resources to client they have lower\n>> reasons to care about otherwise.\n>>\n>> Even with cheaper, more efficient protocols like BIP 157, you may have a\n>> huge discrepancy between what is asked and what is offered. Assuming 10M\n>> light clients [0] each of them consuming ~100MB/month for filters/headers,\n>> that means you're asking 1PB/month of traffic to the backbone network. If\n>> you assume 10K public nodes, like today, assuming _all_ of them opt-in to\n>> signal BIP 157, that's an increase of 100GB/month for each. Which is\n>> consequent with regards to the estimated cost of 350GB/month for running an\n>> actual public node. Widening full-node adoption, specially in term of\n>> geographic distribution means as much as we can to bound its operational\n>> cost.\n>>\n>> Obviously,  deployment of more efficient tx-relay protocol like Erlay\n>> will free up some resources but it maybe wiser to dedicate them to increase\n>> health and security of the backbone network like deploying more outbound\n>> connections.\n>>\n>> Unless your light client protocol is so ridiculous cheap to rely on\n>> niceness of a subset of node operators offering free resources, it won't\n>> scale. And it's likely you will always have a ratio disequilibrium between\n>> numbers of clients and numbers of full-node, even worst their growth rate\n>> won't be the same, first ones are so much easier to setup.\n>>\n>> It doesn't mean servicing filters for free won't work for now, numbers of\n>> BIP157 clients is still pretty low, but what is worrying is  wallet vendors\n>> building such chain access backend, hitting a bandwidth scalability wall\n>> few years from now instead of pursuing better solutions. And if this\n>> happen, maybe suddenly, isn't the quick fix going to be to rely on\n>> centralized services, so much easier to deploy ?\n>>\n>> Of course, it may be brought that actually current full-node operators\n>> don't get anything back from servicing blocks, transactions, addresses...\n>> It may be replied that you have an indirect incentive to participate in\n>> network relay and therefore guarantee censorship-resistance, instead of\n>> directly connecting to miners. You do have today ways to select your\n>> resources exposure like pruning, block-only or being private but the wider\n>> point is the current (non?)-incentives model seems to work for the base\n>> layer. For light clients data, are node operators going to be satisfied to\n>> serve this new *class* of traffic en masse ?\n>>\n>> This doesn't mean you won't find BIP157 servers, ready to serve you with\n>> unlimited credit, but it's more likely their intentions maybe not aligned,\n>> like spying on your transaction broadcast or block fetched. And you do want\n>> peer diversity to avoid every BIP157 servers being on few ASNs for\n>> fault-tolerance. Do people expect a scenario a la Cloudflare, where\n>> everyone connections is to far or less the same set of entities ?\n>>\n>> Moreover, the LN security model diverges hugely from basic on-chain\n>> transactions. Worst-case attack on-chain a malicious light client server\n>> showing a longest, invalid, PoW-signed chain to double-spend the user. On\n>> LN, the *liveliness* requirement means the entity owning your view of the\n>> chain can lie to you on whether your channel has been spent by a revoked\n>> commitment, the real tip of the blockchain or even dry-up block\n>> announcement to trigger unexpected behavior in the client logic. A\n>> malicious light client server may just drop any filters/utxos spends, what\n>> your LN client should do in this case ? [1]\n>>\n>> Therefore, you may want to introduce monetary compensation in exchange of\n>> servicing filters. Light client not dedicating resources to maintain the\n>> network but free-riding on it, you may use their micro-payment capabilities\n>> to price chain access resources [3]. This proposition may suit within the\n>> watchtower paradigm, where another entity is delegated some part of\n>> protocol execution, alleviating client onliness requirement. It needs\n>> further analysis but how your funds may be compromised by a watchtower are\n>> likely to be the same scenario that how a chain validation provider can\n>> compromise you. That said, how do you avoid such \"chain access\" market\n>> turning as an oligopoly is an open question. You may \"bind\" them to\n>> internet topology or ask for fidelity bonds and create some kind of\n>> scarcity but still...\n>>\n>> Maybe I'm completely wrong, missing some numbers, and it's maybe fine to\n>> just rely on few thousands of full-node operators being nice and servicing\n>> friendly millions of LN mobiles clients. But just in case it may be good to\n>> consider a reasonable alternative.\n>>\n>> Thanks Gleb for many points exposed here but all mistakes are my own.\n>>\n>> Cheers,\n>>\n>> Antoine\n>>\n>> [0] UTXO set size may be a bottleneck, but still if you have 2 channels\n>> by clients that's 20M utxos, just roughly ~x3 than today.\n>>\n>> [1] And committing filters as part of headers may not solve everything as\n>> an attacker can just delay or slow announcements to you, so you still need\n>> network access to at least one honest node.\n>>\n>> [2]  It maybe argue that distinction client-vs-peer doesn't hold because\n>> you may start as a client and start synchronizing the chain, relaying\n>> blocks, etc. AFAIK, there is no such hybrid implementation and that's not\n>> what you want to run in a mobile.\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n>\n> --\n> *Igor Cota*\n> Codex Apertus Ltd\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200509/00324e4f/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "On the scalability issues of onboarding millions of LN mobile clients",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Igor Cota",
                "Antoine Riard",
                "Andr\u00e9s G. Aragoneses",
                "Richard Myers",
                "Olaoluwa Osuntokun",
                "ZmnSCPxj"
            ],
            "messages_count": 11,
            "total_messages_chars_count": 84625
        }
    },
    {
        "title": "[Lightning-dev] [bitcoin-dev] On the scalability issues of onboarding millions of LN mobile clients",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2020-05-05T13:00:37",
                "message_text_only": "On Tuesday 05 May 2020 10:17:37 Antoine Riard via bitcoin-dev wrote:\n> Trust-minimization of Bitcoin security model has always relied first and\n> above on running a full-node. This current paradigm may be shifted by LN\n> where fast, affordable, confidential, censorship-resistant payment services\n> may attract a lot of adoption without users running a full-node.\n\nNo, it cannot be shifted. This would compromise Bitcoin itself, which for \nsecurity depends on the assumption that a supermajority of the economy is \nverifying their incoming transactions using their own full node.\n\nThe past few years has seen severe regressions in this area, to the point \nwhere Bitcoin's future seems quite bleak. Without serious improvements to the \nfull node ratio, Bitcoin is likely to fail.\n\nTherefore, all efforts to improve the \"full node-less\" experience are harmful, \nand should be actively avoided. BIP 157 improves privacy of fn-less usage, \nwhile providing no real benefits to full node users (compared to more \nefficient protocols like Stratum/Electrum).\n\nFor this reason, myself and a few others oppose merging support for BIP 157 in \nCore.\n\n> Assuming a user adoption path where a full-node is required to benefit for\n> LN may deprive a lot of users, especially those who are already denied a\n> real financial infrastructure access.\n\nIf Bitcoin can't do it, then Bitcoin can't do it.\nBitcoin can't solve *any* problem if it becomes insecure itself.\n\nLuke\n\nP.S. See also\nhttps://medium.com/@nicolasdorier/why-i-dont-celebrate-neutrino-206bafa5fda0\nhttps://medium.com/@nicolasdorier/neutrino-is-dangerous-for-my-self-sovereignty-18fac5bcdc25"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-05T13:49:58",
                "message_text_only": "Good morning ariard and luke-jr\n\n\n> > Trust-minimization of Bitcoin security model has always relied first and\n> > above on running a full-node. This current paradigm may be shifted by LN\n> > where fast, affordable, confidential, censorship-resistant payment services\n> > may attract a lot of adoption without users running a full-node.\n>\n> No, it cannot be shifted. This would compromise Bitcoin itself, which for\n> security depends on the assumption that a supermajority of the economy is\n> verifying their incoming transactions using their own full node.\n>\n> The past few years has seen severe regressions in this area, to the point\n> where Bitcoin's future seems quite bleak. Without serious improvements to the\n> full node ratio, Bitcoin is likely to fail.\n>\n> Therefore, all efforts to improve the \"full node-less\" experience are harmful,\n> and should be actively avoided. BIP 157 improves privacy of fn-less usage,\n> while providing no real benefits to full node users (compared to more\n> efficient protocols like Stratum/Electrum).\n>\n> For this reason, myself and a few others oppose merging support for BIP 157 in\n> Core.\n\nBIP 157 can be implemented as a separate daemon that processes the blocks downloaded by an attached `bitcoind`, i.e. what Wasabi does.\n\nThe intention, as I understood it, of putting BIP157 directly into bitcoind was to essentially force all `bitcoind` users to possibly service BIP157 clients, in the hope that a BIP157 client can contact any arbitrary fullnode to get BIP157 service.\nThis is supposed to improve to the situation relative to e.g. Electrum, where there are far fewer Electrum servers than fullnodes.\n\nOf course, as ariard computes, deploying BIP157 could lead to an effective DDoS on the fullnode network if a large number of BIP157 clients arise.\nThough maybe this will not occur very fast?  We hope?\n\nIt seems to me that the thing that *could* be done would be to have watchtowers provide light-client services, since that seems to be the major business model of watchtowers, as suggested by ariard as well.\nThis is still less than ideal, but maybe is better than nothing.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "John Newbery",
                "date": "2020-05-05T17:16:30",
                "message_text_only": "There doesn't seem to be anything in the original email that's specific to\nBIP 157. It's a restatement of the arguments against light clients:\n\n- light clients are a burden on the full nodes that serve them\n- if light clients become more popular, there won't be enough full nodes to\nserve them\n- people might build products that depend on altruistic nodes serving data,\nwhich is unsustainable\n- maybe at some point in the future, light clients will need to pay for\nservices\n\nThe choice isn't between people using light clients or not. People already\nuse light clients. The choice between whether we offer them a light client\ntechnology that is better or worse for privacy and scalability.\n\nThe arguments for why BIP 157 is better than the existing light client\ntechnologies are available elsewhere, but to summarize:\n\n- they're unique for a block, which means they can easily be cached.\nServing a filter requires no computation, just i/o (or memory access for\ncached filter/header data) and bandwidth. There are plenty of other\nservices that a full node offers that use i/o and bandwidth, such as\nserving blocks.\n- unique-for-block means clients can download from multiple sources\n- the linked-headers/filters model allows hybrid approaches, where headers\ncheckpoints can be fetched from trusted/signed nodes, with intermediate\nheaders and filters fetched from untrusted sources\n- less possibilities to DoS/waste resources on the serving node\n- better for privacy\n\n> The intention, as I understood it, of putting BIP157 directly into\nbitcoind was to essentially force all `bitcoind` users to possibly service\nBIP157 clients\n\nPlease. No-one is forcing anyone to do anything. To serve filters, a node\nuser needs to download the latest version, set `-blockfilterindex=basic` to\nbuild the compact filters index, and set `-peercfilters` to serve them over\nP2P. This is an optional, off-by-default feature.\n\nRegards,\nJohn\n\n\nOn Tue, May 5, 2020 at 9:50 AM ZmnSCPxj via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning ariard and luke-jr\n>\n>\n> > > Trust-minimization of Bitcoin security model has always relied first\n> and\n> > > above on running a full-node. This current paradigm may be shifted by\n> LN\n> > > where fast, affordable, confidential, censorship-resistant payment\n> services\n> > > may attract a lot of adoption without users running a full-node.\n> >\n> > No, it cannot be shifted. This would compromise Bitcoin itself, which for\n> > security depends on the assumption that a supermajority of the economy is\n> > verifying their incoming transactions using their own full node.\n> >\n> > The past few years has seen severe regressions in this area, to the point\n> > where Bitcoin's future seems quite bleak. Without serious improvements\n> to the\n> > full node ratio, Bitcoin is likely to fail.\n> >\n> > Therefore, all efforts to improve the \"full node-less\" experience are\n> harmful,\n> > and should be actively avoided. BIP 157 improves privacy of fn-less\n> usage,\n> > while providing no real benefits to full node users (compared to more\n> > efficient protocols like Stratum/Electrum).\n> >\n> > For this reason, myself and a few others oppose merging support for BIP\n> 157 in\n> > Core.\n>\n> BIP 157 can be implemented as a separate daemon that processes the blocks\n> downloaded by an attached `bitcoind`, i.e. what Wasabi does.\n>\n> The intention, as I understood it, of putting BIP157 directly into\n> bitcoind was to essentially force all `bitcoind` users to possibly service\n> BIP157 clients, in the hope that a BIP157 client can contact any arbitrary\n> fullnode to get BIP157 service.\n> This is supposed to improve to the situation relative to e.g. Electrum,\n> where there are far fewer Electrum servers than fullnodes.\n>\n> Of course, as ariard computes, deploying BIP157 could lead to an effective\n> DDoS on the fullnode network if a large number of BIP157 clients arise.\n> Though maybe this will not occur very fast?  We hope?\n>\n> It seems to me that the thing that *could* be done would be to have\n> watchtowers provide light-client services, since that seems to be the major\n> business model of watchtowers, as suggested by ariard as well.\n> This is still less than ideal, but maybe is better than nothing.\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200505/be23bd38/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-06T09:21:17",
                "message_text_only": "> The choice between whether we offer them a light client technology that\nis better or worse for privacy and scalability.\n\nAnd offer them a solution which would scale in the long-term.\n\nAgain it's not an argumentation against BIP 157 protocol in itself, the\nproblem I'm interested in is how implementing BIP157 in Core will address\nthis issue ?\n\nLe mar. 5 mai 2020 \u00e0 13:36, John Newbery via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n> There doesn't seem to be anything in the original email that's specific to\n> BIP 157. It's a restatement of the arguments against light clients:\n>\n> - light clients are a burden on the full nodes that serve them\n> - if light clients become more popular, there won't be enough full nodes\n> to serve them\n> - people might build products that depend on altruistic nodes serving\n> data, which is unsustainable\n> - maybe at some point in the future, light clients will need to pay for\n> services\n>\n> The choice isn't between people using light clients or not. People already\n> use light clients. The choice between whether we offer them a light client\n> technology that is better or worse for privacy and scalability.\n>\n> The arguments for why BIP 157 is better than the existing light client\n> technologies are available elsewhere, but to summarize:\n>\n> - they're unique for a block, which means they can easily be cached.\n> Serving a filter requires no computation, just i/o (or memory access for\n> cached filter/header data) and bandwidth. There are plenty of other\n> services that a full node offers that use i/o and bandwidth, such as\n> serving blocks.\n> - unique-for-block means clients can download from multiple sources\n> - the linked-headers/filters model allows hybrid approaches, where headers\n> checkpoints can be fetched from trusted/signed nodes, with intermediate\n> headers and filters fetched from untrusted sources\n> - less possibilities to DoS/waste resources on the serving node\n> - better for privacy\n>\n> > The intention, as I understood it, of putting BIP157 directly into\n> bitcoind was to essentially force all `bitcoind` users to possibly service\n> BIP157 clients\n>\n> Please. No-one is forcing anyone to do anything. To serve filters, a node\n> user needs to download the latest version, set `-blockfilterindex=basic` to\n> build the compact filters index, and set `-peercfilters` to serve them over\n> P2P. This is an optional, off-by-default feature.\n>\n> Regards,\n> John\n>\n>\n> On Tue, May 5, 2020 at 9:50 AM ZmnSCPxj via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Good morning ariard and luke-jr\n>>\n>>\n>> > > Trust-minimization of Bitcoin security model has always relied first\n>> and\n>> > > above on running a full-node. This current paradigm may be shifted by\n>> LN\n>> > > where fast, affordable, confidential, censorship-resistant payment\n>> services\n>> > > may attract a lot of adoption without users running a full-node.\n>> >\n>> > No, it cannot be shifted. This would compromise Bitcoin itself, which\n>> for\n>> > security depends on the assumption that a supermajority of the economy\n>> is\n>> > verifying their incoming transactions using their own full node.\n>> >\n>> > The past few years has seen severe regressions in this area, to the\n>> point\n>> > where Bitcoin's future seems quite bleak. Without serious improvements\n>> to the\n>> > full node ratio, Bitcoin is likely to fail.\n>> >\n>> > Therefore, all efforts to improve the \"full node-less\" experience are\n>> harmful,\n>> > and should be actively avoided. BIP 157 improves privacy of fn-less\n>> usage,\n>> > while providing no real benefits to full node users (compared to more\n>> > efficient protocols like Stratum/Electrum).\n>> >\n>> > For this reason, myself and a few others oppose merging support for BIP\n>> 157 in\n>> > Core.\n>>\n>> BIP 157 can be implemented as a separate daemon that processes the blocks\n>> downloaded by an attached `bitcoind`, i.e. what Wasabi does.\n>>\n>> The intention, as I understood it, of putting BIP157 directly into\n>> bitcoind was to essentially force all `bitcoind` users to possibly service\n>> BIP157 clients, in the hope that a BIP157 client can contact any arbitrary\n>> fullnode to get BIP157 service.\n>> This is supposed to improve to the situation relative to e.g. Electrum,\n>> where there are far fewer Electrum servers than fullnodes.\n>>\n>> Of course, as ariard computes, deploying BIP157 could lead to an\n>> effective DDoS on the fullnode network if a large number of BIP157 clients\n>> arise.\n>> Though maybe this will not occur very fast?  We hope?\n>>\n>> It seems to me that the thing that *could* be done would be to have\n>> watchtowers provide light-client services, since that seems to be the major\n>> business model of watchtowers, as suggested by ariard as well.\n>> This is still less than ideal, but maybe is better than nothing.\n>>\n>> Regards,\n>> ZmnSCPxj\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200506/8f7f3555/attachment.html>"
            },
            {
                "author": "Lloyd Fournier",
                "date": "2020-05-05T15:16:01",
                "message_text_only": "On Tue, May 5, 2020 at 9:01 PM Luke Dashjr via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Tuesday 05 May 2020 10:17:37 Antoine Riard via bitcoin-dev wrote:\n> > Trust-minimization of Bitcoin security model has always relied first and\n> > above on running a full-node. This current paradigm may be shifted by LN\n> > where fast, affordable, confidential, censorship-resistant payment\n> services\n> > may attract a lot of adoption without users running a full-node.\n>\n> No, it cannot be shifted. This would compromise Bitcoin itself, which for\n> security depends on the assumption that a supermajority of the economy is\n> verifying their incoming transactions using their own full node.\n>\n\nHi Luke,\n\nI have heard this claim made several times but have never understood the\nargument behind it. The question I always have is: If I get scammed by not\nverifying my incoming transactions properly how can this affect anyone\nelse? It's very unintuative.  I've been scammed several times in my life in\nfiat currency transactions but as far as I could tell it never negatively\naffected the currency overall!\n\nThe links you point and from what I've seen you say before refer to \"miner\ncontrol\" as the culprit. My only thought is that this is because a light\nclient could follow a dishonest majority of hash power chain. But this just\nbrings me back to the question. If, instead of BTC, I get a payment in some\nminer scamcoin on their dishonest fork (but I think it's BTC because I'm\nrunning a light client) that still seems to only to damage me. Where does\nthe side effect onto others on the network come from?\n\nCheers,\n\nLL\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200505/549643a3/attachment.html>"
            },
            {
                "author": "Chris Belcher",
                "date": "2020-05-12T21:05:46",
                "message_text_only": "On 05/05/2020 16:16, Lloyd Fournier via bitcoin-dev wrote:\n> On Tue, May 5, 2020 at 9:01 PM Luke Dashjr via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n>> On Tuesday 05 May 2020 10:17:37 Antoine Riard via bitcoin-dev wrote:\n>>> Trust-minimization of Bitcoin security model has always relied first and\n>>> above on running a full-node. This current paradigm may be shifted by LN\n>>> where fast, affordable, confidential, censorship-resistant payment\n>> services\n>>> may attract a lot of adoption without users running a full-node.\n>>\n>> No, it cannot be shifted. This would compromise Bitcoin itself, which for\n>> security depends on the assumption that a supermajority of the economy is\n>> verifying their incoming transactions using their own full node.\n>>\n> \n> Hi Luke,\n> \n> I have heard this claim made several times but have never understood the\n> argument behind it. The question I always have is: If I get scammed by not\n> verifying my incoming transactions properly how can this affect anyone\n> else? It's very unintuative.  I've been scammed several times in my life in\n> fiat currency transactions but as far as I could tell it never negatively\n> affected the currency overall!\n> \n> The links you point and from what I've seen you say before refer to \"miner\n> control\" as the culprit. My only thought is that this is because a light\n> client could follow a dishonest majority of hash power chain. But this just\n> brings me back to the question. If, instead of BTC, I get a payment in some\n> miner scamcoin on their dishonest fork (but I think it's BTC because I'm\n> running a light client) that still seems to only to damage me. Where does\n> the side effect onto others on the network come from?\n> \n> Cheers,\n> \n> LL\n> \n\nHello Lloyd,\n\nThe problem comes when a large part of the ecosystem gets scammed at\nonce, which is how such an attack would happen in practice.\n\nFor example, consider if bitcoin had 10000 users. 10 of them use a full\nnode wallet while the other 9990 use an SPV wallet. If a miner attacked\nthe system by printing infinite bitcoins and spending coins without a\nvalid signature, then the 9990 SPV wallets would accept those fake coins\nas payment, and trade the coins amongst themselves. After a time those\ncoins would likely be the ancestors of most active coins in the\n9990-SPV-wallet ecosystem. Bitcoin would split into two currencies:\nfull-node-coin and SPV-coin.\n\nNow the fraud miners may become well known, perhaps being published on\nbitcoin news portals, but the 9990-SPV-wallet ecosystem has a strong\nincentive to be against any rollback. Their recent transactions would\ndisappear and they'd lose money. They would argue that they've already\nbeen using the coin for a while, and it works perfectly fine, and anyway\na coin that can be spent in 9990 places is more useful than one that can\nbe spent in just 10 places. The SPV-wallet community might even decide\nto use something like `invalidateblock` to make sure their SPV-coin\ndoesn't get reorg'd out of existence. There'd also likely be a social\nattack, with every bitcoin community portal being flooded with bots and\nshills advocating the merits of SPV-coin. This is not a hypothetical\nbecause we already saw the same thing during the scalability conflict\n2015-2017.\n\nBefore you know it, \"Bitcoin\" would become SPV-coin with inflation and\narbitrary seizure. Any normal user could download software called\n\"Bitcoin wallet\" which they trust and have used before, but instead of\nusing Bitcoin they'd be using SPV-coin. You may be one of the 10 wallets\nbacked by a full node, but that won't do much good to you when 9990\nusers happily use another coin as their medium of exchange.\n\nRegards\nCB"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-13T19:51:29",
                "message_text_only": "Hi Chris,\n\nWhile approaching this question, I think you should consider economic\nweight of nodes in evaluating miner consensus-hijack success. Even if you\nexpect a disproportionate ratio of full-nodes-vs-SPV, they may not have the\nsame  economic weight at all, therefore even if miners are able to lure a\nmajority of SPV clients they may not be able to stir economic nodes. SPV\nclients users will now have an incentive to cancel their hijacked history\nto stay on the most economic meaningful chain. And it's already assumed,\nthat if you run a bitcoin business or LN routing node, you do want to run\nyour own full-node.\n\nI agree it may be hard to evaluate economic-weight-to-chain-backend\nsegments, specially with offchain you disentangle an onchain output value\nfrom its real payment traffic. To strengthen SPV, you may implement forks\ndetection and fallback to some backup node(s) which would serve as an\nauthoritative source to arbiter between branches. Such backup node(s) must\nbe picked up manually at client initialization, before any risk of conflict\nto avoid Reddit-style of hijack during contentious period or other massive\nsocial engineering. You don't want autopilot-style of recommendations for\npicking up a backup nodes and avoid cenralization of backups, but somehow a\nuniform distribution. A backup node may be a private one, it won't serve\nyou any data beyond headers, and therefore you preserve public nodes\nbandwidth, which IMO is the real bottleneck. I concede it won't work well\nif you have a ratio of 1000-SPV for 1-full-node and people are not\neffectively able to pickup a backup among their social environment.\n\nWhat do you think about this model ?\n\nCheers,\n\nAntoine\n\nLe mar. 12 mai 2020 \u00e0 17:06, Chris Belcher <belcher at riseup.net> a \u00e9crit :\n\n> On 05/05/2020 16:16, Lloyd Fournier via bitcoin-dev wrote:\n> > On Tue, May 5, 2020 at 9:01 PM Luke Dashjr via bitcoin-dev <\n> > bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >\n> >> On Tuesday 05 May 2020 10:17:37 Antoine Riard via bitcoin-dev wrote:\n> >>> Trust-minimization of Bitcoin security model has always relied first\n> and\n> >>> above on running a full-node. This current paradigm may be shifted by\n> LN\n> >>> where fast, affordable, confidential, censorship-resistant payment\n> >> services\n> >>> may attract a lot of adoption without users running a full-node.\n> >>\n> >> No, it cannot be shifted. This would compromise Bitcoin itself, which\n> for\n> >> security depends on the assumption that a supermajority of the economy\n> is\n> >> verifying their incoming transactions using their own full node.\n> >>\n> >\n> > Hi Luke,\n> >\n> > I have heard this claim made several times but have never understood the\n> > argument behind it. The question I always have is: If I get scammed by\n> not\n> > verifying my incoming transactions properly how can this affect anyone\n> > else? It's very unintuative.  I've been scammed several times in my life\n> in\n> > fiat currency transactions but as far as I could tell it never negatively\n> > affected the currency overall!\n> >\n> > The links you point and from what I've seen you say before refer to\n> \"miner\n> > control\" as the culprit. My only thought is that this is because a light\n> > client could follow a dishonest majority of hash power chain. But this\n> just\n> > brings me back to the question. If, instead of BTC, I get a payment in\n> some\n> > miner scamcoin on their dishonest fork (but I think it's BTC because I'm\n> > running a light client) that still seems to only to damage me. Where does\n> > the side effect onto others on the network come from?\n> >\n> > Cheers,\n> >\n> > LL\n> >\n>\n> Hello Lloyd,\n>\n> The problem comes when a large part of the ecosystem gets scammed at\n> once, which is how such an attack would happen in practice.\n>\n> For example, consider if bitcoin had 10000 users. 10 of them use a full\n> node wallet while the other 9990 use an SPV wallet. If a miner attacked\n> the system by printing infinite bitcoins and spending coins without a\n> valid signature, then the 9990 SPV wallets would accept those fake coins\n> as payment, and trade the coins amongst themselves. After a time those\n> coins would likely be the ancestors of most active coins in the\n> 9990-SPV-wallet ecosystem. Bitcoin would split into two currencies:\n> full-node-coin and SPV-coin.\n>\n> Now the fraud miners may become well known, perhaps being published on\n> bitcoin news portals, but the 9990-SPV-wallet ecosystem has a strong\n> incentive to be against any rollback. Their recent transactions would\n> disappear and they'd lose money. They would argue that they've already\n> been using the coin for a while, and it works perfectly fine, and anyway\n> a coin that can be spent in 9990 places is more useful than one that can\n> be spent in just 10 places. The SPV-wallet community might even decide\n> to use something like `invalidateblock` to make sure their SPV-coin\n> doesn't get reorg'd out of existence. There'd also likely be a social\n> attack, with every bitcoin community portal being flooded with bots and\n> shills advocating the merits of SPV-coin. This is not a hypothetical\n> because we already saw the same thing during the scalability conflict\n> 2015-2017.\n>\n> Before you know it, \"Bitcoin\" would become SPV-coin with inflation and\n> arbitrary seizure. Any normal user could download software called\n> \"Bitcoin wallet\" which they trust and have used before, but instead of\n> using Bitcoin they'd be using SPV-coin. You may be one of the 10 wallets\n> backed by a full node, but that won't do much good to you when 9990\n> users happily use another coin as their medium of exchange.\n>\n> Regards\n> CB\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200513/91739e5e/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-14T04:02:07",
                "message_text_only": "Good morning Antoine,\n\n\n> While approaching this question, I think you should consider economic weight of nodes in evaluating miner consensus-hijack success. Even if you expect a disproportionate ratio of full-nodes-vs-SPV, they may not have the same \u00a0economic weight at all, therefore even if miners are able to lure a majority of SPV clients they may not be able to stir economic nodes. SPV clients users will now have an incentive to cancel their hijacked history to stay on the most economic meaningful chain. And it's already assumed, that if you run a bitcoin business or LN routing node, you do want to run your own full-node.\n\nOne hope I have for Lightning is that it will replace centralized custodial services, because:\n\n* Lightning gains some of the scalability advantage of centralized custodial services, because you can now transfer to any Lightning client without touching the blockchain, for much reduced transfer fees.\n* At the same time, it retains your-keys-your-coins noncustodiality, because every update of a Lightning channel requires your keys to sign off on it.\n\nIf most Lightning clients are SPV, then if we compare these two worlds:\n\n* There are a few highly-important centralized custodial services with significant economic weight running fullnodes (i.e. now).\n* There are no highly-important centralized custodial services, and most everyone uses Lightning, but with SPV (i.e. a Lightning future).\n\nThen the distribution of economic weight would be different between these two worlds.\nIt may even be possible, that the Lightning future with massive SPV might end up with more economic weight in SPV nodes, than in the world without Lightning and dependent on centralized custodial services to scale.\n\n\nIt is also entirely possible that custodial services for Lightning will arise anyway and my hope is already dashed, come on universe, work harder will you, would you really disappoint some randomly-generated Internet person like that.\n\n\n>\n> I agree it may be hard to evaluate economic-weight-to-chain-backend segments, specially with offchain you disentangle an onchain output value from its real payment traffic. To strengthen SPV, you may implement forks detection and fallback to some backup node(s) which would serve as an authoritative source to arbiter between branches. Such backup node(s) must be picked up manually at client initialization, before any risk of conflict to avoid Reddit-style of hijack during contentious period or other massive social engineering. You don't want autopilot-style of recommendations for picking up a backup nodes and avoid cenralization of backups, but somehow a uniform distribution. A backup node may be a private one, it won't serve you any data beyond headers, and therefore you preserve public nodes bandwidth, which IMO is the real bottleneck. I concede it won't work well if you have a ratio of 1000-SPV for 1-full-node and people are not effectively able to pickup a backup among their social environment.\n> What do you think about this model ?\n\nMoney makes the world go round, so such backup servers that are publicly-facing rather than privately-owned should be somehow incentivized to do so, or else they would not exist in the first place.\nOf course, a free market tends towards monopoly, because any entity that happens to have even a slight advantage at the business will have more money to use towards business reinvestment and increase its advantage further, until they beat the competition to dust, anyone who has won a 4X game knows to search for and stack those little advantages until you snowball and conquer the world/galaxy/petri dish which is why the endgame of 4X games is so boring compared to the start, we have seen this happen in mining and exchanges and so on, and this works against your desire to have a uniform distribution.\n\nIf everyone runs such a privately-owned server, on the other hand, this is not so different from having a Lightning node you run at your home that has a fullnode as well and which you access via a remote control mobile device, and it is the inconvenience of having such a server at your home that prevents this in the first place.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Orfeas Stefanos Thyfronitis Litos",
                "date": "2020-05-14T06:08:13",
                "message_text_only": ">If everyone runs such a privately-owned server, on the other hand, this\n>is not so different from having a Lightning node you run at your home\n>that has a fullnode as well and which you access via a remote control\n>mobile device, and it is the inconvenience of having such a server at\n>your home that prevents this in the first place.\n\nPrivate full nodes serving headers to a handful of weak devices have been mentioned many times as a good solution against all sorts of problems in a future full of LN + SPV nodes. I agree. It should be therefore a top priority to make the UX of connecting my mobile LN client to my home full node extremely easy, so that centralised services can't improve much on that step. Especially if I already run a full node.\n\nCould someone briefly describe how this UX looks currently? And if it's not as seamless as it could, what blockers are there?\n\nBest,\nOrfeas\n\n-- \nThe University of Edinburgh is a charitable body, registered in\nScotland, with registration number SC005336."
            },
            {
                "author": "Keagan McClelland",
                "date": "2020-05-14T15:25:57",
                "message_text_only": "> It should be therefore a top priority to make the UX of connecting my\nmobile LN client to my home full node extremely easy, so that centralised\nservices can't improve much on that step. Especially if I already run a\nfull node.\n\nFor what it's worth, this is a main research area for us at Start9 Labs.\n\n> Could someone briefly describe how this UX looks currently? And if it's\nnot as seamless as it could, what blockers are there?\n\nAt the root of all of these problems is that a \"private server\" is\nconsidered inconvenient. There is no fundamental reason this has to be the\ncase. The main UX challenges we've found are around installation and\nconfiguration of server applications, not to mention, that users don't have\nan existing mental model for how to imagine applications. Most people who\ndo not work on computers for a living have heard of servers but their\nfirsthand experience with software is \"apps\". The fact that there is a\ncomponent of their applications that runs remotely on computers they don't\nown.\n\nSo in short:\n1. Educating on the distinction between client and server apps is an open\nquestion whose burden will likely fall on the entire industry if we want to\nget this right and not have an exchange takeover of Bitcoin.\n2. Apps that either require \"zero configuration\" or have very easy in-app\nwalkthroughs of the bare essentials of configuration\n3. GUI style installs of server applications familiar to those who have\ninstalled desktop or mobile software.\n\nI'm sure there are more things we'll learn as we grow but these are the top\nthree observations we've made and this is our primary area of work.\n\n> Private full nodes serving headers to a handful of weak devices have been\nmentioned many times as a good solution against all sorts of problems in a\nfuture full of LN + SPV nodes. I agree.\n\nThis is the main thesis I've been going on for a while. Once your full node\nhas synced the whole blockchain and the total set of headers is known, you\ndon't actually even need to carry 100% of the block data, as you can\nre-fetch a needed block from elsewhere and verify the block data matches\nthe header you've already checked for consensus. From there the header\nchain can serve as base truth for a whole set of L2+ services or L1 SPV\nwallets. Ideally, in a model like this, more expensive peer services would\nbe authenticated so that your other applications could get the data they\nneed without exposing your full node to the extra costs of those who are\nnot running their own nodes. Typically we've used Core's RPC API for this\nbut as others have mentioned upthread JSON is a wasteful format and there\nare good reasons that you'd want Lightning to be able to request peer\nservices without necessarily having ownership control over the node.\n\nThe other thing I wanted to note is the fact that the issue isn't that\nLightning does SPV, the issue is around whether or not the node it is\ntethered to is *actually* trusted since SPV necessarily trusts some\ndimensions of the information supplied to it. Doing SPV against a full node\nyou own is no more dangerous than indexing watch only addresses in Core and\nthen asking for wallet/utxo information over RPC.\n\nKeagan\n\nOn Thu, May 14, 2020 at 12:50 AM Orfeas Stefanos Thyfronitis Litos <\no.thyfronitis at ed.ac.uk> wrote:\n\n>\n>\n> >If everyone runs such a privately-owned server, on the other hand, this\n> >is not so different from having a Lightning node you run at your home\n> >that has a fullnode as well and which you access via a remote control\n> >mobile device, and it is the inconvenience of having such a server at\n> >your home that prevents this in the first place.\n>\n> Private full nodes serving headers to a handful of weak devices have been\n> mentioned many times as a good solution against all sorts of problems in a\n> future full of LN + SPV nodes. I agree. It should be therefore a top\n> priority to make the UX of connecting my mobile LN client to my home full\n> node extremely easy, so that centralised services can't improve much on\n> that step. Especially if I already run a full node.\n>\n> Could someone briefly describe how this UX looks currently? And if it's\n> not as seamless as it could, what blockers are there?\n>\n> Best,\n> Orfeas\n>\n> --\n> The University of Edinburgh is a charitable body, registered in\n> Scotland, with registration number SC005336.\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200514/8cf2f0f1/attachment.html>"
            },
            {
                "author": "Christopher Allen",
                "date": "2020-05-17T09:11:33",
                "message_text_only": "On Thu, May 14, 2020 at 8:30 AM Keagan McClelland via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> > It should be therefore a top priority to make the UX of connecting my\n> mobile LN client to my home full node extremely easy, so that centralised\n> services can't improve much on that step. Especially if I already run a\n> full node.\n>\n\nThere already is an emerging approach for this, called QuickConnect\nhttps://github.com/BlockchainCommons/Bitcoin-Standup/blob/master/Docs/Quick-Connect-API.md\n\nIt is currently offered by BitcoinStandup (both Mac and Linux),\nBTCPayServer, Nodl, MyNode, RaspiBlitz full node tools and hardware, and is\nused currently by FullyNoded, FullyNoded2, and a couple of other\nexperimental apps to allow secure connection via Tor v3 from a remote to\nyour own personal full node.\n\nWe know that QuickConnect needs another major iteration and welcome\ncontributions to requirements and/or proposals for the next version.\n\nWe invite you to share your thoughts here.\nhttps://github.com/BlockchainCommons/Bitcoin-Standup/issues/66\n\n\u2014 Christopher Allen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200517/f483ba8b/attachment-0001.html>"
            },
            {
                "author": "William Casarin",
                "date": "2020-05-14T15:27:11",
                "message_text_only": "Orfeas Stefanos Thyfronitis Litos <o.thyfronitis at ed.ac.uk> writes:\n> ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> writes:\n>> If everyone runs such a privately-owned server, on the other hand, this\n>> is not so different from having a Lightning node you run at your home\n>> that has a fullnode as well and which you access via a remote control\n>> mobile device, and it is the inconvenience of having such a server at\n>> your home that prevents this in the first place.\n>\n> Private full nodes serving headers to a handful of weak devices have\n> been mentioned many times as a good solution against all sorts of\n> problems in a future full of LN + SPV nodes. I agree. It should be\n> therefore a top priority to make the UX of connecting my mobile LN\n> client to my home full node extremely easy, so that centralised\n> services can't improve much on that step. Especially if I already run\n> a full node.\n>\n> Could someone briefly describe how this UX looks currently? And if\n> it's not as seamless as it could, what blockers are there?\n\nThe UX for this doesn't have to be complicated. All you need is a node\nprovider like FullyNoded, Casa, etc. My setup at home is a desktop with:\n\n  - bitcoind\n  - clightning\n  - zerotier (or tailscale) (private vpn for connecting to your node from anywhere)\n  - sparkwallet (clightning webui) bound to a zerotier interface\n\nSo as long as you have a node that runs these bits of software, perhaps\nassumeutxo to speed up IBD, and a QR-code automagic setup, then UX\nshould be pretty smooth. You would still need to deal with lightning\nbackups and liquidity issues, but we just need to do more work on the\nsoftware side to make that experience nicer.\n\nCheers,\nWill\n\n\n--\nhttps://jb55.com"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-17T03:37:46",
                "message_text_only": "> * At the same time, it retains your-keys-your-coins noncustodiality,\nbecause every update of a Lightning channel requires your keys to sign off\non it.\n\nYes I agree, I can foresee an easier step where managing low-value channel\nand get your familiar with smooth key management maybe a first step before\nrunning a full-node and getting a more full-fledged key management solution.\n\n> It may even be possible, that the Lightning future with massive SPV might\nend up with more economic weight in SPV nodes, than in the world without\nLightning and dependent on centralized custodial services to scale.\n\nEven evaluating economic weight in Lightning is hard, both parties have\ntheir own chain view, and it's likely if you assume a hub-and-spoke\ntopology, leaf nodes are going to be SPV and internal nodes full-nodes ?\n\n> Money makes the world go round, so such backup servers that are\npublicly-facing rather than privately-owned should be somehow incentivized\nto do so, or else they would not exist in the first place.\n\nI was thinking about the current workflow, Alice downloads her New Shiny\nLN-wallet, she is asked to backup the seed, she is asked to pick-up\nbackup(s) nodes among her friends, relatives or business partners and is\nNOT provided any automatic hint and register backup nodes addresses, maybe\neven do out-of-band key exchange with this full-node operator. Therefore\nyou may avoid centralization by having not such publicly-facing servers. Of\ncourse, Alice can still scrawl the web to and be lured to pickup malicious\npublic servers but if she is severely notified to not do so that may be\nenough.\n\nSo it would be a combination of UX+user education+fallback security\nmechanism to avoid economy hijack. That maybe a better solution rather than\nPoW-only SPV. We have an open network so you can't prevent someone to run\nsuch type of client but at least if they have to do so you can provide them\nwith a better option ?\n\nAntoine\n\n\n\n\nLe jeu. 14 mai 2020 \u00e0 00:02, ZmnSCPxj <ZmnSCPxj at protonmail.com> a \u00e9crit :\n\n> Good morning Antoine,\n>\n>\n> > While approaching this question, I think you should consider economic\n> weight of nodes in evaluating miner consensus-hijack success. Even if you\n> expect a disproportionate ratio of full-nodes-vs-SPV, they may not have the\n> same  economic weight at all, therefore even if miners are able to lure a\n> majority of SPV clients they may not be able to stir economic nodes. SPV\n> clients users will now have an incentive to cancel their hijacked history\n> to stay on the most economic meaningful chain. And it's already assumed,\n> that if you run a bitcoin business or LN routing node, you do want to run\n> your own full-node.\n>\n> One hope I have for Lightning is that it will replace centralized\n> custodial services, because:\n>\n> * Lightning gains some of the scalability advantage of centralized\n> custodial services, because you can now transfer to any Lightning client\n> without touching the blockchain, for much reduced transfer fees.\n> * At the same time, it retains your-keys-your-coins noncustodiality,\n> because every update of a Lightning channel requires your keys to sign off\n> on it.\n>\n> If most Lightning clients are SPV, then if we compare these two worlds:\n>\n> * There are a few highly-important centralized custodial services with\n> significant economic weight running fullnodes (i.e. now).\n> * There are no highly-important centralized custodial services, and most\n> everyone uses Lightning, but with SPV (i.e. a Lightning future).\n>\n> Then the distribution of economic weight would be different between these\n> two worlds.\n> It may even be possible, that the Lightning future with massive SPV might\n> end up with more economic weight in SPV nodes, than in the world without\n> Lightning and dependent on centralized custodial services to scale.\n>\n>\n> It is also entirely possible that custodial services for Lightning will\n> arise anyway and my hope is already dashed, come on universe, work harder\n> will you, would you really disappoint some randomly-generated Internet\n> person like that.\n>\n>\n> >\n> > I agree it may be hard to evaluate economic-weight-to-chain-backend\n> segments, specially with offchain you disentangle an onchain output value\n> from its real payment traffic. To strengthen SPV, you may implement forks\n> detection and fallback to some backup node(s) which would serve as an\n> authoritative source to arbiter between branches. Such backup node(s) must\n> be picked up manually at client initialization, before any risk of conflict\n> to avoid Reddit-style of hijack during contentious period or other massive\n> social engineering. You don't want autopilot-style of recommendations for\n> picking up a backup nodes and avoid cenralization of backups, but somehow a\n> uniform distribution. A backup node may be a private one, it won't serve\n> you any data beyond headers, and therefore you preserve public nodes\n> bandwidth, which IMO is the real bottleneck. I concede it won't work well\n> if you have a ratio of 1000-SPV for 1-full-node and people are not\n> effectively able to pickup a backup among their social environment.\n> > What do you think about this model ?\n>\n> Money makes the world go round, so such backup servers that are\n> publicly-facing rather than privately-owned should be somehow incentivized\n> to do so, or else they would not exist in the first place.\n> Of course, a free market tends towards monopoly, because any entity that\n> happens to have even a slight advantage at the business will have more\n> money to use towards business reinvestment and increase its advantage\n> further, until they beat the competition to dust, anyone who has won a 4X\n> game knows to search for and stack those little advantages until you\n> snowball and conquer the world/galaxy/petri dish which is why the endgame\n> of 4X games is so boring compared to the start, we have seen this happen in\n> mining and exchanges and so on, and this works against your desire to have\n> a uniform distribution.\n>\n> If everyone runs such a privately-owned server, on the other hand, this is\n> not so different from having a Lightning node you run at your home that has\n> a fullnode as well and which you access via a remote control mobile device,\n> and it is the inconvenience of having such a server at your home that\n> prevents this in the first place.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200516/5aa4025e/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-06T09:06:11",
                "message_text_only": "I do see the consensus capture argument by miners but in reality isn't this\nattack scenario have a lot of assumptions on topology an deployment ?\n\nFor such attack to succeed you need miners nodes to be connected to clients\nto feed directly the invalid headers and if these ones are connected to\nheaders/filters gateways, themselves doing full-nodes validation invalid\nchain is going to be sanitized out ?\n\nSure now you trust these gateways, but if you have multiple connections to\nthem and can guarantee they aren't run by the same entity, that maybe an\nacceptable security model, depending of staked amount and your\nexpectations. I more concerned of having a lot of them and being\ndiversified enough to avoid collusion between gateways/chain access\nproviders/miners.\n\nBut even if you light clients is directly connected to the backbone network\nand may be reached by miners you can implement fork anomalies detection and\nfrom then you may have multiples options:\n* halt the wallet, wait for human intervention\n* fallback connection to a trusted server, authoritative on your chain view\n* invalidity proofs?\n\nNow I agree you need a wide-enough, sane backbone network to build on top,\nand we should foster node adoption as much as we can.\n\nLe mar. 5 mai 2020 \u00e0 09:01, Luke Dashjr <luke at dashjr.org> a \u00e9crit :\n\n> On Tuesday 05 May 2020 10:17:37 Antoine Riard via bitcoin-dev wrote:\n> > Trust-minimization of Bitcoin security model has always relied first and\n> > above on running a full-node. This current paradigm may be shifted by LN\n> > where fast, affordable, confidential, censorship-resistant payment\n> services\n> > may attract a lot of adoption without users running a full-node.\n>\n> No, it cannot be shifted. This would compromise Bitcoin itself, which for\n> security depends on the assumption that a supermajority of the economy is\n> verifying their incoming transactions using their own full node.\n>\n> The past few years has seen severe regressions in this area, to the point\n> where Bitcoin's future seems quite bleak. Without serious improvements to\n> the\n> full node ratio, Bitcoin is likely to fail.\n>\n> Therefore, all efforts to improve the \"full node-less\" experience are\n> harmful,\n> and should be actively avoided. BIP 157 improves privacy of fn-less usage,\n> while providing no real benefits to full node users (compared to more\n> efficient protocols like Stratum/Electrum).\n>\n> For this reason, myself and a few others oppose merging support for BIP\n> 157 in\n> Core.\n>\n> > Assuming a user adoption path where a full-node is required to benefit\n> for\n> > LN may deprive a lot of users, especially those who are already denied a\n> > real financial infrastructure access.\n>\n> If Bitcoin can't do it, then Bitcoin can't do it.\n> Bitcoin can't solve *any* problem if it becomes insecure itself.\n>\n> Luke\n>\n> P.S. See also\n>\n> https://medium.com/@nicolasdorier/why-i-dont-celebrate-neutrino-206bafa5fda0\n>\n> https://medium.com/@nicolasdorier/neutrino-is-dangerous-for-my-self-sovereignty-18fac5bcdc25\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200506/7b20c4d4/attachment.html>"
            },
            {
                "author": "Keagan McClelland",
                "date": "2020-05-06T16:00:15",
                "message_text_only": "Hi Antoine,\n\nConsensus capture by miners isn't the only concern here. Consensus capture\nby any subset of users whose interests diverge from the overall consensus\nis equally damaging. The scenario I can imagine here is that the more light\nclients outpace full nodes, the more the costs of security are being\nexternalized from the light clients onto the full nodes. In this situation,\nit can make full nodes harder to run. If they are harder to run it will\nprice out some marginal set of full node operators, which causes a net new\nincrease in light clients (as the disaffected full nodes convert), AND a\nredistribution of load onto a smaller surface area. This is a naturally\nunstable process. It is safe to say that as node counts drop, the set of\nnode operators will increasingly represent economic actors with extreme\nweight. The more this process unfolds, the more likely their interests will\ndiverge from the population at large, and also the more likely they can be\ncoerced into behavior they otherwise wouldn't. After all it is easier to\nfind agents who carry lots of economic weight. This is true independent of\ntheir mining status, we should be just as wary of consensus capture by\nexchanges or HNWI's as we are about miners.\n\nKeagan\n\nOn Wed, May 6, 2020 at 3:06 AM Antoine Riard <antoine.riard at gmail.com>\nwrote:\n\n> I do see the consensus capture argument by miners but in reality isn't\n> this attack scenario have a lot of assumptions on topology an deployment ?\n>\n> For such attack to succeed you need miners nodes to be connected to\n> clients to feed directly the invalid headers and if these ones are\n> connected to headers/filters gateways, themselves doing full-nodes\n> validation invalid chain is going to be sanitized out ?\n>\n> Sure now you trust these gateways, but if you have multiple connections to\n> them and can guarantee they aren't run by the same entity, that maybe an\n> acceptable security model, depending of staked amount and your\n> expectations. I more concerned of having a lot of them and being\n> diversified enough to avoid collusion between gateways/chain access\n> providers/miners.\n>\n> But even if you light clients is directly connected to the backbone\n> network and may be reached by miners you can implement fork anomalies\n> detection and from then you may have multiples options:\n> * halt the wallet, wait for human intervention\n> * fallback connection to a trusted server, authoritative on your chain view\n> * invalidity proofs?\n>\n> Now I agree you need a wide-enough, sane backbone network to build on top,\n> and we should foster node adoption as much as we can.\n>\n> Le mar. 5 mai 2020 \u00e0 09:01, Luke Dashjr <luke at dashjr.org> a \u00e9crit :\n>\n>> On Tuesday 05 May 2020 10:17:37 Antoine Riard via bitcoin-dev wrote:\n>> > Trust-minimization of Bitcoin security model has always relied first and\n>> > above on running a full-node. This current paradigm may be shifted by LN\n>> > where fast, affordable, confidential, censorship-resistant payment\n>> services\n>> > may attract a lot of adoption without users running a full-node.\n>>\n>> No, it cannot be shifted. This would compromise Bitcoin itself, which for\n>> security depends on the assumption that a supermajority of the economy is\n>> verifying their incoming transactions using their own full node.\n>>\n>> The past few years has seen severe regressions in this area, to the point\n>> where Bitcoin's future seems quite bleak. Without serious improvements to\n>> the\n>> full node ratio, Bitcoin is likely to fail.\n>>\n>> Therefore, all efforts to improve the \"full node-less\" experience are\n>> harmful,\n>> and should be actively avoided. BIP 157 improves privacy of fn-less\n>> usage,\n>> while providing no real benefits to full node users (compared to more\n>> efficient protocols like Stratum/Electrum).\n>>\n>> For this reason, myself and a few others oppose merging support for BIP\n>> 157 in\n>> Core.\n>>\n>> > Assuming a user adoption path where a full-node is required to benefit\n>> for\n>> > LN may deprive a lot of users, especially those who are already denied a\n>> > real financial infrastructure access.\n>>\n>> If Bitcoin can't do it, then Bitcoin can't do it.\n>> Bitcoin can't solve *any* problem if it becomes insecure itself.\n>>\n>> Luke\n>>\n>> P.S. See also\n>>\n>> https://medium.com/@nicolasdorier/why-i-dont-celebrate-neutrino-206bafa5fda0\n>>\n>> https://medium.com/@nicolasdorier/neutrino-is-dangerous-for-my-self-sovereignty-18fac5bcdc25\n>>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200506/ce5bff4d/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-07T03:56:17",
                "message_text_only": "What I'm thinking more is if the costs of security are being too much\nexternalized from the light clients onto full nodes, nodes operators are\njust going to stop servicing light clients `peercfilters=false`. The\nbackbone p2p network is going to be fine. But the massive LN light clients\nnetwork built on top is going to rely on centralized services for its chain\naccess and now you may have consensus capture by those..\n\nLe mer. 6 mai 2020 \u00e0 12:00, Keagan McClelland <keagan.mcclelland at gmail.com>\na \u00e9crit :\n\n> Hi Antoine,\n>\n> Consensus capture by miners isn't the only concern here. Consensus capture\n> by any subset of users whose interests diverge from the overall consensus\n> is equally damaging. The scenario I can imagine here is that the more light\n> clients outpace full nodes, the more the costs of security are being\n> externalized from the light clients onto the full nodes. In this situation,\n> it can make full nodes harder to run. If they are harder to run it will\n> price out some marginal set of full node operators, which causes a net new\n> increase in light clients (as the disaffected full nodes convert), AND a\n> redistribution of load onto a smaller surface area. This is a naturally\n> unstable process. It is safe to say that as node counts drop, the set of\n> node operators will increasingly represent economic actors with extreme\n> weight. The more this process unfolds, the more likely their interests will\n> diverge from the population at large, and also the more likely they can be\n> coerced into behavior they otherwise wouldn't. After all it is easier to\n> find agents who carry lots of economic weight. This is true independent of\n> their mining status, we should be just as wary of consensus capture by\n> exchanges or HNWI's as we are about miners.\n>\n> Keagan\n>\n> On Wed, May 6, 2020 at 3:06 AM Antoine Riard <antoine.riard at gmail.com>\n> wrote:\n>\n>> I do see the consensus capture argument by miners but in reality isn't\n>> this attack scenario have a lot of assumptions on topology an deployment ?\n>>\n>> For such attack to succeed you need miners nodes to be connected to\n>> clients to feed directly the invalid headers and if these ones are\n>> connected to headers/filters gateways, themselves doing full-nodes\n>> validation invalid chain is going to be sanitized out ?\n>>\n>> Sure now you trust these gateways, but if you have multiple connections\n>> to them and can guarantee they aren't run by the same entity, that maybe an\n>> acceptable security model, depending of staked amount and your\n>> expectations. I more concerned of having a lot of them and being\n>> diversified enough to avoid collusion between gateways/chain access\n>> providers/miners.\n>>\n>> But even if you light clients is directly connected to the backbone\n>> network and may be reached by miners you can implement fork anomalies\n>> detection and from then you may have multiples options:\n>> * halt the wallet, wait for human intervention\n>> * fallback connection to a trusted server, authoritative on your chain\n>> view\n>> * invalidity proofs?\n>>\n>> Now I agree you need a wide-enough, sane backbone network to build on\n>> top, and we should foster node adoption as much as we can.\n>>\n>> Le mar. 5 mai 2020 \u00e0 09:01, Luke Dashjr <luke at dashjr.org> a \u00e9crit :\n>>\n>>> On Tuesday 05 May 2020 10:17:37 Antoine Riard via bitcoin-dev wrote:\n>>> > Trust-minimization of Bitcoin security model has always relied first\n>>> and\n>>> > above on running a full-node. This current paradigm may be shifted by\n>>> LN\n>>> > where fast, affordable, confidential, censorship-resistant payment\n>>> services\n>>> > may attract a lot of adoption without users running a full-node.\n>>>\n>>> No, it cannot be shifted. This would compromise Bitcoin itself, which\n>>> for\n>>> security depends on the assumption that a supermajority of the economy\n>>> is\n>>> verifying their incoming transactions using their own full node.\n>>>\n>>> The past few years has seen severe regressions in this area, to the\n>>> point\n>>> where Bitcoin's future seems quite bleak. Without serious improvements\n>>> to the\n>>> full node ratio, Bitcoin is likely to fail.\n>>>\n>>> Therefore, all efforts to improve the \"full node-less\" experience are\n>>> harmful,\n>>> and should be actively avoided. BIP 157 improves privacy of fn-less\n>>> usage,\n>>> while providing no real benefits to full node users (compared to more\n>>> efficient protocols like Stratum/Electrum).\n>>>\n>>> For this reason, myself and a few others oppose merging support for BIP\n>>> 157 in\n>>> Core.\n>>>\n>>> > Assuming a user adoption path where a full-node is required to benefit\n>>> for\n>>> > LN may deprive a lot of users, especially those who are already denied\n>>> a\n>>> > real financial infrastructure access.\n>>>\n>>> If Bitcoin can't do it, then Bitcoin can't do it.\n>>> Bitcoin can't solve *any* problem if it becomes insecure itself.\n>>>\n>>> Luke\n>>>\n>>> P.S. See also\n>>>\n>>> https://medium.com/@nicolasdorier/why-i-dont-celebrate-neutrino-206bafa5fda0\n>>>\n>>> https://medium.com/@nicolasdorier/neutrino-is-dangerous-for-my-self-sovereignty-18fac5bcdc25\n>>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200506/def41023/attachment-0001.html>"
            },
            {
                "author": "Keagan McClelland",
                "date": "2020-05-07T04:07:09",
                "message_text_only": "I think that one of the solutions here is to have light clients choose\ntheir full node tethers explicitly. Even if you think it is unrealistic to\nhave everyone run their own node (fwiw, I don\u2019t), there is still a trust\nmodel where you can pick your trusted source.\n\nThis way you could have many light clients working off of a family node,\nand the peer services could be limited to some sort of \u201cauthenticated\u201d\npeers. Perhaps this is better accomplished over the RPC interface in Core,\nbut the idea is to have some sort of peer service model between \u201cfull\npublic\u201d and \u201cowner only\u201d. This limits the amount of costs that can be\nproperly externalized, without exposing risk of consensus capture by\neconomically weighty institutions.\n\nKeagan\n\nOn Wed, May 6, 2020 at 9:56 PM Antoine Riard <antoine.riard at gmail.com>\nwrote:\n\n> What I'm thinking more is if the costs of security are being too much\n> externalized from the light clients onto full nodes, nodes operators are\n> just going to stop servicing light clients `peercfilters=false`. The\n> backbone p2p network is going to be fine. But the massive LN light clients\n> network built on top is going to rely on centralized services for its chain\n> access and now you may have consensus capture by those..\n>\n> Le mer. 6 mai 2020 \u00e0 12:00, Keagan McClelland <keagan.mcclelland at gmail.com>\n> a \u00e9crit :\n>\n>> Hi Antoine,\n>>\n>> Consensus capture by miners isn't the only concern here. Consensus\n>> capture by any subset of users whose interests diverge from the overall\n>> consensus is equally damaging. The scenario I can imagine here is that the\n>> more light clients outpace full nodes, the more the costs of security are\n>> being externalized from the light clients onto the full nodes. In this\n>> situation, it can make full nodes harder to run. If they are harder to run\n>> it will price out some marginal set of full node operators, which causes a\n>> net new increase in light clients (as the disaffected full nodes convert),\n>> AND a redistribution of load onto a smaller surface area. This is a\n>> naturally unstable process. It is safe to say that as node counts drop, the\n>> set of node operators will increasingly represent economic actors with\n>> extreme weight. The more this process unfolds, the more likely their\n>> interests will diverge from the population at large, and also the more\n>> likely they can be coerced into behavior they otherwise wouldn't. After all\n>> it is easier to find agents who carry lots of economic weight. This is true\n>> independent of their mining status, we should be just as wary of consensus\n>> capture by exchanges or HNWI's as we are about miners.\n>>\n>> Keagan\n>>\n>> On Wed, May 6, 2020 at 3:06 AM Antoine Riard <antoine.riard at gmail.com>\n>> wrote:\n>>\n>>> I do see the consensus capture argument by miners but in reality isn't\n>>> this attack scenario have a lot of assumptions on topology an deployment ?\n>>>\n>>> For such attack to succeed you need miners nodes to be connected to\n>>> clients to feed directly the invalid headers and if these ones are\n>>> connected to headers/filters gateways, themselves doing full-nodes\n>>> validation invalid chain is going to be sanitized out ?\n>>>\n>>> Sure now you trust these gateways, but if you have multiple connections\n>>> to them and can guarantee they aren't run by the same entity, that maybe an\n>>> acceptable security model, depending of staked amount and your\n>>> expectations. I more concerned of having a lot of them and being\n>>> diversified enough to avoid collusion between gateways/chain access\n>>> providers/miners.\n>>>\n>>> But even if you light clients is directly connected to the backbone\n>>> network and may be reached by miners you can implement fork anomalies\n>>> detection and from then you may have multiples options:\n>>> * halt the wallet, wait for human intervention\n>>> * fallback connection to a trusted server, authoritative on your chain\n>>> view\n>>> * invalidity proofs?\n>>>\n>>> Now I agree you need a wide-enough, sane backbone network to build on\n>>> top, and we should foster node adoption as much as we can.\n>>>\n>>> Le mar. 5 mai 2020 \u00e0 09:01, Luke Dashjr <luke at dashjr.org> a \u00e9crit :\n>>>\n>>>> On Tuesday 05 May 2020 10:17:37 Antoine Riard via bitcoin-dev wrote:\n>>>> > Trust-minimization of Bitcoin security model has always relied first\n>>>> and\n>>>> > above on running a full-node. This current paradigm may be shifted by\n>>>> LN\n>>>> > where fast, affordable, confidential, censorship-resistant payment\n>>>> services\n>>>> > may attract a lot of adoption without users running a full-node.\n>>>>\n>>>> No, it cannot be shifted. This would compromise Bitcoin itself, which\n>>>> for\n>>>> security depends on the assumption that a supermajority of the economy\n>>>> is\n>>>> verifying their incoming transactions using their own full node.\n>>>>\n>>>> The past few years has seen severe regressions in this area, to the\n>>>> point\n>>>> where Bitcoin's future seems quite bleak. Without serious improvements\n>>>> to the\n>>>> full node ratio, Bitcoin is likely to fail.\n>>>>\n>>>> Therefore, all efforts to improve the \"full node-less\" experience are\n>>>> harmful,\n>>>> and should be actively avoided. BIP 157 improves privacy of fn-less\n>>>> usage,\n>>>> while providing no real benefits to full node users (compared to more\n>>>> efficient protocols like Stratum/Electrum).\n>>>>\n>>>> For this reason, myself and a few others oppose merging support for BIP\n>>>> 157 in\n>>>> Core.\n>>>>\n>>>> > Assuming a user adoption path where a full-node is required to\n>>>> benefit for\n>>>> > LN may deprive a lot of users, especially those who are already\n>>>> denied a\n>>>> > real financial infrastructure access.\n>>>>\n>>>> If Bitcoin can't do it, then Bitcoin can't do it.\n>>>> Bitcoin can't solve *any* problem if it becomes insecure itself.\n>>>>\n>>>> Luke\n>>>>\n>>>> P.S. See also\n>>>>\n>>>> https://medium.com/@nicolasdorier/why-i-dont-celebrate-neutrino-206bafa5fda0\n>>>>\n>>>> https://medium.com/@nicolasdorier/neutrino-is-dangerous-for-my-self-sovereignty-18fac5bcdc25\n>>>>\n>>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200506/26bac9b9/attachment.html>"
            },
            {
                "author": "Braydon Fuller",
                "date": "2020-05-08T19:51:15",
                "message_text_only": "On 5/6/20 9:07 PM, Keagan McClelland wrote:\n\n> I think that one of the solutions here is to have light clients choose\n> their full node tethers explicitly. Even if you think it is unrealistic to\n> have everyone run their own node (fwiw, I don\u2019t), there is still a trust\n> model where you can pick your trusted source.\n>\n> This way you could have many light clients working off of a family node,\n> and the peer services could be limited to some sort of \u201cauthenticated\u201d\n> peers. Perhaps this is better accomplished over the RPC interface in Core,\n> but the idea is to have some sort of peer service model between \u201cfull\n> public\u201d and \u201cowner only\u201d. This limits the amount of costs that can be\n> properly externalized, without exposing risk of consensus capture by\n> economically weighty institutions.\n\nThe RPC interface in Bitcoin Core, and others, is not great for this\nbecause it exposes a lot of functionality that isn't necessary and\nintroduces risks. For example the `gettxoutsetinfo` can start a very\nintensive CPU and disk I/O task. There are several others, for example:\n`stop`, `addnode`, `clearbanned`, `setban`, and etc. Furthermore reading\nfull raw blocks isn't very efficient with JSON. Electrum servers (e.g\nelectrs) for example read blocks from disk instead and use the RPC\ninterface to sync headers. Though, Electrum servers also have a risk of\nDoS with addresses that have many transactions, see the `--txid-limit`\noption [2].\n\n[1]:\nhttps://github.com/bitcoin/bitcoin/blob/5b24f6084ede92d0f493ff416b4726245140b2c1/src/rpc/blockchain.cpp#L954-L956\n[2]:\nhttps://github.com/romanz/electrs/blob/f0a7a325af495ecbc152c0866550dc300011779b/src/query.rs#L284-L289"
            },
            {
                "author": "Keagan McClelland",
                "date": "2020-05-08T20:01:40",
                "message_text_only": "> The RPC interface in Bitcoin Core, and others, is not great for this\n> because it exposes a lot of functionality that isn't necessary and\n> introduces risks.\n\nThis is actually somewhat my point. If the RPC interface was good for this\nand *didn't* introduce risks, we could just use that and be done with it.\nBut I'm finding there are many use cases that you want to have low cost\nways to serve peer services to people whom you have given explicit\npermission, but they shouldn't have full ability to administrate the node.\n\nPerhaps I wasn't explicit in my previous note but what I mean is that there\nseems to be a demand for something *in between* a peer interface, and an\nowner interface. I have little opinion as to whether this belongs in core\nor not, I think there are much more experienced folks who can weight in on\nthat, but without something like this, you cannot limit your exposure for\nserving something like bip157 filters without removing your own ability to\nmake use of some of those same services.\n\nKeagan\n\nOn Fri, May 8, 2020 at 1:51 PM Braydon Fuller <braydon at purse.io> wrote:\n\n> On 5/6/20 9:07 PM, Keagan McClelland wrote:\n>\n> > I think that one of the solutions here is to have light clients choose\n> > their full node tethers explicitly. Even if you think it is unrealistic\n> to\n> > have everyone run their own node (fwiw, I don\u2019t), there is still a trust\n> > model where you can pick your trusted source.\n> >\n> > This way you could have many light clients working off of a family node,\n> > and the peer services could be limited to some sort of \u201cauthenticated\u201d\n> > peers. Perhaps this is better accomplished over the RPC interface in\n> Core,\n> > but the idea is to have some sort of peer service model between \u201cfull\n> > public\u201d and \u201cowner only\u201d. This limits the amount of costs that can be\n> > properly externalized, without exposing risk of consensus capture by\n> > economically weighty institutions.\n>\n> The RPC interface in Bitcoin Core, and others, is not great for this\n> because it exposes a lot of functionality that isn't necessary and\n> introduces risks. For example the `gettxoutsetinfo` can start a very\n> intensive CPU and disk I/O task. There are several others, for example:\n> `stop`, `addnode`, `clearbanned`, `setban`, and etc. Furthermore reading\n> full raw blocks isn't very efficient with JSON. Electrum servers (e.g\n> electrs) for example read blocks from disk instead and use the RPC\n> interface to sync headers. Though, Electrum servers also have a risk of\n> DoS with addresses that have many transactions, see the `--txid-limit`\n> option [2].\n>\n> [1]:\n>\n> https://github.com/bitcoin/bitcoin/blob/5b24f6084ede92d0f493ff416b4726245140b2c1/src/rpc/blockchain.cpp#L954-L956\n> [2]:\n>\n> https://github.com/romanz/electrs/blob/f0a7a325af495ecbc152c0866550dc300011779b/src/query.rs#L284-L289\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200508/dd8331af/attachment-0001.html>"
            },
            {
                "author": "Braydon Fuller",
                "date": "2020-05-08T20:22:30",
                "message_text_only": "On 5/8/20 1:01 PM, Keagan McClelland wrote:\n\n>> The RPC interface in Bitcoin Core, and others, is not great for this\n>> because it exposes a lot of functionality that isn't necessary and\n>> introduces risks.\n> This is actually somewhat my point. If the RPC interface was good for this\n> and *didn't* introduce risks, we could just use that and be done with it.\n> But I'm finding there are many use cases that you want to have low cost\n> ways to serve peer services to people whom you have given explicit\n> permission, but they shouldn't have full ability to administrate the node.\n>\n> Perhaps I wasn't explicit in my previous note but what I mean is that there\n> seems to be a demand for something *in between* a peer interface, and an\n> owner interface. I have little opinion as to whether this belongs in core\n> or not, I think there are much more experienced folks who can weight in on\n> that, but without something like this, you cannot limit your exposure for\n> serving something like bip157 filters without removing your own ability to\n> make use of some of those same services.\n\nAn idea I was thinking about was having three ports for a full node:\n\n1) Consensus bitcoin protocol. This is the existing peer-to-peer\nprotocol without additional services.\n2) Wallet services protocol. Adds additional functionality for wallets.\nFor example bloom filtering, compact block filters, and potentially\noutput and address indexes for electrum-like support. It's nearly\nidentical to the consensus peer-to-peer protocol, supporting the same\nwire format. As it's on another port, various middleware could be added\nto support various authentication and transports.\n3) Control interface. This is the existing JSON-RPC interface, without\nall wallet related RPC methods."
            },
            {
                "author": "Christopher Allen",
                "date": "2020-05-08T21:30:03",
                "message_text_only": "On Fri, May 8, 2020 at 2:00 PM Keagan McClelland via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Perhaps I wasn't explicit in my previous note but what I mean is that\n> there seems to be a demand for something *in between* a peer interface,\n> and an owner interface. I have little opinion as to whether this belongs in\n> core or not, I think there are much more experienced folks who can weight\n> in on that, but without something like this, you cannot limit your exposure\n> for serving something like bip157 filters without removing your own ability\n> to make use of some of those same services.\n>\n\nOur FullyNoded2 multisig wallet on iOS & Mac, communicates with your own\npersonal node over RPC, securing the connection using Tor over a hidden\nonion service and two-way client authentication using a v3 Tor\nAuthentication key: https://github.com/BlockchainCommons/FullyNoded-2\n\nIt many ways the app (and its predecessor FullyNoded1) is an interface\nbetween a personal full node and a user.\n\nHowever, we do wish that the full RPC functionality was not exposed in\nbitcoin-core. I\u2019d love to see a cryptographic capability mechanism such\nthat the remote wallet could only m ask the node functions that it needs,\nand allow escalation for other rarer services it needs with addition\nauthorization.\n\nThis capability mechanism feature set should go both ways, to a minimum\nsubset needed for being a watch-only transaction verification tool, all the\nway to things RPC can\u2019t do like deleting a wallet and changing bitcoin.conf\nparameters and rebooting, without requiring full ssh access to the server\nrunning the node.\n\nIf there are people interested in coordinating some proposals on how to\ndefining different sets of wallet functionality, Blockchain Commons would\nbe interested in hosting that collaboration. This could start as just being\na transparent shim between bitcoin-core & remote RPC, but later could\ninform proposals for the future of the core wallet functionality as it gets\nrefactored.\n\n\u2014 Christopher Allen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200508/b2fc3d0f/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-09T07:48:33",
                "message_text_only": "Hi Christopher,\n\nThanks for Blockchain Commons and Learning Bitcoin from the Command Line!\n\n> If there are people interested in coordinating some proposals on how to\ndefining different sets of wallet functionality, Blockchain Commons would\nbe interested in hosting that collaboration. This could start as just being\na transparent shim between bitcoin-core & remote RPC, but later could\ninform proposals for the future of the core wallet functionality as it gets\nrefactored.\n\nYes generally refactoring in Core wallets are making good progress [0]. I'm\npretty sure feedbacks and proposals on future changes with regards to\nusability would be greatly appreciated.\n\nMaybe you can bring these during a IRC meeting ?\n\nAntoine\n\n[0] See https://github.com/bitcoin/bitcoin/pull/16528 or\nhttps://github.com/bitcoin/bitcoin/pull/16426\n\nLe ven. 8 mai 2020 \u00e0 17:31, Christopher Allen via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n> On Fri, May 8, 2020 at 2:00 PM Keagan McClelland via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Perhaps I wasn't explicit in my previous note but what I mean is that\n>> there seems to be a demand for something *in between* a peer interface,\n>> and an owner interface. I have little opinion as to whether this belongs in\n>> core or not, I think there are much more experienced folks who can weight\n>> in on that, but without something like this, you cannot limit your exposure\n>> for serving something like bip157 filters without removing your own ability\n>> to make use of some of those same services.\n>>\n>\n> Our FullyNoded2 multisig wallet on iOS & Mac, communicates with your own\n> personal node over RPC, securing the connection using Tor over a hidden\n> onion service and two-way client authentication using a v3 Tor\n> Authentication key: https://github.com/BlockchainCommons/FullyNoded-2\n>\n> It many ways the app (and its predecessor FullyNoded1) is an interface\n> between a personal full node and a user.\n>\n> However, we do wish that the full RPC functionality was not exposed in\n> bitcoin-core. I\u2019d love to see a cryptographic capability mechanism such\n> that the remote wallet could only m ask the node functions that it needs,\n> and allow escalation for other rarer services it needs with addition\n> authorization.\n>\n> This capability mechanism feature set should go both ways, to a minimum\n> subset needed for being a watch-only transaction verification tool, all the\n> way to things RPC can\u2019t do like deleting a wallet and changing bitcoin.conf\n> parameters and rebooting, without requiring full ssh access to the server\n> running the node.\n>\n> If there are people interested in coordinating some proposals on how to\n> defining different sets of wallet functionality, Blockchain Commons would\n> be interested in hosting that collaboration. This could start as just being\n> a transparent shim between bitcoin-core & remote RPC, but later could\n> inform proposals for the future of the core wallet functionality as it gets\n> refactored.\n>\n> \u2014 Christopher Allen\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200509/f1180329/attachment.html>"
            },
            {
                "author": "Braydon Fuller",
                "date": "2020-05-08T19:33:55",
                "message_text_only": "On 5/5/20 5:31 PM, Olaoluwa Osuntokun via bitcoin-dev wrote:\n\n> Hi Antoine,\n>\n>> Even with cheaper, more efficient protocols like BIP 157, you may have a\n>> huge discrepancy between what is asked and what is offered. Assuming 10M\n>> light clients [0] each of them consuming ~100MB/month for filters/headers,\n>> that means you're asking 1PB/month of traffic to the backbone network. If\n>> you assume 10K public nodes, like today, assuming _all_ of them opt-in to\n>> signal BIP 157, that's an increase of 100GB/month for each. Which is\n>> consequent with regards to the estimated cost of 350GB/month for running\n>> an actual public node\n> One really dope thing about BIP 157+158, is that the protocol makes serving\n> light clients now _stateless_, since the full node doesn't need to perform\n> any unique work for a given client. As a result, the entire protocol could\n> be served over something like HTTP, taking advantage of all the established\n> CDNs and anycast serving infrastructure, which can reduce syncing time\n> (less latency to\n> fetch data) and also more widely distributed the load of light clients using\n> the existing web infrastructure. Going further, with HTTP/2's server-push\n> capabilities, those serving this data can still push out notifications for\n> new headers, etc.\n\nThe statelessness of compact block filters does look useful. Bloom\nfilters for\nblocks can be inefficient, during a scan with a BIP37 wallet, it's\nnecessary to\ndiscard already received merkle blocks as the filter has been updated\nand the\nprevious results may have missed transactions. Both bitcoinj [1] and\nbreadwallet-core [2] handle it using a similar method. The alternative of\nsynchronizing and alternating between requesting blocks and filter\nupdates leads\nto slow scan times. With compact block filters, a separate wallet\nprocess (from\nthe full node) can make adjustments necessary to what it needs to filter\nwithout\nhaving to communicate with the full node.\n\n[1]:\nhttps://github.com/bitcoinj/bitcoinj/blob/806afa04419ebdc3c15d5adf065979aa7303e7f6/core/src/main/java/org/bitcoinj/core/Peer.java#L1076-L1079\n[2]:\nhttps://github.com/breadwallet/breadwallet-core/blob/8eb05454df3e2d5cca248b4e24eeffa420c97e3a/bitcoin/BRPeer.c#L83-L85"
            }
        ],
        "thread_summary": {
            "title": "On the scalability issues of onboarding millions of LN mobile clients",
            "categories": [
                "Lightning-dev",
                "bitcoin-dev"
            ],
            "authors": [
                "Antoine Riard",
                "Chris Belcher",
                "Luke Dashjr",
                "John Newbery",
                "Orfeas Stefanos Thyfronitis Litos",
                "Braydon Fuller",
                "William Casarin",
                "Keagan McClelland",
                "Christopher Allen",
                "Lloyd Fournier",
                "ZmnSCPxj"
            ],
            "messages_count": 23,
            "total_messages_chars_count": 79041
        }
    },
    {
        "title": "[Lightning-dev] Force close of channel with unresolved htlc",
        "thread_messages": [
            {
                "author": "Subhra Mazumdar",
                "date": "2020-05-05T18:06:14",
                "message_text_only": "Hi,\n     I am having a doubt regarding force closure of channel. Suppose A->B\nthere is an htlc which has been established for transfering fund. Now\nsuppose for some unfortunate reason B doesnt have the witness to resolve\nhtlc and the mean time A suffers crash fault. Then can B close the channel\ngiven that it has no way out of resolving the htlc due to lack of witness?\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200505/b98990c8/attachment.html>"
            },
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2020-05-05T18:40:46",
                "message_text_only": "Dear Subhra,\n\nas discussed bilaterally and after clarification of your question the\nsituation is as follows:\n\nLet us assume A and B have a channel in which A has 4 tokens and B has 6\ntokens\n\nNow A offers an HTLC with the amount of 2 tokens and B accepts (receives)\nthe offer then A and B both have negotiated the HTLC output in the most\nrecent commitment transaction.\n\nIf A stops responding and B has to force close the channel a commitment\ntransaction with 3 UTXOs will hit the chain. One UTXO with 2 tokens\nspendable by A, another one with 6 tokens spendable by B and the received\nHTLC output with 2 tokens. This one can be spend by two different\nconditions as in the offchain protocol\n\n1.) Before the timelock of the HTLC has passed B can spend the output if B\nknows his to_local HTLC secret AND the preimage. OR\n2.) after the timelock A can spend the output if A knows the to_remote HTLC\nsecret.\n\nthe mechanism with HTLCs can be read upon in BOLT 2 (channel operation\nhttps://github.com/lightningnetwork/lightning-rfc/blob/master/02-peer-protocol.md)\nand the scripts can be seen in BOLT 3:\nhttps://github.com/lightningnetwork/lightning-rfc/blob/master/03-transactions.md\n\nA less technical summary that is more focused on explaining the concepts is\ncurrently being developed in the routing chapter of mastering the lightning\nnetwork:\nhttps://github.com/lnbook/lnbook/blob/43ce57298b4da345286ae3b53c42ea3eb9d9b056/routing.asciidoc\n\nWith kind regards Rene Pickhardt\n\nOn Tue, May 5, 2020 at 8:06 PM Subhra Mazumdar <\nsubhra.mazumdar1993 at gmail.com> wrote:\n\n> Hi,\n>      I am having a doubt regarding force closure of channel. Suppose A->B\n> there is an htlc which has been established for transfering fund. Now\n> suppose for some unfortunate reason B doesnt have the witness to resolve\n> htlc and the mean time A suffers crash fault. Then can B close the channel\n> given that it has no way out of resolving the htlc due to lack of witness?\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n\n\n-- \nhttps://www.rene-pickhardt.de\n\nSkype: rene.pickhardt\n\nmobile: +49 (0)176 5762 3618\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200505/ee92c436/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Force close of channel with unresolved htlc",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Ren\u00e9 Pickhardt",
                "Subhra Mazumdar"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 2968
        }
    },
    {
        "title": "[Lightning-dev] Machine-to-machine LN payments",
        "thread_messages": [
            {
                "author": "Eugene",
                "date": "2020-05-14T17:13:54",
                "message_text_only": "Hello, list,\n\nI haven't closely following the Lightning Network's state of affairs since late 2018 and I wondering, is it possible to support the following use-case with LN:\n\n1. A user subscribes to the service by opening a channel with it\n2. User sets his LN node to \"trust\" invoices that come from said service\n3. On subscription renewal, service sends an invoice to the client's LN node\n4. Since the client's node is \"trusting\" service's node, it pays invoice straight away\n\nUser, of course, may cancel the subscription at any time by removing service's LN node public key from the list of \"trusted\". Or the user can set a limit on the amount and the frequency of payments that would be accepted from the trusted node.\n\nFor that matter, the questions are:\n\n1. Is it possible to send invoices just by LN means? (Should we use TLVs?)\n2. Is it possible to enable automatic machine-to-machine payments? As in the example above, by accepting invoices from \"trusted\" nodes.\n\nBest regards,\nEugene\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200514/781455c6/attachment.html>"
            },
            {
                "author": "William Casarin",
                "date": "2020-05-14T17:45:23",
                "message_text_only": "Eugene via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\nwrites:\n\n> Hello, list,\n>\n> I haven't closely following the Lightning Network's state of affairs since late 2018 and I wondering, is it possible to support the following use-case with LN:\n>\n> 1. A user subscribes to the service by opening a channel with it\n> 2. User sets his LN node to \"trust\" invoices that come from said service\n> 3. On subscription renewal, service sends an invoice to the client's LN node\n> 4. Since the client's node is \"trusting\" service's node, it pays invoice straight away\n>\n> User, of course, may cancel the subscription at any time by removing service's LN node public key from the list of \"trusted\". Or the user can set a limit on the amount and the frequency of payments that would be accepted from the trusted node.\n>\n> For that matter, the questions are:\n>\n> 1. Is it possible to send invoices just by LN means? (Should we use TLVs?)\n> 2. Is it possible to enable automatic machine-to-machine payments? As in the example above, by accepting invoices from \"trusted\" nodes.\n\nOffers[0] should support these use cases\n\nCheers,\nWill\n\n[0] https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-November/002276.html"
            },
            {
                "author": "Eugene",
                "date": "2020-05-17T06:27:15",
                "message_text_only": "Hello,\n\nI found a way for one client to initiate a payment from the other by using spontaneous keysend payments:\n\n1. Payee sends keysend payment of negligible amount (1 sat?)\n2. Payer accepts keysend and verifies that it comes from a trusted node\n3. Payer makes a keysend payment of required amount back to Payee\n4. Payee accepts payment\n\nStep two should probably be implemented by a custom plugin that checks incoming keysend messages and pays valid ones back.\n\nThe flow above is basically uses keysend to send an invoice to Payer to be paid. I wonder if there's an other way to send an invoice through LN by Payer's node public key?\n\nCheers,\nEugene\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Friday, 15 May 2020 01:13, Eugene via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n\n> Hello, list,\n>\n> I haven't closely following the Lightning Network's state of affairs since late 2018 and I wondering, is it possible to support the following use-case with LN:\n>\n> 1. A user subscribes to the service by opening a channel with it\n> 2. User sets his LN node to \"trust\" invoices that come from said service\n> 3. On subscription renewal, service sends an invoice to the client's LN node\n> 4. Since the client's node is \"trusting\" service's node, it pays invoice straight away\n>\n> User, of course, may cancel the subscription at any time by removing service's LN node public key from the list of \"trusted\". Or the user can set a limit on the amount and the frequency of payments that would be accepted from the trusted node.\n>\n> For that matter, the questions are:\n>\n> 1. Is it possible to send invoices just by LN means? (Should we use TLVs?)\n> 2. Is it possible to enable automatic machine-to-machine payments? As in the example above, by accepting invoices from \"trusted\" nodes.\n>\n> Best regards,\n> Eugene\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200517/dae3f0a5/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Machine-to-machine LN payments",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "William Casarin",
                "Eugene"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 4396
        }
    },
    {
        "title": "[Lightning-dev] Miners Dust Inflation attacks on Lightning Network",
        "thread_messages": [
            {
                "author": "Antoine Riard",
                "date": "2020-05-18T10:28:21",
                "message_text_only": "Lightning protocol supports a floating dust output selection at channel\ncreation, where each party declares a dust parameter applying to its local\ntransactions. The current spec doesn't enforce or recommend any bound on\nthis value, beyond the requirement of being lower that\n`channel_reserve_satoshis`. When a HTLC is routed through the channel but\nits value is under the local party dust limit, it's burned as fees and not\nadded to the commitment transaction. This rule, which makes LN a good\ncitizen of the Bitcoin blockchain comes at the price of more trust in your\ncounterparty..\n\nLet's consider the following scenario. Mallory announces a channel to Alice\nwith dust-limit-satoshi set to 20% of channel value. Alice should accept\nincoming channels as long as its under her implementation-specific\n`max_dust_limit_satoshis`. Now Mallory can route 4 dust-HTLCs to Mallet\nthrough Alice claiming ~80% of channel value.\n\n        Mallory --> Alice --> Mallet\n\nMallet, in collusion with Mallory, can claim the whole set of HTLCs by\nrevealing the corresponding preimage for each. At the exact same time,\nMallory broadcast her latest commitment transaction on which there is _no_\nHTLCs because all of them are dust. Alice can't claim them onchain but has\nalready paid Mallet forward.\n\nAt first-look, this attack doesn't seem economically rational because\ndust-HTLCs are all committed as fees. But if you assume that Mallory can\ncollude with some mining pool, economics change completely because it's now\na almost zero-cost to add Mallory commitment transaction in a block,\nhashrate won't be wasted. Fees are going back to the miner, and Alice is\nstill robbed. Mallory commitment transaction may stay in miner pool as long\nblock isn't found, without being announced to the rest of the network, and\nHTLCs timelocks don't expire. Attack may still stealth if block isn't\nsigned. It's almost a zero-cost because if you assume block being full,\ncommitment transaction is now competing for block space and there is an\nopportunity cost.\n\nIt's that kind of low-probability-and-hard-to-exploit-vulnerability but you\nwould prefer not having to think about your big LSP hub being targeted by a\nrogue mining pool employee. Even if it's a really small mining pool, you\nmay batch the attack on multiple channels at once for one block found.\n\nDeployment of Stratum V2 may make the attack easier by giving more leverage\nto the local miner.\n\nMitigating may come by negotiating a new\n`max_dust_htlc_value_in_flight_msat` enforced by HTLC recipient, therefore\nexpressing its maximum trust tolerance with regards to dust. Bearing a cost\non a HTLC holder will also render the attack more expensive, even if for\ncounter-measure efficiency you likely need a different order of magnitude\nthat spam-protection.\n\nCheers,\n\nAntoine\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200518/b208e707/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-19T00:52:09",
                "message_text_only": "Good morning Antoine,\n\n\n> Mitigating may come by negotiating a new `max_dust_htlc_value_in_flight_msat` enforced by HTLC recipient, therefore expressing its maximum trust tolerance with regards to dust. Bearing a cost on a HTLC holder will also render the attack more expensive, even if for counter-measure efficiency you likely need a different order of magnitude that spam-protection.\n\nEven without a spec change, such a setting may be enforced by a forwarding node by the simple act of refusing to forward an HTLC once a certain level of incoming dust HTLCs are currently in-flight.\nThat is, the forwarding node can simply accept the incoming new dusty HTLC, but instead of forwarding, claim a `temporary_channel_failure` on the next channel.\nThe attack requires that the forwarding node actually forward the HTLC, after all.\n\nThis will of course lead to reduced reliability on micropayments.\n\nAdding this to the spec does have the advantage that an honest forwarder can hold an HTLC for a while once it notices that the next hop has a bunch of dusty HTLCs in-flight that are beyond the negotiated `max_dust_htlc_value_in_flight_msat`, which might help reliability of micropayments slightly, but there is still the reduction of reliability.\nNot to mention that the easiest code change to respect such a limit would be simply to fail forwarding anyway.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-05-19T22:03:02",
                "message_text_only": "Hi ZmnSCPxj,\n\nAs of today, you can setup a `htlc_minimum_msat` higher than remote's\n`dust_limit_satoshis`, but you don't necessarily know it before announcing\nyour channel parameters if you're initiator.\nIn practice, assuming you can do so, with fees going higher and HTLC\noutputs being encumbered, their cost-to-spend will increase so forbidding\ndust HTLC will outlaw low-value payments, which them are a constant.\n\n> Adding this to the spec does have the advantage that an honest forwarder\ncan hold an HTLC for a while once it notices that the next hop has a bunch\nof dusty HTLCs in-flight that are beyond the negotiated\n`max_dust_htlc_value_in_flight_msat`, which might help reliability of\nmicropayments slightly, but there is still the reduction of reliability.\n\nI agree you can already fail HTLC as a local forwarding policy, which is\nnot great for reliability. So you may have either a negotiated\n`max_dust_htlc_value_in_flight_msat` or refuse an\n`open_channel`/`accept_channel` by receiver considering remote's\n`dust_limit_satoshi` too high.\n\nI do think that's a pretty low-risk scenario but that would be better if\nimplementations somehow bound in-flight dust to lower attack incentive.\n\nAntoine\n\nLe lun. 18 mai 2020 \u00e0 20:52, ZmnSCPxj <ZmnSCPxj at protonmail.com> a \u00e9crit :\n\n> Good morning Antoine,\n>\n>\n> > Mitigating may come by negotiating a new\n> `max_dust_htlc_value_in_flight_msat` enforced by HTLC recipient, therefore\n> expressing its maximum trust tolerance with regards to dust. Bearing a cost\n> on a HTLC holder will also render the attack more expensive, even if for\n> counter-measure efficiency you likely need a different order of magnitude\n> that spam-protection.\n>\n> Even without a spec change, such a setting may be enforced by a forwarding\n> node by the simple act of refusing to forward an HTLC once a certain level\n> of incoming dust HTLCs are currently in-flight.\n> That is, the forwarding node can simply accept the incoming new dusty\n> HTLC, but instead of forwarding, claim a `temporary_channel_failure` on the\n> next channel.\n> The attack requires that the forwarding node actually forward the HTLC,\n> after all.\n>\n> This will of course lead to reduced reliability on micropayments.\n>\n> Adding this to the spec does have the advantage that an honest forwarder\n> can hold an HTLC for a while once it notices that the next hop has a bunch\n> of dusty HTLCs in-flight that are beyond the negotiated\n> `max_dust_htlc_value_in_flight_msat`, which might help reliability of\n> micropayments slightly, but there is still the reduction of reliability.\n> Not to mention that the easiest code change to respect such a limit would\n> be simply to fail forwarding anyway.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200519/fb4e38c3/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-20T03:26:54",
                "message_text_only": "Good morning Antoine,\n\nAs well, I considered doing state machine shenanigans for this (do not sign for removal of HTLC in your outgoing channel until you have irrevocable removal of HTLC in your incoming channel) but this does not work since if you already have a miner willing to cooperate with you and which you can plausibly believe will share the amount with you, the miner can recover the funds by simply closing the outgoing channel as well.\n\n\n> Hi ZmnSCPxj,\n> As of today, you can setup a `htlc_minimum_msat` higher than remote's `dust_limit_satoshis`, but you don't necessarily know it before announcing your channel parameters if you're initiator.\n> In practice, assuming you can do so, with fees going higher and HTLC outputs being encumbered, their cost-to-spend will increase so forbidding dust HTLC will outlaw low-value payments, which them are a constant.\n>\n> > Adding this to the spec does have the advantage that an honest forwarder can hold an HTLC for a while once it notices that the next hop has a bunch of dusty HTLCs in-flight that are beyond the negotiated `max_dust_htlc_value_in_flight_msat`, which might help reliability of micropayments slightly, but there is still the reduction of reliability.\n>\n> I agree you can already fail HTLC as a local forwarding policy, which is not great for reliability. So you may have either a negotiated `max_dust_htlc_value_in_flight_msat` or refuse an `open_channel`/`accept_channel` by receiver considering remote's\u00a0 `dust_limit_satoshi` too high.\n> I do think that's a pretty low-risk scenario but that would be better if implementations somehow bound in-flight dust to lower attack incentive.\n\nEven if such a limit is negotiated it seems reliability is still reduced --- if the limit is too low in practice then it would be easy for the micropayment bandwidth to be saturated anyway and such tiny payments will not push through.\nIt is still slightly better though.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Miners Dust Inflation attacks on Lightning Network",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Antoine Riard",
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 9202
        }
    },
    {
        "title": "[Lightning-dev] Griefing-Penalty: A proposal for mitigating Griefing Attack",
        "thread_messages": [
            {
                "author": "Subhra Mazumdar",
                "date": "2020-05-20T04:12:52",
                "message_text_only": "Hi,\n\n     We went through the discussion of Griefing Attack\n<https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-April/002608.html>\nand after a thorough analysis, we realized that the attack cannot be\nprevented as the adversary doesn\u2019t suffer any loss of funds.\n\nWe propose an efficient countermeasure for the attack, known as\nGriefing-Penalty. Our proposed strategy works for any timelock based\npayment protocol. The penalty compensates for the loss incurred by the\nintermediaries, affected by griefing attack. You will find the paper\nGriefing-Penalty:\nCountermeasure for Griefing Attack in Bitcoin-compatible PCNs\n<https://arxiv.org/abs/2005.09327> on arXiv. We look forward to hearing\nfrom the community on the feasibility of the approach and whether it can be\nimplemented or not.\n\nOur Contribution to the paper:\n\n\u2022 We propose a countermeasure for mitigating griefing attack in\nBitcoin-compatible PCNs, known as Griefing-Penalty. It punishes the griefer\nby forcing it to pay compensation to all the parties whose funds got locked\nfor a certain time period as a result of the attack.\n\n\u2022 The loss of funds incurred upon mounting griefing-attack is proportional\nto the collateral cost of each channel involved in routing the payment.\n\n\u2022 To illustrate the benefit of the proposed countermeasure, we propose a\nnew payment protocol, called as HTLC-GP or Hashed Timelock Contract with\nGriefing-Penalty.\n\n\u2022 We provide a security analysis which proves that our protocol is\nprivacy-preserving as well as mitigates loss due to griefing attack by\ncompensating the honest nodes\n\nWe will briefly summarize the problem and our contribution through an\nexample.\n\nThe problem of Griefing Attack explained briefly\n\nConsider the situation where A wants to transfer 1 msat to C. It figures\nout a path connecting it to C, in the form A->B->C. A establishes an HTLC\nwith B, locking 1 msat in the contract having expiration time of say 2\ndays. B after receiving the incoming contract, forms a contract with C,\nlocking 1 msat in the contract with locktime of 1 day.\n\nA------------------------->B---------------------->C\n\nHTLC(1msat, 2 day)     HTLC(1msat, 1 day)\n\nNow if C griefs, funds of A and B remain locked as they cannot resolve\nHTLC. After an elapsed time of 1 day, the fund gets unlocked and B gets\nback 1 msat. Similarly, B cancels contract with A after 1 day, A unlocks 1\nmsat. The problem with this construction is that C doesn\u2019t lose anything.\n\nGriefing-Penalty: a strategy to penalize the adversary\n\nHence we have come up with the following idea:\n\n1) An off-chain contract established between 2 parties requires both the\nparties to lock funds \u2013 one party locking the amount that is to be\nforwarded and the other party locking the fund which can be claimed as a\npenalty, if this party griefs.\n\n2) The penalty locked is proportional to the product of the amount being\nforwarded and the expiration time of the contract. All the parties affected\nby griefing must get compensation since their liquidity is tied up for a\ncertain period of time.\n\nConsidering the example used for demonstrating griefing attack. We modify\nthe contract and term it as HTLC-GP (Hashed Timelock Contract with Griefing\nPenalty). We assume a rate of penalty, say 0.01 per hour, for calculating\nthe penalty the party has to lock in order to accept an off-chain contract\nrequest.\n\nA forwards the term of the contract to B, requesting B to lock\n0.01*1*48=0.48 msat as a penalty. A locks 1 msat in the contract, so the\ntotal amount locked in the contract is 1.48 msat. In the same way, B\nforwards the term of the contract to C, requesting C to lock 0.01*1*24=0.24\nmsat as a penalty. B locks 1 msat in the contract, so the total amount\nlocked in the contract is 1.24 msat. If the payment is not resolved within\n1 day, all the parties who have forwarded the contract will claim the\npenalty locked in the contract.\n\nA-------------------------------------->B-------------------------------->C\n\nHTLC-GP(1.48 msat, 2 days)       HTLC-GP(1.24 msat,1 day)\n\nIf C releases the preimage before the expiration of locktime, it will claim\nthe full amount locked in the contract, i.e. 1.24 msat. Similarly, B claims\n1.48 msat from the contract established with A.\n\nSuppose C griefs. After an elapse of 1 day, B claims 1.24 msat from the\ncontract. C loses 0.24 msat. When B cancels contract with A, it will settle\nby paying 1.48 msat to A. But then B loses an additional 0.24 msat. This is\nnot desired as B was not involved in mounting the attack. As per the\nobjective, even B should earn a remuneration as it got affected by griefing.\n\nHence, B should have asked C to lock funds in the contract which can be\nused for compensating both B and A. So C must lock 0.48 msat + 0.24 msat =\n0.72 msat. So if C griefs, now it loses 0.72 msat (proportional to the\ncollateral cost of the path). B pays 0.48 msat to A, keeping 0.24 msat with\nitself as compensation.\n\nA-------------------------------------->B-------------------------------->C\n\nHTLC-GP(1.48 msat, 2 days)       HTLC-GP(1.72 msat,1 day)\n\n\n\nA------------------------------------->B-------------------------------->C\n(griefs)\n\n(A gain 0.48 msat)      (B gain 0.24 msat)              (C loses 0.72 msat)\n\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200520/c67d82af/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-20T04:53:39",
                "message_text_only": "Good morning Subhra et al,\n\nI am unsure whether you actually solve the Reverse-Griefing attack that the Griefing-Penalty enables.\nIt seems to me that Reverse-Griefing is worse than Griefing, since it causes loss of funds already owned, whereas griefing only causes loss of opportunity to earn.\n\nIn particular:\n\n> With the introduction of griefing-penalty, in order to avoid paying a compensation, at least two nodes in the path must be corrupted, as per the argument made above.\n\nGiven we route using onion routing, it would be trivial to create a loop in the route so that the same node occurs twice in it, thus trivially meeting the \"at least two nodes in the path must be corrupted\" requirement.\n\nThat is, the sender and the receiver can be the same node, making it appear twice in the path.\n\n>  Though we assume honest party will act rationally, in reality a party is selfish\n\nThis does not make sense.\n\nRationality requires some goal to work toward.\n\nOften, the goal is \"look out for number one\" i.e. be selfish.\n\nThus, an economically rational selfish entity is not a contradiction in terms: instead, it is simply applying its rationality towards its own self-interest.\n\nCan you clarify what *goal* you are assuming the party has, which the party is applying its rationality towards?\n\n--\n\nIn general, all work towards such open standards as Lightning Network and so on have the motivating goal of \"creating value\": by fixing problems and improving specs, everyone gets a better Lightning Network and (hopefully) benefits.\nHowever this is not the ultimate goal towards we work toward.\nInstead, this is an instrumental goal, with the ultimate goal being to acquire more value; the act of creating value is then performed in the hope that the increase in global value will also translate to an increase in your own value.\n\nThus, any forwarding node, by increasing liquidity on the Lightning Network, does so in the hope that it will capture some of the increased value:\n\n* Directly, by earning fees.\n* Indirectly, by promoting the use of Lightning and earning more future fees.\n* Even more indirectly, by promoting the use of Lightning on top of Bitcoin and increasing the value of any Bitcoin held in channels.\n\nThus ultimately all honest behavior is ultimately honestly-rationally-selfish behavior.\n\nSo if an honestly-self-rational node could be tempted to setting up reverse-griefing attacks, it seems to me that grief-penalty cannot work well as a solution to griefing.\n\nThe solution should really prevent griefing without introducing any reverse-griefing.\n\nRegards,\nZmnSCPxj\n\n\n> Hi,\n>\n> We went through the discussion of Griefing Attack and after a thorough analysis, we realized that the attack cannot be prevented as the adversary doesn\u2019t suffer any loss of funds.\n>\n> We propose an efficient countermeasure for the attack, known as Griefing-Penalty. Our proposed strategy works for any timelock based payment protocol. The penalty compensates for the loss incurred by the intermediaries, affected by griefing attack. You will find the paper Griefing-Penalty: Countermeasure for Griefing Attack in Bitcoin-compatible PCNs on arXiv. We look forward to hearing from the community on the feasibility of the approach and whether it can be implemented or not.\n>\n> Our Contribution to the paper:\n>\n> \u2022 We propose a countermeasure for mitigating griefing attack in Bitcoin-compatible PCNs, known as Griefing-Penalty. It punishes the griefer by forcing it to pay compensation to all the parties whose funds got locked for a certain time period as a result of the attack.\n>\n> \u2022 The loss of funds incurred upon mounting griefing-attack is proportional to the collateral cost of each channel involved in routing the payment.\n>\n> \u2022 To illustrate the benefit of the proposed countermeasure, we propose a new payment protocol, called as HTLC-GP or Hashed Timelock Contract with Griefing-Penalty.\n>\n> \u2022 We provide a security analysis which proves that our protocol is privacy-preserving as well as mitigates loss due to griefing attack by compensating the honest nodes\n>\n> We will briefly summarize the problem and our contribution through an example.\n>\n> The problem of Griefing Attack explained briefly\n>\n> Consider the situation where A wants to transfer 1 msat to C. It figures out a path connecting it to C, in the form A->B->C. A establishes an HTLC with B, locking 1 msat in the contract having expiration time of say 2 days. B after receiving the incoming contract, forms a contract with C, locking 1 msat in the contract with locktime of 1 day.\n>\n> A------------------------->B---------------------->C\n>\n> HTLC(1msat, 2 day) \u00a0 \u00a0 HTLC(1msat, 1 day)\n>\n> Now if C griefs, funds of A and B remain locked as they cannot resolve HTLC. After an elapsed time of 1 day, the fund gets unlocked and B gets back 1 msat. Similarly, B cancels contract with A after 1 day, A unlocks 1 msat. The problem with this construction is that C doesn\u2019t lose anything.\n>\n> Griefing-Penalty: a strategy to penalize the adversary\n>\n> Hence we have come up with the following idea:\n>\n> 1) An off-chain contract established between 2 parties requires both the parties to lock funds \u2013 one party locking the amount that is to be forwarded and the other party locking the fund which can be claimed as a penalty, if this party griefs.\n>\n> 2) The penalty locked is proportional to the product of the amount being forwarded and the expiration time of the contract. All the parties affected by griefing must get compensation since their liquidity is tied up for a certain period of time.\n>\n> Considering the example used for demonstrating griefing attack. We modify the contract and term it as HTLC-GP (Hashed Timelock Contract with Griefing Penalty). We assume a rate of penalty, say 0.01 per hour, for calculating the penalty the party has to lock in order to accept an off-chain contract request.\n>\n> A forwards the term of the contract to B, requesting B to lock 0.01*1*48=0.48 msat as a penalty. A locks 1 msat in the contract, so the total amount locked in the contract is 1.48 msat. In the same way, B forwards the term of the contract to C, requesting C to lock 0.01*1*24=0.24 msat as a penalty. B locks 1 msat in the contract, so the total amount locked in the contract is 1.24 msat. If the payment is not resolved within 1 day, all the parties who have forwarded the contract will claim the penalty locked in the contract.\n>\n> A-------------------------------------->B-------------------------------->C\n>\n> HTLC-GP(1.48 msat, 2 days) \u00a0 \u00a0 \u00a0 HTLC-GP(1.24 msat,1 day)\n>\n> If C releases the preimage before the expiration of locktime, it will claim the full amount locked in the contract, i.e. 1.24 msat. Similarly, B claims 1.48 msat from the contract established with A.\n>\n> Suppose C griefs. After an elapse of 1 day, B claims 1.24 msat from the contract. C loses 0.24 msat. When B cancels contract with A, it will settle by paying 1.48 msat to A. But then B loses an additional 0.24 msat. This is not desired as B was not involved in mounting the attack. As per the objective, even B should earn a remuneration as it got affected by griefing.\n>\n> Hence, B should have asked C to lock funds in the contract which can be used for compensating both B and A. So C must lock 0.48 msat + 0.24 msat = 0.72 msat. So if C griefs, now it loses 0.72 msat (proportional to the collateral cost of the path). B pays 0.48 msat to A, keeping 0.24 msat with itself as compensation.\n>\n> A-------------------------------------->B-------------------------------->C\n>\n> HTLC-GP(1.48 msat, 2 days) \u00a0 \u00a0 \u00a0 HTLC-GP(1.72 msat,1 day)\n>\n> A------------------------------------->B-------------------------------->C (griefs)\n>\n> (A gain 0.48 msat)\u00a0 \u00a0 \u00a0 (B gain 0.24 msat)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 (C loses 0.72 msat)\n>\n> --\n> Yours sincerely,\n> Subhra Mazumdar."
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-05-30T04:18:35",
                "message_text_only": "Hi ZmnSCPxj,\n        Thanks for your feedback. We would like to clarify certain points.\n> Can you clarify what *goal* you are assuming the party has, which the\nparty is applying its rationality towards?\n\n   - The goal of griefing-penalty is to penalize any party who intends to\n   launch a  griefing attack on the network. The strategy not only increases\n   the cost of attack but compensates other affected parties. It\n   disincentivizes an adversary from stalling the network and *enforces *good\n   behavior.\n   - Disincentivizing an adversary from carrying out griefing attack\n   definitely improves the credibility of Lightning Network. This will attract\n   more participants, willing to invest in the network, and filter out\n   malicious actors from the system by making the attack financially expensive.\n\n\nUnder the current specification of Lightning Network, griefing attack\ndoesn\u2019t result in any financial loss for the adversary. The attack can\npotentially lead to financial gain out of routing several transactions if a\ncompetitor gets eliminated.\n\n\n\nWith the introduction of *griefing-penalty*, an adversary might follow\neither of the two strategies to avoid paying penalty:\n\n   -\n\n   Myopic strategy: An adversary makes short-term gain by reverse-griefing\n   but loses in the long term because of waiting time involved in earning the\n   profit and also due to closure of channel.\n   -\n\n   Long-term strategy: If a strategy provides short term gain but incurs a\n   substantial loss in the long term without fulfilling any of the objectives\n   of griefing attack, the adversary would choose not to deviate from the\n   protocol and behave honestly.\n\n\n\n> Rationality requires some goal to work toward. Often, the goal is \"look\nout for number one\" i.e. be selfish. Thus, an economically rational selfish\nentity is not a contradiction in terms: instead, it is simply applying its\nrationality towards its own self-interest.\n\nUsing the term \u201crational and selfish\u201d in the Discussion was a poor choice\nof words. Thanks for pointing it out. We define an honest-rational party as\nsomeone who follows the protocol unless a strictly more rewarding strategy\nexists. In our paper, an honest-rational party will follow the protocol as\nthe profit earned by processing several transactions is greater than the\nprofit earned by reverse-griefing.\n\n> So if an honestly-self-rational node could be tempted to setting up\nreverse-griefing attacks, it seems to me that grief-penalty cannot work\nwell as a solution to griefing.\n\nApart from earning less profit, there are several factors which justify why\nan honest rational party would prefer to follow the protocol rather than\nturn malicious and follow a myopic strategy (i.e resort to\nreverse-griefing):\n\n\n   1.\n\n   A party who tries to reverse-grief has to wait for the expiration of the\n   off-chain contract\u2019s locktime before it can broadcast the transaction for\n   earning a penalty.\n   2.\n\n   Note that this output again is encumbered by the RSMC (1000 block\n   relative confirmation times as stated in [1]) This means that it has to\n   wait for 1000 blocks after broadcasting the penalty transaction before it\n   can actually spend the output.\n   3.\n\n   The fund locked in the contract, which acts as compensation in case of\n   misbehavior, is a substantial amount. Definitely, an intermediate party\n   won\u2019t keep its funds unutilized and try to resolve payment as soon as\n   possible.\n   4.\n\n   It leads to channel closure. Any operation performed on-chain is a\n   costly affair.  A rational party will not prefer to close the channel.\n\n\nThus an honest-rational party can earn in either of the two ways:\n\n   1.\n\n   A fee for processing payments.\n   2.\n\n   If affected by griefing attack, it gets compensated for the collateral\n   loss.\n\n\n> Given we route using onion routing, it would be trivial to create a loop\nin the route so that the same node occurs twice in it, thus trivially\nmeeting the \"at least two nodes in the path must be corrupted\" requirement.\nThat is, the sender and the receiver can be the same node, making it appear\ntwice in the path.\n\nOur assumption that at most one party is corrupted under adversarial model\nholds true for self-payment. Please refer to Corollary 1 of our Security\nAnalysis section in the paper <https://arxiv.org/abs/2005.09327>.\n\n> The solution should really prevent griefing without introducing any\nreverse-griefing.\n\nTo avoid reverse-griefing, we may add an extra round (as preprocessing\nstep) before initiating the lock phase. Additionally, the off-chain\ncontract might contain two hashes: one for normal payment and one for\nerror. Thanks to Rene Pickhardt for his suggestions\n<https://bitcoin.stackexchange.com/questions/96108/why-do-multihop-ln-payments-start-settling-from-the-recipients-end/96110#96110>\n.\n\n[1] Poon, J. and Dryja, T., 2016. The bitcoin lightning network: Scalable\noff-chain instant payments.\n<https://lightning.network/lightning-network-paper.pdf>\n\nOn Wed, May 20, 2020 at 10:23 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Subhra et al,\n>\n> I am unsure whether you actually solve the Reverse-Griefing attack that\n> the Griefing-Penalty enables.\n> It seems to me that Reverse-Griefing is worse than Griefing, since it\n> causes loss of funds already owned, whereas griefing only causes loss of\n> opportunity to earn.\n>\n> In particular:\n>\n> > With the introduction of griefing-penalty, in order to avoid paying a\n> compensation, at least two nodes in the path must be corrupted, as per the\n> argument made above.\n>\n> Given we route using onion routing, it would be trivial to create a loop\n> in the route so that the same node occurs twice in it, thus trivially\n> meeting the \"at least two nodes in the path must be corrupted\" requirement.\n>\n> That is, the sender and the receiver can be the same node, making it\n> appear twice in the path.\n>\n> >  Though we assume honest party will act rationally, in reality a party\n> is selfish\n>\n> This does not make sense.\n>\n> Rationality requires some goal to work toward.\n>\n> Often, the goal is \"look out for number one\" i.e. be selfish.\n>\n> Thus, an economically rational selfish entity is not a contradiction in\n> terms: instead, it is simply applying its rationality towards its own\n> self-interest.\n>\n> Can you clarify what *goal* you are assuming the party has, which the\n> party is applying its rationality towards?\n>\n> --\n>\n> In general, all work towards such open standards as Lightning Network and\n> so on have the motivating goal of \"creating value\": by fixing problems and\n> improving specs, everyone gets a better Lightning Network and (hopefully)\n> benefits.\n> However this is not the ultimate goal towards we work toward.\n> Instead, this is an instrumental goal, with the ultimate goal being to\n> acquire more value; the act of creating value is then performed in the hope\n> that the increase in global value will also translate to an increase in\n> your own value.\n>\n> Thus, any forwarding node, by increasing liquidity on the Lightning\n> Network, does so in the hope that it will capture some of the increased\n> value:\n>\n> * Directly, by earning fees.\n> * Indirectly, by promoting the use of Lightning and earning more future\n> fees.\n> * Even more indirectly, by promoting the use of Lightning on top of\n> Bitcoin and increasing the value of any Bitcoin held in channels.\n>\n> Thus ultimately all honest behavior is ultimately\n> honestly-rationally-selfish behavior.\n>\n> So if an honestly-self-rational node could be tempted to setting up\n> reverse-griefing attacks, it seems to me that grief-penalty cannot work\n> well as a solution to griefing.\n>\n> The solution should really prevent griefing without introducing any\n> reverse-griefing.\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> > Hi,\n> >\n> > We went through the discussion of Griefing Attack and after a thorough\n> analysis, we realized that the attack cannot be prevented as the adversary\n> doesn\u2019t suffer any loss of funds.\n> >\n> > We propose an efficient countermeasure for the attack, known as\n> Griefing-Penalty. Our proposed strategy works for any timelock based\n> payment protocol. The penalty compensates for the loss incurred by the\n> intermediaries, affected by griefing attack. You will find the paper\n> Griefing-Penalty: Countermeasure for Griefing Attack in Bitcoin-compatible\n> PCNs on arXiv. We look forward to hearing from the community on the\n> feasibility of the approach and whether it can be implemented or not.\n> >\n> > Our Contribution to the paper:\n> >\n> > \u2022 We propose a countermeasure for mitigating griefing attack in\n> Bitcoin-compatible PCNs, known as Griefing-Penalty. It punishes the griefer\n> by forcing it to pay compensation to all the parties whose funds got locked\n> for a certain time period as a result of the attack.\n> >\n> > \u2022 The loss of funds incurred upon mounting griefing-attack is\n> proportional to the collateral cost of each channel involved in routing the\n> payment.\n> >\n> > \u2022 To illustrate the benefit of the proposed countermeasure, we propose a\n> new payment protocol, called as HTLC-GP or Hashed Timelock Contract with\n> Griefing-Penalty.\n> >\n> > \u2022 We provide a security analysis which proves that our protocol is\n> privacy-preserving as well as mitigates loss due to griefing attack by\n> compensating the honest nodes\n> >\n> > We will briefly summarize the problem and our contribution through an\n> example.\n> >\n> > The problem of Griefing Attack explained briefly\n> >\n> > Consider the situation where A wants to transfer 1 msat to C. It figures\n> out a path connecting it to C, in the form A->B->C. A establishes an HTLC\n> with B, locking 1 msat in the contract having expiration time of say 2\n> days. B after receiving the incoming contract, forms a contract with C,\n> locking 1 msat in the contract with locktime of 1 day.\n> >\n> > A------------------------->B---------------------->C\n> >\n> > HTLC(1msat, 2 day)     HTLC(1msat, 1 day)\n> >\n> > Now if C griefs, funds of A and B remain locked as they cannot resolve\n> HTLC. After an elapsed time of 1 day, the fund gets unlocked and B gets\n> back 1 msat. Similarly, B cancels contract with A after 1 day, A unlocks 1\n> msat. The problem with this construction is that C doesn\u2019t lose anything.\n> >\n> > Griefing-Penalty: a strategy to penalize the adversary\n> >\n> > Hence we have come up with the following idea:\n> >\n> > 1) An off-chain contract established between 2 parties requires both the\n> parties to lock funds \u2013 one party locking the amount that is to be\n> forwarded and the other party locking the fund which can be claimed as a\n> penalty, if this party griefs.\n> >\n> > 2) The penalty locked is proportional to the product of the amount being\n> forwarded and the expiration time of the contract. All the parties affected\n> by griefing must get compensation since their liquidity is tied up for a\n> certain period of time.\n> >\n> > Considering the example used for demonstrating griefing attack. We\n> modify the contract and term it as HTLC-GP (Hashed Timelock Contract with\n> Griefing Penalty). We assume a rate of penalty, say 0.01 per hour, for\n> calculating the penalty the party has to lock in order to accept an\n> off-chain contract request.\n> >\n> > A forwards the term of the contract to B, requesting B to lock\n> 0.01*1*48=0.48 msat as a penalty. A locks 1 msat in the contract, so the\n> total amount locked in the contract is 1.48 msat. In the same way, B\n> forwards the term of the contract to C, requesting C to lock 0.01*1*24=0.24\n> msat as a penalty. B locks 1 msat in the contract, so the total amount\n> locked in the contract is 1.24 msat. If the payment is not resolved within\n> 1 day, all the parties who have forwarded the contract will claim the\n> penalty locked in the contract.\n> >\n> >\n> A-------------------------------------->B-------------------------------->C\n> >\n> > HTLC-GP(1.48 msat, 2 days)       HTLC-GP(1.24 msat,1 day)\n> >\n> > If C releases the preimage before the expiration of locktime, it will\n> claim the full amount locked in the contract, i.e. 1.24 msat. Similarly, B\n> claims 1.48 msat from the contract established with A.\n> >\n> > Suppose C griefs. After an elapse of 1 day, B claims 1.24 msat from the\n> contract. C loses 0.24 msat. When B cancels contract with A, it will settle\n> by paying 1.48 msat to A. But then B loses an additional 0.24 msat. This is\n> not desired as B was not involved in mounting the attack. As per the\n> objective, even B should earn a remuneration as it got affected by griefing.\n> >\n> > Hence, B should have asked C to lock funds in the contract which can be\n> used for compensating both B and A. So C must lock 0.48 msat + 0.24 msat =\n> 0.72 msat. So if C griefs, now it loses 0.72 msat (proportional to the\n> collateral cost of the path). B pays 0.48 msat to A, keeping 0.24 msat with\n> itself as compensation.\n> >\n> >\n> A-------------------------------------->B-------------------------------->C\n> >\n> > HTLC-GP(1.48 msat, 2 days)       HTLC-GP(1.72 msat,1 day)\n> >\n> >\n> A------------------------------------->B-------------------------------->C\n> (griefs)\n> >\n> > (A gain 0.48 msat)      (B gain 0.24 msat)              (C loses 0.72\n> msat)\n> >\n> > --\n> > Yours sincerely,\n> > Subhra Mazumdar.\n>\n>\n>\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200530/13de0e9e/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-30T06:05:36",
                "message_text_only": "Good morning Subhra,\n\n> -   Myopic strategy: An adversary makes short-term gain by reverse-griefing but loses in the long term because of waiting time involved in earning the profit and also due to closure of channel.\n>\n> -   Long-term strategy: If a strategy provides short term gain but incurs a substantial loss in the long term without fulfilling any of the objectives of griefing attack, the adversary would choose not to deviate from the protocol and behave honestly.\u00a0\n\nWhat mechanism protects against the myopic strategy?\n\nThere are many reasons why getting short-term gains *right now* via reverse-griefing is generally better:\n\n* Time discounting.\n  Money you have now is better than money you will have in the future, because you can immediately reinvest the money right now.\n  Thus, future earnings must be discounted by the expected average return on investment compared to current earnings.\n* Counterparty risk.\n  Even if you maintain the channel open in the hope of future earnings, the counterparty can very well just close the channel at any time for no discernible reason.\n  This reduces the expected return on investment by honest behavior.\n* Cheap pseudonyms.\n  All you need is to get 256 bits of entropy and you can connect as a different node.\n  VPNs and cloud servers can make it difficult to nail down specific IP addresses as belonging to you as attacker.\n\nMy reading of the paper suggests that you simply assume that the honest strategy will earn more economically than reverse-griefing; can you provide expected return of investment on other possible investments (e.g. running a JoinMarket maker) to determine time discounting, and the rate at which channels get closed for no good reason to check counterparty risk?\n\nThe fact that a reverse-griefing becomes possible means that, even after ignoring onchain fees, running a node can lead to a negative return on investment, whereas with current Lightning, if we ignore onchain fees, the minimum return on investment is 0 and you can \"only\" earn (again, emphasizing that this holds only if we ignore onchain fees; but in any case, with reverse-griefing possible, this can potentially give even worse negative return on investment if the node is attacked by reverse-griefing).\n\nGriefing can only prevent you from earning.\nReverse-griefing can lose you funds.\n\n\n> > Rationality requires some goal to work toward. Often, the goal is \"look out for number one\" i.e. be selfish. Thus, an economically rational selfish entity is not a contradiction in terms: instead, it is simply applying its rationality towards its own self-interest.\n>\n> Using the term \u201crational and selfish\u201d in the Discussion was a poor choice of words. Thanks for pointing it out. We define an honest-rational party as someone who follows the protocol unless a strictly more rewarding strategy exists. In our paper, an honest-rational party will follow the protocol as the profit earned by processing several transactions is greater than the profit earned by reverse-griefing.\n>\n> > So if an honestly-self-rational node could be tempted to setting up reverse-griefing attacks, it seems to me that grief-penalty cannot work well as a solution to griefing.\n>\n> Apart from earning less profit, there are several factors which justify why an honest rational party would prefer to follow the protocol rather than turn malicious and follow a myopic strategy (i.e resort to reverse-griefing):\n>\n> 1.  A party who tries to reverse-grief has to wait for the expiration of the off-chain contract\u2019s locktime before it can broadcast the transaction for earning a penalty.\u00a0\n\nBut an honest node that hopes to continuously earn money may need to wait even longer before somebody forwards through them, and is generally paid only a few dozen millisatoshi each time.\n\n\n> 2.  Note that this output again is encumbered by the RSMC (1000 block relative confirmation times as stated in [1]) This means that it has to wait for 1000 blocks after broadcasting the penalty transaction before it can actually spend the output.\u00a0\n\nI am unaware of any modern implementation that uses timelocks that large.\n\n\n>\n> 3.  The fund locked in the contract, which acts as compensation in case of misbehavior, is a substantial amount. Definitely, an intermediate party won\u2019t keep its funds unutilized and try to resolve payment as soon as possible.\u00a0\u00a0\u00a0\n\nLike I pointed out elsewhere, griefing attacks are attacks committed by payer/payee conspiracies against forwarding nodes; we can disregard this point since it applies to non-griefing-penalty (i.e. current Lightning) just as well.\n\n\n> 4.  It leads to channel closure. Any operation performed on-chain is a costly affair.\u00a0 A rational party will not prefer to close the channel.\n\nAnd like I pointed out, because any counterparty can close its channel with you at any time, this risk can be discounted by the expected average chance that a counterparty will close the channel for no reason.\nYes, to earn by reverse-griefing you can need to trigger the channel to be closed, but even if you leave it open, there is a chance the counterparty will close it for no reason it will bother to explain to you.\n\n>\n>\n> Thus an honest-rational party can earn in either of the two ways:\n>\n> 1.  A fee for processing payments.\n>\n> 2.  If affected by griefing attack, it gets compensated for the collateral loss.\n>\n>\n> > Given we route using onion routing, it would be trivial to create a loop in the route so that the same node occurs twice in it, thus trivially meeting the \"at least two nodes in the path must be corrupted\" requirement. That is, the sender and the receiver can be the same node, making it appear twice in the path.\n>\n> Our assumption that at most one party is corrupted under adversarial model holds true for self-payment. Please refer to Corollary 1 of our Security Analysis section in the paper.\n\nOkay.\n\n>\n> > The solution should really prevent griefing without introducing any reverse-griefing.\n>\n> To avoid reverse-griefing, we may add an extra round (as preprocessing step) before initiating the lock phase. Additionally, the off-chain contract might contain two hashes: one for normal payment and one for error. Thanks to Rene Pickhardt for his suggestions.\n\n\nCan you describe this in more detail?\n\n\nRegards,\nZmnSCPj"
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-05-30T14:52:37",
                "message_text_only": "Hi ZmnSCPxj,\n\nThanks for the feedback. The 1000 block relative confirmation time was just\na representative value, as stated in [1]. We acknowledge that practical\nimplementations have much lesser confirmation times.\n> Yes, to earn by reverse-griefing you can need to trigger the channel to\nbe closed, but even if you leave it open, there is a chance the\ncounterparty will close it for no reason it will bother to explain to you.\n\nThe possibility exists. Noted.\n\n> Can you describe this in more detail?\nHere is our proposal for mitigating reverse-griefing\nhttps://gist.github.com/subhramazumdar/cf7b043a73db136f6a23091d20e51751\nLooking forward to your comments.\n\n[1] Poon, J. and Dryja, T., 2016. The bitcoin lightning network: Scalable\noff-chain instant payments.\n<https://lightning.network/lightning-network-paper.pdf>\n\nOn Sat, May 30, 2020 at 11:35 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Subhra,\n>\n> > -   Myopic strategy: An adversary makes short-term gain by\n> reverse-griefing but loses in the long term because of waiting time\n> involved in earning the profit and also due to closure of channel.\n> >\n> > -   Long-term strategy: If a strategy provides short term gain but\n> incurs a substantial loss in the long term without fulfilling any of the\n> objectives of griefing attack, the adversary would choose not to deviate\n> from the protocol and behave honestly.\n>\n> What mechanism protects against the myopic strategy?\n>\n> There are many reasons why getting short-term gains *right now* via\n> reverse-griefing is generally better:\n>\n> * Time discounting.\n>   Money you have now is better than money you will have in the future,\n> because you can immediately reinvest the money right now.\n>   Thus, future earnings must be discounted by the expected average return\n> on investment compared to current earnings.\n> * Counterparty risk.\n>   Even if you maintain the channel open in the hope of future earnings,\n> the counterparty can very well just close the channel at any time for no\n> discernible reason.\n>   This reduces the expected return on investment by honest behavior.\n> * Cheap pseudonyms.\n>   All you need is to get 256 bits of entropy and you can connect as a\n> different node.\n>   VPNs and cloud servers can make it difficult to nail down specific IP\n> addresses as belonging to you as attacker.\n>\n> My reading of the paper suggests that you simply assume that the honest\n> strategy will earn more economically than reverse-griefing; can you provide\n> expected return of investment on other possible investments (e.g. running a\n> JoinMarket maker) to determine time discounting, and the rate at which\n> channels get closed for no good reason to check counterparty risk?\n>\n> The fact that a reverse-griefing becomes possible means that, even after\n> ignoring onchain fees, running a node can lead to a negative return on\n> investment, whereas with current Lightning, if we ignore onchain fees, the\n> minimum return on investment is 0 and you can \"only\" earn (again,\n> emphasizing that this holds only if we ignore onchain fees; but in any\n> case, with reverse-griefing possible, this can potentially give even worse\n> negative return on investment if the node is attacked by reverse-griefing).\n>\n> Griefing can only prevent you from earning.\n> Reverse-griefing can lose you funds.\n>\n>\n> > > Rationality requires some goal to work toward. Often, the goal is\n> \"look out for number one\" i.e. be selfish. Thus, an economically rational\n> selfish entity is not a contradiction in terms: instead, it is simply\n> applying its rationality towards its own self-interest.\n> >\n> > Using the term \u201crational and selfish\u201d in the Discussion was a poor\n> choice of words. Thanks for pointing it out. We define an honest-rational\n> party as someone who follows the protocol unless a strictly more rewarding\n> strategy exists. In our paper, an honest-rational party will follow the\n> protocol as the profit earned by processing several transactions is greater\n> than the profit earned by reverse-griefing.\n> >\n> > > So if an honestly-self-rational node could be tempted to setting up\n> reverse-griefing attacks, it seems to me that grief-penalty cannot work\n> well as a solution to griefing.\n> >\n> > Apart from earning less profit, there are several factors which justify\n> why an honest rational party would prefer to follow the protocol rather\n> than turn malicious and follow a myopic strategy (i.e resort to\n> reverse-griefing):\n> >\n> > 1.  A party who tries to reverse-grief has to wait for the expiration of\n> the off-chain contract\u2019s locktime before it can broadcast the transaction\n> for earning a penalty.\n>\n> But an honest node that hopes to continuously earn money may need to wait\n> even longer before somebody forwards through them, and is generally paid\n> only a few dozen millisatoshi each time.\n>\n>\n> > 2.  Note that this output again is encumbered by the RSMC (1000 block\n> relative confirmation times as stated in [1]) This means that it has to\n> wait for 1000 blocks after broadcasting the penalty transaction before it\n> can actually spend the output.\n>\n> I am unaware of any modern implementation that uses timelocks that large.\n>\n>\n> >\n> > 3.  The fund locked in the contract, which acts as compensation in case\n> of misbehavior, is a substantial amount. Definitely, an intermediate party\n> won\u2019t keep its funds unutilized and try to resolve payment as soon as\n> possible.\n>\n> Like I pointed out elsewhere, griefing attacks are attacks committed by\n> payer/payee conspiracies against forwarding nodes; we can disregard this\n> point since it applies to non-griefing-penalty (i.e. current Lightning)\n> just as well.\n>\n>\n> > 4.  It leads to channel closure. Any operation performed on-chain is a\n> costly affair.  A rational party will not prefer to close the channel.\n>\n> And like I pointed out, because any counterparty can close its channel\n> with you at any time, this risk can be discounted by the expected average\n> chance that a counterparty will close the channel for no reason.\n> Yes, to earn by reverse-griefing you can need to trigger the channel to be\n> closed, but even if you leave it open, there is a chance the counterparty\n> will close it for no reason it will bother to explain to you.\n>\n> >\n> >\n> > Thus an honest-rational party can earn in either of the two ways:\n> >\n> > 1.  A fee for processing payments.\n> >\n> > 2.  If affected by griefing attack, it gets compensated for the\n> collateral loss.\n> >\n> >\n> > > Given we route using onion routing, it would be trivial to create a\n> loop in the route so that the same node occurs twice in it, thus trivially\n> meeting the \"at least two nodes in the path must be corrupted\" requirement.\n> That is, the sender and the receiver can be the same node, making it appear\n> twice in the path.\n> >\n> > Our assumption that at most one party is corrupted under adversarial\n> model holds true for self-payment. Please refer to Corollary 1 of our\n> Security Analysis section in the paper.\n>\n> Okay.\n>\n> >\n> > > The solution should really prevent griefing without introducing any\n> reverse-griefing.\n> >\n> > To avoid reverse-griefing, we may add an extra round (as preprocessing\n> step) before initiating the lock phase. Additionally, the off-chain\n> contract might contain two hashes: one for normal payment and one for\n> error. Thanks to Rene Pickhardt for his suggestions.\n>\n>\n> Can you describe this in more detail?\n>\n>\n> Regards,\n> ZmnSCPj\n>\n\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200530/aa9aa0bd/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-31T14:51:34",
                "message_text_only": "Good morning Subhra,\n\n\n> >  Can you describe this in more detail?\n>\n> Here is our proposal for mitigating reverse-griefing\u00a0https://gist.github.com/subhramazumdar/cf7b043a73db136f6a23091d20e51751\n> Looking forward to your comments.\n\nJust to clarify my understanding, during the preprocessing stage no contracts are established yet?\n\nIf so, note that the locking phase is not safe to perform from recipient to sender (which is how it seems to be described).\n\n* R and S are really the same entity (they can be the same node, the forwarding nodes A B and C would not be aware of this at all, or they could be two very cheaply generated pseudonyms of the same entity).\n* R and C establish the contract for 7 msat, using 1 msat from C and 6 msat from R:\n  * R shows x such that h = h(x) is true, with R getting 7 msat.\n  * R shows r such that y = h(r) is true, with C getting 1 msat and R getting 6 msat.\n  * After one day, C gets 7 msat.\n* Similar contracts are established all the way to A.\n* When A contacts S, S suddenly pretends to be asleep.\n* R shows x (which it knows, because S and R are cooperating are the same and x is generated by S).\n  * It thus gets 7 msat --- 6 msat originally from R, for a net gain of 1 msat.\n* A is left holding the bag.\n\nInitial contract establishment has to be done from S to R always, not R to S.\nMulti-stage contracts can be done from R to S (arguably the simple resolution of HTLC chains is \"really' the second stage) for after the initial establishment, but initial establishment always has to be from S to R.\n\nThere may be other issues as well with the overall setup, please wait, I am considering as well what would happen if we correctly establish the contracts from S to R.\n\nThe onion packet can transfer secret data from S to R as well, there is no need for a separate communication from S to R.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Griefing-Penalty: A proposal for mitigating Griefing Attack",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Subhra Mazumdar",
                "ZmnSCPxj"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 42462
        }
    },
    {
        "title": "[Lightning-dev] Array-based Routemap Representation, and the Advantages of Cheney 2-Finger Garbage Collection",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-21T05:01:36",
                "message_text_only": "Introduction\n============\n\nReducing routemap representation size is important to compensate for possible future increases in public Lightning Network size, and also make it more practical to run a Lightning Network node on less-capable devices.\n\nIn this (mildly deranged) writeup, I propose a routemap representation with very minimal reduction in size, but allows for the implicit creation of a routefinding heuristic for pathfinding.\n\nArray-based Storage\n===================\n\nIn a modern world where nearly every device uses a 64-bit processor, a pointer takes up 8 bytes, but an index to a reasonably-sized array can be stored in 4 bytes only.\n\nIn memory garbage collection, one technique known as \"big bag of pages\" basically organizes objects according to size.\nObjects of equal size (and often, same basic type) are put in the same page.\nThus each page is actually an array of such objects, some of which are in-use, some of which are not.\n\nAny Lightning routemap requires two kinds of objects: nodes and channels.\nWe can organize the routemap such that it is stored in two arrays: an array of nodes, and an array of channels.\n\nSince they are now stored in two large arrays, references to channels and references to nodes do not have to be pointers: instead, they can be indices into the array.\nIndeed, if we limit array sizes to 65536 nodes and 65536 channels (reasonable given the current size of the public network), we can get away with using only 2 bytes per reference.\n\nNow an important advantage of the \"big bag of pages\" is that the objects are the same size (and usually type).\nNodes are arguably variable-size: they can have 1 to many channels.\n\nHowever, a technique to avoid variable-size objects is to simply use linked lists.\nWe can take some of the space advantages, and have nodes only contain a reference to their first channel.\nThen each channel has two next pointers.\nAs channels need references to the nodes they connect together anyway, we can store the reference-to-node right next to the next pointer for the list of channels of that node, so that if we are traversing the list of channels of a particular node, we know the correct next pointer to use.\n(Basically, we are embedding the list into the channel object itself, and a channel is a member of two lists, one for each node on each end)\n\nWith this, nodes and channels are fixed size, and we can use a regular array to represent them.\nLimiting the routemap to 65535 channels and 65535 nodes, we can get away with 2 bytes per reference.\n(However, it is probably more reasonable to use 4-byte array indices, as the number of public channels may exceed 60,000 in a few years, maye.)\nAs a regular array as well, the memory manager needs less overhead in managing the objects in an array, versus managing lots of objects of varying size: there is no need to store the size of each object separately, for instance, and any overheads incurred in binning and rounding up object sizes is reduced by simply asking two large array from the memory manager.\n\nDeletion of Channels and Nodes\n==============================\n\nRoutemaps are living things, and random nodes may close channels and disappear from the network completely.\n\nNow, when a channel is closed, we simply remove the channel from both lists it is on.\nWith singly-linked lists this is an O(N) operation on the number of channels a node has, which might be acceptable if we assume that closes are rare.\n\nOf course, when the channel is closed, its storage --- its entry in the channels array --- can now be reused.\nThe reasonable thing to do is to use a freelist and to add the entry to a singly-linked list of free channel entries.\n\nHowever, freelists are boring bog-standard and unexciting solutions, so let us instead consider an insane idea: use Cheney 2-finger Garbage Collection.\n\nCheney 2-finger Garbage Collection\n==================================\n\nhttps://en.wikipedia.org/wiki/Cheney%27s_algorithm\n\nThe Cheney algorithm is a copying semispace collector.\n\n* Copying: live objects are copied, then entire large spaces of garbage and copied-from memory is recovered and reused.\n* Semispace: when moving, we have a fromspace and tospace: fromspace is where objects are moved *from* and tospace is where live objects are moved *to*.\n\nAs a copying algorithm, we need to know if an object has been moved, and *where* it gets moved to.\nThis can be done in two ways:\n\n* Broken Heart tag.\n  The fromspace object header is overwritten with a specific code, and the object memory storage is overwritten with a reference to its new location.\n* Forwarding pointer.\n  Every object includes a forwarding pointer that is permanently a part of its storage, defaults to nil, and (when a collection is ongoing) is a reference to its new location.\n\nSince we want to be able to continue to use fromspace in pathfinding operations even as we are collecting garbage (i.e. incremental collection), we will use a specific forwarding pointer rather than overwriting the object with a broken heart tag.\n\nNow we describe a little the Cheney 2-finger garbage collector.\nSuppose we have the below object graph:\n\n     A --- B --- C --- D\n     |   /       |\n     |  /        |\n     | /         |\n     E --- F --- G\n\nLet us suppose that the object A is the \"root\" object, i.e. it is definitely an object we want to keep around, and any objects accessible from A are also objects we want to keep aroud.\n\nNow, as the moniker \"2-finger\" suggests, the Cheney algorithm requires two pointers.\nOne is the \"scan\" pointer and the other is the \"allocation\" pointer.\nBoth pointers are references to the tospace memory area, and, in our application, can be simple array indices rather than full pointers.\n\nFirst we copy the root object into the tospace, then point the scan pointer at it, and the allocation pointer after it:\n\n    A\n    ^ ^\n\nSince the scan pointer is currently pointing at A, we scan A and check it for references to objects that are not in tospace.\nWe can check this easily by seeing if an object it refers to has a nil forwarding pointer: if it is nil, then it has not been copied into tospace yet.\nThe A object has references to B and E, so we copy those at the allocation pointer and advance the allocation pointer to after the newly-copied objects:\n\n    A B E\n    ^     ^\n\nNow we are done with scanning A, so we advance the scan pointer to the next object, B:\n\n    A B E\n      ^   ^\n\nWe scan B, and notice it has references to A, E, and C.\nA and E already have forwarding pointers to their tospace copies, but C does not have this yet, so we copy C at the allocation pointer and advance the allocation pointer:\n\n    A B E C\n      ^     ^\n\nWe continue with this process, resulting in a tospace with the objects stored in this order:\n\n    A B E C F D G\n\nCheney is a breadth-first stackless collector: we do not have to \"recurse into\" objects in order to perform a deep scan of the object graph (stackless).\nIt is breadth-first since the order in which it scans objects is by \"spreading\" out from the root object A, instead of deeply recursing into an object subgraph and traversing deeply (depth-first).\n\nBreadth-first is generally frowned upon in modern systems, since most object accesses are deep rather than wide, and thus breadth-first tends to arrange objects in ways that are not cache-friendly if most object access is deep.\nObviously, ZmnSCPxj has gone insane and should not be listened to.\n\nBreadth-first Ordering as Pathfinding Heuristic\n===============================================\n\nLet us now review the object graph, and how the objects will be ordered by Cheney:\n\n     A --- B --- C --- D\n     |   /       |\n     |  /        |\n     | /         |\n     E --- F --- G\n\n    A B E C F D G\n\nSuppose we are at object C, and we have a pathfinding task of going from C to A.\nWhat is a nice fast heuristic for finding a path from C to A?\n\nC has links to B, D and G.\nIn the ordering created by the Cheney algorithm, B is to the left of C, while D and G are to its right.\nSo we start our path by looking at which of the object B, D, and G have the lowest address (i.e. which is leftmost in the Cheney-generated ordering).\nB is the leftmost in the order that Cheney produces, thus it is likely the one that is closest to the root node A.\n\nSo we start with C -> B.\nWe are now at B, which has links to A, C, and E.\nWhen looking at the ordering of objects produced by Cheney (equivalently, the object with the lowest address), A is the one that is ordered earliest.\nSo we make our route C -> B -> A, and find we are at our destination!\n\nWhat this all means is that the Cheney breadth-first ordering also creates a nice heuristic.\nIf A is \"our\" node, then in order to create a route from our node to any arbitrary payee, we simply start at the payee and head down links to nodes that have lower addresses, and inevitably we will go towards \"our\" node, the special root node that is at the lowest address in the order Cheney gives us.\n(in our application we would use indices, but it still holds that the lower index is nearer to \"our\" root node).\n\nNote that this is not perfect, which is why this is a \"heuristic\" and not \"hard inviolate rule that must be followed or else the world will burn\".\nPathfinding algorithms can use this as a guide for which nodes to open first, but can evaluate paths using fees and so on as well.\n\nThe heuristic is had \"for free\" --- we need *some* \"address\" or \"index\" to refer to objects anyway, and the fact that, with Cheney, the address itself encodes a heuristic for which node is (most likely) nearer to the special root destination, is basically a pure win.\n\nDisk\n====\n\nNow the big issue is that Cheney is a semispace collector, which basically means that during collection we need twice the memory, which absolutely sucks.\nObviously ZmnSCPxj has gone insane and just wants us to spend twice as much memory on the routemap right after shaving only a few bytes off the representations of nodes and channels.\n\nHowever, nothing in the algorithm actually requires that tospace be in core memory.\nWe could instead write the tospace objects into a disk file.\nCheney \"just\" requires two pointers, which we can implement simply as opening the tospace file twice, once for append (allocation pointer) and one for read/write (scan pointer).\n\nWe need two tospace files, one for node objects and one for channel objects, but in any case, once the Cheney run has completed, we can close the disk files, wait for any pending pathfinding queries to complete (and temporarily block new pathfinding queries), then reload the in-memory arrays from the tospace file(s).\n\nThis may make this technique slightly more palatable for lower-power devices, which often still have some slightly larger amount of free disk space compared to memory space.\n\nIncremental Collection\n======================\n\nWe have observed that garbage collection is itself the same algorithm that creates our pathfinding heuristic to guide pathfinding to finding the shortest path to a specific destination.\nNow, of course we want to do Cheney runs a bit more often than a normal garbage-collected environment would use, in order to refresh our heuristic when the routemap changes (new channels are created, channels are closed).\n\nOf course, while a collection run is ongoing, new changes to the routemap are still occurring, because of course writing out the routemap to disk and then reloading it is not a fast operation.\nWe can handle this by making our collection algorithm incremental.\n\nIncremental algorithms are assisted by the so-called \"tri-color abstraction\".\nhttps://en.wikipedia.org/wiki/Tracing_garbage_collection#Tri-color_marking\nObjects can be black, gray, or white.\n\n* Black - the object is definitely live, and all its referred objects have already been marked as live.\n  Or, this object has completed this run of the collection and need not be revisited by the collector algorithm.\n* Gray - the object is definitely live, but it may contain references to objects that the collector has not moved or marked as live.\n* White - the object may or may not be live; the collector has not scanned any references to it yet.\n\nThe interesting thing is that the Cheney collector gives some very easy ways to determine if a fromspace object is black, gray, or white, without adding any more memory to represent those sets, just the forwarding pointers and the two fingers (which are needed to operate the Cheney algorithm anyway):\n\n* Black - the fromspace object has a non-nil forwarding pointer, and the forwarding pointer is less than the scan pointer.\n* Gray - the fromspace object has a non-nil forwarding pointer, and the forwarding pointer is greater than the scan pointer (and less than the allocation pointer, but that is an invariant that will not be violated unless your implementation is buggy).\n* White - the fromspace object has a nil forwarding pointer yet.\n\nThe importance of the tri-color abstraction lies in the following rule:\n\n* No black object can have a reference to a white object.\n\nThis is because the collection algorithm has already \"finished with\" scanning black objects.\nThus, if the above invariant is violated, then the collection algorithm will stop working correctly.\n\nSo, let us consider what we need to do when the routemap is modified:\n\n* If a channel is closed, if the channel has a forwarding pointer to the channel tospace, we just update the equivalent object in tospace and delete it as well.\n  This cannot cause a violation in the tri-color invariant.\n* If a new channel is announced, we need to determine the colors of the nodes on both ends, and handle as follows:\n  * Black and Black: just add a new channel to the channel tospace as well, and update the tospace nodes to include it.\n  * Black and Gray: same as above.\n  * Black and White: Copy the white object to the node tospace, update the allocation pointer; this promotes the White object to Gray, then fall back to the Black and Gray case above.\n  * Gray and Gray: do nothing; the channel will eventually be added by the collector algorithm once one node or the other is reached by the scan pointer.\n  * Gray and White: do nothing, for similar reasons.\n  * White and White: do nothing, for similar reasons.\n\nWith this, we can pause the Cheney collection at any time to accept incoming changes to the routemap graph, thus retaining responsiveness even while we are performing a collection.\n\nFurther, queries for routes can continue using the fromspace copy of the routemap.\nThus, even while the routemap is being collected, pathfinding algorithms can continue running, again retaining responsiveness even while the collection is being performed.\nAs mentioned before, the only thing that would require blocking of pathfinding would be the switch between fromspace and tospace at the end of Cheney collection, which hopefully is not too slow.\n\nTenuring\n========\n\nBecause the graph is so self-centered (the root is \"our\" own node), if our node happens to not have any path to some subgraph, then they are treated as garbage and are not copied to tospace.\n\nThis is largely fine, if there is no path from our node to that subgraph then we cannot route payments to that subgraph anyway, thus their loss is perfectly fine.\n\nOf course, in the future some new channel may be created from the \"island\" to our node, and then we would have to re-download the gossip for the nodes on that island, which is bad because bandwidth.\n\nTo help against this, we could select some nodes with particularly long-lived channels (short channel IDs include the block that the channel was locked in, are a convenient way to determine the age of a channel, and are needed anyway in order to encode onion routes).\nWe can add these tenured nodes to the root set, executing Cheney as follows:\n\n* First put our own node to the root set and execute Cheney as normal.\n* When Cheney completes (scan pointer == allocation pointer), check if any tenered nodes are still white (have no forwarding pointer) and add them to the gray set (copy them to tospace and advance the allocation pointer).\n  * If any tenured nodes were promoted (scan pointer < allocation pointer), rerun Cheney.\n\nThis still retains our important property that earlier nodes in tospace are nearer to our own node, while still retaining disconnected islands attached to long-lived nodes in case they become reconnected to our own node in the future.\n\nThe set of tenured nodes can be scanned in-between Cheney runs, and can be scanned in a \"background\" manner as well."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-05-21T15:36:02",
                "message_text_only": "> Now the big issue is that Cheney is a semispace collector, which basically means that during collection we need twice the memory, which absolutely sucks.\n> Obviously ZmnSCPxj has gone insane and just wants us to spend twice as much memory on the routemap right after shaving only a few bytes off the representations of nodes and channels.\n>\n> However, nothing in the algorithm actually requires that tospace be in core memory.\n> We could instead write the tospace objects into a disk file.\n> Cheney \"just\" requires two pointers, which we can implement simply as opening the tospace file twice, once for append (allocation pointer) and one for read/write (scan pointer).\n>\n> We need two tospace files, one for node objects and one for channel objects, but in any case, once the Cheney run has completed, we can close the disk files, wait for any pending pathfinding queries to complete (and temporarily block new pathfinding queries), then reload the in-memory arrays from the tospace file(s).\n>\n> This may make this technique slightly more palatable for lower-power devices, which often still have some slightly larger amount of free disk space compared to memory space.\n\nIn fact, this is a cop-out and should be rejected.\nSemispace collection is just bad for memory utilization, and lower-resource devices do not have memory. or sufficient permanent storage, and it is apparent that ZmnSCPxj is just trolling you at this point.\n\nInstead, we should review why qsort, in its in-place array-sorting form, is considered faster than mergesort, even though the average number of compares and so on are approximately the same.\n\nThe reason for that is that qsort, as originally developed, was an in-place array-sort, unlike mergesort which is almost impossible to implement as an in-place sort without tearing your cognitive substrate out and sacrificing your firstorn sentience to the outer gods, and the sheer reduction in cache pressure of in-place sorting due to touching smaller amounts of memory is generally why qsort tends to beat mergesort in sort contests.\n\nAnd the reason why qsort *can* be an in-place sort with only constant amount of extra space needed to run it, is because (1) the elements of an array are equal size and (2) you can always swap two entries of an array in constant space.\n\nNow the original reason why Cheney two-finger semispace is even a *semispace* collector, and thus requires twice as much memory while it is running, is that objects could be different sizes.\nBut remember, we came into this with the realization that by using linked lists we can make all the objects a constant fixed size, making it far amenable to organize them into large arrays of objects.\n\nAnd just as we observe in qsort, that by swapping the pivot to a known location and then swapping it between the two partitions after we have partitioned the current array before recursing into the two sub-arrays, we can realize that we can make Cheney an in-space algorithm rather than a semispace one, by using similar swap operations.\n\nSo let us return to the motivating example:\n\n     A --- B --- C --- D\n     |   /       |\n     |  /        |\n     | /         |\n     E --- F --- G\n\nNow let us pretend that objects have been allocated willy-nilly in the array of nodes, and the nodes are located at random in the array of nodes.\nThe node A, being \"our\" own node, is still the first, because frankly any new node is going to at least know itself and will thus allocate itself as the first node in the node memory space.\n\n    A G B F C E D\n\nWe start the Cheney collection in much the same manner, except that the scan pointer and the alloc pointer point to the same space/array that the nodes are already in.\nThat is, there is no longer a tospace and fromspace, just a single space where the Cheney algorithm works inside.\nSo we start the scan and alloc pointers like so:\n\n    A G B F C E D\n    ^ ^\n\nNow we start by scanning A, which has links to B and E.\nWe swap B to the node that the alloc pointer is pointed at, then advance the alloc pointer:\n\n    A B G F C E D\n    ^   ^\n\nThen we swap E to the node that the alloc pointer is pointed at, then advance the alloc pointer:\n\n    A B E F C G D\n    ^     ^\n\nWith this, we have completed scanning A and can advance the scan pointer by one unit:\n\n    A B E F C G D\n      ^   ^\n\nNow we can pause collection --- the graph is still valid and we can still perform routing queries on it --- but let us continue.\n\nWe scan B.\nWe know that A and E have already been collected, because their indices/addresses are less than the alloc pointer.\nHowever, C is greater than or equal to the alloc pointer, so we swap it with the node in the alloc pointer and advance the alloc pointer:\n\n    A B E C F G D\n      ^     ^\n\nThere are no other nodes that B is linked to, so we advance the scan pointer:\n\n    A B E C F G D\n        ^   ^\n\nE is connected A, B, and F, A and B are below the alloc pointer, but F is at the alloc pointer and thus has to be collected as well.\nFortunately for us, F is also *at* the alloc pointer, so we do not need to actually perform any swap, just advance the alloc pointer:\n\n    A B E C F G D\n        ^     ^\n\nE has no other links, so we advance the scan pointer:\n\n    A B E C F G D\n          ^   ^\n\nContinuing the algorithm, we then end up with the result:\n\n    A B E C F D G\n\nWhich is the same result we would have gotten if we were using a semispace Cheney as well.\n\n-------\n\nNow we might wonder if we can just swap nodes around arbitrarily.\nObviously, if some other thread is accessing the graph, then this is dangerous.\nHowever, if only a single thread or process has access to the graph at any one time, we are fine.\n\nAs noted, routing queries are read-only and thus cannot possibly violate the tri-color invariant, thus we can simply pause the Cheney algorithm after advancing the scan pointer in order for the thread to service routing queries, gossip updates, or channel closes.\nThe graph remains functional and correct, though its heuristic might be inaccurate (remember, this is a heuristic, you should still use a Dijkstra-family algorithm to recover from cases where the heuristic is wrong in practice).\n\nThen the only references to the nodes, when transitioning between GC tasks to query/mutator tasks, are the table of node IDs to nodes, which we can update as well when we swap two nodes.\n\nThe gossip handler only needs to handle one case, which is to promote a White object to a Gray object if a new channel is created between a Black and a White object.\nObjects to the left of the scan pointer are Black, Gray is equal or greater to the scan pointer but less than the alloc pointer, and White is greater or equal to the alloc pointer.\nPromoting a White object to Gray is simply done by swapping with the object at the alloc pointer, then advancing the alloc pointer, as normal.\n\n\nWith this, we can manage channel objects using a freelist instead of a GC, only use GC for the nodes themselves, which is helpful so that channels do not get churned around so much.\n\nFurther, even once the Cheney algorithm ends (scan == alloc), the nodes beyond the scan/alloc pointer are definitely unreachable from this node.\nWe can mark this point, and routefinding queries for nodes beyond this border can just fail immediately with no route.\nAny nodes beyond this point might be true garbage, or they may eventually reconnect to our island.\nThis can be differentiated by checking for nodes that have no channels: we move nodes with channels to the space where nodes without channels are, and then finally discover the point at which we can reset the global allocation pointer for new nodes.\n\n\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Array-based Routemap Representation, and the Advantages of Cheney 2-Finger Garbage Collection",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "ZmnSCPxj"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 24181
        }
    },
    {
        "title": "[Lightning-dev] Speciication Meeting 2020/05/25",
        "thread_messages": [
            {
                "author": "Christian Decker",
                "date": "2020-05-23T11:08:41",
                "message_text_only": "Dear Fellow Bolters,\n\nthe next Lightning Network specification meeting will be this Monday at\n20:00 UTC [1]. The current agenda [2] is still a bit light on issues and\nPRs, which gives us some time to spend on longer term goals, and\nextended discussions. If there are issues that need to be discussed\nfeel free to add them to the agenda (comment and I'll add them to the\nlist), otherwise it'd be good to read up on the longer term topics in\nthe agenda.\n\nThe current agenda looks like this at the moment:\n\n```markdown\n# Pull Request Review\n - Update BOLT 3 transaction test vectors to use static_remotekey #758\n\n# Long Term Updates\n - Trampoline routing #654 (@t-bast)\n - Mempool tx pinning attack (@ariard @TheBlueMatt)\n - Anchor outputs #688 (@joostjager)\n - Blinded paths #765 (@t-bast)\n\n# Backlog\nThe following are topics that we should discuss at some point, so if we\nhave time to discuss them great, otherwise they slip to the next\nmeeting.\n\n - Upfront payments / DoS protection\n - Hornet (@cfromknecht)\n```\n\nSee you all on Monday, and have a great weekend ^^\n\nCheers,\nChristian\n\n[1] https://www.timeanddate.com/worldclock/converter.html?iso=20200525T200000&p1=195&p2=268&p3=179&p4=224&p5=248&p6=5\n[2] https://github.com/lightningnetwork/lightning-rfc/issues/775"
            }
        ],
        "thread_summary": {
            "title": "Speciication Meeting 2020/05/25",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Decker"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1266
        }
    }
]