[
    {
        "title": "[Lightning-dev] Blinded payments and unblinding attacks",
        "thread_messages": [
            {
                "author": "Bastien TEINTURIER",
                "date": "2022-04-01T07:35:50",
                "message_text_only": "Good morning list,\n\nIn the last couple of months, @thomash-acinq and I have spent a lot of time\nworking on route blinding for payments [1]. As you may know, route blinding\nis a prerequisite for onion messages [2] and Bolt 12 offers [3].\n\nUsing route blinding to provide anonymity for onion messages is quite\nsimple, but it is harder to use safely for payments. The reason for that is\nthat the lightning network is a very heterogeneous channels network.\n\nThe parameters used to relay payments vary widely from one channel to the\nother, and can dynamically vary over time: if not accounted for, this can\nprovide an easy fingerprint to let malicious actors guess what channels are\nactually used inside a blinded route. The ideas behind these probing attacks\nare described in more details in the route blinding proposals [4].\n\nTo protect against such attacks, the latest version of the route blinding\nspecification lets the recipient impose what parameters will be used by\nintermediate blinded nodes to relay payments (instead of using the values\nthey advertise in their `channel_update`). The parameters that matter are:\n\n* `fee_base_msat`\n* `fee_proportional_millionths`\n* `cltv_expiry_delta`\n* `htlc_minimum_msat`\n* `features` that impact payment relaying behavior\n\nWe'd like help from this list to figure out whether these are the only\nparameters that an attacker can use to fingerprint channels, or if there\nare others that we need to take into account to guarantee user privacy.\n\nNote that these attacks only work against public channels: wallet users\nrelying on unannounced channels are not at risk and will more easily\nbenefit from route blinding.\n\nI spent a lot of time re-working the specification PR to make it as clear\nas possible: please have a look at it and let me know if I can do anything\nto make it better. Don't hesitate to reach out directly with questions and\nfeedback. I strongly recommend to start with the high-level design doc [5],\nas natural language and detailed examples will help grasp the main ideas\nand subtleties of the proposal.\n\nCheers,\nBastien\n\n[1] https://github.com/lightning/bolts/pull/765\n[2] https://github.com/lightning/bolts/pull/759\n[3] https://github.com/lightning/bolts/pull/798\n[4]\nhttps://github.com/lightning/bolts/blob/route-blinding/proposals/route-blinding.md#attacks\n[5]\nhttps://github.com/lightning/bolts/blob/route-blinding/proposals/route-blinding.md\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220401/6f0347cd/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Blinded payments and unblinding attacks",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Bastien TEINTURIER"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2586
        }
    },
    {
        "title": "[Lightning-dev] lightning channels, stablecoins and fifty shades of privacy",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2022-04-04T08:23:45",
                "message_text_only": "Good morning pushd,\n\n> Good morning,\n>\n> Things that affect privacy particularly when large sums of money are involved in bitcoin:\n>\n> Liquidity, Anonymity set, Amounts, Type of addresses/scripts, Block, Locktime and Version\n>\n> I have left out things that aren't part of bitcoin protocol or blockchain like KYC. It is difficult for users to move large sums of BTC without being observed because bitcoin does not have confidential transactions to hide amounts. Coinjoin implementations have their own issues, trade-offs, some might even censor transactions and big amounts will still be a problem. Coinswap might be an alternative in future however I wanted to share one solution that could be helpful in improving privacy.\n>\n> Synonym did first [stablecoin transaction][1] in a lightning channel using Omni BOLT. Consider Alice starts a bitcoin project in which a lightning channel is used for assets like stablecoin. Bob wants to use 1000 BTC linked with an incident. He opens channels with Alice, gets stablecoin which can be used in any project that supports Omni BOLT assets.\n>\n> Questions:\n>\n> What is the lightning channel capacity when using Omni BOLT?\n>\n> What else can be improved in this setup? Anything else that I maybe missing?\n>\n> I added 'fifty shades of privacy' in subject because it was the first thing that came to my mind when I look at privacy in bitcoin and lightning.\n>\n> \u00a0 [1]: https://youtu.be/MfaqYeyake8\n\nI am not quite sure that using OmniBOLT and a stablecoin (I ssume you mean an asset ostensibly pegged to traditional currency) *improves* the privacy here.\n\nEven if you have onchain confidentiality, your counterparty *has to* know how much of the funds are theirs, and by elimination, since there are only the two of you on that channel, the remainder of the funds is yours.\nNo amount of onchain confidential transactions can hide this fact.\nAnd if the channel is unpublished, then the counterparty knows that any send from you is your own payment, and any receive to you is your own received funds.\n\nUsing a non-Bitcoin assett(whether pegged to a traditional currency or not) simply reduces the likelihood that you will be able to *use* the rest of the network, since most of the network only works with Bitcoin.\nThis reduction in liquidity translates to a reduction in anonymity set, meaning it is probably more likely that Alice will be running most of the nodes that *do* support your OmniBOLT-based asset and even if you try to route your funds elsewhere, if you use OmniBOLT, it is likely that Alice will be able to track where you moved your funds.\n\n\nYou are better off with this scheme if you want to \"clean\" 1000 BTC:\n\n* Set up a published LN node with already-clean funds (or just clean a small amount of BTC using existing CoinJoin methods).\n  * Leave it running for a while, or use your existing one.\n  * Make all or at least most of its channels published!\n  * Make sure it has at least *some* incoming capacity, use the swap-to-onchain trick or buy incoming liquidity.\n* Set up a *throwaway* LN node using your dirty 1000 BTC.\n* On your throwaway, create channel(s) to randomly-selected LN nodes.\n* Send amounts from the throwaway to your published LN node.\n* At a later time, send from your published LN node to e.g. Boltz Exchange offchain-to-onchain swap to get funds back onchain and get more incoming capacity to your published LN node.\n* Repeat until you have drained all the funds from your throwaway node.\n* Close the channels of your throwaway node and destroy all evidence of it having ever existed.\n\nThis provides privacy:\n\n* By using an intermediate published node to temporarily hold your funds:\n  * You disrupt timing correlation from the outgoing payments of your dubious throwaway node to the Boltz Exchange payment: first you pay to your published node, let the funds stew a bit, then send to the Boltz Exchange.\n  * Published node has deniability: payments *to* that node could conceivably be destined elsewhere i.e. the published node can claim it was just forwarding to someone else.\n* Source routing means that Boltz Exchange can report your onchain address, but cannot correlate it with your published node.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "pushd",
                "date": "2022-04-05T08:14:10",
                "message_text_only": "Good morning ZmnSCPxj,\n\u200b\n\n> No amount of onchain confidential transactions can hide this fact.\n\nOn-chain confidential transaction that I mentioned in my email was in this context:\n\nIf someone holds a large sum of BTC or any amount associated with an incident or an old UTXO from 2010, any transaction that spends these UTXOs will be observed by lot of chain analysts.\n\nIf this transaction was confidential, nobody can track amounts. Example: https://liquid.network/testnet/tx/4c8b1615109a29ad0fc9e4b40cdab1da3fe83447547806ee3c60e6dc337d9325\n\n> This reduction in liquidity translates to a reduction in anonymity set, meaning it is probably more likely that Alice will be running most of the nodes that *do* support your OmniBOLT-based asset and even if you try to route your funds elsewhere, if you use OmniBOLT, it is likely that Alice will be able to track where you moved your funds.\n\nI agree, liquidity and anonymity set will be less in this case. Second part can be fixed if the project was decentralized and Alice allows anyone to run nodes for providing liquidity.\n\n> You are better off with this scheme if you want to \"clean\" 1000 BTC:\n\nTried the steps on testnet and swap transaction was https://mempool.space/testnet/tx/2505145b76c978860ee8061f5cf8a59f38d2a25ecacdd2b17f706a67e6a65287\n\n> Source routing means that Boltz Exchange can report your onchain address, but cannot correlate it with your published node.\n\nI used boltz onion link: http://tboltzzrsoc3npe6sydcrh37mtnfhnbrilqi45nao6cgc6dr7n2eo3id.onion however I still need to trust boltz that no logs are saved for swaps. Maybe running own boltz backend can be helpful.\n\nThanks for responding to the email and sharing steps that could be used to break links between UTXOs using lightning. I plan to make this process easier with better UI/UX in a mobile app if this works better than coinjoin.\n\npushd\n---\nparallel lines meet at infinity?\n\n------- Original Message -------\nOn Monday, April 4th, 2022 at 1:53 PM, ZmnSCPxj ZmnSCPxj at protonmail.com wrote:\n\n> Good morning pushd,\n>\n>> Good morning,\n>>\n>> Things that affect privacy particularly when large sums of money are involved in bitcoin:\n>>\n>> Liquidity, Anonymity set, Amounts, Type of addresses/scripts, Block, Locktime and Version\n>>\n>> I have left out things that aren't part of bitcoin protocol or blockchain like KYC. It is difficult for users to move large sums of BTC without being observed because bitcoin does not have confidential transactions to hide amounts. Coinjoin implementations have their own issues, trade-offs, some might even censor transactions and big amounts will still be a problem. Coinswap might be an alternative in future however I wanted to share one solution that could be helpful in improving privacy.\n>>\n>> Synonym did first stablecoin transaction in a lightning channel using Omni BOLT. Consider Alice starts a bitcoin project in which a lightning channel is used for assets like stablecoin. Bob wants to use 1000 BTC linked with an incident. He opens channels with Alice, gets stablecoin which can be used in any project that supports Omni BOLT assets.\n>>\n>> Questions:\n>>\n>> What is the lightning channel capacity when using Omni BOLT?\n>>\n>> What else can be improved in this setup? Anything else that I maybe missing?\n>>\n>> I added 'fifty shades of privacy' in subject because it was the first thing that came to my mind when I look at privacy in bitcoin and lightning.\n>\n> I am not quite sure that using OmniBOLT and a stablecoin (I ssume you mean an asset ostensibly pegged to traditional currency) improves the privacy here.\n>\n> Even if you have onchain confidentiality, your counterparty has to know how much of the funds are theirs, and by elimination, since there are only the two of you on that channel, the remainder of the funds is yours.\n> No amount of onchain confidential transactions can hide this fact.\n> And if the channel is unpublished, then the counterparty knows that any send from you is your own payment, and any receive to you is your own received funds.\n>\n> Using a non-Bitcoin assett(whether pegged to a traditional currency or not) simply reduces the likelihood that you will be able to use the rest of the network, since most of the network only works with Bitcoin.\n> This reduction in liquidity translates to a reduction in anonymity set, meaning it is probably more likely that Alice will be running most of the nodes that do support your OmniBOLT-based asset and even if you try to route your funds elsewhere, if you use OmniBOLT, it is likely that Alice will be able to track where you moved your funds.\n>\n> You are better off with this scheme if you want to \"clean\" 1000 BTC:\n>\n> * Set up a published LN node with already-clean funds (or just clean a small amount of BTC using existing CoinJoin methods).\n> * Leave it running for a while, or use your existing one.\n> * Make all or at least most of its channels published!\n> * Make sure it has at least some incoming capacity, use the swap-to-onchain trick or buy incoming liquidity.\n> * Set up a throwaway LN node using your dirty 1000 BTC.\n> * On your throwaway, create channel(s) to randomly-selected LN nodes.\n> * Send amounts from the throwaway to your published LN node.\n> * At a later time, send from your published LN node to e.g. Boltz Exchange offchain-to-onchain swap to get funds back onchain and get more incoming capacity to your published LN node.\n> * Repeat until you have drained all the funds from your throwaway node.\n> * Close the channels of your throwaway node and destroy all evidence of it having ever existed.\n>\n> This provides privacy:\n>\n> * By using an intermediate published node to temporarily hold your funds:\n> * You disrupt timing correlation from the outgoing payments of your dubious throwaway node to the Boltz Exchange payment: first you pay to your published node, let the funds stew a bit, then send to the Boltz Exchange.\n> * Published node has deniability: payments to that node could conceivably be destined elsewhere i.e. the published node can claim it was just forwarding to someone else.\n> * Source routing means that Boltz Exchange can report your onchain address, but cannot correlate it with your published node.\n>\n> Regards,\n> ZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220405/9506edbb/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-04-05T12:28:35",
                "message_text_only": "Good morning pushd,\n\n> > Source routing means that Boltz Exchange can report your onchain address, but cannot correlate it with your published node.\n>\n> I used boltz onion link: http://tboltzzrsoc3npe6sydcrh37mtnfhnbrilqi45nao6cgc6dr7n2eo3id.onion however I still need to trust boltz that no logs are saved for swaps. Maybe running own boltz backend can be helpful.\n\nEven if Boltz keeps a record of your onchain address forever, all it knows is that you had some Lightning funds that you moved onchain.\nIt does not know that your money was originally from some incident, which is the whole point of source routing.\nIndeed, using an onion link also means that Boltz is unable to correlate your onchain address with your IP address, *and* if you have multiple Boltz swaps (which you probably need if you have 1000 BTC to clean) then Boltz cannot correlate your multiple swaps with each other (though you might want to do something like imitate how `clboss` formats the JSON request, to improve your anonymity set).\n\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "lightning channels, stablecoins and fifty shades of privacy",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "pushd",
                "ZmnSCPxj"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 11634
        }
    },
    {
        "title": "[Lightning-dev] Taro: A Taproot Asset Representation Overlay",
        "thread_messages": [
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2022-04-05T15:06:03",
                "message_text_only": "Hi y'all,\n\nI'm excited to publicly publish a new protocol I've been working on over the\npast few months: Taro. Taro is a Taproot Asset Representation Overlay which\nallows the issuance of normal and also collectible assets on the main\nBitcoin\nchain. Taro uses the Taproot script tree to commit extra asset structured\nmeta\ndata based on a hybrid merkle tree I call a Merkle Sum Sparse Merkle Tree or\nMS-SMT. An MS-SMT combined the properties of a merkle sum tree, with a\nsparse\nmerkle tree, enabling things like easily verifiable asset supply proofs and\nalso efficient proofs of non existence (eg: you prove to me you're no longer\ncommitting to the 1-of-1 holographic beefzard card during our swap). Taro\nasset\ntransfers are then embedded in a virtual/overlay transaction graph which\nuses a\nchain of asset witnesses to provably track the transfer of assets across\ntaproot outputs. Taro also has a scripting system, which allows for\nprogrammatic unlocking/transfer of assets. In the first version, the\nscripting\nsystem is actually a recursive instance of the Bitcoin Script Taproot VM,\nmeaning anything that can be expressed in the latest version of Script can\nbe\nexpressed in the Taro scripting system. Future versions of the scripting\nsystem\ncan introduce new functionality on the Taro layer, like covenants or other\nupdates.\n\nThe Taro design also supports integration with the Lightning Network\n(BOLTs) as\nthe scripting system can be used to emulate the existing HTLC structure,\nwhich\nallows for multi-hop transfers of Taro assets. Rather than modify the\ninternal\nnetwork, the protocol proposes to instead only recognize \"assets at the\nedges\",\nwhich means that only the sender+receiver actually need to know about and\nvalidate the assets. This deployment route means that we don't need to\nbuild up\nan entirely new network and liquidity for each asset. Instead, all asset\ntransfers will utilize the Bitcoin backbone of the Lightning Network, which\nmeans that the internal routers just see Bitcoin transfers as normal, and\ndon't\neven know about assets at the edges. As a result, increased demand for\ntransfers of these assets as the edges (say like a USD stablecoin), which in\nwill turn generate increased demand of LN capacity, result in more\ntransfers, and\nalso more routing revenue for the Bitcoin backbone nodes.\n\nThe set of BIPs are a multi-part suite, with the following breakdown:\n * The main Taro protocol:\nhttps://github.com/Roasbeef/bips/blob/bip-taro/bip-taro.mediawiki\n * The MS-SMT structure:\nhttps://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-ms-smt.mediawiki\n * The Taro VM:\nhttps://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-vm.mediawiki\n * The Taro address format:\nhttps://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-addr.mediawiki\n * The Taro Universe concept:\nhttps://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-universe.mediawiki\n * The Taro flat file proof format:\nhttps://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-proof-file.mediawiki\n\nRather than post them all in line (as the text wouldn't fit in the allowed\nsize\nlimit), all the BIPs can be found above.\n\n-- Laolu\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220405/930b239c/attachment.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2022-04-08T23:54:20",
                "message_text_only": "Hi Laolu,\n\n[Dropping the CC to Bitcoin-Dev as my questions below are LN focused.]\n\nThank your for the detailed proposed BIPs.  One question I have is\nwhether anything about Taro or the way you plan to implement support for\ntransferring fungible assets via asset-aware LN endpoints[1] will \naddress\nthe \"free call option\" problem, which I think was first discussed on\nthis list by Corn\u00e9 Plooy[2] and was later extended by ZmnSCPxj[3], with\nTamas Blummer[4] providing the following summary:\n\n> Failing to route on purpose can be used to opt out of a previously\n> agreed exchange of two different assets.  A rational actor will opt\n> out if the exchange is no longer [advantageous to them]. Anyone who\n> grants an option for free heads [for] financial disaster.\n> \n> This is not an issue for same asset exchange, as in payment routing,\n> since the exchange remains [equitable] at any later time point.\n> \n> Although there is no escape from above reasoning, a market maker could\n> still be profitable as long as the option is worth less than the\n> bid-ask spread.  Therefore the issue does not mean that LN cross asset\n> exchange is not feasible, but that there is lower bound on bid-ask\n> spread, that of the option premium.\n\nI know several attempts at mitigation have previously been discussed on\nthis list, such as barrier escrows[5], so I'm curious whether it's your\nplan to use one of those existing mitigations, suggest a new mitigation,\nor just not worry about it at this point (as Blummer mentioned, it\nprobably doesn't matter for swaps where price volatility is lower than\nfee income).\n\n***\n\nI'd also be curious to learn what you and others on this list think will\nbe different about using Taro versus other attempts to get LN channels\nto cross assets, e.g. allowing payments to be routed from a BTC-based\nchannel to a Liquid-BTC-based channel through an LN bridge node.  I\nbelieve a fair amount of work in LN's early design and implementation\nwas aimed at allowing cross-chain transfers but either because of the\ncomplexity, the free call option problem, or some other problem, it\nseemed to me that work on the problem was largely abandoned.\n\nThanks,\n\n-Dave\n\n[1] https://lightning.engineering/posts/2022-4-5-taro-launch/\n[2] \nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2018-May/001292.html\n[3] \nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2018-December/001752.html\n[4] \nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2018-December/001756.html\n[5] \nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2019-October/002214.html"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2022-04-11T18:59:16",
                "message_text_only": "Hi Harding,\n\nGreat questions!\n\n> anything about Taro or the way you plan to implement support for\n> transferring fungible assets via asset-aware LN endpoints[1] will address\n> the \"free call option\" problem, which I think was first discussed on this\n> list by Corn\u00e9 Plooy[2] and was later extended by ZmnSCPxj[3], with Tamas\n> Blummer[4] providing the following summary\n\nI agree w/ Tamas' quote there in that the problem doesn't exist for\ntransfers using the same asset. Consider a case of Alice sending to Bob,\nwith both of them using a hypothetical asset, USD-beef: if the final/last\nhop withholds the HTLC, then they risk Bob not accepting the HTLC either due\nto the payment timing out, or exchange rate fluctuations resulting in an\ninsufficient amount delivered to the destination (Bob wanted 10 USD-beef,\nbut the bound BTC in the onion route is only now 9 USD-beef), in either case\nthe payment would be cancelled.\n\n> I know several attempts at mitigation have previously been discussed on\n> this list, such as barrier escrows[5], so I'm curious whether it's your\n> plan to use one of those existing mitigations, suggest a new mitigation,\n> or just not worry about it at this point (as Blummer mentioned, it\n> probably doesn't matter for swaps where price volatility is lower than fee\n> income).\n\nI'd say our current plan is a combination of not worry about it at this\npoint, rely on proper pricing of the spread/fee-rate that exists at the\nfirst/last mile, and potentially introducing an upfront payment as well if\nissues pop up (precise option pricing would need to be worked out still).\nOne side benefit of introducing this upfront payment at the edges (the idea\nis that the asset channels are all private chans from the LN perfective, so\na hophint/blinded path is needed to route to them), is that it presents a\ncontrolled experiment where we can toy with the mechanics of such upfront\npayment proposals (which are a lot simpler since there's just one hop to\nfactor in).\n\nAnother difference here vs past attempts/proposals is that since all the\nassets are at the edges, identifying a party creating long lived HTLCs that\ncross an asset boundary is much simpler: the origin party is likely the one\nsending those payments. This makes it easier to detect abuse and stop\nforwarding those HTLCs (or close the channel) as unlike the prior\ngeneralized LN-DEX ideas, the origin will always be that first hop.\n\nI think another open question was exactly how a nuisance party would take\nadvantage of this opportunity:\n\n * Do they close out the channel and instead go to a traditional exchange\n   to make that arbitrage trade? What guarantee do they have that their\n   deposit gets there in time and they're able to profit.\n\n * Do they instead attempt to re-route the swap to use some other market\n   maker elsewhere in the network? In this case, won't things just recurse\n   with each party in the chain attempting to exploit the arbitrage trade?\n\nIMO as long as the spread/fees make sense at the last/first mile, then the\nparties are inactivated to carry out the transfers as they have more\ncertainty w.r.t revenues from the fees vs needing to reply on an arbitrage\ntrade that may or may not exist when they go to actually exploit it.\n\n> I'd also be curious to learn what you and others on this list think will\n> be different about using Taro versus other attempts to get LN channels to\n> cross assets, e.g. allowing payments to be routed from a BTC-based channel\n> to a Liquid-BTC-based channel through an LN bridge node.  I believe a fair\n> amount of work in LN's early design and implementation was aimed at\n> allowing cross-chain transfers but either because of the complexity, the\n> free call option problem, or some other problem, it seemed to me that work\n> on the problem was largely abandoned.\n\nI think the main difference with our approach is that the LN Bitcoin\nBackbone won't explicitly be aware of the existence of any of the assets. As\na result, we won't need core changes to the channel_update method, nor a\nglobal value carved out in the \"realm\" field (instead w/ the scid alias\nfeature that can be used to identify which channel should be used to\ncomplete the route), which was meant to be used to identify public LN routes\nthat crossed chains.\n\nOne other difference with our approach is that given all the assets are\npresented on Bitcoin itself, we don't need to worry about things like the\nother chain being down, translating time lock values, navigating forks\nacross several chains, etc.  As a result, the software can be a lot simpler,\nas everything is anchored in the Bitcoin chain, and we don't actually need\nto build in N different wallets which would really blow up the complexity.\nI think most of the other attempts were also focused on being able to\nemulate DEX-like functionality over the network. In contrast, we're\nconcerned mainly with payments, though I can see others attempting to tackle\nbuilding out an off-chain DEX systems with this new protocol base.\n\n-- Laolu\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220411/d3217ae4/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Taro: A Taproot Asset Representation Overlay",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "David A. Harding",
                "Olaoluwa Osuntokun"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 11052
        }
    },
    {
        "title": "[Lightning-dev] [bitcoin-dev] Taro: A Taproot Asset Representation Overlay",
        "thread_messages": [
            {
                "author": "Ruben Somsen",
                "date": "2022-04-07T17:14:03",
                "message_text_only": "Hi Laolu,\n\nNice work. This is an interesting protocol, in my opinion.\n\nSeeing as there's a large amount of overlap with RGB, a protocol which I\nhave examined quite extensively, I believe some of the issues I uncovered\nin that project also apply here.\n\nThe biggest issue revolves around the scripting expectations for this\nprotocol. Taro is described as being able to have its own scripting\ncapabilities that will initially be similar to Bitcoin and eventually be\nmade to do more. I'm afraid this is fundamentally impossible. Conditional\nscripts (and thus most scripts that could potentially be of interest) won't\nbe possible if the satisfaction of the condition is not recorded publicly\non-chain.\n\nThe core problem here is that you have two levels of scripting. At the\nBitcoin level the UTXO is encumbered by the Bitcoin script, then at the\nTaro level you have yet another script. This may seem similar at first\nglance to how taproot has a key path and a script path, but there are a few\nkey differences. In taproot only one of the two needs to be satisfied,\nwhile here you need to satisfy both. Furthermore, the Taro script is not\nenforced by Bitcoin, meaning those who control the Bitcoin script can\nalways choose to ignore the Taro script and destroy the Taro assets as a\nresult.\n\nI'll describe an example. Imagine Alice wants to send Bob a payment inside\nTaro, but she wants to make it conditional. Bob gets the Taro tokens if he\nreveals a pre-image, while Alice can claim the tokens back after the\ntimelock expires (i.e. the minimum scripting requirements for HTLCs). Alice\nstarts by locking up coins in a 2-of-2 multisig on the mainchain with some\nTaro tokens inside. She then gives Bob a pre-signed transaction that only\nrequires him to reveal the pre-image in order to claim the tokens. The\nissue here is that from Bitcoin's perspective, you're giving Bob a valid\ntransaction, regardless of whether he reveals the pre-image. If Bob\nmaliciously broadcasts it without the pre-image, he will have destroyed\nyour tokens.\n\nOf course this was a contrived example, as these conditions could simply\ntake place entirely in Bitcoin script, but it demonstrates that Taro script\nfundamentally cannot handle conditional payments, which is the basis for\nany meaningful script other than self-encumbering covenants (i.e. if you\nsend your Taro tokens in any way other than specified, the tokens will be\ndestroyed). Luckily this has no effect on whether Taro can function over\nLightning, because solely relying on Bitcoin's scripting capabilities\nshould be sufficient for that use case.\n\nAs a side note, it may be worth pointing out that it *is* possible to\ncreate conditional payments if the satisfaction of the condition is\nrecorded publicly on the mainchain (e.g. in an op_return), making it sort\nof a hybrid on-chain/off-chain model, but it would increase complexity\nconsiderably. I can explain this model in more detail, if it happens to\ninterest you.\n\nNow there's a second issue I want to bring up, but unfortunately my\nunderstanding of how exactly you made assets divisible is not complete\nenough to know how this problem might have manifested in Taro. Nonetheless,\nI'll try to describe it.\n\nOne of the core concepts of Taro/RGB is that the sender of the token has to\nreveal the history to the recipient. In case of an NFT the history is\nsimply every prior owner and grows linearly, but in the case of fungible\ntokens things are more complicated. Let's say Carol receives 2 fungible\nTaro tokens from Alice and 3 fungible Taro tokens from Bob. Now Carol wants\nto send 4 of them to Dave and keep 1. There are two possible designs here:\n\na.) The token history remains separate \u2013 Dave receives Alice's 2 tokens,\nBob's tokens are split and he receives 2 (or 3 from Bob 1 from Alice).\n\nb.) The token history gets merged \u2013 Dave receives 4 tokens (linking the new\noutput with both Alice and Bob's history).\n\nThe issue with a.) is that you're only ever fragmenting tokens, so\neventually you end up with lots of tiny but separate amounts. This will\ncause making large payments to involve sending lots of tokens, each with\ntheir own history. Under this model, I suspect the fixed value token model\n(e.g. 1, 2, 4, 8) might be preferable, as this prevents the entire supply\nfrom getting split into tiny fragments.\n\nThe issue with b.) is that you end up with a linked transaction graph, just\nlike in Bitcoin. If you pick a random Bitcoin UTXO and try to trace it back\nto a coinbase, you'll quickly find that it could have come from many of\nthem. The graph that you'd traverse to get to all of these coinbases is\nequivalent to the amount of history that a recipient of a Taro token has to\nvalidate in order to accept it, which I suspect quickly becomes a\nbottleneck that is not unlike that of a regular blockchain.\n\nIt'd probably be wise to make a model of the potential transaction flow,\nand simulate how it affects the size of the history in order to determine\nwhat's the best approach and to generally get a better idea of how it\naffects scaling. Also, the repeated sharing of history makes me skeptical\nabout the privacy this protocol may provide. If large amounts of history\nmoved through the hands of a large number of people, it wouldn't be very\nprivate.\n\nThere's a third third smaller issue I want to point out, which is easily\nfixable and perhaps was just a typo. In your slides, you showed a\nscreenshot of a taproot tree containing the Taro tree as the third element\nof four. This implies the location of the Taro tree inside the taproot tree\nis not fixed. What needs to be prevented here is that a taproot tree\ncontains more than one Taro tree, as that would enable the owner of the\ncommitment to show different histories to different people.\n\nFinally, let me conclude with two questions. Could you clarify the purpose\nof the sparse merkle tree in your design? I suppose you want to be able to\nopen a commitment and show it contains a certain asset without having to\nreveal any of the other assets and simultaneously guarantee that you\nhaven't committed to the same asset twice (i.e. the SMT guarantees each\nasset gets a specific location in the tree)? Or is there another reason?\n\nAnd the second question \u2013 when transferring Taro token ownership from one\nBitcoin UTXO to another, do you generate a new UTXO for the recipient or do\nyou support the ability to \"teleport\" the tokens to an existing UTXO like\nhow RGB does it? If the latter, have you given consideration to timing\nissues that might occur when someone sends tokens to an existing UTXO that\nsimultaneously happens to get spent by the owner?\n\nIn any case, I hope this email was useful. Feel free to reach out if I can\nclarify anything.\n\nGood luck with the protocol.\n\nBest regards,\nRuben\n\nOn Tue, Apr 5, 2022 at 5:06 PM Olaoluwa Osuntokun via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi y'all,\n>\n> I'm excited to publicly publish a new protocol I've been working on over\n> the\n> past few months: Taro. Taro is a Taproot Asset Representation Overlay which\n> allows the issuance of normal and also collectible assets on the main\n> Bitcoin\n> chain. Taro uses the Taproot script tree to commit extra asset structured\n> meta\n> data based on a hybrid merkle tree I call a Merkle Sum Sparse Merkle Tree\n> or\n> MS-SMT. An MS-SMT combined the properties of a merkle sum tree, with a\n> sparse\n> merkle tree, enabling things like easily verifiable asset supply proofs and\n> also efficient proofs of non existence (eg: you prove to me you're no\n> longer\n> committing to the 1-of-1 holographic beefzard card during our swap). Taro\n> asset\n> transfers are then embedded in a virtual/overlay transaction graph which\n> uses a\n> chain of asset witnesses to provably track the transfer of assets across\n> taproot outputs. Taro also has a scripting system, which allows for\n> programmatic unlocking/transfer of assets. In the first version, the\n> scripting\n> system is actually a recursive instance of the Bitcoin Script Taproot VM,\n> meaning anything that can be expressed in the latest version of Script can\n> be\n> expressed in the Taro scripting system. Future versions of the scripting\n> system\n> can introduce new functionality on the Taro layer, like covenants or other\n> updates.\n>\n> The Taro design also supports integration with the Lightning Network\n> (BOLTs) as\n> the scripting system can be used to emulate the existing HTLC structure,\n> which\n> allows for multi-hop transfers of Taro assets. Rather than modify the\n> internal\n> network, the protocol proposes to instead only recognize \"assets at the\n> edges\",\n> which means that only the sender+receiver actually need to know about and\n> validate the assets. This deployment route means that we don't need to\n> build up\n> an entirely new network and liquidity for each asset. Instead, all asset\n> transfers will utilize the Bitcoin backbone of the Lightning Network, which\n> means that the internal routers just see Bitcoin transfers as normal, and\n> don't\n> even know about assets at the edges. As a result, increased demand for\n> transfers of these assets as the edges (say like a USD stablecoin), which\n> in\n> will turn generate increased demand of LN capacity, result in more\n> transfers, and\n> also more routing revenue for the Bitcoin backbone nodes.\n>\n> The set of BIPs are a multi-part suite, with the following breakdown:\n>  * The main Taro protocol:\n> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro.mediawiki\n>  * The MS-SMT structure:\n> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-ms-smt.mediawiki\n>  * The Taro VM:\n> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-vm.mediawiki\n>  * The Taro address format:\n> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-addr.mediawiki\n>  * The Taro Universe concept:\n> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-universe.mediawiki\n>  * The Taro flat file proof format:\n> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-proof-file.mediawiki\n>\n> Rather than post them all in line (as the text wouldn't fit in the allowed\n> size\n> limit), all the BIPs can be found above.\n>\n> -- Laolu\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220407/88044966/attachment.html>"
            },
            {
                "author": "Alex Schoof",
                "date": "2022-04-07T19:11:39",
                "message_text_only": "Hey Laolu,\n\nReally interesting protocol. I'm not all the way through all of the docs\nyet, but had a few questions/comments:\n- The top-level doc (\nhttps://github.com/Roasbeef/bips/blob/bip-taro/bip-taro.mediawiki) talks\nabout embedding overlay metadata in the taproot script tree. From my\nreading, it seems like what gets committed is the root of the taro MS-SMT\ntree, while leaves of the tree itself are off-chain in a proof file. If\nthat's the case, did you look at other mechanisms to commit to a merkle\nroot? For example, I believe mainstay[1] uses a\npay-to-contract/bip175[2]-like scheme to commit sidechain merkle roots to\np2pkh/p2sh addresses with signature tweaks. Are there other interesting (to\ntaro) spend-paths that need to be allowed that led to the taproot script\ntree being particularly helpful?\n\n- It appears that the transfer proofs are kept off-chain in another file\nwhich is passed between users, where the receiver can validate the transfer\naccording to whatever semantics the taro-vm has at that moment and refuse\nto credit the sender if the transfer breaks some business logic or\nvalidation rules. This reminds me a lot of single-use-seals[3]. Is that the\nright way to think about what's going on here? If it is, then it looks like\na Universe/Multiverse is an offload/aggregation mechanism that can keep\ntrack of asset lineages on behalf of users, which would be useful for light\nclients of heavily-used asset types (so your mobile client doesnt have to\ntraverse the transfer lineage of some high-liquidity stablecoin or\nsomething).\n\n- Rubin made a good point above about how something like a conditional\ntransfer in a taro asset won't necessarily cause the conditional bitcoin\ntransfer to fail. My first thought was to have the \"carrier utxo\" for a\ntaro asset be really small, like dust + some buffer. The thought being that\nI'm basically just paying gas and if I lose `dust+buffer` amount of bitcoin\nbut not a lot of some token, then that's not great but not terrible. Where\nit gets bad is if the value of the taro asset that you're trying to\ntransfer is close to or less than the value of the bitcoin that's being\nused to do the transfer.\n\n- There's been a lot of talk lately on the bitcoin-dev list about\ncovenants, and I wonder if some of those designs (specifically TLUV or CTV)\nmight be useful with Taro, to \"lift\" some of the taro conditions into\ncovenants that encumber the underlying bitcoin. I don't have a design or\nanything, wondering if you've given this any thought.\n\n- was this originally named CMYK?\n\nThanks,\nAlex\n\n\n[1]\nhttps://cloudflare-ipfs.com/ipns/ipfs.commerceblock.com/commerceblock-whitepaper-mainstay.pdf\n[2] https://github.com/bitcoin/bips/blob/master/bip-0175.mediawiki\n[3] https://petertodd.org/2016/commitments-and-single-use-seals\n\nOn Thu, Apr 7, 2022 at 1:14 PM Ruben Somsen <rsomsen at gmail.com> wrote:\n\n> Hi Laolu,\n>\n> Nice work. This is an interesting protocol, in my opinion.\n>\n> Seeing as there's a large amount of overlap with RGB, a protocol which I\n> have examined quite extensively, I believe some of the issues I uncovered\n> in that project also apply here.\n>\n> The biggest issue revolves around the scripting expectations for this\n> protocol. Taro is described as being able to have its own scripting\n> capabilities that will initially be similar to Bitcoin and eventually be\n> made to do more. I'm afraid this is fundamentally impossible. Conditional\n> scripts (and thus most scripts that could potentially be of interest) won't\n> be possible if the satisfaction of the condition is not recorded publicly\n> on-chain.\n>\n> The core problem here is that you have two levels of scripting. At the\n> Bitcoin level the UTXO is encumbered by the Bitcoin script, then at the\n> Taro level you have yet another script. This may seem similar at first\n> glance to how taproot has a key path and a script path, but there are a few\n> key differences. In taproot only one of the two needs to be satisfied,\n> while here you need to satisfy both. Furthermore, the Taro script is not\n> enforced by Bitcoin, meaning those who control the Bitcoin script can\n> always choose to ignore the Taro script and destroy the Taro assets as a\n> result.\n>\n> I'll describe an example. Imagine Alice wants to send Bob a payment inside\n> Taro, but she wants to make it conditional. Bob gets the Taro tokens if he\n> reveals a pre-image, while Alice can claim the tokens back after the\n> timelock expires (i.e. the minimum scripting requirements for HTLCs). Alice\n> starts by locking up coins in a 2-of-2 multisig on the mainchain with some\n> Taro tokens inside. She then gives Bob a pre-signed transaction that only\n> requires him to reveal the pre-image in order to claim the tokens. The\n> issue here is that from Bitcoin's perspective, you're giving Bob a valid\n> transaction, regardless of whether he reveals the pre-image. If Bob\n> maliciously broadcasts it without the pre-image, he will have destroyed\n> your tokens.\n>\n> Of course this was a contrived example, as these conditions could simply\n> take place entirely in Bitcoin script, but it demonstrates that Taro script\n> fundamentally cannot handle conditional payments, which is the basis for\n> any meaningful script other than self-encumbering covenants (i.e. if you\n> send your Taro tokens in any way other than specified, the tokens will be\n> destroyed). Luckily this has no effect on whether Taro can function over\n> Lightning, because solely relying on Bitcoin's scripting capabilities\n> should be sufficient for that use case.\n>\n> As a side note, it may be worth pointing out that it *is* possible to\n> create conditional payments if the satisfaction of the condition is\n> recorded publicly on the mainchain (e.g. in an op_return), making it sort\n> of a hybrid on-chain/off-chain model, but it would increase complexity\n> considerably. I can explain this model in more detail, if it happens to\n> interest you.\n>\n> Now there's a second issue I want to bring up, but unfortunately my\n> understanding of how exactly you made assets divisible is not complete\n> enough to know how this problem might have manifested in Taro. Nonetheless,\n> I'll try to describe it.\n>\n> One of the core concepts of Taro/RGB is that the sender of the token has\n> to reveal the history to the recipient. In case of an NFT the history is\n> simply every prior owner and grows linearly, but in the case of fungible\n> tokens things are more complicated. Let's say Carol receives 2 fungible\n> Taro tokens from Alice and 3 fungible Taro tokens from Bob. Now Carol wants\n> to send 4 of them to Dave and keep 1. There are two possible designs here:\n>\n> a.) The token history remains separate \u2013 Dave receives Alice's 2 tokens,\n> Bob's tokens are split and he receives 2 (or 3 from Bob 1 from Alice).\n>\n> b.) The token history gets merged \u2013 Dave receives 4 tokens (linking the\n> new output with both Alice and Bob's history).\n>\n> The issue with a.) is that you're only ever fragmenting tokens, so\n> eventually you end up with lots of tiny but separate amounts. This will\n> cause making large payments to involve sending lots of tokens, each with\n> their own history. Under this model, I suspect the fixed value token model\n> (e.g. 1, 2, 4, 8) might be preferable, as this prevents the entire supply\n> from getting split into tiny fragments.\n>\n> The issue with b.) is that you end up with a linked transaction graph,\n> just like in Bitcoin. If you pick a random Bitcoin UTXO and try to trace it\n> back to a coinbase, you'll quickly find that it could have come from many\n> of them. The graph that you'd traverse to get to all of these coinbases is\n> equivalent to the amount of history that a recipient of a Taro token has to\n> validate in order to accept it, which I suspect quickly becomes a\n> bottleneck that is not unlike that of a regular blockchain.\n>\n> It'd probably be wise to make a model of the potential transaction flow,\n> and simulate how it affects the size of the history in order to determine\n> what's the best approach and to generally get a better idea of how it\n> affects scaling. Also, the repeated sharing of history makes me skeptical\n> about the privacy this protocol may provide. If large amounts of history\n> moved through the hands of a large number of people, it wouldn't be very\n> private.\n>\n> There's a third third smaller issue I want to point out, which is easily\n> fixable and perhaps was just a typo. In your slides, you showed a\n> screenshot of a taproot tree containing the Taro tree as the third element\n> of four. This implies the location of the Taro tree inside the taproot tree\n> is not fixed. What needs to be prevented here is that a taproot tree\n> contains more than one Taro tree, as that would enable the owner of the\n> commitment to show different histories to different people.\n>\n> Finally, let me conclude with two questions. Could you clarify the purpose\n> of the sparse merkle tree in your design? I suppose you want to be able to\n> open a commitment and show it contains a certain asset without having to\n> reveal any of the other assets and simultaneously guarantee that you\n> haven't committed to the same asset twice (i.e. the SMT guarantees each\n> asset gets a specific location in the tree)? Or is there another reason?\n>\n> And the second question \u2013 when transferring Taro token ownership from one\n> Bitcoin UTXO to another, do you generate a new UTXO for the recipient or do\n> you support the ability to \"teleport\" the tokens to an existing UTXO like\n> how RGB does it? If the latter, have you given consideration to timing\n> issues that might occur when someone sends tokens to an existing UTXO that\n> simultaneously happens to get spent by the owner?\n>\n> In any case, I hope this email was useful. Feel free to reach out if I can\n> clarify anything.\n>\n> Good luck with the protocol.\n>\n> Best regards,\n> Ruben\n>\n> On Tue, Apr 5, 2022 at 5:06 PM Olaoluwa Osuntokun via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi y'all,\n>>\n>> I'm excited to publicly publish a new protocol I've been working on over\n>> the\n>> past few months: Taro. Taro is a Taproot Asset Representation Overlay\n>> which\n>> allows the issuance of normal and also collectible assets on the main\n>> Bitcoin\n>> chain. Taro uses the Taproot script tree to commit extra asset structured\n>> meta\n>> data based on a hybrid merkle tree I call a Merkle Sum Sparse Merkle Tree\n>> or\n>> MS-SMT. An MS-SMT combined the properties of a merkle sum tree, with a\n>> sparse\n>> merkle tree, enabling things like easily verifiable asset supply proofs\n>> and\n>> also efficient proofs of non existence (eg: you prove to me you're no\n>> longer\n>> committing to the 1-of-1 holographic beefzard card during our swap). Taro\n>> asset\n>> transfers are then embedded in a virtual/overlay transaction graph which\n>> uses a\n>> chain of asset witnesses to provably track the transfer of assets across\n>> taproot outputs. Taro also has a scripting system, which allows for\n>> programmatic unlocking/transfer of assets. In the first version, the\n>> scripting\n>> system is actually a recursive instance of the Bitcoin Script Taproot VM,\n>> meaning anything that can be expressed in the latest version of Script\n>> can be\n>> expressed in the Taro scripting system. Future versions of the scripting\n>> system\n>> can introduce new functionality on the Taro layer, like covenants or other\n>> updates.\n>>\n>> The Taro design also supports integration with the Lightning Network\n>> (BOLTs) as\n>> the scripting system can be used to emulate the existing HTLC structure,\n>> which\n>> allows for multi-hop transfers of Taro assets. Rather than modify the\n>> internal\n>> network, the protocol proposes to instead only recognize \"assets at the\n>> edges\",\n>> which means that only the sender+receiver actually need to know about and\n>> validate the assets. This deployment route means that we don't need to\n>> build up\n>> an entirely new network and liquidity for each asset. Instead, all asset\n>> transfers will utilize the Bitcoin backbone of the Lightning Network,\n>> which\n>> means that the internal routers just see Bitcoin transfers as normal, and\n>> don't\n>> even know about assets at the edges. As a result, increased demand for\n>> transfers of these assets as the edges (say like a USD stablecoin), which\n>> in\n>> will turn generate increased demand of LN capacity, result in more\n>> transfers, and\n>> also more routing revenue for the Bitcoin backbone nodes.\n>>\n>> The set of BIPs are a multi-part suite, with the following breakdown:\n>>  * The main Taro protocol:\n>> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro.mediawiki\n>>  * The MS-SMT structure:\n>> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-ms-smt.mediawiki\n>>  * The Taro VM:\n>> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-vm.mediawiki\n>>  * The Taro address format:\n>> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-addr.mediawiki\n>>  * The Taro Universe concept:\n>> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-universe.mediawiki\n>>  * The Taro flat file proof format:\n>> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-proof-file.mediawiki\n>>\n>> Rather than post them all in line (as the text wouldn't fit in the\n>> allowed size\n>> limit), all the BIPs can be found above.\n>>\n>> -- Laolu\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n\n\n-- \n\n\nAlex Schoof\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220407/9dd3bd33/attachment-0001.html>"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2022-04-08T17:30:51",
                "message_text_only": "Hi Ruben,\n\nThanks! I don't really consider things final until we have a good set of\ntest\nvectors in the final set, after which we'd start to transition the set of\ndocuments beyond the draft state.\n\n> Seeing as there's a large amount of overlap with RGB, a protocol which I\nhave\n> examined quite extensively, I believe some of the issues I uncovered in\nthat\n> project also apply here.\n\nI'm happy to hear that someone was actually able to extract enough details\nfrom\nthe RGB devs/docs to be able to analyze it properly! In the past I tried to\nask\ntheir developers questions about how things like transfers worked[1][2],\nbut it\nseemed either people didn't know, or they hadn't finished the core design\n(large TBD sections) as they were working on adding other components to\ncreate\na \"new new Internet\".\n\n> Furthermore, the Taro script is not enforced by Bitcoin, meaning those who\n> control the Bitcoin script can always choose to ignore the Taro script and\n> destroy the Taro assets as a result.\n\nThis is correct, as a result in most contexts, an incentive exists for the\nholder of an asset to observe the Taro validation rules as otherwise, their\nassets are burnt in the process from the PoV of asset verifiers. In the\nsingle\nparty case things are pretty straight forward, but more care needs to be\ntaken\nin cases where one attempts to express partial application and permits\nanyone\nto spend a UTXO in question.\n\nBy strongly binding all assets to Bitcoin UTXOs, we resolve issues related\nto\ndouble spending or duplicate assets, but needs to mind the fact that assets\ncan\nbe burnt if a user doesn't supply a valid witness. There're likely ways to\nget\naround this by lessening the binding to Bitcoin UTXO's, but then the system\nwould need to be able to collect, retain and order all the set of possible\nspends, essentially requiring a parallel network. The core of the system as\nit\nstands today is pretty simple (which was an explicit design goal to avoid\ngetting forever distracted by the large design space), with a minimal\nimplementation being relatively compact given all the Bitcoin context/design\nre-use.\n\nAlso one cool trait of the way commitments are designed is that the Taro\ncommitment impact the final derived taproot output key. As a result,\npotential\nScript extensions like TAPLEAF_UPDATE_VERIFY can actually be used to further\n_bind_ Taro transitions at the Bitcoin level, without Bitcoin explicitly\nneeding to be aware of the Taro rules. In short, covenants can allow Bitcoin\nScript to bind Taro state transitions, without any of the logic bleeding\nover,\nas the covenant just checks for a certain output key, which is a function of\nthe Taro commitment being present.\n\n> There are two possible designs here: a.) The token history remains\nseparate \u2013\n> Dave receives Alice's 2 tokens, Bob's tokens are split and he receives 2\n(or\n> 3 from Bob 1 from Alice).  b.) The token history gets merged \u2013 Dave\nreceives\n> 4 tokens (linking the new output with both Alice and Bob's history).\n\nMechanically, with respect to the way the change/UTXOs work in the system,\nboth\nare expressible: Dave can chose to merge them into a single UTXO (with the\nappropriate witnesses included for each of them), or Dave can keep them\ndistinct in the asset tree. You're correct in that asset issuers may opt to\nissue assets in denominations vs allowing them to be fully divisible.\nUltimately, the compatibility with the LN layer will be the primary way to\nkeep\nasset histories compressed, without relying on another trust model, or\nrelying\non the incentive of an asset issuer to do a \"re-genesis\" which would\neffectively re-create assets in a supply-preserving manner (burn N units,\nthen\nproduce a new genesis outpoint for N units). Alternatively, implementations\ncan\nalso chose to utilize a checkpointing system similar to what some Bitcoin\nfull\nnode clients do today.\n\n>  is that you end up with a linked transaction graph, just like in Bitcoin\n\nThis is correct, the protocol doesn't claim to achieve better privacy\nguarantees than the base chain. However inheriting this transaction graph\nmodel\nimo makes it easier for existing Bitcoin developers to interact with the\nsystem, and all the data structures are very familiar tooling wise. However\nany\nprivacy enhancing protocol used for on-chain top-level Bitcoin UTXOs can\nalso\nbe applied to Taro, so people can use things like coinswap and coinjoin,\nalong\nwith LN to shed prior coin lineages.\n\n> This implies the location of the Taro tree inside the taproot tree is not\n> fixed. What needs to be prevented here is that a taproot tree contains\nmore\n> than one Taro tree, as that would enable the owner of the commitment to\nshow\n> different histories to different people.\n\nGreat observation, I patched a similar issue much earlier in the design\nprocess\nby strongly binding all signatures to a prevOut super-set (so the outpoint\nalong with the unique key apth down into the tree), which prevents\nduplicating\nthe asset across outputs, as signature verification would fail.\n\nIn terms of achieving this level of binding within the Taro tree itself, I\ncan\nthink of three options:\n\n  1. Require the Taro commitment to be in the first/last position within the\n  (fully sorted?) Tapscript tree, and also require its sibling to be the\nhash\n  of some set string (all zeroes or w/e). We'd require the sibling to the\nempty\n  as the tapscript hashes are sorted before hashing so you sort of lose that\n  final ordering information.\n\n  2. Include the position of the Taro commitment within the tapscript tree\n  within the sighash digest (basically the way the single input in the\nvirtual\n  transaction is created from the TLV structure).\n\n  3. Include the position of the Taro commitment within the tapscript tree\nas\n  part of the message that's hashed to derive asset IDs.\n\nAFAICT, #1 resolves the issue entirely, #2 renders transfers outside of the\ncanonical history invalid, and #2 minds hte asset ID to the initial position\nmeaning you can track a canonical lineage from the very start.\n\n> Finally, let me conclude with two questions. Could you clarify the\npurpose of\n> the sparse merkle tree in your design?\n\nSure, it does a few things:\n\n  * Non-inclusion proofs so I can do things like prove to your I'm no longer\n    committing to my 1-of-1 holographic beefzard card when we swap.\n\n  * The key/tree structure means that the tree is history independent,\nmeaning\n    that if you and I insert the same things into the tree in a different\n    order, we'll get the same root hash. This is useful for things like\n    tracking all the issuance events for a given asset, or allowing two\n    entities to sync their knowledge/history of a single asset, or a set of\n    assets.\n\n  * Each asset/script mapping to a unique location within the tree means\nit's\n    easy to ensure uniqueness of certain items/commitments (not possible to\n    commit to the same asset ID twice in the tree as an example).\n\n  * The merkle-sum trait means I that validation is made simpler, as you\njust\n    check that the input+output commitment sum to the same value, and I can\n    also verify that if we're swapping, then you aren't committing to more\n    units that exist (so I make sure I don't get an invalid split).\n\n> And the second question \u2013 when transferring Taro token ownership from one\n> Bitcoin UTXO to another, do you generate a new UTXO for the recipient or\ndo\n> you support the ability to \"teleport\" the tokens to an existing UTXO like\nhow\n> RGB does it? If the latter, have you given consideration to timing issues\n> that might occur when someone sends tokens to an existing UTXO that\n> simultaneously happens to get spent by the owner?\n\nSo for interactive transfers, the UTXOs generated as just the ones part of\nthe\nMIMO transaction. When sending via the address format, a new non-dust\noutput is\ncreated which holds the new commitment, and uses an internal key provided by\nthe receiver, so only they can move the UTXO. Admittedly, I'm not familiar\nwith\nhow the RGB \"teleport\" technique works, I checked out some slide decks a\nwhile\nback, but they were mostly about all the new components they were creating\nand\ntheir milestone of 1 million lines of code. Can you point me to a coherent\nexplanation of the technique? I'd love to compare/contrast so we can analyze\nthe diff tradeoffs being made here.\n\nThanks for an initial round of feedback/analysis, I'll be updating the draft\nover the next few days to better spell things out and particularly that\ncommitment/sighash uniqueness trait.\n\n-- Laolu\n\n[1]:\nhttps://twitter.com/roasbeef/status/1330654936074371073?s=20&t=feV0kWAjJ6MTQlFm06tSxA\n[2]:\nhttps://twitter.com/roasbeef/status/1330692571736117249?s=20&t=feV0kWAjJ6MTQlFm06tSxA\n\nOn Thu, Apr 7, 2022 at 1:14 PM Ruben Somsen <rsomsen at gmail.com> wrote:\n\n> Hi Laolu,\n>\n> Nice work. This is an interesting protocol, in my opinion.\n>\n> Seeing as there's a large amount of overlap with RGB, a protocol which I\n> have examined quite extensively, I believe some of the issues I uncovered\n> in that project also apply here.\n>\n> The biggest issue revolves around the scripting expectations for this\n> protocol. Taro is described as being able to have its own scripting\n> capabilities that will initially be similar to Bitcoin and eventually be\n> made to do more. I'm afraid this is fundamentally impossible. Conditional\n> scripts (and thus most scripts that could potentially be of interest) won't\n> be possible if the satisfaction of the condition is not recorded publicly\n> on-chain.\n>\n> The core problem here is that you have two levels of scripting. At the\n> Bitcoin level the UTXO is encumbered by the Bitcoin script, then at the\n> Taro level you have yet another script. This may seem similar at first\n> glance to how taproot has a key path and a script path, but there are a few\n> key differences. In taproot only one of the two needs to be satisfied,\n> while here you need to satisfy both. Furthermore, the Taro script is not\n> enforced by Bitcoin, meaning those who control the Bitcoin script can\n> always choose to ignore the Taro script and destroy the Taro assets as a\n> result.\n>\n> I'll describe an example. Imagine Alice wants to send Bob a payment inside\n> Taro, but she wants to make it conditional. Bob gets the Taro tokens if he\n> reveals a pre-image, while Alice can claim the tokens back after the\n> timelock expires (i.e. the minimum scripting requirements for HTLCs). Alice\n> starts by locking up coins in a 2-of-2 multisig on the mainchain with some\n> Taro tokens inside. She then gives Bob a pre-signed transaction that only\n> requires him to reveal the pre-image in order to claim the tokens. The\n> issue here is that from Bitcoin's perspective, you're giving Bob a valid\n> transaction, regardless of whether he reveals the pre-image. If Bob\n> maliciously broadcasts it without the pre-image, he will have destroyed\n> your tokens.\n>\n> Of course this was a contrived example, as these conditions could simply\n> take place entirely in Bitcoin script, but it demonstrates that Taro script\n> fundamentally cannot handle conditional payments, which is the basis for\n> any meaningful script other than self-encumbering covenants (i.e. if you\n> send your Taro tokens in any way other than specified, the tokens will be\n> destroyed). Luckily this has no effect on whether Taro can function over\n> Lightning, because solely relying on Bitcoin's scripting capabilities\n> should be sufficient for that use case.\n>\n> As a side note, it may be worth pointing out that it *is* possible to\n> create conditional payments if the satisfaction of the condition is\n> recorded publicly on the mainchain (e.g. in an op_return), making it sort\n> of a hybrid on-chain/off-chain model, but it would increase complexity\n> considerably. I can explain this model in more detail, if it happens to\n> interest you.\n>\n> Now there's a second issue I want to bring up, but unfortunately my\n> understanding of how exactly you made assets divisible is not complete\n> enough to know how this problem might have manifested in Taro. Nonetheless,\n> I'll try to describe it.\n>\n> One of the core concepts of Taro/RGB is that the sender of the token has\n> to reveal the history to the recipient. In case of an NFT the history is\n> simply every prior owner and grows linearly, but in the case of fungible\n> tokens things are more complicated. Let's say Carol receives 2 fungible\n> Taro tokens from Alice and 3 fungible Taro tokens from Bob. Now Carol wants\n> to send 4 of them to Dave and keep 1. There are two possible designs here:\n>\n> a.) The token history remains separate \u2013 Dave receives Alice's 2 tokens,\n> Bob's tokens are split and he receives 2 (or 3 from Bob 1 from Alice).\n>\n> b.) The token history gets merged \u2013 Dave receives 4 tokens (linking the\n> new output with both Alice and Bob's history).\n>\n> The issue with a.) is that you're only ever fragmenting tokens, so\n> eventually you end up with lots of tiny but separate amounts. This will\n> cause making large payments to involve sending lots of tokens, each with\n> their own history. Under this model, I suspect the fixed value token model\n> (e.g. 1, 2, 4, 8) might be preferable, as this prevents the entire supply\n> from getting split into tiny fragments.\n>\n> The issue with b.) is that you end up with a linked transaction graph,\n> just like in Bitcoin. If you pick a random Bitcoin UTXO and try to trace it\n> back to a coinbase, you'll quickly find that it could have come from many\n> of them. The graph that you'd traverse to get to all of these coinbases is\n> equivalent to the amount of history that a recipient of a Taro token has to\n> validate in order to accept it, which I suspect quickly becomes a\n> bottleneck that is not unlike that of a regular blockchain.\n>\n> It'd probably be wise to make a model of the potential transaction flow,\n> and simulate how it affects the size of the history in order to determine\n> what's the best approach and to generally get a better idea of how it\n> affects scaling. Also, the repeated sharing of history makes me skeptical\n> about the privacy this protocol may provide. If large amounts of history\n> moved through the hands of a large number of people, it wouldn't be very\n> private.\n>\n> There's a third third smaller issue I want to point out, which is easily\n> fixable and perhaps was just a typo. In your slides, you showed a\n> screenshot of a taproot tree containing the Taro tree as the third element\n> of four. This implies the location of the Taro tree inside the taproot tree\n> is not fixed. What needs to be prevented here is that a taproot tree\n> contains more than one Taro tree, as that would enable the owner of the\n> commitment to show different histories to different people.\n>\n> Finally, let me conclude with two questions. Could you clarify the purpose\n> of the sparse merkle tree in your design? I suppose you want to be able to\n> open a commitment and show it contains a certain asset without having to\n> reveal any of the other assets and simultaneously guarantee that you\n> haven't committed to the same asset twice (i.e. the SMT guarantees each\n> asset gets a specific location in the tree)? Or is there another reason?\n>\n> And the second question \u2013 when transferring Taro token ownership from one\n> Bitcoin UTXO to another, do you generate a new UTXO for the recipient or do\n> you support the ability to \"teleport\" the tokens to an existing UTXO like\n> how RGB does it? If the latter, have you given consideration to timing\n> issues that might occur when someone sends tokens to an existing UTXO that\n> simultaneously happens to get spent by the owner?\n>\n> In any case, I hope this email was useful. Feel free to reach out if I can\n> clarify anything.\n>\n> Good luck with the protocol.\n>\n> Best regards,\n> Ruben\n>\n> On Tue, Apr 5, 2022 at 5:06 PM Olaoluwa Osuntokun via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi y'all,\n>>\n>> I'm excited to publicly publish a new protocol I've been working on over\n>> the\n>> past few months: Taro. Taro is a Taproot Asset Representation Overlay\n>> which\n>> allows the issuance of normal and also collectible assets on the main\n>> Bitcoin\n>> chain. Taro uses the Taproot script tree to commit extra asset structured\n>> meta\n>> data based on a hybrid merkle tree I call a Merkle Sum Sparse Merkle Tree\n>> or\n>> MS-SMT. An MS-SMT combined the properties of a merkle sum tree, with a\n>> sparse\n>> merkle tree, enabling things like easily verifiable asset supply proofs\n>> and\n>> also efficient proofs of non existence (eg: you prove to me you're no\n>> longer\n>> committing to the 1-of-1 holographic beefzard card during our swap). Taro\n>> asset\n>> transfers are then embedded in a virtual/overlay transaction graph which\n>> uses a\n>> chain of asset witnesses to provably track the transfer of assets across\n>> taproot outputs. Taro also has a scripting system, which allows for\n>> programmatic unlocking/transfer of assets. In the first version, the\n>> scripting\n>> system is actually a recursive instance of the Bitcoin Script Taproot VM,\n>> meaning anything that can be expressed in the latest version of Script\n>> can be\n>> expressed in the Taro scripting system. Future versions of the scripting\n>> system\n>> can introduce new functionality on the Taro layer, like covenants or other\n>> updates.\n>>\n>> The Taro design also supports integration with the Lightning Network\n>> (BOLTs) as\n>> the scripting system can be used to emulate the existing HTLC structure,\n>> which\n>> allows for multi-hop transfers of Taro assets. Rather than modify the\n>> internal\n>> network, the protocol proposes to instead only recognize \"assets at the\n>> edges\",\n>> which means that only the sender+receiver actually need to know about and\n>> validate the assets. This deployment route means that we don't need to\n>> build up\n>> an entirely new network and liquidity for each asset. Instead, all asset\n>> transfers will utilize the Bitcoin backbone of the Lightning Network,\n>> which\n>> means that the internal routers just see Bitcoin transfers as normal, and\n>> don't\n>> even know about assets at the edges. As a result, increased demand for\n>> transfers of these assets as the edges (say like a USD stablecoin), which\n>> in\n>> will turn generate increased demand of LN capacity, result in more\n>> transfers, and\n>> also more routing revenue for the Bitcoin backbone nodes.\n>>\n>> The set of BIPs are a multi-part suite, with the following breakdown:\n>>  * The main Taro protocol:\n>> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro.mediawiki\n>>  * The MS-SMT structure:\n>> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-ms-smt.mediawiki\n>>  * The Taro VM:\n>> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-vm.mediawiki\n>>  * The Taro address format:\n>> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-addr.mediawiki\n>>  * The Taro Universe concept:\n>> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-universe.mediawiki\n>>  * The Taro flat file proof format:\n>> https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-proof-file.mediawiki\n>>\n>> Rather than post them all in line (as the text wouldn't fit in the\n>> allowed size\n>> limit), all the BIPs can be found above.\n>>\n>> -- Laolu\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220408/7193e07c/attachment-0001.html>"
            },
            {
                "author": "Ruben Somsen",
                "date": "2022-04-10T16:51:52",
                "message_text_only": "Hi Laolu,\n\n>happy to hear that someone was actually able to extract enough details\nfrom the RGB devs/docs to be able to analyze it properly\n\nActually, even though I eventually puzzled everything together, this did\nnot go well for me either. There is a ton of documentation, but it's a maze\nof unhelpful details, and none of it clearly maps out the fundamental\ndesign. I was also disappointed by the poor response I received when asking\nquestions, and I ended up getting chastised for helping others understand\nit and pointing out potential flaws[1][2][3].Given my experience, I think\nthe project is not in great shape, so the decision to rebuild from scratch\nseems right to me.\n\nThat said, in my opinion the above should not factor into the decision of\nwhether RGB should be credited in the Taro documentation. The design\nclearly precedes (and seems to have inspired) Taro, so in my opinion this\nshould be acknowledged. Also, the people that are responsible for the\ncurrent shape of RGB aren't the people who originated the idea, so it would\nnot be fair to the originators either (Peter Todd, Alekos Filini, Giacomo\nZucco).\n\n>assets can be burnt if a user doesn't supply a valid witness\n\nI am in agreement with what you said, but it is not clear to me whether we\nare on the same page. What I tried to say was that it does not make sense\nto build scripting support into Taro, because you can't actually do\nanything interesting with it due to this limitation. The only type of smart\ncontract you can build is one where you limit what the owner (as defined by\nBitcoin's script) can do with their own Taro tokens, or else he will burn\nthem \u2013 not very useful. Anything involving a conditional transfer of\nownership to either A or B (i.e. any meaningful type of script) won't work.\nDo you see what I mean, or should I elaborate further?\n\n>TAPLEAF_UPDATE_VERIFY can actually be used to further _bind_ Taro transitions\nat the Bitcoin level, without Bitcoin explicitly needing to be aware\n\nThat is conceptually quite interesting. So theoretically you could get\nBitcoin covenants to enforce certain spending conditions on Taro assets.\nNot sure how practical that ends up being, but intriguing to consider.\n\n>asset issuer to do a \"re-genesis\"\n\nYes, RGB suggested the same thing, and this can work under some\ncircumstances, but note that this won't help for tokens that aim to have a\npublicly audited supply, as the proof that a token was legitimately\nre-issued is the history of the previous token (so you'd actually be making\nthings worse, as now everyone has to verify it). And of course the idea\nalso requires the issuer to be active, which may not always be the case.\n\n>I'm not familiar with how the RGB \"teleport\" technique works [...] Can you\npoint me to a coherent explanation of the technique\n\nTo my knowledge no good explanation exists. \"Teleporting\" is just what I\nthought was a good way of describing it. Basically, in your design when\nAlice wants to send a Taro token to Bob, Alice has to spend her own output,\nmake a new output for Bob, and make a change output for herself. Inside the\nTaro tree you'll then point to the index of Bob's output in order to assign\nthe tokens to his new output. Instead of pointing to the index, you could\npoint to the outpoint (txid, index) of an existing UTXO owned by Bob, thus\n\"teleporting\" the Taro tokens to this UTXO. This saves on-chain space, as\nnow you don't have to create a new output for Bob (but now you have to\nensure Bob doesn't spend from this output while you're simultaneously\nsending tokens to it, as I mentioned in my previous post, as this would\ndestroy the tokens).\n\nThe above also reminds me of another potential issue which you need to be\naware of, if you're not already. Similar to my comment about how the\nlocation of the Taro tree inside the taproot tree needs to be deterministic\nfor the verifier, the output in which you place the Taro tree also needs to\nbe. If it's not, then you can commit to a different Taro tree in each\noutput of the transaction, allowing you to secretly fork the history.\n\nHope this helps.\n\nCheers,\nRuben\n\n[1] https://twitter.com/SomsenRuben/status/1397267261619064836\n[2] https://twitter.com/SomsenRuben/status/1397559406565462017\n[3] https://twitter.com/afilini/status/1397484341236797441\n\nOn Fri, Apr 8, 2022 at 7:48 PM Olaoluwa Osuntokun <laolu32 at gmail.com> wrote:\n\n> (this might be a double post as it ran into the size limit)\n>\n> Hi Ruben,\n>\n> Thanks! I don't really consider things final until we have a good set of\n> test\n> vectors in the final set, after which we'd start to transition the set of\n> documents beyond the draft state.\n>\n> > Seeing as there's a large amount of overlap with RGB, a protocol which I\n> have\n> > examined quite extensively, I believe some of the issues I uncovered in\n> that\n> > project also apply here.\n>\n> I'm happy to hear that someone was actually able to extract enough details\n> from\n> the RGB devs/docs to be able to analyze it properly! In the past I tried\n> to ask\n> their developers questions about how things like transfers worked[1][2],\n> but it\n> seemed either people didn't know, or they hadn't finished the core design\n> (large TBD sections) as they were working on adding other components to\n> create\n> a \"new new Internet\".\n>\n> > Furthermore, the Taro script is not enforced by Bitcoin, meaning those\n> who\n> > control the Bitcoin script can always choose to ignore the Taro script\n> and\n> > destroy the Taro assets as a result.\n>\n> This is correct, as a result in most contexts, an incentive exists for the\n> holder of an asset to observe the Taro validation rules as otherwise, their\n> assets are burnt in the process from the PoV of asset verifiers. In the\n> single\n> party case things are pretty straight forward, but more care needs to be\n> taken\n> in cases where one attempts to express partial application and permits\n> anyone\n> to spend a UTXO in question.\n>\n> By strongly binding all assets to Bitcoin UTXOs, we resolve issues related\n> to\n> double spending or duplicate assets, but needs to mind the fact that\n> assets can\n> be burnt if a user doesn't supply a valid witness. There're likely ways to\n> get\n> around this by lessening the binding to Bitcoin UTXO's, but then the system\n> would need to be able to collect, retain and order all the set of possible\n> spends, essentially requiring a parallel network. The core of the system\n> as it\n> stands today is pretty simple (which was an explicit design goal to avoid\n> getting forever distracted by the large design space), with a minimal\n> implementation being relatively compact given all the Bitcoin\n> context/design\n> re-use.\n>\n> Also one cool trait of the way commitments are designed is that the Taro\n> commitment impact the final derived taproot output key. As a result,\n> potential\n> Script extensions like TAPLEAF_UPDATE_VERIFY can actually be used to\n> further\n> _bind_ Taro transitions at the Bitcoin level, without Bitcoin explicitly\n> needing to be aware of the Taro rules. In short, covenants can allow\n> Bitcoin\n> Script to bind Taro state transitions, without any of the logic bleeding\n> over,\n> as the covenant just checks for a certain output key, which is a function\n> of\n> the Taro commitment being present.\n>\n> > There are two possible designs here: a.) The token history remains\n> separate \u2013\n> > Dave receives Alice's 2 tokens, Bob's tokens are split and he receives 2\n> (or\n> > 3 from Bob 1 from Alice).  b.) The token history gets merged \u2013 Dave\n> receives\n> > 4 tokens (linking the new output with both Alice and Bob's history).\n>\n> Mechanically, with respect to the way the change/UTXOs work in the system,\n> both\n> are expressible: Dave can chose to merge them into a single UTXO (with the\n> appropriate witnesses included for each of them), or Dave can keep them\n> distinct in the asset tree. You're correct in that asset issuers may opt to\n> issue assets in denominations vs allowing them to be fully divisible.\n> Ultimately, the compatibility with the LN layer will be the primary way to\n> keep\n> asset histories compressed, without relying on another trust model, or\n> relying\n> on the incentive of an asset issuer to do a \"re-genesis\" which would\n> effectively re-create assets in a supply-preserving manner (burn N units,\n> then\n> produce a new genesis outpoint for N units). Alternatively,\n> implementations can\n> also chose to utilize a checkpointing system similar to what some Bitcoin\n> full\n> node clients do today.\n>\n> >  is that you end up with a linked transaction graph, just like in Bitcoin\n>\n> This is correct, the protocol doesn't claim to achieve better privacy\n> guarantees than the base chain. However inheriting this transaction graph\n> model\n> imo makes it easier for existing Bitcoin developers to interact with the\n> system, and all the data structures are very familiar tooling wise.\n> However any\n> privacy enhancing protocol used for on-chain top-level Bitcoin UTXOs can\n> also\n> be applied to Taro, so people can use things like coinswap and coinjoin,\n> along\n> with LN to shed prior coin lineages.\n>\n> > This implies the location of the Taro tree inside the taproot tree is not\n> > fixed. What needs to be prevented here is that a taproot tree contains\n> more\n> > than one Taro tree, as that would enable the owner of the commitment to\n> show\n> > different histories to different people.\n>\n> Great observation, I patched a similar issue much earlier in the design\n> process\n> by strongly binding all signatures to a prevOut super-set (so the outpoint\n> along with the unique key apth down into the tree), which prevents\n> duplicating\n> the asset across outputs, as signature verification would fail.\n>\n> In terms of achieving this level of binding within the Taro tree itself, I\n> can\n> think of three options:\n>\n>   1. Require the Taro commitment to be in the first/last position within\n> the\n>   (fully sorted?) Tapscript tree, and also require its sibling to be the\n> hash\n>   of some set string (all zeroes or w/e). We'd require the sibling to the\n> empty\n>   as the tapscript hashes are sorted before hashing so you sort of lose\n> that\n>   final ordering information.\n>\n>   2. Include the position of the Taro commitment within the tapscript tree\n>   within the sighash digest (basically the way the single input in the\n> virtual\n>   transaction is created from the TLV structure).\n>\n>   3. Include the position of the Taro commitment within the tapscript tree\n> as\n>   part of the message that's hashed to derive asset IDs.\n>\n> AFAICT, #1 resolves the issue entirely, #2 renders transfers outside of the\n> canonical history invalid, and #2 minds hte asset ID to the initial\n> position\n> meaning you can track a canonical lineage from the very start.\n>\n> > Finally, let me conclude with two questions. Could you clarify the\n> purpose of\n> > the sparse merkle tree in your design?\n>\n> Sure, it does a few things:\n>\n>   * Non-inclusion proofs so I can do things like prove to your I'm no\n> longer\n>     committing to my 1-of-1 holographic beefzard card when we swap.\n>\n>   * The key/tree structure means that the tree is history independent,\n> meaning\n>     that if you and I insert the same things into the tree in a different\n>     order, we'll get the same root hash. This is useful for things like\n>     tracking all the issuance events for a given asset, or allowing two\n>     entities to sync their knowledge/history of a single asset, or a set of\n>     assets.\n>\n>   * Each asset/script mapping to a unique location within the tree means\n> it's\n>     easy to ensure uniqueness of certain items/commitments (not possible to\n>     commit to the same asset ID twice in the tree as an example).\n>\n>   * The merkle-sum trait means I that validation is made simpler, as you\n> just\n>     check that the input+output commitment sum to the same value, and I can\n>     also verify that if we're swapping, then you aren't committing to more\n>     units that exist (so I make sure I don't get an invalid split).\n>\n> > And the second question \u2013 when transferring Taro token ownership from one\n> > Bitcoin UTXO to another, do you generate a new UTXO for the recipient or\n> do\n> > you support the ability to \"teleport\" the tokens to an existing UTXO\n> like how\n> > RGB does it? If the latter, have you given consideration to timing issues\n> > that might occur when someone sends tokens to an existing UTXO that\n> > simultaneously happens to get spent by the owner?\n>\n> So for interactive transfers, the UTXOs generated as just the ones part of\n> the\n> MIMO transaction. When sending via the address format, a new non-dust\n> output is\n> created which holds the new commitment, and uses an internal key provided\n> by\n> the receiver, so only they can move the UTXO. Admittedly, I'm not familiar\n> with\n> how the RGB \"teleport\" technique works, I checked out some slide decks a\n> while\n> back, but they were mostly about all the new components they were creating\n> and\n> their milestone of 1 million lines of code. Can you point me to a coherent\n> explanation of the technique? I'd love to compare/contrast so we can\n> analyze\n> the diff tradeoffs being made here.\n>\n> Thanks for an initial round of feedback/analysis, I'll be updating the\n> draft\n> over the next few days to better spell things out and particularly that\n> commitment/sighash uniqueness trait.\n>\n> -- Laolu\n>\n> [1]:\n> https://twitter.com/roasbeef/status/1330654936074371073?s=20&t=feV0kWAjJ6MTQlFm06tSxA\n> [2]:\n> https://twitter.com/roasbeef/status/1330692571736117249?s=20&t=feV0kWAjJ6MTQlFm06tSxA\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220410/99b8e403/attachment-0001.html>"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2022-04-11T19:51:55",
                "message_text_only": "Hi Ruben,\n\n> Also, the people that are responsible for the current shape of RGB aren't\n> the people who originated the idea, so it would not be fair to the\n> originators either (Peter Todd, Alekos Filini, Giacomo Zucco).\n\nSure I have no problems acknowledging them in the current BIP draft. Both\nthe protocols build off of ideas re client-side-validation, but then end up\nexploring different parts of the large design space.  Peter Todd is already\nthere, but I can add the others you've listed. I might even just expand that\nsection into a longer \"Related Work\" section along the way.\n\n> What I tried to say was that it does not make sense to build scripting\n> support into Taro, because you can't actually do anything interesting with\n> it due to this limitation.  can do with their own Taro tokens, or else he\n> will burn them \u2013 not very useful\n\nI agree that the usage will be somewhat context specific, and dependent on\nthe security properties one is after. In the current purposefully simplified\nversion, it's correct that ignoring the rules leads to assets being burnt,\nbut in most cases imo that's a sufficient enough incentive to maintain and\nvalidate the relevant set of witnesses.\n\nI was thinking about the scripting layer a bit over the weekend, and came up\nwith a \"issuance covenant\" design sketch that may or may not be useful. At a\nhigh level, lets say we extend the system to allow a specified (so a new\nasset type) or generalized script to be validated when an asset issuance\ntransaction is being validated. If we add some new domain specific covenant\nop codes at the Taro level, then we'd be able to validate issuance events\nlike:\n\n  * \"Issuing N units of this assets can only be done if 1.5*N units of BTC\n    are present in the nth output of the minting transaction. In addition,\n    the output created must commit to a NUMs point for the internal key,\n    meaning that only a script path is possible. The script paths must be\n    revealed, with the only acceptable unlocking leaf being a time lock of 9\n    months\".\n\nI don't fully have a concrete protocol that would use something like that,\nbut that was an attempt to express certain collateralization requirements\nfor issuing certain assets. Verifiers would only recognize that asset if the\nissuance covenant script passes, and (perhaps) the absolute timelock on\nthose coins hasn't expired yet. This seems like a useful primitive for\ncreating assets that are somehow backed by on-chain BTC collateralization.\nHowever this is just a design sketch that needs to answer questions like:\n\n  * are the assets still valid after that timeout period, or are they\n    considered to be burnt?\n\n  * assuming that the \"asset key family\" (used to authorize issuance of\n    related assets) are jointly owned, and maintained in a canonical\n    Universe, then would it be possible for 3rd parties to verify the level\n    of collateralization on-chain, with the join parties maintaining the\n    pool of collateralized assets accordingly?\n\n  * continuing with the above, is it feasible to use a DLC script within one\n    of these fixed tapscript leaves to allow more collateral to be\n    added/removed from the pool backing those assets?\n\nI think it's too early to conclude that the scripting layer isn't useful.\nOver time I plan to add more concrete ideas like the above to the section\ntracking the types of applications that can be built on Taro.\n\n> So theoretically you could get Bitcoin covenants to enforce certain\n> spending conditions on Taro assets. Not sure how practical that ends up\n> being, but intriguing to consider.\n\nExactly! Exactly how practical it ends up being would depend on the types of\ncovenants deployed in the future. With something like a TLUV and OP_CAT (as\nthey're sufficiently generalized vs adding op codes to very the proofs) a\nScript would be able to re-create the set of commitments to restrict the set\nof outputs that can be created after spending. One would use OP_CAT to\nhandle re-creating the taro asset root, and TLUV (or something similar) to\nhandle the Bitcoin tapscript part (swap out leaf index 0 where the taro\ncommitment is, etc).\n\n> The above also reminds me of another potential issue which you need to be\n> aware of, if you're not already. Similar to my comment about how the\n> location of the Taro tree inside the taproot tree needs to be\n> deterministic for the verifier, the output in which you place the Taro\n> tree also needs to be\n\nYep, the location needs to be fully specified which includes factoring the\noutput index as well. A simple way to restrict this would just to say it's\nalways the first output. Otherwise, you could lift the output index into the\nasset ID calculation.\n\n-- Laolu\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220411/b1c5440a/attachment-0001.html>"
            },
            {
                "author": "Ruben Somsen",
                "date": "2022-04-15T13:14:40",
                "message_text_only": "Hi Laolu,\n\n> ignoring the rules leads to assets being burnt, but in most cases imo\nthat's a sufficient enough incentive to maintain and validate the relevant\nset of witnesses\n\nI agree it is sufficient, but only because using Bitcoin script without an\nadditional scripting language inside of Taro is already sufficient. Perhaps\nyou could show me a concrete example where you think replicating Bitcoin's\nscripting capabilities inside Taro can be useful, so I can show you where I\nthink it fails.\n\n> came up with a \"issuance covenant\" design sketch that may or may not be\nuseful\n\nTo summarize my view from my first post, I basically think there are two\nbroad exceptions to the \"can't do scripting\" rule:\n\n1. Self-encumbrance: you have to use the token according to the rules, else\nthe token becomes burned/invalid. The example you're giving here can be\nsaid to fall under this category. The usefulness of this is\nextremely narrow, and merely replicating Bitcoin's script inside of Taro is\ncertainly not sufficient to achieve it.\n\n2. On-chain validation: instead of keeping the satisfaction of the script\noff-chain, you publish it on-chain in the Bitcoin blockchain. This works,\nbut breaks a fundamental design goal of Taro/RGB (remaining off-chain), and\nadds significant complexity.\n\nThese two points lead me to my conclusion that off-chain validation\nprotocols (to rule out the exception in point 2) can't do any meaningful\n(to rule out the exception in point 1) scripting.\n\nThis doesn't mean you can't still add some scripting to facilitate certain\nuse cases that fall under the two exceptions, but a regular scripting\nlanguage for on-chain payments such as Bitcoin's is not going to cut it (at\nleast not without significant changes).\n\nPersonally I'd be inclined to leave out the scripting language altogether\n(as the encumbrance of Bitcoin UTXOs is sufficient in most cases), unless\nyou have a very specific and compelling use case in mind that justify the\ncomplexity.\n\nCheers,\nRuben\n\n\nOn Mon, Apr 11, 2022 at 9:52 PM Olaoluwa Osuntokun <laolu32 at gmail.com>\nwrote:\n\n> Hi Ruben,\n>\n> > Also, the people that are responsible for the current shape of RGB aren't\n> > the people who originated the idea, so it would not be fair to the\n> > originators either (Peter Todd, Alekos Filini, Giacomo Zucco).\n>\n> Sure I have no problems acknowledging them in the current BIP draft. Both\n> the protocols build off of ideas re client-side-validation, but then end up\n> exploring different parts of the large design space.  Peter Todd is already\n> there, but I can add the others you've listed. I might even just expand\n> that\n> section into a longer \"Related Work\" section along the way.\n>\n> > What I tried to say was that it does not make sense to build scripting\n> > support into Taro, because you can't actually do anything interesting\n> with\n> > it due to this limitation.  can do with their own Taro tokens, or else he\n> > will burn them \u2013 not very useful\n>\n> I agree that the usage will be somewhat context specific, and dependent on\n> the security properties one is after. In the current purposefully\n> simplified\n> version, it's correct that ignoring the rules leads to assets being burnt,\n> but in most cases imo that's a sufficient enough incentive to maintain and\n> validate the relevant set of witnesses.\n>\n> I was thinking about the scripting layer a bit over the weekend, and came\n> up\n> with a \"issuance covenant\" design sketch that may or may not be useful. At\n> a\n> high level, lets say we extend the system to allow a specified (so a new\n> asset type) or generalized script to be validated when an asset issuance\n> transaction is being validated. If we add some new domain specific covenant\n> op codes at the Taro level, then we'd be able to validate issuance events\n> like:\n>\n>   * \"Issuing N units of this assets can only be done if 1.5*N units of BTC\n>     are present in the nth output of the minting transaction. In addition,\n>     the output created must commit to a NUMs point for the internal key,\n>     meaning that only a script path is possible. The script paths must be\n>     revealed, with the only acceptable unlocking leaf being a time lock of\n> 9\n>     months\".\n>\n> I don't fully have a concrete protocol that would use something like that,\n> but that was an attempt to express certain collateralization requirements\n> for issuing certain assets. Verifiers would only recognize that asset if\n> the\n> issuance covenant script passes, and (perhaps) the absolute timelock on\n> those coins hasn't expired yet. This seems like a useful primitive for\n> creating assets that are somehow backed by on-chain BTC collateralization.\n> However this is just a design sketch that needs to answer questions like:\n>\n>   * are the assets still valid after that timeout period, or are they\n>     considered to be burnt?\n>\n>   * assuming that the \"asset key family\" (used to authorize issuance of\n>     related assets) are jointly owned, and maintained in a canonical\n>     Universe, then would it be possible for 3rd parties to verify the level\n>     of collateralization on-chain, with the join parties maintaining the\n>     pool of collateralized assets accordingly?\n>\n>   * continuing with the above, is it feasible to use a DLC script within\n> one\n>     of these fixed tapscript leaves to allow more collateral to be\n>     added/removed from the pool backing those assets?\n>\n> I think it's too early to conclude that the scripting layer isn't useful.\n> Over time I plan to add more concrete ideas like the above to the section\n> tracking the types of applications that can be built on Taro.\n>\n> > So theoretically you could get Bitcoin covenants to enforce certain\n> > spending conditions on Taro assets. Not sure how practical that ends up\n> > being, but intriguing to consider.\n>\n> Exactly! Exactly how practical it ends up being would depend on the types\n> of\n> covenants deployed in the future. With something like a TLUV and OP_CAT (as\n> they're sufficiently generalized vs adding op codes to very the proofs) a\n> Script would be able to re-create the set of commitments to restrict the\n> set\n> of outputs that can be created after spending. One would use OP_CAT to\n> handle re-creating the taro asset root, and TLUV (or something similar) to\n> handle the Bitcoin tapscript part (swap out leaf index 0 where the taro\n> commitment is, etc).\n>\n> > The above also reminds me of another potential issue which you need to be\n> > aware of, if you're not already. Similar to my comment about how the\n> > location of the Taro tree inside the taproot tree needs to be\n> > deterministic for the verifier, the output in which you place the Taro\n> > tree also needs to be\n>\n> Yep, the location needs to be fully specified which includes factoring the\n> output index as well. A simple way to restrict this would just to say it's\n> always the first output. Otherwise, you could lift the output index into\n> the\n> asset ID calculation.\n>\n> -- Laolu\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220415/17d2aa29/attachment.html>"
            },
            {
                "author": "Dr Maxim Orlovsky",
                "date": "2022-04-11T16:38:37",
                "message_text_only": "https://twitter.com/dr_orlovsky/status/1513555717218873355?s=21&t=NbHfD-n1NEu8Gdh-dOPifA\n\nYou do not deserve any other form of answer.\n\nOn Tue, Apr 5, 2022 at 5:06 PM, Olaoluwa Osuntokun via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi y'all,\n>\n> I'm excited to publicly publish a new protocol I've been working on over the\n> past few months: Taro. Taro is a Taproot Asset Representation Overlay which\n> allows the issuance of normal and also collectible assets on the main Bitcoin\n> chain. Taro uses the Taproot script tree to commit extra asset structured meta\n> data based on a hybrid merkle tree I call a Merkle Sum Sparse Merkle Tree or\n> MS-SMT. An MS-SMT combined the properties of a merkle sum tree, with a sparse\n> merkle tree, enabling things like easily verifiable asset supply proofs and\n> also efficient proofs of non existence (eg: you prove to me you're no longer\n> committing to the 1-of-1 holographic beefzard card during our swap). Taro asset\n> transfers are then embedded in a virtual/overlay transaction graph which uses a\n> chain of asset witnesses to provably track the transfer of assets across\n> taproot outputs. Taro also has a scripting system, which allows for\n> programmatic unlocking/transfer of assets. In the first version, the scripting\n> system is actually a recursive instance of the Bitcoin Script Taproot VM,\n> meaning anything that can be expressed in the latest version of Script can be\n> expressed in the Taro scripting system. Future versions of the scripting system\n> can introduce new functionality on the Taro layer, like covenants or other\n> updates.\n>\n> The Taro design also supports integration with the Lightning Network (BOLTs) as\n> the scripting system can be used to emulate the existing HTLC structure, which\n> allows for multi-hop transfers of Taro assets. Rather than modify the internal\n> network, the protocol proposes to instead only recognize \"assets at the edges\",\n> which means that only the sender+receiver actually need to know about and\n> validate the assets. This deployment route means that we don't need to build up\n> an entirely new network and liquidity for each asset. Instead, all asset\n> transfers will utilize the Bitcoin backbone of the Lightning Network, which\n> means that the internal routers just see Bitcoin transfers as normal, and don't\n> even know about assets at the edges. As a result, increased demand for\n> transfers of these assets as the edges (say like a USD stablecoin), which in\n> will turn generate increased demand of LN capacity, result in more transfers, and\n> also more routing revenue for the Bitcoin backbone nodes.\n>\n> The set of BIPs are a multi-part suite, with the following breakdown:\n> * The main Taro protocol: https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro.mediawiki\n> * The MS-SMT structure: https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-ms-smt.mediawiki\n> * The Taro VM: https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-vm.mediawiki\n> * The Taro address format: https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-addr.mediawiki\n> * The Taro Universe concept: https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-universe.mediawiki\n> * The Taro flat file proof format: https://github.com/Roasbeef/bips/blob/bip-taro/bip-taro-proof-file.mediawiki\n>\n> Rather than post them all in line (as the text wouldn't fit in the allowed size\n> limit), all the BIPs can be found above.\n>\n> -- Laolu\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220411/acc7e752/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Taro: A Taproot Asset Representation Overlay",
            "categories": [
                "Lightning-dev",
                "bitcoin-dev"
            ],
            "authors": [
                "Dr Maxim Orlovsky",
                "Olaoluwa Osuntokun",
                "Ruben Somsen",
                "Alex Schoof"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 73299
        }
    },
    {
        "title": "[Lightning-dev] Reading moderated emails",
        "thread_messages": [
            {
                "author": "alicexbt",
                "date": "2022-04-09T00:29:14",
                "message_text_only": "Hi Bitcoin Developers,\n\nSince some emails get moderated, I wanted to share one python script that I found useful.\n\nDownload eml file from moderated archives: https://lists.ozlabs.org/pipermail/bitcoin-dev-moderation/\n\nInstall fast_mail_parser and use this python script: https://github.com/namecheap/fast_mail_parser\n\nThis prints body in base64 format and different parts. Email can be read in plain text by decoding the relevant line: https://i.imgur.com/nnd56Li.png\n\nPasting the highlighted content in https://www.base64decode.org/ will decode the email content or using b64decode() in python.\n\n/dev/fd0\n\nSent with [ProtonMail](https://protonmail.com/) secure email.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220409/5bcd9cf0/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Reading moderated emails",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "alicexbt"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 853
        }
    },
    {
        "title": "[Lightning-dev] [bitcoin-dev] [Pre-BIP] Fee Accounts",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2022-04-10T19:32:52",
                "message_text_only": "On Sun, Feb 20, 2022 at 08:29:00AM -0800, Jeremy Rubin wrote:\n> > On Fri, Feb 18, 2022 at 04:38:27PM -0800, Jeremy Rubin wrote:\n> > > > As I said, it's a new kind of pinning attack, distinct from other types\n> > > of pinning attack.\n> > >\n> > > I think pinning is \"formally defined\" as sequences of transactions which\n> > > prevent or make it less likely for you to make any progress (in terms of\n> > > units of computation proceeding).\n> >\n> > Mentioning \"computation\" when talking about transactions is misleading:\n> > blockchain transactions have nothing to do with computation.\n> >\n> \n> It is in fact computation. Branding it as \"misleading\" is misleading... The\n> relevant literature is https://en.wikipedia.org/wiki/Non-blocking_algorithm,\n> sponsors helps get rid of deadlocking so that any thread can be guaranteed\n> to make progress. E.g., this is critical in Eltoo, which is effectively a\n> coordinated multi-party computation on-chain to compute the highest\n> sequence number known by any worker.\n> \n> That transactions are blobs of \"verification\" (which is also itself a\n> computation) less so than dynamic computations is irrelevant to the fact\n> that series of transactions do represent computations.\n\nIt's misleading in the blockchain environment where lots of people have been\ntrying to portray blockchain schemes as \"world computers\" and other nonsense\nmarketing. You would have been better off just saying \"make any progress\"\nwithout mentioning \"computation\" at all.\n\n> > > Something that only increases possibility to make progress cannot be\n> > > pinning.\n> >\n> > It is incorrect to say that all use-cases have the property that any\n> > version of\n> > a transaction being mined is progress.\n> >\n> \n> It is progress, tautologically. Progress is formally definable as a\n> transaction of any kind getting mined. Pinning prevents progress by an\n> adversarial worker. Sponsoring enables progress, but it may not be your\n> preferred interleaving. That's OK, but it's inaccurate to say it is not\n> progress.\n\nLet's try to use terminology with straight-forward meanings. I've yet to see\nany other protocol where \"progess\" can also mean useless work being done.\n\n> I didn't claim there to be a chain of unconfirmed, I claimed that there\n> could be single output chain that you're RBF'ing one step per block.\n> \n> E.g., it could be something like\n> \n> A_0 -> {A_1 w/ CSV 1 block, OP_RETURN {blah, foo}}\n> A_1 -> {A_2 w/ CSV 1 block, OP_RETURN {bar}}\n> \n> such that A_i provably can't have an unconfirmed descendant. The notion\n> would be that you're replacing one with another. E.g., if you're updating\n> the calendar like:\n> \n> \n> Version 0: A_0 -> {A_1 w/ CSV 1 block, OP_RETURN {blah, foo}}\n> Version 1: A_0 -> {A_1 w/ CSV 1 block, OP_RETURN {blah, foo, bar}}\n> Version 2: A_0 -> {A_1 w/ CSV 1 block, OP_RETURN {blah, foo, bar, delta}}\n> \n> and version 1 gets mined, then in A_1's spend you simply shift delta to\n> that (next) calendar.\n> \n> A_1 -> {A_2 w/ CSV 1 block, OP_RETURN {delta}}\n> \n> Thus my claim that someone sponsoring a old version only can delay by 1\n> block the calendar commit.\n\nYou seem to still be confused about OpenTimestamps. There is no output chain at\nall; OTS has no reason to use CheckSequenceVerify and does not. OTS\ntransactions are, from the point of view of the timestamp proofs, entirely\nindependent of one another.\n\nRemember that OTS simply proves data in the past. Nothing more.\n\n> > > Lastly, if you do get \"necromanced\" on an earlier RBF'd transaction by a\n> > > third party for OTS, you should be relatively happy because it cost you\n> > > less fees overall, since the undoing of your later RBF surely returned\n> > some\n> > > satoshis to your wallet.\n> >\n> > As I said above, no it doesn't.\n> >\n> >\n> It does save money since you had to pay to RBF, the N+1st txn will be\n> paying higher fee than the Nth. So if someone else sponsors an earlier\n> version, then you save whatever feerate/fee bumps you would have paid and\n> the funds are again in your change output (or something). You can apply\n> those change output savings to your next batch, which can include any\n> entries that have been dropped .\n\nAgain, that is not true. Because OTS doesn't have a chain of transactions, I'd\nrather do one transaction with all pending commitments at a particular time\nrather than waste money on mining two transactions for a given set of\ncommitments that need timestamping.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220410/e4530413/attachment.sig>"
            },
            {
                "author": "Jeremy Rubin",
                "date": "2022-04-11T13:18:10",
                "message_text_only": "> nonsense marketing\n\nI'm sure the people who are confused about \"blockchain schemes as \\\"world\ncomputers\\\" and other nonsense\nmarketing\" are avid and regular readers of the bitcoin devs mailing list so\nI offer my sincerest apologies to all members of the intersection of those\nsets who were confused by the description given.\n\n> useless work\n\nprogress is not useless work, it *is* useful work in this context. you have\ncommitted to some subset of data that you requested -- if it was 'useless',\nwhy did you *ever* bother to commit it in the first place? However, it is\nnot 'maximally useful' in some sense. However, progress is progress --\nsuppose you only confirmed 50% of the commitments, is that not progress? If\nyou just happened to observe 50% of the commitments commit because of\nproximity to the time a block was mined and tx propagation naturally would\nyou call it useless?\n\n> Remember that OTS simply proves data in the past. Nothing more.\n> OTS doesn't have a chain of transactions\nGotcha -- I've not been able to find an actual spec of Open Time Stamps\nanywhere, so I suppose I just assumed based on how I think it *should*\nwork. Having a chain of transactions would serve to linearize history of\nOTS commitments which would let you prove, given reorgs, that knowledge of\ncommit A was before B a bit more robustly.\n\n>  I'd rather do one transaction with all pending commitments at a\nparticular time\nrather than waste money on mining two transactions for a given set of\ncommitments\n\nThis sounds like a personal preference v.s. a technical requirement.\n\nYou aren't doing any extra transactions in the model i showed, what you're\ndoing is selecting the window for the next based on the prior conf.\n\nSee the diagram below, you would have to (if OTS is correct) support this\nsort of 'attempt/confirm' head that tracks attempted commitments and\nconfirmed ones and 'rewinds' after a confirm to make the next commit\ncontain the prior attempts that didn't make it.\n\n[.........................................................................]\n ------^ confirm head tx 0 at height 34\n        ------------------------^ attempt head after tx 0\n         -----------^ confirm head tx 1 at height 35\n                      --------------------------^ attempt head after tx 1\n                      ------------^ confirm head tx 2 at height 36\n                                     -------------------------------^\nattempt head after tx 2\n                                      -------------------------------^\nconfirm head tx 3 at height 37\n\nyou can compare this to a \"spherical cow\" model where RBF is always perfect\nand guaranteed inclusion:\n\n\n[.........................................................................]\n ------^ confirm head tx 0 at height 34\n       -------------------------^ confirm head tx 1 at height 35\n                                       -----------^ confirm head at tx 1\nheight 36\n                                                       -----------------^\nconfirm head tx 3 at height 37\n\nThe same number of transactions gets used over the time period.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220411/2492791b/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2022-04-15T14:52:47",
                "message_text_only": "On Mon, Apr 11, 2022 at 09:18:10AM -0400, Jeremy Rubin wrote:\n> > nonsense marketing\n> \n> I'm sure the people who are confused about \"blockchain schemes as \\\"world\n> computers\\\" and other nonsense\n> marketing\" are avid and regular readers of the bitcoin devs mailing list so\n> I offer my sincerest apologies to all members of the intersection of those\n> sets who were confused by the description given.\n\nOf course, uninformed people _do_ read all kinds of technical materials. And\nmore importantly, those technical materials get quoted by journalists,\nscammers, etc.\n\n> > useless work\n> \n> progress is not useless work, it *is* useful work in this context. you have\n> committed to some subset of data that you requested -- if it was 'useless',\n> why did you *ever* bother to commit it in the first place? However, it is\n> not 'maximally useful' in some sense. However, progress is progress --\n> suppose you only confirmed 50% of the commitments, is that not progress? If\n> you just happened to observe 50% of the commitments commit because of\n> proximity to the time a block was mined and tx propagation naturally would\n> you call it useless?\n\nPlease don't trim quoted text to the point where all context is lost. Lots of\npeople read this mailing list and doing that isn't helpful to them.\n\n> > Remember that OTS simply proves data in the past. Nothing more.\n> > OTS doesn't have a chain of transactions\n> Gotcha -- I've not been able to find an actual spec of Open Time Stamps\n\nThe technical spec of OpenTimestamps is of course the normative validation\nsource code, currently python-opentimestamps, similar to how the technical spec\nof Bitcoin is the consensus parts of the Bitcoin Core codebase. The explanatory\ndocs are linked on https://opentimestamps.org under the \"How It Works\" section.\nIt'd be good to take the linked post in that section and turn it into better\nexplanatory materials with graphics (esp interactive/animated graphics).\n\n> anywhere, so I suppose I just assumed based on how I think it *should*\n> work. Having a chain of transactions would serve to linearize history of\n> OTS commitments which would let you prove, given reorgs, that knowledge of\n> commit A was before B a bit more robustly.\n\nI'll reply to this as a separate email as this discussion - while useful - is\ngetting quite off topic for this thread.\n\n> >  I'd rather do one transaction with all pending commitments at a\n> particular time\n> rather than waste money on mining two transactions for a given set of\n> commitments\n> \n> This sounds like a personal preference v.s. a technical requirement.\n> \n> You aren't doing any extra transactions in the model i showed, what you're\n> doing is selecting the window for the next based on the prior conf.\n\n...the model you showed is wrong, as there is no reason to have a linearized\ntransaction history. OpenTimestamps proofs don't even have the concept of\ntransactions: the proof format proves that data existed prior to a merkle root\nof a particular Bitcoin block. Not a Bitcoin transaction.\n\n> See the diagram below, you would have to (if OTS is correct) support this\n> sort of 'attempt/confirm' head that tracks attempted commitments and\n> confirmed ones and 'rewinds' after a confirm to make the next commit\n> contain the prior attempts that didn't make it.\n> \n> [.........................................................................]\n>  ------^ confirm head tx 0 at height 34\n>         ------------------------^ attempt head after tx 0\n>          -----------^ confirm head tx 1 at height 35\n>                       --------------------------^ attempt head after tx 1\n>                       ------------^ confirm head tx 2 at height 36\n>                                      -------------------------------^\n> attempt head after tx 2\n>                                       -------------------------------^\n> confirm head tx 3 at height 37\n> \n> you can compare this to a \"spherical cow\" model where RBF is always perfect\n> and guaranteed inclusion:\n> \n> \n> [.........................................................................]\n>  ------^ confirm head tx 0 at height 34\n>        -------------------------^ confirm head tx 1 at height 35\n>                                        -----------^ confirm head at tx 1\n> height 36\n>                                                        -----------------^\n> confirm head tx 3 at height 37\n> \n> The same number of transactions gets used over the time period.\n\nNone of the above has anything to do with how OpenTimestamps works.\n\nAnyway, getting back to the topic at hand, I remain of the opinion that in the\nunlikely event that fee accounts is ever implemented, it should be opt-in.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220415/3d390f28/attachment-0001.sig>"
            },
            {
                "author": "Jeremy Rubin",
                "date": "2022-04-17T20:57:28",
                "message_text_only": "the 'lots of people' stuff (get confused, can't figure out what i'm\nquoting, actually are reading this conversation) is an appeal to an\nauthority that doesn't exist. If something is unclear to you, let me know.\nIf it's unclear to a supposed existential person or set of persons, they\ncan let me know.\n\n\nconcretely, I am confused by how OTS can both support RBF for updating to\nlarger commitments (the reason you're arguing with me) and not have an\nepoch based re-comittings scheme and still be correct. My assumption now,\nshort of a coherent spec that's not just 'read the code', is that OTS\nprobably is not formally correct and has some holes in what is\ncommitted to, or relies on clients re-requesting proofs if they fail to be\ncommitted. in any case, you would be greatly aided by having an actual spec\nfor OTS since i'm not interested in the specifics of OTS software, but I'm\nwilling to look at the protocol. So if you do that, maybe we can talk more\nabout the issue you see with how sponsors works.\n\nfurther, I think that if there is something that sponsors does that could\nmake a hypothetical OTS-like service work better, in a way that would be\nopaque (read: soft-fork like wrt compatibility) to clients, then we should\njust change what OTS is rather than committing ourselves to a worse design\nin service of some unstated design goals. In particular, it seems that\nOTS's servers can be linearized and because old clients aren't looking for\nlinearization, then the new linearization won't be a breaking change for\nold clients, just calendar servers. And new clients can benefit from\nlinearization.\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n\n\nOn Fri, Apr 15, 2022 at 7:52 AM Peter Todd <pete at petertodd.org> wrote:\n\n> On Mon, Apr 11, 2022 at 09:18:10AM -0400, Jeremy Rubin wrote:\n> > > nonsense marketing\n> >\n> > I'm sure the people who are confused about \"blockchain schemes as \\\"world\n> > computers\\\" and other nonsense\n> > marketing\" are avid and regular readers of the bitcoin devs mailing list\n> so\n> > I offer my sincerest apologies to all members of the intersection of\n> those\n> > sets who were confused by the description given.\n>\n> Of course, uninformed people _do_ read all kinds of technical materials.\n> And\n> more importantly, those technical materials get quoted by journalists,\n> scammers, etc.\n>\n> > > useless work\n> >\n> > progress is not useless work, it *is* useful work in this context. you\n> have\n> > committed to some subset of data that you requested -- if it was\n> 'useless',\n> > why did you *ever* bother to commit it in the first place? However, it is\n> > not 'maximally useful' in some sense. However, progress is progress --\n> > suppose you only confirmed 50% of the commitments, is that not progress?\n> If\n> > you just happened to observe 50% of the commitments commit because of\n> > proximity to the time a block was mined and tx propagation naturally\n> would\n> > you call it useless?\n>\n> Please don't trim quoted text to the point where all context is lost. Lots\n> of\n> people read this mailing list and doing that isn't helpful to them.\n>\n> > > Remember that OTS simply proves data in the past. Nothing more.\n> > > OTS doesn't have a chain of transactions\n> > Gotcha -- I've not been able to find an actual spec of Open Time Stamps\n>\n> The technical spec of OpenTimestamps is of course the normative validation\n> source code, currently python-opentimestamps, similar to how the technical\n> spec\n> of Bitcoin is the consensus parts of the Bitcoin Core codebase. The\n> explanatory\n> docs are linked on https://opentimestamps.org under the \"How It Works\"\n> section.\n> It'd be good to take the linked post in that section and turn it into\n> better\n> explanatory materials with graphics (esp interactive/animated graphics).\n>\n> > anywhere, so I suppose I just assumed based on how I think it *should*\n> > work. Having a chain of transactions would serve to linearize history of\n> > OTS commitments which would let you prove, given reorgs, that knowledge\n> of\n> > commit A was before B a bit more robustly.\n>\n> I'll reply to this as a separate email as this discussion - while useful -\n> is\n> getting quite off topic for this thread.\n>\n> > >  I'd rather do one transaction with all pending commitments at a\n> > particular time\n> > rather than waste money on mining two transactions for a given set of\n> > commitments\n> >\n> > This sounds like a personal preference v.s. a technical requirement.\n> >\n> > You aren't doing any extra transactions in the model i showed, what\n> you're\n> > doing is selecting the window for the next based on the prior conf.\n>\n> ...the model you showed is wrong, as there is no reason to have a\n> linearized\n> transaction history. OpenTimestamps proofs don't even have the concept of\n> transactions: the proof format proves that data existed prior to a merkle\n> root\n> of a particular Bitcoin block. Not a Bitcoin transaction.\n>\n> > See the diagram below, you would have to (if OTS is correct) support this\n> > sort of 'attempt/confirm' head that tracks attempted commitments and\n> > confirmed ones and 'rewinds' after a confirm to make the next commit\n> > contain the prior attempts that didn't make it.\n> >\n> >\n> [.........................................................................]\n> >  ------^ confirm head tx 0 at height 34\n> >         ------------------------^ attempt head after tx 0\n> >          -----------^ confirm head tx 1 at height 35\n> >                       --------------------------^ attempt head after tx 1\n> >                       ------------^ confirm head tx 2 at height 36\n> >                                      -------------------------------^\n> > attempt head after tx 2\n> >                                       -------------------------------^\n> > confirm head tx 3 at height 37\n> >\n> > you can compare this to a \"spherical cow\" model where RBF is always\n> perfect\n> > and guaranteed inclusion:\n> >\n> >\n> >\n> [.........................................................................]\n> >  ------^ confirm head tx 0 at height 34\n> >        -------------------------^ confirm head tx 1 at height 35\n> >                                        -----------^ confirm head at tx 1\n> > height 36\n> >                                                        -----------------^\n> > confirm head tx 3 at height 37\n> >\n> > The same number of transactions gets used over the time period.\n>\n> None of the above has anything to do with how OpenTimestamps works.\n>\n> Anyway, getting back to the topic at hand, I remain of the opinion that in\n> the\n> unlikely event that fee accounts is ever implemented, it should be opt-in.\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220417/be59c0a8/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2022-04-28T12:15:02",
                "message_text_only": "On Sun, Apr 17, 2022 at 01:57:28PM -0700, Jeremy Rubin wrote:\n> the 'lots of people' stuff (get confused, can't figure out what i'm\n> quoting, actually are reading this conversation) is an appeal to an\n> authority that doesn't exist. If something is unclear to you, let me know.\n> If it's unclear to a supposed existential person or set of persons, they\n> can let me know.\n\nIt's pretty simple: bitcoin-dev is read by hundreds of people. This has nothing\nto do with authority. It's about not wasting the time of those people.\n\n> concretely, I am confused by how OTS can both support RBF for updating to\n> larger commitments (the reason you're arguing with me) and not have an\n> epoch based re-comittings scheme and still be correct. My assumption now,\n> short of a coherent spec that's not just 'read the code', is that OTS\n> probably is not formally correct and has some holes in what is\n> committed to, or relies on clients re-requesting proofs if they fail to be\n> committed. in any case, you would be greatly aided by having an actual spec\n> for OTS since i'm not interested in the specifics of OTS software, but I'm\n> willing to look at the protocol. So if you do that, maybe we can talk more\n> about the issue you see with how sponsors works.\n\nOpenTimestamps is, as the name suggests, for cryptographic timestamping. As is\nobvious to anyone with a good knowledge of cryptography, a cryptographic\ntimestamp proves that data existed prior to some point in time. That's it.\n\n> further, I think that if there is something that sponsors does that could\n> make a hypothetical OTS-like service work better, in a way that would be\n> opaque (read: soft-fork like wrt compatibility) to clients, then we should\n> just change what OTS is rather than committing ourselves to a worse design\n> in service of some unstated design goals. In particular, it seems that\n> OTS's servers can be linearized and because old clients aren't looking for\n> linearization, then the new linearization won't be a breaking change for\n> old clients, just calendar servers. And new clients can benefit from\n> linearization.\n\nThe fact you keep bringing up linearization for a timestmaping service makes me\nthink something is missing in your understanding of cryptography. Tell me, how\nexactly do you think linearization would help in an example use-case? More\nspecifically, what attack would be prevented?\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220428/3d16d41a/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Fee Accounts",
            "categories": [
                "Lightning-dev",
                "bitcoin-dev",
                "Pre-BIP"
            ],
            "authors": [
                "Peter Todd",
                "Jeremy Rubin"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 22559
        }
    },
    {
        "title": "[Lightning-dev] Gossip Propagation, Anti-spam, and Set Reconciliation",
        "thread_messages": [
            {
                "author": "Alex Myers",
                "date": "2022-04-14T21:00:14",
                "message_text_only": "Hello lightning developers,\n\nI\u2019ve been investigating set reconciliation as a means to reduce bandwidth and redundancy of gossip message propagation. This builds on some earlier work from Rusty using the minisketch library [1]. The idea is that each node will build a sketch representing it\u2019s own gossip set. Alice\u2019s node will encode and transmit this sketch to Bob\u2019s node, where it will be merged with his own sketch, and the differences produced. These differences should ideally be exactly the latest missing gossip of both nodes. Due to size constraints, the set differences will necessarily be encoded, but Bob\u2019s node will be able to identify which gossip Alice is missing, and may then transmit exactly those messages.\n\nThis process is relatively straightforward, with the caveat that the sets must otherwise match very closely (each sketch has a maximum capacity for differences.) The difficulty here is that each node and lightning implementation may have its own rules for gossip acceptance and propagation. Depending on their gossip partners, not all gossip may propagate to the entire network.\n\nCore-lightning implements rate limiting for incoming channel updates and node announcements. The default rate limit is 1 per day, with a burst of 4. I analyzed my node\u2019s gossip over a 14 day period, and found that, of all publicly broadcasting half-channels, 18% of them fell afoul of our spam-limiting rules at least once. [2]\n\nPicking several offending channel ids, and digging further, the majority of these appear to be flapping due to Tor or otherwise intermittent connections. Well connected nodes may be more susceptible to this due to more frequent routing attempts, and failures resulting in a returned channel update (which otherwise might not have been broadcast.)A slight relaxation of the rate limit resolves the majority of these cases.\n\nA smaller subset of channels broadcast frequent channel updates with minor adjustments to htlc_maximum_msat and fee_proportional_millionths parameters. These nodes appear to be power users, with many channels and large balances. I assume this is automated channel management at work.\n\nCore-Lightning has updated rate-limiting in the upcoming release to achieve a higher acceptance of incoming gossip, however, it seems that a broader discussion of rate limits may now be worthwhile. A few immediate ideas:\n\n- A common listing of current default rate limits across lightning network implementations.\n\n- Internal checks of RPC input to limit or warn of network propagation issues if certain rates are exceeded.\n\n- A commonly adopted rate-limit standard.\n\nMy aim is a set reconciliation gossip type, which will use a common, simple heuristic to accept or reject a gossip message. (Think one channel update per block, or perhaps one per block_height << 5.) See my github for my current draft. [3] This solution allows tighter consensus, yet suffers from the same problem as original anti-spam measures \u2013 it remains somewhat arbitrary. I would like to start a conversation regarding gossip propagation, channel_update and node_announcement usage, and perhaps even bandwidth goals for syncing gossip in the future (how about a million channels?) This would aid in the development of gossip set reconciliation, but could also benefit current node connection and routing reliability more generally.\n\nThanks,\n\nAlex\n\n[1] https://github.com/sipa/minisketch\n\n[2] https://github.com/endothermicdev/lnspammityspam/blob/main/sampleoutput.txt\n\n[3] https://github.com/endothermicdev/lightning-rfc/blob/gossip-minisketch/07-routing-gossip.md#set-reconciliation\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220414/daf0c088/attachment.html>"
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2022-04-15T07:15:24",
                "message_text_only": "Good morning Alex,\n\nI\u2019ve been investigating set reconciliation as a means to reduce bandwidth\n\nand redundancy of gossip message propagation.\n>\n\nCool project, glad to see someone working on it! The main difficulty here\nwill\nindeed be to ensure that the number of differences between sets is bounded.\nWe will need to maintain a mechanism to sync the whole graph from scratch\nfor new nodes, so the minisketch diff must be efficient enough otherwise\nnodes\nwill just fall back to a full sync way too often (which would waste a lot of\nbandwidth).\n\nPicking several offending channel ids, and digging further, the majority of\n> these\n\nappear to be flapping due to Tor or otherwise intermittent connections.\n>\n\nOne thing that may help here from an implementation's point of view is to\navoid\nsending a disabled channel update every time a channel goes offline. What\neclair does to avoid spamming is to only send a disabled channel update when\nsomeone actually tries to use that channel. Of course, if people choose this\noffline node in their route, you don't have a choice and will need to send a\ndisabled channel update, but we've observed that many channels come back\nonline before we actually need to use them, so we're saving two channel\nupdates\n(one to disable the channel and one to re-enable it). I think all\nimplementations\nshould do this. Is that the case today?\n\nWe could go even further, and when we receive an htlc that should be relayed\nto an offline node, wait a bit to give them an opportunity to come online\ninstead\nof failing the htlc and sending a disabled channel update. Eclair currently\ndoesn't\ndo that, but it would be very easy to add.\n\n- A common listing of current default rate limits across lightning network\n> implementations.\n>\n\nEclair doesn't do any rate-limiting. We wanted to \"feel the pain\" before\nadding\nanything, and to be honest we haven't really felt it yet.\n\nwhich will use a common, simple heuristic to accept or reject a gossip\n> message.\n\n(Think one channel update per block, or perhaps one per block_height << 5.)\n>\n\nI think it would be easy to come to agreement between implementations and\nrestrict channel updates to at most one every N blocks. We simply need to\nadd\nthe `block_height` in a tlv in `channel_update` and then we'll be able to\nactually\nrate-limit based on it. Given how much time it takes to upgrade most of the\nnetwork, it may be a good idea to add the `block_height` tlv now in the\nspec,\nand act on it later? Unless your work requires bigger changes in channel\nupdate\nin which case it will probably be a new message.\n\nNote that it will never be completely accurate though, as different nodes\ncan\nhave different blockchain tips. My nodes may be one or two blocks late\ncompared\nto the node that emits the channel update. We need to allow a bit of leeway\nthere.\n\nCheers,\nBastien\n\n\n\n\nLe jeu. 14 avr. 2022 \u00e0 23:06, Alex Myers <alex at endothermic.dev> a \u00e9crit :\n\n> Hello lightning developers,\n>\n>\n> I\u2019ve been investigating set reconciliation as a means to reduce bandwidth\n> and redundancy of gossip message propagation. This builds on some earlier work\n> from Rusty using the minisketch library [1]. The idea is that each node\n> will build a sketch representing it\u2019s own gossip set. Alice\u2019s node will\n> encode and transmit this sketch to Bob\u2019s node, where it will be merged with\n> his own sketch, and the differences produced. These differences should\n> ideally be exactly the latest missing gossip of both nodes. Due to size\n> constraints, the set differences will necessarily be encoded, but Bob\u2019s\n> node will be able to identify which gossip Alice is missing, and may then\n> transmit exactly those messages.\n>\n>\n> This process is relatively straightforward, with the caveat that the sets\n> must otherwise match very closely (each sketch has a maximum capacity for\n> differences.) The difficulty here is that each node and lightning\n> implementation may have its own rules for gossip acceptance and\n> propagation. Depending on their gossip partners, not all gossip may\n> propagate to the entire network.\n>\n>\n> Core-lightning implements rate limiting for incoming channel updates and\n> node announcements. The default rate limit is 1 per day, with a burst of\n> 4. I analyzed my node\u2019s gossip over a 14 day period, and found that, of\n> all publicly broadcasting half-channels, 18% of them fell afoul of our\n> spam-limiting rules at least once. [2]\n>\n>\n> Picking several offending channel ids, and digging further, the majority\n> of these appear to be flapping due to Tor or otherwise intermittent\n> connections. Well connected nodes may be more susceptible to this due to more\n> frequent routing attempts, and failures resulting in a returned channel\n> update (which otherwise might not have been broadcast.) A slight\n> relaxation of the rate limit resolves the majority of these cases.\n>\n>\n> A smaller subset of channels broadcast frequent channel updates with minor\n> adjustments to htlc_maximum_msat and fee_proportional_millionths\n> parameters. These nodes appear to be power users, with many channels and\n> large balances. I assume this is automated channel management at work.\n>\n>\n> Core-Lightning has updated rate-limiting in the upcoming release to\n> achieve a higher acceptance of incoming gossip, however, it seems that a\n> broader discussion of rate limits may now be worthwhile. A few immediate\n> ideas:\n>\n> - A common listing of current default rate limits across lightning\n> network implementations.\n>\n> - Internal checks of RPC input to limit or warn of network propagation\n> issues if certain rates are exceeded.\n>\n> - A commonly adopted rate-limit standard.\n>\n>\n> My aim is a set reconciliation gossip type, which will use a common,\n> simple heuristic to accept or reject a gossip message. (Think one channel\n> update per block, or perhaps one per block_height << 5.) See my github\n> for my current draft. [3] This solution allows tighter consensus, yet suffers\n> from the same problem as original anti-spam measures \u2013 it remains\n> somewhat arbitrary. I would like to start a conversation regarding gossip\n> propagation, channel_update and node_announcement usage, and perhaps even\n> bandwidth goals for syncing gossip in the future (how about a million\n> channels?) This would aid in the development of gossip set\n> reconciliation, but could also benefit current node connection and\n> routing reliability more generally.\n>\n>\n> Thanks,\n>\n> Alex\n>\n>\n> [1] https://github.com/sipa/minisketch\n>\n> [2]\n> https://github.com/endothermicdev/lnspammityspam/blob/main/sampleoutput.txt\n>\n> [3]\n> https://github.com/endothermicdev/lightning-rfc/blob/gossip-minisketch/07-routing-gossip.md#set-reconciliation\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220415/98a7eca4/attachment-0001.html>"
            },
            {
                "author": "Alex Myers",
                "date": "2022-04-21T20:31:46",
                "message_text_only": "Hello Bastien,\n\nThank you for your feedback. I hope you don't mind I let it percolate for a while.\n\n> Eclair doesn't do any rate-limiting. We wanted to \"feel the pain\" before adding\n> anything, and to be honest we haven't really felt it yet.\n\nI understand the \u201cfeel the pain first\u201d approach, but attempting set reconciliation has forced me to confront the issue a bit early.\n\nMy thoughts on sync were that set-reconciliation would only be used once a node had fully synced gossip through traditional means (initial_routing_sync / gossip_queries.) There should be many levers to pull in order to help maintain sync after this. I'm going to have to experiment with them a bit before I can claim they are sufficient, but I'm optimistic.\n\n> One thing that may help here from an implementation's point of view is to avoid\n> sending a disabled channel update every time a channel goes offline. What\n> eclair does to avoid spamming is to only send a disabled channel update when\n> someone actually tries to use that channel. Of course, if people choose this\n> offline node in their route, you don't have a choice and will need to send a\n> disabled channel update, but we've observed that many channels come back\n> online before we actually need to use them, so we're saving two channel updates\n> (one to disable the channel and one to re-enable it). I think all implementations\n> should do this. Is that the case today?\n> We could go even further, and when we receive an htlc that should be relayed\n> to an offline node, wait a bit to give them an opportunity to come online instead\n> of failing the htlc and sending a disabled channel update. Eclair currently doesn'tdo that, but it would be very easy to add.\n\nCore-Lightning also delays sending disabled channel updates in an effort to minimize unnecessary gossip. I hadn\u2019t considered an additional delay before failing an htlc on a disabled channel. That will be interesting to explore in the context of transient disconnects of Tor v3 nodes.\n\nI like the idea of a block_height in the channel update tlv. That would be sufficient to enable a simple rate-limit heuristic for this application anyway. Allowing leeway for the chain tip is no problem. I would also expect most implementations to hold a couple updates in reserve, defaulting to predated updates when available. This would allow a \u201cburst\u201d functionality similar to the current LND/CLN rate-limit, but the responsibility is now placed on the originating node to provide that allowance.\n\nCheers,\n\nAlex\n\n------- Original Message -------\nOn Friday, April 15th, 2022 at 2:15 AM, Bastien TEINTURIER <bastien at acinq.fr> wrote:\n\n> Good morning Alex,\n>\n>> I\u2019ve been investigating set reconciliation as a means to reduce bandwidth\n>\n>> and redundancy of gossip message propagation.\n>\n> Cool project, glad to see someone working on it! The main difficulty here will\n> indeed be to ensure that the number of differences between sets is bounded.\n> We will need to maintain a mechanism to sync the whole graph from scratch\n> for new nodes, so the minisketch diff must be efficient enough otherwise nodes\n> will just fall back to a full sync way too often (which would waste a lot of\n> bandwidth).\n>\n>> Picking several offending channel ids, and digging further, the majority of these\n>\n>> appear to be flapping due to Tor or otherwise intermittent connections.\n>\n> One thing that may help here from an implementation's point of view is to avoid\n> sending a disabled channel update every time a channel goes offline. What\n> eclair does to avoid spamming is to only send a disabled channel update when\n> someone actually tries to use that channel. Of course, if people choose this\n> offline node in their route, you don't have a choice and will need to send a\n> disabled channel update, but we've observed that many channels come back\n> online before we actually need to use them, so we're saving two channel updates\n> (one to disable the channel and one to re-enable it). I think all implementations\n> should do this. Is that the case today?\n>\n> We could go even further, and when we receive an htlc that should be relayed\n> to an offline node, wait a bit to give them an opportunity to come online instead\n> of failing the htlc and sending a disabled channel update. Eclair currently doesn't\n> do that, but it would be very easy to add.\n>\n>> - A common listing of current default rate limits across lightning network implementations.\n>\n> Eclair doesn't do any rate-limiting. We wanted to \"feel the pain\" before adding\n> anything, and to be honest we haven't really felt it yet.\n>\n>> which will use a common, simple heuristic to accept or reject a gossip message.\n>\n>> (Think one channel update per block, or perhaps one per block_height << 5.)\n>\n> I think it would be easy to come to agreement between implementations and\n> restrict channel updates to at most one every N blocks. We simply need to add\n> the `block_height` in a tlv in `channel_update` and then we'll be able to actually\n> rate-limit based on it. Given how much time it takes to upgrade most of the\n> network, it may be a good idea to add the `block_height` tlv now in the spec,\n> and act on it later? Unless your work requires bigger changes in channel update\n> in which case it will probably be a new message.\n>\n> Note that it will never be completely accurate though, as different nodes can\n> have different blockchain tips. My nodes may be one or two blocks late compared\n> to the node that emits the channel update. We need to allow a bit of leeway there.\n>\n> Cheers,\n> Bastien\n>\n> Le jeu. 14 avr. 2022 \u00e0 23:06, Alex Myers <alex at endothermic.dev> a \u00e9crit :\n>\n>> Hello lightning developers,\n>>\n>> I\u2019ve been investigating set reconciliation as a means to reduce bandwidth and redundancy of gossip message propagation. This builds on some earlier work from Rusty using the minisketch library [1]. The idea is that each node will build a sketch representing it\u2019s own gossip set. Alice\u2019s node will encode and transmit this sketch to Bob\u2019s node, where it will be merged with his own sketch, and the differences produced. These differences should ideally be exactly the latest missing gossip of both nodes. Due to size constraints, the set differences will necessarily be encoded, but Bob\u2019s node will be able to identify which gossip Alice is missing, and may then transmit exactly those messages.\n>>\n>> This process is relatively straightforward, with the caveat that the sets must otherwise match very closely (each sketch has a maximum capacity for differences.) The difficulty here is that each node and lightning implementation may have its own rules for gossip acceptance and propagation. Depending on their gossip partners, not all gossip may propagate to the entire network.\n>>\n>> Core-lightning implements rate limiting for incoming channel updates and node announcements. The default rate limit is 1 per day, with a burst of 4. I analyzed my node\u2019s gossip over a 14 day period, and found that, of all publicly broadcasting half-channels, 18% of them fell afoul of our spam-limiting rules at least once. [2]\n>>\n>> Picking several offending channel ids, and digging further, the majority of these appear to be flapping due to Tor or otherwise intermittent connections. Well connected nodes may be more susceptible to this due to more frequent routing attempts, and failures resulting in a returned channel update (which otherwise might not have been broadcast.)A slight relaxation of the rate limit resolves the majority of these cases.\n>>\n>> A smaller subset of channels broadcast frequent channel updates with minor adjustments to htlc_maximum_msat and fee_proportional_millionths parameters. These nodes appear to be power users, with many channels and large balances. I assume this is automated channel management at work.\n>>\n>> Core-Lightning has updated rate-limiting in the upcoming release to achieve a higher acceptance of incoming gossip, however, it seems that a broader discussion of rate limits may now be worthwhile. A few immediate ideas:\n>>\n>> - A common listing of current default rate limits across lightning network implementations.\n>>\n>> - Internal checks of RPC input to limit or warn of network propagation issues if certain rates are exceeded.\n>>\n>> - A commonly adopted rate-limit standard.\n>>\n>> My aim is a set reconciliation gossip type, which will use a common, simple heuristic to accept or reject a gossip message. (Think one channel update per block, or perhaps one per block_height << 5.) See my github for my current draft. [3] This solution allows tighter consensus, yet suffers from the same problem as original anti-spam measures \u2013 it remains somewhat arbitrary. I would like to start a conversation regarding gossip propagation, channel_update and node_announcement usage, and perhaps even bandwidth goals for syncing gossip in the future (how about a million channels?) This would aid in the development of gossip set reconciliation, but could also benefit current node connection and routing reliability more generally.\n>>\n>> Thanks,\n>>\n>> Alex\n>>\n>> [1] https://github.com/sipa/minisketch\n>>\n>> [2] https://github.com/endothermicdev/lnspammityspam/blob/main/sampleoutput.txt\n>>\n>> [3] https://github.com/endothermicdev/lightning-rfc/blob/gossip-minisketch/07-routing-gossip.md#set-reconciliation\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220421/a2ddf84f/attachment-0001.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2022-04-21T20:47:27",
                "message_text_only": "On 4/21/22 1:31 PM, Alex Myers wrote:\n> Hello Bastien,\n> \n> Thank you for your feedback. I hope you don't mind I let it percolate for a while.\n> \n>     Eclair doesn't do any rate-limiting. We wanted to \"feel the pain\" before adding\n>     anything, and to be honest we haven't really felt it yet.\n> \n> I understand the \u201cfeel the pain first\u201d approach, but attempting set reconciliation has forced me to \n> confront the issue a bit early.\n> \n> My thoughts on sync were that set-reconciliation would only be used once a node had fully synced \n> gossip through traditional means (initial_routing_sync / gossip_queries.) There should be many \n> levers to pull in order to help maintain sync after this. I'm going to have to experiment with them \n> a bit before I can claim they are sufficient, but I'm optimistic.\n\nPlease, no. initial_routing_sync was removed from most implementations (it sucks) and gossip queries \nis broken in at least five ways. May we can recover it by adding yet more extensions but if we're \ngonna add a minisketch-based sync anyway, please lets also use it for initial sync after restart \n(unless you have no channels at all, in which case lets maybe revive initial_routing_sync...)\n\nMatt"
            },
            {
                "author": "Alex Myers",
                "date": "2022-04-22T16:15:13",
                "message_text_only": "Hi Matt,\n\nAppreciate your responses. Hope you'll bear with me as I'm a bit new to this.\n\n> Instead of trying to make sure everyone\u2019s gossip acceptance matches exactly, which as you point it seems like a quagmire, why not (a) do a sync on startup and (b) do syncs of the *new* things.\n\nI'm not opposed to this technique, and maybe it ends up as a better solution. The rationale for not going full Erlay approach was that it's far less overhead to maintain a single sketch than to maintain a per-peer sketch and associated state for every gossip peer. In this way there's very little cost to adding additional gossip peers, which further encourages propagation and convergence of the gossip network.\n\nIIUC Erlay's design was concerned for privacy of originating nodes. Lightning gossip is public by nature, so I'm not sure we should constrain ourselves to the same design route without trying the alternative first.\n\n> if we're gonna add a minisketch-based sync anyway, please lets also use it for initial sync after restart\n\nThis was out of the scope of what I had in mind, but I will give this some thought. I could see how a block_height reference coupled with set reconciliation could provide some better options here. This may not be all that difficult to shoe-horn in.\n\nRegardless of single sketch or per-peer set reconciliation, it should be easier to implement with tighter rules on rate-limiting. (Keep in mind, the node's graph can presumably be updated independently of the gossip it rebroadcasts if desired.) As a thought experiment, if we consider a CLN-LDK set reconciliation, and that each node is gossiping with 5 other peers in an evenly spaced frequency, we would currently see 42.8 commonly accepted channel_updates over an average 60s window along with 11 more updates which LDK accepts and CLN rejects (spam.)[1] Assuming the other 5 peers have shared 5/6ths of this gossip before the CLN/LDK set reconciliation, we're left with CLN seeing 7 updates to reconcile, while LDK sees 18. Already we've lost 60% efficiency due to lack of a common rate-limit heuristic.\n\nI understand gossip traffic is manageable now, but I'm not sure it will be that long before it becomes an issue. Furthermore, any particular set reconciliation technique would benefit from a simple common rate-limit heuristic, not to mention originating nodes, who may not currently realize their channel updates are being rejected by a portion of the network due to differing criteria across implementations.\n\nThanks,\nAlex\n\n[1] https://github.com/endothermicdev/lnspammityspam/blob/main/sampleoutput.txt\n\n------- Original Message -------\nOn Thursday, April 21st, 2022 at 3:47 PM, Matt Corallo lf-lists at mattcorallo.com wrote:\n\n> On 4/21/22 1:31 PM, Alex Myers wrote:\n>\n>> Hello Bastien,\n>>\n>> Thank you for your feedback. I hope you don't mind I let it percolate for a while.\n>>\n>> Eclair doesn't do any rate-limiting. We wanted to \"feel the pain\" before adding\n>> anything, and to be honest we haven't really felt it yet.\n>>\n>> I understand the \u201cfeel the pain first\u201d approach, but attempting set reconciliation has forced me to\n>> confront the issue a bit early.\n>>\n>> My thoughts on sync were that set-reconciliation would only be used once a node had fully synced\n>> gossip through traditional means (initial_routing_sync / gossip_queries.) There should be many\n>> levers to pull in order to help maintain sync after this. I'm going to have to experiment with them\n>> a bit before I can claim they are sufficient, but I'm optimistic.\n>\n> Please, no. initial_routing_sync was removed from most implementations (it sucks) and gossip queries\n> is broken in at least five ways. May we can recover it by adding yet more extensions but if we're\n> gonna add a minisketch-based sync anyway, please lets also use it for initial sync after restart\n> (unless you have no channels at all, in which case lets maybe revive initial_routing_sync...)\n>\n> Matt\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220422/59ffd174/attachment.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2022-04-22T18:50:45",
                "message_text_only": "On 4/22/22 9:15 AM, Alex Myers wrote:\n> Hi Matt,\n> \n> Appreciate your responses.\u00a0 Hope you'll bear with me as I'm a bit new to this.\n> \n>     Instead of trying to make sure everyone\u2019s gossip acceptance matches exactly, which as you point\n>     it seems like a quagmire, why not (a) do a sync on startup and (b) do syncs of the *new* things.\n> \n> I'm not opposed to this technique, and maybe it ends up as a better solution.\u00a0 The rationale for not \n> going full Erlay approach was that it's far less overhead to maintain a single sketch than to \n> maintain a per-peer sketch and associated state for every gossip peer.\u00a0 In this way there's very \n> little cost to adding additional gossip peers, which further encourages propagation and convergence \n> of the gossip network.\n\nI'm not sure what you mean by per-node state here - I'd think you can implement it with a simple \n\"list of updates that happened since time X\" data, instead of having to maintain per-peer state.\n\n> IIUC Erlay's design was concerned for privacy of originating nodes.\u00a0 Lightning gossip is public by \n> nature, so I'm not sure we should constrain ourselves to the same design route without trying the \n> alternative first.\n\nPart of the design of Erlay, especially the insight of syncing updates instead of full mempools, was \nactually this precise issue - Bitcoin Core nodes differ in policy for a number of reasons \n(especially across updates), and thus syncing the full mempool will result in degenerate cases of \ntrying over and over and over again to sync stuff your peer is rejecting. At least if I recall \ncorrectly.\n\n>     if we're gonna add a minisketch-based sync anyway, please lets also use it for initial sync\n>     after restart\n> \n> This was out of the scope of what I had in mind, but I will give this some thought. I could see how \n> a block_height reference coupled with set reconciliation could provide some better options here. \n> This may not be all that difficult to shoe-horn in.\n> \n> Regardless of single sketch or per-peer set reconciliation, it should be easier to implement with \n> tighter rules on rate-limiting. (Keep in mind, the node's graph can presumably be updated \n> independently of the gossip it rebroadcasts if desired.) As a thought experiment, if we consider a \n> CLN-LDK set reconciliation, and that each node is gossiping with 5 other peers in an evenly spaced \n> frequency, we would currently see 42.8 commonly accepted channel_updates over an average 60s window \n> along with 11 more updates which LDK accepts and CLN rejects (spam.)[1] Assuming the other 5 peers \n> have shared 5/6ths of this gossip before the CLN/LDK set reconciliation, we're left with CLN seeing \n> 7 updates to reconcile, while LDK sees 18.\u00a0 Already we've lost 60% efficiency due to lack of a \n> common rate-limit heuristic.\n\nI do not believe that we will ever form a strong agreement on exactly what the rate-limits should \nbe. And even if we do, we still have the issue of upgrades, where a simple change to the rate-limits \ncauses sync to suddenly blow up and hit degenerate cases all over the place. Unless we can make the \nsync system relatively robust against slightly different policies, I think we're kinda screwed.\n\nWorse, what happens if someone sends updates at exactly the limit of the rate-limiters? Presumably \npeople will do this because \"that's what the limit is and I want to send updates as often as I can \nbecaux...\". Now you'll still have similar issues, I believe.\n\n> I understand gossip traffic is manageable now, but I'm not sure it will be that long before it \n> becomes an issue. Furthermore, any particular set reconciliation technique would benefit from a \n> simple common rate-limit heuristic, not to mention originating nodes, who may not currently realize \n> their channel updates are being rejected by a portion of the network due to differing criteria \n> across implementations.\n\nYes, I agree there is definitely a concern with differing criteria resulting in nodes not realizing \ntheir gossip is not propagating. I agree guidelines would be nice, but guidelines doesn't solve the \nissue for sync, sadly, I think. Luckily lightning does provide a mechanism to bypass the rejection - \nsend an update back with an HTLC failure. If you're trying to route an HTLC and a node has new \nparameters for you, it'll helpfully let you know when you try to use the old parameters.\n\nMatt"
            },
            {
                "author": "Matt Corallo",
                "date": "2022-04-21T13:11:46",
                "message_text_only": "Instead of trying to make sure everyone\u2019s gossip acceptance matches exactly, which as you point it seems like a quagmire, why not (a) do a sync on startup and (b) do syncs of the *new* things. This way you aren\u2019t stuck staring at the same channels every time you do a sync. Sure, if you\u2019re rejecting a large % of channel updates in total you\u2019re gonna end up hitting degenerate cases, but we can consider tuning the sync frequency if that becomes an issue.\n\nLike eclair, we don\u2019t bother to rate limit and don\u2019t see any issues with it, though we will skip relaying outbound updates if we\u2019re saturating outbound connections.\n\n> On Apr 14, 2022, at 17:06, Alex Myers <alex at endothermic.dev> wrote:\n> \n> \ufeff\n> Hello lightning developers,\n> \n> I\u2019ve been investigating set reconciliation as a means to reduce bandwidth and redundancy of gossip message propagation. This builds on some earlier work from Rusty using the minisketch library [1]. The idea is that each node will build a sketch representing it\u2019s own gossip set. Alice\u2019s node will encode and transmit this sketch to Bob\u2019s node, where it will be merged with his own sketch, and the differences produced. These differences should ideally be exactly the latest missing gossip of both nodes. Due to size constraints, the set differences will necessarily be encoded, but Bob\u2019s node will be able to identify which gossip Alice is missing, and may then transmit exactly those messages.\n> \n> This process is relatively straightforward, with the caveat that the sets must otherwise match very closely (each sketch has a maximum capacity for differences.) The difficulty here is that each node and lightning implementation may have its own rules for gossip acceptance and propagation. Depending on their gossip partners, not all gossip may propagate to the entire network.\n> \n> Core-lightning implements rate limiting for incoming channel updates and node announcements. The default rate limit is 1 per day, with a burst of 4. I analyzed my node\u2019s gossip over a 14 day period, and found that, of all publicly broadcasting half-channels, 18% of them fell afoul of our spam-limiting rules at least once. [2]\n> \n> Picking several offending channel ids, and digging further, the majority of these appear to be flapping due to Tor or otherwise intermittent connections. Well connected nodes may be more susceptible to this due to more frequent routing attempts, and failures resulting in a returned channel update (which otherwise might not have been broadcast.) A slight relaxation of the rate limit resolves the majority of these cases.\n> \n> A smaller subset of channels broadcast frequent channel updates with minor adjustments to htlc_maximum_msat and fee_proportional_millionths parameters. These nodes appear to be power users, with many channels and large balances. I assume this is automated channel management at work.\n> \n> Core-Lightning has updated rate-limiting in the upcoming release to achieve a higher acceptance of incoming gossip, however, it seems that a broader discussion of rate limits may now be worthwhile. A few immediate ideas:\n> - A common listing of current default rate limits across lightning network implementations.\n> - Internal checks of RPC input to limit or warn of network propagation issues if certain rates are exceeded.\n> - A commonly adopted rate-limit standard.\n> \n> My aim is a set reconciliation gossip type, which will use a common, simple heuristic to accept or reject a gossip message. (Think one channel update per block, or perhaps one per block_height << 5.) See my github for my current draft. [3] This solution allows tighter consensus, yet suffers from the same problem as original anti-spam measures \u2013 it remains somewhat arbitrary. I would like to start a conversation regarding gossip propagation, channel_update and node_announcement usage, and perhaps even bandwidth goals for syncing gossip in the future (how about a million channels?) This would aid in the development of gossip set reconciliation, but could also benefit current node connection and routing reliability more generally.\n> \n> Thanks,\n> Alex\n> \n> [1] https://github.com/sipa/minisketch\n> [2] https://github.com/endothermicdev/lnspammityspam/blob/main/sampleoutput.txt\n> [3] https://github.com/endothermicdev/lightning-rfc/blob/gossip-minisketch/07-routing-gossip.md#set-reconciliation\n> \n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220421/bfb44d28/attachment.html>"
            },
            {
                "author": "Greg Sanders",
                "date": "2022-04-21T13:20:58",
                "message_text_only": "I think I mentioned this out of band to Alex, but (b) is what Erlay's\nproposal is for Bitcoin gossip, so it's worth studying up.\n\nOn Thu, Apr 21, 2022 at 9:18 AM Matt Corallo <lf-lists at mattcorallo.com>\nwrote:\n\n> Instead of trying to make sure everyone\u2019s gossip acceptance matches\n> exactly, which as you point it seems like a quagmire, why not (a) do a sync\n> on startup and (b) do syncs of the *new* things. This way you aren\u2019t stuck\n> staring at the same channels every time you do a sync. Sure, if you\u2019re\n> rejecting a large % of channel updates in total you\u2019re gonna end up hitting\n> degenerate cases, but we can consider tuning the sync frequency if that\n> becomes an issue.\n>\n> Like eclair, we don\u2019t bother to rate limit and don\u2019t see any issues with\n> it, though we will skip relaying outbound updates if we\u2019re saturating\n> outbound connections.\n>\n> On Apr 14, 2022, at 17:06, Alex Myers <alex at endothermic.dev> wrote:\n>\n> \ufeff\n>\n> Hello lightning developers,\n>\n>\n> I\u2019ve been investigating set reconciliation as a means to reduce bandwidth\n> and redundancy of gossip message propagation. This builds on some earlier work\n> from Rusty using the minisketch library [1]. The idea is that each node\n> will build a sketch representing it\u2019s own gossip set. Alice\u2019s node will\n> encode and transmit this sketch to Bob\u2019s node, where it will be merged with\n> his own sketch, and the differences produced. These differences should\n> ideally be exactly the latest missing gossip of both nodes. Due to size\n> constraints, the set differences will necessarily be encoded, but Bob\u2019s\n> node will be able to identify which gossip Alice is missing, and may then\n> transmit exactly those messages.\n>\n>\n> This process is relatively straightforward, with the caveat that the sets\n> must otherwise match very closely (each sketch has a maximum capacity for\n> differences.) The difficulty here is that each node and lightning\n> implementation may have its own rules for gossip acceptance and\n> propagation. Depending on their gossip partners, not all gossip may\n> propagate to the entire network.\n>\n>\n> Core-lightning implements rate limiting for incoming channel updates and\n> node announcements. The default rate limit is 1 per day, with a burst of\n> 4. I analyzed my node\u2019s gossip over a 14 day period, and found that, of\n> all publicly broadcasting half-channels, 18% of them fell afoul of our\n> spam-limiting rules at least once. [2]\n>\n>\n> Picking several offending channel ids, and digging further, the majority\n> of these appear to be flapping due to Tor or otherwise intermittent\n> connections. Well connected nodes may be more susceptible to this due to more\n> frequent routing attempts, and failures resulting in a returned channel\n> update (which otherwise might not have been broadcast.) A slight\n> relaxation of the rate limit resolves the majority of these cases.\n>\n>\n> A smaller subset of channels broadcast frequent channel updates with minor\n> adjustments to htlc_maximum_msat and fee_proportional_millionths\n> parameters. These nodes appear to be power users, with many channels and\n> large balances. I assume this is automated channel management at work.\n>\n>\n> Core-Lightning has updated rate-limiting in the upcoming release to\n> achieve a higher acceptance of incoming gossip, however, it seems that a\n> broader discussion of rate limits may now be worthwhile. A few immediate\n> ideas:\n>\n> - A common listing of current default rate limits across lightning\n> network implementations.\n>\n> - Internal checks of RPC input to limit or warn of network propagation\n> issues if certain rates are exceeded.\n>\n> - A commonly adopted rate-limit standard.\n>\n>\n> My aim is a set reconciliation gossip type, which will use a common,\n> simple heuristic to accept or reject a gossip message. (Think one channel\n> update per block, or perhaps one per block_height << 5.) See my github\n> for my current draft. [3] This solution allows tighter consensus, yet suffers\n> from the same problem as original anti-spam measures \u2013 it remains\n> somewhat arbitrary. I would like to start a conversation regarding gossip\n> propagation, channel_update and node_announcement usage, and perhaps even\n> bandwidth goals for syncing gossip in the future (how about a million\n> channels?) This would aid in the development of gossip set\n> reconciliation, but could also benefit current node connection and\n> routing reliability more generally.\n>\n>\n> Thanks,\n>\n> Alex\n>\n>\n> [1] https://github.com/sipa/minisketch\n>\n> [2]\n> https://github.com/endothermicdev/lnspammityspam/blob/main/sampleoutput.txt\n>\n> [3]\n> https://github.com/endothermicdev/lightning-rfc/blob/gossip-minisketch/07-routing-gossip.md#set-reconciliation\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220421/ba5e3e5e/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2022-04-22T02:20:56",
                "message_text_only": "Matt Corallo <lf-lists at mattcorallo.com> writes:\n> Sure, if you\u2019re rejecting a large % of channel updates in total\n> you\u2019re gonna end up hitting degenerate cases, but we can consider\n> tuning the sync frequency if that becomes an issue.\n\nLet's be clear: it's a problem.\n\nAllowing only 1 a day, ended up with 18% of channels hitting the spam\nlimit.  We cannot fit that many channel differences inside a set!\n\nPerhaps Alex should post his more detailed results, but it's pretty\nclear that we can't stay in sync with this many differences :(\n\n> gossip queries  is broken in at least five ways.\n\nNaah, it's perfect if you simply want to ask \"give me updates since XXX\"\nto get you close enough on reconnect to start using set reconciliation.\nThis might allow us to remove some of the other features?\n\nBut we might end up with a gossip2 if we want to enable taproot, and use\nblockheight as timestamps, in which case we could probably just support\nthat one operation (and maybe a direct query op).\n\n> Like eclair, we don\u2019t bother to rate limit and don\u2019t see any issues with it, though we will skip relaying outbound updates if we\u2019re saturating outbound connections.\n\nYeah, we did as a trial, and in some cases it's become limiting.  In\nparticular, people restarting their LND nodes once a day resulting in 2\nupdates per day (which, in 0.11.0, we now allow).\n\nCheers,\nRusty."
            },
            {
                "author": "Matt Corallo",
                "date": "2022-04-22T18:55:34",
                "message_text_only": "On 4/21/22 7:20 PM, Rusty Russell wrote:\n> Matt Corallo <lf-lists at mattcorallo.com> writes:\n>> Sure, if you\u2019re rejecting a large % of channel updates in total\n>> you\u2019re gonna end up hitting degenerate cases, but we can consider\n>> tuning the sync frequency if that becomes an issue.\n> \n> Let's be clear: it's a problem.\n> \n> Allowing only 1 a day, ended up with 18% of channels hitting the spam\n> limit.  We cannot fit that many channel differences inside a set!\n> \n> Perhaps Alex should post his more detailed results, but it's pretty\n> clear that we can't stay in sync with this many differences :(\n\nRight, the fact that most nodes don't do any limiting at all and y'all have a *very* aggressive (by \ncomparison) limit is going to be an issue in any context. We could set some guidelines and improve \nthings, but luckily regular-update-sync bypasses some of these issues anyway - if we sync once per \nblock and your limit is once per block, getting 1000 updates per block for some channel doesn't \nresult in multiple failures in the sync. Sure, multiple peers sending different updates for that \nchannel can still cause some failures, but its still much better.\n\n>> gossip queries  is broken in at least five ways.\n> \n> Naah, it's perfect if you simply want to ask \"give me updates since XXX\"\n> to get you close enough on reconnect to start using set reconciliation.\n> This might allow us to remove some of the other features?\n\nSure, but that's *just* the \"gossip_timestamp_filter\" message, there's several other messages and a \nwhole query system that we can throw away if we just want that message :)\n\n> But we might end up with a gossip2 if we want to enable taproot, and use\n> blockheight as timestamps, in which case we could probably just support\n> that one operation (and maybe a direct query op).\n> \n>> Like eclair, we don\u2019t bother to rate limit and don\u2019t see any issues with it, though we will skip relaying outbound updates if we\u2019re saturating outbound connections.\n> \n> Yeah, we did as a trial, and in some cases it's become limiting.  In\n> particular, people restarting their LND nodes once a day resulting in 2\n> updates per day (which, in 0.11.0, we now allow).\n\nWhat do you mean \"its become limiting\"? As in you hit some reasonably-low CPU/disk/bandwidth limit \nin doing this? We have a pretty aggressive bandwidth limit for this kinda stuff (well, indirect \nbandwidth limit) and it very rarely hits in my experience (unless the peer is very overloaded and \nnot responding to pings, which is a somewhat separate thing...)\n\nMatt"
            },
            {
                "author": "Rusty Russell",
                "date": "2022-04-23T01:40:44",
                "message_text_only": "Matt Corallo <lf-lists at mattcorallo.com> writes:\n>> Allowing only 1 a day, ended up with 18% of channels hitting the spam\n>> limit.  We cannot fit that many channel differences inside a set!\n>> \n>> Perhaps Alex should post his more detailed results, but it's pretty\n>> clear that we can't stay in sync with this many differences :(\n>\n> Right, the fact that most nodes don't do any limiting at all and y'all have a *very* aggressive (by \n> comparison) limit is going to be an issue in any context.\n\nI'm unable to find the post years ago where I proposed this limit\nand nobody had major objections.  I just volunteered to go first :)\n\n> We could set some guidelines and improve \n> things, but luckily regular-update-sync bypasses some of these issues anyway - if we sync once per \n> block and your limit is once per block, getting 1000 updates per block for some channel doesn't \n> result in multiple failures in the sync. Sure, multiple peers sending different updates for that \n> channel can still cause some failures, but its still much better.\n\nNodes will want to aggressively spam as much as they can, so I think we\nneed a widely-agreed limit.  I don't really care what it is, but\nsomewhere between per 1 and 1000 blocks makes sense?\n\nNormally I'd suggest a burst, but that's bad for consensus: better to\nsay \"just create your update N-6 blocks behind so you can always create a\nnew one 6 blocks behind\".\n\n>>> gossip queries  is broken in at least five ways.\n>> \n>> Naah, it's perfect if you simply want to ask \"give me updates since XXX\"\n>> to get you close enough on reconnect to start using set reconciliation.\n>> This might allow us to remove some of the other features?\n>\n> Sure, but that's *just* the \"gossip_timestamp_filter\" message, there's several other messages and a \n> whole query system that we can throw away if we just want that message :)\n\nI agree.  Removing features would be nice :)\n\n>> But we might end up with a gossip2 if we want to enable taproot, and use\n>> blockheight as timestamps, in which case we could probably just support\n>> that one operation (and maybe a direct query op).\n>> \n>>> Like eclair, we don\u2019t bother to rate limit and don\u2019t see any issues with it, though we will skip relaying outbound updates if we\u2019re saturating outbound connections.\n>> \n>> Yeah, we did as a trial, and in some cases it's become limiting.  In\n>> particular, people restarting their LND nodes once a day resulting in 2\n>> updates per day (which, in 0.11.0, we now allow).\n>\n> What do you mean \"its become limiting\"? As in you hit some reasonably-low CPU/disk/bandwidth limit \n> in doing this? We have a pretty aggressive bandwidth limit for this kinda stuff (well, indirect \n> bandwidth limit) and it very rarely hits in my experience (unless the peer is very overloaded and \n> not responding to pings, which is a somewhat separate thing...)\n\nBy rejecting more than 1 per day, some LND nodes had 50% of their\nchannels left disabled :(\n\nThis same problem will occur if *anyone* does ratelimiting, unless\n*everyone* does.  And with minisketch, there's a good reason to do so.\n\nCheers,\nRusty."
            },
            {
                "author": "Matt Corallo",
                "date": "2022-04-24T20:56:33",
                "message_text_only": "On 4/22/22 6:40 PM, Rusty Russell wrote:\n> Matt Corallo <lf-lists at mattcorallo.com> writes:\n>>> Allowing only 1 a day, ended up with 18% of channels hitting the spam\n>>> limit.  We cannot fit that many channel differences inside a set!\n>>>\n>>> Perhaps Alex should post his more detailed results, but it's pretty\n>>> clear that we can't stay in sync with this many differences :(\n>>\n>> Right, the fact that most nodes don't do any limiting at all and y'all have a *very* aggressive (by\n>> comparison) limit is going to be an issue in any context.\n> \n> I'm unable to find the post years ago where I proposed this limit\n> and nobody had major objections.  I just volunteered to go first :)\n\nI'm not trying to argue the number is good or bad, only that being several orders of magnitude away \nfrom everything else is going to lead to rejections.\n\n>> We could set some guidelines and improve\n>> things, but luckily regular-update-sync bypasses some of these issues anyway - if we sync once per\n>> block and your limit is once per block, getting 1000 updates per block for some channel doesn't\n>> result in multiple failures in the sync. Sure, multiple peers sending different updates for that\n>> channel can still cause some failures, but its still much better.\n> \n> Nodes will want to aggressively spam as much as they can, so I think we\n> need a widely-agreed limit.  I don't really care what it is, but\n> somewhere between per 1 and 1000 blocks makes sense?\n\nI don't really disagree, but my point is that we should strive for the sync system to not need to \ncare about this number as much as possible. Because views of the rate limits are a local view, not a \nglobal view, you'll always end up with things on the edge getting rejected during sync, and, worse, \nwhen we eventually want to change the limit, we'd be hosed.\n\n\n>>> But we might end up with a gossip2 if we want to enable taproot, and use\n>>> blockheight as timestamps, in which case we could probably just support\n>>> that one operation (and maybe a direct query op).\n>>>\n>>>> Like eclair, we don\u2019t bother to rate limit and don\u2019t see any issues with it, though we will skip relaying outbound updates if we\u2019re saturating outbound connections.\n>>>\n>>> Yeah, we did as a trial, and in some cases it's become limiting.  In\n>>> particular, people restarting their LND nodes once a day resulting in 2\n>>> updates per day (which, in 0.11.0, we now allow).\n>>\n>> What do you mean \"its become limiting\"? As in you hit some reasonably-low CPU/disk/bandwidth limit\n>> in doing this? We have a pretty aggressive bandwidth limit for this kinda stuff (well, indirect\n>> bandwidth limit) and it very rarely hits in my experience (unless the peer is very overloaded and\n>> not responding to pings, which is a somewhat separate thing...)\n> \n> By rejecting more than 1 per day, some LND nodes had 50% of their\n> channels left disabled :(\n> \n> This same problem will occur if *anyone* does ratelimiting, unless\n> *everyone* does.  And with minisketch, there's a good reason to do so.\n\nNone of this seems like a good argument for *not* taking the \"send updates since the last sync in \nthe minisketch\" approach to reduce the damage inconsistent policies cause, though? I'm not really \nsure in a world where you do \"update-based-sketch\" gossip sync you're any worse off than today even \nwith different rate-limit policies, though I obviously agree there are substantial issues with the \nmassively inconsistent rate-limit policies we see today.\n\nMatt"
            },
            {
                "author": "Rusty Russell",
                "date": "2022-04-27T06:53:50",
                "message_text_only": "Matt Corallo <lf-lists at mattcorallo.com> writes:\n>> This same problem will occur if *anyone* does ratelimiting, unless\n>> *everyone* does.  And with minisketch, there's a good reason to do so.\n>\n> None of this seems like a good argument for *not* taking the \"send updates since the last sync in \n> the minisketch\" approach to reduce the damage inconsistent policies\n> cause, though?\n\nYou can't do this, with minisketch.  You end up having to keep all the\nratelimited differences you're ignoring *per peer*, and then cancelling\nthem out of the minisketch on every receive or send.\n\nSo you end up doing that LND and core-lightning do, which is \"pick 3\npeers to gossip with\" and tell everyone else to shut up.\n\nYet the point of minisketch is robustness; you can (at cost of 1 message\nper minute) keep in sync with an arbitrary number of peers.\n\nSo, we might as well define a preferred ratelimit, so nodes know that\nspamming past a certain point is not going to propagate.  At the moment,\nLND has no effective ratelimit at all, so it's a race to the bottom.\n\nWe need that limit eventually, this just makes it more of a priority.\n\n> I'm not really \n> sure in a world where you do \"update-based-sketch\" gossip sync you're any worse off than today even \n> with different rate-limit policies, though I obviously agree there are substantial issues with the \n> massively inconsistent rate-limit policies we see today.\n\nYou can't really do it, since rate-limited junk overwhelms the sketch\nreally fast :(\n\nNote, we *can* actually change the ratelimit in future, either by\nrunning two sketches (feature bit!), or by changing the rate slowly\nenough that they can handle the small differences.\n\nCheers,\nRusty."
            },
            {
                "author": "Matt Corallo",
                "date": "2022-04-28T03:21:48",
                "message_text_only": "On 4/26/22 11:53 PM, Rusty Russell wrote:\n> Matt Corallo <lf-lists at mattcorallo.com> writes:\n>>> This same problem will occur if *anyone* does ratelimiting, unless\n>>> *everyone* does.  And with minisketch, there's a good reason to do so.\n>>\n>> None of this seems like a good argument for *not* taking the \"send updates since the last sync in\n>> the minisketch\" approach to reduce the damage inconsistent policies\n>> cause, though?\n> \n> You can't do this, with minisketch.  You end up having to keep all the\n> ratelimited differences you're ignoring *per peer*, and then cancelling\n> them out of the minisketch on every receive or send.\n\nHmm? I'm a bit confused, let me attempt to restate to make sure we're on the same page. What I \n*think* you said here is: \"If you have a node which is rejecting a large percentage *channel*'s \nupdates (on a per-channel, not per-update basis), and it tries to sync, you'll end up having to keep \nsome huge set of 'I dont want any more updates for that channel' on a per-peer basis\"? Or maybe you \nmight have said \"When you rate-limit, you have to tell your peer that you rate-limited a channel \nupdate and that it shouldn't add that update to its next sketch\"?\n\nEither way, I don't think its all that interesting an issue. The first case is definitely an issue, \nbut is an issue in both a new-data-only sketch and all-data sketch world, and is not completely \nsolved with identical rate-limits in any case. It can be largely addressed by sane software defaults \nand roughly-similar rate-limits, though, and because its a per-channel, not per-update issue I'm \nmuch less concerned.\n\nThe second potential thing I think you might have meant here I don't see as an issue at all? You can \nsimply...let the sketch include one channel update that you ignored? See above discussion of similar \nrate-limits.\n\n> So you end up doing that LND and core-lightning do, which is \"pick 3\n> peers to gossip with\" and tell everyone else to shut up.\n> \n> Yet the point of minisketch is robustness; you can (at cost of 1 message\n> per minute) keep in sync with an arbitrary number of peers.\n> \n> So, we might as well define a preferred ratelimit, so nodes know that\n> spamming past a certain point is not going to propagate.  At the moment,\n> LND has no effective ratelimit at all, so it's a race to the bottom.\n\nI agree there should be *some* rough consensus, but rate-limits are a locally-enforced thing, not a \nglobal one. There will always be races and updates you reject that your peers dont, no matter the \nrate-limit, and while I agree we should have guidelines, we can't \"just make them the same\" - it \nboth doesn't solve the problem and means we can't change them in the future.\n\nUltimately, a updates-based sync is more robust in such a case - if there's some race and your peer \naccepts something you don't it may mean one more entry in the sketch one time, but it won't hang \naround forever.\n\n> We need that limit eventually, this just makes it more of a priority.\n> \n>> I'm not really\n>> sure in a world where you do \"update-based-sketch\" gossip sync you're any worse off than today even\n>> with different rate-limit policies, though I obviously agree there are substantial issues with the\n>> massively inconsistent rate-limit policies we see today.\n> \n> You can't really do it, since rate-limited junk overwhelms the sketch\n> really fast :(\n\nHow is this any better in a non-update-based-sketch? The only way to address it is to have a bigger \nsketch, which you can do no matter the thing you're building the sketch over.\n\nMaybe lets schedule a call to get on the same page, throwing text at each other will likely not move \nvery quickly.\n\nMatt"
            },
            {
                "author": "Rusty Russell",
                "date": "2022-04-29T01:11:50",
                "message_text_only": "Matt Corallo <lf-lists at mattcorallo.com> writes:\n> On 4/26/22 11:53 PM, Rusty Russell wrote:\n>> Matt Corallo <lf-lists at mattcorallo.com> writes:\n>>>> This same problem will occur if *anyone* does ratelimiting, unless\n>>>> *everyone* does.  And with minisketch, there's a good reason to do so.\n>>>\n>>> None of this seems like a good argument for *not* taking the \"send updates since the last sync in\n>>> the minisketch\" approach to reduce the damage inconsistent policies\n>>> cause, though?\n>> \n>> You can't do this, with minisketch.  You end up having to keep all the\n>> ratelimited differences you're ignoring *per peer*, and then cancelling\n>> them out of the minisketch on every receive or send.\n>\n> Hmm? I'm a bit confused, let me attempt to restate to make sure we're on the same page. What I \n> *think* you said here is: \"If you have a node which is rejecting a large percentage *channel*'s \n> updates (on a per-channel, not per-update basis), and it tries to sync, you'll end up having to keep \n> some huge set of 'I dont want any more updates for that channel' on a per-peer basis\"? Or maybe you \n> might have said \"When you rate-limit, you have to tell your peer that you rate-limited a channel \n> update and that it shouldn't add that update to its next sketch\"?\n\nOK, let's step back.  Unlike Bitcoin, we can use a single sketch for\n*all* peers.  This is because we *can* encode enough information that\nyou can get useful info from the 64 bit id, and because it's expensive\nto create them so you can't spam.\n\nThe more boutique per-peer handling we need, the further it gets from\nthis ideal;.\n\n> The second potential thing I think you might have meant here I don't see as an issue at all? You can \n> simply...let the sketch include one channel update that you ignored? See above discussion of similar \n> rate-limits.\n\nNo, you need to get all the ignored ones somehow?  There's so much cruft\nin the sketch you can't decode it.  Now you need to remember the ones\nyou ratelimited, and try to match other's ratelimiting.\n\n>> So you end up doing that LND and core-lightning do, which is \"pick 3\n>> peers to gossip with\" and tell everyone else to shut up.\n>> \n>> Yet the point of minisketch is robustness; you can (at cost of 1 message\n>> per minute) keep in sync with an arbitrary number of peers.\n>> \n>> So, we might as well define a preferred ratelimit, so nodes know that\n>> spamming past a certain point is not going to propagate.  At the moment,\n>> LND has no effective ratelimit at all, so it's a race to the bottom.\n>\n> I agree there should be *some* rough consensus, but rate-limits are a locally-enforced thing, not a \n> global one. There will always be races and updates you reject that your peers dont, no matter the \n> rate-limit, and while I agree we should have guidelines, we can't \"just make them the same\" - it \n> both doesn't solve the problem and means we can't change them in the future.\n\nSure it does!  It severly limits the set divergence to race conditions\n(down to block height divergence, in practice).\n\n> Ultimately, a updates-based sync is more robust in such a case - if there's some race and your peer \n> accepts something you don't it may mean one more entry in the sketch one time, but it won't hang \n> around forever.\n>\n>> We need that limit eventually, this just makes it more of a priority.\n>> \n>>> I'm not really\n>>> sure in a world where you do \"update-based-sketch\" gossip sync you're any worse off than today even\n>>> with different rate-limit policies, though I obviously agree there are substantial issues with the\n>>> massively inconsistent rate-limit policies we see today.\n>> \n>> You can't really do it, since rate-limited junk overwhelms the sketch\n>> really fast :(\n>\n> How is this any better in a non-update-based-sketch? The only way to address it is to have a bigger \n> sketch, which you can do no matter the thing you're building the sketch over.\n>\n> Maybe lets schedule a call to get on the same page, throwing text at each other will likely not move \n> very quickly.\n\nMaybe.  What's a \"non-update\" based sketch?  Some huge percentage of\ngossip is channel_update, so it's kind of the thing we want?\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Gossip Propagation, Anti-spam, and Set Reconciliation",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Matt Corallo",
                "Greg Sanders",
                "Bastien TEINTURIER",
                "Rusty Russell",
                "Alex Myers"
            ],
            "messages_count": 15,
            "total_messages_chars_count": 60280
        }
    },
    {
        "title": "[Lightning-dev] Security issue in anchor outputs implementations",
        "thread_messages": [
            {
                "author": "Bastien TEINTURIER",
                "date": "2022-04-22T09:22:49",
                "message_text_only": "Good morning list,\n\nI will describe here a vulnerability found in older versions of some\nlightning implementations of anchor outputs. As most implementations\nhave not yet released support for anchor outputs, they should verify\nthat they are not impacted by this type of vulnerability while they\nimplement this feature.\n\nI want to thank the impacted implementations for their reactivity in\nfixing this issue, which hasn't impacted any user (as far as I know).\n\n## Timeline\n\n- March 23 2021: I discovered an interesting edge case while\nimplementing anchor outputs in eclair ([1]).\n- August 2021: while I was finalizing support for the 0-htlc-fees\nvariant of anchor outputs in eclair, I was able to do in-depth\ninteroperability tests with other implementations that supported\nanchor outputs (only lnd and c-lightning at that time). These tests\nrevealed that both implementations were impacted by the edge case\ndiscovered in March and that it could be exploited to steal funds.\n- September 2 2021: I notified both development teams.\n- October 11 2021: I disclosed the vulnerability to Electrum and LDK\nto ensure they would not ship a version of anchor outputs containing\nthe same issue (anchor outputs wasn't shipped in their software yet).\n- November 2021: a fix for this vulnerability was released in lnd 0.14.0\nand c-lightning 0.10.2.\n\n## Impacted users\n\n- Users running versions of lnd prior to 0.14.0\n- Users running versions of c-lightning prior to 0.10.2 if they have\nactivated experimental features (and have anchor outputs channels)\n\n## Description of the vulnerability\n\nWith anchor outputs, your lightning node doesn't use `SIGHASH_ALL` when\nsending its signatures for htlc transactions in `commitment_signed`.\nIt uses `SIGHASH_SINGLE | SIGHASH_ANYONECANPAY` instead and the other\nnode is supposed to add a `SIGHASH_ALL` signature when they broadcast\nthe htlc transaction.\n\nInterestingly, this lets the other node combine multiple htlcs in a\nsingle transaction without invalidating your signatures, as long as the\n`nLockTime` of all htlcs match. This has been a known fact for a long\ntime, which can be used to batch transactions and save on fees.\n\nThe vulnerability lies in how *revoked* htlc transactions were handled.\nBecause we historically used `SIGHASH_ALL`, we could assume that htlc\ntransactions had a single output. For example, older eclair versions\nused that fact, and when presented with a revoked htlc transaction,\nwould claim a single output of that transaction via a penalty/justice\ntransaction (see [2]). This was completely ok before anchor outputs.\nBut after anchor outputs, if the revoked htlc transaction actually\ncontained many htlcs, your node should claim *all* of the revoked\noutputs with penalty/justice transactions.\n\nWhen presented with a transaction containing multiple revoked htlcs,\nboth impacted implementations would fail to claim any output. This means\nthe attacker could publish a revoked commitment with htlcs that have\nbeen settled since then, and claim these htlcs a second time on-chain,\nthus stealing funds.\n\nLet's take a concrete example, where Bob is under attack.\nBob has channels with Alice and Carol: Alice ---> Bob ---> Carol.\nAlice sends N htlcs to Carol spending all of her channel balance, which\nCarol then fulfills.\nCarol has then irrevocably received the funds from Bob.\nThen Alice publishes her old commitment where all the htlcs were pending\nand aggregates all of her htlc-timeouts in a single transaction.\nBob will fail to claim the revoked htlc outputs which will go back to\nAlice's on-chain wallet. Bob has thus lost the full channel amount.\n\n## Caveat\n\nAn important caveat is that this attack will not work all the time, so\nit can carry a risk for the attacker. The reason for that is that the\nhtlc transactions have a relative delay of 1 block. If the node under\nattack is able to make his penalty/justice transactions confirm\nimmediately after the revoked commitment (by claiming outputs directly\nfrom the commitment transaction with a high enough feerate) the\nattacker won't be able to broadcast the aggregated htlc transaction\n(and loses their channel reserve).\n\nThe success of the attack depends on what block target implementations\nuse for penalty/justice transactions and how congested the mempool is\n(unless the attacker notices that their peer is offline, in which case\nthey can use this opportunity to carry out the attack).\n\nI'm pretty confident all users have already upgraded to newer versions\n(particularly since there have been important bug fixes on unrelated\nissues since then), but if your node still hasn't upgraded, you should\nconsider doing it as soon as possible.\n\nCheers,\nBastien\n\n[1] https://github.com/ACINQ/eclair/pull/1738\n[2]\nhttps://github.com/ACINQ/eclair/blob/35b070ee5de2ea3847cf64b86f7e47abcca10b95/eclair-core/src/main/scala/fr/acinq/eclair/transactions/Transactions.scala#L613\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220422/62503f9e/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Security issue in anchor outputs implementations",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Bastien TEINTURIER"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 5058
        }
    },
    {
        "title": "[Lightning-dev] [RELEASE] core-lightning v0.11.0: Simon's Carefully Chosen Release Name",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2022-04-26T21:59:03",
                "message_text_only": "We're pleased to announce the 0.11.0 release of c-lightning, named on\nbehalf of @SimonVrouwe.\n\nThis release is the first under the rebranded \"Core Lightning\" name.\n\n(Note: binaries are labelled v0.11.0.1 due to a minor bugfix required\nfor reproducible builds).\n\nHighlights for Users\n====================\n\n* We now finally support multiple live channels to the same peer!\n* If we detect rust support, we'll build the cln-grpc plugin for full\n  native GRPC support.\n* We advertize an external IP address if it's reported by two or more\n  peers (disable-ip-discovery or always-use-proxy disables).\n* You can specify two databases with --wallet, and we'll write to both\n  at once (sqlite3 only).\n* pay supports BOLT 11 payment metadata: we'll send it if it's in the invoice.\n* New setchannel command (deprecates setchannelfee) allows setting max\n  and min HTLC amounts. Try lightning-cli setchannel all 0 for #zerobasefee.\n* pay can be forced to exclude channels or nodes with the exclude\n* Significant speedup in start times for old nodes with many historical HTLCs.\n\nHighlights for the Network\n==========================\n\n* We send the remote node's IP address in the init message, so they can\n  tell  what it is. (lightning/bolts#917)\n* We are more aggressive in sending our own gossip to peers, to help propagation.\n* Default port is set by network, so regtest and testnet defaults are\n  different. (lightning/bolts#968)\n* We never generate legacy onions, it's always TLV.\n  We still forward legacy onions for now.\n* We flush sockets before closing, so errors are more likely to reach the peer.\n* Experimental support for announcing DNS addresses in node_announcement\n  (lightning/bolts#911)\n\nHighlights for Developers\n=========================\n\n* pay has a maxfee parameter, which sets a simple LND-style upper fee\n  (vs using maxfeepercent and exemptfee)\n* You can create invoices with only a description hash, using\n  deschashonly.   We still store the full description, so use restraint!\n* pay has deprecated paying solely by description hash: you should\n  provide the full description, too.\n* delinvoice has a new desconly parameter to simply trim the\n  descriptions, but leave the rest intact.\n* We have a rust crate cln-rpc to easily interact with our JSON-RPC.\n* msggen tool allows easy generation of language bindings for our JSON\n  RPC interface.\n\nMore details can be found in the CHANGELOG.md.\n\nThanks to everyone for their contributions and bug reports; please keep\nthem coming.\n\nSince 0.10.2, we've had 712 commits from 37 different authors over 170 days.\n\nA special thanks goes to the 18 first time contributors (a new record!):\n\n    Aaron Dewes\n    Tim W\n    manreo\n    Gregory Sanders\n    zero fee routing\n    Stephen Webel\n    Michael Dance\n    Marnix\n    lightning-developer\n    kiwiidb\n    Jules Comte\n    JohnOnGit\n    GoofyAF\n    Denis Ahrens\n    Clay Shoaf\n    benthecarman\n    azuchi\n    Anand Suresh\n\nCheers,\nChristian, Rusty, Lisa."
            }
        ],
        "thread_summary": {
            "title": "core-lightning v0.11.0: Simon's Carefully Chosen Release Name",
            "categories": [
                "Lightning-dev",
                "RELEASE"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2956
        }
    },
    {
        "title": "[Lightning-dev] Removing the Sats From the Eltoo Ratchet",
        "thread_messages": [
            {
                "author": "Jeremy Rubin",
                "date": "2022-04-30T19:44:19",
                "message_text_only": "Devs,\n\nOne sketch of an idea on how to improve Eltoo like constructions by making\nthe contract \"optically isolated\".\n\n\nCreate an output F with:\n\nAmount: A, Key: MuSig(A,B)\n\nCreate a second output R with:\n\nAmount: Dust, Key: Musig(A', B')\n\nand sign ratchet updates something like:\n\nAmount: Dust, Key: tr(Musig(A', B'), {OP_1 CHECKSIG <N> CLTV, <Timeout> CSV\nOP_1 CHECKSIG 0 OP_CHECKINPUTOUTPOINT <F> EQUAL})\n\nAnd also sign a Tx where {F, R using path with OP_CHECKINPUT} -> {A's\namount, B's amount}.\nF's signature must commit to R's script for Ratchet with N, but not R's\nTXID.\n\n\nWhy go through the trouble of two UTXOs per channel? Is it even two\nchannels?\n\nHere are some properties this 'flipped channel' might have. Are there\nothers you can think of?\n\n1) Privacy: funds are unlinked from being a channel until end of contested\nclose period. All Ratchet txns look the same on the network, harder for\nthird parties to shake you down for more fees.\n2) Reuse: Ratchet can be reused if channel cooperatively closes / splits\nfunds out\n3) Cooperative close can't be pinned by past reveals of ratchet state for\nM-N channels\n4) Ratchet can create multiple ratchet outputs at a time to drive multiple\nchannel balances -- updating ratchet requires N-N, but each\nsubfunds requires only M-M\n6) Some types of issue in the ratchet protocol still permits recovery in\nthe custody layer\n7) If you still want to carry value along the ratchet, you can splice in\nfunds indirectly into that ratchet without linking the funds on-chain\n(e.g., in a channel factory, can use the trick in 4 to dynamically add a\nsub M-M of the N-N for a new separate balance), only linked on\nuncooperative closes.\n\nI know this is handwave WRT the sighash flags/opcodes required, but I'm\nmerely here to inspire and figured the idea of abstracting the ratchet was\nnovel.\n\nBest,\n\nJeremy\n\n\n\n\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220430/67d39d0a/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Removing the Sats From the Eltoo Ratchet",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Jeremy Rubin"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2082
        }
    }
]