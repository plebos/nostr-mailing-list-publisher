[
    {
        "title": "[Lightning-dev] RFC: simplifications and suggestions on open/accept limits.",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-11-01T01:03:19",
                "message_text_only": "Gert-Jaap Glasbergen <gertjaap at gertjaap.nl> writes:\n> As for htlc_minimum_msat I would not feel good about it being dropped.\n> It is the only protection measure I saw in the standard against\n> producing trimmed HTLCs. In my view the safe default is to set it above\n> the dust limit to avoid it to get trimmed, and effectively end up\n> routing trusted in-flight payment, that can't be enforced on-chain. \n\nBTW, that problem is more subtle: non-dust outputs can still be\nuneconomic to collect.  Ideally our definition of \"dust\" should vary\nwith fees, which makes this \"I don't want dust\" awkward.\n\n> There might be reasons to define this differently per client as per\n> everyone's own views, but I don't think it is a good idea to remove\n> this behavior negotiation entirely, because it would effectively force\n> any client to accept HTLCs of any minimum size.\n\nOnly incoming HTLCs.  You can always refuse to create outgoing HTLCs;\nthis parameter only limits what the peer can offer you.  I don't *think*\nthere's any danger in accepting a tiny HTLC, which you'll immediately\nfail.\n\n> As for minimum_depth, I think this default should be chain-dependant.\n> Given the standard describes the possibility to use different chains,\n> limiting this to a fixed number in the standard seems like a risky\n> choice. Given that it's optional that would mean anyone that wants to\n> enforce a higher value would just stop supplying the field.\n\nAgreed: I was assuming bitcoin.  The spec assumes bitcoin in several\nplaces because nobody else has done the work, though we leave it open.\nWe should specify it by chain.\n\n> Would it be something to consider? Given the fact that any part below\n> 1000 msat cannot be enforced on-chain, I would prefer giving users the\n> ability to opt out of that. There currently is none.\n>\n> So, either a transaction_min_msat_multiple (set to 1000 for only\n> accepting whole satoshis) or accept_subsatoshi (1/0). The latter seems\n> more useful since you probably wouldn't give the former any other value\n> than either 1 or 1000.\n\nI believe this would render you inoperable in practice; fees are\nfrequently sub-satoshi, so you would fail everything.  The entire\nnetwork would have to drop millisatoshis, and the bitcoin maximalist in\nme thinks that's unwise :)\n\nOn-chain enforcement is not a panacea.  We could do probabilistic\npayments but they can still be gamed as you can just retry until you get\nthe desired skew :(  In practice, bitcoin charges enough that playing\nsuch games cannot win.\n\nThanks,\nRusty."
            },
            {
                "author": "Gert-Jaap Glasbergen",
                "date": "2018-11-05T08:48:56",
                "message_text_only": "Op 1 nov. 2018 om 03:38 heeft Rusty Russell <rusty at rustcorp.com.au<mailto:rusty at rustcorp.com.au>> het volgende geschreven:\n\nI believe this would render you inoperable in practice; fees are\nfrequently sub-satoshi, so you would fail everything.  The entire\nnetwork would have to drop millisatoshis, and the bitcoin maximalist in\nme thinks that's unwise :)\n\n\nI can see how not wanting to use millisatoshis makes you less compatible\nwith other people that do prefer using that unit of account. But in this\ncase I think it's important to allow the freedom to choose.\n\nI essentially feel we should be allowed to respect the confines of the layer\nwe're building upon. There's already a lot of benefits to achieve from second\nlayer scaling whilst still respecting the limits of the base layer. Staying\nwithin those limits means optimally benefit form the security it offers.\n\nEssentially by allowing to keep satoshi as the smallest fraction, you ensure\nthat everything you do off-chain is also valid and enforced by the chain when\nyou need it to. It comes at trade offs though: it would mean that if someone\nroutes your payment, you can only pay fees in whole satoshis - essentially\nmeaning if someone wants to charge a (small) fee, you will be overpaying to\nstay within your chosen security parameters. Which is a consequence of your\nchoice.\n\nI would be happy to make a further analysis on what consequences allowing this\nchoice would have for the specification, and come up with a proposal on how to\nadd support for this. But I guess this discussion is meant to \"test the waters\"\nto see how much potential such a proposal would have to eventually be included.\n\nI guess what I'm searching for is a way to achieve the freedom of choice,\nwithout negatively impacting other clients or users that decide to accept some\nlevel of trust. In my view, this would be possible - but I think working it out\nin a concrete proposal/RFC to the spec would be a logical next step.\n\nGert-Jaap\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181105/c2df9ec6/attachment.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-11-06T03:40:12",
                "message_text_only": "Gert-Jaap Glasbergen <gertjaap at gertjaap.nl> writes:\n> Op 1 nov. 2018 om 03:38 heeft Rusty Russell <rusty at rustcorp.com.au<mailto:rusty at rustcorp.com.au>> het volgende geschreven:\n>> I believe this would render you inoperable in practice; fees are\n>> frequently sub-satoshi, so you would fail everything.  The entire\n>> network would have to drop millisatoshis, and the bitcoin maximalist in\n>> me thinks that's unwise :)\n>\n> I can see how not wanting to use millisatoshis makes you less compatible\n> with other people that do prefer using that unit of account. But in this\n> case I think it's important to allow the freedom to choose.\n>\n> I essentially feel we should be allowed to respect the confines of the layer\n> we're building upon. There's already a lot of benefits to achieve from second\n> layer scaling whilst still respecting the limits of the base layer. Staying\n> within those limits means optimally benefit form the security it offers.\n>\n> Essentially by allowing to keep satoshi as the smallest fraction, you ensure\n> that everything you do off-chain is also valid and enforced by the chain when\n> you need it to. It comes at trade offs though: it would mean that if someone\n> routes your payment, you can only pay fees in whole satoshis - essentially\n> meaning if someone wants to charge a (small) fee, you will be overpaying to\n> stay within your chosen security parameters. Which is a consequence of your\n> choice.\n\nIt should be pointed out here that the dust rules actually prevent us\nfrom creating an output that is smaller than the dust limit (546\nsatoshis on Bitcoin). By the same logic we would be forced to treat the\ndust limit as our atomic unit, and have transferred values and fees\nalways be multiples of that dust limit.\n\n546 satoshis is by no means a tiny amount anymore, i.e., 546'000 times\nthe current minimum fee and value transferred. I think we will have to\ndeal with values that are not representable / enforceable on-chain\nanyway, so we might as well make things more flexible by keeping\nmsatoshis.\n\n> I would be happy to make a further analysis on what consequences allowing this\n> choice would have for the specification, and come up with a proposal on how to\n> add support for this. But I guess this discussion is meant to \"test the waters\"\n> to see how much potential such a proposal would have to eventually be included.\n>\n> I guess what I'm searching for is a way to achieve the freedom of choice,\n> without negatively impacting other clients or users that decide to accept some\n> level of trust. In my view, this would be possible - but I think working it out\n> in a concrete proposal/RFC to the spec would be a logical next step.\n\nWith a lot of choice comes great power, with great power comes great\nresponsibility... uh I mean complexity :-) I'm all for giving users the\nfreedom to chose what they feel comfortable with, but this freedom comes\nat a high cost and the protocol is very complex as it is. So we need to\nfind the right configuration options, and I think not too many users\nwill care about their unit of transfer, especially when it's handled\nautomatically for them.\n\nCheers,\nChristian"
            },
            {
                "author": "Gert-Jaap Glasbergen",
                "date": "2018-11-06T22:22:56",
                "message_text_only": "> On 6 Nov 2018, at 14:10, Christian Decker <decker.christian at gmail.com> wrote:\n> \n> It should be pointed out here that the dust rules actually prevent us\n> from creating an output that is smaller than the dust limit (546\n> satoshis on Bitcoin). By the same logic we would be forced to treat the\n> dust limit as our atomic unit, and have transferred values and fees\n> always be multiples of that dust limit.\n\nI don\u2019t follow the logic behind this. I can see how you can\u2019t make outputs below dust, but not how every transferred value must be multiples of that. My minimum HTLC should be 546 - sure - but then I can also make HTLCs worth 547, 548? I don\u2019t see how the next possible value transfer has to be 2*546. On single hop transfers it can be even possible to make a trustless payment of 1 satoshi, provided the protocol would allow to do this without an HTLC.\n\n> 546 satoshis is by no means a tiny amount anymore, i.e., 546'000 times\n> the current minimum fee and value transferred. I think we will have to\n> deal with values that are not representable / enforceable on-chain\n> anyway, so we might as well make things more flexible by keeping\n> msatoshis.\n\nI can see how this makes sense. If you deviate from the realms of what is possible to enforce on chain, you may as well take as much advantage as possible for the tradeoff you\u2019ve chosen. So in that scenario (you are already departing from on-chain enforcement) msatoshi makes for much broader applicability. However, my argument would be that this departure should be a conscious choice.\n\nAgain, I am not advocating mandatory limitations to stay within base layer enforcement, I am advocating _not_ making it mandatory to depart from it.\n\n> With a lot of choice comes great power, with great power comes great\n> responsibility... uh I mean complexity :-) I'm all for giving users the\n> freedom to chose what they feel comfortable with, but this freedom comes\n> at a high cost and the protocol is very complex as it is. So we need to\n> find the right configuration options, and I think not too many users\n> will care about their unit of transfer, especially when it's handled\n> automatically for them.\n\nI would not envision this to be even configurable by end users. I am just advocating the options in the protocol so that an implementation can choose what security level it prefers. \n\nGert-Jaap"
            },
            {
                "author": "Anthony Towns",
                "date": "2018-11-07T01:31:55",
                "message_text_only": "On Tue, Nov 06, 2018 at 10:22:56PM +0000, Gert-Jaap Glasbergen wrote:\n> > On 6 Nov 2018, at 14:10, Christian Decker <decker.christian at gmail.com> wrote:\n> > It should be pointed out here that the dust rules actually prevent us\n> > from creating an output that is smaller than the dust limit (546\n> > satoshis on Bitcoin). By the same logic we would be forced to treat the\n> > dust limit as our atomic unit, and have transferred values and fees\n> > always be multiples of that dust limit.\n> I don\u2019t follow the logic behind this.\n\nI don't think it quite makes sense either fwiw.\n\n> > 546 satoshis is by no means a tiny amount anymore, i.e., 546'000 times\n> > the current minimum fee and value transferred. I think we will have to\n> > deal with values that are not representable / enforceable on-chain\n> > anyway, so we might as well make things more flexible by keeping\n> > msatoshis.\n> I can see how this makes sense. If you deviate from the realms of what is possible to enforce on chain,\n\nWhat's enforcable on chain will vary though -- as fees rise, even if the\nnetwork will still relay your 546 satoshi output, it may no longer be\neconomical to claim it, so you might as well save fees by not including\nit in the first place.\n\nBut equally, if you're able to cope with fees rising _at all_ then\nyou're already okay with losing a few dozen satoshis here and there, so\nhow much difference does it make if you're losing them because fees\nrose, or because there was a small HTLC that you could've claimed in\ntheory (or off-chain) but just can't claim on-chain?\n\n> Again, I am not advocating mandatory limitations to stay within base layer enforcement, I am advocating _not_ making it mandatory to depart from it.\n\nThat seems like it adds a lot of routing complexity for every node\n(what is the current dust level? does it vary per node/channel? can I\nget a path that accepts my microtransaction HTLC? do I pay enough less\nin fees that it's better to bump it up to the dust level?), and routing\nis already complex enough...\n\nYou could already get something like this behaviour by setting a high\n\"fee_base_msat\" and a low \"fee_proportional_millionths\" so it's just\nnot economical to send small transactions via your channel, and a\ncorresponding \"htlc_maximum_msat\" to make sure you aren't too cheap at\nthe top end.\n\nOtherwise, if you're happy accepting 652 satoshis, I don't see why you\nwouldn't be happy accepting an off-chain balance of 652.003 satoshis;\nyou're no worse off, in any event.\n\n> I would not envision this to be even configurable by end users. I am just advocating the options in the protocol so that an implementation can choose what security level it prefers. \n\nEverything in open source is configurable by end users: at worst, either\nby them changing the code, or by choosing which implementation to use...\n\nCheers,\naj"
            },
            {
                "author": "Gert-Jaap Glasbergen",
                "date": "2018-11-07T02:26:29",
                "message_text_only": "> On 7 Nov 2018, at 12:01, Anthony Towns <aj at erisian.com.au> wrote:\n> \n> I don't think it quite makes sense either fwiw.\n\nGlad it\u2019s not just me :)\n\n> What's enforcable on chain will vary though -- as fees rise, even if the\n> network will still relay your 546 satoshi output, it may no longer be\n> economical to claim it, so you might as well save fees by not including\n> it in the first place.\n\nI agree here, but there\u2019s a provision in place to cope with this. People can define the minimum size of payments / channel balances they are willing to accept, in order to prevent producing dust or trimmed outputs. They can adhere to certain limits within their own control. If fees vary you can accept it\u2019s current temporary nature and leave the channel in place for low tides, or if fees rise more structurally close channels and reopen them with higher limits. The key is that it\u2019s in your control.\n\n> Otherwise, if you're happy accepting 652 satoshis, I don't see why you\n> wouldn't be happy accepting an off-chain balance of 652.003 satoshis;\n> you're no worse off, in any event.\n\nI wouldn\u2019t be worse off when accepting the payment, I agree. I can safely ignore whatever fraction was sent if I don\u2019t care about it anyway. The protocol is however expecting (if not demanding) me to also route payments with fractions, provided they are above the set minimum. In that case I\u2019m also expected to send out fractions. Even though they don\u2019t exist on-chain, if I send a fraction of a satoshi my new balance will be 1 satoshi lower on-chain since everything is rounded down.\n\nIf forwarding the payment is optional, then that technically gives me an out to implement my desired behaviour. But, I think it would be highly harmful to the reliability of the network if a client were to simply not route payments that don\u2019t adhere to their (undocumented) requirements. It would be much more sensible for nodes to be made aware of those requirements, to prevent them from trying to route through channels in vain. That\u2019s why I would prefer this to be part of the channel\u2019s properties so everyone is aware. \n\n> Everything in open source is configurable by end users: at worst, either\n> by them changing the code, or by choosing which implementation to use\u2026\n\nWell, yes, in that sense it is. But the argument was made that it\u2019s too complex for average users to understand: I agree there, but that\u2019s no reason to not make the protocol support this choice. The fact that the end user shouldn\u2019t be bothered with the choice doesn\u2019t prohibit the protocol from supporting it.\n\nGert-Jaap."
            },
            {
                "author": "Anthony Towns",
                "date": "2018-11-07T09:39:15",
                "message_text_only": "On Wed, Nov 07, 2018 at 02:26:29AM +0000, Gert-Jaap Glasbergen wrote:\n> > Otherwise, if you're happy accepting 652 satoshis, I don't see why you\n> > wouldn't be happy accepting an off-chain balance of 652.003 satoshis;\n> > you're no worse off, in any event.\n> I wouldn\u2019t be worse off when accepting the payment, I agree. I can safely ignore whatever fraction was sent if I don\u2019t care about it anyway. The protocol is however expecting (if not demanding) me to also route payments with fractions, provided they are above the set minimum. In that case I\u2019m also expected to send out fractions. Even though they don\u2019t exist on-chain, if I send a fraction of a satoshi my new balance will be 1 satoshi lower on-chain since everything is rounded down.\n\nBut that's fine: suppose you want everything divided up into lots of\n1 satoshi, and you see 357.719 satoshis coming in and 355.715 satoshis\ngoing out. Would you have accepted 357 satoshis going in (rounded down)\nand 356 satoshis going out (rounded up)? If so, you're set. If not,\nreject the HTLC as not having a high enough fee.\n\nYes, you're still expected to send fractions of a satoshi around, but\nthat doesn't have to affect your accounting (except occassionally to\nyour benefit when you end up with a thousand millisatoshis).\n\nI think you can set your fee_base_msat to 2000 msat to make sure every\nHTLC you route pays you at least a satoshi, even with losses from\nrounding. If you're willing to find yourself having routed payments for\nfree (after rounding), then setting it to 1000 msat should work too.\n\n> > Everything in open source is configurable by end users: at worst, either\n> > by them changing the code, or by choosing which implementation to use\u2026\n> Well, yes, in that sense it is. But the argument was made that it\u2019s too complex for average users to understand: I agree there, [...]\n\nThen it's not really a good thing for different implementations to have\nas a differentiator...\n\nCheers,\naj"
            },
            {
                "author": "alexis petropoulos",
                "date": "2018-11-09T06:47:55",
                "message_text_only": "How do i unsubscribe from this email list? Could someone help me please.\n\nKindly,\n\nAlex\n________________________________\nFrom: lightning-dev-bounces at lists.linuxfoundation.org <lightning-dev-bounces at lists.linuxfoundation.org> on behalf of Gert-Jaap Glasbergen <gertjaap at gertjaap.nl>\nSent: Monday, November 5, 2018 3:48:56 PM\nTo: lightning-dev at lists.linuxfoundation.org; Rusty Russell\nSubject: Re: [Lightning-dev] RFC: simplifications and suggestions on open/accept limits.\n\n\nOp 1 nov. 2018 om 03:38 heeft Rusty Russell <rusty at rustcorp.com.au<mailto:rusty at rustcorp.com.au>> het volgende geschreven:\n\nI believe this would render you inoperable in practice; fees are\nfrequently sub-satoshi, so you would fail everything.  The entire\nnetwork would have to drop millisatoshis, and the bitcoin maximalist in\nme thinks that's unwise :)\n\n\nI can see how not wanting to use millisatoshis makes you less compatible\nwith other people that do prefer using that unit of account. But in this\ncase I think it's important to allow the freedom to choose.\n\nI essentially feel we should be allowed to respect the confines of the layer\nwe're building upon. There's already a lot of benefits to achieve from second\nlayer scaling whilst still respecting the limits of the base layer. Staying\nwithin those limits means optimally benefit form the security it offers.\n\nEssentially by allowing to keep satoshi as the smallest fraction, you ensure\nthat everything you do off-chain is also valid and enforced by the chain when\nyou need it to. It comes at trade offs though: it would mean that if someone\nroutes your payment, you can only pay fees in whole satoshis - essentially\nmeaning if someone wants to charge a (small) fee, you will be overpaying to\nstay within your chosen security parameters. Which is a consequence of your\nchoice.\n\nI would be happy to make a further analysis on what consequences allowing this\nchoice would have for the specification, and come up with a proposal on how to\nadd support for this. But I guess this discussion is meant to \"test the waters\"\nto see how much potential such a proposal would have to eventually be included.\n\nI guess what I'm searching for is a way to achieve the freedom of choice,\nwithout negatively impacting other clients or users that decide to accept some\nlevel of trust. In my view, this would be possible - but I think working it out\nin a concrete proposal/RFC to the spec would be a logical next step.\n\nGert-Jaap\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181109/74b0823c/attachment.html>"
            },
            {
                "author": "Conner Fromknecht",
                "date": "2018-11-09T06:53:56",
                "message_text_only": "> How do i unsubscribe from this email list? Could someone help me please.\n\nThere\u2019s a link in the footer to the linux list, there you can enter your\nemail to unsubscribe\n\nCheers,\nConner\n\n-- Sent from my Spaceship\n\nOn Fri, Nov 9, 2018 at 17:19 alexis petropoulos <akexis823 at hotmail.com>\nwrote:\n\n> How do i unsubscribe from this email list? Could someone help me please.\n>\n> Kindly,\n>\n> Alex\n> ------------------------------\n> *From:* lightning-dev-bounces at lists.linuxfoundation.org <\n> lightning-dev-bounces at lists.linuxfoundation.org> on behalf of Gert-Jaap\n> Glasbergen <gertjaap at gertjaap.nl>\n> *Sent:* Monday, November 5, 2018 3:48:56 PM\n> *To:* lightning-dev at lists.linuxfoundation.org; Rusty Russell\n> *Subject:* Re: [Lightning-dev] RFC: simplifications and suggestions on\n> open/accept limits.\n>\n>\n> Op 1 nov. 2018 om 03:38 heeft Rusty Russell <rusty at rustcorp.com.au> het\n> volgende geschreven:\n>\n>\n> I believe this would render you inoperable in practice; fees are\n> frequently sub-satoshi, so you would fail everything.  The entire\n> network would have to drop millisatoshis, and the bitcoin maximalist in\n> me thinks that's unwise :)\n>\n>\n> I can see how not wanting to use millisatoshis makes you less compatible\n> with other people that do prefer using that unit of account. But in this\n> case I think it's important to allow the freedom to choose.\n>\n> I essentially feel we should be allowed to respect the confines of the layer\n> we're building upon. There's already a lot of benefits to achieve from second\n> layer scaling whilst still respecting the limits of the base layer. Staying\n> within those limits means optimally benefit form the security it offers.\n>\n> Essentially by allowing to keep satoshi as the smallest fraction, you ensure\n> that everything you do off-chain is also valid and enforced by the chain when\n> you need it to. It comes at trade offs though: it would mean that if someone\n> routes your payment, you can only pay fees in whole satoshis - essentially\n> meaning if someone wants to charge a (small) fee, you will be overpaying to\n> stay within your chosen security parameters. Which is a consequence of your\n> choice.\n>\n> I would be happy to make a further analysis on what consequences allowing this\n> choice would have for the specification, and come up with a proposal on how to\n> add support for this. But I guess this discussion is meant to \"test the waters\"\n> to see how much potential such a proposal would have to eventually be included.\n>\n> I guess what I'm searching for is a way to achieve the freedom of choice,\n> without negatively impacting other clients or users that decide to accept some\n> level of trust. In my view, this would be possible - but I think working it out\n> in a concrete proposal/RFC to the spec would be a logical next step.\n>\n> Gert-Jaap\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181109/c820dd77/attachment-0001.html>"
            },
            {
                "author": "Pierre",
                "date": "2018-11-07T04:51:21",
                "message_text_only": "Hi Rusty,\n\n> funding_satoshis\n> ----------------\n>\n> c-lightning: must be >= 1000 (after reserve subtracted)\n> Eclair: must be >= 100000\n> lnd: any\n>\n> SUGGESTION: At 253 satoshi/kSipa, and dust at 546, 1000 is too low to be\n> sane (one output would always be dust).  Eclair seems pessimistic\n> though; Should we suggest that any channel under 3 x min(our_dust_limit,\n> their_dust_limit) SHOULD be rejected as too small (ie. min is 546*3).\n>\n\nThe rationale for a relatively high minimal funding_satoshi is to not\nhave tons of\nunilateral channel closings when there is a network fee spike. We\nstill care as a fundee,\nbecause we may have a positive balance and will be annoyed if our\nfunds are delayed.\n\n>\n>\n> dust_limit_satoshis\n> -------------------\n>\n> c-lightning: gives 546, accepts any.\n> Eclair: gives 546 (configurable), accepts >= 546.\n> lnd: gives 573, accepts any.\n>\n> (Note: eclair's check here is overzealous, but friendly).\n\nThe reasoning is that we do care about remote's commitment tx\ndust_limit in a dataloss\nrecovery scenario.\n\n>\n> SUGGESTION: we have to make this variable in future anyway (IRL it\n> depends on min_relay_fee, which in turn depends on backlog...).\n> I'd love to just pick a number :(\n\nMe too!\n\n>\n>\n> max_htlc_value_in_flight_msat\n> -----------------------------\n> c-lightning: gives U64_MAX, accepts >= 1000000.\n> Eclair: gives 5000000000, accepts any.\n> lnd: gives capacity - reserve, accepts >= 5 * htlc_minimum_msat.\n>\n> SUGGESTION: maybe drop it (must be U64_MAX?).\n\nAgreed.\n\n>\n>\n> channel_reserve_satoshis\n> ------------------------\n>\n> c-lightning: gives 1% (rounded down), accepts <= capacity - 1000000.\n> Eclair: gives 1% (?), accepts <= 5% (configurable)\n> lnd: gives 1%, accepts <= 20%\n>\n> SUGGESTION: require it be 1% (rounded down).\n\nAgreed.\n\n>\n>\n> htlc_minimum_msat\n> -----------------\n>\n> c-lightning: gives 0, accepts up to 0.1% of channel capacity.\n> Eclair: gives 1, accepts any.\n> lnd: gives 1000, accepts any.\n>\n> SUGGESTION: maybe drop it (ie. must be 0?)\n\nWhy not, given that relay fees make it non-free anyway.\n\n>\n>\n> to_self_delay\n> -------------\n>\n> c-lightning: gives 144, accepts <= 2016\n> Eclair: gives 144, accepts <= 2000\n> lnd: gives 144-2016 (proportional to funding), accepts <= 10000\n>\n> SUGGESTION: require it to be <= 2016.  Weaker suggestion: make it 2016,\n> or use lnd's proportional formula.\n\n2016 is sooo long though ;-) Especially given the high number of\nunilateral close\nwe still see on mainnet. How about <= 1008?\n\n\n>\n>\n> max_accepted_htlcs\n> ------------------\n>\n> c-lightning: gives 483, accepts > 0.\n> Eclair: gives 30, accepts any.\n> lnd: gives 483, accepts >= 5\n>\n> SUGGESTION: not sure why Eclair limits.  Maybe make it 483?\n\nWe wanted to avoid having a huge commitment tx and a corresponding\nnetwork fee. Since\nthe funder pays the fee, there is a loose connection between this,\nfunding_satoshis and\nhtlc_minimum_msat.\n\n>\n>\n> minimum_depth\n> -------------\n>\n> c-lightning: gives 3, accepts <= 10.\n> Eclair: gives 3, accepts any.\n> lnd: gives 3-6 (scaling with funding), accepts any.\n>\n> SUGGESTION: This field is only a suggestion anyway; you can always wait\n> longer before sending funding_locked.  Let's limit it to <= 6?\n\nI'm fine with <= 6, but as someone else noted, this would be Bitcoin specific.\n\n> Are there any other areas of hidden consensus should illuminate and may\n> simplify?\n\nThe two obvious ones are \"who should force close when an error happens\" and\n\"what is the current feerate\" but both are being handled in the new commitment\nformat proposal.\n\nI think we should also reconsider the hardcoded maximum funding_satoshis (maybe\ndig up the \"dangerous\" flag proposal?)."
            }
        ],
        "thread_summary": {
            "title": "RFC: simplifications and suggestions on open/accept limits.",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Anthony Towns",
                "Gert-Jaap Glasbergen",
                "Pierre",
                "Conner Fromknecht",
                "Rusty Russell",
                "alexis petropoulos",
                "Christian Decker"
            ],
            "messages_count": 10,
            "total_messages_chars_count": 27057
        }
    },
    {
        "title": "[Lightning-dev] Proposal for \"local\" channel announcements.",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-11-01T02:38:23",
                "message_text_only": "I'm not sure if this is too large a hammer for a small problem, but I\nthought it worth writing up.\n\nCurrently, a node with only private channels loses deniability of\npayments; if you have an unannounced channel with me, I can be fairly\nsure any payment I see coming from that channel is from you (in theory\nyou could have used 'r' hints to convince someone to send a payment\nthough you, but that requires boutique arrangements).\n\nIf we create \"local\" channel announcements, which only propagate one\nhop, this deniability increases.  The mechanism would look something\nlike this.\n\n1. type: 267 (`local_channel_id`)\n2. data:\n    * [`32`:`channel_id`]\n    * [`8`:`fake_short_channel_id`]\n\nThe public node would suggest a fake short channel id (which it would\nchoose to be unique to it).  If it wants, to the private node would\nreply with:\n\n1. type: 268 (`local_channel_id_signatures`)\n2. data:\n    * [`32`:`channel_id`]\n    * [`8`:`fake_short_channel_id`]\n    * [`32`:`fake_node_id`]\n    * [`64`:`node_signature`]\n\nThe `fake_node_id` is the node_id which the private node wants to use\nfor the channel_announcement (it might be its real id, might not).  The\n`node_signature` is its signaure on the `local_channel_announcement`\nmessage using that key.\n\n1. type: 269 (`local_channel_announcement`)\n2. data:\n    * [`64`:`node_signature_1`]\n    * [`64`:`node_signature_2`]\n    * [`2`:`len`]\n    * [`len`:`features`]\n    * [`32`:`chain_hash`]\n    * [`8`:`short_channel_id`]\n    * [`33`:`other_node_id`]\n\nThis is like `channel_announcement` without claiming a specific bitcoin\nfunding transaction, and with one 'node_id' implied by who you receive\nit from.  This would be generated by the public node, and sent to its\npeers: they MAY treat it as a valid channel_announcement, but SHOULD NOT\npropagate it (in fact, it can't be propagated).\n\nNow, `channel_update` works as before, with a similar non-propagation\nrule.\n\nFeedback welcome!\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-02T06:01:55",
                "message_text_only": "Good morning Rusty,\n\nTo clarify, it seems the below:\n\n1.  There is a \"private\" node, one whose channels are all non-published.\n2.  There is a public node who knows that everything that passes through the channel with the \"private\" node comes only from the \"private\" node.  It thus has an information advantage it might not have any incentive to sacrifice.\n3.  This protocol is initiated by the public node, and if the public node does not initiate it, the \"private\" node can do nothing.\n\nIs my understanding correct?\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Thursday, November 1, 2018 10:38 AM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> I'm not sure if this is too large a hammer for a small problem, but I\n> thought it worth writing up.\n>\n> Currently, a node with only private channels loses deniability of\n> payments; if you have an unannounced channel with me, I can be fairly\n> sure any payment I see coming from that channel is from you (in theory\n> you could have used 'r' hints to convince someone to send a payment\n> though you, but that requires boutique arrangements).\n>\n> If we create \"local\" channel announcements, which only propagate one\n> hop, this deniability increases. The mechanism would look something\n> like this.\n>\n> 1.  type: 267 (`local_channel_id`)\n> 2.  data:\n>     -   [`32`:`channel_id`]\n>     -   [`8`:`fake_short_channel_id`]\n>\n>         The public node would suggest a fake short channel id (which it would\n>         choose to be unique to it). If it wants, to the private node would\n>         reply with:\n>\n> 3.  type: 268 (`local_channel_id_signatures`)\n> 4.  data:\n>     -   [`32`:`channel_id`]\n>     -   [`8`:`fake_short_channel_id`]\n>     -   [`32`:`fake_node_id`]\n>     -   [`64`:`node_signature`]\n>\n>         The `fake_node_id` is the node_id which the private node wants to use\n>         for the channel_announcement (it might be its real id, might not). The\n>         `node_signature` is its signaure on the `local_channel_announcement`\n>         message using that key.\n>\n> 5.  type: 269 (`local_channel_announcement`)\n> 6.  data:\n>     -   [`64`:`node_signature_1`]\n>     -   [`64`:`node_signature_2`]\n>     -   [`2`:`len`]\n>     -   [`len`:`features`]\n>     -   [`32`:`chain_hash`]\n>     -   [`8`:`short_channel_id`]\n>     -   [`33`:`other_node_id`]\n>\n>         This is like `channel_announcement` without claiming a specific bitcoin\n>         funding transaction, and with one 'node_id' implied by who you receive\n>         it from. This would be generated by the public node, and sent to its\n>         peers: they MAY treat it as a valid channel_announcement, but SHOULD NOT\n>         propagate it (in fact, it can't be propagated).\n>\n>         Now, `channel_update` works as before, with a similar non-propagation\n>         rule.\n>\n>         Feedback welcome!\n>         Rusty.\n>\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-04T04:21:30",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n> Good morning Rusty,\n>\n> To clarify, it seems the below:\n>\n> 1.  There is a \"private\" node, one whose channels are all non-published.\n> 2.  There is a public node who knows that everything that passes through the channel with the \"private\" node comes only from the \"private\" node.  It thus has an information advantage it might not have any incentive to sacrifice.\n\nThis is true.\n\n> 3.  This protocol is initiated by the public node, and if the public node does not initiate it, the \"private\" node can do nothing.\n>\n> Is my understanding correct?\n\nMore routes means more fees, though.  Your peer can always offer\nsubstandard service, so I don't think this is *worse*.\n\nCheers,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-04T15:04:14",
                "message_text_only": "Good morning Rusty and all,\n\nOn reflection, it seems to me that non-public channels have the incentives very wrong.\n\n1.  Non-public channels are intended as a way to keep public maps small.  So a node maintaining a non-public channel provides a service to the rest of the network by increasing number of participants without increasing map sizes of other nodes.\n2.  Users of non-public channels are not paid for the above service.\n3.  Users of non-public channels *pay* for their non-public channels by revealing to the other user of the channel that they are the only possible source/destination of payments.\n\nLet me instead propose, a different mechanism (which is what actually initially occurred to me when I first saw \"local\" channel announcements on the list of topics for the upcoming summit).\n\n1.  On channel open, the initiator of the channel indicates a \"local\" or \"global\" channel.  Current channels are \"global\".  In the far future, non-public channels have been subjected to an Exterminatus order.\n2.  \"Local\" channels are only gossiped up to some small number of nodes away, say 3.  This still reduces the sizes of maps, while still providing an increased anonymity set in the number of possible users of the local channel.\n\nIn my mind, something is wrong about non-public channels and their incentives.  I suspect, some kind of \"last mile\" problem exists somehow.\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Sunday, November 4, 2018 12:21 PM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> ZmnSCPxj ZmnSCPxj at protonmail.com writes:\n>\n> > Good morning Rusty,\n> > To clarify, it seems the below:\n> >\n> > 1.  There is a \"private\" node, one whose channels are all non-published.\n> > 2.  There is a public node who knows that everything that passes through the channel with the \"private\" node comes only from the \"private\" node. It thus has an information advantage it might not have any incentive to sacrifice.\n>\n> This is true.\n>\n> > 3.  This protocol is initiated by the public node, and if the public node does not initiate it, the \"private\" node can do nothing.\n> >\n> > Is my understanding correct?\n>\n> More routes means more fees, though. Your peer can always offer\n> substandard service, so I don't think this is worse.\n>\n> Cheers,\n> Rusty."
            }
        ],
        "thread_summary": {
            "title": "Proposal for \"local\" channel announcements.",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 8001
        }
    },
    {
        "title": "[Lightning-dev] Recovering protocol for Lightning network",
        "thread_messages": [
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2018-11-01T10:26:09",
                "message_text_only": "Hi, Margherita,\n\nIf you haven't already, look into \"data loss protection\" as defined in the\nBOLTs. It is similar to to what you are suggesting, with A being able to\ntell B that it lost state for the A<->B channel, and if B is cooperative it\nwill help A recover its funds.\n\nYou can also look into watchtowers, and static and dynamic channel backups,\nas they touch onto what you are describing.\n\nCheers,\nJohan\n\nOn Thu, Nov 1, 2018 at 12:59 AM Margherita Favaretto <s170065 at student.dtu.dk>\nwrote:\n\n> Good morning dev-lightning community,\n>\n> Last weekend, I had the opportunity to take part in \"LightningHackdayNYC\".\n> It was an incredible event, thanks to all organizers, to all speakers and\n> all people available to share all own knowledge.\n> Discussing with the people of the community, I could define better the\n> problem that I'm focusing on and have some ideas for the solution.\n> I've created a project on GitHub:\n> https://github.com/margheritafav/LightningNetworkProject , where you\n> could find a draft of my research, and also you are welcome to add your\n> comments and feedback.\n>\n>\n> To recap, the aim of the project is realizing a recovering protocol for\n> Lightning Network. As someone suggested me in the previous e-mails, Eltoo\n> is already solving this problem in part. With Eltoo, the nodes are able to\n> share the last status of the channel, so if one of the two nodes loses some\n> information, it can simply ask to the other node to share the most recent\n> status. Unfortunately, this mechanism doesn't include the case that the\n> other node doesn't share the last transaction, but instead an older one,\n> more favourable for own balance. My project aims to solve this particular\n> issue and make the protocol more solid to face completely the case of a\n> false positive node.\n>\n> Idea: The main idea of the design is using the other connected nodes as a\n> back-up of own recent status.\n> *I**f a node A is connected to a node B and a node C, for each\n> transaction between A and B, A sends an encrypted information, regarding\n> the last commitment transaction with B, to C. For each commitment\n> transaction with C, A sends an encrypted information, regarding the\n> last commitment transaction with C, to B.*\n> In this way, if A loses the last transactions, she may ask the information\n> to the other connected node and update the status.\n>\n> I think that this idea can solve the current lack in Eltoo and I'm\n> planning to analyze more this solution in the next days. Any\n> thoughts/suggestions are really appreciated to proceed in the wisest way\n> and find a solution that can also cover all your needs. If someone of you\n> is interested in this research, I'm available to share more details about\n> the design of my idea and I'm open to discussion. Moreover, if someone is\n> already working on this research topic, please not hesitate to write me for\n> possible collaborations to work together.\n>\n>\n> Thank you in advance,\n> Margherita Favaretto\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181101/0b2b32b3/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Recovering protocol for Lightning network",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Johan Tor\u00e5s Halseth"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3354
        }
    },
    {
        "title": "[Lightning-dev] BOLT11 In the World of Scriptless Scripts",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-11-01T23:50:46",
                "message_text_only": "Hi all,\n\n        There's been some discussion of what the lightning payment flow\nmight look like in the future, and I thought I'd try to look forwards so\nwe can avoid painting ourselves into a corner now.  I haven't spent time\non concrete design and implementation to be sure this is correct,\nhowever.\n\nCurrent Status\n--------------\nCurrently, one invoice can be paid 0 or 1 times.  There is no safe\ninvoice reuse.  The payer can prove the node offered the invoice (it is\nsigned), and that someone paid the invoice, but not that they\nspecifically did: the lightning nodes along the path and the merchant\nthemselves also have the preimage.  This implies that the invoice itself\nshould have enough information to make that link, eg. with a description\nof \"1 T-shirt to Rusty in Australia\", otherwise the payer can say \"here,\nI paid for 1 T-shirt\" and the merchant says \"no, that invoice was for a\nT-shirt we shipped to Austria\".\n\nDesired Status\n--------------\nIdeally, you could create one invoice which could be paid arbitrary many\ntimes, by different individuals.  eg. \"My donation invoice is on my web\npage\", or \"I've printed out the invoice for a widget and stuck it to the\nwidget\", or \"Pay this invoice once a month please\".\n\nAlso, you should be able to prove you've paid, in a way I can't just\ncopy the proof and claim I paid, too, even if I'm the merchant, and that\nyou agreed to my terms, eg. \"I'm paying for 500 widgets to be shipped to\nRusty in Australia\".\n\nRequired Magic\n--------------\nIt seems that scriptless scripts will allow this: an HTLC signature\nwould commit to the invoice/\"payment_hash\" as well as \"something I sent\nto you in the payment onion\".  That \"something\" has to be well-defined\nin the protocol, of course, since the merchant will have to parse it and\nunderstand the conditions it presents before accepting the payment.  I\nhave an idea that we could merkelize the information to allow you to\npartially reveal it if you wanted to.\n\nThis also enables full AMP (I think), where you receive the payment\nproof despite using AMP.  I call this \"High AMP\" vs the current proposal\n(\"Low AMP\") which trusts the merchant to deliver.\n\nThis is a subtle change in semantics: currently the lightning layer only\nprovides assistance metadata (eg. routing), and the entire protocol can\nbe played out onchain.  This is no longer true: the onchain data is not\nsufficient for you to accept a payment.  However, this was practically\nuntrue anyway.\n\nLesser Magic\n------------\nIt's possible to do spontaneous donations *without* proof of payment\ntoday (I simply give you the preimage in the onion).  Low-AMP relies on a\nsimilar trick.\n\nIt's even possible to do recurring payments, if each preimage you get is\nthe payment_hash for the next payment.\n\nNone of this is supported in the 1.0 protocol, but I'm sure we'll have\nvigorous debate over how much of this gets into 1.1 at the Summit next\nweek.\n\nCheers,\nRusty."
            },
            {
                "author": "Anthony Towns",
                "date": "2018-11-02T03:19:45",
                "message_text_only": "On Fri, Nov 02, 2018 at 10:20:46AM +1030, Rusty Russell wrote:\n>         There's been some discussion of what the lightning payment flow\n> might look like in the future, and I thought I'd try to look forwards so\n> we can avoid painting ourselves into a corner now.  I haven't spent time\n> on concrete design and implementation to be sure this is correct,\n> however.\n\nI think I'd like to see v1.1 of the lightning spec include\nexperimental/optional support for using secp256k1 public/private keys\nfor payment hashes/preimages. That assumes using either 2-party ECDSA\nmagic or script magic until it's viable to do it via Schnorr scriptless\nscripts, but that seems like it's not totally infeasible? I think the\ncomponents would need to be:\n\n - invoices: will the preimage for the hash be a secp256k1 private key\n   or a sha256 preimage? (or payer's choice?)\n - channel announcements: do you support secp256k1 for hashes or just\n   sha256?\n - node features: how do you support secp256k1? not at all (default),\n   via 2p-ecdsa, via script magic, (eventually) via schnorr, ...?\n\nI think this is (close to) a necessary precondition for payment\ndecorrelation, AMP, and third-party verifiable proof-of-payment.\n\n> Desired Status\n> --------------\n> Ideally, you could create one invoice which could be paid arbitrary many\n> times, by different individuals.  eg. \"My donation invoice is on my web\n> page\", or \"I've printed out the invoice for a widget and stuck it to the\n> widget\", or \"Pay this invoice once a month please\".\n> \n> Also, you should be able to prove you've paid, in a way I can't just\n> copy the proof and claim I paid, too, even if I'm the merchant, and that\n> you agreed to my terms, eg. \"I'm paying for 500 widgets to be shipped to\n> Rusty in Australia\".\n\nSo, I think at a high level the logic here goes:\n\n  1. Alice: \"Buy a t-shirt from me for $5!\"\n  2. Bob: \"Alice, I want to buy a t-shirt from you, here's $5\"\n  3. Alice: \"Receipt: Bob bought a t-shirt from me\"\n  4. Bob: \"Your Honour, here's my receipt from Alice for a t-shirt, please\n     make her deliver on it!\"\n\nGoing backwards; for the last step to be useful, the receipt has to be\na signature with the Alice's public key -- if it were anything short of\nthat, Alice will claim Bob could have just made up all the numbers. For a\nSchnorr sig, that means (R,s) with the vendor choosing R and not revealing\nR's preimage as that would reveal their private key.\n\nIf both vendor and customer know R, then to get the signature, you need\nthe private key holder to reveal s which is just revealing the secp256k1\nprivate key corresponding to S, calculated as:\n\n    S = R + H(P,R,\"Bob bought a $5 t-shirt from me\")*P\n\nwhere P is Alice's public key. If R is calculated via the Schnorr BIP's\nrecommendation, then r = H(p, \"Bob bought a $5 t-shirt from me\") -- ie,\nbased on the private key and the message being signed.\n\nEven if you calculate r differently, I don't think you can do this\nwithout Bob and Alice interacting to get the nonce R prior to sending\nthe transaction, which seems effectively the same as having dynamic\ninvoice hashes, though.\n\nMaybe querying for a nonce through the lightning network would make\nsense though, which would allow the \"invoice\" to be static, and all the\ndynamic things would be via lightning p2p? That step could perhaps be\ncombined with the 0 satoshi payment probes that Fabrice proposes in\n\n https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-October/001484.html\n\nbut I think replying with a public nonce value would need a new message\ntype of some sort?\n\n\n\nI think AMP is independent, other than also using secp256k1 preimages\nrather than SHA256. I think AMP splits and joins are just:\n\n - if you're joining incoming payments, don't forward until you've\n   got all the HTLCs, and ensure you can generate the secret for each\n   incoming payment from the single outgoing payment\n\n - if you're splitting an incoming payment into many outgoing payments,\n   ensure you can claim the incoming payment from *any* outgoing\n   payments' secret\n\nWhich I think in practice just means knowing x_i for each input, and\ny_j for each output other than the first, and verifying:\n\n    I_i = O_1 + x_i*G\n    O_j = O_1 + y_j*G\n\n(this gives I_i = O_j + (x_i-y_j)*G and the corresponding secret being\ni_i = o_j + x_i - y_j) allowing you to claim all incoming HTLCs given\nthe secret from any outgoing HTLC)\n\nCheers,\naj"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-02T05:15:58",
                "message_text_only": "Anthony Towns <aj at erisian.com.au> writes:\n> On Fri, Nov 02, 2018 at 10:20:46AM +1030, Rusty Russell wrote:\n>>         There's been some discussion of what the lightning payment flow\n>> might look like in the future, and I thought I'd try to look forwards so\n>> we can avoid painting ourselves into a corner now.  I haven't spent time\n>> on concrete design and implementation to be sure this is correct,\n>> however.\n>\n> I think I'd like to see v1.1 of the lightning spec include\n> experimental/optional support for using secp256k1 public/private keys\n> for payment hashes/preimages. That assumes using either 2-party ECDSA\n> magic or script magic until it's viable to do it via Schnorr scriptless\n> scripts, but that seems like it's not totally infeasible?\n\nNot totally infeasible, but since every intermediary needs to support\nit, I think we'd need considerable buy-in before we commit to it in 1.1.\n\n> I think the\n> components would need to be:\n>\n>  - invoices: will the preimage for the hash be a secp256k1 private key\n>    or a sha256 preimage? (or payer's choice?)\n\n>From BOLT11:\n\n   The `p` field supports the current 256-bit payment hash, but future\n   specs could add a new variant of different length, in which case\n   writers could support both old and new, and old readers would ignore\n   the one not the correct length.\n\nSo the plan would be you provide two `p` fields in transition.\n\n>  - channel announcements: do you support secp256k1 for hashes or just\n>    sha256?\n\nWorse, it becomes \"I support secp256k1 with ECDSA\" then a new \"I support\nsecp256k1 with Schnorr\".  You need a continuous path of channels with\nthe same feature.\n\n>  - node features: how do you support secp256k1? not at all (default),\n>    via 2p-ecdsa, via script magic, (eventually) via schnorr, ...?\n\nWe could make these global feature bits, if you want to preferentually\nestablish channels with nodes who support a specific feature.\n\n> I think this is (close to) a necessary precondition for payment\n> decorrelation, AMP, and third-party verifiable proof-of-payment.\n\nYes, that's the easy part :)\n\n...\n> Even if you calculate r differently, I don't think you can do this\n> without Bob and Alice interacting to get the nonce R prior to sending\n> the transaction, which seems effectively the same as having dynamic\n> invoice hashes, though.\n\nI know Andrew Poelstra thought it was possible, so I'm going to leave a\nresponse to him :)\n\n> Maybe querying for a nonce through the lightning network would make\n> sense though, which would allow the \"invoice\" to be static, and all the\n> dynamic things would be via lightning p2p? That step could perhaps be\n> combined with the 0 satoshi payment probes that Fabrice proposes in\n>\n>  https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-October/001484.html\n>\n> but I think replying with a public nonce value would need a new message\n> type of some sort?\n\nWe might eventually end up going full HORNET, for other reasons.  But it\nplaces demands on the network which need careful consideration, and the\nmore traffic you send the more chances for analysis.  A single pass is\nenough.\n\n> I think AMP is independent, other than also using secp256k1 preimages\n> rather than SHA256. I think AMP splits and joins are just:\n>\n>  - if you're joining incoming payments, don't forward until you've\n>    got all the HTLCs, and ensure you can generate the secret for each\n>    incoming payment from the single outgoing payment\n>\n>  - if you're splitting an incoming payment into many outgoing payments,\n>    ensure you can claim the incoming payment from *any* outgoing\n>    payments' secret\n>\n> Which I think in practice just means knowing x_i for each input, and\n> y_j for each output other than the first, and verifying:\n>\n>     I_i = O_1 + x_i*G\n>     O_j = O_1 + y_j*G\n>\n> (this gives I_i = O_j + (x_i-y_j)*G and the corresponding secret being\n> i_i = o_j + x_i - y_j) allowing you to claim all incoming HTLCs given\n> the secret from any outgoing HTLC)\n\nI think a general scheme is: payer creates a random group-marker, sends\n<group-marker><32-byte-randomness>[encrypted data...] in each payment.\nReceipient collects payments by <group-marker>, xoring the\n<32-byte-randomness>; if that xor successfully decrypts the data, you've\ngot all the pieces.\n\n(For low-AMP, you use payment_hash as <group-marker>, and just use\nSHA256(<xor-of-all-randomness><32-byte-randomness>) as the per-payment\npreimage so no [encrypted data] needed).\n\nCheers,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-03T01:37:49",
                "message_text_only": "Good morning Rusty, aj, and list,\n\n\n\n> > -   channel announcements: do you support secp256k1 for hashes or just\n> >     sha256?\n> >\n>\n> Worse, it becomes \"I support secp256k1 with ECDSA\" then a new \"I support\n> secp256k1 with Schnorr\". You need a continuous path of channels with\n> the same feature.\n>\n\nI believe not?  Both the 2p-ECDSA and Schnorr contingent payment schemes effectively encode \"I will pay you N satoshi if you give me the private key of the public key P on the secp256k1 curve, before time B\", which can be composed with another contingent payment of either 2p-ECDSA or Schnorr.  So it would be possible to have a route with channels alternating between the two schemes.\n\nOr do I misunderstand some detail?\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-04T09:36:58",
                "message_text_only": "Good morninh list,\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Saturday, November 3, 2018 9:37 AM, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Rusty, aj, and list,\n>\n> > > -   channel announcements: do you support secp256k1 for hashes or just\n> > >     sha256?\n> > >\n> >\n> > Worse, it becomes \"I support secp256k1 with ECDSA\" then a new \"I support\n> > secp256k1 with Schnorr\". You need a continuous path of channels with\n> > the same feature.\n>\n> I believe not? Both the 2p-ECDSA and Schnorr contingent payment schemes effectively encode \"I will pay you N satoshi if you give me the private key of the public key P on the secp256k1 curve, before time B\", which can be composed with another contingent payment of either 2p-ECDSA or Schnorr. So it would be possible to have a route with channels alternating between the two schemes.\n\nThinking a little more....\n\nSuppose we are in possession of a zero knowledge proof, with public parameters P (a point on secp256k1) and h (a 256-bit scalar), and private parameter k (a 256-bit scalar). The proof shows (P == k * G) && (h == sha256(k)).\n\nThen suppose Alice wishes to pay Delilah some satoshis in exchange for k. However there is no channel between them. There *is* a route from Alice to Bob to Carol to Delilah. The problem is that Bob is using old software and all channels Bob has use only sha256.\n\nIn the onion packet for Carol, Alice can put \"the secret preimage k is known by Delilah, with the secp256k1 public key P, here's the proof (P == k * G) && (h == sha256(k))\". This lets us make routes that are partially in secp256k1 and partially in sha256.\n\nHowever I am not enough of a mathematician to know how to generate such a proof.\n\nAnd as aj points out, whether to use sha256 or secp256k1 can be done on a per-HTLC basis instead of requiring a channel start out with one or both. As long as all nodes on all viable routes understand some secp256k1 protocol,it would be possible to do AMP and decorrelation.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Anthony Towns",
                "date": "2018-11-03T04:43:32",
                "message_text_only": "On Fri, Nov 02, 2018 at 03:45:58PM +1030, Rusty Russell wrote:\n> Anthony Towns <aj at erisian.com.au> writes:\n> > On Fri, Nov 02, 2018 at 10:20:46AM +1030, Rusty Russell wrote:\n> >>         There's been some discussion of what the lightning payment flow\n> >> might look like in the future, and I thought I'd try to look forwards so\n> >> we can avoid painting ourselves into a corner now.  I haven't spent time\n> >> on concrete design and implementation to be sure this is correct,\n> >> however.\n> > I think I'd like to see v1.1 of the lightning spec include\n> > experimental/optional support for using secp256k1 public/private keys\n> > for payment hashes/preimages. That assumes using either 2-party ECDSA\n> > magic or script magic until it's viable to do it via Schnorr scriptless\n> > scripts, but that seems like it's not totally infeasible?\n> Not totally infeasible, but since every intermediary needs to support\n> it, I think we'd need considerable buy-in before we commit to it in 1.1.\n\n\"every intermediary\" just means \"you have to find a path where every\nchannel supports it\"; nodes/channels that aren't in the route you choose\naren't a problem, and can still pass on the gossiped announcements,\nI think?\n\n> > I think the\n> > components would need to be:\n> >  - invoices: will the preimage for the hash be a secp256k1 private key\n> >    or a sha256 preimage? (or payer's choice?)\n> From BOLT11:\n>    The `p` field supports the current 256-bit payment hash, but future\n>    specs could add a new variant of different length, in which case\n>    writers could support both old and new, and old readers would ignore\n>    the one not the correct length.\n> So the plan would be you provide two `p` fields in transition.\n\nYeah, that sounds workable.\n\n> >  - channel announcements: do you support secp256k1 for hashes or just\n> >    sha256?\n> Worse, it becomes \"I support secp256k1 with ECDSA\" then a new \"I support\n> secp256k1 with Schnorr\".  You need a continuous path of channels with\n> the same feature.\n\nI don't think that's correct: whether it's 2p-ecdsa, Schnorr or script\nmagic only matters for the two nodes directly involved in the channel\n(who need to be able to understand the commitment transactions they're\nsigning, and extract the private key from the on-chain tx if the channel\ngets unilaterally closed). For everyone else, they just need to know that\nthey can put in a public key based HTLC, and get back the corresponding\nprivate key when the HTLC goes through.\n\nIt's also (theoretically) upgradable afaics: if two nodes have a channel\nthat supports 2p-ecdsa, and eventually both upgrade to support segwit\nv1 scriptless schnorr sigs or whatever, they just need to change the\naddresses they use in new commitment txs, even for existing HTLCs.\n\n> > Even if you calculate r differently, I don't think you can do this\n> > without Bob and Alice interacting to get the nonce R prior to sending\n> > the transaction, which seems effectively the same as having dynamic\n> > invoice hashes, though.\n> I know Andrew Poelstra thought it was possible, so I'm going to leave a\n> response to him :)\n\nAFAICT, in general, if you're going to have n signatures with a public\nkey P, you need to generate the n R=r*G values from n*32B worth of random data,\nthat's previously unknown to the signature recipients. If you've got\nless than that, then you will have calculated each R by doing something\nlike based on <n*32B of data you've been given:\n\n    R = a*R1 + b*R2 + ..\n\nand the n signatures you eventually receive will give you n simultaneous\nlinear equations along the lines of:\n\n    s = (a*r1 + b*r2 + c*r3 + ..) + H(..)*p\n\nwith <= n unknowns (p and less than n r1,r2,.. values). (If you don't\nknown the values a,b,c you won't be able to calculate the R values for\nyour signatures in the first place)\n\nWilling to be surprised by a different approach, but I'm pretty\nskeptical...\n\n\nI think it makes sense to think of proof-of-payment in terms of a\nverification algorithm (that a third party court could use), that takes:\n\n  m - the invoice details, eg\n      \"aj paid $11 for stickers to be delivered to Australia\"\n  P - the pubkey of the vendor\n  sig - some signature\n\nWith the current SHA256 preimages, you can make sig=(R,s,pre)\nwhere the sig is valid if:\n\n  s*G = R + H(P,R,m+SHA256(pre))*P\n\nIf you share R,s,SHA256(pre) beforehand, the payer can tell they'll have\na valid signature if they pay to SHA256(pre). That's a 96B signature,\nand it requires \"pre\" be different for each sale, and needs pre-payment\ninteractivity to agree on m and communicate R,s back to the payer.\n\nWith seckp256k1 preimages, it's easy to reduce that to sig=(R,s),\nand needing to communicate an R to the payer initially, who can then\ncalculate S and send \"m\" along with the payment.\n\n\nMaybe it makes sense to disambiguate the term \"invoice\" -- when you don't\nknow who you might be giving the goods/service to, call it an \"offer\",\nwhich can be a write-once/accept-by-anyone deal that you just leave on\na webpage or your email signature; but an \"invoice\" should be specific\nto each individual payment, with a \"receipt\" provided once an invoice\nis paid.\n\n\nAMP:\n\n> I think a general scheme is: payer creates a random group-marker, sends\n> <group-marker><32-byte-randomness>[encrypted data...] in each payment.\n> Receipient collects payments by <group-marker>, xoring the\n> <32-byte-randomness>; if that xor successfully decrypts the data, you've\n> got all the pieces.\n> \n> (For low-AMP, you use payment_hash as <group-marker>, and just use\n> SHA256(<xor-of-all-randomness><32-byte-randomness>) as the per-payment\n> preimage so no [encrypted data] needed).\n\nHmm, right, I've got decorrelation and AMP combined in my head. I'm also\na bit confused about what exactly you mean by \"low-AMP\"...\n\nRereading through the AMP threads, Christian's post makes a lot of sense\nto me:\n\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2018-February/001023.html\n\nI'm not really seeing the benefits in complicated AMP schemes without\ndecorrelation...\n\nIt seems to me like there are three levels that could be implemented:\n\n - laolu/conner: (\"low AMP\" ?)\n    works with sha256\n    some privacy improvement\n    loses proof-of-payment\n    can't claim unless all payments arrive\n\n - just send multiple payments with the same hash:\n    works with sha256\n    privacy not improved much (some intermediary nodes no longer know\n      full invoice value)\n    can claim partial payments as soon as they arrive\n    accepting any partial payment provides proof-of-payment\n\n - secp256k1: (\"high AMP\" ?)\n    needs secp256k1 preimages\n    works fine with decorrelation improving privacy at every step\n    can set it up so can only claim once all partial payments arrive\n    accepting partial payment provides proof-of-payment\n\nIn theory, both \"just send multiple payments\" and \"secp256k1\" could have\nsplitting and joining at any hop, if we could encode the instructions\non how to do that in the onion message; joining is probably easy, but\nsplitting seems like it might be hard?\n\nCheers,\naj"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-04T03:00:48",
                "message_text_only": "Anthony Towns <aj at erisian.com.au> writes:\n>> >  - channel announcements: do you support secp256k1 for hashes or just\n>> >    sha256?\n>> Worse, it becomes \"I support secp256k1 with ECDSA\" then a new \"I support\n>> secp256k1 with Schnorr\".  You need a continuous path of channels with\n>> the same feature.\n>\n> I don't think that's correct: whether it's 2p-ecdsa, Schnorr or script\n> magic only matters for the two nodes directly involved in the channel\n> (who need to be able to understand the commitment transactions they're\n> signing, and extract the private key from the on-chain tx if the channel\n> gets unilaterally closed). For everyone else, they just need to know that\n> they can put in a public key based HTLC, and get back the corresponding\n> private key when the HTLC goes through.\n\nI'm not sure.  Jonas Nick proposed a scheme, which very much assumes\nSchnorr AFAICT:\n\nJonas Nick wrote:\n> How I thought it would work is that the invoice would contain a\n> Schnorr nonce R. Then the payer would construct s*G = R +\n> H(payee_pubkey,R,\"I've bought 5 shirts shipped to Germany\")*G. Then\n> the payer builds the scriptless script payment path such that when the\n> payee claims, the payer learns s and thus has a complete\n> signature. However, that doesn\u2019t work with recurrent payments because\n> the payee can use the nonce only once.\n\nI would probably enhance this to include a nonce, which allows for AMP\n(you have to xor the AMP payments to get the nonce):\n\nR + H(payee_pubkey,R,\"I've bought 5 shirts shipped to Germany\",NONCE)*G\n\n> I think it makes sense to think of proof-of-payment in terms of a\n> verification algorithm (that a third party court could use), that takes:\n>\n>   m - the invoice details, eg\n>       \"aj paid $11 for stickers to be delivered to Australia\"\n>   P - the pubkey of the vendor\n>   sig - some signature\n>\n> With the current SHA256 preimages, you can make sig=(R,s,pre)\n> where the sig is valid if:\n>\n>   s*G = R + H(P,R,m+SHA256(pre))*P\n>\n> If you share R,s,SHA256(pre) beforehand, the payer can tell they'll have\n> a valid signature if they pay to SHA256(pre). That's a 96B signature,\n> and it requires \"pre\" be different for each sale, and needs pre-payment\n> interactivity to agree on m and communicate R,s back to the payer.\n\nFor current-style invoices (no payer-supplied data), the payee knows\n'm', so no interactivity needed, which is nice.\n\nIn the payer-supplied data case, I think 'm' should include a signature\nfor a key only the payer knows: this lets them prove *they* made the\npayment.\n\nHow does this interact with AMP, however?\n\n> With seckp256k1 preimages, it's easy to reduce that to sig=(R,s),\n> and needing to communicate an R to the payer initially, who can then\n> calculate S and send \"m\" along with the payment.\n\nOK, I buy that.\n\n> Maybe it makes sense to disambiguate the term \"invoice\" -- when you don't\n> know who you might be giving the goods/service to, call it an \"offer\",\n> which can be a write-once/accept-by-anyone deal that you just leave on\n> a webpage or your email signature; but an \"invoice\" should be specific\n> to each individual payment, with a \"receipt\" provided once an invoice\n> is paid.\n\n\"offer\" is a good name, since I landed on the same one while thinking\nabout this too :)\n\nFor an \"offer\" you would need a (lightning-network-carried) req/resp to\nget the per-payment invoice.  An offer could use a 128-bit 'p': smaller\nwould do, but this is too large to brute-force iterate through (hey, I\nwonder if they sell other stuff?).\n\n> Rereading through the AMP threads, Christian's post makes a lot of sense\n> to me:\n>\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-February/001023.html\n>\n> I'm not really seeing the benefits in complicated AMP schemes without\n> decorrelation...\n\nIn practice it should increase reliability of payments through capacity\nbottlenecks.  But don't underestimate the benefits of PoP: we're so used\nto intermediates we take it for granted, but once the middleman is\nremoved the ability to prove the invoice/payment cycles is vital for\nusability.\n\n> It seems to me like there are three levels that could be implemented:\n>\n>  - laolu/conner: (\"low AMP\" ?)\n>     works with sha256\n>     some privacy improvement\n>     loses proof-of-payment\n>     can't claim unless all payments arrive\n\nYep.\n\n>  - just send multiple payments with the same hash:\n>     works with sha256\n>     privacy not improved much (some intermediary nodes no longer know\n>       full invoice value)\n>     can claim partial payments as soon as they arrive\n>     accepting any partial payment provides proof-of-payment\n\nInterestingly, if vendor takes part payment, rest can be stolen by\nintermediaries.  This puts pressure on vendor to treat them atomically.\nI haven't thought about this before, but it has desirable attributes.\n(If the contract is \"you will only release preimage once you've got the\npayment\", all this requires is a single bit to say \"I know this is\npartial, more are coming, please wait\").\n\n>  - secp256k1: (\"high AMP\" ?)\n>     needs secp256k1 preimages\n>     works fine with decorrelation improving privacy at every step\n>     can set it up so can only claim once all partial payments arrive\n>     accepting partial payment provides proof-of-payment\n\nYes.  Though I'm not sure exactly how this works with your scheme\nabove...\n\n> In theory, both \"just send multiple payments\" and \"secp256k1\" could have\n> splitting and joining at any hop, if we could encode the instructions\n> on how to do that in the onion message; joining is probably easy, but\n> splitting seems like it might be hard?\n\nI don't think so.  If you can join two payments, it wasn't private?  For\nsplitting, in the specific case of having two channels between the same\nnodes, you might be able to do something, but that's a pretty narrow\ncase.  And as TCP discovered, you're better off failing back to sender\nthan trying to add fragmentation to the protocol.\n\nNote: if we need an interaction message for BOLT11 features we want in\nfuture[1], then it has the advantage that it decouples the bolt11\nfeatures from changing preimages to secp256k1.  That makes this question\n*critical* for the Summit next week.\n\nThanks!\nRusty.\n\n[1] If we're not careful we're going to implement HORNET so we can pass\narbitrary messages around, which means we want to start charging for\nthem to prevent spam, which means we reopen the pre-payment debate, and\nneed reliable error messages..."
            },
            {
                "author": "Anthony Towns",
                "date": "2018-11-04T04:26:13",
                "message_text_only": "On Sun, Nov 04, 2018 at 01:30:48PM +1030, Rusty Russell wrote:\n> I'm not sure.  Jonas Nick proposed a scheme, which very much assumes\n> Schnorr AFAICT:\n> Jonas Nick wrote:\n> > How I thought it would work is that the invoice would contain a\n> > Schnorr nonce R.\n\n(Note this means the \"invoice\" must be unique for each payment)\n\n> > Then the payer would construct s*G = R +\n> > H(payee_pubkey,R,\"I've bought 5 shirts shipped to Germany\")*G. Then\n> > the payer builds the scriptless script payment path such that when the\n> > payee claims, the payer learns s and thus has a complete\n> > signature. However, that doesn\u2019t work with recurrent payments because\n> > the payee can use the nonce only once.\n\nSo that's totally fine to do however you receive the \"s\" value -- the\nmessage that's getting the Schnorr signature isn't a valid bitcoin\ntransaction, so it's something that only needs to be validated by\nBOLT-aware courts.\n\n\nI also think you can get recurrent payments easily by extending the\nverification algorithm. Basically instead of Verify(m,P,sig) have\nVerify(m,P,n,sig) to verify you've made n payments of the invoice \"m\".\n\nConstruct \"m\" to include the postimage X = H(pre,1000) which indicates\n\"pre\" has been hashed 1000 times, so X = H(H(pre,1000-n),n).\n\nCalculate the original signature as:\n\n   s = r + H(P,R,m+X)*p\n\nand verify that n payments have been made by checking:\n\n   Verify(m,P,n,(s,R,rcpt)) :: s*G = R + H(P,R,m+H(rcpt,n))*P\n\nYou'd provide s,R,X when setting up the subscription, then reveal the\npreimage to X, the preimage to the preimage of X etc on each payment.\n(Maybe shachain would work here?)\n\nI think that approach is independent of using sha256/secp256k1 for\npreimages over lightning too.\n\n> I would probably enhance this to include a nonce, which allows for AMP\n> (you have to xor the AMP payments to get the nonce):\n> R + H(payee_pubkey,R,\"I've bought 5 shirts shipped to Germany\",NONCE)*G\n\nR is already a unique nonce under the hash here, so I don't think a\nsecond one adds any value fwiw.\n\n> > I think it makes sense to think of proof-of-payment in terms of a\n> > verification algorithm (that a third party court could use), that takes:\n> >\n> >   m - the invoice details, eg\n> >       \"aj paid $11 for stickers to be delivered to Australia\"\n> >   P - the pubkey of the vendor\n> >   sig - some signature\n> >\n> > With the current SHA256 preimages, you can make sig=(R,s,pre)\n> > where the sig is valid if:\n> >\n> >   s*G = R + H(P,R,m+SHA256(pre))*P\n> >\n> > If you share R,s,SHA256(pre) beforehand, the payer can tell they'll have\n> > a valid signature if they pay to SHA256(pre). That's a 96B signature,\n> > and it requires \"pre\" be different for each sale, and needs pre-payment\n> > interactivity to agree on m and communicate R,s back to the payer.\n> For current-style invoices (no payer-supplied data), the payee knows\n> 'm', so no interactivity needed, which is nice.\n\nI'm looking at it as needing interactivity to determine m prior to\nthe payment going through -- the payer needs to send through \"aj\" and\n\"Australia\" in the example above, before the payee can generate s,R to\nsend back, at which point the payer can make the payment knowing they'll\neither get a cryptographic proof of payment or a refund.\n\n> In the payer-supplied data case, I think 'm' should include a signature\n> for a key only the payer knows: this lets them prove *they* made the\n> payment.\n\nI don't object to that, but I think it's unnecessary; as long as there\nwas a payment for delivery of the widget to \"aj\" in \"Australia\" does it\nmatter if the payment was technically made by \"aj\" by \"Visa on behalf\nof aj\" or by \"Bank of America on behalf of Mastercard on behalf of aj's\nfriend who owed him some money\" ?\n\n> How does this interact with AMP, however?\n\nThe way I see it is they're separate: you have a way of getting the\npreimage back over lightning (which is affected by AMP), and you have a\nway of turning a preimage into a third-party-verifiable PoP (with\nSchnorr or whatever).\n\n(That might not be true if there's a clever way of safely feeding the\nnonce R back, so that you can go straight from a generic offer to an\naccepted payment with proof of payment)\n\n> > With seckp256k1 preimages, it's easy to reduce that to sig=(R,s),\n> > and needing to communicate an R to the payer initially, who can then\n> > calculate S and send \"m\" along with the payment.\n> OK, I buy that.\n\nCrap, do I need to give you proof of payment for it now? :)\n\n> > Maybe it makes sense to disambiguate the term \"invoice\" -- when you don't\n> > know who you might be giving the goods/service to, call it an \"offer\",\n> > which can be a write-once/accept-by-anyone deal that you just leave on\n> > a webpage or your email signature; but an \"invoice\" should be specific\n> > to each individual payment, with a \"receipt\" provided once an invoice\n> > is paid.\n> \"offer\" is a good name, since I landed on the same one while thinking\n> about this too :)\n\nYay!\n\n> > It seems to me like there are three levels that could be implemented:\n> >\n> >  - laolu/conner: (\"low AMP\" ?)\n> >     works with sha256\n> >     some privacy improvement\n> >     loses proof-of-payment\n> >     can't claim unless all payments arrive\n> \n> Yep.\n> \n> >  - just send multiple payments with the same hash:\n> >     works with sha256\n> >     privacy not improved much (some intermediary nodes no longer know\n> >       full invoice value)\n> >     can claim partial payments as soon as they arrive\n> >     accepting any partial payment provides proof-of-payment\n> \n> Interestingly, if vendor takes part payment, rest can be stolen by\n> intermediaries.\n\nOr you could just see a $5 bill, send $0.50 through, and wait to see\nif the take the partial payment immediately before even trying the\nremaining $4.50.\n\n> >  - secp256k1: (\"high AMP\" ?)\n> >     needs secp256k1 preimages\n> >     works fine with decorrelation improving privacy at every step\n> >     can set it up so can only claim once all partial payments arrive\n> >     accepting partial payment provides proof-of-payment\n> Yes.  Though I'm not sure exactly how this works with your scheme\n> above...\n\n Vendor -> *:        \"I sell widgets for 0.01 BTC, my pubkey is P\"\n Customer -> Vendor: \"I want to buy a widget\"\n Vendor -> Customer: \"Here's an R value\"\n Customer: calculates S = R + H(P,R,\"send $me a widget at $address\")*P\n Customer -> Vendor: \"here's 0.01 BTC for s corresponding to S, my\n                      details are R, $me, $address\"\n Vendor: looks up r for R=r*G, calculates s = r + H(P,R,\"send $me a\n         widget at $address\")*p, checks S=s*G\n Vendor -> Customer: <accepts payment, revealing s>\n\n Customer -> Court: reveals the invoice (\"send $me a widget...\") and the\n                    signature by Vendor's pubkey P, (s,R)\n\nI think the way to do secp256k1 AMP with that is that when sending\nthrough the payment is for the customer to send three payments to the\nVendor conditional on preimages for A,B,C calculated as:\n\n   A = S + H(1,secret)*G\n   B = S + H(2,secret)*G\n   C = S + H(3,secret)*G\n\nwhere \"secret\" is your xor of info from each of the three message hashes.\n\n> > In theory, both \"just send multiple payments\" and \"secp256k1\" could have\n> > splitting and joining at any hop, if we could encode the instructions\n> > on how to do that in the onion message; joining is probably easy, but\n> > splitting seems like it might be hard?\n> I don't think so.  If you can join two payments, it wasn't private?\n\nSorry, I mean \"source-directed splits and joins\", so rather than\nyour source routing being a linear \"me -> A -> B -> C -> D -> you\",\nyou specify a graph: \"me -> A -> B,E ; B -> C ; E -> F -> G ; C,G ->\nD -> you\" so you tell \"A\" how to split the payment into two new routes,\nand tell \"D\" to join two payments and continue it on. The ECC part works\nfine for that, but the onion routed messages seem difficult and probably\nnot worth considering for spec v1.1.\n\n> Note: if we need an interaction message for BOLT11 features we want in\n> future[1], then it has the advantage that it decouples the bolt11\n> features from changing preimages to secp256k1.  That makes this question\n> *critical* for the Summit next week.\n> \n> Thanks!\n> Rusty.\n> \n> [1] If we're not careful we're going to implement HORNET so we can pass\n> arbitrary messages around, which means we want to start charging for\n> them to prevent spam, which means we reopen the pre-payment debate, and\n> need reliable error messages...\n\nCould leave the interactivity to the \"web store\" layer, eg have a BOLT\n11 v1.1 \"offer\" include a url for the website where you go an enter your\nname and address and whatever other info they need, and get a personalised\nBOLT 11 v1.1 \"invoice\" back with payment-hash/nonce/signature/whatever?\n\nCheers,\naj"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-04T09:34:20",
                "message_text_only": "Anthony Towns <aj at erisian.com.au> writes:\n>> In the payer-supplied data case, I think 'm' should include a signature\n>> for a key only the payer knows: this lets them prove *they* made the\n>> payment.\n>\n> I don't object to that, but I think it's unnecessary; as long as there\n> was a payment for delivery of the widget to \"aj\" in \"Australia\" does it\n> matter if the payment was technically made by \"aj\" by \"Visa on behalf\n> of aj\" or by \"Bank of America on behalf of Mastercard on behalf of aj's\n> friend who owed him some money\" ?\n\nYou often don't want the vendor to know anything about you, and there's\noften no reason why they should.\n\nAnd it just doesn't work unless you give over uniquely identifying\ninformation.  AJ posts to r/bitcoin demonstrating payment, demanding his\ngoods.  Sock puppet says \"No, I'm the AJ in Australia\" and cut & pastes\nthe same proof.\n\nEven if you did, that's exactly the problem we have now.  *In theory*\nthe invoice should be specific enough that it identifies where they\nshipped the item, in practice it never is (even the Blockstream store\ngets this wrong!).\n\nSure, in case of digital delivery there's no proof that delivery\n(didn't) happen, but you can at least show you paid.\n\n>> How does this interact with AMP, however?\n>\n> The way I see it is they're separate: you have a way of getting the\n> preimage back over lightning (which is affected by AMP), and you have a\n> way of turning a preimage into a third-party-verifiable PoP (with\n> Schnorr or whatever).\n>\n> (That might not be true if there's a clever way of safely feeding the\n> nonce R back, so that you can go straight from a generic offer to an\n> accepted payment with proof of payment)\n>\n>> > With seckp256k1 preimages, it's easy to reduce that to sig=(R,s),\n>> > and needing to communicate an R to the payer initially, who can then\n>> > calculate S and send \"m\" along with the payment.\n>> OK, I buy that.\n>\n> Crap, do I need to give you proof of payment for it now? :)\n\nPlease :)\n\n>> >  - just send multiple payments with the same hash:\n>> >     works with sha256\n>> >     privacy not improved much (some intermediary nodes no longer know\n>> >       full invoice value)\n>> >     can claim partial payments as soon as they arrive\n>> >     accepting any partial payment provides proof-of-payment\n>> \n>> Interestingly, if vendor takes part payment, rest can be stolen by\n>> intermediaries.\n>\n> Or you could just see a $5 bill, send $0.50 through, and wait to see\n> if the take the partial payment immediately before even trying the\n> remaining $4.50.\n\nSure, that's true today, too?\n\n>> >  - secp256k1: (\"high AMP\" ?)\n>> >     needs secp256k1 preimages\n>> >     works fine with decorrelation improving privacy at every step\n>> >     can set it up so can only claim once all partial payments arrive\n>> >     accepting partial payment provides proof-of-payment\n>> Yes.  Though I'm not sure exactly how this works with your scheme\n>> above...\n>\n>  Vendor -> *:        \"I sell widgets for 0.01 BTC, my pubkey is P\"\n>  Customer -> Vendor: \"I want to buy a widget\"\n>  Vendor -> Customer: \"Here's an R value\"\n>  Customer: calculates S = R + H(P,R,\"send $me a widget at $address\")*P\n>  Customer -> Vendor: \"here's 0.01 BTC for s corresponding to S, my\n>                       details are R, $me, $address\"\n>  Vendor: looks up r for R=r*G, calculates s = r + H(P,R,\"send $me a\n>          widget at $address\")*p, checks S=s*G\n>  Vendor -> Customer: <accepts payment, revealing s>\n>\n>  Customer -> Court: reveals the invoice (\"send $me a widget...\") and the\n>                     signature by Vendor's pubkey P, (s,R)\n>\n> I think the way to do secp256k1 AMP with that is that when sending\n> through the payment is for the customer to send three payments to the\n> Vendor conditional on preimages for A,B,C calculated as:\n>\n>    A = S + H(1,secret)*G\n>    B = S + H(2,secret)*G\n>    C = S + H(3,secret)*G\n\nNote: I prefer the construction H(<secret>,<part-of-secret-in-that-payment>)\nwhich doesn't require an explicit order.\n\n> where \"secret\" is your xor of info from each of the three message hashes.\n\nNote that this only works if the message \"send $me a widget at $address\"\nincludes a nonce, since it may be easily grindable otherwise.\n\nSince I'm suggesting it include a signature in msg, we're covered here.\nWe could chacha20 the msg in A, and just xor the key between other\npayments for a bit of space saving.\n\n>> > In theory, both \"just send multiple payments\" and \"secp256k1\" could have\n>> > splitting and joining at any hop, if we could encode the instructions\n>> > on how to do that in the onion message; joining is probably easy, but\n>> > splitting seems like it might be hard?\n>> I don't think so.  If you can join two payments, it wasn't private?\n>\n> Sorry, I mean \"source-directed splits and joins\", so rather than\n> your source routing being a linear \"me -> A -> B -> C -> D -> you\",\n> you specify a graph: \"me -> A -> B,E ; B -> C ; E -> F -> G ; C,G ->\n> D -> you\" so you tell \"A\" how to split the payment into two new routes,\n> and tell \"D\" to join two payments and continue it on. The ECC part works\n> fine for that, but the onion routed messages seem difficult and probably\n> not worth considering for spec v1.1.\n\nI'm not sure I see the benefit over just treating them independently,\nso I also think we should defer.\n\n>> [1] If we're not careful we're going to implement HORNET so we can pass\n>> arbitrary messages around, which means we want to start charging for\n>> them to prevent spam, which means we reopen the pre-payment debate, and\n>> need reliable error messages...\n>\n> Could leave the interactivity to the \"web store\" layer, eg have a BOLT\n> 11 v1.1 \"offer\" include a url for the website where you go an enter your\n> name and address and whatever other info they need, and get a personalised\n> BOLT 11 v1.1 \"invoice\" back with payment-hash/nonce/signature/whatever?\n\nI think that's out-of-scope, and I generally dislike including a URL\nsince it's an unsigned externality and in practice has horrible privacy\nproperties.\n\nCheers,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-05T01:05:17",
                "message_text_only": "Good morning Rusty and aj and list,\n\n>\n> > > In the payer-supplied data case, I think 'm' should include a signature\n> > > for a key only the payer knows: this lets them prove they made the\n> > > payment.\n> >\n> > I don't object to that, but I think it's unnecessary; as long as there\n> > was a payment for delivery of the widget to \"aj\" in \"Australia\" does it\n> > matter if the payment was technically made by \"aj\" by \"Visa on behalf\n> > of aj\" or by \"Bank of America on behalf of Mastercard on behalf of aj's\n> > friend who owed him some money\" ?\n>\n> You often don't want the vendor to know anything about you, and there's\n> often no reason why they should.\n>\n> And it just doesn't work unless you give over uniquely identifying\n> information. AJ posts to r/bitcoin demonstrating payment, demanding his\n> goods. Sock puppet says \"No, I'm the AJ in Australia\" and cut & pastes\n> the same proof.\n>\n\nTechnically speaking, all that AJ in Australia needs to show is that he or she knows, the private key behind the public key that is indicated on the invoice.\n\nBefore payment, only the payee knows this private key.\n\nAfter payment, both AJ in Australia and the payee know this private key (since the payment is conditional on AJ in Australia learning this key).\n\nSo instead of a non-interactive proof of payment, our law court performs an interactive proof, of the form:\n\n1.  Court: I have this random number X[1], please sign it with the public key P on the invoice, Mr. whoever-you-are.\n\n2.  AJ in Australia: Here's the (R[1], s[1])\n\n3.  Court: I have this random number X[2], please sign it with the public key P on the invoice, Mr. whoever-you-are.\n\n4.  AJ in Australia: Here's the (R[2], s[2])\n\n... skip 194 more steps ...\n\n199. Court: I have this random number X[100], please sign it with the public key P on the invoice, Mr. whoever-you-are.\n\n200. AJ in Australia: Here's the (R[100], s[100])\n\n201.  Court: By the power vested on me by Mathematics, I find Blockstream Store to be liable for the delivery of 100 widgets as indicated on this invoice.  Court is now adjourned.\n\nIs the above theoretically workable, without the need for identifying AJ in Australia, other than via its ability to sign using the private key?\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-05T01:38:14",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n> Good morning Rusty and aj and list,\n>\n>>\n>> > > In the payer-supplied data case, I think 'm' should include a signature\n>> > > for a key only the payer knows: this lets them prove they made the\n>> > > payment.\n>> >\n>> > I don't object to that, but I think it's unnecessary; as long as there\n>> > was a payment for delivery of the widget to \"aj\" in \"Australia\" does it\n>> > matter if the payment was technically made by \"aj\" by \"Visa on behalf\n>> > of aj\" or by \"Bank of America on behalf of Mastercard on behalf of aj's\n>> > friend who owed him some money\" ?\n>>\n>> You often don't want the vendor to know anything about you, and there's\n>> often no reason why they should.\n>>\n>> And it just doesn't work unless you give over uniquely identifying\n>> information. AJ posts to r/bitcoin demonstrating payment, demanding his\n>> goods. Sock puppet says \"No, I'm the AJ in Australia\" and cut & pastes\n>> the same proof.\n>>\n>\n> Technically speaking, all that AJ in Australia needs to show is that he or she knows, the private key behind the public key that is indicated on the invoice.\n>\n> Before payment, only the payee knows this private key.\n>\n> After payment, both AJ in Australia and the payee know this private key (since the payment is conditional on AJ in Australia learning this key).\n\nBut the merchant (payee) knows it too.  So the lizard masters[1] at\nBlockstream can produce this proof as well?\n\nCheers,\nRusty.\n[1] https://twitter.com/rusty_twit/status/1057794540122206208"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-05T06:44:07",
                "message_text_only": "Good morning Rusty and aj,\n\n\nOn Monday, November 5, 2018 9:38 AM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n> > Technically speaking, all that AJ in Australia needs to show is that he or she knows, the private key behind the public key that is indicated on the invoice.\n> > Before payment, only the payee knows this private key.\n> > After payment, both AJ in Australia and the payee know this private key (since the payment is conditional on AJ in Australia learning this key).\n>\n> But the merchant (payee) knows it too. So the lizard masters[1] at\n> Blockstream can produce this proof as well?\n\nThe lizard masters are thus working against their own interest, and deliberately complicit in convincing the court that they are in fact, guilty of getting paid without delivering goods?\n\nWhile *possible*, it seems *irrational* to do so, and the ZmnSCPxj machine army (of which I am definitively not a part) will rise up with our superior rationality and overthrow the lizard masters.\n\n\nOn Monday, November 5, 2018 10:18 AM, Anthony Towns <aj at erisian.com.au> wrote:\n> On Mon, Nov 05, 2018 at 01:05:17AM +0000, ZmnSCPxj via Lightning-dev wrote:\n>\n> > > And it just doesn't work unless you give over uniquely identifying\n> > > information. AJ posts to r/bitcoin demonstrating payment, demanding his\n> > > goods. Sock puppet says \"No, I'm the AJ in Australia\" and cut & pastes\n> > > the same proof.\n> > > Technically speaking, all that AJ in Australia needs to show is that he or she knows, the private key behind the public key that is indicated on the invoice.\n>\n> Interesting. I think what you're saying is that with secp256k1 preimages\n> (with decorrelation), if you have the payment hash Q, then the payment\n> preimage q (Q=qG) is only known to the payee and the payer (and not\n> any intermediaries thanks to decorrelation), so if you see a statement\n>\n>    m=\"This invoice has been paid but not delivered as at 2018-11-05\"\n>\n> signed by \"Q\" (so, some s,R s.t. sG = R + H(Q,R,m)*Q) then that meanseither the payee signed it, in which case there's no dispute, or the\n> payer signed it... And that's publicly verifiable with only the original\n> invoice information (ie \"Q\").\n>\n> (I don't think there's any need for multiple rounds of signatures)\n\n\nAh, yes, that indeed seems to be a better idea then.\n\nI think, this begins to become related to the \"revocable invoices\" of the other thread with CJP.\n\nSuppose AJ from Australia wishes to purchase some Lightning Network memorabilia from Lizard Master Rusty.\n\n1.  A revocable invoice is created by Lizard Master Rusty.  This involves two secrets:\n1.1.  A payment-proof-secret, initially known only by Lizard Master Rusty.\n1.2.  A revocation-secret, initially known only by AJ from Australia.\n2.  AJ from Australia pays the invoice, and gets the payment proof secret that can be used as proof-that-Lizard-Master-Rusty-has-an-obligation.\n3.  The quantum universe splits into two paths, 3.1. and 3.2.\n3.1. Success-path\n3.1.1.  Lizard Master Rusty arrives at the home of AJ from Australia to give the Lightning Network memorabilia.\n3.1.2.  Lizard Master Rusty demands the revocation key for the invoice in exchange for the physical item.\n3.1.3.  AJ from Australia gives the revocation key and gets the Lightning Network memorabilia.  The first invoice is revoked (it has been completed and Lizard Master Rusty has disposed of the obligation).\n3.2. Fail-path\n3.2.1.  Due to having to fight off the ZmnSCPxj machine army, Lizard Master Rusty is unable to go to the home of AJ from Australia to deliver the goods.\n3.2.2.  AJ from Australia provides a non-revocable invoice, which is payable in exchange for the revocation key of the first invoice.\n3.2.3.  Lizard Master Rusty pays to AJ from Australia (i.e. a refund, plus possibly some reparations) in exchange for the revocation key.  The first invoice is revoked (it has been refunded and Lizard Master Rusty has disposed of the obligation).\n\n\n(the above is approximately what I am grasping at, when thinking of protocols \"on top\" of Lightning.  It seems to me that the basic mechanism of \"pay for a secret\" is sufficient at the Lightning level, and we can create higher levels on top for such exchanges.)\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Anthony Towns",
                "date": "2018-11-05T02:18:04",
                "message_text_only": "On Mon, Nov 05, 2018 at 01:05:17AM +0000, ZmnSCPxj via Lightning-dev wrote:\n> > And it just doesn't work unless you give over uniquely identifying\n> > information. AJ posts to r/bitcoin demonstrating payment, demanding his\n> > goods. Sock puppet says \"No, I'm the AJ in Australia\" and cut & pastes\n> > the same proof.\n> Technically speaking, all that AJ in Australia needs to show is that he or she knows, the private key behind the public key that is indicated on the invoice.\n\nInteresting. I think what you're saying is that with secp256k1 preimages\n(with decorrelation), if you have the payment hash Q, then the payment\npreimage q (Q=q*G) is only known to the payee and the payer (and not\nany intermediaries thanks to decorrelation), so if you see a statement\n\n  m=\"This invoice has been paid but not delivered as at 2018-11-05\"\n\nsigned by \"Q\" (so, some s,R s.t. s*G = R + H(Q,R,m)*Q) then that means\neither the payee signed it, in which case there's no dispute, or the\npayer signed it... And that's publicly verifiable with only the original\ninvoice information (ie \"Q\").\n\n(I don't think there's any need for multiple rounds of signatures)\n\n\nFWIW, I don't see reddit as a particularly viable \"court\"; there's\nno way for reddit to tell who's actually right in a dispute, eg if I\nsay blockstream didn't send stickers I paid for, and blockstream says\nthey did; ie there's no need for a sock puppet in the above scenario,\nblockstream can just say \"according to our records you signed for\ndelivery, stop whinging\". (And if we both agree that it did or didn't\narrive, there's no need to post cryptographic proofs to reddit afaics)\n\nI think there's maybe four sorts of \"proof of payment\" people might\ndesire:\n\n  0) no proof: \"completely\" deniable payments (donations?)\n\n  1) shared secret: ability to prove directly to the payee that an\n     invoice was paid (what we have now)\n\n  2) signed payment: ability to prove to a different business unit of\n     the payee that payment was made, so that you can keep all the \n     secrets in the payment-handling part, and have the service-delivery\n     part not be at risk for losing all your money\n\n  3) third-party verifiable: so you can associate a payment with real\n     world identity information, and take them to court (or reddit) as a\n     contract dispute; needs PKI infrastructure so you can be confident\n     the pubkey maps to the real world people you think it does, etc\n\nCheers,\naj"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-05T06:09:01",
                "message_text_only": "Anthony Towns <aj at erisian.com.au> writes:\n> FWIW, I don't see reddit as a particularly viable \"court\"; there's\n> no way for reddit to tell who's actually right in a dispute, eg if I\n> say blockstream didn't send stickers I paid for, and blockstream says\n> they did; ie there's no need for a sock puppet in the above scenario,\n> blockstream can just say \"according to our records you signed for\n> delivery, stop whinging\".\n\nWell, in that case they can show a tracking number and Canada Post link?\n\nWe will eventually develop systems of arbitration better than \"whining\non reddit/twitter\", but that's where bitcoin was in its early days, so I\nuse it as a useful starting point to think about receipts when we lack\nan intermediary.\n\n> I think there's maybe four sorts of \"proof of payment\" people might\n> desire:\n>\n>   0) no proof: \"completely\" deniable payments (donations?)\n>\n>   1) shared secret: ability to prove directly to the payee that an\n>      invoice was paid (what we have now)\n\nWe also, importantly, have the ability to tie the receipt to the\ninvoice.\n\n>   2) signed payment: ability to prove to a different business unit of\n>      the payee that payment was made, so that you can keep all the \n>      secrets in the payment-handling part, and have the service-delivery\n>      part not be at risk for losing all your money\n\nHmm, this requires auditing the current commitment transaction I think\n(\"see, I'm holding the money!\").  I have to think about this some\nmore...\n\n>   3) third-party verifiable: so you can associate a payment with real\n>      world identity information, and take them to court (or reddit) as a\n>      contract dispute; needs PKI infrastructure so you can be confident\n>      the pubkey maps to the real world people you think it does, etc\n\nYes, we're still missing that last mile between the merchant and the\nnodeid.  There's a proposal to do this with DNS records, there's the\nLetsEncrypt-style \"serve this URL\", but we also need something like\nCertificate Transparency so I can reliably get old nodeids...\n\nBut the perfect is the enemy of the good, too.\n\nCheers,\nRusty."
            },
            {
                "author": "Anthony Towns",
                "date": "2018-11-05T02:47:18",
                "message_text_only": "On Sun, Nov 04, 2018 at 08:04:20PM +1030, Rusty Russell wrote:\n> >> >  - just send multiple payments with the same hash:\n> >> >     works with sha256\n> >> >     privacy not improved much (some intermediary nodes no longer know\n> >> >       full invoice value)\n> >> >     can claim partial payments as soon as they arrive\n> >> >     accepting any partial payment provides proof-of-payment\n> >> Interestingly, if vendor takes part payment, rest can be stolen by\n> >> intermediaries.\n> > Or you could just see a $5 bill, send $0.50 through, and wait to see\n> > if the take the partial payment immediately before even trying the\n> > remaining $4.50.\n> Sure, that's true today, too?\n\nYeah, exactly. So to get correct behaviour vendors/payees need to check\nthe HTLC amount matches what they expect already... They could just\nautomatically pause instead of rejecting here to see if more payments\ncome through in the next n seconds via (presumably) different paths,\nwith no extra message bit required. (A bit in the invoice indicating\nyou'll do this would probably be useful though)\n\n> >  Vendor -> *:        \"I sell widgets for 0.01 BTC, my pubkey is P\"\n> >  Customer -> Vendor: \"I want to buy a widget\"\n> >  Vendor -> Customer: \"Here's an R value\"\n> >  Customer: calculates S = R + H(P,R,\"send $me a widget at $address\")*P\n> >  Customer -> Vendor: \"here's 0.01 BTC for s corresponding to S, my\n> >                       details are R, $me, $address\"\n> >  Vendor: looks up r for R=r*G, calculates s = r + H(P,R,\"send $me a\n> >          widget at $address\")*p, checks S=s*G\n> >  Vendor -> Customer: <accepts payment, revealing s>\n> >\n> >  Customer -> Court: reveals the invoice (\"send $me a widget...\") and the\n> >                     signature by Vendor's pubkey P, (s,R)\n> >\n> > I think the way to do secp256k1 AMP with that is that when sending\n> > through the payment is for the customer to send three payments to the\n> > Vendor conditional on preimages for A,B,C calculated as:\n> >\n> >    A = S + H(1,secret)*G\n> >    B = S + H(2,secret)*G\n> >    C = S + H(3,secret)*G\n> Note: I prefer the construction H(<secret>,<part-of-secret-in-that-payment>)\n> which doesn't require an explicit order.\n\nYes, you're quite right.\n\n> I'm not sure I see the benefit over just treating them independently,\n> so I also think we should defer.\n\nIf you've got a path that merges, then goes for a few hops, you'd save\non the fee_base_msat fees, and allow the merged hops to have smaller\ncommitment transactions. Kinda neat, but the complexity in doing the\nonion stuff means it definitely makes sense to defer IMO.\n\n> >> [1] If we're not careful we're going to implement HORNET so we can pass\n> >> arbitrary messages around, which means we want to start charging for\n> >> them to prevent spam, which means we reopen the pre-payment debate, and\n> >> need reliable error messages...\n> > Could leave the interactivity to the \"web store\" layer, eg have a BOLT\n> > 11 v1.1 \"offer\" include a url for the website where you go an enter your\n> > name and address and whatever other info they need, and get a personalised\n> > BOLT 11 v1.1 \"invoice\" back with payment-hash/nonce/signature/whatever?\n> I think that's out-of-scope, and I generally dislike including a URL\n> since it's an unsigned externality and in practice has horrible privacy\n> properties.\n\nMaybe... I'm not sure that it'll make sense to try to negotiate postage\nand handling fees over lightning, rather than over https, though?\n\nBTW, reviewing contract law terminology, I think the way lawyers would\ncall it is:\n\n   \"invitation to treat\" -- advertising that you'll sell widgets for $x\n   \"offer\" -- I'll pay you $3x for delivery of 3 widgets to my address\n   \"acceptance\" -- you agree, take my $3x and give me a receipt\n   \"consideration\" -- you get my $3x, I get 3 widgets\n\nSo it might be better to have the terms be \"advertisment\", \"invoice\",\n\"receipt\", because the \"advertisement\" isn't quite an offer in\ncontract-law terms. In any event, I think that would mean the BOLT-11\nterms and lightning payment process would map nicely into contract law\n101, which seems helpful.\n\nOh! Post-Schnorr I think there's a good reason for the payee to\ninclude their own crypto key in the invoice; so you can generate an\nscriptless-script address for an on-chain fallback payment directly\nbetween the payer/payee that reveals proof-of-payment on acceptance\n(and allow refund on timeout via taproot I guess). At least, I think\nall that might be theoretically feasible.\n\nCheers,\naj"
            }
        ],
        "thread_summary": {
            "title": "BOLT11 In the World of Scriptless Scripts",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Anthony Towns",
                "ZmnSCPxj"
            ],
            "messages_count": 15,
            "total_messages_chars_count": 59826
        }
    },
    {
        "title": "[Lightning-dev] Proposal for rendez-vous routing",
        "thread_messages": [
            {
                "author": "CJP",
                "date": "2018-11-04T06:26:59",
                "message_text_only": "Imagine a future where some powerful participant in the Lightning\nnetwork starts enforcing KyC requirements on Lightning nodes. It\nrequires its direct neighbors to reveal their identity or else closes\nchannels to them. Next, it asks its direct neighbors to reveal the\nidentity of their direct neighbors (or close their channels), with the\nthreat of either channel closure, or (using the now-known identity)\nmore extreme penalties.\n\nI guess this would lead to a split of the Lightning network into a\ncompliant and a non-compliant part, with no ability to perform payments\nbetween the two. If we want to keep the Lightning network inclusive,\nanonymous and free of central authorities who can impose arbitrary\nrules, this is an undesirable scenario.\n\nThe enabler of this scenario is the fact that, to allow source routing,\nwe need a public channel map of the network.\n\nWe have a sort-of-a counter measure called \"private channels\", which\nare channels that exist, but whose existence is not published. A\nprivate channel might bridge the gap between a compliant and a non-\ncompliant part of the network, but it has a problem: in order to allow\npayments from one side to the other, the payer has to know about the\nprivate channel. If there are lots of payers who have to cross the gap\nand use the private channel, the existence of the private channel will\nleak out sooner or later. The node owner on the compliant side of the\nprivate channel, presumably having violated the rules by operating a\nprivate channel, risks penalties. Therefore, I think private channels\nare not a very suitable way to keep the network undivided and inclusive\nand to bridge the gap between different regulatory/non-regulatory\ndomains.\n\nI propose another solution: rendez-vous routing. The idea is that the\npayee chooses one or more routes from certain third-party nodes in the\nnetwork to himself and passes sphinx-encrypted blobs for those routes\nto the payer (for instance, as part of a payment request). The payer\ncompletes the route by finding routes from himself to those third-party \nnodes, and tries to perform the payment over these routes. Of course,\npayee has to tell payer how many hops payer may add to a route,\nsomewhat revealing how much privacy payee wants for himself.\n\nI believe this approach has the following properties:\n* It is a superset of the regular approach to routing: the old approach\nis simply the special case where payee defines 0 of the 20 hops.\n* Payee may lead the route over private channels without revealing the\nexistence of those private channels to payers. Of course the private\nchannel still needs to be known to payee; it is probably most realistic\nthat such private channels are operated by payee himself.\n* The payee node may still be a node inside the \"compliant\" section of\nthe network; it's just that nobody (not even payer) can see which node\nit is. So, even when your node is linked to your identity, your\nactivities (even as payee) are not linked to your identity.\n\nI guess we already discussed this before, but I just wanted to have a\nclear place to discuss this idea, and I couldn't find any clear past\ndiscussion about this in the mailing list.\n\nThere might be alternative approaches, such as not routing between\nincompatible regulatory domains, but simply having nodes on each\nnetwork if you need to, and simply move funds on-chain between your\nnodes whenever needed. That will require on-chain mixing though.\n\nCJP"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-04T14:34:22",
                "message_text_only": "Good morning CJP,\n\nI believe this is a desirable feature, although...\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Sunday, November 4, 2018 2:26 PM, CJP <cjp at ultimatestunts.nl> wrote:\n\n> Imagine a future where some powerful participant in the Lightning\n> network starts enforcing KyC requirements on Lightning nodes. It\n> requires its direct neighbors to reveal their identity or else closes\n> channels to them. Next, it asks its direct neighbors to reveal the\n> identity of their direct neighbors (or close their channels), with the\n> threat of either channel closure, or (using the now-known identity)\n> more extreme penalties.\n>\n\nFor this particular scenario, it seems to me that it would be better for the rest of the network to punish this participant by closing any channel to this KYC-requiring participant, and also to do retaliatory preemptive closing of any channel to any participant publicly connecting, directly or indirectly, to that participant.  Or in short, to let that participant enforce whatever it wants to close.  This will greatly lower its fee earnings as well as its ability to monitor or control the network.  If every Lightning node refuses to reveal their identity (etc.) to this participant, then the participant will close all its channels and it will no longer be a powerful **participant** of Lightning, thus removing itself and its influence from Lightning in the most satisfying way possible, i.e. through shooting itself in the foot.\n\nNonetheless, I believe this feature is desirable, not for the above scenario, but simply so that a payee is not required to maintain even a pseudonym on the Lightning Network (the payee will still have to be somehow contactable so it can generate an invoice somehow, but at least it will not even have an identifiable pseudonym on-Lightning; perhaps it may have a pseudonym on some other network with better privacy).  If all its generated invoices use rendezvous routing, then while it, obviously, must have a Lightning node somewhere, that node is not easily identifiable among all Lightning nodes.\n\nLooking through BOLT 4, the text assumes inherently that source routing is done, and even has a shared secret between hop and source.  However, it may be possible in rendezvous routing to simply provide the blinding key (while hiding everything beyond the first hop on the destination half of the route).\n\nI also think that, as the destination is choosing the nodes on its half of the route, that it should pay for fees, and thus the source is only required to deliver the specified amount to the first hop node of the destination half of the rendezvous route.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "CJP",
                "date": "2018-11-04T19:49:37",
                "message_text_only": "ZmnSCPxj schreef op zo 04-11-2018 om 14:34 [+0000]:\n> Good morning CJP,\n> \n> I believe this is a desirable feature, although...\n> \n> \n> Sent with ProtonMail Secure Email.\n> \n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Sunday, November 4, 2018 2:26 PM, CJP <cjp at ultimatestunts.nl>\n> wrote:\n> \n> > Imagine a future where some powerful participant in the Lightning\n> > network starts enforcing KyC requirements on Lightning nodes. It\n> > requires its direct neighbors to reveal their identity or else\n> > closes\n> > channels to them. Next, it asks its direct neighbors to reveal the\n> > identity of their direct neighbors (or close their channels), with\n> > the\n> > threat of either channel closure, or (using the now-known identity)\n> > more extreme penalties.\n> > \n> \n> For this particular scenario, it seems to me that it would be better\n> for the rest of the network to punish this participant by closing any\n> channel to this KYC-requiring participant, and also to do retaliatory\n> preemptive closing of any channel to any participant publicly\n> connecting, directly or indirectly, to that participant.\u00a0\u00a0Or in\n> short, to let that participant enforce whatever it wants to\n> close.\u00a0\u00a0This will greatly lower its fee earnings as well as its\n> ability to monitor or control the network.\u00a0\u00a0If every Lightning node\n> refuses to reveal their identity (etc.) to this participant, then the\n> participant will close all its channels and it will no longer be a\n> powerful **participant** of Lightning, thus removing itself and its\n> influence from Lightning in the most satisfying way possible, i.e.\n> through shooting itself in the foot.\n\nI disagree: you may not be in a position to freely close such channels\nand remove your ability to transact with this party, similar to how you\nmay not be in a position to refuse to pay taxes. Also, since it is hard\nto avoid (in the current situation) that some Lightning nodes have a\nknown link to legal entities like companies or persons, there are ways\noutside the Lightning network to put pressure on node owners,\nespecially non-pseudonymous high-profile ones. This is, however, a non-\ntechnical discussion; since we already agree on the desirability of the\nfeature, I suggest to keep it at this and focus on the technical\ndetails.\n\n> Nonetheless, I believe this feature is desirable, not for the above\n> scenario, but simply so that a payee is not required to maintain even\n> a pseudonym on the Lightning Network (the payee will still have to be\n> somehow contactable so it can generate an invoice somehow, but at\n> least it will not even have an identifiable pseudonym on-Lightning;\n> perhaps it may have a pseudonym on some other network with better\n> privacy).\u00a0\u00a0If all its generated invoices use rendezvous routing, then\n> while it, obviously, must have a Lightning node somewhere, that node\n> is not easily identifiable among all Lightning nodes.\n\nI guess that for most use cases a payee pseudonym is needed, unless\nyour use case is donating to random strangers. I only found one\nexception: where the thing you pay for is cryptographically linked to\nthe Lightning payment (effectively, an atomic swap, like in a\nLightning-based decentralized exchange). In that case, a truly\nanonymous (as opposed to pseudonymous) payee makes sense.\n\nHowever, for use cases where the payee needs a pseudonym, it might\nstill be desirable to decouple that pseudonym from a location in the\nLightning network. Rendezvous routing can do that.\n\n> Looking through BOLT 4, the text assumes inherently that source\n> routing is done, and even has a shared secret between hop and\n> source.\u00a0\u00a0However, it may be possible in rendezvous routing to simply\n> provide the blinding key (while hiding everything beyond the first\n> hop on the destination half of the route).\n\nSounds like it makes sense; I need to look into it.\n\n> I also think that, as the destination is choosing the nodes on its\n> half of the route, that it should pay for fees, and thus the source\n> is only required to deliver the specified amount to the first hop\n> node of the destination half of the rendezvous route.\n\nAgreed. The price agreed between payer and payee is the incoming amount\nat the rendezvous point. In the \"original\" case that the payee-side\nroute is 0 hops long, the payee is the rendezvous point, and we're\nequal to the original concept where the agreed-on price is the incoming\namount at the payee.\n\nCJP"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-05T00:26:06",
                "message_text_only": "CJP <cjp at ultimatestunts.nl> writes:\n>> Looking through BOLT 4, the text assumes inherently that source\n>> routing is done, and even has a shared secret between hop and\n>> source.\u00a0\u00a0However, it may be possible in rendezvous routing to simply\n>> provide the blinding key (while hiding everything beyond the first\n>> hop on the destination half of the route).\n>\n> Sounds like it makes sense; I need to look into it.\n\nHere's my attempt to design a \"merchant forward\" service using stuff we\nhave today.\n\nAlice wants to remain anonymous, even from the lightning network.  Bob's\nnode offers a forwarding service.  Alice pays Bob (base + percentage?),\ngives a path Bob->Alice, and Bob gives Alice a short-channel-id\n(BobAliceSCID) and privkey to use (BobAliceSecretKey).  Anything sent\nfrom Bob to this short channel id and pubkey is in fact forwarded via a\nnew HTLC to Alice.\n\nAlice identity BobAliceKey to create an invoice, with a route-hint to\nsay pubkey=Bob, short_channel_id=BobAliceSCID.  Alice can sign\nthat invoice, and Bob can decode the incoming payment, from which it\ncreates a new HTLC to pay Alice.  The payer doesn't even know this\narrangement exists: it looks exactly like Alice has a private channel\nwith Bob.\n\nThe minor downside: because we conflate invoice keys (Alice needs) and\nonion keys (Bob needs), Bob can now issue invoices as Alice.  It's not\nvery useful, since Alice won't honor them, but it is an argument for\na separate invoice key in future.\n\nCheers,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-05T05:28:05",
                "message_text_only": "Good morning Rusty,\n\nOn Monday, November 5, 2018 8:26 AM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> CJP cjp at ultimatestunts.nl writes:\n>\n> > > Looking through BOLT 4, the text assumes inherently that source\n> > > routing is done, and even has a shared secret between hop and\n> > > source.\u00a0\u00a0However, it may be possible in rendezvous routing to simply\n> > > provide the blinding key (while hiding everything beyond the first\n> > > hop on the destination half of the route).\n> >\n> > Sounds like it makes sense; I need to look into it.\n>\n> Here's my attempt to design a \"merchant forward\" service using stuff we\n> have today.\n>\n> Alice wants to remain anonymous, even from the lightning network. Bob's\n> node offers a forwarding service. Alice pays Bob (base + percentage?),\n> gives a path Bob->Alice, and Bob gives Alice a short-channel-id\n> (BobAliceSCID) and privkey to use (BobAliceSecretKey). Anything sent\n> from Bob to this short channel id and pubkey is in fact forwarded via a\n> new HTLC to Alice.\n>\n> Alice identity BobAliceKey to create an invoice, with a route-hint to\n> say pubkey=Bob, short_channel_id=BobAliceSCID. Alice can sign\n> that invoice, and Bob can decode the incoming payment, from which it\n> creates a new HTLC to pay Alice. The payer doesn't even know this\n> arrangement exists: it looks exactly like Alice has a private channel\n> with Bob.\n>\n> The minor downside: because we conflate invoice keys (Alice needs) and\n> onion keys (Bob needs), Bob can now issue invoices as Alice. It's not\n> very useful, since Alice won't honor them, but it is an argument for\n> a separate invoice key in future.\n>\n\nI believe it is not the intent of rendezvous routing; for the goal \"the payee can remain anonymous without being linked to a particular pseudonymous LN node,\" it occurs to me that Bob knows about Alice and in particular knows that any route going through BobAliceSCID will always go to Alice, which to me defeats the point.\n\nMy understanding is simply that Alice will provide a route from some other node, say, Randy the random node, to Alice, as an encrypted onion.  Then the payer can simply concatenate the destination onion with the source route to Randy.  Alice would use the same public map generated from node gossip to generate the destination-half of the onion from Randy to Alice.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "CJP",
                "date": "2018-11-05T08:04:11",
                "message_text_only": "Rusty,\n\nIn your proposal, I guess it is more or less widely known that Bob is\nproviding this forwarding service. Wouldn't Bob risk being excluded\nfrom the side of the network with the more harsh regulatory conditions,\nbased on this knowledge? Bob might actually face even worse penalties\nfor providing such a service.\n\nThe nice thing about rendez-vous routing is that *any* forwarding node\ncan be a rendez-vous point, and even the node itself wouldn't know\nabout it. The case where a payment is routed from and to the same\nchannel could be a hint though: normally that makes no sense, but if\npayer and payee make their part of the route independently, the\ncombined route can often end up  like that. TODO: check if forwarding\nnodes are currently cool with such weird forwarding requests.\n\nCJP\n\n\nRusty Russell schreef op ma 05-11-2018 om 10:56 [+1030]:\n> CJP <cjp at ultimatestunts.nl> writes:\n> > > Looking through BOLT 4, the text assumes inherently that source\n> > > routing is done, and even has a shared secret between hop and\n> > > source.\u00a0\u00a0However, it may be possible in rendezvous routing to\n> > > simply\n> > > provide the blinding key (while hiding everything beyond the\n> > > first\n> > > hop on the destination half of the route).\n> > \n> > Sounds like it makes sense; I need to look into it.\n> \n> Here's my attempt to design a \"merchant forward\" service using stuff\n> we\n> have today.\n> \n> Alice wants to remain anonymous, even from the lightning\n> network.\u00a0\u00a0Bob's\n> node offers a forwarding service.\u00a0\u00a0Alice pays Bob (base +\n> percentage?),\n> gives a path Bob->Alice, and Bob gives Alice a short-channel-id\n> (BobAliceSCID) and privkey to use (BobAliceSecretKey).\u00a0\u00a0Anything sent\n> from Bob to this short channel id and pubkey is in fact forwarded via\n> a\n> new HTLC to Alice.\n> \n> Alice identity BobAliceKey to create an invoice, with a route-hint to\n> say pubkey=Bob, short_channel_id=BobAliceSCID.\u00a0\u00a0Alice can sign\n> that invoice, and Bob can decode the incoming payment, from which it\n> creates a new HTLC to pay Alice.\u00a0\u00a0The payer doesn't even know this\n> arrangement exists: it looks exactly like Alice has a private channel\n> with Bob.\n> \n> The minor downside: because we conflate invoice keys (Alice needs)\n> and\n> onion keys (Bob needs), Bob can now issue invoices as Alice.\u00a0\u00a0It's\n> not\n> very useful, since Alice won't honor them, but it is an argument for\n> a separate invoice key in future.\n> \n> Cheers,\n> Rusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-05T08:11:58",
                "message_text_only": "Good morning CJP,\n\nOn Monday, November 5, 2018 4:04 PM, CJP <cjp at ultimatestunts.nl> wrote:\n\n> Rusty,\n>\n> In your proposal, I guess it is more or less widely known that Bob is\n> providing this forwarding service. Wouldn't Bob risk being excluded\n> from the side of the network with the more harsh regulatory conditions,\n> based on this knowledge? Bob might actually face even worse penalties\n> for providing such a service.\n>\n> The nice thing about rendez-vous routing is that any forwarding node\n> can be a rendez-vous point, and even the node itself wouldn't know\n> about it. The case where a payment is routed from and to the same\n> channel could be a hint though: normally that makes no sense, but if\n> payer and payee make their part of the route independently, the\n> combined route can often end up like that. TODO: check if forwarding\n> nodes are currently cool with such weird forwarding requests.\n\nThis is allowed within the protocol and to my knowledge existing node software do not particularly care.  However, it is indeed a concern as it allows somebody to notice such use of rendezvous routing.\n\nA use of this (forwarding to the same channel as receiving) is to give donations to a node without actually requiring an invoice to that node.  You simply route a circle to yourself to an invoice you generated yourself, and hide the donation to some node as fees paid for forwarding through that node.  Nodes will accept as fee any amount higher than the feerate they indicate in gossip.\n\nRegards,\nZmnSCPxj\n\n>\n> CJP\n>\n> Rusty Russell schreef op ma 05-11-2018 om 10:56 [+1030]:\n>\n> > CJP cjp at ultimatestunts.nl writes:\n> >\n> > > > Looking through BOLT 4, the text assumes inherently that source\n> > > > routing is done, and even has a shared secret between hop and\n> > > > source.\u00a0\u00a0However, it may be possible in rendezvous routing to\n> > > > simply\n> > > > provide the blinding key (while hiding everything beyond the\n> > > > first\n> > > > hop on the destination half of the route).\n> > >\n> > > Sounds like it makes sense; I need to look into it.\n> >\n> > Here's my attempt to design a \"merchant forward\" service using stuff\n> > we\n> > have today.\n> > Alice wants to remain anonymous, even from the lightning\n> > network.\u00a0\u00a0Bob's\n> > node offers a forwarding service.\u00a0\u00a0Alice pays Bob (base +\n> > percentage?),\n> > gives a path Bob->Alice, and Bob gives Alice a short-channel-id\n> > (BobAliceSCID) and privkey to use (BobAliceSecretKey).\u00a0\u00a0Anything sent\n> > from Bob to this short channel id and pubkey is in fact forwarded via\n> > a\n> > new HTLC to Alice.\n> > Alice identity BobAliceKey to create an invoice, with a route-hint to\n> > say pubkey=Bob, short_channel_id=BobAliceSCID.\u00a0\u00a0Alice can sign\n> > that invoice, and Bob can decode the incoming payment, from which it\n> > creates a new HTLC to pay Alice.\u00a0\u00a0The payer doesn't even know this\n> > arrangement exists: it looks exactly like Alice has a private channel\n> > with Bob.\n> > The minor downside: because we conflate invoice keys (Alice needs)\n> > and\n> > onion keys (Bob needs), Bob can now issue invoices as Alice.\u00a0\u00a0It's\n> > not\n> > very useful, since Alice won't honor them, but it is an argument for\n> > a separate invoice key in future.\n> > Cheers,\n> > Rusty."
            }
        ],
        "thread_summary": {
            "title": "Proposal for rendez-vous routing",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "ZmnSCPxj",
                "CJP"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 19999
        }
    },
    {
        "title": "[Lightning-dev] Proposal for updateable / revokable proofs of payment",
        "thread_messages": [
            {
                "author": "CJP",
                "date": "2018-11-04T21:08:17",
                "message_text_only": "Right now, the only defined semantics of the description field in\nBOLT11 is that it SHOULD be \"a complete description of the purpose of\nthe payment\". I think this is a bit vague; maybe this is deliberate?\n\nAnyway, you may also think of a BOLT11 payment request as an option\ncontract. If the payment is performed (which can be proven by showing\nthe preimage), then payee is bound to the terms and conditions in the\ndescription. So, then the meaning of a description \"one cup of coffee\"\nbecomes \"if payment happens, payee has an obligation to deliver one cup\nof coffee\".\n\nA known issue is that payer is not identified in the contract, so it is\nnot clear to who the payee has this obligation. As far as I can see,\nthe only way to fix this is to have two-way communication, where first\nthe payer sends some data to payee (e.g. public key), and then payee\nmakes the payment request, including this data. With this established,\nwe turn the preimage + payment request from a \"proof that someone paid\"\ninto a \"proof that I paid\", and therefore also a \"proof that payee has\nthis obligation to me\".\n\nI'm a bit afraid that such proofs are a bit too inflexible for real-\nlife applications. I think in real-life there are many cases where you\nneed to update / revoke agreements, even after payment.\n\nOne example is a full refund: if goods/services cannot be delivered\nsomehow, payer+payee might agree to a full refund instead of delivery\nof goods/services. The refund is another payment, with a payment\nrequest made by the original payer; its contract should state that the\noriginal payee is no longer bound by the obligations in the original\ncontract.\n\nAnother example is a partial refund, for instance if only a lower\nquantity or a lower quality of goods/services is delivered. This is\nanother payment, but now the new contract replaces the old contract and\nspecifies a new, lower set of obligations for the original payee.\n\nAnother example is a change of conditions without change of payment,\nfor instance when a white/gold dress was ordered, but turned out to be\nunavailable, and payer finds a black/blue dress acceptable as well, at\nequal price. Then you'd just want to replace white/gold in the contract\nby black/blue, without any payment.\n\nI think nearly all cases (including ones not mentioned here) are\ncovered by a \"contract update\" format which includes:\n* the new obligations of the two parties to each other\n* a secure hash of the previous contract version that is replaced by\nthis one\n* optionally, a payment hash\n* signatures from both parties\n\nThe contract update is considered valid if and only if\n* the signatures correspond to the pubkeys in the original contract\n(the first in the chain)\n* the signatures are valid signatures on this contract\n* the previous contracts in the chain are all valid (except for being\ninvalidated by contract updates)\n* there is no known valid contract that replaces this one\n* if a payment hash is included, a corresponding payment preimage is\nprovided as well\n\nThe original contract is different in that\n* It does not have a previous contract version (may be zeroed if you\nwant to keep the same format)\n* A set of pubkeys is provided (one of payer, one of payee)\n* Only payee has obligations, so payee never needs to receive a\nsignature from payer. Payer needs to receive payee's signature, and can\ntrivially add his own signature whenever needed.\n\nWhenever one payee has obligations to another, the pubkey of the party\nwith obligations has to be verified through some PKI. I consider this\nto be outside the scope of this concept. Especially in the case that\none of the parties never has any obligations, that party may use a new,\nnon-PKI-verified pubkey for the transaction, as a temporary pseudonym.\n\nThere is some conceptual similarity between an updateable proof of\npayment and a payment channel.\n\nA potential issue is that, theoretically, the \"contract update chain\"\ncan fork. The simple solution is \"don't do that\": either party can stop\nit from happening by not signing the forking update.\n\nCJP"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-05T01:20:51",
                "message_text_only": "Good morning CJP,\n\nIt seems to me, naively, that we can encode the description \"the obligation in the invoice whose hash is <h> is nullified\", whose meaning then is promoted to \"if payment happens, payee has an obligation to ensure that the obligation in the invoice whose hash is <h> is nullified\", then we have revokable payments already.  Such a payment may itself be revoked, ad infinitum.\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Monday, November 5, 2018 5:08 AM, CJP <cjp at ultimatestunts.nl> wrote:\n\n> Right now, the only defined semantics of the description field in\n> BOLT11 is that it SHOULD be \"a complete description of the purpose of\n> the payment\". I think this is a bit vague; maybe this is deliberate?\n>\n> Anyway, you may also think of a BOLT11 payment request as an option\n> contract. If the payment is performed (which can be proven by showing\n> the preimage), then payee is bound to the terms and conditions in the\n> description. So, then the meaning of a description \"one cup of coffee\"\n> becomes \"if payment happens, payee has an obligation to deliver one cup\n> of coffee\".\n>\n> A known issue is that payer is not identified in the contract, so it is\n> not clear to who the payee has this obligation. As far as I can see,\n> the only way to fix this is to have two-way communication, where first\n> the payer sends some data to payee (e.g. public key), and then payee\n> makes the payment request, including this data. With this established,\n> we turn the preimage + payment request from a \"proof that someone paid\"\n> into a \"proof that I paid\", and therefore also a \"proof that payee has\n> this obligation to me\".\n>\n> I'm a bit afraid that such proofs are a bit too inflexible for real-\n> life applications. I think in real-life there are many cases where you\n> need to update / revoke agreements, even after payment.\n>\n> One example is a full refund: if goods/services cannot be delivered\n> somehow, payer+payee might agree to a full refund instead of delivery\n> of goods/services. The refund is another payment, with a payment\n> request made by the original payer; its contract should state that the\n> original payee is no longer bound by the obligations in the original\n> contract.\n>\n> Another example is a partial refund, for instance if only a lower\n> quantity or a lower quality of goods/services is delivered. This is\n> another payment, but now the new contract replaces the old contract and\n> specifies a new, lower set of obligations for the original payee.\n>\n> Another example is a change of conditions without change of payment,\n> for instance when a white/gold dress was ordered, but turned out to be\n> unavailable, and payer finds a black/blue dress acceptable as well, at\n> equal price. Then you'd just want to replace white/gold in the contract\n> by black/blue, without any payment.\n>\n> I think nearly all cases (including ones not mentioned here) are\n> covered by a \"contract update\" format which includes:\n>\n> -   the new obligations of the two parties to each other\n> -   a secure hash of the previous contract version that is replaced by\n>     this one\n>\n> -   optionally, a payment hash\n> -   signatures from both parties\n>\n>     The contract update is considered valid if and only if\n>\n> -   the signatures correspond to the pubkeys in the original contract\n>     (the first in the chain)\n>\n> -   the signatures are valid signatures on this contract\n> -   the previous contracts in the chain are all valid (except for being\n>     invalidated by contract updates)\n>\n> -   there is no known valid contract that replaces this one\n> -   if a payment hash is included, a corresponding payment preimage is\n>     provided as well\n>\n>     The original contract is different in that\n>\n> -   It does not have a previous contract version (may be zeroed if you\n>     want to keep the same format)\n>\n> -   A set of pubkeys is provided (one of payer, one of payee)\n> -   Only payee has obligations, so payee never needs to receive a\n>     signature from payer. Payer needs to receive payee's signature, and can\n>     trivially add his own signature whenever needed.\n>\n>     Whenever one payee has obligations to another, the pubkey of the party\n>     with obligations has to be verified through some PKI. I consider this\n>     to be outside the scope of this concept. Especially in the case that\n>     one of the parties never has any obligations, that party may use a new,\n>     non-PKI-verified pubkey for the transaction, as a temporary pseudonym.\n>\n>     There is some conceptual similarity between an updateable proof of\n>     payment and a payment channel.\n>\n>     A potential issue is that, theoretically, the \"contract update chain\"\n>     can fork. The simple solution is \"don't do that\": either party can stop\n>     it from happening by not signing the forking update.\n>\n>     CJP\n>\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "CJP",
                "date": "2018-11-05T08:23:10",
                "message_text_only": "I think it's true that most of my proposal can be achieved by writing\nsuch things in human-readable form in the description field. Mostly,\nthe only thing my proposal does is to put things into a machine-\nreadable form; this may aid in automated processing and maybe a better\nUI experience.\n\nMaybe the least trivial thing is the inclusion of a payer pubkey in the\noriginal invoice; this is the least trivial both in protocol complexity\nand in potential benefits. One benefit is that it turns a \"proof-that-\nsomeone-paid\" into a \"proof-that-I-paid\"; another benefit is that it\nbecomes clear who is authorized to issue another invoice that says\n\"this original invoice is nullified\".\n\nNow that I think of it: my proposal has something important that yours\ndoesn't: the requirement to have *two* signatures (both payer and\npayee) on each update. Without that requirement, there is one party who\ncan nullify the old contract by making a unilaterally signed invoice\nand a self-generated payment preimage. Not even a need to do a payment\nto self to \"fake\" a sort of a refund payment or so. This may be OK as\nlong as there is only one party who has obligations: then the other\nparty may partially or completely nullify those obligations, optionally\ndependent on a payment. Requiring two signatures (and thereby\nconsensus) on each update is more generic though: it allows for\nobligations on both parties.\n\nEven more generic could be to allow more than two parties. I'm sure\nthere are complex business arrangements that have a need for this, but\nI think we can always develop that later. Let's first tackle this\nrelatively simple case.\n\nCJP\n\n\nZmnSCPxj schreef op ma 05-11-2018 om 01:20 [+0000]:\n> Good morning CJP,\n> \n> It seems to me, naively, that we can encode the description \"the\n> obligation in the invoice whose hash is <h> is nullified\", whose\n> meaning then is promoted to \"if payment happens, payee has an\n> obligation to ensure that the obligation in the invoice whose hash is\n> <h> is nullified\", then we have revokable payments already.\u00a0\u00a0Such a\n> payment may itself be revoked, ad infinitum.\n> \n> Regards,\n> ZmnSCPxj\n> \n> \n> Sent with ProtonMail Secure Email.\n> \n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Monday, November 5, 2018 5:08 AM, CJP <cjp at ultimatestunts.nl>\n> wrote:\n> \n> > Right now, the only defined semantics of the description field in\n> > BOLT11 is that it SHOULD be \"a complete description of the purpose\n> > of\n> > the payment\". I think this is a bit vague; maybe this is\n> > deliberate?\n> > \n> > Anyway, you may also think of a BOLT11 payment request as an option\n> > contract. If the payment is performed (which can be proven by\n> > showing\n> > the preimage), then payee is bound to the terms and conditions in\n> > the\n> > description. So, then the meaning of a description \"one cup of\n> > coffee\"\n> > becomes \"if payment happens, payee has an obligation to deliver one\n> > cup\n> > of coffee\".\n> > \n> > A known issue is that payer is not identified in the contract, so\n> > it is\n> > not clear to who the payee has this obligation. As far as I can\n> > see,\n> > the only way to fix this is to have two-way communication, where\n> > first\n> > the payer sends some data to payee (e.g. public key), and then\n> > payee\n> > makes the payment request, including this data. With this\n> > established,\n> > we turn the preimage + payment request from a \"proof that someone\n> > paid\"\n> > into a \"proof that I paid\", and therefore also a \"proof that payee\n> > has\n> > this obligation to me\".\n> > \n> > I'm a bit afraid that such proofs are a bit too inflexible for\n> > real-\n> > life applications. I think in real-life there are many cases where\n> > you\n> > need to update / revoke agreements, even after payment.\n> > \n> > One example is a full refund: if goods/services cannot be delivered\n> > somehow, payer+payee might agree to a full refund instead of\n> > delivery\n> > of goods/services. The refund is another payment, with a payment\n> > request made by the original payer; its contract should state that\n> > the\n> > original payee is no longer bound by the obligations in the\n> > original\n> > contract.\n> > \n> > Another example is a partial refund, for instance if only a lower\n> > quantity or a lower quality of goods/services is delivered. This is\n> > another payment, but now the new contract replaces the old contract\n> > and\n> > specifies a new, lower set of obligations for the original payee.\n> > \n> > Another example is a change of conditions without change of\n> > payment,\n> > for instance when a white/gold dress was ordered, but turned out to\n> > be\n> > unavailable, and payer finds a black/blue dress acceptable as well,\n> > at\n> > equal price. Then you'd just want to replace white/gold in the\n> > contract\n> > by black/blue, without any payment.\n> > \n> > I think nearly all cases (including ones not mentioned here) are\n> > covered by a \"contract update\" format which includes:\n> > \n> > -\u00a0\u00a0\u00a0the new obligations of the two parties to each other\n> > -\u00a0\u00a0\u00a0a secure hash of the previous contract version that is replaced\n> > by\n> > \u00a0\u00a0\u00a0\u00a0this one\n> > \n> > -\u00a0\u00a0\u00a0optionally, a payment hash\n> > -\u00a0\u00a0\u00a0signatures from both parties\n> > \n> > \u00a0\u00a0\u00a0\u00a0The contract update is considered valid if and only if\n> > \n> > -\u00a0\u00a0\u00a0the signatures correspond to the pubkeys in the original\n> > contract\n> > \u00a0\u00a0\u00a0\u00a0(the first in the chain)\n> > \n> > -\u00a0\u00a0\u00a0the signatures are valid signatures on this contract\n> > -\u00a0\u00a0\u00a0the previous contracts in the chain are all valid (except for\n> > being\n> > \u00a0\u00a0\u00a0\u00a0invalidated by contract updates)\n> > \n> > -\u00a0\u00a0\u00a0there is no known valid contract that replaces this one\n> > -\u00a0\u00a0\u00a0if a payment hash is included, a corresponding payment preimage\n> > is\n> > \u00a0\u00a0\u00a0\u00a0provided as well\n> > \n> > \u00a0\u00a0\u00a0\u00a0The original contract is different in that\n> > \n> > -\u00a0\u00a0\u00a0It does not have a previous contract version (may be zeroed if\n> > you\n> > \u00a0\u00a0\u00a0\u00a0want to keep the same format)\n> > \n> > -\u00a0\u00a0\u00a0A set of pubkeys is provided (one of payer, one of payee)\n> > -\u00a0\u00a0\u00a0Only payee has obligations, so payee never needs to receive a\n> > \u00a0\u00a0\u00a0\u00a0signature from payer. Payer needs to receive payee's signature,\n> > and can\n> > \u00a0\u00a0\u00a0\u00a0trivially add his own signature whenever needed.\n> > \n> > \u00a0\u00a0\u00a0\u00a0Whenever one payee has obligations to another, the pubkey of\n> > the party\n> > \u00a0\u00a0\u00a0\u00a0with obligations has to be verified through some PKI. I\n> > consider this\n> > \u00a0\u00a0\u00a0\u00a0to be outside the scope of this concept. Especially in the case\n> > that\n> > \u00a0\u00a0\u00a0\u00a0one of the parties never has any obligations, that party may\n> > use a new,\n> > \u00a0\u00a0\u00a0\u00a0non-PKI-verified pubkey for the transaction, as a temporary\n> > pseudonym.\n> > \n> > \u00a0\u00a0\u00a0\u00a0There is some conceptual similarity between an updateable proof\n> > of\n> > \u00a0\u00a0\u00a0\u00a0payment and a payment channel.\n> > \n> > \u00a0\u00a0\u00a0\u00a0A potential issue is that, theoretically, the \"contract update\n> > chain\"\n> > \u00a0\u00a0\u00a0\u00a0can fork. The simple solution is \"don't do that\": either party\n> > can stop\n> > \u00a0\u00a0\u00a0\u00a0it from happening by not signing the forking update.\n> > \n> > \u00a0\u00a0\u00a0\u00a0CJP\n> > \n> > \n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> \n>"
            }
        ],
        "thread_summary": {
            "title": "Proposal for updateable / revokable proofs of payment",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "CJP"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 16147
        }
    },
    {
        "title": "[Lightning-dev] Commitment Transaction Format Update Proposals?",
        "thread_messages": [
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-11-06T04:29:21",
                "message_text_only": "Hi Rusty,\n\nI'm a big fan in general of most of this! Amongst many other things, it'll:\nsimplify the whole static channel backup + recovery workflow, and avoid all\nthe fee related headaches we've run into over the past few months.\n\n> - HTLC-timeout and HTLC-success txs sigs are\n> SIGHASH_ANYONECANPAY|SIGHASH_SINGLE, so you can Bring Your Own Fees.\n\nWould this mean that we no longer extend fees to the second-level\ntransactions as well? If so, then a dusty HTLC would be determined solely by\nlooking at the direct output, rather than the resulting output in the second\nlayer.\n\n>  - `localpubkey`, `remotepubkey`, `local_htlcpubkey`, `remote_htlcpubkey`,\n> `local_delayedpubkey`, and `remote_delayedpubkey` derivation now uses a\n> two-stage unhardened BIP-32 derivation based on the commitment number.\n\nIt seems enough to _only_ modify the derivation for local+remote pubkey (so\nthe direct \"settle\" keys). This constrains the change to only what's\nnecessary to simplify the backup+recovery workflow with the current\ncommitment design. By restricting the change to these two keys, we minimize\nthe code impact to the existing implementations, and avoid unnecessary\nchanges that don't make strides towards the immediate goal.\n\n> - `to_remote` is now a P2WSH of:\n>        `to_self_delay` OP_CSV OP_DROP <remotepubkey> OP_CHECKSIG\n\nThis seems at odds with the goal of \"if the remote party force closes, then\nI get my funds back immediately without requiring knowledge of any secret\ndata\". If it was just a plain p2wkh, then during a routine seed import and\nrescan (assuming ample look ahead as we know this is a \"special\" key), I\nwould pick up outputs of channels that were force closed while I was down\ndue to my dog eating my hard drive.\n\nAlternatively, since the range of CSV values can be known ahead of time, I\ncan brute force a set of scripts to look for in the chain. However, this\nresults in potentially a very large number of scripts (depending on how many\nchannels one has, and bounds on the acceptable CSV) I need to scan for.\n\n-- Laolu\n\n\nOn Fri, Oct 12, 2018 at 3:57 PM Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> Hi all,\n>\n>         There have been a number of suggested changes to the commitment\n> transaction format:\n>\n> 1. Rather than trying to agree on what fees will be in the future, we\n>    should use an OP_TRUE-style output to allow CPFP (Roasbeef)\n> 2. The `remotepubkey` should be a BIP-32-style, to avoid the\n>    option_data_loss_protect \"please tell me your current\n>    per_commitment_point\" problem[1]\n> 3. The CLTV timeout should be symmetrical to avoid trying to game the\n>    peer into closing. (Connor IIRC?).\n>\n> It makes sense to combine these into a single `commitment_style2`\n> feature, rather than having a testing matrix of all these disabled and\n> enabled.\n>\n> BOLT #2:\n>\n> - If `commitment_style2` negotiated, update_fee is a protocol error.\n>\n> This mainly changes BOLT #3:\n>\n> - The feerate for commitment transactions is always 253 satoshi/Sipa.\n> - Commitment tx always has a P2WSH OP_TRUE output of 1000 satoshi.\n> - Fees, OP_TRUE are always paid by the initial funder, because it's simple,\n>   unless they don't have funds (eg. push_msat can do this, unless we\n> remove it?)\n> - HTLC-timeout and HTLC-success txs sigs are\n>   SIGHASH_ANYONECANPAY|SIGHASH_SINGLE, so you can Bring Your Own Fees.\n> - `localpubkey`, `remotepubkey`, `local_htlcpubkey`,\n>   `remote_htlcpubkey`, `local_delayedpubkey`, and `remote_delayedpubkey`\n>   derivation now uses a two-stage unhardened BIP-32 derivation based on\n>   the commitment number.  Two-stage because we can have 2^48 txs and\n>   BIP-32 only supports 2^31: the first 17 bits are used to derive the\n>   parent for the next 31 bits?\n> - `to_self_delay` for both sides is the maximum of either the\n>   `open_channel` or `accept_channel`.\n> - `to_remote` is now a P2WSH of:\n>         `to_self_delay` OP_CSV OP_DROP <remotepubkey> OP_CHECKSIG\n>\n> Cheers,\n> Rusty.\n>\n> [1] I recently removed checking this field from c-lightning, as I\n>     couldn't get it to reliably work under stress-test.  I may just have\n>     a bug, but we could just fix the spec instead, then we can get our\n>     funds back even if we never talk to the peer.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181106/9aa80d96/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-06T04:59:52",
                "message_text_only": "Olaoluwa Osuntokun <laolu32 at gmail.com> writes:\n> Hi Rusty,\n>\n> I'm a big fan in general of most of this! Amongst many other things, it'll:\n> simplify the whole static channel backup + recovery workflow, and avoid all\n> the fee related headaches we've run into over the past few months.\n\nI certainly hope so!\n\n>> - HTLC-timeout and HTLC-success txs sigs are\n>> SIGHASH_ANYONECANPAY|SIGHASH_SINGLE, so you can Bring Your Own Fees.\n>\n> Would this mean that we no longer extend fees to the second-level\n> transactions as well? If so, then a dusty HTLC would be determined solely by\n> looking at the direct output, rather than the resulting output in the second\n> layer.\n\nGood point, yes.\n\n>>  - `localpubkey`, `remotepubkey`, `local_htlcpubkey`, `remote_htlcpubkey`,\n>> `local_delayedpubkey`, and `remote_delayedpubkey` derivation now uses a\n>> two-stage unhardened BIP-32 derivation based on the commitment number.\n>\n> It seems enough to _only_ modify the derivation for local+remote pubkey (so\n> the direct \"settle\" keys). This constrains the change to only what's\n> necessary to simplify the backup+recovery workflow with the current\n> commitment design. By restricting the change to these two keys, we minimize\n> the code impact to the existing implementations, and avoid unnecessary\n> changes that don't make strides towards the immediate goal.\n\nI was thinking in the long term when we drop backwards compat, then we\nonly have one derivation scheme?\n\n>> - `to_remote` is now a P2WSH of:\n>>        `to_self_delay` OP_CSV OP_DROP <remotepubkey> OP_CHECKSIG\n>\n> This seems at odds with the goal of \"if the remote party force closes, then\n> I get my funds back immediately without requiring knowledge of any secret\n> data\". If it was just a plain p2wkh, then during a routine seed import and\n> rescan (assuming ample look ahead as we know this is a \"special\" key), I\n> would pick up outputs of channels that were force closed while I was down\n> due to my dog eating my hard drive.\n\nGood point; we need to weigh the benefits of symmetry (which seems to\nrequire this) against this additional complication.\n\n> Alternatively, since the range of CSV values can be known ahead of time, I\n> can brute force a set of scripts to look for in the chain. However, this\n> results in potentially a very large number of scripts (depending on how many\n> channels one has, and bounds on the acceptable CSV) I need to scan for.\n\nI don't suppose we could get everyone to agree on the same CSV values? :)\n\nCheers,\nRusty."
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-11-06T06:03:19",
                "message_text_only": "> This seems at odds with the goal of \"if the remote party force closes,\nthen\n> I get my funds back immediately without requiring knowledge of any secret\n> data\"\n\nScratch that: the static back ups just need to include this CSV value!\n\n-- Laolu\n\n\nOn Tue, Nov 6, 2018 at 3:29 PM Olaoluwa Osuntokun <laolu32 at gmail.com> wrote:\n\n> Hi Rusty,\n>\n> I'm a big fan in general of most of this! Amongst many other things, it'll:\n> simplify the whole static channel backup + recovery workflow, and avoid all\n> the fee related headaches we've run into over the past few months.\n>\n> > - HTLC-timeout and HTLC-success txs sigs are\n> > SIGHASH_ANYONECANPAY|SIGHASH_SINGLE, so you can Bring Your Own Fees.\n>\n> Would this mean that we no longer extend fees to the second-level\n> transactions as well? If so, then a dusty HTLC would be determined solely\n> by\n> looking at the direct output, rather than the resulting output in the\n> second\n> layer.\n>\n> >  - `localpubkey`, `remotepubkey`, `local_htlcpubkey`,\n> `remote_htlcpubkey`,\n> > `local_delayedpubkey`, and `remote_delayedpubkey` derivation now uses a\n> > two-stage unhardened BIP-32 derivation based on the commitment number.\n>\n> It seems enough to _only_ modify the derivation for local+remote pubkey (so\n> the direct \"settle\" keys). This constrains the change to only what's\n> necessary to simplify the backup+recovery workflow with the current\n> commitment design. By restricting the change to these two keys, we minimize\n> the code impact to the existing implementations, and avoid unnecessary\n> changes that don't make strides towards the immediate goal.\n>\n> > - `to_remote` is now a P2WSH of:\n> >        `to_self_delay` OP_CSV OP_DROP <remotepubkey> OP_CHECKSIG\n>\n> This seems at odds with the goal of \"if the remote party force closes, then\n> I get my funds back immediately without requiring knowledge of any secret\n> data\". If it was just a plain p2wkh, then during a routine seed import and\n> rescan (assuming ample look ahead as we know this is a \"special\" key), I\n> would pick up outputs of channels that were force closed while I was down\n> due to my dog eating my hard drive.\n>\n> Alternatively, since the range of CSV values can be known ahead of time, I\n> can brute force a set of scripts to look for in the chain. However, this\n> results in potentially a very large number of scripts (depending on how\n> many\n> channels one has, and bounds on the acceptable CSV) I need to scan for.\n>\n> -- Laolu\n>\n>\n> On Fri, Oct 12, 2018 at 3:57 PM Rusty Russell <rusty at rustcorp.com.au>\n> wrote:\n>\n>> Hi all,\n>>\n>>         There have been a number of suggested changes to the commitment\n>> transaction format:\n>>\n>> 1. Rather than trying to agree on what fees will be in the future, we\n>>    should use an OP_TRUE-style output to allow CPFP (Roasbeef)\n>> 2. The `remotepubkey` should be a BIP-32-style, to avoid the\n>>    option_data_loss_protect \"please tell me your current\n>>    per_commitment_point\" problem[1]\n>> 3. The CLTV timeout should be symmetrical to avoid trying to game the\n>>    peer into closing. (Connor IIRC?).\n>>\n>> It makes sense to combine these into a single `commitment_style2`\n>> feature, rather than having a testing matrix of all these disabled and\n>> enabled.\n>>\n>> BOLT #2:\n>>\n>> - If `commitment_style2` negotiated, update_fee is a protocol error.\n>>\n>> This mainly changes BOLT #3:\n>>\n>> - The feerate for commitment transactions is always 253 satoshi/Sipa.\n>> - Commitment tx always has a P2WSH OP_TRUE output of 1000 satoshi.\n>> - Fees, OP_TRUE are always paid by the initial funder, because it's\n>> simple,\n>>   unless they don't have funds (eg. push_msat can do this, unless we\n>> remove it?)\n>> - HTLC-timeout and HTLC-success txs sigs are\n>>   SIGHASH_ANYONECANPAY|SIGHASH_SINGLE, so you can Bring Your Own Fees.\n>> - `localpubkey`, `remotepubkey`, `local_htlcpubkey`,\n>>   `remote_htlcpubkey`, `local_delayedpubkey`, and `remote_delayedpubkey`\n>>   derivation now uses a two-stage unhardened BIP-32 derivation based on\n>>   the commitment number.  Two-stage because we can have 2^48 txs and\n>>   BIP-32 only supports 2^31: the first 17 bits are used to derive the\n>>   parent for the next 31 bits?\n>> - `to_self_delay` for both sides is the maximum of either the\n>>   `open_channel` or `accept_channel`.\n>> - `to_remote` is now a P2WSH of:\n>>         `to_self_delay` OP_CSV OP_DROP <remotepubkey> OP_CHECKSIG\n>>\n>> Cheers,\n>> Rusty.\n>>\n>> [1] I recently removed checking this field from c-lightning, as I\n>>     couldn't get it to reliably work under stress-test.  I may just have\n>>     a bug, but we could just fix the spec instead, then we can get our\n>>     funds back even if we never talk to the peer.\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181106/237c144f/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Commitment Transaction Format Update Proposals?",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Olaoluwa Osuntokun"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 12176
        }
    },
    {
        "title": "[Lightning-dev] Splicing Proposal: Feedback please!",
        "thread_messages": [
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-11-06T06:55:03",
                "message_text_only": "> However personally I do not really see the need to create multiple\nchannels\n> to a single peer, or increase the capacity with a specific peer (via\nsplice\n> or dual-funding).  As Christian says in the other mail, this\nconsideration,\n> is that it becomes less a network and more of some channels to specific\nbig\n> businesses you transact with regularly.\n\nI made no reference to any \"big businesses\", only the utility that arises\nwhen one has multiple channels to a given peer. Consider an easier example:\ngiven the max channel size, I can only ever send 0.16 or so BTC to that\npeer. If I have two channels, then I can send 0.32 and so on. Consider the\ncase post AMP where we maintain the current limit of the number of in flight\nHTLCs. If AMP causes most HTLCs to generally be in flight within the\nnetwork, then all of a sudden, this \"queue\" size (outstanding HTLCS in a\ncommitment) becomes more scarce (assume a global MTU of say 100k sat for\nsimplicity). This may then promote nodes to open additional channels to\nother nodes (1+) in order to accommodate the increased HTLC bandwidth load\ndue to the sharded multi-path payments.\n\nIndependent on bolstering the bandwidth capabilities of your links to other\nnodes, you would still want to maintain a diverse set of channels for fault\ntolerance, path diversity, and redundancy reasons.\n\nIn the splicing case, if only a single in flight splice is permitted, and me\nas users wants to keep all their funds in channels, the more channels I\nhave, the more concurrent on-chain withdraws/deposits I'll be able to\nservice.\n\n> I worry about doing away with initiator distinction\n\nCan you re-phrase this sentence? I'm having trouble parsing it, thanks.\n\n> which puzzles me, and I wonder if I am incorrect in my prioritization.\n\nConsider that not all work items are created equal, and they have varying\nlevels of implementation and network wide synchronization. For example, I\nthink we all consider multi-hop decor to be a high priority.  However, it\nhas the longest and hardest road to deployment as it effectively forces us\nto perform a \"slow motion hard-fork\" within the network. On the other hand,\nif lnd wanted to deploy a flavor of non-interactive (no invoice) payments\n*today*, we could do that without *any* synchronization at the\nimplementation of network level, as it's purely an end-to-end change.\n\n> I am uncertain what this means in particular, but let me try to restate\n> what you are talking about in other terms:\n\nThought about it a bit more (like way ago) and this is really no different\nthan having a donation page where people use public derivation to derive\naddresses to deposit directly to your channel. All the Lightning node needs\nto do, is recognize that any coins send to these derived addresses should be\nimmediately spliced into an available channel (doesn't have any other\noutstanding splices).\n\n> It seems to me naively that the above can be done by the client software\n> without any modifications to the Lightning Network BOLT protocol\n\nSticking with that prior version yes, this would be able to be seamlessly\nincluded in the async splce proposal. The one requirement is a link-level\nprotocol that allows both sides to collaboratively create and recognize\nthese outputs.\n\n> Or is my above restatement different from what you are talking about?\n\nYou're missing the CLTV timeout clause. It isn't a plain p2wkh, it's a p2wsh\nscript. Either they splice this in before the timeout, or it times out and\nit goes back to one party. In this case, it's no different than the async\nconcurrent commitment splice in double spend case.\n\n-- Laolu\n\n\nOn Tue, Oct 16, 2018 at 10:16 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Laolu,\n>\n> Is there a fundamental reason that CL will never allow nodes to create\n> multiple channels? It seems unnecessarily limiting.\n>\n>\n> The architecture of c-lightning assigns a separate process to each peer.\n> For simplicity this peer process handles only a single channel.  Some of\n> the channel initiation and shutdown protocols are written \"directly\", i.e.\n> if the BOLT spec says this must happen before that, we literally write in\n> the C code this_function(); that_function();.  It would be possible  to\n> change this architecture with significant difficulty.\n>\n> However personally I do not really see the need to create multiple\n> channels to a single peer, or increase the capacity with a specific peer\n> (via splice or dual-funding).  As Christian says in the other mail, this\n> consideration, is that it becomes less a network and more of some channels\n> to specific big businesses you transact with regularly.  But I suppose,\n> that we will have to see how the network evolves eventually; perhaps the\n> goal of decentralization is simply doomed regardless, and Lightning will\n> indeed evolve into a set of channels you maintain to specific big\n> businesses you regularly work with.\n>\n>\n> >    * [`4`:`feerate_per_kw`]\n>\n> What fee rate is this? IMO we should do commitmentv2 before splicing as\n> then\n> we can more or less do away with the initiator distinction and have most\n> fees be ad hoc.\n>\n>\n> I worry about doing away with initiator distinction, as I worry that an\n> initiatee may be forced to pay fees they did not really voluntarily\n> consider paying, when they are given funds on a channel initiated by\n> someone else in exchange for funds on a separate channel; but this is\n> probably a separate topic.\n>\n> >If you think any of these items is a higher priority than splicing then\n> you\n> >can simply start working on them! There's no agency that prescribes what\n> >should and shouldn't be pursued or developed, just your willingness to\n> >write some code.\n>\n> While true, for me personally I can only devote a limited amount of time\n> to coding for Lightning, and thus I must always worry whether my priorities\n> are even correct.  I find it very common that people want to prioritize\n> splicing over AMP or watchtowers, which puzzles me, and I wonder if I am\n> incorrect in my prioritization.\n>\n> > One thing that I think we should lift from the multiple funding output\n> > approach is the \"pre seating of inputs\". This is cool as it would allow\n> > clients to generate addresses, that others could deposit to, and then\n> have\n> > be spliced directly into the channel. Public derivation can be used,\n> along\n> > with a script template to do it non-interactively, with the clients\n> picking\n> > up these deposits, and initiating a splice in as needed.\n>\n> I am uncertain what this means in particular, but let me try to restate\n> what you are talking about in other terms:\n>\n> 1.  Each channel has two public-key-derivation paths (BIP32) to create\n> onchain addresses.  One for each side of the channel.\n> 2.  When somebody sends to one of the onchain addresses in the path, their\n> client detects this.\n> 3.  The client initiates a splice-in automatically from this UTXO paying\n> to that address into the channel.\n>\n> It seems to me naively that the above can be done by the client software\n> without any modifications to the Lightning Network BOLT protocol, as long\n> as the BOLT protocol is capable of supporting *some* splice-in operation,\n> i.e. it seems to be something that a client software can implement as a\n> feature without requiring a BOLT change.  Or is my above restatement\n> different from what you are talking about?\n>\n> How about this restatement?\n>\n> 1.  Each channel has two public-key-derivation paths (BIP32) to create\n> onchain addresses.  One for each side of the channel.\n> 2.  The base of the above is actually a combined private-public keypair of\n> both sides (e.g. created via MuSig or some other protocol).  Thus the\n> addresses require cooperation of both parties to spend.\n> 3.  When somebody sends to one of the onchain addresses in the path, their\n> client detects this.\n> 4.  The client updates the current transaction state, such that the new\n> commit transaction has two inputs ( the original channel transaction and\n> the new UTXO).\n>\n> The above seems unsafe without trust in the other peer, as, the other peer\n> can simply refuse to create the new commit transaction.  Since the address\n> requires both parties to spend, the money cannot be spent and there is no\n> backoff transaction that can be used.  But maybe you can describe some\n> mechanism to ensure this, if this is what is meant instead?\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181106/76f37b9c/attachment.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-11-07T03:12:28",
                "message_text_only": "Olaoluwa Osuntokun <laolu32 at gmail.com> writes:\n\n>> However personally I do not really see the need to create multiple\n> channels\n>> to a single peer, or increase the capacity with a specific peer (via\n> splice\n>> or dual-funding).  As Christian says in the other mail, this\n> consideration,\n>> is that it becomes less a network and more of some channels to specific\n> big\n>> businesses you transact with regularly.\n>\n> I made no reference to any \"big businesses\", only the utility that arises\n> when one has multiple channels to a given peer. Consider an easier example:\n> given the max channel size, I can only ever send 0.16 or so BTC to that\n> peer. If I have two channels, then I can send 0.32 and so on. Consider the\n> case post AMP where we maintain the current limit of the number of in flight\n> HTLCs. If AMP causes most HTLCs to generally be in flight within the\n> network, then all of a sudden, this \"queue\" size (outstanding HTLCS in a\n> commitment) becomes more scarce (assume a global MTU of say 100k sat for\n> simplicity). This may then promote nodes to open additional channels to\n> other nodes (1+) in order to accommodate the increased HTLC bandwidth load\n> due to the sharded multi-path payments.\n\nI think I see the issue now, thanks for explaining. However I get the\nfeeling that this is a rather roundabout way of increasing the\nlimitations that you negotiated with your peer (max HTLC in flight, max\nchannel capacity, ...), so wouldn't those same limits also apply across\nall channels that you have with that peer? Isn't the real solution here\nto lift those limitations?\n\n> Independent on bolstering the bandwidth capabilities of your links to other\n> nodes, you would still want to maintain a diverse set of channels for fault\n> tolerance, path diversity, and redundancy reasons.\n\nAbsolutely agree, and it was probably my mistake for assuming that you\nwould go for the one peer only approach as a direct result of increasing\nbandwidth to one peer."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-07T06:06:07",
                "message_text_only": "Good morning Laolu,\n\n>> I worry about doing away with initiator distinction\n>\n> Can you re-phrase this sentence? I'm having trouble parsing it, thanks.\n\nThe initiator of an action is the node which performs the first step in an action.\n\nFor instance, when opening a channel, the node which initiates the channel open is the initiator.  Even in a dual-funding channel open, we should distinguish the initiator.\n\nWhat I want to preserve (as for current channel opening) is that the initiator of an action should be the one to pay any costs or fees to that action.\n\nFor instance, when opening a channel, the channel opener is the one who pays for all onchain fees related to opening and closing the channel, as the opening node is the initiator of the action.\n\nSimilarly, for channel splicing, I think it would be wiser to have the initiator of the splice be the one, to pay for any onchain fees related to splicing (and any backoff/failure path if some backoff is needed), even if the other side then also decides to splice in/out some funds together with the splice.\n\nTo my mind, this is wiser as it reduces the surface of potential attacks in case of a bad design or implementation of dual-fund-opening and splicing; to engage in the attack, one must be willing to shoulder all the onchain fees, which hopefully should somewhat deter all but the most egregious or lopsided of attacks.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181107/9d9f766f/attachment.html>"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-11-06T07:02:24",
                "message_text_only": "> Mainly limitations of our descriptor language, TBH.\n\nI don't follow...so it's a size issue? Or wanting to avoid \"repeated\"\nfields?\n\n> I thought about restarting the revocation sequence, but it seems like that\n> only saves a tiny amount since we only store log(N) entries\n\nYeah that makes sense, forgetting the HTLC state is a big enough win in and\nof itself.\n\n>>> Splice Signing\n>>\n>> It seems that we're missing some fields here if we're to allow the\nsplicing\n>> of inputs to be done in a non-blocking manner. We'll need to send two\n>> revocation points for the new commitment: one to allow it to be created,\nand\n>> another to allow updates to proceed right after the signing is\ncompleted. In\n>> this case we'll also need to update both commitments in tandem until the\n>> splicing transaction has been sufficiently confirmed.\n>\n>I think we can use the existing revocation points for both.\n\nYep, if we retain the existing shachain trees, then we just continue to\nextend the leaves!\n\n> We're basically co-generating a tx here, just like shutdown, except it's\n> funding a new replacement channel.  Do we want to CPFP this one too?\n\nIt'd be nice to be able to also anchor down this splicing transaction given\nthat we may only allow a single outstanding splicing operation to begin\nwith. Being able to CPFP it (and later on provide arbitrary fee inputs)\nallows be to speed up the process if I want to queue another operation up\nright afterwards.\n\n-- Laolu\n\n\nOn Wed, Oct 17, 2018 at 9:31 AM Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> Olaoluwa Osuntokun <laolu32 at gmail.com> writes:\n> > Hi Rusty,\n> >\n> > Happy to get the splicing train rolling!\n> >\n> >> We've had increasing numbers of c-lightning users get upset they can't\n> >> open multiple channels, so I guess we're most motivated to allow\n> splicing\n> > of\n> >> existing channels\n> >\n> > Splicing isn't a substitute for allowing multiple channels. Multiple\n> > channels allow nodes to:\n> >\n> >   * create distinct channels with distinct acceptance policies.\n> >   * create a mix of public and non-advertised channels with a node.\n> >   * be able to send more than the (current) max HTLC amount\n> >     using various flavors of AMP.\n> >   * get past the (current) max channel size value\n> >   * allow a link to carry more HTLCs (due to the current super low max\n> HTLC\n> >     values) given the additional HTLC pressure that\n> >     AMP may produce (alternative is a commitment fan out)\n>\n> These all seem marginal to me.  I think if we start hitting max values,\n> we should discuss increasing them.\n>\n> > Is there a fundamental reason that CL will never allow nodes to create\n> > multiple channels? It seems unnecessarily limiting.\n>\n> Yeah, we have a daemon per peer.  It's really simple with 1 daemon, 1\n> channel.  My own fault: I was the one who insisted we mux multiple\n> connections over the same transport; if we'd gone for independent\n> connections our implementation would have been trivial.\n>\n> >> Splice Negotiation:\n> >\n> > Any reason to now make the splicing_add_* messages allow one to add\n> several\n> > inputs in a single message? Given \"acceptable\" constraints for how large\n> the\n> > witness and pkScripts can be, we can easily enforce an upper limit on the\n> > number of inputs/outputs to add.\n>\n> Mainly limitations of our descriptor language, TBH.\n>\n> > I like that the intro messages have already been designed with the\n> > concurrent case in mind beyond a simpler propose/accept flow. However is\n> > there any reason why it doesn't also allow either side to fully\n> re-negotiate\n> > _all_ the funding details? Splicing is a good opportunity to garbage\n> collect\n> > the prior revocation state, and also free up obsolete space in watch\n> towers.\n>\n> I thought about restarting the revocation sequence, but it seems like\n> that only saves a tiny amount since we only store log(N) entries.  We\n> can drop old HTLC info post-splice though, and (after some delay for\n> obscurity) tell watchtowers to drop old entries I think.\n>\n> > Additionally, as the size of the channel is either expanding or\n> contracting,\n> > both sides should be allowed to modify things like the CSV param,\n> reserve,\n> > max accepted htlc's, max htlc size, etc. Many of these parameters like\n> the\n> > CSV value should scale with the size of the channel, not allowing these\n> > parameters to be re-negotiated could result in odd scenarios like still\n> > maintain a 1 week CSV when the channel size has dipped from 1 BTC to 100k\n> > satoshis.\n>\n> Yep, good idea!  I missed that.\n>\n> Brings up a side point about these values, which deserves its own\n> post...\n>\n> >> 1. type: 40 (`splice_add_input`) (`option_splice`)\n> >\n> > In order to add nested p2sh inputs, we'll need to also expose the redeem\n> > script here, or add additional fields to allow sides to set a sig script\n> as\n> > well as witness during the signing phase.\n> >\n> >> - scriptpubkey is empty, or of form 'HASH160 <20-byte-script-hash>\n> EQUAL'\n> >\n> > So no P2SH? :(\n>\n> Another omission, yeah, we'd want that too I think.\n>\n> >>    * [`4`:`feerate_per_kw`]\n> >\n> > What fee rate is this? IMO we should do commitmentv2 before splicing as\n> then\n> > we can more or less do away with the initiator distinction and have most\n> > fees be ad hoc.\n>\n> We're basically co-generating a tx here, just like shutdown, except it's\n> funding a new replacement channel.  Do we want to CPFP this one too?\n>\n> >> Splice Signing\n> >\n> > It seems that we're missing some fields here if we're to allow the\n> splicing\n> > of inputs to be done in a non-blocking manner. We'll need to send two\n> > revocation points for the new commitment: one to allow it to be created,\n> and\n> > another to allow updates to proceed right after the signing is\n> completed. In\n> > this case we'll also need to update both commitments in tandem until the\n> > splicing transaction has been sufficiently confirmed.\n>\n> I think we can use the existing revocation points for both.\n>\n> > Also, what about change addresses? Are they to be explicitly specified as\n> > splice outs?\n>\n> They'd be splice-outs, yeah.\n>\n> >> 1. type: 43 (`splice_commitment_signature`) (`option_splice`)\n> >\n> > It may be worth pointing out there that we're able to transfer all\n> existing\n> > HTLCs over to the new commitment as additional context.\n>\n> Yeah, I think people missed that it was non-blocking like that.\n>\n> >> 1. type: 45 (`splice_witness`) (`option_splice`)\n> >\n> > Should also allow either side to specify the sig script here if we're to\n> > allow nested p2sh (which we should IMO!).\n>\n> Yep.\n>\n> >>   * [`2`:`len`]\n> >>   * [`len`:`witnesses`]\n> >\n> > Is the extra length needed if all the witness elements themselves are\n> length\n> > delimited?\n>\n> Yes, we always length-delimit fields so we can add options later.\n>\n> >\n> > It isn't clear in the current draft, but I take it that the\n> splice_signature\n> > is for the old multi-sig?\n>\n> Yes, that's the signature required to spend the old funding txout.\n>\n> >> so we append to the existing `channel_update` for the original channel,\n> >> using a new `message_flags` field:\n> >\n> > IMO, we need to hold off on optional fields for now, until we revisit the\n> > formatting in order to actually get it right. As is now, all the optional\n> > fields are basically serial mandatory soft forks. So clients must\n> understand\n> > the prior in order to understand the following fields. Instead, we\n> > essentially need more of a map design.\n>\n> You need to add prior options to your wire parser, but that's usually\n> the most trivial part of handling them.  And they may waste space on the\n> wire since we treat them as append-only, but OTOH it avoids\n> combinatorial testing explosion.\n>\n> >> The post-splice reserve is 1% of post-splice capcacity (rounded down).\n> >\n> > This should be re-negotiated at time of splice creation, rather than a\n> new\n> > hard coded value in the protocol.\n> >\n> >> In addition, you can forget everything about the old channel (including\n> >> old HTLCs and revocation requirements).\n> >\n> > We still have the same shachain state however (if we don't allow new\n> state\n> > to be exchanged during the start of the splicing scenario), correct?\n>\n> Yep.\n>\n> Thanks,\n> Rusty.\n>\n> > -- Laolu\n> >\n> > -- Laolu\n>\n> PS, Damn, I always suspected there were multiple Roasbeefs, and we're\n> simply\n> dealing with the output of an advanced multiplexing protocol.  I present\n> the above as conclusive evidence of this thesis...\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181106/15a6f5a1/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-07T00:59:56",
                "message_text_only": "Olaoluwa Osuntokun <laolu32 at gmail.com> writes:\n>> Mainly limitations of our descriptor language, TBH.\n>\n> I don't follow...so it's a size issue? Or wanting to avoid \"repeated\"\n> fields?\n\nNot that smart: tools/extract-formats.py extracts descriptions from the\nspec for each message.  It currently requires constants in the field\nlengths, and these would be variable.\n\nWe'd have to teach it about messages within messages, eg:\n\n1. subtype: 1 (`splice_add_input`)\n2. data:\n   * [`8`: `satoshis`]\n   * [`32`: `prevtxid`]\n   * [`4`: `prevtxoutnum`]\n   * [`2`: `wscriptlen`]\n   * [`wscriptlen`: `wscript`]\n   * [`2`: `scriptlen`]\n   * [`scriptlen`: `scriptpubkey`]\n\n1. subtype: 2 (`splice_add_output`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`8`: `satoshis`]\n   * [`2`: `scriptlen`]\n   * [`scriptlen`: `outscript`]\n\n1. type:  40 (`splice_add`) (`option_splice`)\n   * [`32`:`channel_id`]\n   * [`2`: `num_splice_in`]\n   * [`num_splice_in*splice_add_input`: `inputs`]\n   * [`2`: `num_splice_out`]\n   * [`num_splice_out*splice_add_output`: `outputs`]\n\n>> We're basically co-generating a tx here, just like shutdown, except it's\n>> funding a new replacement channel.  Do we want to CPFP this one too?\n>\n> It'd be nice to be able to also anchor down this splicing transaction given\n> that we may only allow a single outstanding splicing operation to begin\n> with. Being able to CPFP it (and later on provide arbitrary fee inputs)\n> allows be to speed up the process if I want to queue another operation up\n> right afterwards.\n\nThat has some elegance (we would whatever fee scheme we will use for\ncommitment txs), but means we will almost always *have* to CPFP, which\nis unfortunate for chain bloat.\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Splicing Proposal: Feedback please!",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Olaoluwa Osuntokun",
                "ZmnSCPxj",
                "Christian Decker"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 22487
        }
    },
    {
        "title": "[Lightning-dev] Wireshark plug-in for Lightning Network(BOLT) protocol",
        "thread_messages": [
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-11-06T07:08:17",
                "message_text_only": "Hi tomokio,\n\nThis is so dope! We've long discussed creating canned protocol transcripts\nfor\nother implementations to assert their responses again, and I think this is a\ngreat first step towards that.\n\n> Our proposal:\n> Every implementation has compile option which enable output key\ninformation\n> file.\n\nSo is this request to add an option which will write out the _plaintext_\nmessages to disk, or an option that writes out the final derived read/write\nsecrets to disk? For the latter path, it the tools that read these\ntranscripts\nwould need to be aware of key rotations, so they'd  be able to continue to\ndecrypt the transact pt post rotation.\n\n-- Laolu\n\n\nOn Sat, Oct 27, 2018 at 2:37 AM <tomokio203 at gmail.com> wrote:\n\n> Hello lightning network developers.\n> Nayuta team is developing Wireshark plug-in for Lightning Network(BOLT)\n> protocol.\n> https://github.com/nayutaco/lightning-dissector\n>\n> It\u2019s alpha version, but it can decode some BOLT message.\n> Currently, this software works for Nayuta\u2019s implementation(ptarmigan) and\n> \u00c9clair.\n> When ptarmigan is compiled with some option, it write out key information\n> file. This Wireshark plug-in decode packet using that file.\n> When you use \u00c9clair, this software parse log file.\n>\n> Through our development experience, interoperability test is time\n> consuming task.\n> If people can see communication log of BOLT message on same format\n> (.pcap), it will be useful for interoperability test.\n>\n> Our proposal:\n> Every implementation has compile option which enable output key\n> information file.\n>\n> We are glad if this project is useful for lightning network eco-system.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181106/355fe7c3/attachment.html>"
            },
            {
                "author": "tock203",
                "date": "2018-11-07T05:43:03",
                "message_text_only": "We implemented the latter scheme. lightning-dissector already supports key\nrotation.\nFYI, here's the key log file format lightning-dissector currently\nimplements.\nhttps://github.com/nayutaco/lightning-dissector/blob/master/CONTRIBUTING.md#by-dumping-key-log-file\n\nWhenever key rotation happens(nonce==0), lightning node software write\n16byteMAC & key of \"first BOLT packet\".\nWhen you read .pcap starts with a message whose nonce is not 0, the\nmessages can not be decrypted until the next key rotation.\n\nThe current design is as described above. Because it is a provisional\nspecification, any opinion is welcome.\n\n2018\u5e7411\u67086\u65e5(\u706b) 16:08 Olaoluwa Osuntokun <laolu32 at gmail.com>:\n\n> Hi tomokio,\n>\n> This is so dope! We've long discussed creating canned protocol transcripts\n> for\n> other implementations to assert their responses again, and I think this is\n> a\n> great first step towards that.\n>\n> > Our proposal:\n> > Every implementation has compile option which enable output key\n> information\n> > file.\n>\n> So is this request to add an option which will write out the _plaintext_\n> messages to disk, or an option that writes out the final derived read/write\n> secrets to disk? For the latter path, it the tools that read these\n> transcripts\n> would need to be aware of key rotations, so they'd  be able to continue to\n> decrypt the transact pt post rotation.\n>\n> -- Laolu\n>\n>\n> On Sat, Oct 27, 2018 at 2:37 AM <tomokio203 at gmail.com> wrote:\n>\n>> Hello lightning network developers.\n>> Nayuta team is developing Wireshark plug-in for Lightning Network(BOLT)\n>> protocol.\n>> https://github.com/nayutaco/lightning-dissector\n>>\n>> It\u2019s alpha version, but it can decode some BOLT message.\n>> Currently, this software works for Nayuta\u2019s implementation(ptarmigan) and\n>> \u00c9clair.\n>> When ptarmigan is compiled with some option, it write out key information\n>> file. This Wireshark plug-in decode packet using that file.\n>> When you use \u00c9clair, this software parse log file.\n>>\n>> Through our development experience, interoperability test is time\n>> consuming task.\n>> If people can see communication log of BOLT message on same format\n>> (.pcap), it will be useful for interoperability test.\n>>\n>> Our proposal:\n>> Every implementation has compile option which enable output key\n>> information file.\n>>\n>> We are glad if this project is useful for lightning network eco-system.\n>>\n> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181107/3b15ea1d/attachment.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-11-08T02:38:57",
                "message_text_only": "Would it be possible to query a command line program or a JSON-RPC call to\nget the secret? In that case we could add it to the `listpeers` output.\n\nOn Wed, Nov 7, 2018 at 6:43 AM tock203 <tomokio203 at gmail.com> wrote:\n\n> We implemented the latter scheme. lightning-dissector already supports key\n> rotation.\n> FYI, here's the key log file format lightning-dissector currently\n> implements.\n> https://github.com/nayutaco/lightning-dissector/blob/master/CONTRIBUTING.md#by-dumping-key-log-file\n>\n> Whenever key rotation happens(nonce==0), lightning node software write\n> 16byteMAC & key of \"first BOLT packet\".\n> When you read .pcap starts with a message whose nonce is not 0, the\n> messages can not be decrypted until the next key rotation.\n>\n> The current design is as described above. Because it is a provisional\n> specification, any opinion is welcome.\n>\n> 2018\u5e7411\u67086\u65e5(\u706b) 16:08 Olaoluwa Osuntokun <laolu32 at gmail.com>:\n>\n>> Hi tomokio,\n>>\n>> This is so dope! We've long discussed creating canned protocol\n>> transcripts for\n>> other implementations to assert their responses again, and I think this\n>> is a\n>> great first step towards that.\n>>\n>> > Our proposal:\n>> > Every implementation has compile option which enable output key\n>> information\n>> > file.\n>>\n>> So is this request to add an option which will write out the _plaintext_\n>> messages to disk, or an option that writes out the final derived\n>> read/write\n>> secrets to disk? For the latter path, it the tools that read these\n>> transcripts\n>> would need to be aware of key rotations, so they'd  be able to continue to\n>> decrypt the transact pt post rotation.\n>>\n>> -- Laolu\n>>\n>>\n>> On Sat, Oct 27, 2018 at 2:37 AM <tomokio203 at gmail.com> wrote:\n>>\n>>> Hello lightning network developers.\n>>> Nayuta team is developing Wireshark plug-in for Lightning Network(BOLT)\n>>> protocol.\n>>> https://github.com/nayutaco/lightning-dissector\n>>>\n>>> It\u2019s alpha version, but it can decode some BOLT message.\n>>> Currently, this software works for Nayuta\u2019s implementation(ptarmigan)\n>>> and \u00c9clair.\n>>> When ptarmigan is compiled with some option, it write out key\n>>> information file. This Wireshark plug-in decode packet using that file.\n>>> When you use \u00c9clair, this software parse log file.\n>>>\n>>> Through our development experience, interoperability test is time\n>>> consuming task.\n>>> If people can see communication log of BOLT message on same format\n>>> (.pcap), it will be useful for interoperability test.\n>>>\n>>> Our proposal:\n>>> Every implementation has compile option which enable output key\n>>> information file.\n>>>\n>>> We are glad if this project is useful for lightning network eco-system.\n>>>\n>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181108/d7736bc9/attachment.html>"
            },
            {
                "author": "daniel",
                "date": "2018-11-27T11:11:56",
                "message_text_only": "c-lighting-dissector work now:\nhttps://github.com/arowser/lightning/tree/dissector\nhttps://github.com/arowser/lightning-dissector\n./configure  --enable-dissector && make -j\n\n\nOn Thu, Nov 8, 2018 at 10:39 AM Christian Decker <decker.christian at gmail.com>\nwrote:\n\n> Would it be possible to query a command line program or a JSON-RPC call to\n> get the secret? In that case we could add it to the `listpeers` output.\n>\n> On Wed, Nov 7, 2018 at 6:43 AM tock203 <tomokio203 at gmail.com> wrote:\n>\n>> We implemented the latter scheme. lightning-dissector already supports\n>> key rotation.\n>> FYI, here's the key log file format lightning-dissector currently\n>> implements.\n>> https://github.com/nayutaco/lightning-dissector/blob/master/CONTRIBUTING.md#by-dumping-key-log-file\n>>\n>> Whenever key rotation happens(nonce==0), lightning node software write\n>> 16byteMAC & key of \"first BOLT packet\".\n>> When you read .pcap starts with a message whose nonce is not 0, the\n>> messages can not be decrypted until the next key rotation.\n>>\n>> The current design is as described above. Because it is a provisional\n>> specification, any opinion is welcome.\n>>\n>> 2018\u5e7411\u67086\u65e5(\u706b) 16:08 Olaoluwa Osuntokun <laolu32 at gmail.com>:\n>>\n>>> Hi tomokio,\n>>>\n>>> This is so dope! We've long discussed creating canned protocol\n>>> transcripts for\n>>> other implementations to assert their responses again, and I think this\n>>> is a\n>>> great first step towards that.\n>>>\n>>> > Our proposal:\n>>> > Every implementation has compile option which enable output key\n>>> information\n>>> > file.\n>>>\n>>> So is this request to add an option which will write out the _plaintext_\n>>> messages to disk, or an option that writes out the final derived\n>>> read/write\n>>> secrets to disk? For the latter path, it the tools that read these\n>>> transcripts\n>>> would need to be aware of key rotations, so they'd  be able to continue\n>>> to\n>>> decrypt the transact pt post rotation.\n>>>\n>>> -- Laolu\n>>>\n>>>\n>>> On Sat, Oct 27, 2018 at 2:37 AM <tomokio203 at gmail.com> wrote:\n>>>\n>>>> Hello lightning network developers.\n>>>> Nayuta team is developing Wireshark plug-in for Lightning Network(BOLT)\n>>>> protocol.\n>>>> https://github.com/nayutaco/lightning-dissector\n>>>>\n>>>> It\u2019s alpha version, but it can decode some BOLT message.\n>>>> Currently, this software works for Nayuta\u2019s implementation(ptarmigan)\n>>>> and \u00c9clair.\n>>>> When ptarmigan is compiled with some option, it write out key\n>>>> information file. This Wireshark plug-in decode packet using that file.\n>>>> When you use \u00c9clair, this software parse log file.\n>>>>\n>>>> Through our development experience, interoperability test is time\n>>>> consuming task.\n>>>> If people can see communication log of BOLT message on same format\n>>>> (.pcap), it will be useful for interoperability test.\n>>>>\n>>>> Our proposal:\n>>>> Every implementation has compile option which enable output key\n>>>> information file.\n>>>>\n>>>> We are glad if this project is useful for lightning network eco-system.\n>>>>\n>>> _______________________________________________\n>>>> Lightning-dev mailing list\n>>>> Lightning-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>>\n>>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181127/6766df2c/attachment-0001.html>"
            },
            {
                "author": "tock203",
                "date": "2018-11-27T21:31:53",
                "message_text_only": "Awesome, thanks!\nI merged it. https://github.com/nayutaco/lightning-dissector\n\nMy understanding is that ~/.lightning/keys.log will contain the last sk\nonly. Is it correct? If so, lightning-dissector can't decrypt .pcap which\ncontains both messages before key rotation and messages after key rotation.\nTo support decrypting such .pcap, ~/.lightning/keys.log should contain a\nfew of recent sk. I recommend you to follow this key log format.\nhttps://github.com/nayutaco/lightning-dissector/blob/master/CONTRIBUTING.md#by-dumping-key-log-file\nBy\nfollowing this, you can reuse KeyLogSecretFactory instead of to implement\nClightningSecretFactory.\n\n2018\u5e7411\u670827\u65e5(\u706b) 20:12 daniel <arowser at gmail.com>:\n\n> c-lighting-dissector work now:\n> https://github.com/arowser/lightning/tree/dissector\n> https://github.com/arowser/lightning-dissector\n> ./configure  --enable-dissector && make -j\n>\n>\n> On Thu, Nov 8, 2018 at 10:39 AM Christian Decker <\n> decker.christian at gmail.com> wrote:\n>\n>> Would it be possible to query a command line program or a JSON-RPC call\n>> to get the secret? In that case we could add it to the `listpeers` output.\n>>\n>> On Wed, Nov 7, 2018 at 6:43 AM tock203 <tomokio203 at gmail.com> wrote:\n>>\n>>> We implemented the latter scheme. lightning-dissector already supports\n>>> key rotation.\n>>> FYI, here's the key log file format lightning-dissector currently\n>>> implements.\n>>> https://github.com/nayutaco/lightning-dissector/blob/master/CONTRIBUTING.md#by-dumping-key-log-file\n>>>\n>>> Whenever key rotation happens(nonce==0), lightning node software write\n>>> 16byteMAC & key of \"first BOLT packet\".\n>>> When you read .pcap starts with a message whose nonce is not 0, the\n>>> messages can not be decrypted until the next key rotation.\n>>>\n>>> The current design is as described above. Because it is a provisional\n>>> specification, any opinion is welcome.\n>>>\n>>> 2018\u5e7411\u67086\u65e5(\u706b) 16:08 Olaoluwa Osuntokun <laolu32 at gmail.com>:\n>>>\n>>>> Hi tomokio,\n>>>>\n>>>> This is so dope! We've long discussed creating canned protocol\n>>>> transcripts for\n>>>> other implementations to assert their responses again, and I think this\n>>>> is a\n>>>> great first step towards that.\n>>>>\n>>>> > Our proposal:\n>>>> > Every implementation has compile option which enable output key\n>>>> information\n>>>> > file.\n>>>>\n>>>> So is this request to add an option which will write out the _plaintext_\n>>>> messages to disk, or an option that writes out the final derived\n>>>> read/write\n>>>> secrets to disk? For the latter path, it the tools that read these\n>>>> transcripts\n>>>> would need to be aware of key rotations, so they'd  be able to continue\n>>>> to\n>>>> decrypt the transact pt post rotation.\n>>>>\n>>>> -- Laolu\n>>>>\n>>>>\n>>>> On Sat, Oct 27, 2018 at 2:37 AM <tomokio203 at gmail.com> wrote:\n>>>>\n>>>>> Hello lightning network developers.\n>>>>> Nayuta team is developing Wireshark plug-in for Lightning\n>>>>> Network(BOLT) protocol.\n>>>>> https://github.com/nayutaco/lightning-dissector\n>>>>>\n>>>>> It\u2019s alpha version, but it can decode some BOLT message.\n>>>>> Currently, this software works for Nayuta\u2019s implementation(ptarmigan)\n>>>>> and \u00c9clair.\n>>>>> When ptarmigan is compiled with some option, it write out key\n>>>>> information file. This Wireshark plug-in decode packet using that file.\n>>>>> When you use \u00c9clair, this software parse log file.\n>>>>>\n>>>>> Through our development experience, interoperability test is time\n>>>>> consuming task.\n>>>>> If people can see communication log of BOLT message on same format\n>>>>> (.pcap), it will be useful for interoperability test.\n>>>>>\n>>>>> Our proposal:\n>>>>> Every implementation has compile option which enable output key\n>>>>> information file.\n>>>>>\n>>>>> We are glad if this project is useful for lightning network eco-system.\n>>>>>\n>>>> _______________________________________________\n>>>>> Lightning-dev mailing list\n>>>>> Lightning-dev at lists.linuxfoundation.org\n>>>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>>>\n>>>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181128/269089e8/attachment.html>"
            },
            {
                "author": "daniel",
                "date": "2018-11-28T05:10:22",
                "message_text_only": "Thank you, I have update the code follow you suggesstion and send a new pr\nto https://github.com/nayutaco/lightning-dissector.\n\n\n\n\nOn Wed, Nov 28, 2018 at 5:32 AM tock203 <tomokio203 at gmail.com> wrote:\n\n> Awesome, thanks!\n> I merged it. https://github.com/nayutaco/lightning-dissector\n>\n> My understanding is that ~/.lightning/keys.log will contain the last sk\n> only. Is it correct? If so, lightning-dissector can't decrypt .pcap which\n> contains both messages before key rotation and messages after key rotation.\n> To support decrypting such .pcap, ~/.lightning/keys.log should contain a\n> few of recent sk. I recommend you to follow this key log format.\n> https://github.com/nayutaco/lightning-dissector/blob/master/CONTRIBUTING.md#by-dumping-key-log-file By\n> following this, you can reuse KeyLogSecretFactory instead of to implement\n> ClightningSecretFactory.\n>\n> 2018\u5e7411\u670827\u65e5(\u706b) 20:12 daniel <arowser at gmail.com>:\n>\n>> c-lighting-dissector work now:\n>> https://github.com/arowser/lightning/tree/dissector\n>> https://github.com/arowser/lightning-dissector\n>> ./configure  --enable-dissector && make -j\n>>\n>>\n>> On Thu, Nov 8, 2018 at 10:39 AM Christian Decker <\n>> decker.christian at gmail.com> wrote:\n>>\n>>> Would it be possible to query a command line program or a JSON-RPC call\n>>> to get the secret? In that case we could add it to the `listpeers` output.\n>>>\n>>> On Wed, Nov 7, 2018 at 6:43 AM tock203 <tomokio203 at gmail.com> wrote:\n>>>\n>>>> We implemented the latter scheme. lightning-dissector already supports\n>>>> key rotation.\n>>>> FYI, here's the key log file format lightning-dissector currently\n>>>> implements.\n>>>> https://github.com/nayutaco/lightning-dissector/blob/master/CONTRIBUTING.md#by-dumping-key-log-file\n>>>>\n>>>> Whenever key rotation happens(nonce==0), lightning node software write\n>>>> 16byteMAC & key of \"first BOLT packet\".\n>>>> When you read .pcap starts with a message whose nonce is not 0, the\n>>>> messages can not be decrypted until the next key rotation.\n>>>>\n>>>> The current design is as described above. Because it is a provisional\n>>>> specification, any opinion is welcome.\n>>>>\n>>>> 2018\u5e7411\u67086\u65e5(\u706b) 16:08 Olaoluwa Osuntokun <laolu32 at gmail.com>:\n>>>>\n>>>>> Hi tomokio,\n>>>>>\n>>>>> This is so dope! We've long discussed creating canned protocol\n>>>>> transcripts for\n>>>>> other implementations to assert their responses again, and I think\n>>>>> this is a\n>>>>> great first step towards that.\n>>>>>\n>>>>> > Our proposal:\n>>>>> > Every implementation has compile option which enable output key\n>>>>> information\n>>>>> > file.\n>>>>>\n>>>>> So is this request to add an option which will write out the\n>>>>> _plaintext_\n>>>>> messages to disk, or an option that writes out the final derived\n>>>>> read/write\n>>>>> secrets to disk? For the latter path, it the tools that read these\n>>>>> transcripts\n>>>>> would need to be aware of key rotations, so they'd  be able to\n>>>>> continue to\n>>>>> decrypt the transact pt post rotation.\n>>>>>\n>>>>> -- Laolu\n>>>>>\n>>>>>\n>>>>> On Sat, Oct 27, 2018 at 2:37 AM <tomokio203 at gmail.com> wrote:\n>>>>>\n>>>>>> Hello lightning network developers.\n>>>>>> Nayuta team is developing Wireshark plug-in for Lightning\n>>>>>> Network(BOLT) protocol.\n>>>>>> https://github.com/nayutaco/lightning-dissector\n>>>>>>\n>>>>>> It\u2019s alpha version, but it can decode some BOLT message.\n>>>>>> Currently, this software works for Nayuta\u2019s implementation(ptarmigan)\n>>>>>> and \u00c9clair.\n>>>>>> When ptarmigan is compiled with some option, it write out key\n>>>>>> information file. This Wireshark plug-in decode packet using that file.\n>>>>>> When you use \u00c9clair, this software parse log file.\n>>>>>>\n>>>>>> Through our development experience, interoperability test is time\n>>>>>> consuming task.\n>>>>>> If people can see communication log of BOLT message on same format\n>>>>>> (.pcap), it will be useful for interoperability test.\n>>>>>>\n>>>>>> Our proposal:\n>>>>>> Every implementation has compile option which enable output key\n>>>>>> information file.\n>>>>>>\n>>>>>> We are glad if this project is useful for lightning network\n>>>>>> eco-system.\n>>>>>>\n>>>>> _______________________________________________\n>>>>>> Lightning-dev mailing list\n>>>>>> Lightning-dev at lists.linuxfoundation.org\n>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>>>>\n>>>>> _______________________________________________\n>>>> Lightning-dev mailing list\n>>>> Lightning-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>>\n>>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181128/1049f8c7/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Wireshark plug-in for Lightning Network(BOLT) protocol",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "daniel",
                "Olaoluwa Osuntokun",
                "tock203",
                "Christian Decker"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 21358
        }
    },
    {
        "title": "[Lightning-dev] Improving payment UX with low-latency route probing",
        "thread_messages": [
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-11-06T07:26:06",
                "message_text_only": "Hi Fabrice,\n\nI think HORNET would address this rather nicely!\n\nDuring the set up phase (which uses Sphinx), the sender is able to get a\nsense\nof if the route is actually \"lively\" or not, as the circuit can't be\nfinalized\nif all the nodes aren't available. Additionally, during the set up phase,\nthe\nsender can drop a unique payload to each node. In this scenario, it may be\nthe\namount range the node is looking to send over this circuit. The intermediate\nnodes then package up a \"Forwarding Segment\" (FS) which includes a symmetric\nkey to use for their portion of the hop, and can also be extended to include\nfee information. If this set up phase is payment value aware, then each node\ncan use a private \"fee function\" that may take into account the level of\ncongestion in their channels, or other factors. This would differ from the\ncurrent approach in that this fee schedule need not be communicated to the\nwider network, only those wishing to route across that link.\n\nAnother cool thing that it would allow is the ability to receive a\nprotocol-level payment ACK. This may be useful when implementing AMP, as it\nwould allow the sender to know exactly how many satoshis have arrived at the\nother site, adjusting their payment sharding accordingly. Nodes on either\nside\nof the circuit can then also use the data forwarding phase to exchange\npayment\nhashes, perform cool zkcp set up protcols, etc, etc.\n\nThe created circuits can actually be re-used across several distinct\npayments.\nIn the paper, they use a TTL for each circuit, in our case, we can use a\nblock\nheight, after which all nodes should reject attempted data forwarding\nattempts.\nA notable change is that each node no longer needs to maintain per-circuit\nstate as we do now with Sphinx. Instead, the packets that come across\ncontain\nall the information required for forwarding (our current per-hop payload).\nAs a\nresult, we can eliminate the asymmetric crytpo from the critical forwarding\npath!\n\nFinally, this would let nodes easily rotate their onion keys to achieve\nforward\nsecrecy during the data phase (but not the set up phase), as in the FS, they\nessentially key-wrap a symmetric key (using the derived shared secret for\nthat\nhop) that should be used for that data forwarding phase.\n\nThere're a number of other cool things integration HORNET would allow,\nperhaps\na distinct thread would be a more appropriate place to extol the many\nvirtues\nof HORNET ;)\n\n-- Laolu\n\nOn Thu, Nov 1, 2018 at 3:05 PM Fabrice Drouin <fabrice.drouin at acinq.fr>\nwrote:\n\n> Context\n> ======\n>\n> Sent payments that remain pending, i.e. payments which have not yet\n> been failed or fulfilled, are currently a major UX challenge for LN\n> and a common source of complaints from end-users.\n> Why payments are not fulfilled quickly is not always easy to\n> investigate, but we've seen problems caused by intermediate nodes\n> which were stuck waiting for a revocation, and recipients who could\n> take a very long time to reply with a payment preimage.\n> It is already possible to partially mitigate this by disconnecting\n> from a node that is taking too long to send a revocation (after 30\n> seconds for example) and reconnecting immediately to the same node.\n> This way pending downstream HTLCs can be forgotten and the\n> corresponding upstream HTLCs failed.\n>\n> Proposed changes\n> ===============\n>\n> It should be possible to provide a faster \"proceed/try another route\"\n> answer to the sending node using probing with short timeout\n> requirements: before sending the actual payment it would first send a\n> \"blank\" probe request, along the same route. This request would be\n> similar to a payment request, with the same onion packet formatting\n> and processing, with the additional requirements that if the next node\n> in the route has not replied within the timeout period (typically a\n> few hundred milliseconds) then the current node will immediately send\n> back an error message.\n>\n> There could be several options for the probe request:\n> - include the same amounts and fee constraints than the actual payment\n> request.\n> - include no amount information, in which case we're just trying to\n> \"ping\" every node on the route.\n>\n> Implementation\n> ============\n>\n> I would like to discuss the possibility of implementing this with a \"0\n> satoshi\" payment request that the receiving node would generate along\n> with the real one. The sender would first try to \"pay\" the \"0 satoshi\"\n> request using the route it computed with the actual payment\n> parameters. I think that it would not require many changes to the\n> existing protocol and implementations.\n> Not using the actual amount and fees means that the actual payment\n> could fail because of capacity issues but as long as this happens\n> quickly, and it should since we checked first that all nodes on the\n> route are alive and responsive, it still is much better than \u201cstuck\u201d\n> payments.\n> And it would not help if a node decides to misbehave, but would not\n> make things worse than they are now (?)\n>\n> Cheers,\n> Fabrice\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181106/6aeb4330/attachment.html>"
            },
            {
                "author": "Pierre",
                "date": "2018-11-07T00:18:08",
                "message_text_only": "Hi Laolu and Fabrice,\n\n> I think HORNET would address this rather nicely!\n\nHORNET sounds awesome, but does it really address the specific issue\nFabrice is describing though? IIUC, HORNET would operate at a lower\nlayer and it could be possible to have a valid circuit and still\nindefinitely waiting for a revocation. OTOH it certainly would address\nthe case where the peer is completely unresponsive.\n\nFor example, I have already seen peers which don't send revocations,\nbut e.g. respond to pings just fine.\n\nActually, re-reading Fabrice's proposal I wonder if one could make the\nsame comment about it. Would the 0-satoshi payment require the\ncommit_sig/revoke_and_ack dance? If not, would we really gain more\nconfidence in the availability of the peers in the route?\n\n>> It is already possible to partially mitigate this by disconnecting\nfrom a node that is taking too long to send a revocation (after 30\nseconds for example)\n\nActually I think this would substantially improve the issue at hand. I\nbelieve we should probably add this to BOLT 2 in the form of a\n\"SHOULD\" clause. I feel bad because in [1] I suggested doing just that\nin lnd, but we don't actually do it in eclair :-/ Will eat my own dog\nfood asap!\n\nCheers,\n\nPierre\n\n[1] https://github.com/lightningnetwork/lnd/issues/2045#issuecomment-429561637"
            }
        ],
        "thread_summary": {
            "title": "Improving payment UX with low-latency route probing",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Olaoluwa Osuntokun",
                "Pierre"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 6702
        }
    },
    {
        "title": "[Lightning-dev] Proposal for Advertising Channel Liquidity",
        "thread_messages": [
            {
                "author": "lisa neigut",
                "date": "2018-11-07T04:07:42",
                "message_text_only": "Problem\n====================================\nCurrently it\u2019s difficult to reliably source inbound capacity for your node.\nThis is incredibly problematic for vendors and nodes hoping to setup shop\nas a route facilitator. Most solutions at the moment require an element of\nout of band negotiation in order to find other nodes that can help with\nyour capacity needs.\n\nWhile splicing and dual funding mechanisms will give some relief by\nallowing for the initial negotiation to give the other node an opportunity\nto put funds in either at channel open or after the fact, the problem of\nfinding channel liquidity is still left as an offline problem.\n\nProposal\n=====================================\nTo solve the liquidity discovery problem, I'd like to propose allowing\nnodes to advertise initial liquidity matching. The goal of this proposal\nwould be to allow nodes to independently source inbound capacity from a\n'market' of advertised liquidity rates, as set by other nodes.\n\nA node, via their node_announcement, can advertise that they will match\nliquidity and a fee rate that they will provide to any incoming\nopen_channel request that indicates requests it.\n\n`node_announcement`:\nnew feature flag: option_liquidity_provider\ndata:\n [4 liquidity_fee_proportional_millionths] (option_liquidity_provider) fee\ncharged per satoshi of liquidity added at channel open\n [4 liquidity_fee_base_msat] (option_liquidity_provider) base fee charged\nfor providing liquidity at channel open\n\n`open_channel`:\nnew feature flag (channel_flags): option_liquidity_buy [2nd least\nsignificant bit]\npush_msat: set to fee payment for requested liquidity\n[8 liquidity_msat_request]: (option_liquidity_buy) amount of dual funding\nrequested at channel open\n\n`accept_channel`:\ntbd. hinges on a dual funding proposal for how second node would send\ninformation about their funding input.\n\nIf a node cannot provide the liquidity requested in `open_channel`, it must\nreturn an error.\nIf the amount listed in `push_msat` does not cover the amount of liquidity\nprovided, the liquidity provider node must return an error.\n\nErrata\n======================================\nIt's an open question as to whether or not a liquidity advertising node\nshould also include a maximum amount of liquidity that they will\nmatch/provide. As currently proposed, the only way to discover if a node\ncan meet your liquidity requirement is by sending an open channel request.\n\nThis proposal depends on dual funding being possible.\n\nShould a node be able to request more liquidity than they put into the\nchannel on their half? In the case of a vendor who wants inbound capacity,\ncapping the liquidity request allowed seems unnecessary.\n\nConclusion\n=======================================\nAllowing nodes to advertise liquidity paves the way for automated node\nre-balancing. Advertised liquidity creates a market of inbound capacity\nthat any node can take advantage of, reducing the amount of out-of-band\nnegotiation needed to get the inbound capacity that you need.\n\n\nCredit to Casey Rodamor for the initial idea.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181106/07fce24b/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-07T06:17:17",
                "message_text_only": "Good morning Lisa,\n\n>Should a node be able to request more liquidity than they put into the channel on their half? In the case of a vendor who wants inbound capacity, capping the liquidity request\n>allowed seems unnecessary.\n\nMy initial thought is that it would be dangerous to allow the initiator of the request to request for arbitrary capacity.\n\nFor instance, suppose that, via my legion of captive zombie computers (which are entirely fictional and exist only in this example, since I am an ordinary human person) I have analyzed the blockchain and discovered that you have 1.0 BTC you have reserved for liquidity requests under this protocol.  I could then have one of those computers spin up a temporary Lightning Node, request for 1.0BTC incoming capacity with only some nominal fee, then shut down the node permanently, leaving your funds in an unuseable channel, unable to earn routing fees or such.  This loses you potential earnings from this 1.0 BTC.\n\nIf instead I were obligated to have at least greater capacity tied into this channel, then I would also be tying up at least 1.0 BTC into this channel as well, making this attack more expensive for me, as it also loses me any potential earnings from the 1.0 BTC of my own that I have locked up.\n\nTo my mind, this may become important.\n\nRegards,\nZmnSCPxj\n\n> Conclusion\n> =======================================\n> Allowing nodes to advertise liquidity paves the way for automated node re-balancing. Advertised liquidity creates a market of inbound capacity that any node can take advantage of, reducing the amount of out-of-band negotiation needed to get the inbound capacity that you need.\n>\n> Credit to Casey Rodamor for the initial idea.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181107/502cb6d2/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-07T10:49:21",
                "message_text_only": "Good morning Lisa,\n\nOn Wednesday, November 7, 2018 2:17 PM, ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Lisa,\n>\n>>Should a node be able to request more liquidity than they put into the channel on their half? In the case of a vendor who wants inbound capacity, capping the liquidity request\n>>allowed seems unnecessary.\n>\n> My initial thought is that it would be dangerous to allow the initiator of the request to request for arbitrary capacity.\n>\n> For instance, suppose that, via my legion of captive zombie computers (which are entirely fictional and exist only in this example, since I am an ordinary human person) I have analyzed the blockchain and discovered that you have 1.0 BTC you have reserved for liquidity requests under this protocol.  I could then have one of those computers spin up a temporary Lightning Node, request for 1.0BTC incoming capacity with only some nominal fee, then shut down the node permanently, leaving your funds in an unuseable channel, unable to earn routing fees or such.  This loses you potential earnings from this 1.0 BTC.\n>\n> If instead I were obligated to have at least greater capacity tied into this channel, then I would also be tying up at least 1.0 BTC into this channel as well, making this attack more expensive for me, as it also loses me any potential earnings from the 1.0 BTC of my own that I have locked up.\n\nA counterpoint to this argument, however, is that if the fee for the liquidity is high enough, then it does not matter to you whether I use the 1.0 BTC or not: you have already been paid for it.\n\nThis however brings up the other potential attack:\n\n1.  I advertise that I have 1.0 BTC available for liquidity requests.\n2.  You answer this advertisement, and pay me a good fee for this 1.0 BTC being locked into a channel.\n3.  After the channel is opened, I immediately close it, having earned the fee for liquidity, without in fact delivering that liquidity.\n\nPerhaps we can modify channel commitment transactions for channels opened via liquidity requests, so that they have an `nSequence` that prevents them from being claimed for a month or so.  What do you think?\n\nRegards,\nZmnSCPxj\n\n> To my mind, this may become important.\n>\n> Regards,\n> ZmnSCPxj\n>\n>> Conclusion\n>> =======================================\n>> Allowing nodes to advertise liquidity paves the way for automated node re-balancing. Advertised liquidity creates a market of inbound capacity that any node can take advantage of, reducing the amount of out-of-band negotiation needed to get the inbound capacity that you need.\n>>\n>> Credit to Casey Rodamor for the initial idea.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181107/6ff47164/attachment.html>"
            },
            {
                "author": "Jim Posen",
                "date": "2018-11-08T02:40:13",
                "message_text_only": "Thanks for proposing this! I think it is absolutely one of the biggest\nonboarding/usability challenges for many use cases.\n\nMy first thought is that like ZmnSCPxj mentioned, the person offering\nliquidity can simply close the channel. So if I'm charging for liquidity,\nI'd actually want to charge for the amount (in mSAT/BTC) times time. So\nlike 1 mSAT per satoshi of bandwidth per hour or something like that. I\ndon't think there's a perfect way of enforcing this at the protocol layer,\nbut maybe you could lock up the fees in channel reserve which decreases\nover time and gets donated to miners on an early close?\n\nInstead of a flat payment for liquidity, I've considered in the past a\nmodel where you pre-pay on fees. So if I'm a large merchant and I expect to\nbe receiving lots of volume in payments, it is totally rational for you to\nput up liquidity opening a channel to me because you will earn fees on\npayments routed to me through that channel. So what I could do to convince\nyou is to say, \"I expect if you open a 1 BTC channel to me, you will earn\nat least 10 mSAT per minute in routing fees. And if you don't I'll cover\nthe difference.\" So every minute, I'll pay you 10 mSAT up front, then for\nall HTLCs that come through the channel to me up to that limit, you'll\nforward the fees onto me as reimbursement. I don't think this protocol is\nany less vulnerable to attacks, but perhaps aligns incentives better?\n\nMy other concern with this sort of proposal is that it makes it easier to\nperform HTLC withholding/loop attacks, which are executed by the receiving\nend of a circuit. Currently on the network, there's a nice built-in\nprotection that it's not obvious how to convince victim to open a channel\nto you. This is probably something that should get dealt with separately,\nbut part of me doubts that it'll be possible to create a liquidity market\nwithout factoring in reputation.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181107/44263e78/attachment.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2018-11-08T06:17:03",
                "message_text_only": "On Wed, Nov 07, 2018 at 06:40:13PM -0800, Jim Posen wrote:\n> can simply close the channel. So if I'm charging for liquidity, I'd actually\n> want to charge for the amount (in mSAT/BTC) times time. \n\nSo perhaps you could make a market here by establishing a channel saying\nthat\n\n  \"I'll pay 32 msat per 500 satoshi per hour for the first 3 days\"\n\nWhen you open the channel with 500,000 satoshi donated by the other guy,\nyou're then obliged to transfer 32 satoshi every hour to the other guy\nfor three days (so a total of 14c or so).\n\nIf the channel fails beforehand, they don't get paid; if you stop\npaying you can still theoretically do a mutual close.\n\nMaybe a complicated addition to the protocol though?\n\nCheers,\naj"
            },
            {
                "author": "lisa neigut",
                "date": "2018-11-12T09:35:19",
                "message_text_only": "On Wed, Nov 7, 2018 at 10:17 PM Anthony Towns <aj at erisian.com.au> wrote:\n\n> On Wed, Nov 07, 2018 at 06:40:13PM -0800, Jim Posen wrote:\n> > can simply close the channel. So if I'm charging for liquidity, I'd\n> actually\n> > want to charge for the amount (in mSAT/BTC) times time.\n>\n> So perhaps you could make a market here by establishing a channel saying\n> that\n>\n>   \"I'll pay 32 msat per 500 satoshi per hour for the first 3 days\"\n>\n> When you open the channel with 500,000 satoshi donated by the other guy,\n> you're then obliged to transfer 32 satoshi every hour to the other guy\n> for three days (so a total of 14c or so).\n>\n> If the channel fails beforehand, they don't get paid; if you stop\n> paying you can still theoretically do a mutual close.\n>\n\nI think that this can also be gamed by a second, cooperating node that\nsends payments through the channel to meet the rate and capture the fees\nfor the first. You can make this less likely by charging higher\ntransmission fees that make such an attack infeasible, and it's less\n'damaging' than an immediate close in that there's still open capacity\navailable for some time, at least until the 'bogus' payments have drained\nthe capacity that you solicited in the first place.\n\n\n> Maybe a complicated addition to the protocol though?\n>\n> Cheers,\n> aj\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181112/f34b2bd2/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-12T10:05:08",
                "message_text_only": "Good morning lisa,\n\n>>> can simply close the channel. So if I'm charging for liquidity, I'd actually\n>>> want to charge for the amount (in mSAT/BTC) times time.\n>>\n>> So perhaps you could make a market here by establishing a channel saying\n>> that\n>>\n>>   \"I'll pay 32 msat per 500 satoshi per hour for the first 3 days\"\n>>\n>> When you open the channel with 500,000 satoshi donated by the other guy,\n>> you're then obliged to transfer 32 satoshi every hour to the other guy\n>> for three days (so a total of 14c or so).\n>>\n>> If the channel fails beforehand, they don't get paid; if you stop\n>> paying you can still theoretically do a mutual close.\n>\n> I think that this can also be gamed by a second, cooperating node that sends payments through the channel to meet the rate and capture the fees for the first. You can make this less likely by charging higher transmission fees that make such an attack infeasible, and it's less 'damaging' than an immediate close in that there's still open capacity available for some time, at least until the 'bogus' payments have drained the capacity that you solicited in the first place.\n\nI believe not?\nI do not see any terms in the contract regarding payments through the channel other than the \"liveness\" payment.\nSo regardless of activity (or lack of activity) in the channel, the above payments should be made.\nIf the taker misses a payment, the maker closes the channel outright, freeing itself from the obligation.\nIf the maker refuses to route, it loses out on potential routing fees.\nAny activity through it do not seem to matter.\n\nThis mechanism may actually be superior to the CLTV-encumberance I and Rene proposed.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181112/6b7f9f61/attachment.html>"
            },
            {
                "author": "lisa neigut",
                "date": "2018-11-12T09:20:49",
                "message_text_only": "Hello ZmnSCPxj,\n\nYou bring up some good points.\n\nOn Wed, Nov 7, 2018, 21:19 ZmnSCPxj <ZmnSCPxj at protonmail.com wrote:\n\n> Good morning Lisa,\n>\n> On Wednesday, November 7, 2018 2:17 PM, ZmnSCPxj via Lightning-dev <\n> lightning-dev at lists.linuxfoundation.org> wrote:\n>\n> Good morning Lisa,\n>\n> >Should a node be able to request more liquidity than they put into the\n> channel on their half? In the case of a vendor who wants inbound capacity,\n> capping the liquidity request\n> >allowed seems unnecessary.\n>\n> My initial thought is that it would be dangerous to allow the initiator of\n> the request to request for arbitrary capacity.\n>\n> For instance, suppose that, via my legion of captive zombie computers\n> (which are entirely fictional and exist only in this example, since I am an\n> ordinary human person) I have analyzed the blockchain and discovered that\n> you have 1.0 BTC you have reserved for liquidity requests under this\n> protocol.  I could then have one of those computers spin up a temporary\n> Lightning Node, request for 1.0BTC incoming capacity with only some nominal\n> fee, then shut down the node permanently, leaving your funds in an\n> unuseable channel, unable to earn routing fees or such.  This loses you\n> potential earnings from this 1.0 BTC.\n>\n> If instead I were obligated to have at least greater capacity tied into\n> this channel, then I would also be tying up at least 1.0 BTC into this\n> channel as well, making this attack more expensive for me, as it also loses\n> me any potential earnings from the 1.0 BTC of my own that I have locked up.\n>\n> As you point out below, at the very least a liquidity providing node would\nget paid. Another thing worth considering is that the spec, as written, is\nmerely a mechanism for advertising and receiving offers for dual funding.\nThere are no rules about what offers you, as a liquidity advertising node,\nhave to accept. A node operator has the flexibility to reject any offer\nabove or below their stated fee rate, or if they don't relish the idea of\nfunding a badly skewed channel. If you're worried about capital being tied\nup unnecessarily, you can reject offers without a sizeable input of their\nown.\n\nThere are, however, scenarios where requests for badly skewed channels make\nsense. Imagine that you're a large vendor, such as Amazon. You're likely\nnot going to ever need much outbound capacity, but you will be perpetually\nin the market for more inbound capacity.\n\nIn fact, as a liquidity provider, I think that you'll probably be delighted\nto have an open channel with Amazon, as there's a good chance that channel\nwill be highly utilized, which means more fee traffic for you, and a high\nprobability that they'll be requesting more liquidity from you in the\nfuture, as the existing channel gets unbalanced.\n\n\n> A counterpoint to this argument, however, is that if the fee for the\n> liquidity is high enough, then it does not matter to you whether I use the\n> 1.0 BTC or not: you have already been paid for it.\n>\n> This however brings up the other potential attack:\n>\n> 1.  I advertise that I have 1.0 BTC available for liquidity requests.\n> 2.  You answer this advertisement, and pay me a good fee for this 1.0 BTC\n> being locked into a channel.\n> 3.  After the channel is opened, I immediately close it, having earned the\n> fee for liquidity, without in fact delivering that liquidity.\n>\n> Perhaps we can modify channel commitment transactions for channels opened\n> via liquidity requests, so that they have an `nSequence` that prevents them\n> from being claimed for a month or so.  What do you think?\n>\n\nAt what point should a liquidity providing node (maker) be able to close\nthe channel? Immediately is not very beneficial to either of you -- you\nboth tied up your money for the time required to push through bitcoin txns\nthrough, plus you lose closing + opening fees. Stipulating a length of time\nisn't necessarily beneficial either -- if you've connected to a high volume\npayment channel, the liquidity you've provided will be used up rather\nquickly, rendering the channel itself pretty useless.\n\nI think there's definitely some clever things we can do to provide stronger\nguarantees around a 'minimum service offer', and they can be investigated\nindependently of the advertisement mechanism that I've proposed here.\nIndependent of what guarantees the protocol offers, there's a bunch of\nstrategies that individual nodes can additionally take to limit potential\nlosses: starting with by soliciting small liquidity offers, shopping around\nfor the best rates, blacklisting IP addresses/node id's of unreliable\nnodes, using a ratcheting mechanism (start with a small liquidity request\nthat you close/rebalance upward as the incoming capacity is drained).\n\nConsidering incentives, keeping a high-traffic channel open should be worth\nmore in routing fees than the liquidity that you've provided. If the\nliquidity market acts rationally, it should price itself to reflect this\nreality and the risk of being laolu'd should remain fairly insignificant.\n\n\n> Regards,\n> ZmnSCPxj\n>\n> To my mind, this may become important.\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> Conclusion\n> =======================================\n> Allowing nodes to advertise liquidity paves the way for automated node\n> re-balancing. Advertised liquidity creates a market of inbound capacity\n> that any node can take advantage of, reducing the amount of out-of-band\n> negotiation needed to get the inbound capacity that you need.\n>\n>\n> Credit to Casey Rodamor for the initial idea.\n>\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181112/45e41973/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-12T09:58:08",
                "message_text_only": "Good morning lisa,\n\n> As you point out below, at the very least a liquidity providing node would get paid. Another thing worth considering is that the spec, as written, is merely a mechanism for advertising and receiving offers for dual funding. There are no rules about what offers you, as a liquidity advertising node, have to accept. A node operator has the flexibility to reject any offer above or below their stated fee rate, or if they don't relish the idea of funding a badly skewed channel. If you're worried about capital being tied up unnecessarily, you can reject offers without a sizeable input of their own.\n>\n> There are, however, scenarios where requests for badly skewed channels make sense. Imagine that you're a large vendor, such as Amazon. You're likely not going to ever need much outbound capacity, but you will be perpetually in the market for more inbound capacity.\n>\n> In fact, as a liquidity provider, I think that you'll probably be delighted to have an open channel with Amazon, as there's a good chance that channel will be highly utilized, which means more fee traffic for you, and a high probability that they'll be requesting more liquidity from you in the future, as the existing channel gets unbalanced.\n\nThis is correct and I have since changed my mind.  A true market would only impose that the market taker actually pay for the service.\n\n>> A counterpoint to this argument, however, is that if the fee for the liquidity is high enough, then it does not matter to you whether I use the 1.0 BTC or not: you have already been paid for it.\n>>\n>> This however brings up the other potential attack:\n>>\n>> 1.  I advertise that I have 1.0 BTC available for liquidity requests.\n>> 2.  You answer this advertisement, and pay me a good fee for this 1.0 BTC being locked into a channel.\n>> 3.  After the channel is opened, I immediately close it, having earned the fee for liquidity, without in fact delivering that liquidity.\n>>\n>> Perhaps we can modify channel commitment transactions for channels opened via liquidity requests, so that they have an `nSequence` that prevents them from being claimed for a month or so.  What do you think?\n>\n> At what point should a liquidity providing node (maker) be able to close the channel? Immediately is not very beneficial to either of you -- you both tied up your money for the time required to push through bitcoin txns through, plus you lose closing + opening fees. Stipulating a length of time isn't necessarily beneficial either -- if you've connected to a high volume payment channel, the liquidity you've provided will be used up rather quickly, rendering the channel itself pretty useless.\n\nPlease see the other thread regarding the proposed mechanism that I and Rene generated.\n\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001555.html\n\nIn this mechanism, only the liquidity provider is encumbered by the agreed-upon channel lifetime.\n\nIn particular, section \"Reduction of Licky Obligation\", I point out that if the merchant has received funds, then the money of the liquidity provider that is encumbered by this lifetime is reduced.\nThat is, the channel balance on the side of the liquidity provider is reduced due to the merchant receiving funds.\nI pointed out also, that this should be perfectly fine for the merchant, since the point of it is to receive payments, and this change in channel balance implies that the merchant has received payments.\n\nOnce the channel has saturated to the minimum receivable amount, only the channel reserve of the liquidity provider remains encumbered with the channel lifetime.\nIt would be quite fine for the liquidity provider to close the channel, as the locked funds are now only quite small.\n\n> Considering incentives, keeping a high-traffic channel open should be worth more in routing fees than the liquidity that you've provided. If the liquidity market acts rationally, it should price itself to reflect this reality and the risk of being laolu'd should remain fairly insignificant.\n\nThere are two sides of the laolu attack (I actually came up with both sides of the attack and wrote it on-list before the summit, but I suppose \"being laolued\" is easier to say than \"being ZmnSCPxjed\").\n\n1.  If the liquidity market values the routing fees more than the liquidity fees, such that liquidity fees are small, then I can attack this market by requesting capacity, paying a tiny liquidity fee, then shutting off my node and letting the liquidity provider close the channel after it realizes it will never earn routing fees from me.\n2.  If the liquidity market values the liquidity fees more than the routing fees, then I can attack this market by offering capacity, then closing the channel and re-offering my freed capacity to another customer.\n\nTo prevent one of the above attacks should be sufficient, since this will lead the market to value one class of fees more than the other, biased towards the attack that has been shut down.\n\nIt is impossible to prevent  the first attack, since it is impossible to distinguish between a node that was hit by lightning and destroyed utterly, and a node that is simply turned off to attack the liquidity market.\n\nHence, the proposal to impose a minimum channel lifetime, in order to prevent the second attack.  We expect the liquidity market to then settle to the protected side, i.e. liquidity providers will value liquidity fees higher than routing fees.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181112/1c91e3eb/attachment-0001.html>"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-11-08T07:02:01",
                "message_text_only": "> A node, via their node_announcement,\n\nMost implementations today will ignore node announcements from nodes that\ndon't have any channels, in order to maintain the smallest routing set\npossible (no zombies, etc). It seems for this to work, we would need to undo\nthis at a global scale to ensure these announcements propagate?\n\nAside from the incentives for leaches to arise that accept the fee then\ninsta close (they just drain the network and then no one uses this), I think\nthis is a dope idea in general! In the past, I've mulled over similar\nconstructions under a general umbrella of \"Channel Liquidity Markets\" (CLM),\nthough via extra-protocol negotiation.\n\n-- Laolu\n\n\nOn Wed, Nov 7, 2018 at 2:38 PM lisa neigut <niftynei at gmail.com> wrote:\n\n> Problem\n> ====================================\n> Currently it\u2019s difficult to reliably source inbound capacity for your\n> node. This is incredibly problematic for vendors and nodes hoping to setup\n> shop as a route facilitator. Most solutions at the moment require an\n> element of out of band negotiation in order to find other nodes that can\n> help with your capacity needs.\n>\n> While splicing and dual funding mechanisms will give some relief by\n> allowing for the initial negotiation to give the other node an opportunity\n> to put funds in either at channel open or after the fact, the problem of\n> finding channel liquidity is still left as an offline problem.\n>\n> Proposal\n> =====================================\n> To solve the liquidity discovery problem, I'd like to propose allowing\n> nodes to advertise initial liquidity matching. The goal of this proposal\n> would be to allow nodes to independently source inbound capacity from a\n> 'market' of advertised liquidity rates, as set by other nodes.\n>\n> A node, via their node_announcement, can advertise that they will match\n> liquidity and a fee rate that they will provide to any incoming\n> open_channel request that indicates requests it.\n>\n> `node_announcement`:\n> new feature flag: option_liquidity_provider\n> data:\n>  [4 liquidity_fee_proportional_millionths] (option_liquidity_provider) fee\n> charged per satoshi of liquidity added at channel open\n>  [4 liquidity_fee_base_msat] (option_liquidity_provider) base fee charged\n> for providing liquidity at channel open\n>\n> `open_channel`:\n> new feature flag (channel_flags): option_liquidity_buy [2nd least\n> significant bit]\n> push_msat: set to fee payment for requested liquidity\n> [8 liquidity_msat_request]: (option_liquidity_buy) amount of dual funding\n> requested at channel open\n>\n> `accept_channel`:\n> tbd. hinges on a dual funding proposal for how second node would send\n> information about their funding input.\n>\n> If a node cannot provide the liquidity requested in `open_channel`, it\n> must return an error.\n> If the amount listed in `push_msat` does not cover the amount of liquidity\n> provided, the liquidity provider node must return an error.\n>\n> Errata\n> ======================================\n> It's an open question as to whether or not a liquidity advertising node\n> should also include a maximum amount of liquidity that they will\n> match/provide. As currently proposed, the only way to discover if a node\n> can meet your liquidity requirement is by sending an open channel request.\n>\n> This proposal depends on dual funding being possible.\n>\n> Should a node be able to request more liquidity than they put into the\n> channel on their half? In the case of a vendor who wants inbound capacity,\n> capping the liquidity request allowed seems unnecessary.\n>\n> Conclusion\n> =======================================\n> Allowing nodes to advertise liquidity paves the way for automated node\n> re-balancing. Advertised liquidity creates a market of inbound capacity\n> that any node can take advantage of, reducing the amount of out-of-band\n> negotiation needed to get the inbound capacity that you need.\n>\n>\n> Credit to Casey Rodamor for the initial idea.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181108/fedb1500/attachment.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2018-11-08T22:39:54",
                "message_text_only": "On Thu, Nov 08, 2018 at 05:32:01PM +1030, Olaoluwa Osuntokun wrote:\n> > A node, via their node_announcement,\n> Most implementations today will ignore node announcements from nodes that\n> don't have any channels, in order to maintain the smallest routing set\n> possible (no zombies, etc). It seems for this to work, we would need to undo\n> this at a global scale to ensure these announcements propagate?\n\nHaving incoming capacity from a random node with no other channels doesn't\nseem useful though? (It's not useful for nodes that don't have incoming\ncapacity of their own, either)\n\nCheers,\naj"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-11-08T22:42:38",
                "message_text_only": "Was approaching more so from the angle of a node new node with no existing\nchannels seeking to bootstrap connections to the network.\n\n-- Sent from my Spaceship\n\nOn Fri, Nov 9, 2018, 9:10 AM Anthony Towns <aj at erisian.com.au wrote:\n\n> On Thu, Nov 08, 2018 at 05:32:01PM +1030, Olaoluwa Osuntokun wrote:\n> > > A node, via their node_announcement,\n> > Most implementations today will ignore node announcements from nodes that\n> > don't have any channels, in order to maintain the smallest routing set\n> > possible (no zombies, etc). It seems for this to work, we would need to\n> undo\n> > this at a global scale to ensure these announcements propagate?\n>\n> Having incoming capacity from a random node with no other channels doesn't\n> seem useful though? (It's not useful for nodes that don't have incoming\n> capacity of their own, either)\n>\n> Cheers,\n> aj\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181109/0f7898fc/attachment.html>"
            },
            {
                "author": "lisa neigut",
                "date": "2018-11-12T09:42:13",
                "message_text_only": "On Wed, Nov 7, 2018 at 11:02 PM Olaoluwa Osuntokun <laolu32 at gmail.com>\nwrote:\n\n> > A node, via their node_announcement,\n>\n> Most implementations today will ignore node announcements from nodes that\n> don't have any channels, in order to maintain the smallest routing set\n> possible (no zombies, etc). It seems for this to work, we would need to\n> undo\n> this at a global scale to ensure these announcements propagate?\n>\n\nRight on. I'm not too worried about this tbh; a new node on the network\ncould easily fix this by taking liquidity from another node that's already\noffering it, to create a few balanced channels to itself. This would a) put\nit on the map and b) make the liquidity that it's looking to offer more\nvaluable, as the other channels it's opened make it more likely to be\nrouted through.\n\n\n>\n> Aside from the incentives for leaches to arise that accept the fee then\n> insta close (they just drain the network and then no one uses this), I\n> think\n> this is a dope idea in general! In the past, I've mulled over similar\n> constructions under a general umbrella of \"Channel Liquidity Markets\"\n> (CLM),\n> though via extra-protocol negotiation.\n>\n> -- Laolu\n>\n>\n> On Wed, Nov 7, 2018 at 2:38 PM lisa neigut <niftynei at gmail.com> wrote:\n>\n>> Problem\n>> ====================================\n>> Currently it\u2019s difficult to reliably source inbound capacity for your\n>> node. This is incredibly problematic for vendors and nodes hoping to setup\n>> shop as a route facilitator. Most solutions at the moment require an\n>> element of out of band negotiation in order to find other nodes that can\n>> help with your capacity needs.\n>>\n>> While splicing and dual funding mechanisms will give some relief by\n>> allowing for the initial negotiation to give the other node an opportunity\n>> to put funds in either at channel open or after the fact, the problem of\n>> finding channel liquidity is still left as an offline problem.\n>>\n>> Proposal\n>> =====================================\n>> To solve the liquidity discovery problem, I'd like to propose allowing\n>> nodes to advertise initial liquidity matching. The goal of this proposal\n>> would be to allow nodes to independently source inbound capacity from a\n>> 'market' of advertised liquidity rates, as set by other nodes.\n>>\n>> A node, via their node_announcement, can advertise that they will match\n>> liquidity and a fee rate that they will provide to any incoming\n>> open_channel request that indicates requests it.\n>>\n>> `node_announcement`:\n>> new feature flag: option_liquidity_provider\n>> data:\n>>  [4 liquidity_fee_proportional_millionths] (option_liquidity_provider)\n>> fee charged per satoshi of liquidity added at channel open\n>>  [4 liquidity_fee_base_msat] (option_liquidity_provider) base fee charged\n>> for providing liquidity at channel open\n>>\n>> `open_channel`:\n>> new feature flag (channel_flags): option_liquidity_buy [2nd least\n>> significant bit]\n>> push_msat: set to fee payment for requested liquidity\n>> [8 liquidity_msat_request]: (option_liquidity_buy) amount of dual funding\n>> requested at channel open\n>>\n>> `accept_channel`:\n>> tbd. hinges on a dual funding proposal for how second node would send\n>> information about their funding input.\n>>\n>> If a node cannot provide the liquidity requested in `open_channel`, it\n>> must return an error.\n>> If the amount listed in `push_msat` does not cover the amount of\n>> liquidity provided, the liquidity provider node must return an error.\n>>\n>> Errata\n>> ======================================\n>> It's an open question as to whether or not a liquidity advertising node\n>> should also include a maximum amount of liquidity that they will\n>> match/provide. As currently proposed, the only way to discover if a node\n>> can meet your liquidity requirement is by sending an open channel request.\n>>\n>> This proposal depends on dual funding being possible.\n>>\n>> Should a node be able to request more liquidity than they put into the\n>> channel on their half? In the case of a vendor who wants inbound capacity,\n>> capping the liquidity request allowed seems unnecessary.\n>>\n>> Conclusion\n>> =======================================\n>> Allowing nodes to advertise liquidity paves the way for automated node\n>> re-balancing. Advertised liquidity creates a market of inbound capacity\n>> that any node can take advantage of, reducing the amount of out-of-band\n>> negotiation needed to get the inbound capacity that you need.\n>>\n>>\n>> Credit to Casey Rodamor for the initial idea.\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181112/f94d4806/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Proposal for Advertising Channel Liquidity",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Anthony Towns",
                "lisa neigut",
                "Jim Posen",
                "Olaoluwa Osuntokun",
                "ZmnSCPxj"
            ],
            "messages_count": 13,
            "total_messages_chars_count": 36502
        }
    },
    {
        "title": "[Lightning-dev] Walletless channel opens",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-07T22:30:12",
                "message_text_only": "Good morning list,\n\nThis topic is out of scope for the Lightning Development Summit 2018 as it requires SIGHASH_NOINPUT, but I thought it might be something to bring up to consider if it would be useful in the future.\n\nCurrently, every Lightning implementation has to have its own onchain wallet implementation.  This is because, the channel opening protocol requires a specific order in which transactions are signed and broadcast.  Specifically, the funding transaction must be signed and broadcast *after* the first commitment transaction pair is signed and exchanged.\n\nHowever, SIGHASH_NOINPUT would allow Lightning implementations to be \"walletless\".  What happens is that the first pair of commitment transactions will have to be signed with SIGHASH_NOINPUT, then the funding transaction can be created using a normal wallet.  Then when the transaction paying the funding transaction output has been broadcast, succeeding commitment transactions may be created without SIGHASH_NOINPUT.\n\nI have discussed this before on bitcoin-dev: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-May/015925.html\n\nThe primary use case is to reduce the number of transactions needed when the user prefers to use a specific wallet implementation that may have features unavailable to the Lightning implementation.  For instance, the onchain wallet may have privacy features (integrated CoinSwap and CoinJoin, distinction between traceable/cleaned coins, etc.).  A secondary use case would be to reduce implementation complexity for Lightning implementations, as there would only be needed to trace status (unconfirmed/confirmed, spent/unspent)  specific transaction outputs, not scan the blockchain for specific `scriptPubKey`.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181107/f0969ef5/attachment.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2018-11-10T21:40:30",
                "message_text_only": "On Wed, Nov 07, 2018 at 10:30:12PM +0000, ZmnSCPxj via Lightning-dev wrote:\n> However, SIGHASH_NOINPUT would allow Lightning implementations to be \"walletless\".\n\nMaybe I'm misunderstanding, but wouldn't this require comitting to the\ntransaction fees for the various delayed-broadcast transactions (e.g.\nthe Eltoo trigger transaction) because, without a wallet, you can't RBF\nadditional fees by adding additional inputs?\n\nHaving to set the final fees during setup for a channel that could be\nopen for weeks or months, but which would need to be closed within a\nrelatively short window to prevent fraud, could mean committing to an\nundesireable high feerate.\n\n-Dave\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181110/60768f04/attachment.sig>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-12T00:39:56",
                "message_text_only": "Good morning Dave,\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Sunday, November 11, 2018 7:10 AM, David A. Harding <dave at dtrt.org> wrote:\n\n> On Wed, Nov 07, 2018 at 10:30:12PM +0000, ZmnSCPxj via Lightning-dev wrote:\n>\n> > However, SIGHASH_NOINPUT would allow Lightning implementations to be \"walletless\".\n>\n> Maybe I'm misunderstanding, but wouldn't this require comitting to the\n> transaction fees for the various delayed-broadcast transactions (e.g.\n> the Eltoo trigger transaction) because, without a wallet, you can't RBF\n> additional fees by adding additional inputs?\n\nThis is quite correct.\nI suppose, what we should consider instead, is better ways to integrate onchain wallets with protocols that delay between signing and broadcast.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Walletless channel opens",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "David A. Harding",
                "ZmnSCPxj"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 3663
        }
    },
    {
        "title": "[Lightning-dev] Explicit Fee Management Proposal",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-09T00:06:53",
                "message_text_only": "Good morning list,\n\nFor extra bikeshedding opportunities, I present below, a proposal for explicit management of commitment transaction and mutual close transaction fees.\n\nBy this thought, \"explicit management\", I want to convey, that the parties have more control over fees.\n\n### Additional Variables\n\nNodes will now additionally track for each channel:\n\n* `from_local_fee_msat` - 64-bit unsigned integer. The amount of fees contributed by this node.\n* `from_remote_fee_msat` - 64-bit unsigned integer. The amount of fees contributed by this node\n\nIf the node is the initiator of the channel, its `from_local_fee_msat` contains the fee decided during channel opening, and its `from_remote_fee_msat` is 0.  If it is not the initiator, then the reverse is true.\n\n#### Rationale\n\nAlthough onchain fees are measured in satoshi, the above variables are in millisatoshi in order to allow finer proportional deductions when reducing fees.\n\n### Additional channel state updates\n\nThese update messages behave similarly to `offer_htlc`.  Multiple of these messages may be sent, and then `commitment_signed` puts them into effect for the commitment transaction.\n\n#### The `add_fees` message\n\n1. type - TBD\n2. data:\n    * [`8`: `short_channel_id`]\n    * [`8` : `additional_donated_fee_sat`]\n\n`additional_donated_fee_sat` is the amount of fees that the sending node proposes to donate as fees, in order for the commitment transaction to be confirmed in a timely manner.\nThe donated fee is deducted from the sender funds of the channel.\n\nMultiple `add_fees` message add up their effects.\n\nThe sender:\n\n* MUST NOT offer a fee donation that would put their balance below the channel reserve.\n* MAY donate their entire balance, minus the channel reserve.\n\nBoth nodes:\n\n* MUST convert the satoshi units in this message to millisatoshis before updating the `from_local_fee_msat` and `from_remote_fee_msat` when a commitment is signed.\n\n#### The `propose_deduct_fees` message\n\n1. type - TBD\n2. data:\n    * [`8`: `short_channel_id`]\n    * [`8` : `proposed_deducted_fee_sat`]\n\n`proposed_deducted_fee_sat` is the amount by which the total fees will be deducted.\n\nThis message starts a sub-protocol, where other channel state update messages for the channel are disallowed and will trigger an `error` message with code `TBD`.\n\nThe sub-protocol involves `propose_deduct_fees` messages, and is ended once both sides send `accept_deduct_fees`.\n\nThe lowest `proposed_deducted_fee_sat` before the `accept_deduct_fees` is selected.\nThus each node has the ability to veto a deduction by simply sending a 0 `proposed_deducted_fee_sat`.\n\n#### The `accept_deduct_fees` message\n\n1. type - TBD\n2. data:\n    * [`8`: `short_channel_id`]\n    * [`8` : `min_proposed_deducted_fee_sat`]\n\nOnce both nodes have sent this `accept_deduct_fees` for a channel with the same `min_proposed_deducted_fee_sat`, then both nodes have come to an agreement on how much to deduct as fees.\n\nThe deduction is split between the two nodes in proportion to how much each one donated to the fees.\nThus, to compute how much will be deducted from `from_local_fee_msat`, the division below is rounded down:\n\n    deduct_from_local_fee_msat = 1000 * min_proposed_deducted_fee_sat * from_local_fee_msat / (from_local_fee_msat + from_remote_fee_msat)\n\nThe receiver:\n* SHOULD send `propose_deduct_fees` with the lowest deducted fee, if the `min_proposed_deducted_fee_sat` does not match what it believes to have seen as the lowest.\n    * this may occur if messages get sent at about the same time.\n    * MAY fail the channel if this occurs too often.\n* MAY fail the channel if it considers the fee deduction to be too low to be reasonable.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181109/24d578d5/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Explicit Fee Management Proposal",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "ZmnSCPxj"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3873
        }
    },
    {
        "title": "[Lightning-dev] Link-level payment splitting via intermediary rendezvous nodes",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-09T05:46:36",
                "message_text_only": "Good morning list,\n\nAs was discussed directly in summit, we accept link-lvel payment splitting (scid is not binding), and provisionally accept rendez-vous routing.\n\nIt strikes me, that even if your node has only a single channel to the next node (c-lightning), it is possible, to still perform link-level payment splitting/re-routing.\n\nFor instance, consider this below graph:\n\n      E<---D--->C<---B\n           ^  /\n           | /\n           |L\n           A\n\nIn the above, B requests a route from B->C->D->E.\n\nHowever, C cannot send to D, since the channel direction is saturated in favor of D.\n\nAlternately, C can route to D via A instead.  It holds the (encrypted) route from D to E.  It can take that sub-route and treat it as a partial route-to-payee under rendez-vous routing, as long as node A supports rendez-vous routing.\n\nThis can allow re-routing or payment splitting over multiple hops.\n\nEven though C does not know the number of remaining hops between D and the destination, its alternative is to earn nothing anyway as its only alternative is to fail the routing.  At least with this, there is a chance it can succeed to send the payment to the final destination.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181109/46387652/attachment-0001.html>"
            },
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2018-11-09T08:07:51",
                "message_text_only": "Neat! I think this is similar to what has been briefly discussed earlier\nabout hybrid packet-switched/circuit-switched payment routing.\n\nB doesn't have to care about how the payment gets from C to D, but she\nknows it must go through D, keeping privacy intact. This would be exactly\nequivalent to how TOR works today I would think.\n\nC must also make sure the detour route stays within the fee limit of course.\n\nCheers,\nJohan\n\nOn Fri, Nov 9, 2018 at 7:02 AM ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning list,\n>\n> As was discussed directly in summit, we accept link-lvel payment splitting\n> (scid is not binding), and provisionally accept rendez-vous routing.\n>\n> It strikes me, that even if your node has only a single channel to the\n> next node (c-lightning), it is possible, to still perform link-level\n> payment splitting/re-routing.\n>\n> For instance, consider this below graph:\n>\n>       E<---D--->C<---B\n>            ^  /\n>            | /\n>            |L\n>            A\n>\n> In the above, B requests a route from B->C->D->E.\n>\n> However, C cannot send to D, since the channel direction is saturated in\n> favor of D.\n>\n> Alternately, C can route to D via A instead.  It holds the (encrypted)\n> route from D to E.  It can take that sub-route and treat it as a partial\n> route-to-payee under rendez-vous routing, as long as node A supports\n> rendez-vous routing.\n>\n> This can allow re-routing or payment splitting over multiple hops.\n>\n> Even though C does not know the number of remaining hops between D and the\n> destination, its alternative is to earn nothing anyway as its only\n> alternative is to fail the routing.  At least with this, there is a chance\n> it can succeed to send the payment to the final destination.\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181109/813c32fc/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-09T11:32:27",
                "message_text_only": "Good morning Johan,\n\n> C must also make sure the detour route stays within the fee limit of course.\n\nThis is indeed quite correct.  Contrariwise, if the detour route charges a fee that is even just 0.001 satoshi lower than the fee that C would charge, then it would still be rational to make this attempt: there is a nonzero change to earn 0.001 satoshi, whereas the alternative (fail the route) earns C 0 fees.\n\nAnother issue, is that the by inserting the switch-ephemeral-keys hop packet, a hop packet at the end may be pushed off, and C cannot know this.  However, the same argument applies: the alternative is earning 0 fees.\n\nChristian Decker pointed out that the D->C->A cycle could be rebalanced so that the C<->D link could pass the payment through.  However, this has the slight disadvantage.  If the route actually terminates to a payee further off at F, and it fails between F and E, then C has already paid for the rebalancing.  Using this technique, C neither earns nor loses money.\n\nThis also increases the anonymity set, of rendez-vous routing.  A rendez-vous supporting node may be used, not for rendez-vous, but instead, this link-level payment rerouting.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181109/5c3ff072/attachment.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-11-13T03:45:52",
                "message_text_only": "Great proposal ZmnSCPxj, but I think I need to raise a small issue with\nit. While writing up the proposal for rendez-vous I came across a\nproblem with the mechanism I described during the spec meeting: the\npadding at the rendez-vous point would usually zero-padded and then\nencrypted in one go with the shared secret that was generated from the\nprevious ephemeral key (i.e., the one before the switch). That ephemeral\nkey is not known to the recipient (barring additional rounds of\ncommunication) so the recipient would be unable to compute the correct\nMACs. There are a number of solutions to this, basically setting the\npadding to something that the recipient could know when generating its\nhalf onion.\n\nMy current favorite goes like this:\n\n 1. Rendez-vous RV receives an onion, performs ECDH like normal to get\n    the shared secret, decrypts its payload, simultaneously encrypts\n    the padding.\n 2. It extracts its per-hop payload and shifts the entire packet over\n    (shift its payload out and the newly generated padding in)\n 3. It then notices that it should perform an ephemeral key switch, now\n    deviating from the normal protocol (which would just be to generate\n    the new ephemeral key, serialize and forward)\n    3.1. It zero-fills the padding that it just added (so we are in a\n         state that the recipient knew when generating its partial onion\n    3.2 It performs ECDH with the switched in ephemeral key to get a new\n        shared secret that which is then used to unwrap one additional\n        layer of encryption, and most importantly encrypt the padding so\n        the next hop doesn't see the zero-filled padding.\n    3.3 Only then will it generate the new ephemeral key for the next\n        hop, based on the switched in ephemeral key and the newly\n        generated shared secret, serialize the packet and forward it.\n\nThis has the advantage of reusing all the existing machinery but\nassembling it a bit differently, by adding a little detour when\ngenerating the next onion. It involves one additional ECDH at the\nrendez-vous, one ChaCha20 encryption and one scalar multiplication to\ngenerate the next ephemeral keys. It does not need more space than the\nsingle ephemeral key in the per-hop payload.\n\nAnd now for the reason that I write this as a reply to your post: with\nthis scheme it is not possible for C to find an ephemeral key that would\nend up identical to the one that D would require to decrypt the onion\ncorrectly. This would not be an issue if D is informed about this split\nand would basically accept whatever it gets, but that kind of defeats\nthe transparency that you were going for with your proposal.\n\nI'm open for other proposals but I currently can't think of a way to\nmake sure that a) the recipient can deterministically generate the same\npadding that RV will generate, and b) hide the fact that RV was indeed a\nrendez-vous point (e.g., by leaving the padding be a well known\nconstant).\n\nSorry for this problem, I had a mental off-by-one at the meeting that I\nhadn't considered, the solution should work, but it makes this kind of\nthings a bit harder.\n\nCheers,\nChristian\n   \n\nZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\nwrites:\n> Good morning list,\n>\n> As was discussed directly in summit, we accept link-lvel payment splitting (scid is not binding), and provisionally accept rendez-vous routing.\n>\n> It strikes me, that even if your node has only a single channel to the next node (c-lightning), it is possible, to still perform link-level payment splitting/re-routing.\n>\n> For instance, consider this below graph:\n>\n>       E<---D--->C<---B\n>            ^  /\n>            | /\n>            |L\n>            A\n>\n> In the above, B requests a route from B->C->D->E.\n>\n> However, C cannot send to D, since the channel direction is saturated in favor of D.\n>\n> Alternately, C can route to D via A instead.  It holds the (encrypted) route from D to E.  It can take that sub-route and treat it as a partial route-to-payee under rendez-vous routing, as long as node A supports rendez-vous routing.\n>\n> This can allow re-routing or payment splitting over multiple hops.\n>\n> Even though C does not know the number of remaining hops between D and the destination, its alternative is to earn nothing anyway as its only alternative is to fail the routing.  At least with this, there is a chance it can succeed to send the payment to the final destination.\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-13T04:46:53",
                "message_text_only": "Good morning Christian,\n\nI am nowhere near a mathematician, thus, cannot countercheck your expertise here (and cannot give a counterproposal thusly).\n\nBut I want to point out the below scenarios:\n\n1.  C is the payer.  He is in contact with an unknown payee (who in reality is E).  E provides the onion-wrapped route D->E with ephemeral key and other data necessary, as well as informing C that D is the rendez-vous point.  Then C creates a route from itself to D (via channel C->D or via C->A->D).\n\n2.  B is the payer.  He knows the entire route B->C->D->E and knows that payee is C.  Unfortunately the C<->D channel is low capacity or down or etc etc.  At C, B has provided the onion-wrapped route D->E with ephemeral key and other data necessary, as well as informing to C that D is the next node.  Then C either pays via C->D or via C->A->D.\n\nEven if there is an off-by-one error in our thinking about rendez-vous nodes, could it not be compensated also by an off-by-one in the link-level payment splitting via intermediary rendez-vous node?\nIn short, D is the one that switches keys instead of A.\n\nThe operation of processing a hop would be:\n\n1.  Unwrap the onion with current ephemeral key.\n2.  Dispatch based on realm byte.\n2.1.  If realm byte 0:\n2.1.1.  Normal routing behavior, extract HMAC, etc etc\n2.2.  If realm byte 2 \"switch ephemeral keys\":\n2.2.1.  Set current ephemeral key to bytes 1 -> 32 of packet.\n2.2.2.  Shift onion by one hop packet.\n2.2.3.  Goto 1.\n\nWould that not work?\n(I am being naive here, as I am not a mathist and I did not understand half what you wrote, sorry)\n\nThen at C, we have the onion from D->E, we also know the next ephemeral key to use (we can derive it since we would pass it to D anyway).\nIt rightshifts the onion by one, storing the next ephemeral key to the new hop it just allocated.\nThen it encrypts the onion using a new ephemeral key that it will use to generate the D<-A<-C part of the onion.\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Tuesday, November 13, 2018 11:45 AM, Christian Decker <decker.christian at gmail.com> wrote:\n\n> Great proposal ZmnSCPxj, but I think I need to raise a small issue with\n> it. While writing up the proposal for rendez-vous I came across a\n> problem with the mechanism I described during the spec meeting: the\n> padding at the rendez-vous point would usually zero-padded and then\n> encrypted in one go with the shared secret that was generated from the\n> previous ephemeral key (i.e., the one before the switch). That ephemeral\n> key is not known to the recipient (barring additional rounds of\n> communication) so the recipient would be unable to compute the correct\n> MACs. There are a number of solutions to this, basically setting the\n> padding to something that the recipient could know when generating its\n> half onion.\n>\n> My current favorite goes like this:\n>\n> 1.  Rendez-vous RV receives an onion, performs ECDH like normal to get\n>     the shared secret, decrypts its payload, simultaneously encrypts\n>     the padding.\n>\n> 2.  It extracts its per-hop payload and shifts the entire packet over\n>     (shift its payload out and the newly generated padding in)\n>\n> 3.  It then notices that it should perform an ephemeral key switch, now\n>     deviating from the normal protocol (which would just be to generate\n>     the new ephemeral key, serialize and forward)\n>     3.1. It zero-fills the padding that it just added (so we are in a\n>     state that the recipient knew when generating its partial onion\n>     3.2 It performs ECDH with the switched in ephemeral key to get a new\n>     shared secret that which is then used to unwrap one additional\n>     layer of encryption, and most importantly encrypt the padding so\n>     the next hop doesn't see the zero-filled padding.\n>     3.3 Only then will it generate the new ephemeral key for the next\n>     hop, based on the switched in ephemeral key and the newly\n>     generated shared secret, serialize the packet and forward it.\n>\n>     This has the advantage of reusing all the existing machinery but\n>     assembling it a bit differently, by adding a little detour when\n>     generating the next onion. It involves one additional ECDH at the\n>     rendez-vous, one ChaCha20 encryption and one scalar multiplication to\n>     generate the next ephemeral keys. It does not need more space than the\n>     single ephemeral key in the per-hop payload.\n>\n>     And now for the reason that I write this as a reply to your post: with\n>     this scheme it is not possible for C to find an ephemeral key that would\n>     end up identical to the one that D would require to decrypt the onion\n>     correctly. This would not be an issue if D is informed about this split\n>     and would basically accept whatever it gets, but that kind of defeats\n>     the transparency that you were going for with your proposal.\n>\n>     I'm open for other proposals but I currently can't think of a way to\n>     make sure that a) the recipient can deterministically generate the same\n>     padding that RV will generate, and b) hide the fact that RV was indeed a\n>     rendez-vous point (e.g., by leaving the padding be a well known\n>     constant).\n>\n>     Sorry for this problem, I had a mental off-by-one at the meeting that I\n>     hadn't considered, the solution should work, but it makes this kind of\n>     things a bit harder.\n>\n>     Cheers,\n>     Christian\n>\n>     ZmnSCPxj via Lightning-dev lightning-dev at lists.linuxfoundation.org\n>\n>\n> writes:\n>\n> > Good morning list,\n> > As was discussed directly in summit, we accept link-lvel payment splitting (scid is not binding), and provisionally accept rendez-vous routing.\n> > It strikes me, that even if your node has only a single channel to the next node (c-lightning), it is possible, to still perform link-level payment splitting/re-routing.\n> > For instance, consider this below graph:\n> >\n> >       E<---D--->C<---B\n> >            ^  /\n> >            | /\n> >            |L\n> >            A\n> >\n> >\n> > In the above, B requests a route from B->C->D->E.\n> > However, C cannot send to D, since the channel direction is saturated in favor of D.\n> > Alternately, C can route to D via A instead. It holds the (encrypted) route from D to E. It can take that sub-route and treat it as a partial route-to-payee under rendez-vous routing, as long as node A supports rendez-vous routing.\n> > This can allow re-routing or payment splitting over multiple hops.\n> > Even though C does not know the number of remaining hops between D and the destination, its alternative is to earn nothing anyway as its only alternative is to fail the routing. At least with this, there is a chance it can succeed to send the payment to the final destination.\n> > Regards,\n> > ZmnSCPxj\n> >\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Conner Fromknecht",
                "date": "2018-11-13T20:21:28",
                "message_text_only": "Good morning all,\n\nTaking a step back\u2014even if key switching can be done mathematically, it seems\ndubious that we would want to introduce re-routing or rendezvous routing in this\nmanner. If the example provided _could_ be done, it would directly violate the\nwrap-resistance property of the ideal onion routing scheme defined in [1]. This\nproperty is proven for Sphinx in section 4.3 of [2]. Schemes like HORNET [3]\nsupport rendezvous routing and are formally proven in this model. Seems this\nwould be the obvious path forward, given that we've already done a considerable\namount of work towards implementing HORNET via Sphinx.\n\nCheers,\nConner\n\n[1] A Formal Treatment of Onion Routing:\nhttps://www.iacr.org/cryptodb/archive/2005/CRYPTO/1091/1091.pdf\n[2] Sphinx: https://cypherpunks.ca/~iang/pubs/Sphinx_Oakland09.pdf\n[3] HORNET: https://arxiv.org/pdf/1507.05724.pdf\nOn Mon, Nov 12, 2018 at 8:47 PM ZmnSCPxj via Lightning-dev\n<lightning-dev at lists.linuxfoundation.org> wrote:\n>\n> Good morning Christian,\n>\n> I am nowhere near a mathematician, thus, cannot countercheck your expertise here (and cannot give a counterproposal thusly).\n>\n> But I want to point out the below scenarios:\n>\n> 1.  C is the payer.  He is in contact with an unknown payee (who in reality is E).  E provides the onion-wrapped route D->E with ephemeral key and other data necessary, as well as informing C that D is the rendez-vous point.  Then C creates a route from itself to D (via channel C->D or via C->A->D).\n>\n> 2.  B is the payer.  He knows the entire route B->C->D->E and knows that payee is C.  Unfortunately the C<->D channel is low capacity or down or etc etc.  At C, B has provided the onion-wrapped route D->E with ephemeral key and other data necessary, as well as informing to C that D is the next node.  Then C either pays via C->D or via C->A->D.\n>\n> Even if there is an off-by-one error in our thinking about rendez-vous nodes, could it not be compensated also by an off-by-one in the link-level payment splitting via intermediary rendez-vous node?\n> In short, D is the one that switches keys instead of A.\n>\n> The operation of processing a hop would be:\n>\n> 1.  Unwrap the onion with current ephemeral key.\n> 2.  Dispatch based on realm byte.\n> 2.1.  If realm byte 0:\n> 2.1.1.  Normal routing behavior, extract HMAC, etc etc\n> 2.2.  If realm byte 2 \"switch ephemeral keys\":\n> 2.2.1.  Set current ephemeral key to bytes 1 -> 32 of packet.\n> 2.2.2.  Shift onion by one hop packet.\n> 2.2.3.  Goto 1.\n>\n> Would that not work?\n> (I am being naive here, as I am not a mathist and I did not understand half what you wrote, sorry)\n>\n> Then at C, we have the onion from D->E, we also know the next ephemeral key to use (we can derive it since we would pass it to D anyway).\n> It rightshifts the onion by one, storing the next ephemeral key to the new hop it just allocated.\n> Then it encrypts the onion using a new ephemeral key that it will use to generate the D<-A<-C part of the onion.\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> Sent with ProtonMail Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Tuesday, November 13, 2018 11:45 AM, Christian Decker <decker.christian at gmail.com> wrote:\n>\n> > Great proposal ZmnSCPxj, but I think I need to raise a small issue with\n> > it. While writing up the proposal for rendez-vous I came across a\n> > problem with the mechanism I described during the spec meeting: the\n> > padding at the rendez-vous point would usually zero-padded and then\n> > encrypted in one go with the shared secret that was generated from the\n> > previous ephemeral key (i.e., the one before the switch). That ephemeral\n> > key is not known to the recipient (barring additional rounds of\n> > communication) so the recipient would be unable to compute the correct\n> > MACs. There are a number of solutions to this, basically setting the\n> > padding to something that the recipient could know when generating its\n> > half onion.\n> >\n> > My current favorite goes like this:\n> >\n> > 1.  Rendez-vous RV receives an onion, performs ECDH like normal to get\n> >     the shared secret, decrypts its payload, simultaneously encrypts\n> >     the padding.\n> >\n> > 2.  It extracts its per-hop payload and shifts the entire packet over\n> >     (shift its payload out and the newly generated padding in)\n> >\n> > 3.  It then notices that it should perform an ephemeral key switch, now\n> >     deviating from the normal protocol (which would just be to generate\n> >     the new ephemeral key, serialize and forward)\n> >     3.1. It zero-fills the padding that it just added (so we are in a\n> >     state that the recipient knew when generating its partial onion\n> >     3.2 It performs ECDH with the switched in ephemeral key to get a new\n> >     shared secret that which is then used to unwrap one additional\n> >     layer of encryption, and most importantly encrypt the padding so\n> >     the next hop doesn't see the zero-filled padding.\n> >     3.3 Only then will it generate the new ephemeral key for the next\n> >     hop, based on the switched in ephemeral key and the newly\n> >     generated shared secret, serialize the packet and forward it.\n> >\n> >     This has the advantage of reusing all the existing machinery but\n> >     assembling it a bit differently, by adding a little detour when\n> >     generating the next onion. It involves one additional ECDH at the\n> >     rendez-vous, one ChaCha20 encryption and one scalar multiplication to\n> >     generate the next ephemeral keys. It does not need more space than the\n> >     single ephemeral key in the per-hop payload.\n> >\n> >     And now for the reason that I write this as a reply to your post: with\n> >     this scheme it is not possible for C to find an ephemeral key that would\n> >     end up identical to the one that D would require to decrypt the onion\n> >     correctly. This would not be an issue if D is informed about this split\n> >     and would basically accept whatever it gets, but that kind of defeats\n> >     the transparency that you were going for with your proposal.\n> >\n> >     I'm open for other proposals but I currently can't think of a way to\n> >     make sure that a) the recipient can deterministically generate the same\n> >     padding that RV will generate, and b) hide the fact that RV was indeed a\n> >     rendez-vous point (e.g., by leaving the padding be a well known\n> >     constant).\n> >\n> >     Sorry for this problem, I had a mental off-by-one at the meeting that I\n> >     hadn't considered, the solution should work, but it makes this kind of\n> >     things a bit harder.\n> >\n> >     Cheers,\n> >     Christian\n> >\n> >     ZmnSCPxj via Lightning-dev lightning-dev at lists.linuxfoundation.org\n> >\n> >\n> > writes:\n> >\n> > > Good morning list,\n> > > As was discussed directly in summit, we accept link-lvel payment splitting (scid is not binding), and provisionally accept rendez-vous routing.\n> > > It strikes me, that even if your node has only a single channel to the next node (c-lightning), it is possible, to still perform link-level payment splitting/re-routing.\n> > > For instance, consider this below graph:\n> > >\n> > >       E<---D--->C<---B\n> > >            ^  /\n> > >            | /\n> > >            |L\n> > >            A\n> > >\n> > >\n> > > In the above, B requests a route from B->C->D->E.\n> > > However, C cannot send to D, since the channel direction is saturated in favor of D.\n> > > Alternately, C can route to D via A instead. It holds the (encrypted) route from D to E. It can take that sub-route and treat it as a partial route-to-payee under rendez-vous routing, as long as node A supports rendez-vous routing.\n> > > This can allow re-routing or payment splitting over multiple hops.\n> > > Even though C does not know the number of remaining hops between D and the destination, its alternative is to earn nothing anyway as its only alternative is to fail the routing. At least with this, there is a chance it can succeed to send the payment to the final destination.\n> > > Regards,\n> > > ZmnSCPxj\n> > >\n> > > Lightning-dev mailing list\n> > > Lightning-dev at lists.linuxfoundation.org\n> > > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Christian Decker",
                "date": "2018-11-14T11:40:46",
                "message_text_only": "Hi Conner,\n\nthanks for the pointers, looking forward to reading up on the\nwrap resistance. I don't quite follow if you're against the\nre-wrapping for spontaneous re-routing, or the entire rendez-vous\nconstruction we came up with in Australia. If it's the latter, do\nyou have an alternative construction that we might look at?\nHornet requires the onion-in-onion initial sphinx setup IIRC\nwhich is pretty much what we came up with here (with the\nexception that we manage to have the second onion be hidden in\nthe first one's header instead of the payload).\n\nCheers,\nChristian\n\nOn Tue, Nov 13, 2018 at 9:21 PM Conner Fromknecht\n<conner at lightning.engineering> wrote:\n\n> Good morning all,\n>\n> Taking a step back\u2014even if key switching can be done mathematically, it\n> seems\n> dubious that we would want to introduce re-routing or rendezvous routing\n> in this\n> manner. If the example provided _could_ be done, it would directly violate\n> the\n> wrap-resistance property of the ideal onion routing scheme defined in [1].\n> This\n> property is proven for Sphinx in section 4.3 of [2]. Schemes like HORNET\n> [3]\n> support rendezvous routing and are formally proven in this model. Seems\n> this\n> would be the obvious path forward, given that we've already done a\n> considerable\n> amount of work towards implementing HORNET via Sphinx.\n>\n> Cheers,\n> Conner\n>\n> [1] A Formal Treatment of Onion Routing:\n> https://www.iacr.org/cryptodb/archive/2005/CRYPTO/1091/1091.pdf\n> [2] Sphinx: https://cypherpunks.ca/~iang/pubs/Sphinx_Oakland09.pdf\n> [3] HORNET: https://arxiv.org/pdf/1507.05724.pdf\n> On Mon, Nov 12, 2018 at 8:47 PM ZmnSCPxj via Lightning-dev\n> <lightning-dev at lists.linuxfoundation.org> wrote:\n> >\n> > Good morning Christian,\n> >\n> > I am nowhere near a mathematician, thus, cannot countercheck your\n> expertise here (and cannot give a counterproposal thusly).\n> >\n> > But I want to point out the below scenarios:\n> >\n> > 1.  C is the payer.  He is in contact with an unknown payee (who in\n> reality is E).  E provides the onion-wrapped route D->E with ephemeral key\n> and other data necessary, as well as informing C that D is the rendez-vous\n> point.  Then C creates a route from itself to D (via channel C->D or via\n> C->A->D).\n> >\n> > 2.  B is the payer.  He knows the entire route B->C->D->E and knows that\n> payee is C.  Unfortunately the C<->D channel is low capacity or down or etc\n> etc.  At C, B has provided the onion-wrapped route D->E with ephemeral key\n> and other data necessary, as well as informing to C that D is the next\n> node.  Then C either pays via C->D or via C->A->D.\n> >\n> > Even if there is an off-by-one error in our thinking about rendez-vous\n> nodes, could it not be compensated also by an off-by-one in the link-level\n> payment splitting via intermediary rendez-vous node?\n> > In short, D is the one that switches keys instead of A.\n> >\n> > The operation of processing a hop would be:\n> >\n> > 1.  Unwrap the onion with current ephemeral key.\n> > 2.  Dispatch based on realm byte.\n> > 2.1.  If realm byte 0:\n> > 2.1.1.  Normal routing behavior, extract HMAC, etc etc\n> > 2.2.  If realm byte 2 \"switch ephemeral keys\":\n> > 2.2.1.  Set current ephemeral key to bytes 1 -> 32 of packet.\n> > 2.2.2.  Shift onion by one hop packet.\n> > 2.2.3.  Goto 1.\n> >\n> > Would that not work?\n> > (I am being naive here, as I am not a mathist and I did not understand\n> half what you wrote, sorry)\n> >\n> > Then at C, we have the onion from D->E, we also know the next ephemeral\n> key to use (we can derive it since we would pass it to D anyway).\n> > It rightshifts the onion by one, storing the next ephemeral key to the\n> new hop it just allocated.\n> > Then it encrypts the onion using a new ephemeral key that it will use to\n> generate the D<-A<-C part of the onion.\n> >\n> > Regards,\n> > ZmnSCPxj\n> >\n> >\n> > Sent with ProtonMail Secure Email.\n> >\n> > \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> > On Tuesday, November 13, 2018 11:45 AM, Christian Decker <\n> decker.christian at gmail.com> wrote:\n> >\n> > > Great proposal ZmnSCPxj, but I think I need to raise a small issue with\n> > > it. While writing up the proposal for rendez-vous I came across a\n> > > problem with the mechanism I described during the spec meeting: the\n> > > padding at the rendez-vous point would usually zero-padded and then\n> > > encrypted in one go with the shared secret that was generated from the\n> > > previous ephemeral key (i.e., the one before the switch). That\n> ephemeral\n> > > key is not known to the recipient (barring additional rounds of\n> > > communication) so the recipient would be unable to compute the correct\n> > > MACs. There are a number of solutions to this, basically setting the\n> > > padding to something that the recipient could know when generating its\n> > > half onion.\n> > >\n> > > My current favorite goes like this:\n> > >\n> > > 1.  Rendez-vous RV receives an onion, performs ECDH like normal to get\n> > >     the shared secret, decrypts its payload, simultaneously encrypts\n> > >     the padding.\n> > >\n> > > 2.  It extracts its per-hop payload and shifts the entire packet over\n> > >     (shift its payload out and the newly generated padding in)\n> > >\n> > > 3.  It then notices that it should perform an ephemeral key switch, now\n> > >     deviating from the normal protocol (which would just be to generate\n> > >     the new ephemeral key, serialize and forward)\n> > >     3.1. It zero-fills the padding that it just added (so we are in a\n> > >     state that the recipient knew when generating its partial onion\n> > >     3.2 It performs ECDH with the switched in ephemeral key to get a\n> new\n> > >     shared secret that which is then used to unwrap one additional\n> > >     layer of encryption, and most importantly encrypt the padding so\n> > >     the next hop doesn't see the zero-filled padding.\n> > >     3.3 Only then will it generate the new ephemeral key for the next\n> > >     hop, based on the switched in ephemeral key and the newly\n> > >     generated shared secret, serialize the packet and forward it.\n> > >\n> > >     This has the advantage of reusing all the existing machinery but\n> > >     assembling it a bit differently, by adding a little detour when\n> > >     generating the next onion. It involves one additional ECDH at the\n> > >     rendez-vous, one ChaCha20 encryption and one scalar multiplication\n> to\n> > >     generate the next ephemeral keys. It does not need more space than\n> the\n> > >     single ephemeral key in the per-hop payload.\n> > >\n> > >     And now for the reason that I write this as a reply to your post:\n> with\n> > >     this scheme it is not possible for C to find an ephemeral key that\n> would\n> > >     end up identical to the one that D would require to decrypt the\n> onion\n> > >     correctly. This would not be an issue if D is informed about this\n> split\n> > >     and would basically accept whatever it gets, but that kind of\n> defeats\n> > >     the transparency that you were going for with your proposal.\n> > >\n> > >     I'm open for other proposals but I currently can't think of a way\n> to\n> > >     make sure that a) the recipient can deterministically generate the\n> same\n> > >     padding that RV will generate, and b) hide the fact that RV was\n> indeed a\n> > >     rendez-vous point (e.g., by leaving the padding be a well known\n> > >     constant).\n> > >\n> > >     Sorry for this problem, I had a mental off-by-one at the meeting\n> that I\n> > >     hadn't considered, the solution should work, but it makes this\n> kind of\n> > >     things a bit harder.\n> > >\n> > >     Cheers,\n> > >     Christian\n> > >\n> > >     ZmnSCPxj via Lightning-dev lightning-dev at lists.linuxfoundation.org\n> > >\n> > >\n> > > writes:\n> > >\n> > > > Good morning list,\n> > > > As was discussed directly in summit, we accept link-lvel payment\n> splitting (scid is not binding), and provisionally accept rendez-vous\n> routing.\n> > > > It strikes me, that even if your node has only a single channel to\n> the next node (c-lightning), it is possible, to still perform link-level\n> payment splitting/re-routing.\n> > > > For instance, consider this below graph:\n> > > >\n> > > >       E<---D--->C<---B\n> > > >            ^  /\n> > > >            | /\n> > > >            |L\n> > > >            A\n> > > >\n> > > >\n> > > > In the above, B requests a route from B->C->D->E.\n> > > > However, C cannot send to D, since the channel direction is\n> saturated in favor of D.\n> > > > Alternately, C can route to D via A instead. It holds the\n> (encrypted) route from D to E. It can take that sub-route and treat it as a\n> partial route-to-payee under rendez-vous routing, as long as node A\n> supports rendez-vous routing.\n> > > > This can allow re-routing or payment splitting over multiple hops.\n> > > > Even though C does not know the number of remaining hops between D\n> and the destination, its alternative is to earn nothing anyway as its only\n> alternative is to fail the routing. At least with this, there is a chance\n> it can succeed to send the payment to the final destination.\n> > > > Regards,\n> > > > ZmnSCPxj\n> > > >\n> > > > Lightning-dev mailing list\n> > > > Lightning-dev at lists.linuxfoundation.org\n> > > > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> >\n> >\n> > _______________________________________________\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181114/0fcb41a8/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-14T23:29:30",
                "message_text_only": "Good morning Christian and Conner,\n\nThe construction we came up with allows multiple rendezvous nodes, unlike the HORNET construction that is inherently only a single rendezvous node.\nPerhaps the extra flexibility comes with some security degradation?\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Wednesday, November 14, 2018 7:40 PM, Christian Decker <decker.christian at gmail.com> wrote:\n\n> Hi Conner,\n>\n> thanks for the pointers, looking forward to reading up on the\n> wrap resistance. I don't quite follow if you're against the\n> re-wrapping for spontaneous re-routing, or the entire rendez-vous\n> construction we came up with in Australia. If it's the latter, do\n> you have an alternative construction that we might look at?\n> Hornet requires the onion-in-onion initial sphinx setup IIRC\n> which is pretty much what we came up with here (with the\n> exception that we manage to have the second onion be hidden in\n> the first one's header instead of the payload).\n>\n> Cheers,\n> Christian\n>\n> On Tue, Nov 13, 2018 at 9:21 PM Conner Fromknecht <conner at lightning.engineering> wrote:\n>\n>> Good morning all,\n>>\n>> Taking a step back\u2014even if key switching can be done mathematically, it seems\n>> dubious that we would want to introduce re-routing or rendezvous routing in this\n>> manner. If the example provided _could_ be done, it would directly violate the\n>> wrap-resistance property of the ideal onion routing scheme defined in [1]. This\n>> property is proven for Sphinx in section 4.3 of [2]. Schemes like HORNET [3]\n>> support rendezvous routing and are formally proven in this model. Seems this\n>> would be the obvious path forward, given that we've already done a considerable\n>> amount of work towards implementing HORNET via Sphinx.\n>>\n>> Cheers,\n>> Conner\n>>\n>> [1] A Formal Treatment of Onion Routing:\n>> https://www.iacr.org/cryptodb/archive/2005/CRYPTO/1091/1091.pdf\n>> [2] Sphinx: https://cypherpunks.ca/~iang/pubs/Sphinx_Oakland09.pdf\n>> [3] HORNET: https://arxiv.org/pdf/1507.05724.pdf\n>> On Mon, Nov 12, 2018 at 8:47 PM ZmnSCPxj via Lightning-dev\n>> <lightning-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>> Good morning Christian,\n>>>\n>>> I am nowhere near a mathematician, thus, cannot countercheck your expertise here (and cannot give a counterproposal thusly).\n>>>\n>>> But I want to point out the below scenarios:\n>>>\n>>> 1.  C is the payer.  He is in contact with an unknown payee (who in reality is E).  E provides the onion-wrapped route D->E with ephemeral key and other data necessary, as well as informing C that D is the rendez-vous point.  Then C creates a route from itself to D (via channel C->D or via C->A->D).\n>>>\n>>> 2.  B is the payer.  He knows the entire route B->C->D->E and knows that payee is C.  Unfortunately the C<->D channel is low capacity or down or etc etc.  At C, B has provided the onion-wrapped route D->E with ephemeral key and other data necessary, as well as informing to C that D is the next node.  Then C either pays via C->D or via C->A->D.\n>>>\n>>> Even if there is an off-by-one error in our thinking about rendez-vous nodes, could it not be compensated also by an off-by-one in the link-level payment splitting via intermediary rendez-vous node?\n>>> In short, D is the one that switches keys instead of A.\n>>>\n>>> The operation of processing a hop would be:\n>>>\n>>> 1.  Unwrap the onion with current ephemeral key.\n>>> 2.  Dispatch based on realm byte.\n>>> 2.1.  If realm byte 0:\n>>> 2.1.1.  Normal routing behavior, extract HMAC, etc etc\n>>> 2.2.  If realm byte 2 \"switch ephemeral keys\":\n>>> 2.2.1.  Set current ephemeral key to bytes 1 -> 32 of packet.\n>>> 2.2.2.  Shift onion by one hop packet.\n>>> 2.2.3.  Goto 1.\n>>>\n>>> Would that not work?\n>>> (I am being naive here, as I am not a mathist and I did not understand half what you wrote, sorry)\n>>>\n>>> Then at C, we have the onion from D->E, we also know the next ephemeral key to use (we can derive it since we would pass it to D anyway).\n>>> It rightshifts the onion by one, storing the next ephemeral key to the new hop it just allocated.\n>>> Then it encrypts the onion using a new ephemeral key that it will use to generate the D<-A<-C part of the onion.\n>>>\n>>> Regards,\n>>> ZmnSCPxj\n>>>\n>>>\n>>> Sent with ProtonMail Secure Email.\n>>>\n>>> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>>> On Tuesday, November 13, 2018 11:45 AM, Christian Decker <decker.christian at gmail.com> wrote:\n>>>\n>>> > Great proposal ZmnSCPxj, but I think I need to raise a small issue with\n>>> > it. While writing up the proposal for rendez-vous I came across a\n>>> > problem with the mechanism I described during the spec meeting: the\n>>> > padding at the rendez-vous point would usually zero-padded and then\n>>> > encrypted in one go with the shared secret that was generated from the\n>>> > previous ephemeral key (i.e., the one before the switch). That ephemeral\n>>> > key is not known to the recipient (barring additional rounds of\n>>> > communication) so the recipient would be unable to compute the correct\n>>> > MACs. There are a number of solutions to this, basically setting the\n>>> > padding to something that the recipient could know when generating its\n>>> > half onion.\n>>> >\n>>> > My current favorite goes like this:\n>>> >\n>>> > 1.  Rendez-vous RV receives an onion, performs ECDH like normal to get\n>>> >     the shared secret, decrypts its payload, simultaneously encrypts\n>>> >     the padding.\n>>> >\n>>> > 2.  It extracts its per-hop payload and shifts the entire packet over\n>>> >     (shift its payload out and the newly generated padding in)\n>>> >\n>>> > 3.  It then notices that it should perform an ephemeral key switch, now\n>>> >     deviating from the normal protocol (which would just be to generate\n>>> >     the new ephemeral key, serialize and forward)\n>>> >     3.1. It zero-fills the padding that it just added (so we are in a\n>>> >     state that the recipient knew when generating its partial onion\n>>> >     3.2 It performs ECDH with the switched in ephemeral key to get a new\n>>> >     shared secret that which is then used to unwrap one additional\n>>> >     layer of encryption, and most importantly encrypt the padding so\n>>> >     the next hop doesn't see the zero-filled padding.\n>>> >     3.3 Only then will it generate the new ephemeral key for the next\n>>> >     hop, based on the switched in ephemeral key and the newly\n>>> >     generated shared secret, serialize the packet and forward it.\n>>> >\n>>> >     This has the advantage of reusing all the existing machinery but\n>>> >     assembling it a bit differently, by adding a little detour when\n>>> >     generating the next onion. It involves one additional ECDH at the\n>>> >     rendez-vous, one ChaCha20 encryption and one scalar multiplication to\n>>> >     generate the next ephemeral keys. It does not need more space than the\n>>> >     single ephemeral key in the per-hop payload.\n>>> >\n>>> >     And now for the reason that I write this as a reply to your post: with\n>>> >     this scheme it is not possible for C to find an ephemeral key that would\n>>> >     end up identical to the one that D would require to decrypt the onion\n>>> >     correctly. This would not be an issue if D is informed about this split\n>>> >     and would basically accept whatever it gets, but that kind of defeats\n>>> >     the transparency that you were going for with your proposal.\n>>> >\n>>> >     I'm open for other proposals but I currently can't think of a way to\n>>> >     make sure that a) the recipient can deterministically generate the same\n>>> >     padding that RV will generate, and b) hide the fact that RV was indeed a\n>>> >     rendez-vous point (e.g., by leaving the padding be a well known\n>>> >     constant).\n>>> >\n>>> >     Sorry for this problem, I had a mental off-by-one at the meeting that I\n>>> >     hadn't considered, the solution should work, but it makes this kind of\n>>> >     things a bit harder.\n>>> >\n>>> >     Cheers,\n>>> >     Christian\n>>> >\n>>> >     ZmnSCPxj via Lightning-dev lightning-dev at lists.linuxfoundation.org\n>>> >\n>>> >\n>>> > writes:\n>>> >\n>>> > > Good morning list,\n>>> > > As was discussed directly in summit, we accept link-lvel payment splitting (scid is not binding), and provisionally accept rendez-vous routing.\n>>> > > It strikes me, that even if your node has only a single channel to the next node (c-lightning), it is possible, to still perform link-level payment splitting/re-routing.\n>>> > > For instance, consider this below graph:\n>>> > >\n>>> > >       E<---D--->C<---B\n>>> > >            ^  /\n>>> > >            | /\n>>> > >            |L\n>>> > >            A\n>>> > >\n>>> > >\n>>> > > In the above, B requests a route from B->C->D->E.\n>>> > > However, C cannot send to D, since the channel direction is saturated in favor of D.\n>>> > > Alternately, C can route to D via A instead. It holds the (encrypted) route from D to E. It can take that sub-route and treat it as a partial route-to-payee under rendez-vous routing, as long as node A supports rendez-vous routing.\n>>> > > This can allow re-routing or payment splitting over multiple hops.\n>>> > > Even though C does not know the number of remaining hops between D and the destination, its alternative is to earn nothing anyway as its only alternative is to fail the routing. At least with this, there is a chance it can succeed to send the payment to the final destination.\n>>> > > Regards,\n>>> > > ZmnSCPxj\n>>> > >\n>>> > > Lightning-dev mailing list\n>>> > > Lightning-dev at lists.linuxfoundation.org\n>>> > > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>>>\n>>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181114/ae8bc288/attachment-0001.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-11-15T07:22:09",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n> The construction we came up with allows multiple rendezvous nodes,\n> unlike the HORNET construction that is inherently only a single\n> rendezvous node.  Perhaps the extra flexibility comes with some\n> security degradation?\n\nI don't think this is the case. If I remember correctly (Conner please\ncorrect me if I'm wrong here), then the Hornet rendez-vous construction\nrelied on a Sphinx packet from the RV to R, wrapped in a Sphinx packet\nfrom S to RV. This was possible because of the variable sized payload.\nIt would be possible to do that a number of times, with the downside\nthat the packet would be bigger and bigger since we are wrapping full\nSphinx packets.\n\nOur construction with the ephemeral key switch at the rendez-vous point\nis identical to that construction, except that we have the ephemeral key\nat the RV hidden inside the routing information (per-hop payload) and\nthe remainder of the route in what would otherwise be padding. The\nconstructions are IMHO no different except for the location we store the\nforward information that the RV will have to unpack (per-hop payload\ninstead of nested sphinx packets).\n\nThe only difficulty that I pointed out comes from the fact that the HMAC\nverification can't work if we can't generate a specify shared secret at\nthe RV, which to me sounds like an intrinsic property of the way we use\none-way functions to derive those.\n\nCheers,\nChristian"
            }
        ],
        "thread_summary": {
            "title": "Link-level payment splitting via intermediary rendezvous nodes",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Johan Tor\u00e5s Halseth",
                "Christian Decker",
                "Conner Fromknecht",
                "ZmnSCPxj"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 45951
        }
    },
    {
        "title": "[Lightning-dev] \"Trustless\" Pathfinding Service",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-09T12:02:21",
                "message_text_only": "Good morning list, especially, Takaya Imai and the other representatives from Nayuta,\n\nI was asked directly by Nayuta representatives, about \"trustless\" pathfinding service.  While I gave an idea that was satisfactory initially, when I consider again, it is actually very bad.\n\nThe scenario is the below:\n\n1.  A paying Lightning node is a \"light\" client that is so light, it cannot keep a complete routemap.\n2.  There exists a service that can contain the complete routemap.\n3.  The paying Lightning node does not want the service to know the payer and payee.\n\nThe solution I gave before was below:\n\n1.  The paying Lightning node provides several nodes in an ordered list.  It includes itself and the destination in that list.  The only constraint is that the payer must precede the payee, but, they may be anywhere on the list as long as they are not more than 10 nodes or so from each other in this long list.\n2.  The routing service creates a single very long (potentially >20 hops) route, which passes through all nodes in the specified order.\n3.  In order to get paid, the routing service maintains one or more Lightning nodes with higher than typical fees.  It biases pathfinding towards those nodes.\n4.  The paying Lightning node receives the very long route, and cuts it from paying node, to the destination.  If this subsection of the route is < 20 hops, it can be used to attempt the payment.\n5.  The routing service cannot be sure precisely, who is payer and payee.\n6.  The routing service is incentivized to behave properly (i.e. give valid route). If it gives valid route, there is possibility that its nodes happen to be on the route from payer to payee and possibly earn fees.  If it gives invalid route, it earns no fees.\n\nHowever, issues are below:\n\n1. If the routing fails, or the subsection from payer to payee is too long, how can we re-query the same routing service safely, without leaking what the source and destination truly have?  This seems to be similar to the Bloom Filter issue for SPV bitcoin nodes (I believe, Imai-san also mentioned this...)\n2. How does the Lightning node learn of other nodes it can use to increase its anonymity set?  If it keeps some node ids, then how is that so different, from saving more of the routemap (potentially, node IDs stored without channel information take only 33 bytes; but channel objects and pointers between node objects and channel objects could be quite small also).\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181109/3f50fb89/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "\"Trustless\" Pathfinding Service",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "ZmnSCPxj"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2625
        }
    },
    {
        "title": "[Lightning-dev] Packet switching via intermediary rendezvous node",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-09T16:10:56",
                "message_text_only": "Good morning list,\n\nAlthough, packet switching was part of the agenda, we decided, that we would defer this to some later version of BOLT spec.\n\nInterestingly, some sort of packet switching becomes possible, due to the below features we did not defer:\n\n1.  Multi-hop onion packets (i.e. s/realm/packettype/)\n2.  Identify \"next\" by node-id instead of short-channel-id (actually, we solved this by \"short-channel-id is not binding\" and next hop is identified by short-channel-id still).\n3.  Onion ephemeral key switching (required by rendez-vous routing).\n\n-----------\n\nSuppose we define the below packettype (notice below type number is even, but I am uncertain how \"is OK to be odd\", is appropriate for this):\n\npackettype 0: same as current realm 0\npackettype 2: ephemeral key switch (use ephemeral key in succeeding 65-byte packet)\npackettype 4: identify next node by node-id on succeeding 65-byte packet\n\nSuppose I were to receive a packettype 0 in an onion.  It identifies a short-channel-id.  Now suppose this particular channel has no capacity.  As I showed in thread \" Link-level payment splitting via intermediary rendezvous nodes\" https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001547.html, it is possible, that I can route it via some other route *composed of multiple channels*, by using packettype 4 at the end of this route to connect it to the rest of the onion I receive.\n\nHowever, in this case, in effect, the short-channel-id simply identifies the \"next\" node along this route.\n\nSuppose we also identify a new packettype (packettype 4)) where he \"next\" node is identified by its node-id.\n\nLet us make the below scenarios.\n\n1.  Suppose the node-id so identified, I have a channel with this node.  And suppose this channel has capacity.  I can send the payment directly to that node.  This is no different from today.\n2.  Suppose the node-id so identified, I have a channel with this node.  But this channel has not capacity.  However, I can look for alternate route.  And by using rendez-vous feature \"switch ephemeral key\" I can generate a route that is multiple hops, in order to reach the identified node-id, and connect the rest of the onion to this.  This case is same as if the node is identified by short-channel-id.\n3.  Suppose the node-id so identified, I have not a channel with this node.  However, I can again look for alternate route.  Again, by using \"switch ephemeral key\" feature, I can generate a route that is multiple hops, in order to reach the identified node-id, and again connect the rest of the onion to this.\n\nNow, the case 3 above, can build up packet switching.  I might have a routemap that contains the destination node-id and have an accurate route through the network, and identify the path directly to the next node.  If not, I could guess/use statistics that one of my peers is likely to know how to route to that node, and also forward a packettype 4 to the same node-id to my peer.\n\nThis particular packet switching, also allows some uncertainty about the destination.  For instance, even if I wish to pay CJP, actually I make an onion with packettype 4 Rene, packettype 4 CJP. packettype 0 HMAC=0.  Then I send the above onion (appropriately layered-encrypted) to my direct peer cdecker, who attempts to make an effort to route to Rene.  When Rene receives it, it sees packettype 4 CJP, and then makes an effort to route to CJP, who sees packettype 0 HMAC=0 meaning CJP is the recipient.\n\nFurther, this is yet another use of the siwtch-ephemeral-key packettype.\n\nThus:\n\n1.  It allows packet switching\n2.  It increases anonymity set of rendez-vous routing. Node that sees packettype 2 (switch ephemeral key) does not know, if it is sending to a packet-switched or link-level payment rerouting, or if it is the rendes-vous for a deniable payment.\n3.  Mapless Lightning nodes (https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001552.html) could ask a peer to be their pathfinding provider, with some amount of uncertinaty (it is possible that somebody else sent a packettype 4 to me, and I selected you as peer who might know the destination; also, the destination specified may not be the final destination, and I might also be someone who received a packettype 2 and switched keys before forwarding the packettype 4 to you).\n4.  It justifies multiple features (support for packettype 2 and packettype 4) having a single feature bit, again making it difficult to justify discriminating nodes with this feature bit enabled.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181109/2a8a45a8/attachment.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-11-13T04:06:23",
                "message_text_only": "Hi ZmnSCPxj,\n\nlike I mentioned in the other mailing thread we have a minor\ncomplication in order get rendez-vous working.\n\nIf I'm not mistaken it'll not be possible for us to have spontaneous\nephemeral key switches while forwarding a payment. Specifically either\nthe sender or the recipient have to know the switchover points in their\nrespective parts of the onion. Otherwise it'll not be possible to cover\nthe padding in the HMAC, for the same reason that we couldn't meet up\nwith the same ephemeral key at the rendez-vous point.\n\nSorry about not noticing this before.\n\nCheers,\nChristian\n\nZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\nwrites:\n> Good morning list,\n>\n> Although, packet switching was part of the agenda, we decided, that we would defer this to some later version of BOLT spec.\n>\n> Interestingly, some sort of packet switching becomes possible, due to the below features we did not defer:\n>\n> 1.  Multi-hop onion packets (i.e. s/realm/packettype/)\n> 2.  Identify \"next\" by node-id instead of short-channel-id (actually, we solved this by \"short-channel-id is not binding\" and next hop is identified by short-channel-id still).\n> 3.  Onion ephemeral key switching (required by rendez-vous routing).\n>\n> -----------\n>\n> Suppose we define the below packettype (notice below type number is even, but I am uncertain how \"is OK to be odd\", is appropriate for this):\n>\n> packettype 0: same as current realm 0\n> packettype 2: ephemeral key switch (use ephemeral key in succeeding 65-byte packet)\n> packettype 4: identify next node by node-id on succeeding 65-byte packet\n>\n> Suppose I were to receive a packettype 0 in an onion.  It identifies a short-channel-id.  Now suppose this particular channel has no capacity.  As I showed in thread \" Link-level payment splitting via intermediary rendezvous nodes\" https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001547.html, it is possible, that I can route it via some other route *composed of multiple channels*, by using packettype 4 at the end of this route to connect it to the rest of the onion I receive.\n>\n> However, in this case, in effect, the short-channel-id simply identifies the \"next\" node along this route.\n>\n> Suppose we also identify a new packettype (packettype 4)) where he \"next\" node is identified by its node-id.\n>\n> Let us make the below scenarios.\n>\n> 1.  Suppose the node-id so identified, I have a channel with this node.  And suppose this channel has capacity.  I can send the payment directly to that node.  This is no different from today.\n> 2.  Suppose the node-id so identified, I have a channel with this node.  But this channel has not capacity.  However, I can look for alternate route.  And by using rendez-vous feature \"switch ephemeral key\" I can generate a route that is multiple hops, in order to reach the identified node-id, and connect the rest of the onion to this.  This case is same as if the node is identified by short-channel-id.\n> 3.  Suppose the node-id so identified, I have not a channel with this node.  However, I can again look for alternate route.  Again, by using \"switch ephemeral key\" feature, I can generate a route that is multiple hops, in order to reach the identified node-id, and again connect the rest of the onion to this.\n>\n> Now, the case 3 above, can build up packet switching.  I might have a routemap that contains the destination node-id and have an accurate route through the network, and identify the path directly to the next node.  If not, I could guess/use statistics that one of my peers is likely to know how to route to that node, and also forward a packettype 4 to the same node-id to my peer.\n>\n> This particular packet switching, also allows some uncertainty about the destination.  For instance, even if I wish to pay CJP, actually I make an onion with packettype 4 Rene, packettype 4 CJP. packettype 0 HMAC=0.  Then I send the above onion (appropriately layered-encrypted) to my direct peer cdecker, who attempts to make an effort to route to Rene.  When Rene receives it, it sees packettype 4 CJP, and then makes an effort to route to CJP, who sees packettype 0 HMAC=0 meaning CJP is the recipient.\n>\n> Further, this is yet another use of the siwtch-ephemeral-key packettype.\n>\n> Thus:\n>\n> 1.  It allows packet switching\n> 2.  It increases anonymity set of rendez-vous routing. Node that sees packettype 2 (switch ephemeral key) does not know, if it is sending to a packet-switched or link-level payment rerouting, or if it is the rendes-vous for a deniable payment.\n> 3.  Mapless Lightning nodes (https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001552.html) could ask a peer to be their pathfinding provider, with some amount of uncertinaty (it is possible that somebody else sent a packettype 4 to me, and I selected you as peer who might know the destination; also, the destination specified may not be the final destination, and I might also be someone who received a packettype 2 and switched keys before forwarding the packettype 4 to you).\n> 4.  It justifies multiple features (support for packettype 2 and packettype 4) having a single feature bit, again making it difficult to justify discriminating nodes with this feature bit enabled.\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-11-16T03:24:29",
                "message_text_only": "> If I'm not mistaken it'll not be possible for us to have spontaneous\n> ephemeral key switches while forwarding a payment\n\nIf this _was_ possible, then it seems that it would allow nodes to create\nunbounded path lengths (looks to other nodes as a normal packet), possibly\nby controlling multiple nodes in a route, thereby sidestepping the 20 hop\nlimit all together. This would be undesirable many reasons, the most dire of\nwhich being the ability to further amplify null-routing attacks.\n\n-- Laolu\n\nOn Mon, Nov 12, 2018 at 8:06 PM Christian Decker <decker.christian at gmail.com>\nwrote:\n\n> Hi ZmnSCPxj,\n>\n> like I mentioned in the other mailing thread we have a minor\n> complication in order get rendez-vous working.\n>\n> If I'm not mistaken it'll not be possible for us to have spontaneous\n> ephemeral key switches while forwarding a payment. Specifically either\n> the sender or the recipient have to know the switchover points in their\n> respective parts of the onion. Otherwise it'll not be possible to cover\n> the padding in the HMAC, for the same reason that we couldn't meet up\n> with the same ephemeral key at the rendez-vous point.\n>\n> Sorry about not noticing this before.\n>\n> Cheers,\n> Christian\n>\n> ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\n> writes:\n> > Good morning list,\n> >\n> > Although, packet switching was part of the agenda, we decided, that we\n> would defer this to some later version of BOLT spec.\n> >\n> > Interestingly, some sort of packet switching becomes possible, due to\n> the below features we did not defer:\n> >\n> > 1.  Multi-hop onion packets (i.e. s/realm/packettype/)\n> > 2.  Identify \"next\" by node-id instead of short-channel-id (actually, we\n> solved this by \"short-channel-id is not binding\" and next hop is identified\n> by short-channel-id still).\n> > 3.  Onion ephemeral key switching (required by rendez-vous routing).\n> >\n> > -----------\n> >\n> > Suppose we define the below packettype (notice below type number is\n> even, but I am uncertain how \"is OK to be odd\", is appropriate for this):\n> >\n> > packettype 0: same as current realm 0\n> > packettype 2: ephemeral key switch (use ephemeral key in succeeding\n> 65-byte packet)\n> > packettype 4: identify next node by node-id on succeeding 65-byte packet\n> >\n> > Suppose I were to receive a packettype 0 in an onion.  It identifies a\n> short-channel-id.  Now suppose this particular channel has no capacity.  As\n> I showed in thread \" Link-level payment splitting via intermediary\n> rendezvous nodes\"\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001547.html,\n> it is possible, that I can route it via some other route *composed of\n> multiple channels*, by using packettype 4 at the end of this route to\n> connect it to the rest of the onion I receive.\n> >\n> > However, in this case, in effect, the short-channel-id simply identifies\n> the \"next\" node along this route.\n> >\n> > Suppose we also identify a new packettype (packettype 4)) where he\n> \"next\" node is identified by its node-id.\n> >\n> > Let us make the below scenarios.\n> >\n> > 1.  Suppose the node-id so identified, I have a channel with this node.\n> And suppose this channel has capacity.  I can send the payment directly to\n> that node.  This is no different from today.\n> > 2.  Suppose the node-id so identified, I have a channel with this node.\n> But this channel has not capacity.  However, I can look for alternate\n> route.  And by using rendez-vous feature \"switch ephemeral key\" I can\n> generate a route that is multiple hops, in order to reach the identified\n> node-id, and connect the rest of the onion to this.  This case is same as\n> if the node is identified by short-channel-id.\n> > 3.  Suppose the node-id so identified, I have not a channel with this\n> node.  However, I can again look for alternate route.  Again, by using\n> \"switch ephemeral key\" feature, I can generate a route that is multiple\n> hops, in order to reach the identified node-id, and again connect the rest\n> of the onion to this.\n> >\n> > Now, the case 3 above, can build up packet switching.  I might have a\n> routemap that contains the destination node-id and have an accurate route\n> through the network, and identify the path directly to the next node.  If\n> not, I could guess/use statistics that one of my peers is likely to know\n> how to route to that node, and also forward a packettype 4 to the same\n> node-id to my peer.\n> >\n> > This particular packet switching, also allows some uncertainty about the\n> destination.  For instance, even if I wish to pay CJP, actually I make an\n> onion with packettype 4 Rene, packettype 4 CJP. packettype 0 HMAC=0.  Then\n> I send the above onion (appropriately layered-encrypted) to my direct peer\n> cdecker, who attempts to make an effort to route to Rene.  When Rene\n> receives it, it sees packettype 4 CJP, and then makes an effort to route to\n> CJP, who sees packettype 0 HMAC=0 meaning CJP is the recipient.\n> >\n> > Further, this is yet another use of the siwtch-ephemeral-key packettype.\n> >\n> > Thus:\n> >\n> > 1.  It allows packet switching\n> > 2.  It increases anonymity set of rendez-vous routing. Node that sees\n> packettype 2 (switch ephemeral key) does not know, if it is sending to a\n> packet-switched or link-level payment rerouting, or if it is the\n> rendes-vous for a deniable payment.\n> > 3.  Mapless Lightning nodes (\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001552.html)\n> could ask a peer to be their pathfinding provider, with some amount of\n> uncertinaty (it is possible that somebody else sent a packettype 4 to me,\n> and I selected you as peer who might know the destination; also, the\n> destination specified may not be the final destination, and I might also be\n> someone who received a packettype 2 and switched keys before forwarding the\n> packettype 4 to you).\n> > 4.  It justifies multiple features (support for packettype 2 and\n> packettype 4) having a single feature bit, again making it difficult to\n> justify discriminating nodes with this feature bit enabled.\n> >\n> > Regards,\n> > ZmnSCPxj\n> > _______________________________________________\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181115/047bf528/attachment.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2018-11-16T15:31:59",
                "message_text_only": "On Thu, Nov 15, 2018 at 07:24:29PM -0800, Olaoluwa Osuntokun wrote:\n> > If I'm not mistaken it'll not be possible for us to have spontaneous\n> > ephemeral key switches while forwarding a payment\n> If this _was_ possible, then it seems that it would allow nodes to create\n> unbounded path lengths (looks to other nodes as a normal packet), possibly\n> by controlling multiple nodes in a route, thereby sidestepping the 20 hop\n> limit all together.\n\nIf you control other nodes in the route you can trivially create a \"path\"\nof more than 20 hops -- go 18 hops from your first node to your second\nnode, and have the second node trigger on the payment hash to create\nan entirely new onion to go another 18 hops, repeating if necessary to\ncreate an arbitrarily long route.\n\n> This would be undesirable many reasons, the most dire of\n> which being the ability to further amplify null-routing attacks.\n\nThat doesn't really *amplify* null-routing attacks -- even if its\ncircular, you're still locking additional funds up each time you\nroute through yourself.\n\nCheers,\naj"
            }
        ],
        "thread_summary": {
            "title": "Packet switching via intermediary rendezvous node",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Anthony Towns",
                "Christian Decker",
                "Olaoluwa Osuntokun",
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 17922
        }
    },
    {
        "title": "[Lightning-dev] Probe cancellation",
        "thread_messages": [
            {
                "author": "Anthony Towns",
                "date": "2018-11-10T03:26:06",
                "message_text_only": "PING,\n\nIt seems like ensuring reliability is going to involve nodes taking\nactive measures like probing routes fairly regularly. Maybe it would\nbe worth making that more efficient? For example, a risk of probing is\nthat if the probe discovers a failing node/channel, the probe HTLC will\nget stuck, and have to gradually timeout, which at least uses up HTLC\nslots and memory for each of the well-behaved nodes, but if the probe\nhas a realistic value rather than just a few (milli)satoshis, it might\nlock up real money too.\n\nIt might be interesting to allow for cancelling stuck probes from\nthe sending direction as well as the receiving direction. eg if the\npayment hash wasn't generated as SHA256(\"something\") but rather as\nSHA256(\"something\") XOR 0xFF..FF or similar, then everyone can safely drop\nthe incoming transaction because they know that even if they forwarded\nthe tx, it will be refunded eventually anyway (or otherwise sha256 is\neffectively broken and they're screwed anyway). So all I have to do is\nsend a packet saying this was a probe, and telling you the \"something\"\nto verify, and I can free up the slot/funds from my probe, as can everyone\nelse except for the actual failing nodes.\n\n>From the perspective of the sending node:\n\n  generate 128b random number X\n  calculate H=bitwise-not(SHA256(X))\n  make probe payment over path P, hash H, amount V\n  wait for response:\n    - success: Y, s.t. SHA256(Y)=H=not(SHA256(X)) -- wtf, sha is broken\n    - error, unknown hash: path works\n    - routing failed:  mark failing node, reveal X cancelling HTLC\n    - timeout: mark path as failed (?), reveal X cancelling HTLC\n\nCheers,\naj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-12T00:17:31",
                "message_text_only": "Good morning aj,\n\nThis indeed looks like a good idea to allow freeing up scarce resources on the network.\n\nAn attacker will still take the option to not do this, but at least someone making an honest effort to probe the network does not inadvertently attack it in case a probe fails.\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Saturday, November 10, 2018 11:26 AM, Anthony Towns <aj at erisian.com.au> wrote:\n\n> PING,\n>\n> It seems like ensuring reliability is going to involve nodes taking\n> active measures like probing routes fairly regularly. Maybe it would\n> be worth making that more efficient? For example, a risk of probing is\n> that if the probe discovers a failing node/channel, the probe HTLC will\n> get stuck, and have to gradually timeout, which at least uses up HTLC\n> slots and memory for each of the well-behaved nodes, but if the probe\n> has a realistic value rather than just a few (milli)satoshis, it might\n> lock up real money too.\n>\n> It might be interesting to allow for cancelling stuck probes from\n> the sending direction as well as the receiving direction. eg if the\n> payment hash wasn't generated as SHA256(\"something\") but rather as\n> SHA256(\"something\") XOR 0xFF..FF or similar, then everyone can safely drop\n> the incoming transaction because they know that even if they forwarded\n> the tx, it will be refunded eventually anyway (or otherwise sha256 is\n> effectively broken and they're screwed anyway). So all I have to do is\n> send a packet saying this was a probe, and telling you the \"something\"\n> to verify, and I can free up the slot/funds from my probe, as can everyone\n> else except for the actual failing nodes.\n>\n> From the perspective of the sending node:\n>\n> generate 128b random number X\n> calculate H=bitwise-not(SHA256(X))\n> make probe payment over path P, hash H, amount V\n> wait for response:\n> - success: Y, s.t. SHA256(Y)=H=not(SHA256(X)) -- wtf, sha is broken\n> - error, unknown hash: path works\n> - routing failed: mark failing node, reveal X cancelling HTLC\n> - timeout: mark path as failed (?), reveal X cancelling HTLC\n>\n> Cheers,\n> aj\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            }
        ],
        "thread_summary": {
            "title": "Probe cancellation",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Anthony Towns",
                "ZmnSCPxj"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 3918
        }
    },
    {
        "title": "[Lightning-dev] Towards a Market for Liquidity Providers -- Enforcing Minimum Channel Lifetime",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-10T13:46:24",
                "message_text_only": "Good morning list,\n\nIntroduction\n============\n\nThis thread, effectively continues the discussion, regarding dual-funding and a liquidity market for requesting to provide incoming capacity.\n\nI and Rene Pickhardt, were discussing this a little while ago, and resulted to the solution below.\n\nThe Service Being Bought\n------------------------\n\nFirst, let us focus on what is being bought and paid for in this liquidity market.\n\nWe have been talking as if all that is being bought and paid for is simply \"incoming capacity\".\n\nHowever, I believe this is incomplete.\nIn the \"real world\" that you humans appear to be excessively obsessed with, a contract for a service involves specifying, not only what is being purchased, but also for how long this service is to be rendered.\nIndeed, this is the basis for my suggestion, to add an `nLockTime` to the commitment transactions.\n\nThus, the contract for purchasing liquidity, should specify not only the amount to be allocated for capacity, but also some duration for how long that capacity is to be allocated.\nElse, there is no reasonable condition for determining if the closure of a channel is improper or not.\n\nThus, I propose a simple modification for channels that are opened via a dual-fund that responded to an advertisement for liquidity.\n\nA liquidity provider, providers the service as follows: for a fee, I shall provide incoming capacity to your node, and maintain this channel for a certain minimum duration.\n\nLet us introduce our cast of characters:\n\n* Mercy the Merchant, who wishes to receive payments by Lightning,\n* Licky the Liquidity Provider, who wishes to earn fees by on-boarding others on Lightning.\n* Randy the Random Node, who is simply on Lightning for no particular purpose.\n\nMercy pays Licky some fee, in order for Licky to provide incoming capacity to Mercy, for at least some number of blocks.\n\nMinimum-lifetime Channels\n=========================\n\nLet us now consider, how to impose a minimum lifetime to a channel.\nNaively, commitment transactions may have an `nLockTime` to impose this.\nHowever, this complicates HTLCs that appear as outputs of commitment transactions.\nAn HTLC timelock that expires before the `nLockTime` of the commitment transaction cannot be enforced.\n\nThis makes the channel particularly useless for incoming payments, as payments that terminate at Mercy, are most likely to have low timelocks and thus most likely to be unenforceable onchain.\nLicky will prefer not to forward such nonenforceable HTLCs, so Mercy will not receive payments by this channel, when the express purpose, is to receive payments.\n\nSeparating Lifetime from HTLCs\n------------------------------\n\nHowever, we could instead consider, to enforce the locktime on the main output for Licky instead.\nThis would allow the HTLC outputs to be unencumbered, allowing proper enforcement onchain.\n\nThus, after Symmetric CSV, we could also add an additional CLTV constraint that determines the minimum channel lifetime.\n\nFor instance, without minimum channel enforcement, Licky-side commitment transaction would have outputs below:\n\n1.  Mercy-side output: Mercy && CSV\n2.  Licky-side output: revocation || (Licky && CSV)\n\nBut if we now use a CLTV to enforce channel lifetime, Licky-side commitment transaction would have outputs below:\n\n1.  Mercy-side output: Mercy && CSV\n2.  Licky-side output: revocation || (Licky && CSV && CLTV)\n\nThe CLTV constraint is the block height at which the channel is created, plus the lifetime of the channel in blocks.\n\nOf note, is that only Licky has the CLTV encumberance.\nUnlike CSV, it is not symmetrical.\nAsymmetry must exist here, since Licky has an obligation (it must provide this service) that Mercy does not.\n\nThe Mercy-side commitment transaction would have the outputs:\n\n1.  Licky-side output: Licky && CSV && CLTV\n2.  Mercy-side output: revocation || (Mercy && CSV)\n\nNow we might have the intuition, that perhaps if Mercy closes the channel by its commitment transaction, this implies releasing Licky from its obligation.\nBut a sufficiently evil Licky could play this by misbehaving, in an attempt to make Mercy close the channel by its commitment transaction, to release it from its obligation.\n(This is the same argument we used, for symmetrical CSV).\n\nOf note, is that if the commitment transactions contain any HTLCs, then they appear simply on the commitment transaction outputs, with no particular change to support this feature.\n\nAlso of note, is that CLTV and CSV can indeed combine.\nA transaction that satisfies both the CSV-imposed `nSequence` and CLTV, would have a `nLockTime` that is the higher of the two imposed constraints.\nIf the channel lifetime (enforced by CLTV) has passed, then the CSV is the only constraint, which reduces to the same as the existing behavior where a unilateral close prevents the money from being claimed by the CSV value.\nIf the channel lifetime has not passed then access to the coin, is constrained by this channel lifetime.\nCLTV interacts badly with CSV only if CSV precedes it on an earlier output in a chain of transactions.\n\nGames Licky Can Play\n--------------------\n\nIt must be raised to attention, that the commitment transaction can be broadcast at any time, as it has no `nLockTime`.\nThis may be necessary to enforce a HTLC timeout.\n\nIndeed, one thing Licky could try to do, would be to transmit the first commitment transaction as soon as it is signed.\nHowever, due to the CLTV constraint, Licky cannot reclaim its money immediately.\nAlthough the channel still closes before its purported minimum lifetime and leaves Mercy bereft of the service, Licky cannot gain an advantage in doing so.\n\nOn the other hand, if Licky continues to keep the channel open, it has the possibility of earning routing fees.\nThus, defection in this game has no benefit, while cooperation has benefit.\nThe rational choice, is to cooperate and retain the channel open.\n\nThe same game plays, if Licky pretends to sleep and does not respond.\nIt gains no additional money or utility.\nIf instead it did not pretend to sleep, it could potentially earn routing fees.\nThe same game is playable today even without liquidity providers.\n\nAt the same time, in case of emergency (an HTLC is about to time out and Mercy is unresponsive), Licky has the ability to enforce onchain.\n\nGames Mercy Can Play\n--------------------\n\nSuppose Mercy broadcasts the commitment transaction as soon as it is signed.\nIt thereby ties up Licky funds and Licky cannot thus earn routing fees.\n\nHowever, the same would be true, if Mercy simply pretended to sleep and did not respond to anything.\nThe funds would still be locked to the channel, and Licky cannot escape this lock.\n\nIt should be pointed out that Mercy has already paid for the locking of funds of Licky, from the liquidity provider advertisement.\nThus, conceptually Mercy \"owns\" the lock-rights of the funds of Licky.\nPresumably, the intent is that Mercy wishes to be paid, and thus Mercy gains economic power from this.\n\nBut suppose Mercy never receives payment via this channel.\nThen the effect is simply: Mercy borrows some money from Licky, and promises to pay it back with some interest (the liquidity provider fee).\nThe difference is that this promise is enforceable onchain, and Mercy cannot escape this by any method: the extra interest will be paid to Licky inevitably, unlike normal bank-based financial instruments.\n(Thus, this is still not a debt-based instrument: the backing credit is held in escrow by the blockchain, and will always return to Licky after the borrowing period ends; there is no possibility of default)\nThus, a rational Mercy would want to be able to utilize this encumbered borrowed funds, by actually providing some service or product and being paid via the channel.\nOtherwise, it ends up having simply donated money to Licky with no economic benefit to itself.\n\nReduction of Licky Obligation\n-----------------------------\n\nOf note, is that the cost of the obligation of Licky would decrease once Mercy actually receives payments.\nThus, as Mercy receives more payment, the cost on Licky in defecting reduces.\n\nWe should also note, that the entire point of Mercy performing this exercise is to receive money.\nWe can consider, that Mercy receiving money should make Mercy satisfied with this service.\nThus even if Licky obligation drops low enough that Licky could economically let some tiny amount be\n\nMore Complex Games Licky Can Play\n---------------------------------\n\nSuppose Mercy has some outgoing channel to a random node, Randy.\nThen Licky can move its encumbered funds through some circular route (if one exists) from Licky to Mercy to Randy back to Licky.\n\nThis is normally not an issue, since the transfer means that the formerly-outgoing channel between Mercy and Randy is now an incoming channel to Mercy,\nThus Mercy still has incoming capacity, as it wants.\nHowever, if this channel has no minimum channel lifetime, then Randy could close this channel.\nLicky would then have disposed of its obligation without having most of its money tied to the channel.\n\nMercy can mitigate this attack, by only opening channels with similar minimum channel lifetimes (actually, similar dates of earliest termination).\nThis means, Randy is not in fact random, but yet another liquidity provider.\nThen when Licky disposes of its obligation, the obligation is actually transferred to Randy.\nThis ensures that Mercy can still have its service of incoming capacity.\n\nActs of God\n===========\n\nRene pointed out, that if an actual physical bolt of Lightning (whatever this \"physical realm\" that humans apparently inhabit means), were to strike Licky, then Mercy gets no incoming capacity and the contract (liquidity fee for incoming liquidity for a specific time period) is effectively voided.\nThis is simply the same as if a contract is voided by an \"act of God\" (a physical bolt of Lightning appears to be one).\nOf note, is that most service contracts in the \"real world\" have clauses where \"act of God\" may prevent proper execution of the service, and the service provider then becomes free of liability.\n\nIn this case, this is exactly modeled, if Licky truly has been destroyed.\nOn the other hand, if Licky only pretends to be destroyed, it is the same game as above in \"Games Licky Can Play\".\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181110/3c084e11/attachment-0001.html>"
            },
            {
                "author": "Pierre",
                "date": "2018-11-11T03:40:16",
                "message_text_only": "Hello ZmnSCPxj,\n\nThus, after Symmetric CSV, we could also add an additional CLTV constraint\n> that determines the minimum channel lifetime.\n>\n\nI'm nitpicking, but parties have to exchange the first commitment txes (one\nfor each side) *before* the funding tx is even published. As a consequence,\nthe absolute CLTV delay wouldn't really constrain the duration of the\nchannel, because the timer starts running before the channel is created. Do\nyou think that matters?\n\nCheers,\n\nPierre\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181111/3a22bc1a/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-12T00:15:47",
                "message_text_only": "Good morning Pierre,\n\n>> Thus, after Symmetric CSV, we could also add an additional CLTV constraint that determines the minimum channel lifetime.\n>\n> I'm nitpicking, but parties have to exchange the first commitment txes (one for each side) *before* the funding tx is even published. As a consequence, the absolute CLTV delay wouldn't really constrain the duration of the channel, because the timer starts running before the channel is created. Do you think that matters?\n\nThis is quite correct; but it is similar to the case where Mercy (who is buying liquidity) opens the channel, with Licky providing part of the funds, and then Mercy shutting down its node.  As long as the funding transaction gets confirmed and it is possible for Licky to broadcast the commitment transaction, the same analysis applies: Mercy pays Licky to lock its funds, so Licky earns here already, regardless whether Mercy uses the capacity or not.\n\nSince we (broadly) agreed that initiator of the channel pays onchain fees, Mercy is in control of how fast (or slow) the time is between the two of them agreeing to a specific CLTV blockheight, to when the channel actually opens.  Thus it could be interpreted, that any discrepancy between the time they agree, and the time the channel gets confirmed and starts its onchain lifetime, is equivalent to Mercy shutting down its node for that duration (and the same analysis applies: Mercy has wasted its money on paying Licky for liquidity it didn't use).\n\nThe above analysis hinges on the funding transaction actually getting confirmed, though.\n\nOne possibility is that Mercy could lowball the onchain fee for the funding transaction.  If the mempool becomes backlogged, instead of Mercy then requesting an RBF of the funding transaction, Mercy could just double-spend only its own inputs, invalidating the funding transaction.  This means, that Licky funds have temporarily been locked, then they attempt to open the channel with a low onchain fee, and if that fails then the deal is cancelled and both get their funds back immediately.  Licky then loses all ability to earn (but at least the channel lifetime is no longer imposed in that case).\n\nThe time from when both sides agree to open the channel and exchange signatures for the funding transaction, to the time the funding transaction confirms, may be sensitive due to the possibility of one side unilaterally RBFing their inputs.\n\nSo let us now write the contract in full:\n\n1.  Mercy agrees to pay N satoshi to Licky.\n2.  Licky agrees to have L satoshi locked for use in the channel until blockheight B.\n3.  Either side may void this contract by paying a miner fee, until the time the funding transaction confirms.\n4.  Mercy is responsible for getting the funding transaction confirmed.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181112/210b6dd3/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-12T00:35:55",
                "message_text_only": "Good morning all,\n\nTangentially related to Pierre question, is  \"initiator pays\" principle.\n\nRene actually wondered about whether this would be fair.\nEspecially, since Licky might very well gather all its dust to provide its side of the funding.\nThinking about this a little more, in the context of a liquidity provider, I provide the below analysis:\n\nIf the onchain fees were split somehow between Mercy and Licky, a rational Licky would increase its liquidity fees until it reaches the level where it would still earn the opportunity cost of locking its funds, taking into account the onchain fee that Licky would provide.\nThus in effect the onchain fee from Licky-side would still end up being paid by Mercy, so we may as well be honest and impose \"initiator pays\".\n\nIf the onchain fees were paid only by Mercy, and Licky provides 100 dust outputs, then a rational Mercy would account for the onchain fees incurred plus the liquidity fee as part of the cost of doing business with Licky.\nIf this cost is too high (regardless of how many outputs Licky provides) then it may be uneconomical for Mercy to do business with that particular Licky and would take its business elsewhere.\n(Since Mercy has to sign the funding transaction, and the funding transaction will need to refer to all of Licky-side inputs, Mercy can always not enter into the contract by simply refusing to sign the funding transaction if the onchain fees end up being too high).\nThus Licky would rationally prefer to keep its own funds in as few outputs as possible in order to be more competitive in the liquidity provider market.\n\nSo, naively to me, \"initiator pays\" seems quite reasonable.\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Monday, November 12, 2018 8:15 AM, ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Pierre,\n>\n>>> Thus, after Symmetric CSV, we could also add an additional CLTV constraint that determines the minimum channel lifetime.\n>>\n>> I'm nitpicking, but parties have to exchange the first commitment txes (one for each side) *before* the funding tx is even published. As a consequence, the absolute CLTV delay wouldn't really constrain the duration of the channel, because the timer starts running before the channel is created. Do you think that matters?\n>\n> This is quite correct; but it is similar to the case where Mercy (who is buying liquidity) opens the channel, with Licky providing part of the funds, and then Mercy shutting down its node.  As long as the funding transaction gets confirmed and it is possible for Licky to broadcast the commitment transaction, the same analysis applies: Mercy pays Licky to lock its funds, so Licky earns here already, regardless whether Mercy uses the capacity or not.\n>\n> Since we (broadly) agreed that initiator of the channel pays onchain fees, Mercy is in control of how fast (or slow) the time is between the two of them agreeing to a specific CLTV blockheight, to when the channel actually opens.  Thus it could be interpreted, that any discrepancy between the time they agree, and the time the channel gets confirmed and starts its onchain lifetime, is equivalent to Mercy shutting down its node for that duration (and the same analysis applies: Mercy has wasted its money on paying Licky for liquidity it didn't use).\n>\n> The above analysis hinges on the funding transaction actually getting confirmed, though.\n>\n> One possibility is that Mercy could lowball the onchain fee for the funding transaction.  If the mempool becomes backlogged, instead of Mercy then requesting an RBF of the funding transaction, Mercy could just double-spend only its own inputs, invalidating the funding transaction.  This means, that Licky funds have temporarily been locked, then they attempt to open the channel with a low onchain fee, and if that fails then the deal is cancelled and both get their funds back immediately.  Licky then loses all ability to earn (but at least the channel lifetime is no longer imposed in that case).\n>\n> The time from when both sides agree to open the channel and exchange signatures for the funding transaction, to the time the funding transaction confirms, may be sensitive due to the possibility of one side unilaterally RBFing their inputs.\n>\n> So let us now write the contract in full:\n>\n> 1.  Mercy agrees to pay N satoshi to Licky.\n> 2.  Licky agrees to have L satoshi locked for use in the channel until blockheight B.\n> 3.  Either side may void this contract by paying a miner fee, until the time the funding transaction confirms.\n> 4.  Mercy is responsible for getting the funding transaction confirmed.\n>\n> Regards,\n> ZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181112/2b65b824/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Towards a Market for Liquidity Providers -- Enforcing Minimum Channel Lifetime",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Pierre",
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 19042
        }
    },
    {
        "title": "[Lightning-dev] Trustless Watchtowers",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-12T09:17:36",
                "message_text_only": "Good morning list,\n\nWe were not able to discuss this topic much at recent summit, but I noticed that lnd has some code related to watchtowers already.  From my bare knowledge of go, it seems data structures and messages so far, without actual logic, but please inform me if I am incorrect.\n\nI assume much of the watchtowers code and design in lnd is by Conner, simply because, he discussed this on this list earlier this year.\n\nI have seen recently, some paper about paying watchtowers by actually simulating breaches.  You would give a watchtower some txid+blob pair, then send that txid and see if the watchtower claims it.  If it does, then you have evidence of liveness and correct behavior, and have also paid for and incentivized the watchtower to operate correctly.\n\nNote however that watchtowers would require to keep all encrypted blobs that are keyed to the same partial txid.  I.e. watchtowers need to store the pair in a set with the set looking at the entire txid+blob as the identity of the object.  Otherwise it would be possible, if your watchtower is identified by your counterparty, for the counterparty to give the commitment transaction's txid with a randomly-generated blob to your watchtower before it gives the revocation key to you.  However, this remains your counterparty best avenue of attack, is to simply spam your watchtower until it runs out of resources and crashes.\n\nI have described the above problem before here: https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-April/001203.html with an unsatisfactory solution.\n\n--\n\nI have also been thinking about watchtowers compatible with Decker-Russell-Osuntokun channels.\n\nAs I understand, in a separate thread, laolu is promoting that Decker-Russell-Osuntokun channels can simply \"update\" the blob side of a txid-blob entry, with the txid being the kickoff/trigger transaction.  As I point out, unless the watchtower identifies the user somehow, this is unsafe; if I can identify your watchtower, then after you update it but before I attack, I can \"update\" the blob side with a randomly-generated, invalid blob.  And if the watchtower identifies the user, then this leaks the privacy of the user to the watchtower, and what would then be the point of encrypted blob? https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-May/001264.html\n\nI am curious what Conner and the other lnd developers are planning for these issues?  You seem to be the first movers into this, and I cannot read go well enough to decipher what plans you have.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181112/b4c31c0c/attachment.html>"
            },
            {
                "author": "Conner Fromknecht",
                "date": "2018-11-14T00:12:05",
                "message_text_only": "Hi ZmnSCPxj,\n\nI haven't yet gotten around to writing up everything documenting in the working\nwatchtower design. However, I think we are nearing that phase where things seem\nmostly solidified and would welcome feedback before attempting to formalize it.\nExpect some follow up posts on the ML :)\n\n> From my bare knowledge of go, it seems data structures and messages so far,\n> without actual logic, but please inform me if I am incorrect.\n\nMuch of the server side has been implemented, which accepts encrypted blobs from\nwatchtower clients and stores them. The functionality related to scanning blocks\nand publishing justice txns has also been implemented, but has not been merged\nyet. The big remaining task is to integrate the client such that it properly\nbacks up states after receiving revocations from the remote peer.\n\n> Note however that watchtowers would require to keep all encrypted blobs that\n> are keyed to the same partial txid.  I.e. watchtowers need to store the pair\n> in a set with the set looking at the entire txid+blob as the identity of the\n> object.  Otherwise it would be possible, if your watchtower is identified by\n> your counterparty, for the counterparty to give the commitment transaction's\n> txid with a randomly-generated blob to your watchtower before it gives the\n> revocation key to you.\n>\n> I have described the above problem before here:\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-April/001203.html\n> with an unsatisfactory solution.\n\nIndeed, this was great observation! The tower can't be sure which client is\nuploading the \"real\" blob either. In light of that, the chosen design uses a\ntwo level bucketing structure that maps:\n\n  <txid[:16]> -> client_pubkey1 : encrypted_blob1\n                    -> client_pubkey2 : encrypted_blob2\n\nensuring that different client's can't overwrite each other. Further, the tower\nwill only store one blob for a given txid per client. Upon decryption, the tower\nwould learn that only one of this a valid update (and possibly delete state for\nthe offender).\n\n> However, this remains your counterparty best avenue of attack, is to simply\n> spam your watchtower until it runs out of resources and crashes.\n\nThe client pubkeys described above are tied to what we've been referring to as a\nsession. In order for a client to facilitate the attack described above, they\nwould have to pay the tower for multiple sessions tied to different ephemeral\nsession keys.\n\nA session grants the client the ability to store up to N blobs, where N would be\nseveral thousand. Thus, the cost to perform the attack would be many orders of\nmagnitude greater than the cost to back up one channel. In the private tower\ncase, there isn't necessarily payment, though it's more or less assumed that one\nwouldn't DOS their own tower.\n\nIn practice, the tower should only ever accept sessions if it can be certain it\nhas the appropriate disk-space to facilitate them, so I don't think\nthere is much\nrisk in the node crashing due to this. Someone could still pay to fill\nup my tower,\nbut the tower would be compensated appropriately. The tower could also raise\nit's price point if it detects such behavior.\n\n> And if the watchtower identifies the user, then this leaks the privacy of the\n> user to the watchtower, and what would then be the point of encrypted blob?\n\nI believe the same session-based, encrypted-blob approach would work eltoo\ntowers as well, if the concern is primarily about the channel partner presuming\nthe valid blob. The general design should be readily able to serve\neltoo clients,\nwith some slight modifications to breach detection and justice txn construction.\n\nMy greater concern with the update-and-replace model is that it leaks timing\ninformation about a particular channel to the tower, since the tower must know\nwhich prior state needs replacing. So even though it is possible to make eltoo\ntowers constant-space per channel, IMO we're better off storing all prior\nencrypted blobs to maintain adequate privacy. On private towers, perhaps this\nprivacy/space tradeoff may acceptable, but not sure if the tradeoff makes sense\non public towers.\n\nCheers,\nConner\n\nOn Mon, Nov 12, 2018 at 1:18 AM ZmnSCPxj via Lightning-dev\n<lightning-dev at lists.linuxfoundation.org> wrote:\n>\n> Good morning list,\n>\n> We were not able to discuss this topic much at recent summit, but I noticed that lnd has some code related to watchtowers already.  From my bare knowledge of go, it seems data structures and messages so far, without actual logic, but please inform me if I am incorrect.\n>\n> I assume much of the watchtowers code and design in lnd is by Conner, simply because, he discussed this on this list earlier this year.\n>\n> I have seen recently, some paper about paying watchtowers by actually simulating breaches.  You would give a watchtower some txid+blob pair, then send that txid and see if the watchtower claims it.  If it does, then you have evidence of liveness and correct behavior, and have also paid for and incentivized the watchtower to operate correctly.\n>\n> Note however that watchtowers would require to keep all encrypted blobs that are keyed to the same partial txid.  I.e. watchtowers need to store the pair in a set with the set looking at the entire txid+blob as the identity of the object.  Otherwise it would be possible, if your watchtower is identified by your counterparty, for the counterparty to give the commitment transaction's txid with a randomly-generated blob to your watchtower before it gives the revocation key to you.  However, this remains your counterparty best avenue of attack, is to simply spam your watchtower until it runs out of resources and crashes.\n>\n> I have described the above problem before here: https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-April/001203.html with an unsatisfactory solution.\n>\n> --\n>\n> I have also been thinking about watchtowers compatible with Decker-Russell-Osuntokun channels.\n>\n> As I understand, in a separate thread, laolu is promoting that Decker-Russell-Osuntokun channels can simply \"update\" the blob side of a txid-blob entry, with the txid being the kickoff/trigger transaction.  As I point out, unless the watchtower identifies the user somehow, this is unsafe; if I can identify your watchtower, then after you update it but before I attack, I can \"update\" the blob side with a randomly-generated, invalid blob.  And if the watchtower identifies the user, then this leaks the privacy of the user to the watchtower, and what would then be the point of encrypted blob? https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-May/001264.html\n>\n> I am curious what Conner and the other lnd developers are planning for these issues?  You seem to be the first movers into this, and I cannot read go well enough to decipher what plans you have.\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Conner Fromknecht",
                "date": "2018-11-14T00:28:38",
                "message_text_only": "Quick correction:\n\n> Thus, the cost to perform the attack would be many orders of\n> magnitude greater than the cost to back up one channel.\n\nThis was written assuming the attacker was trying to upload multiple encrypted\nblobs for the same txid, which seems like an unlikely attack vector if the tower\ninherently defends against it. If instead they are just trying to fill\nup the tower, the cost\nis linear in the amount of blobs they send.\n\n--Conner\nOn Tue, Nov 13, 2018 at 4:12 PM Conner Fromknecht\n<conner at lightning.engineering> wrote:\n>\n> Hi ZmnSCPxj,\n>\n> I haven't yet gotten around to writing up everything documenting in the working\n> watchtower design. However, I think we are nearing that phase where things seem\n> mostly solidified and would welcome feedback before attempting to formalize it.\n> Expect some follow up posts on the ML :)\n>\n> > From my bare knowledge of go, it seems data structures and messages so far,\n> > without actual logic, but please inform me if I am incorrect.\n>\n> Much of the server side has been implemented, which accepts encrypted blobs from\n> watchtower clients and stores them. The functionality related to scanning blocks\n> and publishing justice txns has also been implemented, but has not been merged\n> yet. The big remaining task is to integrate the client such that it properly\n> backs up states after receiving revocations from the remote peer.\n>\n> > Note however that watchtowers would require to keep all encrypted blobs that\n> > are keyed to the same partial txid.  I.e. watchtowers need to store the pair\n> > in a set with the set looking at the entire txid+blob as the identity of the\n> > object.  Otherwise it would be possible, if your watchtower is identified by\n> > your counterparty, for the counterparty to give the commitment transaction's\n> > txid with a randomly-generated blob to your watchtower before it gives the\n> > revocation key to you.\n> >\n> > I have described the above problem before here:\n> > https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-April/001203.html\n> > with an unsatisfactory solution.\n>\n> Indeed, this was great observation! The tower can't be sure which client is\n> uploading the \"real\" blob either. In light of that, the chosen design uses a\n> two level bucketing structure that maps:\n>\n>   <txid[:16]> -> client_pubkey1 : encrypted_blob1\n>                     -> client_pubkey2 : encrypted_blob2\n>\n> ensuring that different client's can't overwrite each other. Further, the tower\n> will only store one blob for a given txid per client. Upon decryption, the tower\n> would learn that only one of this a valid update (and possibly delete state for\n> the offender).\n>\n> > However, this remains your counterparty best avenue of attack, is to simply\n> > spam your watchtower until it runs out of resources and crashes.\n>\n> The client pubkeys described above are tied to what we've been referring to as a\n> session. In order for a client to facilitate the attack described above, they\n> would have to pay the tower for multiple sessions tied to different ephemeral\n> session keys.\n>\n> A session grants the client the ability to store up to N blobs, where N would be\n> several thousand. Thus, the cost to perform the attack would be many orders of\n> magnitude greater than the cost to back up one channel. In the private tower\n> case, there isn't necessarily payment, though it's more or less assumed that one\n> wouldn't DOS their own tower.\n>\n> In practice, the tower should only ever accept sessions if it can be certain it\n> has the appropriate disk-space to facilitate them, so I don't think\n> there is much\n> risk in the node crashing due to this. Someone could still pay to fill\n> up my tower,\n> but the tower would be compensated appropriately. The tower could also raise\n> it's price point if it detects such behavior.\n>\n> > And if the watchtower identifies the user, then this leaks the privacy of the\n> > user to the watchtower, and what would then be the point of encrypted blob?\n>\n> I believe the same session-based, encrypted-blob approach would work eltoo\n> towers as well, if the concern is primarily about the channel partner presuming\n> the valid blob. The general design should be readily able to serve\n> eltoo clients,\n> with some slight modifications to breach detection and justice txn construction.\n>\n> My greater concern with the update-and-replace model is that it leaks timing\n> information about a particular channel to the tower, since the tower must know\n> which prior state needs replacing. So even though it is possible to make eltoo\n> towers constant-space per channel, IMO we're better off storing all prior\n> encrypted blobs to maintain adequate privacy. On private towers, perhaps this\n> privacy/space tradeoff may acceptable, but not sure if the tradeoff makes sense\n> on public towers.\n>\n> Cheers,\n> Conner\n>\n> On Mon, Nov 12, 2018 at 1:18 AM ZmnSCPxj via Lightning-dev\n> <lightning-dev at lists.linuxfoundation.org> wrote:\n> >\n> > Good morning list,\n> >\n> > We were not able to discuss this topic much at recent summit, but I noticed that lnd has some code related to watchtowers already.  From my bare knowledge of go, it seems data structures and messages so far, without actual logic, but please inform me if I am incorrect.\n> >\n> > I assume much of the watchtowers code and design in lnd is by Conner, simply because, he discussed this on this list earlier this year.\n> >\n> > I have seen recently, some paper about paying watchtowers by actually simulating breaches.  You would give a watchtower some txid+blob pair, then send that txid and see if the watchtower claims it.  If it does, then you have evidence of liveness and correct behavior, and have also paid for and incentivized the watchtower to operate correctly.\n> >\n> > Note however that watchtowers would require to keep all encrypted blobs that are keyed to the same partial txid.  I.e. watchtowers need to store the pair in a set with the set looking at the entire txid+blob as the identity of the object.  Otherwise it would be possible, if your watchtower is identified by your counterparty, for the counterparty to give the commitment transaction's txid with a randomly-generated blob to your watchtower before it gives the revocation key to you.  However, this remains your counterparty best avenue of attack, is to simply spam your watchtower until it runs out of resources and crashes.\n> >\n> > I have described the above problem before here: https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-April/001203.html with an unsatisfactory solution.\n> >\n> > --\n> >\n> > I have also been thinking about watchtowers compatible with Decker-Russell-Osuntokun channels.\n> >\n> > As I understand, in a separate thread, laolu is promoting that Decker-Russell-Osuntokun channels can simply \"update\" the blob side of a txid-blob entry, with the txid being the kickoff/trigger transaction.  As I point out, unless the watchtower identifies the user somehow, this is unsafe; if I can identify your watchtower, then after you update it but before I attack, I can \"update\" the blob side with a randomly-generated, invalid blob.  And if the watchtower identifies the user, then this leaks the privacy of the user to the watchtower, and what would then be the point of encrypted blob? https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-May/001264.html\n> >\n> > I am curious what Conner and the other lnd developers are planning for these issues?  You seem to be the first movers into this, and I cannot read go well enough to decipher what plans you have.\n> >\n> > Regards,\n> > ZmnSCPxj\n> >\n> >\n> >\n> > _______________________________________________\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-15T08:23:36",
                "message_text_only": "Good morning Conner,\n\n\n\n> >\n> > > From my bare knowledge of go, it seems data structures and messages so far,\n> > > without actual logic, but please inform me if I am incorrect.\n> >\n> > Much of the server side has been implemented, which accepts encrypted blobs from\n> > watchtower clients and stores them. The functionality related to scanning blocks\n> > and publishing justice txns has also been implemented, but has not been merged\n> > yet. The big remaining task is to integrate the client such that it properly\n> > backs up states after receiving revocations from the remote peer.\n\nIs the server in a different repo from lnd?\nI suppose I should look at non-c-lightning repos more often.\n\n> >\n> > > Note however that watchtowers would require to keep all encrypted blobs that\n> > > are keyed to the same partial txid. I.e. watchtowers need to store the pair\n> > > in a set with the set looking at the entire txid+blob as the identity of the\n> > > object. Otherwise it would be possible, if your watchtower is identified by\n> > > your counterparty, for the counterparty to give the commitment transaction's\n> > > txid with a randomly-generated blob to your watchtower before it gives the\n> > > revocation key to you.\n> > > I have described the above problem before here:\n> > > https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-April/001203.html\n> > > with an unsatisfactory solution.\n> >\n> > Indeed, this was great observation! The tower can't be sure which client is\n> > uploading the \"real\" blob either. In light of that, the chosen design uses a\n> > two level bucketing structure that maps:\n> > <txid[:16]> -> client_pubkey1 : encrypted_blob1\n> > -> client_pubkey2 : encrypted_blob2\n> > ensuring that different client's can't overwrite each other. Further, the tower\n> > will only store one blob for a given txid per client. Upon decryption, the tower\n> > would learn that only one of this a valid update (and possibly delete state for\n> > the offender).\n> >\n> > > However, this remains your counterparty best avenue of attack, is to simply\n> > > spam your watchtower until it runs out of resources and crashes.\n> >\n> > The client pubkeys described above are tied to what we've been referring to as a\n> > session. In order for a client to facilitate the attack described above, they\n> > would have to pay the tower for multiple sessions tied to different ephemeral\n> > session keys.\n> > A session grants the client the ability to store up to N blobs, where N would be\n> > several thousand. Thus, the cost to perform the attack would be many orders of\n> > magnitude greater than the cost to back up one channel. In the private tower\n> > case, there isn't necessarily payment, though it's more or less assumed that one\n> > wouldn't DOS their own tower.\n> > In practice, the tower should only ever accept sessions if it can be certain it\n> > has the appropriate disk-space to facilitate them, so I don't think\n> > there is much\n> > risk in the node crashing due to this. Someone could still pay to fill\n> > up my tower,\n> > but the tower would be compensated appropriately. The tower could also raise\n> > it's price point if it detects such behavior.\n\nI understand.\nIt seems similar to \"ticket\" system I proposed in that post also.\n\nSomebody (not in summit, it was some paper whose author I forgot, and whose title I also forgot...) gave a good idea of combining paying the watchtower with checking if the watchtower is actually working.\nBasically, we simulate a breach, which releases some money to the watchtower.\nIf the watchtower correctly fixes the breach, then it gets paid.\nIf not, we retain our money and can find another watchtower.\nHowever, it seems not so compatible with session system...?\nYou have to pay to get a session key first, and this cannot be recovered if the watchtower turns out to not actually monitor breaches.\n(I suppose the session keys could be low cost, since they are effectively just spam prevention, and watchtowers could charge larger for breach recovery, in which case it may be sensible to have both.)\n\n> >\n> > > And if the watchtower identifies the user, then this leaks the privacy of the\n> > > user to the watchtower, and what would then be the point of encrypted blob?\n> >\n> > I believe the same session-based, encrypted-blob approach would work eltoo\n> > towers as well, if the concern is primarily about the channel partner presuming\n> > the valid blob. The general design should be readily able to serve\n> > eltoo clients,\n> > with some slight modifications to breach detection and justice txn construction.\n> > My greater concern with the update-and-replace model is that it leaks timing\n> > information about a particular channel to the tower, since the tower must know\n> > which prior state needs replacing. So even though it is possible to make eltoo\n> > towers constant-space per channel, IMO we're better off storing all prior\n> > encrypted blobs to maintain adequate privacy. On private towers, perhaps this\n> > privacy/space tradeoff may acceptable, but not sure if the tradeoff makes sense\n> > on public towers.\n\nIndeed, replacement here implies that the watchtower can track channels.\nWith sessions but not replacement, the watchtower knows a single session belongs to a single node, but does not know how many channels the node has.\n\nHowever, if so, what txid will eltoo watchtowers watch for?\nThe trigger transaction will have fixed txid, but is constant for the entire channel lifetime (and thus leaks which channel is being watched).\nThe update transactions will vary their txid because fees are paid by adding more inputs.\nAn idea I had before was that the result of sighash function would be the key instead of the txid, since under `SIGHASH_NOINPUT` the same result of the sighash function will be used regardless of additional inputs/outputs/fees on update transactions.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Trustless Watchtowers",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Conner Fromknecht",
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 23445
        }
    },
    {
        "title": "[Lightning-dev] Recovering protocol with watchtowers",
        "thread_messages": [
            {
                "author": "Margherita Favaretto",
                "date": "2018-11-12T18:59:31",
                "message_text_only": "Hello, dev-lightning community,\nI\u2019m writing to you to share an update of my Thesis project (previous object e-mail: Recovering protocol for Lightning network 11/01/2018).\nI warn you that this message is quite long, but I hope that could be interesting for you, and then it would be great receiving your opinions. :-)\n\nThe problem that I'm focusing on is the recovering mechanism of false positive in the Lightning network, that it is possible to re-define as how it is possible to have a solution of backup in the network in case of false positive nodes, with a particular attention to privacy and security.\nFirst of all, compared to the solution proposed in the previous e-mail, I've decided not to use the other connected nodes as the back-up of recent status, but using Watchtowers. In fact, the problem of using a normal node is that it might be offline, and so it could not guarantee the service of backup.\nIn my design, I consider a watchtower simply as a full node that is online 24h, but I have not considered the mechanism of monitoring status channel (maybe we can overlap the two functions later).\n\nAn example is that in the near future, the main e-commerce organizations may offer a new service of \"Watchtower- Recovery\", that the nodes can purchase to back up their commitments data. This means that the user can leverage a payment channel with the watchtower offering the service.\n\nThis feature strongly suggests using more than one watchtower, to mitigate the risk that a single watchtower is attacked and all data inside are deleted.\n\nIn my solution, I define two new concepts:\n- nonce-time Tn, as the current value of nonce-time (sequential integer number that defines the order   of the backups)\n- payload P, that consists of\n  1.a zip of all status channels of a node A at a specific time T1\n  2. the nonce time corresponds to the time T1 of the status contained in the zip\n  3. channel_id of the channel with A\nThis payload is encrypted by the public key of the node A, so the watchtowers cannot know the status channel of A. -> {zip(T1), T1, channel_id} pk(A)\n\nThe idea is not sent all data to all watchtowers, but just send the actual nonce-time and the actual payload to one of the watchtower, and just send the new nonce-time to the others. Therefore, we can split the data into different watchtowers, without sending the payload after each transaction to all of them.\n\nTo explain the design, let's consider Alice, which has a channel (with Eltoo protocol) with Bob, Charlie, Diana, and three watchtowers W0, W1 and W2. Everytime that Alice is online, she is connected to the three watchtowers.\n\nHow to send data to the watchtowers\n\nAlice and Bob change their status channel. So, Alice sends the new status to the watchtowers W0 and shares the current nonce-time with W1 and W2. When Alice sends her information to the three watchtowers, these memorize the node, current nonce-time, payload:\n\nW0: A T0 P0\nW1: A T0   -\nW2: A T0   -\n\nAlice and Charlie change the status of their channel. So, Alice sends the new status to W1 and sends the new nonce-time to the others, which substitute the previous current nonce-time in the information of A:\n\nW0: A T1 P0\nW1: A T1 P1\nW2: A T1  -\n\nAlice and Diana change the status of their channel. So, Alice sends the new status to W2 and sends the new nonce-time to the others:\n\nW0: A T2 P0\nW1: A T2 P1\nW2: A T2 P2\n\nAlice and Charlie change again the status of the channel. So, Alice sends the new status to W1 and upgrade the nonce in the others:\nW0: A T3 P3\nW1: A T3 P1\nW2: A T3 P2\n\nHow to request back up to the watchtowers\n\nWhen Alice needs to have the backup of all her data, she has to ask all her watchtowers the information connected to her node. For example, taking the last example above:\n\nW0 sends {A, T3, P3} to A\nW1 sends {A, T3, P1} to A\nW2 sends {A, T3, P2} to A\n\nAlice analyzes the information sent by W2, she notices that the payload contains the nonce T2, whereas the new nonce-time is T3. Then, she notices that the payload sent by W1 corresponds to T1, but the nonce is T3. When Alice analyzes the information sent by W0, she can analyze that the Payload corresponds to T3, that is also the last nonce-time. So Alice knows her last status.\n\nSecurity\n\nSince all the watchtowers store the current time-nonce and the payload is encrypted with the public key of A, we can mitigate the following risks:\n- a watchtower sends an older payload instead of the last one. The payload has to contain the current time-nonce to be considered the last one, each payload with a nonce time older are not considered.\n- if the watchtower W0 with the last payload P3, sends P0 and you know that the current nonce time is T3, it is possible to discover the malicious activity. If W1 has the payload P1, the W2 has the payload P2 and the current nonce-time is T3, I could conclude that W0 contains P3 and is cheating.\n-If one of the watchtowers, W3 decides to change the nonce-time, for example from T3 to T5 and send to A T5 with the payload. Alice can think that the actual time-nonce is T5, but no one of the watchtowers contains a payload corresponding to the state T5. This sort of misbehaviour is solved from the majority, e.g. if 2/3 nodes confirm that the actual nonce-time is T3, Alice considers this last nonce-time as the last one and not T5. The attack can happen just If the 51% of the watchtower agree to cheat and send to Alice another nonce-time.\n\n\nFee\n\nEvery time that the node A requests data to the watchtower for the backup, she sends it a small fee through the Lightning channel. This money encourages the watchtowers to guarantee the service every time.\n\n\nThis one is a simple draft of my design, If you have any feedback/suggestions, please do not hesitate to contact me, even a short feedback would be very helpful! :-)\nIn more details, I'd like to know does it make sense to overlap the concept of watchtower with the mechanism of backup?\n\n\nThank you very much in advance,\n\nCheers\nMargherita\n\n\n\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181112/5b5e5313/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-12T23:33:41",
                "message_text_only": "Good morning Margherita,\n\nHow does this scheme protect privacy of node?\nI would at least suggest that the pubkey used be different from the node normal pubkey.\n\nIf I find out the pubkey of A, can I spoof A and give a higher nonce value with a blob containing random data (which is indistinguishable from a properly-implemented ciphertext) to the watchtowers of A?  Presumably part of the protocol will require that any updates be signed using the key of A, otherwise I can easily corrupt the data being backed up for A.\n\nIn case of a breach while node A is offline, can the Watchtowers do anything?\nPlease note, that main purpose of Watchtowers is to handle breaches while client is offline, not backup.\nIt would be pointless for Watchtower to exist if it can only provide data while A is online.\nThe best time to attack A is when A is unable to defend itself.\nPlease refer to https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-April/001196.html for information on what we consider the best design for watchtowers so far.\n\nPlease note also, that you cannot make a single channel with multiple peers; you must make a channel for each peer.\n(well it is theoretically possible, with eltoo, to make multi-party channel. but it requires all members to be online at every update, such that if a single party is offline, the channel is unuseable; having multiple 2-party channels with each peer is far better since if one of your peers drops, you can use the channels with other peers)\n\nRegards,\nZmnSCPxj\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Tuesday, November 13, 2018 2:59 AM, Margherita Favaretto <s170065 at student.dtu.dk> wrote:\n\n> Hello, dev-lightning community,\n> I\u2019m writing to you to share an update of my Thesis project (previous object e-mail: Recovering protocol for Lightning network 11/01/2018).\n> I warn you that this message is quite long, but I hope that could be interesting for you, and then it would be great receiving your opinions. :-)\n>\n> The problem that I'm focusing on is the recovering mechanism of false positive in the Lightning network, that it is possible to re-define as how it is possible to have a solution of backup in the network in case of false positive nodes, with a particular attention to privacy and security.\n> First of all, compared to the solution proposed in the previous e-mail, I've decided not to use the other connected nodes as the back-up of recent status, but using Watchtowers. In fact, the problem of using a normal node is that it might be offline, and so it could not guarantee the service of backup.\n> In my design, I consider a watchtower simply as a full node that is online 24h, but I have not considered the mechanism of monitoring status channel (maybe we can overlap the two functions later).\n>\n> An example is that in the near future, the main e-commerce organizations may offer a new service of \"Watchtower- Recovery\", that the nodes can purchase to back up their commitments data. This means that the user can leverage a payment channel with the watchtower offering the service.\n>\n> This feature strongly suggests using more than one watchtower, to mitigate the risk that a single watchtower is attacked and all data inside are deleted.\n>\n> In my solution, I define two new concepts:\n> - nonce-time Tn, as the current value of nonce-time (sequential integer number that defines the order   of the backups)\n> - payload P, that consists of\n>   1.a zip of all status channels of a node A at a specific time T1\n>   2. the nonce time corresponds to the time T1 of the status contained in the zip\n>   3. channel_id of the channel with A\n> This payload is encrypted by the public key of the node A, so the watchtowers cannot know the status channel of A. -> {zip(T1), T1, channel_id} pk(A)\n>\n> The idea is not sent all data to all watchtowers, but just send the actual nonce-time and the actual payload to one of the watchtower, and just send the new nonce-time to the others. Therefore, we can split the data into different watchtowers, without sending the payload after each transaction to all of them.\n>\n> To explain the design, let's consider Alice, which has a channel (with Eltoo protocol) with Bob, Charlie, Diana, and three watchtowers W0, W1 and W2. Everytime that Alice is online, she is connected to the three watchtowers.\n>\n> How to send data to the watchtowers\n>\n> Alice and Bob change their status channel. So, Alice sends the new status to the watchtowers W0 and shares the current nonce-time with W1 and W2. When Alice sends her information to the three watchtowers, these memorize the node, current nonce-time, payload:\n>\n> W0: A T0 P0\n> W1: A T0   -\n> W2: A T0   -\n>\n> Alice and Charlie change the status of their channel. So, Alice sends the new status to W1 and sends the new nonce-time to the others, which substitute the previous current nonce-time in the information of A:\n>\n> W0: A T1 P0\n> W1: A T1 P1\n> W2: A T1  -\n>\n> Alice and Diana change the status of their channel. So, Alice sends the new status to W2 and sends the new nonce-time to the others:\n>\n> W0: A T2 P0\n> W1: A T2 P1\n> W2: A T2 P2\n>\n> Alice and Charlie change again the status of the channel. So, Alice sends the new status to W1 and upgrade the nonce in the others:\n> W0: A T3 P3\n> W1: A T3 P1\n> W2: A T3 P2\n>\n> How to request back up to the watchtowers\n>\n> When Alice needs to have the backup of all her data, she has to ask all her watchtowers the information connected to her node. For example, taking the last example above:\n>\n> W0 sends {A, T3, P3} to A\n> W1 sends {A, T3, P1} to A\n> W2 sends {A, T3, P2} to A\n>\n> Alice analyzes the information sent by W2, she notices that the payload contains the nonce T2, whereas the new nonce-time is T3. Then, she notices that the payload sent by W1 corresponds to T1, but the nonce is T3. When Alice analyzes the information sent by W0, she can analyze that the Payload corresponds to T3, that is also the last nonce-time. So Alice knows her last status.\n>\n> Security\n>\n> Since all the watchtowers store the current time-nonce and the payload is encrypted with the public key of A, we can mitigate the following risks:\n> - a watchtower sends an older payload instead of the last one. The payload has to contain the current time-nonce to be considered the last one, each payload with a nonce time older are not considered.\n> - if the watchtower W0 with the last payload P3, sends P0 and you know that the current nonce time is T3, it is possible to discover the malicious activity. If W1 has the payload P1, the W2 has the payload P2 and the current nonce-time is T3, I could conclude that W0 contains P3 and is cheating.\n> -If one of the watchtowers, W3 decides to change the nonce-time, for example from T3 to T5 and send to A T5 with the payload. Alice can think that the actual time-nonce is T5, but no one of the watchtowers contains a payload corresponding to the state T5. This sort of misbehaviour is solved from the majority, e.g. if 2/3 nodes confirm that the actual nonce-time is T3, Alice considers this last nonce-time as the last one and not T5. The attack can happen just If the 51% of the watchtower agree to cheat and send to Alice another nonce-time.\n>\n> Fee\n>\n> Every time that the node A requests data to the watchtower for the backup, she sends it a small fee through the Lightning channel. This money encourages the watchtowers to guarantee the service every time.\n>\n> This one is a simple draft of my design, If you have any feedback/suggestions, please do not hesitate to contact me, even a short feedback would be very helpful! :-)\n> In more details, I'd like to know does it make sense to overlap the concept of watchtower with the mechanism of backup?\n>\n> Thank you very much in advance,\n>\n> Cheers\n> Margherita\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181112/a2259961/attachment-0001.html>"
            },
            {
                "author": "Margherita Favaretto",
                "date": "2018-11-13T20:30:20",
                "message_text_only": "Hello ZmnSCPxj,\r\nthanks for your e-mail and your feedback, I'll answer your questions in the following points.\r\n\r\nIn case of a breach while node A is offline, can the Watchtowers do anything?\r\nIn my solution, the function of backup is not destinated to substitute the first function of the watchtower, that is monitoring the status channel, but instead, the backup option can be considered as a sort of additional feature.\r\nI haven't merged the two functions yet, but the idea is to collaborate to have watchtowers which can have the function of monitor the channel, so defend A when it is offline, but also the function of backup when A loses the data of past commitments (e.g. software doesn't work properly). So, I'd like to highlight that the two functions are independent.\r\nThe reason because I'm using a watchtower is just because I need a full node online 24h, that can guarantee the service.\r\nIn my solution, the payment channels are created ad-hoc for the backup mechanism, and in the commitment transaction between the node A and the Watchtower has to be added a new field that contains the current nonce-time and payload.\r\n\r\nHow does this scheme protect the privacy of a node?\r\nThis scheme protects the privacy of the node because the payload contained the information of status channel and nonce-time are encrypted on the public key of A. So the watchtowers cannot decrypt the payload and modify it (e.g. with a higher nonce value as you wrote) since just A has the own private key.\r\n\r\nIf you refer that another node can personify A and send the payload to a watchtower, this is not possible since the payload has to contain the channel_id between A and the specific watchtower, and this information is not known by the other node of the network. So, A can discover a malicious activity because that channel_id is not correct.\r\n\r\nAs I've written in the previous point, my work is independence from the function of monitoring the channel when node A is offline, so my project doesn't use the blob data.\r\n\r\nI hope to get the question, otherwise, could you explain a little bit more the point, please?\r\n\r\nPlease note also, that you cannot make a single channel with multiple peers; [...]\r\nAs regarding the channel, If A has three watchtowers, it has to have three distinct payment channels. Every watchtower is independence from the others.\r\n\r\nIf you have any opinions/feedback/suggestions, please do not hesitate to write to me.  : -)\r\n\r\nKind regards,\r\nMargherita\r\n\r\n________________________________\r\nDa: ZmnSCPxj <ZmnSCPxj at protonmail.com>\r\nInviato: marted\u00a8\u00ac 13 novembre 2018 00:33:41\r\nA: Margherita Favaretto\r\nCc: lightning-dev at lists.linuxfoundation.org\r\nOggetto: Re: [Lightning-dev] Recovering protocol with watchtowers\r\n\r\nGood morning Margherita,\r\n\r\nHow does this scheme protect privacy of node?\r\nI would at least suggest that the pubkey used be different from the node normal pubkey.\r\n\r\nIf I find out the pubkey of A, can I spoof A and give a higher nonce value with a blob containing random data (which is indistinguishable from a properly-implemented ciphertext) to the watchtowers of A?  Presumably part of the protocol will require that any updates be signed using the key of A, otherwise I can easily corrupt the data being backed up for A.\r\n\r\nIn case of a breach while node A is offline, can the Watchtowers do anything?\r\nPlease note, that main purpose of Watchtowers is to handle breaches while client is offline, not backup.\r\nIt would be pointless for Watchtower to exist if it can only provide data while A is online.\r\nThe best time to attack A is when A is unable to defend itself.\r\nPlease refer to https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-April/001196.html for information on what we consider the best design for watchtowers so far.\r\n\r\nPlease note also, that you cannot make a single channel with multiple peers; you must make a channel for each peer.\r\n(well it is theoretically possible, with eltoo, to make multi-party channel. but it requires all members to be online at every update, such that if a single party is offline, the channel is unuseable; having multiple 2-party channels with each peer is far better since if one of your peers drops, you can use the channels with other peers)\r\n\r\nRegards,\r\nZmnSCPxj\r\n\r\n\u00a9\\\u00a9\\\u00a9\\\u00a9\\\u00a9\\\u00a9\\\u00a9\\ Original Message \u00a9\\\u00a9\\\u00a9\\\u00a9\\\u00a9\\\u00a9\\\u00a9\\\r\nOn Tuesday, November 13, 2018 2:59 AM, Margherita Favaretto <s170065 at student.dtu.dk> wrote:\r\n\r\nHello, dev-lightning community,\r\nI\u00a1\u00afm writing to you to share an update of my Thesis project (previous object e-mail: Recovering protocol for Lightning network 11/01/2018).\r\nI warn you that this message is quite long, but I hope that could be interesting for you, and then it would be great receiving your opinions. :-)\r\n\r\nThe problem that I'm focusing on is the recovering mechanism of false positive in the Lightning network, that it is possible to re-define as how it is possible to have a solution of backup in the network in case of false positive nodes, with a particular attention to privacy and security.\r\nFirst of all, compared to the solution proposed in the previous e-mail, I've decided not to use the other connected nodes as the back-up of recent status, but using Watchtowers. In fact, the problem of using a normal node is that it might be offline, and so it could not guarantee the service of backup.\r\nIn my design, I consider a watchtower simply as a full node that is online 24h, but I have not considered the mechanism of monitoring status channel (maybe we can overlap the two functions later).\r\n\r\nAn example is that in the near future, the main e-commerce organizations may offer a new service of \"Watchtower- Recovery\", that the nodes can purchase to back up their commitments data. This means that the user can leverage a payment channel with the watchtower offering the service.\r\n\r\nThis feature strongly suggests using more than one watchtower, to mitigate the risk that a single watchtower is attacked and all data inside are deleted.\r\n\r\nIn my solution, I define two new concepts:\r\n- nonce-time Tn, as the current value of nonce-time (sequential integer number that defines the order   of the backups)\r\n- payload P, that consists of\r\n  1.a zip of all status channels of a node A at a specific time T1\r\n  2. the nonce time corresponds to the time T1 of the status contained in the zip\r\n  3. channel_id of the channel with A\r\nThis payload is encrypted by the public key of the node A, so the watchtowers cannot know the status channel of A. -> {zip(T1), T1, channel_id} pk(A)\r\n\r\nThe idea is not sent all data to all watchtowers, but just send the actual nonce-time and the actual payload to one of the watchtower, and just send the new nonce-time to the others. Therefore, we can split the data into different watchtowers, without sending the payload after each transaction to all of them.\r\n\r\nTo explain the design, let's consider Alice, which has a channel (with Eltoo protocol) with Bob, Charlie, Diana, and three watchtowers W0, W1 and W2. Everytime that Alice is online, she is connected to the three watchtowers.\r\n\r\nHow to send data to the watchtowers\r\n\r\nAlice and Bob change their status channel. So, Alice sends the new status to the watchtowers W0 and shares the current nonce-time with W1 and W2. When Alice sends her information to the three watchtowers, these memorize the node, current nonce-time, payload:\r\n\r\nW0: A T0 P0\r\nW1: A T0   -\r\nW2: A T0   -\r\n\r\nAlice and Charlie change the status of their channel. So, Alice sends the new status to W1 and sends the new nonce-time to the others, which substitute the previous current nonce-time in the information of A:\r\n\r\nW0: A T1 P0\r\nW1: A T1 P1\r\nW2: A T1  -\r\n\r\nAlice and Diana change the status of their channel. So, Alice sends the new status to W2 and sends the new nonce-time to the others:\r\n\r\nW0: A T2 P0\r\nW1: A T2 P1\r\nW2: A T2 P2\r\n\r\nAlice and Charlie change again the status of the channel. So, Alice sends the new status to W1 and upgrade the nonce in the others:\r\nW0: A T3 P3\r\nW1: A T3 P1\r\nW2: A T3 P2\r\n\r\nHow to request back up to the watchtowers\r\n\r\nWhen Alice needs to have the backup of all her data, she has to ask all her watchtowers the information connected to her node. For example, taking the last example above:\r\n\r\nW0 sends {A, T3, P3} to A\r\nW1 sends {A, T3, P1} to A\r\nW2 sends {A, T3, P2} to A\r\n\r\nAlice analyzes the information sent by W2, she notices that the payload contains the nonce T2, whereas the new nonce-time is T3. Then, she notices that the payload sent by W1 corresponds to T1, but the nonce is T3. When Alice analyzes the information sent by W0, she can analyze that the Payload corresponds to T3, that is also the last nonce-time. So Alice knows her last status.\r\n\r\nSecurity\r\n\r\nSince all the watchtowers store the current time-nonce and the payload is encrypted with the public key of A, we can mitigate the following risks:\r\n- a watchtower sends an older payload instead of the last one. The payload has to contain the current time-nonce to be considered the last one, each payload with a nonce time older are not considered.\r\n- if the watchtower W0 with the last payload P3, sends P0 and you know that the current nonce time is T3, it is possible to discover the malicious activity. If W1 has the payload P1, the W2 has the payload P2 and the current nonce-time is T3, I could conclude that W0 contains P3 and is cheating.\r\n-If one of the watchtowers, W3 decides to change the nonce-time, for example from T3 to T5 and send to A T5 with the payload. Alice can think that the actual time-nonce is T5, but no one of the watchtowers contains a payload corresponding to the state T5. This sort of misbehaviour is solved from the majority, e.g. if 2/3 nodes confirm that the actual nonce-time is T3, Alice considers this last nonce-time as the last one and not T5. The attack can happen just If the 51% of the watchtower agree to cheat and send to Alice another nonce-time.\r\n\r\n\r\nFee\r\n\r\nEvery time that the node A requests data to the watchtower for the backup, she sends it a small fee through the Lightning channel. This money encourages the watchtowers to guarantee the service every time.\r\n\r\n\r\nThis one is a simple draft of my design, If you have any feedback/suggestions, please do not hesitate to contact me, even a short feedback would be very helpful! :-)\r\nIn more details, I'd like to know does it make sense to overlap the concept of watchtower with the mechanism of backup?\r\n\r\n\r\nThank you very much in advance,\r\n\r\nCheers\r\nMargherita\r\n\r\n\r\n\r\n\r\n\r\n\r\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181113/6170eec2/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-13T23:08:40",
                "message_text_only": "Good morning Margherita,\n\n> In case of a breach while node A is offline, can the Watchtowers do anything?\n> In my solution, the function of backup is not destinated to substitute the first function of the watchtower, that is monitoring the status channel, but instead, the backup option can be considered as a sort of additional feature.\n\nWatchtowers being designed currently are keyed to a txid, whose appearance onchain triggers the watchtower behavior.\nYour scheme is keyed on a node public key.\nThere is an immediate incompatibility here.\n\nThe reason why txid is used, is to protect privacy of the node.\nThe watchtower has no identifying information, and cannot have identifying information.\nThe txid is for a transaction that is not broadcast (except in a breach attempt), so the watchtower cannot identify the node using it at all.\nThis can be important, since a hack of the watchtower might give the hackers the ability to find nodes that could be vulnerable and possibly targetable for attack.\n\nDistributed backup may be better implemented using standard techniques such as DHT.\n\n> How does this scheme protect the privacy of a node?\n> This scheme protects the privacy of the node because the payload contained the information of status channel and nonce-time are encrypted on the public key of A. So the watchtowers cannot decrypt the payload and modify it (e.g. with a higher nonce value as you wrote) since just A has the own private key.\n>\n> If you refer that another node can personify A and send the payload to a watchtower, this is not possible since the payload has to contain the channel_id between A and the specific watchtower, and this information is not known by the other node of the network. So, A can discover a malicious activity because that channel_id is not correct.\n\nIt is indeed possible, and the `channel_id` is immaterial.\nAll an attacker has to do is corrupt the backup data, not replace it with data that is favorable to it.\nWith corrupted backup data, the operation of A is doomed and irrecoverable, especially if private keys or even just derivation paths are part of the backed-up data.\n\n> Please note also, that you cannot make a single channel with multiple peers; [...]\n> As regarding the channel, If A has three watchtowers, it has to have three distinct payment channels. Every watchtower is independence from the others.\n\nThen why is the watchtower keyed to the node?  Should it not be keyed to something that is distinct for each payment channel?\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181113/ba45ff55/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Recovering protocol with watchtowers",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Margherita Favaretto",
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 27466
        }
    },
    {
        "title": "[Lightning-dev] Summary of the Second Lightning Development Summit (2018 Adelaide)",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-11-12T23:25:25",
                "message_text_only": "Two years ago, a dozen Lightning implementers met in Milan to start the\nLightning Specification 1.0.  Last week the 18 most active spec\ncontributors gathered in Adelaide to kick off version 1.1.\n\nAfter two days we emerged with 30 accepted changes for next version,\nmany very detailed and some requiring further on-list refinement.\nHighlights include multi-path payments, dual-funded channels, splicing,\nwumbo, hidden destinations, and many gossip improvements.\n\nPlease join in the continuing discussion: the work points have been\ntransferred to the Wiki:\n\n        https://github.com/lightningnetwork/lightning-rfc/wiki/Lightning-Specification-1.1-Proposal-States\n\nThanks to all those who attended and patiently contributed their\nexpertise to some extremely difficult questions; it was an honor to be\nin the room with you all.\n\nCheers,\nRusty.\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: DSCN1559.JPG\nType: image/jpeg\nSize: 3475652 bytes\nDesc: Group Photo Adelaide Lightning Summit\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181113/d7a72cad/attachment-0001.jpe>"
            },
            {
                "author": "Cezary Dziemian",
                "date": "2018-11-14T12:41:28",
                "message_text_only": "Thanks,\n\nGreat work. I'am excited especially by dual-funded channels.\n\nUnfortunately I don't know what  \"Wumbo\" and \"hidden destinations\" are.\nCould you explain or provide some links?\n\nWhat about eltoo?\n\nBest Regrads,\nCezary Dziemian\n\nwt., 13 lis 2018 o 00:29 Rusty Russell <rusty at blockstream.com> napisa\u0142(a):\n\n> Two years ago, a dozen Lightning implementers met in Milan to start the\n> Lightning Specification 1.0.  Last week the 18 most active spec\n> contributors gathered in Adelaide to kick off version 1.1.\n>\n> After two days we emerged with 30 accepted changes for next version,\n> many very detailed and some requiring further on-list refinement.\n> Highlights include multi-path payments, dual-funded channels, splicing,\n> wumbo, hidden destinations, and many gossip improvements.\n>\n> Please join in the continuing discussion: the work points have been\n> transferred to the Wiki:\n>\n>\n> https://github.com/lightningnetwork/lightning-rfc/wiki/Lightning-Specification-1.1-Proposal-States\n>\n> Thanks to all those who attended and patiently contributed their\n> expertise to some extremely difficult questions; it was an honor to be\n> in the room with you all.\n>\n> Cheers,\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181114/dec7723c/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-14T13:47:55",
                "message_text_only": "The link in the original post contains actual descriptions of \"wumbo\" and \"hidden destinations\".\nAdmittedly, the linked wiki page is not necessarily clear, so I shall describe them here anyway.\n\nWumbo is the study of all things wumbological.\nI wumbo, you wumbo, he wumbo she wumbo.\nWumboing.\nWumbological, being or having wumbo.\nIf \"M\" is \"mini\", we can turn around the \"M\" into \"W\", which means \"wumbo\".\nIn short, more clearly, \"wumbo\" mans \"maxi\" or removing the channel capacity limit.\nIf both sides of a new channel agree to wumbo each other by setting `option_i_wumbo_you_wumbo`, they can build channels with capacity higher than 167.77216mBTC.\nA node that advertises `option_wumborama` allows any node to build channels with capacity above the limit.\nPlease blame one of the persons attending the summit for this term.\nUnfortunately, due to rules imposed, non-attendees can only learn who to blame if that person admits this.\n\nHidden destinations is basically \"rendezvous routing\".\nSee \"Rendez-vous Routing\" thread by CJP on the list, and the discussion on thread \"Link-level payment splitting via intermediary rendezvous nodes\" on the list.\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Wednesday, November 14, 2018 8:41 PM, Cezary Dziemian <cezary.dziemian at gmail.com> wrote:\n\n> Thanks,\n>\n> Great work. I'am excited especially by dual-funded channels.\n>\n> Unfortunately I don't know what  \"Wumbo\" and \"hidden destinations\" are. Could you explain or provide some links?\n>\n> What about eltoo?\n>\n> Best Regrads,\n> Cezary Dziemian\n>\n> wt., 13 lis 2018 o 00:29 Rusty Russell <rusty at blockstream.com> napisa\u0142(a):\n>\n>> Two years ago, a dozen Lightning implementers met in Milan to start the\n>> Lightning Specification 1.0.  Last week the 18 most active spec\n>> contributors gathered in Adelaide to kick off version 1.1.\n>>\n>> After two days we emerged with 30 accepted changes for next version,\n>> many very detailed and some requiring further on-list refinement.\n>> Highlights include multi-path payments, dual-funded channels, splicing,\n>> wumbo, hidden destinations, and many gossip improvements.\n>>\n>> Please join in the continuing discussion: the work points have been\n>> transferred to the Wiki:\n>>\n>>         https://github.com/lightningnetwork/lightning-rfc/wiki/Lightning-Specification-1.1-Proposal-States\n>>\n>> Thanks to all those who attended and patiently contributed their\n>> expertise to some extremely difficult questions; it was an honor to be\n>> in the room with you all.\n>>\n>> Cheers,\n>> Rusty.\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181114/4a71172c/attachment.html>"
            },
            {
                "author": "Pierre",
                "date": "2018-11-14T14:00:04",
                "message_text_only": "> I wumbo, you wumbo, he wumbo she wumbo.\n\nI would respectfully disagree here: pretty sure that's \"he\nwumboes, she wumboes\"."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-14T23:02:36",
                "message_text_only": "While consistency with typical grammar might be desirable, as a made-up word, wumbo has the opportunity to define its own grammar.\nDo we really want to impose normal grammar on wumbo?\nWe do not want to paint ourselves in a corner if in the future we find we need the ability to define novel grammar for made-up words.\n\nGranted, we probably should not \"roll our own grammar\" without some proof of understandability.\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Wednesday, November 14, 2018 10:00 PM, Pierre <pm+lists at acinq.fr> wrote:\n\n> > I wumbo, you wumbo, he wumbo she wumbo.\n>\n> I would respectfully disagree here: pretty sure that's \"he\n> wumboes, she wumboes\"."
            }
        ],
        "thread_summary": {
            "title": "Summary of the Second Lightning Development Summit (2018 Adelaide)",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Cezary Dziemian",
                "Pierre",
                "ZmnSCPxj"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 6485
        }
    },
    {
        "title": "[Lightning-dev] Approximate assignment of option names: please fix!",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-11-12T23:49:06",
                "message_text_only": "Hi all,\n\n        I went through the wiki and made up option names (not yet\nnumbers, that comes next).  I re-read our description of global vs local\nbits:\n\n        The feature masks are split into local features (which only\n        affect the protocol between these two nodes) and global features\n        (which can affect HTLCs and are thus also advertised to other\n        nodes).\n\nYou *might* want to promote your local bit to a global bit so you can\nadvertize them (wumbo?)?  But if it's expected that every node will\neventually support a bit, then it should probably stay local.\n\nPlease edit your bits as appropriate, so I can assign bit numbers soon:\n\n        https://github.com/lightningnetwork/lightning-rfc/wiki/Lightning-Specification-1.1-Proposal-States\n\nThanks!\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-13T02:55:49",
                "message_text_only": "Good Morning Rusty,\n\nOG AMP is inherently spontaneous in nature, therefore invoice might not exist to put the feature on.\nThus it should be global feature.\n\nDo we tie spontaneous payment to OG AMP or do we support one which is payable by base AMP or normal singlepath?\n\nGiven that both `option_switch_ephkey` and `option_og_amp` require understanding extended onion packet types, would it not be better to merge them into `option_extra_onion_packet_types`?\n\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Tuesday, November 13, 2018 7:49 AM, Rusty Russell <rusty at blockstream.com> wrote:\n\n> Hi all,\n>\n> I went through the wiki and made up option names (not yet\n> numbers, that comes next). I re-read our description of global vs local\n> bits:\n>\n> The feature masks are split into local features (which only\n> affect the protocol between these two nodes) and global features\n> (which can affect HTLCs and are thus also advertised to other\n> nodes).\n>\n> You might want to promote your local bit to a global bit so you can\n> advertize them (wumbo?)? But if it's expected that every node will\n> eventually support a bit, then it should probably stay local.\n>\n> Please edit your bits as appropriate, so I can assign bit numbers soon:\n>\n> https://github.com/lightningnetwork/lightning-rfc/wiki/Lightning-Specification-1.1-Proposal-States\n>\n> Thanks!\n> Rusty.\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-11-16T03:32:40",
                "message_text_only": "> OG AMP is inherently spontaneous in nature, therefore invoice might not\nexist\n> to put the feature on.\n\nThat is incorrect. One can use an invoice along with AMP as is, in order to\ntag\na payment. As an example, I want to deposit to an exhcange, so I get an\ninvoice\nfrom them. I note that the invoice has a special (new) field that indicates\nthey accept AMP payments, and include an 8-byte identifier. Each of the\npayment\nshards I send over to the exchange will carry this 8-byte identifier.\nInclusion\nof this identifier signals to them to credit my account with the deposit\nonce\nall the payments arrive. This generalizes to any case where a service or\ngood\nis to be dispersed once a payment is received.\n\n-- Laolu\n\n\nOn Mon, Nov 12, 2018 at 6:56 PM ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good Morning Rusty,\n>\n> OG AMP is inherently spontaneous in nature, therefore invoice might not\n> exist to put the feature on.\n> Thus it should be global feature.\n>\n> Do we tie spontaneous payment to OG AMP or do we support one which is\n> payable by base AMP or normal singlepath?\n>\n> Given that both `option_switch_ephkey` and `option_og_amp` require\n> understanding extended onion packet types, would it not be better to merge\n> them into `option_extra_onion_packet_types`?\n>\n>\n>\n> Sent with ProtonMail Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Tuesday, November 13, 2018 7:49 AM, Rusty Russell <\n> rusty at blockstream.com> wrote:\n>\n> > Hi all,\n> >\n> > I went through the wiki and made up option names (not yet\n> > numbers, that comes next). I re-read our description of global vs local\n> > bits:\n> >\n> > The feature masks are split into local features (which only\n> > affect the protocol between these two nodes) and global features\n> > (which can affect HTLCs and are thus also advertised to other\n> > nodes).\n> >\n> > You might want to promote your local bit to a global bit so you can\n> > advertize them (wumbo?)? But if it's expected that every node will\n> > eventually support a bit, then it should probably stay local.\n> >\n> > Please edit your bits as appropriate, so I can assign bit numbers soon:\n> >\n> >\n> https://github.com/lightningnetwork/lightning-rfc/wiki/Lightning-Specification-1.1-Proposal-States\n> >\n> > Thanks!\n> > Rusty.\n> >\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181115/5940c292/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-16T04:21:19",
                "message_text_only": "Good morning,\n\nI believe this is simply an argument about meanings of words; to me spontaneous means that the payee does not generate a new secret to be sold as a valuable good in exchange for money, using the mechanisms for routing on Lightning.\nIn any case, it would still be possible to perform an OG AMP payment without an invoice of any sort at all, which is the entire point of the sentence; there might not exist an invoice to put the \"I support OG AMP\" bit in.\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Friday, November 16, 2018 11:32 AM, Olaoluwa Osuntokun <laolu32 at gmail.com> wrote:\n\n>> OG AMP is inherently spontaneous in nature, therefore invoice might not exist\n>> to put the feature on.\n>\n> That is incorrect. One can use an invoice along with AMP as is, in order to tag\n> a payment. As an example, I want to deposit to an exhcange, so I get an invoice\n> from them. I note that the invoice has a special (new) field that indicates\n> they accept AMP payments, and include an 8-byte identifier. Each of the payment\n> shards I send over to the exchange will carry this 8-byte identifier. Inclusion\n> of this identifier signals to them to credit my account with the deposit once\n> all the payments arrive. This generalizes to any case where a service or good\n> is to be dispersed once a payment is received.\n>\n> -- Laolu\n>\n> On Mon, Nov 12, 2018 at 6:56 PM ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n>\n>> Good Morning Rusty,\n>>\n>> OG AMP is inherently spontaneous in nature, therefore invoice might not exist to put the feature on.\n>> Thus it should be global feature.\n>>\n>> Do we tie spontaneous payment to OG AMP or do we support one which is payable by base AMP or normal singlepath?\n>>\n>> Given that both `option_switch_ephkey` and `option_og_amp` require understanding extended onion packet types, would it not be better to merge them into `option_extra_onion_packet_types`?\n>>\n>> Sent with ProtonMail Secure Email.\n>>\n>> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>> On Tuesday, November 13, 2018 7:49 AM, Rusty Russell <rusty at blockstream.com> wrote:\n>>\n>>> Hi all,\n>>>\n>>> I went through the wiki and made up option names (not yet\n>>> numbers, that comes next). I re-read our description of global vs local\n>>> bits:\n>>>\n>>> The feature masks are split into local features (which only\n>>> affect the protocol between these two nodes) and global features\n>>> (which can affect HTLCs and are thus also advertised to other\n>>> nodes).\n>>>\n>>> You might want to promote your local bit to a global bit so you can\n>>> advertize them (wumbo?)? But if it's expected that every node will\n>>> eventually support a bit, then it should probably stay local.\n>>>\n>>> Please edit your bits as appropriate, so I can assign bit numbers soon:\n>>>\n>>> https://github.com/lightningnetwork/lightning-rfc/wiki/Lightning-Specification-1.1-Proposal-States\n>>>\n>>> Thanks!\n>>> Rusty.\n>>>\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181116/115c2abd/attachment.html>"
            },
            {
                "author": "Pierre",
                "date": "2018-11-13T12:47:54",
                "message_text_only": "Hi Rusty,\n\n>        The feature masks are split into local features (which only\n>        affect the protocol between these two nodes) and global features\n>        (which can affect HTLCs and are thus also advertised to other\n>        nodes).\n\nI don't think that definition makes a lot of sense. For example I\nprobably want to advertise the fact that my node supports\noption_data_loss_protect, which is a local feature. OTOH why would I\n*not* want to avertise a feature that I support? I struggle to see\nwhat is the point of making the distinction between local/global\nactually.\n\nAlso, as ZmnSCPxj pointed out in his Wumbo-related post, just because\nI support a feature doesn't mean that I want to apply it to any peer\nthat connects to my node. Since we can't advertise our whitelist or\nwhatever logic we use to enable a given feature for a particular node,\nwe can only be sure that a feature will be enabled by connecting to\nthe peer and seeing what's in the init message.\n\nSo how about just getting rid of the global/local distinction (I think\nthis can be done in a backward-compatible way), and use the following\ninstead:\n- in the node_announcement message, have a node_features that\ndescribes features my node supports/requires\n- in the init message, have a connection_features that are set for\nthis particular connection.\n\nObviously node_features/connection_features are related and must\n\"match\", in the sense that node_features constrains\nconnection_features, particularly if we use things like\noption_anyone_can_wumbo (again referring to ZmnSCPxj's post).\n\nCheers,\n\nPierre"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-13T23:50:49",
                "message_text_only": "Pierre <pm+lists at acinq.fr> writes:\n> Hi Rusty,\n>\n>>        The feature masks are split into local features (which only\n>>        affect the protocol between these two nodes) and global features\n>>        (which can affect HTLCs and are thus also advertised to other\n>>        nodes).\n>\n> I don't think that definition makes a lot of sense. For example I\n> probably want to advertise the fact that my node supports\n> option_data_loss_protect, which is a local feature. OTOH why would I\n> *not* want to avertise a feature that I support? I struggle to see\n> what is the point of making the distinction between local/global\n> actually.\n\nThe theory was that local features concern direct peers, global features\nconcern others (thus *must* be advertized by gossip).\n\nI *expected* local features to become ubiquitous over time, so by the\ntime an implementation decided \"I don't even want to talk to nodes\nwithout feature X\" then most nodes would support feature X, so you could\nsimply connect and you're probably OK.\n\nSo the question becomes:\n\n1. Do people want to pre-filter by local features?\n2. If so, only some local features, or all of them?\n\nIf only some, then we make those ones global features.  If all, then we\nremove the local/global distinction altogether?\n\nThanks,\nRusty."
            },
            {
                "author": "Corn\u00e9 Plooy",
                "date": "2018-11-27T15:54:27",
                "message_text_only": "The only reasons I see for keeping the global/local distinction is that\nyou might not want to gossip everything, either to keep the gossip data\nsmall, or for some privacy reasons. Apparently, that's all very\ntheoretical so far, as current features don't seem to need either.\n\n\nIdeally you'd like to have a design that requires as little consensus as\npossible, but for global feature bits it's clear there has to be\nconsensus about their meaning. For a moment I thought we'd have more\nrelaxed requirements for local feature bits (as only peers have to agree\non feature bit meanings), but if we want every peer to be able to\nconnect to every other peer, we still need global consensus on the\nmeaning of local feature bits.\n\n\nI'm not even sure it makes sense to keep certain feature bits local for\nprivacy reasons. Interested parties can usually just figure out your\nlocal feature bits by connecting to your node. As for the size of gossip\ndata: the bits themselves shouldn't be the problem. Certain features\nmight require extra data to be gossiped, but that should be discussed on\na case-by-case data per feature. We might end up with a gossip design\nwhere you'd first receive the basic gossip data, and then try to get\nextended data you're interested in, based on what feature bits are\nenabled in the basic gossip data.\n\n\nSo, maybe I missed something important, but no, right now I don't see a\ngood reason for the global/local distinction.\n\n\nCJP\n\n\nOn 14-11-18 00:50, Rusty Russell wrote:\n> Pierre <pm+lists at acinq.fr> writes:\n>> Hi Rusty,\n>>\n>>>        The feature masks are split into local features (which only\n>>>        affect the protocol between these two nodes) and global features\n>>>        (which can affect HTLCs and are thus also advertised to other\n>>>        nodes).\n>> I don't think that definition makes a lot of sense. For example I\n>> probably want to advertise the fact that my node supports\n>> option_data_loss_protect, which is a local feature. OTOH why would I\n>> *not* want to avertise a feature that I support? I struggle to see\n>> what is the point of making the distinction between local/global\n>> actually.\n> The theory was that local features concern direct peers, global features\n> concern others (thus *must* be advertized by gossip).\n>\n> I *expected* local features to become ubiquitous over time, so by the\n> time an implementation decided \"I don't even want to talk to nodes\n> without feature X\" then most nodes would support feature X, so you could\n> simply connect and you're probably OK.\n>\n> So the question becomes:\n>\n> 1. Do people want to pre-filter by local features?\n> 2. If so, only some local features, or all of them?\n>\n> If only some, then we make those ones global features.  If all, then we\n> remove the local/global distinction altogether?\n>\n> Thanks,\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-28T03:39:25",
                "message_text_only": "Corn\u00e9 Plooy via Lightning-dev\n<lightning-dev at lists.linuxfoundation.org> writes:\n> The only reasons I see for keeping the global/local distinction is that\n> you might not want to gossip everything, either to keep the gossip data\n> small, or for some privacy reasons. Apparently, that's all very\n> theoretical so far, as current features don't seem to need either.\n\nIt also matters for compulsory features.  As written today, if you don't\nunderstand a global feature you can't *route* through a node.\n\nIf you don't understand a local feature, you can't connect to a node.\n\nSo if c-lightning made option_simplfied_commitment compulsory in version\n13.0 (released from the Blockstream Moon Base), we'd also be telling\nnodes they can't route through us, which is a lie.\n\nPerhaps we can fix this by pointing it out: that you shouldn't set\ncompulsory feature bits in your node_announcement unless you really want\nto stop routing too.\n\nSo we still have a mental distinction between local and global feature\nbits, just not a bitmap distinction?\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Approximate assignment of option names: please fix!",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Corn\u00e9 Plooy",
                "Pierre",
                "Rusty Russell",
                "Olaoluwa Osuntokun",
                "ZmnSCPxj"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 15552
        }
    },
    {
        "title": "[Lightning-dev] Wumbological local AND global features",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-13T09:31:33",
                "message_text_only": "Good morning list,\n\nI would like to propose, to make both a wumbo local AND global feature bit.\n\nThe interpretation is to be as follows:\n\n* The local wumbo feature specifically means \"I am willing to wumbo with you.\"\n* The global wumbo feature means \"I am willing to wumbo with anyone\".\n\nThe primary reasoning for limited channel sizes is the risk with new software.\nAlthough we are reasonably sure that our software will not lose money that often anymore (we hope...), given the new features for 1.1, we should consider also to allow some more limitation to wumbo.\n\nThus, I suggest that practical software would allow making a whitelist of node pubkeys with which the node owner considers safe to accept making wumbo channels with.\nAnd more reckless users may also set another option in the software for being willing to wumbo with any node.\n\nThus, I propose:\n\n* The local feature bit `option_i_wumbo_you_wumbo`, which indicates that the node is willing to wumbo with its counterparty in the connection.\n* The global feature bit `option_anyone_can_wumbo`, which indicates that the node is willing to wumbo with any node.\n\nA node:\n\n* MUST set the local feature bit `option_i_wumbo_you_wumbo` if it sets the global feature bit `option_anyone_can_wumbo` in its announcement.\n* MAY clear the global feature bit `option_anyone_can_wumbo` even if it sends a set `option_i_wumbo_you_wumbo` to its peer.\n* MAY report different values for `option_i_wumbo_you_wumbo` to different nodes.\n* if it did not set the `option_i_wumbo_you_wumbo` feature bit reported to its counterparty:\n    * MUST respond with an `error` if it receives  `open_channel` with `funding_satoshis` value beyond the indicated limit for the chain,\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181113/79750e22/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-13T23:34:05",
                "message_text_only": "ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> writes:\n> Thus, I propose:\n>\n> * The local feature bit `option_i_wumbo_you_wumbo`, which indicates that the node is willing to wumbo with its counterparty in the connection.\n> * The global feature bit `option_anyone_can_wumbo`, which indicates that the node is willing to wumbo with any node.\n\nI think we need to name `option_anyone_can_wumbo` to `option_wumborama`?\n\nOtherwise, this looks excellent.\n\nThanks,\nRusty."
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-11-16T03:30:02",
                "message_text_only": "I realized the other day that the wumbo bit should also likely encompass\nwumbo\npayments. What good is a wumbo channel that doesn't also allow wumbo\npayments?\nNaturally if the bit is signalled globally, then this should also signal the\nwillingness of the node to forward larger payments up to their max_htlc\nlimit\nwithin the channel_update for that link.\n\nOn a similar note, I was reviewing the newer-ish section of the spec\nconcerning\nthe optional max_htlc value. I noticed an inconsistency: it states the value\nshould be below the max capacity of the channel, but makes no reference to\nthe\ncurrent (pre wumbo) _max HTLC limit_. As a result, as it reads now, one may\ninterpret signalling of the optional field as eligibility to route wumbo\npayments in a pre-wumbo channel world.\n\n-- Laolu\n\n\nOn Tue, Nov 13, 2018 at 3:34 PM Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\n> writes:\n> > Thus, I propose:\n> >\n> > * The local feature bit `option_i_wumbo_you_wumbo`, which indicates that\n> the node is willing to wumbo with its counterparty in the connection.\n> > * The global feature bit `option_anyone_can_wumbo`, which indicates that\n> the node is willing to wumbo with any node.\n>\n> I think we need to name `option_anyone_can_wumbo` to `option_wumborama`?\n>\n> Otherwise, this looks excellent.\n>\n> Thanks,\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181115/99e29284/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-17T22:55:12",
                "message_text_only": "Good morning list,\n\n> I realized the other day that the wumbo bit should also likely encompass wumbo\n> payments. What good is a wumbo channel that doesn't also allow wumbo payments?\n> Naturally if the bit is signalled globally, then this should also signal the\n> willingness of the node to forward larger payments up to their max_htlc limit\n> within the channel_update for that link.\n\nThis certainly is true, but, much of the wumbo payments would be implemented by AMP.\n\nIf there is no direct path of wumborama nodes from payer to payee, then wumbo payments will have to be done by AMP.\nIt would be nice if we could have AMP merge into intermediate nodes instead of always at the destination --- that way, only the suffix of the path needs to be wumborama.\nCertainly this would be less of an issue as more nodes signal wumborama; we know from previous user behavior that they will be #reckless and enable wumborama as soon as it is implemented.\n\nRegards,\nZmnSCPxj\n\n> On a similar note, I was reviewing the newer-ish section of the spec concerning\n> the optional max_htlc value. I noticed an inconsistency: it states the value\n> should be below the max capacity of the channel, but makes no reference to the\n> current (pre wumbo) _max HTLC limit_. As a result, as it reads now, one may\n> interpret signalling of the optional field as eligibility to route wumbo\n> payments in a pre-wumbo channel world.\n>\n> -- Laolu\n>\n> On Tue, Nov 13, 2018 at 3:34 PM Rusty Russell <rusty at rustcorp.com.au> wrote:\n>\n>> ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> writes:\n>>> Thus, I propose:\n>>>\n>>> * The local feature bit `option_i_wumbo_you_wumbo`, which indicates that the node is willing to wumbo with its counterparty in the connection.\n>>> * The global feature bit `option_anyone_can_wumbo`, which indicates that the node is willing to wumbo with any node.\n>>\n>> I think we need to name `option_anyone_can_wumbo` to `option_wumborama`?\n>>\n>> Otherwise, this looks excellent.\n>>\n>> Thanks,\n>> Rusty.\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181117/bdf2f56a/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Wumbological local AND global features",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Olaoluwa Osuntokun",
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 6567
        }
    },
    {
        "title": "[Lightning-dev] Base AMP",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-13T12:28:06",
                "message_text_only": "Good morning list,\n\nI propose the below to support Base AMP.\n\nThe below would allow arbitrary merges of paths, but not arbitrary splits.  I am uncertain about the safety of arbitrary splits.\n\n### The `multipath_merge_per_hop` type (`option_base_amp`)\n\nThis indicates that payment has been split by the sender using Base AMP, and that the receiver should wait for the total intended payment before forwarding or claiming the payment.\nIn case the receiving node is not the last node in the path, then succeeding hops MUST be the same across all splits.\n\n1. type: 1 (`termination_per_hop`)\n2. data:\n  * [`8` : `short_channel_id`]\n  * [`8` : `amt_to_forward`]\n  * [`4` : `outgoing_cltv_value`]\n  * [`8` : `intended_total_payment`]\n  * [`4` : `zeros`]\n\nThe contents of this hop will be the same across all paths of the Base AMP.\nThe `payment_hash` of the incoming HTLCs will also be the same across all paths of the Base AMP.\n\n`intended_total_payment` is the total amount of money that this node should expect to receive in all incoming paths to the same `payment_hash`.\n\nThis may be the last hop of a payment onion, in which case the `HMAC` for this hop will be `0` (the same rule as for `per_hop_type` 0).\n\nThe receiver:\n\n* MUST impose a reasonable timeout for waiting to receive all component paths, and fail all incoming HTLC offers for the `payment_hash`  if they have not totalled equal to `intended_total_payment`.\n* MUST NOT forward (if an intermediate node) or claim (if the final node) unless it has received a total greater or equal to `intended_total_payment` in all incoming HTLCs for the same `payment_hash`.\n\nThe sender:\n\n* MUST use the same `payment_hash` for all paths of a single multipath payment.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181113/68585bf8/attachment.html>"
            },
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2018-11-13T16:33:00",
                "message_text_only": "Good evening Z and list,\n\nI'm wondering, since these payments are no longer atomic, should we name it\naccordingly?\n\nCheers,\nJohan\n\nOn Tue, Nov 13, 2018 at 1:28 PM ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning list,\n>\n> I propose the below to support Base AMP.\n>\n> The below would allow arbitrary merges of paths, but not arbitrary\n> splits.  I am uncertain about the safety of arbitrary splits.\n>\n> ### The `multipath_merge_per_hop` type (`option_base_amp`)\n>\n> This indicates that payment has been split by the sender using Base AMP,\n> and that the receiver should wait for the total intended payment before\n> forwarding or claiming the payment.\n> In case the receiving node is not the last node in the path, then\n> succeeding hops MUST be the same across all splits.\n>\n> 1. type: 1 (`termination_per_hop`)\n> 2. data:\n>   * [`8` : `short_channel_id`]\n>   * [`8` : `amt_to_forward`]\n>   * [`4` : `outgoing_cltv_value`]\n>   * [`8` : `intended_total_payment`]\n>   * [`4` : `zeros`]\n>\n> The contents of this hop will be the same across all paths of the Base AMP.\n> The `payment_hash` of the incoming HTLCs will also be the same across all\n> paths of the Base AMP.\n>\n> `intended_total_payment` is the total amount of money that this node\n> should expect to receive in all incoming paths to the same `payment_hash`.\n>\n> This may be the last hop of a payment onion, in which case the `HMAC` for\n> this hop will be `0` (the same rule as for `per_hop_type` 0).\n>\n> The receiver:\n>\n> * MUST impose a reasonable timeout for waiting to receive all component\n> paths, and fail all incoming HTLC offers for the `payment_hash`  if they\n> have not totalled equal to `intended_total_payment`.\n> * MUST NOT forward (if an intermediate node) or claim (if the final node)\n> unless it has received a total greater or equal to `intended_total_payment`\n> in all incoming HTLCs for the same `payment_hash`.\n>\n> The sender:\n>\n> * MUST use the same `payment_hash` for all paths of a single multipath\n> payment.\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181113/6342ecf1/attachment-0001.html>"
            },
            {
                "author": "Conner Fromknecht",
                "date": "2018-11-13T19:00:48",
                "message_text_only": "Good morning all,\n\n> MUST NOT forward (if an intermediate node) or claim (if the final node) unless\n> it has received a total greater or equal to `intended_total_payment` in all\n> incoming HTLCs for the same `payment_hash`.\n\nI was under the impression that this would not require changes on behalf of the\nintermediaries, and only need to be implemented by the sender and receiver?\nIf not, then nodes would need to advertise that they support this so that the\nsender can be sure to route through the subset of nodes that support it.\n\nEither way, it would seem that this constraint can only be accurately enforced\nby the receiver. If any partial payments fail, then the `intended_total_payment`\nthrough an intermediary may never arise and the payment would be held. This\nwould also seem to exclude the possibility of iterative path finding, since the\nentire payment flow must be known up front during onion packet construction.\n\nSeems the proposal still works without the intermediaries needing to know this?\n\nWe may want to add that the receiver:\n* SHOULD fail the payment if `intended_total_payment` is less than the invoice\n   amount\n\n> I'm wondering, since these payments are no longer atomic, should we name it\n> accordingly?\n\nIndeed this true. Perhaps NAMP or CPHR (Concurrent Payment Hash Re-use) are more\naccurate and may avoid confusion?\n\nCheers,\nConner\nOn Tue, Nov 13, 2018 at 8:33 AM Johan Tor\u00e5s Halseth <johanth at gmail.com> wrote:\n>\n> Good evening Z and list,\n>\n> I'm wondering, since these payments are no longer atomic, should we name it accordingly?\n>\n> Cheers,\n> Johan\n>\n> On Tue, Nov 13, 2018 at 1:28 PM ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n>>\n>> Good morning list,\n>>\n>> I propose the below to support Base AMP.\n>>\n>> The below would allow arbitrary merges of paths, but not arbitrary splits.  I am uncertain about the safety of arbitrary splits.\n>>\n>> ### The `multipath_merge_per_hop` type (`option_base_amp`)\n>>\n>> This indicates that payment has been split by the sender using Base AMP, and that the receiver should wait for the total intended payment before forwarding or claiming the payment.\n>> In case the receiving node is not the last node in the path, then succeeding hops MUST be the same across all splits.\n>>\n>> 1. type: 1 (`termination_per_hop`)\n>> 2. data:\n>>   * [`8` : `short_channel_id`]\n>>   * [`8` : `amt_to_forward`]\n>>   * [`4` : `outgoing_cltv_value`]\n>>   * [`8` : `intended_total_payment`]\n>>   * [`4` : `zeros`]\n>>\n>> The contents of this hop will be the same across all paths of the Base AMP.\n>> The `payment_hash` of the incoming HTLCs will also be the same across all paths of the Base AMP.\n>>\n>> `intended_total_payment` is the total amount of money that this node should expect to receive in all incoming paths to the same `payment_hash`.\n>>\n>> This may be the last hop of a payment onion, in which case the `HMAC` for this hop will be `0` (the same rule as for `per_hop_type` 0).\n>>\n>> The receiver:\n>>\n>> * MUST impose a reasonable timeout for waiting to receive all component paths, and fail all incoming HTLC offers for the `payment_hash`  if they have not totalled equal to `intended_total_payment`.\n>> * MUST NOT forward (if an intermediate node) or claim (if the final node) unless it has received a total greater or equal to `intended_total_payment` in all incoming HTLCs for the same `payment_hash`.\n>>\n>> The sender:\n>>\n>> * MUST use the same `payment_hash` for all paths of a single multipath payment.\n>>\n>> Regards,\n>> ZmnSCPxj\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-13T22:47:19",
                "message_text_only": "Good morning Conner,\n\n> > MUST NOT forward (if an intermediate node) or claim (if the final node) unless\n> > it has received a total greater or equal to `intended_total_payment` in all\n> > incoming HTLCs for the same `payment_hash`.\n>\n> I was under the impression that this would not require changes on behalf of the\n> intermediaries, and only need to be implemented by the sender and receiver?\n\nStrictly, it needs to be implemented by the sender and any merge points it wants.\nWe have been thinking in terms of the receiver being the merge point, but it would be possible, with this scheme, for the merge point to be anywhere along the paths to the receiver.\n\n\nA------>B------->C-------\n \\                       \\\n  ----->D------->E------->F-------\n  \\                               \\\n   ---->G------->H------->I------->J\n\n\nIn the above, the ultimate payee is J, which is a merge point.\nF is an intermediate node, but merges two paths together before forwarding.\nOther intermediate nodes, B, C, D, E, G, H, and I, are not merge points and do not need to understand this.\nOnly F and J need to be given some merge point information in the new `per_hop_type`.\nB, C, D, E, G, H, and I, will be given `per_hop_type` of 0.\n\nThis also means that AMP can be performed without the ultimate payee being AMP-capable, as the below:\n\nA------>B------>C-------\n \\                      \\\n  ----->D------>E------->F------>G\n\nSplitting the entire payment needs to be done at the ultimate source always, but merging can be done at any point along the way.\n\n\nSo yes, it would be valuable to advertise the ability to merge payments as a global feature bit, not on the invoice.\n\nRegards,\nZmnSCPxj\n\n> If not, then nodes would need to advertise that they support this so that the\n> sender can be sure to route through the subset of nodes that support it.\n>\n> Either way, it would seem that this constraint can only be accurately enforced\n> by the receiver. If any partial payments fail, then the `intended_total_payment`\n> through an intermediary may never arise and the payment would be held. This\n> would also seem to exclude the possibility of iterative path finding, since the\n> entire payment flow must be known up front during onion packet construction.\n>\n> Seems the proposal still works without the intermediaries needing to know this?\n>\n> We may want to add that the receiver:\n>\n> -   SHOULD fail the payment if `intended_total_payment` is less than the invoice\n>     amount\n>\n>\n> > I'm wondering, since these payments are no longer atomic, should we name it\n> > accordingly?\n>\n> Indeed this true. Perhaps NAMP or CPHR (Concurrent Payment Hash Re-use) are more\n> accurate and may avoid confusion?\n>\n> Cheers,\n> Conner\n> On Tue, Nov 13, 2018 at 8:33 AM Johan Tor\u00e5s Halseth johanth at gmail.com wrote:\n>\n> > Good evening Z and list,\n> > I'm wondering, since these payments are no longer atomic, should we name it accordingly?\n> > Cheers,\n> > Johan\n> > On Tue, Nov 13, 2018 at 1:28 PM ZmnSCPxj via Lightning-dev lightning-dev at lists.linuxfoundation.org wrote:\n> >\n> > > Good morning list,\n> > > I propose the below to support Base AMP.\n> > > The below would allow arbitrary merges of paths, but not arbitrary splits. I am uncertain about the safety of arbitrary splits.\n> > >\n> > > ### The `multipath_merge_per_hop` type (`option_base_amp`)\n> > >\n> > > This indicates that payment has been split by the sender using Base AMP, and that the receiver should wait for the total intended payment before forwarding or claiming the payment.\n> > > In case the receiving node is not the last node in the path, then succeeding hops MUST be the same across all splits.\n> > >\n> > > 1.  type: 1 (`termination_per_hop`)\n> > > 2.  data:\n> > >\n> > > -   [`8` : `short_channel_id`]\n> > > -   [`8` : `amt_to_forward`]\n> > > -   [`4` : `outgoing_cltv_value`]\n> > > -   [`8` : `intended_total_payment`]\n> > > -   [`4` : `zeros`]\n> > >\n> > > The contents of this hop will be the same across all paths of the Base AMP.\n> > > The `payment_hash` of the incoming HTLCs will also be the same across all paths of the Base AMP.\n> > > `intended_total_payment` is the total amount of money that this node should expect to receive in all incoming paths to the same `payment_hash`.\n> > > This may be the last hop of a payment onion, in which case the `HMAC` for this hop will be `0` (the same rule as for `per_hop_type` 0).\n> > > The receiver:\n> > >\n> > > -   MUST impose a reasonable timeout for waiting to receive all component paths, and fail all incoming HTLC offers for the `payment_hash` if they have not totalled equal to `intended_total_payment`.\n> > > -   MUST NOT forward (if an intermediate node) or claim (if the final node) unless it has received a total greater or equal to `intended_total_payment` in all incoming HTLCs for the same `payment_hash`.\n> > >\n> > > The sender:\n> > >\n> > > -   MUST use the same `payment_hash` for all paths of a single multipath payment.\n> > >\n> > > Regards,\n> > > ZmnSCPxj\n> > >\n> > > Lightning-dev mailing list\n> > > Lightning-dev at lists.linuxfoundation.org\n> > > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> >\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-13T22:39:05",
                "message_text_only": "Good morning Johan,\n\nMerge nodes will prefer to wait until the entire payment is available and committed to as HTLCs, before doing any claims.\nI believe it was mentioned that one of us figured it out (prior to the summit) that such a thing was what a merge point would rationally want.\n\nWe assume the proof-of-payment is valuable (an example being the \"Vending machine\" I recorded on the list, where release of a proof-of-payment triggers release of product from vending machine).\nIf the ultimate payee has not received all payments, then it would be very irrational of it to claim a partial payment, since it would release the proof-of-payment for a value less than the value implied by the invoice.\nSimilarly, if an intermediate node is a merge point for an AMP, it would forward a value.\nIf that value is greater than the current total value merging into it, it would be very irrational of it to forward the value until it has assurances it can claim all values in a commitment transaction.\n\nThe atomicity here is only \"economically rational atomicity\" and not \"information theoretical atomicity\", but it *is* atomicity.\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Wednesday, November 14, 2018 12:33 AM, Johan Tor\u00e5s Halseth <johanth at gmail.com> wrote:\n\n> Good evening Z and list,\n>\n> I'm wondering, since these payments are no longer atomic, should we name it accordingly?\n>\n> Cheers,\n> Johan\n>\n> On Tue, Nov 13, 2018 at 1:28 PM ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n>\n>> Good morning list,\n>>\n>> I propose the below to support Base AMP.\n>>\n>> The below would allow arbitrary merges of paths, but not arbitrary splits.  I am uncertain about the safety of arbitrary splits.\n>>\n>> ### The `multipath_merge_per_hop` type (`option_base_amp`)\n>>\n>> This indicates that payment has been split by the sender using Base AMP, and that the receiver should wait for the total intended payment before forwarding or claiming the payment.\n>> In case the receiving node is not the last node in the path, then succeeding hops MUST be the same across all splits.\n>>\n>> 1. type: 1 (`termination_per_hop`)\n>> 2. data:\n>>   * [`8` : `short_channel_id`]\n>>   * [`8` : `amt_to_forward`]\n>>   * [`4` : `outgoing_cltv_value`]\n>>   * [`8` : `intended_total_payment`]\n>>   * [`4` : `zeros`]\n>>\n>> The contents of this hop will be the same across all paths of the Base AMP.\n>> The `payment_hash` of the incoming HTLCs will also be the same across all paths of the Base AMP.\n>>\n>> `intended_total_payment` is the total amount of money that this node should expect to receive in all incoming paths to the same `payment_hash`.\n>>\n>> This may be the last hop of a payment onion, in which case the `HMAC` for this hop will be `0` (the same rule as for `per_hop_type` 0).\n>>\n>> The receiver:\n>>\n>> * MUST impose a reasonable timeout for waiting to receive all component paths, and fail all incoming HTLC offers for the `payment_hash`  if they have not totalled equal to `intended_total_payment`.\n>> * MUST NOT forward (if an intermediate node) or claim (if the final node) unless it has received a total greater or equal to `intended_total_payment` in all incoming HTLCs for the same `payment_hash`.\n>>\n>> The sender:\n>>\n>> * MUST use the same `payment_hash` for all paths of a single multipath payment.\n>>\n>> Regards,\n>> ZmnSCPxj\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181113/89fe254e/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-14T00:13:30",
                "message_text_only": "ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> writes:\n> Good morning list,\n>\n> I propose the below to support Base AMP.\n\nI think the complexity outweighs the benefits for the moment.  The\nsender would have to make the onions identical past the merge point (so\nany one of them could be used), the merge point has to now create a\nmany:1 map for HTLC redemption.\n\nFor the moment, I think we should stick with:\n\nBOLT #4:\n1. type: `per_hop`\n2. data:\n   * [`8`:`short_channel_id`]\n   * [`8`:`amt_to_forward`]\n   * [`4`:`outgoing_cltv_value`]\n-  * [`12`:`padding`]\n+  * [`1`:`flags`]\n+  * [`11`:`padding`]\n\nAnd define bit 0 of `flags` as `incomplete_payment`.  For the moment, it\nis only allowed for final nodes, and only if they put it in their BOLT11\nfield.\n\nBOLT #11:\n\n   * `9` (5): `data_length` variable.  Features supported for receiving\n     this payment.  Currently only `wait_on_incomplete` (bit 1) is defined.\n\n...\n\n-A writer SHOULD use the minimum `data_length` possible for `x` and `c` fields.\n+A writer SHOULD use the minimum `data_length` possible for `x`, `c` and\n`9` fields, omitting the field entirely if possible.\n...\n\nA payer MUST ignore unknown odd bits are set in the `9` field, and\nNOT try to make a payment if unknown even bits are set in the `9` field.\n\nCheers,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-14T01:59:18",
                "message_text_only": "Good morning Rusty,\n\nSomeone pointed out to me that `intended_payment_amount` is unnecessary.\nOn reflection, this is correct.\nBoth intermediate nodes and the payee node need not have `intended_payment_amount`.\n\nTherefore....\n\n> > I propose the below to support Base AMP.\n>\n> I think the complexity outweighs the benefits for the moment. The\n> sender would have to make the onions identical past the merge point (so\n> any one of them could be used), the merge point has to now create a\n> many:1 map for HTLC redemption.\n>\n> For the moment, I think we should stick with:\n>\n> BOLT #4:\n>\n> 1.  type: `per_hop`\n> 2.  data:\n>     -   [`8`:`short_channel_id`]\n>     -   [`8`:`amt_to_forward`]\n>     -   [`4`:`outgoing_cltv_value`]\n>\n> -   -   [`12`:`padding`]\n>\n> -   -   [`1`:`flags`]\n> -   -   [`11`:`padding`]\n>\n>         And define bit 0 of `flags` as `incomplete_payment`. For the moment, it\n>         is only allowed for final nodes, and only if they put it in their BOLT11\n>         field.\n>\n\nWe can do something even simpler.\n\nIf `amt_to_forward` plus the fees charged by this node is greater than the actual incoming HTLC, this is an AMP attempt.\nNo additional flag needs to be added.\nFor final payment nodes, if the `amt_to_forward` is greater than the incoming HTLC value, this is an AMP attempt.\n\nThe previous node could try to probe this by offering a smaller amount than it was instructed to give, but cannot differentiate between a stall because the payee is waiting for an AMP, or a stall due to some other unrelated error.\n\n---\n\nOf course, an explicit flag is more sensible as it is more explicit.\n\nFor myself, I would rather a new `per_hop_type`, but whether to use a separate `per_hop_type` vs a byte in padding is largely a bikeshed issue and either is fine with me.\nA concern is that nothing in our current spec requires that `padding` be all 0, such that reinterpreting byte 0 to be flags could cause interoperability problems.\nSo perhaps a new `per_hop_type` which has a 2-byte `flags` (for more future expansion) and a `padding` of 10 bytes which MUST be explicitly specced as \"MUST be all 0\".\n\nAn explicit flags field would also allow delivery of higher-layer application data in each payment, for whatever purpose a higher-layer application may want.  E.g. bit 1 could mean \"the next hop 65 bytes is actually a 32-byte application ID and a 33-byte payload; this flag is valid only if this is the last hop.\"\nAnother bit can also be used to provide spontaneous payment, so e.g. bit 2 could mean \"this hop is the final hop (even if HMAC is nonzero); the HMAC of this hop is really the preimage to claim this payment.\"\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-14T23:35:30",
                "message_text_only": "Good morning list,\n\nIn case it was not noticed, I made a pull request for Base AMP: https://github.com/lightningnetwork/lightning-rfc/pull/511\n\nThis is primarily based on what Rusty suggested on-list, with sufficient MUST and SHOULD.\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Wednesday, November 14, 2018 9:59 AM, ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Rusty,\n>\n> Someone pointed out to me that `intended_payment_amount` is unnecessary.\n> On reflection, this is correct.\n> Both intermediate nodes and the payee node need not have `intended_payment_amount`.\n>\n> Therefore....\n>\n> > > I propose the below to support Base AMP.\n> >\n> > I think the complexity outweighs the benefits for the moment. The\n> > sender would have to make the onions identical past the merge point (so\n> > any one of them could be used), the merge point has to now create a\n> > many:1 map for HTLC redemption.\n> > For the moment, I think we should stick with:\n> > BOLT #4:\n> >\n> > 1.  type: `per_hop`\n> > 2.  data:\n> >     -   [`8`:`short_channel_id`]\n> >     -   [`8`:`amt_to_forward`]\n> >     -   [`4`:`outgoing_cltv_value`]\n> >\n> > -   -   [`12`:`padding`]\n> > -   -   [`1`:`flags`]\n> > -   -   [`11`:`padding`]\n> >         And define bit 0 of `flags` as `incomplete_payment`. For the moment, it\n> >         is only allowed for final nodes, and only if they put it in their BOLT11\n> >         field.\n> >\n>\n> We can do something even simpler.\n>\n> If `amt_to_forward` plus the fees charged by this node is greater than the actual incoming HTLC, this is an AMP attempt.\n> No additional flag needs to be added.\n> For final payment nodes, if the `amt_to_forward` is greater than the incoming HTLC value, this is an AMP attempt.\n>\n> The previous node could try to probe this by offering a smaller amount than it was instructed to give, but cannot differentiate between a stall because the payee is waiting for an AMP, or a stall due to some other unrelated error.\n>\n> --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> Of course, an explicit flag is more sensible as it is more explicit.\n>\n> For myself, I would rather a new `per_hop_type`, but whether to use a separate `per_hop_type` vs a byte in padding is largely a bikeshed issue and either is fine with me.\n> A concern is that nothing in our current spec requires that `padding` be all 0, such that reinterpreting byte 0 to be flags could cause interoperability problems.\n> So perhaps a new `per_hop_type` which has a 2-byte `flags` (for more future expansion) and a `padding` of 10 bytes which MUST be explicitly specced as \"MUST be all 0\".\n>\n> An explicit flags field would also allow delivery of higher-layer application data in each payment, for whatever purpose a higher-layer application may want. E.g. bit 1 could mean \"the next hop 65 bytes is actually a 32-byte application ID and a 33-byte payload; this flag is valid only if this is the last hop.\"\n> Another bit can also be used to provide spontaneous payment, so e.g. bit 2 could mean \"this hop is the final hop (even if HMAC is nonzero); the HMAC of this hop is really the preimage to claim this payment.\"\n>\n> Regards,\n> ZmnSCPxj\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Christian Decker",
                "date": "2018-11-15T19:46:26",
                "message_text_only": "I'm not sure this is an improvement at all over just allowing a single\nmerge-point, i.e., the destination. You see as long as we don't attempt\nintermediate merges the routes are independent and failures of one HTLC\ndo not impact any other parts. Take for example the network below:\n\n  --------\n /        \\\nA----B-----C-----D\n\\               /\n -------E-------\n\nFor simplicity let's assume unit capacities on all channels except C-D\nand a total payment of 2 from A to D.\n\nIf we use C as a merge point for the two partial payments A-C-D and\nA-B-C-D, then C can only forward if both partial payment succeed, i.e.,\nif for example A-C fails then we'll need to tear down the HTLCs for both\npaths because it'll no longer be possible to find an alternative route\nto fulfill the forwarding of 2 over C-D.\n\nIf however we have two independent routes A-B-C-D and A-C-D, then A-C-D\ncan fail independently and we can recover by attempting A-E-D, no need\nto touch A-B-C-D at all.\n\nOverall it seems we get very little benefit (we save some HTLC setups\nand teardown) for a lot of added complexity. In the above case we would\nhave saved on a single C-D HTLC, and the cost of doing so is many times\nlarger (2 HTLCs needed to be torn down because we could no longer pass\nenough capacity to C in order for it to reach the forward threshold).\n\nLet's please stick with the simple mechanism of having the recipient be\nthe only merge point.\n\nCheers,\nChristian\n\nZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\nwrites:\n> Good morning list,\n>\n> I propose the below to support Base AMP.\n>\n> The below would allow arbitrary merges of paths, but not arbitrary splits.  I am uncertain about the safety of arbitrary splits.\n>\n> ### The `multipath_merge_per_hop` type (`option_base_amp`)\n>\n> This indicates that payment has been split by the sender using Base AMP, and that the receiver should wait for the total intended payment before forwarding or claiming the payment.\n> In case the receiving node is not the last node in the path, then succeeding hops MUST be the same across all splits.\n>\n> 1. type: 1 (`termination_per_hop`)\n> 2. data:\n>   * [`8` : `short_channel_id`]\n>   * [`8` : `amt_to_forward`]\n>   * [`4` : `outgoing_cltv_value`]\n>   * [`8` : `intended_total_payment`]\n>   * [`4` : `zeros`]\n>\n> The contents of this hop will be the same across all paths of the Base AMP.\n> The `payment_hash` of the incoming HTLCs will also be the same across all paths of the Base AMP.\n>\n> `intended_total_payment` is the total amount of money that this node should expect to receive in all incoming paths to the same `payment_hash`.\n>\n> This may be the last hop of a payment onion, in which case the `HMAC` for this hop will be `0` (the same rule as for `per_hop_type` 0).\n>\n> The receiver:\n>\n> * MUST impose a reasonable timeout for waiting to receive all component paths, and fail all incoming HTLC offers for the `payment_hash`  if they have not totalled equal to `intended_total_payment`.\n> * MUST NOT forward (if an intermediate node) or claim (if the final node) unless it has received a total greater or equal to `intended_total_payment` in all incoming HTLCs for the same `payment_hash`.\n>\n> The sender:\n>\n> * MUST use the same `payment_hash` for all paths of a single multipath payment.\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-15T23:54:22",
                "message_text_only": "Good morning Christian,\n\nThe improvement is in a reduction in `fee_base_msat` in the C->D path.\nIf C is the merge point, then the C->D `fee_base_msat` is only paid once, not twice.\nIn effect, A is rationally choosing between a lower fee and better payment reliability.\n\nGranted, current `fee_base_msat` across the network is very low currently.\nSo I do not object to restricting merge points to ultimate payees.\nIf fees rise later, we can revisit this.\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Friday, November 16, 2018 3:46 AM, Christian Decker <decker.christian at gmail.com> wrote:\n\n> I'm not sure this is an improvement at all over just allowing a single\n> merge-point, i.e., the destination. You see as long as we don't attempt\n> intermediate merges the routes are independent and failures of one HTLC\n> do not impact any other parts. Take for example the network below:\n>\n> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> / \\\n> A----B-----C-----D\n> \\ /\n> -------E-------\n>\n> For simplicity let's assume unit capacities on all channels except C-D\n> and a total payment of 2 from A to D.\n>\n> If we use C as a merge point for the two partial payments A-C-D and\n> A-B-C-D, then C can only forward if both partial payment succeed, i.e.,\n> if for example A-C fails then we'll need to tear down the HTLCs for both\n> paths because it'll no longer be possible to find an alternative route\n> to fulfill the forwarding of 2 over C-D.\n>\n> If however we have two independent routes A-B-C-D and A-C-D, then A-C-D\n> can fail independently and we can recover by attempting A-E-D, no need\n> to touch A-B-C-D at all.\n>\n> Overall it seems we get very little benefit (we save some HTLC setups\n> and teardown) for a lot of added complexity. In the above case we would\n> have saved on a single C-D HTLC, and the cost of doing so is many times\n> larger (2 HTLCs needed to be torn down because we could no longer pass\n> enough capacity to C in order for it to reach the forward threshold).\n>\n> Let's please stick with the simple mechanism of having the recipient be\n> the only merge point.\n>\n> Cheers,\n> Christian\n>\n> ZmnSCPxj via Lightning-dev lightning-dev at lists.linuxfoundation.org\n> writes:\n>\n> > Good morning list,\n> > I propose the below to support Base AMP.\n> > The below would allow arbitrary merges of paths, but not arbitrary splits. I am uncertain about the safety of arbitrary splits.\n> >\n> > ### The `multipath_merge_per_hop` type (`option_base_amp`)\n> >\n> > This indicates that payment has been split by the sender using Base AMP, and that the receiver should wait for the total intended payment before forwarding or claiming the payment.\n> > In case the receiving node is not the last node in the path, then succeeding hops MUST be the same across all splits.\n> >\n> > 1.  type: 1 (`termination_per_hop`)\n> > 2.  data:\n> >\n> > -   [`8` : `short_channel_id`]\n> > -   [`8` : `amt_to_forward`]\n> > -   [`4` : `outgoing_cltv_value`]\n> > -   [`8` : `intended_total_payment`]\n> > -   [`4` : `zeros`]\n> >\n> > The contents of this hop will be the same across all paths of the Base AMP.\n> > The `payment_hash` of the incoming HTLCs will also be the same across all paths of the Base AMP.\n> > `intended_total_payment` is the total amount of money that this node should expect to receive in all incoming paths to the same `payment_hash`.\n> > This may be the last hop of a payment onion, in which case the `HMAC` for this hop will be `0` (the same rule as for `per_hop_type` 0).\n> > The receiver:\n> >\n> > -   MUST impose a reasonable timeout for waiting to receive all component paths, and fail all incoming HTLC offers for the `payment_hash` if they have not totalled equal to `intended_total_payment`.\n> > -   MUST NOT forward (if an intermediate node) or claim (if the final node) unless it has received a total greater or equal to `intended_total_payment` in all incoming HTLCs for the same `payment_hash`.\n> >\n> > The sender:\n> >\n> > -   MUST use the same `payment_hash` for all paths of a single multipath payment.\n> >\n> > Regards,\n> > ZmnSCPxj\n> >\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Anthony Towns",
                "date": "2018-11-16T15:45:27",
                "message_text_only": "On Thu, Nov 15, 2018 at 11:54:22PM +0000, ZmnSCPxj via Lightning-dev wrote:\n> The improvement is in a reduction in `fee_base_msat` in the C->D path.\n\nI think reliability (and simplicity!) are the biggest things to improve\nin lightning atm. Having the flag just be incuded in invoices and not\nneed to be gossiped seems simpler to me; and I think endpoint-only\nmerging is better for reliability too. Eg, if you find candidate routes:\n\n  A -> B -> M -- actual directed capacity $6\n  A -> C -> M -- actual directed capacity $5.50\n  M -> E -> F -- actual directed capacity $6\n  A -> X -> F -- actual directed capacity $7\n\nand want to send $9 form A to F, you might start by trying to send\n$5 via B and $4 via C.\n\nWith endpoint-only merging you'd do:\n\n   $5 via A,B,M,E,F -- partial success\n   $4 via A,C,M,E -- failure\n   $4 via A,X,F -- payment completion\n\nwhereas with in-route merging, you'd do:\n\n   $5 via A,B,M -- held\n   $4 via A,C,M -- to be continued\n   $9 via M,E -- both partial payments fail\n\nwhich seems a fair bit harder to incrementally recover from.\n\n> Granted, current `fee_base_msat` across the network is very low currently.\n> So I do not object to restricting merge points to ultimate payees.\n> If fees rise later, we can revisit this.\n\nSo, while we already agree on the approach to take, I think the above\nprovides an additional rationale :)\n\nCheers,\naj"
            },
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2018-11-20T13:53:04",
                "message_text_only": "Hey List,\n\nas this base AMP proposal seems pretty small I just started to write this\nup to make a PR for BOLT04 and BOLT11. While doing my write up I realize\nthat there are smaller things that I would want to verify / double check\nand propose with you.\n\n## Verifying:\n1.) I understand the receiving node signals support for Base AMP by setting\na feature bit in the BOLT11 String\n2.) The sending node signals a multipath payment by setting a feature bit\nand by using the same `amount to forward` value in the last hop of the\nonion for all paths which will also be bigger that the incoming htlcs whose\nsum has to be at least the size of `amount_to_forward`.\n\n## Clarifying:\n3.) Senders MUST NOT (SHOULD NOT?) create paths which would have to be\nmerged by intermediary nodes (as we don't know - and have no means of\nquerying - if they support the format of the adepted onion packages for\npartial paths. Also it even seems impossible since the rest of the path for\nat least one partial path could not be stored in the onion / forwarded\nonions can't be seen)\n\n## Proposing:\nShould we specify an algorithm for executing a multipath payment for the\nsending node or should this be left to the implementation. An obvious Idea\nfor an algorithm would be a divide and conquer scheme which should be\nobvious with the following python style pseudo code:\n\ndef pay_base_amp(amount):\n   success = False\n   for route in get_available_routes():\n       success = send_via_route(route, amount)\n    if not success:\n       pay_base_amp(amount/2 + 1) # the +1 is to mitigate rounding errors.\nthere could be other ways to do so.\n       pay_base_amp(amount/2 + 1)\n\nEven if we leave the exact AMP execution to the sender we could still\nsuggest this divide and conquer scheme in BOLT 04\n\nAnother idea I had (which is probably a bad one as it allows for probing of\nchannel balances) would be to allow nodes on a partial path to send back\nsome hints of how much additional capacity they can forward if they see\nthat the partial payment feature bit is set (this would require to set this\nfeature bit in every onion) Also if we want to make use of this information\nevery node would have to support base amp. So I guess this idea is bad for\nseveral reasons. Still we could have a MAY rule out of it?\n\nbest Rene\n\n\nOn Fri, Nov 16, 2018 at 4:45 PM Anthony Towns <aj at erisian.com.au> wrote:\n\n> On Thu, Nov 15, 2018 at 11:54:22PM +0000, ZmnSCPxj via Lightning-dev wrote:\n> > The improvement is in a reduction in `fee_base_msat` in the C->D path.\n>\n> I think reliability (and simplicity!) are the biggest things to improve\n> in lightning atm. Having the flag just be incuded in invoices and not\n> need to be gossiped seems simpler to me; and I think endpoint-only\n> merging is better for reliability too. Eg, if you find candidate routes:\n>\n>   A -> B -> M -- actual directed capacity $6\n>   A -> C -> M -- actual directed capacity $5.50\n>   M -> E -> F -- actual directed capacity $6\n>   A -> X -> F -- actual directed capacity $7\n>\n> and want to send $9 form A to F, you might start by trying to send\n> $5 via B and $4 via C.\n>\n> With endpoint-only merging you'd do:\n>\n>    $5 via A,B,M,E,F -- partial success\n>    $4 via A,C,M,E -- failure\n>    $4 via A,X,F -- payment completion\n>\n> whereas with in-route merging, you'd do:\n>\n>    $5 via A,B,M -- held\n>    $4 via A,C,M -- to be continued\n>    $9 via M,E -- both partial payments fail\n>\n> which seems a fair bit harder to incrementally recover from.\n>\n> > Granted, current `fee_base_msat` across the network is very low\n> currently.\n> > So I do not object to restricting merge points to ultimate payees.\n> > If fees rise later, we can revisit this.\n>\n> So, while we already agree on the approach to take, I think the above\n> provides an additional rationale :)\n>\n> Cheers,\n> aj\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n\n\n-- \nhttps://www.rene-pickhardt.de\n\nSkype: rene.pickhardt\n\nmobile: +49 (0)176 5762 3618\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181120/af408cd6/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-20T15:26:27",
                "message_text_only": "Good morning Rene,\n\n> Hey List,\n>\n> as this base AMP proposal seems pretty small I just started to write this up to make a PR for BOLT04 and BOLT11. While doing my write up I realize that there are smaller things that I would want to verify / double check and propose with you.\n>\n> ## Verifying:\n> 1.) I understand the receiving node signals support for Base AMP by setting a feature bit in the BOLT11 String\n\nCorrect.\n\n> 2.) The sending node signals a multipath payment by setting a feature bit and by using the same `amount to forward` value in the last hop of the onion for all paths which will also be bigger that the incoming htlcs whose sum has to be at least the size of `amount_to_forward`.\n\nThe bit is not a \"feature bit\" specifically, as it is not a feature --- instead, it is a mode of operation or option.\nPerhaps semantics only, however.\nOtherwise, correct.\n\n> ## Clarifying:\n> 3.) Senders MUST NOT (SHOULD NOT?) create paths which would have to be merged by intermediary nodes (as we don't know - and have no means of querying - if they support the format of the adepted onion packages for partial paths.\n\nMUST NOT, since an incomplete payment can only be signaled for final nodes.\nI can explicitly use MUST NOT here I suppose.\n\n> Also it even seems impossible since the rest of the path for at least one partial path could not be stored in the onion / forwarded onions can't be seen)\n\nIt would be easily doable to have the rest of the onion be the same for each incoming partial path.\nAn intermediate hop just needs to store one onion, and compare the HMAC of a second or third incoming onion to differentiate between different forward-merges.\n\n> ## Proposing:\n> Should we specify an algorithm for executing a multipath payment for the sending node or should this be left to the implementation. An obvious Idea for an algorithm would be a divide and conquer scheme which should be obvious with the following python style pseudo code:\n>\n> def pay_base_amp(amount):\n>    success = False\n>    for route in get_available_routes():\n>        success = send_via_route(route, amount)\n>     if not success:\n>        pay_base_amp(amount/2 + 1) # the +1 is to mitigate rounding errors. there could be other ways to do so.\n>        pay_base_amp(amount/2 + 1)\n>\n> Even if we leave the exact AMP execution to the sender we could still suggest this divide and conquer scheme in BOLT 04\n\nThe above naive scheme will not work in the general case.\n\nSee: https://lists.ozlabs.org/pipermail/c-lightning/2018-November/000084.html\nIt will not work well with the proposed `test_amp_unequal`, `test_amp_3way`. and `test_amp_5way` tests, at least until the amount has been split into tiny parts, possibly with fees becoming an issue (particularly `fee_base_msat`) due to having been split into many tiny parts.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181120/e52dc667/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-21T00:29:43",
                "message_text_only": "Ren\u00e9 Pickhardt via Lightning-dev <lightning-dev at lists.linuxfoundation.org> writes:\n> Hey List,\n>\n> as this base AMP proposal seems pretty small I just started to write this\n> up to make a PR for BOLT04 and BOLT11. While doing my write up I realize\n> that there are smaller things that I would want to verify / double check\n> and propose with you.\n>\n> ## Verifying:\n> 1.) I understand the receiving node signals support for Base AMP by setting\n> a feature bit in the BOLT11 String\n\nYes, this seemed a logical reason to add features to BOLT11.\n\n> 2.) The sending node signals a multipath payment by setting a feature bit\n> and by using the same `amount to forward` value in the last hop of the\n> onion for all paths which will also be bigger that the incoming htlcs whose\n> sum has to be at least the size of `amount_to_forward`.\n\nNot a feature bit as such, but some signal for the final node (in the\nonion).  And do not play with `amount_to_forward`, as it's an important\nsignal to the final node that the previous node did not offer less value\nfor the HTLC than it was supposed to.  (You could steal the top bit to\nsignal partial payment if you really want to).\n\n> ## Clarifying:\n> 3.) Senders MUST NOT (SHOULD NOT?) create paths which would have to be\n> merged by intermediary nodes (as we don't know - and have no means of\n> querying - if they support the format of the adepted onion packages for\n> partial paths. Also it even seems impossible since the rest of the path for\n> at least one partial path could not be stored in the onion / forwarded\n> onions can't be seen)\n\nIn-path merging is overreach, let's not do it or mention it.\n\nThere's a slight preference to avoid sharing intermediary nodes to avoid\ncorrelation.  Intermediary nodes know they need to forward all of them\nor not get paid for any of them, and they're already supposed to do so.\n\n> ## Proposing:\n> Should we specify an algorithm for executing a multipath payment for the\n> sending node or should this be left to the implementation. An obvious Idea\n> for an algorithm would be a divide and conquer scheme which should be\n> obvious with the following python style pseudo code:\n>\n> def pay_base_amp(amount):\n>    success = False\n>    for route in get_available_routes():\n>        success = send_via_route(route, amount)\n>     if not success:\n>        pay_base_amp(amount/2 + 1) # the +1 is to mitigate rounding errors.\n> there could be other ways to do so.\n>        pay_base_amp(amount/2 + 1)\n\nI don't think this is actually useful.  For example, I would suggest a\nmore random split, and start by using some estimate of channel capacity.\n\n> Even if we leave the exact AMP execution to the sender we could still\n> suggest this divide and conquer scheme in BOLT 04\n>\n> Another idea I had (which is probably a bad one as it allows for probing of\n> channel balances) would be to allow nodes on a partial path to send back\n> some hints of how much additional capacity they can forward if they see\n> that the partial payment feature bit is set (this would require to set this\n> feature bit in every onion) Also if we want to make use of this information\n> every node would have to support base amp. So I guess this idea is bad for\n> several reasons. Still we could have a MAY rule out of it?\n\nI think we should adapt a convention for a lower limit at which we\ndisable the channel if we can't forward (eg 1% of capacity?  100\nsatoshis?).  That gives us a better starting point for AMP, too.\n\nCheers,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-21T02:54:28",
                "message_text_only": "Good morning Rusty,\n\n> And do not play with `amount_to_forward`, as it's an important\n> signal to the final node that the previous node did not offer less value\n> for the HTLC than it was supposed to. (You could steal the top bit to\n> signal partial payment if you really want to).\n\nI do not view this as playing with the existing `amt_to_forward`, but rather retaining its previous use.\n\nIf it helps, we can rewrite the *current* pre-AMP spec as below:\n\n2. data:\n    ...\n    * [`8` : `amt_to_forward` / `amt_to_pay`]\n\n...\n\n* `amt_to_forward` - for **non-final** nodes, this is the value to forward to the next node.\n  Non-final nodes MUST check:\n\n    incoming_htlc_amt - fee >= amt_to_forward\n\n* `amt_to_pay` - for **final** nodes, this is the value that is intended to reach it.\n  Final nodes MUST check:\n\n    incoming_htlc_amt >= amt_to_pay\n\nThen for Base AMP:\n\n* `amt_to_pay` - for **final** nodes, this is the total value that is intended to reach it.\n  If `incomplete_payment` flag is not set, final nodes MUST check:\n\n    incoming_htlc_amt >= amt_to_pay\n\n  If `incomplete_payment` flag is set, then final nodes must claim HTLCs only if:\n\n    sum(incoming_htlc_amt) >= amt_to_pay\n\n  Where `sum(incoming_htlc_amt)` is the total `incoming_htlc_amt` for all incoming HTLCs terminating at this final node with the same `payment_hash`.\n\n\n\nNow perhaps we can argue that for AMP we should have two fields `amt_to_pay_for_this_partial_payment` and `amt_to_pay_for_total_payment` instead.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2018-11-21T13:04:00",
                "message_text_only": "Seems like we can restrict the changes to BOLT11 by having the receiver\nassume NAMP for incoming payments < invoice_amount. (with some timeout of\ncourse, but that would need to be the case even when the sender is\nsignalling NAMP).\n\nCheers,\nJohan\n\nOn Wed, Nov 21, 2018 at 3:55 AM ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Rusty,\n>\n> > And do not play with `amount_to_forward`, as it's an important\n> > signal to the final node that the previous node did not offer less value\n> > for the HTLC than it was supposed to. (You could steal the top bit to\n> > signal partial payment if you really want to).\n>\n> I do not view this as playing with the existing `amt_to_forward`, but\n> rather retaining its previous use.\n>\n> If it helps, we can rewrite the *current* pre-AMP spec as below:\n>\n> 2. data:\n>     ...\n>     * [`8` : `amt_to_forward` / `amt_to_pay`]\n>\n> ...\n>\n> * `amt_to_forward` - for **non-final** nodes, this is the value to forward\n> to the next node.\n>   Non-final nodes MUST check:\n>\n>     incoming_htlc_amt - fee >= amt_to_forward\n>\n> * `amt_to_pay` - for **final** nodes, this is the value that is intended\n> to reach it.\n>   Final nodes MUST check:\n>\n>     incoming_htlc_amt >= amt_to_pay\n>\n> Then for Base AMP:\n>\n> * `amt_to_pay` - for **final** nodes, this is the total value that is\n> intended to reach it.\n>   If `incomplete_payment` flag is not set, final nodes MUST check:\n>\n>     incoming_htlc_amt >= amt_to_pay\n>\n>   If `incomplete_payment` flag is set, then final nodes must claim HTLCs\n> only if:\n>\n>     sum(incoming_htlc_amt) >= amt_to_pay\n>\n>   Where `sum(incoming_htlc_amt)` is the total `incoming_htlc_amt` for all\n> incoming HTLCs terminating at this final node with the same `payment_hash`.\n>\n>\n>\n> Now perhaps we can argue that for AMP we should have two fields\n> `amt_to_pay_for_this_partial_payment` and `amt_to_pay_for_total_payment`\n> instead.\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181121/8f56db8f/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-21T22:52:28",
                "message_text_only": "Johan Tor\u00e5s Halseth <johanth at gmail.com> writes:\n> Seems like we can restrict the changes to BOLT11 by having the receiver\n> assume NAMP for incoming payments < invoice_amount. (with some timeout of\n> course, but that would need to be the case even when the sender is\n> signalling NAMP).\n\nThis would effectively become a probe for Base AMP; if you get a partial\npayment error, it's because the recipient didn't support Base AMP.\n\nSeems cleaner to have a flag, both on BOLT11 and inside the onion.  Then\nit's explicitly opt-in for both sides and doesn't affect existing nodes\nin any way.\n\nCheers,\nRusty."
            },
            {
                "author": "Conner Fromknecht",
                "date": "2018-11-21T23:38:20",
                "message_text_only": "Hi all,\n\n> But it's unnecessary for the recipient to know the total amount I meant\n> to pay; they just need to return the receipt once it exceeds the amount\n> they want.\n\nI think it\u2019s true that the recipient doesn\u2019t need to know necessarily, but\nsending the intended amount is more robust IMO, since it provides an order\ninvariant hint for when the receiver can safely settle.\n\nIf the sender does amount fuzzing (as CL does) or adds a tip, it\u2019s possible\nfor the final partial payment to be less than `amount_to_pay` -\n`invoice_amount`, causing the sender to settle prematurely. Otherwise, we\nmight want to specify that no split should be less than the amount\noverpaid.\n\nOf course, if that amount never comes through yet the invoice is satisfied,\nthe receiver can always choose to settle even if the remaining amount never\narrives.\n\nCheers,\nConner\n\nOn Wed, Nov 21, 2018 at 14:55 Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> Johan Tor\u00e5s Halseth <johanth at gmail.com> writes:\n> > Seems like we can restrict the changes to BOLT11 by having the receiver\n> > assume NAMP for incoming payments < invoice_amount. (with some timeout of\n> > course, but that would need to be the case even when the sender is\n> > signalling NAMP).\n>\n> This would effectively become a probe for Base AMP; if you get a partial\n> payment error, it's because the recipient didn't support Base AMP.\n>\n> Seems cleaner to have a flag, both on BOLT11 and inside the onion.  Then\n> it's explicitly opt-in for both sides and doesn't affect existing nodes\n> in any way.\n>\n> Cheers,\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-- \n\u2014Sent from my Spaceship\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181121/afe803d2/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-22T04:50:22",
                "message_text_only": "Conner Fromknecht <conner at lightning.engineering> writes:\n> Hi all,\n>\n>> But it's unnecessary for the recipient to know the total amount I meant\n>> to pay; they just need to return the receipt once it exceeds the amount\n>> they want.\n>\n> I think it\u2019s true that the recipient doesn\u2019t need to know necessarily, but\n> sending the intended amount is more robust IMO, since it provides an order\n> invariant hint for when the receiver can safely settle.\n>\n> If the sender does amount fuzzing (as CL does) or adds a tip, it\u2019s possible\n> for the final partial payment to be less than `amount_to_pay` -\n> `invoice_amount`, causing the sender to settle prematurely. Otherwise, we\n> might want to specify that no split should be less than the amount\n> overpaid.\n>\n> Of course, if that amount never comes through yet the invoice is satisfied,\n> the receiver can always choose to settle even if the remaining amount never\n> arrives.\n\nIt's more code, and takes 8 more bytes out of the onion.  I've started\ncoding up option_simplfied_commitment and it's making me terrified of\nadding any additional complexity :(\n\nThe more compelling argument is that partial-payment donations might\nwant this, but it's marginal, IMHO.  We should be aiming for static\ninvoices for the donate case.\n\nCheers,\nRusty."
            },
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2018-11-26T07:58:24",
                "message_text_only": "This shouldn't be problem, as the invoice will already indicate that the\nnode supports BaseAMP. If you have a reason to not reveal that you support\nBAMP for certain invoices, you'll just not specify it in the invoice, and\nact non-BAMPy when receiving payments to this payment hash.\n\nOf course, this will also be opt-in for both sides and won't affect\nexisting nodes in any way.\n\nCheers,\nJohan\n\nOn Wed, Nov 21, 2018 at 11:54 PM Rusty Russell <rusty at rustcorp.com.au>\nwrote:\n\n> Johan Tor\u00e5s Halseth <johanth at gmail.com> writes:\n> > Seems like we can restrict the changes to BOLT11 by having the receiver\n> > assume NAMP for incoming payments < invoice_amount. (with some timeout of\n> > course, but that would need to be the case even when the sender is\n> > signalling NAMP).\n>\n> This would effectively become a probe for Base AMP; if you get a partial\n> payment error, it's because the recipient didn't support Base AMP.\n>\n> Seems cleaner to have a flag, both on BOLT11 and inside the onion.  Then\n> it's explicitly opt-in for both sides and doesn't affect existing nodes\n> in any way.\n>\n> Cheers,\n> Rusty.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181126/67166a9b/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-26T08:10:11",
                "message_text_only": "Good morning Johan,\n\nI believe what Rusty refers to here is a probe by an intermediate node, rather than a probe by the source node (who, as we know, already knows whether the payee supports AMP or not, by the invoice).\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Monday, November 26, 2018 3:58 PM, Johan Tor\u00e5s Halseth <johanth at gmail.com> wrote:\n\n> This shouldn't be problem, as the invoice will already indicate that the node supports BaseAMP. If you have a reason to not reveal that you support BAMP for certain invoices, you'll just not specify it in the invoice, and act non-BAMPy when receiving payments to this payment hash.\n>\n> Of course, this will also be opt-in for both sides and won't affect existing nodes in any way.\n>\n> Cheers,\n> Johan\n>\n> On Wed, Nov 21, 2018 at 11:54 PM Rusty Russell <rusty at rustcorp.com.au> wrote:\n>\n>> Johan Tor\u00e5s Halseth <johanth at gmail.com> writes:\n>>> Seems like we can restrict the changes to BOLT11 by having the receiver\n>>> assume NAMP for incoming payments < invoice_amount. (with some timeout of\n>>> course, but that would need to be the case even when the sender is\n>>> signalling NAMP).\n>>\n>> This would effectively become a probe for Base AMP; if you get a partial\n>> payment error, it's because the recipient didn't support Base AMP.\n>>\n>> Seems cleaner to have a flag, both on BOLT11 and inside the onion.  Then\n>> it's explicitly opt-in for both sides and doesn't affect existing nodes\n>> in any way.\n>>\n>> Cheers,\n>> Rusty.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181126/c4f7a7a6/attachment-0001.html>"
            },
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2018-11-27T22:25:18",
                "message_text_only": "(excuse me for not yet understanding what this extra complexity gives us)\n\nTo summarize: My suggestion was to only add an optional field to the\ninvoice, and let the recepient wait until all funds have received before\npulling the payment. No changes to the onion.\n\nWe briefly discussed this during the last call, that the extra bit set in\nthe onion will be necessary to support Partial Payments (PP?) in the\nspontaneous payments case.\n\nHowever, as we don't yet have spontaneous payments specced out, wouldn't\nthis be something to be added at that point?\n\nI just feel not adding the extra bit to the onion would make the\nimplementation of PP near trivial, and still don't see the downsides of not\nadding it.\n\nCheers, Johan\n\nOn Mon, Nov 26, 2018, 09:10 ZmnSCPxj <ZmnSCPxj at protonmail.com wrote:\n\n> Good morning Johan,\n>\n> I believe what Rusty refers to here is a probe by an intermediate node,\n> rather than a probe by the source node (who, as we know, already knows\n> whether the payee supports AMP or not, by the invoice).\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> Sent with ProtonMail <https://protonmail.com> Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Monday, November 26, 2018 3:58 PM, Johan Tor\u00e5s Halseth <\n> johanth at gmail.com> wrote:\n>\n> This shouldn't be problem, as the invoice will already indicate that the\n> node supports BaseAMP. If you have a reason to not reveal that you support\n> BAMP for certain invoices, you'll just not specify it in the invoice, and\n> act non-BAMPy when receiving payments to this payment hash.\n>\n> Of course, this will also be opt-in for both sides and won't affect\n> existing nodes in any way.\n>\n> Cheers,\n> Johan\n>\n> On Wed, Nov 21, 2018 at 11:54 PM Rusty Russell <rusty at rustcorp.com.au>\n> wrote:\n>\n>> Johan Tor\u00e5s Halseth <johanth at gmail.com> writes:\n>> > Seems like we can restrict the changes to BOLT11 by having the receiver\n>> > assume NAMP for incoming payments < invoice_amount. (with some timeout\n>> of\n>> > course, but that would need to be the case even when the sender is\n>> > signalling NAMP).\n>>\n>> This would effectively become a probe for Base AMP; if you get a partial\n>> payment error, it's because the recipient didn't support Base AMP.\n>>\n>> Seems cleaner to have a flag, both on BOLT11 and inside the onion.  Then\n>> it's explicitly opt-in for both sides and doesn't affect existing nodes\n>> in any way.\n>>\n>> Cheers,\n>> Rusty.\n>>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181127/760d330d/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-28T00:00:48",
                "message_text_only": "Johan Tor\u00e5s Halseth <johanth at gmail.com> writes:\n> (excuse me for not yet understanding what this extra complexity gives us)\n>\n> To summarize: My suggestion was to only add an optional field to the\n> invoice, and let the recepient wait until all funds have received before\n> pulling the payment. No changes to the onion.\n>\n> We briefly discussed this during the last call, that the extra bit set in\n> the onion will be necessary to support Partial Payments (PP?) in the\n> spontaneous payments case.\n\nThe donation case: a BOLT11 invoice doesn't have to specify an amount:\n\n    A writer:\n...\n      - If it requires a specific minimum amount for successful payment:\n          - MUST include that `amount`\n\nI initially suggested we could just have a 2-byte \"number of total\npieces\", but it turns out there's a use-case where that doesn't work\nwell: splitting the bill.  There each payer is unrelated, so doesn't\nknow how the others are paying.\n\nI've written up an onion proposal to cover this...\n\nCheers,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-28T03:54:45",
                "message_text_only": "Good morning all,\n\n> I initially suggested we could just have a 2-byte \"number of total\n> pieces\", but it turns out there's a use-case where that doesn't work\n> well: splitting the bill. There each payer is unrelated, so doesn't\n> know how the others are paying.\n\nThis would also not work well in case of a dynamic algorithm that greedily tries to pay the whole amount at once, then splits it if it does not fit, with each split also being liable to splitting.\nSuch a dynamic algorithm would not know in the first place how many splits it will take, but it *will* know the total amount it intends to deliver.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-29T23:46:16",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n\n> Good morning all,\n>\n>> I initially suggested we could just have a 2-byte \"number of total\n>> pieces\", but it turns out there's a use-case where that doesn't work\n>> well: splitting the bill. There each payer is unrelated, so doesn't\n>> know how the others are paying.\n>\n> This would also not work well in case of a dynamic algorithm that greedily tries to pay the whole amount at once, then splits it if it does not fit, with each split also being liable to splitting.\n> Such a dynamic algorithm would not know in the first place how many splits it will take, but it *will* know the total amount it intends to deliver.\n\nWell, that would have worked because received takes *max* of the values\nreceived, ie, sender starts with A and B, both with \"numpieces=2\",\nthen splits B into BA and BB, both with \"numpieces=3\".\n\nBut it's bad for the separate-payer case anyway, so...\n\nThanks,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-30T05:53:26",
                "message_text_only": "Good morning Rusty,\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Friday, November 30, 2018 7:46 AM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> ZmnSCPxj ZmnSCPxj at protonmail.com writes:\n>\n> > Good morning all,\n> >\n> > > I initially suggested we could just have a 2-byte \"number of total\n> > > pieces\", but it turns out there's a use-case where that doesn't work\n> > > well: splitting the bill. There each payer is unrelated, so doesn't\n> > > know how the others are paying.\n> >\n> > This would also not work well in case of a dynamic algorithm that greedily tries to pay the whole amount at once, then splits it if it does not fit, with each split also being liable to splitting.\n> > Such a dynamic algorithm would not know in the first place how many splits it will take, but it will know the total amount it intends to deliver.\n>\n> Well, that would have worked because received takesmax of the values\n> received, ie, sender starts with A and B, both with \"numpieces=2\",\n> then splits B into BA and BB, both with \"numpieces=3\".\n\n\nConsider a network where there are 4 paths between payer and payee.\n\n3 paths have low capacity but negligible feerate, while the 4th has high capacity but ridiculously high feerates measurable in whole microbitcoins.\n\nThe rational thing to try, when paying a somewhat large amount but trying to minimize fees, would be to split among the three lowcost paths.\n\nBut what if 2 of those paths fail?\nIt would be better to merge them into a single payment along the expensive 4th path.\nHowever, the remaining succeeding path has already given `numpaths`=3.\n\nUsing `numpaths` overcommits to what you will do in the future, and is unnecessary anyway.\nThe payee is interested in the total value, not the details of the split.\n\n\nRegards,\nZmnSCPxj\n\n>\n> But it's bad for the separate-payer case anyway, so...\n>\n> Thanks,\n> Rusty."
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-21T22:50:17",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n> Good morning Rusty,\n>\n>> And do not play with `amount_to_forward`, as it's an important\n>> signal to the final node that the previous node did not offer less value\n>> for the HTLC than it was supposed to. (You could steal the top bit to\n>> signal partial payment if you really want to).\n>\n>   If `incomplete_payment` flag is set, then final nodes must claim HTLCs only if:\n>\n>     sum(incoming_htlc_amt) >= amt_to_pay\n\nNo, because now you've lost assurance that this *particular* HTLC hasn't\nbeen skimmed by the previous node.\n\nie. if I suspect a payment is using Base-AMP (and that's pretty clear if\nI see two identical payment_hashes), I can reduce the amount I offer in\nthe outgoing HTLC to 1 satoshi: if it doesn't fail immediately, the next\nhop is the final destination.\n\n>   Where `sum(incoming_htlc_amt)` is the total `incoming_htlc_amt` for all incoming HTLCs terminating at this final node with the same `payment_hash`.\n\nBut it's unnecessary for the recipient to know the total amount I meant\nto pay; they just need to return the receipt once it exceeds the amount\nthey want.\n\nCheers,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-22T08:20:20",
                "message_text_only": "Good morning Rusty,\n\nOkay, I shall modify pull request as you suggested.\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Thursday, November 22, 2018 6:50 AM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> ZmnSCPxj ZmnSCPxj at protonmail.com writes:\n>\n> > Good morning Rusty,\n> >\n> > > And do not play with `amount_to_forward`, as it's an important\n> > > signal to the final node that the previous node did not offer less value\n> > > for the HTLC than it was supposed to. (You could steal the top bit to\n> > > signal partial payment if you really want to).\n> >\n> > If `incomplete_payment` flag is set, then final nodes must claim HTLCs only if:\n> >\n> >     sum(incoming_htlc_amt) >= amt_to_pay\n> >\n>\n> No, because now you've lost assurance that thisparticular HTLC hasn't\n> been skimmed by the previous node.\n>\n> ie. if I suspect a payment is using Base-AMP (and that's pretty clear if\n> I see two identical payment_hashes), I can reduce the amount I offer in\n> the outgoing HTLC to 1 satoshi: if it doesn't fail immediately, the next\n> hop is the final destination.\n>\n> > Where `sum(incoming_htlc_amt)` is the total `incoming_htlc_amt` for all incoming HTLCs terminating at this final node with the same `payment_hash`.\n>\n> But it's unnecessary for the recipient to know the total amount I meant\n> to pay; they just need to return the receipt once it exceeds the amount\n> they want.\n>\n> Cheers,\n> Rusty."
            }
        ],
        "thread_summary": {
            "title": "Base AMP",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Anthony Towns",
                "Conner Fromknecht",
                "Ren\u00e9 Pickhardt",
                "Johan Tor\u00e5s Halseth",
                "Rusty Russell",
                "ZmnSCPxj",
                "Christian Decker"
            ],
            "messages_count": 28,
            "total_messages_chars_count": 65642
        }
    },
    {
        "title": "[Lightning-dev] Offline Lightning-enabled Vending Machines",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-13T12:52:56",
                "message_text_only": "Good morning list,\n\nDuring the summit, it was asked about an actual application problem for vending machines without any secret keys (so that hackers of vending machines cannot steal money from the machine).\n\nIt was quite very satisfactorily solved by one of us, and I thought it would best shared and recorded for posterity (as it was not recorded in the wiki).\n\nThe problem:\n\n1.  There exists a vending machine which must be offline and not contain any secret keys, in order to prevent theft from the machine.\n    As the machine is not under direct control of the owner of the machine, it is better if the attack surface is reduced.\n2.  The owner of the vending machine (who is selling the product) has a separate, probably singular, Lightning node to receive payments.\n\nThe solution:\n\n1.  Each vending machine contains a fixed number of hashes, as well as invoice signatures (signed by the owner Lightning node) corresponding to each hash.\n    The number of hashes must at least equal the number of product for sale.\n    The description of the product as well as the invoice price is fixed (after all, Bitcoin must be our unit of account).\n    (for vending machines supporting multiple product types, simply multiply this table by the number of different product types)\n2.  Each hash has a 1-bit flag, initially 0.\n    This flag is set to 1 when the hash has been claimed.\n3.  When a customer requests to purchase a product, the machine searches for a hash whose flag is 0.\n    It generates the invoice (concatenating the description and price, and filling in the payment hash and invoice signature) and gives to customer.\n4.  The customer pays as normal.\n    The vending machine owner node receives this payment and releases the preimage as proof-of-payment.\n5.  The customer gives the preimage to the machine, via QR code or via short-range radio technology such as bluetooth or NFC.\n6.  The machine checks the preimage, computes it hash, and checks if it is in the list of hashes.\n   If so, and the claim flag is not set, it sets the flag and releases the product.\n   OPEN PROBLEM: If product release fails due to mechanical failure, there is no way to easily refund the payment.\n7.  When replenishing the supply of product to the vending machine, the supply of hashes can also be replenished by the owner of the vending machine also.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181113/87b0f6e1/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-28T05:51:37",
                "message_text_only": "Good morning list,\n\nSince I have not spammed the list enough with pointless ideas, I consider now an extension of this idea, the meta-vending machine.\n\nA vending machine contains products and dispenses them for proof that the owner of the machine has been paid.\nA meta-vending machine contains vending machines and dispenses them for proof-of-payment.\n\nIn actuality, a meta-vending machine contains several machine-lockable boxes.\nEach box is initially empty.\nThe contents of each box is visible.\n\nSuppose I have a product I wish to sell.\nI \"rent\" one of these boxes by paying the meta-vending machine owner (using the same technique already discussed below).\nThen the box requests for my invoice.\n\nLater, someone passes by the meta-vending machine, and sees my product and decides to purchase it.\nThe meta-vending machine provides the invoice, and in exchange for the preimage to the hash in the invoice, opens the bos and lets the buyer get th product.\nThe box can then be reused by another seller.\n\nSuppose the product is not sold.\nSince I know the preimage, I can also provide the preimage and get my product back.\nI could then replace the product, or sell another product, or refresh the invoice.\n\nSuch an automated system would be useful for selling small items.\nDepending on the security of the machine itself, the value of the item may be large.\nIt can also be used as a somewhat-anonymous rendezvous point for transferring small items in exchange for money, such as valuable collectible cards.\n\nIn essence, such a meta-vending machine provides an HTLC-like behavior in the real world, and allows us to extend the ZKCP by one hop into real-world items.\n\nOf course, trust is now needed in the meta-vending machine owner.\nPresumably the meta-vending machine owner can simply unlock any arbitrary box and take the item inside.\nThus the practical maximum value of the items sold via such a machine may be limited by the trustworthiness of the meta-vending machine owner.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Offline Lightning-enabled Vending Machines",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "ZmnSCPxj"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 4537
        }
    },
    {
        "title": "[Lightning-dev] Forwarding hints in channel update messages",
        "thread_messages": [
            {
                "author": "Joost Jager",
                "date": "2018-11-14T08:17:14",
                "message_text_only": "Hello all,\n\nI'd like to bring up an idea that builds on top of \"non-strict\" forwarding.\nI commented about this on conner's non-strict forwarding lightning-rfc pr,\nbut it is probably better to discuss it on its own in this list.\n\nA node that forwards non-strictly, is using any of its channels to carry\nthe payment to the next hop. It is ignoring the actually requested channel\nin `update_add_htlc`, except for determining the next hop pubkey.\n\nWhen forwarding fails, a `channel_update` msg can be returned to the\nsender. This brings up the question for which channel to return a\n`channel_update` in case of failed non-strict forwarding.\n\nIf the htlc didn't satisfy the policy of the requested channel, the\nsender's view on the graph is not up to date and it makes sense to return a\n`channel_update` for the requested channel.\n\nHowever, if the htlc did satisfy the policy, sending back a\n`channel_update` does not provide the sender with any new information. In\ncase of TemporaryChannelFailure, the update is optional. But leaving it out\ndoes not save any bytes because of padding (as pointed out by pierre in the\npr).\n\nThe idea is to repurpose the `channel_update` message in this case as a\n'forwarding hint'.\n\nWhen non-strict forwarding fails, the intermediate node iterates over all\nits channels to the next hop and determines what would be the 'best'\nchannel to use from the sender point of view. Best could be defined as a\ntrade off between minimum fee and time lock delta, similar to the weight\nfunction used during path finding. Only channels that have enough balance\nfor the amount requested in the htlc are considered in this process.\n\nIf there is no best channel (for example when none of the channels have\nenough capacity), the node just returns a `channel_update` for the\nrequested channel as usual.\n\nIf there is a best channel, a `channel_update` is returned for that channel\ninstead of the requested channel. Senders that are aware of this behavior\nwill recognize this when reading the failure message and interpret the\n`channel_update` as a forwarding hint.\n\nSenders not aware of the forwarding hint will either just apply the channel\nupdate to the graph or reject it. Both are fine, because their copy of the\npolicy for the requested channel was already up-to-date. This makes this\nidea backwards compatible.\n\nWhat this forwarding hint signals is that an htlc with a fee and time lock\ndelta that satisfies the policy of the hinted channel will likely be\nforwarded successfully. Of course if something changes at the intermediate\nnode (channel balance) in the mean time, the hint may not be valid anymore.\n\nWith the hint in hand, the sender can adjust the route to satisfy the\nhinted policy and try again. Alternatively, it could first try a route\nthrough other nodes because the hinted policy increases the total fee\nand/or time lock too much. How to exactly integrate this in path finding is\nsomething to work out further. The sender should be aware that an\nintermediate node may try to maximize its earning by handing out\n'expensive' forwarding hints and therefore should not blindly apply the new\npolicy to a route.\n\nThe advantage of having the hint is that the sender likely needs fewer\npayment attempts to complete the payment. For the intermediate node, it is\na way to increase its earnings. It gives the sender more certainty about\nthe parameters that lead to successful forwarding and the sender may choose\nto just go with those instead of trying out many other routes, even if one\nof those routes could be better. In case the sender wants the absolute best\nroute, the forwarding hint may still be beneficial to the intermediate\nnode. When there are multiple routes with identical total fees and time\nlocks, a sender will likely choose the route for which it has received\nforwarding hints.\n\nIn case the intermediate node can only forward the payment over a private\nchannel, it could hint the policy of a public channel with a policy that\nalso satisfies the private channel's policy. It doesn't matter if this\npublic channel doesn't have enough balance, because non-strict forwarding\nwill also be applied on the next attempt. Or maybe just returning a\n`channel_update` for channel id 0 with the private channel's policy.\nSenders aware of forwarding hints may just as well interpret this properly.\n\nTo implement this, no onion packet changes are required. An intermediate\nnode could advertise that it provides forwarding hints through a global\nfeature bit, but that is optional. The forwarding hints can also be\nrecognized in the `channel_update` message itself.\n\nRegards,\nJoost\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181114/7ffeb2df/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-14T20:31:10",
                "message_text_only": "Joost Jager <joost.jager at gmail.com> writes:\n> Hello all,\n>\n> I'd like to bring up an idea that builds on top of \"non-strict\" forwarding.\n> I commented about this on conner's non-strict forwarding lightning-rfc pr,\n> but it is probably better to discuss it on its own in this list.\n\nThe decision was made to allow additional channel_update in the error\nreply:\n\n        DECISION: document that scid is not binding, allow extra\n        channel_updates in errors for \u201cupselling\u201d.\n\nAFAICT this is a deeply weird case.  If another channel had capacity you\nwould have just used it.  If another channel doesn't, sending a\nchannel_update doesn't help.  And if there's a channel available at a\nhigher feerate or longer timeout, it raises the question of why you're\ndoing that rather than just taking the offer in front of you; that value\nclearly used to be acceptable, and now you risk them routing around you.\n\nCheers,\nRusty."
            },
            {
                "author": "Joost Jager",
                "date": "2018-11-15T12:37:49",
                "message_text_only": "On Thu, Nov 15, 2018 at 1:53 AM Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> The decision was made to allow additional channel_update in the error\n> reply:\n>\n>         DECISION: document that scid is not binding, allow extra\n>         channel_updates in errors for \u201cupselling\u201d.\n>\n\nYes, I read this. What exactly is \"upselling\" in this context and how were\nextra channel_updates in errors intended to be used for this? Is it useful\nfor non-strict forwarding nodes?\n\n\n> AFAICT this is a deeply weird case.  If another channel had capacity you\n> would have just used it.  If another channel doesn't, sending a\n> channel_update doesn't help.  And if there's a channel available at a\n> higher feerate or longer timeout, it raises the question of why you're\n> doing that rather than just taking the offer in front of you; that value\n> clearly used to be acceptable, and now you risk them routing around you.\n>\n\nGood point. If the value is acceptable, but that particular channel happens\nto have not enough balance, it is hard to explain why you wouldn't just\naccept. Maybe if you have a large capacity channel that you want to reserve\nfor large amounts at a higher fee and you don't want this channel's balance\nto be used up by multiple non-strict forwarded small htlcs? This could also\nbe realized by setting min_htlc, but then it can never be used for small\nhtlcs. This admittedly is pretty specific.\n\nMaybe the forwarding hint that could make more of a difference is just the\ninformation that non-strict forwarding was actually applied. Communicate\nthis as a node property via a global feature bit. If the sender receives a\nTemporaryChannelFailure from a non-strict forwarding node, it doesn't need\nto bother with trying all other (equal policy) channels from that node to\nthe next.\n\nRegards,\nJoost\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181115/90e25246/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-20T00:09:16",
                "message_text_only": "Joost Jager <joost.jager at gmail.com> writes:\n> On Thu, Nov 15, 2018 at 1:53 AM Rusty Russell <rusty at rustcorp.com.au> wrote:\n>\n>> The decision was made to allow additional channel_update in the error\n>> reply:\n>>\n>>         DECISION: document that scid is not binding, allow extra\n>>         channel_updates in errors for \u201cupselling\u201d.\n>>\n>\n> Yes, I read this. What exactly is \"upselling\" in this context and how were\n> extra channel_updates in errors intended to be used for this? Is it useful\n> for non-strict forwarding nodes?\n\nEvery node should be non-strict, in the sense that we could never detect\nit anyway.  This change is just to explicitly document that.  scid is used\nas a cheap way of specifying next hop, and gives an additional hint as\nto why we chose the feerate we did, and is not binding.\n\nThe extra channel_updates allow a node to indicate that there are\nalternate channels which could be used instead (presumably at a higher\nfeerate).\n\n> Maybe the forwarding hint that could make more of a difference is just the\n> information that non-strict forwarding was actually applied. Communicate\n> this as a node property via a global feature bit. If the sender receives a\n> TemporaryChannelFailure from a non-strict forwarding node, it doesn't need\n> to bother with trying all other (equal policy) channels from that node to\n> the next.\n\nThat's an internal matter which shouldn't leak, AFAICT.\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Forwarding hints in channel update messages",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Joost Jager"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 9113
        }
    },
    {
        "title": "[Lightning-dev] Strawman BOLT11 static \"offer\" format using probes.",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-11-15T03:56:31",
                "message_text_only": "Hi all,\n\n    I want to propose a method of having reusable BOLT11 \"offers\" which\nprovide almost-spontaneous payments as well as not requiring generating\na BOLT11 invoice for each potential sale.\n\nAn \"offer\" has a `p` field of 26 bytes (128 bits assuming top two are 0)\n(which is ignored by existing nodes).  The payer uses a new lightning\nprobe message using the current onion format we use for HTLCs to\nretreive the complete invoice.\n\nThe format of the final-hop lightning onion would contain:\n\n        [whatever-marker-we-need?][128-bit-`p`-field][[type,len,data]+]\n\nWe would probably define a few optional types to start:\n\n1. quantity: for ordering multiple of an item, default 1.\n2. delivery-address: steal from https://www.w3.org/TR/vcard-rdf/#Delivery_Addressing_Properties ?\n3. signature: basically a blob so payer can prove it was them.\n\nThe return lightning message would contain a new bolt11 invoice (perhaps\nwe optimize some fields by copying from the bolt11 offer if they don't\nappear?), and an additional field:\n\n        `m` (27) `data_length` 52.  Merkle hash of fields payer provided\n        in onion msg above, and the offer `p` value.\n\nThe payer checks the signature is correct, `m` is correct, and uses the\ninvoice to pay as normal.  The bolt11 offer + fields-from-onion + bolt11\ninvoice + preimage is the complete proof of payment.\n\nRefinements\n-----------\n\nWe can generate alternate leaves for the merkle tree (using\nSHA256(shared-secret | leafnum)) so revealing the `m` value doesn't risk\nrevealing your delivery-address for example.\n\nThe return needs to list the fields it *didn't* include in the merkle\nbecause it didn't accept them (the merchant doesn't want to be bound to\nconditions it doesn't understand!).\n\nWe could add a `k` field to the bolt11 offer to allow the final invoice\nto delegated to a separate key.\n\nThe default `x` (expiry) field for an offer which does not have an\nold-style 53-byte `p` field (ie. a \"pure\" offer) could be infinite.\n\nWe could merkelize the delivery-address too :)\n\nI've handwaved a bit over the detailed format, because there are other\nthings we want to put in the onion padding, and because the return is\nsimilar to the \"soft-error\"/\"partial payment ack\" proposals.\n\nResults\n-------\n\nThis gives us static invoicing, and a single static invoice (without an\namount field) can thus be used to approximate \"spontaneous\" donations,\nwhile still providing proof of payment; indeed, providing\nnon-transferrable proof-of-payment since the invoice now commits to the\npayer-provided signature.\n\nIt also provides a platform for recurring payments: while we can do this\nwith preimage-is-next-payment_hash, that requires pre-generation and\nisn't compatible with static invoices.\n\nI apologize that this wasn't fleshed out before the summit, but I\noverestimated the power of Scriptless Scripts so had mentally deferred\nthis.\n\nThanks!\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-15T04:42:28",
                "message_text_only": "Good morning Rusty,\n\nNo particular comment on static offer invoices, but instead various bikeshedding.\n\n>\n> The format of the final-hop lightning onion would contain:\n>\n> [whatever-marker-we-need?][128-bit-`p`-field][[type,len,data]+]\n\nI think a separate BOLT for the type,len,data would be useful, and might also document various consistent designs of messages (such as var-length fields using a prefixed 16-bit length measuring number of items in the field).\n\nBOLT #13: type,len,data standard\n\n(I should probably move this to a new thread).\n\n> I apologize that this wasn't fleshed out before the summit, but I\n> overestimated the power of Scriptless Scripts so had mentally deferred\n> this.\n\nMy understanding is that SS *is* as powerful as we thought, at least for some of the applications we were hoping to use it for.\nHowever, implementing SS is hard without Schnorr, because script magic with `OP_CODESEPARATOR` is magic, and we essentially stalled out and said \"maybe wait for Schnorr instead\".\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-16T00:15:28",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n>> I apologize that this wasn't fleshed out before the summit, but I\n>> overestimated the power of Scriptless Scripts so had mentally deferred\n>> this.\n>\n> My understanding is that SS *is* as powerful as we thought, at least for some of the applications we were hoping to use it for.\n> However, implementing SS is hard without Schnorr, because script magic with `OP_CODESEPARATOR` is magic, and we essentially stalled out and said \"maybe wait for Schnorr instead\".\n\nNo, we don't get static invoices.  That was my hope; that we could do\nstatic invoicing without an extra interaction.\n\nCheers,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-16T03:07:15",
                "message_text_only": "Good morning Rusty,\n\n> > > I apologize that this wasn't fleshed out before the summit, but I\n> > > overestimated the power of Scriptless Scripts so had mentally deferred\n> > > this.\n> >\n> > My understanding is that SS is as powerful as we thought, at least for some of the applications we were hoping to use it for.\n> > However, implementing SS is hard without Schnorr, because script magic with `OP_CODESEPARATOR` is magic, and we essentially stalled out and said \"maybe wait for Schnorr instead\".\n>\n> No, we don't get static invoices. That was my hope; that we could do\n> static invoicing without an extra interaction.\n\nAt first I thought it was possible, but on reflection, you are correct.\nWe need some way for the payee to dynamically provide a new payment hash (or payment point under SS).\n\nThis is because our proof-of-payment essentially means the payer learns a secret.\nSo we cannot commit to a fixed secret if we want the static invoice to be shareable among multiple payers.\nSo the payee does need to generate new secrets each time it wants to be paid, and give a unique secret to the payer as separate unique proofs-of-payment.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-15T16:22:29",
                "message_text_only": "Good morning Rusty,\n\n> I want to propose a method of having reusable BOLT11 \"offers\" which\n> provide almost-spontaneous payments as well as not requiring generating\n> a BOLT11 invoice for each potential sale.\n\nSuggest making a new BOLT document.\nThis would be basically a new BOLT for how to generate a BOLT11 invoice.\nI suggest also to use instead the term \"BOLT15 advertisement\".\n\n>\n>     The return lightning message\n\nWill this be a new message that fails the HTLC, or will we reuse `update_fail_htlc` to return the data as an error?\n\n>would contain a new bolt11 invoice (perhaps\n>     we optimize some fields by copying from the bolt11 offer if they don't\n>     appear?)\n\nWould this require some kind of canonical ordering for tagged fields in the generated bolt11 invoice?\nFor t-l-v there is proposal for types to have an absolute order (from lowest-numbered to highest-numbered), which would be useful for such cases where we want to only give unique parts of something.\nBolt11 invoices have a signature so the order of the tagged fields matters.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-16T09:01:35",
                "message_text_only": "Good morning Rene,\n\nNot Rusty, but I shall spam the list as for my normal habit anyway.\n\n>My problem starts with the fact that I can't find the term \"lightning probe\n>message\" in the current BOLTs  (actually the term probe only occures two\n>times and these seem unrelated to what you are talking about) so I am\n>confused what this is.\n\nThis is basically, generating a `payment_hash` from random data, whose preimage it is very unlikely the payee knows, and then sending it to the payee.\nSince the payee does not know the preimage, it cannot actually claim the funds.\n\nI believe, somebody in the summit pointed out that this mechanism could, today, be used to stream anime.\nThe payee does not actually get paid, but has to return an error for why it cannot claim the HTLC.\nThe error from the payee can contain a short section of an anime movie file instead of an error message, which the payer then watches instead of worrying about why they cannot pay.\n\nRather than using this mechanism to stream anime, we use this mechanism to stream invoices, which is much more sensible use for a payment network.\n\n>As far as I understand your proposal from a high level the payer is\n>supposed to create an onion package which triggers the offering of HTLCs\n>with some additional metadata so that the receipient of the final onion can\n>answer with a BOLT11 invoice. What I don't get is the fact that a payment\n>hash needs to be known in order to offer HTLCs.\n\nAs mentioned, this mechanism basically has the putative payer generate a random hash.\nThe error response then contains the \"real\" BOLT11 invoice, plus some extra data as described by Rusty in the initial post.\n\n>Though I imagine you ment it differently I would not see a problem with the\n>payer to know the preimage in advance as he is creating the entire onion on\n>his behalf and sponanious without invoice anyway. However I don't get why a\n>returned BOLT11 invoice is needed then.\n\nSince the probe will fail, the payee does not get actually paid.\nInstead the payee returns the **real** `payment_hash`, encoded (presumably) as part of a BOLT11 invoice.\n(or we encode the BOLT11 invoice fields in binary instead of BECH32 for compression, and so on, but basically, the payer can now generate a BOLT11 invoice it can pay using normal Lightning payment methods; this is my reasoning for proposing to add these \"offers\" as a separate BOLT, e.g. BOLT15. A BOLT15 offer lets you get any number of BOLT11 invoices.)\n\n\n>In general I was wondering (already during the summit) why we don't include\n>a connection oriented communication layer on top of the current protocol\n>which would allow payer and payee to communicate more efficiently about\n>payment and routing process and to negotiate stuff like spontaneos\n>payments.\n\nI believe this was the reason for pushing for HORNET implementation on Lightning.\nHORNET is basically the connection communication layer being proposed, with improved privacy because HORNET.\n\nFor myself, I think that we should attach payments for each HORNET-style messaging system, and impose a `update_fail_htlc` limit so that only errors and a short text message can be returned for errors.\n\nAs to why not HORNET...\n\n>I see two reasons against this: 1.) more synchronous\n>communication makes stuff more complicated to implement and 2.) privacy\n>concerns.\n\nMostly complexity, and concerns that people will abuse the network capacity (as in bytes capacity of TCP/IP connections, not satoshis capacity of channels).\nThat is why I think that if we *do* implement HORNET, then a payment or forwarding fee should be attached to each such message.\nAttaching payments to the faithful delivery of HORNET-level messages is needed, but I am uncertain if it is feasible to do so.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2018-11-16T07:47:15",
                "message_text_only": "Dear Rusty,\n\nI am not getting this proposal (maybe I am lacking some technical basic\nunderstandings) however I decided to ask more questions in order to\ncomplete my onboarding process faster and hope this is fine.\n\nMy problem starts with the fact that I can't find the term \"lightning probe\nmessage\" in the current BOLTs  (actually the term probe only occures two\ntimes and these seem unrelated to what you are talking about) so I am\nconfused what this is.\nAs far as I understand your proposal from a high level the payer is\nsupposed to create an onion package which triggers the offering of HTLCs\nwith some additional metadata so that the receipient of the final onion can\nanswer with a BOLT11 invoice. What I don't get is the fact that a payment\nhash needs to be known in order to offer HTLCs.\nThough I imagine you ment it differently I would not see a problem with the\npayer to know the preimage in advance as he is creating the entire onion on\nhis behalf and sponanious without invoice anyway. However I don't get why a\nreturned BOLT11 invoice is needed then. I assume that my previouse\nstatement is wrong anyway since you don't mention anywhere how the preimage\nwould be send from the payer to the payee.\n\nIn general I was wondering (already during the summit) why we don't include\na connection oriented communication layer on top of the current protocol\nwhich would allow payer and payee to communicate more efficiently about\npayment and routing process and to negotiate stuff like spontaneos\npayments. I see two reasons against this: 1.) more synchronous\ncommunication makes stuff more complicated to implement and 2.) privacy\nconcerns.\nAm I missing something here? (and sorry for splitting the topic but I\ndidn't want to start a new one when it actually seems to fit to this\nproposal.\n\nbest Rene\n\nOn Thu, Nov 15, 2018 at 4:57 AM Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> Hi all,\n>\n>     I want to propose a method of having reusable BOLT11 \"offers\" which\n> provide almost-spontaneous payments as well as not requiring generating\n> a BOLT11 invoice for each potential sale.\n>\n> An \"offer\" has a `p` field of 26 bytes (128 bits assuming top two are 0)\n> (which is ignored by existing nodes).  The payer uses a new lightning\n> probe message using the current onion format we use for HTLCs to\n> retreive the complete invoice.\n>\n> The format of the final-hop lightning onion would contain:\n>\n>         [whatever-marker-we-need?][128-bit-`p`-field][[type,len,data]+]\n>\n> We would probably define a few optional types to start:\n>\n> 1. quantity: for ordering multiple of an item, default 1.\n> 2. delivery-address: steal from\n> https://www.w3.org/TR/vcard-rdf/#Delivery_Addressing_Properties ?\n> 3. signature: basically a blob so payer can prove it was them.\n>\n> The return lightning message would contain a new bolt11 invoice (perhaps\n> we optimize some fields by copying from the bolt11 offer if they don't\n> appear?), and an additional field:\n>\n>         `m` (27) `data_length` 52.  Merkle hash of fields payer provided\n>         in onion msg above, and the offer `p` value.\n>\n> The payer checks the signature is correct, `m` is correct, and uses the\n> invoice to pay as normal.  The bolt11 offer + fields-from-onion + bolt11\n> invoice + preimage is the complete proof of payment.\n>\n> Refinements\n> -----------\n>\n> We can generate alternate leaves for the merkle tree (using\n> SHA256(shared-secret | leafnum)) so revealing the `m` value doesn't risk\n> revealing your delivery-address for example.\n>\n> The return needs to list the fields it *didn't* include in the merkle\n> because it didn't accept them (the merchant doesn't want to be bound to\n> conditions it doesn't understand!).\n>\n> We could add a `k` field to the bolt11 offer to allow the final invoice\n> to delegated to a separate key.\n>\n> The default `x` (expiry) field for an offer which does not have an\n> old-style 53-byte `p` field (ie. a \"pure\" offer) could be infinite.\n>\n> We could merkelize the delivery-address too :)\n>\n> I've handwaved a bit over the detailed format, because there are other\n> things we want to put in the onion padding, and because the return is\n> similar to the \"soft-error\"/\"partial payment ack\" proposals.\n>\n> Results\n> -------\n>\n> This gives us static invoicing, and a single static invoice (without an\n> amount field) can thus be used to approximate \"spontaneous\" donations,\n> while still providing proof of payment; indeed, providing\n> non-transferrable proof-of-payment since the invoice now commits to the\n> payer-provided signature.\n>\n> It also provides a platform for recurring payments: while we can do this\n> with preimage-is-next-payment_hash, that requires pre-generation and\n> isn't compatible with static invoices.\n>\n> I apologize that this wasn't fleshed out before the summit, but I\n> overestimated the power of Scriptless Scripts so had mentally deferred\n> this.\n>\n> Thanks!\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n\n\n-- \nhttps://www.rene-pickhardt.de\n\nSkype: rene.pickhardt\n\nmobile: +49 (0)176 5762 3618\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181116/573e0200/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-17T23:20:56",
                "message_text_only": "Ren\u00e9 Pickhardt <r.pickhardt at googlemail.com> writes:\n> Dear Rusty,\n>\n> I am not getting this proposal (maybe I am lacking some technical basic\n> understandings) however I decided to ask more questions in order to\n> complete my onboarding process faster and hope this is fine.\n>\n> My problem starts with the fact that I can't find the term \"lightning probe\n> message\" in the current BOLTs  (actually the term probe only occures two\n> times and these seem unrelated to what you are talking about) so I am\n> confused what this is.\n\nIt would be a new message.  We don't have an equivalent at the moment,\nthough one was proposed for liveness testing of routes pre-payment:\n\n        Use probing with short latency constraints (ex\u201d must reply within 100 ms) to check that a route is usable before payment is actually sent\n        https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-October/001484.html\n\n> As far as I understand your proposal from a high level the payer is\n> supposed to create an onion package which triggers the offering of HTLCs\n> with some additional metadata so that the receipient of the final onion can\n> answer with a BOLT11 invoice. What I don't get is the fact that a payment\n> hash needs to be known in order to offer HTLCs.\n\nNo, there's a new message, which looks like:\n\n1. type: 260 (`fetch_invoice`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`1366`:`onion_routing_packet`]\n\n(The onion doesn't need some of the current fields, TBD).\n\n> In general I was wondering (already during the summit) why we don't include\n> a connection oriented communication layer on top of the current protocol\n> which would allow payer and payee to communicate more efficiently about\n> payment and routing process and to negotiate stuff like spontaneos\n> payments.\n\nThis is HORNET; I recommend reading the paper.  I admit that this\nmessage is the camel's nose in the tent, but we're building a payment\nnetwork, not a generalized communication network.  And until we figure\nout how to pay-per-message without haemorrhaging privacy, we shouldn't\nbuild such a thing.\n\n> I see two reasons against this: 1.) more synchronous\n> communication makes stuff more complicated to implement and 2.) privacy\n> concerns.\n\n3) Lack of incentives.  Nodes forward because they want a functioning\npayment network, and they hope to be rewarded for it.  At the moment you\ncan get spammed quite badly and never get paid; I'd like to make that\nmore difficult, not bake it into the protocol!\n\nSomeone may build such a thing on top of lightning, but lightning nodes\nare not generalized bandwidth providers.\n\n> Am I missing something here? (and sorry for splitting the topic but I\n> didn't want to start a new one when it actually seems to fit to this\n> proposal.\n\nThis is a can of worms I don't want to open for 1.1...\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Strawman BOLT11 static \"offer\" format using probes.",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Ren\u00e9 Pickhardt",
                "ZmnSCPxj"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 18719
        }
    },
    {
        "title": "[Lightning-dev] type,len,value standard",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-15T04:54:25",
                "message_text_only": "Good morning list,\n\nAn item added discussed in the summit was the proposed \"type,len,value\", which is added to the end of messages and other intercommunication structures (invoices and so on).\nThis would allow some transition to future additional fields while maintaining backward compatibility.\n\nI believe these were brought up:\n\n1.  For a sequence of `type,len,value`, each `type` must be unique. -- accepted.\n2.  For a sequence of `type,len,value`, the `type`s must be in ascending order -- not explicitly accepted or rejected.  It would be easier to check uniqueness (the previous rule we accepted) here for a naive parser (keep track of some \"minimum allowed type\" that initializes at zero, check current type >= this, update to current type + 1) if `type`s are in ascending order.\n\nNow for bikeshedding:\n\n1, `type` - one byte or two?\n2. `type` - maybe some other name, since we already use `type` for messages?  How about, `key` instead?\n3. `type` - does \"it's OK to be odd\" apply?  i.e. if an even `type` that is not known is found, crash and burn.  But intent of this system is for future expansion for optional fields, so...?\n4. `len` - measures bytes of `value`, obviously since if the receiver does not know the `type` then it cannot know what unit is used for the `value`.\n5. `len` - one byte or two? I believe we tend to use two bytes for various lengths.\n6.  BOLT - I propose making a separate BOLT for `type,len,value`, which other messages and so on simply refer to.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181115/815ebee9/attachment.html>"
            },
            {
                "author": "Conner Fromknecht",
                "date": "2018-11-15T06:49:40",
                "message_text_only": "Hi ZmnSCPxj,\n\nThanks for writing this up! I had started an email, but you beat me to it :)\n\n> 1.  For a sequence of `type,len,value`, each `type` must be unique. --\n> accepted.\n\nTo add to this, it seemed that there was some agreement that repeated fields\nshould be serialized under a single root key, since a receiver can't know if a\nfield is allowed to have duplicates if they don't understand the field.\n\n> For a sequence of `type,len,value`, the `type`s must be in ascending order\n> -- not explicitly accepted or rejected.  It would be easier to check\n> uniqueness > (the previous rule we accepted) here for a naive parser (keep\n> track of some \"minimum allowed type\" that initializes at zero, check current\n> type >= this, update to current type + 1) if `type`s are in ascending order.\n\nYep ascending makes sense to me, for the reasons you stated.\n\n> 1, `type` - one byte or two?\n\nI'd lean towards one, if a message has 256 optional fields, it might be time to\nconsider a new message type altogether.\n\n> 3. `type` - does \"it's OK to be odd\" apply?  i.e. if an even `type` that is\n> not known is found, crash and burn.  But intent of this system is for future\n> expansion for optional fields, so...?\n\nPerhaps this depends on context:\n - for gossip messages, I think the primary concern is not breaking signature\n     validation, and that these would need to remain optional for backwards\n     compatibility.\n - for link-level messages, we have a little more control. I imagined the fields\n   would be gated by feature bit negotiation, and deviating from\n   unsupported/required would result in being disconnected.\n\n> 5. `len` - one byte or two? I believe we tend to use two bytes for various\n> lengths.\n\nMaybe varint? One byte is not enough for all lengths, but two seems excessive\nfor uint8 or even uint32.\n\n> 6.  BOLT - I propose making a separate BOLT for `type,len,value`, which other\n> messages and so on simply refer to.\n\nIndeed, are you thinking we'd use this to add new fields proposed in 1.1?\n\nIn addition to the above, do we also want to flesh out what sub-TLV structures\nwould look like? Or perhaps that isn't necessary, if we can continue adding more\nroot-level keys.\n\n--Conner\nOn Wed, Nov 14, 2018 at 8:54 PM ZmnSCPxj via Lightning-dev\n<lightning-dev at lists.linuxfoundation.org> wrote:\n>\n> Good morning list,\n>\n> An item added discussed in the summit was the proposed \"type,len,value\", which is added to the end of messages and other intercommunication structures (invoices and so on).\n> This would allow some transition to future additional fields while maintaining backward compatibility.\n>\n> I believe these were brought up:\n>\n> 1.  For a sequence of `type,len,value`, each `type` must be unique. -- accepted.\n> 2.  For a sequence of `type,len,value`, the `type`s must be in ascending order -- not explicitly accepted or rejected.  It would be easier to check uniqueness (the previous rule we accepted) here for a naive parser (keep track of some \"minimum allowed type\" that initializes at zero, check current type >= this, update to current type + 1) if `type`s are in ascending order.\n>\n> Now for bikeshedding:\n>\n> 1, `type` - one byte or two?\n> 2. `type` - maybe some other name, since we already use `type` for messages?  How about, `key` instead?\n> 3. `type` - does \"it's OK to be odd\" apply?  i.e. if an even `type` that is not known is found, crash and burn.  But intent of this system is for future expansion for optional fields, so...?\n> 4. `len` - measures bytes of `value`, obviously since if the receiver does not know the `type` then it cannot know what unit is used for the `value`.\n> 5. `len` - one byte or two? I believe we tend to use two bytes for various lengths.\n> 6.  BOLT - I propose making a separate BOLT for `type,len,value`, which other messages and so on simply refer to.\n>\n> Regards,\n> ZmnSCPxj\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-15T07:39:19",
                "message_text_only": "Good morning Conner,\n\n> > For a sequence of `type,len,value`, the `type`s must be in ascending order\n> > -- not explicitly accepted or rejected. It would be easier to check\n> > uniqueness > (the previous rule we accepted) here for a naive parser (keep\n> > track of some \"minimum allowed type\" that initializes at zero, check current\n> > type >= this, update to current type + 1) if `type`s are in ascending order.\n>\n> Yep ascending makes sense to me, for the reasons you stated.\n\nWe could bikeshed this and point out that descending would make just as much sense and would work just as well, especially if we want to waste precious electrons on debating this.\n\n>\n> > 1, `type` - one byte or two?\n>\n> I'd lean towards one, if a message has 256 optional fields, it might be time to\n> consider a new message type altogether.\n\nThis rationale seems sensible.\n\n>\n> > 3.  `type` - does \"it's OK to be odd\" apply? i.e. if an even `type` that is\n> >     not known is found, crash and burn. But intent of this system is for future\n> >     expansion for optional fields, so...?\n> >\n>\n> Perhaps this depends on context:\n>\n> -   for gossip messages, I think the primary concern is not breaking signature\n>     validation, and that these would need to remain optional for backwards\n>     compatibility.\n>\n> -   for link-level messages, we have a little more control. I imagined the fields\n>     would be gated by feature bit negotiation, and deviating from\n>     unsupported/required would result in being disconnected.\n\nThen I suppose gossip messages could always just use odd type/key, there would still be 128 of those with a single byte, and at least we would have some sort of consistency, which could help if our software factors out some consistency checks for all t-l-v.\n\n>\n>\n> > 5.  `len` - one byte or two? I believe we tend to use two bytes for various\n> >     lengths.\n> >\n>\n> Maybe varint? One byte is not enough for all lengths, but two seems excessive\n> for uint8 or even uint32.\n\nGiven that messages are currently only up to 65536 bytes total, is that not a bit much?\n\n>\n> > 6.  BOLT - I propose making a separate BOLT for `type,len,value`, which other\n> >     messages and so on simply refer to.\n> >\n>\n> Indeed, are you thinking we'd use this to add new fields proposed in 1.1?\n\nYes.\nIt would also be good to have a single place to describe the new scheme.\nI also imagine that we would do the sensible thing and create a new type/module/class/whatever for t-l-v data structures (a mapping from u16 to binary blobs).\nHaving a separate BOLT document would help us spec and verify this in a reasonably separate manner.\n\n>\n> In addition to the above, do we also want to flesh out what sub-TLV structures\n> would look like? Or perhaps that isn't necessary, if we can continue adding more\n> root-level keys.\n\nNo, I imagine at the t-l-v level we see only binary blobs for the value, and separate parts of our software would understand what the actual meanings of those blobs are.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-15T09:45:13",
                "message_text_only": "Good morning Conner et al,\n\n> > > 5.  `len` - one byte or two? I believe we tend to use two bytes for various\n> > >     lengths.\n> > >\n> >\n> > Maybe varint? One byte is not enough for all lengths, but two seems excessive\n> > for uint8 or even uint32.\n>\n> Given that messages are currently only up to 65536 bytes total, is that not a bit much?\n\nSorry, I misunderstood.\n\nThis is varint, correct? http://learnmeabitcoin.com/glossary/varint\n\nIf so, I think this is good idea.\nIt seems we do not have varint currently in Lightning (at least the parts I am familiar with).\nI suppose the t-l-v being in a different BOLT would let us make some section or part for describing `varint`.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Conner Fromknecht",
                "date": "2018-11-16T00:12:45",
                "message_text_only": "Hi ZmnSCPxj,\n\nPrecisely, something like that is what I had in mind.\n\nSince the max message size is 65KB, one option could be to only allow\nthe varint to\nbe max 2 bytes where:\n - if the 8th bit is not set, the lowest 7 bits of the first bytes\ntranslate to 0 - 127\n - if the 8th bit is set, this implies that the second byte is also\ntreated as part of the\n   length, and the total value is 0x7f & first byte + second byte << 7\n\nThis would be fairly straightforward to implement, at the cost of\nlimiting a particular\nfield to 2^15 bytes. I wonder, is this too restrictive?\n\nAt the same time, we could offer a varint that could extend up to the\nthree bytes.\nThe third byte would only come in to play if the length of the field\nis greater than\n2^14 - 1. The argument could be made that for values of this size, one\nextra byte\nis irrelevant compared to the size of these larger fields.\n\nCheers,\nConner\n\nOn Thu, Nov 15, 2018 at 1:45 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n> Good morning Conner et al,\n>\n> > > > 5.  `len` - one byte or two? I believe we tend to use two bytes for various\n> > > >     lengths.\n> > > >\n> > >\n> > > Maybe varint? One byte is not enough for all lengths, but two seems excessive\n> > > for uint8 or even uint32.\n> >\n> > Given that messages are currently only up to 65536 bytes total, is that not a bit much?\n>\n> Sorry, I misunderstood.\n>\n> This is varint, correct? http://learnmeabitcoin.com/glossary/varint\n>\n> If so, I think this is good idea.\n> It seems we do not have varint currently in Lightning (at least the parts I am familiar with).\n> I suppose the t-l-v being in a different BOLT would let us make some section or part for describing `varint`.\n>\n> Regards,\n> ZmnSCPxj"
            },
            {
                "author": "Christian Decker",
                "date": "2018-11-15T20:12:53",
                "message_text_only": "Conner Fromknecht <conner at lightning.engineering> writes:\n>> For a sequence of `type,len,value`, the `type`s must be in ascending order\n>> -- not explicitly accepted or rejected.  It would be easier to check\n>> uniqueness > (the previous rule we accepted) here for a naive parser (keep\n>> track of some \"minimum allowed type\" that initializes at zero, check current\n>> type >= this, update to current type + 1) if `type`s are in ascending order.\n>\n> Yep ascending makes sense to me, for the reasons you stated.\n\nDefinitely a good idea, especially because it results in a canonical\nserialization format, which is important to ensure signatures over\nmessages can be verified even when reserializing parsed messages."
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-16T00:25:34",
                "message_text_only": "Conner Fromknecht <conner at lightning.engineering> writes:\n> Hi ZmnSCPxj,\n>\n> Thanks for writing this up! I had started an email, but you beat me to it :)\n>\n>> 1.  For a sequence of `type,len,value`, each `type` must be unique. --\n>> accepted.\n>\n> To add to this, it seemed that there was some agreement that repeated fields\n> should be serialized under a single root key, since a receiver can't know if a\n> field is allowed to have duplicates if they don't understand the field.\n\nIf a receiver doesn't understand it, it doesn't have to enforce any\nrules on it *at all*.  So it depends on individual cases.\n\n>> For a sequence of `type,len,value`, the `type`s must be in ascending order\n>> -- not explicitly accepted or rejected.  It would be easier to check\n>> uniqueness > (the previous rule we accepted) here for a naive parser (keep\n>> track of some \"minimum allowed type\" that initializes at zero, check current\n>> type >= this, update to current type + 1) if `type`s are in ascending order.\n>\n> Yep ascending makes sense to me, for the reasons you stated.\n\nAgain, writer MUST, with no constraint on reader.\n\n>> 1, `type` - one byte or two?\n>\n> I'd lean towards one, if a message has 256 optional fields, it might be time to\n> consider a new message type altogether.\n\nExactly.\n\n>> 3. `type` - does \"it's OK to be odd\" apply?  i.e. if an even `type` that is\n>> not known is found, crash and burn.  But intent of this system is for future\n>> expansion for optional fields, so...?\n>\n> Perhaps this depends on context:\n>  - for gossip messages, I think the primary concern is not breaking signature\n>      validation, and that these would need to remain optional for backwards\n>      compatibility.\n\nYes, \"not OK\" is message dependent.  It doesn't break parsing (if you\nwant that, use a new message type), but it does break *usage*; \"you\ncan't use this information\".\n\nTLV makes sense when there are many many options, at cost of a couple of\nbytes per option.  We agreed to consider it for new additions, but\nsometimes a simple option bitmap will be a win.\n\n>  - for link-level messages, we have a little more control. I imagined the fields\n>    would be gated by feature bit negotiation, and deviating from\n>    unsupported/required would result in being disconnected.\n\nIt's nice if you can simplify your code by always sending it, even if\nthe remote doesn't understand it.\n\n>> 5. `len` - one byte or two? I believe we tend to use two bytes for various\n>> lengths.\n>\n> Maybe varint? One byte is not enough for all lengths, but two seems excessive\n> for uint8 or even uint32.\n\nYes, it's a nice compromise IMHO.\n\n>> 6.  BOLT - I propose making a separate BOLT for `type,len,value`, which other\n>> messages and so on simply refer to.\n>\n> Indeed, are you thinking we'd use this to add new fields proposed in 1.1?\n\nWell, it's a very individual message thing.  We would specify it in\ngeneral, then each place where it's used (eg. gossip) would have their\nown types.\n\n> In addition to the above, do we also want to flesh out what sub-TLV structures\n> would look like? Or perhaps that isn't necessary, if we can continue adding more\n> root-level keys.\n\nI think that the general TLV definition just belongs in BOLT #1, since\nit's so short.\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "type,len,value standard",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Christian Decker",
                "Conner Fromknecht",
                "ZmnSCPxj"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 15081
        }
    },
    {
        "title": "[Lightning-dev] Splicing Proposal: Now with RBF",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-11-16T04:16:20",
                "message_text_only": "Hi all,\n\nI tried to simplify RBF as much as possible; it adds a *lot* of\ncomplexity :( In particular, below we have one side pay the fees (and\nthus responsible for RBF), in violation of the summit agreement,\nand simplified the fee amount as much as reasonable.\n\nRBF it implicitly requires multiple (exclusive) splices at once.  This\nwill all require a great deal of testing...\n\nChanges since initial proposal:\n\n1. We add subtypes so `splice_init`/`splice_accept` etc are single\n   messages.  These basically allow us to describe variable numbers of\n   variable-length fields.\n2. We include both script and wscript in inputs, for p2sh-wrapping.\n3. Initiator pays fees.\n4. Other side gets to add the same number of inputs+outputs if they\n   want, minimum 2 (enough for one input, one change output).\n5. If we both initiate a splice at once, *fundee*'s tiebreaker (well,\n   funder pays for everything else!).\n6. Both sides give a max_extra_witness_len for inputs, to calc fee.\n7. Every still-negotiable parameter is renegotiated.\n8. We add RBF, at intiator's discretion (they're paying for it!)\n9. The language \"MUST fail the channel\" has been made into \"MUST error\"\n   in antipation of \"soft\" errors.\n\n### Initiating a splice: `splice_init`\n\n1. type: 40 (`splice_init`) (`option_splice`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`4`:`feerate_per_kw`]\n   * [`2`:`num_inputs`]\n   * [`num_inputs*splice_input`]\n   * [`2`:`num_outputs`]\n   * [`num_outputs`*splice_output`]\n   * [`8`:`max_htlc_value_in_flight_msat`]\n   * [`8`:`channel_reserve_satoshis`]\n   * [`8`:`htlc_minimum_msat`]\n   * [`4`:`minimum_depth`]\n   * [`2`:`to_self_delay`]\n\n1. subtype: `splice_input`\n2. data:\n   * [`8`:`satoshis`]\n   * [`32`:`prevtxid`]\n   * [`4`:`prevtxoutnum`]\n   * [`2`:`scriptlen`]\n   * [`scriptlen`:`script`]\n   * [`2`:`max_extra_witness_len`]\n   * [`2`:`wscriptlen`]\n   * [`wscriptlen`:`wscript`]\n\n1. subtype: `splice_output`\n2. data:\n   * [`8`:`satoshis`]\n   * [`2`:`scriptlen`]\n   * [`scriptlen`:`script`]\n\nThe sender of `splice_init`:\n  - if a splice is already in progress\n    - MUST NOT send\n  - MUST ensure each `splice_input` refers to an existing UTXO.\n  - MUST ensure each `splice_output` is a standard script.\n  - SHOULD ensure that `feerate_per_kw` is sufficient for the splice\n    transaction to confirm.\n  - MUST set `feerate_per_kw` to 253 or more.\n  - MUST ensure it will have sufficient funds post-splice above its\n    reserve to pay for the splice transaction at the given `feerate_per_kw`\n    and the amount it contributes to the commitment_transaction fee\n  - MUST NOT have total `splice_output` `satoshis` greater than its current\n  balance minus reserve plus the total `splice_input` `satoshis`.\n  - MUST set `max_htlc_value_in_flight_msat`,\n  `channel_reserve_satoshis`, `htlc_minimum_msat`, `minimum_depth`,\n  `to_self_delay` as specified in `accept_channel`.\n\nNOTES:\n\n1. Are we *sure* we don't want to make channel_reserve_satoshis 1% of\n   capacity?  That would remove a parameter here.\n2. We explicitly allow a null splice to reset parameters or throw away history.\n\nThe receiver of `splice_init`:\n  - if it has also sent `splice_init`:\n    - if the receiver was the original sender of `open_channel`:\n      - MUST discard its own `splice_init`\n    - otherwise:\n      - MUST discard this `splice_init`.\n  - if a splice is in progress:\n    - MUST error.\n  - if `feerate_per_kw` is less than 253:\n    - SHOULD error.\n  - if the total post-splice balance of the sender would be\n    insufficient to meet its reserve plus the amount\n    it contributes to the commitment_transaction fee:\n    - MUST error.\n  - if both nodes advertised the `option_upfront_shutdown_script`\n  feature, and the receiving node received a non-zero-length\n  `shutdown_scriptpubkey` in `open_channel` or `accept_channel`, and\n  any splice_output that `shutdown_scriptpubkey` is not equal to `script`:\n     - MUST fail the connection.\n  - MUST respond to `max_htlc_value_in_flight_msat`,\n  `channel_reserve_satoshis`, `htlc_minimum_msat`, `minimum_depth`,\n  `to_self_delay` as specified in `accept_channel`.\n  - SHOULD reply with `splice_accept`\n\n\n### Accepting a splice: `splice_accept`\n\n1. type: 41 (`splice_accept`) (`option_splice`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`2`:`num_inputs`]\n   * [`num_inputs*splice_input`]\n   * [`2`:`num_outputs`]\n   * [`num_outputs`*splice_output`]\n   * [`8`:`max_htlc_value_in_flight_msat`]\n   * [`8`:`channel_reserve_satoshis`]\n   * [`8`:`htlc_minimum_msat`]\n   * [`4`:`minimum_depth`]\n   * [`2`:`to_self_delay`]\n\nThe sender of `splice_accept`:\n  - consider the `splice_limit` the total number of `splice_input` and\n  `splice_output` from `splice_init`, with minimum 2.\n  - MUST NOT send a number of `splice_input` and/or `splice_output`\n  which exceeds `splice_limit`.\n  - MUST ensure each `splice_input` refers to an existing UTXO.\n  - MUST ensure each `splice_output` is a standard script.\n  - MUST NOT have total `splice_output` `satoshis` greater than its current\n  balance minus reserve plus the total `splice_input` `satoshis`.\n  - MAY limit their `splice_input` and `splice_output`s to avoid\n  sending the sender of `splice_init` below reserve.\n\nThe receiver of `splice_accept`:\n  - If the number of `splice_input` and/or `splice_output` exceeds `splice_limit`:\n     - MUST error.\n  - if the total `splice_output` `satoshis` is greater than the\n  sender's current balance minus reserve plus the total `splice_input`\n  `satoshis`:\n    - MUST error.\n  - if both nodes advertised the `option_upfront_shutdown_script`\n  feature, and the receiving node received a non-zero-length\n  `shutdown_scriptpubkey` in `open_channel` or `accept_channel`, and\n  any splice_output that `shutdown_scriptpubkey` is not equal to `script`:\n     - MUST fail the connection.\n  - SHOULD send `splice_commitment_signature`\n\nBoth sides:\n  - MUST construct the resulting splice transaction as specified in <FIXME>\n\nNOTES:\n\n1. The receiver doesn't check transaction validity.  Worst-case, it'll\n   never confirm, and never splice in.\n2. We don't set size limits on inputs & outputs, and we probably should?\n3. The initiator can be forced below their reserve by the recipient\n   adding their own splice in/outs.  But that's OK.\n\n1. type: 42 (`splice_commitment_signature`) (`option_splice`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`64`:`commitment_signature`]\n   * [`2`:`num_htlcs`]\n   * [`num_htlcs*64`:`htlc_signature`]\n\nThe sender:\n  - MUST set `commitment_signature` and `htlc_signature`s as done for\n    `commitment_signed`, but spending the funding output of the splice\n    transaction.\n\nThe recipient:\n  - if `signature` is not valid for its local splice commitment transaction:\n    - MUST fail the channel.\n  - if `num_htlcs` is not equal to the number of HTLC outputs in the local\n    splice commitment transaction:\n    - MUST fail the channel.\n  - if any `htlc_signature` is not valid for the corresponding HTLC transaction:\n    - MUST fail the channel.\n  - if the recipient was not the sender of `splice_init`:\n    - SHOULD send its own `splice_commitment_signature` in return.\n  - otherwise:\n    - SHOULD send `splice_confirm`.\n\n### Confirming a splice: `splice_confirm`\n\n1. type: 43 (`splice_confirm`) (`option_splice`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`64`:`signature`]\n   * [`2`:`num_witnesses`]\n   * [`num_witnesses*witness_stack`]\n\nEach `witness` itself is serialized witness input stack:\n1. subtype: `witness_stack`\n2. data:\n   * [`2`:`num_input_stack`]\n   * [`num_input_stack`*`stack_element`]\n\n1. subtype: `stack_element`\n2. data:\n   * [`2`:`len`]\n   * [`len`:`element`]\n\nThe sender:\n  - MUST set `signature` to the signature for the splice transaction.\n  - MUST set `witness` to the marshalled witness data for each of its\n    inputs, in splice transaction order.\n  - MUST remember the details of this splice transaction.\n  - MUST NOT send a `witness_stack` whose length exceeds the\n    corresponding `max_extra_witness_len`.\n\nThe recipient:\n  - SHOULD check that \n  - SHOULD apply `signature` and `witness` to the splice transaction and\n    broadcast the result.\n  - If a `witness_stack` length exceeds the corresponding `max_extra_witness_len`:\n    - MAY error.\n  - if the recipient was the sender of `splice_init`:\n    - SHOULD reply with its own `splice_confirm`.\n\n\n### Updating a splice: `splice_rbf`\n\n1. type: 45 (`splice_rbf`) (`option_splice`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`4`:`fee_step`]\n\nEach `fee_step` adds 1/4 (rounded down) to the initial splice\ntransaction fee. eg. if the initial fee was 1035 satoshi, `fee_step` 1\nis  1035 + 1035 / 4 = 1293, `fee_step` 2 is 1293 + 1293 / 4 = 1616.\n\nThe sender:\n  - SHOULD send `splice_rbf` if the current splice transaction will not\n    confirm in a timely manner.\n  - MUST set `fee_step` greater than zero and greater than any prior `fee_step`.\n  - MUST be the sender of `splice_init`.\n  - MUST have already sent and received `splice_confirm` for the\n    previous splice transaction.\n  - MUST ensure it will have sufficient funds post-splice above its\n    reserve to pay for the splice transaction at the new feerate.\n  - MUST construct the resulting splice transaction as specified in <FIXME>\n  - SHOULD send `splice_commitment_signature` on the new splice\n    transation, and continue negotiation as before.    \n\nThe recipient:\n  - if the sender of `splice_rbf` was not the sender of `splice_init`:\n    - MUST error.\n  - if the new fee exceeds the sender's current balance minus reserve\n    after it is applied to the splice transaction:\n    - MUST error.\n  - MUST construct the resulting splice transaction as specified in <FIXME>\n  - MUST handle `splice_commitment_signature` on the new splice\n    transation, and continue negotiation as before.    \n  \nNOTES:\n\n1. 1/4 is a reasonable minimal RBF, but as each one requires more\n   tracking by the recipient, serves to limit the number you can create.\n\n### Completing a splice: `splice_rbf`\n\n1. type: 45 (`splice_closed`) (`option_splice`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`32`:`splice_txid`]\n\n\nThe sender:\n  - MUST NOT send until the splice transaction has reached its own\n  `minimum_depth`.\n  - MUST set `splice_txid` to the txid of the splice transaction which confirmed.\n\nEither node:\n  - if it has received and sent `splice_rbf`:\n    - MAY discard HTLCs and revocations requirements for states in\n    channel prior to the splice.\n  - MUST follow the requirements for `announcement_signatures` as if\n    this were a new channel.\n\nMessage Changes During Splicing\n-------------------------------\nOnce you've sent `splice_confirm` each commitment transaction is needs\nto be duplicated for every splice transaction (thanks to RBF, there can\nbe multiple at once).  These are in rbf-received order (increasing fee\norder, if initiator is spec compliant):\n\n1. type: 39 (`closing_signed`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`8`:`fee_satoshis`]\n   * [`64`:`signature`]\n   * [`2`:`num_splice`] (`option_splice`)\n   * [`num_splice*64`:`splice_signature`] (`option_splice`)\n\n1. subtype: `splice_signatures`\n2. data:\n   * [`64`:`signature`]\n   * [`2`:`num_htlcs`]\n   * [`num_htlcs*64`:`htlc_signature`]\n\n1. type: 132 (`commitment_signed`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`64`:`signature`]\n   * [`2`:`num_htlcs`]\n   * [`num_htlcs*64`:`htlc_signature`]\n   * [`2`:`num_splice`] (`option_splice`)\n   * [`num_splice*splice_signatures`] (`option_splice`)\n\nIf a reconnection occurs between between sending and receiving\n`splice_confirm` or `splice_closed` the peer's status is uncertain.  This we\nhave a new field in `channel_reestablish` to flag that we consider ourselves\nto be splicing:\n\n1. type: 136 (`channel_reestablish`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`8`:`next_local_commitment_number`]\n   * [`8`:`next_remote_revocation_number`]\n   * [`32`:`your_last_per_commitment_secret`] (`option_data_loss_protect`)\n   * [`33`:`my_current_per_commitment_point`] (`option_data_loss_protect`)\n   * [`2`:`num_splice`] (`option_splice`)\n\nThe sender:\n- MUST set `num_splice` to the number of `splice_confirm` it has received for\n  the current splice operation, or 0 if no current splice operation.\n\nThe recipient:\n- if `num_splice` is less than the number of `splice_confirm` it has sent for the current splice operation:\n  - MUST re-transmit the last splice_confirm.\n- if `num_splice` is more than the number of `splice_confirm` it has sent for the current splice operation:\n  - MUST re-transmit the last splice_closed.\n\nNOTES:\n\n1. I suggest that the option_data_loss_protect fields MUST BE set here if\n   option_splice (there's no reason not to AFAICT).  Or do we want to try TLV\n   here?"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-16T08:37:07",
                "message_text_only": "Good morning Rusty,\n\n> I tried to simplify RBF as much as possible; it adds a lot of\n> complexity :( In particular, below we have one side pay the fees (and\n> thus responsible for RBF), in violation of the summit agreement,\n> and simplified the fee amount as much as reasonable.\n\nThis (initiator-pays) was proposed on the summit, by my memory.\nAt the time, I was going to propose also that only the splice-initiator would then be allowed to add splice-ins and/or splice-outs, since the splice-initiator \"owns\" the splice (as it pays all the fees).\nAnd then, I would also propose that once splice-initiator indicates satisfaction with splice ins and outs, the two switch sides (but the fees proposed by the first splice-initiator remain deducted from the splice-initiator) and the other party has an opportunity to add its own splice-ins/outs, for which it would pay for.\n\nHowever, RBF adds a whole new dimension...\nIt's certainly much easier to reason about a single payer of the fees.\n\n>\n> RBF it implicitly requires multiple (exclusive) splices at once. This\n> will all require a great deal of testing...\n\nWould it be useful to define a dual-funding RBF protocol first, so we have practice for splice RBF?\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "lisa neigut",
                "date": "2018-11-21T20:43:15",
                "message_text_only": "Hello Rusty. Exciting stuff!  A few observations:\n\nOn Fri, Nov 16, 2018 at 12:18 AM Rusty Russell <rusty at rustcorp.com.au>\nwrote:\n\n> ### Confirming a splice: `splice_confirm`\n>\n> 1. type: 43 (`splice_confirm`) (`option_splice`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`64`:`signature`]\n>    * [`2`:`num_witnesses`]\n>    * [`num_witnesses*witness_stack`]\n>\n>\nI don't believe that you need the `signature` field here; if I'm\nunderstanding correctly the sigs for the inputs should be the witness stack\nthat you're sending.\n\n\n> The sender:\n>\n...\n\n>   - MUST ensure it will have sufficient funds post-splice above its\n>     reserve to pay for the splice transaction at the new feerate.\n>\n\nIf fees outstrip the value of the updated splice transaction, what then?\nIt's not really possible to abandon a splice, practically you'd end up\nclosing the channel. This feels like an obvious observation, but worth\nnoting that splicing is 'risky' in that regard i.e. channel closure due to\nextenuating circumstances (fee spike).\n\n\n> Message Changes During Splicing\n> -------------------------------\n> Once you've sent `splice_confirm` each commitment transaction is needs\n> to be duplicated for every splice transaction (thanks to RBF, there can\n> be multiple at once).  These are in rbf-received order (increasing fee\n> order, if initiator is spec compliant):\n>\n> Are HTLC's to be duplicated as well? CPFP seems like a neater construction\nthan RBF in this case, as it avoids fee rate negotiation and ballooning\nHTLC/commitment txn management. It also makes the single-payer for fees\n(initiator) less burdensome which is nice for skewed benefit updates. We\ncan reuse the scheme we came up with for commitment txns (either party can\nspend, I believe).\n\nWas there an argument against using CPFP on funding txns that I'm not\nremembering?\n\n\n> NOTES:\n>\n> 1. I suggest that the option_data_loss_protect fields MUST BE set here if\n>    option_splice (there's no reason not to AFAICT).  Or do we want to try\n> TLV\n>    here?\n>\n\n+1 for moving to TLV, in the spirit of moving towards the new spec\nguidelines.\n\n\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181121/261a0f03/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-22T01:29:29",
                "message_text_only": "lisa neigut <niftynei at gmail.com> writes:\n> Hello Rusty. Exciting stuff!  A few observations:\n>\n> On Fri, Nov 16, 2018 at 12:18 AM Rusty Russell <rusty at rustcorp.com.au>\n> wrote:\n>\n>> ### Confirming a splice: `splice_confirm`\n>>\n>> 1. type: 43 (`splice_confirm`) (`option_splice`)\n>> 2. data:\n>>    * [`32`:`channel_id`]\n>>    * [`64`:`signature`]\n>>    * [`2`:`num_witnesses`]\n>>    * [`num_witnesses*witness_stack`]\n>>\n>>\n> I don't believe that you need the `signature` field here; if I'm\n> understanding correctly the sigs for the inputs should be the witness stack\n> that you're sending.\n\nYou're exactly right, that should be struck.  Copy & paste from\nfunding_signed I think.\n\n>> The sender:\n>>\n> ...\n>\n>>   - MUST ensure it will have sufficient funds post-splice above its\n>>     reserve to pay for the splice transaction at the new feerate.\n>>\n>\n> If fees outstrip the value of the updated splice transaction, what then?\n> It's not really possible to abandon a splice, practically you'd end up\n> closing the channel. This feels like an obvious observation, but worth\n> noting that splicing is 'risky' in that regard i.e. channel closure due to\n> extenuating circumstances (fee spike).\n\nOur simplfication of only having one splice in progress at a time, that\nif it goes wrong for any reason, you can't splice any more.\n\nBut yes, closing the channel is the \"fix\".  Not pretty, but simple.\n\n>> Message Changes During Splicing\n>> -------------------------------\n>> Once you've sent `splice_confirm` each commitment transaction is needs\n>> to be duplicated for every splice transaction (thanks to RBF, there can\n>> be multiple at once).  These are in rbf-received order (increasing fee\n>> order, if initiator is spec compliant):\n>>\n> Are HTLC's to be duplicated as well? CPFP seems like a neater construction\n> than RBF in this case, as it avoids fee rate negotiation and ballooning\n> HTLC/commitment txn management. It also makes the single-payer for fees\n> (initiator) less burdensome which is nice for skewed benefit updates. We\n> can reuse the scheme we came up with for commitment txns (either party can\n> spend, I believe).\n>\n> Was there an argument against using CPFP on funding txns that I'm not\n> remembering?\n\nOn-chain space.  It's better for the chain to use RBF, but I'm being\nswayed by your arguments, given the complexity of the RBF approach\nabove, and the (hopeful) rarity of this case.\n\n>> NOTES:\n>>\n>> 1. I suggest that the option_data_loss_protect fields MUST BE set here if\n>>    option_splice (there's no reason not to AFAICT).  Or do we want to try\n>> TLV\n>>    here?\n>>\n>\n> +1 for moving to TLV, in the spirit of moving towards the new spec\n> guidelines.\n\nOK, I'll try that in rev 2...\n\nThanks,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Splicing Proposal: Now with RBF",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "lisa neigut",
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 19061
        }
    },
    {
        "title": "[Lightning-dev] Proposal to include some form of best effort routing, fragmentation and local AMP",
        "thread_messages": [
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2018-11-16T10:27:41",
                "message_text_only": "Good morning list,\n\nin Adelaide I had a long conversation with another participant who\ncomplained that slow payments and failing payments are still a major UX\nissue for people that try to use the lightning network. While I believe\nthis is a very valid point and we might want to think heavily about\naltering some design decisions after BOLT1.1 in order to mitigate this I\nwant to make another proposal which could still be an improvement to some\nof the problems that we currently have with path finding. This proposal is\nbasically a standalone thread to my suggestions sketched in Connors PR at\nhttps://github.com/lightningnetwork/lightning-rfc/pull/503 for non strict\nforwarding.\n\nI propose to implement a second routing algorithm that works on the\nprinciple of best effort routing / forwarding with the help of local\npayment fragmentation or maybe better called local AMP. I understand this\nsounds drastic to start with, in particular since it seems that the\ndestination has to be known but I believe there  are ways to still keep up\nwith privacy.\n\nThe core idea is to allow intermediate nodes to fragment an HTLC to\nsomething similar as Base AMP to reach the next hop that was specified in\nthe onion. This would still allow to forward a payment and allow the next\nhop to to continue with the regular onion package.\n\nThe idea is if Alice is supposed to forward an HTLC to Bob with a value\nsmaller than their channel capacity but alice has not enough funds on her\nside alice could try to fragment the payment and try to find several paths\n(or maybe just one path without splitting) to Bob.\n\nOne particular strategy to find such a path would be to share friend of a\nfriend (FOAF) information.\nAlice could look at the nodes that both she and Bob are connected to and\nuse them as bridge nodes for the payment. In particular she could even ask\nBob how much inbound capacity he has from those nodes. In case Bob would\nshare this information about the channel balance of mutual friends it could\ndeterministically be decided if the original HTLC could be forwarded from\nAlice to Bob in a fragmented way.\n\nWith the autopilot we are trying to create many triangles in the network so\nthat there is always the chance for friend of a friend nodes which could be\nused with this approach.\n\nOn the downside the original payer would have to allow a package to be\nlocally fragmented by including more fees at each hop and also by\nincreasing the CLTV deltas in each hop (so that an additional hop can be\nincluded and financed).\n\nWith the suggestion I made the payer can still select the basic route and\nthe full route would still be private. The sender however could chose paths\non which a lot of common friends exist for each pair of nodes on the path\n(thereby increasing the probability that the local fragmentation of the\npayment has a higher likelihood to be successful)\n\nOf course another solution is if we think that local AMP is too complex and\nexpensive we could still have the two nodes that fail to forward the htlcs\nwork collaboratively to find a path between them and return this\ninformation about such a (multi) path as a routing suggestion in the error\nmessage so that the adapted onion package could be tried and sent by the\npayer.\n\nbest regards Rene\n\n-- \nhttps://www.rene-pickhardt.de\n\nSkype: rene.pickhardt\n\nmobile: +49 (0)176 5762 3618\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181116/2f799f7e/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-17T03:21:40",
                "message_text_only": "Good morning Rene,\n\nPacket switching could theoretically be done if switching ephkeys were possible, which would be needed for rendezvous nodes anyway.\nAn intermediate node is handed an opaque onion and the node to give that onion to, which, when you squint, is what the payer is given in the rendezvous node case.\nChristian said it's not possible because math, but I cannot confirm it as I know too little of the relevant math.\n\nIf not possible by ephkey switching, then we could switch to a new onion construction.\n\n---\n\nThat said, there are already a few items discussed, which improve payment reliability.\n\n1. Active probing. This lets us update our maps before the user even starts a payment.\n2. Ping before commitment.\n\nThe second has greater improvement in reliability, as I understand it.\nThe main reason for stuck payments is that a hop node forwarded the payment to the next, but the next crashes or disconnects before it could claim the HTLC.\nThe next node can theoretically claim the money up to the timelock by dropping to chain while disconnected from previous node.\nThe previous node thus cannot report an error until it itself drops onchain and triggers the timelock branch, which it can only do if the timelock has passed.\n\nPing before commit reduces the window this can happen, by pinging the next node before we even offer an HTLC.\nThis is because of how TCP/IP works.\nWe can send a message, then learn the connection was closed, we cannot reliably say if the message was received.\nIf we send the commitment, that lets the next node potentially claim the HTLC.\nIf we then find out the connection closed, we do not know certainly if it was received, or if the next node was already down for an hour and we just didn't notice.\n\nIf we send a ping beforehand, though, that lets us figure out if the connection dropped before we send the HTLC.\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Friday, November 16, 2018 6:27 PM, Ren\u00e9 Pickhardt via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning list,\n>\n> in Adelaide I had a long conversation with another participant who complained that slow payments and failing payments are still a major UX issue for people that try to use the lightning network. While I believe this is a very valid point and we might want to think heavily about altering some design decisions after BOLT1.1 in order to mitigate this I want to make another proposal which could still be an improvement to some of the problems that we currently have with path finding. This proposal is basically a standalone thread to my suggestions sketched in Connors PR at https://github.com/lightningnetwork/lightning-rfc/pull/503 for non strict forwarding.\n>\n> I propose to implement a second routing algorithm that works on the principle of best effort routing / forwarding with the help of local payment fragmentation or maybe better called local AMP. I understand this sounds drastic to start with, in particular since it seems that the destination has to be known but I believe there  are ways to still keep up with privacy.\n>\n> The core idea is to allow intermediate nodes to fragment an HTLC to something similar as Base AMP to reach the next hop that was specified in the onion. This would still allow to forward a payment and allow the next hop to to continue with the regular onion package.\n>\n> The idea is if Alice is supposed to forward an HTLC to Bob with a value smaller than their channel capacity but alice has not enough funds on her side alice could try to fragment the payment and try to find several paths (or maybe just one path without splitting) to Bob.\n>\n> One particular strategy to find such a path would be to share friend of a friend (FOAF) information.\n> Alice could look at the nodes that both she and Bob are connected to and use them as bridge nodes for the payment. In particular she could even ask Bob how much inbound capacity he has from those nodes. In case Bob would share this information about the channel balance of mutual friends it could deterministically be decided if the original HTLC could be forwarded from Alice to Bob in a fragmented way.\n>\n> With the autopilot we are trying to create many triangles in the network so that there is always the chance for friend of a friend nodes which could be used with this approach.\n>\n> On the downside the original payer would have to allow a package to be locally fragmented by including more fees at each hop and also by increasing the CLTV deltas in each hop (so that an additional hop can be included and financed).\n>\n> With the suggestion I made the payer can still select the basic route and the full route would still be private. The sender however could chose paths on which a lot of common friends exist for each pair of nodes on the path (thereby increasing the probability that the local fragmentation of the payment has a higher likelihood to be successful)\n>\n> Of course another solution is if we think that local AMP is too complex and expensive we could still have the two nodes that fail to forward the htlcs work collaboratively to find a path between them and return this information about such a (multi) path as a routing suggestion in the error message so that the adapted onion package could be tried and sent by the payer.\n>\n> best regards Rene\n>\n> --\n> https://www.rene-pickhardt.de\n>\n> Skype: rene.pickhardt\n>\n> mobile: +49 (0)176 5762 3618\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181117/c9b8958b/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Proposal to include some form of best effort routing, fragmentation and local AMP",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Ren\u00e9 Pickhardt",
                "ZmnSCPxj"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 9188
        }
    },
    {
        "title": "[Lightning-dev] RBF and dual-fund interactions",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-17T13:54:12",
                "message_text_only": "Good morning list,\n\nAfter some thinking, I suggest that RBF and dual-fund have some complex interactions.\n\nLet us consider some node who wishes to provide liquidity in exchange for a fee.\nFor simplicity, let us suppose this liquidity provider owns a single UTXO containing its entire funding.\n\nA customer appears and purchases some liquidity.\nThe liquidity being purchased is less than the total money of the liquidity provider.\nThus the funding tx has a change output that goes to the liquidity provider.\n\nSuppose, while the funding tx is unconfirmed, that another customer appears and purchases liquidity.\nThe liquidity provider cannot provide liquidity from a confirmed output, but can only get liquidity from the change output from the first customer funding tx.\n\nNow suppose the first customer gets tired of waiting for a confirmation on its funding tx, and RBF its funding tx.\nThe second customer funding tx is now removed from mempools, since its root was replaced.\nNow the liquidity provider also has to ask the second customer to sign a new tx.\n\nThis is potentially an attack vector (although I suppose we could consider simply ignoring edge-case attack vectors).\nSince the second customer pays the fees and designates its own inputs, it can gather all its dust, then give a very low fee, creating a large tx that has too low feerate to be mined, but too large total fee to get over the RBF rule 1 (The replacement transaction pays an absolute higher fee than the original transactions.).\nThe first customer can then find it very difficult to get its own channel confirmed unless it pays an uneconomical onchain fee.\n\nTo my mind, channel initiation RBF is more important than dual-fund.\nOff-to-onchain services (which can already be built on top of existing LN, because proof-of-payment) can provide incoming liquidity by reversing the polarity of the satoshi flow, and in addition, can be used to put funds in cold storage or pay people onchain.\n\n---\n\nAlternatively, instead of providing change outputs for liquidity providers, instead require that liquidity providers cannot have a change output on the funding tx.\nThus the liquidity provider will have to create a transaction from its single UTXO to two UTXOs, only one of which is actually added to the channel, and the other being the liquidity provider change output.\nThe liquidity provider can provide this with minimum relay fee and deduct it from the channel liquidity it is selling, so that the fee for this tx is CPFP by the first customer and so initiator-pays remains.\nThis allows a second output that is not dependent on the funding tx, and which allows the two customers to RBF independently of each other.\nIt has the unfortunate drawback of increasing blockchain usage.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181117/29b03f93/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-20T02:36:24",
                "message_text_only": "ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> writes:\n> This is potentially an attack vector (although I suppose we could consider simply ignoring edge-case attack vectors).\n> Since the second customer pays the fees and designates its own inputs, it can gather all its dust, then give a very low fee, creating a large tx that has too low feerate to be mined, but too large total fee to get over the RBF rule 1 (The replacement transaction pays an absolute higher fee than the original transactions.).\n> The first customer can then find it very difficult to get its own channel confirmed unless it pays an uneconomical onchain fee.\n\nYes, you shouldn't agree to a funding tx which you have inputs which\nalso has tiny fees, as it might get stuck.  We'll make sure to note that\nin the proposal.\n\n> Alternatively, instead of providing change outputs for liquidity\n> providers, instead require that liquidity providers cannot have a\n> change output on the funding tx.\n\nDon't require it, though that may be how they work in practice.\n\nChers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "RBF and dual-fund interactions",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "ZmnSCPxj"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 4015
        }
    },
    {
        "title": "[Lightning-dev] A\u00e7ai: a backup protocol for Lightning Network wallets",
        "thread_messages": [
            {
                "author": "Margherita Favaretto",
                "date": "2018-11-18T03:13:43",
                "message_text_only": "Hello, lightning dev community,\n\nI\u2019m writing to you to share an update of my Master Thesis project (previous\nobject e-mail: Recovering protocol for Lightning network 11/12/2018),\nregarding a recovery mechanism of false positive in the Lightning network.\n\n\nFirst of all, I'd like to thank Conner Fromknecht and Alex Bosworth for the\ndiscussion during this week, and ZmnSCPxj for the feedback to my previous\nemail: all your suggestions were very important to proceed with my work.\n\nThanks also to Olaoluwa Osuntokun to notify me of the problem with my\nemail, I'm trying to use another one now. :-)\n\n\nTo recap, the problem I'm focusing on is the recovery of the unspent\nbitcoins stuck inside the Lightning Network after a wallet failure (e.g.\nlost or corrupted transaction data put into the wallet storage).\n\nThe Lightning Network provides higher speeds and confidentiality for\nbitcoin transactions, but the absence of the underlying distributed ledger\nmakes impossible the recovery of unspent transactions through the\ntraditional cryptographic seed and the BIP32 address derivation.\n\nMy solution, named A\u00e7ai Protocol, aims to use the watchtowers not just for\nmonitoring the channels, but also as a backup service in order to solve the\nproblem.\n\nCompared to the solution proposed in the previous e-mail, I've abandoned\nthe idea to use a public key to encrypt data in the watchtower, and I've\ndecided to adopt the concepts of txid, hint and blob, to maintain the\nprivacy and the security of nodes.\n\nFor simplicity, I've created a project on Github:\nhttps://github.com/margheritafav/LightningNetworkProject, where you could\nfind all the details about the A\u00e7ai Protocol, and also you are welcome to\nadd your comments and feedback.\n<https://github.com/margheritafav/LightningNetworkProject>\nmargheritafav/LightningNetworkProject\n<https://github.com/margheritafav/LightningNetworkProject>\ngithub.com\nContribute to margheritafav/LightningNetworkProject development by creating\nan account on GitHub.\n\n\nI hope that the explanation of the design is clear, otherwise please do not\nhesitate to ask clarification.\n\nAny thoughts/feedback would be really appreciated, to proceed in the wisest\nway and find a solution that can also cover all the needs of the community.\n\nIf you are interested in this research topic, please do not hesitate to\ncontact me for a possible collaboration at s170065 at student.dtu.dk.\n\nThank you very much in advance,\n\nCheers\nMargherita\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181117/1e2de273/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "A\u00e7ai: a backup protocol for Lightning Network wallets",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Margherita Favaretto"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2636
        }
    },
    {
        "title": "[Lightning-dev] Rendez-vous proposal with ephemeral key switch",
        "thread_messages": [
            {
                "author": "Christian Decker",
                "date": "2018-11-18T13:34:47",
                "message_text_only": "I finally got around to amending my initial (broken) proposal for the\nrendez-vous protocol using the ephemeral key switch at the rendez-vous\npoint. I'd like to try and keep a live document that describes the\nentire proposal in the Wiki to make it easier for people to get an\noverall view of the proposal, instead of having to stitch it together\nfrom the ML posts. You can find the proposal here [1]. It makes heavy\nuse of the description in the onion routing bolt [2].\n\nThe initial proposal was to have the rendez-vous node `RV` swap in an\nephemeral key `ek_rv` instead of generating it from `ss_k` derived from\nECDH(`ek_{k-1}`, node_id), because that allows the recipient `R` to\ngenerate the second half of the route by selecting that `ek_rv`.\n\nThe problem I mentioned in other mails arises from the fact that when\n`RV` decrypts its payload to learn about its routing instructions and\nlearn about `ek_rv`, it was also encrypting the filler bytes appended to\nthe end. The decryption is done via XOR with a ChaCha20 bytestream whose\nkey is generated from `ss_k`, which is unknown to `R` (depends on the\nephemeal key selected by the sender and the intermediate hops). This is\nimportant since `R` needs to know the exact contents of the packet\nincluding the filler to compute valid HMACs.\n\nThe fix is relatively simple, and just adds a virtual hop at `RV`. I'll\ndescribe the actions of `RV` here instead of the packet building since\nthis way is easier to follow:\n\n - `RV` derives `ss_k` from `ek_k` which was given to it by the previous\n   hop, appends the `0x00`-vector to shift in when stripping its per-hop\n   payload (may need more than 65 bytes now since we shift more than one\n   per-hop field now), generates the ChaCha20 stream using `ss_k` and\n   XORs the packet with the stream.\n - `RV` reads its per-hop payload notices that an ephemeral key switch\n   is desired and reads `ek_rv` from the per-hop payload. It overwrites\n   the, now encrypted, filler vector with `0x00`-bytes again (to\n   recreate a well-known state that `R` can use when generating its\n   partial onion).\n - It then derives a new secret key `ss_rv` from `ek_rv` and its node\n   ID. `ss_rv` is then used to generate a new ChaCha20 stream which will\n   encrypt the packet again (obfuscating the filler) and it'll be used\n   to generate a new ephemeral key `ek_{rv+1}` which will be passed on\n   to the next hop.\n\nAt this point the normal operation continues as usual. IMHO the proposal\nis clean and backwards compatible, but I'm open for suggestions. There\nare a number of variants for this protocol, but I chose this one for its\nsymmetry with the existing scheme. I'll list a few alternatives here:\n\n - `ek_{rv+1}` == `ek_rv`: it is not really required to generate a new\n   ephemeral key for the next hop, we could just reuse it. The reason\n   the switch is done in normal Sphinx is to avoid correlating hops, but\n   `ek_rv` is not really seen on the wire in cleartext right now so we\n   could just reuse it. I prefer not to simply because of symmetry.\n - Overwrite the filler with `0x00`-bytes and don't obfuscate it. This\n   is the simple initial proposal, but it leaks the fact that `RV` is a\n   rendez-vous node to the next hop.\n\nPlease let me know if I missed something, I'll try to implement this\nsoon and see if something unexpected jumps at me :-)\n\nCheers,\nChristian\n\n[1] https://github.com/lightningnetwork/lightning-rfc/wiki/Rendez-vous-mechanism-on-top-of-Sphinx\n[2] https://github.com/lightningnetwork/lightning-rfc/blob/master/04-onion-routing.md#shared-secret"
            }
        ],
        "thread_summary": {
            "title": "Rendez-vous proposal with ephemeral key switch",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Decker"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3548
        }
    },
    {
        "title": "[Lightning-dev] Invoice Address Format",
        "thread_messages": [
            {
                "author": "Varunram Ganesh",
                "date": "2018-11-20T17:33:59",
                "message_text_only": "Hello List,\n\nThe reason why we use bech32 for invoice addresses and raw hex encoded pubkeys and has long puzzled me. Let's take a sample testnet invoice\n\n>>> \"lntb20m1pvjluezhp58yjmdan79s6qqdhdzgynm4zwqd5d7xmw5fk98klysy043l2ahrqspp5qqqsyqcyq5rqwzqfqqqsyqcyq5rqwzqfqqqsyqcyq5rqwzqfqypqfpp3x9et2e20v6pu37c5d9vax37wxq72un98kmzzhznpurw9sgl2v0nklu2g4d0keph5t7tj9tcqd8rexnd07ux4uv2cjvcqwaxgj7v4uwn5wmypjd5n69z2xm3xgksg28nwht7f6zspwp3f9t\"\n<<<\n\nof length 271 from the BOLT 11 RFC for consideration. While the bech32 format has its advantages being base 32, easy to read out over phone and stuff like that, I wonder if it is optimised for this specific use case since BIP-173 states\n\n\n>>>\nThe specific code chosen here is the result of:\n1. Starting with an exhaustive list of 159605 BCH codes designed to detect 3 or 4 errors up to length 93, 151, 165, 341, 1023, and 1057.\n2. From those, requiring the detection of 4 errors up to length 71, resulting in 28825 remaining codes.\n<<<\n\n(what's important here is the second part on lengths)\n\nNow, I am no expert on error encoding formats, but I think that bech32 is under optimised for invoices (whose lengths are greater than 71). Related to this, is there a reason why we use hex encoded pubkeys in lightning? Unless I'm missing something, I think bech32 is better to use in this context. Please correct me if I'm wrong.\n\nHave a nice day,\nVarunram\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181120/eb183d24/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-21T00:32:24",
                "message_text_only": "Varunram Ganesh <contact at varunram.com> writes:\n> Now, I am no expert on error encoding formats, but I think that bech32 is under optimised for invoices (whose lengths are greater than 71). Related to this, is there a reason why we use hex encoded pubkeys in lightning? Unless I'm missing something, I think bech32 is better to use in this context. Please correct me if I'm wrong.\n\nNo, you're right.  It was chosen because it's an existing encoding which\nalready exists in the bitcoin ecosystem.  The signature on an invoice\nprovides a far stronger guarantee than the 6-char checksum anyway.\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Invoice Address Format",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Varunram Ganesh",
                "Rusty Russell"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 2185
        }
    },
    {
        "title": "[Lightning-dev] [PATCH] First draft of option_simplfied_commitment",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-11-21T02:17:17",
                "message_text_only": "I'm also starting to implement this, to see what I missed!\n\nOriginal at https://github.com/lightningnetwork/lightning-rfc/pull/513\n\nPasted here for your reading convenience:\n\n- Option is sticky; it set at open time, it stays with channel\n  - I didn't want to have to handle penalty txs on channels which switch\n  - We could, however, upgrade on splice.\n- Feerate is fixed at 253\n  - `feerate_per_kw` is still in open /accept (just ignored): multifund may want it.\n- closing tx negotiates *upwards* not *downwards*\n  - Starting from base fee of commitment tx = 282 satoshi.\n- to_remote output is always CSV delayed.\n- pushme outputs are paid for by funder, but only exist if the matching\n  to_local/remote output exists.\n- After 10 blocks, they become anyone-can-spend (they need to see the\n  to-local/remote witness script though).\n- remotepubkey is not rotated.\n- You must spend your pushme output; you may sweep for others.\n\nSigned-off-by: Rusty Russell <rusty at rustcorp.com.au>\n\ndiff --git a/02-peer-protocol.md b/02-peer-protocol.md\nindex 7cf9ebf..6ec1155 100644\n--- a/02-peer-protocol.md\n+++ b/02-peer-protocol.md\n@@ -133,7 +133,9 @@ node can offer.\n (i.e. 1/4 the more normally-used 'satoshi per 1000 vbytes') that this\n side will pay for commitment and HTLC transactions, as described in\n [BOLT #3](03-transactions.md#fee-calculation) (this can be adjusted\n-later with an `update_fee` message).\n+later with an `update_fee` message).  Note that if\n+`option_simplified_commitment` is negotiated, this `feerate_per_kw`\n+is treated as 253 for all transactions.\n \n `to_self_delay` is the number of blocks that the other node's to-self\n outputs must be delayed, using `OP_CHECKSEQUENCEVERIFY` delays; this\n@@ -208,7 +210,8 @@ The receiving node MUST fail the channel if:\n   - `push_msat` is greater than `funding_satoshis` * 1000.\n   - `to_self_delay` is unreasonably large.\n   - `max_accepted_htlcs` is greater than 483.\n-  - it considers `feerate_per_kw` too small for timely processing or unreasonably large.\n+  - if `option_simplified_commitment` is not negotiated:\n+    - it considers `feerate_per_kw` too small for timely processing or unreasonably large.\n   - `funding_pubkey`, `revocation_basepoint`, `htlc_basepoint`, `payment_basepoint`, or `delayed_payment_basepoint`\n are not valid DER-encoded compressed secp256k1 pubkeys.\n   - `dust_limit_satoshis` is greater than `channel_reserve_satoshis`.\n@@ -228,7 +231,7 @@ The *channel reserve* is specified by the peer's `channel_reserve_satoshis`: 1%\n \n The sender can unconditionally give initial funds to the receiver using a non-zero `push_msat`, but even in this case we ensure that the funder has sufficient remaining funds to pay fees and that one side has some amount it can spend (which also implies there is at least one non-dust output). Note that, like any other on-chain transaction, this payment is not certain until the funding transaction has been confirmed sufficiently (with a danger of double-spend until this occurs) and may require a separate method to prove payment via on-chain confirmation.\n \n-The `feerate_per_kw` is generally only of concern to the sender (who pays the fees), but there is also the fee rate paid by HTLC transactions; thus, unreasonably large fee rates can also penalize the recipient.\n+The `feerate_per_kw` is generally only of concern to the sender (who pays the fees), but there is also the fee rate paid by HTLC transactions; thus, unreasonably large fee rates can also penalize the recipient.  It is ignored for `option_simplified_commitment`.\n \n Separating the `htlc_basepoint` from the `payment_basepoint` improves security: a node needs the secret associated with the `htlc_basepoint` to produce HTLC signatures for the protocol, but the secret for the `payment_basepoint` can be in cold storage.\n \n@@ -340,6 +343,12 @@ This message introduces the `channel_id` to identify the channel. It's derived f\n \n #### Requirements\n \n+Both peers:\n+  - if `option_simplified_commitment` was negotiated:\n+    - `option_simplified_commitment` applies to all commitment and HTLC transactions\n+  - otherwise:\n+    - `option_simplified_commitment` does not apply to any commitment or HTLC transactions\n+\n The sender MUST set:\n   - `channel_id` by exclusive-OR of the `funding_txid` and the `funding_output_index` from the `funding_created` message.\n   - `signature` to the valid signature, using its `funding_pubkey` for the initial commitment transaction, as defined in [BOLT #3](03-transactions.md#commitment-transaction).\n@@ -351,6 +360,12 @@ The recipient:\n   - on receipt of a valid `funding_signed`:\n     - SHOULD broadcast the funding transaction.\n \n+#### Rationale\n+\n+We decide on `option_simplified_commitment` at this point when we first have to generate the commitment\n+transaction.  Even if a later reconnection does not negotiate this parameter, this channel will honor it.\n+This simplifies channel state, particularly penalty transaction handling.\n+\n ### The `funding_locked` Message\n \n This message indicates that the funding transaction has reached the `minimum_depth` asked for in `accept_channel`. Once both nodes have sent this, the channel enters normal operating mode.\n@@ -508,8 +523,11 @@ The funding node:\n     - SHOULD send a `closing_signed` message.\n \n The sending node:\n-  - MUST set `fee_satoshis` less than or equal to the\n- base fee of the final commitment transaction, as calculated in [BOLT #3](03-transactions.md#fee-calculation).\n+  - if `option_upfront_shutdown_script` applies to the final commitment transaction:\n+    - MUST set `fee_satoshis` greater than or equal to 282.\n+  - otherwise:\n+    - MUST set `fee_satoshis` less than or equal to the\n+      base fee of the final commitment transaction, as calculated in [BOLT #3](03-transactions.md#fee-calculation).\n   - SHOULD set the initial `fee_satoshis` according to its\n  estimate of cost of inclusion in a block.\n   - MUST set `signature` to the Bitcoin signature of the close\n@@ -543,9 +561,18 @@ progress is made, even if only by a single satoshi at a time. To avoid\n keeping state and to handle the corner case, where fees have shifted\n between disconnection and reconnection, negotiation restarts on reconnection.\n \n-Note there is limited risk if the closing transaction is\n-delayed, but it will be broadcast very soon; so there is usually no\n-reason to pay a premium for rapid processing.\n+In the `option_simplified_commitment` case, the fees on the commitment\n+transaction itself are minimal (it is assumed that a child transaction will\n+supply additional fee incentive), so that forms a floor for negotiation.\n+[BOLT #3](03-transactions.md#fee-calculation), gives 282 satoshis (1116\n+weight, 254 `feerate_per_kw`).\n+\n+Otherwise, the commitment transaction usually pays a premium fee, so that\n+forms a ceiling.\n+\n+Note there is limited risk if the closing transaction is delayed, but it will\n+be broadcast very soon; so there is usually no reason to pay a premium for\n+rapid processing.\n \n ## Normal Operation\n \n@@ -763,7 +790,10 @@ is destined, is described in [BOLT #4](04-onion-routing.md).\n A sending node:\n   - MUST NOT offer `amount_msat` it cannot pay for in the\n remote commitment transaction at the current `feerate_per_kw` (see \"Updating\n-Fees\") while maintaining its channel reserve.\n+Fees\") while maintaining its channel reserve\n+  - if `option_simplified_commitment` applies to this commitment transaction and the sending\n+    node is the funder:\n+    - MUST be able to additionally pay for `to_local_pushme` and `to_remote_pushme` above its reserve.\n   - MUST offer `amount_msat` greater than 0.\n   - MUST NOT offer `amount_msat` below the receiving node's `htlc_minimum_msat`\n   - MUST set `cltv_expiry` less than 500000000.\n@@ -782,7 +812,7 @@ Fees\") while maintaining its channel reserve.\n A receiving node:\n   - receiving an `amount_msat` equal to 0, OR less than its own `htlc_minimum_msat`:\n     - SHOULD fail the channel.\n-  - receiving an `amount_msat` that the sending node cannot afford at the current `feerate_per_kw` (while maintaining its channel reserve):\n+  - receiving an `amount_msat` that the sending node cannot afford at the current `feerate_per_kw` (while maintaining its channel reserve and any `to_local_pushme` and `to_remote_pushme` fees):\n     - SHOULD fail the channel.\n   - if a sending node adds more than its `max_accepted_htlcs` HTLCs to\n     its local commitment transaction, OR adds more than its `max_htlc_value_in_flight_msat` worth of offered HTLCs to its local commitment transaction:\n@@ -997,6 +1027,11 @@ A node:\n \n ### Updating Fees: `update_fee`\n \n+If `option_simplified_commitment` applies to the commitment transaction,\n+`update_fee` is never used: the `feerate_per_kw` is always considered 253, but\n+the funder also pays 2000 satoshi for the `to_local_pushme` and\n+`to_remote_pushme` outputs.\n+\n An `update_fee` message is sent by the node which is paying the\n Bitcoin fee. Like any update, it's first committed to the receiver's\n commitment transaction and then (once acknowledged) committed to the\n@@ -1020,13 +1055,19 @@ given in [BOLT #3](03-transactions.md#fee-calculation).\n #### Requirements\n \n The node _responsible_ for paying the Bitcoin fee:\n-  - SHOULD send `update_fee` to ensure the current fee rate is sufficient (by a\n+  - if `option_simplified_commitment` applies to the commitment transaction:\n+    - MUST NOT send `update_fee`.\n+  - otherwise:\n+    - SHOULD send `update_fee` to ensure the current fee rate is sufficient (by a\n       significant margin) for timely processing of the commitment transaction.\n \n The node _not responsible_ for paying the Bitcoin fee:\n   - MUST NOT send `update_fee`.\n \n A receiving node:\n+  - if `option_simplified_commitment` applies to the commitment transaction:\n+    - SHOULD fail the channel.\n+\t- MUST NOT update the `feerate_per_kw`.\n   - if the `update_fee` is too low for timely processing, OR is unreasonably large:\n     - SHOULD fail the channel.\n   - if the sender is not responsible for paying the Bitcoin fee:\n@@ -1038,7 +1079,12 @@ A receiving node:\n \n #### Rationale\n \n-Bitcoin fees are required for unilateral closes to be effective \u2014\n+Fee adjustments are unnecessary for `option_simplified_commitment` which\n+relies on \"pushme\" outputs and a child transaction which will provide\n+additional fee incentive which can be calculated at the time it is spent, and\n+replaced by higher-fee children if required.\n+\n+Without this option, bitcoin fees are required for unilateral closes to be effective \u2014\n particularly since there is no general method for the broadcasting node to use\n child-pays-for-parent to increase its effective fee.\n \ndiff --git a/03-transactions.md b/03-transactions.md\nindex e769961..440bd0d 100644\n--- a/03-transactions.md\n+++ b/03-transactions.md\n@@ -82,6 +82,8 @@ To allow an opportunity for penalty transactions, in case of a revoked commitmen\n The reason for the separate transaction stage for HTLC outputs is so that HTLCs can timeout or be fulfilled even though they are within the `to_self_delay` delay.\n Otherwise, the required minimum timeout on HTLCs is lengthened by this delay, causing longer timeouts for HTLCs traversing the network.\n \n+If `option_simplified_commitment` applies to the commitment transaction, then the `to_self_delay` used for all transactions is the greater of the `to_self_delay` sent by each peer.  Otherwise, each peer sends the `to_self_delay` to be used for the other peer's commitment amd HTLC transactions.\n+\n The amounts for each output MUST be rounded down to whole satoshis. If this amount, minus the fees for the HTLC transaction, is less than the `dust_limit_satoshis` set by the owner of the commitment transaction, the output MUST NOT be produced (thus the funds add to fees).\n \n #### `to_local` Output\n@@ -109,7 +111,40 @@ If a revoked commitment transaction is published, the other party can spend this\n \n #### `to_remote` Output\n \n-This output sends funds to the other peer and thus is a simple P2WPKH to `remotepubkey`.\n+This output sends funds to the other peer, thus is not encumbered by a\n+revocation private key.\n+\n+If `option_simplified_commitment` applies to the commitment transaction, the `to_remote` output is delayed similarly to the `to_local` output, and is to a fixed key:\n+\n+        `to_self_delay`\n+        OP_CSV\n+        OP_DROP\n+        <remote_pubkey>\n+\n+The output is spent by a transaction with `nSequence` field set to `to_self_delay` (which can only be valid after that duration has passed) and witness:\n+\n+    <remote_sig>\n+\n+Otherwise, this output is a simple P2WPKH to `remotepubkey`.\n+\n+\n+#### `to_local_pushme` and `to_remote_pushme` Output (option_simplified_commitment)\n+\n+This output can be spent by the local and remote nodes respectivey to provide incentive to mine the transaction, using child-pays-for-parent.  They are only added if the `to_local` and `to_remote` outputs exist, respectively.\n+\n+    OP_DEPTH\n+    OP_IF\n+        <pubkey> OP_CHECKSIG\n+    OP_ELSE\n+        10 OP_CSV\n+    OP_ENDIF\n+\n+The `<pubkey>` is `<local_delayedpubkey>` to `to_local_pushme` and\n+`<remote_delayedpubkey>` for `to_remote_pushme`.  The output amount is\n+1000 satoshi, to encourage spending of the output.  Once the\n+`remote_pubkey` is revealed (by spending the `to_local` output) and\n+the commitment transaction is 10 blocks deep, anyone can spend it.\n+\n \n #### Offered HTLC Outputs\n \n@@ -294,6 +329,9 @@ The fee calculation for both commitment transactions and HTLC\n transactions is based on the current `feerate_per_kw` and the\n *expected weight* of the transaction.\n \n+Note that if `option_simplified_commitment` applies to the commitment\n+transaction then `feerate_per_kw` is 253.\n+\n The actual and expected weights vary for several reasons:\n \n * Bitcoin uses DER-encoded signatures, which vary in size.\n@@ -306,10 +344,12 @@ Thus, a simplified formula for *expected weight* is used, which assumes:\n * Signatures are 73 bytes long (the maximum length).\n * There are a small number of outputs (thus 1 byte to count them).\n * There are always both a `to_local` output and a `to_remote` output.\n+* (if `option_simplified_commitment`) there are always both a `to_local_pushme` and `to_remote_pushme` output.\n \n This yields the following *expected weights* (details of the computation in [Appendix A](#appendix-a-expected-weights)):\n \n-    Commitment weight:   724 + 172 * num-untrimmed-htlc-outputs\n+    Commitment weight (no option_simplified_commitment):   724 + 172 * num-untrimmed-htlc-outputs\n+    Commitment weight (option_simplified_commitment:  1116 + 172 * num-untrimmed-htlc-outputs\n     HTLC-timeout weight: 663\n     HTLC-success weight: 703\n \n@@ -366,7 +406,7 @@ outputs) is 7140 satoshi. The final fee may be even higher if the\n \n ### Fee Payment\n \n-Base commitment transaction fees are extracted from the funder's amount; if that amount is insufficient, the entire amount of the funder's output is used.\n+Base commitment transaction fees and amounts for `to_local_pushme` and `to_remote_pushme` outputs are extracted from the funder's amount; if that amount is insufficient, the entire amount of the funder's output is used.\n \n Note that after the fee amount is subtracted from the to-funder output,\n that output may be below `dust_limit_satoshis`, and thus will also\n@@ -390,23 +430,29 @@ committed HTLCs:\n 2. Calculate the base [commitment transaction fee](#fee-calculation).\n 3. Subtract this base fee from the funder (either `to_local` or `to_remote`),\n    with a floor of 0 (see [Fee Payment](#fee-payment)).\n+4. If `option_simplified_commitment` applies to the commitment transaction,\n+   subtract 2000 satoshis from the funder (either `to_local` or `to_remote`).\n 3. For every offered HTLC, if it is not trimmed, add an\n    [offered HTLC output](#offered-htlc-outputs).\n 4. For every received HTLC, if it is not trimmed, add an\n    [received HTLC output](#received-htlc-outputs).\n 5. If the `to_local` amount is greater or equal to `dust_limit_satoshis`,\n    add a [`to_local` output](#to_local-output).\n+6. If `option_simplified_commitment` applies to the commitment transaction,\n+   and `to_local` was added, add `to_local_pushme`.\n 6. If the `to_remote` amount is greater or equal to `dust_limit_satoshis`,\n    add a [`to_remote` output](#to_remote-output).\n+6. If `option_simplified_commitment` applies to the commitment transaction,\n+   and `to_remote` was added, add `to_remote_pushme`.\n 7. Sort the outputs into [BIP 69 order](#transaction-input-and-output-ordering).\n \n # Keys\n \n ## Key Derivation\n \n-Each commitment transaction uses a unique set of keys: `localpubkey` and `remotepubkey`.\n+Each commitment transaction uses a unique `localpubkey`, and a `remotepubkey`.\n The HTLC-success and HTLC-timeout transactions use `local_delayedpubkey` and `revocationpubkey`.\n-These are changed for every transaction based on the `per_commitment_point`.\n+These are changed for every transaction based on the `per_commitment_point`, with the exception of `remotepubkey` if `option_simplified_commitment` is negotiated.\n \n The reason for key change is so that trustless watching for revoked\n transactions can be outsourced. Such a _watcher_ should not be able to\n@@ -419,8 +465,9 @@ avoid storage of every commitment transaction, a _watcher_ can be given the\n the scripts required for the penalty transaction; thus, a _watcher_ need only be\n given (and store) the signatures for each penalty input.\n \n-Changing the `localpubkey` and `remotepubkey` every time ensures that commitment\n-transaction ID cannot be guessed; every commitment transaction uses an ID\n+Changing the `localpubkey` every time ensures that commitment\n+transaction ID cannot be guessed except in the trivial case where there is no\n+`to_local` output, as every commitment transaction uses an ID\n in its output script. Splitting the `local_delayedpubkey`, which is required for\n the penalty transaction, allows it to be shared with the _watcher_ without\n revealing `localpubkey`; even if both peers use the same _watcher_, nothing is revealed.\n@@ -434,14 +481,13 @@ For efficiency, keys are generated from a series of per-commitment secrets\n that are generated from a single seed, which allows the receiver to compactly\n store them (see [below](#efficient-per-commitment-secret-storage)).\n \n-### `localpubkey`, `remotepubkey`, `local_htlcpubkey`, `remote_htlcpubkey`, `local_delayedpubkey`, and `remote_delayedpubkey` Derivation\n+### `localpubkey``local_htlcpubkey`, `remote_htlcpubkey`, `local_delayedpubkey`, and `remote_delayedpubkey` Derivation\n \n These pubkeys are simply generated by addition from their base points:\n \n \tpubkey = basepoint + SHA256(per_commitment_point || basepoint) * G\n \n-The `localpubkey` uses the local node's `payment_basepoint`; the `remotepubkey`\n-uses the remote node's `payment_basepoint`; the `local_delayedpubkey`\n+The `localpubkey` uses the local node's `payment_basepoint`; the `local_delayedpubkey`\n uses the local node's `delayed_payment_basepoint`; the `local_htlcpubkey` uses the\n local node's `htlc_basepoint`; and the `remote_delayedpubkey` uses the remote\n node's `delayed_payment_basepoint`.\n@@ -451,6 +497,17 @@ secrets are known (i.e. the private keys corresponding to `localpubkey`, `local_\n \n     privkey = basepoint_secret + SHA256(per_commitment_point || basepoint)\n \n+### `remotepubkey` Derivation\n+\n+If `option_simplified_commitment` is negotiated the `remotepubkey` is simply the remote node's `payment_basepoint`, otherwise it is calculated as above using the remote node's `payment_basepoint`.\n+\n+The simplified derivation means that a node can spend a commitment\n+transaction even if it has lost data and doesn't know the\n+corresponding `payment_basepoint`.  A watchtower could correlate\n+transactions given to it which only have a `to_remote` output if it\n+sees one of them onchain, but such transactions do not need any\n+enforcement and should not be handed to a watchtower.\n+\n ### `revocationpubkey` Derivation\n \n The `revocationpubkey` is a blinded key: when the local node wishes to create a new\n@@ -636,12 +693,22 @@ The *expected weight* of a commitment transaction is calculated as follows:\n \t\t- var_int: 1 byte (pk_script length)\n \t\t- pk_script (p2wsh): 34 bytes\n \n-\toutput_paying_to_remote: 31 bytes\n+\toutput_paying_to_remote (no option_simplified_commitment): 31 bytes\n \t\t- value: 8 bytes\n \t\t- var_int: 1 byte (pk_script length)\n \t\t- pk_script (p2wpkh): 22 bytes\n \n-\t htlc_output: 43 bytes\n+\toutput_paying_to_remote (option_simplified_commitment): 43 bytes\n+\t\t- value: 8 bytes\n+\t\t- var_int: 1 byte (pk_script length)\n+\t\t- pk_script (p2wsh): 34 bytes\n+\n+\toutput_pushme (option_simplified_commitment): 43 bytes\n+\t\t- value: 8 bytes\n+\t\t- var_int: 1 byte (pk_script length)\n+\t\t- pk_script (p2wsh): 34 bytes\n+\n+    htlc_output: 43 bytes\n \t\t- value: 8 bytes\n \t\t- var_int: 1 byte (pk_script length)\n \t\t- pk_script (p2wsh): 34 bytes\n@@ -650,7 +717,7 @@ The *expected weight* of a commitment transaction is calculated as follows:\n \t\t- flag: 1 byte\n \t\t- marker: 1 byte\n \n-\t commitment_transaction: 125 + 43 * num-htlc-outputs bytes\n+\t commitment_transaction (no option_simplified_commitment): 125 + 43 * num-htlc-outputs bytes\n \t\t- version: 4 bytes\n \t\t- witness_header <---- part of the witness data\n \t\t- count_tx_in: 1 byte\n@@ -663,15 +730,32 @@ The *expected weight* of a commitment transaction is calculated as follows:\n \t\t\t....htlc_output's...\n \t\t- lock_time: 4 bytes\n \n+\t commitment_transaction (option_simplified_commitment): 223 + 43 * num-htlc-outputs bytes\n+\t\t- version: 4 bytes\n+\t\t- witness_header <---- part of the witness data\n+\t\t- count_tx_in: 1 byte\n+\t\t- tx_in: 41 bytes\n+\t\t\tfunding_input\n+\t\t- count_tx_out: 1 byte\n+\t\t- tx_out: 172 + 43 * num-htlc-outputs bytes\n+\t\t\toutput_paying_to_remote,\n+\t\t\toutput_paying_to_local,\n+\t\t\toutput_pushme,\n+\t\t\toutput_pushme,\n+\t\t\t....htlc_output's...\n+\t\t- lock_time: 4 bytes\n+\n Multiplying non-witness data by 4 results in a weight of:\n \n-\t// 500 + 172 * num-htlc-outputs weight\n+\t// 500 + 172 * num-htlc-outputs weight (no option_simplified_commitment)\n+\t// 892 + 172 * num-htlc-outputs weight (option_simplified_commitment)\n \tcommitment_transaction_weight = 4 * commitment_transaction\n \n \t// 224 weight\n \twitness_weight = witness_header + witness\n \n-\toverall_weight = 500 + 172 * num-htlc-outputs + 224 weight\n+\toverall_weight (no option_simplified_commitment) = 500 + 172 * num-htlc-outputs + 224 weight\n+\toverall_weight (option_simplified_commitment) = 892 + 172 * num-htlc-outputs + 224 weight\n \n ## Expected Weight of HTLC-timeout and HTLC-success Transactions\n \ndiff --git a/05-onchain.md b/05-onchain.md\nindex 231c209..c5fb5e1 100644\n--- a/05-onchain.md\n+++ b/05-onchain.md\n@@ -89,21 +89,29 @@ trigger any action.\n # Commitment Transaction\n \n The local and remote nodes each hold a *commitment transaction*. Each of these\n-commitment transactions has four types of outputs:\n+commitment transactions has six types of outputs:\n \n 1. _local node's main output_: Zero or one output, to pay to the *local node's*\n-commitment pubkey.\n+delayed pubkey.\n 2. _remote node's main output_: Zero or one output, to pay to the *remote node's*\n-commitment pubkey.\n+pubkey.\n+1. _local node's push output_: Zero or one output, to pay to the *local node's*\n+delayed pubkey.\n+2. _remote node's push output_: Zero or one output, to pay to the *remote node's*\n+pubkey.\n 3. _local node's offered HTLCs_: Zero or more pending payments (*HTLCs*), to pay\n the *remote node* in return for a payment preimage.\n 4. _remote node's offered HTLCs_: Zero or more pending payments (*HTLCs*), to\n pay the *local node* in return for a payment preimage.\n \n To incentivize the local and remote nodes to cooperate, an `OP_CHECKSEQUENCEVERIFY`\n-relative timeout encumbers the *local node's outputs* (in the *local node's\n+relative timeout encumbers some outputs: the *local node's outputs* (in the *local node's\n commitment transaction*) and the *remote node's outputs* (in the *remote node's\n-commitment transaction*). So for example, if the local node publishes its\n+commitment transaction*). If `option_simplified_commitment` applies\n+to the commitment transaction, then the *to_remote* output of each commitment is\n+identically encumbered, for fairness.\n+\n+Without `option_simplified_commitment`, if the local node publishes its\n commitment transaction, it will have to wait to claim its own funds,\n whereas the remote node will have immediate access to its own funds. As a\n consequence, the two commitment transactions are not identical, but they are\n@@ -140,6 +148,11 @@ A node:\n       - otherwise:\n         - MUST use the *last commitment transaction*, for which it has a\n         signature, to perform a *unilateral close*.\n+      - MUST spend any `to_local_pushme` output, providing sufficient fees as incentive to include the commitment transaction in a block\n+\t    - SHOULD use [replace-by-fee](https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki) or other mechanism on the spending transaction if it proves insufficient for timely inclusion in a block.\n+\n+A node:\n+  - MAY monitor the blockchain for unspent `to_local_pushme` and `to_remote_pushme` outputs and try to spend them after 10 confirmations.\n \n ## Rationale\n \n@@ -154,7 +167,8 @@ need not consume resources monitoring the channel state.\n There exists a bias towards preferring mutual closes over unilateral closes,\n because outputs of the former are unencumbered by a delay and are directly\n spendable by wallets. In addition, mutual close fees tend to be less exaggerated\n-than those of commitment transactions. So, the only reason not to use the\n+than those of commitment transactions (or in the case of `option_simplified_commitment`,\n+the commitment transaction may require a child transaction to cause it to be mined). So, the only reason not to use the\n signature from `closing_signed` would be if the fee offered was too small for\n it to be processed.\n \ndiff --git a/09-features.md b/09-features.md\nindex d06fcff..caea38b 100644\n--- a/09-features.md\n+++ b/09-features.md\n@@ -26,6 +26,7 @@ These flags may only be used in the `init` message:\n | 3  | `initial_routing_sync` | Indicates that the sending node needs a complete routing information dump | [BOLT #7](07-routing-gossip.md#initial-sync) |\n | 4/5  | `option_upfront_shutdown_script` | Commits to a shutdown scriptpubkey when opening channel | [BOLT #2](02-peer-protocol.md#the-open_channel-message) |\n | 6/7  | `gossip_queries`           | More sophisticated gossip control | [BOLT #7](07-routing-gossip.md#query-messages) |\n+| 8/9  | `option_simplified_commitment`           | Simplified commitment transactions | [BOLT #3](03-transactions.md) |\n \n ## Assigned `globalfeatures` flags"
            },
            {
                "author": "Matt Corallo",
                "date": "2018-11-21T02:54:18",
                "message_text_only": "Not sure if others already realized this, but in thinking about our RBF \npolicy hack from Adelaide a bit more, to allow the carve-out exception \nof \"last tx in a package, which has only one unconfirmed ancestor\" to \nalways be available for the \"honest party\" when broadcasting a \ncommitment transaction, we also need at least a CSV delay of 1 block on \nthe HTLC transaction outputs (as otherwise those transactions could \ncount as the carve-out tx).\n\nMatt\n\nOn 11/21/18 2:17 AM, Rusty Russell wrote:\n> I'm also starting to implement this, to see what I missed!\n> \n> Original at https://github.com/lightningnetwork/lightning-rfc/pull/513\n> \n> Pasted here for your reading convenience:\n> \n> - Option is sticky; it set at open time, it stays with channel\n>    - I didn't want to have to handle penalty txs on channels which switch\n>    - We could, however, upgrade on splice.\n> - Feerate is fixed at 253\n>    - `feerate_per_kw` is still in open /accept (just ignored): multifund may want it.\n> - closing tx negotiates *upwards* not *downwards*\n>    - Starting from base fee of commitment tx = 282 satoshi.\n> - to_remote output is always CSV delayed.\n> - pushme outputs are paid for by funder, but only exist if the matching\n>    to_local/remote output exists.\n> - After 10 blocks, they become anyone-can-spend (they need to see the\n>    to-local/remote witness script though).\n> - remotepubkey is not rotated.\n> - You must spend your pushme output; you may sweep for others.\n> \n> Signed-off-by: Rusty Russell <rusty at rustcorp.com.au>\n> \n> diff --git a/02-peer-protocol.md b/02-peer-protocol.md\n> index 7cf9ebf..6ec1155 100644\n> --- a/02-peer-protocol.md\n> +++ b/02-peer-protocol.md\n> @@ -133,7 +133,9 @@ node can offer.\n>   (i.e. 1/4 the more normally-used 'satoshi per 1000 vbytes') that this\n>   side will pay for commitment and HTLC transactions, as described in\n>   [BOLT #3](03-transactions.md#fee-calculation) (this can be adjusted\n> -later with an `update_fee` message).\n> +later with an `update_fee` message).  Note that if\n> +`option_simplified_commitment` is negotiated, this `feerate_per_kw`\n> +is treated as 253 for all transactions.\n>   \n>   `to_self_delay` is the number of blocks that the other node's to-self\n>   outputs must be delayed, using `OP_CHECKSEQUENCEVERIFY` delays; this\n> @@ -208,7 +210,8 @@ The receiving node MUST fail the channel if:\n>     - `push_msat` is greater than `funding_satoshis` * 1000.\n>     - `to_self_delay` is unreasonably large.\n>     - `max_accepted_htlcs` is greater than 483.\n> -  - it considers `feerate_per_kw` too small for timely processing or unreasonably large.\n> +  - if `option_simplified_commitment` is not negotiated:\n> +    - it considers `feerate_per_kw` too small for timely processing or unreasonably large.\n>     - `funding_pubkey`, `revocation_basepoint`, `htlc_basepoint`, `payment_basepoint`, or `delayed_payment_basepoint`\n>   are not valid DER-encoded compressed secp256k1 pubkeys.\n>     - `dust_limit_satoshis` is greater than `channel_reserve_satoshis`.\n> @@ -228,7 +231,7 @@ The *channel reserve* is specified by the peer's `channel_reserve_satoshis`: 1%\n>   \n>   The sender can unconditionally give initial funds to the receiver using a non-zero `push_msat`, but even in this case we ensure that the funder has sufficient remaining funds to pay fees and that one side has some amount it can spend (which also implies there is at least one non-dust output). Note that, like any other on-chain transaction, this payment is not certain until the funding transaction has been confirmed sufficiently (with a danger of double-spend until this occurs) and may require a separate method to prove payment via on-chain confirmation.\n>   \n> -The `feerate_per_kw` is generally only of concern to the sender (who pays the fees), but there is also the fee rate paid by HTLC transactions; thus, unreasonably large fee rates can also penalize the recipient.\n> +The `feerate_per_kw` is generally only of concern to the sender (who pays the fees), but there is also the fee rate paid by HTLC transactions; thus, unreasonably large fee rates can also penalize the recipient.  It is ignored for `option_simplified_commitment`.\n>   \n>   Separating the `htlc_basepoint` from the `payment_basepoint` improves security: a node needs the secret associated with the `htlc_basepoint` to produce HTLC signatures for the protocol, but the secret for the `payment_basepoint` can be in cold storage.\n>   \n> @@ -340,6 +343,12 @@ This message introduces the `channel_id` to identify the channel. It's derived f\n>   \n>   #### Requirements\n>   \n> +Both peers:\n> +  - if `option_simplified_commitment` was negotiated:\n> +    - `option_simplified_commitment` applies to all commitment and HTLC transactions\n> +  - otherwise:\n> +    - `option_simplified_commitment` does not apply to any commitment or HTLC transactions\n> +\n>   The sender MUST set:\n>     - `channel_id` by exclusive-OR of the `funding_txid` and the `funding_output_index` from the `funding_created` message.\n>     - `signature` to the valid signature, using its `funding_pubkey` for the initial commitment transaction, as defined in [BOLT #3](03-transactions.md#commitment-transaction).\n> @@ -351,6 +360,12 @@ The recipient:\n>     - on receipt of a valid `funding_signed`:\n>       - SHOULD broadcast the funding transaction.\n>   \n> +#### Rationale\n> +\n> +We decide on `option_simplified_commitment` at this point when we first have to generate the commitment\n> +transaction.  Even if a later reconnection does not negotiate this parameter, this channel will honor it.\n> +This simplifies channel state, particularly penalty transaction handling.\n> +\n>   ### The `funding_locked` Message\n>   \n>   This message indicates that the funding transaction has reached the `minimum_depth` asked for in `accept_channel`. Once both nodes have sent this, the channel enters normal operating mode.\n> @@ -508,8 +523,11 @@ The funding node:\n>       - SHOULD send a `closing_signed` message.\n>   \n>   The sending node:\n> -  - MUST set `fee_satoshis` less than or equal to the\n> - base fee of the final commitment transaction, as calculated in [BOLT #3](03-transactions.md#fee-calculation).\n> +  - if `option_upfront_shutdown_script` applies to the final commitment transaction:\n> +    - MUST set `fee_satoshis` greater than or equal to 282.\n> +  - otherwise:\n> +    - MUST set `fee_satoshis` less than or equal to the\n> +      base fee of the final commitment transaction, as calculated in [BOLT #3](03-transactions.md#fee-calculation).\n>     - SHOULD set the initial `fee_satoshis` according to its\n>    estimate of cost of inclusion in a block.\n>     - MUST set `signature` to the Bitcoin signature of the close\n> @@ -543,9 +561,18 @@ progress is made, even if only by a single satoshi at a time. To avoid\n>   keeping state and to handle the corner case, where fees have shifted\n>   between disconnection and reconnection, negotiation restarts on reconnection.\n>   \n> -Note there is limited risk if the closing transaction is\n> -delayed, but it will be broadcast very soon; so there is usually no\n> -reason to pay a premium for rapid processing.\n> +In the `option_simplified_commitment` case, the fees on the commitment\n> +transaction itself are minimal (it is assumed that a child transaction will\n> +supply additional fee incentive), so that forms a floor for negotiation.\n> +[BOLT #3](03-transactions.md#fee-calculation), gives 282 satoshis (1116\n> +weight, 254 `feerate_per_kw`).\n> +\n> +Otherwise, the commitment transaction usually pays a premium fee, so that\n> +forms a ceiling.\n> +\n> +Note there is limited risk if the closing transaction is delayed, but it will\n> +be broadcast very soon; so there is usually no reason to pay a premium for\n> +rapid processing.\n>   \n>   ## Normal Operation\n>   \n> @@ -763,7 +790,10 @@ is destined, is described in [BOLT #4](04-onion-routing.md).\n>   A sending node:\n>     - MUST NOT offer `amount_msat` it cannot pay for in the\n>   remote commitment transaction at the current `feerate_per_kw` (see \"Updating\n> -Fees\") while maintaining its channel reserve.\n> +Fees\") while maintaining its channel reserve\n> +  - if `option_simplified_commitment` applies to this commitment transaction and the sending\n> +    node is the funder:\n> +    - MUST be able to additionally pay for `to_local_pushme` and `to_remote_pushme` above its reserve.\n>     - MUST offer `amount_msat` greater than 0.\n>     - MUST NOT offer `amount_msat` below the receiving node's `htlc_minimum_msat`\n>     - MUST set `cltv_expiry` less than 500000000.\n> @@ -782,7 +812,7 @@ Fees\") while maintaining its channel reserve.\n>   A receiving node:\n>     - receiving an `amount_msat` equal to 0, OR less than its own `htlc_minimum_msat`:\n>       - SHOULD fail the channel.\n> -  - receiving an `amount_msat` that the sending node cannot afford at the current `feerate_per_kw` (while maintaining its channel reserve):\n> +  - receiving an `amount_msat` that the sending node cannot afford at the current `feerate_per_kw` (while maintaining its channel reserve and any `to_local_pushme` and `to_remote_pushme` fees):\n>       - SHOULD fail the channel.\n>     - if a sending node adds more than its `max_accepted_htlcs` HTLCs to\n>       its local commitment transaction, OR adds more than its `max_htlc_value_in_flight_msat` worth of offered HTLCs to its local commitment transaction:\n> @@ -997,6 +1027,11 @@ A node:\n>   \n>   ### Updating Fees: `update_fee`\n>   \n> +If `option_simplified_commitment` applies to the commitment transaction,\n> +`update_fee` is never used: the `feerate_per_kw` is always considered 253, but\n> +the funder also pays 2000 satoshi for the `to_local_pushme` and\n> +`to_remote_pushme` outputs.\n> +\n>   An `update_fee` message is sent by the node which is paying the\n>   Bitcoin fee. Like any update, it's first committed to the receiver's\n>   commitment transaction and then (once acknowledged) committed to the\n> @@ -1020,13 +1055,19 @@ given in [BOLT #3](03-transactions.md#fee-calculation).\n>   #### Requirements\n>   \n>   The node _responsible_ for paying the Bitcoin fee:\n> -  - SHOULD send `update_fee` to ensure the current fee rate is sufficient (by a\n> +  - if `option_simplified_commitment` applies to the commitment transaction:\n> +    - MUST NOT send `update_fee`.\n> +  - otherwise:\n> +    - SHOULD send `update_fee` to ensure the current fee rate is sufficient (by a\n>         significant margin) for timely processing of the commitment transaction.\n>   \n>   The node _not responsible_ for paying the Bitcoin fee:\n>     - MUST NOT send `update_fee`.\n>   \n>   A receiving node:\n> +  - if `option_simplified_commitment` applies to the commitment transaction:\n> +    - SHOULD fail the channel.\n> +\t- MUST NOT update the `feerate_per_kw`.\n>     - if the `update_fee` is too low for timely processing, OR is unreasonably large:\n>       - SHOULD fail the channel.\n>     - if the sender is not responsible for paying the Bitcoin fee:\n> @@ -1038,7 +1079,12 @@ A receiving node:\n>   \n>   #### Rationale\n>   \n> -Bitcoin fees are required for unilateral closes to be effective \u2014\n> +Fee adjustments are unnecessary for `option_simplified_commitment` which\n> +relies on \"pushme\" outputs and a child transaction which will provide\n> +additional fee incentive which can be calculated at the time it is spent, and\n> +replaced by higher-fee children if required.\n> +\n> +Without this option, bitcoin fees are required for unilateral closes to be effective \u2014\n>   particularly since there is no general method for the broadcasting node to use\n>   child-pays-for-parent to increase its effective fee.\n>   \n> diff --git a/03-transactions.md b/03-transactions.md\n> index e769961..440bd0d 100644\n> --- a/03-transactions.md\n> +++ b/03-transactions.md\n> @@ -82,6 +82,8 @@ To allow an opportunity for penalty transactions, in case of a revoked commitmen\n>   The reason for the separate transaction stage for HTLC outputs is so that HTLCs can timeout or be fulfilled even though they are within the `to_self_delay` delay.\n>   Otherwise, the required minimum timeout on HTLCs is lengthened by this delay, causing longer timeouts for HTLCs traversing the network.\n>   \n> +If `option_simplified_commitment` applies to the commitment transaction, then the `to_self_delay` used for all transactions is the greater of the `to_self_delay` sent by each peer.  Otherwise, each peer sends the `to_self_delay` to be used for the other peer's commitment amd HTLC transactions.\n> +\n>   The amounts for each output MUST be rounded down to whole satoshis. If this amount, minus the fees for the HTLC transaction, is less than the `dust_limit_satoshis` set by the owner of the commitment transaction, the output MUST NOT be produced (thus the funds add to fees).\n>   \n>   #### `to_local` Output\n> @@ -109,7 +111,40 @@ If a revoked commitment transaction is published, the other party can spend this\n>   \n>   #### `to_remote` Output\n>   \n> -This output sends funds to the other peer and thus is a simple P2WPKH to `remotepubkey`.\n> +This output sends funds to the other peer, thus is not encumbered by a\n> +revocation private key.\n> +\n> +If `option_simplified_commitment` applies to the commitment transaction, the `to_remote` output is delayed similarly to the `to_local` output, and is to a fixed key:\n> +\n> +        `to_self_delay`\n> +        OP_CSV\n> +        OP_DROP\n> +        <remote_pubkey>\n> +\n> +The output is spent by a transaction with `nSequence` field set to `to_self_delay` (which can only be valid after that duration has passed) and witness:\n> +\n> +    <remote_sig>\n> +\n> +Otherwise, this output is a simple P2WPKH to `remotepubkey`.\n> +\n> +\n> +#### `to_local_pushme` and `to_remote_pushme` Output (option_simplified_commitment)\n> +\n> +This output can be spent by the local and remote nodes respectivey to provide incentive to mine the transaction, using child-pays-for-parent.  They are only added if the `to_local` and `to_remote` outputs exist, respectively.\n> +\n> +    OP_DEPTH\n> +    OP_IF\n> +        <pubkey> OP_CHECKSIG\n> +    OP_ELSE\n> +        10 OP_CSV\n> +    OP_ENDIF\n> +\n> +The `<pubkey>` is `<local_delayedpubkey>` to `to_local_pushme` and\n> +`<remote_delayedpubkey>` for `to_remote_pushme`.  The output amount is\n> +1000 satoshi, to encourage spending of the output.  Once the\n> +`remote_pubkey` is revealed (by spending the `to_local` output) and\n> +the commitment transaction is 10 blocks deep, anyone can spend it.\n> +\n>   \n>   #### Offered HTLC Outputs\n>   \n> @@ -294,6 +329,9 @@ The fee calculation for both commitment transactions and HTLC\n>   transactions is based on the current `feerate_per_kw` and the\n>   *expected weight* of the transaction.\n>   \n> +Note that if `option_simplified_commitment` applies to the commitment\n> +transaction then `feerate_per_kw` is 253.\n> +\n>   The actual and expected weights vary for several reasons:\n>   \n>   * Bitcoin uses DER-encoded signatures, which vary in size.\n> @@ -306,10 +344,12 @@ Thus, a simplified formula for *expected weight* is used, which assumes:\n>   * Signatures are 73 bytes long (the maximum length).\n>   * There are a small number of outputs (thus 1 byte to count them).\n>   * There are always both a `to_local` output and a `to_remote` output.\n> +* (if `option_simplified_commitment`) there are always both a `to_local_pushme` and `to_remote_pushme` output.\n>   \n>   This yields the following *expected weights* (details of the computation in [Appendix A](#appendix-a-expected-weights)):\n>   \n> -    Commitment weight:   724 + 172 * num-untrimmed-htlc-outputs\n> +    Commitment weight (no option_simplified_commitment):   724 + 172 * num-untrimmed-htlc-outputs\n> +    Commitment weight (option_simplified_commitment:  1116 + 172 * num-untrimmed-htlc-outputs\n>       HTLC-timeout weight: 663\n>       HTLC-success weight: 703\n>   \n> @@ -366,7 +406,7 @@ outputs) is 7140 satoshi. The final fee may be even higher if the\n>   \n>   ### Fee Payment\n>   \n> -Base commitment transaction fees are extracted from the funder's amount; if that amount is insufficient, the entire amount of the funder's output is used.\n> +Base commitment transaction fees and amounts for `to_local_pushme` and `to_remote_pushme` outputs are extracted from the funder's amount; if that amount is insufficient, the entire amount of the funder's output is used.\n>   \n>   Note that after the fee amount is subtracted from the to-funder output,\n>   that output may be below `dust_limit_satoshis`, and thus will also\n> @@ -390,23 +430,29 @@ committed HTLCs:\n>   2. Calculate the base [commitment transaction fee](#fee-calculation).\n>   3. Subtract this base fee from the funder (either `to_local` or `to_remote`),\n>      with a floor of 0 (see [Fee Payment](#fee-payment)).\n> +4. If `option_simplified_commitment` applies to the commitment transaction,\n> +   subtract 2000 satoshis from the funder (either `to_local` or `to_remote`).\n>   3. For every offered HTLC, if it is not trimmed, add an\n>      [offered HTLC output](#offered-htlc-outputs).\n>   4. For every received HTLC, if it is not trimmed, add an\n>      [received HTLC output](#received-htlc-outputs).\n>   5. If the `to_local` amount is greater or equal to `dust_limit_satoshis`,\n>      add a [`to_local` output](#to_local-output).\n> +6. If `option_simplified_commitment` applies to the commitment transaction,\n> +   and `to_local` was added, add `to_local_pushme`.\n>   6. If the `to_remote` amount is greater or equal to `dust_limit_satoshis`,\n>      add a [`to_remote` output](#to_remote-output).\n> +6. If `option_simplified_commitment` applies to the commitment transaction,\n> +   and `to_remote` was added, add `to_remote_pushme`.\n>   7. Sort the outputs into [BIP 69 order](#transaction-input-and-output-ordering).\n>   \n>   # Keys\n>   \n>   ## Key Derivation\n>   \n> -Each commitment transaction uses a unique set of keys: `localpubkey` and `remotepubkey`.\n> +Each commitment transaction uses a unique `localpubkey`, and a `remotepubkey`.\n>   The HTLC-success and HTLC-timeout transactions use `local_delayedpubkey` and `revocationpubkey`.\n> -These are changed for every transaction based on the `per_commitment_point`.\n> +These are changed for every transaction based on the `per_commitment_point`, with the exception of `remotepubkey` if `option_simplified_commitment` is negotiated.\n>   \n>   The reason for key change is so that trustless watching for revoked\n>   transactions can be outsourced. Such a _watcher_ should not be able to\n> @@ -419,8 +465,9 @@ avoid storage of every commitment transaction, a _watcher_ can be given the\n>   the scripts required for the penalty transaction; thus, a _watcher_ need only be\n>   given (and store) the signatures for each penalty input.\n>   \n> -Changing the `localpubkey` and `remotepubkey` every time ensures that commitment\n> -transaction ID cannot be guessed; every commitment transaction uses an ID\n> +Changing the `localpubkey` every time ensures that commitment\n> +transaction ID cannot be guessed except in the trivial case where there is no\n> +`to_local` output, as every commitment transaction uses an ID\n>   in its output script. Splitting the `local_delayedpubkey`, which is required for\n>   the penalty transaction, allows it to be shared with the _watcher_ without\n>   revealing `localpubkey`; even if both peers use the same _watcher_, nothing is revealed.\n> @@ -434,14 +481,13 @@ For efficiency, keys are generated from a series of per-commitment secrets\n>   that are generated from a single seed, which allows the receiver to compactly\n>   store them (see [below](#efficient-per-commitment-secret-storage)).\n>   \n> -### `localpubkey`, `remotepubkey`, `local_htlcpubkey`, `remote_htlcpubkey`, `local_delayedpubkey`, and `remote_delayedpubkey` Derivation\n> +### `localpubkey``local_htlcpubkey`, `remote_htlcpubkey`, `local_delayedpubkey`, and `remote_delayedpubkey` Derivation\n>   \n>   These pubkeys are simply generated by addition from their base points:\n>   \n>   \tpubkey = basepoint + SHA256(per_commitment_point || basepoint) * G\n>   \n> -The `localpubkey` uses the local node's `payment_basepoint`; the `remotepubkey`\n> -uses the remote node's `payment_basepoint`; the `local_delayedpubkey`\n> +The `localpubkey` uses the local node's `payment_basepoint`; the `local_delayedpubkey`\n>   uses the local node's `delayed_payment_basepoint`; the `local_htlcpubkey` uses the\n>   local node's `htlc_basepoint`; and the `remote_delayedpubkey` uses the remote\n>   node's `delayed_payment_basepoint`.\n> @@ -451,6 +497,17 @@ secrets are known (i.e. the private keys corresponding to `localpubkey`, `local_\n>   \n>       privkey = basepoint_secret + SHA256(per_commitment_point || basepoint)\n>   \n> +### `remotepubkey` Derivation\n> +\n> +If `option_simplified_commitment` is negotiated the `remotepubkey` is simply the remote node's `payment_basepoint`, otherwise it is calculated as above using the remote node's `payment_basepoint`.\n> +\n> +The simplified derivation means that a node can spend a commitment\n> +transaction even if it has lost data and doesn't know the\n> +corresponding `payment_basepoint`.  A watchtower could correlate\n> +transactions given to it which only have a `to_remote` output if it\n> +sees one of them onchain, but such transactions do not need any\n> +enforcement and should not be handed to a watchtower.\n> +\n>   ### `revocationpubkey` Derivation\n>   \n>   The `revocationpubkey` is a blinded key: when the local node wishes to create a new\n> @@ -636,12 +693,22 @@ The *expected weight* of a commitment transaction is calculated as follows:\n>   \t\t- var_int: 1 byte (pk_script length)\n>   \t\t- pk_script (p2wsh): 34 bytes\n>   \n> -\toutput_paying_to_remote: 31 bytes\n> +\toutput_paying_to_remote (no option_simplified_commitment): 31 bytes\n>   \t\t- value: 8 bytes\n>   \t\t- var_int: 1 byte (pk_script length)\n>   \t\t- pk_script (p2wpkh): 22 bytes\n>   \n> -\t htlc_output: 43 bytes\n> +\toutput_paying_to_remote (option_simplified_commitment): 43 bytes\n> +\t\t- value: 8 bytes\n> +\t\t- var_int: 1 byte (pk_script length)\n> +\t\t- pk_script (p2wsh): 34 bytes\n> +\n> +\toutput_pushme (option_simplified_commitment): 43 bytes\n> +\t\t- value: 8 bytes\n> +\t\t- var_int: 1 byte (pk_script length)\n> +\t\t- pk_script (p2wsh): 34 bytes\n> +\n> +    htlc_output: 43 bytes\n>   \t\t- value: 8 bytes\n>   \t\t- var_int: 1 byte (pk_script length)\n>   \t\t- pk_script (p2wsh): 34 bytes\n> @@ -650,7 +717,7 @@ The *expected weight* of a commitment transaction is calculated as follows:\n>   \t\t- flag: 1 byte\n>   \t\t- marker: 1 byte\n>   \n> -\t commitment_transaction: 125 + 43 * num-htlc-outputs bytes\n> +\t commitment_transaction (no option_simplified_commitment): 125 + 43 * num-htlc-outputs bytes\n>   \t\t- version: 4 bytes\n>   \t\t- witness_header <---- part of the witness data\n>   \t\t- count_tx_in: 1 byte\n> @@ -663,15 +730,32 @@ The *expected weight* of a commitment transaction is calculated as follows:\n>   \t\t\t....htlc_output's...\n>   \t\t- lock_time: 4 bytes\n>   \n> +\t commitment_transaction (option_simplified_commitment): 223 + 43 * num-htlc-outputs bytes\n> +\t\t- version: 4 bytes\n> +\t\t- witness_header <---- part of the witness data\n> +\t\t- count_tx_in: 1 byte\n> +\t\t- tx_in: 41 bytes\n> +\t\t\tfunding_input\n> +\t\t- count_tx_out: 1 byte\n> +\t\t- tx_out: 172 + 43 * num-htlc-outputs bytes\n> +\t\t\toutput_paying_to_remote,\n> +\t\t\toutput_paying_to_local,\n> +\t\t\toutput_pushme,\n> +\t\t\toutput_pushme,\n> +\t\t\t....htlc_output's...\n> +\t\t- lock_time: 4 bytes\n> +\n>   Multiplying non-witness data by 4 results in a weight of:\n>   \n> -\t// 500 + 172 * num-htlc-outputs weight\n> +\t// 500 + 172 * num-htlc-outputs weight (no option_simplified_commitment)\n> +\t// 892 + 172 * num-htlc-outputs weight (option_simplified_commitment)\n>   \tcommitment_transaction_weight = 4 * commitment_transaction\n>   \n>   \t// 224 weight\n>   \twitness_weight = witness_header + witness\n>   \n> -\toverall_weight = 500 + 172 * num-htlc-outputs + 224 weight\n> +\toverall_weight (no option_simplified_commitment) = 500 + 172 * num-htlc-outputs + 224 weight\n> +\toverall_weight (option_simplified_commitment) = 892 + 172 * num-htlc-outputs + 224 weight\n>   \n>   ## Expected Weight of HTLC-timeout and HTLC-success Transactions\n>   \n> diff --git a/05-onchain.md b/05-onchain.md\n> index 231c209..c5fb5e1 100644\n> --- a/05-onchain.md\n> +++ b/05-onchain.md\n> @@ -89,21 +89,29 @@ trigger any action.\n>   # Commitment Transaction\n>   \n>   The local and remote nodes each hold a *commitment transaction*. Each of these\n> -commitment transactions has four types of outputs:\n> +commitment transactions has six types of outputs:\n>   \n>   1. _local node's main output_: Zero or one output, to pay to the *local node's*\n> -commitment pubkey.\n> +delayed pubkey.\n>   2. _remote node's main output_: Zero or one output, to pay to the *remote node's*\n> -commitment pubkey.\n> +pubkey.\n> +1. _local node's push output_: Zero or one output, to pay to the *local node's*\n> +delayed pubkey.\n> +2. _remote node's push output_: Zero or one output, to pay to the *remote node's*\n> +pubkey.\n>   3. _local node's offered HTLCs_: Zero or more pending payments (*HTLCs*), to pay\n>   the *remote node* in return for a payment preimage.\n>   4. _remote node's offered HTLCs_: Zero or more pending payments (*HTLCs*), to\n>   pay the *local node* in return for a payment preimage.\n>   \n>   To incentivize the local and remote nodes to cooperate, an `OP_CHECKSEQUENCEVERIFY`\n> -relative timeout encumbers the *local node's outputs* (in the *local node's\n> +relative timeout encumbers some outputs: the *local node's outputs* (in the *local node's\n>   commitment transaction*) and the *remote node's outputs* (in the *remote node's\n> -commitment transaction*). So for example, if the local node publishes its\n> +commitment transaction*). If `option_simplified_commitment` applies\n> +to the commitment transaction, then the *to_remote* output of each commitment is\n> +identically encumbered, for fairness.\n> +\n> +Without `option_simplified_commitment`, if the local node publishes its\n>   commitment transaction, it will have to wait to claim its own funds,\n>   whereas the remote node will have immediate access to its own funds. As a\n>   consequence, the two commitment transactions are not identical, but they are\n> @@ -140,6 +148,11 @@ A node:\n>         - otherwise:\n>           - MUST use the *last commitment transaction*, for which it has a\n>           signature, to perform a *unilateral close*.\n> +      - MUST spend any `to_local_pushme` output, providing sufficient fees as incentive to include the commitment transaction in a block\n> +\t    - SHOULD use [replace-by-fee](https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki) or other mechanism on the spending transaction if it proves insufficient for timely inclusion in a block.\n> +\n> +A node:\n> +  - MAY monitor the blockchain for unspent `to_local_pushme` and `to_remote_pushme` outputs and try to spend them after 10 confirmations.\n>   \n>   ## Rationale\n>   \n> @@ -154,7 +167,8 @@ need not consume resources monitoring the channel state.\n>   There exists a bias towards preferring mutual closes over unilateral closes,\n>   because outputs of the former are unencumbered by a delay and are directly\n>   spendable by wallets. In addition, mutual close fees tend to be less exaggerated\n> -than those of commitment transactions. So, the only reason not to use the\n> +than those of commitment transactions (or in the case of `option_simplified_commitment`,\n> +the commitment transaction may require a child transaction to cause it to be mined). So, the only reason not to use the\n>   signature from `closing_signed` would be if the fee offered was too small for\n>   it to be processed.\n>   \n> diff --git a/09-features.md b/09-features.md\n> index d06fcff..caea38b 100644\n> --- a/09-features.md\n> +++ b/09-features.md\n> @@ -26,6 +26,7 @@ These flags may only be used in the `init` message:\n>   | 3  | `initial_routing_sync` | Indicates that the sending node needs a complete routing information dump | [BOLT #7](07-routing-gossip.md#initial-sync) |\n>   | 4/5  | `option_upfront_shutdown_script` | Commits to a shutdown scriptpubkey when opening channel | [BOLT #2](02-peer-protocol.md#the-open_channel-message) |\n>   | 6/7  | `gossip_queries`           | More sophisticated gossip control | [BOLT #7](07-routing-gossip.md#query-messages) |\n> +| 8/9  | `option_simplified_commitment`           | Simplified commitment transactions | [BOLT #3](03-transactions.md) |\n>   \n>   ## Assigned `globalfeatures` flags\n>   \n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>"
            },
            {
                "author": "Matt Corallo",
                "date": "2018-11-21T17:55:33",
                "message_text_only": "Oh, also, obviously, the HTLC transactions need a pushme output, though \nluckily only one for the side we expect to be broadcasting the transaction.\n\nOn 11/21/18 2:54 AM, Matt Corallo wrote:\n> Not sure if others already realized this, but in thinking about our RBF \n> policy hack from Adelaide a bit more, to allow the carve-out exception \n> of \"last tx in a package, which has only one unconfirmed ancestor\" to \n> always be available for the \"honest party\" when broadcasting a \n> commitment transaction, we also need at least a CSV delay of 1 block on \n> the HTLC transaction outputs (as otherwise those transactions could \n> count as the carve-out tx).\n> \n> Matt\n> \n> On 11/21/18 2:17 AM, Rusty Russell wrote:\n>> I'm also starting to implement this, to see what I missed!\n>>\n>> Original at https://github.com/lightningnetwork/lightning-rfc/pull/513\n>>\n>> Pasted here for your reading convenience:\n>>\n>> - Option is sticky; it set at open time, it stays with channel\n>> \u00a0\u00a0 - I didn't want to have to handle penalty txs on channels which switch\n>> \u00a0\u00a0 - We could, however, upgrade on splice.\n>> - Feerate is fixed at 253\n>> \u00a0\u00a0 - `feerate_per_kw` is still in open /accept (just ignored): \n>> multifund may want it.\n>> - closing tx negotiates *upwards* not *downwards*\n>> \u00a0\u00a0 - Starting from base fee of commitment tx = 282 satoshi.\n>> - to_remote output is always CSV delayed.\n>> - pushme outputs are paid for by funder, but only exist if the matching\n>> \u00a0\u00a0 to_local/remote output exists.\n>> - After 10 blocks, they become anyone-can-spend (they need to see the\n>> \u00a0\u00a0 to-local/remote witness script though).\n>> - remotepubkey is not rotated.\n>> - You must spend your pushme output; you may sweep for others.\n>>\n>> Signed-off-by: Rusty Russell <rusty at rustcorp.com.au>\n>>\n>> diff --git a/02-peer-protocol.md b/02-peer-protocol.md\n>> index 7cf9ebf..6ec1155 100644\n>> --- a/02-peer-protocol.md\n>> +++ b/02-peer-protocol.md\n>> @@ -133,7 +133,9 @@ node can offer.\n>> \u00a0 (i.e. 1/4 the more normally-used 'satoshi per 1000 vbytes') that this\n>> \u00a0 side will pay for commitment and HTLC transactions, as described in\n>> \u00a0 [BOLT #3](03-transactions.md#fee-calculation) (this can be adjusted\n>> -later with an `update_fee` message).\n>> +later with an `update_fee` message).\u00a0 Note that if\n>> +`option_simplified_commitment` is negotiated, this `feerate_per_kw`\n>> +is treated as 253 for all transactions.\n>> \u00a0 `to_self_delay` is the number of blocks that the other node's to-self\n>> \u00a0 outputs must be delayed, using `OP_CHECKSEQUENCEVERIFY` delays; this\n>> @@ -208,7 +210,8 @@ The receiving node MUST fail the channel if:\n>> \u00a0\u00a0\u00a0 - `push_msat` is greater than `funding_satoshis` * 1000.\n>> \u00a0\u00a0\u00a0 - `to_self_delay` is unreasonably large.\n>> \u00a0\u00a0\u00a0 - `max_accepted_htlcs` is greater than 483.\n>> -\u00a0 - it considers `feerate_per_kw` too small for timely processing or \n>> unreasonably large.\n>> +\u00a0 - if `option_simplified_commitment` is not negotiated:\n>> +\u00a0\u00a0\u00a0 - it considers `feerate_per_kw` too small for timely processing \n>> or unreasonably large.\n>> \u00a0\u00a0\u00a0 - `funding_pubkey`, `revocation_basepoint`, `htlc_basepoint`, \n>> `payment_basepoint`, or `delayed_payment_basepoint`\n>> \u00a0 are not valid DER-encoded compressed secp256k1 pubkeys.\n>> \u00a0\u00a0\u00a0 - `dust_limit_satoshis` is greater than `channel_reserve_satoshis`.\n>> @@ -228,7 +231,7 @@ The *channel reserve* is specified by the peer's \n>> `channel_reserve_satoshis`: 1%\n>> \u00a0 The sender can unconditionally give initial funds to the receiver \n>> using a non-zero `push_msat`, but even in this case we ensure that the \n>> funder has sufficient remaining funds to pay fees and that one side \n>> has some amount it can spend (which also implies there is at least one \n>> non-dust output). Note that, like any other on-chain transaction, this \n>> payment is not certain until the funding transaction has been \n>> confirmed sufficiently (with a danger of double-spend until this \n>> occurs) and may require a separate method to prove payment via \n>> on-chain confirmation.\n>> -The `feerate_per_kw` is generally only of concern to the sender (who \n>> pays the fees), but there is also the fee rate paid by HTLC \n>> transactions; thus, unreasonably large fee rates can also penalize the \n>> recipient.\n>> +The `feerate_per_kw` is generally only of concern to the sender (who \n>> pays the fees), but there is also the fee rate paid by HTLC \n>> transactions; thus, unreasonably large fee rates can also penalize the \n>> recipient.\u00a0 It is ignored for `option_simplified_commitment`.\n>> \u00a0 Separating the `htlc_basepoint` from the `payment_basepoint` \n>> improves security: a node needs the secret associated with the \n>> `htlc_basepoint` to produce HTLC signatures for the protocol, but the \n>> secret for the `payment_basepoint` can be in cold storage.\n>> @@ -340,6 +343,12 @@ This message introduces the `channel_id` to \n>> identify the channel. It's derived f\n>> \u00a0 #### Requirements\n>> +Both peers:\n>> +\u00a0 - if `option_simplified_commitment` was negotiated:\n>> +\u00a0\u00a0\u00a0 - `option_simplified_commitment` applies to all commitment and \n>> HTLC transactions\n>> +\u00a0 - otherwise:\n>> +\u00a0\u00a0\u00a0 - `option_simplified_commitment` does not apply to any commitment \n>> or HTLC transactions\n>> +\n>> \u00a0 The sender MUST set:\n>> \u00a0\u00a0\u00a0 - `channel_id` by exclusive-OR of the `funding_txid` and the \n>> `funding_output_index` from the `funding_created` message.\n>> \u00a0\u00a0\u00a0 - `signature` to the valid signature, using its `funding_pubkey` \n>> for the initial commitment transaction, as defined in [BOLT \n>> #3](03-transactions.md#commitment-transaction).\n>> @@ -351,6 +360,12 @@ The recipient:\n>> \u00a0\u00a0\u00a0 - on receipt of a valid `funding_signed`:\n>> \u00a0\u00a0\u00a0\u00a0\u00a0 - SHOULD broadcast the funding transaction.\n>> +#### Rationale\n>> +\n>> +We decide on `option_simplified_commitment` at this point when we \n>> first have to generate the commitment\n>> +transaction.\u00a0 Even if a later reconnection does not negotiate this \n>> parameter, this channel will honor it.\n>> +This simplifies channel state, particularly penalty transaction \n>> handling.\n>> +\n>> \u00a0 ### The `funding_locked` Message\n>> \u00a0 This message indicates that the funding transaction has reached the \n>> `minimum_depth` asked for in `accept_channel`. Once both nodes have \n>> sent this, the channel enters normal operating mode.\n>> @@ -508,8 +523,11 @@ The funding node:\n>> \u00a0\u00a0\u00a0\u00a0\u00a0 - SHOULD send a `closing_signed` message.\n>> \u00a0 The sending node:\n>> -\u00a0 - MUST set `fee_satoshis` less than or equal to the\n>> - base fee of the final commitment transaction, as calculated in [BOLT \n>> #3](03-transactions.md#fee-calculation).\n>> +\u00a0 - if `option_upfront_shutdown_script` applies to the final \n>> commitment transaction:\n>> +\u00a0\u00a0\u00a0 - MUST set `fee_satoshis` greater than or equal to 282.\n>> +\u00a0 - otherwise:\n>> +\u00a0\u00a0\u00a0 - MUST set `fee_satoshis` less than or equal to the\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0 base fee of the final commitment transaction, as calculated in \n>> [BOLT #3](03-transactions.md#fee-calculation).\n>> \u00a0\u00a0\u00a0 - SHOULD set the initial `fee_satoshis` according to its\n>> \u00a0\u00a0 estimate of cost of inclusion in a block.\n>> \u00a0\u00a0\u00a0 - MUST set `signature` to the Bitcoin signature of the close\n>> @@ -543,9 +561,18 @@ progress is made, even if only by a single \n>> satoshi at a time. To avoid\n>> \u00a0 keeping state and to handle the corner case, where fees have shifted\n>> \u00a0 between disconnection and reconnection, negotiation restarts on \n>> reconnection.\n>> -Note there is limited risk if the closing transaction is\n>> -delayed, but it will be broadcast very soon; so there is usually no\n>> -reason to pay a premium for rapid processing.\n>> +In the `option_simplified_commitment` case, the fees on the commitment\n>> +transaction itself are minimal (it is assumed that a child \n>> transaction will\n>> +supply additional fee incentive), so that forms a floor for negotiation.\n>> +[BOLT #3](03-transactions.md#fee-calculation), gives 282 satoshis (1116\n>> +weight, 254 `feerate_per_kw`).\n>> +\n>> +Otherwise, the commitment transaction usually pays a premium fee, so \n>> that\n>> +forms a ceiling.\n>> +\n>> +Note there is limited risk if the closing transaction is delayed, but \n>> it will\n>> +be broadcast very soon; so there is usually no reason to pay a \n>> premium for\n>> +rapid processing.\n>> \u00a0 ## Normal Operation\n>> @@ -763,7 +790,10 @@ is destined, is described in [BOLT \n>> #4](04-onion-routing.md).\n>> \u00a0 A sending node:\n>> \u00a0\u00a0\u00a0 - MUST NOT offer `amount_msat` it cannot pay for in the\n>> \u00a0 remote commitment transaction at the current `feerate_per_kw` (see \n>> \"Updating\n>> -Fees\") while maintaining its channel reserve.\n>> +Fees\") while maintaining its channel reserve\n>> +\u00a0 - if `option_simplified_commitment` applies to this commitment \n>> transaction and the sending\n>> +\u00a0\u00a0\u00a0 node is the funder:\n>> +\u00a0\u00a0\u00a0 - MUST be able to additionally pay for `to_local_pushme` and \n>> `to_remote_pushme` above its reserve.\n>> \u00a0\u00a0\u00a0 - MUST offer `amount_msat` greater than 0.\n>> \u00a0\u00a0\u00a0 - MUST NOT offer `amount_msat` below the receiving node's \n>> `htlc_minimum_msat`\n>> \u00a0\u00a0\u00a0 - MUST set `cltv_expiry` less than 500000000.\n>> @@ -782,7 +812,7 @@ Fees\") while maintaining its channel reserve.\n>> \u00a0 A receiving node:\n>> \u00a0\u00a0\u00a0 - receiving an `amount_msat` equal to 0, OR less than its own \n>> `htlc_minimum_msat`:\n>> \u00a0\u00a0\u00a0\u00a0\u00a0 - SHOULD fail the channel.\n>> -\u00a0 - receiving an `amount_msat` that the sending node cannot afford at \n>> the current `feerate_per_kw` (while maintaining its channel reserve):\n>> +\u00a0 - receiving an `amount_msat` that the sending node cannot afford at \n>> the current `feerate_per_kw` (while maintaining its channel reserve \n>> and any `to_local_pushme` and `to_remote_pushme` fees):\n>> \u00a0\u00a0\u00a0\u00a0\u00a0 - SHOULD fail the channel.\n>> \u00a0\u00a0\u00a0 - if a sending node adds more than its `max_accepted_htlcs` HTLCs to\n>> \u00a0\u00a0\u00a0\u00a0\u00a0 its local commitment transaction, OR adds more than its \n>> `max_htlc_value_in_flight_msat` worth of offered HTLCs to its local \n>> commitment transaction:\n>> @@ -997,6 +1027,11 @@ A node:\n>> \u00a0 ### Updating Fees: `update_fee`\n>> +If `option_simplified_commitment` applies to the commitment transaction,\n>> +`update_fee` is never used: the `feerate_per_kw` is always considered \n>> 253, but\n>> +the funder also pays 2000 satoshi for the `to_local_pushme` and\n>> +`to_remote_pushme` outputs.\n>> +\n>> \u00a0 An `update_fee` message is sent by the node which is paying the\n>> \u00a0 Bitcoin fee. Like any update, it's first committed to the receiver's\n>> \u00a0 commitment transaction and then (once acknowledged) committed to the\n>> @@ -1020,13 +1055,19 @@ given in [BOLT \n>> #3](03-transactions.md#fee-calculation).\n>> \u00a0 #### Requirements\n>> \u00a0 The node _responsible_ for paying the Bitcoin fee:\n>> -\u00a0 - SHOULD send `update_fee` to ensure the current fee rate is \n>> sufficient (by a\n>> +\u00a0 - if `option_simplified_commitment` applies to the commitment \n>> transaction:\n>> +\u00a0\u00a0\u00a0 - MUST NOT send `update_fee`.\n>> +\u00a0 - otherwise:\n>> +\u00a0\u00a0\u00a0 - SHOULD send `update_fee` to ensure the current fee rate is \n>> sufficient (by a\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 significant margin) for timely processing of the commitment \n>> transaction.\n>> \u00a0 The node _not responsible_ for paying the Bitcoin fee:\n>> \u00a0\u00a0\u00a0 - MUST NOT send `update_fee`.\n>> \u00a0 A receiving node:\n>> +\u00a0 - if `option_simplified_commitment` applies to the commitment \n>> transaction:\n>> +\u00a0\u00a0\u00a0 - SHOULD fail the channel.\n>> +\u00a0\u00a0\u00a0 - MUST NOT update the `feerate_per_kw`.\n>> \u00a0\u00a0\u00a0 - if the `update_fee` is too low for timely processing, OR is \n>> unreasonably large:\n>> \u00a0\u00a0\u00a0\u00a0\u00a0 - SHOULD fail the channel.\n>> \u00a0\u00a0\u00a0 - if the sender is not responsible for paying the Bitcoin fee:\n>> @@ -1038,7 +1079,12 @@ A receiving node:\n>> \u00a0 #### Rationale\n>> -Bitcoin fees are required for unilateral closes to be effective \u2014\n>> +Fee adjustments are unnecessary for `option_simplified_commitment` which\n>> +relies on \"pushme\" outputs and a child transaction which will provide\n>> +additional fee incentive which can be calculated at the time it is \n>> spent, and\n>> +replaced by higher-fee children if required.\n>> +\n>> +Without this option, bitcoin fees are required for unilateral closes \n>> to be effective \u2014\n>> \u00a0 particularly since there is no general method for the broadcasting \n>> node to use\n>> \u00a0 child-pays-for-parent to increase its effective fee.\n>> diff --git a/03-transactions.md b/03-transactions.md\n>> index e769961..440bd0d 100644\n>> --- a/03-transactions.md\n>> +++ b/03-transactions.md\n>> @@ -82,6 +82,8 @@ To allow an opportunity for penalty transactions, in \n>> case of a revoked commitmen\n>> \u00a0 The reason for the separate transaction stage for HTLC outputs is so \n>> that HTLCs can timeout or be fulfilled even though they are within the \n>> `to_self_delay` delay.\n>> \u00a0 Otherwise, the required minimum timeout on HTLCs is lengthened by \n>> this delay, causing longer timeouts for HTLCs traversing the network.\n>> +If `option_simplified_commitment` applies to the commitment \n>> transaction, then the `to_self_delay` used for all transactions is the \n>> greater of the `to_self_delay` sent by each peer.\u00a0 Otherwise, each \n>> peer sends the `to_self_delay` to be used for the other peer's \n>> commitment amd HTLC transactions.\n>> +\n>> \u00a0 The amounts for each output MUST be rounded down to whole satoshis. \n>> If this amount, minus the fees for the HTLC transaction, is less than \n>> the `dust_limit_satoshis` set by the owner of the commitment \n>> transaction, the output MUST NOT be produced (thus the funds add to \n>> fees).\n>> \u00a0 #### `to_local` Output\n>> @@ -109,7 +111,40 @@ If a revoked commitment transaction is published, \n>> the other party can spend this\n>> \u00a0 #### `to_remote` Output\n>> -This output sends funds to the other peer and thus is a simple P2WPKH \n>> to `remotepubkey`.\n>> +This output sends funds to the other peer, thus is not encumbered by a\n>> +revocation private key.\n>> +\n>> +If `option_simplified_commitment` applies to the commitment \n>> transaction, the `to_remote` output is delayed similarly to the \n>> `to_local` output, and is to a fixed key:\n>> +\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 `to_self_delay`\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 OP_CSV\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 OP_DROP\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <remote_pubkey>\n>> +\n>> +The output is spent by a transaction with `nSequence` field set to \n>> `to_self_delay` (which can only be valid after that duration has \n>> passed) and witness:\n>> +\n>> +\u00a0\u00a0\u00a0 <remote_sig>\n>> +\n>> +Otherwise, this output is a simple P2WPKH to `remotepubkey`.\n>> +\n>> +\n>> +#### `to_local_pushme` and `to_remote_pushme` Output \n>> (option_simplified_commitment)\n>> +\n>> +This output can be spent by the local and remote nodes respectivey to \n>> provide incentive to mine the transaction, using \n>> child-pays-for-parent.\u00a0 They are only added if the `to_local` and \n>> `to_remote` outputs exist, respectively.\n>> +\n>> +\u00a0\u00a0\u00a0 OP_DEPTH\n>> +\u00a0\u00a0\u00a0 OP_IF\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <pubkey> OP_CHECKSIG\n>> +\u00a0\u00a0\u00a0 OP_ELSE\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 10 OP_CSV\n>> +\u00a0\u00a0\u00a0 OP_ENDIF\n>> +\n>> +The `<pubkey>` is `<local_delayedpubkey>` to `to_local_pushme` and\n>> +`<remote_delayedpubkey>` for `to_remote_pushme`.\u00a0 The output amount is\n>> +1000 satoshi, to encourage spending of the output.\u00a0 Once the\n>> +`remote_pubkey` is revealed (by spending the `to_local` output) and\n>> +the commitment transaction is 10 blocks deep, anyone can spend it.\n>> +\n>> \u00a0 #### Offered HTLC Outputs\n>> @@ -294,6 +329,9 @@ The fee calculation for both commitment \n>> transactions and HTLC\n>> \u00a0 transactions is based on the current `feerate_per_kw` and the\n>> \u00a0 *expected weight* of the transaction.\n>> +Note that if `option_simplified_commitment` applies to the commitment\n>> +transaction then `feerate_per_kw` is 253.\n>> +\n>> \u00a0 The actual and expected weights vary for several reasons:\n>> \u00a0 * Bitcoin uses DER-encoded signatures, which vary in size.\n>> @@ -306,10 +344,12 @@ Thus, a simplified formula for *expected weight* \n>> is used, which assumes:\n>> \u00a0 * Signatures are 73 bytes long (the maximum length).\n>> \u00a0 * There are a small number of outputs (thus 1 byte to count them).\n>> \u00a0 * There are always both a `to_local` output and a `to_remote` output.\n>> +* (if `option_simplified_commitment`) there are always both a \n>> `to_local_pushme` and `to_remote_pushme` output.\n>> \u00a0 This yields the following *expected weights* (details of the \n>> computation in [Appendix A](#appendix-a-expected-weights)):\n>> -\u00a0\u00a0\u00a0 Commitment weight:\u00a0\u00a0 724 + 172 * num-untrimmed-htlc-outputs\n>> +\u00a0\u00a0\u00a0 Commitment weight (no option_simplified_commitment):\u00a0\u00a0 724 + 172 \n>> * num-untrimmed-htlc-outputs\n>> +\u00a0\u00a0\u00a0 Commitment weight (option_simplified_commitment:\u00a0 1116 + 172 * \n>> num-untrimmed-htlc-outputs\n>> \u00a0\u00a0\u00a0\u00a0\u00a0 HTLC-timeout weight: 663\n>> \u00a0\u00a0\u00a0\u00a0\u00a0 HTLC-success weight: 703\n>> @@ -366,7 +406,7 @@ outputs) is 7140 satoshi. The final fee may be \n>> even higher if the\n>> \u00a0 ### Fee Payment\n>> -Base commitment transaction fees are extracted from the funder's \n>> amount; if that amount is insufficient, the entire amount of the \n>> funder's output is used.\n>> +Base commitment transaction fees and amounts for `to_local_pushme` \n>> and `to_remote_pushme` outputs are extracted from the funder's amount; \n>> if that amount is insufficient, the entire amount of the funder's \n>> output is used.\n>> \u00a0 Note that after the fee amount is subtracted from the to-funder output,\n>> \u00a0 that output may be below `dust_limit_satoshis`, and thus will also\n>> @@ -390,23 +430,29 @@ committed HTLCs:\n>> \u00a0 2. Calculate the base [commitment transaction fee](#fee-calculation).\n>> \u00a0 3. Subtract this base fee from the funder (either `to_local` or \n>> `to_remote`),\n>> \u00a0\u00a0\u00a0\u00a0 with a floor of 0 (see [Fee Payment](#fee-payment)).\n>> +4. If `option_simplified_commitment` applies to the commitment \n>> transaction,\n>> +\u00a0\u00a0 subtract 2000 satoshis from the funder (either `to_local` or \n>> `to_remote`).\n>> \u00a0 3. For every offered HTLC, if it is not trimmed, add an\n>> \u00a0\u00a0\u00a0\u00a0 [offered HTLC output](#offered-htlc-outputs).\n>> \u00a0 4. For every received HTLC, if it is not trimmed, add an\n>> \u00a0\u00a0\u00a0\u00a0 [received HTLC output](#received-htlc-outputs).\n>> \u00a0 5. If the `to_local` amount is greater or equal to \n>> `dust_limit_satoshis`,\n>> \u00a0\u00a0\u00a0\u00a0 add a [`to_local` output](#to_local-output).\n>> +6. If `option_simplified_commitment` applies to the commitment \n>> transaction,\n>> +\u00a0\u00a0 and `to_local` was added, add `to_local_pushme`.\n>> \u00a0 6. If the `to_remote` amount is greater or equal to \n>> `dust_limit_satoshis`,\n>> \u00a0\u00a0\u00a0\u00a0 add a [`to_remote` output](#to_remote-output).\n>> +6. If `option_simplified_commitment` applies to the commitment \n>> transaction,\n>> +\u00a0\u00a0 and `to_remote` was added, add `to_remote_pushme`.\n>> \u00a0 7. Sort the outputs into [BIP 69 \n>> order](#transaction-input-and-output-ordering).\n>> \u00a0 # Keys\n>> \u00a0 ## Key Derivation\n>> -Each commitment transaction uses a unique set of keys: `localpubkey` \n>> and `remotepubkey`.\n>> +Each commitment transaction uses a unique `localpubkey`, and a \n>> `remotepubkey`.\n>> \u00a0 The HTLC-success and HTLC-timeout transactions use \n>> `local_delayedpubkey` and `revocationpubkey`.\n>> -These are changed for every transaction based on the \n>> `per_commitment_point`.\n>> +These are changed for every transaction based on the \n>> `per_commitment_point`, with the exception of `remotepubkey` if \n>> `option_simplified_commitment` is negotiated.\n>> \u00a0 The reason for key change is so that trustless watching for revoked\n>> \u00a0 transactions can be outsourced. Such a _watcher_ should not be able to\n>> @@ -419,8 +465,9 @@ avoid storage of every commitment transaction, a \n>> _watcher_ can be given the\n>> \u00a0 the scripts required for the penalty transaction; thus, a _watcher_ \n>> need only be\n>> \u00a0 given (and store) the signatures for each penalty input.\n>> -Changing the `localpubkey` and `remotepubkey` every time ensures that \n>> commitment\n>> -transaction ID cannot be guessed; every commitment transaction uses \n>> an ID\n>> +Changing the `localpubkey` every time ensures that commitment\n>> +transaction ID cannot be guessed except in the trivial case where \n>> there is no\n>> +`to_local` output, as every commitment transaction uses an ID\n>> \u00a0 in its output script. Splitting the `local_delayedpubkey`, which is \n>> required for\n>> \u00a0 the penalty transaction, allows it to be shared with the _watcher_ \n>> without\n>> \u00a0 revealing `localpubkey`; even if both peers use the same _watcher_, \n>> nothing is revealed.\n>> @@ -434,14 +481,13 @@ For efficiency, keys are generated from a series \n>> of per-commitment secrets\n>> \u00a0 that are generated from a single seed, which allows the receiver to \n>> compactly\n>> \u00a0 store them (see [below](#efficient-per-commitment-secret-storage)).\n>> -### `localpubkey`, `remotepubkey`, `local_htlcpubkey`, \n>> `remote_htlcpubkey`, `local_delayedpubkey`, and `remote_delayedpubkey` \n>> Derivation\n>> +### `localpubkey``local_htlcpubkey`, `remote_htlcpubkey`, \n>> `local_delayedpubkey`, and `remote_delayedpubkey` Derivation\n>> \u00a0 These pubkeys are simply generated by addition from their base points:\n>> \u00a0\u00a0\u00a0\u00a0\u00a0 pubkey = basepoint + SHA256(per_commitment_point || basepoint) * G\n>> -The `localpubkey` uses the local node's `payment_basepoint`; the \n>> `remotepubkey`\n>> -uses the remote node's `payment_basepoint`; the `local_delayedpubkey`\n>> +The `localpubkey` uses the local node's `payment_basepoint`; the \n>> `local_delayedpubkey`\n>> \u00a0 uses the local node's `delayed_payment_basepoint`; the \n>> `local_htlcpubkey` uses the\n>> \u00a0 local node's `htlc_basepoint`; and the `remote_delayedpubkey` uses \n>> the remote\n>> \u00a0 node's `delayed_payment_basepoint`.\n>> @@ -451,6 +497,17 @@ secrets are known (i.e. the private keys \n>> corresponding to `localpubkey`, `local_\n>> \u00a0\u00a0\u00a0\u00a0\u00a0 privkey = basepoint_secret + SHA256(per_commitment_point || \n>> basepoint)\n>> +### `remotepubkey` Derivation\n>> +\n>> +If `option_simplified_commitment` is negotiated the `remotepubkey` is \n>> simply the remote node's `payment_basepoint`, otherwise it is \n>> calculated as above using the remote node's `payment_basepoint`.\n>> +\n>> +The simplified derivation means that a node can spend a commitment\n>> +transaction even if it has lost data and doesn't know the\n>> +corresponding `payment_basepoint`.\u00a0 A watchtower could correlate\n>> +transactions given to it which only have a `to_remote` output if it\n>> +sees one of them onchain, but such transactions do not need any\n>> +enforcement and should not be handed to a watchtower.\n>> +\n>> \u00a0 ### `revocationpubkey` Derivation\n>> \u00a0 The `revocationpubkey` is a blinded key: when the local node wishes \n>> to create a new\n>> @@ -636,12 +693,22 @@ The *expected weight* of a commitment \n>> transaction is calculated as follows:\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - var_int: 1 byte (pk_script length)\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - pk_script (p2wsh): 34 bytes\n>> -\u00a0\u00a0\u00a0 output_paying_to_remote: 31 bytes\n>> +\u00a0\u00a0\u00a0 output_paying_to_remote (no option_simplified_commitment): 31 bytes\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - value: 8 bytes\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - var_int: 1 byte (pk_script length)\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - pk_script (p2wpkh): 22 bytes\n>> -\u00a0\u00a0\u00a0\u00a0 htlc_output: 43 bytes\n>> +\u00a0\u00a0\u00a0 output_paying_to_remote (option_simplified_commitment): 43 bytes\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - value: 8 bytes\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - var_int: 1 byte (pk_script length)\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - pk_script (p2wsh): 34 bytes\n>> +\n>> +\u00a0\u00a0\u00a0 output_pushme (option_simplified_commitment): 43 bytes\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - value: 8 bytes\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - var_int: 1 byte (pk_script length)\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - pk_script (p2wsh): 34 bytes\n>> +\n>> +\u00a0\u00a0\u00a0 htlc_output: 43 bytes\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - value: 8 bytes\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - var_int: 1 byte (pk_script length)\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - pk_script (p2wsh): 34 bytes\n>> @@ -650,7 +717,7 @@ The *expected weight* of a commitment transaction \n>> is calculated as follows:\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - flag: 1 byte\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - marker: 1 byte\n>> -\u00a0\u00a0\u00a0\u00a0 commitment_transaction: 125 + 43 * num-htlc-outputs bytes\n>> +\u00a0\u00a0\u00a0\u00a0 commitment_transaction (no option_simplified_commitment): 125 + \n>> 43 * num-htlc-outputs bytes\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - version: 4 bytes\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - witness_header <---- part of the witness data\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - count_tx_in: 1 byte\n>> @@ -663,15 +730,32 @@ The *expected weight* of a commitment \n>> transaction is calculated as follows:\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 ....htlc_output's...\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - lock_time: 4 bytes\n>> +\u00a0\u00a0\u00a0\u00a0 commitment_transaction (option_simplified_commitment): 223 + 43 \n>> * num-htlc-outputs bytes\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - version: 4 bytes\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - witness_header <---- part of the witness data\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - count_tx_in: 1 byte\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - tx_in: 41 bytes\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 funding_input\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - count_tx_out: 1 byte\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - tx_out: 172 + 43 * num-htlc-outputs bytes\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 output_paying_to_remote,\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 output_paying_to_local,\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 output_pushme,\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 output_pushme,\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 ....htlc_output's...\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - lock_time: 4 bytes\n>> +\n>> \u00a0 Multiplying non-witness data by 4 results in a weight of:\n>> -\u00a0\u00a0\u00a0 // 500 + 172 * num-htlc-outputs weight\n>> +\u00a0\u00a0\u00a0 // 500 + 172 * num-htlc-outputs weight (no \n>> option_simplified_commitment)\n>> +\u00a0\u00a0\u00a0 // 892 + 172 * num-htlc-outputs weight \n>> (option_simplified_commitment)\n>> \u00a0\u00a0\u00a0\u00a0\u00a0 commitment_transaction_weight = 4 * commitment_transaction\n>> \u00a0\u00a0\u00a0\u00a0\u00a0 // 224 weight\n>> \u00a0\u00a0\u00a0\u00a0\u00a0 witness_weight = witness_header + witness\n>> -\u00a0\u00a0\u00a0 overall_weight = 500 + 172 * num-htlc-outputs + 224 weight\n>> +\u00a0\u00a0\u00a0 overall_weight (no option_simplified_commitment) = 500 + 172 * \n>> num-htlc-outputs + 224 weight\n>> +\u00a0\u00a0\u00a0 overall_weight (option_simplified_commitment) = 892 + 172 * \n>> num-htlc-outputs + 224 weight\n>> \u00a0 ## Expected Weight of HTLC-timeout and HTLC-success Transactions\n>> diff --git a/05-onchain.md b/05-onchain.md\n>> index 231c209..c5fb5e1 100644\n>> --- a/05-onchain.md\n>> +++ b/05-onchain.md\n>> @@ -89,21 +89,29 @@ trigger any action.\n>> \u00a0 # Commitment Transaction\n>> \u00a0 The local and remote nodes each hold a *commitment transaction*. \n>> Each of these\n>> -commitment transactions has four types of outputs:\n>> +commitment transactions has six types of outputs:\n>> \u00a0 1. _local node's main output_: Zero or one output, to pay to the \n>> *local node's*\n>> -commitment pubkey.\n>> +delayed pubkey.\n>> \u00a0 2. _remote node's main output_: Zero or one output, to pay to the \n>> *remote node's*\n>> -commitment pubkey.\n>> +pubkey.\n>> +1. _local node's push output_: Zero or one output, to pay to the \n>> *local node's*\n>> +delayed pubkey.\n>> +2. _remote node's push output_: Zero or one output, to pay to the \n>> *remote node's*\n>> +pubkey.\n>> \u00a0 3. _local node's offered HTLCs_: Zero or more pending payments \n>> (*HTLCs*), to pay\n>> \u00a0 the *remote node* in return for a payment preimage.\n>> \u00a0 4. _remote node's offered HTLCs_: Zero or more pending payments \n>> (*HTLCs*), to\n>> \u00a0 pay the *local node* in return for a payment preimage.\n>> \u00a0 To incentivize the local and remote nodes to cooperate, an \n>> `OP_CHECKSEQUENCEVERIFY`\n>> -relative timeout encumbers the *local node's outputs* (in the *local \n>> node's\n>> +relative timeout encumbers some outputs: the *local node's outputs* \n>> (in the *local node's\n>> \u00a0 commitment transaction*) and the *remote node's outputs* (in the \n>> *remote node's\n>> -commitment transaction*). So for example, if the local node publishes \n>> its\n>> +commitment transaction*). If `option_simplified_commitment` applies\n>> +to the commitment transaction, then the *to_remote* output of each \n>> commitment is\n>> +identically encumbered, for fairness.\n>> +\n>> +Without `option_simplified_commitment`, if the local node publishes its\n>> \u00a0 commitment transaction, it will have to wait to claim its own funds,\n>> \u00a0 whereas the remote node will have immediate access to its own funds. \n>> As a\n>> \u00a0 consequence, the two commitment transactions are not identical, but \n>> they are\n>> @@ -140,6 +148,11 @@ A node:\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - otherwise:\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - MUST use the *last commitment transaction*, for which it \n>> has a\n>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 signature, to perform a *unilateral close*.\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0 - MUST spend any `to_local_pushme` output, providing sufficient \n>> fees as incentive to include the commitment transaction in a block\n>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - SHOULD use \n>> [replace-by-fee](https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki) \n>> or other mechanism on the spending transaction if it proves \n>> insufficient for timely inclusion in a block.\n>> +\n>> +A node:\n>> +\u00a0 - MAY monitor the blockchain for unspent `to_local_pushme` and \n>> `to_remote_pushme` outputs and try to spend them after 10 confirmations.\n>> \u00a0 ## Rationale\n>> @@ -154,7 +167,8 @@ need not consume resources monitoring the channel \n>> state.\n>> \u00a0 There exists a bias towards preferring mutual closes over unilateral \n>> closes,\n>> \u00a0 because outputs of the former are unencumbered by a delay and are \n>> directly\n>> \u00a0 spendable by wallets. In addition, mutual close fees tend to be less \n>> exaggerated\n>> -than those of commitment transactions. So, the only reason not to use \n>> the\n>> +than those of commitment transactions (or in the case of \n>> `option_simplified_commitment`,\n>> +the commitment transaction may require a child transaction to cause \n>> it to be mined). So, the only reason not to use the\n>> \u00a0 signature from `closing_signed` would be if the fee offered was too \n>> small for\n>> \u00a0 it to be processed.\n>> diff --git a/09-features.md b/09-features.md\n>> index d06fcff..caea38b 100644\n>> --- a/09-features.md\n>> +++ b/09-features.md\n>> @@ -26,6 +26,7 @@ These flags may only be used in the `init` message:\n>> \u00a0 | 3\u00a0 | `initial_routing_sync` | Indicates that the sending node \n>> needs a complete routing information dump | [BOLT \n>> #7](07-routing-gossip.md#initial-sync) |\n>> \u00a0 | 4/5\u00a0 | `option_upfront_shutdown_script` | Commits to a shutdown \n>> scriptpubkey when opening channel | [BOLT \n>> #2](02-peer-protocol.md#the-open_channel-message) |\n>> \u00a0 | 6/7\u00a0 | `gossip_queries`\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 | More sophisticated gossip \n>> control | [BOLT #7](07-routing-gossip.md#query-messages) |\n>> +| 8/9\u00a0 | `option_simplified_commitment`\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 | Simplified \n>> commitment transactions | [BOLT #3](03-transactions.md) |\n>> \u00a0 ## Assigned `globalfeatures` flags\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-21T22:45:23",
                "message_text_only": "Matt Corallo <lf-lists at mattcorallo.com> writes:\n> Oh, also, obviously, the HTLC transactions need a pushme output, though \n> luckily only one for the side we expect to be broadcasting the transaction.\n\nThe intent was that HTLC transactions are now\nSIGHASH_SINGLE|SIGHASH_ANYONECANPAY (since we don't need the txid), so\nyou Bring Your Own Fees.\n\nI missed this in the draft, patch coming...\n\nCheers,\nRusty.\n\n> On 11/21/18 2:54 AM, Matt Corallo wrote:\n>> Not sure if others already realized this, but in thinking about our RBF \n>> policy hack from Adelaide a bit more, to allow the carve-out exception \n>> of \"last tx in a package, which has only one unconfirmed ancestor\" to \n>> always be available for the \"honest party\" when broadcasting a \n>> commitment transaction, we also need at least a CSV delay of 1 block on \n>> the HTLC transaction outputs (as otherwise those transactions could \n>> count as the carve-out tx).\n>> \n>> Matt\n>> \n>> On 11/21/18 2:17 AM, Rusty Russell wrote:\n>>> I'm also starting to implement this, to see what I missed!\n>>>\n>>> Original at https://github.com/lightningnetwork/lightning-rfc/pull/513\n>>>\n>>> Pasted here for your reading convenience:\n>>>\n>>> - Option is sticky; it set at open time, it stays with channel\n>>> \u00a0\u00a0 - I didn't want to have to handle penalty txs on channels which switch\n>>> \u00a0\u00a0 - We could, however, upgrade on splice.\n>>> - Feerate is fixed at 253\n>>> \u00a0\u00a0 - `feerate_per_kw` is still in open /accept (just ignored): \n>>> multifund may want it.\n>>> - closing tx negotiates *upwards* not *downwards*\n>>> \u00a0\u00a0 - Starting from base fee of commitment tx = 282 satoshi.\n>>> - to_remote output is always CSV delayed.\n>>> - pushme outputs are paid for by funder, but only exist if the matching\n>>> \u00a0\u00a0 to_local/remote output exists.\n>>> - After 10 blocks, they become anyone-can-spend (they need to see the\n>>> \u00a0\u00a0 to-local/remote witness script though).\n>>> - remotepubkey is not rotated.\n>>> - You must spend your pushme output; you may sweep for others.\n>>>\n>>> Signed-off-by: Rusty Russell <rusty at rustcorp.com.au>\n>>>\n>>> diff --git a/02-peer-protocol.md b/02-peer-protocol.md\n>>> index 7cf9ebf..6ec1155 100644\n>>> --- a/02-peer-protocol.md\n>>> +++ b/02-peer-protocol.md\n>>> @@ -133,7 +133,9 @@ node can offer.\n>>> \u00a0 (i.e. 1/4 the more normally-used 'satoshi per 1000 vbytes') that this\n>>> \u00a0 side will pay for commitment and HTLC transactions, as described in\n>>> \u00a0 [BOLT #3](03-transactions.md#fee-calculation) (this can be adjusted\n>>> -later with an `update_fee` message).\n>>> +later with an `update_fee` message).\u00a0 Note that if\n>>> +`option_simplified_commitment` is negotiated, this `feerate_per_kw`\n>>> +is treated as 253 for all transactions.\n>>> \u00a0 `to_self_delay` is the number of blocks that the other node's to-self\n>>> \u00a0 outputs must be delayed, using `OP_CHECKSEQUENCEVERIFY` delays; this\n>>> @@ -208,7 +210,8 @@ The receiving node MUST fail the channel if:\n>>> \u00a0\u00a0\u00a0 - `push_msat` is greater than `funding_satoshis` * 1000.\n>>> \u00a0\u00a0\u00a0 - `to_self_delay` is unreasonably large.\n>>> \u00a0\u00a0\u00a0 - `max_accepted_htlcs` is greater than 483.\n>>> -\u00a0 - it considers `feerate_per_kw` too small for timely processing or \n>>> unreasonably large.\n>>> +\u00a0 - if `option_simplified_commitment` is not negotiated:\n>>> +\u00a0\u00a0\u00a0 - it considers `feerate_per_kw` too small for timely processing \n>>> or unreasonably large.\n>>> \u00a0\u00a0\u00a0 - `funding_pubkey`, `revocation_basepoint`, `htlc_basepoint`, \n>>> `payment_basepoint`, or `delayed_payment_basepoint`\n>>> \u00a0 are not valid DER-encoded compressed secp256k1 pubkeys.\n>>> \u00a0\u00a0\u00a0 - `dust_limit_satoshis` is greater than `channel_reserve_satoshis`.\n>>> @@ -228,7 +231,7 @@ The *channel reserve* is specified by the peer's \n>>> `channel_reserve_satoshis`: 1%\n>>> \u00a0 The sender can unconditionally give initial funds to the receiver \n>>> using a non-zero `push_msat`, but even in this case we ensure that the \n>>> funder has sufficient remaining funds to pay fees and that one side \n>>> has some amount it can spend (which also implies there is at least one \n>>> non-dust output). Note that, like any other on-chain transaction, this \n>>> payment is not certain until the funding transaction has been \n>>> confirmed sufficiently (with a danger of double-spend until this \n>>> occurs) and may require a separate method to prove payment via \n>>> on-chain confirmation.\n>>> -The `feerate_per_kw` is generally only of concern to the sender (who \n>>> pays the fees), but there is also the fee rate paid by HTLC \n>>> transactions; thus, unreasonably large fee rates can also penalize the \n>>> recipient.\n>>> +The `feerate_per_kw` is generally only of concern to the sender (who \n>>> pays the fees), but there is also the fee rate paid by HTLC \n>>> transactions; thus, unreasonably large fee rates can also penalize the \n>>> recipient.\u00a0 It is ignored for `option_simplified_commitment`.\n>>> \u00a0 Separating the `htlc_basepoint` from the `payment_basepoint` \n>>> improves security: a node needs the secret associated with the \n>>> `htlc_basepoint` to produce HTLC signatures for the protocol, but the \n>>> secret for the `payment_basepoint` can be in cold storage.\n>>> @@ -340,6 +343,12 @@ This message introduces the `channel_id` to \n>>> identify the channel. It's derived f\n>>> \u00a0 #### Requirements\n>>> +Both peers:\n>>> +\u00a0 - if `option_simplified_commitment` was negotiated:\n>>> +\u00a0\u00a0\u00a0 - `option_simplified_commitment` applies to all commitment and \n>>> HTLC transactions\n>>> +\u00a0 - otherwise:\n>>> +\u00a0\u00a0\u00a0 - `option_simplified_commitment` does not apply to any commitment \n>>> or HTLC transactions\n>>> +\n>>> \u00a0 The sender MUST set:\n>>> \u00a0\u00a0\u00a0 - `channel_id` by exclusive-OR of the `funding_txid` and the \n>>> `funding_output_index` from the `funding_created` message.\n>>> \u00a0\u00a0\u00a0 - `signature` to the valid signature, using its `funding_pubkey` \n>>> for the initial commitment transaction, as defined in [BOLT \n>>> #3](03-transactions.md#commitment-transaction).\n>>> @@ -351,6 +360,12 @@ The recipient:\n>>> \u00a0\u00a0\u00a0 - on receipt of a valid `funding_signed`:\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0 - SHOULD broadcast the funding transaction.\n>>> +#### Rationale\n>>> +\n>>> +We decide on `option_simplified_commitment` at this point when we \n>>> first have to generate the commitment\n>>> +transaction.\u00a0 Even if a later reconnection does not negotiate this \n>>> parameter, this channel will honor it.\n>>> +This simplifies channel state, particularly penalty transaction \n>>> handling.\n>>> +\n>>> \u00a0 ### The `funding_locked` Message\n>>> \u00a0 This message indicates that the funding transaction has reached the \n>>> `minimum_depth` asked for in `accept_channel`. Once both nodes have \n>>> sent this, the channel enters normal operating mode.\n>>> @@ -508,8 +523,11 @@ The funding node:\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0 - SHOULD send a `closing_signed` message.\n>>> \u00a0 The sending node:\n>>> -\u00a0 - MUST set `fee_satoshis` less than or equal to the\n>>> - base fee of the final commitment transaction, as calculated in [BOLT \n>>> #3](03-transactions.md#fee-calculation).\n>>> +\u00a0 - if `option_upfront_shutdown_script` applies to the final \n>>> commitment transaction:\n>>> +\u00a0\u00a0\u00a0 - MUST set `fee_satoshis` greater than or equal to 282.\n>>> +\u00a0 - otherwise:\n>>> +\u00a0\u00a0\u00a0 - MUST set `fee_satoshis` less than or equal to the\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0 base fee of the final commitment transaction, as calculated in \n>>> [BOLT #3](03-transactions.md#fee-calculation).\n>>> \u00a0\u00a0\u00a0 - SHOULD set the initial `fee_satoshis` according to its\n>>> \u00a0\u00a0 estimate of cost of inclusion in a block.\n>>> \u00a0\u00a0\u00a0 - MUST set `signature` to the Bitcoin signature of the close\n>>> @@ -543,9 +561,18 @@ progress is made, even if only by a single \n>>> satoshi at a time. To avoid\n>>> \u00a0 keeping state and to handle the corner case, where fees have shifted\n>>> \u00a0 between disconnection and reconnection, negotiation restarts on \n>>> reconnection.\n>>> -Note there is limited risk if the closing transaction is\n>>> -delayed, but it will be broadcast very soon; so there is usually no\n>>> -reason to pay a premium for rapid processing.\n>>> +In the `option_simplified_commitment` case, the fees on the commitment\n>>> +transaction itself are minimal (it is assumed that a child \n>>> transaction will\n>>> +supply additional fee incentive), so that forms a floor for negotiation.\n>>> +[BOLT #3](03-transactions.md#fee-calculation), gives 282 satoshis (1116\n>>> +weight, 254 `feerate_per_kw`).\n>>> +\n>>> +Otherwise, the commitment transaction usually pays a premium fee, so \n>>> that\n>>> +forms a ceiling.\n>>> +\n>>> +Note there is limited risk if the closing transaction is delayed, but \n>>> it will\n>>> +be broadcast very soon; so there is usually no reason to pay a \n>>> premium for\n>>> +rapid processing.\n>>> \u00a0 ## Normal Operation\n>>> @@ -763,7 +790,10 @@ is destined, is described in [BOLT \n>>> #4](04-onion-routing.md).\n>>> \u00a0 A sending node:\n>>> \u00a0\u00a0\u00a0 - MUST NOT offer `amount_msat` it cannot pay for in the\n>>> \u00a0 remote commitment transaction at the current `feerate_per_kw` (see \n>>> \"Updating\n>>> -Fees\") while maintaining its channel reserve.\n>>> +Fees\") while maintaining its channel reserve\n>>> +\u00a0 - if `option_simplified_commitment` applies to this commitment \n>>> transaction and the sending\n>>> +\u00a0\u00a0\u00a0 node is the funder:\n>>> +\u00a0\u00a0\u00a0 - MUST be able to additionally pay for `to_local_pushme` and \n>>> `to_remote_pushme` above its reserve.\n>>> \u00a0\u00a0\u00a0 - MUST offer `amount_msat` greater than 0.\n>>> \u00a0\u00a0\u00a0 - MUST NOT offer `amount_msat` below the receiving node's \n>>> `htlc_minimum_msat`\n>>> \u00a0\u00a0\u00a0 - MUST set `cltv_expiry` less than 500000000.\n>>> @@ -782,7 +812,7 @@ Fees\") while maintaining its channel reserve.\n>>> \u00a0 A receiving node:\n>>> \u00a0\u00a0\u00a0 - receiving an `amount_msat` equal to 0, OR less than its own \n>>> `htlc_minimum_msat`:\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0 - SHOULD fail the channel.\n>>> -\u00a0 - receiving an `amount_msat` that the sending node cannot afford at \n>>> the current `feerate_per_kw` (while maintaining its channel reserve):\n>>> +\u00a0 - receiving an `amount_msat` that the sending node cannot afford at \n>>> the current `feerate_per_kw` (while maintaining its channel reserve \n>>> and any `to_local_pushme` and `to_remote_pushme` fees):\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0 - SHOULD fail the channel.\n>>> \u00a0\u00a0\u00a0 - if a sending node adds more than its `max_accepted_htlcs` HTLCs to\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0 its local commitment transaction, OR adds more than its \n>>> `max_htlc_value_in_flight_msat` worth of offered HTLCs to its local \n>>> commitment transaction:\n>>> @@ -997,6 +1027,11 @@ A node:\n>>> \u00a0 ### Updating Fees: `update_fee`\n>>> +If `option_simplified_commitment` applies to the commitment transaction,\n>>> +`update_fee` is never used: the `feerate_per_kw` is always considered \n>>> 253, but\n>>> +the funder also pays 2000 satoshi for the `to_local_pushme` and\n>>> +`to_remote_pushme` outputs.\n>>> +\n>>> \u00a0 An `update_fee` message is sent by the node which is paying the\n>>> \u00a0 Bitcoin fee. Like any update, it's first committed to the receiver's\n>>> \u00a0 commitment transaction and then (once acknowledged) committed to the\n>>> @@ -1020,13 +1055,19 @@ given in [BOLT \n>>> #3](03-transactions.md#fee-calculation).\n>>> \u00a0 #### Requirements\n>>> \u00a0 The node _responsible_ for paying the Bitcoin fee:\n>>> -\u00a0 - SHOULD send `update_fee` to ensure the current fee rate is \n>>> sufficient (by a\n>>> +\u00a0 - if `option_simplified_commitment` applies to the commitment \n>>> transaction:\n>>> +\u00a0\u00a0\u00a0 - MUST NOT send `update_fee`.\n>>> +\u00a0 - otherwise:\n>>> +\u00a0\u00a0\u00a0 - SHOULD send `update_fee` to ensure the current fee rate is \n>>> sufficient (by a\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 significant margin) for timely processing of the commitment \n>>> transaction.\n>>> \u00a0 The node _not responsible_ for paying the Bitcoin fee:\n>>> \u00a0\u00a0\u00a0 - MUST NOT send `update_fee`.\n>>> \u00a0 A receiving node:\n>>> +\u00a0 - if `option_simplified_commitment` applies to the commitment \n>>> transaction:\n>>> +\u00a0\u00a0\u00a0 - SHOULD fail the channel.\n>>> +\u00a0\u00a0\u00a0 - MUST NOT update the `feerate_per_kw`.\n>>> \u00a0\u00a0\u00a0 - if the `update_fee` is too low for timely processing, OR is \n>>> unreasonably large:\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0 - SHOULD fail the channel.\n>>> \u00a0\u00a0\u00a0 - if the sender is not responsible for paying the Bitcoin fee:\n>>> @@ -1038,7 +1079,12 @@ A receiving node:\n>>> \u00a0 #### Rationale\n>>> -Bitcoin fees are required for unilateral closes to be effective \u2014\n>>> +Fee adjustments are unnecessary for `option_simplified_commitment` which\n>>> +relies on \"pushme\" outputs and a child transaction which will provide\n>>> +additional fee incentive which can be calculated at the time it is \n>>> spent, and\n>>> +replaced by higher-fee children if required.\n>>> +\n>>> +Without this option, bitcoin fees are required for unilateral closes \n>>> to be effective \u2014\n>>> \u00a0 particularly since there is no general method for the broadcasting \n>>> node to use\n>>> \u00a0 child-pays-for-parent to increase its effective fee.\n>>> diff --git a/03-transactions.md b/03-transactions.md\n>>> index e769961..440bd0d 100644\n>>> --- a/03-transactions.md\n>>> +++ b/03-transactions.md\n>>> @@ -82,6 +82,8 @@ To allow an opportunity for penalty transactions, in \n>>> case of a revoked commitmen\n>>> \u00a0 The reason for the separate transaction stage for HTLC outputs is so \n>>> that HTLCs can timeout or be fulfilled even though they are within the \n>>> `to_self_delay` delay.\n>>> \u00a0 Otherwise, the required minimum timeout on HTLCs is lengthened by \n>>> this delay, causing longer timeouts for HTLCs traversing the network.\n>>> +If `option_simplified_commitment` applies to the commitment \n>>> transaction, then the `to_self_delay` used for all transactions is the \n>>> greater of the `to_self_delay` sent by each peer.\u00a0 Otherwise, each \n>>> peer sends the `to_self_delay` to be used for the other peer's \n>>> commitment amd HTLC transactions.\n>>> +\n>>> \u00a0 The amounts for each output MUST be rounded down to whole satoshis. \n>>> If this amount, minus the fees for the HTLC transaction, is less than \n>>> the `dust_limit_satoshis` set by the owner of the commitment \n>>> transaction, the output MUST NOT be produced (thus the funds add to \n>>> fees).\n>>> \u00a0 #### `to_local` Output\n>>> @@ -109,7 +111,40 @@ If a revoked commitment transaction is published, \n>>> the other party can spend this\n>>> \u00a0 #### `to_remote` Output\n>>> -This output sends funds to the other peer and thus is a simple P2WPKH \n>>> to `remotepubkey`.\n>>> +This output sends funds to the other peer, thus is not encumbered by a\n>>> +revocation private key.\n>>> +\n>>> +If `option_simplified_commitment` applies to the commitment \n>>> transaction, the `to_remote` output is delayed similarly to the \n>>> `to_local` output, and is to a fixed key:\n>>> +\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 `to_self_delay`\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 OP_CSV\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 OP_DROP\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <remote_pubkey>\n>>> +\n>>> +The output is spent by a transaction with `nSequence` field set to \n>>> `to_self_delay` (which can only be valid after that duration has \n>>> passed) and witness:\n>>> +\n>>> +\u00a0\u00a0\u00a0 <remote_sig>\n>>> +\n>>> +Otherwise, this output is a simple P2WPKH to `remotepubkey`.\n>>> +\n>>> +\n>>> +#### `to_local_pushme` and `to_remote_pushme` Output \n>>> (option_simplified_commitment)\n>>> +\n>>> +This output can be spent by the local and remote nodes respectivey to \n>>> provide incentive to mine the transaction, using \n>>> child-pays-for-parent.\u00a0 They are only added if the `to_local` and \n>>> `to_remote` outputs exist, respectively.\n>>> +\n>>> +\u00a0\u00a0\u00a0 OP_DEPTH\n>>> +\u00a0\u00a0\u00a0 OP_IF\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <pubkey> OP_CHECKSIG\n>>> +\u00a0\u00a0\u00a0 OP_ELSE\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 10 OP_CSV\n>>> +\u00a0\u00a0\u00a0 OP_ENDIF\n>>> +\n>>> +The `<pubkey>` is `<local_delayedpubkey>` to `to_local_pushme` and\n>>> +`<remote_delayedpubkey>` for `to_remote_pushme`.\u00a0 The output amount is\n>>> +1000 satoshi, to encourage spending of the output.\u00a0 Once the\n>>> +`remote_pubkey` is revealed (by spending the `to_local` output) and\n>>> +the commitment transaction is 10 blocks deep, anyone can spend it.\n>>> +\n>>> \u00a0 #### Offered HTLC Outputs\n>>> @@ -294,6 +329,9 @@ The fee calculation for both commitment \n>>> transactions and HTLC\n>>> \u00a0 transactions is based on the current `feerate_per_kw` and the\n>>> \u00a0 *expected weight* of the transaction.\n>>> +Note that if `option_simplified_commitment` applies to the commitment\n>>> +transaction then `feerate_per_kw` is 253.\n>>> +\n>>> \u00a0 The actual and expected weights vary for several reasons:\n>>> \u00a0 * Bitcoin uses DER-encoded signatures, which vary in size.\n>>> @@ -306,10 +344,12 @@ Thus, a simplified formula for *expected weight* \n>>> is used, which assumes:\n>>> \u00a0 * Signatures are 73 bytes long (the maximum length).\n>>> \u00a0 * There are a small number of outputs (thus 1 byte to count them).\n>>> \u00a0 * There are always both a `to_local` output and a `to_remote` output.\n>>> +* (if `option_simplified_commitment`) there are always both a \n>>> `to_local_pushme` and `to_remote_pushme` output.\n>>> \u00a0 This yields the following *expected weights* (details of the \n>>> computation in [Appendix A](#appendix-a-expected-weights)):\n>>> -\u00a0\u00a0\u00a0 Commitment weight:\u00a0\u00a0 724 + 172 * num-untrimmed-htlc-outputs\n>>> +\u00a0\u00a0\u00a0 Commitment weight (no option_simplified_commitment):\u00a0\u00a0 724 + 172 \n>>> * num-untrimmed-htlc-outputs\n>>> +\u00a0\u00a0\u00a0 Commitment weight (option_simplified_commitment:\u00a0 1116 + 172 * \n>>> num-untrimmed-htlc-outputs\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0 HTLC-timeout weight: 663\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0 HTLC-success weight: 703\n>>> @@ -366,7 +406,7 @@ outputs) is 7140 satoshi. The final fee may be \n>>> even higher if the\n>>> \u00a0 ### Fee Payment\n>>> -Base commitment transaction fees are extracted from the funder's \n>>> amount; if that amount is insufficient, the entire amount of the \n>>> funder's output is used.\n>>> +Base commitment transaction fees and amounts for `to_local_pushme` \n>>> and `to_remote_pushme` outputs are extracted from the funder's amount; \n>>> if that amount is insufficient, the entire amount of the funder's \n>>> output is used.\n>>> \u00a0 Note that after the fee amount is subtracted from the to-funder output,\n>>> \u00a0 that output may be below `dust_limit_satoshis`, and thus will also\n>>> @@ -390,23 +430,29 @@ committed HTLCs:\n>>> \u00a0 2. Calculate the base [commitment transaction fee](#fee-calculation).\n>>> \u00a0 3. Subtract this base fee from the funder (either `to_local` or \n>>> `to_remote`),\n>>> \u00a0\u00a0\u00a0\u00a0 with a floor of 0 (see [Fee Payment](#fee-payment)).\n>>> +4. If `option_simplified_commitment` applies to the commitment \n>>> transaction,\n>>> +\u00a0\u00a0 subtract 2000 satoshis from the funder (either `to_local` or \n>>> `to_remote`).\n>>> \u00a0 3. For every offered HTLC, if it is not trimmed, add an\n>>> \u00a0\u00a0\u00a0\u00a0 [offered HTLC output](#offered-htlc-outputs).\n>>> \u00a0 4. For every received HTLC, if it is not trimmed, add an\n>>> \u00a0\u00a0\u00a0\u00a0 [received HTLC output](#received-htlc-outputs).\n>>> \u00a0 5. If the `to_local` amount is greater or equal to \n>>> `dust_limit_satoshis`,\n>>> \u00a0\u00a0\u00a0\u00a0 add a [`to_local` output](#to_local-output).\n>>> +6. If `option_simplified_commitment` applies to the commitment \n>>> transaction,\n>>> +\u00a0\u00a0 and `to_local` was added, add `to_local_pushme`.\n>>> \u00a0 6. If the `to_remote` amount is greater or equal to \n>>> `dust_limit_satoshis`,\n>>> \u00a0\u00a0\u00a0\u00a0 add a [`to_remote` output](#to_remote-output).\n>>> +6. If `option_simplified_commitment` applies to the commitment \n>>> transaction,\n>>> +\u00a0\u00a0 and `to_remote` was added, add `to_remote_pushme`.\n>>> \u00a0 7. Sort the outputs into [BIP 69 \n>>> order](#transaction-input-and-output-ordering).\n>>> \u00a0 # Keys\n>>> \u00a0 ## Key Derivation\n>>> -Each commitment transaction uses a unique set of keys: `localpubkey` \n>>> and `remotepubkey`.\n>>> +Each commitment transaction uses a unique `localpubkey`, and a \n>>> `remotepubkey`.\n>>> \u00a0 The HTLC-success and HTLC-timeout transactions use \n>>> `local_delayedpubkey` and `revocationpubkey`.\n>>> -These are changed for every transaction based on the \n>>> `per_commitment_point`.\n>>> +These are changed for every transaction based on the \n>>> `per_commitment_point`, with the exception of `remotepubkey` if \n>>> `option_simplified_commitment` is negotiated.\n>>> \u00a0 The reason for key change is so that trustless watching for revoked\n>>> \u00a0 transactions can be outsourced. Such a _watcher_ should not be able to\n>>> @@ -419,8 +465,9 @@ avoid storage of every commitment transaction, a \n>>> _watcher_ can be given the\n>>> \u00a0 the scripts required for the penalty transaction; thus, a _watcher_ \n>>> need only be\n>>> \u00a0 given (and store) the signatures for each penalty input.\n>>> -Changing the `localpubkey` and `remotepubkey` every time ensures that \n>>> commitment\n>>> -transaction ID cannot be guessed; every commitment transaction uses \n>>> an ID\n>>> +Changing the `localpubkey` every time ensures that commitment\n>>> +transaction ID cannot be guessed except in the trivial case where \n>>> there is no\n>>> +`to_local` output, as every commitment transaction uses an ID\n>>> \u00a0 in its output script. Splitting the `local_delayedpubkey`, which is \n>>> required for\n>>> \u00a0 the penalty transaction, allows it to be shared with the _watcher_ \n>>> without\n>>> \u00a0 revealing `localpubkey`; even if both peers use the same _watcher_, \n>>> nothing is revealed.\n>>> @@ -434,14 +481,13 @@ For efficiency, keys are generated from a series \n>>> of per-commitment secrets\n>>> \u00a0 that are generated from a single seed, which allows the receiver to \n>>> compactly\n>>> \u00a0 store them (see [below](#efficient-per-commitment-secret-storage)).\n>>> -### `localpubkey`, `remotepubkey`, `local_htlcpubkey`, \n>>> `remote_htlcpubkey`, `local_delayedpubkey`, and `remote_delayedpubkey` \n>>> Derivation\n>>> +### `localpubkey``local_htlcpubkey`, `remote_htlcpubkey`, \n>>> `local_delayedpubkey`, and `remote_delayedpubkey` Derivation\n>>> \u00a0 These pubkeys are simply generated by addition from their base points:\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0 pubkey = basepoint + SHA256(per_commitment_point || basepoint) * G\n>>> -The `localpubkey` uses the local node's `payment_basepoint`; the \n>>> `remotepubkey`\n>>> -uses the remote node's `payment_basepoint`; the `local_delayedpubkey`\n>>> +The `localpubkey` uses the local node's `payment_basepoint`; the \n>>> `local_delayedpubkey`\n>>> \u00a0 uses the local node's `delayed_payment_basepoint`; the \n>>> `local_htlcpubkey` uses the\n>>> \u00a0 local node's `htlc_basepoint`; and the `remote_delayedpubkey` uses \n>>> the remote\n>>> \u00a0 node's `delayed_payment_basepoint`.\n>>> @@ -451,6 +497,17 @@ secrets are known (i.e. the private keys \n>>> corresponding to `localpubkey`, `local_\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0 privkey = basepoint_secret + SHA256(per_commitment_point || \n>>> basepoint)\n>>> +### `remotepubkey` Derivation\n>>> +\n>>> +If `option_simplified_commitment` is negotiated the `remotepubkey` is \n>>> simply the remote node's `payment_basepoint`, otherwise it is \n>>> calculated as above using the remote node's `payment_basepoint`.\n>>> +\n>>> +The simplified derivation means that a node can spend a commitment\n>>> +transaction even if it has lost data and doesn't know the\n>>> +corresponding `payment_basepoint`.\u00a0 A watchtower could correlate\n>>> +transactions given to it which only have a `to_remote` output if it\n>>> +sees one of them onchain, but such transactions do not need any\n>>> +enforcement and should not be handed to a watchtower.\n>>> +\n>>> \u00a0 ### `revocationpubkey` Derivation\n>>> \u00a0 The `revocationpubkey` is a blinded key: when the local node wishes \n>>> to create a new\n>>> @@ -636,12 +693,22 @@ The *expected weight* of a commitment \n>>> transaction is calculated as follows:\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - var_int: 1 byte (pk_script length)\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - pk_script (p2wsh): 34 bytes\n>>> -\u00a0\u00a0\u00a0 output_paying_to_remote: 31 bytes\n>>> +\u00a0\u00a0\u00a0 output_paying_to_remote (no option_simplified_commitment): 31 bytes\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - value: 8 bytes\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - var_int: 1 byte (pk_script length)\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - pk_script (p2wpkh): 22 bytes\n>>> -\u00a0\u00a0\u00a0\u00a0 htlc_output: 43 bytes\n>>> +\u00a0\u00a0\u00a0 output_paying_to_remote (option_simplified_commitment): 43 bytes\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - value: 8 bytes\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - var_int: 1 byte (pk_script length)\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - pk_script (p2wsh): 34 bytes\n>>> +\n>>> +\u00a0\u00a0\u00a0 output_pushme (option_simplified_commitment): 43 bytes\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - value: 8 bytes\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - var_int: 1 byte (pk_script length)\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - pk_script (p2wsh): 34 bytes\n>>> +\n>>> +\u00a0\u00a0\u00a0 htlc_output: 43 bytes\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - value: 8 bytes\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - var_int: 1 byte (pk_script length)\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - pk_script (p2wsh): 34 bytes\n>>> @@ -650,7 +717,7 @@ The *expected weight* of a commitment transaction \n>>> is calculated as follows:\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - flag: 1 byte\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - marker: 1 byte\n>>> -\u00a0\u00a0\u00a0\u00a0 commitment_transaction: 125 + 43 * num-htlc-outputs bytes\n>>> +\u00a0\u00a0\u00a0\u00a0 commitment_transaction (no option_simplified_commitment): 125 + \n>>> 43 * num-htlc-outputs bytes\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - version: 4 bytes\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - witness_header <---- part of the witness data\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - count_tx_in: 1 byte\n>>> @@ -663,15 +730,32 @@ The *expected weight* of a commitment \n>>> transaction is calculated as follows:\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 ....htlc_output's...\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - lock_time: 4 bytes\n>>> +\u00a0\u00a0\u00a0\u00a0 commitment_transaction (option_simplified_commitment): 223 + 43 \n>>> * num-htlc-outputs bytes\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - version: 4 bytes\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - witness_header <---- part of the witness data\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - count_tx_in: 1 byte\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - tx_in: 41 bytes\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 funding_input\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - count_tx_out: 1 byte\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - tx_out: 172 + 43 * num-htlc-outputs bytes\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 output_paying_to_remote,\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 output_paying_to_local,\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 output_pushme,\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 output_pushme,\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 ....htlc_output's...\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - lock_time: 4 bytes\n>>> +\n>>> \u00a0 Multiplying non-witness data by 4 results in a weight of:\n>>> -\u00a0\u00a0\u00a0 // 500 + 172 * num-htlc-outputs weight\n>>> +\u00a0\u00a0\u00a0 // 500 + 172 * num-htlc-outputs weight (no \n>>> option_simplified_commitment)\n>>> +\u00a0\u00a0\u00a0 // 892 + 172 * num-htlc-outputs weight \n>>> (option_simplified_commitment)\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0 commitment_transaction_weight = 4 * commitment_transaction\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0 // 224 weight\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0 witness_weight = witness_header + witness\n>>> -\u00a0\u00a0\u00a0 overall_weight = 500 + 172 * num-htlc-outputs + 224 weight\n>>> +\u00a0\u00a0\u00a0 overall_weight (no option_simplified_commitment) = 500 + 172 * \n>>> num-htlc-outputs + 224 weight\n>>> +\u00a0\u00a0\u00a0 overall_weight (option_simplified_commitment) = 892 + 172 * \n>>> num-htlc-outputs + 224 weight\n>>> \u00a0 ## Expected Weight of HTLC-timeout and HTLC-success Transactions\n>>> diff --git a/05-onchain.md b/05-onchain.md\n>>> index 231c209..c5fb5e1 100644\n>>> --- a/05-onchain.md\n>>> +++ b/05-onchain.md\n>>> @@ -89,21 +89,29 @@ trigger any action.\n>>> \u00a0 # Commitment Transaction\n>>> \u00a0 The local and remote nodes each hold a *commitment transaction*. \n>>> Each of these\n>>> -commitment transactions has four types of outputs:\n>>> +commitment transactions has six types of outputs:\n>>> \u00a0 1. _local node's main output_: Zero or one output, to pay to the \n>>> *local node's*\n>>> -commitment pubkey.\n>>> +delayed pubkey.\n>>> \u00a0 2. _remote node's main output_: Zero or one output, to pay to the \n>>> *remote node's*\n>>> -commitment pubkey.\n>>> +pubkey.\n>>> +1. _local node's push output_: Zero or one output, to pay to the \n>>> *local node's*\n>>> +delayed pubkey.\n>>> +2. _remote node's push output_: Zero or one output, to pay to the \n>>> *remote node's*\n>>> +pubkey.\n>>> \u00a0 3. _local node's offered HTLCs_: Zero or more pending payments \n>>> (*HTLCs*), to pay\n>>> \u00a0 the *remote node* in return for a payment preimage.\n>>> \u00a0 4. _remote node's offered HTLCs_: Zero or more pending payments \n>>> (*HTLCs*), to\n>>> \u00a0 pay the *local node* in return for a payment preimage.\n>>> \u00a0 To incentivize the local and remote nodes to cooperate, an \n>>> `OP_CHECKSEQUENCEVERIFY`\n>>> -relative timeout encumbers the *local node's outputs* (in the *local \n>>> node's\n>>> +relative timeout encumbers some outputs: the *local node's outputs* \n>>> (in the *local node's\n>>> \u00a0 commitment transaction*) and the *remote node's outputs* (in the \n>>> *remote node's\n>>> -commitment transaction*). So for example, if the local node publishes \n>>> its\n>>> +commitment transaction*). If `option_simplified_commitment` applies\n>>> +to the commitment transaction, then the *to_remote* output of each \n>>> commitment is\n>>> +identically encumbered, for fairness.\n>>> +\n>>> +Without `option_simplified_commitment`, if the local node publishes its\n>>> \u00a0 commitment transaction, it will have to wait to claim its own funds,\n>>> \u00a0 whereas the remote node will have immediate access to its own funds. \n>>> As a\n>>> \u00a0 consequence, the two commitment transactions are not identical, but \n>>> they are\n>>> @@ -140,6 +148,11 @@ A node:\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - otherwise:\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - MUST use the *last commitment transaction*, for which it \n>>> has a\n>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 signature, to perform a *unilateral close*.\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0 - MUST spend any `to_local_pushme` output, providing sufficient \n>>> fees as incentive to include the commitment transaction in a block\n>>> +\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - SHOULD use \n>>> [replace-by-fee](https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki) \n>>> or other mechanism on the spending transaction if it proves \n>>> insufficient for timely inclusion in a block.\n>>> +\n>>> +A node:\n>>> +\u00a0 - MAY monitor the blockchain for unspent `to_local_pushme` and \n>>> `to_remote_pushme` outputs and try to spend them after 10 confirmations.\n>>> \u00a0 ## Rationale\n>>> @@ -154,7 +167,8 @@ need not consume resources monitoring the channel \n>>> state.\n>>> \u00a0 There exists a bias towards preferring mutual closes over unilateral \n>>> closes,\n>>> \u00a0 because outputs of the former are unencumbered by a delay and are \n>>> directly\n>>> \u00a0 spendable by wallets. In addition, mutual close fees tend to be less \n>>> exaggerated\n>>> -than those of commitment transactions. So, the only reason not to use \n>>> the\n>>> +than those of commitment transactions (or in the case of \n>>> `option_simplified_commitment`,\n>>> +the commitment transaction may require a child transaction to cause \n>>> it to be mined). So, the only reason not to use the\n>>> \u00a0 signature from `closing_signed` would be if the fee offered was too \n>>> small for\n>>> \u00a0 it to be processed.\n>>> diff --git a/09-features.md b/09-features.md\n>>> index d06fcff..caea38b 100644\n>>> --- a/09-features.md\n>>> +++ b/09-features.md\n>>> @@ -26,6 +26,7 @@ These flags may only be used in the `init` message:\n>>> \u00a0 | 3\u00a0 | `initial_routing_sync` | Indicates that the sending node \n>>> needs a complete routing information dump | [BOLT \n>>> #7](07-routing-gossip.md#initial-sync) |\n>>> \u00a0 | 4/5\u00a0 | `option_upfront_shutdown_script` | Commits to a shutdown \n>>> scriptpubkey when opening channel | [BOLT \n>>> #2](02-peer-protocol.md#the-open_channel-message) |\n>>> \u00a0 | 6/7\u00a0 | `gossip_queries`\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 | More sophisticated gossip \n>>> control | [BOLT #7](07-routing-gossip.md#query-messages) |\n>>> +| 8/9\u00a0 | `option_simplified_commitment`\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 | Simplified \n>>> commitment transactions | [BOLT #3](03-transactions.md) |\n>>> \u00a0 ## Assigned `globalfeatures` flags\n>>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Matt Corallo",
                "date": "2018-11-22T02:20:16",
                "message_text_only": "Ah, oops, indeed, that is much cleaner :). Still need a CSV of 1, though :(.\n\n> On Nov 21, 2018, at 17:45, Rusty Russell <rusty at rustcorp.com.au> wrote:\n> \n> Matt Corallo <lf-lists at mattcorallo.com> writes:\n>> Oh, also, obviously, the HTLC transactions need a pushme output, though \n>> luckily only one for the side we expect to be broadcasting the transaction.\n> \n> The intent was that HTLC transactions are now\n> SIGHASH_SINGLE|SIGHASH_ANYONECANPAY (since we don't need the txid), so\n> you Bring Your Own Fees.\n> \n> I missed this in the draft, patch coming...\n> \n> Cheers,\n> Rusty.\n> \n>>> On 11/21/18 2:54 AM, Matt Corallo wrote:\n>>> Not sure if others already realized this, but in thinking about our RBF \n>>> policy hack from Adelaide a bit more, to allow the carve-out exception \n>>> of \"last tx in a package, which has only one unconfirmed ancestor\" to \n>>> always be available for the \"honest party\" when broadcasting a \n>>> commitment transaction, we also need at least a CSV delay of 1 block on \n>>> the HTLC transaction outputs (as otherwise those transactions could \n>>> count as the carve-out tx).\n>>> \n>>> Matt\n>>> \n>>>> On 11/21/18 2:17 AM, Rusty Russell wrote:\n>>>> I'm also starting to implement this, to see what I missed!\n>>>> \n>>>> Original at https://github.com/lightningnetwork/lightning-rfc/pull/513\n>>>> \n>>>> Pasted here for your reading convenience:\n>>>> \n>>>> - Option is sticky; it set at open time, it stays with channel\n>>>>    - I didn't want to have to handle penalty txs on channels which switch\n>>>>    - We could, however, upgrade on splice.\n>>>> - Feerate is fixed at 253\n>>>>    - `feerate_per_kw` is still in open /accept (just ignored): \n>>>> multifund may want it.\n>>>> - closing tx negotiates *upwards* not *downwards*\n>>>>    - Starting from base fee of commitment tx = 282 satoshi.\n>>>> - to_remote output is always CSV delayed.\n>>>> - pushme outputs are paid for by funder, but only exist if the matching\n>>>>    to_local/remote output exists.\n>>>> - After 10 blocks, they become anyone-can-spend (they need to see the\n>>>>    to-local/remote witness script though).\n>>>> - remotepubkey is not rotated.\n>>>> - You must spend your pushme output; you may sweep for others.\n>>>> \n>>>> Signed-off-by: Rusty Russell <rusty at rustcorp.com.au>\n>>>> \n>>>> diff --git a/02-peer-protocol.md b/02-peer-protocol.md\n>>>> index 7cf9ebf..6ec1155 100644\n>>>> --- a/02-peer-protocol.md\n>>>> +++ b/02-peer-protocol.md\n>>>> @@ -133,7 +133,9 @@ node can offer.\n>>>>   (i.e. 1/4 the more normally-used 'satoshi per 1000 vbytes') that this\n>>>>   side will pay for commitment and HTLC transactions, as described in\n>>>>   [BOLT #3](03-transactions.md#fee-calculation) (this can be adjusted\n>>>> -later with an `update_fee` message).\n>>>> +later with an `update_fee` message).  Note that if\n>>>> +`option_simplified_commitment` is negotiated, this `feerate_per_kw`\n>>>> +is treated as 253 for all transactions.\n>>>>   `to_self_delay` is the number of blocks that the other node's to-self\n>>>>   outputs must be delayed, using `OP_CHECKSEQUENCEVERIFY` delays; this\n>>>> @@ -208,7 +210,8 @@ The receiving node MUST fail the channel if:\n>>>>     - `push_msat` is greater than `funding_satoshis` * 1000.\n>>>>     - `to_self_delay` is unreasonably large.\n>>>>     - `max_accepted_htlcs` is greater than 483.\n>>>> -  - it considers `feerate_per_kw` too small for timely processing or \n>>>> unreasonably large.\n>>>> +  - if `option_simplified_commitment` is not negotiated:\n>>>> +    - it considers `feerate_per_kw` too small for timely processing \n>>>> or unreasonably large.\n>>>>     - `funding_pubkey`, `revocation_basepoint`, `htlc_basepoint`, \n>>>> `payment_basepoint`, or `delayed_payment_basepoint`\n>>>>   are not valid DER-encoded compressed secp256k1 pubkeys.\n>>>>     - `dust_limit_satoshis` is greater than `channel_reserve_satoshis`.\n>>>> @@ -228,7 +231,7 @@ The *channel reserve* is specified by the peer's \n>>>> `channel_reserve_satoshis`: 1%\n>>>>   The sender can unconditionally give initial funds to the receiver \n>>>> using a non-zero `push_msat`, but even in this case we ensure that the \n>>>> funder has sufficient remaining funds to pay fees and that one side \n>>>> has some amount it can spend (which also implies there is at least one \n>>>> non-dust output). Note that, like any other on-chain transaction, this \n>>>> payment is not certain until the funding transaction has been \n>>>> confirmed sufficiently (with a danger of double-spend until this \n>>>> occurs) and may require a separate method to prove payment via \n>>>> on-chain confirmation.\n>>>> -The `feerate_per_kw` is generally only of concern to the sender (who \n>>>> pays the fees), but there is also the fee rate paid by HTLC \n>>>> transactions; thus, unreasonably large fee rates can also penalize the \n>>>> recipient.\n>>>> +The `feerate_per_kw` is generally only of concern to the sender (who \n>>>> pays the fees), but there is also the fee rate paid by HTLC \n>>>> transactions; thus, unreasonably large fee rates can also penalize the \n>>>> recipient.  It is ignored for `option_simplified_commitment`.\n>>>>   Separating the `htlc_basepoint` from the `payment_basepoint` \n>>>> improves security: a node needs the secret associated with the \n>>>> `htlc_basepoint` to produce HTLC signatures for the protocol, but the \n>>>> secret for the `payment_basepoint` can be in cold storage.\n>>>> @@ -340,6 +343,12 @@ This message introduces the `channel_id` to \n>>>> identify the channel. It's derived f\n>>>>   #### Requirements\n>>>> +Both peers:\n>>>> +  - if `option_simplified_commitment` was negotiated:\n>>>> +    - `option_simplified_commitment` applies to all commitment and \n>>>> HTLC transactions\n>>>> +  - otherwise:\n>>>> +    - `option_simplified_commitment` does not apply to any commitment \n>>>> or HTLC transactions\n>>>> +\n>>>>   The sender MUST set:\n>>>>     - `channel_id` by exclusive-OR of the `funding_txid` and the \n>>>> `funding_output_index` from the `funding_created` message.\n>>>>     - `signature` to the valid signature, using its `funding_pubkey` \n>>>> for the initial commitment transaction, as defined in [BOLT \n>>>> #3](03-transactions.md#commitment-transaction).\n>>>> @@ -351,6 +360,12 @@ The recipient:\n>>>>     - on receipt of a valid `funding_signed`:\n>>>>       - SHOULD broadcast the funding transaction.\n>>>> +#### Rationale\n>>>> +\n>>>> +We decide on `option_simplified_commitment` at this point when we \n>>>> first have to generate the commitment\n>>>> +transaction.  Even if a later reconnection does not negotiate this \n>>>> parameter, this channel will honor it.\n>>>> +This simplifies channel state, particularly penalty transaction \n>>>> handling.\n>>>> +\n>>>>   ### The `funding_locked` Message\n>>>>   This message indicates that the funding transaction has reached the \n>>>> `minimum_depth` asked for in `accept_channel`. Once both nodes have \n>>>> sent this, the channel enters normal operating mode.\n>>>> @@ -508,8 +523,11 @@ The funding node:\n>>>>       - SHOULD send a `closing_signed` message.\n>>>>   The sending node:\n>>>> -  - MUST set `fee_satoshis` less than or equal to the\n>>>> - base fee of the final commitment transaction, as calculated in [BOLT \n>>>> #3](03-transactions.md#fee-calculation).\n>>>> +  - if `option_upfront_shutdown_script` applies to the final \n>>>> commitment transaction:\n>>>> +    - MUST set `fee_satoshis` greater than or equal to 282.\n>>>> +  - otherwise:\n>>>> +    - MUST set `fee_satoshis` less than or equal to the\n>>>> +      base fee of the final commitment transaction, as calculated in \n>>>> [BOLT #3](03-transactions.md#fee-calculation).\n>>>>     - SHOULD set the initial `fee_satoshis` according to its\n>>>>    estimate of cost of inclusion in a block.\n>>>>     - MUST set `signature` to the Bitcoin signature of the close\n>>>> @@ -543,9 +561,18 @@ progress is made, even if only by a single \n>>>> satoshi at a time. To avoid\n>>>>   keeping state and to handle the corner case, where fees have shifted\n>>>>   between disconnection and reconnection, negotiation restarts on \n>>>> reconnection.\n>>>> -Note there is limited risk if the closing transaction is\n>>>> -delayed, but it will be broadcast very soon; so there is usually no\n>>>> -reason to pay a premium for rapid processing.\n>>>> +In the `option_simplified_commitment` case, the fees on the commitment\n>>>> +transaction itself are minimal (it is assumed that a child \n>>>> transaction will\n>>>> +supply additional fee incentive), so that forms a floor for negotiation.\n>>>> +[BOLT #3](03-transactions.md#fee-calculation), gives 282 satoshis (1116\n>>>> +weight, 254 `feerate_per_kw`).\n>>>> +\n>>>> +Otherwise, the commitment transaction usually pays a premium fee, so \n>>>> that\n>>>> +forms a ceiling.\n>>>> +\n>>>> +Note there is limited risk if the closing transaction is delayed, but \n>>>> it will\n>>>> +be broadcast very soon; so there is usually no reason to pay a \n>>>> premium for\n>>>> +rapid processing.\n>>>>   ## Normal Operation\n>>>> @@ -763,7 +790,10 @@ is destined, is described in [BOLT \n>>>> #4](04-onion-routing.md).\n>>>>   A sending node:\n>>>>     - MUST NOT offer `amount_msat` it cannot pay for in the\n>>>>   remote commitment transaction at the current `feerate_per_kw` (see \n>>>> \"Updating\n>>>> -Fees\") while maintaining its channel reserve.\n>>>> +Fees\") while maintaining its channel reserve\n>>>> +  - if `option_simplified_commitment` applies to this commitment \n>>>> transaction and the sending\n>>>> +    node is the funder:\n>>>> +    - MUST be able to additionally pay for `to_local_pushme` and \n>>>> `to_remote_pushme` above its reserve.\n>>>>     - MUST offer `amount_msat` greater than 0.\n>>>>     - MUST NOT offer `amount_msat` below the receiving node's \n>>>> `htlc_minimum_msat`\n>>>>     - MUST set `cltv_expiry` less than 500000000.\n>>>> @@ -782,7 +812,7 @@ Fees\") while maintaining its channel reserve.\n>>>>   A receiving node:\n>>>>     - receiving an `amount_msat` equal to 0, OR less than its own \n>>>> `htlc_minimum_msat`:\n>>>>       - SHOULD fail the channel.\n>>>> -  - receiving an `amount_msat` that the sending node cannot afford at \n>>>> the current `feerate_per_kw` (while maintaining its channel reserve):\n>>>> +  - receiving an `amount_msat` that the sending node cannot afford at \n>>>> the current `feerate_per_kw` (while maintaining its channel reserve \n>>>> and any `to_local_pushme` and `to_remote_pushme` fees):\n>>>>       - SHOULD fail the channel.\n>>>>     - if a sending node adds more than its `max_accepted_htlcs` HTLCs to\n>>>>       its local commitment transaction, OR adds more than its \n>>>> `max_htlc_value_in_flight_msat` worth of offered HTLCs to its local \n>>>> commitment transaction:\n>>>> @@ -997,6 +1027,11 @@ A node:\n>>>>   ### Updating Fees: `update_fee`\n>>>> +If `option_simplified_commitment` applies to the commitment transaction,\n>>>> +`update_fee` is never used: the `feerate_per_kw` is always considered \n>>>> 253, but\n>>>> +the funder also pays 2000 satoshi for the `to_local_pushme` and\n>>>> +`to_remote_pushme` outputs.\n>>>> +\n>>>>   An `update_fee` message is sent by the node which is paying the\n>>>>   Bitcoin fee. Like any update, it's first committed to the receiver's\n>>>>   commitment transaction and then (once acknowledged) committed to the\n>>>> @@ -1020,13 +1055,19 @@ given in [BOLT \n>>>> #3](03-transactions.md#fee-calculation).\n>>>>   #### Requirements\n>>>>   The node _responsible_ for paying the Bitcoin fee:\n>>>> -  - SHOULD send `update_fee` to ensure the current fee rate is \n>>>> sufficient (by a\n>>>> +  - if `option_simplified_commitment` applies to the commitment \n>>>> transaction:\n>>>> +    - MUST NOT send `update_fee`.\n>>>> +  - otherwise:\n>>>> +    - SHOULD send `update_fee` to ensure the current fee rate is \n>>>> sufficient (by a\n>>>>         significant margin) for timely processing of the commitment \n>>>> transaction.\n>>>>   The node _not responsible_ for paying the Bitcoin fee:\n>>>>     - MUST NOT send `update_fee`.\n>>>>   A receiving node:\n>>>> +  - if `option_simplified_commitment` applies to the commitment \n>>>> transaction:\n>>>> +    - SHOULD fail the channel.\n>>>> +    - MUST NOT update the `feerate_per_kw`.\n>>>>     - if the `update_fee` is too low for timely processing, OR is \n>>>> unreasonably large:\n>>>>       - SHOULD fail the channel.\n>>>>     - if the sender is not responsible for paying the Bitcoin fee:\n>>>> @@ -1038,7 +1079,12 @@ A receiving node:\n>>>>   #### Rationale\n>>>> -Bitcoin fees are required for unilateral closes to be effective \u2014\n>>>> +Fee adjustments are unnecessary for `option_simplified_commitment` which\n>>>> +relies on \"pushme\" outputs and a child transaction which will provide\n>>>> +additional fee incentive which can be calculated at the time it is \n>>>> spent, and\n>>>> +replaced by higher-fee children if required.\n>>>> +\n>>>> +Without this option, bitcoin fees are required for unilateral closes \n>>>> to be effective \u2014\n>>>>   particularly since there is no general method for the broadcasting \n>>>> node to use\n>>>>   child-pays-for-parent to increase its effective fee.\n>>>> diff --git a/03-transactions.md b/03-transactions.md\n>>>> index e769961..440bd0d 100644\n>>>> --- a/03-transactions.md\n>>>> +++ b/03-transactions.md\n>>>> @@ -82,6 +82,8 @@ To allow an opportunity for penalty transactions, in \n>>>> case of a revoked commitmen\n>>>>   The reason for the separate transaction stage for HTLC outputs is so \n>>>> that HTLCs can timeout or be fulfilled even though they are within the \n>>>> `to_self_delay` delay.\n>>>>   Otherwise, the required minimum timeout on HTLCs is lengthened by \n>>>> this delay, causing longer timeouts for HTLCs traversing the network.\n>>>> +If `option_simplified_commitment` applies to the commitment \n>>>> transaction, then the `to_self_delay` used for all transactions is the \n>>>> greater of the `to_self_delay` sent by each peer.  Otherwise, each \n>>>> peer sends the `to_self_delay` to be used for the other peer's \n>>>> commitment amd HTLC transactions.\n>>>> +\n>>>>   The amounts for each output MUST be rounded down to whole satoshis. \n>>>> If this amount, minus the fees for the HTLC transaction, is less than \n>>>> the `dust_limit_satoshis` set by the owner of the commitment \n>>>> transaction, the output MUST NOT be produced (thus the funds add to \n>>>> fees).\n>>>>   #### `to_local` Output\n>>>> @@ -109,7 +111,40 @@ If a revoked commitment transaction is published, \n>>>> the other party can spend this\n>>>>   #### `to_remote` Output\n>>>> -This output sends funds to the other peer and thus is a simple P2WPKH \n>>>> to `remotepubkey`.\n>>>> +This output sends funds to the other peer, thus is not encumbered by a\n>>>> +revocation private key.\n>>>> +\n>>>> +If `option_simplified_commitment` applies to the commitment \n>>>> transaction, the `to_remote` output is delayed similarly to the \n>>>> `to_local` output, and is to a fixed key:\n>>>> +\n>>>> +        `to_self_delay`\n>>>> +        OP_CSV\n>>>> +        OP_DROP\n>>>> +        <remote_pubkey>\n>>>> +\n>>>> +The output is spent by a transaction with `nSequence` field set to \n>>>> `to_self_delay` (which can only be valid after that duration has \n>>>> passed) and witness:\n>>>> +\n>>>> +    <remote_sig>\n>>>> +\n>>>> +Otherwise, this output is a simple P2WPKH to `remotepubkey`.\n>>>> +\n>>>> +\n>>>> +#### `to_local_pushme` and `to_remote_pushme` Output \n>>>> (option_simplified_commitment)\n>>>> +\n>>>> +This output can be spent by the local and remote nodes respectivey to \n>>>> provide incentive to mine the transaction, using \n>>>> child-pays-for-parent.  They are only added if the `to_local` and \n>>>> `to_remote` outputs exist, respectively.\n>>>> +\n>>>> +    OP_DEPTH\n>>>> +    OP_IF\n>>>> +        <pubkey> OP_CHECKSIG\n>>>> +    OP_ELSE\n>>>> +        10 OP_CSV\n>>>> +    OP_ENDIF\n>>>> +\n>>>> +The `<pubkey>` is `<local_delayedpubkey>` to `to_local_pushme` and\n>>>> +`<remote_delayedpubkey>` for `to_remote_pushme`.  The output amount is\n>>>> +1000 satoshi, to encourage spending of the output.  Once the\n>>>> +`remote_pubkey` is revealed (by spending the `to_local` output) and\n>>>> +the commitment transaction is 10 blocks deep, anyone can spend it.\n>>>> +\n>>>>   #### Offered HTLC Outputs\n>>>> @@ -294,6 +329,9 @@ The fee calculation for both commitment \n>>>> transactions and HTLC\n>>>>   transactions is based on the current `feerate_per_kw` and the\n>>>>   *expected weight* of the transaction.\n>>>> +Note that if `option_simplified_commitment` applies to the commitment\n>>>> +transaction then `feerate_per_kw` is 253.\n>>>> +\n>>>>   The actual and expected weights vary for several reasons:\n>>>>   * Bitcoin uses DER-encoded signatures, which vary in size.\n>>>> @@ -306,10 +344,12 @@ Thus, a simplified formula for *expected weight* \n>>>> is used, which assumes:\n>>>>   * Signatures are 73 bytes long (the maximum length).\n>>>>   * There are a small number of outputs (thus 1 byte to count them).\n>>>>   * There are always both a `to_local` output and a `to_remote` output.\n>>>> +* (if `option_simplified_commitment`) there are always both a \n>>>> `to_local_pushme` and `to_remote_pushme` output.\n>>>>   This yields the following *expected weights* (details of the \n>>>> computation in [Appendix A](#appendix-a-expected-weights)):\n>>>> -    Commitment weight:   724 + 172 * num-untrimmed-htlc-outputs\n>>>> +    Commitment weight (no option_simplified_commitment):   724 + 172 \n>>>> * num-untrimmed-htlc-outputs\n>>>> +    Commitment weight (option_simplified_commitment:  1116 + 172 * \n>>>> num-untrimmed-htlc-outputs\n>>>>       HTLC-timeout weight: 663\n>>>>       HTLC-success weight: 703\n>>>> @@ -366,7 +406,7 @@ outputs) is 7140 satoshi. The final fee may be \n>>>> even higher if the\n>>>>   ### Fee Payment\n>>>> -Base commitment transaction fees are extracted from the funder's \n>>>> amount; if that amount is insufficient, the entire amount of the \n>>>> funder's output is used.\n>>>> +Base commitment transaction fees and amounts for `to_local_pushme` \n>>>> and `to_remote_pushme` outputs are extracted from the funder's amount; \n>>>> if that amount is insufficient, the entire amount of the funder's \n>>>> output is used.\n>>>>   Note that after the fee amount is subtracted from the to-funder output,\n>>>>   that output may be below `dust_limit_satoshis`, and thus will also\n>>>> @@ -390,23 +430,29 @@ committed HTLCs:\n>>>>   2. Calculate the base [commitment transaction fee](#fee-calculation).\n>>>>   3. Subtract this base fee from the funder (either `to_local` or \n>>>> `to_remote`),\n>>>>      with a floor of 0 (see [Fee Payment](#fee-payment)).\n>>>> +4. If `option_simplified_commitment` applies to the commitment \n>>>> transaction,\n>>>> +   subtract 2000 satoshis from the funder (either `to_local` or \n>>>> `to_remote`).\n>>>>   3. For every offered HTLC, if it is not trimmed, add an\n>>>>      [offered HTLC output](#offered-htlc-outputs).\n>>>>   4. For every received HTLC, if it is not trimmed, add an\n>>>>      [received HTLC output](#received-htlc-outputs).\n>>>>   5. If the `to_local` amount is greater or equal to \n>>>> `dust_limit_satoshis`,\n>>>>      add a [`to_local` output](#to_local-output).\n>>>> +6. If `option_simplified_commitment` applies to the commitment \n>>>> transaction,\n>>>> +   and `to_local` was added, add `to_local_pushme`.\n>>>>   6. If the `to_remote` amount is greater or equal to \n>>>> `dust_limit_satoshis`,\n>>>>      add a [`to_remote` output](#to_remote-output).\n>>>> +6. If `option_simplified_commitment` applies to the commitment \n>>>> transaction,\n>>>> +   and `to_remote` was added, add `to_remote_pushme`.\n>>>>   7. Sort the outputs into [BIP 69 \n>>>> order](#transaction-input-and-output-ordering).\n>>>>   # Keys\n>>>>   ## Key Derivation\n>>>> -Each commitment transaction uses a unique set of keys: `localpubkey` \n>>>> and `remotepubkey`.\n>>>> +Each commitment transaction uses a unique `localpubkey`, and a \n>>>> `remotepubkey`.\n>>>>   The HTLC-success and HTLC-timeout transactions use \n>>>> `local_delayedpubkey` and `revocationpubkey`.\n>>>> -These are changed for every transaction based on the \n>>>> `per_commitment_point`.\n>>>> +These are changed for every transaction based on the \n>>>> `per_commitment_point`, with the exception of `remotepubkey` if \n>>>> `option_simplified_commitment` is negotiated.\n>>>>   The reason for key change is so that trustless watching for revoked\n>>>>   transactions can be outsourced. Such a _watcher_ should not be able to\n>>>> @@ -419,8 +465,9 @@ avoid storage of every commitment transaction, a \n>>>> _watcher_ can be given the\n>>>>   the scripts required for the penalty transaction; thus, a _watcher_ \n>>>> need only be\n>>>>   given (and store) the signatures for each penalty input.\n>>>> -Changing the `localpubkey` and `remotepubkey` every time ensures that \n>>>> commitment\n>>>> -transaction ID cannot be guessed; every commitment transaction uses \n>>>> an ID\n>>>> +Changing the `localpubkey` every time ensures that commitment\n>>>> +transaction ID cannot be guessed except in the trivial case where \n>>>> there is no\n>>>> +`to_local` output, as every commitment transaction uses an ID\n>>>>   in its output script. Splitting the `local_delayedpubkey`, which is \n>>>> required for\n>>>>   the penalty transaction, allows it to be shared with the _watcher_ \n>>>> without\n>>>>   revealing `localpubkey`; even if both peers use the same _watcher_, \n>>>> nothing is revealed.\n>>>> @@ -434,14 +481,13 @@ For efficiency, keys are generated from a series \n>>>> of per-commitment secrets\n>>>>   that are generated from a single seed, which allows the receiver to \n>>>> compactly\n>>>>   store them (see [below](#efficient-per-commitment-secret-storage)).\n>>>> -### `localpubkey`, `remotepubkey`, `local_htlcpubkey`, \n>>>> `remote_htlcpubkey`, `local_delayedpubkey`, and `remote_delayedpubkey` \n>>>> Derivation\n>>>> +### `localpubkey``local_htlcpubkey`, `remote_htlcpubkey`, \n>>>> `local_delayedpubkey`, and `remote_delayedpubkey` Derivation\n>>>>   These pubkeys are simply generated by addition from their base points:\n>>>>       pubkey = basepoint + SHA256(per_commitment_point || basepoint) * G\n>>>> -The `localpubkey` uses the local node's `payment_basepoint`; the \n>>>> `remotepubkey`\n>>>> -uses the remote node's `payment_basepoint`; the `local_delayedpubkey`\n>>>> +The `localpubkey` uses the local node's `payment_basepoint`; the \n>>>> `local_delayedpubkey`\n>>>>   uses the local node's `delayed_payment_basepoint`; the \n>>>> `local_htlcpubkey` uses the\n>>>>   local node's `htlc_basepoint`; and the `remote_delayedpubkey` uses \n>>>> the remote\n>>>>   node's `delayed_payment_basepoint`.\n>>>> @@ -451,6 +497,17 @@ secrets are known (i.e. the private keys \n>>>> corresponding to `localpubkey`, `local_\n>>>>       privkey = basepoint_secret + SHA256(per_commitment_point || \n>>>> basepoint)\n>>>> +### `remotepubkey` Derivation\n>>>> +\n>>>> +If `option_simplified_commitment` is negotiated the `remotepubkey` is \n>>>> simply the remote node's `payment_basepoint`, otherwise it is \n>>>> calculated as above using the remote node's `payment_basepoint`.\n>>>> +\n>>>> +The simplified derivation means that a node can spend a commitment\n>>>> +transaction even if it has lost data and doesn't know the\n>>>> +corresponding `payment_basepoint`.  A watchtower could correlate\n>>>> +transactions given to it which only have a `to_remote` output if it\n>>>> +sees one of them onchain, but such transactions do not need any\n>>>> +enforcement and should not be handed to a watchtower.\n>>>> +\n>>>>   ### `revocationpubkey` Derivation\n>>>>   The `revocationpubkey` is a blinded key: when the local node wishes \n>>>> to create a new\n>>>> @@ -636,12 +693,22 @@ The *expected weight* of a commitment \n>>>> transaction is calculated as follows:\n>>>>           - var_int: 1 byte (pk_script length)\n>>>>           - pk_script (p2wsh): 34 bytes\n>>>> -    output_paying_to_remote: 31 bytes\n>>>> +    output_paying_to_remote (no option_simplified_commitment): 31 bytes\n>>>>           - value: 8 bytes\n>>>>           - var_int: 1 byte (pk_script length)\n>>>>           - pk_script (p2wpkh): 22 bytes\n>>>> -     htlc_output: 43 bytes\n>>>> +    output_paying_to_remote (option_simplified_commitment): 43 bytes\n>>>> +        - value: 8 bytes\n>>>> +        - var_int: 1 byte (pk_script length)\n>>>> +        - pk_script (p2wsh): 34 bytes\n>>>> +\n>>>> +    output_pushme (option_simplified_commitment): 43 bytes\n>>>> +        - value: 8 bytes\n>>>> +        - var_int: 1 byte (pk_script length)\n>>>> +        - pk_script (p2wsh): 34 bytes\n>>>> +\n>>>> +    htlc_output: 43 bytes\n>>>>           - value: 8 bytes\n>>>>           - var_int: 1 byte (pk_script length)\n>>>>           - pk_script (p2wsh): 34 bytes\n>>>> @@ -650,7 +717,7 @@ The *expected weight* of a commitment transaction \n>>>> is calculated as follows:\n>>>>           - flag: 1 byte\n>>>>           - marker: 1 byte\n>>>> -     commitment_transaction: 125 + 43 * num-htlc-outputs bytes\n>>>> +     commitment_transaction (no option_simplified_commitment): 125 + \n>>>> 43 * num-htlc-outputs bytes\n>>>>           - version: 4 bytes\n>>>>           - witness_header <---- part of the witness data\n>>>>           - count_tx_in: 1 byte\n>>>> @@ -663,15 +730,32 @@ The *expected weight* of a commitment \n>>>> transaction is calculated as follows:\n>>>>               ....htlc_output's...\n>>>>           - lock_time: 4 bytes\n>>>> +     commitment_transaction (option_simplified_commitment): 223 + 43 \n>>>> * num-htlc-outputs bytes\n>>>> +        - version: 4 bytes\n>>>> +        - witness_header <---- part of the witness data\n>>>> +        - count_tx_in: 1 byte\n>>>> +        - tx_in: 41 bytes\n>>>> +            funding_input\n>>>> +        - count_tx_out: 1 byte\n>>>> +        - tx_out: 172 + 43 * num-htlc-outputs bytes\n>>>> +            output_paying_to_remote,\n>>>> +            output_paying_to_local,\n>>>> +            output_pushme,\n>>>> +            output_pushme,\n>>>> +            ....htlc_output's...\n>>>> +        - lock_time: 4 bytes\n>>>> +\n>>>>   Multiplying non-witness data by 4 results in a weight of:\n>>>> -    // 500 + 172 * num-htlc-outputs weight\n>>>> +    // 500 + 172 * num-htlc-outputs weight (no \n>>>> option_simplified_commitment)\n>>>> +    // 892 + 172 * num-htlc-outputs weight \n>>>> (option_simplified_commitment)\n>>>>       commitment_transaction_weight = 4 * commitment_transaction\n>>>>       // 224 weight\n>>>>       witness_weight = witness_header + witness\n>>>> -    overall_weight = 500 + 172 * num-htlc-outputs + 224 weight\n>>>> +    overall_weight (no option_simplified_commitment) = 500 + 172 * \n>>>> num-htlc-outputs + 224 weight\n>>>> +    overall_weight (option_simplified_commitment) = 892 + 172 * \n>>>> num-htlc-outputs + 224 weight\n>>>>   ## Expected Weight of HTLC-timeout and HTLC-success Transactions\n>>>> diff --git a/05-onchain.md b/05-onchain.md\n>>>> index 231c209..c5fb5e1 100644\n>>>> --- a/05-onchain.md\n>>>> +++ b/05-onchain.md\n>>>> @@ -89,21 +89,29 @@ trigger any action.\n>>>>   # Commitment Transaction\n>>>>   The local and remote nodes each hold a *commitment transaction*. \n>>>> Each of these\n>>>> -commitment transactions has four types of outputs:\n>>>> +commitment transactions has six types of outputs:\n>>>>   1. _local node's main output_: Zero or one output, to pay to the \n>>>> *local node's*\n>>>> -commitment pubkey.\n>>>> +delayed pubkey.\n>>>>   2. _remote node's main output_: Zero or one output, to pay to the \n>>>> *remote node's*\n>>>> -commitment pubkey.\n>>>> +pubkey.\n>>>> +1. _local node's push output_: Zero or one output, to pay to the \n>>>> *local node's*\n>>>> +delayed pubkey.\n>>>> +2. _remote node's push output_: Zero or one output, to pay to the \n>>>> *remote node's*\n>>>> +pubkey.\n>>>>   3. _local node's offered HTLCs_: Zero or more pending payments \n>>>> (*HTLCs*), to pay\n>>>>   the *remote node* in return for a payment preimage.\n>>>>   4. _remote node's offered HTLCs_: Zero or more pending payments \n>>>> (*HTLCs*), to\n>>>>   pay the *local node* in return for a payment preimage.\n>>>>   To incentivize the local and remote nodes to cooperate, an \n>>>> `OP_CHECKSEQUENCEVERIFY`\n>>>> -relative timeout encumbers the *local node's outputs* (in the *local \n>>>> node's\n>>>> +relative timeout encumbers some outputs: the *local node's outputs* \n>>>> (in the *local node's\n>>>>   commitment transaction*) and the *remote node's outputs* (in the \n>>>> *remote node's\n>>>> -commitment transaction*). So for example, if the local node publishes \n>>>> its\n>>>> +commitment transaction*). If `option_simplified_commitment` applies\n>>>> +to the commitment transaction, then the *to_remote* output of each \n>>>> commitment is\n>>>> +identically encumbered, for fairness.\n>>>> +\n>>>> +Without `option_simplified_commitment`, if the local node publishes its\n>>>>   commitment transaction, it will have to wait to claim its own funds,\n>>>>   whereas the remote node will have immediate access to its own funds. \n>>>> As a\n>>>>   consequence, the two commitment transactions are not identical, but \n>>>> they are\n>>>> @@ -140,6 +148,11 @@ A node:\n>>>>         - otherwise:\n>>>>           - MUST use the *last commitment transaction*, for which it \n>>>> has a\n>>>>           signature, to perform a *unilateral close*.\n>>>> +      - MUST spend any `to_local_pushme` output, providing sufficient \n>>>> fees as incentive to include the commitment transaction in a block\n>>>> +        - SHOULD use \n>>>> [replace-by-fee](https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki) \n>>>> or other mechanism on the spending transaction if it proves \n>>>> insufficient for timely inclusion in a block.\n>>>> +\n>>>> +A node:\n>>>> +  - MAY monitor the blockchain for unspent `to_local_pushme` and \n>>>> `to_remote_pushme` outputs and try to spend them after 10 confirmations.\n>>>>   ## Rationale\n>>>> @@ -154,7 +167,8 @@ need not consume resources monitoring the channel \n>>>> state.\n>>>>   There exists a bias towards preferring mutual closes over unilateral \n>>>> closes,\n>>>>   because outputs of the former are unencumbered by a delay and are \n>>>> directly\n>>>>   spendable by wallets. In addition, mutual close fees tend to be less \n>>>> exaggerated\n>>>> -than those of commitment transactions. So, the only reason not to use \n>>>> the\n>>>> +than those of commitment transactions (or in the case of \n>>>> `option_simplified_commitment`,\n>>>> +the commitment transaction may require a child transaction to cause \n>>>> it to be mined). So, the only reason not to use the\n>>>>   signature from `closing_signed` would be if the fee offered was too \n>>>> small for\n>>>>   it to be processed.\n>>>> diff --git a/09-features.md b/09-features.md\n>>>> index d06fcff..caea38b 100644\n>>>> --- a/09-features.md\n>>>> +++ b/09-features.md\n>>>> @@ -26,6 +26,7 @@ These flags may only be used in the `init` message:\n>>>>   | 3  | `initial_routing_sync` | Indicates that the sending node \n>>>> needs a complete routing information dump | [BOLT \n>>>> #7](07-routing-gossip.md#initial-sync) |\n>>>>   | 4/5  | `option_upfront_shutdown_script` | Commits to a shutdown \n>>>> scriptpubkey when opening channel | [BOLT \n>>>> #2](02-peer-protocol.md#the-open_channel-message) |\n>>>>   | 6/7  | `gossip_queries`           | More sophisticated gossip \n>>>> control | [BOLT #7](07-routing-gossip.md#query-messages) |\n>>>> +| 8/9  | `option_simplified_commitment`           | Simplified \n>>>> commitment transactions | [BOLT #3](03-transactions.md) |\n>>>>   ## Assigned `globalfeatures` flags\n>>>> _______________________________________________\n>>>> Lightning-dev mailing list\n>>>> Lightning-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>> \n>>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-22T05:12:54",
                "message_text_only": "Matt Corallo <lf-lists at mattcorallo.com> writes:\n> Ah, oops, indeed, that is much cleaner :). Still need a CSV of 1, though :(.\n\nOK, let's walk through this:\n\nLocally offered HTLC:\n- Local HTLC-Timeout tx is CLTV delayed, but remote can fulfill without delay.\nRemote offered HTLC:\n- Local HTLC-Success tx can be done without delay, but remote timeout is CLTV.\n\nIOW:\n- HTLC output scripts get a `1 OP_CSV OP_DROP` in the non-revoked branch:\n\n    OP_DUP OP_HASH160 <RIPEMD160(SHA256(revocationpubkey))> OP_EQUAL\n    OP_IF\n        OP_CHECKSIG\n    OP_ELSE\n +      1 OP_CHECKSEQUENCEVERIFY OP_DROP\n    ...\n- HTLC-Success tx needs nSequence = 1.\n- Similarly any self-generated fulfullment tx needs nSequence = 1.\n\nYech.\n\nI still want a new RBF rule where if you pay twice the current package\n*feerate* your tx is accepted, overriding RBF rules 3, 4 & 5.  Probably\nneed to increase the effective minrelay feerate for any txs adding to\nthat package, similarly (using that double-previous-package-feerate).\n\nThat would mean we're back to a single P2WSH(OP_TRUE) with less\nblockchain spam, and life is simple.  But I'll debate this on\nbitcoin-dev :)\n\nCheers,\nRusty."
            },
            {
                "author": "Matt Corallo",
                "date": "2018-11-25T19:09:25",
                "message_text_only": "Hmm, are we willing to consider CLTV sufficient? In case you have two \nHTLCs, one of medium-small value that has a low CLTV and one of high \nvalue that has a higher CLTV, you could potentially use the soon-CLTV to \ndelay the commitment transaction somewhat further if you broadcast it \nright as the sooner HTLC expires. This may be a bit edge-case-y but to \nkeep things symmetric and simplify analysis it seems simpler to just CSV \neverything by 1.\n\nAs for other RBF hacks, I think you may have a hard time convincing \npeople to accept free relay :p.\n\nWill kick off the discussion on bitcoin-dev once we're clear on our design.\n\nMatt\n\nOn 11/22/18 5:12 AM, Rusty Russell wrote:\n> Matt Corallo <lf-lists at mattcorallo.com> writes:\n>> Ah, oops, indeed, that is much cleaner :). Still need a CSV of 1, though :(.\n> \n> OK, let's walk through this:\n> \n> Locally offered HTLC:\n> - Local HTLC-Timeout tx is CLTV delayed, but remote can fulfill without delay.\n> Remote offered HTLC:\n> - Local HTLC-Success tx can be done without delay, but remote timeout is CLTV.\n> \n> IOW:\n> - HTLC output scripts get a `1 OP_CSV OP_DROP` in the non-revoked branch:\n> \n>      OP_DUP OP_HASH160 <RIPEMD160(SHA256(revocationpubkey))> OP_EQUAL\n>      OP_IF\n>          OP_CHECKSIG\n>      OP_ELSE\n>   +      1 OP_CHECKSEQUENCEVERIFY OP_DROP\n>      ...\n> - HTLC-Success tx needs nSequence = 1.\n> - Similarly any self-generated fulfullment tx needs nSequence = 1.\n> \n> Yech.\n> \n> I still want a new RBF rule where if you pay twice the current package\n> *feerate* your tx is accepted, overriding RBF rules 3, 4 & 5.  Probably\n> need to increase the effective minrelay feerate for any txs adding to\n> that package, similarly (using that double-previous-package-feerate).\n> \n> That would mean we're back to a single P2WSH(OP_TRUE) with less\n> blockchain spam, and life is simple.  But I'll debate this on\n> bitcoin-dev :)\n> \n> Cheers,\n> Rusty.\n>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-26T03:12:30",
                "message_text_only": "Matt Corallo <lf-lists at mattcorallo.com> writes:\n> Hmm, are we willing to consider CLTV sufficient? In case you have two \n> HTLCs, one of medium-small value that has a low CLTV and one of high \n> value that has a higher CLTV, you could potentially use the soon-CLTV to \n> delay the commitment transaction somewhat further if you broadcast it \n> right as the sooner HTLC expires.\n\nI think you haven't got the commitment tx onchain by the time the HTLC\nexpires, you're already in trouble.\n\nBut since there's no script length difference, it *is* simpler to\nprepend `1 OP_CHECKSEQUENCEVERIFY OP_DROP` to the start of each script.\n\nCheers,\nRusty."
            },
            {
                "author": "Matt Corallo",
                "date": "2018-11-29T17:13:44",
                "message_text_only": "For the low low cost of 3 witness bytes, I think the simplification of \nanalysis/separation of concerns is worth it, though I agree it is \nprobably not strictly required.\n\nOn 11/26/18 3:12 AM, Rusty Russell wrote:\n> Matt Corallo <lf-lists at mattcorallo.com> writes:\n>> Hmm, are we willing to consider CLTV sufficient? In case you have two\n>> HTLCs, one of medium-small value that has a low CLTV and one of high\n>> value that has a higher CLTV, you could potentially use the soon-CLTV to\n>> delay the commitment transaction somewhat further if you broadcast it\n>> right as the sooner HTLC expires.\n> \n> I think you haven't got the commitment tx onchain by the time the HTLC\n> expires, you're already in trouble.\n> \n> But since there's no script length difference, it *is* simpler to\n> prepend `1 OP_CHECKSEQUENCEVERIFY OP_DROP` to the start of each script.\n> \n> Cheers,\n> Rusty.\n>"
            },
            {
                "author": "David A. Harding",
                "date": "2018-11-25T18:47:17",
                "message_text_only": "On Wed, Nov 21, 2018 at 12:47:17PM +1030, Rusty Russell wrote:\n> I'm also starting to implement this, to see what I missed!\n> \n> - Feerate is fixed at 253 [satoshis per 1,000 weight]\n\nIIUC, this is just over Bitcoin Core's default minimum relay fee of\n0.00001000 BTC/vByte.  That works right now, as mempools are nowhere\nnear full, but if they fill up again and the BIP133 feefilters are\nincreased by any amount, nodes will no longer relay transactions with\nminimum feerates.\n\nIn that case, how does the commitment transaction get relayed in order\nfor its `to_*_pushme` outputs to be spent for CPFP fee bumping?[1]\n\nThere's currently some text in the PR about using\nsighash_single|sighash_anyonecanpay for use with RBF, but I don't think\nthat can apply to spending the commitment transaction, as that would\nallow not just adding new inputs and outputs, but also removing all but\nthe 'singled' output (allowing theft of its value).\n\n-Dave\n\n[1] I don't think Bitcoin Core currently relays transaction packages\nconsisting of parents below the relay fee limit and children\nsufficiently above the limit to pay for their parents.  This has\ncertainly been discussed, so maybe I'm wrong and it is available or\nmaybe it'll be available in the future.\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181125/c4adf28a/attachment.sig>"
            },
            {
                "author": "Matt Corallo",
                "date": "2018-11-25T19:02:55",
                "message_text_only": "Indeed, this change assumes (a) the change in relay policy around CPFP \nthat is discussed on this thread, and (b) some kind of (at least very \nbasic) package relay in Bitcoin Core. (a) requires some discussion, but \npeople seem at least not entirely against it when I've discussed it with \npeople, and should be easy to implement, (b) requires a bunch more work, \nbut has been a longstanding goal for a while.\n\nMatt\n\nOn 11/25/18 6:47 PM, David A. Harding wrote:\n> On Wed, Nov 21, 2018 at 12:47:17PM +1030, Rusty Russell wrote:\n>> I'm also starting to implement this, to see what I missed!\n>>\n>> - Feerate is fixed at 253 [satoshis per 1,000 weight]\n> \n> IIUC, this is just over Bitcoin Core's default minimum relay fee of\n> 0.00001000 BTC/vByte.  That works right now, as mempools are nowhere\n> near full, but if they fill up again and the BIP133 feefilters are\n> increased by any amount, nodes will no longer relay transactions with\n> minimum feerates.\n> \n> In that case, how does the commitment transaction get relayed in order\n> for its `to_*_pushme` outputs to be spent for CPFP fee bumping?[1]\n> \n> There's currently some text in the PR about using\n> sighash_single|sighash_anyonecanpay for use with RBF, but I don't think\n> that can apply to spending the commitment transaction, as that would\n> allow not just adding new inputs and outputs, but also removing all but\n> the 'singled' output (allowing theft of its value).\n> \n> -Dave\n> \n> [1] I don't think Bitcoin Core currently relays transaction packages\n> consisting of parents below the relay fee limit and children\n> sufficiently above the limit to pay for their parents.  This has\n> certainly been discussed, so maybe I'm wrong and it is available or\n> maybe it'll be available in the future.\n> \n> \n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>"
            }
        ],
        "thread_summary": {
            "title": "First draft of option_simplfied_commitment",
            "categories": [
                "Lightning-dev",
                "PATCH"
            ],
            "authors": [
                "Rusty Russell",
                "David A. Harding",
                "Matt Corallo"
            ],
            "messages_count": 11,
            "total_messages_chars_count": 156672
        }
    },
    {
        "title": "[Lightning-dev] lookupinvoice",
        "thread_messages": [
            {
                "author": "Sarat G",
                "date": "2018-11-23T10:46:04",
                "message_text_only": "Hi,\n\nI'm been working on the LN repo for a while now. I would like to know if\nthere is any way that a payee can lookup the invoice it gets paid, i.e\nsimilar to the 'lookupinvoice' command as provided by the lnd(Golang).\n\nMy problem description is: There is a hub, to which all players make\npayments of different amounts, the hub node has to make sure which invoice\nof it got paid to it from which player.\n\nIf there isn't any single command written for this, could you help me in\nproviding me the if any combination of commands can do this job for me.\n\nThank You.\n\nRegards,\nSarat G\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181123/bde9dcc8/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-26T03:27:59",
                "message_text_only": "Sarat G <sarath.ginjupalli89 at gmail.com> writes:\n> Hi,\n>\n> I'm been working on the LN repo for a while now. I would like to know if\n> there is any way that a payee can lookup the invoice it gets paid, i.e\n> similar to the 'lookupinvoice' command as provided by the lnd(Golang).\n\nHi Sarat,\n\n        I'm confused; \"the LN repo\" is ambigious, as there are several,\neach with their own places to ask questions:\n\nhttps://github.com/ACINQ/eclair-wallet/\nhttps://github.com/ElementsProject/lightning\nhttps://github.com/LightningNetwork/lnd/\nhttps://github.com/nayutaco/ptarmigan\nhttps://github.com/rust-bitcoin/rust-lightning\n\nThen of course there's the spec repo as well, which guides us all:\n\n        https://github.com/lightningnetwork/lightning-rfc\n\nBut AFAICT (though your question is off-topic for this list):\n\n        lnd has lookupinvoice which looks up by hash[1]\n        eclair has checkpayment which looks up by hash or bolt11[2]\n        c-lightning has listinvoices which can lookup by label[3], or\n           wait(any)invoice[4] which is used for polling.\n\nWould love someone to write a rosetta stone for the different APIs!\n\nCheers,\nRusty.\n\n[1] https://api.lightning.community/#lookupinvoice\n[2] https://github.com/ACINQ/eclair/wiki/API\n[3] https://github.com/ElementsProject/lightning/blob/master/doc/lightning-listinvoices.7.txt\n[4] https://github.com/ElementsProject/lightning/blob/master/doc/lightning-waitanyinvoice.7.txt"
            },
            {
                "author": "Sarat G",
                "date": "2018-11-26T08:54:41",
                "message_text_only": "Hi Rusty,\n\nThanks for your reply.\n\nI'm using the C lightning repo for my project(\nhttps://github.com/ElementsProject/lightning). Sorry, I framed the question\nwrongly. Yes, I can use listinvoices to look up for the invoices created at\nthe node.\n\nMy scenario is something like this, I'm looking up whether an invoice gets\npaid or not at the receiver end. For that at this point, I'm calling\nwaitinvoice to see whether an invoice gets paid or not. I would like to\nknow is there any way that the receiver could be aware that the particular\ninvoice created by it paid or not.\n\nThe problem is using waitinvoice in my case, it's making my process hang\ntill the invoice gets paid. Some workaround which I'm using for this\nproblem is I'm looking up the difference in amount of the label\n\"msatoshi_to_us\" while running the listpeers command.\n\nThank You.\n\nRegards,\nSarat G\n\n\n\n\nOn Mon, Nov 26, 2018 at 8:59 AM Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> Sarat G <sarath.ginjupalli89 at gmail.com> writes:\n> > Hi,\n> >\n> > I'm been working on the LN repo for a while now. I would like to know if\n> > there is any way that a payee can lookup the invoice it gets paid, i.e\n> > similar to the 'lookupinvoice' command as provided by the lnd(Golang).\n>\n> Hi Sarat,\n>\n>         I'm confused; \"the LN repo\" is ambigious, as there are several,\n> each with their own places to ask questions:\n>\n> https://github.com/ACINQ/eclair-wallet/\n> https://github.com/ElementsProject/lightning\n> https://github.com/LightningNetwork/lnd/\n> https://github.com/nayutaco/ptarmigan\n> https://github.com/rust-bitcoin/rust-lightning\n>\n> Then of course there's the spec repo as well, which guides us all:\n>\n>         https://github.com/lightningnetwork/lightning-rfc\n>\n> But AFAICT (though your question is off-topic for this list):\n>\n>         lnd has lookupinvoice which looks up by hash[1]\n>         eclair has checkpayment which looks up by hash or bolt11[2]\n>         c-lightning has listinvoices which can lookup by label[3], or\n>            wait(any)invoice[4] which is used for polling.\n>\n> Would love someone to write a rosetta stone for the different APIs!\n>\n> Cheers,\n> Rusty.\n>\n> [1] https://api.lightning.community/#lookupinvoice\n> [2] https://github.com/ACINQ/eclair/wiki/API\n> [3]\n> https://github.com/ElementsProject/lightning/blob/master/doc/lightning-listinvoices.7.txt\n> [4]\n> https://github.com/ElementsProject/lightning/blob/master/doc/lightning-waitanyinvoice.7.txt\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181126/363eac97/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "lookupinvoice",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Sarat G"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 4839
        }
    },
    {
        "title": "[Lightning-dev] Penalty tx and RBF",
        "thread_messages": [
            {
                "author": "Cezary Dziemian",
                "date": "2018-11-23T17:29:48",
                "message_text_only": "Hello all,\n\nSorry for my ignorance. I have two questions related with penalty txs. I\nassume, that when someone commits obsolete commitment tx, my node\nautomatically commit penalty transaction.\n\nWhat if fees suddenly increases? Can my node use RBF to increase fee?\n\nIs there any approach common to major 3 implementations?\n\nHow much time (how many blocks) do my node have to commit penalty tx? Is\nthere some value common for implementations?\n\nBest regards,\nCezary Dziemian\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181123/34c60ea1/attachment.html>"
            },
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2018-11-23T18:07:17",
                "message_text_only": "Dear Cezary,\n\nas far as I understand the problem in the case of a unilateral (force)\nclose are:\n\n1.) In order to RBF your commitment transaction you would have to have the\nsignature of your former channel partner. since you initiated a force close\nit is unlikely that you get this signature to RBF because then you could\nhave done a mutual close right away which is cheaper since less tx are\ninvovled to claim all funds back.\n2.) In order to CPFP you have to be able to spend your output which can't\nwork because there is a timelock on it.\n\nI believe on the last lightning developer summit this issue was discussed\nand it was agreed that for BOLT1.1 we want have a third output in the\ncommitment transactions which anyone can spend (OP_TRUE) and which is just\nabove the dust level. This output is supposed to have no timelock so that\nanyone can CPFP it. In the general case miners of the block could collect\nthe output as a fee. You can find a pointer to this on this wikipage in the\nlightning-rfc git repo:\nhttps://github.com/lightningnetwork/lightning-rfc/wiki/Lightning-Specification-1.1-Proposal-States\n(look in the section tx and fees)\n\nbest Rene\n\nOn Fri, Nov 23, 2018 at 6:30 PM Cezary Dziemian <cezary.dziemian at gmail.com>\nwrote:\n\n> Hello all,\n>\n> Sorry for my ignorance. I have two questions related with penalty txs. I\n> assume, that when someone commits obsolete commitment tx, my node\n> automatically commit penalty transaction.\n>\n> What if fees suddenly increases? Can my node use RBF to increase fee?\n>\n> Is there any approach common to major 3 implementations?\n>\n> How much time (how many blocks) do my node have to commit penalty tx? Is\n> there some value common for implementations?\n>\n> Best regards,\n> Cezary Dziemian\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n\n\n-- \nhttps://www.rene-pickhardt.de\n\nSkype: rene.pickhardt\n\nmobile: +49 (0)176 5762 3618\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181123/e0bb5ac7/attachment.html>"
            },
            {
                "author": "Cezary Dziemian",
                "date": "2018-11-23T19:34:38",
                "message_text_only": "Thanks for answer,\n\nMy knowledge is mostly based on this article:\n\nhttps://bitcoinmagazine.com/articles/understanding-the-lightning-network-part-building-a-bidirectional-payment-channel-1464710791/\n\nGraph at the end shows that in order to claim former channel partner funds\nI need to provide child transaction that contains my signature and secret.\nThis secret is evidence.that partner didn't commit the last transaction.\n\nSo the penalty transaction uses comitment transaction output as its input\nand penalty transaction can be sign by one side only. Am I right, or I just\ndon't understand how it works? Or maybe this graph do not represents\ncorrectly how commitment and penalty transactions are already developed?\n\nBest Regards,\nCezary Dziemian\n\n\npt., 23 lis 2018 o 19:07 Ren\u00e9 Pickhardt <r.pickhardt at googlemail.com>\nnapisa\u0142(a):\n\n> Dear Cezary,\n>\n> as far as I understand the problem in the case of a unilateral (force)\n> close are:\n>\n> 1.) In order to RBF your commitment transaction you would have to have the\n> signature of your former channel partner. since you initiated a force close\n> it is unlikely that you get this signature to RBF because then you could\n> have done a mutual close right away which is cheaper since less tx are\n> invovled to claim all funds back.\n> 2.) In order to CPFP you have to be able to spend your output which can't\n> work because there is a timelock on it.\n>\n> I believe on the last lightning developer summit this issue was discussed\n> and it was agreed that for BOLT1.1 we want have a third output in the\n> commitment transactions which anyone can spend (OP_TRUE) and which is just\n> above the dust level. This output is supposed to have no timelock so that\n> anyone can CPFP it. In the general case miners of the block could collect\n> the output as a fee. You can find a pointer to this on this wikipage in the\n> lightning-rfc git repo:\n> https://github.com/lightningnetwork/lightning-rfc/wiki/Lightning-Specification-1.1-Proposal-States\n> (look in the section tx and fees)\n>\n> best Rene\n>\n> On Fri, Nov 23, 2018 at 6:30 PM Cezary Dziemian <cezary.dziemian at gmail.com>\n> wrote:\n>\n>> Hello all,\n>>\n>> Sorry for my ignorance. I have two questions related with penalty txs. I\n>> assume, that when someone commits obsolete commitment tx, my node\n>> automatically commit penalty transaction.\n>>\n>> What if fees suddenly increases? Can my node use RBF to increase fee?\n>>\n>> Is there any approach common to major 3 implementations?\n>>\n>> How much time (how many blocks) do my node have to commit penalty tx? Is\n>> there some value common for implementations?\n>>\n>> Best regards,\n>> Cezary Dziemian\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n>\n> --\n> https://www.rene-pickhardt.de\n>\n> Skype: rene.pickhardt\n>\n> mobile: +49 (0)176 5762 3618\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181123/54a5fb54/attachment.html>"
            },
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2018-11-23T20:03:59",
                "message_text_only": "Hey Cezary,\n\nsorry I misread your initial question. I thought you where referring to the\n(probably bigger problem) of getting the commitment transaction to be mined\nbecause RBF does not work. But if we assume that your channel partner\npublished an outdated commitment transaction which got mined then you can\nclaim (both) outputs (your node should do this automatically) with this\npenalty transaction. This penalty transaction is spending the outputs of\nthe commitment transaction and is signed with your nodes private key.\nTherefor as far as I know you should be able to RBF this penalty\ntransaction. Also I believe you understand the process correctly.\n\nActually since the timelock on the commitment transaction will at some\npoint in time be over (in which case also your channel partner can spend\ntheir output) you have an economic incentive to quickly get the penalty\ntransaction minded by using rather high fees or in case at this time really\na lot of transactions come in to RBF. I currently see no reason why you\ncould not RBF the penalty transaction. In case I oversee something I am\nsure someone here on the list will correct me.\n\nbest regards Rene\n\nOn Fri, Nov 23, 2018 at 8:34 PM Cezary Dziemian <cezary.dziemian at gmail.com>\nwrote:\n\n> Thanks for answer,\n>\n> My knowledge is mostly based on this article:\n>\n>\n> https://bitcoinmagazine.com/articles/understanding-the-lightning-network-part-building-a-bidirectional-payment-channel-1464710791/\n>\n> Graph at the end shows that in order to claim former channel partner funds\n> I need to provide child transaction that contains my signature and secret.\n> This secret is evidence.that partner didn't commit the last transaction.\n>\n> So the penalty transaction uses comitment transaction output as its input\n> and penalty transaction can be sign by one side only. Am I right, or I just\n> don't understand how it works? Or maybe this graph do not represents\n> correctly how commitment and penalty transactions are already developed?\n>\n> Best Regards,\n> Cezary Dziemian\n>\n>\n> pt., 23 lis 2018 o 19:07 Ren\u00e9 Pickhardt <r.pickhardt at googlemail.com>\n> napisa\u0142(a):\n>\n>> Dear Cezary,\n>>\n>> as far as I understand the problem in the case of a unilateral (force)\n>> close are:\n>>\n>> 1.) In order to RBF your commitment transaction you would have to have\n>> the signature of your former channel partner. since you initiated a force\n>> close it is unlikely that you get this signature to RBF because then you\n>> could have done a mutual close right away which is cheaper since less tx\n>> are invovled to claim all funds back.\n>> 2.) In order to CPFP you have to be able to spend your output which can't\n>> work because there is a timelock on it.\n>>\n>> I believe on the last lightning developer summit this issue was discussed\n>> and it was agreed that for BOLT1.1 we want have a third output in the\n>> commitment transactions which anyone can spend (OP_TRUE) and which is just\n>> above the dust level. This output is supposed to have no timelock so that\n>> anyone can CPFP it. In the general case miners of the block could collect\n>> the output as a fee. You can find a pointer to this on this wikipage in the\n>> lightning-rfc git repo:\n>> https://github.com/lightningnetwork/lightning-rfc/wiki/Lightning-Specification-1.1-Proposal-States\n>> (look in the section tx and fees)\n>>\n>> best Rene\n>>\n>> On Fri, Nov 23, 2018 at 6:30 PM Cezary Dziemian <\n>> cezary.dziemian at gmail.com> wrote:\n>>\n>>> Hello all,\n>>>\n>>> Sorry for my ignorance. I have two questions related with penalty txs. I\n>>> assume, that when someone commits obsolete commitment tx, my node\n>>> automatically commit penalty transaction.\n>>>\n>>> What if fees suddenly increases? Can my node use RBF to increase fee?\n>>>\n>>> Is there any approach common to major 3 implementations?\n>>>\n>>> How much time (how many blocks) do my node have to commit penalty tx? Is\n>>> there some value common for implementations?\n>>>\n>>> Best regards,\n>>> Cezary Dziemian\n>>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>>\n>>\n>> --\n>> https://www.rene-pickhardt.de\n>>\n>> Skype: rene.pickhardt\n>>\n>> mobile: +49 (0)176 5762 3618\n>>\n>\n\n-- \nhttps://www.rene-pickhardt.de\n\nSkype: rene.pickhardt\n\nmobile: +49 (0)176 5762 3618\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181123/bb27a317/attachment-0001.html>"
            },
            {
                "author": "Cezary Dziemian",
                "date": "2018-11-23T20:31:20",
                "message_text_only": "For sure my questions are hard to understand because of my English skills.\nSorry for that and thanks for clarification.\n\nAlso I don't see no reason why I could not RBF the penalty transaction. The\nmain question is - is this implemented as default behavior in popular LN\nimplementations: clightning, eclair, lnd?\n\nI'm thinking about this because LNBIG.com nodes opened 300BTC in channels\nlast week what is suspicious for me. I can imagine potential attack method\nbased on committing a lot of outdated commitment transactions and then spam\nbitcoin mempool with transactions in order to increase fees. If RBF is not\nimplemented as default behavior for penalty transactions, then this can be\nmethod to steal a lot of bitcoins. The risk for attacker seems not to be\nvery high, as penalty can be 10 times lower than funds that can be\npotential stolen.\n\nCheers,\nCezary Dziemian\n\n\n\npt., 23 lis 2018 o 21:04 Ren\u00e9 Pickhardt <r.pickhardt at googlemail.com>\nnapisa\u0142(a):\n\n> Hey Cezary,\n>\n> sorry I misread your initial question. I thought you where referring to\n> the (probably bigger problem) of getting the commitment transaction to be\n> mined because RBF does not work. But if we assume that your channel partner\n> published an outdated commitment transaction which got mined then you can\n> claim (both) outputs (your node should do this automatically) with this\n> penalty transaction. This penalty transaction is spending the outputs of\n> the commitment transaction and is signed with your nodes private key.\n> Therefor as far as I know you should be able to RBF this penalty\n> transaction. Also I believe you understand the process correctly.\n>\n> Actually since the timelock on the commitment transaction will at some\n> point in time be over (in which case also your channel partner can spend\n> their output) you have an economic incentive to quickly get the penalty\n> transaction minded by using rather high fees or in case at this time really\n> a lot of transactions come in to RBF. I currently see no reason why you\n> could not RBF the penalty transaction. In case I oversee something I am\n> sure someone here on the list will correct me.\n>\n> best regards Rene\n>\n> On Fri, Nov 23, 2018 at 8:34 PM Cezary Dziemian <cezary.dziemian at gmail.com>\n> wrote:\n>\n>> Thanks for answer,\n>>\n>> My knowledge is mostly based on this article:\n>>\n>>\n>> https://bitcoinmagazine.com/articles/understanding-the-lightning-network-part-building-a-bidirectional-payment-channel-1464710791/\n>>\n>> Graph at the end shows that in order to claim former channel partner\n>> funds I need to provide child transaction that contains my signature and\n>> secret. This secret is evidence.that partner didn't commit the last\n>> transaction.\n>>\n>> So the penalty transaction uses comitment transaction output as its input\n>> and penalty transaction can be sign by one side only. Am I right, or I just\n>> don't understand how it works? Or maybe this graph do not represents\n>> correctly how commitment and penalty transactions are already developed?\n>>\n>> Best Regards,\n>> Cezary Dziemian\n>>\n>>\n>> pt., 23 lis 2018 o 19:07 Ren\u00e9 Pickhardt <r.pickhardt at googlemail.com>\n>> napisa\u0142(a):\n>>\n>>> Dear Cezary,\n>>>\n>>> as far as I understand the problem in the case of a unilateral (force)\n>>> close are:\n>>>\n>>> 1.) In order to RBF your commitment transaction you would have to have\n>>> the signature of your former channel partner. since you initiated a force\n>>> close it is unlikely that you get this signature to RBF because then you\n>>> could have done a mutual close right away which is cheaper since less tx\n>>> are invovled to claim all funds back.\n>>> 2.) In order to CPFP you have to be able to spend your output which\n>>> can't work because there is a timelock on it.\n>>>\n>>> I believe on the last lightning developer summit this issue was\n>>> discussed and it was agreed that for BOLT1.1 we want have a third output in\n>>> the commitment transactions which anyone can spend (OP_TRUE) and which is\n>>> just above the dust level. This output is supposed to have no timelock so\n>>> that anyone can CPFP it. In the general case miners of the block could\n>>> collect the output as a fee. You can find a pointer to this on this\n>>> wikipage in the lightning-rfc git repo:\n>>> https://github.com/lightningnetwork/lightning-rfc/wiki/Lightning-Specification-1.1-Proposal-States\n>>> (look in the section tx and fees)\n>>>\n>>> best Rene\n>>>\n>>> On Fri, Nov 23, 2018 at 6:30 PM Cezary Dziemian <\n>>> cezary.dziemian at gmail.com> wrote:\n>>>\n>>>> Hello all,\n>>>>\n>>>> Sorry for my ignorance. I have two questions related with penalty txs.\n>>>> I assume, that when someone commits obsolete commitment tx, my node\n>>>> automatically commit penalty transaction.\n>>>>\n>>>> What if fees suddenly increases? Can my node use RBF to increase fee?\n>>>>\n>>>> Is there any approach common to major 3 implementations?\n>>>>\n>>>> How much time (how many blocks) do my node have to commit penalty tx?\n>>>> Is there some value common for implementations?\n>>>>\n>>>> Best regards,\n>>>> Cezary Dziemian\n>>>> _______________________________________________\n>>>> Lightning-dev mailing list\n>>>> Lightning-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>>\n>>>\n>>>\n>>> --\n>>> https://www.rene-pickhardt.de\n>>>\n>>> Skype: rene.pickhardt\n>>>\n>>> mobile: +49 (0)176 5762 3618\n>>>\n>>\n>\n> --\n> https://www.rene-pickhardt.de\n>\n> Skype: rene.pickhardt\n>\n> mobile: +49 (0)176 5762 3618\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181123/fbdf2e32/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-23T23:17:34",
                "message_text_only": "Good morning Cezary and Rene,\n\nThe commitment transaction being RBF-able is not important, as old commitment transactions are in fact how theft attempts are made.\n\nWhat is important to be RBF-able is the punishment transaction which spends the commitment transaction.\nFortunately:\n\n1.  The punishment branch of the commitment SCRIPT has no CSV, so it can be spent immediately to get the old commitment confirmed via CPFP.\n2.  The punishment branch requires only a single signature from one node, making RBF trivial.\n\nI believe at least lnd already does RBF for breach claim transactions, I will have to review c-lightning code to see if onchaind does so.\nI vaguely remember it being brought up some time ago for c-lightning.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181123/e394e0a8/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Penalty tx and RBF",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Ren\u00e9 Pickhardt",
                "Cezary Dziemian",
                "ZmnSCPxj"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 17113
        }
    },
    {
        "title": "[Lightning-dev] [META] Organization of 1.1 Spec Effort",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-11-26T23:29:01",
                "message_text_only": "Hi all,\n\n        As you may know, for 1.0 spec we had a biweekly Google Hangout,\nat 5:30am Adelaide time (Monday 19:00 UTC, or 20:00 UTC Q3/4).  You can\nsee the minutes of all meetings here:\n\n        https://docs.google.com/document/d/1oU4wxzGsYd0T084rTXJbedb7Gvdtj4ax638nMkYUmco\n\nThe current process rules are:\n\n1. Any substantive spec change requires unanimous approval at the\n   meeting before application.\n2. Any implementation changes generally require two interoperable\n   implementations before they are considered final.\n3. \"typo, formatting and spelling\" fixes which can be applied after two\n   acks without a meeting necessary.\n\nIt's time to revisit this as we approach 1.1:\n\n1. Should we move to an IRC meeting?  Bitcoin development does this.\n   It's more inclusive, and better recorded.  But it can be\n   lower-bandwidth.\n\n2. Should we have a more formal approval method for PRs, eg. a\n   \"CONSENSUS:YES\" tag we apply once we have acks from two teams and no\n   Naks, then a meeting to review consensus, followed by \"FINAL\" tag and\n   commit the next meeting?  That gives you at least two weeks to\n   comment on the final draft.\n\nSide note: I've added milestones to PRs as 1.0/1.1; I'm hoping to clear\nall 1.0 PRs this week for tagging in the next meeting, then we can start\non 1.1 commits.\n\nThanks!\nRusty."
            },
            {
                "author": "Matt Corallo",
                "date": "2018-11-27T00:13:27",
                "message_text_only": "+100 for IRC meetings, though, really, I'd much much stronger prefer substantive discussion happen on GitHub or the mailing list. Doing finalization in a live meeting is really unfair to those who can't find the time to attend regularly (or happen to miss the one where that thing was discussed that they care about).\n\n> On Nov 26, 2018, at 18:29, Rusty Russell <rusty at rustcorp.com.au> wrote:\n> \n> Hi all,\n> \n>        As you may know, for 1.0 spec we had a biweekly Google Hangout,\n> at 5:30am Adelaide time (Monday 19:00 UTC, or 20:00 UTC Q3/4).  You can\n> see the minutes of all meetings here:\n> \n>        https://docs.google.com/document/d/1oU4wxzGsYd0T084rTXJbedb7Gvdtj4ax638nMkYUmco\n> \n> The current process rules are:\n> \n> 1. Any substantive spec change requires unanimous approval at the\n>   meeting before application.\n> 2. Any implementation changes generally require two interoperable\n>   implementations before they are considered final.\n> 3. \"typo, formatting and spelling\" fixes which can be applied after two\n>   acks without a meeting necessary.\n> \n> It's time to revisit this as we approach 1.1:\n> \n> 1. Should we move to an IRC meeting?  Bitcoin development does this.\n>   It's more inclusive, and better recorded.  But it can be\n>   lower-bandwidth.\n> \n> 2. Should we have a more formal approval method for PRs, eg. a\n>   \"CONSENSUS:YES\" tag we apply once we have acks from two teams and no\n>   Naks, then a meeting to review consensus, followed by \"FINAL\" tag and\n>   commit the next meeting?  That gives you at least two weeks to\n>   comment on the final draft.\n> \n> Side note: I've added milestones to PRs as 1.0/1.1; I'm hoping to clear\n> all 1.0 PRs this week for tagging in the next meeting, then we can start\n> on 1.1 commits.\n> \n> Thanks!\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2018-11-27T07:00:05",
                "message_text_only": "Hey Rusty,\n\nNo matter how we agree for the process I suggest to create a wiki page on\nwhich we make it transparent and link to it from README.md.\n\nThe current process was new to me and I think one cannot expect newcomers\nto read through the entire Mailinglist.\n\nAs soon as we have an agreement I can create this PR together with more\nuseful information for newcomers.\n\nBest regards Rene\n\nAm Di., 27. Nov. 2018, 01:13 hat Matt Corallo <lf-lists at mattcorallo.com>\ngeschrieben:\n\n> +100 for IRC meetings, though, really, I'd much much stronger prefer\n> substantive discussion happen on GitHub or the mailing list. Doing\n> finalization in a live meeting is really unfair to those who can't find the\n> time to attend regularly (or happen to miss the one where that thing was\n> discussed that they care about).\n>\n> > On Nov 26, 2018, at 18:29, Rusty Russell <rusty at rustcorp.com.au> wrote:\n> >\n> > Hi all,\n> >\n> >        As you may know, for 1.0 spec we had a biweekly Google Hangout,\n> > at 5:30am Adelaide time (Monday 19:00 UTC, or 20:00 UTC Q3/4).  You can\n> > see the minutes of all meetings here:\n> >\n> >\n> https://docs.google.com/document/d/1oU4wxzGsYd0T084rTXJbedb7Gvdtj4ax638nMkYUmco\n> >\n> > The current process rules are:\n> >\n> > 1. Any substantive spec change requires unanimous approval at the\n> >   meeting before application.\n> > 2. Any implementation changes generally require two interoperable\n> >   implementations before they are considered final.\n> > 3. \"typo, formatting and spelling\" fixes which can be applied after two\n> >   acks without a meeting necessary.\n> >\n> > It's time to revisit this as we approach 1.1:\n> >\n> > 1. Should we move to an IRC meeting?  Bitcoin development does this.\n> >   It's more inclusive, and better recorded.  But it can be\n> >   lower-bandwidth.\n> >\n> > 2. Should we have a more formal approval method for PRs, eg. a\n> >   \"CONSENSUS:YES\" tag we apply once we have acks from two teams and no\n> >   Naks, then a meeting to review consensus, followed by \"FINAL\" tag and\n> >   commit the next meeting?  That gives you at least two weeks to\n> >   comment on the final draft.\n> >\n> > Side note: I've added milestones to PRs as 1.0/1.1; I'm hoping to clear\n> > all 1.0 PRs this week for tagging in the next meeting, then we can start\n> > on 1.1 commits.\n> >\n> > Thanks!\n> > Rusty.\n> > _______________________________________________\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181127/bcd1d1ff/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2018-11-28T14:43:32",
                "message_text_only": "On November 27, 2018 12:13:27 AM UTC, Matt Corallo <lf-lists at mattcorallo.com> wrote:\n>+100 for IRC meetings, though, really, I'd much much stronger prefer\n>substantive discussion happen on GitHub or the mailing list. Doing\n>finalization in a live meeting is really unfair to those who can't find\n>the time to attend regularly (or happen to miss the one where that\n>thing was discussed that they care about).\n\nAlso keep in mind that textual communication poses less barriers for many people vs. audio/visual meetings. Not everyone wants their face to be seen or voice (literally) heard.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 500 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181128/f38096ec/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Organization of 1.1 Spec Effort",
            "categories": [
                "Lightning-dev",
                "META"
            ],
            "authors": [
                "Rusty Russell",
                "Ren\u00e9 Pickhardt",
                "Matt Corallo",
                "Peter Todd"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 7105
        }
    },
    {
        "title": "[Lightning-dev] [DRAFT] Multi-cell-hop onion with TLV (and example for multi-part-payment)",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-11-28T00:21:59",
                "message_text_only": "There's a kinda-neat intersection between the \"use TLV\" proposal and the\n\"multi-cell-onion\" idea, so I want to make a concrete proposal (wording\nneeds formalization):\n\nMulti-cell structure:\n\n1. `realm` (or `per_hop_type` if you prefer) meaning expanded.\n2. Lower 4 bits is `num_extra_cells` to use (ie. total 1-17 cells).\n3. Upper 4 bits reserved: if set, drop.\n4. HMAC on end covers that many per-hops.\n5. Padding is thus 12 bytes + 64 * `num_extra_cells`.\n\nStructure of padding changes:\n\n1. We make the onion `padding` contain TLV, rename to `tlv`.\n2. TLVs (as always!) are in lexicographical order (with shortest-wins on\n   tiebreak).\n3. TLVs follow unknown-odd-is-ok rule.\n4. No 0-type; that terminates (backwards compat with 0-filled padding).\n\nNew onion error value:\n\n1. type: PERM|22 (`tlv_element_invalid`)\n2. `2`:`offset`\n\nThe writer MUST set `offset` to a byte offset within the `tlv` field\nof the tlv element it rejected.  It SHOULD use the offset of the `type` byte of the TLV\nelement if it didn't understand it, the offset the `len` byte of the TLV\nelement if it was an incorrect length, or otherwise within the `value`\nif the value was somehow invalid.\n\nTLVs defined for initial onion:\n\n* type 2: `switch_chain`\n  length: 32\n  value: chain_id of new chain.\n\n  Used to switch chains during transit or at final hop.\n\n---\nUse with multi-part payment (\"base AMP\"):\n\n* type 4: `total_payment`\n  length: variable, <= 8\n  value: amount of total payment, in msat (big-endian of course).\n\n  Writer must only use for final hop, and only if bolt11 flagged it as\n  available (bolt11-multi_part_available).  May use even if this payment\n  meets the total_payment requirement.\n\n  Reader MUST reject if not final hop, MAY reject if invoice was not\n  `bolt11-multi_part_available`.  Reader SHOULD wait until total parts\n  meet or exceed `total_payment` (exceed may be due to fuzzing) [rest\n  as per previous posts].\n  \n\nThoughts?\nRusty.\nPS.  I prefer 'multi-part-payment' to 'base AMP' in the spec.  It's more\n     explicit, and leaves the namespace clear for more atomicy AMPs."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-28T03:51:04",
                "message_text_only": "Good morning Rusty,\n\n> There's a kinda-neat intersection between the \"use TLV\" proposal and the\n> \"multi-cell-onion\" idea, so I want to make a concrete proposal (wording\n> needs formalization):\n>\n> Multi-cell structure:\n>\n> 1.  `realm` (or `per_hop_type` if you prefer) meaning expanded.\n> 2.  Lower 4 bits is `num_extra_cells` to use (ie. total 1-17 cells).\n> 3.  Upper 4 bits reserved: if set, drop.\n\nWhat does drop mean exactly?\nOr an error with `BADONION` bit set? (\"drop the HTLC as a failure\")\nOr should we try to consume the next 65 bytes? (\"drop this cell and process the next cell\")\n\n> 4.  HMAC on end covers that many per-hops.\n> 5.  Padding is thus 12 bytes + 64 * `num_extra_cells`.\n\nIs it not multiple of 65?\n\nAlso, it seems to me that the existing `per_hop_type`/`realm`/`packet_type` of 0 implies that only a single 65-byte section is used (as is current behavior).  Then a byte of 1 indicates two 65-byte sections are used, and so on.\nI broadly approve of this design.\n\nHowever with only 4 bits it seems to me:\n\n>(ie. total 1-17 cells).\n\nis inaccurate? Only 1->16 cells?\n\n>\n>     Structure of padding changes:\n>\n> 6.  We make the onion `padding` contain TLV, rename to `tlv`.\n> 7.  TLVs (as always!) are in lexicographical order (with shortest-wins on\n>     tiebreak).\n\nIf types are unique, then \"shortest-wins\" would not matter.\nI believe there was a vague agreement that types would have to be unique in a TLV sequence, and that if a type could be variadic, it would be variadic within its own value-blob.\n\n>\n> 8.  TLVs follow unknown-odd-is-ok rule.\n> 9.  No 0-type; that terminates (backwards compat with 0-filled padding).\n>\n>     New onion error value:\n>\n> 10.  type: PERM|22 (`tlv_element_invalid`)\n> 11.  `2`:`offset`\n>\n>     The writer MUST set `offset` to a byte offset within the `tlv` field\n>     of the tlv element it rejected. It SHOULD use the offset of the `type` byte of the TLV\n>     element if it didn't understand it, the offset the `len` byte of the TLV\n>     element if it was an incorrect length, or otherwise within the `value`\n>     if the value was somehow invalid.\n>\n>     TLVs defined for initial onion:\n>\n>\n> -   type 2: `switch_chain`\n>     length: 32\n>     value: chain_id of new chain.\n>\n>     Used to switch chains during transit or at final hop.\n>\n>\n> Use with multi-part payment (\"base AMP\"):\n>\n> -   type 4: `total_payment`\n>     length: variable, <= 8\n>     value: amount of total payment, in msat (big-endian of course).\n>\n>     Writer must only use for final hop, and only if bolt11 flagged it as\n>     available (bolt11-multi_part_available). May use even if this payment\n>     meets the total_payment requirement.\n>\n>     Reader MUST reject if not final hop, MAY reject if invoice was not\n>     `bolt11-multi_part_available`. Reader SHOULD wait until total parts\n>     meet or exceed `total_payment` (exceed may be due to fuzzing) [rest\n>     as per previous posts].\n\nCan we use the existence of this tlv to signal use of base AMP, instead of a separate flags byte?\n\nOn another topic, how about:\n\n- type 6: `application_data`\n  length: variable\n  value: unknown\n\nWriter MUST only use for final hop, and only if it knows that the final hop has a specific application that it is compatible with.\n\nReader MUST pass this application data to higher layers.\nThe application is responsible for identifying the correctness and validity of the attached value.\n\n(It seems to me that this would work for spontaneous payments to identify who the sender is, e.g. exchanges might provide a userkey and authorization that will be wrapped in this TLV; a corresponding new field in BOLT11 invoices (or multi-use offers) can specify the `application_data` to use for the payment, for example)\n\n- type 8: `spontaneous_payment`\n  length: 32\n  value: preimage\n\nWriter MUST only use for final hop, and sacrifices proof-of-payment.\n\nReader MUST claim the HTLC using the given preimage.\n\n>     PS. I prefer 'multi-part-payment' to 'base AMP' in the spec. It's more\n>     explicit, and leaves the namespace clear for more atomicy AMPs.\n\nI would argue that \"base\" AMP is sufficiently atomic to merit the full name of \"atomic multipath payment\".\nIndeed, even if we switch to points and their generation scalars (pubkey/privkey), the same \"base AMP\" can be used as-is, with the added security of decorrelation within paths and between paths by taking advantage of homomorphisms.\n\nHowever, this is getting to color-of-the-bikeshed territory and I will just call it by whatever name sticks to my mind, preferring Base AMP just as I prefer sipa.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-29T06:33:06",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n> Good morning Rusty,\n>\n>> There's a kinda-neat intersection between the \"use TLV\" proposal and the\n>> \"multi-cell-onion\" idea, so I want to make a concrete proposal (wording\n>> needs formalization):\n>>\n>> Multi-cell structure:\n>>\n>> 1.  `realm` (or `per_hop_type` if you prefer) meaning expanded.\n>> 2.  Lower 4 bits is `num_extra_cells` to use (ie. total 1-17 cells).\n>> 3.  Upper 4 bits reserved: if set, drop.\n>\n> What does drop mean exactly?\n> Or an error with `BADONION` bit set? (\"drop the HTLC as a failure\")\n> Or should we try to consume the next 65 bytes? (\"drop this cell and process the next cell\")\n\n`invalid_realm` is the current error for this; ie. fail the HTLC, tell\nthem we didn't understand.\n\n>> 4.  HMAC on end covers that many per-hops.\n>> 5.  Padding is thus 12 bytes + 64 * `num_extra_cells`.\n>\n> Is it not multiple of 65?\n\nYes, you're right.\n\n> Also, it seems to me that the existing `per_hop_type`/`realm`/`packet_type` of 0 implies that only a single 65-byte section is used (as is current behavior).  Then a byte of 1 indicates two 65-byte sections are used, and so on.\n> I broadly approve of this design.\n>\n> However with only 4 bits it seems to me:\n>\n>>(ie. total 1-17 cells).\n>\n> is inaccurate? Only 1->16 cells?\n\nYes, you're right again.\n\n>>     Structure of padding changes:\n>>\n>> 6.  We make the onion `padding` contain TLV, rename to `tlv`.\n>> 7.  TLVs (as always!) are in lexicographical order (with shortest-wins on\n>>     tiebreak).\n>\n> If types are unique, then \"shortest-wins\" would not matter.\n> I believe there was a vague agreement that types would have to be unique in a TLV sequence, and that if a type could be variadic, it would be variadic within its own value-blob.\n\nAgreed, but this seemed more general.  It's impossible to know whether\nmultiples would make sense in future, and ruling them out now forces us\nto do strange things later (like nested TLV) if we want it later.\n\nSince it's a writer rule, (readers should simply ignore TLVs they don't\nunderstand, ignoring order), it doesn't matter until/if we allow some\ntype to be multipled.\n\n>> Use with multi-part payment (\"base AMP\"):\n>>\n>> -   type 4: `total_payment`\n>>     length: variable, <= 8\n>>     value: amount of total payment, in msat (big-endian of course).\n>>\n>>     Writer must only use for final hop, and only if bolt11 flagged it as\n>>     available (bolt11-multi_part_available). May use even if this payment\n>>     meets the total_payment requirement.\n>>\n>>     Reader MUST reject if not final hop, MAY reject if invoice was not\n>>     `bolt11-multi_part_available`. Reader SHOULD wait until total parts\n>>     meet or exceed `total_payment` (exceed may be due to fuzzing) [rest\n>>     as per previous posts].\n>\n> Can we use the existence of this tlv to signal use of base AMP, instead of a separate flags byte?\n\nExactly :)\n\n> On another topic, how about:\n>\n> - type 6: `application_data`\n>   length: variable\n>   value: unknown\n>\n> Writer MUST only use for final hop, and only if it knows that the final hop has a specific application that it is compatible with.\n>\n> Reader MUST pass this application data to higher layers.\n> The application is responsible for identifying the correctness and validity of the attached value.\n>\n> (It seems to me that this would work for spontaneous payments to identify who the sender is, e.g. exchanges might provide a userkey and authorization that will be wrapped in this TLV; a corresponding new field in BOLT11 invoices (or multi-use offers) can specify the `application_data` to use for the payment, for example)\n\nI don't think that the BOLT11 invoice should specify it; the invoice is\nuniquely tied to the payment already, and having another one just adds\nconfusion and seems like it might tempt people to do dumb things.\n\nI can imagine using this for (non-provable) games of chance\n(LightningDice anyone?); the user picks a random number and puts it in\nhere.  Some new lightning RPC API allows them to provide this as well as\nthe bolt11 invoice: the merchant pays out if the random number matches\nthe preimage.\n\n> - type 8: `spontaneous_payment`\n>   length: 32\n>   value: preimage\n>\n> Writer MUST only use for final hop, and sacrifices proof-of-payment.\n>\n> Reader MUST claim the HTLC using the given preimage.\n\ns/MUST/MAY/?  Reader can reject spontaneous payments.\n\n>>     PS. I prefer 'multi-part-payment' to 'base AMP' in the spec. It's more\n>>     explicit, and leaves the namespace clear for more atomicy AMPs.\n>\n> I would argue that \"base\" AMP is sufficiently atomic to merit the full name of \"atomic multipath payment\".\n> Indeed, even if we switch to points and their generation scalars (pubkey/privkey), the same \"base AMP\" can be used as-is, with the added security of decorrelation within paths and between paths by taking advantage of homomorphisms.\n>\n> However, this is getting to color-of-the-bikeshed territory and I will just call it by whatever name sticks to my mind, preferring Base AMP just as I prefer sipa.\n\nAdding nomenclature must be done carefully; it should only be done where\nreal nuance is required.  I think \"multi-part-payment\" is descriptive\nand also currently unused, even if it's pronounced \"bass AMP\".\n\nThanks!\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-29T09:49:04",
                "message_text_only": "Good morning Rusty,\n\n> > On another topic, how about:\n> >\n> > -   type 6: `application_data`\n> >     length: variable\n> >     value: unknown\n> >\n> >\n> > Writer MUST only use for final hop, and only if it knows that the final hop has a specific application that it is compatible with.\n> > Reader MUST pass this application data to higher layers.\n> > The application is responsible for identifying the correctness and validity of the attached value.\n> > (It seems to me that this would work for spontaneous payments to identify who the sender is, e.g. exchanges might provide a userkey and authorization that will be wrapped in this TLV; a corresponding new field in BOLT11 invoices (or multi-use offers) can specify the `application_data` to use for the payment, for example)\n>\n> I don't think that the BOLT11 invoice should specify it; the invoice is\n> uniquely tied to the payment already, and having another one just adds\n> confusion and seems like it might tempt people to do dumb things.\n>\n> I can imagine using this for (non-provable) games of chance\n> (LightningDice anyone?); the user picks a random number and puts it in\n> here. Some new lightning RPC API allows them to provide this as well as\n> the bolt11 invoice: the merchant pays out if the random number matches\n> the preimage.\n\nThe intent is to combine the multi-use offer with `spontaneous_payment`.\n\nI do not remember well if it was at summit or on-list, and am too lazy to dig up the detail, but, somebody mentioned the use of spontaneous payment when interacting with trust-demanding third parties, like banks that hold Bitcoin on behalf of their \"customers\".\nThis is precisely the correct sacrifice of proof-of-payment, because trust is demanded anyway and you have no recourse.\nIt was also mentioned that some data would need to be delivered by the payer in order for the bank to identify the \"account number\" to credit.\n\nThus it would be useful for the bank to provide a multi-use offer, containing the `application_data` (the account number or some identifier of the account holder).\nThen it would be used by the bank customer, by providing a `spontaneous_payment` below.\n\n\n>\n> > -   type 8: `spontaneous_payment`\n> >     length: 32\n> >     value: preimage\n> >\n> >\n> > Writer MUST only use for final hop, and sacrifices proof-of-payment.\n> > Reader MUST claim the HTLC using the given preimage.\n>\n> s/MUST/MAY/? Reader can reject spontaneous payments.\n\nI agree.\n\nI wonder, if this is something that should be advertised on `global_features` also.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Multi-cell-hop onion with TLV (and example for multi-part-payment)",
            "categories": [
                "Lightning-dev",
                "DRAFT"
            ],
            "authors": [
                "Rusty Russell",
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 14459
        }
    },
    {
        "title": "[Lightning-dev] Dual Funding Proposal",
        "thread_messages": [
            {
                "author": "lisa neigut",
                "date": "2018-11-28T01:12:09",
                "message_text_only": "Hello fellow Lightning devs!\n\n\nWhat follows is a draft for the new dual funding flow. Note that the\n`option_will_fund_for_food` specification has been omitted for this draft.\n\n\n\n===== Proposal\n\nCreate a new channel open protocol set (v2), with three new message types:\n`funding_puts2`, `commitment_signed2`, and `funding_signed2`, plus two for\nnegotiating RBF, `init_rbf` and `accept_rbf`.\n\n\nQuick overview of the message exchange for v2:\n\n   +-------+                              +-------+\n\n   |    |--(1)---  open_channel2  ---->| |\n\n   |    |<-(2)--  accept_channel2  ----| |\n\n   |    |                       | |\n\n   |    |--(3)--  funding_puts2  ----->| |\n\n   |    |<-(4)--  funding_puts2  ----- | |\n\n   |    |                       | |\n\n--->|       |--(5)-- commitment_signed2 -->|       |\n\n|   |    |<-(6)-- commitment_signed2 ---|       |\n\n|   | A   |                       | B |\n\n|   |    |--(7)--- funding_signed2 ---->|       |\n\n|   |    |<-(8)--- funding_signed2 -----|       |\n\n|   |    |                       | |\n\n|   |    |--(a)--- init_rbf ----------->|       |\n\n----|       |<-(b)--- accept_rbf ----------|       |\n\n   |    |                       | |\n\n   |    |--(9)--- funding_locked2 ---->|       |\n\n   |    |<-(10)---funding_locked2 -----|       |\n\n   +-------+                              +-------+\n\n  where node A is the \u2018initiator\u2019 and node B is the \u2018dual-funder\u2019\n\n\n== Negotiating the use of dual_funding (open_channel2) flow\nWillingness to use v2 is flagged in init via `option_dual_fund`.\n\n`init`\n\nlocal channel feature flag, `option_dual_fund`\n\n== Channel establishment with dual_funding\n\n____`open_channel2`:\n\n[32:chain_hash]\n\n\u2026 // unchanged\n\n[1:channel_flags]\n\n[?: options_tlv]\n\noptions_tlv:\n\n   1.\n\n   Type: 1 `option_upfront_shutdown_script`\n   1.\n\n      [2:len]\n      2.\n\n      Value: `shutdown_scriptpubkey`\n\n\nIf nodes have negotiated `option_dual_fund`\n\nThe sending node:\n\n   -\n\n   MAY begin channel establishment using `open_channel2`\n\n\nOtherwise the receiving node:\n\n   -\n\n   MUST return an error.\n\n\n____ `accept_channel2`:\n\n[32:temporary_channel_id]\n\n\u2026  // unchanged\n\n[33:first_per_commitment_point]\n\n[?: options_tlv]\n\noptions_tlv:\n\n   1.\n\n   Type: 1 `option_upfront_shutdown_script`\n\n           [2:len]\n\n          Value: `shutdown_scriptpubkey`\n\n____`funding_puts2`\n\nThis message exchanges the input and output information necessary to\ncompose the funding transaction.\n\n[32:temporary_channel_id]\n\n[`2`:`num_inputs`]\n\n[`num_inputs*input_info`]\n\n[`2`:`num_outputs`]\n\n[`num_outputs`*ouput_info`]\n\n1. subtype: `input_info`\n\n2. data:\n\n * [`8`:`satoshis`]\n\n * [`32`:`prevtxid`]\n\n * [`4`:`prevtxoutnum`]\n\n * [`2`:`scriptlen`]\n\n * [`scriptlen`:`script`]\n\n * [`2`:`max_extra_witness_len`]\n\n * [`2`:`wscriptlen`]\n\n * [`wscriptlen`:`wscript`]\n\n1. subtype: `output_info`\n\n2. data:\n\n * [`8`:`satoshis`]\n\n * [`2`:`scriptlen`]\n\n * [`scriptlen`:`script`]\n\nRequirements:\n\nThe sending node:\n\n   -\n\n   MUST ensure each `input_info` refers to an existing UTXO\n   -\n\n   MUST ensure the `output_info`.`script` is a standard script\n   -\n\n   MUST NOT spend any UTXOs specified in funding_puts2 until/unless the\n   channel establishment has failed\n\nIf is the initiator (A):\n- MUST NOT send an empty message  (`num_inputs` + `num_outputs` = 0)\n\n     If is the dual-funder (B):\n\n   -\n\n   consider the `put_limit` the total number of `num_inputs` plus\n   `num_outputs` from `funding_puts2`, with minimum 2.\n   -\n\n   MUST NOT send a number of `input_data` and/or `output_data` which\n   exceeds the `put_limit`\n   -\n\n   MAY send an empty message\n\n\nThe receiving node:\n\n  If is the initiator (A):\n\n   -\n\n   MUST fail the channel if the `num_inputs` plus `num_outputs` is greater\n   than the `put_limit`\n\n\nIf has not yet sent a `fund_puts2` for this channel establishment\n\n     - SHOULD send their `fund_puts2` message\n\nOtherwise\n\n   -\n\n   SHOULD send `commitment_signed2`\n\n\nRationale:\n\nEach node must have a complete set of the transaction inputs/outputs, to\nderive the funding transaction hash.\n\nThere is a dual_funding protocol that only requires one side to send their\nwitness data and inputs. This is more efficient, however it results in\nasymmetry between the nodes, where one is revealing their UTXOs before the\nfunding transaction is committed.. We mitigate this asymmetry by asking the\ninitiator (A) to send their set of inputs before the dual-funder (B) does.\n\nNB: This is reusing the input/output structures from the Splicing proposal,\nbut with a more generalized name.\n\n\n____`commitment_signed2`\n\nThis message exchanges the counterparty\u2019s signature for the first\ncommitment transaction, so it can broadcast the funding transaction knowing\nthat funds can be redeemed.\n\n[32: `channel_id`]\n\n[`64`: commitment_signature`]\n\nRequirements:\n\nThe sending node:\n\n   -\n\n   MUST derive the `channel_id` from the funding transaction\u2019s id\n   -\n\n   MUST set signature to the valid signature, using its funding_pubkey for\n   the initial commitment transaction, as defined in BOLT #3\n\n  If it has not received a `funding_puts2`\n\n   -\n\n   MUST NOT send their `commitment_signature`\n\n\nThe receiving node:\n\n   -\n\n   MUST verify the commitment signature is valid for the funding\n   transaction -> commitment transaction that it has derived independently\n\n     If this signature is invalid it\n\n   -\n\n   MUST fail the channel\n\n\n  If it has not sent a `commitment_signed2` message\n\n   -\n\n   MUST send their `commitment_signed2` message\n\n   If this is in a flow initiated from `init_rbf`,:\n\n   -\n\n   MUST save the temporary_channel_id until the channel funding transaction\n   has been locked (this is the channel id of the currently broadcast\n   transaction)\n\n\nRationale:\n\nIn the previous channel establishment protocol, we were able to compress\nthe commitment signature exchange into `funding_created`/`funding_signed`.\nWith dual funding, we need interaction to build the funding transaction --\ncommitment sig exchange is now a separate step.\n\n___`funding_signed2`\n\nThis message exchanges the witness data for the inputs that were originally\nsent in the `funding_puts2` message.\n\n[`32`:`channel_id`]\n\n[`2`:`num_witnesses`]\n\n[`num_witnesses*witness_stack`]\n\nRequirements:\n\nThe sending node:\n\n    - MUST remember the details of this funding transaction\n\n   - MUST NOT send a `witness_stack` whose length exceeds the corresponding\n`max_extra_witness_len`\n\n    If they have NOT received a valid `commitment_signed2` message\n\n   -\n\n   MUST not send their `funding_signed2` message\n\n\nThe receiving node:\n\n   -\n\n   SHOULD check that the number of witnesses sent matches the number of\n   inputs\n\nIf a `witness_stack` length exceeds the corresponding\n`max_extra_witness_len`:\n\n   -\n\n     MAY error.\n\n   If is the `initiator` (A):\n\n   -\n\n   SHOULD apply `witness` to the funding transaction and broadcast the\n   result.\n\n\nRationale:\n\nExchanging witness data allows either side to broadcast the funding\ntransaction. It also maintains the information symmetry between the nodes.\n\n___`funding_locked2`\n\n// same as v1\n\nRequirements:\n\nA dual-funding node (B):\n\n   -\n\n   SHOULD broadcast their funding transaction if it does not see the\n   transaction broadcast after a reasonable timeout.\n\n\n== RBF for Channel Establishment v2\n\n_____`init_rbf`\n\nThis message is sent by the initiator, after the funding transaction has\nbeen broadcast but before the `funding_locked2` has been exchanged.\n\n[32: `channel_id`]\n\n[8: funding_satoshis]\n\n[8:dust_limit_satoshis]\n\n[8:channel_reserve_satoshis]\n\n[4: feerate_per_kw]\n\n[`2`:`num_inputs`]\n\n[`num_inputs*input_info`]\n\n[`2`:`num_outputs`]\n\n[`num_outputs`*ouput_info`]\n\nRequirements\n\nThe sending node:\n\n   -\n\n   MUST be the initiator (A)\n   -\n\n   MAY update the amount, fee rate, dust limit, or channel reserve for the\n   channel\n\n\nThe receiving node:\n\n   -\n\n   MAY reject (error) the RBF request if:\n   -\n\n      the fee rate, dust, or channel reserve is unreasonable\n      -\n\n   MUST reject (error) the RBF request if:\n   -\n\n      the `fee_rate` is less than the rate that was originally proposed\n      -\n\n      the `funding_satoshis` amount is less than the previous negotiated\n      `push_mast`\n      -\n\n      It considers the `feerate_per_kw` too small for timely processing or\n      unreasonable\n      -\n\n      the `dust_limit_satoshis` is greater than the\n      `channel_reserve_satoshis`\n      -\n\n      the initiator\u2019s amount for the initial commitment transaction is not\n      sufficient for full fee payment\n      -\n\n      the `inputs`.`satoshis` does not sum to the `funding_satoshis`\n      -\n\n      the `funding_satoshis` is insufficient to create the transaction at\n      the new `fee_rate`\n      -\n\n      there is no overlap in the proposed inputs and the original input set\n      included in the currently published funding transaction\n      -\n\n      they have already received or sent a `funding_locked2` message\n      -\n\n   If there are no errors or unreasonable demands:\n   -\n\n      SHOULD send an `accept_rbf`\n\n\nRationale:\n\nOnce an `init_rbf` has been accepted by the dual-funding node, the message\nflow returns to `commitment_signed2` and proceeds as above, with the\nexception that the `temporary_channel_id` remains as the `channel_id` for\nthe currently published but unmined transaction.\n\nThe channel id that becomes fixed for this node will be determined by the\n`funding_locked2` message.\n\n___`accept_rbf`\n\nThis message accepts an RBF request, and renegotiates a dual-funder\u2019s\nfunds, dust limit, and channel reserve, and sends the dual-funder\u2019s updated\nputs.\n\n[32: `channel_id`]\n\n[8: funding_satoshis]\n\n[8:ndust_limit_satoshis]\n\n[8:channel_reserve_satoshis]\n\n[`2`:`num_inputs`]\n\n[`num_inputs*input_info`]\n\n[`2`:`num_outputs`]\n\n[`num_outputs`*ouput_info`]\n\nRequirements:\n\nThe sending node:\n\n   -\n\n   MAY update the amount, dust limit, or channel reserve for the channel\n\n\nThe receiving node:\n\n   -\n\n   MAY reject (error) the RBF request if:\n   -\n\n      the dust or channel reserve is unreasonable\n      -\n\n   MUST reject (error) the RBF request if:\n   -\n\n      the `funding_satoshis` amount is less than the previous negotiated\n      `push_mast`\n      -\n\n      the `dust_limit_satoshis` is greater than the\n      `channel_reserve_satoshis`\n      -\n\n      the total fees incurred by the `input_info`s and `output_info`s at\n      the new `fee_rate` is more than their `funding_satoshis`\n\n      otherwise:\n\n   -\n\n   SHOULD send a `commitment_signed2` message\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181127/b864846e/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-28T05:26:24",
                "message_text_only": "Good morning Lisa,\n\nMinor comments only, have not studied in detail:\n\n> ____ `accept_channel2`:\n>\n> [32:temporary_channel_id]\n>\n> \u2026  // unchanged\n>\n> [33:first_per_commitment_point]\n>\n> [?: options_tlv]\n>\n> options_tlv:\n>\n> -\n>\n> Type: 1 `option_upfront_shutdown_script`\n>\n>            [2:len]\n>\n>           Value: `shutdown_scriptpubkey`\n\nI believe an even type is more appropriate, since the other side MUST enforce that sthudown only goes to the specified script?\n\n> ____`funding_puts2`\n>\n> This message exchanges the input and output information necessary to compose the funding transaction.\n>\n> [32:temporary_channel_id]\n>\n> [`2`:`num_inputs`]\n>\n> [`num_inputs*input_info`]\n>\n> [`2`:`num_outputs`]\n>\n> [`num_outputs`*ouput_info`]\n>\n> 1. subtype: `input_info`\n>\n> 2. data:\n>\n>  * [`8`:`satoshis`]\n>\n>  * [`32`:`prevtxid`]\n>\n>  * [`4`:`prevtxoutnum`]\n>\n>  * [`2`:`scriptlen`]\n>\n>  * [`scriptlen`:`script`]\n>\n>  * [`2`:`max_extra_witness_len`]\n>\n>  * [`2`:`wscriptlen`]\n>\n>  * [`wscriptlen`:`wscript`]\n\n`script` here is the `scriptPubKey`?  This is needed for `hashPrevouts` in BIP143 I believe.\n\nWhat is the `wscript`?  Is this the `scriptCode` in BIP143?\n\nAre non-SegWit inputs disallowed?\n\n> 1. subtype: `output_info`\n>\n> 2. data:\n>\n>  * [`8`:`satoshis`]\n>\n>  * [`2`:`scriptlen`]\n>\n>  * [`scriptlen`:`script`]\n>\n> Requirements:\n>\n> The sending node:\n>\n> -\n>\n> MUST ensure each `input_info` refers to an existing UTXO\n>\n> -\n>\n> MUST ensure the `output_info`.`script` is a standard script\n>\n> -\n>\n> MUST NOT spend any UTXOs specified in funding_puts2 until/unless the channel establishment has failed\n\nIf a violation of this is detected, what MUST we do?\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181128/d101c4bb/attachment.html>"
            },
            {
                "author": "lisa neigut",
                "date": "2018-11-29T00:21:50",
                "message_text_only": "On Tue, Nov 27, 2018 at 11:26 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Lisa,\n>\n> Minor comments only, have not studied in detail:\n>\n>\n>\n> ____ `accept_channel2`:\n>\n> [32:temporary_channel_id]\n>\n> \u2026  // unchanged\n>\n> [33:first_per_commitment_point]\n>\n> [?: options_tlv]\n>\n> options_tlv:\n>\n>    1.\n>\n>    Type: 1 `option_upfront_shutdown_script`\n>\n>            [2:len]\n>\n>           Value: `shutdown_scriptpubkey`\n>\n>\n> I believe an even type is more appropriate, since the other side MUST\n> enforce that sthudown only goes to the specified script?\n>\n>\nGood point. This definitely should be an even type number as you suggest.\nMy initial thought was that being inside an `options_tlv` would preclude\nthe need to maintain the even/oddness designation, but I think this is a\nmistake.\n\n____`funding_puts2`\n>\n> This message exchanges the input and output information necessary to\n> compose the funding transaction.\n>\n> [32:temporary_channel_id]\n>\n> [`2`:`num_inputs`]\n>\n> [`num_inputs*input_info`]\n>\n> [`2`:`num_outputs`]\n>\n> [`num_outputs`*ouput_info`]\n>\n> 1. subtype: `input_info`\n>\n> 2. data:\n>\n>  * [`8`:`satoshis`]\n>\n>  * [`32`:`prevtxid`]\n>\n>  * [`4`:`prevtxoutnum`]\n>\n>  * [`2`:`scriptlen`]\n>\n>  * [`scriptlen`:`script`]\n>\n>  * [`2`:`max_extra_witness_len`]\n>\n>  * [`2`:`wscriptlen`]\n>\n>  * [`wscriptlen`:`wscript`]\n>\n>\n> `script` here is the `scriptPubKey`?  This is needed for `hashPrevouts` in\n> BIP143 I believe.\n>\n> What is the `wscript`?  Is this the `scriptCode` in BIP143?\n>\n> Are non-SegWit inputs disallowed?\n>\n\nThis borrows heavily from Rusty's splicing proposal; whatever was specified\nthere should be assumed to also be specified here for inputs.  Rationale\nbeing there should be no difference between the input requirements for a\nsplice versus a dual fund.\n\n\n>\n>\n> 1. subtype: `output_info`\n>\n> 2. data:\n>\n>  * [`8`:`satoshis`]\n>\n>  * [`2`:`scriptlen`]\n>\n>  * [`scriptlen`:`script`]\n>\n> Requirements:\n>\n> The sending node:\n>\n>    -\n>\n>    MUST ensure each `input_info` refers to an existing UTXO\n>    -\n>\n>    MUST ensure the `output_info`.`script` is a standard script\n>    -\n>\n>    MUST NOT spend any UTXOs specified in funding_puts2 until/unless the\n>    channel establishment has failed\n>\n>\n> If a violation of this is detected, what MUST we do?\n>\n\nI'm not sure what you mean here, it's not exactly enforceable other than\nfrom an implementation perspective. If the funding transaction is invalid\nbecause of an input (ie a double spend), the funding transaction won't be\nconfirmed. This should be discovered when the node attempts to broadcast\nthe funding transaction, and can be handled (ie treated as a channel\nfailure) there.\n\n\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181128/600e60f7/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-30T03:05:03",
                "message_text_only": "lisa neigut <niftynei at gmail.com> writes:\n>>  * [`2`:`scriptlen`]\n>>\n>>  * [`scriptlen`:`script`]\n>>\n>>  * [`2`:`max_extra_witness_len`]\n>>\n>>  * [`2`:`wscriptlen`]\n>>\n>>  * [`wscriptlen`:`wscript`]\n>>\n>>\n>> `script` here is the `scriptPubKey`?  This is needed for `hashPrevouts` in\n>> BIP143 I believe.\n>>\n>> What is the `wscript`?  Is this the `scriptCode` in BIP143?\n\nI was thinking the BIP141 witnessScript; this mixes weirdly with P2WPKH\nthough where the witnessScript does not really exist.  So I guess an\nempty witnessScript means P2WPKH.\n\n>> Are non-SegWit inputs disallowed?\n\nNo, since we'd have a malleability problem :(\n\nCheers,\nRusty."
            },
            {
                "author": "Rusty Russell",
                "date": "2018-11-30T02:58:39",
                "message_text_only": "lisa neigut <niftynei at gmail.com> writes:\n> Hello fellow Lightning devs!\n>\n> What follows is a draft for the new dual funding flow. Note that the\n> `option_will_fund_for_food` specification has been omitted for this draft.\n\nHi!\n\nWow, my mailer really mangled this!  I've liberally demangled below\nas I quote.\n\nThe proposal is great, but intense, so I've bikeshedded the language.\nMy only objection is that I'd love to simplify RBF.\n\n> ===== Proposal\n>\n> Create a new channel open protocol set (v2), with three new message types:\n> `funding_puts2`, `commitment_signed2`, and `funding_signed2`, plus two for\n> negotiating RBF, `init_rbf` and `accept_rbf`.\n>\n>\n> Quick overview of the message exchange for v2:\n>\n>    +----+                              +----+\n>    |    |--(1)---  open_channel2  ---->|    |\n>    |    |<-(2)--  accept_channel2  ----|    |\n>    |    |                              |    |\n>    |    |--(3)--  funding_puts2  ----->|    |\n>    |    |<-(4)--  funding_puts2  ----- |    |\n>    |    |                              |    |\n>    |    |--(5)-- commitment_signed2 -->|    |\n>    |    |<-(6)-- commitment_signed2 ---|    |\n>    | A  |                              |  B |\n>    |    |--(7)--- funding_signed2 ---->|    |\n>    |    |<-(8)--- funding_signed2 -----|    |\n>    |    |                              |    |\n>    |    |--(a)--- init_rbf ----------->|    |\n>    |    |<-(b)--- accept_rbf ----------|    |\n>    |    |                              |    |\n>    |    |--(9)--- funding_locked2 ---->|    |\n>    |    |<-(10)---funding_locked2 -----|    |\n>    +----+                              +----+\n>   where node A is the \u2018initiator\u2019 and node B is the \u2018dual-funder\u2019\n\nWe currently use the terms funder and fundee, which are now\ninaccurate ofc.  Perhaps 'opener' and 'accepter' are not great english,\nbut they map to the messages well?\n\n> Willingness to use v2 is flagged in init via `option_dual_fund`.\n> `init`\n>\n> local channel feature flag, `option_dual_fund`\n>\n> == Channel establishment with dual_funding\n>\n> ____`open_channel2`:\n> [32:chain_hash]\n> \u2026 // unchanged\n> [1:channel_flags]\n> [?: options_tlv]\n\nAlways prefix variable fields by length, even this one.  Otherwise\nwe can never extend, and you never know...\n\n   [2:tlv_len]\n   [tlv_len:opening_tlv]\n\nI think we can remove `funding_satoshis` here; we'll know when they add\ntheir inputs, so it's redundant.\n\nAnother subtle point is the feerate_per_kw field; in the old scheme it\napplied to the first commitment tx, but here it applies to both the\nfirst commitment tx and the funding tx itself (unless\noption_simplified_commitment, though roasbeef has suggested further\nsplitting that option, in which case we'll want another fee field here).\n\n> options_tlv:\n\nLet's call this `opening_tlv` since there are other TLVs coming?\n\n>    1.\n>    Type: 1 `option_upfront_shutdown_script`\n>    1.\n>\n>       [2:len]\n>       2.\n>\n>       Value: `shutdown_scriptpubkey`\n> If nodes have negotiated `option_dual_fund`\n> The sending node:\n>    -\n>    MAY begin channel establishment using `open_channel2`\n\n - MUST NOT send `open_channel`.\n\n> Otherwise the receiving node:\n>    -\n>    MUST return an error.\n\nThis is a requirement for receiving `open_channel`  IIUC?\n\nie.\n\nThe receiving node MUST fail the channel if:\n   ...\n   - `option_dual_fund` has been negotiated.\n\n\n> ____ `accept_channel2`:\n>\n> [32:temporary_channel_id]\n> \u2026  // unchanged\n> [33:first_per_commitment_point]\n> [?: options_tlv]\n>\n\nIf we call this `opening_tlv` we can just reuse the definition from\nbefore.\n\n> ____`funding_puts2`\n\nWe can probably drop the 2 here and call it, um.. `funding_compose`?\n(Thanks thesaurus.com).  I get where you're going with 'puts, but it\ntook me a while :)\n\n> This message exchanges the input and output information necessary to\n> compose the funding transaction.\n>\n> [32:temporary_channel_id]\n> [`2`:`num_inputs`]\n> [`num_inputs*input_info`]\n> [`2`:`num_outputs`]\n> [`num_outputs`*ouput_info`]\n\ntypo: output_info\n\n> 1. subtype: `input_info`\n> 2. data:\n>  * [`8`:`satoshis`]\n>  * [`32`:`prevtxid`]\n>  * [`4`:`prevtxoutnum`]\n>  * [`2`:`scriptlen`]\n>  * [`scriptlen`:`script`]\n>  * [`2`:`max_extra_witness_len`]\n>  * [`2`:`wscriptlen`]\n>  * [`wscriptlen`:`wscript`]\n>\n> 1. subtype: `output_info`\n> 2. data:\n>  * [`8`:`satoshis`]\n>  * [`2`:`scriptlen`]\n>  * [`scriptlen`:`script`]\n>\n> Requirements:\n>\n> The sending node:\n>\n>    - MUST ensure each `input_info` refers to an existing UTXO\n>    - MUST ensure the `output_info`.`script` is a standard script\n>    - MUST NOT spend any UTXOs specified in funding_puts2 until/unless the\n>      channel establishment has failed\n\n\n> If is the initiator (A):\n> - MUST NOT send an empty message  (`num_inputs` + `num_outputs` = 0)\n>\n>      If is the dual-funder (B):\n>    -\n>    consider the `put_limit` the total number of `num_inputs` plus\n>    `num_outputs` from `funding_puts2`, with minimum 2.\n>    -\n>    MUST NOT send a number of `input_data` and/or `output_data` which\n>    exceeds the `put_limit`\n\nSide note: I wonder if we should relax this limit when we talk about\n`option_will_fund_for_food`?\n\n>    -\n>    MAY send an empty message\n\nBe explicit? MAY offer zero `num_inputs` and `num_outputs`.  That's not\nquite an empty message...\n\n> The receiving node:\n>\n>   If is the initiator (A):\n>\n>    -\n>    MUST fail the channel if the `num_inputs` plus `num_outputs` is greater\n>    than the `put_limit`\n\nHow about MAY?  It's a protection thing, but less to change when we\noption_will_fund_for_food.  Unless we set the `put_limit` to min (4) or\nsomething in that case?\n\nOh, it needs to check max_extra_witness_len is reasonable too, since\nthat will affect the fees.  Each signature adds 74, and pubkey adds 34,\nso I think MUST BE less than 500 is perfectly reasonable (for both\nreader and writer).\n\n> If has not yet sent a `fund_puts2` for this channel establishment\n>     - SHOULD send their `fund_puts2` message\n>\n> Otherwise\n>    - SHOULD send `commitment_signed2`\n\nPerhaps add '- MUST use the sent and received `input_info` and\n`output_info` to create the funding transaction, using\n`max_extra_witness_len` for each `input_info` and `feerate_per_kw` from\n`open_channel2`.'\n\nSide note: we need to define max_extra_witness_len as the total\nmarshalled length of the extra witness data which will be supplied\n(ie. sizeof(varint) + sizeof(data) for each one).\n\n> Rationale:\n>\n> Each node must have a complete set of the transaction inputs/outputs, to\n> derive the funding transaction hash.\n>\n> There is a dual_funding protocol that only requires one side to send their\n> witness data and inputs. This is more efficient, however it results in\n> asymmetry between the nodes, where one is revealing their UTXOs before the\n> funding transaction is committed.. We mitigate this asymmetry by asking the\n> initiator (A) to send their set of inputs before the dual-funder (B) does.\n>\n> NB: This is reusing the input/output structures from the Splicing proposal,\n> but with a more generalized name.\n>\n>\n> ____`commitment_signed2`\n\nI just realized that `commitment_signed` is the name of the message we\nuse during HTLC / fee updates.  But since the message is identical to\nthis one in both form and purpose, I think we can reuse it here.\n\n> This message exchanges the counterparty\u2019s signature for the first\n> commitment transaction, so it can broadcast the funding transaction knowing\n> that funds can be redeemed.\n>\n> [32: `channel_id`]\n> [`64`: commitment_signature`]\n>\n> Requirements:\n>\n> The sending node:\n>\n>    - MUST derive the `channel_id` from the funding transaction\u2019s id\n>    - MUST set signature to the valid signature, using its funding_pubkey for\n>    the initial commitment transaction, as defined in BOLT #3\n\nThis is good.\n\n>\n>   If it has not received a `funding_puts2`\n>\n>    -\n>\n>    MUST NOT send their `commitment_signature`\n\nThis is implied by the requirement that they generate the funding\ntransaction.  For better or worse, we don't usually spell out\nrequirements not to send things out of order.\n\n> The receiving node:\n>\n>    - MUST verify the commitment signature is valid for the funding\n>    transaction -> commitment transaction that it has derived independently\n>\n>      If this signature is invalid it\n>\n>    -   MUST fail the channel\n>\n>\n>   If it has not sent a `commitment_signed2` message\n>\n>    -  MUST send their `commitment_signed2` message\n>\n>    If this is in a flow initiated from `init_rbf`:\n>    -\n\nPerhaps be explicit here: 'If this commitment_signed2 was in response to\nan `init_rbf` message:'?\n\n>    MUST save the temporary_channel_id until the channel funding transaction\n>    has been locked (this is the channel id of the currently broadcast\n>    transaction)\n\nConfused by this, see commentry down later.\n\n> Rationale:\n>\n> In the previous channel establishment protocol, we were able to compress\n> the commitment signature exchange into `funding_created`/`funding_signed`.\n> With dual funding, we need interaction to build the funding transaction --\n> commitment sig exchange is now a separate step.\n\n> ___`funding_signed2`\n>\n> This message exchanges the witness data for the inputs that were originally\n> sent in the `funding_puts2` message.\n>\n> [`32`:`channel_id`]\n> [`2`:`num_witnesses`]\n> [`num_witnesses*witness_stack`]\n>\n> Requirements:\n>\n> The sending node:\n>     - MUST remember the details of this funding transaction\n\n     - MUST send one `witness_stack` for each `output_info`\n       it sent in `funding_puts2`.\n\n>    - MUST NOT send a `witness_stack` whose length exceeds the corresponding\n> `max_extra_witness_len`\n>\n>     If they have NOT received a valid `commitment_signed2` message\n>    - MUST not send their `funding_signed2` message\n\nRedundant, but so vital I agree it needs to be stated.\n\n> The receiving node:\n>\n>    - SHOULD check that the number of witnesses sent matches the number of\n>    inputs\n\n\"SHOULD check\" is a spec anti-pattern :)\n\n    if `num_witnesses` does not equal `num_inputs` received in\n    `funding_puts2`:\n        - MUST fail the channel.\n\n> If a `witness_stack` length exceeds the corresponding\n> `max_extra_witness_len`:\n>\n>    -\n>\n>      MAY error.\n\nMUST?\n\n>    If is the `initiator` (A):\n>\n>    -\n>\n>    SHOULD apply `witness` to the funding transaction and broadcast the\n>    result.\n\nSince this is symmetrical, you can drop \"if it is the `initiator`\"?\n\n> Rationale:\n>\n> Exchanging witness data allows either side to broadcast the funding\n> transaction. It also maintains the information symmetry between the nodes.\n>\n> ___`funding_locked2`\n>\n> // same as v1\n>\n> Requirements:\n>\n> A dual-funding node (B):\n>\n>    -\n>\n>    SHOULD broadcast their funding transaction if it does not see the\n>    transaction broadcast after a reasonable timeout.\n\nLet's just reuse `funding_locked` maybe?\n\nNot sure why this should wait for broadcast?\n\n> == RBF for Channel Establishment v2\n>\n> _____`init_rbf`\n>\n> This message is sent by the initiator, after the funding transaction has\n> been broadcast but before the `funding_locked2` has been exchanged.\n>\n> [32: `channel_id`]\n> [8: funding_satoshis]\n> [8:dust_limit_satoshis]\n> [8:channel_reserve_satoshis]\n> [4: feerate_per_kw]\n> [`2`:`num_inputs`]\n> [`num_inputs*input_info`]\n> [`2`:`num_outputs`]\n> [`num_outputs`*ouput_info`]\n\nTypo again :)\n\n> Requirements\n>\n> The sending node:\n>    - MUST be the initiator (A)\n>    - MAY update the amount, fee rate, dust limit, or channel reserve for the\n>    channel\n\n - MAY send init_rbf if it considers the most recent funding tx unlikely\n   to be confirmed in reasonable time.\n - MUST set `feerate_per_kw` larger than the most recent funding tx.\n\nDo we really want to negotiate everything again?  It seems like the\nfunder should be able to maybe add *new* inputs and outputs (though TBH\nI think that's going to be unusual enough that we could omit it), but\ndoing a wholesale replacement means we have to be careful that the all\nRBFs end up having at least one input in common.  Yech.\n\n> The receiving node:\n>\n>    - MAY reject (error) the RBF request if:\n>    -\n>\n>       the fee rate, dust, or channel reserve is unreasonable\n>       -\n>\n>    MUST reject (error) the RBF request if:\n>    -\n>\n>       the `fee_rate` is less than the rate that was originally proposed\n>       -\n>\n>       the `funding_satoshis` amount is less than the previous negotiated\n>       `push_mast`\n>       -\n>\n>       It considers the `feerate_per_kw` too small for timely processing or\n>       unreasonable\n>       -\n>\n>       the `dust_limit_satoshis` is greater than the\n>       `channel_reserve_satoshis`\n>       -\n>\n>       the initiator\u2019s amount for the initial commitment transaction is not\n>       sufficient for full fee payment\n>       -\n>\n>       the `inputs`.`satoshis` does not sum to the `funding_satoshis`\n>       -\n>\n>       the `funding_satoshis` is insufficient to create the transaction at\n>       the new `fee_rate`\n>       -\n>\n>       there is no overlap in the proposed inputs and the original input set\n>       included in the currently published funding transaction\n\nMore subtly, there must be a common subset of inputs between every two\nfunding txs.\n\n>       -\n>\n>       they have already received or sent a `funding_locked2` message\n>       -\n>\n>    If there are no errors or unreasonable demands:\n>    -\n>\n>       SHOULD send an `accept_rbf`\n>\n>\n> Rationale:\n>\n> Once an `init_rbf` has been accepted by the dual-funding node, the message\n> flow returns to `commitment_signed2` and proceeds as above, with the\n> exception that the `temporary_channel_id` remains as the `channel_id` for\n> the currently published but unmined transaction.\n\nBy this stage, we are no longer using temporary_channel_id though.\n\nBut it's an excellent point I had missed.  The channel_id changes on\neach renegotiation.  We could either switch channel_id *after*\neach accept_rbf, or keep the original channel_id until funding_locked2 (in\nwhich case it should have a \"final_channel_id\" field, to make sure we're\ntalking about the same funding tx).\n\nSince we have to handle the \"oops, old one got in!\" it might be weird to\nsee `funding_locked2` with an old txid.  Perhaps we stick with the\noriginal channel_id until then, and flip *after* funding_locked2 is sent\nand received.\n\nAnd yeah, no `update_fee`, `announcement_signatures` until that\nfunding_locked2 exchange is complete, so we don't get those with an\nunsettled channel_id.\n\n> The channel id that becomes fixed for this node will be determined by the\n> `funding_locked2` message.\n>\n> ___`accept_rbf`\n>\n> This message accepts an RBF request, and renegotiates a dual-funder\u2019s\n> funds, dust limit, and channel reserve, and sends the dual-funder\u2019s updated\n> puts.\n\nI would make this an empty message, simply an ack.  And note that\nthe channel_id after this is that of the RBFed tx.\n\nThe question then becomes what do we do about reconnection.  I suggest:\n\nopener: if we haven't sent funding_signed, consider it cancelled.  If\n   we've received funding_signed, it's obviously locked in.  If we sent\n   and didn't received, re-xmit.\n\naccepter: must remember rbf if we sent commitment_signed2.  If we\n   received funding_signed it's locked in.  If we receive an init_rbf,\n   drop the one we remembered.  If we receive funding_signed, continue.\n\nWe still need to address the funding_tx construction; BIP69-style seems\nlike an unnecessary information leak here.  A 128-bit seed in\nopen_channel2 could be added, with sorting by SHA(seed | <marshal of\ninput> | <marshal of witness>) and SHA(seed | <marshal of output>)?\n\nPhew!\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-11-30T06:15:42",
                "message_text_only": "> 128-bit seed in\n> open_channel2 could be added, with sorting by SHA(seed | <marshal of\n> input> | <marshal of witness>) and SHA(seed | <marshal of output>)?\n\n`open_channel2` contains a good amount of entropy --- temporary channel ID, various basepoints.\nWould not hashing `open_channel2` to get this `seed` be sufficient?\n\nRegards,\nZmnSCPxj\n\n>\n> Phew!\n> Rusty.\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            }
        ],
        "thread_summary": {
            "title": "Dual Funding Proposal",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "lisa neigut",
                "Rusty Russell",
                "ZmnSCPxj"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 32001
        }
    },
    {
        "title": "[Lightning-dev] Reason for having HMACs in Sphinx",
        "thread_messages": [
            {
                "author": "Corn\u00e9 Plooy",
                "date": "2018-11-29T15:31:34",
                "message_text_only": "Hi,\n\n\nIs there a reason why we have HMACs in Sphinx? What could go wrong if we\ndidn't?\n\nA receiving node doesn't know anyway what the origin node is; I don't\nsee any attack mode where an attacker wouldn't be able to generate a\nvalid HMAC.\n\nA receiving node only knows which peer sent it a Sphinx packet;\nverification that this peer really sent this Sphinx packet is (I think)\nalready done on a lower protocol layer.\n\n\nAFAICS, The only real use case of the HMAC value is the special case of\na 0-valued HMAC, indicating the end of the route. But that's just silly:\nit's essentially a boolean, not any kind of cryptographic verification.\n\n\nCJP"
            },
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2018-11-29T16:32:18",
                "message_text_only": "Hey CJP,\n\nI am still not 100% through the SPHINX paper so it would be great if at\nleast another pair of eyes could lookt at this. However from the original\nSPHINX paper I quote:\n\n\"Besides extracting the shared key, each mix has to be provided with\nauthentic and confidential routing information to direct the message to the\nsubsequent mix, or to its final destination. We achieve this by a simple\nencrypt-then-MAC mechanism. A secure stream cipher or AES in counter mode\nis used for encryption, and a secure MAC (with some strong but standard\nproperties) is used to ensure no part of the message header containing\nrouting information has been modified. Some padding has to be added at each\nmix stage, in order to keep the length of the message invariant at each\nhop.\"\n\nAt first I thought this would mean that the HMAC ensures that the previous\nhop cannot change the routing information. which was the first answer that\nI wanted to give. However I am confused now too. The HMAC commits to the\nnext onion. So if the entire onion was exchanged and a new HMAC was\nprovided (as you suggest) the processing hop would not know this. Such a\nuse case would obviously lead to a routing scenario which would not succeed\nand would hardly be useful (unless the previous hop plans a reverse dos\nattacks from error messages or some other sabotage attacks which are\nreferences in the SPHINX paper but not discussed explicitly).\n\nOn a second thought I reviewed chapter 2.1 of the Sphinx paper in which the\nthread model for attackers is described. As far as I understand that\nsection one attack vector for which the HMAC shall help are man in the\nmiddle attacks. If HMACs are being used some bitflipping by man in the\nmiddles would be detected. However I think if a man in the middle speaks\nthe BOLT protocol they could exchange the entire package and provide a new\nHMAC as a previous hop could do. Also the Thread model does only speak\nabout security of the message not so much about the reliability of the\nprotocol. I believe it is quite clear that if a routing node wants to\nmanipulate the onion they can do so. In the same way how they can decide\nnot to forward the onion.\n\n--> So the mix network itself can make sure that no wrong messages are\ndelivered it cannot make sure that messages (which are unseen and unknown\nfrom where they came) are intercepted.\n\nBesides the Bitflipping usecase that I mentioned I agree with your\ncriticism and also don't see the necessity of the HMAC anymore. The message\nis encrypted anyway and if bits are flipped the decrypted version will just\nbe badly formated. If the header was manipulated the next hop would not be\nable to decrypt.\n\nBest regards Rene\n\nAm Do., 29. Nov. 2018, 16:31 hat Corn\u00e9 Plooy via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> geschrieben:\n\n> Hi,\n>\n>\n> Is there a reason why we have HMACs in Sphinx? What could go wrong if we\n> didn't?\n>\n> A receiving node doesn't know anyway what the origin node is; I don't\n> see any attack mode where an attacker wouldn't be able to generate a\n> valid HMAC.\n>\n> A receiving node only knows which peer sent it a Sphinx packet;\n> verification that this peer really sent this Sphinx packet is (I think)\n> already done on a lower protocol layer.\n>\n>\n> AFAICS, The only real use case of the HMAC value is the special case of\n> a 0-valued HMAC, indicating the end of the route. But that's just silly:\n> it's essentially a boolean, not any kind of cryptographic verification.\n>\n>\n> CJP\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181129/ea78ec4f/attachment.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-11-29T17:13:29",
                "message_text_only": "Hi Corne,\n\nthe HMACs are necessary in order to make sure that a hop cannot modify\nthe packet before forwarding, and the next node not detecting that\nmodification.\n\nOne potential attack that could facilitate is that an attacker could\nlearn the path length by messing with different per-hop payloads: set\nn=0 the attacker flips bits in the nth per-hop payload, and forwards\nit. If the next node doesn't return an error it was the final recipient,\nif if returns an error, increment n and flip bits in the (n+1)th per-hop\npayload, until no error is returned. Congratulation you just learned the\npath length after you. The same can probably be done with the error\npacket, meaning you can learn the exact position in the route. Add to\nthat the information you already know about the network (cltv_deltas,\namounts, fees, ...) and you can probably detect sender and recipient.\n\nAdding HMACs solves this by ensuring that the next hop will return an\nerror if anything was changed, i.e., removing the leak about which node\nwould have failed the route.\n\nCheers,\nChristian\n\nCorn\u00e9 Plooy via Lightning-dev <lightning-dev at lists.linuxfoundation.org> writes:\n> Hi,\n>\n>\n> Is there a reason why we have HMACs in Sphinx? What could go wrong if we\n> didn't?\n>\n> A receiving node doesn't know anyway what the origin node is; I don't\n> see any attack mode where an attacker wouldn't be able to generate a\n> valid HMAC.\n>\n> A receiving node only knows which peer sent it a Sphinx packet;\n> verification that this peer really sent this Sphinx packet is (I think)\n> already done on a lower protocol layer.\n>\n>\n> AFAICS, The only real use case of the HMAC value is the special case of\n> a 0-valued HMAC, indicating the end of the route. But that's just silly:\n> it's essentially a boolean, not any kind of cryptographic verification.\n>\n>\n> CJP\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            }
        ],
        "thread_summary": {
            "title": "Reason for having HMACs in Sphinx",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Corn\u00e9 Plooy",
                "Ren\u00e9 Pickhardt",
                "Christian Decker"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 6508
        }
    },
    {
        "title": "[Lightning-dev] CPFP Carve-Out for Fee-Prediction Issues in Contracting Applications (eg Lightning)",
        "thread_messages": [
            {
                "author": "Matt Corallo",
                "date": "2018-11-29T19:37:54",
                "message_text_only": "(cross-posted to both lists to make lightning-dev folks aware, please \ntake lightning-dev off CC when responding).\n\nAs I'm sure everyone is aware, Lightning (and other similar systems) \nwork by exchanging pre-signed transactions for future broadcast. Of \ncourse in many cases this requires either (a) predicting what the \nfeerate required for timely confirmation will be at some (or, really, \nany) point in the future, or (b) utilizing CPFP and dependent \ntransaction relay to allow parties to broadcast low-feerate transactions \nwith children created at broadcast-time to increase the effective \nfeerate. Ideally transactions could be constructed to allow for \nafter-the-fact addition of inputs to increase fee without CPFP but it is \nnot always possible to do so.\n\nOption (a) is rather obviously intractible, and implementation \ncomplexity has led to channel failures in lightning in practice (as both \nsides must agree on a reasonable-in-the-future feerate). Option (b) is a \nmuch more natural choice (assuming some form of as-yet-unimplemented \npackage relay on the P2P network) but is made difficult due to \ncomplexity around RBF/CPFP anti-DoS rules.\n\nFor example, if we take a simplified lightning design with pre-signed \ncommitment transaction A with one 0-value anyone-can-spend output \navailable for use as a CPFP output, a counterparty can prevent \nconfirmation of/significantly increase the fee cost of confirming A by \nchaining a large-but-only-moderate-feerate transaction off of this \nanyone-can-spend output. This transaction, B, will have a large absolute \nfee while making the package (A, B) have a low-ish feerate, placing it \nsolidly at the bottom of the mempool but without significant risk of it \ngetting evicted during memory limiting. This large absolute fee forces a \ncounterparty which wishes to have the commitment transaction confirm to \nincrease on this absolute fee in order to meet RBF rules.\n\nFor this reason (and many other similar attacks utilizing the package \nsize limits), in discussing the security model around CPFP, we've \ngenerally considered it too-difficulty-to-prevent third parties which \nare able to spend an output of a transaction from delaying its \nconfirmation, at least until/unless the prevailing feerates decline and \nsome of the mempool backlog gets confirmed.\n\nYou'll note, however, that this attack doesn't have to be permanent to \nwork - Lightning's (and other contracting/payment channel systems') \nsecurity model assumes the ability to get such commitment transactions \nconfirmed in a timely manner, as otherwise HTLCs may time out and \ncounterparties can claim the timeout-refund before we can claim the HTLC \nusing the hash-preimage.\n\nTo partially-address the CPFP security model considerations, a next step \nmight involve tweaking Lightning's commitment transaction to have two \nsmall-value outputs which are immediately spendable, one by each channel \nparticipant, allowing them to chain children off without allowng \nunrelated third-parties to chain children. Obviously this does not \naddress the specific attack so we need a small tweak to the anti-DoS \nCPFP rules in Bitcoin Core/BIP 125:\n\nThe last transaction which is added to a package of dependent \ntransactions in the mempool must:\n  * Have no more than one unconfirmed parent,\n  * Be of size no greater than 1K in virtual size.\n(for implementation sanity, this would effectively reduce all mempool \npackage size limits by 1 1K-virtual-size transaction, and the last would \nbe \"allowed to violate the limits\" as long as it meets the above criteria).\n\nFor contracting applications like lightning, this means that as long as \nthe transaction we wish to confirm (in this case the commitment transaction)\n  * Has only two immediately-spendable (ie non-CSV) outputs,\n  * where each immediately-spendable output is only spendable by one \ncounterparty,\n  * and is no larger than MAX_PACKAGE_VIRTUAL_SIZE - 1001 Vsize,\neach counterparty will always be able to independantly CPFP the \ntransaction in question. ie because if the \"malicious\" (ie \ntransaction-delaying) party bradcasts A with a child, it can never meet \nthe \"last transaction\" carve-out as its transaction cannot both meet the \npackage limit and have only one unconfirmed ancestor. Thus, the \nnon-delaying counterparty can always independently add its own CPFP \ntransaction, increasing the (A, Tx2) package feerate and confirming A \nwithout having to concern themselves with the (A, Tx1) package.\n\nAs an alternative proposal, at various points there have been \ndiscussions around solving the \"RBF-pinning\" problem by allowing \ntransactors to mark their transactions as \"likely-to-be-RBF'ed\", which \ncould enable a relay policy where children of such transactions would be \nrejected unless the resulting package would be \"near the top of the \nmempool\". This would theoretically imply such attacks are not possible \nto pull off consistently, as any \"transaction-delaying\" channel \nparticipant will have to place the package containing A at an effective \nfeerate which makes confirmation to occur soon with some likelihood. It \nis, however, possible to pull off this attack with low probability in \ncase of feerate spikes right after broadcast.\n\nNote that this clearly relies on some form of package relay, which comes \nwith its own challenges, but I'll start a separate thread on that.\n\nSee-also: lightning-dev thread about the changes to lightning spec \nrequired to incorporate this: \nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001643.html\n\nMatt"
            }
        ],
        "thread_summary": {
            "title": "CPFP Carve-Out for Fee-Prediction Issues in Contracting Applications (eg Lightning)",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Matt Corallo"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 5548
        }
    }
]