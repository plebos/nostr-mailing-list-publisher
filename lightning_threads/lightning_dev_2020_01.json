[
    {
        "title": "[Lightning-dev] On Path Privacy",
        "thread_messages": [
            {
                "author": "darosior",
                "date": "2020-01-02T10:49:09",
                "message_text_only": "Hi ZmnSCPxj,\n\nJust a nit to add for reference to this great writeup.\n\n\n> -   Add random tweaks to your channel traversal costs.\n>     -   This is done currently by the C-Lightning route randomization feature, but note that it is currently set to up to a +/-5% tweak.\n>         -   [This paper](https://arxiv.org/pdf/1909.06890) evaluates the C-Lightning route randomization as well.\n>             It suggest adding random tweaks to the costs of entire routes instead, though it may not be easy for normal pathfinding algorithms to implement this.\n\nSince the authors made this analysis, the total fuzzing has been replaced by a tweak of both the base and proportional fees, added along the CTLV during the shadow route random walk.\nhttps://github.com/ElementsProject/lightning/blob/8c387932c0095ffbe7314a73004337f5cc15ece0/plugins/pay.c#L827\n\nRegards,\nDarosior\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 477 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200102/91b4ba7b/attachment-0001.sig>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-20T01:21:46",
                "message_text_only": "Good morning list,\n\nFew people have responded to this topic, but when has that ever stopped me from spamming the mailinglist?\n\nAnalysis of Path Extension for Privacy\n======================================\n\nAs mentioned before, increasing the path length deliberately, by any means, intuitively makes it seem that privacy is improved.\nI will now show how this is not a panacea and that its cost in terms of increased fees, increased risk of stuckness, and increased worst-case stuckness might not justify its benefits, which are weaker (at least on the current network) than they might seem at first glance.\n\nLet us first start with an example network:\n\n\n    A -- B -- S1-- C -- D -- G -- H\n         |  /    /   \\  |  /      |\n         | /    /     \\ | /       |\n         I -- J         E -- S2-- F\n\nLet us suppose that `A` wishes to make a payment to `F`.\nFurther, let us assume for simplicity that all nodes charge the same amount for forwarding, and that they all charge 0.01 units base and 0 proportional.\n\nFinally, let us also assume that `S1` and `S2` are two nodes run by a single surveillor, and that all the other nodes are otherwise not interested in destroying Lightning privacy.\nNow, obviously `A` and `F` do not know that `S1` and `S2` are run run by a surveillor, thus cannot identify S1 and S2 as belonging to a single actor that wants to snoop their payment.\n\n\nNow let us suppose that A takes the shortest path `A -> B -> S1 -> C -> E -> S2 -> F`.\nWould it be improved to artifically increase the path length?\n\nWe can observe that, with the current network, due to the same hash being used in the entire route, `S1` and `S2` can easily notice when they are on the same route.\n\nThus, suppose we increased the path length by taking this route instead: `A -> B -> S1 -> I -> J -> C -> D -> G -> E -> S2 -> F`.\nThen our surveillor gets exactly the same information as in the case `A -> B -> S1 -> C -> E -> S2 -> F`.\n\n* An incoming payment went into S1 via B, so the payer must be A or B (taking the shortest-path heuristic pre-S1).\n* An outgoing payment went out of S2 via F, so the payer must be F (taking the shortest-path heuristic post-S2).\n\nThus, in many cases, it is immaterial if we actually inserted greater length onto the path.\nWe can generally expect that surveillors can easily just buy a bunch of BTC and insert many nodes into the network to act as surveillance nodes, especially since forwarding pays fees and thus the requirement to lock funds in channels is not in fact an opportunity cost.\nOnce a path passes through more than one surveillor nodes, any increase in length between the two endmost cooperating surveillor nodes does not improve privacy.\nThus `A` would end up paying the costs of increased path length (higher fees, higher risk of stuckness, highest worst-case stuckness) *without* any benefit to its privacy.\n\nIndeed, we might point out that if `A` took the path `A -> B -> S1 -> C -> D -> G -> H -> F`, then it would have avoided `S2` and the single surveillor would have a much larger set of possible destinations to analyze.\nBut if it instead took the longer path `A -> B -> S1 -> I -> J -> C -> D -> G -> E -> S2 -> F`, then `S2` would have helped the surveillor pin down the destination that either A or B is paying to.\n\nWhich brings the next point: longer path also means increased chances of going through *two* surveillance nodes, and thus having the payment endpoints (ultimate sender, ultimate receiver) be identified by surveillor nodes.\nThe increased path length also means less reliable forwarding (more nodes can fail), meaning it is now more likely that `A` will have to find another route.\nThis increases the chances that `S1` and `S2` will be on *some* route.\nAnd because the same hash will *also* be used on the alternate routing attempts, then if on one attempt we went `A -> B -> S1 -> C -> D -> G -> H -> F` and on the next attempt we went `A -> I -> J -> C -> E -> S2 -> F`, then both `S1` and `S2` can still triangulate the ultimate payer and ultimate payee as with getting the shortest path in the first place!\n\nThe intuition that \"sub-optimal paths means better privacy\" is countered by the intuition that \"the more people you tell, the less private it is\".\nAt least on the current network, the fact that we can identify a single payment (across multiple nodes within an attempt, and across multiple attempts trying to forward the same payment) means increased path length does not buy a lot of privacy, and the significant losses in useability might not be commensurate to the mild increase in privacy it *theoretically* could get.\n\nFortunately, the PTLC-based path decorrelation fixes most of these, and with that, at least it is hard for `S1` and `S2` to identify if forwards going through them are the same payment, at least from the payment hash.\n\nDigression: `permuteroute` Privacy\n----------------------------------\n\nPreviously, [I discussed the `permuteroute` algorithm](https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-August/002095.html), which is basically the Path Splicing technique applied to Lightning payments.\nTLDR: When a payment fails at a particular node or channel along a route, we copy the path prefix before the break, the path postfix after the break, and make a route around the break, getting better time behavior since it is likely that the area around the break has alternate routes that are still relatively short (Dijkstra algorithm in particular has a massive increase in runtime for every additional node on the shortest path, so if the shortest path is very short, the runtime for the Dijkstra run to bridge the break would be much faster than if we redid it from the source to the destination).\n\nAn advantage of `permuteroute` is also the fact that *you do not tell more people about your payment*.\nThe prefix of path is reused rather than looking for a completely new path, and the nodes along that prefix *already* knows about the payment and its hash and its amount and its CLTV-delta, from the previous failing payment attempt.\nTelling them approximately the same details *again* in the next payment attempt is not an *additional* privacy leak at least.\n(in general a `permuteroute` will either increase or give the same path length as the previous attempted path, so the first attempt will give, via the unremovable data CLTV-delta and amount, the shortest distance from a surveillor node to the destination, and subsequent `permuteroute` attempts will tend to give a *longer* distance to the destination, which does not help the surveillor to *narrow down* the destination, thus does not increase privacy leaks to the nodes on the reused prefix.)\n\nThus, I expect that `permuteroute` will give, not only a good improvement in practical pathfinding speed, it would also give a mild practical improvement in privacy compared to using high-randomization pathfinding techniques like the Rusty Russell Random Route Ralgorithm for *every* payment attempt.\n\nPrivacy Non-Improvement Due To Practical Limits\n-----------------------------------------------\n\nThere is a practical limit to the number of nodes you can stuff onto an artificially lengthened path.\nUnfortunately, it means as well that privacy improvement at the destination end translates to privacy reduction at the source end.\n\nFor instance, it is likely that wallets would want to bound the outgoing CLTV-delta at the ultimate sender.\nIf this CLTV-delta were, for instance, to be a year away from the current blockheight, then at the worst-case, in case of a stuck payment, the funds used in a stuck payment would be locked for a year in an HTLC.\nThus, obviously wallets will be designed to impose some maximum CLTV-delta at the ultimate sender.\nFor example, C-Lightning limits this, by default, to 576 blocks.\n\nKnowing this limit, if an arbitrary forwarding node were, for instance, to note that the incoming HTLC had a CLTV that was 548 blocks in the future, then it can guess that the ultimate sender is a node within 28 CTLV-delta blocks away from it.\nOf course, such a large CLTV means that the outgoing HTLC probably has a similarly large CLTV relative to now, meaning that the destination is harder to find.\nBut in effect, any improvement in making the destination harder to find comes with a decay in the privacy of the source.\n\nAs well, the amount can give a lesser degree of this, if the forwarding node can guess some standard amount is the final payment at the destination; C-Lightning imposes a default `maxfeepercent` limit of 0.5%.\n\nThis works with only analyzing CLTV-delta (and maybe amount, but that is much less reliable), from a single forwarding node, thus path decorrelation does *not* help with this (path decorrelation helps when multiple, but not all, forwarding nodes are controlled by a single surveillor).\nCLTV-delta and amount are unremoveable data and thus this analysis is always possible, so any improvement we can use to improve destination privacy is likely to come at the cost of the source privacy.\n\nThis may still be a good tradeoff: the onion protocol used makes identifying the source very difficult, whereas the destination is tightly constrained by the CLTV-delta that must be provided to every forwarding node, so sacrificing a little source privacy to get a little destination privacy may still be worth it, but it should as well be noted that payment information is much more valuable if information about *both* the payer *and* the payee is available.\n\nRandom Walk Loops\n-----------------\n\nIncreasing the path length using a naive form of Rusty Russell Random Route Ralgorithm may lead to loops being formed in the proposed path, e.g. `A - > B -> S1 -> C -> E -> G -> D -> E -> S2 -> F`.\nFor the node `E`, which appears twice in that route, this is not much different from the case that it is running two separate nodes `S1` and `S2`: a node it controls appears more than once on the same route, thus leading to the ability to eliminate intermediate hops from consideration.\nThat is, the \"detour\" through `G` and `D` becomes immaterial to the analysis that `E` can perform on the route.\nThe end result is that we pay more for including `G` and `D`, but they do not increase our privacy against the node that happens to be the pivot on a loop.\n\nThus, we should use path length increasing algorithms that specifically avoid loops being formed.\nOf course, this can now be used as a basis for a heuristic by which a forwarding node can eliminate some nodes from its analysis by simply assuming that loops do not occur.\n\nWith path decorrelation, identifying loops becomes difficult and they will have much lower privacy loss.\n\nAnalysis of Multipath and JIT Routing for Privacy\n=================================================\n\nMultipath gives an improvement to useability, allowing payments to be distributed across multiple paths rather than requiring that the entire payment be successfully routable as a single large payment.\n\nI would point out as well that Just-In-Time Rebalancing, more commonly known as JIT Routing, gives you most of what multipath gives, but with much simpler software design.\n(Nothing prevents Just-In-Time rebalancing from being done by the ultimate payer, so as long as the payer has *some* channel that can hold the entire payment, it would be perfectly fine to initially have the ultimate payer with its funds distributed across multiple channels, which is another thing that people have been thinking would require multipath to solve: Just-in-time rebalance works with this as well.)\n\nI will now demonstrate that JIT Routing gives better privacy than multipath, at least with the current network.\n\nWith multipath, every part of the payment has the same hash.\nThus, suppose `A` splits a single payment into two parts, each taking paths `A -> B -> S1 -> C -> D -> G -> H -> F` and `A -> I -> J -> C -> E -> S2 -> F`.\nAgain, this gives `S1` and `S2` the same tight information, that it is likely the ultimate sender is either `A` or `B` and the ultimate destination is `F`.\n`S1` and `S2` need only compare their CLTV-deltas (data that cannot be removed from the payment) to determine which one is likely to be nearer the source and which is likely to be nearer the destination, and thereby get better triangulation of both the ultimate sender and ultimate receiver.\n\nIn fact, it is worse than that.\nMultiple cooperating surveillors that find themselves on different parts of the same payment can use the unremovable CLTV-delta information to create a Venn diagram of the possible destinations, then consider that the destination is the intersection of those nodes that are within the outgoing CLTV-delta of each of them.\n(Similar information as well can be extracted from multiple attempts of a single payment.)\n\nOn the other hand, an important property of JIT Routing is that a rebalance attempt triggered by a payment has a different hash from the payment.\nThus, the other nodes that would be involved in the JIT Routing are never given the important detail of the hash of the actual payment, thus preventing them from easily being correlated.\nBecause there is only a single path for the \"real\" payment, we follow the principle \"telling more people makes it less private\": only the nodes specified by the ultimate payer in the payment onion are told of the *actual* payment details, all the other \"supporting\" nodes that facilitate the payment by allowing rebalances are not told about the payment details, they only get told about rebalances, which are much less interesting (it is literally just shuffling your own money around).\nIn particular, they are *not* told the CLTV-delta of the \"main\" payment path, which is the largest single-node privacy leak in Lightning (for multi-node surveillors, the hash is an even bigger privacy leak).\n\n\nOf course, path decorrelation helps reduce the issues that multipath has.\nCLTV-deltas are still an issue under multipath though, and the fact that rebalances triggered by a payment do not leak the actual CLTV-deltas of the original payment is still an important advantage that JIT Routing has over even decorrelated multipath.\n\n\nAnalysis of Path Decerrelation for Privacy\n==========================================\n\nAs noted above, path decorrelation mitigates privacy issues with both artificially-lengthened paths, and multipath.\n\nOf note is that these only close privacy leaks regarding hashes.\nCLTV-delta in particular is still not fixed by path decorrelation.\n\nHowever, path decorrelation does enable some important possible techniques.\n\nExtended Shadow Routing\n-----------------------\n\nAs noted before, artificially increasing the path length makes it harder for forwarding nodes to use the shortest-path heuristic to determine te ultimate payer and ultimate payee of a payment attempt.\nIncreasing the path length tends to increase the number of hop nodes that are traversed, increasing costs, risk of stuck payments, and lock time of stuck payments.\n\nWe can observe in particular that when considering stuckness, every additional hop node affects our useability twice:\n\n* Every additional hop node is another hop node that could fail between forwarding and claiming.\n* Every additional hop node demands additional CLTV-delta for that hop, increasing the total amount of time we will offer on the first outgoing HTLC.\n\nThus, very long routes tend to greatly reduce useability.\n\nA way to mitigate this would be to use \"extended shadow routing\", where instead of *actually* taking a longer path, we *pretend* to take a longer path and overpay some forwarding nodes with more fees and CLTV-delta than they demand.\n\nFor example, as noted above, the shortest path from `A` to `F` is `A -> B -> S1 -> C -> E -> S2 -> F`.\nOr more precisely, if `A` has to pay 1.0 unit to `F`, and all hop nodes have a 0.01 base fee and 0 proportional fee, the route is: `A ->1.05-> B ->1.04-> S1 ->1.03-> C ->1.02-> E ->1.01-> S2 ->1.00-> F`.\n(I have elided the CLTV-delta requirements, but I am sure you can imagine the CLTV-delta requirements from this; indeed, CLTV-delta is a much better way to break privacy than the amount, so consider the example as a proxy for CLTV-delta being used to analyze the path.)\n\nWith path decorrelation, `S1` and `S2` can no longer rely on a single hash along the entire route.\nEven so, they could still determine the shortest path between them, and thereby know the expected difference in amount and CLTV-delta from the outgoing of `S1` to the incoming of `S2`.\n>From this, they can determine with high probability that forwards of similar value and sidereal timing are actually belonging to the same single payment.\n\nNow suppose instead `A` took the sub-optimal path `A ->1.07-> B ->1.06-> S1 ->1.05-> C ->1.04-> D ->1.03-> G ->1.02-> E ->1.01-> S2 ->1.00-> F`.\nNow `S1` and `S2` can no longer use the shortest path between them to determine that this is a single payment --- the outgoing of `S1` minus the incoming of `S2` is no longer the cost of the direct path between them, so they cannot assign high probability that the two forwards they see are hops of the same payment.\nBut for `A`, this comes at the cost of higher fees, higher CLTV-delta, and higher risk of payment attempt failure --- now any failures at `D` and `G` will affect the payment experience.\n\nTo mitigate this, instead `A` can take this sub-optimal path that has fewer nodes but overpays the fees and CLTV-delta of `C`: `A ->1.07-> B ->1.06-> S1 ->1.05-> C ->1.02-> E ->1.01-> S2 ->1.00-> F`.\nThis is extended shadow routing, where not only do we overpay at the destination, we also randomly overpay intermediate hops.\nWe still use the shortest path in terms of hops, but the random overpaying we do at intermediate hops makes it harder for other intermediate hops to determine if the forwards belong to the same payment or not.\n\n(Again, just to be clear: we also adjust the CLTV-delta correspondingly to overpay the CLTV-delta demanded by `C`.)\n\nStandardized Multipart Splitting Amounts\n----------------------------------------\n\nOf course, if the only payment going around with an amount of 1.0 units is the payment between `A` and `F`, and all the other payments do not, it is still possible, even with path decorrelation, for `S1` and `S2` to correlate the forwards by looking at the payment amounts.\n\nFortunately, if we are able to fix the triangulation issues with multipath by implementing path decorrelation, we can subsequently use multipath to fix the amount-correlation issue.\n(Nothing to be done about the CLTV-delta, though...)\nThis is done by specifying a set of standardized payment amounts, and forcing our algorithms to split with those amounts always, possibly overpaying the destination a little just to hide all the payment amounts of a multipath to standardized payment amounts.\n\nFor example, suppose we define standardized payment amounts 16, 8, 4, 2, 1, 0.5, 0.25, 0.125, 0.0625.\nIf we want to pay 1.3 units, we could split our payment into 1, 0.25, and 0.0625, leading to a total of 1.3125 units, for a 0.96% overpayment.\n\nThe advantage of this is that it strengthens increasing the path length (whether for real, or by \"extended shadow routing\" which just artificially increases the path length by overpaying intermediate hops).\nAs noted before, if the only payment going around with 1.0 units is that between `A` and `F`, then `S1` and `S2` can increase the probability they assign that the two forwards they see belong to the same payment, even if we increased the path length between them so they can no longer use the shortest-path heuristic.\nBut if we use standardized payment amounts, and 1.0 is one of the standard amounts, then `S1` and `S2` cannot be certain that the two forwards they individually see are the same payment --- they could be two unrelated standard-amount payments instead.\nThis reduces amount-based correlation.\n\nIn particular, with path decorrelation, multiple attempts of a part are now also harder to correlate --- it could be that those are unrelated attempts from a different payment.\n\nOf course, this topic is likely to lead to a lot of debate.\nFor instance, powers of two might not be the best (maybe a Fibonacci sequence would be better to minimize overpayment, in much the same way they reduce unused space in `malloc` implementations), multipart receivers might not want to receive a multipart payment composed of payments below the dust threshold (because if they have to drop onchain, they may end up getting multiple incoming parts worth zilch each), more standard payment amounts just split the anonymity set (and what number of standard payment amounts is optimal?) and so on.\nSince the benefit of standardized multipart splitting amounts lies in there *being* a standard, I suggest we instead just vote on *whether or not* to define such a standardized set of amounts, and if we do decide to go with this, just hold a lottery on who exactly will define the standardized amounts.\n(instead replacing the long debates on what standardized payment amounts to use with long debates on how to do a trustless online-only lottery)\n\nNo matter what set of standardized amounts we define, it seems to me that there will be payments so small that splitting them up would be unnecessarily uneconomical, or the payment amount might be smaller than the smallest standardized amount.\nWe might accept the loss of privacy in those if we consider them to be small and not of much interest.\n\nAmount Decorrelation By Self-Payment\n------------------------------------\n\nWe already know that we can perform donations by using a self-payment, hiding the donation in the fee of the node we wish to pay.\n\nWith PTLCs, which are a requirement of path decorrelation anyway, we can increase the security of such circular payments (they can no longer be stolen by wormhole attacks), and also have a proof-of-payment arrive from the payee (by using the sum of the payee secret plus a secret known by the payer at the payee hop).\nThis also implements a form of stuckless payments.\n\nIf we use two standardized sets of payments with a small difference between them, it becomes possible as well to pay smaller amounts by paying using the *difference* between two standard payment amounts.\nAs well, the return path ends up misleading successful analysis, as it *inverts* the direction of who is the *actual* payer and who is the *actual* payee.\nThis could be used to mislead analysis by using a standard amount in the forward section of the path and then use a non-standard amount in the return path, allowing payment of tiny amounts that are impractical given the standard set, but misleading the *actual* amount and who is the *actual* payer and *actual* payee.\n\nAs a concrete example, suppose `A` wants to pay `I` a tiny 0.1 units, and does not care that the fees it ends up paying may be a significant fraction of that micropayment.\nIt could do: `A ->8.01-> B ->8.0-> I ->7.9-> S1 ->7.89-> B ->7.88-> A`.\n`A` ends up paying 8.01 - 7.88 = 0.13, so it paid 0.1 to `I` and 0.03 in fees.\n`S1` might end up being able to analyze the non-standard amount of `7.9-> S1 ->7.89` and determine that `I` pays `A` about 7.88 units, when in fact the actual payment is `A` paying `I` 0.1 units.\n\nAgainst this technique, we should also remind of the principle \"telling more people makes it less private\", however.\nAs well, this increases the number of hop nodes that could fail the payment, meaning more payment attempts (and thus more people getting told of the payment).\nMore analysis on the use of circular payments when paying may be in order.\n\nIn any case, this would require explicit support in the BOLT spec as well, as we would need invoices to be payable with a direct payment, and with an indirect circular payment as well.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "On Path Privacy",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "darosior",
                "ZmnSCPxj"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 24902
        }
    },
    {
        "title": "[Lightning-dev] Lightning in a Taproot future",
        "thread_messages": [
            {
                "author": "David A. Harding",
                "date": "2020-01-05T13:58:47",
                "message_text_only": "On Wed, Dec 18, 2019 at 02:51:56PM +1100, Lloyd Fournier wrote:\n> Hi ZmnSCPxj and Aj,\n> \n> Thanks for starting this discussion ZmnSCPxj. Although transactions with\n> relative lock times are easily distinguishable today, couldn't this\n> situation be improved? Even just a few wallets changing their behaviour to\n> set relative time locks on normal payments would weaken the heuristic. \n\nAs mentioned in ZmnSCPxj's post, some wallets (most notably Bitcoin\nCore) provide partial anti-fee-sniping protection by setting their\nnLockTime to the next-block height[1].  In line with your idea to do the\nsame with nSequence, I think it would be possible to suggest to the\nBitcoin Core project that they also set nSequence to the block age of\nthe UTXO being spent (if possible[2]).  I think this could slightly\nenhance existing anti-fee-sniping by limiting a sniper's ability to\nrearrange ancestor transactions.  For example, imagine we have two\ntransactions both created by Bitcoin Core on the best block chain:\n\n                      tx0               tx1\n                       |                 |\n          [ ]---------[ ]-------[ ]-----[ ]----\n    Block 600,000    ..01      ..02    ..03\n\nLet's assume tx0 and tx1 were both confirmed quickly, so their nLockTime\nequals their block height.  That means a fee sniper's reorg can't move\neither transaction further back in the chain, burying them under\naddition PoW.  Let's also assume that tx1 is a child of tx0 and sets its\nnSequence to 2 blocks.  Now tx0 also can't be moved further forward in\nthe chain without also moving tx1 further forward, meaning any reduction\nin the amount of PoW covering one transaction would also reduce the\namount of PoW covering any of its descendant transactions (if they\nopt-in to this scheme).\n\nBitcoin Core obviously has the information necessary to add an\nappropriate nSequence to its transactions because it has a copy of the\nUTXO set, but *every* wallet should be keeping track of its transaction's\nconfirmation scores, so every wallet should know the nSequence delta to\nuse to allow its transactions to be confirmed in the next block but no\nearlier block.\n\nMy question here would be whether this change would be useful in providing\nprivacy for the scheme ZmnSCPxj described.  IIUC, the pre-signed\ntransactions Zmn described wouldn't need to use both relative locktime\n(nSequence) and absolute locktime (nLockTime) at the same time, so it\nwould be possible to set nLockTime to an appropriate value when using\nnSequence for security.  This might not blend in perfectly with\nanti-fee-sniping (especially to relay nodes) but perhaps Bitcoin Core's\nfuzzing[1] could be increased to help compensate.\n\n-Dave\n\n[1] I think Bitcoin Core implements low-probability fuzzing of the\nnLockTime to help cover for wallets that send transactions while still\nsyncing to the tip.  E.g. an instance fully synced to the current chain\ntip might set 1-in-100 of its transactions nLockTime to some past block\nheight so that spy nodes can't tell whether that transaction was\ntransmitted by a fuzzing node or one of the nodes that just happened to\nbe IBD syncing from them at that moment.\n\n[2] nSequence can only encode up to a max of 65,535 for the block\ndistance; see BIP68.  Also, obviously, if the parent transaction is\nunconfirmed at the time one of its outputs is spent, the child can't\nhave a relative lock-height unless you want to delay its confirmation.\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200105/42a10c0d/attachment.sig>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-06T07:37:20",
                "message_text_only": "> indeed one can argue that the entire point of enabling Schnorr and Taproot at the base layer is to allow us to use payment point+scalar at the Lightning layer.\n\nJust to be clear, this statement is intended to be facetious, along the same vein as \"Lightning Network is so awesome, we just had to invent Bitcoin for it\".\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-07T00:26:05",
                "message_text_only": "Good morning David,\n\n> On Wed, Dec 18, 2019 at 02:51:56PM +1100, Lloyd Fournier wrote:\n>\n> > Hi ZmnSCPxj and Aj,\n> > Thanks for starting this discussion ZmnSCPxj. Although transactions with\n> > relative lock times are easily distinguishable today, couldn't this\n> > situation be improved? Even just a few wallets changing their behaviour to\n> > set relative time locks on normal payments would weaken the heuristic.\n>\n> As mentioned in ZmnSCPxj's post, some wallets (most notably Bitcoin\n> Core) provide partial anti-fee-sniping protection by setting their\n> nLockTime to the next-block height[1]. In line with your idea to do the\n> same with nSequence, I think it would be possible to suggest to the\n> Bitcoin Core project that they also set nSequence to the block age of\n> the UTXO being spent (if possible[2]). I think this could slightly\n> enhance existing anti-fee-sniping by limiting a sniper's ability to\n> rearrange ancestor transactions. For example, imagine we have two\n> transactions both created by Bitcoin Core on the best block chain:\n>\n> tx0 tx1\n> | |\n> [ ]---------[ ]-------[ ]-----[ ]----\n> Block 600,000 ..01 ..02 ..03\n>\n> Let's assume tx0 and tx1 were both confirmed quickly, so their nLockTime\n> equals their block height. That means a fee sniper's reorg can't move\n> either transaction further back in the chain, burying them under\n> addition PoW. Let's also assume that tx1 is a child of tx0 and sets its\n> nSequence to 2 blocks. Now tx0 also can't be moved further forward in\n> the chain without also moving tx1 further forward, meaning any reduction\n> in the amount of PoW covering one transaction would also reduce the\n> amount of PoW covering any of its descendant transactions (if they\n> opt-in to this scheme).\n>\n> Bitcoin Core obviously has the information necessary to add an\n> appropriate nSequence to its transactions because it has a copy of the\n> UTXO set, but every wallet should be keeping track of its transaction's\n> confirmation scores, so every wallet should know the nSequence delta to\n> use to allow its transactions to be confirmed in the next block but no\n> earlier block.\n>\n> My question here would be whether this change would be useful in providing\n> privacy for the scheme ZmnSCPxj described. IIUC, the pre-signed\n> transactions Zmn described wouldn't need to use both relative locktime\n> (nSequence) and absolute locktime (nLockTime) at the same time, so it\n> would be possible to set nLockTime to an appropriate value when using\n> nSequence for security. This might not blend in perfectly with\n> anti-fee-sniping (especially to relay nodes) but perhaps Bitcoin Core's\n> fuzzing[1] could be increased to help compensate.\n\nUnfortunately it does not quite work to have a transaction with *both* non-zero `nLockTime` and relative-locktime `nSequence`.\n\nFor `nLockTime`-only (no relative locktime, i.e. all `nSequence` is 0xFFFFFFE), these are used in HTLC / PTLC contracts.\nThe beneficiary of the timelock branch of the HTLC/PTLC will publish it at around the `nLockTime`, which matches with the behavior that Bitcoin Core will produce.\n\nFor `nSequence` relative-locktime transactions that protect the security of the channel mechanism, these are used in unilateral closes.\nThe issue is that a unilateral close might occur far, far in the future.\nThus, any non-0 `nLockTime` you signed up for at the time the commitment transaction was signed, will likely be obsolete.\n\nInstead, what Bitcoin Core would have to do would be something like:\n\n* Toss a coin:\n  * If it is heads, use a non-relative-locktime `nSequence` and an `nLockTime` of the next block (i.e. current behavior).\n  * If it is tails, use a relative-locktime `nSequence` equal to the confirmations of the output being spent, and an `nLockTime` of 0.\n\nThen we would hide the Lightning relative-locktime transactions with an `nLockTime` of 0.\n\nNote that `nLockTime` transactions can be used in general as a backoff for cooperative protocols such as CoinSwap.\nI allude to this use here: https://github.com/AdamISZ/CoinSwapCS/issues/53\nThus we expect that there will be more users of `nLockTime`d transactions than relative-timelock `nSequence` transactions.\nIt might be wise to bias the above coin towards using the relative-locktime `nSequence` more often than the `nLockTime`.\n\nAs far as I can tell, relative-locktime is most often used for unlimited-lifetime offchain updateable mechanisms, of which Lightning Poon-Dryja, Decker-Wattenhofer, and \"eltoo\" Decker-Russell-Osuntokun are the examples most readily available from my cortex-analogue.\nAll intra-chain swaps (submarine swaps, CoinSwap, Lightning multi-hop routing) should use absolute-locktime, and can be optimized to some extent by use of `nLockTime` ordinary spends.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-10T15:24:56",
                "message_text_only": "Good morning,\n\nAnother point regarding the use of \"purely scriptless\" (i.e. using pre-signed `nLockTime` and `nSequence`d transactions) is that there are significantly more signatures to be generated cooperatively.\nWe need to use MuSig for these in order to hide in the much larger 1-of-1 anonymity set.\nThere are two branches per PTLC (pointlock and timelock), and one of those branches would lead to a revocable output (which has a relative-locktime), thus 3 signatures (just for one HTLC).\nIt is probably safe to perform the MuSig for all three signatures in one MuSig exchange, and probably for all PTLCs on each commitment transaction as well, plus the revocable `to_self` output.\nHowever the commitment transaction itself would have to be signed *after* all the PTLCs and revocable `to_self` have been signed, so we cannot run the MuSig for this in parallel with the PTLCs and `to_self`.\n\nNow, we know we can hide the timelock branches, as well as the revocable outputs, with other `nLockTime`d and `nSequence`d transactions.\n\n* The timelock branch will be enforced by one of the participants, and will come onchain (if not congested) at the same blockheight indicated by the `nLockTime`.\n* The revocable output will be claimed at the end of the revocation grace period, and will come onchain (if not congested) at the relative blocktime indicaated by the `nSequence`.\n\nBoth of the above will be indistinguishable from the anti-fee-sniping behavior (once we modify Bitcoin Core to randomly select between absolute and relative anti-fee-sniping), thus hides among the other transactions made by Bitcoin Core.\n\nHowever, the commitment transaction itself, and the pointlock branch, cannot hide among the anti-fee-sniping behavior.\n\n* The commitment transaction is kept indefinitely, and if there is no activity on the channel, a million blocks may pass since its `nLockTime` and `nSequence` have been fixed.\n  * Thus, any `nLockTime` or `nSequence` we put in the commitment transaction would be well in the past by the time the commitment transaction appears onchain, and thus they can be identified that way.\n  * We could just recreate the commitment transaction every time a new block comes in, so that the latest commitment transaction always has an up-to-date `nLockTime` or `nSequence`, but now every block would cause a system shock across the entire Lightning Network as all nodes update their channel states with their peers.\n    * But what happens if the peer is offline at a new block?\n      We are forced to keep around a commitment transaction with a past `nLockTime`/`nSequence`.\n      If the peer remains offline we might then decide to push the commitment transaction, but since the peer is offline, it will have the past `nLockTime`/`nSequence`.\n* The pointlock branch is dependent on the commitment transaction above, and encounters the same issues.\n\nSo in general it might be better for commitment transactions, as well as scriptless script pointlocks, to not have a fee-sniping-protection-emulation.\nBut this means we also do not want to have all wallets use fee-sniping-protection.\n\nAnother point, and the reason why I pointed out that you need at least two MuSig rounds (the first running all the PTLC and revocable outputs in parallel, the second signing just the commitment hosting them), is that this increases latency of each update.\nThis is fine if you are on open network, but on e.g. Tor each turnaround is greatly increased, and the multiple MuSig rounds get more delay.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "David A. Harding",
                "date": "2020-01-10T18:30:07",
                "message_text_only": "On Tue, Jan 07, 2020 at 12:26:05AM +0000, ZmnSCPxj wrote:\n> For `nSequence` relative-locktime transactions that protect the\n> security of the channel mechanism, these are used in unilateral\n> closes.  The issue is that a unilateral close might occur far, far in\n> the future.  Thus, any non-0 `nLockTime` you signed up for at the time\n> the commitment transaction was signed, will likely be obsolete.\n\nAs long as there's no conflict created by using both relative and\nabsolute locktimes in the same transaction, I don't think there's any\nproblem.  Multiple versions of a commitment transaction may be signed,\neach with different nLockTimes but all other parts of the transaction\nthe same (including any relative timelocks).  This obviously requires a\ntiny bit of extra CPU plus modest amounts of extra bandwidth and\nstorage, but it seems within reason for people who want better privacy.\n\n> Instead, what Bitcoin Core would have to do would be something like:\n> \n> * Toss a coin:\n>   * If it is heads, use a non-relative-locktime `nSequence` and an `nLockTime` of the next block (i.e. current behavior).\n>   * If it is tails, use a relative-locktime `nSequence` equal to the confirmations of the output being spent, and an `nLockTime` of 0.\n> \n> Then we would hide the Lightning relative-locktime transactions with an `nLockTime` of 0.\n\nCommitment transactions for current two-party LN have at least two\noutputs; the chance of both outputs being spent with an nLockTime of 0\nis 25% (assuming every non-LN onchain transaction uses the above\nscheme).  That's a fairly significant bias that can be combined with\nother indicators to identify LN transactions for analytics or censorship.\n\n-Dave\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200110/1ae4f757/attachment.sig>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-12T15:01:06",
                "message_text_only": "Good morning David,\n\n\n> On Tue, Jan 07, 2020 at 12:26:05AM +0000, ZmnSCPxj wrote:\n>\n> > For `nSequence` relative-locktime transactions that protect the\n> > security of the channel mechanism, these are used in unilateral\n> > closes. The issue is that a unilateral close might occur far, far in\n> > the future. Thus, any non-0 `nLockTime` you signed up for at the time\n> > the commitment transaction was signed, will likely be obsolete.\n>\n> As long as there's no conflict created by using both relative and\n> absolute locktimes in the same transaction, I don't think there's any\n> problem. Multiple versions of a commitment transaction may be signed,\n> each with different nLockTimes but all other parts of the transaction\n> the same (including any relative timelocks). This obviously requires a\n> tiny bit of extra CPU plus modest amounts of extra bandwidth and\n> storage, but it seems within reason for people who want better privacy.\n\nYes, but how many `nLockTime` candidates are enough?\nIf there is not enough granularity, then you will be forced to use an `nLockTime` that is in the past, and if the blockchain layer is not congested then, it is a smoking gun of such pre-signed transactions.\nEither that or you wait for the next available `nLockTime`.\n\nFurther, there must always exist some limit on the largest-`nLockTime` commitment transaction you keep.\nIf the largest-`nLockTime` commitment transaction is now approaching, and the counterparty goes offline, then you have a Morton fork:\n\n* Drop the commitment transaction at the correct blockheight now.\n  * You regret this later if the counterparty comes online, since now your channel is in a closed state.\n* Keep the channel open.\n  * You regret this later if the counterparty remains offline, since now your commitment transaction is badly out-of-date and you lose privacy if you drop it.\n\nWe see this already with `update_fee` disagreements, if the funder gives an apparently-lowball fee estimate, do you drop now (and lose possible revenue), or do you wait (and risk that later, that lowball fee estimate is even lower for the current situation).\nDue to user complaint we have gone the \"wait and maybe suffer later\" route but that is the choice that leaks privacy in the above fork.\n\n>\n> > Instead, what Bitcoin Core would have to do would be something like:\n> >\n> > -   Toss a coin:\n> >     -   If it is heads, use a non-relative-locktime `nSequence` and an `nLockTime` of the next block (i.e. current behavior).\n> >     -   If it is tails, use a relative-locktime `nSequence` equal to the confirmations of the output being spent, and an `nLockTime` of 0.\n> >\n> > Then we would hide the Lightning relative-locktime transactions with an `nLockTime` of 0.\n>\n> Commitment transactions for current two-party LN have at least two\n> outputs; the chance of both outputs being spent with an nLockTime of 0\n> is 25% (assuming every non-LN onchain transaction uses the above\n> scheme). That's a fairly significant bias that can be combined with\n> other indicators to identify LN transactions for analytics or censorship.\n\n\nHmm?\n\nAssuming both counterparties have a balance on the channel, then at least one of the outputs must be spendable (disregarding the revocation branch) with a relative lock time, so if we select between \"0 `nLockTime` but enabled `nSequence`\" vs \"current blockheight plus one `nLockTime`\" at 50%, and there are only the two \"main\" outputs and no PTLCs, then you get exactly 50% of the outputs being spent with one policy and 50% being spent with the other policy.\n\nBasically, on every Poon-Dryja commitment transaction, assuming there are no PTLCs/HTLCs and both sides have money in the channel, then:\n\n* one output will be directly spendable by the remote side.\n* one output will be spendable by the local side, but only after a relative locktime from the commitment transaction.\n\nSo if the remote side uses an `nLockTime`-enabled transaction, and the local side uses a `nSequence`-enabled transaction to scriptlessly implement relative locktime, then we match the 50% coin toss.\n\nUnless you are referring to something else?\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "David A. Harding",
                "date": "2020-01-12T18:04:41",
                "message_text_only": "On Sun, Jan 12, 2020 at 03:01:06PM +0000, ZmnSCPxj wrote:\n> Basically, on every Poon-Dryja commitment transaction [...]\n> \n> * one output will be directly spendable by the remote side.\n> * one output will be spendable by the local side [...] after a\n>   relative locktime [...]\n> \n> So if the remote side uses an `nLockTime`-enabled transaction, and the\n> local side uses a `nSequence`-enabled transaction to scriptlessly\n> implement relative locktime, then we match the 50% coin toss.\n\nThat's better, but I don't think it's quite as good as you claim.\n\nGiven a parent transaction with two outputs which are spent as two\nseparate child transactions, the four equal-probability outcomes for a\nnon-LN wallet that randomly sets either nSequence or nLockTime are:\n\n    | child 0   | child 1   |\n    |-----------|-----------|\n    | nLockTime | nLockTime |\n    | nLockTime | nSequence |\n    | nSequence | nLockTime |\n    | nSequence | nSequence |\n\nYou're proposing that either (nLockTime, nSequence) or (nSequence,\nnLockTime) be used.  That's 50% of the options, which is not the same as\nthe results of a 50% coin toss.  A block chain analyst can rule out any\ntransactions pairs using (nLockTime, nLockTime) or (nSequence,\nnSequence) as unilateral closes.  This eliminates 50% of transactions\nfrom the anonymity set protecting LN unilateral closes.\n\nWe could obviously improve that by having the remote side randomly\nselect between nLockTime and nSequence for its transaction, but I don't\nbelieve that you ever get access to the full anonymity set like you do\nwhen dual timelocking.\n\n-Dave\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200112/2a4fb4a1/attachment.sig>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-24T09:56:10",
                "message_text_only": "Good morning David, and list,\n\nIt seems to me possible (though potentially undesirable) to have a \"maximally private\" channel that uses *only* absolute locktimes.\n\nFor maximum privacy, you would need to sign new pairs of commitment transactions at every block anyway.\nAnd if you sign a new pair \"too late\", you run the risk that a block will arrive and then make your transaction obviously not match the Bitcoin Core anti-fee-sniping behavior, thus distinguishable, thus non-private, so to preserve the privacy of your channels you would have to drop onchain as soon as a block arrives but your counterparty is not responding quickly enough to sign a new commitment transaction (and all the dreary other transactions needed to make the commitment transaction actually contain the contracts you want, in Scriptless Script form) *and* revoke the previous commitment transaction.\n\nSo suppose you start at block height N.\nYou and your counterparty sign commitment transactions that have an `nLockTime` of N+2.\n\nThe consideration here is that if those commitment transactions are unrevoked as of block height N+2, then one or the other commitment transaction ***will*** be dropped onchain, because if not then the transaction will be \"out of place\" in the block and obviously is not a Bitcoin Core anti-fee-sniping transaction.\n\nNow, for a commitment transaction to be revocable, the outputs that are owned by the holder of the commitment transaction must be revocable.\nTypically, that is implemented by adding a relative-timelock, and a branch that allows immediate revocation.\nBoth branches can be actually be implemented in Scriptless Script: relative-locktime by pre-signing an `nSequence`d transaction, immediate revocation by revealing your share of the pubkey.\n\nBut note that we have a strong promise that this commitment transaction will appear at block height N+2 (unless revoked by then), because privacy.\nSo we know as well that the \"relative-locktime\" branch will appear at block height N+2+R, where R is the relative-locktime.\nSince we already know what *absolute* blockheight we want it to appear in, we could just use an absolute-locktime `nLockTime` requirement, with the pre-signed N+2+R for that transaction that spends the commitment transaction.\n\nSo the relative-locktime times needed here can instead be transposed to absolute locktimes, i.e. `nLockTime`d transactions that are indistinguishable from Bitcoin Core anti-fee-sniping transactions.\n\nSo no need to modify the Bitcoin Core to use `nSequence` as well for anti-fee-sniping.\n\nWhy is the commitment transaction set up with an `nLockTime` of N+2?\nBecause if a block arrives, the block height is now N+1.\nSo now the participants have to create a pair of commitment transactions at N+3 and revoke their held N+2 transactions.\nIf not, then they have to drop the N+2 commitment transaction *now* so that miners can include them in the *next* block at height N+2.\n\n(We could switch to N+3 instead, that at least gives a one-block-duration limit for the other side to respond in and update their transactions)\n\nOf course, the drawbacks are:\n\n* If this is widespread, there will be bursts of activity on the Lightning network at every block.\n* The use of MuSig Schnorr signing means a good amount of turnarounds, which is bad for high-latency connections like Tor hidden services, further compounded by the need to perform such signing rituals at each block.\n* As soon as your counterparty drops offline, the channel between you will now be at high risk of simply being dropped onchain right now, i.e. closing.\n\nBut note the extreme privacy!\nNow there is no need for relative locktimes, just absolute ones, and we already have a plausible anonymity set for absolute-locktime transactions (Bitcoin Core anti-fee-sniping).\nWith Schnorr and Scriptless Script, and the above technique of \"just sign new commitments at every block\", even a unilateral close is indistinguishable from normal spends by Bitcoin Core, and if you still use an unpublished channel (perish the thought!) they are no longer obvious to onchain analysis as Lightning Network channels.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-27T01:40:30",
                "message_text_only": "Good morning list,\n\n> Good morning David, and list,\n>\n> It seems to me possible (though potentially undesirable) to have a \"maximally private\" channel that uses only absolute locktimes.\n>\n> For maximum privacy, you would need to sign new pairs of commitment transactions at every block anyway.\n> And if you sign a new pair \"too late\", you run the risk that a block will arrive and then make your transaction obviously not match the Bitcoin Core anti-fee-sniping behavior, thus distinguishable, thus non-private, so to preserve the privacy of your channels you would have to drop onchain as soon as a block arrives but your counterparty is not responding quickly enough to sign a new commitment transaction (and all the dreary other transactions needed to make the commitment transaction actually contain the contracts you want, in Scriptless Script form) and revoke the previous commitment transaction.\n>\n> So suppose you start at block height N.\n> You and your counterparty sign commitment transactions that have an `nLockTime` of N+2.\n>\n> The consideration here is that if those commitment transactions are unrevoked as of block height N+2, then one or the other commitment transaction will be dropped onchain, because if not then the transaction will be \"out of place\" in the block and obviously is not a Bitcoin Core anti-fee-sniping transaction.\n>\n> Now, for a commitment transaction to be revocable, the outputs that are owned by the holder of the commitment transaction must be revocable.\n> Typically, that is implemented by adding a relative-timelock, and a branch that allows immediate revocation.\n> Both branches can be actually be implemented in Scriptless Script: relative-locktime by pre-signing an `nSequence`d transaction, immediate revocation by revealing your share of the pubkey.\n>\n> But note that we have a strong promise that this commitment transaction will appear at block height N+2 (unless revoked by then), because privacy.\n> So we know as well that the \"relative-locktime\" branch will appear at block height N+2+R, where R is the relative-locktime.\n> Since we already know what absolute blockheight we want it to appear in, we could just use an absolute-locktime `nLockTime` requirement, with the pre-signed N+2+R for that transaction that spends the commitment transaction.\n\n\nNo, sorry, this is insecure, because the \"revoked by then\" branch still exists, this is daft, lower-level cognition agents proposing this have been reduced in influence in the overall community of sub-agents.\nSo no, we still need relative-locktime here.\n\n\nI would also like to point out that the revelation of relative-locktime requirements would only happen in a unilateral honest closs (they can be hidden in a unilateral dishonest close that is caught and revoked, by using the revocation key as a shard of the Taproot key).\nMutual closes can be simple spends in a Taproot future of a Schnorr output, and thus have good privacy.\nI have not trawled the data yet but I believe unilateral closes are a tiny fraction of mutual closes, so this privacy leak might be acceptable.\n\nAgainst this, however, we might consider that as Lightning becomes more stable, deliberate closure of channels becomes less likely, meaning more closes will be \"accidental\", e.g. bugs, nodes going offline, etc.\nThus unilateral closes may increase in proportion compared to mutual closes in the future, in which case we might want to re-consider privacy for unilateral closes.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Lightning in a Taproot future",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "David A. Harding",
                "ZmnSCPxj"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 27862
        }
    },
    {
        "title": "[Lightning-dev] Byzantine nodes in Lightning network",
        "thread_messages": [
            {
                "author": "Subhra Mazumdar",
                "date": "2020-01-05T14:11:12",
                "message_text_only": "Is there any literature available on how protocols would get affected in\npresence of Byzantine nodes ? For example, consider that a 2 byzantine\nnodes open a payment channel, since none of the intermediate transaction in\na channel gets recorded, will this impact other transactions which gets\nrouted through this channel ?\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200105/4ce9c472/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-07T12:18:34",
                "message_text_only": "Good morning Subhra,\n\n\n> Is there any literature available on how protocols would get affected in presence of Byzantine nodes ?\n\nI am unaware of such.\n\nIn any case, when considering Byzantine faults, a Byzantine fault occurs where one node appears functional to some subset of the the system, but appears broken to a different subset.\n\nWhen considering the channel mechanism (ignoring the payment layer on top that is built on cross-channel atomic swaps that are built on HTLCs), then the channel mechanism involves only two nodes.\n\nThus a Byzantine fault is impossible, at least when considering the channel mechanism.\nByzantine faults can only occur if at least three nodes exist: node A appears broken to node B but looks perfectly fine to node C.\nAt the channel mechanism layer, we only consider that if your channel counterparty seems broken, you can always just drop the channel onchain at any time and enforce any state needed by the payment layer onchain.\nThus, the blockchain resistance to Byzantine actors comes into play when you drop channels onchain.\n\nMore interesting is considering the payment layer on top of the channel layer.\n\nIf the payment is from a payer with a direct channel to the payee, then it is completely uninteresting, as again this is the same impossible-to-Byzantine, two-participant, we-can-always-drop-things-onchain-at-any-time case.\n\nThe interesting case is with a forward, wherein some remote payer sends payments through one or more forwarding nodes.\nThere is already much literature and analysis regarding the multi-hop forwarding mechanism, including the original Poon-Dryja paper, as well as the \"multi-hop locks\" paper.\n\nFor the most part, for a hop node on a payment attempt, there are three participants:\n\n* Itself.\n* The incoming node.\n* The outgoing node.\n\nLet us consider each case.\n\n* Suppose itself is Byzantine.\n  * Suppose it acts correctly to the incoming node, but acts strangely to the outgoing node.\n    * Then the outgoing node will not claim the payment and itself will be unable to claim the payment.\n      * At worst-case, the HTLC timeout will come into play and force failure of the payment.\n  * Suppose it acts correctly to the outgoing node, but acts strangely to the incoming node.\n    * The the outgoing node will claim the payment, but itself will be unable to claim the incoming payment.\n      * Itself, if it is rational, would avoid this case, since it would end up paying the payee while the supposed payer does not actually give any money.\n* Suppose the incoming node is Byzantine.\n  * Then itself would not even know what the outgoing node would be, so this devolves to a 2-participant case.\n* Suppose the outgoing node is Byzantine.\n  * Then the outgoing node would be unable to claim the payment.\n    * Itself will then fail the incoming payment.\n\nThe same analysis holds for all hop nodes on a single payment attempt.\n\n\n> For example, consider that a 2 byzantine nodes open a payment channel, since none of the intermediate transaction in a channel gets recorded, will this impact other transactions which gets routed through this channel ?\n\nDo you mean that the 2 cooperating nodes have a direct payment channel with each other and want to somehow negatively affect the rest of the network?\n\nThose two nodes would be indistinguishable from a single node that has the channels of both nodes.\n\nIn fact, the channel between those nodes would be \"wasted\", i.e. locked for no good reason.\nThe aggregate of the two nodes would own all the money in that payment channel, and would uselessly allocate funds from one node to the other, even though they true owner is their aggregate and it is no different from the aggregate HODLing its funds in a hot wallet.\n\nIn such a case, it is immaterial to the rest of the network what games the aggregate of both nodes plays with the money that it holds solely as its own, in much the same way that you might mentally allocate your liquid funds as \"okay, I shall spend 10mBTC on buying new anime, 25mBTC on buying figurines of Asuka-sama, and 100mBTC in donating to ZmnSCPxj, the rest I shall keep in reserve\" and nobody else would care (because obviously Rei-chan is objectively better than Asuka-sama).\n\nThe only interesting case is if the two nodes are truly independent of each other.\nBut then the Byzantine problem also arises between these two nodes, thus if they are Byzantine anyway, they are far more likely to be unable to coordinate to attack the rest of the network and are far more likely to harm each other (but this is a cop-out).\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Byzantine nodes in Lightning network",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Subhra Mazumdar",
                "ZmnSCPxj"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 5117
        }
    },
    {
        "title": "[Lightning-dev] Research on proactive fee free channel rebalancing in the friend of a friend network / and roadmap for a protocol extension",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-07T02:30:00",
                "message_text_only": "Good morning Rene, and list,\n\nIt seems to me that the rule used here might be useful to guide how to split a payment for multipath as well.\n\nFor example, consider the case where a payer Alice has channels to Bob and Charlie.\n\n* Alice-Bob has A=0.5, B=0.5\n* Alice-Charlie has A=0.5, C=0.5\n\nIn that case, in order to retain balance, if Alice has to pay 0.1, it should strive to split the payment into a 0.05 via Alice-Bob and 0.05 via Alice-Charlie.\n\nWould it be possible to derive such a calculation from your published rule?\nFor example, if one of the payer channels is imbalanced in favor of the payer, then the payment probably should not be split, but if the payment is big enough that it would be imbalanced against the payer afterwards, then some small amount must be split out to another channel.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2020-01-07T14:57:41",
                "message_text_only": "Good morning ZmnSCPxj, and list,\n\nthe answer to your question is absolutely yes and we can can achieve this\nactually in a very simple and elegant way.\n\nPlease find attached a clear and simple adaption of the algorithm described\nfrom the paper for a general multipath payment and a small python code\nexample available at:\nhttps://github.com/renepickhardt/Imbalance-measure-and-proactive-channel-rebalancing-algorithm-for-the-Lightning-Network/blob/master/code/mppalgo.py\nthat computes this in a model case (assuming 10 payment channels that all\nhave a capacity of 1 BTC just to save some lines in coding). The output of\nthe code is at the end of the Mail.\n\n\nAlgorithm to conduct payments which optimally (? I have not proved this yet\nbut I see no way that would be more optimal with respect to the\nGinicoefficients) reduces the imbalance of nodes when conducting a\n(multipath)payment.\n\nLet us assume a node $u$ wants to pay someone for an amount $a$.\n\n1. We assume the payment was already achieved over some channel(s) and\ncompute the new node balance coefficient $\\nu'_u$ after this imaginary\npayment has been conducted as $\\frac{\\tau_u - a}{\\kappa_u}$. remember\n\\tau_u is just the total amount of funds that node $u$ currently has and\n$\\kappa_u$ is the sum of the capacities of all its payment channels.\n2. For all online channel partners $\\{v_1,...,v_d\\}$ we compute\n$\\zeta_{(u,v_1),...,\\zeta_{(u,v_d})}$\n3. Let us assume channels are ordered such that\n$\\zeta_{(u,v_1)>...>\\zeta_{(u,v_d'})}$ and omit channels with $\\zeta(u,v_i)\n- \\nu'_u < 0$ Those channels need more funds and should not be used to pay.\nThat is why we might have $d' < d$\n5. Compute all $d'$ rebalancing amounts $r_i =\nc(u,v_i)*(\\zeta_{(u,v_i)}-\\nu'_u)$ as in the paper but with the new node's\nbalance coefficient!\n6. set $R = sum_i r_i$\n7. distribute payments across channels  $a_i = a*r_i/R$ being the amount\n$a_i$ that should be paid on channel $i$. Recall $a_i < a$ and $sum_i a_i =\na$ and $a_i < r_i$. This means that with this computation all channel have\nenough liquidity to do the subpayments and the subpayments will add up to\nthe amount (ignoring channel reserves)\n8. probe for paths for each amount and channel (potentially split the\namount for a channel across several paths that all start with that\nchannel). As we don't know what the rest of the network looks like we don't\nknow if we will be able to find paths for each channel (as before)\n\nNow the really nice side effect: We could compute routing hints for the\ninvoices in the same way! by now taking the channels where $\\zeta(u,v_i) -\n\\nu'_u$ < 0. We could also split the amounts in that way and also give\namounts together with the routing hints. This would allow a sender to send\nthe payments in a way that is most benefitial too us. (The sender could\nalso follow the above method for their outgoing channels) Only the rest of\nthe network might suffer worse imbalance bus guess what they charge a\nrouting fee for that service!\n\nWith these nice results let me just review some notation from the paper (so\nthat we in future might all agree to this wording/termonology):\n\n* *Rebalancing* is the operation of moving funds along circular paths\nbetween channels. As pointed out in the past this does not really change\nthe topology of the graph as the properties like the max flow / min cut\nwill not be affected by this. As such some people (including myself) have\nargued in the past that multipathpayments are sufficient for path finding\nas they will quicker find the max flow and that rebalancing is not\nnecessary. However the results of my research indicate that such operations\nwill increase the likelihood of arbitrary payments to succeed and thus (at\nleast in my interpretation) increase the reliability of the network.\n* in particular a node is *balanced* if the zeta values are the same and\nthe gini coefficient is zero. While this is the case for all channels being\n50-50 there are far less strict ways of achieving a good balance than\nasking for channels to be opened in such a way that everyone ha 50-50.\n* *Making payments actually changes the topology* of the network (similarly\nto opening and closing channels). With the notation of the paper the \\tau\nvalues change and are part of the topology. This way \"rebalancing\" with\nsubmarine swaps using loop or any of those services is not a rebalancing\noperation in the sense of the paper and/or the above point but in fact a\nchange of topology.\n* combining topology changes with rebalancing operations (which is often\nthe goal when making submarine swaps) seems however to be a good idea. In\nthat sense your general thought of rebalancing while paying should be\npursued.\n\nLast but not least the promised output of the example code:\n\n$ python3 mppalgo.py\n0.3 initial imblance\nnew funds 4.8 and new node balance coefficient 0.48\n\nConduct the following payments:\nchannel 0 old balance: 1.00, payment amount 0.22 new balance 0.78\nchannel 1 old balance: 0.90, payment amount 0.18 new balance 0.72\nchannel 2 old balance: 0.80, payment amount 0.14 new balance 0.66\nchannel 3 old balance: 0.70, payment amount 0.10 new balance 0.60\nchannel 4 old balance: 0.60, payment amount 0.05 new balance 0.55\nchannel 5 old balance: 0.50, payment amount 0.01 new balance 0.49\n\n---- unchanged channels as they need more funds on our side ----\n\nchannel 6 old balance: 0.40, payment amount 0.00 new balance 0.40\nchannel 7 old balance: 0.30, payment amount 0.00 new balance 0.30\nchannel 8 old balance: 0.20, payment amount 0.00 new balance 0.20\nchannel 9 old balance: 0.10, payment amount 0.00 new balance 0.10\ntotal amount paid over several channels:  0.7\n(was asked to send: 0.7)\n\nnew imbalance 0.25 and old imbalance 0.30\n\nHave a nice day! Rene\n\n\nOn Tue, Jan 7, 2020 at 3:30 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Rene, and list,\n>\n> It seems to me that the rule used here might be useful to guide how to\n> split a payment for multipath as well.\n>\n> For example, consider the case where a payer Alice has channels to Bob and\n> Charlie.\n>\n> * Alice-Bob has A=0.5, B=0.5\n> * Alice-Charlie has A=0.5, C=0.5\n>\n> In that case, in order to retain balance, if Alice has to pay 0.1, it\n> should strive to split the payment into a 0.05 via Alice-Bob and 0.05 via\n> Alice-Charlie.\n>\n> Would it be possible to derive such a calculation from your published rule?\n> For example, if one of the payer channels is imbalanced in favor of the\n> payer, then the payment probably should not be split, but if the payment is\n> big enough that it would be imbalanced against the payer afterwards, then\n> some small amount must be split out to another channel.\n>\n> Regards,\n> ZmnSCPxj\n>\n\n\n-- \nhttps://www.rene-pickhardt.de\n\nSkype: rene.pickhardt\n\nmobile: +49 (0)176 5762 3618\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200107/53e1fd73/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-07T15:26:42",
                "message_text_only": "Good morning Rene,\n\nI am glad my question has triggered such interest from you!\n\nI will confess that I do not yet understand the math you demonstrated and have not seen your program at all yet.\nIt is a good thing as well that it can be used to derive routehints for invoices.\n\nI do have a follow-up thought.\n\n-----\n\nI would like to point out that:\n\n* A JIT Routing is really just a rebalancing while you have a forwarding.\n* A rebalance is just a self-payment.\n* A self-payment is a payment, and as such can be split via multipath.\n* The multipath algorithm you derived here can still be reused for this case.\n\nSuppose a node wishes to forward via some channel that sadly has insufficient capacity.\nThen we can use your MPP algorithm, removing that target channel from our computations, and with the target amount being the difference between the available capacity on that channel and the value to be forwarded.\nThen we can determine how much amount we can pull from our *other* channels, and then generate an MPP self-payment / rebalance.\n\nFurther, the algorithm you described, appears to me to be most useful if the payer is not currently very well-balanced.\nThat is, the algorithm you described strives to move the payer from unbalanced to balanced.\nIf the payer is already perfectly balanced then the algorithm will strive to split the payment to all channels the payer has.\n\nThus, it seems to me that we may be better off with a \"lazy\" balancing scheme, aka JIT Routing.\n\n* If we have to pay, use the MPP splitting algorithm to better move towards balance.\n* If we have to forward but have insufficient funds in the forwarding, again use the MPP splitting algorithm to determine which other channels are best to source the money from to rebalance.\n\nIt may be useful to implement as a C-Lightning plugin with a `suggestsplit` that is given a target amount, plus an optional array of local channels to exclude, and outputs an array of channels plus how much it suggests to get from that channel.\nThen the multipath payment algorithm could refer to this, and a putative JIT routing plugin can refer to this as well.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-08T06:50:43",
                "message_text_only": "Good morning again Rene,\n\nAn observation I would like to make is that, as I understand it, the model inherently assumes that all nodes are equally likely to be payer and equally likely to be payee.\n\nWhile in a complete economy this is to be expected (the \"customer\" of a \"merchant\" will be an \"employee\" of some other \"merchant\") in an equilibrium state, it seems to me that transient states might exist where some nodes will demand more incoming funds.\nFor example, consider a manufacturer that has just released a new model of their product; generally the expectation is that customer interest in the new model will be high when just recently released, thus transiently such manufacturers will need more incoming liquidity than in equilibrium.\n\nThus I think JIT Routing is still more useful in practice than a proactive rebalancing policy, as it is more resilient to such transient shocks to the system.\nEvery rebalance is effectively a speculation that capacity in one (set of) channel(s) is less useful than capacity in another (set of) channel(s).\nTargeting some kind of \"perfect balance\" assumes that the equilibrium state will be that payments will generally be equal in all directions (an equilibrium state that I expect to be true, actually, once entire economies switch to the Lightning Network), but I think we should provision our nodes to also be resilient against transient shocks.\n\nThough I could also be overestimating the effects of such transient shocks, in which case equilibrium probably implies that targeting a perfect balance proactively would be better.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Research on proactive fee free channel rebalancing in the friend of a friend network / and roadmap for a protocol extension",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Ren\u00e9 Pickhardt",
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 11485
        }
    },
    {
        "title": "[Lightning-dev] Speculations on hardware wallet support for Lightning",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-14T15:14:57",
                "message_text_only": "Good morning list,\n\nI have been thinking of this for some time without really getting any good results, and in any case [this C-Lightning mailing list post](https://lists.ozlabs.org/pipermail/c-lightning/2019-December/000172.html) brings up similar topic.\nAs well, 0 or more people have asked me opinions on related topics as well.\n\nIn any case, the goal is to have some hardware unit, using only a simple communications channel with the software, to act as signer for all Lightning-related things (channel funding, channel updates, reclaiming funds after channel close).\nAs is typical for such Bitcoin-related hardware units, it might possess its own user interface by which it can require confirmation of certain actions.\nAlso, to reduce risk of hacking, the hardware unit does not have a connection to the netwrok, only a communications channel that is restricted to a local direct connection (such as USB).\n\nI will now demonstrate that such a design cannot achieve what an onchain Bitcoin hardware wallet does, namely that the hardware need not tr\\*st the software and need not keep any state beyond the private key (which remains constant).\nFor Lightning, it seems any hardware would require tr\\*st in the software *and* some state.\n\nCast of characters:\n\n* The hardware for this node.\n* The software for this node.\n* The other node.\n\nWhat I will attempt here would be to create a hardware that has as little tr\\*st in the software as possible, and reduce the state that the hardware signer has to store.\nIf these two goals conflict, I will attempt to reduce the tr\\*st in the software.\n\nChannel Updates\n===============\n\nOnchain hardware wallets do not require user interaction just to receive funds.\nThus, let us consider this goal.\n\nOn Lightning, funds are received by getting an HTLC that this node can claim from the other node on the channel.\nThis incoming HTLC deducts from the funds owned by the remote node.\n\nThus, the hardware only needs to verify that:\n\n* The funds owned by this node on the channel remains the same.\n* A new HTLC is added that this node can claim if it knows the preimage.\n\nThis requires that the hardware be able to compare a current state with a proposed new state.\nPresumably, the software for this node provides the current state, then the proposed new state, then if the hardware confirms that the state changes \"correctly\", it will sign the proposed new state.\n\nThe problem is, how can the hardware check that the \"current state\" is correct?\nFor example, suppose a channel was funded by this node, and thus all funds are owned by this node.\nThen the software is corrupted, and then it claims to the hardware that the current state is that all funds are owned by the other node and that the other node is offering an HTLC.\nThe hardware believes this claim of what the current state is, and signs the state where almost all the funds are owned by the other node.\n\nNote that we cannot have the software send the entire history of the channel to the hardware either.\nThe software can be corrupted into sending only a partial history, rewinding some set of recent channel updates, then a new history can be created on top of that, where this node is paid far less.\nOn the blockchain the longer and presumably \"more true\" history can be attested to with proof-of-work, but the hardware does not have a network connection and is thus under a persistent state of Sybil attack from the node software.\n\nThus, the hardware has to remember at least what the current state is, and store this knowledge in persistent, secure, modifiable memory that the software cannot touch.\nIt need not store the *whole* state: for example, it could store just a commitment to the current state (and have the software store the entire state).\nIn fact, it is best for the hardware to store the *signature* for the commitment transaction:\n\n* The signature commits to the commitment transaction, which is a representation of the current state, thus the signature itself is a sufficient commitment to the current state.\n  * There is the issue of outputs with values too small to have outputs on the commitment transactions (i.e. below the dust limit).\n    * We can use sign-to-contract, where the signature commits to *another* preimage, one which contains the outputs that are too small to put on the Bitcoin-level commitment transaction.\n* In case of a communication breakdown between the hardware and the software, the hardware can re-send the signature of the latest commitment transaction.\n  * This is important since the hardware and the software now have to synchronize their state storage!\n    The procedure is:\n    * The software stores the new state in a \"proposed\" slot in its persistent memory.\n    * The software sends the current and proposed states to the hardware for signing the proposed state.\n    * The hardware validates the update, then signs the proposed state and replaces the signature in its persistent memory.\n    * The hardware sends the new signature.\n    * The software moves the state in the proposed slot to the current slot.\n  * With the above, if the software ever starts up with a state in the \"proposed\" slot for a channel, it can query the hardware for the most recent signature, and determine if the most recent signed is in the \"proposed\" or \"current\" slot.\n    * Thus, the hardware only requires an atomic update to its persistent memory.\n\nThe hardware can safely resend the most recent signature, assuming it can trust its own persistent modifiable memory.\nThis is because presumably it validated every update leading to the most recent signature in the past, else this signature in its memory would not have existed in the first place.\n\nAs each channel has two sets of commitment transactions, the hardware has to store two commitments to commitment transactions for *each* channel.\n\nAnother point is that revocations of *own* old commitment transactions can be issued by the hardware itself.\nThis requires only a shachain; the hardware can hash the concatenation of the private key plus some channel-unique data (the full channel ID may be enough) to form the shachain seed for the revocation sequence of *own* commitment transactions.\n\nTr\\*sted Eventual Synchrony of Two Commitments\n==============================================\n\nEach channel has two commitment transactions, one for each node.\nThe commitment transaction for a particular node identifies which of the two nodes actually performed the unilateral close.\nIn particular, the BOLT spec allows both commitment transactions to drift out of synchrony with each other.\n\nEventually, if the channel becomes relatively inactive (no updates going through it), then it is expected that the two commitment transactions will eventually converge into a single common state.\nBut the two commitments may remain not completely in-synch indefinitely.\n\nIn order to properly determine synchrony, the hardware has to have an honest account of the transcript between the software for this node, and the other node.\nThe only source of this information is the software.\nThe software cannot falsely give a signature from the other node that updates our *own* commitment transaction, but the software can definitely lie and deny that the remote side has done so.\nThus, the two commitment transactions may drift out of synch significantly.\n\nThere might not be any significant attacks enabled by having the two commitments out-of-sync indefinitely.\nThis may prevent some HTLCs from being safely forwardable, but that only means stalls in payment forwarding.\n\n\nNon-publication of Revoked Transactions\n=======================================\n\nWith Poon-Dryja, publication of old state is fatal and is an easy way for a corrupted node software to donate money to the other node.\nEven with Decker-Wattenhofer or Decker-Russell-Osuntokun, a corrupted node software can simply publish an old state where most of the money is allocated to the other node, and not publish the latest state, so switching to Decker-Russell-Osuntokun (\"eltoo\") is not a large increase in security for a hardware signer.\n\nTo prevent publication of our *own* commitment transaction at least, the hardware can simply not sign *own* commitment transactions as they are created.\n(the hardware still has to immediately sign the *remote* commitment transaction, as part of the update protocol requires handing over that signature to the other node.)\n\nInstead of storing a signature for our \"own* commitment transaction, the hardware can store a simple hash or txid of the latest *own* commitment transaction.\nThus:\n\n* The hardware stores:\n  * The latest signature for the *remote* commitment transaction.\n  * The latest txid for the *own* commitment transaction.\n\nThe hardware will only sign an *own* commitment transaction that matches the txid currently stored in it.\nFurther, this particular commitment must now become the *last* commitment and the hardware should subsequently reject all attempts to further advance the state.\n\nWhen updating the *own* commitment transaction, the software must provide the signature from the other node for the next commitment transaction, as well as the current and proposed-next commitment transaction.\nThe hardware validates that the state change is valid, changes the *own* commitment txid, and then returns the equivalent revocation key for the just-replaced commitment transaction.\n\nCommunications breakdown between the hardware and software can still occur between the time the hardware sends the signature for the latest (and last) commitment transaction, and when the software receives it.\nThus, the hardware has to have a concept of a \"closed\" channel, where it marks that the current txid for the *own* commitment transaction is the last one, and it will provide the signature for that commitment transaction, but refuse to sign any other commitment transaction and refuse to advance the state of the channel.\nTo reduce the complexity of the software-hardware interface, we could also allow the hardware to sign a mutual close transaction that matches the *own* and *remote* commitment transactions even in this \"closed\" state.\nFinally the channel can later be removed from the (presumably limited) persistent storage of the hardware.\n\nThus the protocol for our own unilateral or mutual close would be:\n\n* The software requests to close the channel.\n* The hardware marks the channel as closed, which prevents the channel from updating in the future.\n* The software requests a signature for the final commitment or mutual close transaction.\n  * For mutual closes it provides the commitment transaction and the mutual close, and the hardware validates that the mutual close matches the commitment transaction.\n  * For unilateral closes the hardware also provides the signatures to claim the revocable outputs.\n* The software receives the signature and broadcasts the commitment or mutual close transaction onchain.\n* Once the transaction is deeply confirmed, the software requests the channel to be deleted from the hardware persistent storage.\n\nThus the hardware provides three APIs:\n\n* Mark-as-close.\n* Get-final-signature (unilateral or mutual close option).\n* Delete-closed.\n\nAt restart, the software can query the hardware for any channels that are currently being closed, and can check the mempool and blockchain for whether they have completed the close or not.\n\nTr\\*sted Revocation of Old Remote State\n=======================================\n\nUnfortunately, the hardware has to tr\\*st the software to check that the other node is not cheating.\nAs the hardware itself is not capable of accessing the blockchain or mempool, it cannot do this checking directly.\nThus, revocation of old remote state is not ensurable by the hardware.\n\nAs revocation can only be done by the software anyway, the revocation secrets for the *remote* commitment transactions can be stored by the software only.\nThe hardware need never learn the revocation secrets as it can do nothing with them anyway.\n\nOpening a Channel\n=================\n\nOf course, before we even start having updates to channel state, first we must have opened channels.\n\nOpening will of course allocate a slot in the hardware persistent memory for the channel.\nFurther, it must respect the opening sequence.\n\nWhen opening a channel where the other node is the only funder, then it is sufficient to just propose some initial state for both commitment transactions and have the hardware initialize a slot in its persistent memory with this channel open.\n\nHowever, when opening a channel where some of the funds come from this node, the hardware will also later sign the funding transaction spending its own funds and feeding into the channel to be funded.\nThe software provides the other node signature for the *own* initial commitment transaction.\nThe hardware then validates that it is able to claim the equivalent amount in both the *own* and *remote* commitment transactions.\nIf there is a difference, that implies that this node is what pays the fee, and the hardware should probably double-confirm with the user using its UI whether the paid fees are acceptab;e.\n\nTr\\*sted Forwarding\n===================\n\nForwarding should be automated and not require a confirmation from the user on the hardware unit UI.\nUnfortunately, the hardware has to trust the software to actually perform forwarding correctly.\n(indeed, it is unlikely that confirmation from the user would be able to give users a good way to understand what is being asked when a forwarding attempt is made)\n\nWhen forwarding, the hardware has to sign off on an update that actively spends money from funds owned by this node, on the basis of a promise that some other HTLC is offering money of greater value to this node.\nCertainly the hardware can demand that the software provide a current channel state showing the incoming HTLC, before it signs off on an updated channel state that instantiates the outgoing HTLC from the funds owned by this node.\n\nHowever, the hardware has to keep track that an incoming HTLC only has at most one outgoing HTLC,.\nIt cannot identify using the hash, incidentally: it is theoretically possible for a route to loop through a node twice, e.g. A -> B -> C -> D -> E -> C -> F, where C appears twice.\nFurther, if a payment attempt fails, then the ultimate payer might still try to route through this node, giving a different postfix past this node, so this node may forward the same hash twice on two or more different payment attempts.\nThus, the software and the hardware have to agree on some other identifier on HTLCs.\nIn C-Lightning, for example, HTLCs are internally identified by the database ID that they happen to get assigned to; database IDs are simply automatically-incremented counters.\n\nRegardless, even if we somehow, the *enforcement* of HTLCs is still controlled by the software:\n\n* The hardware has no access to the blockchain, thus it cannot know if the incoming HTLC is in fact something in the deep past already.\n  A corrupted software can induce the hardware to create an outgoing HTLC whose timelock is deeply in the past, then refuse to take the timelock branch of the outgoing HTLC while letting the timelock branch of the incoming HTLC be claimed by the other nodes.\n\nThus, forwarding is still trusted.\n\nAlternately, we can also point out that the only purpose of forwarding is actually just to improve our privacy.\n(in case it is not obvious, this is hyperbole)\nBy forwarding, it becomes ambiguous whether we are the ultimate payee if we get an incoming HTLC, and ambiguous whether we are the ultimate payer if we send an outgoing HTLC.\nIf we never forward, then this privacy is lost.\n(This is the same argument that rejects unpublished channels: nodes that only have unpublished channels cannot forward, thus every activity on their node is obviously arising or terminating at their node: unpublished channels delenda est)\n\nI will also point out that I laid out the goals for this exercise would be to reduce trust requirements first and state requirements second: privacy was not listed.\nThus, removing the ability to forward automatically can be removed for the purpose of this exercise.\n\nRetrying Payments\n=================\n\nWhen trying a payment once, the hardware can confirm to the user via its own UI whether to authorize the payment.\nHowever, when *re*trying a payment, it would be onerous if the hardware had to keep asking the user to confirm each payment attempt.\n\nInstead, the hardware can keep track of exactly one pending outgoing payment that the software will try its best to deliver.\nThe hardware can store the hash of this payment, and a maximum sendable amount (the nominal payment amount plus any extra that would pay for fees and any other privacy-improving routing techniques the software may apply).\nInitially the payment slot will be empty.\nThen, when the software initiates a payment, the hardware can be given the various data in the invoice, which it can display to the user in its UI, and when the user confirms the payment, it can load the hash and maximum allowed value into the payment slot.\n\nThen, when the software requests a new channel state, such that a new HTLC matching the payment slot hash is created from funds owned by this node, the hardware can keep track of the number of such HTLCs currently instantiated.\nAs the HTLC has to be instantiated on both commitment transactions, the hardware has to keep track, in persistent memory, a single counter that goes from 0 to 2.\nWhen such an HTLC is instantiated from the own node funds, the hardware increments this pointer if it is less than two.\nThen if such an HTLC is removed, and the funds returned to our own node funds, the hardware decrements this pointer.\nIf the HTLC is removed with the funds given to the other node, then the hardware must demand the preimage of the hash, as proof that indeed, the payment occurred.\nThen it can decrement that counter and set a flag that the payment has been completed (and thus the outgoing HTLC cannot be added again, i.e. the counter cannot be incremented).\nThen when the counter has fallen to zero with the payment-complete flag set, the hardware can clear the payment slot.\n\nThe hardware can support having multiple payments in parallel running by providing more than one payment slot.\n\nAccepting Payments\n==================\n\nThis is trivial: the hardware will sign off on all state updates that retain or increase the amount of funds owned by this node.\nPayment preimages for incoming payments need not even be known by the hardware, ever.\nThus there is no trust or storage requirements for accepting payments.\n\nReducing Storage Size\n=====================\n\nThe hardware can, instead of storing multiple channel slots and payment slots in its own persistent memory, can instead just store a single *commitment* to the current state it knows to be valid.\nThis can be done by transforming its state into a purely-functional data structure and merklizing it.\n\nA purely-functional data structure is a data structure where structural nodes, once constructed, cannot be modified.\nFor example, a singly-linked list can be made into a purely-functional data structure,\nIf we have a list A -> B -> C -> null, then we can \"mutate\" this structure by creating a new list with a different prefix, such as Q -> R -> C -> null.\nThe old C -> null node in the original list can be reused.\n\nBinary search trees are also easily transformed into purely-functional data structures.\nGenerally, the Okasaki book is the primary reference for purely-functional data structures.\n\nThen, to Merklize a purely-functional data structure, simply means that all pointers are replaced with hashes.\n\nThus, a Merkle tree is nothing more than a plain binary tree, Merklized.\n\n>From this point of view, the blockchain is nothing more than a Merklized singly-linked list, with the `prevBlockHash` serving as the \"next\" pointer.\nNew blocks are prepended to the front of this singly-linked list, and the \"null\" terminating the singly-linked list is nothing more than genesis.\n\nFor the hardware state, the top node can contain two \"pointers\", one for the channel data and one for the running-payments data.\nThe root is then the \"pointer\" to the current top node.\nThose \"pointers\" then point to two red-black (or other balanced purely functional) trees, one for the channel data and one for the running payments.\nWhen channel data only is updated, the top node is replaced, but the node for the running payments data is just copied from the previous top node.\nSimilarly, only the path to the channel data through the red-black tree is affected.\n\nUsing a Merklized purely-functional data structure to store the entire hardware state allows the hardware to only absolutely require a secure persistent memory that fits 32 bytes, enough for a single commitment.\nThis can allow some leeway in storing this root data redundantly in multiple places, and to encode it with error correction and detection, and so on.\n\nWhenever the software makes a request to the hardware, which in the above discussion requires the hardware to read its internal state, the software instead serializes the internal state.\nThen the hardware can validate that the software has not given it incorrect state.\nSimilarly, when the hardware has to update its state, it can give the reserialization of the modified data, and update its internal state.\nThe cute thing is that, just as a standard Merkle tree inclusion proof only requires sending a small subset of the entire Merkle tree, the software need not send the *entire* hardware state --- it can send only those parts that are relevant to the specific channel(s) and outgoing payment attempt(s) that it is currently asking for.\nThis can let the hardware be very cheap and limited, with the software handling all of the *actual* state storage.\n\nHowever, we must now be very careful to ensure that the state of both hardware and software remain the same even if both become powered off or some communication failure occurs.\nMy suggestion is for the software to store two copies of the hardware state (both \"copies\" can share some data files due to he purely-functional nature of the data, but some nodes will exist in only one copy or the other).\nThen, whenever the hardware has to update the state:\n\n* The software gives the part of the state that needs updating by the hardware.\n* The hardware provides the updated state data, plus a signature of the concatenation of the old root plus the new root as well as the new root.\n* The software stores the new state data (but retains the old state data).\n* The software asks the hardware to update its single root variable.\n  It provides the current root plus the new root, as well as the previous signature of the concatenation of those.\n* The hardware validates that the current root in its slot matches, that the signature is indeed a valid signature of itself, then updates its root slot.\n* The software deletes the parts of the old state data that were not reused in the new state.\n\nAt any time, if power is shut off, the software and hardware can recover by checking the current root held in the hardware.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Devrandom",
                "date": "2020-01-16T00:44:25",
                "message_text_only": "Thank you for the detailed evaluation.  Please see inline comments.\nTo make reading easier, I've replaced some uncontroversial text with\n[...].\n\nOn Tue, Jan 14, 2020 at 7:15 AM ZmnSCPxj via Lightning-dev\n<lightning-dev at lists.linuxfoundation.org> wrote:\n\n>\n> [...]\n> In any case, the goal is to have some hardware unit, using only a simple communications channel with the software, to act as signer for all Lightning-related things (channel funding, channel updates, reclaiming funds after channel close).\n> As is typical for such Bitcoin-related hardware units, it might possess its own user interface by which it can require confirmation of certain actions.\n> Also, to reduce risk of hacking, the hardware unit does not have a connection to the netwrok, only a communications channel that is restricted to a local direct connection (such as USB).\n>\n> I will now demonstrate that such a design cannot achieve what an onchain Bitcoin hardware wallet does, namely that the hardware need not tr\\*st the software and need not keep any state beyond the private key (which remains constant).\n> For Lightning, it seems any hardware would require tr\\*st in the software *and* some state.\n\n\nAgreed, any external signer must maintain state because it must not\nsign revoked transactions, etc. .\n\n>\n> Channel Updates\n> ===============\n>\n> [...]\n> Thus, the hardware has to remember at least what the current state is, and store this knowledge in persistent, secure, modifiable memory that the software cannot touch.\n\n\nAgreed.\n\n> It need not store the *whole* state: for example, it could store just a commitment to the current state (and have the software store the entire state).\n> In fact, it is best for the hardware to store the *signature* for the commitment transaction:\n\n\nI would say that's not enough, if we assume that the attacker can\ndestroy the underlying data, and destroy all backups.  If the attacker\ncan do that, the node is at the mercy of channel partners, since they\nwill be able to publish old state without the possibility of\nretaliation.  Thus there needs to be a secure form of storage where at\nleast one backup must be recoverable at all times within the penalty\ntime window.\n\nI do agree that a low-resource hardware wallet may just store the\nsignature, or other commitment to the state.  In that case, we could\nstore the full data using an append-only log to a hardened machine\nthat specializes in preventing destruction of data by an attacker.\n\n>\n> [...]\n>\n> Tr\\*sted Eventual Synchrony of Two Commitments\n> ==============================================\n> [...]\n> This may prevent some HTLCs from being safely forwardable, but that only means stalls in payment forwarding.\n\n\nThis is a good point we haven't considered in our original writeup.\nIntuitively, you are right that this can only result in stalls.\n\n>\n>\n>\n> Non-publication of Revoked Transactions\n> =======================================\n>\n> [...]\n> To prevent publication of our *own* commitment transaction at least, the hardware can simply not sign *own* commitment transactions as they are created.\n\n\nAgreed.\n\n>\n> [...]\n> Thus, the hardware has to have a concept of a \"closed\" channel, where it marks that the current txid for the *own* commitment transaction is the last one, and it\n\n\nAgreed.\n\n>\n> [...]\n> Thus the hardware provides three APIs:\n>\n> * Mark-as-close.\n> * Get-final-signature (unilateral or mutual close option).\n> * Delete-closed.\n\n\nIt seems that the first API call can be folded into the second.  Also,\ndelete must be only performed once enough time has passed so that the\nclosing tx is unlikely to be reorged out of existence.  This requires\nthe hardware wallet to have a trusted source of knowledge about the\nstate of the blockchain or current time.  We wrote about UTXO set\noracle and the use of roughtime oracles in our original writeup.\n\n>\n> [...]\n> Tr\\*sted Revocation of Old Remote State\n> =======================================\n>\n> Unfortunately, the hardware has to tr\\*st the software to check that the other node is not cheating.\n> As the hardware itself is not capable of accessing the blockchain or mempool, it cannot do this checking directly.\n> Thus, revocation of old remote state is not ensurable by the hardware.\n\n\nI am more optimistic about this.  Publishing of penalty transactions\ncan be delegated to a quorum of watchtowers, some possibly run by\nother entities.  The node software can prove to the hardware that the\nwatchtowers have been informed of new state by providing a receipt\nsigned by the watchtowers.  Thus it's possible to reduce trust in the\nnode software.\n\n>\n>\n> As revocation can only be done by the software anyway, the revocation secrets for the *remote* commitment transactions can be stored by the software only.\n> The hardware need never learn the revocation secrets as it can do nothing with them anyway.\n\n\nI would at least back up the secrets in the secure storage attached to\nthe hardware store, so that the node can be recreated if the node\nsoftware has been catastrophically compromised.\n\n>\n> Opening a Channel\n> =================\n>\n> [...]\n> If there is a difference, that implies that this node is what pays the fee, and the hardware should probably double-confirm with the user using its UI whether the paid fees are acceptab;e.\n\n\nIf the fee is under a preset threshold, it can be auto-approved.\n\n>\n>\n> Tr\\*sted Forwarding\n> ===================\n>\n> Forwarding should be automated and not require a confirmation from the user on the hardware unit UI.\n> Unfortunately, the hardware has to trust the software to actually perform forwarding correctly.\n\n\nLet's look at this carefully, I feel it should be possible to prove\ncorrectness of forwarding to the hardware.\n\n>\n> However, the hardware has to keep track that an incoming HTLC only has at most one outgoing HTLC,.\n> It cannot identify using the hash, incidentally: it is theoretically possible for a route to loop through a node twice, e.g. A -> B -> C -> D -> E -> C -> F, where C  appears twice.\n\n\nI think it's enough to require that each incoming HTLC can be\nassociated with a single outgoing HTLC.  The hardware would have to\nmaintain state about which HTLCs have been \"used up\" in this way.\n\n>\n> Further, if a payment attempt fails, then the ultimate payer might still try to route through this node, giving a different postfix past this node, so this node may forward the same hash twice on two or more different payment attempts.\n\n\nhmm... that doesn't sound safe, because then two different nodes would\nbe able to claim the funds from us, and we can only propagate back to\na single input, so we lose funds.  If the Lightning protocol allows\nthis, then it sounds like a design issue.  Seems like the failed HTLC\nshould be invalidated first.  The invalidation can be proven to the\nhardware (a new commitment tx is signed, removing the HTLC, or the\noutgoing channel is closed).\n\n>\n> [...]\n> Regardless, even if we somehow, the *enforcement* of HTLCs is still controlled by the software:\n>\n> * The hardware has no access to the blockchain, thus it cannot know if the incoming HTLC is in fact something in the deep past already.\n>   A corrupted software can induce the hardware to create an outgoing HTLC whose timelock is deeply in the past, then refuse to take the timelock branch of the outgoing HTLC while letting the timelock branch of the incoming HTLC be claimed by the other nodes.\n\n\nSee above about watchtowers, and trusted sources of time/blockchain state.\n\n>\n>\n> Thus, forwarding is still trusted.\n>\n> [...]\n> Reducing Storage Size\n> =====================\n>\n> The hardware can, instead of storing multiple channel slots and payment slots in its own persistent memory, can instead just store a single *commitment* to the current state it knows to be valid.\n\n\nAgreed, but see the need to have a reliable backup above.\n\n>\n>\n>\n> Regards,\n> ZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-16T01:36:42",
                "message_text_only": "Good morning ZmnSCPxj,\n\n>\n> > It need not store the whole state: for example, it could store just a commitment to the current state (and have the software store the entire state).\n> > In fact, it is best for the hardware to store the signature for the commitment transaction:\n>\n> I would say that's not enough, if we assume that the attacker can\n> destroy the underlying data, and destroy all backups. If the attacker\n> can do that, the node is at the mercy of channel partners, since they\n> will be able to publish old state without the possibility of\n> retaliation. Thus there needs to be a secure form of storage where at\n> least one backup must be recoverable at all times within the penalty\n> time window.\n\nRight, that does seem correct.\n\n>\n> > [...]\n> > Tr\\*sted Revocation of Old Remote State\n> >\n> > ==============================================\n> >\n> > Unfortunately, the hardware has to tr\\*st the software to check that the other node is not cheating.\n> > As the hardware itself is not capable of accessing the blockchain or mempool, it cannot do this checking directly.\n> > Thus, revocation of old remote state is not ensurable by the hardware.\n>\n> I am more optimistic about this. Publishing of penalty transactions\n> can be delegated to a quorum of watchtowers, some possibly run by\n> other entities. The node software can prove to the hardware that the\n> watchtowers have been informed of new state by providing a receipt\n> signed by the watchtowers. Thus it's possible to reduce trust in the\n> node software.\n\nI had not thought of having the watchtower(s) sign a receipt of the channel state being backed up there, thank you.\n\n>\n> > As revocation can only be done by the software anyway, the revocation secrets for the remote commitment transactions can be stored by the software only.\n> > The hardware need never learn the revocation secrets as it can do nothing with them anyway.\n>\n> I would at least back up the secrets in the secure storage attached to\n> the hardware store, so that the node can be recreated if the node\n> software has been catastrophically compromised.\n\nWell, if the hardware itself has only a tiny secure storage (e.g. the example of only being able to store a commitment to the entire state) there would be no space to put those in as well, even with shachains.\nFurther, all previous HTLC hashes and timelocks need to be stored as well, since old commitment transactions will only have P2WSH output to represent those HTLC hashes and timelocks, and the actual HTLC hashes and timelocks need to be shown as well in order to revoke the old HTLCs.\nIt seems to me that, since the amount of storage needed would be linear on the number of HTLCs that ever appeared on the channel, a hardware with storage limits would not be appropriate to store this state and your append-only log machine might do better for that purpose.\n\n>\n> > Opening a Channel\n> >\n> > ==================\n> >\n> > [...]\n> > If there is a difference, that implies that this node is what pays the fee, and the hardware should probably double-confirm with the user using its UI whether the paid fees are acceptab;e.\n>\n> If the fee is under a preset threshold, it can be auto-approved.\n\nIt would have to be a sophisticated threshold: a corrupted software would split up the node funds into tiny 546-satoshi channels, paying a funding tx fee each time.\nI suppose when considering autopilot it would have to be auto-approved though.\n\n>\n> > Tr\\*sted Forwarding\n> >\n> > ====================\n> >\n> > Forwarding should be automated and not require a confirmation from the user on the hardware unit UI.\n> > Unfortunately, the hardware has to trust the software to actually perform forwarding correctly.\n>\n> Let's look at this carefully, I feel it should be possible to prove\n> correctness of forwarding to the hardware.\n\nI believe not.\nConsider this sequence of events:\n\n* The hardware approves an outgoing HTLC on one channel based on the existence of an incoming HTLC on another channel.\n* Both channels are dropped unilaterally onchain, with their respective latest states, before the outgoing HTLC can be claimed offchain.\n* The software lets the outgoing HTLC to be claimed by the other node using the hashlock branch.\n* The software lets time pass and lets the incoming HTLC be claimed by the other node using the timelock branch.\n\nAs the hardware is incapable of actually pushing transactions onchain, it cannot do anything about the incoming HTLC getting lapsed (though since it has its own UI, if it had read access to the UTXO set somehow, it could give a warning to the user using its UI and maybe hope the user notices?).\nIndeed it is hard to give the hardware even read access to the blockchain in order to even *know* about the outgoing HTLC getting claimed by hashlock, without serious increases in hackability, storage, and sophistication of the hardware.\nOnce you start having a hardware *that* sophisticated, it becomes more and more like a complete Lightning node, and if you could implement that in a *secure* unit, you would not need a separate software to drive it, the software would effectively *be* inside the trusted hardware unit (when the entire point of this exercise is to have a separate software we have reduced trust in).\n\n>\n> > However, the hardware has to keep track that an incoming HTLC only has at most one outgoing HTLC,.\n> > It cannot identify using the hash, incidentally: it is theoretically possible for a route to loop through a node twice, e.g. A -> B -> C -> D -> E -> C -> F, where C appears twice.\n>\n> I think it's enough to require that each incoming HTLC can be\n> associated with a single outgoing HTLC. The hardware would have to\n> maintain state about which HTLCs have been \"used up\" in this way.\n>\n> > Further, if a payment attempt fails, then the ultimate payer might still try to route through this node, giving a different postfix past this node, so this node may forward the same hash twice on two or more different payment attempts.\n>\n> hmm... that doesn't sound safe, because then two different nodes would\n> be able to claim the funds from us, and we can only propagate back to\n> a single input, so we lose funds. If the Lightning protocol allows\n> this, then it sounds like a design issue. Seems like the failed HTLC\n> should be invalidated first. The invalidation can be proven to the\n> hardware (a new commitment tx is signed, removing the HTLC, or the\n> outgoing channel is closed).\n\nWell, the incoming HTLC would have to be deleted as well before the payer re-attempts (otherwise the payer could give out multiple HTLCs that are simultaneously claimable).\nThe \"flag\" we associate with each incoming HTLC would be deleted when the incoming HTLC is deleted as well, and separate incoming HTLCs would have to be used to authorize separate outgoing HTLCs.\n\nIn any case the point of this digression above was that we cannot key on the *hash* of the HTLC, we have to have some identifier of HTLC (shared between software and hardware) that is *not* the *hash*, but some other identifier.\n\n>\n> > [...]\n> > Regardless, even if we somehow, the enforcement of HTLCs is still controlled by the software:\n> >\n> > -   The hardware has no access to the blockchain, thus it cannot know if the incoming HTLC is in fact something in the deep past already.\n> >     A corrupted software can induce the hardware to create an outgoing HTLC whose timelock is deeply in the past, then refuse to take the timelock branch of the outgoing HTLC while letting the timelock branch of the incoming HTLC be claimed by the other nodes.\n> >\n>\n> See above about watchtowers, and trusted sources of time/blockchain state.\n\nWatchtowers, at least as currently designed, treat each channel in isolation.\nForwarding is about events on two channels.\nSo you would need a more sophisticated watchtower design as well.\n\n>\n> > Thus, forwarding is still trusted.\n> >\n> > [...]\n> > Reducing Storage Size\n> >\n> > ============================\n> >\n> > The hardware can, instead of storing multiple channel slots and payment slots in its own persistent memory, can instead just store a single commitment to the current state it knows to be valid.\n>\n> Agreed, but see the need to have a reliable backup above.\n\n\nI imagine that secure of a memory would be expensive to implement and thus limited, thus if you implement it all in the hardware, you would impose limits on the number of channels and updates and so on.\n\nThe idea of having a secure append-only log could also be used for the off-hardware state storage as well anyway, if you are trusting it enough to be able to recover the node state.\nThe append-only log machine can even just accept new hardware states when it sees the signature from the hardware attesting the change in root as well, so that it forms a secure channel between the hardware and the append-only log machine.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-01-16T22:30:01",
                "message_text_only": "Hey Zeeman,\n\ntl;dr A LN node paired with an external signer can be distrusted and LN\nfunds be safe in any case\nif signer is connected to a N-set of watchtowers and at least one of them\nis non-compromised.\n\nThanks for this interesting post, I was thinking about LN hardware wallets\nsupport for a while too,\nI do think LN model has its own pitfalls compare to base layer but that\ndoesn't mean we can't\nsubstantially improve current one\nmonolithic-LN-node-with-unsafe-key-material-in-RAM deployment and\nstill have automatic processing of HTLCs.\n\nLN security model differs compare to base layer by requiring onchain\nmonitoring and\nreaction to keep your funds safe. That's quite the contrary on how HW have\nbeen designed\nuntil now where UTXO state access isn't assumed to be secure. That's said\nthe cool\nthing is you may have multiple monitoring bckends/watchtowers running on\ndifferent\ninfrastructures, if one of them stay non-compromised and enforce protocol\nrules you\nshould be fine [0].\n\nSo let's go through whole LN operations with a deployment such that Alice\nthe LN processing\nnode, Bob and Caroll the channel peers, Sally the external signer, Will a\nset of N watchtowers.\nWill is part of the same entity than Alice, run on different infra, is\nseeded with\nsame secret (to derive same local keys), and have authenticated\ncommunication with Sally.\n\nAttacks scenario are 1) node compromised, where an attacker would leverage\nsecret keys\nto sign closing/justice/sweep transaftions to a attacker-controlled\naddress. 2) node\ncompromised + peer collusion, where an attacker broadcast revoked\ncommitment/non-revoked\ncommitment with a HTLC to timeout/obtain a commitment with outgoing HTLC\nbut not incoming one.\n>From the perspective of signer, you can't dissociate peer collusion so it\nshould always\nbe assumed and the straighter policy enforced.\n\nAlice inits Sally with 2\nfunding_transactions+remote_sigs+per_commitment_point+balances states,\nfor both link AB and AC. Balance states have to be user-input validated (or\ncan be deduced if Sally\nis also an onchain wallet and fundings spent from controlled-keys modulo\npush_msat max being hardcoded).\n\nSally send to Will these requests through Alice. When Will see fundings\nconfirmed it replies\nthe computed channel_id to Sally and stores sigs, who then can safely\nconsiders these channels\nactivated.\n\nBob initiates a payment to Caroll through link AB+AC, Alice receives the\nmessages and ask Sally to\nsign Bob's remote, as it's a balance increases, no proof is asked. Sally\nsend to Will vector\nof HTLCs (hash+locktime)+previous_state revocation\nsecret+per_commitment_point. Will can return\nSally an error if locktime are in the past of channel has been closed so\nSally won't accept latter\noutgoing HTLC paired with such incoming channel. If a revoked commitment is\nbroadcast on AB and Alice\nis compromised, Will generate justice transactions and take the funds back.\n\nAlice builds outgoing payment and asks Sally to sign outgoing commitment\ndecreasing local\nbalance with incoming HTLC as a proof. Sally can send Will the new outgoing\ncommitment\ntied with HTLC proof, if HTLC proof can't be tied to an incoming valid\nchan, an error should\nbe returned to Sally and signature aborted.\n\nAt HTLC fulfillement by Caroll, Alice should pass the preimage to Caroll\nwho pass it to Will.\nIf Alice is compromised, Will be able to claim incoming HTLC. Will should\nalso be able to parse\nonchain HTLCs and extract preimage to claim backward in case of Alice\nwithholding the preimage.\n\nAt any block reception, Will should be able to broadcast commitment and\ntimeout HTLCs in\ncase of Alice being unreliable/compromised.\n\nTo avoid burning-to-fees attack, if Alice asks Sally to sign a\ndecrasing-balance commitment\nwithout a HTLC proof, which is credible for update_fee, fees can be bounded\nto some value.\nBounds should scope dust HTLCs too.\n\nAt channel closing, Will can observe it, if Sally ask to valid any HTLC\nproof, return an error.\n\nExternal signer should store commitment numbers and balances for each\nchannel and do key derivation\nlocally (at least for local, for remote you can't trust provided\nper_commitment_point anyway).\n\n\nVoila, I think this describes a master-slaves scheme, where external signer\nis coupled with\nwatchtowers to serve as UTXO oracles, while mitigating node compromised. It\nwould be\nfairly complex to design and implement it right but on the long-term it's\nworth it if you\nassume a world of wumbo channels and mutiple-btcs HTLCs [1]\n\nDevrandom work is a pretty headstart towards such safe API and we should\nkeep experimenting\nwith this to patch unthought corner-cases. The futur alternative is every\nHW vendor designing\nits LN-implementation specific support, and a lot of them being flawed by\nmissing LN security\nmodel oddities. A lack of such standard programming interface on base layer\nHW and the number\nof vuln due to mishandling change or derivation is something to meditate on.\n\n\n> It would have to be a sophisticated threshold: a corrupted software would\nsplit up the node funds into tiny 546-satoshi channels, paying a funding tx\nfee each time.\n> I suppose when considering autopilot it would have to be auto-approved\nthough.\n\nA signer can implement further checks to asses channel opening utility.\nLike a channels provider signer\nwould verify than no more than X channels with Y liquidity are opened on\ntime period Z. And you\nmay ask for a user invoice signed by a different component than your LN\nnode.\n\n> > It cannot identify using the hash, incidentally: it is theoretically\npossible for a route to loop through a node twice, e.g. A -> B -> C -> D ->\nE -> C -> F, where C appears twice.\n\nIf you store latest HTLC outputs on the watchtower, at incoming link\nupdate, if there is\ndiscrepancy between stored set and submitted by node set, something is\nwrong. Further, hash replay\nisn't safe right now : https://eprint.iacr.org/2019/1149.pdf\n\n> So you would need a more sophisticated watchtower design as well.\n\nIn most watchtowers discussion, it's only assumed to do justice delegation.\nBut if you're a routing node, that's not enough to be safe, you should also\ntimeout HTLC\nand do outgoing-to-incoming preimage passing in case of regular node\nfailure. Luckily,\nwatchtowers aren't specified yet...\n\n> I imagine that secure of a memory would be expensive to implement and\nthus limited, thus if you implement it all in the hardware, you would\nimpose limits on the number of channels and updates and so.\n\nAll this discussion may be irrelevant anyway, I've heard about 10-100MB HSM\nwith hardened Linux, so just\nrun a minimal LN node on it but that would create a dependency on HSM\nvendors and there is only a few\nof them..\n\nAntoine\n\n[0] Introducing watchtowers opens some problems like state must be\nsynchronized to avoid\nspurious broadcast of revoked commitments and trusted external signer to\navoid one of them\nspending to a malicious addresses. Though they provide also a security\nboost against p2p sybil\nattacks if each run its own full-node.\n\n[1] This kind of deployment may only serve important processing LN nodes\nfirst, but designing\nspecialized hardware/interfaces for them will also benefit more thrifty\nnodes operators by\ncommoditization on the long term\n\nLe mer. 15 janv. 2020 \u00e0 20:36, ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n> Good morning ZmnSCPxj,\n>\n> >\n> > > It need not store the whole state: for example, it could store just a\n> commitment to the current state (and have the software store the entire\n> state).\n> > > In fact, it is best for the hardware to store the signature for the\n> commitment transaction:\n> >\n> > I would say that's not enough, if we assume that the attacker can\n> > destroy the underlying data, and destroy all backups. If the attacker\n> > can do that, the node is at the mercy of channel partners, since they\n> > will be able to publish old state without the possibility of\n> > retaliation. Thus there needs to be a secure form of storage where at\n> > least one backup must be recoverable at all times within the penalty\n> > time window.\n>\n> Right, that does seem correct.\n>\n> >\n> > > [...]\n> > > Tr\\*sted Revocation of Old Remote State\n> > >\n> > > ==============================================\n> > >\n> > > Unfortunately, the hardware has to tr\\*st the software to check that\n> the other node is not cheating.\n> > > As the hardware itself is not capable of accessing the blockchain or\n> mempool, it cannot do this checking directly.\n> > > Thus, revocation of old remote state is not ensurable by the hardware.\n> >\n> > I am more optimistic about this. Publishing of penalty transactions\n> > can be delegated to a quorum of watchtowers, some possibly run by\n> > other entities. The node software can prove to the hardware that the\n> > watchtowers have been informed of new state by providing a receipt\n> > signed by the watchtowers. Thus it's possible to reduce trust in the\n> > node software.\n>\n> I had not thought of having the watchtower(s) sign a receipt of the\n> channel state being backed up there, thank you.\n>\n> >\n> > > As revocation can only be done by the software anyway, the revocation\n> secrets for the remote commitment transactions can be stored by the\n> software only.\n> > > The hardware need never learn the revocation secrets as it can do\n> nothing with them anyway.\n> >\n> > I would at least back up the secrets in the secure storage attached to\n> > the hardware store, so that the node can be recreated if the node\n> > software has been catastrophically compromised.\n>\n> Well, if the hardware itself has only a tiny secure storage (e.g. the\n> example of only being able to store a commitment to the entire state) there\n> would be no space to put those in as well, even with shachains.\n> Further, all previous HTLC hashes and timelocks need to be stored as well,\n> since old commitment transactions will only have P2WSH output to represent\n> those HTLC hashes and timelocks, and the actual HTLC hashes and timelocks\n> need to be shown as well in order to revoke the old HTLCs.\n> It seems to me that, since the amount of storage needed would be linear on\n> the number of HTLCs that ever appeared on the channel, a hardware with\n> storage limits would not be appropriate to store this state and your\n> append-only log machine might do better for that purpose.\n>\n> >\n> > > Opening a Channel\n> > >\n> > > ==================\n> > >\n> > > [...]\n> > > If there is a difference, that implies that this node is what pays the\n> fee, and the hardware should probably double-confirm with the user using\n> its UI whether the paid fees are acceptab;e.\n> >\n> > If the fee is under a preset threshold, it can be auto-approved.\n>\n> It would have to be a sophisticated threshold: a corrupted software would\n> split up the node funds into tiny 546-satoshi channels, paying a funding tx\n> fee each time.\n> I suppose when considering autopilot it would have to be auto-approved\n> though.\n>\n> >\n> > > Tr\\*sted Forwarding\n> > >\n> > > ====================\n> > >\n> > > Forwarding should be automated and not require a confirmation from the\n> user on the hardware unit UI.\n> > > Unfortunately, the hardware has to trust the software to actually\n> perform forwarding correctly.\n> >\n> > Let's look at this carefully, I feel it should be possible to prove\n> > correctness of forwarding to the hardware.\n>\n> I believe not.\n> Consider this sequence of events:\n>\n> * The hardware approves an outgoing HTLC on one channel based on the\n> existence of an incoming HTLC on another channel.\n> * Both channels are dropped unilaterally onchain, with their respective\n> latest states, before the outgoing HTLC can be claimed offchain.\n> * The software lets the outgoing HTLC to be claimed by the other node\n> using the hashlock branch.\n> * The software lets time pass and lets the incoming HTLC be claimed by the\n> other node using the timelock branch.\n>\n> As the hardware is incapable of actually pushing transactions onchain, it\n> cannot do anything about the incoming HTLC getting lapsed (though since it\n> has its own UI, if it had read access to the UTXO set somehow, it could\n> give a warning to the user using its UI and maybe hope the user notices?).\n> Indeed it is hard to give the hardware even read access to the blockchain\n> in order to even *know* about the outgoing HTLC getting claimed by\n> hashlock, without serious increases in hackability, storage, and\n> sophistication of the hardware.\n> Once you start having a hardware *that* sophisticated, it becomes more and\n> more like a complete Lightning node, and if you could implement that in a\n> *secure* unit, you would not need a separate software to drive it, the\n> software would effectively *be* inside the trusted hardware unit (when the\n> entire point of this exercise is to have a separate software we have\n> reduced trust in).\n>\n> >\n> > > However, the hardware has to keep track that an incoming HTLC only has\n> at most one outgoing HTLC,.\n> > > It cannot identify using the hash, incidentally: it is theoretically\n> possible for a route to loop through a node twice, e.g. A -> B -> C -> D ->\n> E -> C -> F, where C appears twice.\n> >\n> > I think it's enough to require that each incoming HTLC can be\n> > associated with a single outgoing HTLC. The hardware would have to\n> > maintain state about which HTLCs have been \"used up\" in this way.\n> >\n> > > Further, if a payment attempt fails, then the ultimate payer might\n> still try to route through this node, giving a different postfix past this\n> node, so this node may forward the same hash twice on two or more different\n> payment attempts.\n> >\n> > hmm... that doesn't sound safe, because then two different nodes would\n> > be able to claim the funds from us, and we can only propagate back to\n> > a single input, so we lose funds. If the Lightning protocol allows\n> > this, then it sounds like a design issue. Seems like the failed HTLC\n> > should be invalidated first. The invalidation can be proven to the\n> > hardware (a new commitment tx is signed, removing the HTLC, or the\n> > outgoing channel is closed).\n>\n> Well, the incoming HTLC would have to be deleted as well before the payer\n> re-attempts (otherwise the payer could give out multiple HTLCs that are\n> simultaneously claimable).\n> The \"flag\" we associate with each incoming HTLC would be deleted when the\n> incoming HTLC is deleted as well, and separate incoming HTLCs would have to\n> be used to authorize separate outgoing HTLCs.\n>\n> In any case the point of this digression above was that we cannot key on\n> the *hash* of the HTLC, we have to have some identifier of HTLC (shared\n> between software and hardware) that is *not* the *hash*, but some other\n> identifier.\n>\n> >\n> > > [...]\n> > > Regardless, even if we somehow, the enforcement of HTLCs is still\n> controlled by the software:\n> > >\n> > > -   The hardware has no access to the blockchain, thus it cannot know\n> if the incoming HTLC is in fact something in the deep past already.\n> > >     A corrupted software can induce the hardware to create an outgoing\n> HTLC whose timelock is deeply in the past, then refuse to take the timelock\n> branch of the outgoing HTLC while letting the timelock branch of the\n> incoming HTLC be claimed by the other nodes.\n> > >\n> >\n> > See above about watchtowers, and trusted sources of time/blockchain\n> state.\n>\n> Watchtowers, at least as currently designed, treat each channel in\n> isolation.\n> Forwarding is about events on two channels.\n> So you would need a more sophisticated watchtower design as well.\n>\n> >\n> > > Thus, forwarding is still trusted.\n> > >\n> > > [...]\n> > > Reducing Storage Size\n> > >\n> > > ============================\n> > >\n> > > The hardware can, instead of storing multiple channel slots and\n> payment slots in its own persistent memory, can instead just store a single\n> commitment to the current state it knows to be valid.\n> >\n> > Agreed, but see the need to have a reliable backup above.\n>\n>\n> I imagine that secure of a memory would be expensive to implement and thus\n> limited, thus if you implement it all in the hardware, you would impose\n> limits on the number of channels and updates and so on.\n>\n> The idea of having a secure append-only log could also be used for the\n> off-hardware state storage as well anyway, if you are trusting it enough to\n> be able to recover the node state.\n> The append-only log machine can even just accept new hardware states when\n> it sees the signature from the hardware attesting the change in root as\n> well, so that it forms a secure channel between the hardware and the\n> append-only log machine.\n>\n> Regards,\n> ZmnSCPxj\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200116/c76f14bb/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Speculations on hardware wallet support for Lightning",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Devrandom",
                "Antoine Riard",
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 56869
        }
    },
    {
        "title": "[Lightning-dev] Data Lightning Atomic Swap (DLAS-down, DLAS-up)",
        "thread_messages": [
            {
                "author": "Subhra Mazumdar",
                "date": "2020-01-16T07:14:45",
                "message_text_only": "Hello Takaya,\n        I really liked the idea of data atomic swap mentioned over here. So\nas of now if we consider transfer of a file (may of few KB) then you split\nit into several blocks and use atomic multi path payment whole using the\nblocks for embedding with the preimage inorder to obtain payment. But it\nmight be the case you may not have sufficient number of path to transfer\nall the blocks at one go because of preimage size limitation of 256 bit (I\ndidn't get the point that there is no limitation on data size, can anyone\nexplain that ?). So may be you need several iteration and I presume thats\nwhat lightning network will pitch in where we have several such\nmicrotransactions going on. What happens if it fails in an iteration ? So\nthe recipient of the file remains happy with the partial content ? Or will\nthe payment be revoked (not sure how) if recipient doesn't get the full\ncontent ?\n\nOn Mon, Nov 11, 2019 at 6:29 AM Takaya Imai <takaya.imai at frontier-ptnrs.com>\nwrote:\n\n> Hi all,\n>\n> I propose Data Lightning Atomic Swap.\n> Anyone already have the same idea?\n>\n>\n> [Abstract]\n> This proposal is a way to swap data and lightning payment atomically.\n> It has two patterns, one is for a payer to swap data-download with\n> lightning payment to a payee (DLAS-down), the other is for a payer to swap\n> data-upload with lightning payment to a payee (DLAS-up).\n>\n> The data is embedded to preimage so sending and receiving the data need\n> lightning payment at the same time.\n>\n> ---------\n>\n> [Motivation]\n> Atomic Swaps among crypto currencies has various ways to implement\n> (on-chain to on-chain[1], on-chain to of-chain(Submarine Swap[2])). And\n> Atomic Swaps between data and crypto currencies are also proposed as a part\n> of TumbleBit mechanism[3], Storm mechanism[4] and so on.\n>\n> Recently Joost Jager proposed Instant messages with lightning onion\n> routing, whatsat[5], which use recent sphinx payload change[6]. This is\n> very awesome but not atomic with lightning payment.\n>\n> Atomic lightning mechanism for data is useful in use cases below.\n>\n> ---------\n>\n> [Pros & Cons]\n>\n> * DLAS-down\n> ** Pros\n> *** Atomic data download exchange with lightning payment\n> ** Cons\n> *** It needs better mechanism to expand data size\n>\n> * DLAS-up\n> ** Pros\n> *** Atomic data upload exchange with lightning payment\n> ** Cons\n> *** OG AMP[7] is needed to implement\n>\n> ---------\n>\n> [What I describe]\n> * A way to swap data with lightning payment atomically.\n>\n> ---------\n>\n> [What I do not describe]\n> * A way to detect that data is correct or not, namely zero knowledge proof\n> process.\n>\n> For example, probabilistic checkable proof like TumbleBit[3] proposed.\n> Just message as data is no problem because no need to check the message is\n> correct or not.\n>\n> * A way in case that different preimages are used in a payment route like\n> Multi-hop locks.\n>\n> ---------\n>\n> [Specification]\n>\n> Lightning Network(LN) has a mechanism about preimage like a brief image\n> below.\n>\n> Payer                             Mediators\n>  Payee\n>\n> =================================================================================\n>\n> Preimage\n> Preimage Hash  <--------------------- invoice ------------------------\n>  Preimage Hash\n> Preimage Hash  ---------------->   Preimage Hash -------------------->\n>  Preimage Hash\n> Preimage       <\u2014-------------\u2014-   Preimage      <--------------------\n>  Preimage\n>\n> As you know, preimage Payer gets can be a proof of payment because Payer\n> can not get it if the payment is executed correctly.\n>\n>\n>\n> 1, Data download <->  lightning (DLAS-down)\n>\n>\n> Payer sends lightning payment and receives data from Payee atomically.\n>\n>\n> Payer                             Mediators\n>  Payee\n>\n> =================================================================================\n> Payer Channel Pubkey <----------------------------------------------->\n> Payee Channel Pubkey\n>\n>\n>  data(256bit, padded)\n>\n>  enc_key = (Payee Channel Secret Key * Payer Channel Pubkey).x  (256bit)\n> enc_key = (Payer Channel Secret Key * Payee Channel Pubkey).x  (256bit)\n>\n>  enc_data = data XOR enc_key\n> sha256(enc_data) <--------------------- invoice ----------------------\n> sha256(enc_data)\n> sha256(enc_data) ----------------> sha256(enc_data) ----------------->\n> sha256(enc_data)\n> enc_data         <---------------- enc_data <-------------------------\n> enc_data\n> data = enc_data XOR enc_key\n>\n>\n> * The size of data is restricted to 256 bits. Identically, it should be\n> extended to larger data and the data should be transferred in several\n> payment paths like DLAS-up.\n> * Channel Pubkey is only one for one channel and the data can be decrypted\n> if enc_key is leaked. So enc_key should be generated newly every time by a\n> way like hash chain but the protocol image above is just example for\n> simplicity.\n> * .x means X axis value of points on Elliptic Curve.\n> * If data is less than 256 bits, then 0x00 is padded (I am not sure which\n> of big endian and little endian is better).\n>\n>\n>\n> 2, Data upload <->  lightning (DLAS-down)\n>\n> Payer sends data and lightning payment from Payee atomically.\n> This is like OG AMP(Atomic Multi-path Payment)[7] system.\n>\n> Payer                             Mediators\n>  Payee\n>\n> =================================================================================\n> data(512bit, padded)\n>\n> share1(256bit)\n> share2(256bit)\n>\n> base_s = share1 XOR share2\n> data1(256bit) ||  data2(256bit) = data(512bit)\n> XOR_d1 = data1 XOR base_s\n> XOR_d2 = data2 XOR base_s\n> PreImg1 = sha256(base_s || data || 1)\n> PreImg2 = sha256(base_s || data || 2)\n>\n> sha256(PreImg1), XOR_d1, share1 -> sha256(PreImg1), XOR_d1, share1  ->\n> sha256(PreImg1), XOR_d1, share1\n> sha256(PreImg2), XOR_d2, share2 -> sha256(PreImg2), XOR_d2, share2  ->\n> sha256(PreImg2), XOR_d2, share1\n>\n>\n>  base s = share1 XOR share2\n>\n>  data = (XOR_d1 XOR base_s) || (XOR_d2 XOR base_s)\n>\n>  PreImg1 = sha256(base_s || data || 1)\n>\n>  PreImg2 = sha256(base_s || data || 2)\n>\n> PreImg1    <-------------------    PreImg1    <---------------------\n> PreImg1\n> PreImg2    <-------------------    PreImg2    <---------------------\n> PreImg2\n>\n>\n> * This protocol example has 512 bits data and they are transferred in two\n> paths. However, it can transfer larger data in several payment paths like\n> [5].\n> * || means string concatenation.\n> * If data is less than 512 bits, then 0x00 is padded(I am not sure which\n> of big endian and little endian is better).\n>\n>\n> ---------\n>\n>\n> [Use Cases]\n>\n> 1, Lightning Network ecosystem\n>\n> * Hosting Incentives like Acai Protocol\n> ** Watchtower Hosting incentive, Backup Hosting incentive\n> *** Commitment tx data sending to Data Host(DLAS-up)\n> **** Commitment tx data is embedded in preimage so that Payer can not send\n> the data without remittance\n> *** Channel backup data receiving from Data Host(DLAS-down)\n> **** Channel backup data is embedded in preimage so that Payer can not\n> receive the data without remittance\n>\n> 2, Crypto currency Problems\n>\n> * Distributed secret key sharing (just come up with an idea though)\n> ** As a key backup, one of secret key shares is distributed with\n> encryption(DLAS-up) to some nodes, which nodes receive lightning payment as\n> key managing fee. And the nodes send a proof for managing the key as\n> response of bloom filter periodically, and exchange encrypted secret key\n> share with lightning payment to asset holder(DLAS-down).\n> ** For example 2 out of 3 multi signature key sharing, asset holder puts\n> the first key, the custodial has the second key, and the third key at the\n> lightning distribution nodes. Asset holders usually spend assets using\n> their key and the key on Distributed Nodes.\n>\n>\n> 3, Problems so far\n>\n> * Prevention email spam and DDoS attack with large data\n> ** Payer can not send email or data without remittance(DLAS-up)\n> ** Payer can not receive reply-email without remittance(DLAS-down)\n>\n> * Incentive of receiving advertisements on browser or desktop/mobile app\n> ** Payer can not send advertisements without remittance(DLAS-up)\n>\n> * Bounty for code bug fixes based on cryptographic proofs or secret\n> computations\n> ** (DLAS-down)\n>\n>\n>\n> [References]\n>\n> [1] https://bitcointalk.org/index.php?topic=321228\n> [2] https://twitter.com/roasbeef/status/964608261830750208\n> [3] https://eprint.iacr.org/2016/575\n> [4] https://github.com/storm-org/storm-spec\n> [5] https://twitter.com/joostjgr/status/1190714028626251779\n> [6] https://github.com/lightningnetwork/lightning-rfc/pull/619\n> [7]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-February/000993.html\n>\n>\n> document on github:\n> https://github.com/takaya-imai/data_lightning_atomic_swap\n>\n> Best regards,\n> Takaya Imai\n> Email: takaya.imai at frontier-ptnrs.com, takaya.imai at unitedbitcoiners.com\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200116/6ea563b8/attachment-0001.html>"
            },
            {
                "author": "Takaya Imai",
                "date": "2020-01-20T06:26:49",
                "message_text_only": "Hi ZmnSCPxj,\n\nSorry for late reply.\nThe no restriction version is very good.\n\nThanks,\nTakaya Imai\n\n2019\u5e7411\u670812\u65e5(\u706b) 9:13 ZmnSCPxj <ZmnSCPxj at protonmail.com>:\n\n> Good morning Imai-san,\n>\n> I believe for the download case this is superior:\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-June/002035.html\n> This has no restriction on the size of the data.\n>\n> For the upload case, it seems for either OG AMP or with payment points +\n> scalars and payment decorrelation, the summed blinding factor (i.e. the\n> data sent in response to ACK in Stuckless) can be used to send data to the\n> payee, by using an encryption key as well.\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200120/b60362ff/attachment.html>"
            },
            {
                "author": "Takaya Imai",
                "date": "2020-01-20T06:33:28",
                "message_text_only": "Hi Subhra,\n\nthanks for your question.\n\n> So as of now if we consider transfer of a file (may of few KB) then you\nsplit it into several blocks and use atomic multi path payment whole using\nthe blocks for embedding with the preimage inorder to obtain payment.\n> But it might be the case you may not have sufficient number of path to\ntransfer all the blocks at one go because of preimage size limitation of\n256 bit (I didn't get the point that there is no limitation on data size,\ncan anyone explain that ?).\n\nYes. It needs many blocks and paths if large file.\nBut it has no problem because it can use the same path several times.\n\nOf course it needs much money to transfer large file. But this is good\npoint in order to retain lightning network stable.\n\nFor DOS attack, OG AMP has the same problem. It might that recipient needs\na limit how many split blocks the recipient accept\n\n> So may be you need several iteration and I presume thats what lightning\nnetwork will pitch in where we have several such microtransactions going on.\n> What happens if it fails in an iteration ? So the recipient of the file\nremains happy with the partial content ? Or will the payment be revoked\n(not sure how) if recipient doesn't get the full content ?\n\nThis is about the DLAS-up protocol.\nThe protocol uses OG AMP so the payments and data transfers are revoked in\ncase that it fails.\n\nThanks,\nTakaya Imai\n\n2020\u5e741\u670816\u65e5(\u6728) 16:14 Subhra Mazumdar <subhra.mazumdar1993 at gmail.com>:\n\n> Hello Takaya,\n>         I really liked the idea of data atomic swap mentioned over here.\n> So as of now if we consider transfer of a file (may of few KB) then you\n> split it into several blocks and use atomic multi path payment whole using\n> the blocks for embedding with the preimage inorder to obtain payment. But\n> it might be the case you may not have sufficient number of path to transfer\n> all the blocks at one go because of preimage size limitation of 256 bit (I\n> didn't get the point that there is no limitation on data size, can anyone\n> explain that ?). So may be you need several iteration and I presume thats\n> what lightning network will pitch in where we have several such\n> microtransactions going on. What happens if it fails in an iteration ? So\n> the recipient of the file remains happy with the partial content ? Or will\n> the payment be revoked (not sure how) if recipient doesn't get the full\n> content ?\n>\n> On Mon, Nov 11, 2019 at 6:29 AM Takaya Imai <\n> takaya.imai at frontier-ptnrs.com> wrote:\n>\n>> Hi all,\n>>\n>> I propose Data Lightning Atomic Swap.\n>> Anyone already have the same idea?\n>>\n>>\n>> [Abstract]\n>> This proposal is a way to swap data and lightning payment atomically.\n>> It has two patterns, one is for a payer to swap data-download with\n>> lightning payment to a payee (DLAS-down), the other is for a payer to swap\n>> data-upload with lightning payment to a payee (DLAS-up).\n>>\n>> The data is embedded to preimage so sending and receiving the data need\n>> lightning payment at the same time.\n>>\n>> ---------\n>>\n>> [Motivation]\n>> Atomic Swaps among crypto currencies has various ways to implement\n>> (on-chain to on-chain[1], on-chain to of-chain(Submarine Swap[2])). And\n>> Atomic Swaps between data and crypto currencies are also proposed as a part\n>> of TumbleBit mechanism[3], Storm mechanism[4] and so on.\n>>\n>> Recently Joost Jager proposed Instant messages with lightning onion\n>> routing, whatsat[5], which use recent sphinx payload change[6]. This is\n>> very awesome but not atomic with lightning payment.\n>>\n>> Atomic lightning mechanism for data is useful in use cases below.\n>>\n>> ---------\n>>\n>> [Pros & Cons]\n>>\n>> * DLAS-down\n>> ** Pros\n>> *** Atomic data download exchange with lightning payment\n>> ** Cons\n>> *** It needs better mechanism to expand data size\n>>\n>> * DLAS-up\n>> ** Pros\n>> *** Atomic data upload exchange with lightning payment\n>> ** Cons\n>> *** OG AMP[7] is needed to implement\n>>\n>> ---------\n>>\n>> [What I describe]\n>> * A way to swap data with lightning payment atomically.\n>>\n>> ---------\n>>\n>> [What I do not describe]\n>> * A way to detect that data is correct or not, namely zero knowledge\n>> proof process.\n>>\n>> For example, probabilistic checkable proof like TumbleBit[3] proposed.\n>> Just message as data is no problem because no need to check the message\n>> is correct or not.\n>>\n>> * A way in case that different preimages are used in a payment route like\n>> Multi-hop locks.\n>>\n>> ---------\n>>\n>> [Specification]\n>>\n>> Lightning Network(LN) has a mechanism about preimage like a brief image\n>> below.\n>>\n>> Payer                             Mediators\n>>  Payee\n>>\n>> =================================================================================\n>>\n>> Preimage\n>> Preimage Hash  <--------------------- invoice ------------------------\n>>  Preimage Hash\n>> Preimage Hash  ---------------->   Preimage Hash -------------------->\n>>  Preimage Hash\n>> Preimage       <\u2014-------------\u2014-   Preimage      <--------------------\n>>  Preimage\n>>\n>> As you know, preimage Payer gets can be a proof of payment because Payer\n>> can not get it if the payment is executed correctly.\n>>\n>>\n>>\n>> 1, Data download <->  lightning (DLAS-down)\n>>\n>>\n>> Payer sends lightning payment and receives data from Payee atomically.\n>>\n>>\n>> Payer                             Mediators\n>>  Payee\n>>\n>> =================================================================================\n>> Payer Channel Pubkey <----------------------------------------------->\n>> Payee Channel Pubkey\n>>\n>>\n>>  data(256bit, padded)\n>>\n>>  enc_key = (Payee Channel Secret Key * Payer Channel Pubkey).x  (256bit)\n>> enc_key = (Payer Channel Secret Key * Payee Channel Pubkey).x  (256bit)\n>>\n>>  enc_data = data XOR enc_key\n>> sha256(enc_data) <--------------------- invoice ----------------------\n>> sha256(enc_data)\n>> sha256(enc_data) ----------------> sha256(enc_data) ----------------->\n>> sha256(enc_data)\n>> enc_data         <---------------- enc_data <-------------------------\n>> enc_data\n>> data = enc_data XOR enc_key\n>>\n>>\n>> * The size of data is restricted to 256 bits. Identically, it should be\n>> extended to larger data and the data should be transferred in several\n>> payment paths like DLAS-up.\n>> * Channel Pubkey is only one for one channel and the data can be\n>> decrypted if enc_key is leaked. So enc_key should be generated newly every\n>> time by a way like hash chain but the protocol image above is just example\n>> for simplicity.\n>> * .x means X axis value of points on Elliptic Curve.\n>> * If data is less than 256 bits, then 0x00 is padded (I am not sure which\n>> of big endian and little endian is better).\n>>\n>>\n>>\n>> 2, Data upload <->  lightning (DLAS-down)\n>>\n>> Payer sends data and lightning payment from Payee atomically.\n>> This is like OG AMP(Atomic Multi-path Payment)[7] system.\n>>\n>> Payer                             Mediators\n>>  Payee\n>>\n>> =================================================================================\n>> data(512bit, padded)\n>>\n>> share1(256bit)\n>> share2(256bit)\n>>\n>> base_s = share1 XOR share2\n>> data1(256bit) ||  data2(256bit) = data(512bit)\n>> XOR_d1 = data1 XOR base_s\n>> XOR_d2 = data2 XOR base_s\n>> PreImg1 = sha256(base_s || data || 1)\n>> PreImg2 = sha256(base_s || data || 2)\n>>\n>> sha256(PreImg1), XOR_d1, share1 -> sha256(PreImg1), XOR_d1, share1  ->\n>> sha256(PreImg1), XOR_d1, share1\n>> sha256(PreImg2), XOR_d2, share2 -> sha256(PreImg2), XOR_d2, share2  ->\n>> sha256(PreImg2), XOR_d2, share1\n>>\n>>\n>>  base s = share1 XOR share2\n>>\n>>  data = (XOR_d1 XOR base_s) || (XOR_d2 XOR base_s)\n>>\n>>  PreImg1 = sha256(base_s || data || 1)\n>>\n>>  PreImg2 = sha256(base_s || data || 2)\n>>\n>> PreImg1    <-------------------    PreImg1    <---------------------\n>> PreImg1\n>> PreImg2    <-------------------    PreImg2    <---------------------\n>> PreImg2\n>>\n>>\n>> * This protocol example has 512 bits data and they are transferred in two\n>> paths. However, it can transfer larger data in several payment paths like\n>> [5].\n>> * || means string concatenation.\n>> * If data is less than 512 bits, then 0x00 is padded(I am not sure which\n>> of big endian and little endian is better).\n>>\n>>\n>> ---------\n>>\n>>\n>> [Use Cases]\n>>\n>> 1, Lightning Network ecosystem\n>>\n>> * Hosting Incentives like Acai Protocol\n>> ** Watchtower Hosting incentive, Backup Hosting incentive\n>> *** Commitment tx data sending to Data Host(DLAS-up)\n>> **** Commitment tx data is embedded in preimage so that Payer can not\n>> send the data without remittance\n>> *** Channel backup data receiving from Data Host(DLAS-down)\n>> **** Channel backup data is embedded in preimage so that Payer can not\n>> receive the data without remittance\n>>\n>> 2, Crypto currency Problems\n>>\n>> * Distributed secret key sharing (just come up with an idea though)\n>> ** As a key backup, one of secret key shares is distributed with\n>> encryption(DLAS-up) to some nodes, which nodes receive lightning payment as\n>> key managing fee. And the nodes send a proof for managing the key as\n>> response of bloom filter periodically, and exchange encrypted secret key\n>> share with lightning payment to asset holder(DLAS-down).\n>> ** For example 2 out of 3 multi signature key sharing, asset holder puts\n>> the first key, the custodial has the second key, and the third key at the\n>> lightning distribution nodes. Asset holders usually spend assets using\n>> their key and the key on Distributed Nodes.\n>>\n>>\n>> 3, Problems so far\n>>\n>> * Prevention email spam and DDoS attack with large data\n>> ** Payer can not send email or data without remittance(DLAS-up)\n>> ** Payer can not receive reply-email without remittance(DLAS-down)\n>>\n>> * Incentive of receiving advertisements on browser or desktop/mobile app\n>> ** Payer can not send advertisements without remittance(DLAS-up)\n>>\n>> * Bounty for code bug fixes based on cryptographic proofs or secret\n>> computations\n>> ** (DLAS-down)\n>>\n>>\n>>\n>> [References]\n>>\n>> [1] https://bitcointalk.org/index.php?topic=321228\n>> [2] https://twitter.com/roasbeef/status/964608261830750208\n>> [3] https://eprint.iacr.org/2016/575\n>> [4] https://github.com/storm-org/storm-spec\n>> [5] https://twitter.com/joostjgr/status/1190714028626251779\n>> [6] https://github.com/lightningnetwork/lightning-rfc/pull/619\n>> [7]\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-February/000993.html\n>>\n>>\n>> document on github:\n>> https://github.com/takaya-imai/data_lightning_atomic_swap\n>>\n>> Best regards,\n>> Takaya Imai\n>> Email: takaya.imai at frontier-ptnrs.com, takaya.imai at unitedbitcoiners.com\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n>\n> --\n> Yours sincerely,\n> Subhra Mazumdar.\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200120/dd3a091b/attachment-0001.html>"
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-01-20T08:30:57",
                "message_text_only": "Thanks Takaya for clearing my doubts. Regarding the answer to the question\n\n \"What happens if it fails in an iteration ? So the recipient of the file\nremains happy with the partial content ? Or will the payment be revoked\n(not sure how) if recipient doesn't get the full content ?\n\nThis is about the DLAS-up protocol.\nThe protocol uses OG AMP so the payments and data transfers are revoked in\ncase that it fails\"\n\nI am talking about different iterations. If it's the case that you have a\n5GB file then you are sending 256bit via each path. May be in one iteration\nyou are able to send some 200 byte (assuming we get 8 paths at a time). So\nit's the case that you need 5GB/200B iterations. But og amp guarantees\natomic delivery for blocks per iteration right and not for all the\niterations taken together ? Also how do you ensure correctness of the file\nshared (using Zk proof ?) ?\n\n\n\n\n\n\n\n\nOn Mon, Jan 20, 2020, 12:03 Takaya Imai <takaya.imai at frontier-ptnrs.com>\nwrote:\n\n> Hi Subhra,\n>\n> thanks for your question.\n>\n> > So as of now if we consider transfer of a file (may of few KB) then you\n> split it into several blocks and use atomic multi path payment whole using\n> the blocks for embedding with the preimage inorder to obtain payment.\n> > But it might be the case you may not have sufficient number of path to\n> transfer all the blocks at one go because of preimage size limitation of\n> 256 bit (I didn't get the point that there is no limitation on data size,\n> can anyone explain that ?).\n>\n> Yes. It needs many blocks and paths if large file.\n> But it has no problem because it can use the same path several times.\n>\n> Of course it needs much money to transfer large file. But this is good\n> point in order to retain lightning network stable.\n>\n> For DOS attack, OG AMP has the same problem. It might that recipient needs\n> a limit how many split blocks the recipient accept\n>\n> > So may be you need several iteration and I presume thats what lightning\n> network will pitch in where we have several such microtransactions going on.\n> >.\n>\n> Thanks,\n> Takaya Imai\n>\n> 2020\u5e741\u670816\u65e5(\u6728) 16:14 Subhra Mazumdar <subhra.mazumdar1993 at gmail.com>:\n>\n>> Hello Takaya,\n>>         I really liked the idea of data atomic swap mentioned over here.\n>> So as of now if we consider transfer of a file (may of few KB) then you\n>> split it into several blocks and use atomic multi path payment whole using\n>> the blocks for embedding with the preimage inorder to obtain payment. But\n>> it might be the case you may not have sufficient number of path to transfer\n>> all the blocks at one go because of preimage size limitation of 256 bit (I\n>> didn't get the point that there is no limitation on data size, can anyone\n>> explain that ?). So may be you need several iteration and I presume thats\n>> what lightning network will pitch in where we have several such\n>> microtransactions going on. What happens if it fails in an iteration ? So\n>> the recipient of the file remains happy with the partial content ? Or will\n>> the payment be revoked (not sure how) if recipient doesn't get the full\n>> content ?\n>>\n>> On Mon, Nov 11, 2019 at 6:29 AM Takaya Imai <\n>> takaya.imai at frontier-ptnrs.com> wrote:\n>>\n>>> Hi all,\n>>>\n>>> I propose Data Lightning Atomic Swap.\n>>> Anyone already have the same idea?\n>>>\n>>>\n>>> [Abstract]\n>>> This proposal is a way to swap data and lightning payment atomically.\n>>> It has two patterns, one is for a payer to swap data-download with\n>>> lightning payment to a payee (DLAS-down), the other is for a payer to swap\n>>> data-upload with lightning payment to a payee (DLAS-up).\n>>>\n>>> The data is embedded to preimage so sending and receiving the data need\n>>> lightning payment at the same time.\n>>>\n>>> ---------\n>>>\n>>> [Motivation]\n>>> Atomic Swaps among crypto currencies has various ways to implement\n>>> (on-chain to on-chain[1], on-chain to of-chain(Submarine Swap[2])). And\n>>> Atomic Swaps between data and crypto currencies are also proposed as a part\n>>> of TumbleBit mechanism[3], Storm mechanism[4] and so on.\n>>>\n>>> Recently Joost Jager proposed Instant messages with lightning onion\n>>> routing, whatsat[5], which use recent sphinx payload change[6]. This is\n>>> very awesome but not atomic with lightning payment.\n>>>\n>>> Atomic lightning mechanism for data is useful in use cases below.\n>>>\n>>> ---------\n>>>\n>>> [Pros & Cons]\n>>>\n>>> * DLAS-down\n>>> ** Pros\n>>> *** Atomic data download exchange with lightning payment\n>>> ** Cons\n>>> *** It needs better mechanism to expand data size\n>>>\n>>> * DLAS-up\n>>> ** Pros\n>>> *** Atomic data upload exchange with lightning payment\n>>> ** Cons\n>>> *** OG AMP[7] is needed to implement\n>>>\n>>> ---------\n>>>\n>>> [What I describe]\n>>> * A way to swap data with lightning payment atomically.\n>>>\n>>> ---------\n>>>\n>>> [What I do not describe]\n>>> * A way to detect that data is correct or not, namely zero knowledge\n>>> proof process.\n>>>\n>>> For example, probabilistic checkable proof like TumbleBit[3] proposed.\n>>> Just message as data is no problem because no need to check the message\n>>> is correct or not.\n>>>\n>>> * A way in case that different preimages are used in a payment route\n>>> like Multi-hop locks.\n>>>\n>>> ---------\n>>>\n>>> [Specification]\n>>>\n>>> Lightning Network(LN) has a mechanism about preimage like a brief image\n>>> below.\n>>>\n>>> Payer                             Mediators\n>>>  Payee\n>>>\n>>> =================================================================================\n>>>\n>>> Preimage\n>>> Preimage Hash  <--------------------- invoice ------------------------\n>>>  Preimage Hash\n>>> Preimage Hash  ---------------->   Preimage Hash -------------------->\n>>>  Preimage Hash\n>>> Preimage       <\u2014-------------\u2014-   Preimage      <--------------------\n>>>  Preimage\n>>>\n>>> As you know, preimage Payer gets can be a proof of payment because Payer\n>>> can not get it if the payment is executed correctly.\n>>>\n>>>\n>>>\n>>> 1, Data download <->  lightning (DLAS-down)\n>>>\n>>>\n>>> Payer sends lightning payment and receives data from Payee atomically.\n>>>\n>>>\n>>> Payer                             Mediators\n>>>  Payee\n>>>\n>>> =================================================================================\n>>> Payer Channel Pubkey <----------------------------------------------->\n>>> Payee Channel Pubkey\n>>>\n>>>\n>>>  data(256bit, padded)\n>>>\n>>>  enc_key = (Payee Channel Secret Key * Payer Channel Pubkey).x  (256bit)\n>>> enc_key = (Payer Channel Secret Key * Payee Channel Pubkey).x  (256bit)\n>>>\n>>>  enc_data = data XOR enc_key\n>>> sha256(enc_data) <--------------------- invoice ----------------------\n>>> sha256(enc_data)\n>>> sha256(enc_data) ----------------> sha256(enc_data) ----------------->\n>>> sha256(enc_data)\n>>> enc_data         <---------------- enc_data <-------------------------\n>>> enc_data\n>>> data = enc_data XOR enc_key\n>>>\n>>>\n>>> * The size of data is restricted to 256 bits. Identically, it should be\n>>> extended to larger data and the data should be transferred in several\n>>> payment paths like DLAS-up.\n>>> * Channel Pubkey is only one for one channel and the data can be\n>>> decrypted if enc_key is leaked. So enc_key should be generated newly every\n>>> time by a way like hash chain but the protocol image above is just example\n>>> for simplicity.\n>>> * .x means X axis value of points on Elliptic Curve.\n>>> * If data is less than 256 bits, then 0x00 is padded (I am not sure\n>>> which of big endian and little endian is better).\n>>>\n>>>\n>>>\n>>> 2, Data upload <->  lightning (DLAS-down)\n>>>\n>>> Payer sends data and lightning payment from Payee atomically.\n>>> This is like OG AMP(Atomic Multi-path Payment)[7] system.\n>>>\n>>> Payer                             Mediators\n>>>  Payee\n>>>\n>>> =================================================================================\n>>> data(512bit, padded)\n>>>\n>>> share1(256bit)\n>>> share2(256bit)\n>>>\n>>> base_s = share1 XOR share2\n>>> data1(256bit) ||  data2(256bit) = data(512bit)\n>>> XOR_d1 = data1 XOR base_s\n>>> XOR_d2 = data2 XOR base_s\n>>> PreImg1 = sha256(base_s || data || 1)\n>>> PreImg2 = sha256(base_s || data || 2)\n>>>\n>>> sha256(PreImg1), XOR_d1, share1 -> sha256(PreImg1), XOR_d1, share1  ->\n>>> sha256(PreImg1), XOR_d1, share1\n>>> sha256(PreImg2), XOR_d2, share2 -> sha256(PreImg2), XOR_d2, share2  ->\n>>> sha256(PreImg2), XOR_d2, share1\n>>>\n>>>\n>>>  base s = share1 XOR share2\n>>>\n>>>  data = (XOR_d1 XOR base_s) || (XOR_d2 XOR base_s)\n>>>\n>>>  PreImg1 = sha256(base_s || data || 1)\n>>>\n>>>  PreImg2 = sha256(base_s || data || 2)\n>>>\n>>> PreImg1    <-------------------    PreImg1    <---------------------\n>>> PreImg1\n>>> PreImg2    <-------------------    PreImg2    <---------------------\n>>> PreImg2\n>>>\n>>>\n>>> * This protocol example has 512 bits data and they are transferred in\n>>> two paths. However, it can transfer larger data in several payment paths\n>>> like [5].\n>>> * || means string concatenation.\n>>> * If data is less than 512 bits, then 0x00 is padded(I am not sure which\n>>> of big endian and little endian is better).\n>>>\n>>>\n>>> ---------\n>>>\n>>>\n>>> [Use Cases]\n>>>\n>>> 1, Lightning Network ecosystem\n>>>\n>>> * Hosting Incentives like Acai Protocol\n>>> ** Watchtower Hosting incentive, Backup Hosting incentive\n>>> *** Commitment tx data sending to Data Host(DLAS-up)\n>>> **** Commitment tx data is embedded in preimage so that Payer can not\n>>> send the data without remittance\n>>> *** Channel backup data receiving from Data Host(DLAS-down)\n>>> **** Channel backup data is embedded in preimage so that Payer can not\n>>> receive the data without remittance\n>>>\n>>> 2, Crypto currency Problems\n>>>\n>>> * Distributed secret key sharing (just come up with an idea though)\n>>> ** As a key backup, one of secret key shares is distributed with\n>>> encryption(DLAS-up) to some nodes, which nodes receive lightning payment as\n>>> key managing fee. And the nodes send a proof for managing the key as\n>>> response of bloom filter periodically, and exchange encrypted secret key\n>>> share with lightning payment to asset holder(DLAS-down).\n>>> ** For example 2 out of 3 multi signature key sharing, asset holder puts\n>>> the first key, the custodial has the second key, and the third key at the\n>>> lightning distribution nodes. Asset holders usually spend assets using\n>>> their key and the key on Distributed Nodes.\n>>>\n>>>\n>>> 3, Problems so far\n>>>\n>>> * Prevention email spam and DDoS attack with large data\n>>> ** Payer can not send email or data without remittance(DLAS-up)\n>>> ** Payer can not receive reply-email without remittance(DLAS-down)\n>>>\n>>> * Incentive of receiving advertisements on browser or desktop/mobile app\n>>> ** Payer can not send advertisements without remittance(DLAS-up)\n>>>\n>>> * Bounty for code bug fixes based on cryptographic proofs or secret\n>>> computations\n>>> ** (DLAS-down)\n>>>\n>>>\n>>>\n>>> [References]\n>>>\n>>> [1] https://bitcointalk.org/index.php?topic=321228\n>>> [2] https://twitter.com/roasbeef/status/964608261830750208\n>>> [3] https://eprint.iacr.org/2016/575\n>>> [4] https://github.com/storm-org/storm-spec\n>>> [5] https://twitter.com/joostjgr/status/1190714028626251779\n>>> [6] https://github.com/lightningnetwork/lightning-rfc/pull/619\n>>> [7]\n>>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-February/000993.html\n>>>\n>>>\n>>> document on github:\n>>> https://github.com/takaya-imai/data_lightning_atomic_swap\n>>>\n>>> Best regards,\n>>> Takaya Imai\n>>> Email: takaya.imai at frontier-ptnrs.com, takaya.imai at unitedbitcoiners.com\n>>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>>\n>>\n>> --\n>> Yours sincerely,\n>> Subhra Mazumdar.\n>>\n>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200120/257e2885/attachment-0001.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2020-01-20T18:01:40",
                "message_text_only": "On 11/9/19 4:31 AM, Takaya Imai wrote:\n> [What I do not describe]\n> * A way to detect that data is correct or not, namely zero knowledge\n> proof process.\n\nHave you come across Zero Knowledge Contingent Payments? Originally it\nwas designed for on-chain applications but it slots neatly into\nlightning as it only requires a method to lock funds to a hash preimage.\n\nMatt"
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-01-20T18:10:54",
                "message_text_only": "Are you referring to the paper Zero knowledge contingent payment revisited\n? I will look into the construction. Thanks for the information! :)\n\nOn Mon, Jan 20, 2020, 23:31 Matt Corallo <lf-lists at mattcorallo.com> wrote:\n\n> On 11/9/19 4:31 AM, Takaya Imai wrote:\n> > [What I do not describe]\n> > * A way to detect that data is correct or not, namely zero knowledge\n> > proof process.\n>\n> Have you come across Zero Knowledge Contingent Payments? Originally it\n> was designed for on-chain applications but it slots neatly into\n> lightning as it only requires a method to lock funds to a hash preimage.\n>\n> Matt\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200120/3823fa3d/attachment.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2020-01-20T18:18:01",
                "message_text_only": "That paper discusses it, but I don't think there was ever a paper proper\non ZKCP. There are various discussions of it, though, if you google.\nSadly this is common in this space - lots of great ideas where no one\never bothered to write academic-style papers about them (hence why\nacademic papers around Bitcoin tend to miss nearly all relevant context,\nsadly).\n\nMatt\n\nOn 1/20/20 6:10 PM, Subhra Mazumdar wrote:\n> Are you referring to the paper Zero knowledge contingent payment\n> revisited ? I will look into the construction. Thanks for the\n> information! :)\n> \n> On Mon, Jan 20, 2020, 23:31 Matt Corallo <lf-lists at mattcorallo.com\n> <mailto:lf-lists at mattcorallo.com>> wrote:\n> \n>     On 11/9/19 4:31 AM, Takaya Imai wrote:\n>     > [What I do not describe]\n>     > * A way to detect that data is correct or not, namely zero knowledge\n>     > proof process.\n> \n>     Have you come across Zero Knowledge Contingent Payments? Originally it\n>     was designed for on-chain applications but it slots neatly into\n>     lightning as it only requires a method to lock funds to a hash preimage.\n> \n>     Matt\n>     _______________________________________________\n>     Lightning-dev mailing list\n>     Lightning-dev at lists.linuxfoundation.org\n>     <mailto:Lightning-dev at lists.linuxfoundation.org>\n>     https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>"
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-01-20T18:23:27",
                "message_text_only": "But isn't it that the use of ZK proof will render the system slow and hence\ndefy the very purpose of lightning network which intends to make things\nscalable as well as faster transaction ?\n\nOn Mon, Jan 20, 2020 at 11:48 PM Matt Corallo <lf-lists at mattcorallo.com>\nwrote:\n\n> That paper discusses it, but I don't think there was ever a paper proper\n> on ZKCP. There are various discussions of it, though, if you google.\n> Sadly this is common in this space - lots of great ideas where no one\n> ever bothered to write academic-style papers about them (hence why\n> academic papers around Bitcoin tend to miss nearly all relevant context,\n> sadly).\n>\n> Matt\n>\n> On 1/20/20 6:10 PM, Subhra Mazumdar wrote:\n> > Are you referring to the paper Zero knowledge contingent payment\n> > revisited ? I will look into the construction. Thanks for the\n> > information! :)\n> >\n> > On Mon, Jan 20, 2020, 23:31 Matt Corallo <lf-lists at mattcorallo.com\n> > <mailto:lf-lists at mattcorallo.com>> wrote:\n> >\n> >     On 11/9/19 4:31 AM, Takaya Imai wrote:\n> >     > [What I do not describe]\n> >     > * A way to detect that data is correct or not, namely zero\n> knowledge\n> >     > proof process.\n> >\n> >     Have you come across Zero Knowledge Contingent Payments? Originally\n> it\n> >     was designed for on-chain applications but it slots neatly into\n> >     lightning as it only requires a method to lock funds to a hash\n> preimage.\n> >\n> >     Matt\n> >     _______________________________________________\n> >     Lightning-dev mailing list\n> >     Lightning-dev at lists.linuxfoundation.org\n> >     <mailto:Lightning-dev at lists.linuxfoundation.org>\n> >     https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> >\n>\n\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200120/4e58bfdf/attachment-0001.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2020-01-20T18:29:44",
                "message_text_only": "Zk proofs are incredibly fast these days for small-ish programs. They\u2019re much too slow for a consensus system where every party needs to download and validate them, but for relatively simple programs a two-party system using them is very doable.\n\n> On Jan 20, 2020, at 13:23, Subhra Mazumdar <subhra.mazumdar1993 at gmail.com> wrote:\n> \n> \ufeff\n> But isn't it that the use of ZK proof will render the system slow and hence defy the very purpose of lightning network which intends to make things scalable as well as faster transaction ?\n> \n>> On Mon, Jan 20, 2020 at 11:48 PM Matt Corallo <lf-lists at mattcorallo.com> wrote:\n>> That paper discusses it, but I don't think there was ever a paper proper\n>> on ZKCP. There are various discussions of it, though, if you google.\n>> Sadly this is common in this space - lots of great ideas where no one\n>> ever bothered to write academic-style papers about them (hence why\n>> academic papers around Bitcoin tend to miss nearly all relevant context,\n>> sadly).\n>> \n>> Matt\n>> \n>> On 1/20/20 6:10 PM, Subhra Mazumdar wrote:\n>> > Are you referring to the paper Zero knowledge contingent payment\n>> > revisited ? I will look into the construction. Thanks for the\n>> > information! :)\n>> > \n>> > On Mon, Jan 20, 2020, 23:31 Matt Corallo <lf-lists at mattcorallo.com\n>> > <mailto:lf-lists at mattcorallo.com>> wrote:\n>> > \n>> >     On 11/9/19 4:31 AM, Takaya Imai wrote:\n>> >     > [What I do not describe]\n>> >     > * A way to detect that data is correct or not, namely zero knowledge\n>> >     > proof process.\n>> > \n>> >     Have you come across Zero Knowledge Contingent Payments? Originally it\n>> >     was designed for on-chain applications but it slots neatly into\n>> >     lightning as it only requires a method to lock funds to a hash preimage.\n>> > \n>> >     Matt\n>> >     _______________________________________________\n>> >     Lightning-dev mailing list\n>> >     Lightning-dev at lists.linuxfoundation.org\n>> >     <mailto:Lightning-dev at lists.linuxfoundation.org>\n>> >     https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>> > \n> \n> \n> -- \n> Yours sincerely,\n> Subhra Mazumdar.\n> \n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200120/e6281052/attachment.html>"
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-01-20T18:33:04",
                "message_text_only": "Sounds good. But how do I provide a correctness for the entire asset to be\ntransferred when I am already partitioning into several units (say chunks\nof file ? ) So as an when the block of file is received then we have to\ngive a ZK proof \"block x is part of File F\". Is it how this should work ?\n\nOn Mon, Jan 20, 2020 at 11:59 PM Matt Corallo <lf-lists at mattcorallo.com>\nwrote:\n\n> Zk proofs are incredibly fast these days for small-ish programs. They\u2019re\n> much too slow for a consensus system where every party needs to download\n> and validate them, but for relatively simple programs a two-party system\n> using them is very doable.\n>\n> On Jan 20, 2020, at 13:23, Subhra Mazumdar <subhra.mazumdar1993 at gmail.com>\n> wrote:\n>\n> \ufeff\n> But isn't it that the use of ZK proof will render the system slow and\n> hence defy the very purpose of lightning network which intends to make\n> things scalable as well as faster transaction ?\n>\n> On Mon, Jan 20, 2020 at 11:48 PM Matt Corallo <lf-lists at mattcorallo.com>\n> wrote:\n>\n>> That paper discusses it, but I don't think there was ever a paper proper\n>> on ZKCP. There are various discussions of it, though, if you google.\n>> Sadly this is common in this space - lots of great ideas where no one\n>> ever bothered to write academic-style papers about them (hence why\n>> academic papers around Bitcoin tend to miss nearly all relevant context,\n>> sadly).\n>>\n>> Matt\n>>\n>> On 1/20/20 6:10 PM, Subhra Mazumdar wrote:\n>> > Are you referring to the paper Zero knowledge contingent payment\n>> > revisited ? I will look into the construction. Thanks for the\n>> > information! :)\n>> >\n>> > On Mon, Jan 20, 2020, 23:31 Matt Corallo <lf-lists at mattcorallo.com\n>> > <mailto:lf-lists at mattcorallo.com>> wrote:\n>> >\n>> >     On 11/9/19 4:31 AM, Takaya Imai wrote:\n>> >     > [What I do not describe]\n>> >     > * A way to detect that data is correct or not, namely zero\n>> knowledge\n>> >     > proof process.\n>> >\n>> >     Have you come across Zero Knowledge Contingent Payments? Originally\n>> it\n>> >     was designed for on-chain applications but it slots neatly into\n>> >     lightning as it only requires a method to lock funds to a hash\n>> preimage.\n>> >\n>> >     Matt\n>> >     _______________________________________________\n>> >     Lightning-dev mailing list\n>> >     Lightning-dev at lists.linuxfoundation.org\n>> >     <mailto:Lightning-dev at lists.linuxfoundation.org>\n>> >     https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>> >\n>>\n>\n>\n> --\n> Yours sincerely,\n> Subhra Mazumdar.\n>\n>\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200121/c4ed4a75/attachment.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2020-01-20T18:56:12",
                "message_text_only": "Don\u2019t and data in lighting payments unless you have to. It\u2019s super DoS-y and rude to your peers. If you\u2019re just transferring a file, you can use ZKCP to send an encrypted copy of the file with the encryption key being the payment_preimage, making the whole thing one big atomic action.\n\n> On Jan 20, 2020, at 13:33, Subhra Mazumdar <subhra.mazumdar1993 at gmail.com> wrote:\n> \n> \ufeff\n> Sounds good. But how do I provide a correctness for the entire asset to be transferred when I am already partitioning into several units (say chunks of file ? ) So as an when the block of file is received then we have to give a ZK proof \"block x is part of File F\". Is it how this should work ?\n> \n>> On Mon, Jan 20, 2020 at 11:59 PM Matt Corallo <lf-lists at mattcorallo.com> wrote:\n>> Zk proofs are incredibly fast these days for small-ish programs. They\u2019re much too slow for a consensus system where every party needs to download and validate them, but for relatively simple programs a two-party system using them is very doable.\n>> \n>>>> On Jan 20, 2020, at 13:23, Subhra Mazumdar <subhra.mazumdar1993 at gmail.com> wrote:\n>>>> \n>>> \ufeff\n>>> But isn't it that the use of ZK proof will render the system slow and hence defy the very purpose of lightning network which intends to make things scalable as well as faster transaction ?\n>>> \n>>>> On Mon, Jan 20, 2020 at 11:48 PM Matt Corallo <lf-lists at mattcorallo.com> wrote:\n>>>> That paper discusses it, but I don't think there was ever a paper proper\n>>>> on ZKCP. There are various discussions of it, though, if you google.\n>>>> Sadly this is common in this space - lots of great ideas where no one\n>>>> ever bothered to write academic-style papers about them (hence why\n>>>> academic papers around Bitcoin tend to miss nearly all relevant context,\n>>>> sadly).\n>>>> \n>>>> Matt\n>>>> \n>>>> On 1/20/20 6:10 PM, Subhra Mazumdar wrote:\n>>>> > Are you referring to the paper Zero knowledge contingent payment\n>>>> > revisited ? I will look into the construction. Thanks for the\n>>>> > information! :)\n>>>> > \n>>>> > On Mon, Jan 20, 2020, 23:31 Matt Corallo <lf-lists at mattcorallo.com\n>>>> > <mailto:lf-lists at mattcorallo.com>> wrote:\n>>>> > \n>>>> >     On 11/9/19 4:31 AM, Takaya Imai wrote:\n>>>> >     > [What I do not describe]\n>>>> >     > * A way to detect that data is correct or not, namely zero knowledge\n>>>> >     > proof process.\n>>>> > \n>>>> >     Have you come across Zero Knowledge Contingent Payments? Originally it\n>>>> >     was designed for on-chain applications but it slots neatly into\n>>>> >     lightning as it only requires a method to lock funds to a hash preimage.\n>>>> > \n>>>> >     Matt\n>>>> >     _______________________________________________\n>>>> >     Lightning-dev mailing list\n>>>> >     Lightning-dev at lists.linuxfoundation.org\n>>>> >     <mailto:Lightning-dev at lists.linuxfoundation.org>\n>>>> >     https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>> > \n>>> \n>>> \n>>> -- \n>>> Yours sincerely,\n>>> Subhra Mazumdar.\n>>> \n> \n> \n> -- \n> Yours sincerely,\n> Subhra Mazumdar.\n> \n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200120/522c5165/attachment-0001.html>"
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-01-21T00:36:21",
                "message_text_only": "So is it sufficient to give a zk proof of the entire file and not of the\nindividual blocks which are transferred at each iteration? Also does it\nmake sense that you make partial payment per block instead of waiting for\nthe total file to arrive. It might be the case that the zk proof of the\ntotal file is correct but then sender might cheat while sending individual\nblock.\n\nOn Tue, Jan 21, 2020, 00:26 Matt Corallo <lf-lists at mattcorallo.com> wrote:\n\n> Don\u2019t and data in lighting payments unless you have to. It\u2019s super DoS-y\n> and rude to your peers. If you\u2019re just transferring a file, you can use\n> ZKCP to send an encrypted copy of the file with the encryption key being\n> the payment_preimage, making the whole thing one big atomic action.\n>\n> On Jan 20, 2020, at 13:33, Subhra Mazumdar <subhra.mazumdar1993 at gmail.com>\n> wrote:\n>\n> \ufeff\n> Sounds good. But how do I provide a correctness for the entire asset to be\n> transferred when I am already partitioning into several units (say chunks\n> of file ? ) So as an when the block of file is received then we have to\n> give a ZK proof \"block x is part of File F\". Is it how this should work ?\n>\n> On Mon, Jan 20, 2020 at 11:59 PM Matt Corallo <lf-lists at mattcorallo.com>\n> wrote:\n>\n>> Zk proofs are incredibly fast these days for small-ish programs. They\u2019re\n>> much too slow for a consensus system where every party needs to download\n>> and validate them, but for relatively simple programs a two-party system\n>> using them is very doable.\n>>\n>> On Jan 20, 2020, at 13:23, Subhra Mazumdar <subhra.mazumdar1993 at gmail.com>\n>> wrote:\n>>\n>> \ufeff\n>> But isn't it that the use of ZK proof will render the system slow and\n>> hence defy the very purpose of lightning network which intends to make\n>> things scalable as well as faster transaction ?\n>>\n>> On Mon, Jan 20, 2020 at 11:48 PM Matt Corallo <lf-lists at mattcorallo.com>\n>> wrote:\n>>\n>>> That paper discusses it, but I don't think there was ever a paper proper\n>>> on ZKCP. There are various discussions of it, though, if you google.\n>>> Sadly this is common in this space - lots of great ideas where no one\n>>> ever bothered to write academic-style papers about them (hence why\n>>> academic papers around Bitcoin tend to miss nearly all relevant context,\n>>> sadly).\n>>>\n>>> Matt\n>>>\n>>> On 1/20/20 6:10 PM, Subhra Mazumdar wrote:\n>>> > Are you referring to the paper Zero knowledge contingent payment\n>>> > revisited ? I will look into the construction. Thanks for the\n>>> > information! :)\n>>> >\n>>> > On Mon, Jan 20, 2020, 23:31 Matt Corallo <lf-lists at mattcorallo.com\n>>> > <mailto:lf-lists at mattcorallo.com>> wrote:\n>>> >\n>>> >     On 11/9/19 4:31 AM, Takaya Imai wrote:\n>>> >     > [What I do not describe]\n>>> >     > * A way to detect that data is correct or not, namely zero\n>>> knowledge\n>>> >     > proof process.\n>>> >\n>>> >     Have you come across Zero Knowledge Contingent Payments?\n>>> Originally it\n>>> >     was designed for on-chain applications but it slots neatly into\n>>> >     lightning as it only requires a method to lock funds to a hash\n>>> preimage.\n>>> >\n>>> >     Matt\n>>> >     _______________________________________________\n>>> >     Lightning-dev mailing list\n>>> >     Lightning-dev at lists.linuxfoundation.org\n>>> >     <mailto:Lightning-dev at lists.linuxfoundation.org>\n>>> >     https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>> >\n>>>\n>>\n>>\n>> --\n>> Yours sincerely,\n>> Subhra Mazumdar.\n>>\n>>\n>\n> --\n> Yours sincerely,\n> Subhra Mazumdar.\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200121/6e78e4d8/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-21T00:47:23",
                "message_text_only": "Good morning Subhra,\n\nRefer to this protocol instead of DLAS: https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-June/002035.html\nIn this protocol, an *encrypted* form of the *entire file* is sent.\nConsequently, a *single* payment is made, where the payment preimage is the decryption key.\nKnowing an additional zk proof is necessary to show that the file is indeed encrypted using the decryption key that is the preimage of the given hash (the linked thread has details I believe).\n\nRelevantly, there is no need to consider blocks of a file when using the linked protocol instead of DLAS.\nOf course, a Zk-proof of some property of the entire file, that can be understood by an end-user, may not be possible.\nLikely, you might want to prove of a video file that a thumbnail of the video file is extracted from a frame of the video, and show that thumbnail to the end-user.\nLooking at the *rest* of the frames of the video (after you have paid for its decryption) may very reveal them to be frames of a video of Rick Astley singing \"Never Gonna Give You Up\".\n!\n\nRegards,\nZmnSCPxj\n\n> So is it sufficient to give a zk proof of the entire file and not of the individual blocks which are transferred at each iteration? Also does it make sense that you make partial payment per block instead of waiting for the total file to arrive. It might be the case that the zk proof of the total file is correct but then sender might cheat while sending individual block.\n>\n> On Tue, Jan 21, 2020, 00:26 Matt Corallo <lf-lists at mattcorallo.com> wrote:\n>\n> > Don\u2019t and data in lighting payments unless you have to. It\u2019s super DoS-y and rude to your peers. If you\u2019re just transferring a file, you can use ZKCP to send an encrypted copy of the file with the encryption key being the payment_preimage, making the whole thing one big atomic action.\n> >\n> > > On Jan 20, 2020, at 13:33, Subhra Mazumdar <subhra.mazumdar1993 at gmail.com> wrote:\n> >\n> > > \ufeff\n> > > Sounds good. But how do I provide a correctness for the entire asset to be transferred when I am already partitioning into several units (say chunks of file ? ) So as an when the block of file is received then we have to give a ZK proof \"block x is part of File F\". Is it how this should work ?\n> > >\n> > > On Mon, Jan 20, 2020 at 11:59 PM Matt Corallo <lf-lists at mattcorallo.com> wrote:\n> > >\n> > > > Zk proofs are incredibly fast these days for small-ish programs. They\u2019re much too slow for a consensus system where every party needs to download and validate them, but for relatively simple programs a two-party system using them is very doable.\n> > > >\n> > > > > On Jan 20, 2020, at 13:23, Subhra Mazumdar <subhra.mazumdar1993 at gmail.com> wrote:\n> > > >\n> > > > > \ufeff\n> > > > > But isn't it that the use of ZK proof will render the system slow and hence defy the very purpose of lightning network which intends to make things scalable as well as faster transaction ?\n> > > > >\n> > > > > On Mon, Jan 20, 2020 at 11:48 PM Matt Corallo <lf-lists at mattcorallo.com> wrote:\n> > > > >\n> > > > > > That paper discusses it, but I don't think there was ever a paper proper\n> > > > > > on ZKCP. There are various discussions of it, though, if you google.\n> > > > > > Sadly this is common in this space - lots of great ideas where no one\n> > > > > > ever bothered to write academic-style papers about them (hence why\n> > > > > > academic papers around Bitcoin tend to miss nearly all relevant context,\n> > > > > > sadly).\n> > > > > >\n> > > > > > Matt\n> > > > > >\n> > > > > > On 1/20/20 6:10 PM, Subhra Mazumdar wrote:\n> > > > > > > Are you referring to the paper Zero knowledge contingent payment\n> > > > > > > revisited ? I will look into the construction. Thanks for the\n> > > > > > > information! :)\n> > > > > > >\n> > > > > > > On Mon, Jan 20, 2020, 23:31 Matt Corallo <lf-lists at mattcorallo.com\n> > > > > > > <mailto:lf-lists at mattcorallo.com>> wrote:\n> > > > > > >\n> > > > > > >\u00a0 \u00a0 \u00a0On 11/9/19 4:31 AM, Takaya Imai wrote:\n> > > > > > >\u00a0 \u00a0 \u00a0> [What I do not describe]\n> > > > > > >\u00a0 \u00a0 \u00a0> * A way to detect that data is correct or not, namely zero knowledge\n> > > > > > >\u00a0 \u00a0 \u00a0> proof process.\n> > > > > > >\n> > > > > > >\u00a0 \u00a0 \u00a0Have you come across Zero Knowledge Contingent Payments? Originally it\n> > > > > > >\u00a0 \u00a0 \u00a0was designed for on-chain applications but it slots neatly into\n> > > > > > >\u00a0 \u00a0 \u00a0lightning as it only requires a method to lock funds to a hash preimage.\n> > > > > > >\n> > > > > > >\u00a0 \u00a0 \u00a0Matt\n> > > > > > >\u00a0 \u00a0 \u00a0_______________________________________________\n> > > > > > >\u00a0 \u00a0 \u00a0Lightning-dev mailing list\n> > > > > > >\u00a0 \u00a0 \u00a0Lightning-dev at lists.linuxfoundation.org\n> > > > > > >\u00a0 \u00a0 \u00a0<mailto:Lightning-dev at lists.linuxfoundation.org>\n> > > > > > >\u00a0 \u00a0 \u00a0https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> > > > > > >\n> > > > >\n> > > > > --\n> > > > > Yours sincerely,\n> > > > > Subhra Mazumdar.\n> > >\n> > > --\n> > > Yours sincerely,\n> > > Subhra Mazumdar."
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-01-21T01:47:49",
                "message_text_only": "Thanks for the link. I will have a look.\n\nOn Tue, Jan 21, 2020, 06:17 ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Subhra,\n>\n> Refer to this protocol instead of DLAS:\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-June/002035.html\n> In this protocol, an *encrypted* form of the *entire file* is sent.\n> Consequently, a *single* payment is made, where the payment preimage is\n> the decryption key.\n> Knowing an additional zk proof is necessary to show that the file is\n> indeed encrypted using the decryption key that is the preimage of the given\n> hash (the linked thread has details I believe).\n>\n> Relevantly, there is no need to consider blocks of a file when using the\n> linked protocol instead of DLAS.\n> Of course, a Zk-proof of some property of the entire file, that can be\n> understood by an end-user, may not be possible.\n> Likely, you might want to prove of a video file that a thumbnail of the\n> video file is extracted from a frame of the video, and show that thumbnail\n> to the end-user.\n> Looking at the *rest* of the frames of the video (after you have paid for\n> its decryption) may very reveal them to be frames of a video of Rick Astley\n> singing \"Never Gonna Give You Up\".\n> !\n>\n> Regards,\n> ZmnSCPxj\n>\n> > So is it sufficient to give a zk proof of the entire file and not of the\n> individual blocks which are transferred at each iteration? Also does it\n> make sense that you make partial payment per block instead of waiting for\n> the total file to arrive. It might be the case that the zk proof of the\n> total file is correct but then sender might cheat while sending individual\n> block.\n> >\n> > On Tue, Jan 21, 2020, 00:26 Matt Corallo <lf-lists at mattcorallo.com>\n> wrote:\n> >\n> > > Don\u2019t and data in lighting payments unless you have to. It\u2019s super\n> DoS-y and rude to your peers. If you\u2019re just transferring a file, you can\n> use ZKCP to send an encrypted copy of the file with the encryption key\n> being the payment_preimage, making the whole thing one big atomic action.\n> > >\n> > > > On Jan 20, 2020, at 13:33, Subhra Mazumdar <\n> subhra.mazumdar1993 at gmail.com> wrote:\n> > >\n> > > > \ufeff\n> > > > Sounds good. But how do I provide a correctness for the entire asset\n> to be transferred when I am already partitioning into several units (say\n> chunks of file ? ) So as an when the block of file is received then we have\n> to give a ZK proof \"block x is part of File F\". Is it how this should work ?\n> > > >\n> > > > On Mon, Jan 20, 2020 at 11:59 PM Matt Corallo <\n> lf-lists at mattcorallo.com> wrote:\n> > > >\n> > > > > Zk proofs are incredibly fast these days for small-ish programs.\n> They\u2019re much too slow for a consensus system where every party needs to\n> download and validate them, but for relatively simple programs a two-party\n> system using them is very doable.\n> > > > >\n> > > > > > On Jan 20, 2020, at 13:23, Subhra Mazumdar <\n> subhra.mazumdar1993 at gmail.com> wrote:\n> > > > >\n> > > > > > \ufeff\n> > > > > > But isn't it that the use of ZK proof will render the system\n> slow and hence defy the very purpose of lightning network which intends to\n> make things scalable as well as faster transaction ?\n> > > > > >\n> > > > > > On Mon, Jan 20, 2020 at 11:48 PM Matt Corallo <\n> lf-lists at mattcorallo.com> wrote:\n> > > > > >\n> > > > > > > That paper discusses it, but I don't think there was ever a\n> paper proper\n> > > > > > > on ZKCP. There are various discussions of it, though, if you\n> google.\n> > > > > > > Sadly this is common in this space - lots of great ideas where\n> no one\n> > > > > > > ever bothered to write academic-style papers about them (hence\n> why\n> > > > > > > academic papers around Bitcoin tend to miss nearly all\n> relevant context,\n> > > > > > > sadly).\n> > > > > > >\n> > > > > > > Matt\n> > > > > > >\n> > > > > > > On 1/20/20 6:10 PM, Subhra Mazumdar wrote:\n> > > > > > > > Are you referring to the paper Zero knowledge contingent\n> payment\n> > > > > > > > revisited ? I will look into the construction. Thanks for the\n> > > > > > > > information! :)\n> > > > > > > >\n> > > > > > > > On Mon, Jan 20, 2020, 23:31 Matt Corallo <\n> lf-lists at mattcorallo.com\n> > > > > > > > <mailto:lf-lists at mattcorallo.com>> wrote:\n> > > > > > > >\n> > > > > > > >     On 11/9/19 4:31 AM, Takaya Imai wrote:\n> > > > > > > >     > [What I do not describe]\n> > > > > > > >     > * A way to detect that data is correct or not, namely\n> zero knowledge\n> > > > > > > >     > proof process.\n> > > > > > > >\n> > > > > > > >     Have you come across Zero Knowledge Contingent Payments?\n> Originally it\n> > > > > > > >     was designed for on-chain applications but it slots\n> neatly into\n> > > > > > > >     lightning as it only requires a method to lock funds to\n> a hash preimage.\n> > > > > > > >\n> > > > > > > >     Matt\n> > > > > > > >     _______________________________________________\n> > > > > > > >     Lightning-dev mailing list\n> > > > > > > >     Lightning-dev at lists.linuxfoundation.org\n> > > > > > > >     <mailto:Lightning-dev at lists.linuxfoundation.org>\n> > > > > > > >\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> > > > > > > >\n> > > > > >\n> > > > > > --\n> > > > > > Yours sincerely,\n> > > > > > Subhra Mazumdar.\n> > > >\n> > > > --\n> > > > Yours sincerely,\n> > > > Subhra Mazumdar.\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200121/b167ddfe/attachment-0001.html>"
            },
            {
                "author": "Andr\u00e9s G. Aragoneses",
                "date": "2020-01-21T07:37:47",
                "message_text_only": "Hey ZmnSCPxj,\n\nOn Tue, 21 Jan 2020 at 08:47, ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Subhra,\n>\n> Refer to this protocol instead of DLAS:\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-June/002035.html\n> In this protocol, an *encrypted* form of the *entire file* is sent.\n> Consequently, a *single* payment is made, where the payment preimage is\n> the decryption key.\n> Knowing an additional zk proof is necessary to show that the file is\n> indeed encrypted using the decryption key that is the preimage of the given\n> hash (the linked thread has details I believe).\n>\n> Relevantly, there is no need to consider blocks of a file when using the\n> linked protocol instead of DLAS.\n> Of course, a Zk-proof of some property of the entire file, that can be\n> understood by an end-user, may not be possible.\n> Likely, you might want to prove of a video file that a thumbnail of the\n> video file is extracted from a frame of the video, and show that thumbnail\n> to the end-user.\n> Looking at the *rest* of the frames of the video (after you have paid for\n> its decryption) may very reveal them to be frames of a video of Rick Astley\n> singing \"Never Gonna Give You Up\".\n>\n\nI wanted to ask a simple question with regards to the NeverGonnaGiveYouUp\nproblem.\nLet's say you use this technology for a specific use case subset of what\nhas been proposed: the payer wants to exchange bitcoin (via LN) in exchange\nfor some data. The data, in this case, was known by the payer at some point\nin the past, so the payer encrypted it with his own private key, and gave\nit to someone for backup purposes (after that, he gets a hash of the data,\nwhich she keeps, and deletes the data from her end). At some point in the\nfuture, when she wants to retrieve the data, the payee can only supply a\nbunch of bytes whose hash match with the hash that the payer has, therefore\nthe NeverGonnaGiveYouUp problem can't happen here, am I right?\n\nThanks\n\n\n\n> !\n>\n> Regards,\n> ZmnSCPxj\n>\n> > So is it sufficient to give a zk proof of the entire file and not of the\n> individual blocks which are transferred at each iteration? Also does it\n> make sense that you make partial payment per block instead of waiting for\n> the total file to arrive. It might be the case that the zk proof of the\n> total file is correct but then sender might cheat while sending individual\n> block.\n> >\n> > On Tue, Jan 21, 2020, 00:26 Matt Corallo <lf-lists at mattcorallo.com>\n> wrote:\n> >\n> > > Don\u2019t and data in lighting payments unless you have to. It\u2019s super\n> DoS-y and rude to your peers. If you\u2019re just transferring a file, you can\n> use ZKCP to send an encrypted copy of the file with the encryption key\n> being the payment_preimage, making the whole thing one big atomic action.\n> > >\n> > > > On Jan 20, 2020, at 13:33, Subhra Mazumdar <\n> subhra.mazumdar1993 at gmail.com> wrote:\n> > >\n> > > > \ufeff\n> > > > Sounds good. But how do I provide a correctness for the entire asset\n> to be transferred when I am already partitioning into several units (say\n> chunks of file ? ) So as an when the block of file is received then we have\n> to give a ZK proof \"block x is part of File F\". Is it how this should work ?\n> > > >\n> > > > On Mon, Jan 20, 2020 at 11:59 PM Matt Corallo <\n> lf-lists at mattcorallo.com> wrote:\n> > > >\n> > > > > Zk proofs are incredibly fast these days for small-ish programs.\n> They\u2019re much too slow for a consensus system where every party needs to\n> download and validate them, but for relatively simple programs a two-party\n> system using them is very doable.\n> > > > >\n> > > > > > On Jan 20, 2020, at 13:23, Subhra Mazumdar <\n> subhra.mazumdar1993 at gmail.com> wrote:\n> > > > >\n> > > > > > \ufeff\n> > > > > > But isn't it that the use of ZK proof will render the system\n> slow and hence defy the very purpose of lightning network which intends to\n> make things scalable as well as faster transaction ?\n> > > > > >\n> > > > > > On Mon, Jan 20, 2020 at 11:48 PM Matt Corallo <\n> lf-lists at mattcorallo.com> wrote:\n> > > > > >\n> > > > > > > That paper discusses it, but I don't think there was ever a\n> paper proper\n> > > > > > > on ZKCP. There are various discussions of it, though, if you\n> google.\n> > > > > > > Sadly this is common in this space - lots of great ideas where\n> no one\n> > > > > > > ever bothered to write academic-style papers about them (hence\n> why\n> > > > > > > academic papers around Bitcoin tend to miss nearly all\n> relevant context,\n> > > > > > > sadly).\n> > > > > > >\n> > > > > > > Matt\n> > > > > > >\n> > > > > > > On 1/20/20 6:10 PM, Subhra Mazumdar wrote:\n> > > > > > > > Are you referring to the paper Zero knowledge contingent\n> payment\n> > > > > > > > revisited ? I will look into the construction. Thanks for the\n> > > > > > > > information! :)\n> > > > > > > >\n> > > > > > > > On Mon, Jan 20, 2020, 23:31 Matt Corallo <\n> lf-lists at mattcorallo.com\n> > > > > > > > <mailto:lf-lists at mattcorallo.com>> wrote:\n> > > > > > > >\n> > > > > > > >     On 11/9/19 4:31 AM, Takaya Imai wrote:\n> > > > > > > >     > [What I do not describe]\n> > > > > > > >     > * A way to detect that data is correct or not, namely\n> zero knowledge\n> > > > > > > >     > proof process.\n> > > > > > > >\n> > > > > > > >     Have you come across Zero Knowledge Contingent Payments?\n> Originally it\n> > > > > > > >     was designed for on-chain applications but it slots\n> neatly into\n> > > > > > > >     lightning as it only requires a method to lock funds to\n> a hash preimage.\n> > > > > > > >\n> > > > > > > >     Matt\n> > > > > > > >     _______________________________________________\n> > > > > > > >     Lightning-dev mailing list\n> > > > > > > >     Lightning-dev at lists.linuxfoundation.org\n> > > > > > > >     <mailto:Lightning-dev at lists.linuxfoundation.org>\n> > > > > > > >\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> > > > > > > >\n> > > > > >\n> > > > > > --\n> > > > > > Yours sincerely,\n> > > > > > Subhra Mazumdar.\n> > > >\n> > > > --\n> > > > Yours sincerely,\n> > > > Subhra Mazumdar.\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200121/b6c831d6/attachment.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2020-01-21T07:55:43",
                "message_text_only": "Indeed. To go further, anything where the file can be proven correct under a zkSNARK (ie you can write a relatively simple program to do so) does not bear such an issue.\n\n> On Jan 21, 2020, at 02:38, Andr\u00e9s G. Aragoneses <knocte at gmail.com> wrote:\n> \n> \ufeff\n> Hey ZmnSCPxj,\n> \n>> On Tue, 21 Jan 2020 at 08:47, ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n>> Good morning Subhra,\n>> \n>> Refer to this protocol instead of DLAS: https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-June/002035.html\n>> In this protocol, an *encrypted* form of the *entire file* is sent.\n>> Consequently, a *single* payment is made, where the payment preimage is the decryption key.\n>> Knowing an additional zk proof is necessary to show that the file is indeed encrypted using the decryption key that is the preimage of the given hash (the linked thread has details I believe).\n>> \n>> Relevantly, there is no need to consider blocks of a file when using the linked protocol instead of DLAS.\n>> Of course, a Zk-proof of some property of the entire file, that can be understood by an end-user, may not be possible.\n>> Likely, you might want to prove of a video file that a thumbnail of the video file is extracted from a frame of the video, and show that thumbnail to the end-user.\n>> Looking at the *rest* of the frames of the video (after you have paid for its decryption) may very reveal them to be frames of a video of Rick Astley singing \"Never Gonna Give You Up\".\n> \n> I wanted to ask a simple question with regards to the NeverGonnaGiveYouUp problem.\n> Let's say you use this technology for a specific use case subset of what has been proposed: the payer wants to exchange bitcoin (via LN) in exchange for some data. The data, in this case, was known by the payer at some point in the past, so the payer encrypted it with his own private key, and gave it to someone for backup purposes (after that, he gets a hash of the data, which she keeps, and deletes the data from her end). At some point in the future, when she wants to retrieve the data, the payee can only supply a bunch of bytes whose hash match with the hash that the payer has, therefore the NeverGonnaGiveYouUp problem can't happen here, am I right?\n> \n> Thanks\n> \n>  \n>> !\n>> \n>> Regards,\n>> ZmnSCPxj\n>> \n>> > So is it sufficient to give a zk proof of the entire file and not of the individual blocks which are transferred at each iteration? Also does it make sense that you make partial payment per block instead of waiting for the total file to arrive. It might be the case that the zk proof of the total file is correct but then sender might cheat while sending individual block.\n>> >\n>> > On Tue, Jan 21, 2020, 00:26 Matt Corallo <lf-lists at mattcorallo.com> wrote:\n>> >\n>> > > Don\u2019t and data in lighting payments unless you have to. It\u2019s super DoS-y and rude to your peers. If you\u2019re just transferring a file, you can use ZKCP to send an encrypted copy of the file with the encryption key being the payment_preimage, making the whole thing one big atomic action.\n>> > >\n>> > > > On Jan 20, 2020, at 13:33, Subhra Mazumdar <subhra.mazumdar1993 at gmail.com> wrote:\n>> > >\n>> > > > \ufeff\n>> > > > Sounds good. But how do I provide a correctness for the entire asset to be transferred when I am already partitioning into several units (say chunks of file ? ) So as an when the block of file is received then we have to give a ZK proof \"block x is part of File F\". Is it how this should work ?\n>> > > >\n>> > > > On Mon, Jan 20, 2020 at 11:59 PM Matt Corallo <lf-lists at mattcorallo.com> wrote:\n>> > > >\n>> > > > > Zk proofs are incredibly fast these days for small-ish programs. They\u2019re much too slow for a consensus system where every party needs to download and validate them, but for relatively simple programs a two-party system using them is very doable.\n>> > > > >\n>> > > > > > On Jan 20, 2020, at 13:23, Subhra Mazumdar <subhra.mazumdar1993 at gmail.com> wrote:\n>> > > > >\n>> > > > > > \ufeff\n>> > > > > > But isn't it that the use of ZK proof will render the system slow and hence defy the very purpose of lightning network which intends to make things scalable as well as faster transaction ?\n>> > > > > >\n>> > > > > > On Mon, Jan 20, 2020 at 11:48 PM Matt Corallo <lf-lists at mattcorallo.com> wrote:\n>> > > > > >\n>> > > > > > > That paper discusses it, but I don't think there was ever a paper proper\n>> > > > > > > on ZKCP. There are various discussions of it, though, if you google.\n>> > > > > > > Sadly this is common in this space - lots of great ideas where no one\n>> > > > > > > ever bothered to write academic-style papers about them (hence why\n>> > > > > > > academic papers around Bitcoin tend to miss nearly all relevant context,\n>> > > > > > > sadly).\n>> > > > > > >\n>> > > > > > > Matt\n>> > > > > > >\n>> > > > > > > On 1/20/20 6:10 PM, Subhra Mazumdar wrote:\n>> > > > > > > > Are you referring to the paper Zero knowledge contingent payment\n>> > > > > > > > revisited ? I will look into the construction. Thanks for the\n>> > > > > > > > information! :)\n>> > > > > > > >\n>> > > > > > > > On Mon, Jan 20, 2020, 23:31 Matt Corallo <lf-lists at mattcorallo.com\n>> > > > > > > > <mailto:lf-lists at mattcorallo.com>> wrote:\n>> > > > > > > >\n>> > > > > > > >     On 11/9/19 4:31 AM, Takaya Imai wrote:\n>> > > > > > > >     > [What I do not describe]\n>> > > > > > > >     > * A way to detect that data is correct or not, namely zero knowledge\n>> > > > > > > >     > proof process.\n>> > > > > > > >\n>> > > > > > > >     Have you come across Zero Knowledge Contingent Payments? Originally it\n>> > > > > > > >     was designed for on-chain applications but it slots neatly into\n>> > > > > > > >     lightning as it only requires a method to lock funds to a hash preimage.\n>> > > > > > > >\n>> > > > > > > >     Matt\n>> > > > > > > >     _______________________________________________\n>> > > > > > > >     Lightning-dev mailing list\n>> > > > > > > >     Lightning-dev at lists.linuxfoundation.org\n>> > > > > > > >     <mailto:Lightning-dev at lists.linuxfoundation.org>\n>> > > > > > > >     https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>> > > > > > > >\n>> > > > > >\n>> > > > > > --\n>> > > > > > Yours sincerely,\n>> > > > > > Subhra Mazumdar.\n>> > > >\n>> > > > --\n>> > > > Yours sincerely,\n>> > > > Subhra Mazumdar.\n>> \n>> \n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200121/0df0e90c/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Data Lightning Atomic Swap (DLAS-down, DLAS-up)",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Matt Corallo",
                "Andr\u00e9s G. Aragoneses",
                "Takaya Imai",
                "Subhra Mazumdar",
                "ZmnSCPxj"
            ],
            "messages_count": 16,
            "total_messages_chars_count": 73576
        }
    },
    {
        "title": "[Lightning-dev] Lightning Spec Meeting 2020/01/20",
        "thread_messages": [
            {
                "author": "Christian Decker",
                "date": "2020-01-17T15:02:09",
                "message_text_only": "Dear Fellow Protocol Devs,\n\nour next meeting is this Monday (2020/01/20) and I thought I'd try to\nfollow up on my new years resolution to add some more structure to the\nspec meetings. I drafted an agenda for Monday [1], hoping to give\neverybody a couple of days before the meeting to get up to speed with\nthe open Issues and Pull Requests that are going to be discussed. My\nhope is that this speeds up the actual process of agreeing or discarding\nindividual proposals, and keep the short time we can meet as productive\nas possible.\n\nI kept the list of Issues and PRs short on purpose, to allow a good\ndiscussion, and reduce the ACK / NACK slog to a minimum. In addition I\nadded a couple of items for longer term discussions.\n\nThis week @niftynei and @t-bast have agreed to give a short status\nupdate on the dual-funding and the trampoline proposals respectively. I\nthink we could add a discussion of research results to future meetings,\nto balance both short-term and long-term goals.\n\nThe document is a tentative agenda, so if there's something missing that\nshould be discussed, or you think is urgent, please let me know as a\ncomment in the document or here. However keep in mind that issues or PRs\non the agenda should be actionable (not require more than ~5 minutes of\ndiscussion) :-)\n\nCheers,\nChristian\n\n[1] https://paper.dropbox.com/doc/Lightning-Spec-Meeting-20200120--AskYSrKxdj_MThuRPYLTRRhYAQ-SA160p27VepiVZcnbKcZE"
            }
        ],
        "thread_summary": {
            "title": "Lightning Spec Meeting 2020/01/20",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Decker"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1424
        }
    },
    {
        "title": "[Lightning-dev] Decoy node_ids and short_channel_ids",
        "thread_messages": [
            {
                "author": "Bastien TEINTURIER",
                "date": "2020-01-20T16:44:53",
                "message_text_only": "Good morning list,\n\nI'd like to explore some enhancements for unannounced (sometimes called\nprivate) channels.\nUnannounced channels are really useful for mobile nodes that won't be\nonline often enough to route\npayments. That does leak information to your channel peer, but that's a\ntopic for another post.\n\nOne of the nice properties of unannounced channels is that they help break\nlinkability between\non-chain and off-chain payments (because only your channel peer knows the\nlink between your\n`funding_key`, your on-chain UTXOs and your `node_id`).\n\nHowever the current implementation is broken: invoices leak both your\n`node_id` and\n`short_channel_id` (via the signature and Bolt 11 routing hints [1]).\nIt doesn't have to be like this though; invoices don't always require you\nto use your real\n`short_channel_id` nor your real `node_id`.\n\nLet's set the scene:\n\n* Alice is our mobile wallet user\n* Bob is a normal lightning node connected to Alice via an unannounced\nchannel\n* Carol wants to pay Alice via Bolt 11 invoices\n\nThere is already a first proposal to fix this problem [2], with the\nfollowing trade-offs:\n\n(-) Adds a new stateful protocol (with new messages) between Alice and Bob\n(-) Can't use a unique `short_channel_id` for every invoice\n(+) Carol doesn't need to change anything from the existing flow\n\nI'd like to propose an alternative design with the following, different\ntrade-offs:\n\n(+) No state to synchronize between Alice and Bob\n(+) Can use unique `short_channel_id`s and `node_id`s for each invoice\n(-) But Carol needs to add a new record in the onion (probably needs a\nfeature bit)\n\n## Decoy `node_id`s\n\nAlice currently signs all invoices with the private key associated to her\n`node_id`.\nThis makes sense when Alice wants to be reached via public channels, but it\nisn't used at all when\nAlice provides routing hints. In that case she can generate a one-time\nprivate key and sign the\ninvoice with it. This way Alice doesn't leak her real `node_id` to payers.\n\n## Decoy `short_channel_id`s\n\nHere is a simple construction for generating a `decoy_short_channel_id`:\n\n* Alice draws a random `invoice_key`\n* Alice computes the corresponding public key: `P_I = invoice_key * G`\n* Alice computes `decoy_short_channel_id = H(invoice_key * bob_node_id) xor\nshort_channel_id`\n* Alice provides a routing hint using `decoy_short_channel_id` in the\ninvoice\n* Alice provides `P_I` in the invoice\n\nNow when Carol wants to pay, she has to include `P_I` in the onion payload\nfor Bob.\nWhen Bob receives the HTLC, he can compute `short_channel_id =\nH(bob_private_key * P_I) xor decoy_short_channel_id`.\nThat allows Bob to correctly forward the payment to Alice without any prior\nnegotiation.\n\n## Improvements\n\nThe two main drawbacks of this scheme are:\n\n1. It uses 33 bytes in the invoice\n2. It uses 33 bytes in the onion payload for Bob\n\nWe can easily get rid of (1.) by leveraging the `payment_secret`. The\nimproved scheme is:\n\n* Alice draws a random `decoy_key`\n* Alice computes the corresponding `decoy_node_id = decoy_key * G`\n* Alice draws a random `payment_secret`\n* Alice computes `decoy_short_channel_id = H(payment_secret * decoy_key *\nbob_node_id) xor short_channel_id`\n* Alice uses the `decoy_key` to sign the invoice\n* Carol recovers `decoy_node_id` from the invoice signature\n* Carol includes `P_I = payment_secret * decoy_node_id` in the onion\npayload for Bob\n* Bob can compute `short_channel_id = H(bob_private_key * P_I) xor\ndecoy_short_channel_id`\n\nBut I don't see how to get rid of (2.). If anyone has a clever idea on how\nto do that, I'd love to hear it!\n\nThese constructions definitely need more eyes on them; I don't see anything\nobviously broken, but\nneither did the designers of PKCS #1 until Bleichenbacher ruined the party\n[3].\n\nThank you for reading,\nBastien\n\n[1]\nhttps://github.com/lightningnetwork/lightning-rfc/blob/master/11-payment-encoding.md#tagged-fields\n[2] https://github.com/lightningnetwork/lightning-rfc/pull/681\n[3] http://archiv.infsec.ethz.ch/education/fs08/secsem/bleichenbacher98.pdf\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200120/f54dc2eb/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Decoy node_ids and short_channel_ids",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Bastien TEINTURIER"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4219
        }
    },
    {
        "title": "[Lightning-dev] Layered commitments with eltoo",
        "thread_messages": [
            {
                "author": "Anthony Towns",
                "date": "2020-01-21T08:20:18",
                "message_text_only": "Hi all,\n\nAt present, BOLT-3 commitment transactions provide a two-layer\npay-to-self path, so that you can reduce the three options:\n\n  1) pay-to-them due to revoked commitment\n  2) pay-to-me due to timeout (or: preimage known)\n  3) pay-to-them due to preimage known (or: timeout)\n\nto just the two options:\n\n  1) pay-to-them due to revoked commitment\n  2) pay-to-me due to timeout (or: preimage known)\n\nThis allows the `to_self_delay` and the HTLC timeout (and hence the\n`cltv_expiry_delta`) to be chosen independently.\n\nAs it stands, both the original eltoo proposal [0] and the\nANYPREVOUT-based sketch [1] don't have this property, which means that\neither the `cltv_expiry_delta` needs to take the `to_self_delay` into\naccount, or you risk not being able to claim funds to cover payments\nyou forward.\n\n[0] https://blockstream.com/eltoo.pdf\n[1] https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-May/001996.html\n\nI think if we drop the commitment to the input value from\nANYPREVOUTANYSCRIPT signatures, it's possible to come up with a scheme\nthat preserves the other benefits of eltoo while also having the same\nbenefits BOLT-3 currently achieves. I think for eltoo it needs to be a\nchannel-wide \"shared_delay\" rather than a \"to_self\" delay, so I'll use\nthat.\n\nHere's the setup. We have four types of transaction:\n\n * funding transaction, posted on-chain as part of channel setup\n * update transaction, posted on-chain to close the channel at a\n   given state\n * revocable claim transaction, posted on-chain to reveal a preimage\n   or establish a timeout has passed\n * settlement transaction, to actually claim funds\n\nAs with eltoo, if a stale update transaction is posted, it can be spent\nvia any subsequent update transaction with no penalty. The revocable\nclaim transactions have roughly the same goal as the second layer BOLT-3\ntransactions, that is going from:\n\n  1) spent by a later update transaction\n  2) pay-to-me due to timeout (or: preimage known)\n  3) pay-to-them due to preimage known (or: timeout)\n\nto\n\n  1) spent by a later update transaction\n  2) pay-to-me due to timeout (or: preimage known)\n\nIn detail:\n\n * Get a pubkey from each peer (A, B), and calculate P=MuSig(A,B).\n\n * Each state update involves constructing and calculating signatures\n   for new update transactions, revocable claim transactions and\n   settlement transactions.\n\n * The update transaction has k+2 outputs, where k is the number of open\n   PTLCs. Each PTLC output pays to P as the internal key, and:\n\n     IF CODESEP [i] ELSE [500e6+n+1] CLTV ENDIF DROP OP_1 CHECKSIG\n\n   as the script. i varies from 1..k; n is the state counter, starting\n   at 1 and counting up.\n\n   Each balance output pays to P as the internal key and:\n\n     IF CODESEP IF [balance_pubkey_n] [shared_delay] CSV ELSE OP_1 OP_0 ENDIF\n     ELSE OP_1 [500e6+n+1] CLTV ENDIF \n     DROP CHECKSIG\n\n   as the script.\n\n   The signature that allows an update tx to spend a previous update tx\n   is calculated using ALL|ANYPREVOUTANYSCRIPT, a locktime of 500e6+n,\n   with the key P, and codesep_pos=0xffff_ffff.\n\n * For each output of the update tx and each party that can spend it,\n   we also construct a revocable claim transaction. These are designed\n   to update a single output of each PTLC, and their output pays to P\n   as the internal key, and the script:\n\n     IF [i*P+p] CODESEP ELSE [500e6+n+1] CLTV ENDIF DROP OP_1 CHECKSIG\n\n   (swapping the position of the CODESEP opcode, and encoding both i and\n   p in the script -- P is the number of peers in the channel, so 2\n   here, and p is an identifier for each peer so either 0 or 1; i=1..k\n   for HTLCs, i=0 for the balances)\n\n   The signature that allows this tx to be applied to the update tx\n   is calculated as SINGLE|ANYPREVOUT, with the script committed and\n   codesep_pos=1. This signature should be made conditional for each\n   PTLC, either by being an adaptor signature requiring the point preimage\n   to be added, or by having a locktime given.\n\n * For each revocable claim transaction, we also construct a settlement\n   transaction. The outputs of the settlement transactions are just\n   an address for whichever peer receives the funds.\n\n   These are also done by SINGLE|ANYPREVOUT signatures, with nSequence\n   set to the shared_delay. There's no locktime or adaptor signatures\n   needed here, since they were taken care of for the revocable claim\n   transaction.  The signatures commit to the respective scripts, and\n   set codesep_pos to either 1 or 2 depending on whether a revocable\n   claim is being spent or not.\n\n * The funding transaction pays to internal key P, with tapscript:\n\n     \"OP_1 CHECKSIGVERIFY 500e6 CLTV\"\n\nThen: to spend from the funding transaction cooperatively, you make a\nnew SIGHASH_ALL signature based the output key Q for the funding tx.\n\nIf you can't do that, you post two transactions: the latest update tx,\nand another tx that includes any revocable claim tx's you can already\nclaim and an input to cover fees, and any change from the fees. You then\nwait for the shared_delay to pass, and can then use the settlement txs\nto finish claiming the funds, and do whatever you like afterwards.\n\nIf someone else posts an update tx, and you have a later one, then\nyou construct a new update tx, with an input for each unspent output\n(whether directly from the update tx, or from a revocable claim tx),\nwith the witness for each being the update tx's ANYPREVOUTANYSCRIPT\nsignature (and a \"0\" to choose the right path of the IF). You then post\nthat, and another tx that includes your revocable claims txs and pays\nthe fees, and continue as before.\n\nIf someone else posts the latest update tx, you can post any revocable\nclaims you have to lock those funds in, then need to just wait for the\nshared_delay to pass, so that you can claim your balance and post and\nsettlement txs you have. If you'd had a bad crash and lost the current\nchannel state, you can work out which output is your balance, and claim\nit using just your private key, however you'll lose any PTLCs you may\nhave otherwise been able to claim.\n\nThere's \"only\" 1+2*(P+2*k) signatures that need to be calculated for\neach state -- 1 for the update transaction, and 2 (revocable commit and\nsettlement) for each of the P balances and both of the ways (preimage\nreveal and timeout) each of the k PTLCs can be claimed.\n\n\nI think you can distinguish each signature so it's only used for the\nappropriate transaction,\n\n -> update sig has codesep_pos=0xffff_ffff which forces the CLTV path\n    to be taken, and nLockTime set so it's only valid for earlier\n    updates' scripts\n\n -> revocable claim sig has codesep_pos=1 and commits to the script\n    which encodes by the state n and either the HTLC index i, or the\n    balance's owner's pubkey\n\n -> settlement sig has codesep_pos=2 and commits to the script, which\n    encodes the state n, the HTLC index i, and the peer who claimed the\n    funds\n\nThis doesn't work well with HTLCs because you'd need to encode the HTLC\nin script, which means you need to keep a record of every HTLC hash in\ncase it appears in an old published update tx that you want to update\nto a new update transaction. I think more generally it's only compatible\nwith contracts that can be encoded in a scriptless script, as otherwise\nyou'd need to remember the contract details in perpetuity in case an old\nstate was published that you needed to update. I think deferring the\ncontract details to settlement would solve the revocable part of the\nproblem, but would bring back the delay/locktime conflict so doesn't\nseem helpful.\n\nThis should work fine with the \"A CHECKSIGVERIFY B CHECKSIG\" alternate\nscripts mentioned in [2] for shortcutting roundtrips, though having more\nthan one script path would make every uncooperative close more expensive\nthan only having one script path.\n\n[2] https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-December/002385.html\n\nI think this construction generalises fine to multiparty channels,\nthough maybe there are cheaper ones for two-party channels which might\nbe worth optimising for. I think the obvious optimisations to two-party\nchannels fail if you bring in untrusted watchtowers -- though that might\nbe fixable if you make it so watchtowers get signatures that apply\nagainst earlier update tx's but not the funding tx -- I think that'd\njust require calculating an extra signature per state.\n\nIt's a pretty artificial structure all round, so definitely gives away\nthat eltoo is in use as soon as an uncooperative close starts, and\nalso gives away the number of participants in the channel (because the\nbalance outputs are distinguishable in order to allow balance recovery\nafter loss of state info).\n\n\nThis all only works if ANYPREVOUTANYSCRIPT doesn't commit to the value of\nthe input -- otherwise reusing the single \"update\" signature won't allow\nyou to collect every revocable claim tx output back to redistribute all\ntheir funds correctly. That's a significant change to NOINPUT/BIP 118 as\nit stands.\n\nCheers,\naj"
            }
        ],
        "thread_summary": {
            "title": "Layered commitments with eltoo",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Anthony Towns"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 8999
        }
    },
    {
        "title": "[Lightning-dev] [PATCH] First draft of option_simplfied_commitment",
        "thread_messages": [
            {
                "author": "Joost Jager",
                "date": "2020-01-22T07:41:26",
                "message_text_only": ">\n> By my calculations, at minfee it will cost you ~94 satoshis to spend.\n> Dust limit is 294 for Segwit outputs (basically assuming 3x minfee).\n>\n\n> So I'm actually happy to say \"anchor outputs are 294 satoshi\".  These\n> are simply spendable, and still only $3 each if BTC is $1M.  Lower is\n> better (as long as we stick with funder-pays), as long as they do\n> eventually get spent.\n>\n\nQuick note here: the anchor outputs are P2WSH and for those the default\ndust limit is 330 satoshis.\n\nJoost\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200122/f4561bd1/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "First draft of option_simplfied_commitment",
            "categories": [
                "Lightning-dev",
                "PATCH"
            ],
            "authors": [
                "Joost Jager"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 678
        }
    },
    {
        "title": "[Lightning-dev] Reduce the amount of collateral locked by scripts for transferring funds in lightning network",
        "thread_messages": [
            {
                "author": "Subhra Mazumdar",
                "date": "2020-01-25T14:06:37",
                "message_text_only": "Hi,\n     I was wondering when parties apply condition on fraction of channel\nfund for ensuring successful payment, entire channel fund is held. Is it\npossible to lock just partial amount of fund of a payment channel and leave\nthe rest to be used by some another payment request ? Concept of\nsubchannels of a single channel has been suggested in \"Atomic multi-channel\nupdates with constant collateral in bitcoin-compatible payment-channel\nnetworks\"\nhttps://scholar.google.com/scholar?cluster=40566801298747858&hl=en&as_sdt=2005&sciodt=0,5\nbut I am still in doubt what happens during closing of subchannel ?\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200125/7db6f203/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-27T00:45:13",
                "message_text_only": "Good morning Subhra,\n\nThis does not seem to make sense?\nFor a payment that is less than the channel funds on your side, only that amount is locked behind an HTLC, and the rest remains useable for other HTLCs.\n\nWhat exactly are you referring to?\n\nRegards,\nZmnSCPxj\n\n> Hi,\n> \u00a0\u00a0\u00a0\u00a0 I was wondering when parties apply condition on fraction of channel fund for ensuring successful payment, entire channel fund is held. Is it possible to lock just partial amount of fund of a payment channel and leave the rest to be used by some another payment request ? Concept of subchannels of a single channel has been suggested in \"Atomic multi-channel updates with constant collateral in bitcoin-compatible payment-channel networks\"\u00a0 https://scholar.google.com/scholar?cluster=40566801298747858&hl=en&as_sdt=2005&sciodt=0,5 but I am still in doubt what happens during closing of subchannel ?\n> --\n> Yours sincerely,\n> Subhra Mazumdar."
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-01-27T04:23:16",
                "message_text_only": "Hi ZmnSCPxj,\n      It is stated in the paper \"Atomic multi-channel updates with constant\ncollateral in bitcoin-compatible payment-channel networks\" and I am quoting\nverbatim (page 11) (last email still waiting moderator approval) \"Phase I:\nSetup. The first phase requires to freeze the coins available at each\nchannel involved in the protocol. Doing this naively (i.e., locking the\ncomplete balance in the channel at once) would lock more coins than\nrequired, unnecessarily increasing the collateral in the protocol. Instead,\nduring the setup phase, the balance at each payment channel is split in\ntwo, effectively creating thereby two sub-channels: one sub-channel is set\nwith the coins required for the present protocol session, while the other\none is set with the\nremaining coins, which can then be freely spent. In the illustrative\nexample shown in Figure 4.2, the setup phase starts with the user A\ncollaborating with user B to create the transaction Tx A\nsetup , where they split the 10 coins they have in the channel in two\nsub-channels: one sub-channel with 8 coins to be used in the rest of the\nprotocol session and one sub-channel with the rest (i.e., 2 coins). This\ntransaction is signed by both users so that it can be eventually enforced\non-chain if required. The rest of the users behave analogously. Note that\noperations at each channel in this phase of the protocol can be carried out\nin parallel.\" Does this sound good ?\n\nOn Mon, Jan 27, 2020 at 9:41 AM Subhra Mazumdar <\nsubhra.mazumdar1993 at gmail.com> wrote:\n\n> Hi ZmnSCPxj,\n>        It is stated in the paper \"Atomic multi-channel updates with\n> constant collateral in bitcoin-compatible payment-channel networks\". I am\n> attaching the screenshot of the paragraph which mentions about locking the\n> amount which is required for payment transfer and not the entire channel\n> fund.\n>\n> On Mon, Jan 27, 2020 at 6:15 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n>> Good morning Subhra,\n>>\n>> This does not seem to make sense?\n>> For a payment that is less than the channel funds on your side, only that\n>> amount is locked behind an HTLC, and the rest remains useable for other\n>> HTLCs.\n>>\n>> What exactly are you referring to?\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>> > Hi,\n>> >      I was wondering when parties apply condition on fraction of\n>> channel fund for ensuring successful payment, entire channel fund is held.\n>> Is it possible to lock just partial amount of fund of a payment channel and\n>> leave the rest to be used by some another payment request ? Concept of\n>> subchannels of a single channel has been suggested in \"Atomic multi-channel\n>> updates with constant collateral in bitcoin-compatible payment-channel\n>> networks\"\n>> https://scholar.google.com/scholar?cluster=40566801298747858&hl=en&as_sdt=2005&sciodt=0,5\n>> but I am still in doubt what happens during closing of subchannel ?\n>> > --\n>> > Yours sincerely,\n>> > Subhra Mazumdar.\n>>\n>>\n>>\n>\n> --\n> Yours sincerely,\n> Subhra Mazumdar.\n>\n>\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200127/b8248846/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-27T15:10:24",
                "message_text_only": "Good morning Subhra,\n\nThe paper does not describe how Lightning works today, so I was confused.\nIt seems to claim to have a constant *lock time*, but still a decrementing *amount*, across the entire payment attempt.\nIn any case: any offchain updateable cryptocurrency system can host any contract that the hosting cryptocurrency system can host, including instances of itself.\n\nTo be a little clear, here is how I view a class hierarchy of cryptocurrency systems.\n\n    abstract class CryptocurrencySystem { ... };\n    final class Blockchain : public CryptocurrencySystem {\n    public:\n        /* A blockchain requires the laws of physics in order to work.  */\n        Blockchain(LawsOfPhysics);\n        ...\n    };\n    abstract class OffchainCryptocurrencySystem : public CryptocurrencySystem {\n    public:\n        /* An offchain cryptocurrency system requires a pre-existing\n         * cryptocurrency system in order to work.\n         */\n        OffchainCryptocurrencySystem(CryptocurrencySystem);\n        ...\n    };\n    final class PoonDryja : public OffchainCryptocurrencySystem {\n    public:\n        /* The Lightning Network Poon-Dryja mechanism is an offchain\n         * cryptocurrency system.\n         */\n        PoonDryja(CryptocurrencySystem host) : OffchainCryptocurrencySystem(host) { ... }\n        ...\n    };\n\nOf note is that the construction of an `OffchainCryptocurrencySystem` aka \"payment channel\" does *not* require a `Blockchain`!\nIt requires any `CryptocurrencySystem`.\nWhile the only `CryptocurrencySystem` that needs only a real world in order to instantiate it, is a `Blockchain`, an `OffchainCryptocurrencySystem` is itself a `CryptocurrencySystem` that can be used to instantiate another `OffchainCryptocurrencySystem`.\n\nSo, the base technique used by the AMCU paper is to realize that, from a payment channel (aka `OffchainCryptocurrencySystem`) it can instantiate *two* inner payment channels.\nSo something like this:\n\n     void amcu_algorithm(OffchainCryptocurrencySystem channel) {\n         OffchainCryptocurrencySystem subchannel1 = new OffchainCryptocurrencySystem(channel);\n         OffchainCryptocurrencySystem subchannel2 = new OffchainCryptocurrencySystem(channel);\n         ...\n     }\n\nThis is doable in any offchain cryptocurrency system (though is not currently coded in any Lightning Network implementation, because maintenance issues).\nSee also: https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-December/001721.html\n\nHow does it \"close\" a sub-channel?\nWell, how do you \"claim\" an HTLC or \"fail\" an HTLC inside an existing Lightning Network payment channel?\nBasically, the participants in the offchain updateable cryptocurrency system decide according to the rules of the protocol, in a way that is also consistent with the rules of the hosting cryptocurrency system (in the case of LN, the Bitcoin blockchain).\nFor example, in Lightning, in order to \"claim\" an HTLC, the participant with the ability to claim that HTLC must present the preimage corresponding to the hash indicated in the contract.\nThen the participants check that the rules have been followed, then update the channel state to remove the HTLC and put the money that used to be in the HTLC into the fund of who claimed it.\n\nSimilarly, if you have a super-channel containing a sub-channel, and want to \"close\" the sub-channel, what do you do?\nClosing the sub-channel requires particular protocol rules to be followed, culminating in a transaction that spends the fund of the sub-channel to whatever set of contracts was agreed to be the latest channel state.\nThen, that transaction is presented to the participants in the super-channel, who validate that it is indeed a valid spending of the sub-channel funds, then agree to update the channel state, removing the sub-channel funds and re-assigning it to the outputs of the latest channel state of the sub-channel.\n\nMore concretely. suppose we have:\n\n    channel the_super_channel:\n        1 Bitcoin -> ZmnSCPxj\n        1 Bitcoin -> Subhra\n        2 Bitcoin -> channel the_sub_channel (ZmnSCPxj && Subhra)\n    channel the_sub_channel:\n        1 Bitcoin -> HTLC(H=ZmnSCPxj hash=XXXXX,T=Subhra timelock=615021)\n        1 Bitcoin -> Subhra\n\nThen to close the inner channel, what happens is then all the participants in the super-channel agree to update to this new state:\n\n    channel the_super_channel:\n        1 Bitcoin -> ZmnSCPxj\n        1 Bitcoin -> Subhra\n        1 Bitcoin -> HTLC(H=ZmnSCPxj hash=XXXXX,T=Subhra timelock=615021)\n        1 Bitcoin -> Subhra\n\n(As an optimization, they could merge the two \"Subhra\" outputs together into a single 2 Bitcoin output, which is what is automatically done by Lightning for HTLC claims and fails.)\n\nHow are sub-channels created?\nBy whatever was agreed upon by the participants of the channel.\nFor example, suppose ZmnSCPxj propose to make a sub-channel of its own funds in a new sub-channel.\nThen the total state becomes:\n\n    channel the_super_channel:\n        1 Bitcoin -> channel the_new_sub_channel (ZmnSCPxj && Subhra)\n        1 Bitcoin -> Subhra\n        1 Bitcoin -> HTLC(H=ZmnSCPxj hash=XXXXX,T=Subhra timelock=615021)\n        1 Bitcoin -> Subhra\n    channel the_new_sub_channel:\n        1 Bitcoin -> ZmnSCPxj\n\nOr, from another point-of-view: offchain updateable cryptocurrency systems implement a cut-through mechanism.\nIn principle, presenting a transaction to the participants of the offchain updateable cryptocurrency system, that can validly spend one or more outputs of the current state of the system (and does not consume any coins outside of the system), should be enough to convince the participants to delete those spent outputs and replace it with the outputs of that transaction in the next state of the offchain cryptocurrency system.\n(This is not done in Lightning simply because sending smaller pieces of data containing just the essential parts of the transactions that *would* have fulfilled the HTLCs is cheaper than sending entire transactions through.\nNot to mention having to embed a SCRIPT interpreter in our codebases would be ***HORRID***.)\nAnd a transaction which spends some output to create a payment channel is just another transaction that such a system can process according to the rules of the hosting cryptocurrency system.\nSimilarly, a transaction which formalizes the closure of a payment channel is just another transaction, which represents a change in the state of the cryptocurrency system.\n\nOne might consider that cryptocurrency systems basically allow the creation and destruction of UTXOs.\nThus, both blockchains and payment channels are cryptocurrency systems.\nThe difference is that blockchains allow safely storing coins held by anyone, whereas payment channels can only safely store coins held by the participants of the channel (because it is an n-of-n federation where *you* the user is a member of that federation: see https://zmnscpxj.github.io/offchain/safety.html).\n\nConversely, I think the measuring-stick for the AMCU technique is that it should be possible to do it onchain to implement a multi-participant CoinSwap, because in principle a channel is just a cryptocurrency system and a blockchain is one as well.\n\nIn any case, from a skim of the AMCU paper, it looks like all the intermediate hops *need* to validate that all the *other* intermediate hops follow the protocol, by presenting all the transactions involved.\nThis probably implies that all the intermediate hops know the entire route, and thus who the ultimate sender and receiver are, thus utterly bad for privacy.\nHopefully my reading is wrong, or this is fixable, but if neither, it is unlikely to be used in Lightning.\n\nRegards,\nZmnSCPxj\n\n> Hi ZmnSCPxj,\n> \u00a0\u00a0\u00a0\u00a0\u00a0 It is stated in the paper \"Atomic multi-channel updates with constant collateral in bitcoin-compatible payment-channel networks\" and I am quoting verbatim (page 11) (last email still waiting moderator approval) \"Phase I: Setup. The first phase requires to freeze the coins available at each channel involved in the protocol. Doing this naively (i.e., locking the complete balance in the channel at once) would lock more coins than required, unnecessarily increasing the collateral in the protocol. Instead, during the setup phase, the balance at each payment channel is split in two, effectively creating thereby two sub-channels: one sub-channel is set with the coins required for the present protocol session, while the other one is set with the\n> remaining coins, which can then be freely spent. In the illustrative example shown in Figure 4.2, the setup phase starts with the user A collaborating with user B to create the transaction Tx A\n> setup , where they split the 10 coins they have in the channel in two sub-channels: one sub-channel with 8 coins to be used in the rest of the protocol session and one sub-channel with the rest (i.e., 2 coins). This transaction is signed by both users so that it can be eventually enforced on-chain if required. The rest of the users behave analogously. Note that operations at each channel in this phase of the protocol can be carried out in parallel.\" Does this sound good ?\n>\n> On Mon, Jan 27, 2020 at 9:41 AM Subhra Mazumdar <subhra.mazumdar1993 at gmail.com> wrote:\n>\n> > Hi ZmnSCPxj,\n> > \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 It is stated in the paper \"Atomic multi-channel updates with constant collateral in bitcoin-compatible payment-channel networks\". I am attaching the screenshot of the paragraph which mentions about locking the amount which is required for payment transfer and not the entire channel fund.\n> >\n> > On Mon, Jan 27, 2020 at 6:15 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n> >\n> > > Good morning Subhra,\n> > >\n> > > This does not seem to make sense?\n> > > For a payment that is less than the channel funds on your side, only that amount is locked behind an HTLC, and the rest remains useable for other HTLCs.\n> > >\n> > > What exactly are you referring to?\n> > >\n> > > Regards,\n> > > ZmnSCPxj\n> > >\n> > > > Hi,\n> > > > \u00a0\u00a0\u00a0\u00a0 I was wondering when parties apply condition on fraction of channel fund for ensuring successful payment, entire channel fund is held. Is it possible to lock just partial amount of fund of a payment channel and leave the rest to be used by some another payment request ? Concept of subchannels of a single channel has been suggested in \"Atomic multi-channel updates with constant collateral in bitcoin-compatible payment-channel networks\"\u00a0 https://scholar.google.com/scholar?cluster=40566801298747858&hl=en&as_sdt=2005&sciodt=0,5 but I am still in doubt what happens during closing of subchannel ?\n> > > > --\n> > > > Yours sincerely,\n> > > > Subhra Mazumdar.\n> >\n> > --\n> > Yours sincerely,\n> > Subhra Mazumdar.\n>\n> --\n> Yours sincerely,\n> Subhra Mazumdar."
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-01-28T05:24:27",
                "message_text_only": "Good Morning.\nYes it is stated that relationship anonymity gets violated.\nThis probably implies that all the intermediate hops know the entire route,\nand thus who the ultimate sender and receiver are, thus utterly bad for\nprivacy. Hopefully my reading is wrong, or this is fixable, but if neither,\nit is unlikely to be used in Lightning. - As stated under accountability\n\"Accountability. The AMCU sacrifices strong privacy guarantees such as\nrelationship anonymity [22] to achieve not only atomicity and reduced\ncollateral but also a notion of accountability. In particular, if\nin any of the protocol phases one of the users reports a failure instead of\nsuccess, the protocol allows the\nblaming user to provide a proof of misbehavior. In a nutshell, provided\nthat all users have agreed on the set\nof addresses composing the channels set as protocol inputs, the steps of\nthe protocol are deterministically\ndefined. Thus, at each step a user can blame the channel counterparty if it\ndoes not provide the signature for\nthe transaction created at that phase. Note that the counterparty can also\nshow that she was falsely blamed by\nactually providing the missing signature. In this case, the protocol can\ncontinue to the following phase.\"\nReference [22] - Giulio Malavolta, Pedro Moreno-Sanchez, Aniket Kate,\nMatteo Maffei, and Srivatsan Ravi. Concurrency\nand privacy with payment-channel networks. In Bhavani M. Thuraisingham,\nDavid Evans, Tal Malkin,\nand Dongyan Xu, editors, ACM CCS 17: 24th Conference on Computer and\nCommunications Security,\npages 455\u2013471. ACM Press, October / November 2017.\n\nConversely, I think the measuring-stick for the AMCU technique is that it\nshould be possible to do it onchain to implement a multi-participant\nCoinSwap, because in principle a channel is just a cryptocurrency system\nand a blockchain is one as well.\n\n> Can you state in details how would  amultiparticipant CoinSwap behave ?\n>\n\n\nThe paper does not describe how Lightning works today, so I was confused.\n> It seems to claim to have a constant *lock time*, but still a decrementing\n> *amount*, across the entire payment attempt.\n> In any case: any offchain updateable cryptocurrency system can host any\n> contract that the hosting cryptocurrency system can host, including\n> instances of itself.\n>\n> To be a little clear, here is how I view a class hierarchy of\n> cryptocurrency systems.\n>\n>     abstract class CryptocurrencySystem { ... };\n>     final class Blockchain : public CryptocurrencySystem {\n>     public:\n>         /* A blockchain requires the laws of physics in order to work.  */\n>         Blockchain(LawsOfPhysics);\n>         ...\n>     };\n>     abstract class OffchainCryptocurrencySystem : public\n> CryptocurrencySystem {\n>     public:\n>         /* An offchain cryptocurrency system requires a pre-existing\n>          * cryptocurrency system in order to work.\n>          */\n>         OffchainCryptocurrencySystem(CryptocurrencySystem);\n>         ...\n>     };\n>     final class PoonDryja : public OffchainCryptocurrencySystem {\n>     public:\n>         /* The Lightning Network Poon-Dryja mechanism is an offchain\n>          * cryptocurrency system.\n>          */\n>         PoonDryja(CryptocurrencySystem host) :\n> OffchainCryptocurrencySystem(host) { ... }\n>         ...\n>     };\n>\n> Of note is that the construction of an `OffchainCryptocurrencySystem` aka\n> \"payment channel\" does *not* require a `Blockchain`!\n> It requires any `CryptocurrencySystem`.\n> While the only `CryptocurrencySystem` that needs only a real world in\n> order to instantiate it, is a `Blockchain`, an\n> `OffchainCryptocurrencySystem` is itself a `CryptocurrencySystem` that can\n> be used to instantiate another `OffchainCryptocurrencySystem`.\n>\n> So, the base technique used by the AMCU paper is to realize that, from a\n> payment channel (aka `OffchainCryptocurrencySystem`) it can instantiate\n> *two* inner payment channels.\n> So something like this:\n>\n>      void amcu_algorithm(OffchainCryptocurrencySystem channel) {\n>          OffchainCryptocurrencySystem subchannel1 = new\n> OffchainCryptocurrencySystem(channel);\n>          OffchainCryptocurrencySystem subchannel2 = new\n> OffchainCryptocurrencySystem(channel);\n>          ...\n>      }\n>\n> This is doable in any offchain cryptocurrency system (though is not\n> currently coded in any Lightning Network implementation, because\n> maintenance issues).\n> See also:\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-December/001721.html\n>\n> How does it \"close\" a sub-channel?\n> Well, how do you \"claim\" an HTLC or \"fail\" an HTLC inside an existing\n> Lightning Network payment channel?\n> Basically, the participants in the offchain updateable cryptocurrency\n> system decide according to the rules of the protocol, in a way that is also\n> consistent with the rules of the hosting cryptocurrency system (in the case\n> of LN, the Bitcoin blockchain).\n> For example, in Lightning, in order to \"claim\" an HTLC, the participant\n> with the ability to claim that HTLC must present the preimage corresponding\n> to the hash indicated in the contract.\n> Then the participants check that the rules have been followed, then update\n> the channel state to remove the HTLC and put the money that used to be in\n> the HTLC into the fund of who claimed it.\n>\n> Similarly, if you have a super-channel containing a sub-channel, and want\n> to \"close\" the sub-channel, what do you do?\n> Closing the sub-channel requires particular protocol rules to be followed,\n> culminating in a transaction that spends the fund of the sub-channel to\n> whatever set of contracts was agreed to be the latest channel state.\n> Then, that transaction is presented to the participants in the\n> super-channel, who validate that it is indeed a valid spending of the\n> sub-channel funds, then agree to update the channel state, removing the\n> sub-channel funds and re-assigning it to the outputs of the latest channel\n> state of the sub-channel.\n>\n> More concretely. suppose we have:\n>\n>     channel the_super_channel:\n>         1 Bitcoin -> ZmnSCPxj\n>         1 Bitcoin -> Subhra\n>         2 Bitcoin -> channel the_sub_channel (ZmnSCPxj && Subhra)\n>     channel the_sub_channel:\n>         1 Bitcoin -> HTLC(H=ZmnSCPxj hash=XXXXX,T=Subhra timelock=615021)\n>         1 Bitcoin -> Subhra\n>\n> Then to close the inner channel, what happens is then all the participants\n> in the super-channel agree to update to this new state:\n>\n>     channel the_super_channel:\n>         1 Bitcoin -> ZmnSCPxj\n>         1 Bitcoin -> Subhra\n>         1 Bitcoin -> HTLC(H=ZmnSCPxj hash=XXXXX,T=Subhra timelock=615021)\n>         1 Bitcoin -> Subhra\n>\n> (As an optimization, they could merge the two \"Subhra\" outputs together\n> into a single 2 Bitcoin output, which is what is automatically done by\n> Lightning for HTLC claims and fails.)\n>\n> How are sub-channels created?\n> By whatever was agreed upon by the participants of the channel.\n> For example, suppose ZmnSCPxj propose to make a sub-channel of its own\n> funds in a new sub-channel.\n> Then the total state becomes:\n>\n>     channel the_super_channel:\n>         1 Bitcoin -> channel the_new_sub_channel (ZmnSCPxj && Subhra)\n>         1 Bitcoin -> Subhra\n>         1 Bitcoin -> HTLC(H=ZmnSCPxj hash=XXXXX,T=Subhra timelock=615021)\n>         1 Bitcoin -> Subhra\n>     channel the_new_sub_channel:\n>         1 Bitcoin -> ZmnSCPxj\n>\n> Or, from another point-of-view: offchain updateable cryptocurrency systems\n> implement a cut-through mechanism.\n> In principle, presenting a transaction to the participants of the offchain\n> updateable cryptocurrency system, that can validly spend one or more\n> outputs of the current state of the system (and does not consume any coins\n> outside of the system), should be enough to convince the participants to\n> delete those spent outputs and replace it with the outputs of that\n> transaction in the next state of the offchain cryptocurrency system.\n> (This is not done in Lightning simply because sending smaller pieces of\n> data containing just the essential parts of the transactions that *would*\n> have fulfilled the HTLCs is cheaper than sending entire transactions\n> through.\n> Not to mention having to embed a SCRIPT interpreter in our codebases would\n> be ***HORRID***.)\n> And a transaction which spends some output to create a payment channel is\n> just another transaction that such a system can process according to the\n> rules of the hosting cryptocurrency system.\n> Similarly, a transaction which formalizes the closure of a payment channel\n> is just another transaction, which represents a change in the state of the\n> cryptocurrency system.\n>\n> One might consider that cryptocurrency systems basically allow the\n> creation and destruction of UTXOs.\n> Thus, both blockchains and payment channels are cryptocurrency systems.\n> The difference is that blockchains allow safely storing coins held by\n> anyone, whereas payment channels can only safely store coins held by the\n> participants of the channel (because it is an n-of-n federation where *you*\n> the user is a member of that federation: see\n> https://zmnscpxj.github.io/offchain/safety.html).\n>\n> Conversely, I think the measuring-stick for the AMCU technique is that it\n> should be possible to do it onchain to implement a multi-participant\n> CoinSwap, because in principle a channel is just a cryptocurrency system\n> and a blockchain is one as well.\n>\n>\n\n> In any case, from a skim of the AMCU paper, it looks like all the\n> intermediate hops *need* to validate that all the *other* intermediate hops\n> follow the protocol, by presenting all the transactions involved.\n> This probably implies that all the intermediate hops know the entire\n> route, and thus who the ultimate sender and receiver are, thus utterly bad\n> for privacy.\n> Hopefully my reading is wrong, or this is fixable, but if neither, it is\n> unlikely to be used in Lightning.\n>\n>\n\n\n\n\n> Regards,\n> ZmnSCPxj\n>\n> > Hi ZmnSCPxj,\n> >       It is stated in the paper \"Atomic multi-channel updates with\n> constant collateral in bitcoin-compatible payment-channel networks\" and I\n> am quoting verbatim (page 11) (last email still waiting moderator approval)\n> \"Phase I: Setup. The first phase requires to freeze the coins available at\n> each channel involved in the protocol. Doing this naively (i.e., locking\n> the complete balance in the channel at once) would lock more coins than\n> required, unnecessarily increasing the collateral in the protocol. Instead,\n> during the setup phase, the balance at each payment channel is split in\n> two, effectively creating thereby two sub-channels: one sub-channel is set\n> with the coins required for the present protocol session, while the other\n> one is set with the\n> > remaining coins, which can then be freely spent. In the illustrative\n> example shown in Figure 4.2, the setup phase starts with the user A\n> collaborating with user B to create the transaction Tx A\n> > setup , where they split the 10 coins they have in the channel in two\n> sub-channels: one sub-channel with 8 coins to be used in the rest of the\n> protocol session and one sub-channel with the rest (i.e., 2 coins). This\n> transaction is signed by both users so that it can be eventually enforced\n> on-chain if required. The rest of the users behave analogously. Note that\n> operations at each channel in this phase of the protocol can be carried out\n> in parallel.\" Does this sound good ?\n> >\n> > On Mon, Jan 27, 2020 at 9:41 AM Subhra Mazumdar <\n> subhra.mazumdar1993 at gmail.com> wrote:\n> >\n> > > Hi ZmnSCPxj,\n> > >        It is stated in the paper \"Atomic multi-channel updates with\n> constant collateral in bitcoin-compatible payment-channel networks\". I am\n> attaching the screenshot of the paragraph which mentions about locking the\n> amount which is required for payment transfer and not the entire channel\n> fund.\n> > >\n> > > On Mon, Jan 27, 2020 at 6:15 AM ZmnSCPxj <ZmnSCPxj at protonmail.com>\n> wrote:\n> > >\n> > > > Good morning Subhra,\n> > > >\n> > > > This does not seem to make sense?\n> > > > For a payment that is less than the channel funds on your side, only\n> that amount is locked behind an HTLC, and the rest remains useable for\n> other HTLCs.\n> > > >\n> > > > What exactly are you referring to?\n> > > >\n> > > > Regards,\n> > > > ZmnSCPxj\n> > > >\n> > > > > Hi,\n> > > > >      I was wondering when parties apply condition on fraction of\n> channel fund for ensuring successful payment, entire channel fund is held.\n> Is it possible to lock just partial amount of fund of a payment channel and\n> leave the rest to be used by some another payment request ? Concept of\n> subchannels of a single channel has been suggested in \"Atomic multi-channel\n> updates with constant collateral in bitcoin-compatible payment-channel\n> networks\"\n> https://scholar.google.com/scholar?cluster=40566801298747858&hl=en&as_sdt=2005&sciodt=0,5\n> but I am still in doubt what happens during closing of subchannel ?\n> > > > > --\n> > > > > Yours sincerely,\n> > > > > Subhra Mazumdar.\n> > >\n> > > --\n> > > Yours sincerely,\n> > > Subhra Mazumdar.\n> >\n> > --\n> > Yours sincerely,\n> > Subhra Mazumdar.\n>\n>\n>\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200128/f13562c5/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Reduce the amount of collateral locked by scripts for transferring funds in lightning network",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Subhra Mazumdar",
                "ZmnSCPxj"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 29015
        }
    },
    {
        "title": "[Lightning-dev] Not revealing the channel capacity during opening of channel in lightning network",
        "thread_messages": [
            {
                "author": "Subhra Mazumdar",
                "date": "2020-01-27T07:14:41",
                "message_text_only": "Dear All,\n         What can be the potential problem if a channel is opened whereby\nthe channel capacity is not revealed publicly but just a range proof of the\nattribute (capacity >0 and capacity < value) is provided ? Will it pose a\nproblem during routing of transaction ? What are the pros and cons ?\nI think that revealing channel capacity make the channels susceptible to\nchannel exhaustion attack or a particular node might be targeted for node\nisolation attack ?\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200127/396a7593/attachment.html>"
            },
            {
                "author": "Ugam Kamat",
                "date": "2020-01-27T07:50:02",
                "message_text_only": "Hey Subhra \u2013 In order to have faith that the channel announced by the nodes is actually locked on the Bitcoin mainchain we need to have the outpoint (`txid` and `vout`) of the funding transaction. If we do not verify that the funding transaction has been confirmed, nodes can cheat us that a particular transaction is confirmed when it is not the case. As a result we require that nodes announce this information along with the public keys and the signatures of the public keys that was used to lock the funding transaction.\n\n \n\nThis information is broadcasted in the `channel_announcement` message in the `short_channel_id` field which includes the block number, transaction number and vout. Since Bitcoin does not allow confidential transactions, we can query the blockchain and find out the channel capacity even when the amounts are never explicitly mentioned. \n\n \n\n \n\nUgam\n\n \n\nFrom: Lightning-dev <lightning-dev-bounces at lists.linuxfoundation.org> On Behalf Of Subhra Mazumdar\nSent: Monday, January 27, 2020 12:45 PM\nTo: lightning-dev at lists.linuxfoundation.org\nSubject: [Lightning-dev] Not revealing the channel capacity during opening of channel in lightning network\n\n \n\nDear All,\n\n         What can be the potential problem if a channel is opened whereby the channel capacity is not revealed publicly but just a range proof of the attribute (capacity >0 and capacity < value) is provided ? Will it pose a problem during routing of transaction ? What are the pros and cons ?\n\nI think that revealing channel capacity make the channels susceptible to channel exhaustion attack or a particular node might be targeted for node isolation attack ? \n\n\n-- \n\nYours sincerely,\nSubhra Mazumdar.\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200127/cf9b0f81/attachment-0001.html>"
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-01-27T08:11:33",
                "message_text_only": "Hey thanks for clearing the confusion. Well then may be we can look out for\nsuch a provision in off chain payment systems for Monero.\n\nOn Mon, Jan 27, 2020, 13:20 Ugam Kamat <ugamkamat1 at gmail.com> wrote:\n\n> Hey Subhra \u2013 In order to have faith that the channel announced by the\n> nodes is actually locked on the Bitcoin mainchain we need to have the\n> outpoint (`txid` and `vout`) of the funding transaction. If we do not\n> verify that the funding transaction has been confirmed, nodes can cheat us\n> that a particular transaction is confirmed when it is not the case. As a\n> result we require that nodes announce this information along with the\n> public keys and the signatures of the public keys that was used to lock the\n> funding transaction.\n>\n>\n>\n> This information is broadcasted in the `channel_announcement` message in\n> the `short_channel_id` field which includes the block number, transaction\n> number and vout. Since Bitcoin does not allow confidential transactions, we\n> can query the blockchain and find out the channel capacity even when the\n> amounts are never explicitly mentioned.\n>\n>\n>\n>\n>\n> Ugam\n>\n>\n>\n> *From:* Lightning-dev <lightning-dev-bounces at lists.linuxfoundation.org> *On\n> Behalf Of *Subhra Mazumdar\n> *Sent:* Monday, January 27, 2020 12:45 PM\n> *To:* lightning-dev at lists.linuxfoundation.org\n> *Subject:* [Lightning-dev] Not revealing the channel capacity during\n> opening of channel in lightning network\n>\n>\n>\n> Dear All,\n>\n>          What can be the potential problem if a channel is opened whereby\n> the channel capacity is not revealed publicly but just a range proof of the\n> attribute (capacity >0 and capacity < value) is provided ? Will it pose a\n> problem during routing of transaction ? What are the pros and cons ?\n>\n> I think that revealing channel capacity make the channels susceptible to\n> channel exhaustion attack or a particular node might be targeted for node\n> isolation attack ?\n>\n>\n> --\n>\n> Yours sincerely,\n> Subhra Mazumdar.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200127/0a7e9949/attachment.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2020-01-27T14:41:58",
                "message_text_only": "Note that there's no real reason lightning nodes *have* to have\nconfidence in that - if a node routes your payment to the next hop, how\nthey do it doesn't really matter. Allowing things like non-lightning\n\"channels\" (eg just a contractual agreement to settle up later between\ntwo mutually-trusting parties) would actually be quite compelling.\n\nThe reason lightning nodes *today* require proof-of-funds-locked is\nlargely for DoS resistance, effectively rate-limiting flooding the\nglobal routing table with garbage, but such rate-limiting could be\naccomplished (albeit with a ton more complexity) via other means.\n\nMatt\n\nOn 1/27/20 7:50 AM, Ugam Kamat wrote:\n> Hey Subhra \u2013 In order to have faith that the channel announced by the\n> nodes is actually locked on the Bitcoin mainchain we need to have the\n> outpoint (`txid` and `vout`) of the funding transaction. If we do not\n> verify that the funding transaction has been confirmed, nodes can cheat\n> us that a particular transaction is confirmed when it is not the case.\n> As a result we require that nodes announce this information along with\n> the public keys and the signatures of the public keys that was used to\n> lock the funding transaction.\n> \n> \u00a0\n> \n> This information is broadcasted in the `channel_announcement` message in\n> the `short_channel_id` field which includes the block number,\n> transaction number and vout. Since Bitcoin does not allow confidential\n> transactions, we can query the blockchain and find out the channel\n> capacity even when the amounts are never explicitly mentioned.\n> \n> \u00a0\n> \n> \u00a0\n> \n> Ugam\n> \n> \u00a0\n> \n> *From:* Lightning-dev <lightning-dev-bounces at lists.linuxfoundation.org>\n> *On Behalf Of *Subhra Mazumdar\n> *Sent:* Monday, January 27, 2020 12:45 PM\n> *To:* lightning-dev at lists.linuxfoundation.org\n> *Subject:* [Lightning-dev] Not revealing the channel capacity during\n> opening of channel in lightning network\n> \n> \u00a0\n> \n> Dear All,\n> \n> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 What can be the potential problem if a channel is opened\n> whereby the channel capacity is not revealed publicly but just a range\n> proof of the attribute (capacity >0 and capacity < value) is provided ?\n> Will it pose a problem during routing of transaction ? What are the pros\n> and cons ?\n> \n> I think that revealing channel capacity make the channels susceptible to\n> channel exhaustion attack or a particular node might be targeted for\n> node isolation attack ?\n> \n> \n> -- \n> \n> Yours sincerely,\n> Subhra Mazumdar.\n> \n> \n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>"
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-01-27T15:04:05",
                "message_text_only": "So introducing proof of knowledge of fund locked instead of revealing the\namount of fund locked by counterparties will introduce added complexity\nwhile routing but how effective is this going to be against handling\nattacks like hijacking of routes and channel exhaustion ?\n\nOn Mon, Jan 27, 2020, 20:12 Matt Corallo <lf-lists at mattcorallo.com> wrote:\n\n> Note that there's no real reason lightning nodes *have* to have\n> confidence in that - if a node routes your payment to the next hop, how\n> they do it doesn't really matter. Allowing things like non-lightning\n> \"channels\" (eg just a contractual agreement to settle up later between\n> two mutually-trusting parties) would actually be quite compelling.\n>\n> The reason lightning nodes *today* require proof-of-funds-locked is\n> largely for DoS resistance, effectively rate-limiting flooding the\n> global routing table with garbage, but such rate-limiting could be\n> accomplished (albeit with a ton more complexity) via other means.\n>\n> Matt\n>\n> On 1/27/20 7:50 AM, Ugam Kamat wrote:\n> > Hey Subhra \u2013 In order to have faith that the channel announced by the\n> > nodes is actually locked on the Bitcoin mainchain we need to have the\n> > outpoint (`txid` and `vout`) of the funding transaction. If we do not\n> > verify that the funding transaction has been confirmed, nodes can cheat\n> > us that a particular transaction is confirmed when it is not the case.\n> > As a result we require that nodes announce this information along with\n> > the public keys and the signatures of the public keys that was used to\n> > lock the funding transaction.\n> >\n> >\n> >\n> > This information is broadcasted in the `channel_announcement` message in\n> > the `short_channel_id` field which includes the block number,\n> > transaction number and vout. Since Bitcoin does not allow confidential\n> > transactions, we can query the blockchain and find out the channel\n> > capacity even when the amounts are never explicitly mentioned.\n> >\n> >\n> >\n> >\n> >\n> > Ugam\n> >\n> >\n> >\n> > *From:* Lightning-dev <lightning-dev-bounces at lists.linuxfoundation.org>\n> > *On Behalf Of *Subhra Mazumdar\n> > *Sent:* Monday, January 27, 2020 12:45 PM\n> > *To:* lightning-dev at lists.linuxfoundation.org\n> > *Subject:* [Lightning-dev] Not revealing the channel capacity during\n> > opening of channel in lightning network\n> >\n> >\n> >\n> > Dear All,\n> >\n> >          What can be the potential problem if a channel is opened\n> > whereby the channel capacity is not revealed publicly but just a range\n> > proof of the attribute (capacity >0 and capacity < value) is provided ?\n> > Will it pose a problem during routing of transaction ? What are the pros\n> > and cons ?\n> >\n> > I think that revealing channel capacity make the channels susceptible to\n> > channel exhaustion attack or a particular node might be targeted for\n> > node isolation attack ?\n> >\n> >\n> > --\n> >\n> > Yours sincerely,\n> > Subhra Mazumdar.\n> >\n> >\n> > _______________________________________________\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> >\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200127/0d63c8b7/attachment.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2020-01-27T15:15:10",
                "message_text_only": "Why require a funding locked? Just require proof-of-UTXO - its only for\nanti-DoS, again there is no reason to require a standard lightning\nchannel on-chain for this.\n\nIn general proving 2-of-2 multisig UTXO ownership doesn't do much to\nprevent route hijacking to begin with, so it shouldn't be much different.\n\nMatt\n\nOn 1/27/20 3:04 PM, Subhra Mazumdar wrote:\n> So introducing proof of knowledge of fund locked instead of revealing\n> the amount of fund locked by counterparties will introduce added\n> complexity while routing but how effective is this going to be against\n> handling attacks like hijacking of routes and channel exhaustion ?\n> \n> On Mon, Jan 27, 2020, 20:12 Matt Corallo <lf-lists at mattcorallo.com\n> <mailto:lf-lists at mattcorallo.com>> wrote:\n> \n>     Note that there's no real reason lightning nodes *have* to have\n>     confidence in that - if a node routes your payment to the next hop, how\n>     they do it doesn't really matter. Allowing things like non-lightning\n>     \"channels\" (eg just a contractual agreement to settle up later between\n>     two mutually-trusting parties) would actually be quite compelling.\n> \n>     The reason lightning nodes *today* require proof-of-funds-locked is\n>     largely for DoS resistance, effectively rate-limiting flooding the\n>     global routing table with garbage, but such rate-limiting could be\n>     accomplished (albeit with a ton more complexity) via other means.\n> \n>     Matt\n> \n>     On 1/27/20 7:50 AM, Ugam Kamat wrote:\n>     > Hey Subhra \u2013 In order to have faith that the channel announced by the\n>     > nodes is actually locked on the Bitcoin mainchain we need to have the\n>     > outpoint (`txid` and `vout`) of the funding transaction. If we do not\n>     > verify that the funding transaction has been confirmed, nodes can\n>     cheat\n>     > us that a particular transaction is confirmed when it is not the case.\n>     > As a result we require that nodes announce this information along with\n>     > the public keys and the signatures of the public keys that was used to\n>     > lock the funding transaction.\n>     >\n>     > \u00a0\n>     >\n>     > This information is broadcasted in the `channel_announcement`\n>     message in\n>     > the `short_channel_id` field which includes the block number,\n>     > transaction number and vout. Since Bitcoin does not allow confidential\n>     > transactions, we can query the blockchain and find out the channel\n>     > capacity even when the amounts are never explicitly mentioned.\n>     >\n>     > \u00a0\n>     >\n>     > \u00a0\n>     >\n>     > Ugam\n>     >\n>     > \u00a0\n>     >\n>     > *From:* Lightning-dev\n>     <lightning-dev-bounces at lists.linuxfoundation.org\n>     <mailto:lightning-dev-bounces at lists.linuxfoundation.org>>\n>     > *On Behalf Of *Subhra Mazumdar\n>     > *Sent:* Monday, January 27, 2020 12:45 PM\n>     > *To:* lightning-dev at lists.linuxfoundation.org\n>     <mailto:lightning-dev at lists.linuxfoundation.org>\n>     > *Subject:* [Lightning-dev] Not revealing the channel capacity during\n>     > opening of channel in lightning network\n>     >\n>     > \u00a0\n>     >\n>     > Dear All,\n>     >\n>     > \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 What can be the potential problem if a channel is opened\n>     > whereby the channel capacity is not revealed publicly but just a range\n>     > proof of the attribute (capacity >0 and capacity < value) is\n>     provided ?\n>     > Will it pose a problem during routing of transaction ? What are\n>     the pros\n>     > and cons ?\n>     >\n>     > I think that revealing channel capacity make the channels\n>     susceptible to\n>     > channel exhaustion attack or a particular node might be targeted for\n>     > node isolation attack ?\n>     >\n>     >\n>     > --\n>     >\n>     > Yours sincerely,\n>     > Subhra Mazumdar.\n>     >\n>     >\n>     > _______________________________________________\n>     > Lightning-dev mailing list\n>     > Lightning-dev at lists.linuxfoundation.org\n>     <mailto:Lightning-dev at lists.linuxfoundation.org>\n>     > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>     >\n>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-27T15:19:01",
                "message_text_only": "Good morning Subhra,\n\n> So introducing proof of knowledge of fund locked instead of revealing the amount of fund locked by counterparties will introduce added complexity while routing but how effective is this going to be against handling attacks like hijacking of routes and channel exhaustion ?\n\nThe added complexity is spam-prevention, as mentioned, and not routing in particular.\nPathfinding algorithms can just use the lower limit of the rangeproof to filter out channels too small to pass a particular payment through, C-Lightning (and probably other implementations) already does this, using the known channel capacity as the limit (knowledge of the exact channel capacity is a rangeproof whose lower limit equals the upper limit, yes?).\n\nNow, since the proofs involved are likely to be larger than just a simple 64-bit integer that indicates the location of the funding transaction on the blockchain (24-bit blockheight, 24-bit transaction index within block, 16-bit output index), the spam-prevention might end up requiring *more* data than the spam it stops, so ---\n(Though if Matt has some ideas here I would be greatly interested --- we do have to change the encodings of short-channel-ids at some point, if only to support channel factories....)\n\nRegards,\nZmnSCPxj\n\n>\n> On Mon, Jan 27, 2020, 20:12 Matt Corallo <lf-lists at mattcorallo.com> wrote:\n>\n> > Note that there's no real reason lightning nodes *have* to have\n> > confidence in that - if a node routes your payment to the next hop, how\n> > they do it doesn't really matter. Allowing things like non-lightning\n> > \"channels\" (eg just a contractual agreement to settle up later between\n> > two mutually-trusting parties) would actually be quite compelling.\n> >\n> > The reason lightning nodes *today* require proof-of-funds-locked is\n> > largely for DoS resistance, effectively rate-limiting flooding the\n> > global routing table with garbage, but such rate-limiting could be\n> > accomplished (albeit with a ton more complexity) via other means.\n> >\n> > Matt\n> >\n> > On 1/27/20 7:50 AM, Ugam Kamat wrote:\n> > > Hey Subhra \u2013 In order to have faith that the channel announced by the\n> > > nodes is actually locked on the Bitcoin mainchain we need to have the\n> > > outpoint (`txid` and `vout`) of the funding transaction. If we do not\n> > > verify that the funding transaction has been confirmed, nodes can cheat\n> > > us that a particular transaction is confirmed when it is not the case.\n> > > As a result we require that nodes announce this information along with\n> > > the public keys and the signatures of the public keys that was used to\n> > > lock the funding transaction.\n> > >\n> > > \u00a0\n> > >\n> > > This information is broadcasted in the `channel_announcement` message in\n> > > the `short_channel_id` field which includes the block number,\n> > > transaction number and vout. Since Bitcoin does not allow confidential\n> > > transactions, we can query the blockchain and find out the channel\n> > > capacity even when the amounts are never explicitly mentioned.\n> > >\n> > > \u00a0\n> > >\n> > > \u00a0\n> > >\n> > > Ugam\n> > >\n> > > \u00a0\n> > >\n> > > *From:* Lightning-dev <lightning-dev-bounces at lists.linuxfoundation.org>\n> > > *On Behalf Of *Subhra Mazumdar\n> > > *Sent:* Monday, January 27, 2020 12:45 PM\n> > > *To:* lightning-dev at lists.linuxfoundation.org\n> > > *Subject:* [Lightning-dev] Not revealing the channel capacity during\n> > > opening of channel in lightning network\n> > >\n> > > \u00a0\n> > >\n> > > Dear All,\n> > >\n> > > \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 What can be the potential problem if a channel is opened\n> > > whereby the channel capacity is not revealed publicly but just a range\n> > > proof of the attribute (capacity >0 and capacity < value) is provided ?\n> > > Will it pose a problem during routing of transaction ? What are the pros\n> > > and cons ?\n> > >\n> > > I think that revealing channel capacity make the channels susceptible to\n> > > channel exhaustion attack or a particular node might be targeted for\n> > > node isolation attack ?\n> > >\n> > >\n> > > --\n> > >\n> > > Yours sincerely,\n> > > Subhra Mazumdar.\n> > >\n> > >\n> > > _______________________________________________\n> > > Lightning-dev mailing list\n> > > Lightning-dev at lists.linuxfoundation.org\n> > > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> > >"
            },
            {
                "author": "Matt Corallo",
                "date": "2020-01-27T15:33:18",
                "message_text_only": "Note the distinction - there is almost nothing done today to prevent\nspam and route-hijacks (aka someone providing routing for a lower fee\nand users happily taking it) in the routing DB today. The issue of\nanti-DoS is somewhat different - we do have reasonable protection from\nsomeone OOM'ing every node on the network by opening a billion channels.\nAnti-DoS could reasonably be accomplished with simple equivalent proofs,\nthough of course they would be somewhat more expensive to create/validate.\n\nMatt\n\nOn 1/27/20 3:19 PM, ZmnSCPxj wrote:\n> Good morning Subhra,\n> \n>> So introducing proof of knowledge of fund locked instead of revealing the amount of fund locked by counterparties will introduce added complexity while routing but how effective is this going to be against handling attacks like hijacking of routes and channel exhaustion ?\n> \n> The added complexity is spam-prevention, as mentioned, and not routing in particular.\n> Pathfinding algorithms can just use the lower limit of the rangeproof to filter out channels too small to pass a particular payment through, C-Lightning (and probably other implementations) already does this, using the known channel capacity as the limit (knowledge of the exact channel capacity is a rangeproof whose lower limit equals the upper limit, yes?).\n> \n> Now, since the proofs involved are likely to be larger than just a simple 64-bit integer that indicates the location of the funding transaction on the blockchain (24-bit blockheight, 24-bit transaction index within block, 16-bit output index), the spam-prevention might end up requiring *more* data than the spam it stops, so ---\n> (Though if Matt has some ideas here I would be greatly interested --- we do have to change the encodings of short-channel-ids at some point, if only to support channel factories....)\n> \n> Regards,\n> ZmnSCPxj\n> \n>>\n>> On Mon, Jan 27, 2020, 20:12 Matt Corallo <lf-lists at mattcorallo.com> wrote:\n>>\n>>> Note that there's no real reason lightning nodes *have* to have\n>>> confidence in that - if a node routes your payment to the next hop, how\n>>> they do it doesn't really matter. Allowing things like non-lightning\n>>> \"channels\" (eg just a contractual agreement to settle up later between\n>>> two mutually-trusting parties) would actually be quite compelling.\n>>>\n>>> The reason lightning nodes *today* require proof-of-funds-locked is\n>>> largely for DoS resistance, effectively rate-limiting flooding the\n>>> global routing table with garbage, but such rate-limiting could be\n>>> accomplished (albeit with a ton more complexity) via other means.\n>>>\n>>> Matt\n>>>\n>>> On 1/27/20 7:50 AM, Ugam Kamat wrote:\n>>>> Hey Subhra \u2013 In order to have faith that the channel announced by the\n>>>> nodes is actually locked on the Bitcoin mainchain we need to have the\n>>>> outpoint (`txid` and `vout`) of the funding transaction. If we do not\n>>>> verify that the funding transaction has been confirmed, nodes can cheat\n>>>> us that a particular transaction is confirmed when it is not the case.\n>>>> As a result we require that nodes announce this information along with\n>>>> the public keys and the signatures of the public keys that was used to\n>>>> lock the funding transaction.\n>>>>\n>>>> \u00a0\n>>>>\n>>>> This information is broadcasted in the `channel_announcement` message in\n>>>> the `short_channel_id` field which includes the block number,\n>>>> transaction number and vout. Since Bitcoin does not allow confidential\n>>>> transactions, we can query the blockchain and find out the channel\n>>>> capacity even when the amounts are never explicitly mentioned.\n>>>>\n>>>> \u00a0\n>>>>\n>>>> \u00a0\n>>>>\n>>>> Ugam\n>>>>\n>>>> \u00a0\n>>>>\n>>>> *From:* Lightning-dev <lightning-dev-bounces at lists.linuxfoundation.org>\n>>>> *On Behalf Of *Subhra Mazumdar\n>>>> *Sent:* Monday, January 27, 2020 12:45 PM\n>>>> *To:* lightning-dev at lists.linuxfoundation.org\n>>>> *Subject:* [Lightning-dev] Not revealing the channel capacity during\n>>>> opening of channel in lightning network\n>>>>\n>>>> \u00a0\n>>>>\n>>>> Dear All,\n>>>>\n>>>> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 What can be the potential problem if a channel is opened\n>>>> whereby the channel capacity is not revealed publicly but just a range\n>>>> proof of the attribute (capacity >0 and capacity < value) is provided ?\n>>>> Will it pose a problem during routing of transaction ? What are the pros\n>>>> and cons ?\n>>>>\n>>>> I think that revealing channel capacity make the channels susceptible to\n>>>> channel exhaustion attack or a particular node might be targeted for\n>>>> node isolation attack ?\n>>>>\n>>>>\n>>>> --\n>>>>\n>>>> Yours sincerely,\n>>>> Subhra Mazumdar.\n>>>>\n>>>>\n>>>> _______________________________________________\n>>>> Lightning-dev mailing list\n>>>> Lightning-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>>\n> \n>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-27T15:55:21",
                "message_text_only": "Good morning Matt,\n\nThread-hijack...\n\n> route-hijacks (aka someone providing routing for a lower fee\n> and users happily taking it)\n\nI observe that this is something of a catch-22.\n\nIf users *notice* lower fees and go to lower-fee channels, then route-hijacking is possible and surveillors can pay (via sacrificed fees) for better surveillance.\nIf users *ignore* lower fees, then forwarding nodes will jack up their prices to 21 million Bitcoin `fee_base`, because users are going to go through their nodes with equal probability as lower-priced nodes.\n\nIn many ways, traits that make one a good forwarding node (large number of channels, cheap fees, central location, high uptime, low latency...) also makes one a good surveillance node, sigh.\nFortunately this second-layer Lightning network remains censorship-resistant (censorship leads to loss of profit from fees, same as on the blockchain layer, and censors can be evicted by jacking up your willingness to pay fees (including onchain fees to move your channels away from the censoring node and towards the node you want to pay to, which again is an eviction of the censor), just as effectively as on the blockchain layer).\n\nRegards,\nZmnSCPxj\n\n> in the routing DB today. The issue of\n> anti-DoS is somewhat different - we do have reasonable protection from\n> someone OOM'ing every node on the network by opening a billion channels.\n> Anti-DoS could reasonably be accomplished with simple equivalent proofs,\n> though of course they would be somewhat more expensive to create/validate.\n>\n> Matt\n>\n> On 1/27/20 3:19 PM, ZmnSCPxj wrote:\n>\n> > Good morning Subhra,\n> >\n> > > So introducing proof of knowledge of fund locked instead of revealing the amount of fund locked by counterparties will introduce added complexity while routing but how effective is this going to be against handling attacks like hijacking of routes and channel exhaustion ?\n> >\n> > The added complexity is spam-prevention, as mentioned, and not routing in particular.\n> > Pathfinding algorithms can just use the lower limit of the rangeproof to filter out channels too small to pass a particular payment through, C-Lightning (and probably other implementations) already does this, using the known channel capacity as the limit (knowledge of the exact channel capacity is a rangeproof whose lower limit equals the upper limit, yes?).\n> > Now, since the proofs involved are likely to be larger than just a simple 64-bit integer that indicates the location of the funding transaction on the blockchain (24-bit blockheight, 24-bit transaction index within block, 16-bit output index), the spam-prevention might end up requiring more data than the spam it stops, so ---\n> > (Though if Matt has some ideas here I would be greatly interested --- we do have to change the encodings of short-channel-ids at some point, if only to support channel factories....)\n> > Regards,\n> > ZmnSCPxj\n> >\n> > > On Mon, Jan 27, 2020, 20:12 Matt Corallo lf-lists at mattcorallo.com wrote:\n> > >\n> > > > Note that there's no real reason lightning nodes have to have\n> > > > confidence in that - if a node routes your payment to the next hop, how\n> > > > they do it doesn't really matter. Allowing things like non-lightning\n> > > > \"channels\" (eg just a contractual agreement to settle up later between\n> > > > two mutually-trusting parties) would actually be quite compelling.\n> > > > The reason lightning nodes today require proof-of-funds-locked is\n> > > > largely for DoS resistance, effectively rate-limiting flooding the\n> > > > global routing table with garbage, but such rate-limiting could be\n> > > > accomplished (albeit with a ton more complexity) via other means.\n> > > > Matt\n> > > > On 1/27/20 7:50 AM, Ugam Kamat wrote:\n> > > >\n> > > > > Hey Subhra \u2013 In order to have faith that the channel announced by the\n> > > > > nodes is actually locked on the Bitcoin mainchain we need to have the\n> > > > > outpoint (`txid` and `vout`) of the funding transaction. If we do not\n> > > > > verify that the funding transaction has been confirmed, nodes can cheat\n> > > > > us that a particular transaction is confirmed when it is not the case.\n> > > > > As a result we require that nodes announce this information along with\n> > > > > the public keys and the signatures of the public keys that was used to\n> > > > > lock the funding transaction.\n> > > > >\n> > > > > This information is broadcasted in the `channel_announcement` message in\n> > > > > the `short_channel_id` field which includes the block number,\n> > > > > transaction number and vout. Since Bitcoin does not allow confidential\n> > > > > transactions, we can query the blockchain and find out the channel\n> > > > > capacity even when the amounts are never explicitly mentioned.\n> > > > >\n> > > > > Ugam\n> > > > >\n> > > > > From: Lightning-dev lightning-dev-bounces at lists.linuxfoundation.org\n> > > > > *On Behalf Of *Subhra Mazumdar\n> > > > > Sent: Monday, January 27, 2020 12:45 PM\n> > > > > To: lightning-dev at lists.linuxfoundation.org\n> > > > > Subject: [Lightning-dev] Not revealing the channel capacity during\n> > > > > opening of channel in lightning network\n> > > > >\n> > > > > Dear All,\n> > > > > What can be the potential problem if a channel is opened\n> > > > > whereby the channel capacity is not revealed publicly but just a range\n> > > > > proof of the attribute (capacity >0 and capacity < value) is provided ?\n> > > > > Will it pose a problem during routing of transaction ? What are the pros\n> > > > > and cons ?\n> > > > > I think that revealing channel capacity make the channels susceptible to\n> > > > > channel exhaustion attack or a particular node might be targeted for\n> > > > > node isolation attack ?\n> > > > > --\n> > > > > Yours sincerely,\n> > > > > Subhra Mazumdar.\n> > > > >\n> > > > > Lightning-dev mailing list\n> > > > > Lightning-dev at lists.linuxfoundation.org\n> > > > > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Matt Corallo",
                "date": "2020-01-27T16:22:47",
                "message_text_only": "Right, but there are approaches that are not as susceptible - an\nobvious, albeit somewhat naive, approach would be to define a fixed and\nproportional max fee, and pick a random (with some privacy properties eg\nbiasing towards old or good-reputation nodes, routing across nodes\nhosted on different ISPs/Tor/across continents, etc) route that pays no\nmore than those fees unless no such route is available. You could\nimagine hard-coding such fees to \"fees that are generally available on\nthe network as observed in the real world\".\n\nMatt\n\nOn 1/27/20 3:55 PM, ZmnSCPxj wrote:\n> Good morning Matt,\n> \n> Thread-hijack...\n> \n>> route-hijacks (aka someone providing routing for a lower fee\n>> and users happily taking it)\n> \n> I observe that this is something of a catch-22.\n> \n> If users *notice* lower fees and go to lower-fee channels, then route-hijacking is possible and surveillors can pay (via sacrificed fees) for better surveillance.\n> If users *ignore* lower fees, then forwarding nodes will jack up their prices to 21 million Bitcoin `fee_base`, because users are going to go through their nodes with equal probability as lower-priced nodes.\n> \n> In many ways, traits that make one a good forwarding node (large number of channels, cheap fees, central location, high uptime, low latency...) also makes one a good surveillance node, sigh.\n> Fortunately this second-layer Lightning network remains censorship-resistant (censorship leads to loss of profit from fees, same as on the blockchain layer, and censors can be evicted by jacking up your willingness to pay fees (including onchain fees to move your channels away from the censoring node and towards the node you want to pay to, which again is an eviction of the censor), just as effectively as on the blockchain layer).\n> \n> Regards,\n> ZmnSCPxj\n> \n>> in the routing DB today. The issue of\n>> anti-DoS is somewhat different - we do have reasonable protection from\n>> someone OOM'ing every node on the network by opening a billion channels.\n>> Anti-DoS could reasonably be accomplished with simple equivalent proofs,\n>> though of course they would be somewhat more expensive to create/validate.\n>>\n>> Matt\n>>\n>> On 1/27/20 3:19 PM, ZmnSCPxj wrote:\n>>\n>>> Good morning Subhra,\n>>>\n>>>> So introducing proof of knowledge of fund locked instead of revealing the amount of fund locked by counterparties will introduce added complexity while routing but how effective is this going to be against handling attacks like hijacking of routes and channel exhaustion ?\n>>>\n>>> The added complexity is spam-prevention, as mentioned, and not routing in particular.\n>>> Pathfinding algorithms can just use the lower limit of the rangeproof to filter out channels too small to pass a particular payment through, C-Lightning (and probably other implementations) already does this, using the known channel capacity as the limit (knowledge of the exact channel capacity is a rangeproof whose lower limit equals the upper limit, yes?).\n>>> Now, since the proofs involved are likely to be larger than just a simple 64-bit integer that indicates the location of the funding transaction on the blockchain (24-bit blockheight, 24-bit transaction index within block, 16-bit output index), the spam-prevention might end up requiring more data than the spam it stops, so ---\n>>> (Though if Matt has some ideas here I would be greatly interested --- we do have to change the encodings of short-channel-ids at some point, if only to support channel factories....)\n>>> Regards,\n>>> ZmnSCPxj\n>>>\n>>>> On Mon, Jan 27, 2020, 20:12 Matt Corallo lf-lists at mattcorallo.com wrote:\n>>>>\n>>>>> Note that there's no real reason lightning nodes have to have\n>>>>> confidence in that - if a node routes your payment to the next hop, how\n>>>>> they do it doesn't really matter. Allowing things like non-lightning\n>>>>> \"channels\" (eg just a contractual agreement to settle up later between\n>>>>> two mutually-trusting parties) would actually be quite compelling.\n>>>>> The reason lightning nodes today require proof-of-funds-locked is\n>>>>> largely for DoS resistance, effectively rate-limiting flooding the\n>>>>> global routing table with garbage, but such rate-limiting could be\n>>>>> accomplished (albeit with a ton more complexity) via other means.\n>>>>> Matt\n>>>>> On 1/27/20 7:50 AM, Ugam Kamat wrote:\n>>>>>\n>>>>>> Hey Subhra \u2013 In order to have faith that the channel announced by the\n>>>>>> nodes is actually locked on the Bitcoin mainchain we need to have the\n>>>>>> outpoint (`txid` and `vout`) of the funding transaction. If we do not\n>>>>>> verify that the funding transaction has been confirmed, nodes can cheat\n>>>>>> us that a particular transaction is confirmed when it is not the case.\n>>>>>> As a result we require that nodes announce this information along with\n>>>>>> the public keys and the signatures of the public keys that was used to\n>>>>>> lock the funding transaction.\n>>>>>>\n>>>>>> This information is broadcasted in the `channel_announcement` message in\n>>>>>> the `short_channel_id` field which includes the block number,\n>>>>>> transaction number and vout. Since Bitcoin does not allow confidential\n>>>>>> transactions, we can query the blockchain and find out the channel\n>>>>>> capacity even when the amounts are never explicitly mentioned.\n>>>>>>\n>>>>>> Ugam\n>>>>>>\n>>>>>> From: Lightning-dev lightning-dev-bounces at lists.linuxfoundation.org\n>>>>>> *On Behalf Of *Subhra Mazumdar\n>>>>>> Sent: Monday, January 27, 2020 12:45 PM\n>>>>>> To: lightning-dev at lists.linuxfoundation.org\n>>>>>> Subject: [Lightning-dev] Not revealing the channel capacity during\n>>>>>> opening of channel in lightning network\n>>>>>>\n>>>>>> Dear All,\n>>>>>> What can be the potential problem if a channel is opened\n>>>>>> whereby the channel capacity is not revealed publicly but just a range\n>>>>>> proof of the attribute (capacity >0 and capacity < value) is provided ?\n>>>>>> Will it pose a problem during routing of transaction ? What are the pros\n>>>>>> and cons ?\n>>>>>> I think that revealing channel capacity make the channels susceptible to\n>>>>>> channel exhaustion attack or a particular node might be targeted for\n>>>>>> node isolation attack ?\n>>>>>> --\n>>>>>> Yours sincerely,\n>>>>>> Subhra Mazumdar.\n>>>>>>\n>>>>>> Lightning-dev mailing list\n>>>>>> Lightning-dev at lists.linuxfoundation.org\n>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> \n>"
            },
            {
                "author": "Christian Decker",
                "date": "2020-01-29T13:14:19",
                "message_text_only": "Matt Corallo <lf-lists at mattcorallo.com> writes:\n> Right, but there are approaches that are not as susceptible - an\n> obvious, albeit somewhat naive, approach would be to define a fixed and\n> proportional max fee, and pick a random (with some privacy properties eg\n> biasing towards old or good-reputation nodes, routing across nodes\n> hosted on different ISPs/Tor/across continents, etc) route that pays no\n> more than those fees unless no such route is available. You could\n> imagine hard-coding such fees to \"fees that are generally available on\n> the network as observed in the real world\".\n\nThis is sort of what we do already in c-lightning, namely we set up a\nfee budget of 0.5% and then select a random route within this\nconstraint. On top we also fuzz the amount and other parameters within\nthis range and similar ones in order to obfuscate the distance to the\nrecipient, i.e., slightly overpaying the recipient, but simulating a\nshadow route.\n\nSo while not fixed in the network, we built our own fuzzing on top of\nthe real fees. The rationaly behind this is that users will simply not\ncare to optimize down to the satoshi, and the resulting randomization\nhelps privcay. We don't have real numbers but recent research results\nshow that attempting to squeeze the very last bit of fees out has a\ndetrimental effect on sender-receiver-privcay (surprise...).\n\nCheers,\nChristian"
            }
        ],
        "thread_summary": {
            "title": "Not revealing the channel capacity during opening of channel in lightning network",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Matt Corallo",
                "Ugam Kamat",
                "Subhra Mazumdar",
                "ZmnSCPxj",
                "Christian Decker"
            ],
            "messages_count": 11,
            "total_messages_chars_count": 37596
        }
    },
    {
        "title": "[Lightning-dev] DRAFT: interactive tx construction protocol",
        "thread_messages": [
            {
                "author": "lisa neigut",
                "date": "2020-01-28T01:51:28",
                "message_text_only": "Some of the feedback I received from the check-in for the dual-funding\nproposal this past Monday was along the lines that we look at simplifying\nfor breaking it into smaller, more manageable chunks.\n\nThe biggest piece of the dual-funding protocol update is definitely the\nmove from a single peer constructing a transaction to two participants.\nWe're also going to likely want to reuse this portion of the protocol for\nbatched closings and splicing. To that extent, it seemed useful to\nhighlight it in a separate email.\n\nThis is a change from the existing proposal in the dual-funding PR #524\n<https://github.com/lightningnetwork/lightning-rfc/pull/524> -- it allows\nfor the removal of inputs and outputs.\n\nThe set of messages are as follows.\n\n\nNote that the 'initiation' of this protocol will be different depending on\nthe case of the transaction (open, close or splice):\n\n1. type:   440 `tx_add_input`\n\n2. data:\n\n    * [`32*byte`:`channel_identifier`]\n\n    * [`u64`:`sats`]\n\n    * [`sha256`:`prevtx_txid`]\n\n    * [`u32`:`prevtx_vout`]\n\n    * [`u16`:`prevtx_scriptpubkey_len`]\n\n    * [`prevtx_scriptpubkey_len*byte`:`prevtx_scriptpubkey`]\n\n    * [`u16`:`max_witness_len`]\n\n    * [`u16`:`scriptlen`]\n\n    * [`scriptlen*byte`:`script`]\n\n    * [`byte`:`signal_rbf`]\n\n1. type: 442 `tx_add_output`\n\n2. data:\n\n    * [`32*byte`:`channel_identifier`]\n\n    * [`u64`:`sats`]\n\n    * [`u16`:`scriptlen`]\n\n    * [`scriptlen*byte`:`script`]\n\n1. type: 444 `tx_remove_input`\n\n2. data:\n\n    * [`32*byte`:`channel_identifier`]\n\n    * [`sha256`:`prevtx_txid`]\n\n    * [`u32`:`prevtx_vout`]\n\n1. type: 446 `tx_remove_output`\n\n2. data:\n\n    * [`32*byte`:`channel_identifier`]\n\n    * [`u64`:`sats`]\n\n    * [`u16`:`scriptlen`]\n\n    * [`scriptlen*byte`:`script`]\n\n1. type: 448 `tx_complete`\n\n2. data:\n\n    * [`32*byte`:`channel_identifier`]\n\n    * [`u16`:`num_inputs`]\n\n    * [`u16`:`num_outputs`]\n\n1. type:  448 `tx_sigs`\n\n2. data:\n\n    * [`channel_id`:`channel_identifier`]\n\n    * [`u16`:`num_witnesses`]\n\n    * [`num_witnesses*witness_stack`:`witness_stack`]\n\n1. subtype: `witness_stack`\n\n2. data:\n\n    * [`sha256`:`prevtx_txid`]\n\n    * [`u32`:`prevtx_vout`]\n\n    * [`u16`:`num_input_witness`]\n\n    * [`num_input_witness*witness_element`:`witness_element`]\n\n1. subtype: `witness_element`\n\n2. data:\n\n    * [`u16`:`len`]\n\n    * [`len*byte`:`witness`]\n\n\n\n## General Notes\n\n- Validity of inputs/outputs is not checked until both peers have sent\nconsecutive `tx_complete`  messages.\n\n- Duplicate inputs or outputs is a protocol error.\n\n- Feerate is set by the initiator, or in the case of a closing transaction,\nnegotiated before the transaction construction is initiated.\n\n- Every peer pays fees for the inputs + outputs they contribute, plus\nenough to cover the maximum estimate of their witnesses. Overpayment of\nfees is permissible.\n\n- Initiator is responsible for contributing the output/input in question,\ni.e. the\n\n  funding output in the case of an opening, or the funding input in the\ncase of a close.\n\n  (This means that the opener will pay for the opening output). In the case\nof a splice,\n\n  the initiator of the splice pays for the funding tx's inclusion as an\ninput and the\n\n  new 'funding tx' output.\n\n- Any contributor may signal that their input is RBF'able. The nSequence\nfor this input should be set to 0xFEFF FFFF, 0xFFFFFFFF otherwise.\n\n- The initiating peer is understood to be paying the fee for the shared\ntransaction fields (nVersion [4], segwit marker + flag [2], input + output\ncounts [2-18], witness count [1-9], nLocktime [4]; total [13-40bytes])\n\n- Inputs MUST be segwit compatible (PW* or P2SH-PW*)\n\n- All output scripts must be standard\n\n- nLocktime is always set to 0x00000000.\n\n- The `num_inputs` and `num_outputs` in `tx_complete` is a count of that\npeer\u2019s final input and output contributions, net any removals.\n\n- Either peer may add or remove inputs and outputs until both peers have\nsuccessfully\n\n  exchanged a `tx_complete` message in succession.\n\n- Either peer may only add or remove their own input or output.\n\n- In the case that a `tx_complete` agreement cannot be reached, either peer\nmay\n\n  fail the channel or open protocol (whatever is reasonable for the\nparticular case)\n\n  - In the case of a splice, this would be a soft error (channel returns to\nnormal operation until\n\n    otherwise failed or closed.)\n\n  - In the case of an open, this would be a failure to open the channel.\n\n  - In the case of a close, a failed collaborative close would result in an\nerror and a unilateral close.\n\n### Considering the Simple Open case (2 parties)\n\n- Both peers signal `opt_dual_fund`\n\n- Opener initiates a channel open with `open_channel2` message, indicating\nthe feerate for the opening transaction\n\n- Accepter signals acceptance of channel open as proposed, including\nproposed feerate, via `accept_channel2`\n\n- Opener sends `tx_add_output`, with the funding output for the sum of both\npeer\u2019s funding_amount\n\n- Opener sends `tx_add_input` for each input the wish to add to the funding\ntransaction\n\n- Opener sends `tx_add_output` for their change\n\n- Opener sends `tx_complete`\n\n- Accepter sends `tx_add_input` for each input they wish to add to the\nfunding transaction\n\n- Accepter sends `tx_add_output` for their change.\n\n- Accepter sends `tx_complete`\n\n- Opener sends `tx_complete`\n\n- Opener and accepter exchange commitment signatures; etc.\n\n### Considering the Splice case:\n\n- Both peers signal `opt_splice_ok`\n\n- One peer initiates a splice, also signaling the feerate for the\ntransaction. Exact protocol unspecified herein.\n\n- Initiator sends `tx_add_input` with the original funding output\n\n- Initiator sends `tx_add_output` with the new, post-splice funding output\n\n- Initiator sends `tx_add_input/output` as needed to add all desired inputs\n+ outputs\n\n- Initiator sends `tx_complete`\n\n- Peer sends `tx_add_input/output` as needed to add all desired inputs +\noutputs\n\n- Initiator sends `tx_complete`\n\n- Peer sends `tx_complete`\n\n- Initiator + peer exchange commitment signatures, etc.\n\n### Considering the Close case:\n\n- Both peers signal `opt_collaborative_close` in their `node_announcement`.\n\n- A peer initiates a close sending a `shutdown`, as per usual.\n\n- A feerate is negotiated. Out of band for this particular portion of the\nprotocol.\n\n-The closing initiator (peer which first sent `shutdown`), sends\n`tx_add_input` to spend the funding output and `tx_add_output` to add their\noutput for the channel closure.\n\n- The peer responds with `tx_add_output`, adding their output to the close\ntransaction.\n\n- If `option_upfront_shutdown_script` is flagged but no such output with a\nvalue at or within a reasonable feerate gap of the peer's funding output is\npresent, then the peer must fail the channel.\n\n\n## Updating a collaborative transaction with RBF:\n\n- If any input is flagged as RBF\u2019able, then the transaction is considered\neligible for RBF\n\n- RBF can be initiated by either party, and serves as an initiation for\nanother round of transaction composition, as outlined above.\n\n- Note that this section has been cribbed and re-purposed from the original\nRBF proposal for splicing, see\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001621.html\n\n1. type: 45 (`init_rbf`) (`option_collaborative_rbf`)\n\n2. data:\n\n   * [`32`:`channel_id`]\n\n   * [`4`:`fee_step`]\n\nEach `fee_step` adds 1/4 (rounded down) to the initial\n\ntransaction feerate. eg. if the initial feerate was 512 satoshis per\nkiloweight, `fee_step` 1\n\nis  512 + 512 / 4 = 640, `fee_step` 2 is 640 + 640 / 4 = 800.\n\nThe sender:\n\n  - MUST set `fee_step` greater than zero and greater than any prior\n`fee_step`.\n\nThe recipient:\n\n  - if the new fee exceeds the sender's current balance minus reserve\n\n    after it is applied to the splice transaction:\n\n    - MUST error.\n\n\n\nNOTES:\n\n1. 1/4 is a reasonable minimal RBF, but as each one requires more\n\n   tracking by the recipient, serves to limit the number you can create.\n\n2. Rule 4 of BIP125 requires a feerate increase to at least surpass the\nminimum transaction relay setting. Ratcheting by 25% should satisfy this\nrequirement\n\n3. An additional rule will be added to the checks of an RBF transaction\nthat it must include at least one identical, replaceable input as the\noriginal transaction.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200127/ca2e504d/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-01-30T00:21:14",
                "message_text_only": "Hey thanks for this proposal!\n\n2 high-level questions:\n\nWhat about multi-party tx construction ? By multi-party, let's define\nAlice initiate a tx construction to Bob and then Bob announce a\nconstruction to Caroll and \"bridge\" all inputs/outputs\nadditions/substractions\nin both directions. I think the current proposal hold, if you are a bit more\ntolerant and bridge peer don't send a tx_complete before receiving ones\nfrom all its peers.\n\nWhat about transactions format ? I think we should coordinate with Coinjoin\npeople to converge to a common one to avoid leaking protocol usage when\nwe can hinder under Taproot. Like setting the nLocktime or sorting inputs\nin some protocol-specific fashion. Ideally we should have a BIP for format\nbut every layer 2 protocols its own set of messages concerning the\nconstruction.\n\n> nLocktime is always set to 0x000000\nMaybe we can implement anti-fee sniping and mask among wallet core\ntxn set:\nhttps://github.com/bitcoin/bitcoin/blob/aabec94541e23a67a9f30dc2c80dab3383a01737/src/wallet/wallet.cpp#L2519\n?\n\n> In the case of a close, a failed collaborative close would result in an\nerror and a uninlateral close\"\nOr can we do first a mutual closing tx, hold tx broadcast for a bit if\n\"opt_dual_fund\"\nis signaled to see if a tx_construction + add_funding_input for the channel\nis received\nsoon ? At least that would be a dual opt-in to know than one party can\nsubmit a funding-outpoint\nas part of a composed tx ?\n\nAntoine\n\nLe lun. 27 janv. 2020 \u00e0 20:51, lisa neigut <niftynei at gmail.com> a \u00e9crit :\n\n> Some of the feedback I received from the check-in for the dual-funding\n> proposal this past Monday was along the lines that we look at simplifying\n> for breaking it into smaller, more manageable chunks.\n>\n> The biggest piece of the dual-funding protocol update is definitely the\n> move from a single peer constructing a transaction to two participants.\n> We're also going to likely want to reuse this portion of the protocol for\n> batched closings and splicing. To that extent, it seemed useful to\n> highlight it in a separate email.\n>\n> This is a change from the existing proposal in the dual-funding PR #524\n> <https://github.com/lightningnetwork/lightning-rfc/pull/524> -- it allows\n> for the removal of inputs and outputs.\n>\n> The set of messages are as follows.\n>\n>\n> Note that the 'initiation' of this protocol will be different depending\n> on the case of the transaction (open, close or splice):\n>\n> 1. type:   440 `tx_add_input`\n>\n> 2. data:\n>\n>     * [`32*byte`:`channel_identifier`]\n>\n>     * [`u64`:`sats`]\n>\n>     * [`sha256`:`prevtx_txid`]\n>\n>     * [`u32`:`prevtx_vout`]\n>\n>     * [`u16`:`prevtx_scriptpubkey_len`]\n>\n>     * [`prevtx_scriptpubkey_len*byte`:`prevtx_scriptpubkey`]\n>\n>     * [`u16`:`max_witness_len`]\n>\n>     * [`u16`:`scriptlen`]\n>\n>     * [`scriptlen*byte`:`script`]\n>\n>     * [`byte`:`signal_rbf`]\n>\n> 1. type: 442 `tx_add_output`\n>\n> 2. data:\n>\n>     * [`32*byte`:`channel_identifier`]\n>\n>     * [`u64`:`sats`]\n>\n>     * [`u16`:`scriptlen`]\n>\n>     * [`scriptlen*byte`:`script`]\n>\n> 1. type: 444 `tx_remove_input`\n>\n> 2. data:\n>\n>     * [`32*byte`:`channel_identifier`]\n>\n>     * [`sha256`:`prevtx_txid`]\n>\n>     * [`u32`:`prevtx_vout`]\n>\n> 1. type: 446 `tx_remove_output`\n>\n> 2. data:\n>\n>     * [`32*byte`:`channel_identifier`]\n>\n>     * [`u64`:`sats`]\n>\n>     * [`u16`:`scriptlen`]\n>\n>     * [`scriptlen*byte`:`script`]\n>\n> 1. type: 448 `tx_complete`\n>\n> 2. data:\n>\n>     * [`32*byte`:`channel_identifier`]\n>\n>     * [`u16`:`num_inputs`]\n>\n>     * [`u16`:`num_outputs`]\n>\n> 1. type:  448 `tx_sigs`\n>\n> 2. data:\n>\n>     * [`channel_id`:`channel_identifier`]\n>\n>     * [`u16`:`num_witnesses`]\n>\n>     * [`num_witnesses*witness_stack`:`witness_stack`]\n>\n> 1. subtype: `witness_stack`\n>\n> 2. data:\n>\n>     * [`sha256`:`prevtx_txid`]\n>\n>     * [`u32`:`prevtx_vout`]\n>\n>     * [`u16`:`num_input_witness`]\n>\n>     * [`num_input_witness*witness_element`:`witness_element`]\n>\n> 1. subtype: `witness_element`\n>\n> 2. data:\n>\n>     * [`u16`:`len`]\n>\n>     * [`len*byte`:`witness`]\n>\n>\n>\n> ## General Notes\n>\n> - Validity of inputs/outputs is not checked until both peers have sent\n> consecutive `tx_complete`  messages.\n>\n> - Duplicate inputs or outputs is a protocol error.\n>\n> - Feerate is set by the initiator, or in the case of a closing\n> transaction, negotiated before the transaction construction is initiated.\n>\n> - Every peer pays fees for the inputs + outputs they contribute, plus\n> enough to cover the maximum estimate of their witnesses. Overpayment of\n> fees is permissible.\n>\n> - Initiator is responsible for contributing the output/input in question,\n> i.e. the\n>\n>   funding output in the case of an opening, or the funding input in the\n> case of a close.\n>\n>   (This means that the opener will pay for the opening output). In the\n> case of a splice,\n>\n>   the initiator of the splice pays for the funding tx's inclusion as an\n> input and the\n>\n>   new 'funding tx' output.\n>\n> - Any contributor may signal that their input is RBF'able. The nSequence\n> for this input should be set to 0xFEFF FFFF, 0xFFFFFFFF otherwise.\n>\n> - The initiating peer is understood to be paying the fee for the shared\n> transaction fields (nVersion [4], segwit marker + flag [2], input + output\n> counts [2-18], witness count [1-9], nLocktime [4]; total [13-40bytes])\n>\n> - Inputs MUST be segwit compatible (PW* or P2SH-PW*)\n>\n> - All output scripts must be standard\n>\n> - nLocktime is always set to 0x00000000.\n>\n> - The `num_inputs` and `num_outputs` in `tx_complete` is a count of that\n> peer\u2019s final input and output contributions, net any removals.\n>\n> - Either peer may add or remove inputs and outputs until both peers have\n> successfully\n>\n>   exchanged a `tx_complete` message in succession.\n>\n> - Either peer may only add or remove their own input or output.\n>\n> - In the case that a `tx_complete` agreement cannot be reached, either\n> peer may\n>\n>   fail the channel or open protocol (whatever is reasonable for the\n> particular case)\n>\n>   - In the case of a splice, this would be a soft error (channel returns\n> to normal operation until\n>\n>     otherwise failed or closed.)\n>\n>   - In the case of an open, this would be a failure to open the channel.\n>\n>   - In the case of a close, a failed collaborative close would result in\n> an error and a unilateral close.\n>\n> ### Considering the Simple Open case (2 parties)\n>\n> - Both peers signal `opt_dual_fund`\n>\n> - Opener initiates a channel open with `open_channel2` message, indicating\n> the feerate for the opening transaction\n>\n> - Accepter signals acceptance of channel open as proposed, including\n> proposed feerate, via `accept_channel2`\n>\n> - Opener sends `tx_add_output`, with the funding output for the sum of\n> both peer\u2019s funding_amount\n>\n> - Opener sends `tx_add_input` for each input the wish to add to the\n> funding transaction\n>\n> - Opener sends `tx_add_output` for their change\n>\n> - Opener sends `tx_complete`\n>\n> - Accepter sends `tx_add_input` for each input they wish to add to the\n> funding transaction\n>\n> - Accepter sends `tx_add_output` for their change.\n>\n> - Accepter sends `tx_complete`\n>\n> - Opener sends `tx_complete`\n>\n> - Opener and accepter exchange commitment signatures; etc.\n>\n> ### Considering the Splice case:\n>\n> - Both peers signal `opt_splice_ok`\n>\n> - One peer initiates a splice, also signaling the feerate for the\n> transaction. Exact protocol unspecified herein.\n>\n> - Initiator sends `tx_add_input` with the original funding output\n>\n> - Initiator sends `tx_add_output` with the new, post-splice funding output\n>\n> - Initiator sends `tx_add_input/output` as needed to add all desired\n> inputs + outputs\n>\n> - Initiator sends `tx_complete`\n>\n> - Peer sends `tx_add_input/output` as needed to add all desired inputs +\n> outputs\n>\n> - Initiator sends `tx_complete`\n>\n> - Peer sends `tx_complete`\n>\n> - Initiator + peer exchange commitment signatures, etc.\n>\n> ### Considering the Close case:\n>\n> - Both peers signal `opt_collaborative_close` in their `node_announcement`.\n>\n> - A peer initiates a close sending a `shutdown`, as per usual.\n>\n> - A feerate is negotiated. Out of band for this particular portion of the\n> protocol.\n>\n> -The closing initiator (peer which first sent `shutdown`), sends\n> `tx_add_input` to spend the funding output and `tx_add_output` to add their\n> output for the channel closure.\n>\n> - The peer responds with `tx_add_output`, adding their output to the close\n> transaction.\n>\n> - If `option_upfront_shutdown_script` is flagged but no such output with a\n> value at or within a reasonable feerate gap of the peer's funding output is\n> present, then the peer must fail the channel.\n>\n>\n> ## Updating a collaborative transaction with RBF:\n>\n> - If any input is flagged as RBF\u2019able, then the transaction is considered\n> eligible for RBF\n>\n> - RBF can be initiated by either party, and serves as an initiation for\n> another round of transaction composition, as outlined above.\n>\n> - Note that this section has been cribbed and re-purposed from the\n> original RBF proposal for splicing, see\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001621.html\n>\n> 1. type: 45 (`init_rbf`) (`option_collaborative_rbf`)\n>\n> 2. data:\n>\n>    * [`32`:`channel_id`]\n>\n>    * [`4`:`fee_step`]\n>\n> Each `fee_step` adds 1/4 (rounded down) to the initial\n>\n> transaction feerate. eg. if the initial feerate was 512 satoshis per\n> kiloweight, `fee_step` 1\n>\n> is  512 + 512 / 4 = 640, `fee_step` 2 is 640 + 640 / 4 = 800.\n>\n> The sender:\n>\n>   - MUST set `fee_step` greater than zero and greater than any prior\n> `fee_step`.\n>\n> The recipient:\n>\n>   - if the new fee exceeds the sender's current balance minus reserve\n>\n>     after it is applied to the splice transaction:\n>\n>     - MUST error.\n>\n>\n>\n> NOTES:\n>\n> 1. 1/4 is a reasonable minimal RBF, but as each one requires more\n>\n>    tracking by the recipient, serves to limit the number you can create.\n>\n> 2. Rule 4 of BIP125 requires a feerate increase to at least surpass the\n> minimum transaction relay setting. Ratcheting by 25% should satisfy this\n> requirement\n>\n> 3. An additional rule will be added to the checks of an RBF transaction\n> that it must include at least one identical, replaceable input as the\n> original transaction.\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200129/d155c0a0/attachment-0001.html>"
            },
            {
                "author": "darosior",
                "date": "2020-01-30T09:06:45",
                "message_text_only": "Hi Antoine and all,\n\n\n\n\n\n\n\nAbout nLockTime fun thing is Lisa, Cdecker and I had this conversation to integrate it to C-lightning just yesterday.\n\n\n\n\n\n\n\nUnfortunately you need to add a \"My tip is xxxx\" to the openchannel msg, otherwise if you set nLockTime to tip. (cdecker)\n\n\n\n\n\n\n\nMoreover in case of reorg the funding tx (now non-final) would be dropped from mempool ? But you could set nLockTime to, say, tip - 6. (niftynei)\n\n\n\n\n\n\n\nAntoine\n\n\n\n\n\n\\-------- Original Message --------\nOn Jan 30, 2020, 01:21, Antoine Riard < antoine.riard at gmail.com> wrote:\n\n>\n>\n>\n> Hey thanks for this proposal!\n>\n>\n>\n> 2 high-level questions:\n>\n>\n>\n>\n>\n> What about multi-party tx construction ? By multi-party, let's define\n>\n> Alice initiate a tx construction to Bob and then Bob announce a\n>\n>\n> construction to Caroll and \"bridge\" all inputs/outputs additions/substractions\n>\n>\n> in both directions. I think the current proposal hold, if you are a bit more\n>\n>\n> tolerant and bridge peer don't send a tx\\_complete before receiving ones\n>\n>\n> from all its peers.\n>\n>\n>\n>\n>\n> What about transactions format ? I think we should coordinate with Coinjoin\n>\n>\n> people to converge to a common one to avoid leaking protocol usage when\n> we can hinder under Taproot. Like setting the nLocktime or sorting inputs\n>\n>\n> in some protocol-specific fashion. Ideally we should have a BIP for format\n>\n>\n> but every layer 2 protocols its own set of messages concerning the construction.\n>\n> > nLocktime is always set to 0x000000\n> Maybe we can implement anti-fee sniping and mask among wallet core\n> txn set: [https://github.com/bitcoin/bitcoin/blob/aabec94541e23a67a9f30dc2c80dab3383a01737/src/wallet/wallet.cpp\\#L2519][https_github.com_bitcoin_bitcoin_blob_aabec94541e23a67a9f30dc2c80dab3383a01737_src_wallet_wallet.cpp_L2519] ?\n>\n> > In the case of a close, a failed collaborative close would result in an error and a uninlateral close\"\n> Or can we do first a mutual closing tx, hold tx broadcast for a bit if \"opt\\_dual\\_fund\"\n> is signaled to see if a tx\\_construction + add\\_funding\\_input for the channel is received\n> soon ? At least that would be a dual opt-in to know than one party can submit a funding-outpoint\n> as part of a composed tx ?\n>\n>\n>\n>\n> Antoine\n>\n>\n>\n>\n>\n> Le\u00a0lun. 27 janv. 2020 \u00e0\u00a020:51, lisa neigut <[niftynei at gmail.com][niftynei_gmail.com]> a \u00e9crit\u00a0:\n>\n>\n> > Some of the feedback I received from the check-in for the dual-funding proposal this past Monday was along the lines that we look at simplifying for breaking it into smaller, more manageable chunks.\n> >\n> >\n> >\n> >\n> > The biggest piece of the dual-funding protocol update is definitely the move from a single peer constructing a transaction to two participants. We're also going to likely want to reuse this portion of the protocol for batched closings and splicing. To that extent, it seemed useful to highlight it in a separate email.\n> >\n> >\n> >\n> >\n> > This is a change from the existing proposal in the dual-funding [PR \\#524][PR _524] \\-- it allows for the removal of inputs and outputs.\n> >\n> >\n> >\n> >\n> > The set of messages are as follows.\n> >\n> >\n> >\n> >\n> > Note that the 'initiation' of this protocol will be different depending on the case of the transaction (open, close or splice):\n> >\n> >\n> >\n> >\n> > 1. type: \u00a0 440 \\`tx\\_add\\_input\\`\n> >\n> > 2. data:\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`32\\*byte\\`:\\`channel\\_identifier\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u64\\`:\\`sats\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`sha256\\`:\\`prevtx\\_txid\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u32\\`:\\`prevtx\\_vout\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`prevtx\\_scriptpubkey\\_len\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`prevtx\\_scriptpubkey\\_len\\*byte\\`:\\`prevtx\\_scriptpubkey\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`max\\_witness\\_len\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`scriptlen\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`scriptlen\\*byte\\`:\\`script\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`byte\\`:\\`signal\\_rbf\\`\\]\n> >\n> >\n> >\n> >\n> > 1. type: 442 \\`tx\\_add\\_output\\`\n> >\n> > 2. data:\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`32\\*byte\\`:\\`channel\\_identifier\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u64\\`:\\`sats\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`scriptlen\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`scriptlen\\*byte\\`:\\`script\\`\\]\n> >\n> >\n> >\n> >\n> > 1. type: 444 \\`tx\\_remove\\_input\\`\n> >\n> > 2. data:\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`32\\*byte\\`:\\`channel\\_identifier\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`sha256\\`:\\`prevtx\\_txid\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u32\\`:\\`prevtx\\_vout\\`\\]\n> >\n> >\n> >\n> >\n> > 1. type: 446 \\`tx\\_remove\\_output\\`\n> >\n> > 2. data:\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`32\\*byte\\`:\\`channel\\_identifier\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u64\\`:\\`sats\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`scriptlen\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`scriptlen\\*byte\\`:\\`script\\`\\]\n> >\n> >\n> >\n> >\n> > 1. type: 448 \\`tx\\_complete\\`\n> >\n> > 2. data:\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`32\\*byte\\`:\\`channel\\_identifier\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`num\\_inputs\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`num\\_outputs\\`\\]\n> >\n> >\n> >\n> >\n> > 1. type:\u00a0 448 \\`tx\\_sigs\\`\n> >\n> > 2. data:\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`channel\\_id\\`:\\`channel\\_identifier\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`num\\_witnesses\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`num\\_witnesses\\*witness\\_stack\\`:\\`witness\\_stack\\`\\]\n> >\n> >\n> >\n> >\n> > 1. subtype: \\`witness\\_stack\\`\n> >\n> > 2. data:\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`sha256\\`:\\`prevtx\\_txid\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u32\\`:\\`prevtx\\_vout\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`num\\_input\\_witness\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`num\\_input\\_witness\\*witness\\_element\\`:\\`witness\\_element\\`\\]\n> >\n> >\n> >\n> >\n> > 1. subtype: \\`witness\\_element\\`\n> >\n> > 2. data:\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`len\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`len\\*byte\\`:\\`witness\\`\\]\n> >\n> >\n> >\n> >\n> >\n> >\n> >\n> > \\#\\# General Notes\n> >\n> > \\- Validity of inputs/outputs is not checked until both peers have sent consecutive \\`tx\\_complete\\`\u00a0\u00a0messages.\n> >\n> > \\- Duplicate inputs or outputs is a protocol error.\n> >\n> > \\- Feerate is set by the initiator, or in the case of a closing transaction, negotiated before the transaction construction is initiated.\n> >\n> > \\- Every peer pays fees for the inputs + outputs they contribute, plus enough to cover the maximum estimate of their witnesses. Overpayment of fees is permissible.\n> >\n> > \\- Initiator is responsible for contributing the output/input in question, i.e. the\u00a0\n> >\n> > \u00a0\u00a0funding output in the case of an opening, or the funding input in the case of a close.\u00a0\n> >\n> > \u00a0\u00a0(This means that the opener will pay for the opening output). In the case of a splice,\n> >\n> > \u00a0\u00a0the initiator of the splice pays for the funding tx's inclusion as an input and the\n> >\n> > \u00a0\u00a0new 'funding tx' output.\n> >\n> > \\- Any contributor may signal that their input is RBF'able. The nSequence for this input should be set to 0xFEFF FFFF, 0xFFFFFFFF otherwise.\n> >\n> > \\- The initiating peer is understood to be paying the fee for the shared transaction fields (nVersion \\[4\\], segwit marker + flag \\[2\\], input + output counts \\[2-18\\], witness count \\[1-9\\], nLocktime \\[4\\]; total \\[13-40bytes\\])\n> >\n> > \\- Inputs MUST be segwit compatible (PW\\* or P2SH-PW\\*)\n> >\n> > \\- All output scripts must be standard\n> >\n> > \\- nLocktime is always set to 0x00000000.\n> >\n> > \\- The \\`num\\_inputs\\` and \\`num\\_outputs\\` in \\`tx\\_complete\\` is a count of that peer\u2019s final input and output contributions, net any removals.\n> >\n> >\n> >\n> >\n> > \\- Either peer may add or remove inputs and outputs until both peers have successfully\n> >\n> > \u00a0\u00a0exchanged a \\`tx\\_complete\\` message in succession.\n> >\n> > \\- Either peer may only add or remove their own input or output.\n> >\n> > \\- In the case that a \\`tx\\_complete\\` agreement cannot be reached, either peer may\n> >\n> > \u00a0\u00a0fail the channel or open protocol (whatever is reasonable for the particular case)\n> >\n> > \u00a0\u00a0- In the case of a splice, this would be a soft error (channel returns to normal operation until\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n> >\n> > \u00a0\u00a0\u00a0\u00a0otherwise failed or closed.)\n> >\n> > \u00a0\u00a0- In the case of an open, this would be a failure to open the channel.\n> >\n> > \u00a0\u00a0- In the case of a close, a failed collaborative close would result in an error and a unilateral close.\n> >\n> >\n> >\n> >\n> > \\#\\#\\# Considering the Simple Open case (2 parties)\n> >\n> > \\- Both peers signal \\`opt\\_dual\\_fund\\`\n> >\n> > \\- Opener initiates a channel open with \\`open\\_channel2\\` message, indicating the feerate for the opening transaction\n> >\n> > \\- Accepter signals acceptance of channel open as proposed, including proposed feerate, via \\`accept\\_channel2\\`\n> >\n> > \\- Opener sends \\`tx\\_add\\_output\\`, with the funding output for the sum of both peer\u2019s funding\\_amount\n> >\n> > \\- Opener sends \\`tx\\_add\\_input\\` for each input the wish to add to the funding transaction\n> >\n> > \\- Opener sends \\`tx\\_add\\_output\\` for their change\u00a0\n> >\n> > \\- Opener sends \\`tx\\_complete\\`\n> >\n> > \\- Accepter sends \\`tx\\_add\\_input\\` for each input they wish to add to the funding transaction\n> >\n> > \\- Accepter sends \\`tx\\_add\\_output\\` for their change.\n> >\n> > \\- Accepter sends \\`tx\\_complete\\`\n> >\n> > \\- Opener sends \\`tx\\_complete\\`\n> >\n> > \\- Opener and accepter exchange commitment signatures; etc.\n> >\n> >\n> >\n> >\n> > \\#\\#\\# Considering the Splice case:\n> >\n> > \\- Both peers signal \\`opt\\_splice\\_ok\\`\n> >\n> > \\- One peer initiates a splice, also signaling the feerate for the transaction. Exact protocol unspecified herein.\n> >\n> > \\- Initiator sends \\`tx\\_add\\_input\\` with the original funding output\n> >\n> > \\- Initiator sends \\`tx\\_add\\_output\\` with the new, post-splice funding output\n> >\n> > \\- Initiator sends \\`tx\\_add\\_input/output\\` as needed to add all desired inputs + outputs\n> >\n> > \\- Initiator sends \\`tx\\_complete\\`\n> >\n> > \\- Peer sends \\`tx\\_add\\_input/output\\` as needed to add all desired inputs + outputs\n> >\n> > \\- Initiator sends \\`tx\\_complete\\`\n> >\n> > \\- Peer sends \\`tx\\_complete\\`\n> >\n> > \\- Initiator + peer exchange commitment signatures, etc.\n> >\n> >\n> >\n> >\n> > \\#\\#\\# Considering the Close case:\n> >\n> > \\- Both peers signal \\`opt\\_collaborative\\_close\\` in their \\`node\\_announcement\\`.\n> >\n> > \\- A peer initiates a close sending a \\`shutdown\\`, as per usual.\u00a0\n> >\n> > \\- A feerate is negotiated. Out of band for this particular portion of the protocol.\n> >\n> > \\-The closing initiator (peer which first sent \\`shutdown\\`), sends \\`tx\\_add\\_input\\` to spend the funding output and \\`tx\\_add\\_output\\` to add their output for the channel closure.\n> >\n> > \\- The peer responds with \\`tx\\_add\\_output\\`, adding their output to the close transaction.\n> >\n> > \\- If \\`option\\_upfront\\_shutdown\\_script\\` is flagged but no such output with a value at or within a reasonable feerate gap of the peer's funding output is present, then the peer must fail the channel.\u00a0\n> >\n> >\n> >\n> >\n> >\n> > \\#\\# Updating a collaborative transaction with RBF:\n> >\n> > \\- If any input is flagged as RBF\u2019able, then the transaction is considered eligible for RBF\n> >\n> > \\- RBF can be initiated by either party, and serves as an initiation for another round of transaction composition, as outlined above.\n> >\n> > \\- Note that this section has been cribbed and re-purposed from the original RBF proposal for splicing, see https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001621.html\n> >\n> >\n> >\n> >\n> > 1. type: 45 (\\`init\\_rbf\\`) (\\`option\\_collaborative\\_rbf\\`)\n> >\n> > 2. data:\n> >\n> > \u00a0\u00a0\u00a0\\* \\[\\`32\\`:\\`channel\\_id\\`\\]\n> >\n> > \u00a0\u00a0\u00a0\\* \\[\\`4\\`:\\`fee\\_step\\`\\]\n> >\n> >\n> >\n> >\n> > Each \\`fee\\_step\\` adds 1/4 (rounded down) to the initial\u00a0\n> >\n> > transaction feerate. eg. if the initial feerate was 512 satoshis per kiloweight, \\`fee\\_step\\` 1\n> >\n> > is\u00a0 512 + 512 / 4 = 640, \\`fee\\_step\\` 2 is 640 + 640 / 4 = 800.\n> >\n> >\n> >\n> >\n> > The sender:\n> >\n> > \u00a0\u00a0- MUST set \\`fee\\_step\\` greater than zero and greater than any prior \\`fee\\_step\\`.\n> >\n> >\n> >\n> >\n> > The recipient:\n> >\n> > \u00a0\u00a0- if the new fee exceeds the sender's current balance minus reserve\n> >\n> > \u00a0\u00a0\u00a0\u00a0after it is applied to the splice transaction:\n> >\n> > \u00a0\u00a0\u00a0\u00a0- MUST error.\n> >\n> > \u00a0\u00a0\n> >\n> > NOTES:\n> >\n> > 1. 1/4 is a reasonable minimal RBF, but as each one requires more\n> >\n> > \u00a0\u00a0\u00a0tracking by the recipient, serves to limit the number you can create.\n> >\n> > 2. Rule 4 of BIP125 requires a feerate increase to at least surpass the minimum transaction relay setting. Ratcheting by 25% should satisfy this requirement\n> >\n> > 3. An additional rule will be added to the checks of an RBF transaction that it must include at least one identical, replaceable input as the original transaction.\n> >\n> >\n> >\n> >\n> > \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n> > Lightning-dev mailing list\n> > [Lightning-dev at lists.linuxfoundation.org][Lightning-dev_lists.linuxfoundation.org]\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> >\n\n\n[https_github.com_bitcoin_bitcoin_blob_aabec94541e23a67a9f30dc2c80dab3383a01737_src_wallet_wallet.cpp_L2519]: https://github.com/bitcoin/bitcoin/blob/aabec94541e23a67a9f30dc2c80dab3383a01737/src/wallet/wallet.cpp#L2519\n[niftynei_gmail.com]: mailto:niftynei at gmail.com\n[PR _524]: https://github.com/lightningnetwork/lightning-rfc/pull/524\n[Lightning-dev_lists.linuxfoundation.org]: mailto:Lightning-dev at lists.linuxfoundation.org\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200130/d9c6c20e/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 489 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200130/d9c6c20e/attachment-0001.sig>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-01-30T18:09:42",
                "message_text_only": "Hey Darosior,\n\nYou don't need a strict synchronization between both peers,\njust let nLocktime picked up by initiator and announce it at\nsame time than feerate or at `tx_complete`. Worst-case,\na slow-block-processing receiver may not be able to get\nthe transaction accepted by its local mempool, but IMO that's\nfine if at least the initiator is able to do so. We are requiring peers\nto be weakly in sync before operating channel anyway (`funding_locked`\nexchange).\n\nFunding_tx can already be drop from mempool for others\nreasons like mempool shrinks or expiry so broadcaster\nshould always be ready to re-send it or bump feerate.\n\nOr are you describing another issue ?\n\nLe jeu. 30 janv. 2020 \u00e0 04:06, darosior <darosior at protonmail.com> a \u00e9crit :\n\n> Hi Antoine and all,\n>\n>\n> About nLockTime fun thing is Lisa, Cdecker and I had this conversation to\n> integrate it to C-lightning just yesterday.\n>\n>\n> Unfortunately you need to add a \"My tip is xxxx\" to the openchannel msg,\n> otherwise if you set nLockTime to tip. (cdecker)\n>\n>\n> Moreover in case of reorg the funding tx (now non-final) would be dropped\n> from mempool ? But you could set nLockTime to, say, tip - 6. (niftynei)\n>\n>\n> Antoine\n>\n>\n> -------- Original Message --------\n> On Jan 30, 2020, 01:21, Antoine Riard < antoine.riard at gmail.com> wrote:\n>\n>\n> Hey thanks for this proposal!\n>\n> 2 high-level questions:\n>\n> What about multi-party tx construction ? By multi-party, let's define\n> Alice initiate a tx construction to Bob and then Bob announce a\n> construction to Caroll and \"bridge\" all inputs/outputs\n> additions/substractions\n> in both directions. I think the current proposal hold, if you are a bit\n> more\n> tolerant and bridge peer don't send a tx_complete before receiving ones\n> from all its peers.\n>\n> What about transactions format ? I think we should coordinate with Coinjoin\n> people to converge to a common one to avoid leaking protocol usage when\n> we can hinder under Taproot. Like setting the nLocktime or sorting inputs\n> in some protocol-specific fashion. Ideally we should have a BIP for format\n> but every layer 2 protocols its own set of messages concerning the\n> construction.\n>\n> > nLocktime is always set to 0x000000\n> Maybe we can implement anti-fee sniping and mask among wallet core\n> txn set:\n> https://github.com/bitcoin/bitcoin/blob/aabec94541e23a67a9f30dc2c80dab3383a01737/src/wallet/wallet.cpp#L2519\n> ?\n>\n> > In the case of a close, a failed collaborative close would result in an\n> error and a uninlateral close\"\n> Or can we do first a mutual closing tx, hold tx broadcast for a bit if\n> \"opt_dual_fund\"\n> is signaled to see if a tx_construction + add_funding_input for the\n> channel is received\n> soon ? At least that would be a dual opt-in to know than one party can\n> submit a funding-outpoint\n> as part of a composed tx ?\n>\n> Antoine\n>\n> Le lun. 27 janv. 2020 \u00e0 20:51, lisa neigut <niftynei at gmail.com> a \u00e9crit :\n>\n>> Some of the feedback I received from the check-in for the dual-funding\n>> proposal this past Monday was along the lines that we look at simplifying\n>> for breaking it into smaller, more manageable chunks.\n>>\n>> The biggest piece of the dual-funding protocol update is definitely the\n>> move from a single peer constructing a transaction to two participants.\n>> We're also going to likely want to reuse this portion of the protocol\n>> for batched closings and splicing. To that extent, it seemed useful to\n>> highlight it in a separate email.\n>>\n>> This is a change from the existing proposal in the dual-funding PR #524\n>> <https://github.com/lightningnetwork/lightning-rfc/pull/524> -- it\n>> allows for the removal of inputs and outputs.\n>>\n>> The set of messages are as follows.\n>>\n>>\n>> Note that the 'initiation' of this protocol will be different depending\n>> on the case of the transaction (open, close or splice):\n>>\n>> 1. type:   440 `tx_add_input`\n>>\n>> 2. data:\n>>\n>>     * [`32*byte`:`channel_identifier`]\n>>\n>>     * [`u64`:`sats`]\n>>\n>>     * [`sha256`:`prevtx_txid`]\n>>\n>>     * [`u32`:`prevtx_vout`]\n>>\n>>     * [`u16`:`prevtx_scriptpubkey_len`]\n>>\n>>     * [`prevtx_scriptpubkey_len*byte`:`prevtx_scriptpubkey`]\n>>\n>>     * [`u16`:`max_witness_len`]\n>>\n>>     * [`u16`:`scriptlen`]\n>>\n>>     * [`scriptlen*byte`:`script`]\n>>\n>>     * [`byte`:`signal_rbf`]\n>>\n>> 1. type: 442 `tx_add_output`\n>>\n>> 2. data:\n>>\n>>     * [`32*byte`:`channel_identifier`]\n>>\n>>     * [`u64`:`sats`]\n>>\n>>     * [`u16`:`scriptlen`]\n>>\n>>     * [`scriptlen*byte`:`script`]\n>>\n>> 1. type: 444 `tx_remove_input`\n>>\n>> 2. data:\n>>\n>>     * [`32*byte`:`channel_identifier`]\n>>\n>>     * [`sha256`:`prevtx_txid`]\n>>\n>>     * [`u32`:`prevtx_vout`]\n>>\n>> 1. type: 446 `tx_remove_output`\n>>\n>> 2. data:\n>>\n>>     * [`32*byte`:`channel_identifier`]\n>>\n>>     * [`u64`:`sats`]\n>>\n>>     * [`u16`:`scriptlen`]\n>>\n>>     * [`scriptlen*byte`:`script`]\n>>\n>> 1. type: 448 `tx_complete`\n>>\n>> 2. data:\n>>\n>>     * [`32*byte`:`channel_identifier`]\n>>\n>>     * [`u16`:`num_inputs`]\n>>\n>>     * [`u16`:`num_outputs`]\n>>\n>> 1. type:  448 `tx_sigs`\n>>\n>> 2. data:\n>>\n>>     * [`channel_id`:`channel_identifier`]\n>>\n>>     * [`u16`:`num_witnesses`]\n>>\n>>     * [`num_witnesses*witness_stack`:`witness_stack`]\n>>\n>> 1. subtype: `witness_stack`\n>>\n>> 2. data:\n>>\n>>     * [`sha256`:`prevtx_txid`]\n>>\n>>     * [`u32`:`prevtx_vout`]\n>>\n>>     * [`u16`:`num_input_witness`]\n>>\n>>     * [`num_input_witness*witness_element`:`witness_element`]\n>>\n>> 1. subtype: `witness_element`\n>>\n>> 2. data:\n>>\n>>     * [`u16`:`len`]\n>>\n>>     * [`len*byte`:`witness`]\n>>\n>>\n>>\n>> ## General Notes\n>>\n>> - Validity of inputs/outputs is not checked until both peers have sent\n>> consecutive `tx_complete`  messages.\n>>\n>> - Duplicate inputs or outputs is a protocol error.\n>>\n>> - Feerate is set by the initiator, or in the case of a closing\n>> transaction, negotiated before the transaction construction is initiated.\n>>\n>> - Every peer pays fees for the inputs + outputs they contribute, plus\n>> enough to cover the maximum estimate of their witnesses. Overpayment of\n>> fees is permissible.\n>>\n>> - Initiator is responsible for contributing the output/input in question,\n>> i.e. the\n>>\n>>   funding output in the case of an opening, or the funding input in the\n>> case of a close.\n>>\n>>   (This means that the opener will pay for the opening output). In the\n>> case of a splice,\n>>\n>>   the initiator of the splice pays for the funding tx's inclusion as an\n>> input and the\n>>\n>>   new 'funding tx' output.\n>>\n>> - Any contributor may signal that their input is RBF'able. The nSequence\n>> for this input should be set to 0xFEFF FFFF, 0xFFFFFFFF otherwise.\n>>\n>> - The initiating peer is understood to be paying the fee for the shared\n>> transaction fields (nVersion [4], segwit marker + flag [2], input + output\n>> counts [2-18], witness count [1-9], nLocktime [4]; total [13-40bytes])\n>>\n>> - Inputs MUST be segwit compatible (PW* or P2SH-PW*)\n>>\n>> - All output scripts must be standard\n>>\n>> - nLocktime is always set to 0x00000000.\n>>\n>> - The `num_inputs` and `num_outputs` in `tx_complete` is a count of that\n>> peer\u2019s final input and output contributions, net any removals.\n>>\n>> - Either peer may add or remove inputs and outputs until both peers have\n>> successfully\n>>\n>>   exchanged a `tx_complete` message in succession.\n>>\n>> - Either peer may only add or remove their own input or output.\n>>\n>> - In the case that a `tx_complete` agreement cannot be reached, either\n>> peer may\n>>\n>>   fail the channel or open protocol (whatever is reasonable for the\n>> particular case)\n>>\n>>   - In the case of a splice, this would be a soft error (channel returns\n>> to normal operation until\n>>\n>>     otherwise failed or closed.)\n>>\n>>   - In the case of an open, this would be a failure to open the channel.\n>>\n>>   - In the case of a close, a failed collaborative close would result in\n>> an error and a unilateral close.\n>>\n>> ### Considering the Simple Open case (2 parties)\n>>\n>> - Both peers signal `opt_dual_fund`\n>>\n>> - Opener initiates a channel open with `open_channel2` message,\n>> indicating the feerate for the opening transaction\n>>\n>> - Accepter signals acceptance of channel open as proposed, including\n>> proposed feerate, via `accept_channel2`\n>>\n>> - Opener sends `tx_add_output`, with the funding output for the sum of\n>> both peer\u2019s funding_amount\n>>\n>> - Opener sends `tx_add_input` for each input the wish to add to the\n>> funding transaction\n>>\n>> - Opener sends `tx_add_output` for their change\n>>\n>> - Opener sends `tx_complete`\n>>\n>> - Accepter sends `tx_add_input` for each input they wish to add to the\n>> funding transaction\n>>\n>> - Accepter sends `tx_add_output` for their change.\n>>\n>> - Accepter sends `tx_complete`\n>>\n>> - Opener sends `tx_complete`\n>>\n>> - Opener and accepter exchange commitment signatures; etc.\n>>\n>> ### Considering the Splice case:\n>>\n>> - Both peers signal `opt_splice_ok`\n>>\n>> - One peer initiates a splice, also signaling the feerate for the\n>> transaction. Exact protocol unspecified herein.\n>>\n>> - Initiator sends `tx_add_input` with the original funding output\n>>\n>> - Initiator sends `tx_add_output` with the new, post-splice funding output\n>>\n>> - Initiator sends `tx_add_input/output` as needed to add all desired\n>> inputs + outputs\n>>\n>> - Initiator sends `tx_complete`\n>>\n>> - Peer sends `tx_add_input/output` as needed to add all desired inputs +\n>> outputs\n>>\n>> - Initiator sends `tx_complete`\n>>\n>> - Peer sends `tx_complete`\n>>\n>> - Initiator + peer exchange commitment signatures, etc.\n>>\n>> ### Considering the Close case:\n>>\n>> - Both peers signal `opt_collaborative_close` in their\n>> `node_announcement`.\n>>\n>> - A peer initiates a close sending a `shutdown`, as per usual.\n>>\n>> - A feerate is negotiated. Out of band for this particular portion of the\n>> protocol.\n>>\n>> -The closing initiator (peer which first sent `shutdown`), sends\n>> `tx_add_input` to spend the funding output and `tx_add_output` to add their\n>> output for the channel closure.\n>>\n>> - The peer responds with `tx_add_output`, adding their output to the\n>> close transaction.\n>>\n>> - If `option_upfront_shutdown_script` is flagged but no such output with\n>> a value at or within a reasonable feerate gap of the peer's funding output\n>> is present, then the peer must fail the channel.\n>>\n>>\n>> ## Updating a collaborative transaction with RBF:\n>>\n>> - If any input is flagged as RBF\u2019able, then the transaction is considered\n>> eligible for RBF\n>>\n>> - RBF can be initiated by either party, and serves as an initiation for\n>> another round of transaction composition, as outlined above.\n>>\n>> - Note that this section has been cribbed and re-purposed from the\n>> original RBF proposal for splicing, see\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001621.html\n>>\n>> 1. type: 45 (`init_rbf`) (`option_collaborative_rbf`)\n>>\n>> 2. data:\n>>\n>>    * [`32`:`channel_id`]\n>>\n>>    * [`4`:`fee_step`]\n>>\n>> Each `fee_step` adds 1/4 (rounded down) to the initial\n>>\n>> transaction feerate. eg. if the initial feerate was 512 satoshis per\n>> kiloweight, `fee_step` 1\n>>\n>> is  512 + 512 / 4 = 640, `fee_step` 2 is 640 + 640 / 4 = 800.\n>>\n>> The sender:\n>>\n>>   - MUST set `fee_step` greater than zero and greater than any prior\n>> `fee_step`.\n>>\n>> The recipient:\n>>\n>>   - if the new fee exceeds the sender's current balance minus reserve\n>>\n>>     after it is applied to the splice transaction:\n>>\n>>     - MUST error.\n>>\n>>\n>>\n>> NOTES:\n>>\n>> 1. 1/4 is a reasonable minimal RBF, but as each one requires more\n>>\n>>    tracking by the recipient, serves to limit the number you can create.\n>>\n>> 2. Rule 4 of BIP125 requires a feerate increase to at least surpass the\n>> minimum transaction relay setting. Ratcheting by 25% should satisfy this\n>> requirement\n>>\n>> 3. An additional rule will be added to the checks of an RBF transaction\n>> that it must include at least one identical, replaceable input as the\n>> original transaction.\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200130/fb2d641c/attachment-0001.html>"
            },
            {
                "author": "darosior",
                "date": "2020-01-30T18:18:58",
                "message_text_only": "Sorry I wasn't clear enough in the \\`(cdecker)\\` paragraph.\n\n\n\n\n\n\n\nThe funding transaction sig would actually fail verification if tip differs between funder and fundee.\n\n\n\n\n\n\n\nDarosior ( i'll stick with my pseudo, first names definitely don't have enough entropy :-) )\n\\-------- Original Message --------\nOn Jan 30, 2020, 19:09, Antoine Riard < antoine.riard at gmail.com> wrote:\n\n>\n>\n>\n> Hey Darosior,\n>\n>\n>\n> You don't need a strict synchronization between both peers,\n>\n>\n> just let nLocktime picked up by initiator and announce it at\n>\n>\n> same time than feerate or at \\`tx\\_complete\\`. Worst-case,\n>\n>\n> a slow-block-processing receiver may not be able to get\n>\n>\n> the transaction accepted by its local mempool, but IMO that's\n> fine if at least the initiator is able to do so. We are requiring peers\n>\n>\n> to be weakly in sync before operating channel anyway (\\`funding\\_locked\\`\n>\n>\n> exchange).\n>\n>\n>\n>\n>\n> Funding\\_tx can already be drop from mempool for others\n>\n>\n> reasons like mempool shrinks or expiry so broadcaster\n>\n>\n> should always be ready to re-send it or bump feerate.\n>\n>\n>\n> Or are you describing another issue ?\n>\n>\n>\n>\n>\n> Le\u00a0jeu. 30 janv. 2020 \u00e0\u00a004:06, darosior <[darosior at protonmail.com][darosior_protonmail.com]> a \u00e9crit\u00a0:\n>\n>\n> > Hi Antoine and all,\n> >\n> >\n> >\n> >\n> >\n> >\n> >\n> > About nLockTime fun thing is Lisa, Cdecker and I had this conversation to integrate it to C-lightning just yesterday.\n> >\n> >\n> >\n> >\n> >\n> >\n> >\n> > Unfortunately you need to add a \"My tip is xxxx\" to the openchannel msg, otherwise if you set nLockTime to tip. (cdecker)\n> >\n> >\n> >\n> >\n> >\n> >\n> >\n> > Moreover in case of reorg the funding tx (now non-final) would be dropped from mempool ? But you could set nLockTime to, say, tip - 6. (niftynei)\n> >\n> >\n> >\n> >\n> >\n> >\n> >\n> > Antoine\n> >\n> >\n> >\n> >\n> >\n> > \\-------- Original Message --------\n> > On Jan 30, 2020, 01:21, Antoine Riard < [antoine.riard at gmail.com][antoine.riard_gmail.com]> wrote:\n> >\n> > >\n> > >\n> > >\n> > > Hey thanks for this proposal!\n> > >\n> > >\n> > >\n> > > 2 high-level questions:\n> > >\n> > >\n> > >\n> > >\n> > >\n> > > What about multi-party tx construction ? By multi-party, let's define\n> > >\n> > > Alice initiate a tx construction to Bob and then Bob announce a\n> > >\n> > >\n> > > construction to Caroll and \"bridge\" all inputs/outputs additions/substractions\n> > >\n> > >\n> > > in both directions. I think the current proposal hold, if you are a bit more\n> > >\n> > >\n> > > tolerant and bridge peer don't send a tx\\_complete before receiving ones\n> > >\n> > >\n> > > from all its peers.\n> > >\n> > >\n> > >\n> > >\n> > >\n> > > What about transactions format ? I think we should coordinate with Coinjoin\n> > >\n> > >\n> > > people to converge to a common one to avoid leaking protocol usage when\n> > > we can hinder under Taproot. Like setting the nLocktime or sorting inputs\n> > >\n> > >\n> > > in some protocol-specific fashion. Ideally we should have a BIP for format\n> > >\n> > >\n> > > but every layer 2 protocols its own set of messages concerning the construction.\n> > >\n> > > > nLocktime is always set to 0x000000\n> > > Maybe we can implement anti-fee sniping and mask among wallet core\n> > > txn set: [https://github.com/bitcoin/bitcoin/blob/aabec94541e23a67a9f30dc2c80dab3383a01737/src/wallet/wallet.cpp\\#L2519][https_github.com_bitcoin_bitcoin_blob_aabec94541e23a67a9f30dc2c80dab3383a01737_src_wallet_wallet.cpp_L2519] ?\n> > >\n> > > > In the case of a close, a failed collaborative close would result in an error and a uninlateral close\"\n> > > Or can we do first a mutual closing tx, hold tx broadcast for a bit if \"opt\\_dual\\_fund\"\n> > > is signaled to see if a tx\\_construction + add\\_funding\\_input for the channel is received\n> > > soon ? At least that would be a dual opt-in to know than one party can submit a funding-outpoint\n> > > as part of a composed tx ?\n> > >\n> > >\n> > >\n> > >\n> > > Antoine\n> > >\n> > >\n> > >\n> > >\n> > >\n> > > Le\u00a0lun. 27 janv. 2020 \u00e0\u00a020:51, lisa neigut <[niftynei at gmail.com][niftynei_gmail.com]> a \u00e9crit\u00a0:\n> > >\n> > >\n> > > > Some of the feedback I received from the check-in for the dual-funding proposal this past Monday was along the lines that we look at simplifying for breaking it into smaller, more manageable chunks.\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > The biggest piece of the dual-funding protocol update is definitely the move from a single peer constructing a transaction to two participants. We're also going to likely want to reuse this portion of the protocol for batched closings and splicing. To that extent, it seemed useful to highlight it in a separate email.\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > This is a change from the existing proposal in the dual-funding [PR \\#524][PR _524] \\-- it allows for the removal of inputs and outputs.\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > The set of messages are as follows.\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > Note that the 'initiation' of this protocol will be different depending on the case of the transaction (open, close or splice):\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > 1. type: \u00a0 440 \\`tx\\_add\\_input\\`\n> > > >\n> > > > 2. data:\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`32\\*byte\\`:\\`channel\\_identifier\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u64\\`:\\`sats\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`sha256\\`:\\`prevtx\\_txid\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u32\\`:\\`prevtx\\_vout\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`prevtx\\_scriptpubkey\\_len\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`prevtx\\_scriptpubkey\\_len\\*byte\\`:\\`prevtx\\_scriptpubkey\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`max\\_witness\\_len\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`scriptlen\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`scriptlen\\*byte\\`:\\`script\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`byte\\`:\\`signal\\_rbf\\`\\]\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > 1. type: 442 \\`tx\\_add\\_output\\`\n> > > >\n> > > > 2. data:\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`32\\*byte\\`:\\`channel\\_identifier\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u64\\`:\\`sats\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`scriptlen\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`scriptlen\\*byte\\`:\\`script\\`\\]\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > 1. type: 444 \\`tx\\_remove\\_input\\`\n> > > >\n> > > > 2. data:\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`32\\*byte\\`:\\`channel\\_identifier\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`sha256\\`:\\`prevtx\\_txid\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u32\\`:\\`prevtx\\_vout\\`\\]\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > 1. type: 446 \\`tx\\_remove\\_output\\`\n> > > >\n> > > > 2. data:\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`32\\*byte\\`:\\`channel\\_identifier\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u64\\`:\\`sats\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`scriptlen\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`scriptlen\\*byte\\`:\\`script\\`\\]\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > 1. type: 448 \\`tx\\_complete\\`\n> > > >\n> > > > 2. data:\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`32\\*byte\\`:\\`channel\\_identifier\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`num\\_inputs\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`num\\_outputs\\`\\]\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > 1. type:\u00a0 448 \\`tx\\_sigs\\`\n> > > >\n> > > > 2. data:\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`channel\\_id\\`:\\`channel\\_identifier\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`num\\_witnesses\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`num\\_witnesses\\*witness\\_stack\\`:\\`witness\\_stack\\`\\]\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > 1. subtype: \\`witness\\_stack\\`\n> > > >\n> > > > 2. data:\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`sha256\\`:\\`prevtx\\_txid\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u32\\`:\\`prevtx\\_vout\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`num\\_input\\_witness\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`num\\_input\\_witness\\*witness\\_element\\`:\\`witness\\_element\\`\\]\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > 1. subtype: \\`witness\\_element\\`\n> > > >\n> > > > 2. data:\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`len\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`len\\*byte\\`:\\`witness\\`\\]\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > \\#\\# General Notes\n> > > >\n> > > > \\- Validity of inputs/outputs is not checked until both peers have sent consecutive \\`tx\\_complete\\`\u00a0\u00a0messages.\n> > > >\n> > > > \\- Duplicate inputs or outputs is a protocol error.\n> > > >\n> > > > \\- Feerate is set by the initiator, or in the case of a closing transaction, negotiated before the transaction construction is initiated.\n> > > >\n> > > > \\- Every peer pays fees for the inputs + outputs they contribute, plus enough to cover the maximum estimate of their witnesses. Overpayment of fees is permissible.\n> > > >\n> > > > \\- Initiator is responsible for contributing the output/input in question, i.e. the\u00a0\n> > > >\n> > > > \u00a0\u00a0funding output in the case of an opening, or the funding input in the case of a close.\u00a0\n> > > >\n> > > > \u00a0\u00a0(This means that the opener will pay for the opening output). In the case of a splice,\n> > > >\n> > > > \u00a0\u00a0the initiator of the splice pays for the funding tx's inclusion as an input and the\n> > > >\n> > > > \u00a0\u00a0new 'funding tx' output.\n> > > >\n> > > > \\- Any contributor may signal that their input is RBF'able. The nSequence for this input should be set to 0xFEFF FFFF, 0xFFFFFFFF otherwise.\n> > > >\n> > > > \\- The initiating peer is understood to be paying the fee for the shared transaction fields (nVersion \\[4\\], segwit marker + flag \\[2\\], input + output counts \\[2-18\\], witness count \\[1-9\\], nLocktime \\[4\\]; total \\[13-40bytes\\])\n> > > >\n> > > > \\- Inputs MUST be segwit compatible (PW\\* or P2SH-PW\\*)\n> > > >\n> > > > \\- All output scripts must be standard\n> > > >\n> > > > \\- nLocktime is always set to 0x00000000.\n> > > >\n> > > > \\- The \\`num\\_inputs\\` and \\`num\\_outputs\\` in \\`tx\\_complete\\` is a count of that peer\u2019s final input and output contributions, net any removals.\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > \\- Either peer may add or remove inputs and outputs until both peers have successfully\n> > > >\n> > > > \u00a0\u00a0exchanged a \\`tx\\_complete\\` message in succession.\n> > > >\n> > > > \\- Either peer may only add or remove their own input or output.\n> > > >\n> > > > \\- In the case that a \\`tx\\_complete\\` agreement cannot be reached, either peer may\n> > > >\n> > > > \u00a0\u00a0fail the channel or open protocol (whatever is reasonable for the particular case)\n> > > >\n> > > > \u00a0\u00a0- In the case of a splice, this would be a soft error (channel returns to normal operation until\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0otherwise failed or closed.)\n> > > >\n> > > > \u00a0\u00a0- In the case of an open, this would be a failure to open the channel.\n> > > >\n> > > > \u00a0\u00a0- In the case of a close, a failed collaborative close would result in an error and a unilateral close.\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > \\#\\#\\# Considering the Simple Open case (2 parties)\n> > > >\n> > > > \\- Both peers signal \\`opt\\_dual\\_fund\\`\n> > > >\n> > > > \\- Opener initiates a channel open with \\`open\\_channel2\\` message, indicating the feerate for the opening transaction\n> > > >\n> > > > \\- Accepter signals acceptance of channel open as proposed, including proposed feerate, via \\`accept\\_channel2\\`\n> > > >\n> > > > \\- Opener sends \\`tx\\_add\\_output\\`, with the funding output for the sum of both peer\u2019s funding\\_amount\n> > > >\n> > > > \\- Opener sends \\`tx\\_add\\_input\\` for each input the wish to add to the funding transaction\n> > > >\n> > > > \\- Opener sends \\`tx\\_add\\_output\\` for their change\u00a0\n> > > >\n> > > > \\- Opener sends \\`tx\\_complete\\`\n> > > >\n> > > > \\- Accepter sends \\`tx\\_add\\_input\\` for each input they wish to add to the funding transaction\n> > > >\n> > > > \\- Accepter sends \\`tx\\_add\\_output\\` for their change.\n> > > >\n> > > > \\- Accepter sends \\`tx\\_complete\\`\n> > > >\n> > > > \\- Opener sends \\`tx\\_complete\\`\n> > > >\n> > > > \\- Opener and accepter exchange commitment signatures; etc.\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > \\#\\#\\# Considering the Splice case:\n> > > >\n> > > > \\- Both peers signal \\`opt\\_splice\\_ok\\`\n> > > >\n> > > > \\- One peer initiates a splice, also signaling the feerate for the transaction. Exact protocol unspecified herein.\n> > > >\n> > > > \\- Initiator sends \\`tx\\_add\\_input\\` with the original funding output\n> > > >\n> > > > \\- Initiator sends \\`tx\\_add\\_output\\` with the new, post-splice funding output\n> > > >\n> > > > \\- Initiator sends \\`tx\\_add\\_input/output\\` as needed to add all desired inputs + outputs\n> > > >\n> > > > \\- Initiator sends \\`tx\\_complete\\`\n> > > >\n> > > > \\- Peer sends \\`tx\\_add\\_input/output\\` as needed to add all desired inputs + outputs\n> > > >\n> > > > \\- Initiator sends \\`tx\\_complete\\`\n> > > >\n> > > > \\- Peer sends \\`tx\\_complete\\`\n> > > >\n> > > > \\- Initiator + peer exchange commitment signatures, etc.\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > \\#\\#\\# Considering the Close case:\n> > > >\n> > > > \\- Both peers signal \\`opt\\_collaborative\\_close\\` in their \\`node\\_announcement\\`.\n> > > >\n> > > > \\- A peer initiates a close sending a \\`shutdown\\`, as per usual.\u00a0\n> > > >\n> > > > \\- A feerate is negotiated. Out of band for this particular portion of the protocol.\n> > > >\n> > > > \\-The closing initiator (peer which first sent \\`shutdown\\`), sends \\`tx\\_add\\_input\\` to spend the funding output and \\`tx\\_add\\_output\\` to add their output for the channel closure.\n> > > >\n> > > > \\- The peer responds with \\`tx\\_add\\_output\\`, adding their output to the close transaction.\n> > > >\n> > > > \\- If \\`option\\_upfront\\_shutdown\\_script\\` is flagged but no such output with a value at or within a reasonable feerate gap of the peer's funding output is present, then the peer must fail the channel.\u00a0\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > \\#\\# Updating a collaborative transaction with RBF:\n> > > >\n> > > > \\- If any input is flagged as RBF\u2019able, then the transaction is considered eligible for RBF\n> > > >\n> > > > \\- RBF can be initiated by either party, and serves as an initiation for another round of transaction composition, as outlined above.\n> > > >\n> > > > \\- Note that this section has been cribbed and re-purposed from the original RBF proposal for splicing, see https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001621.html\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > 1. type: 45 (\\`init\\_rbf\\`) (\\`option\\_collaborative\\_rbf\\`)\n> > > >\n> > > > 2. data:\n> > > >\n> > > > \u00a0\u00a0\u00a0\\* \\[\\`32\\`:\\`channel\\_id\\`\\]\n> > > >\n> > > > \u00a0\u00a0\u00a0\\* \\[\\`4\\`:\\`fee\\_step\\`\\]\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > Each \\`fee\\_step\\` adds 1/4 (rounded down) to the initial\u00a0\n> > > >\n> > > > transaction feerate. eg. if the initial feerate was 512 satoshis per kiloweight, \\`fee\\_step\\` 1\n> > > >\n> > > > is\u00a0 512 + 512 / 4 = 640, \\`fee\\_step\\` 2 is 640 + 640 / 4 = 800.\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > The sender:\n> > > >\n> > > > \u00a0\u00a0- MUST set \\`fee\\_step\\` greater than zero and greater than any prior \\`fee\\_step\\`.\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > The recipient:\n> > > >\n> > > > \u00a0\u00a0- if the new fee exceeds the sender's current balance minus reserve\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0after it is applied to the splice transaction:\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0- MUST error.\n> > > >\n> > > > \u00a0\u00a0\n> > > >\n> > > > NOTES:\n> > > >\n> > > > 1. 1/4 is a reasonable minimal RBF, but as each one requires more\n> > > >\n> > > > \u00a0\u00a0\u00a0tracking by the recipient, serves to limit the number you can create.\n> > > >\n> > > > 2. Rule 4 of BIP125 requires a feerate increase to at least surpass the minimum transaction relay setting. Ratcheting by 25% should satisfy this requirement\n> > > >\n> > > > 3. An additional rule will be added to the checks of an RBF transaction that it must include at least one identical, replaceable input as the original transaction.\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n> > > > Lightning-dev mailing list\n> > > > [Lightning-dev at lists.linuxfoundation.org][Lightning-dev_lists.linuxfoundation.org]\n> > > > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> > > >\n\n\n[darosior_protonmail.com]: mailto:darosior at protonmail.com\n[antoine.riard_gmail.com]: mailto:antoine.riard at gmail.com\n[https_github.com_bitcoin_bitcoin_blob_aabec94541e23a67a9f30dc2c80dab3383a01737_src_wallet_wallet.cpp_L2519]: https://github.com/bitcoin/bitcoin/blob/aabec94541e23a67a9f30dc2c80dab3383a01737/src/wallet/wallet.cpp#L2519\n[niftynei_gmail.com]: mailto:niftynei at gmail.com\n[PR _524]: https://github.com/lightningnetwork/lightning-rfc/pull/524\n[Lightning-dev_lists.linuxfoundation.org]: mailto:Lightning-dev at lists.linuxfoundation.org\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200130/462dc521/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 489 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200130/462dc521/attachment-0001.sig>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-01-30T18:45:39",
                "message_text_only": "> The funding transaction sig would actually fail verification if tip\ndiffers between funder and fundee\n\nYes that's the reason I wrote the initiator can just\nannounce its own and receiver use it to sign the funding tx,\neven if receiver tip is backward. Funding tx won't propagate\nfrom receiver mempool but that's fine if it does from the initiator\none.\n\nOr are you talking about the commitment tx (different issue and there is\nbroader privacy leaks there) ?\n\n> Darosior ( i'll stick with my pseudo, first names definitely don't have\nenough entropy :-) )\n\nAhaha yeah this pseudo-random-name-generator is definitely not trustworthy\n:p\n\n\nLe jeu. 30 janv. 2020 \u00e0 13:19, darosior <darosior at protonmail.com> a \u00e9crit :\n\n> Sorry I wasn't clear enough in the `(cdecker)` paragraph.\n>\n>\n> The funding transaction sig would actually fail verification if tip\n> differs between funder and fundee.\n>\n>\n> Darosior ( i'll stick with my pseudo, first names definitely don't have\n> enough entropy :-) )\n> -------- Original Message --------\n> On Jan 30, 2020, 19:09, Antoine Riard < antoine.riard at gmail.com> wrote:\n>\n>\n> Hey Darosior,\n>\n> You don't need a strict synchronization between both peers,\n> just let nLocktime picked up by initiator and announce it at\n> same time than feerate or at `tx_complete`. Worst-case,\n> a slow-block-processing receiver may not be able to get\n> the transaction accepted by its local mempool, but IMO that's\n> fine if at least the initiator is able to do so. We are requiring peers\n> to be weakly in sync before operating channel anyway (`funding_locked`\n> exchange).\n>\n> Funding_tx can already be drop from mempool for others\n> reasons like mempool shrinks or expiry so broadcaster\n> should always be ready to re-send it or bump feerate.\n>\n> Or are you describing another issue ?\n>\n> Le jeu. 30 janv. 2020 \u00e0 04:06, darosior <darosior at protonmail.com> a\n> \u00e9crit :\n>\n>> Hi Antoine and all,\n>>\n>>\n>> About nLockTime fun thing is Lisa, Cdecker and I had this conversation to\n>> integrate it to C-lightning just yesterday.\n>>\n>>\n>> Unfortunately you need to add a \"My tip is xxxx\" to the openchannel msg,\n>> otherwise if you set nLockTime to tip. (cdecker)\n>>\n>>\n>> Moreover in case of reorg the funding tx (now non-final) would be dropped\n>> from mempool ? But you could set nLockTime to, say, tip - 6. (niftynei)\n>>\n>>\n>> Antoine\n>>\n>>\n>> -------- Original Message --------\n>> On Jan 30, 2020, 01:21, Antoine Riard < antoine.riard at gmail.com> wrote:\n>>\n>>\n>> Hey thanks for this proposal!\n>>\n>> 2 high-level questions:\n>>\n>> What about multi-party tx construction ? By multi-party, let's define\n>> Alice initiate a tx construction to Bob and then Bob announce a\n>> construction to Caroll and \"bridge\" all inputs/outputs\n>> additions/substractions\n>> in both directions. I think the current proposal hold, if you are a bit\n>> more\n>> tolerant and bridge peer don't send a tx_complete before receiving ones\n>> from all its peers.\n>>\n>> What about transactions format ? I think we should coordinate with\n>> Coinjoin\n>> people to converge to a common one to avoid leaking protocol usage when\n>> we can hinder under Taproot. Like setting the nLocktime or sorting inputs\n>> in some protocol-specific fashion. Ideally we should have a BIP for format\n>> but every layer 2 protocols its own set of messages concerning the\n>> construction.\n>>\n>> > nLocktime is always set to 0x000000\n>> Maybe we can implement anti-fee sniping and mask among wallet core\n>> txn set:\n>> https://github.com/bitcoin/bitcoin/blob/aabec94541e23a67a9f30dc2c80dab3383a01737/src/wallet/wallet.cpp#L2519\n>> ?\n>>\n>> > In the case of a close, a failed collaborative close would result in an\n>> error and a uninlateral close\"\n>> Or can we do first a mutual closing tx, hold tx broadcast for a bit if\n>> \"opt_dual_fund\"\n>> is signaled to see if a tx_construction + add_funding_input for the\n>> channel is received\n>> soon ? At least that would be a dual opt-in to know than one party can\n>> submit a funding-outpoint\n>> as part of a composed tx ?\n>>\n>> Antoine\n>>\n>> Le lun. 27 janv. 2020 \u00e0 20:51, lisa neigut <niftynei at gmail.com> a \u00e9crit :\n>>\n>>> Some of the feedback I received from the check-in for the dual-funding\n>>> proposal this past Monday was along the lines that we look at simplifying\n>>> for breaking it into smaller, more manageable chunks.\n>>>\n>>> The biggest piece of the dual-funding protocol update is definitely the\n>>> move from a single peer constructing a transaction to two participants.\n>>> We're also going to likely want to reuse this portion of the protocol\n>>> for batched closings and splicing. To that extent, it seemed useful to\n>>> highlight it in a separate email.\n>>>\n>>> This is a change from the existing proposal in the dual-funding PR #524\n>>> <https://github.com/lightningnetwork/lightning-rfc/pull/524> -- it\n>>> allows for the removal of inputs and outputs.\n>>>\n>>> The set of messages are as follows.\n>>>\n>>>\n>>> Note that the 'initiation' of this protocol will be different depending\n>>> on the case of the transaction (open, close or splice):\n>>>\n>>> 1. type:   440 `tx_add_input`\n>>>\n>>> 2. data:\n>>>\n>>>     * [`32*byte`:`channel_identifier`]\n>>>\n>>>     * [`u64`:`sats`]\n>>>\n>>>     * [`sha256`:`prevtx_txid`]\n>>>\n>>>     * [`u32`:`prevtx_vout`]\n>>>\n>>>     * [`u16`:`prevtx_scriptpubkey_len`]\n>>>\n>>>     * [`prevtx_scriptpubkey_len*byte`:`prevtx_scriptpubkey`]\n>>>\n>>>     * [`u16`:`max_witness_len`]\n>>>\n>>>     * [`u16`:`scriptlen`]\n>>>\n>>>     * [`scriptlen*byte`:`script`]\n>>>\n>>>     * [`byte`:`signal_rbf`]\n>>>\n>>> 1. type: 442 `tx_add_output`\n>>>\n>>> 2. data:\n>>>\n>>>     * [`32*byte`:`channel_identifier`]\n>>>\n>>>     * [`u64`:`sats`]\n>>>\n>>>     * [`u16`:`scriptlen`]\n>>>\n>>>     * [`scriptlen*byte`:`script`]\n>>>\n>>> 1. type: 444 `tx_remove_input`\n>>>\n>>> 2. data:\n>>>\n>>>     * [`32*byte`:`channel_identifier`]\n>>>\n>>>     * [`sha256`:`prevtx_txid`]\n>>>\n>>>     * [`u32`:`prevtx_vout`]\n>>>\n>>> 1. type: 446 `tx_remove_output`\n>>>\n>>> 2. data:\n>>>\n>>>     * [`32*byte`:`channel_identifier`]\n>>>\n>>>     * [`u64`:`sats`]\n>>>\n>>>     * [`u16`:`scriptlen`]\n>>>\n>>>     * [`scriptlen*byte`:`script`]\n>>>\n>>> 1. type: 448 `tx_complete`\n>>>\n>>> 2. data:\n>>>\n>>>     * [`32*byte`:`channel_identifier`]\n>>>\n>>>     * [`u16`:`num_inputs`]\n>>>\n>>>     * [`u16`:`num_outputs`]\n>>>\n>>> 1. type:  448 `tx_sigs`\n>>>\n>>> 2. data:\n>>>\n>>>     * [`channel_id`:`channel_identifier`]\n>>>\n>>>     * [`u16`:`num_witnesses`]\n>>>\n>>>     * [`num_witnesses*witness_stack`:`witness_stack`]\n>>>\n>>> 1. subtype: `witness_stack`\n>>>\n>>> 2. data:\n>>>\n>>>     * [`sha256`:`prevtx_txid`]\n>>>\n>>>     * [`u32`:`prevtx_vout`]\n>>>\n>>>     * [`u16`:`num_input_witness`]\n>>>\n>>>     * [`num_input_witness*witness_element`:`witness_element`]\n>>>\n>>> 1. subtype: `witness_element`\n>>>\n>>> 2. data:\n>>>\n>>>     * [`u16`:`len`]\n>>>\n>>>     * [`len*byte`:`witness`]\n>>>\n>>>\n>>>\n>>> ## General Notes\n>>>\n>>> - Validity of inputs/outputs is not checked until both peers have sent\n>>> consecutive `tx_complete`  messages.\n>>>\n>>> - Duplicate inputs or outputs is a protocol error.\n>>>\n>>> - Feerate is set by the initiator, or in the case of a closing\n>>> transaction, negotiated before the transaction construction is initiated.\n>>>\n>>> - Every peer pays fees for the inputs + outputs they contribute, plus\n>>> enough to cover the maximum estimate of their witnesses. Overpayment of\n>>> fees is permissible.\n>>>\n>>> - Initiator is responsible for contributing the output/input in\n>>> question, i.e. the\n>>>\n>>>   funding output in the case of an opening, or the funding input in the\n>>> case of a close.\n>>>\n>>>   (This means that the opener will pay for the opening output). In the\n>>> case of a splice,\n>>>\n>>>   the initiator of the splice pays for the funding tx's inclusion as an\n>>> input and the\n>>>\n>>>   new 'funding tx' output.\n>>>\n>>> - Any contributor may signal that their input is RBF'able. The nSequence\n>>> for this input should be set to 0xFEFF FFFF, 0xFFFFFFFF otherwise.\n>>>\n>>> - The initiating peer is understood to be paying the fee for the shared\n>>> transaction fields (nVersion [4], segwit marker + flag [2], input + output\n>>> counts [2-18], witness count [1-9], nLocktime [4]; total [13-40bytes])\n>>>\n>>> - Inputs MUST be segwit compatible (PW* or P2SH-PW*)\n>>>\n>>> - All output scripts must be standard\n>>>\n>>> - nLocktime is always set to 0x00000000.\n>>>\n>>> - The `num_inputs` and `num_outputs` in `tx_complete` is a count of that\n>>> peer\u2019s final input and output contributions, net any removals.\n>>>\n>>> - Either peer may add or remove inputs and outputs until both peers have\n>>> successfully\n>>>\n>>>   exchanged a `tx_complete` message in succession.\n>>>\n>>> - Either peer may only add or remove their own input or output.\n>>>\n>>> - In the case that a `tx_complete` agreement cannot be reached, either\n>>> peer may\n>>>\n>>>   fail the channel or open protocol (whatever is reasonable for the\n>>> particular case)\n>>>\n>>>   - In the case of a splice, this would be a soft error (channel returns\n>>> to normal operation until\n>>>\n>>>     otherwise failed or closed.)\n>>>\n>>>   - In the case of an open, this would be a failure to open the channel.\n>>>\n>>>   - In the case of a close, a failed collaborative close would result in\n>>> an error and a unilateral close.\n>>>\n>>> ### Considering the Simple Open case (2 parties)\n>>>\n>>> - Both peers signal `opt_dual_fund`\n>>>\n>>> - Opener initiates a channel open with `open_channel2` message,\n>>> indicating the feerate for the opening transaction\n>>>\n>>> - Accepter signals acceptance of channel open as proposed, including\n>>> proposed feerate, via `accept_channel2`\n>>>\n>>> - Opener sends `tx_add_output`, with the funding output for the sum of\n>>> both peer\u2019s funding_amount\n>>>\n>>> - Opener sends `tx_add_input` for each input the wish to add to the\n>>> funding transaction\n>>>\n>>> - Opener sends `tx_add_output` for their change\n>>>\n>>> - Opener sends `tx_complete`\n>>>\n>>> - Accepter sends `tx_add_input` for each input they wish to add to the\n>>> funding transaction\n>>>\n>>> - Accepter sends `tx_add_output` for their change.\n>>>\n>>> - Accepter sends `tx_complete`\n>>>\n>>> - Opener sends `tx_complete`\n>>>\n>>> - Opener and accepter exchange commitment signatures; etc.\n>>>\n>>> ### Considering the Splice case:\n>>>\n>>> - Both peers signal `opt_splice_ok`\n>>>\n>>> - One peer initiates a splice, also signaling the feerate for the\n>>> transaction. Exact protocol unspecified herein.\n>>>\n>>> - Initiator sends `tx_add_input` with the original funding output\n>>>\n>>> - Initiator sends `tx_add_output` with the new, post-splice funding\n>>> output\n>>>\n>>> - Initiator sends `tx_add_input/output` as needed to add all desired\n>>> inputs + outputs\n>>>\n>>> - Initiator sends `tx_complete`\n>>>\n>>> - Peer sends `tx_add_input/output` as needed to add all desired inputs +\n>>> outputs\n>>>\n>>> - Initiator sends `tx_complete`\n>>>\n>>> - Peer sends `tx_complete`\n>>>\n>>> - Initiator + peer exchange commitment signatures, etc.\n>>>\n>>> ### Considering the Close case:\n>>>\n>>> - Both peers signal `opt_collaborative_close` in their\n>>> `node_announcement`.\n>>>\n>>> - A peer initiates a close sending a `shutdown`, as per usual.\n>>>\n>>> - A feerate is negotiated. Out of band for this particular portion of\n>>> the protocol.\n>>>\n>>> -The closing initiator (peer which first sent `shutdown`), sends\n>>> `tx_add_input` to spend the funding output and `tx_add_output` to add their\n>>> output for the channel closure.\n>>>\n>>> - The peer responds with `tx_add_output`, adding their output to the\n>>> close transaction.\n>>>\n>>> - If `option_upfront_shutdown_script` is flagged but no such output with\n>>> a value at or within a reasonable feerate gap of the peer's funding output\n>>> is present, then the peer must fail the channel.\n>>>\n>>>\n>>> ## Updating a collaborative transaction with RBF:\n>>>\n>>> - If any input is flagged as RBF\u2019able, then the transaction is\n>>> considered eligible for RBF\n>>>\n>>> - RBF can be initiated by either party, and serves as an initiation for\n>>> another round of transaction composition, as outlined above.\n>>>\n>>> - Note that this section has been cribbed and re-purposed from the\n>>> original RBF proposal for splicing, see\n>>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001621.html\n>>>\n>>> 1. type: 45 (`init_rbf`) (`option_collaborative_rbf`)\n>>>\n>>> 2. data:\n>>>\n>>>    * [`32`:`channel_id`]\n>>>\n>>>    * [`4`:`fee_step`]\n>>>\n>>> Each `fee_step` adds 1/4 (rounded down) to the initial\n>>>\n>>> transaction feerate. eg. if the initial feerate was 512 satoshis per\n>>> kiloweight, `fee_step` 1\n>>>\n>>> is  512 + 512 / 4 = 640, `fee_step` 2 is 640 + 640 / 4 = 800.\n>>>\n>>> The sender:\n>>>\n>>>   - MUST set `fee_step` greater than zero and greater than any prior\n>>> `fee_step`.\n>>>\n>>> The recipient:\n>>>\n>>>   - if the new fee exceeds the sender's current balance minus reserve\n>>>\n>>>     after it is applied to the splice transaction:\n>>>\n>>>     - MUST error.\n>>>\n>>>\n>>>\n>>> NOTES:\n>>>\n>>> 1. 1/4 is a reasonable minimal RBF, but as each one requires more\n>>>\n>>>    tracking by the recipient, serves to limit the number you can create.\n>>>\n>>> 2. Rule 4 of BIP125 requires a feerate increase to at least surpass the\n>>> minimum transaction relay setting. Ratcheting by 25% should satisfy this\n>>> requirement\n>>>\n>>> 3. An additional rule will be added to the checks of an RBF transaction\n>>> that it must include at least one identical, replaceable input as the\n>>> original transaction.\n>>>\n>>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200130/98cbf857/attachment-0001.html>"
            },
            {
                "author": "darosior",
                "date": "2020-01-30T19:48:08",
                "message_text_only": "> Yes that's the reason I wrote the initiator can just announce its own and receiver use it to sign the funding tx, even if receiver tip is backward. Funding tx won't propagate from receiver mempool but that's fine if it does from the initiator one.\n\n\n\n\n\n\n\nAh, then we are back to my first response where niftynei proposed to accord on setting it to tip-6 so that reorg is not a problem (or if it is, there are bigger).\n\\-------- Original Message --------\nOn Jan 30, 2020, 19:45, Antoine Riard < antoine.riard at gmail.com> wrote:\n\n>\n>\n>\n> > The funding transaction sig would actually fail verification if tip differs between funder and fundee\n>\n>\n>\n> Yes that's the reason I wrote the initiator can just\n>\n>\n> announce its own and receiver use it to sign the funding tx,\n>\n>\n> even if receiver tip is backward. Funding tx won't propagate\n>\n>\n> from receiver mempool but that's fine if it does from the initiator\n>\n> one.\n>\n>\n>\n> Or are you talking about the commitment tx (different issue and there is\n>\n>\n> broader privacy leaks there) ?\n>\n> > Darosior ( i'll stick with my pseudo, first names definitely don't have enough entropy :-) )\n>\n>\n>\n> Ahaha yeah this pseudo-random-name-generator is definitely not trustworthy :p\n>\n>\n>\n>\n>\n>\n>\n>\n> Le\u00a0jeu. 30 janv. 2020 \u00e0\u00a013:19, darosior <[darosior at protonmail.com][darosior_protonmail.com]> a \u00e9crit\u00a0:\n>\n>\n> > Sorry I wasn't clear enough in the \\`(cdecker)\\` paragraph.\n> >\n> >\n> >\n> >\n> >\n> >\n> >\n> > The funding transaction sig would actually fail verification if tip differs between funder and fundee.\n> >\n> >\n> >\n> >\n> >\n> >\n> >\n> > Darosior ( i'll stick with my pseudo, first names definitely don't have enough entropy :-) )\n> > \\-------- Original Message --------\n> > On Jan 30, 2020, 19:09, Antoine Riard < [antoine.riard at gmail.com][antoine.riard_gmail.com]> wrote:\n> >\n> > >\n> > >\n> > >\n> > > Hey Darosior,\n> > >\n> > >\n> > >\n> > > You don't need a strict synchronization between both peers,\n> > >\n> > >\n> > > just let nLocktime picked up by initiator and announce it at\n> > >\n> > >\n> > > same time than feerate or at \\`tx\\_complete\\`. Worst-case,\n> > >\n> > >\n> > > a slow-block-processing receiver may not be able to get\n> > >\n> > >\n> > > the transaction accepted by its local mempool, but IMO that's\n> > > fine if at least the initiator is able to do so. We are requiring peers\n> > >\n> > >\n> > > to be weakly in sync before operating channel anyway (\\`funding\\_locked\\`\n> > >\n> > >\n> > > exchange).\n> > >\n> > >\n> > >\n> > >\n> > >\n> > > Funding\\_tx can already be drop from mempool for others\n> > >\n> > >\n> > > reasons like mempool shrinks or expiry so broadcaster\n> > >\n> > >\n> > > should always be ready to re-send it or bump feerate.\n> > >\n> > >\n> > >\n> > > Or are you describing another issue ?\n> > >\n> > >\n> > >\n> > >\n> > >\n> > > Le\u00a0jeu. 30 janv. 2020 \u00e0\u00a004:06, darosior <[darosior at protonmail.com][darosior_protonmail.com]> a \u00e9crit\u00a0:\n> > >\n> > >\n> > > > Hi Antoine and all,\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > About nLockTime fun thing is Lisa, Cdecker and I had this conversation to integrate it to C-lightning just yesterday.\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > Unfortunately you need to add a \"My tip is xxxx\" to the openchannel msg, otherwise if you set nLockTime to tip. (cdecker)\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > Moreover in case of reorg the funding tx (now non-final) would be dropped from mempool ? But you could set nLockTime to, say, tip - 6. (niftynei)\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > Antoine\n> > > >\n> > > >\n> > > >\n> > > >\n> > > >\n> > > > \\-------- Original Message --------\n> > > > On Jan 30, 2020, 01:21, Antoine Riard < [antoine.riard at gmail.com][antoine.riard_gmail.com]> wrote:\n> > > >\n> > > > >\n> > > > >\n> > > > >\n> > > > > Hey thanks for this proposal!\n> > > > >\n> > > > >\n> > > > >\n> > > > > 2 high-level questions:\n> > > > >\n> > > > >\n> > > > >\n> > > > >\n> > > > >\n> > > > > What about multi-party tx construction ? By multi-party, let's define\n> > > > >\n> > > > > Alice initiate a tx construction to Bob and then Bob announce a\n> > > > >\n> > > > >\n> > > > > construction to Caroll and \"bridge\" all inputs/outputs additions/substractions\n> > > > >\n> > > > >\n> > > > > in both directions. I think the current proposal hold, if you are a bit more\n> > > > >\n> > > > >\n> > > > > tolerant and bridge peer don't send a tx\\_complete before receiving ones\n> > > > >\n> > > > >\n> > > > > from all its peers.\n> > > > >\n> > > > >\n> > > > >\n> > > > >\n> > > > >\n> > > > > What about transactions format ? I think we should coordinate with Coinjoin\n> > > > >\n> > > > >\n> > > > > people to converge to a common one to avoid leaking protocol usage when\n> > > > > we can hinder under Taproot. Like setting the nLocktime or sorting inputs\n> > > > >\n> > > > >\n> > > > > in some protocol-specific fashion. Ideally we should have a BIP for format\n> > > > >\n> > > > >\n> > > > > but every layer 2 protocols its own set of messages concerning the construction.\n> > > > >\n> > > > > > nLocktime is always set to 0x000000\n> > > > > Maybe we can implement anti-fee sniping and mask among wallet core\n> > > > > txn set: [https://github.com/bitcoin/bitcoin/blob/aabec94541e23a67a9f30dc2c80dab3383a01737/src/wallet/wallet.cpp\\#L2519][https_github.com_bitcoin_bitcoin_blob_aabec94541e23a67a9f30dc2c80dab3383a01737_src_wallet_wallet.cpp_L2519] ?\n> > > > >\n> > > > > > In the case of a close, a failed collaborative close would result in an error and a uninlateral close\"\n> > > > > Or can we do first a mutual closing tx, hold tx broadcast for a bit if \"opt\\_dual\\_fund\"\n> > > > > is signaled to see if a tx\\_construction + add\\_funding\\_input for the channel is received\n> > > > > soon ? At least that would be a dual opt-in to know than one party can submit a funding-outpoint\n> > > > > as part of a composed tx ?\n> > > > >\n> > > > >\n> > > > >\n> > > > >\n> > > > > Antoine\n> > > > >\n> > > > >\n> > > > >\n> > > > >\n> > > > >\n> > > > > Le\u00a0lun. 27 janv. 2020 \u00e0\u00a020:51, lisa neigut <[niftynei at gmail.com][niftynei_gmail.com]> a \u00e9crit\u00a0:\n> > > > >\n> > > > >\n> > > > > > Some of the feedback I received from the check-in for the dual-funding proposal this past Monday was along the lines that we look at simplifying for breaking it into smaller, more manageable chunks.\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > The biggest piece of the dual-funding protocol update is definitely the move from a single peer constructing a transaction to two participants. We're also going to likely want to reuse this portion of the protocol for batched closings and splicing. To that extent, it seemed useful to highlight it in a separate email.\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > This is a change from the existing proposal in the dual-funding [PR \\#524][PR _524] \\-- it allows for the removal of inputs and outputs.\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > The set of messages are as follows.\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > Note that the 'initiation' of this protocol will be different depending on the case of the transaction (open, close or splice):\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > 1. type: \u00a0 440 \\`tx\\_add\\_input\\`\n> > > > > >\n> > > > > > 2. data:\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`32\\*byte\\`:\\`channel\\_identifier\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u64\\`:\\`sats\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`sha256\\`:\\`prevtx\\_txid\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u32\\`:\\`prevtx\\_vout\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`prevtx\\_scriptpubkey\\_len\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`prevtx\\_scriptpubkey\\_len\\*byte\\`:\\`prevtx\\_scriptpubkey\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`max\\_witness\\_len\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`scriptlen\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`scriptlen\\*byte\\`:\\`script\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`byte\\`:\\`signal\\_rbf\\`\\]\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > 1. type: 442 \\`tx\\_add\\_output\\`\n> > > > > >\n> > > > > > 2. data:\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`32\\*byte\\`:\\`channel\\_identifier\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u64\\`:\\`sats\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`scriptlen\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`scriptlen\\*byte\\`:\\`script\\`\\]\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > 1. type: 444 \\`tx\\_remove\\_input\\`\n> > > > > >\n> > > > > > 2. data:\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`32\\*byte\\`:\\`channel\\_identifier\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`sha256\\`:\\`prevtx\\_txid\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u32\\`:\\`prevtx\\_vout\\`\\]\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > 1. type: 446 \\`tx\\_remove\\_output\\`\n> > > > > >\n> > > > > > 2. data:\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`32\\*byte\\`:\\`channel\\_identifier\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u64\\`:\\`sats\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`scriptlen\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`scriptlen\\*byte\\`:\\`script\\`\\]\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > 1. type: 448 \\`tx\\_complete\\`\n> > > > > >\n> > > > > > 2. data:\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`32\\*byte\\`:\\`channel\\_identifier\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`num\\_inputs\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`num\\_outputs\\`\\]\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > 1. type:\u00a0 448 \\`tx\\_sigs\\`\n> > > > > >\n> > > > > > 2. data:\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`channel\\_id\\`:\\`channel\\_identifier\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`num\\_witnesses\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`num\\_witnesses\\*witness\\_stack\\`:\\`witness\\_stack\\`\\]\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > 1. subtype: \\`witness\\_stack\\`\n> > > > > >\n> > > > > > 2. data:\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`sha256\\`:\\`prevtx\\_txid\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u32\\`:\\`prevtx\\_vout\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`num\\_input\\_witness\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`num\\_input\\_witness\\*witness\\_element\\`:\\`witness\\_element\\`\\]\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > 1. subtype: \\`witness\\_element\\`\n> > > > > >\n> > > > > > 2. data:\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`u16\\`:\\`len\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0\\* \\[\\`len\\*byte\\`:\\`witness\\`\\]\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > \\#\\# General Notes\n> > > > > >\n> > > > > > \\- Validity of inputs/outputs is not checked until both peers have sent consecutive \\`tx\\_complete\\`\u00a0\u00a0messages.\n> > > > > >\n> > > > > > \\- Duplicate inputs or outputs is a protocol error.\n> > > > > >\n> > > > > > \\- Feerate is set by the initiator, or in the case of a closing transaction, negotiated before the transaction construction is initiated.\n> > > > > >\n> > > > > > \\- Every peer pays fees for the inputs + outputs they contribute, plus enough to cover the maximum estimate of their witnesses. Overpayment of fees is permissible.\n> > > > > >\n> > > > > > \\- Initiator is responsible for contributing the output/input in question, i.e. the\u00a0\n> > > > > >\n> > > > > > \u00a0\u00a0funding output in the case of an opening, or the funding input in the case of a close.\u00a0\n> > > > > >\n> > > > > > \u00a0\u00a0(This means that the opener will pay for the opening output). In the case of a splice,\n> > > > > >\n> > > > > > \u00a0\u00a0the initiator of the splice pays for the funding tx's inclusion as an input and the\n> > > > > >\n> > > > > > \u00a0\u00a0new 'funding tx' output.\n> > > > > >\n> > > > > > \\- Any contributor may signal that their input is RBF'able. The nSequence for this input should be set to 0xFEFF FFFF, 0xFFFFFFFF otherwise.\n> > > > > >\n> > > > > > \\- The initiating peer is understood to be paying the fee for the shared transaction fields (nVersion \\[4\\], segwit marker + flag \\[2\\], input + output counts \\[2-18\\], witness count \\[1-9\\], nLocktime \\[4\\]; total \\[13-40bytes\\])\n> > > > > >\n> > > > > > \\- Inputs MUST be segwit compatible (PW\\* or P2SH-PW\\*)\n> > > > > >\n> > > > > > \\- All output scripts must be standard\n> > > > > >\n> > > > > > \\- nLocktime is always set to 0x00000000.\n> > > > > >\n> > > > > > \\- The \\`num\\_inputs\\` and \\`num\\_outputs\\` in \\`tx\\_complete\\` is a count of that peer\u2019s final input and output contributions, net any removals.\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > \\- Either peer may add or remove inputs and outputs until both peers have successfully\n> > > > > >\n> > > > > > \u00a0\u00a0exchanged a \\`tx\\_complete\\` message in succession.\n> > > > > >\n> > > > > > \\- Either peer may only add or remove their own input or output.\n> > > > > >\n> > > > > > \\- In the case that a \\`tx\\_complete\\` agreement cannot be reached, either peer may\n> > > > > >\n> > > > > > \u00a0\u00a0fail the channel or open protocol (whatever is reasonable for the particular case)\n> > > > > >\n> > > > > > \u00a0\u00a0- In the case of a splice, this would be a soft error (channel returns to normal operation until\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0otherwise failed or closed.)\n> > > > > >\n> > > > > > \u00a0\u00a0- In the case of an open, this would be a failure to open the channel.\n> > > > > >\n> > > > > > \u00a0\u00a0- In the case of a close, a failed collaborative close would result in an error and a unilateral close.\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > \\#\\#\\# Considering the Simple Open case (2 parties)\n> > > > > >\n> > > > > > \\- Both peers signal \\`opt\\_dual\\_fund\\`\n> > > > > >\n> > > > > > \\- Opener initiates a channel open with \\`open\\_channel2\\` message, indicating the feerate for the opening transaction\n> > > > > >\n> > > > > > \\- Accepter signals acceptance of channel open as proposed, including proposed feerate, via \\`accept\\_channel2\\`\n> > > > > >\n> > > > > > \\- Opener sends \\`tx\\_add\\_output\\`, with the funding output for the sum of both peer\u2019s funding\\_amount\n> > > > > >\n> > > > > > \\- Opener sends \\`tx\\_add\\_input\\` for each input the wish to add to the funding transaction\n> > > > > >\n> > > > > > \\- Opener sends \\`tx\\_add\\_output\\` for their change\u00a0\n> > > > > >\n> > > > > > \\- Opener sends \\`tx\\_complete\\`\n> > > > > >\n> > > > > > \\- Accepter sends \\`tx\\_add\\_input\\` for each input they wish to add to the funding transaction\n> > > > > >\n> > > > > > \\- Accepter sends \\`tx\\_add\\_output\\` for their change.\n> > > > > >\n> > > > > > \\- Accepter sends \\`tx\\_complete\\`\n> > > > > >\n> > > > > > \\- Opener sends \\`tx\\_complete\\`\n> > > > > >\n> > > > > > \\- Opener and accepter exchange commitment signatures; etc.\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > \\#\\#\\# Considering the Splice case:\n> > > > > >\n> > > > > > \\- Both peers signal \\`opt\\_splice\\_ok\\`\n> > > > > >\n> > > > > > \\- One peer initiates a splice, also signaling the feerate for the transaction. Exact protocol unspecified herein.\n> > > > > >\n> > > > > > \\- Initiator sends \\`tx\\_add\\_input\\` with the original funding output\n> > > > > >\n> > > > > > \\- Initiator sends \\`tx\\_add\\_output\\` with the new, post-splice funding output\n> > > > > >\n> > > > > > \\- Initiator sends \\`tx\\_add\\_input/output\\` as needed to add all desired inputs + outputs\n> > > > > >\n> > > > > > \\- Initiator sends \\`tx\\_complete\\`\n> > > > > >\n> > > > > > \\- Peer sends \\`tx\\_add\\_input/output\\` as needed to add all desired inputs + outputs\n> > > > > >\n> > > > > > \\- Initiator sends \\`tx\\_complete\\`\n> > > > > >\n> > > > > > \\- Peer sends \\`tx\\_complete\\`\n> > > > > >\n> > > > > > \\- Initiator + peer exchange commitment signatures, etc.\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > \\#\\#\\# Considering the Close case:\n> > > > > >\n> > > > > > \\- Both peers signal \\`opt\\_collaborative\\_close\\` in their \\`node\\_announcement\\`.\n> > > > > >\n> > > > > > \\- A peer initiates a close sending a \\`shutdown\\`, as per usual.\u00a0\n> > > > > >\n> > > > > > \\- A feerate is negotiated. Out of band for this particular portion of the protocol.\n> > > > > >\n> > > > > > \\-The closing initiator (peer which first sent \\`shutdown\\`), sends \\`tx\\_add\\_input\\` to spend the funding output and \\`tx\\_add\\_output\\` to add their output for the channel closure.\n> > > > > >\n> > > > > > \\- The peer responds with \\`tx\\_add\\_output\\`, adding their output to the close transaction.\n> > > > > >\n> > > > > > \\- If \\`option\\_upfront\\_shutdown\\_script\\` is flagged but no such output with a value at or within a reasonable feerate gap of the peer's funding output is present, then the peer must fail the channel.\u00a0\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > \\#\\# Updating a collaborative transaction with RBF:\n> > > > > >\n> > > > > > \\- If any input is flagged as RBF\u2019able, then the transaction is considered eligible for RBF\n> > > > > >\n> > > > > > \\- RBF can be initiated by either party, and serves as an initiation for another round of transaction composition, as outlined above.\n> > > > > >\n> > > > > > \\- Note that this section has been cribbed and re-purposed from the original RBF proposal for splicing, see https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001621.html\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > 1. type: 45 (\\`init\\_rbf\\`) (\\`option\\_collaborative\\_rbf\\`)\n> > > > > >\n> > > > > > 2. data:\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\\* \\[\\`32\\`:\\`channel\\_id\\`\\]\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\\* \\[\\`4\\`:\\`fee\\_step\\`\\]\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > Each \\`fee\\_step\\` adds 1/4 (rounded down) to the initial\u00a0\n> > > > > >\n> > > > > > transaction feerate. eg. if the initial feerate was 512 satoshis per kiloweight, \\`fee\\_step\\` 1\n> > > > > >\n> > > > > > is\u00a0 512 + 512 / 4 = 640, \\`fee\\_step\\` 2 is 640 + 640 / 4 = 800.\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > The sender:\n> > > > > >\n> > > > > > \u00a0\u00a0- MUST set \\`fee\\_step\\` greater than zero and greater than any prior \\`fee\\_step\\`.\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > The recipient:\n> > > > > >\n> > > > > > \u00a0\u00a0- if the new fee exceeds the sender's current balance minus reserve\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0after it is applied to the splice transaction:\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0\u00a0- MUST error.\n> > > > > >\n> > > > > > \u00a0\u00a0\n> > > > > >\n> > > > > > NOTES:\n> > > > > >\n> > > > > > 1. 1/4 is a reasonable minimal RBF, but as each one requires more\n> > > > > >\n> > > > > > \u00a0\u00a0\u00a0tracking by the recipient, serves to limit the number you can create.\n> > > > > >\n> > > > > > 2. Rule 4 of BIP125 requires a feerate increase to at least surpass the minimum transaction relay setting. Ratcheting by 25% should satisfy this requirement\n> > > > > >\n> > > > > > 3. An additional rule will be added to the checks of an RBF transaction that it must include at least one identical, replaceable input as the original transaction.\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > >\n> > > > > > \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n> > > > > > Lightning-dev mailing list\n> > > > > > [Lightning-dev at lists.linuxfoundation.org][Lightning-dev_lists.linuxfoundation.org]\n> > > > > > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> > > > > >\n\n\n[darosior_protonmail.com]: mailto:darosior at protonmail.com\n[antoine.riard_gmail.com]: mailto:antoine.riard at gmail.com\n[https_github.com_bitcoin_bitcoin_blob_aabec94541e23a67a9f30dc2c80dab3383a01737_src_wallet_wallet.cpp_L2519]: https://github.com/bitcoin/bitcoin/blob/aabec94541e23a67a9f30dc2c80dab3383a01737/src/wallet/wallet.cpp#L2519\n[niftynei_gmail.com]: mailto:niftynei at gmail.com\n[PR _524]: https://github.com/lightningnetwork/lightning-rfc/pull/524\n[Lightning-dev_lists.linuxfoundation.org]: mailto:Lightning-dev at lists.linuxfoundation.org\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200130/3aac971c/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 489 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200130/3aac971c/attachment-0001.sig>"
            },
            {
                "author": "lisa neigut",
                "date": "2020-01-30T02:00:09",
                "message_text_only": "hi max \u2014 great question. PSBT is a great protocol for wallet interop but a\nbit overweight for tx collaboration between two peers\n\nOn Wed, Jan 29, 2020 at 17:29 Max Dignan <maxdignan at gmail.com> wrote:\n\n> Hey Antoine,\n>\n> Would PSBT (BIP 174 -\n> https://github.com/bitcoin/bips/blob/master/bip-0174.mediawiki) be a good\n> solution to this?\n>\n> -Max\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200129/c9d358a8/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-01-30T02:40:49",
                "message_text_only": "Hi Max,\n\nSorry by transaction format I didn't mean a binary transaction format,\nbut format like we use in BOLT3 :\nhttps://github.com/lightningnetwork/lightning-rfc/blob/master/03-transactions.md\n\nMy concern is, e.g LN implementations setting nLocktime to 0x00000000,\nCoinjoin wallets always disabling nSequence and core wallet transactions\ndoing anti-fee snipping. Now even if all of them are using Taproot outputs\nyou're still leaking what protocol/tooling you're using to an external\nobserver\ndue to discrepancies in transaction fields. So we should obfuscate or using\nstandard values as much as protocol semantics let us doing it to break chain\nanalysis heuristics.\n\nLe mer. 29 janv. 2020 \u00e0 21:00, lisa neigut <niftynei at gmail.com> a \u00e9crit :\n\n> hi max \u2014 great question. PSBT is a great protocol for wallet interop but a\n> bit overweight for tx collaboration between two peers\n>\n> On Wed, Jan 29, 2020 at 17:29 Max Dignan <maxdignan at gmail.com> wrote:\n>\n>> Hey Antoine,\n>>\n>> Would PSBT (BIP 174 -\n>> https://github.com/bitcoin/bips/blob/master/bip-0174.mediawiki) be a\n>> good solution to this?\n>>\n>> -Max\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200129/9921c64a/attachment.html>"
            },
            {
                "author": "Max Dignan",
                "date": "2020-01-30T02:52:44",
                "message_text_only": "Hey,\n\nOk gotcha now. Re-read your prior post. Thanks for the feedback both of you!\n\nThanks,\nMax\n\n> On Jan 29, 2020, at 9:00 PM, lisa neigut <niftynei at gmail.com> wrote:\n> \n> \ufeff\n> hi max \u2014 great question. PSBT is a great protocol for wallet interop but a bit overweight for tx collaboration between two peers\n> \n>> On Wed, Jan 29, 2020 at 17:29 Max Dignan <maxdignan at gmail.com> wrote:\n>> Hey Antoine,\n>> \n>> Would PSBT (BIP 174 - https://github.com/bitcoin/bips/blob/master/bip-0174.mediawiki) be a good solution to this?\n>> \n>> -Max\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200129/fcc10bf5/attachment.html>"
            },
            {
                "author": "darosior",
                "date": "2020-01-30T10:03:17",
                "message_text_only": "Hi Lisa and all,\n\nGiven the discussion about utxos snooping, I wondered if there was any obvious drawbacks of using a transaction chain construction ?\n\nSince the obvious target of the probing is the accepter, it seems that the opener needs to at least have something at stake in order to be revealed some of the accepter's utxos.\nThus, the opener giving the accepter a signed transaction commited to the channel opening is one way of avoiding the opener to probe gratuitously. I was thinking of something like:\n\nA is opener, B is accepter.\nA could sign the first input (and accordingly the 2of2 output) with SIGHASH_SINGLE|SIGHASH_ANYONECANPAY. Unfortunately this doesn't handle A's change, but it can be solved using a chain of transaction.\nA creates a first transaction txA1:\n\n    txA1 (SIGHASH_ALL)\n     _________________ __________________________\n    | A's input 1    | A's channel participation |\n    |----------------|---------------------------\n    | A's input 2    | A's change                |\n    |----------------|---------------------------\n    | A's input n    |\n    |________________|\n    \n\n\nAnd then creates /signs the funding transaction out of the first output of txA1:\n\n    txA2 (SIGHASH_SINGLE|SIGHASH_ANYONECANPAY)\n     _________________ _______________\n    | txA1 vout 0    | 2of2 with B    |\n    |________________|________________\n\nSince txA2 is signed with SINGLE|ANYONECANPAY, B can add inputs to fulfill the value requirement of the 2of2, and add outputs for its own change.\n\nThis comes at the cost of more setup fees opener-side, but avoids the accepter to be gratuitously probed, so this is arguably a far lesser evil.\nIs there any other downside I'm missing here ?\n\nAntoine\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nLe mardi, janvier 28, 2020 2:51 AM, lisa neigut <niftynei at gmail.com> a \u00e9crit\u00a0:\n\n> Some of the feedback I received from the check-in for the dual-funding proposal this past Monday was along the lines that we look at simplifying for breaking it into smaller, more manageable chunks.\n> \n\n> The biggest piece of the dual-funding protocol update is definitely the move from a single peer constructing a transaction to two participants. We're also going to likely want to reuse this portion of the protocol for batched closings and splicing. To that extent, it seemed useful to highlight it in a separate email.\n> \n\n> This is a change from the existing proposal in the dual-funding PR #524 -- it allows for the removal of inputs and outputs.\n> \n\n> The set of messages are as follows.\n> \n\n> Note that the 'initiation' of this protocol will be different depending on the case of the transaction (open, close or splice):\n> \n\n> 1. type: \u00a0 440 `tx_add_input`\n> \n\n> 2. data:\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`32*byte`:`channel_identifier`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`u64`:`sats`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`sha256`:`prevtx_txid`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`u32`:`prevtx_vout`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`u16`:`prevtx_scriptpubkey_len`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`prevtx_scriptpubkey_len*byte`:`prevtx_scriptpubkey`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`u16`:`max_witness_len`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`u16`:`scriptlen`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`scriptlen*byte`:`script`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`byte`:`signal_rbf`]\n> \n\n> 1. type: 442 `tx_add_output`\n> \n\n> 2. data:\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`32*byte`:`channel_identifier`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`u64`:`sats`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`u16`:`scriptlen`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`scriptlen*byte`:`script`]\n> \n\n> 1. type: 444 `tx_remove_input`\n> \n\n> 2. data:\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`32*byte`:`channel_identifier`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`sha256`:`prevtx_txid`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`u32`:`prevtx_vout`]\n> \n\n> 1. type: 446 `tx_remove_output`\n> \n\n> 2. data:\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`32*byte`:`channel_identifier`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`u64`:`sats`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`u16`:`scriptlen`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`scriptlen*byte`:`script`]\n> \n\n> 1. type: 448 `tx_complete`\n> \n\n> 2. data:\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`32*byte`:`channel_identifier`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`u16`:`num_inputs`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`u16`:`num_outputs`]\n> \n\n> 1. type:\u00a0 448 `tx_sigs`\n> \n\n> 2. data:\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`channel_id`:`channel_identifier`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`u16`:`num_witnesses`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`num_witnesses*witness_stack`:`witness_stack`]\n> \n\n> 1. subtype: `witness_stack`\n> \n\n> 2. data:\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`sha256`:`prevtx_txid`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`u32`:`prevtx_vout`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`u16`:`num_input_witness`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`num_input_witness*witness_element`:`witness_element`]\n> \n\n> 1. subtype: `witness_element`\n> \n\n> 2. data:\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`u16`:`len`]\n> \n\n> \u00a0\u00a0\u00a0\u00a0* [`len*byte`:`witness`]\n> \n\n> ## General Notes\n> \n\n> - Validity of inputs/outputs is not checked until both peers have sent consecutive `tx_complete`\u00a0\u00a0messages.\n> \n\n> - Duplicate inputs or outputs is a protocol error.\n> \n\n> - Feerate is set by the initiator, or in the case of a closing transaction, negotiated before the transaction construction is initiated.\n> \n\n> - Every peer pays fees for the inputs + outputs they contribute, plus enough to cover the maximum estimate of their witnesses. Overpayment of fees is permissible.\n> \n\n> - Initiator is responsible for contributing the output/input in question, i.e. the\u00a0\n> \n\n> \u00a0\u00a0funding output in the case of an opening, or the funding input in the case of a close.\u00a0\n> \n\n> \u00a0\u00a0(This means that the opener will pay for the opening output). In the case of a splice,\n> \n\n> \u00a0\u00a0the initiator of the splice pays for the funding tx's inclusion as an input and the\n> \n\n> \u00a0\u00a0new 'funding tx' output.\n> \n\n> - Any contributor may signal that their input is RBF'able. The nSequence for this input should be set to 0xFEFF FFFF, 0xFFFFFFFF otherwise.\n> \n\n> - The initiating peer is understood to be paying the fee for the shared transaction fields (nVersion [4], segwit marker + flag [2], input + output counts [2-18], witness count [1-9], nLocktime [4]; total [13-40bytes])\n> \n\n> - Inputs MUST be segwit compatible (PW* or P2SH-PW*)\n> \n\n> - All output scripts must be standard\n> \n\n> - nLocktime is always set to 0x00000000.\n> \n\n> - The `num_inputs` and `num_outputs` in `tx_complete` is a count of that peer\u2019s final input and output contributions, net any removals.\n> \n\n> - Either peer may add or remove inputs and outputs until both peers have successfully\n> \n\n> \u00a0\u00a0exchanged a `tx_complete` message in succession.\n> \n\n> - Either peer may only add or remove their own input or output.\n> \n\n> - In the case that a `tx_complete` agreement cannot be reached, either peer may\n> \n\n> \u00a0\u00a0fail the channel or open protocol (whatever is reasonable for the particular case)\n> \n\n> \u00a0\u00a0- In the case of a splice, this would be a soft error (channel returns to normal operation until\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n> \n\n> \u00a0\u00a0\u00a0\u00a0otherwise failed or closed.)\n> \n\n> \u00a0\u00a0- In the case of an open, this would be a failure to open the channel.\n> \n\n> \u00a0\u00a0- In the case of a close, a failed collaborative close would result in an error and a unilateral close.\n> \n\n> ### Considering the Simple Open case (2 parties)\n> \n\n> - Both peers signal `opt_dual_fund`\n> \n\n> - Opener initiates a channel open with `open_channel2` message, indicating the feerate for the opening transaction\n> \n\n> - Accepter signals acceptance of channel open as proposed, including proposed feerate, via `accept_channel2`\n> \n\n> - Opener sends `tx_add_output`, with the funding output for the sum of both peer\u2019s funding_amount\n> \n\n> - Opener sends `tx_add_input` for each input the wish to add to the funding transaction\n> \n\n> - Opener sends `tx_add_output` for their change\u00a0\n> \n\n> - Opener sends `tx_complete`\n> \n\n> - Accepter sends `tx_add_input` for each input they wish to add to the funding transaction\n> \n\n> - Accepter sends `tx_add_output` for their change.\n> \n\n> - Accepter sends `tx_complete`\n> \n\n> - Opener sends `tx_complete`\n> \n\n> - Opener and accepter exchange commitment signatures; etc.\n> \n\n> ### Considering the Splice case:\n> \n\n> - Both peers signal `opt_splice_ok`\n> \n\n> - One peer initiates a splice, also signaling the feerate for the transaction. Exact protocol unspecified herein.\n> \n\n> - Initiator sends `tx_add_input` with the original funding output\n> \n\n> - Initiator sends `tx_add_output` with the new, post-splice funding output\n> \n\n> - Initiator sends `tx_add_input/output` as needed to add all desired inputs + outputs\n> \n\n> - Initiator sends `tx_complete`\n> \n\n> - Peer sends `tx_add_input/output` as needed to add all desired inputs + outputs\n> \n\n> - Initiator sends `tx_complete`\n> \n\n> - Peer sends `tx_complete`\n> \n\n> - Initiator + peer exchange commitment signatures, etc.\n> \n\n> ### Considering the Close case:\n> \n\n> - Both peers signal `opt_collaborative_close` in their `node_announcement`.\n> \n\n> - A peer initiates a close sending a `shutdown`, as per usual.\u00a0\n> \n\n> - A feerate is negotiated. Out of band for this particular portion of the protocol.\n> \n\n> -The closing initiator (peer which first sent `shutdown`), sends `tx_add_input` to spend the funding output and `tx_add_output` to add their output for the channel closure.\n> \n\n> - The peer responds with `tx_add_output`, adding their output to the close transaction.\n> \n\n> - If `option_upfront_shutdown_script` is flagged but no such output with a value at or within a reasonable feerate gap of the peer's funding output is present, then the peer must fail the channel.\u00a0\n> \n\n> ## Updating a collaborative transaction with RBF:\n> \n\n> - If any input is flagged as RBF\u2019able, then the transaction is considered eligible for RBF\n> \n\n> - RBF can be initiated by either party, and serves as an initiation for another round of transaction composition, as outlined above.\n> \n\n> - Note that this section has been cribbed and re-purposed from the original RBF proposal for splicing, see https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001621.html\n> \n\n> 1. type: 45 (`init_rbf`) (`option_collaborative_rbf`)\n> \n\n> 2. data:\n> \n\n> \u00a0\u00a0\u00a0* [`32`:`channel_id`]\n> \n\n> \u00a0\u00a0\u00a0* [`4`:`fee_step`]\n> \n\n> Each `fee_step` adds 1/4 (rounded down) to the initial\u00a0\n> \n\n> transaction feerate. eg. if the initial feerate was 512 satoshis per kiloweight, `fee_step` 1\n> \n\n> is\u00a0 512 + 512 / 4 = 640, `fee_step` 2 is 640 + 640 / 4 = 800.\n> \n\n> The sender:\n> \n\n> \u00a0\u00a0- MUST set `fee_step` greater than zero and greater than any prior `fee_step`.\n> \n\n> The recipient:\n> \n\n> \u00a0\u00a0- if the new fee exceeds the sender's current balance minus reserve\n> \n\n> \u00a0\u00a0\u00a0\u00a0after it is applied to the splice transaction:\n> \n\n> \u00a0\u00a0\u00a0\u00a0- MUST error.\n> \n\n> NOTES:\n> \n\n> 1. 1/4 is a reasonable minimal RBF, but as each one requires more\n> \n\n> \u00a0\u00a0\u00a0tracking by the recipient, serves to limit the number you can create.\n> \n\n> 2. Rule 4 of BIP125 requires a feerate increase to at least surpass the minimum transaction relay setting. Ratcheting by 25% should satisfy this requirement\n> \n\n> 3. An additional rule will be added to the checks of an RBF transaction that it must include at least one identical, replaceable input as the original transaction.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200130/d137558a/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 477 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200130/d137558a/attachment-0001.sig>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-30T14:38:57",
                "message_text_only": "Good morning darosior,\n\n> Hi Lisa and all,\n>\n> Given the discussion about utxos snooping, I wondered if there was any obvious drawbacks of using a transaction chain construction ?\n>\n> Since the obvious target of the probing is the accepter, it seems that the opener needs to at least have something at stake in order to be revealed some of the accepter's utxos.\n> Thus, the opener giving the accepter a signed transaction commited to the channel opening is one way of avoiding the opener to probe gratuitously. I was thinking of something like:\n>\n> A is opener, B is accepter.\n> A could sign the first input (and accordingly the 2of2 output) with SIGHASH_SINGLE|SIGHASH_ANYONECANPAY. Unfortunately this doesn't handle A's change, but it can be solved using a chain of transaction.\n> A creates a first transaction txA1:\n>\n>     txA1 (SIGHASH_ALL)\n>      _________________ __________________________\n>     | A's input 1    | A's channel participation |\n>     |----------------|---------------------------\n>     | A's input 2    | A's change                |\n>     |----------------|---------------------------\n>     | A's input n    |\n>     |________________|\n>\n>\n> And then creates /signs the funding transaction out of the first output of txA1:\n>\n>     txA2 (SIGHASH_SINGLE|SIGHASH_ANYONECANPAY)\n>      _________________ _______________\n>     | txA1 vout 0    | 2of2 with B    |\n>     |________________|________________\n>\n> Since txA2 is signed with SINGLE|ANYONECANPAY, B can add inputs to fulfill the value requirement of the 2of2, and add outputs for its own change.\n>\n> This comes at the cost of more setup fees opener-side, but avoids the accepter to be gratuitously probed, so this is arguably a far lesser evil.\n> Is there any other downside I'm missing here ?\n\nThis is an excellent idea.\nA drawback is that anything that is not `SIGHASH_ALL` sticks out in chain analysis.\nThis is not an issue currently with Lightning since every 2-of-2 is (almost) definitely a Lightning Channel, but future improvements (Schnorr, Taproot) let us get better hiding, so the `SIGHASH_SINGLE | SIGHASH_ANYONECANPAY` is a massive flag.\nAs the point of protecting against this kind of probing is privacy, this is not a perfect privacy solution.\n\n\nWe could also consider PoDLE as used in JoinMarket, which solves a similar problem.\nhttps://gist.github.com/AdamISZ/9cbba5e9408d23813ca8#defence-2-committing-to-a-utxo-in-publicplaintext-at-the-start-of-the-handshake\nBasically, a PoDLE commits to a UTXO, without being trivially grindable from the UTXO set and also including a proof that the creator of the PoDLE knows the secret key behind it.\nIt can later be opened to reveal which UTXO the opener allocated.\nIf the opener aborts (i.e. does not provide its signatures to the funding transaction) then the acceptor can gossip the UTXO and the revealed PoDLE as well to the rest of Lightning, so that the opener at least cannot reuse the same UTXO to probe other potential acceptors.\n(though, my understanding, there is no clear way to determine *when* we can safely delete old PoDLEs: maybe each node can keep it around for a month, which might be good enough to limit the practical ability of a snoop to probe other nodes)\nI believe JoinMarket also has solved the issue of allowing a UTXO to be used at most N times (for example due to \"honest\" failures, such as connectivity interruptions which might cause an abort of the protocol); I think it involves appending a single byte to something that is hashed, and ensuring its value is less than N, so that it can only be used from 0 to N - 1 (and thus allow a UTXO to be used at most N times).\n\nGetting into contact with waxwing / Adam Gibson for this might be useful to fill out how PoDLE works and so on; basically, I believe this issue is a practically solved problem already for JoinMarket, though waxwing may be able to provide a more nuanced opinion.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-30T23:31:59",
                "message_text_only": "Good morning darosior, ariard, niftynei, and list,\n\n> We could also consider PoDLE as used in JoinMarket, which solves a similar problem.\n> https://gist.github.com/AdamISZ/9cbba5e9408d23813ca8#defence-2-committing-to-a-utxo-in-publicplaintext-at-the-start-of-the-handshake\n> Basically, a PoDLE commits to a UTXO, without being trivially grindable from the UTXO set and also including a proof that the creator of the PoDLE knows the secret key behind it.\n> It can later be opened to reveal which UTXO the opener allocated.\n> If the opener aborts (i.e. does not provide its signatures to the funding transaction) then the acceptor can gossip the UTXO and the revealed PoDLE as well to the rest of Lightning, so that the opener at least cannot reuse the same UTXO to probe other potential acceptors.\n> (though, my understanding, there is no clear way to determine when we can safely delete old PoDLEs: maybe each node can keep it around for a month, which might be good enough to limit the practical ability of a snoop to probe other nodes)\n> I believe JoinMarket also has solved the issue of allowing a UTXO to be used at most N times (for example due to \"honest\" failures, such as connectivity interruptions which might cause an abort of the protocol); I think it involves appending a single byte to something that is hashed, and ensuring its value is less than N, so that it can only be used from 0 to N - 1 (and thus allow a UTXO to be used at most N times).\n>\n> Getting into contact with waxwing / Adam Gibson for this might be useful to fill out how PoDLE works and so on; basically, I believe this issue is a practically solved problem already for JoinMarket, though waxwing may be able to provide a more nuanced opinion.\n\nI communicated with waxwing, and he said:\n\n* See also: https://joinmarket.me/blog/blog/poodle \\[sic\\].\n* The counter I mentioned is implemented using the second generator point.\n  * The PoDLE construction requires the standard base point `G`, and another generator point `J`.\n  * To create the generator point `J`, JoinMarket appends the counter byte (the one used to limit N number of uses of the same UTXO) to `G`, hashes it, then uses a coerce-to-point.\n* PoDLE is sometimes called DLEQ elsewhere.\n* There is no concrete answer on \"when to delete old PoDLE\"; JoinMarket never deletes (though they might if throughput increases).\n* Watermarks like `nLockTime`, `nSequence`, `nVersion` are currently fixed values; JoinMarket sees no reason to change this since equal-valued CoinJoins are otherwise obvious to chain analysis anyway.\n  * But note: JoinMarket implements PayJoin, which is not otherwise obvious onchain, and does indeed do anti-fee-sniping emulation for PayJoin.\n  * JoinMarket also strives to make similar feerates across users.\n\nIn any case, for myself, my thoughts are:\n\n* I observe that our use-case is quite similar to a PayJoin:\n  * The opener proposes to make a payment (to a channel between the opener and the acceptor, rather than outright giving control to the acceptor as in PayJoin).\n  * The acceptor adds some UTXOs which will contribute to the payment output (i.e. the channel).\n  * This probably does mean we want to later consider `nLockTime` anti-fee-sniping as well in multi-funded channel opens.\n* Speaking of multi-funded channel opens, it seems to me this interactive tx construction mechanism as well can be later used for channel factories.\n  * Similarly, PoDLE techniques would be useful as well to multi-funded channel factories.\n* It would probably be a good idea to share PoDLE format with JoinMarket so we can share PoDLE with them (there could be bridges that share PoDLE between a JoinMarket maker and a Lightning node, and each network already has its own gossip protocols, so LN just needs a gossip protocol for sharing PoDLEs as well).\n* Probably we can mandate in some BOLT spec to retain PoDLE for at least a year or a month or two weeks or so, which should be enough to slow down probe attempts.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "darosior",
                "date": "2020-01-31T11:23:31",
                "message_text_only": "Hi ZmnSCPxj,\n\nUsing joinmarket's PoDLEs is a great idea, and it seems preferable to using a transaction chain with a distinguishable SIGHASH.\n\nJust a naive question, what is described in https://gist.github.com/AdamISZ/9cbba5e9408d23813ca8#defence-2-committing-to-a-utxo-in-publicplaintext-at-the-start-of-the-handshake and https://joinmarket.me/blog/blog/poodle/ uses Schnorr signature. Can we use this protocol with ECDSA ?\n\nI'm now thinking about how this could be integrated into niftynei's work on the dual-funded channel proposal. The PoDLE broadcast protocol seems to be the bigger part.\n\n*Imagining the size of the monster PR if PoDLEs ever get integrated*\nRegards,\nDarosior\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nLe vendredi, janvier 31, 2020 12:31 AM, ZmnSCPxj <ZmnSCPxj at protonmail.com> a \u00e9crit\u00a0:\n\n> Good morning darosior, ariard, niftynei, and list,\n> \n\n> > We could also consider PoDLE as used in JoinMarket, which solves a similar problem.\n> > https://gist.github.com/AdamISZ/9cbba5e9408d23813ca8#defence-2-committing-to-a-utxo-in-publicplaintext-at-the-start-of-the-handshake\n> > Basically, a PoDLE commits to a UTXO, without being trivially grindable from the UTXO set and also including a proof that the creator of the PoDLE knows the secret key behind it.\n> > It can later be opened to reveal which UTXO the opener allocated.\n> > If the opener aborts (i.e. does not provide its signatures to the funding transaction) then the acceptor can gossip the UTXO and the revealed PoDLE as well to the rest of Lightning, so that the opener at least cannot reuse the same UTXO to probe other potential acceptors.\n> > (though, my understanding, there is no clear way to determine when we can safely delete old PoDLEs: maybe each node can keep it around for a month, which might be good enough to limit the practical ability of a snoop to probe other nodes)\n> > I believe JoinMarket also has solved the issue of allowing a UTXO to be used at most N times (for example due to \"honest\" failures, such as connectivity interruptions which might cause an abort of the protocol); I think it involves appending a single byte to something that is hashed, and ensuring its value is less than N, so that it can only be used from 0 to N - 1 (and thus allow a UTXO to be used at most N times).\n> > Getting into contact with waxwing / Adam Gibson for this might be useful to fill out how PoDLE works and so on; basically, I believe this issue is a practically solved problem already for JoinMarket, though waxwing may be able to provide a more nuanced opinion.\n> \n\n> I communicated with waxwing, and he said:\n> \n\n> -   See also: https://joinmarket.me/blog/blog/poodle \\[sic\\].\n> -   The counter I mentioned is implemented using the second generator point.\n>     -   The PoDLE construction requires the standard base point `G`, and another generator point `J`.\n>     -   To create the generator point `J`, JoinMarket appends the counter byte (the one used to limit N number of uses of the same UTXO) to `G`, hashes it, then uses a coerce-to-point.\n> -   PoDLE is sometimes called DLEQ elsewhere.\n> -   There is no concrete answer on \"when to delete old PoDLE\"; JoinMarket never deletes (though they might if throughput increases).\n> -   Watermarks like `nLockTime`, `nSequence`, `nVersion` are currently fixed values; JoinMarket sees no reason to change this since equal-valued CoinJoins are otherwise obvious to chain analysis anyway.\n>     -   But note: JoinMarket implements PayJoin, which is not otherwise obvious onchain, and does indeed do anti-fee-sniping emulation for PayJoin.\n>     -   JoinMarket also strives to make similar feerates across users.\n>         \n\n>         In any case, for myself, my thoughts are:\n>         \n\n> -   I observe that our use-case is quite similar to a PayJoin:\n>     -   The opener proposes to make a payment (to a channel between the opener and the acceptor, rather than outright giving control to the acceptor as in PayJoin).\n>     -   The acceptor adds some UTXOs which will contribute to the payment output (i.e. the channel).\n>     -   This probably does mean we want to later consider `nLockTime` anti-fee-sniping as well in multi-funded channel opens.\n> -   Speaking of multi-funded channel opens, it seems to me this interactive tx construction mechanism as well can be later used for channel factories.\n>     -   Similarly, PoDLE techniques would be useful as well to multi-funded channel factories.\n> -   It would probably be a good idea to share PoDLE format with JoinMarket so we can share PoDLE with them (there could be bridges that share PoDLE between a JoinMarket maker and a Lightning node, and each network already has its own gossip protocols, so LN just needs a gossip protocol for sharing PoDLEs as well).\n> -   Probably we can mandate in some BOLT spec to retain PoDLE for at least a year or a month or two weeks or so, which should be enough to slow down probe attempts.\n>     \n\n>     Regards,\n>     ZmnSCPxj\n>\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 477 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200131/4b9c0503/attachment.sig>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-01-31T23:56:46",
                "message_text_only": "Good morning darosior,\n\n> Hi ZmnSCPxj,\n>\n> Using joinmarket's PoDLEs is a great idea, and it seems preferable to using a transaction chain with a distinguishable SIGHASH.\n>\n> Just a naive question, what is described in https://gist.github.com/AdamISZ/9cbba5e9408d23813ca8#defence-2-committing-to-a-utxo-in-publicplaintext-at-the-start-of-the-handshake and https://joinmarket.me/blog/blog/poodle/ uses Schnorr signature. Can we use this protocol with ECDSA ?\n\nI cannot really grok the exact mathematics of ECDSA, and the signing scheme for PoDLE is not *exactly* Schnorr but certainly uses the same schema.\n\nIt looks to me that the DLEQ proof is based on Fiat-Shamir (as Schnorr signing is), though you might do better from an answer from an actual cryptographer.\n\nIn any case it is not used onchain anyway, and it is not going to be exactly the same as normal ECDSA signing so code reuse is still unlikely.\n\n\n> I'm now thinking about how this could be integrated into niftynei's work on the dual-funded channel proposal. The PoDLE broadcast protocol seems to be the bigger part.\n>\n> Imagining the size of the monster PR if PoDLEs ever get integrated\n\nAnother wrinkle is that, PoDLE needs to be exchanged if the acceptor wants to add its own funds.\nIf the opener offers to open a channel but the acceptor is not interested in revealing its own funds, then the opener need not reveal PoDLE of its UTXOs.\n\nIt seems to me that individual PoDLEs are small enough (32 bytes, `h(P2)` is all you need for the commitment, the signature-like thing is part of the opening, if my understanding is correct) that a simple gossip protocol might work.\n\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "DRAFT: interactive tx construction protocol",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "darosior",
                "Antoine Riard",
                "Max Dignan",
                "lisa neigut",
                "ZmnSCPxj"
            ],
            "messages_count": 15,
            "total_messages_chars_count": 124918
        }
    },
    {
        "title": "[Lightning-dev] DRAFT: interactive tx construction  protocol",
        "thread_messages": [
            {
                "author": "Max Dignan",
                "date": "2020-01-30T01:28:53",
                "message_text_only": "Hey Antoine,\n\nWould PSBT (BIP 174 - https://github.com/bitcoin/bips/blob/master/bip-0174.mediawiki <https://github.com/bitcoin/bips/blob/master/bip-0174.mediawiki>) be a good solution to this?\n\n-Max\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200129/6fb5cf24/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "DRAFT: interactive tx construction  protocol",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Max Dignan"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 383
        }
    },
    {
        "title": "[Lightning-dev] Remove from list",
        "thread_messages": [
            {
                "author": "pnewmanster",
                "date": "2020-01-29T16:33:48",
                "message_text_only": "Sent from my Samsung Galaxy smartphone.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200129/78ebb7c7/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Remove from list",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "pnewmanster"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 224
        }
    },
    {
        "title": "[Lightning-dev] Lightning Spec Meeting 2020/02/03",
        "thread_messages": [
            {
                "author": "Christian Decker",
                "date": "2020-01-31T14:00:38",
                "message_text_only": "Dear Fellow Protocol Devs,\n\nthe next meeting is this Monday (2020/02/03), and to facilitate review\nand meeting preparations we have prepared a short agenda [1].\n\nWe switched over to a Github issue to prepare the agenda, since we\nalready heavily rely on the infrastructure for all of our other\ntasks. Since this requires a bit of curation to keep the top post\nupdated I am curating the list based on feedback on the issue and in\nother places. If you think that there is an open issue, open pull\nrequest, or other topic that should be discussed next Monday please let\nme know and I'll amend accordingly. Please let me know as soon as\npossible to give other devs a chance to catch up prior to the meeting.\n\nThe current agenda looks like this:\n\n\n```markdown\n# Pull Request Review\n- [ ] Single-option large channel proposal #596\n- [ ] BOLT 7: be more aggressive about sending our own gossip. #684\n- [ ] Bolt 1: Specify that extensions to existing messages must use TLV #714 (@t-bast)\n - Gossip channel queries\n   - [ ] BOLT7: reply_channel_range parameter #560\n   - [ ] BOLT 7: clarify how to decode empty arrays #729\n   - [ ] BOLT 7: clarify how to encode multiple `reply_channel_range` messages #730\n\n# Long Term Updates\n- [ ] Current status of the trampoline routing proposal (@t-bast)\n\n# Research\n- [ ] How can we improve the gossip (`gossip_queries_ex`)? (@t-bast)\n```\n\nLooking forward to Monday,\nChristian\n\n[1] https://github.com/lightningnetwork/lightning-rfc/issues/731"
            }
        ],
        "thread_summary": {
            "title": "Lightning Spec Meeting 2020/02/03",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Decker"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1472
        }
    }
]