[
    {
        "title": "[Lightning-dev] RouteBoost: Adding 'r=' fields to BOLT 11 invoices to flag capacity",
        "thread_messages": [
            {
                "author": "Pierre",
                "date": "2018-10-04T12:01:55",
                "message_text_only": "Ha! I actually came up with the idea two months ago (but you beat me\nto it on the implementation so we're even :-)\n\nhttps://github.com/ACINQ/eclair-wallet/issues/101#issuecomment-408619207\n\n\nLe jeu. 20 sept. 2018 \u00e0 04:12, Rusty Russell <rusty at blockstream.com> a \u00e9crit :\n>\n> Hi all,\n>\n>         I'm considering a change to c-lightning, where `invoice` would\n> automatically append an 'r' field for a channel which has sufficient\n> *incoming* capacity for the amount (using a weighted probability across\n> our peers).\n>\n>          This isn't quite what 'r' was for, but it would be a useful\n> hint for payment routing and also potentially for establishing an\n> initial channel.  This is an issue for the Blockstream Store which\n> deliberately doesn't advertize an address any more to avoid\n> centralization.\n>\n> Thoughts welcome!\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Matt Corallo",
                "date": "2018-10-08T04:38:59",
                "message_text_only": "Resending due to ML bugs....\n\nOn a related note, it would be nice to get some clarity on appropriate\nusage of the r= field here.\nThe way I had implemented it initially was that if an invoice had an r=\nfield any publicly-discovered last-hop routes would be ignored as the r=\ndata is most likely more up-to-date than any public route rumor information.\nHowever, if it's only used as a hint and only one or two out of\npotentially many channels are included in it, that may make little sense.\n\nNot really sure what the appropriate guidance should be, probably\nsomething like SHOULD prefer to use invoice-r=-provided-hints over\npublicly-discovered routes however MAY use other last-hops in case a\nsubstantially better route is known?\n\nMatt\n\nOn 09/19/18 22:10, Rusty Russell wrote:\n> Hi all,\n> \n>         I'm considering a change to c-lightning, where `invoice` would\n> automatically append an 'r' field for a channel which has sufficient\n> *incoming* capacity for the amount (using a weighted probability across\n> our peers).\n> \n>          This isn't quite what 'r' was for, but it would be a useful\n> hint for payment routing and also potentially for establishing an\n> initial channel.  This is an issue for the Blockstream Store which\n> deliberately doesn't advertize an address any more to avoid\n> centralization.\n> \n> Thoughts welcome!\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-10-08T05:16:19",
                "message_text_only": "Matt Corallo <lf-lists at mattcorallo.com> writes:\n> On a related note, it would be nice to get some clarity on appropriate\n> usage of the r= field here.\n> The way I had implemented it initially was that if an invoice had an r=\n> field any publicly-discovered last-hop routes would be ignored as the r=\n> data is most likely more up-to-date than any public route rumor information.\n\n> However, if it's only used as a hint and only one or two out of\n> potentially many channels are included in it, that may make little sense.\n\nThere were originally two proposed uses of r=:\n\n1. For payments via unannounced channels.\n2. For routing hints for nodes which don't have a complete topology.\n\n> Not really sure what the appropriate guidance should be, probably\n> something like SHOULD prefer to use invoice-r=-provided-hints over\n> publicly-discovered routes however MAY use other last-hops in case a\n> substantially better route is known?\n\nNote that r can provide zero-or-more full routes, not just a single hop\nas is done here.  But there's no reason to believe that the invoicer has\nmore knowledge about all but the last hop.\n\nSo, I'd recommend that the payer SHOULD prefer to use the final hops\nspecified in `r` fields over other equivalent routes it knows.\n\n(Note the weasel word \"equivalent\" here: you might bias against these\ndue to fees, timeouts, or even privacy concerns.  Also note that I\nhaven't implemented this yet!).\n\nCheers,\nRusty."
            },
            {
                "author": "Pierre",
                "date": "2018-10-08T11:22:37",
                "message_text_only": "> But there's no reason to believe that the invoicer has more knowledge about all but the last hop.\n\nI disagree: there is a good chance that the receiver is a 24/7 running\nmerchant/website, with a full up-to-date view of the network, whereas\nthe payer is most likely a mobile wallet with less\naccurate/partial/out of date information.\n\nAt least this is what we are seeing on the current mainnet. Routing\ntable sync is hard on mobile clients, and I think that it makes sense\nthat receivers \"help\" senders, after all incentives are aligned.\n\nCheers,\n\nPierre"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-10-10T00:37:24",
                "message_text_only": "Pierre <pm+lists at acinq.fr> writes:\n>> But there's no reason to believe that the invoicer has more knowledge about all but the last hop.\n>\n> I disagree: there is a good chance that the receiver is a 24/7 running\n> merchant/website, with a full up-to-date view of the network, whereas\n> the payer is most likely a mobile wallet with less\n> accurate/partial/out of date information.\n>\n> At least this is what we are seeing on the current mainnet. Routing\n> table sync is hard on mobile clients, and I think that it makes sense\n> that receivers \"help\" senders, after all incentives are aligned.\n\nGood qualification; I agree.  Certainly if the payer knows its\ninformation is less reliable it should prefer the provided route.\n\nCheers,\nRusty."
            },
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2018-10-10T11:57:11",
                "message_text_only": "I agree the r-fields are useful to populate for public channels in many\nsituations, but care must be taken to not _always_ try them first without\naccounting for potentially high fees on those channels.\n\n- Johan\nOn Wed, Oct 10, 2018 at 5:46 AM Rusty Russell <rusty at blockstream.com> wrote:\n\n> Pierre <pm+lists at acinq.fr> writes:\n> >> But there's no reason to believe that the invoicer has more knowledge\n> about all but the last hop.\n> >\n> > I disagree: there is a good chance that the receiver is a 24/7 running\n> > merchant/website, with a full up-to-date view of the network, whereas\n> > the payer is most likely a mobile wallet with less\n> > accurate/partial/out of date information.\n> >\n> > At least this is what we are seeing on the current mainnet. Routing\n> > table sync is hard on mobile clients, and I think that it makes sense\n> > that receivers \"help\" senders, after all incentives are aligned.\n>\n> Good qualification; I agree.  Certainly if the payer knows its\n> information is less reliable it should prefer the provided route.\n>\n> Cheers,\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181010/f522d3b5/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-10-08T10:57:02",
                "message_text_only": "Good morning Matt,\n\nIn my implementation that might get into c-lightning (i.e. my pull request, which I should probably update some time before universe heat death) the r= fields are preferred, but if unable to find routes to the nodes indicated in the r= fields, we always fall back to our known node map before failing completely.\n\nBasically, we retry each r= field until all routes to the node indicated have failed (no more viable routes), then move to the next r= field (if exists), or if no more r= fields, try finding the node itself directly in the node map.\n\n\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Monday, October 8, 2018 12:38 PM, Matt Corallo <lf-lists at mattcorallo.com> wrote:\n\n> Resending due to ML bugs....\n>\n> On a related note, it would be nice to get some clarity on appropriate\n> usage of the r= field here.\n> The way I had implemented it initially was that if an invoice had an r=\n> field any publicly-discovered last-hop routes would be ignored as the r=\n> data is most likely more up-to-date than any public route rumor information.\n> However, if it's only used as a hint and only one or two out of\n> potentially many channels are included in it, that may make little sense.\n>\n> Not really sure what the appropriate guidance should be, probably\n> something like SHOULD prefer to use invoice-r=-provided-hints over\n> publicly-discovered routes however MAY use other last-hops in case a\n> substantially better route is known?\n>\n> Matt\n>\n> On 09/19/18 22:10, Rusty Russell wrote:\n>\n> > Hi all,\n> >\n> >         I'm considering a change to c-lightning, where `invoice` would\n> >\n> >\n> > automatically append an 'r' field for a channel which has sufficient\n> > incoming capacity for the amount (using a weighted probability across\n> > our peers).\n> >\n> >          This isn't quite what 'r' was for, but it would be a useful\n> >\n> >\n> > hint for payment routing and also potentially for establishing an\n> > initial channel. This is an issue for the Blockstream Store which\n> > deliberately doesn't advertize an address any more to avoid\n> > centralization.\n> > Thoughts welcome!\n> > Rusty.\n> >\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            }
        ],
        "thread_summary": {
            "title": "RouteBoost: Adding 'r=' fields to BOLT 11 invoices to flag capacity",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Matt Corallo",
                "Pierre",
                "Johan Tor\u00e5s Halseth",
                "Rusty Russell",
                "ZmnSCPxj"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 9202
        }
    },
    {
        "title": "[Lightning-dev] Proposal for syncing channel updates",
        "thread_messages": [
            {
                "author": "Fabrice Drouin",
                "date": "2018-10-04T12:46:19",
                "message_text_only": "Hi,\n\nThis a a proposal for an extension of our current \u201cchannel queries\u201d\nthat should allow nodes to properly sync their outdated channel\nupdates. I already opened a issue on the RFC\u2019s github repo\n(https://github.com/lightningnetwork/lightning-rfc/issues/480) but\ndecided to post here too to, to have a less \u201cconstrained\u201d discussion.\nAnd it looks like a fairly standard synchronisation problem so maybe\nsomeone will think of others similar schemes that have been used in a\ndifferent context.\n\nThanks,\n\nFabrice\n\nBackground: Routing Table Sync\n\n(If you\u2019re familiar with LN you can just skip this section)\n\nLN is a p2p network of nodes, which can be represented as a graph\nwhere nodes are vertices and channels are edges, and where you can pay\nany node you can find a route to:\n- each nodes maintains a routing table i.e. a full view of the LN graph\n- to send a payment, nodes use their local routing table to compute a\nroute to the destination, and send a onion-like message to the first\nnode on that route, which will forward it to the next node and so on\nuntil it reaches its destination\n\nThe routing table includes:\n- \u201cstatic\u201d information: channel announcements\n- \u201cdynamic\u201d information: channel updates (relay fees)\n(It also includes node announcements, which are not needed for route\ncomputation)\nUsing our graph analogy, channel updates would be edge parameters\n(cost, max capacity, min payment amount, \u2026). They can change often,\nusually when nodes decide to change their relay fee policy, but also\nto signify that a channel is temporarily unusable. A new channel\nupdate will replace the previous one.\n\nChannel ids are identified with an 8 bytes \"short transaction id\": we\nuse the blockchain coordinates of the funding tx: block height (4\nbytes) + tx index (2 bytes) + output index (2 bytes)\n\nChanel updates include a channel id, a direction (for a channel\nbetween Alice and Bob there are 2 channel updates: one for Alice->Bob\nand one for Bob->Alice), fee parameters, and a 4 bytes timestamp.\n\nTo compute routes, nodes need a way to keep their routing table\nup-to-date: we call it \"routing table sync\" or \"routing sync\".\n\nThere is something else to consider: route finding is only needed when\nyou're * sending * payments, not when you're relaying them or\nreceiving them. A node that sits in the \"middle\" of the LN network and\njust keeps relaying payments would work even if it has no routing\ninformation at all.\n\nLikewise, a node that just creates payment requests and receives\npayments does not need a routing table.\n\nOn the other end of the spectrum, a LN \"wallet\" that is mostly used to\nsend payments will not work very well it its routing table is missing\ninfo or contains outdated info, so routing sync is a very important\nissue for LN wallets, which are also typically offline more often than\nother nodes.\n\nIf your wallet is missing channel announcements it may not be able to\nfind a route, and if its channel updates are outdated it may compute a\nroute that includes channels that are temporarily disabled, or use fee\nrates that are too old and will be refused by relaying nodes. In this\ncase nodes can return errors that include their most recent channel\nupdate, so that the sender can try again, but this will only work well\nif just a few channel updates are outdated.\n\nSo far, these are the \u201crouting table sync\u201d schemes that have been\nspecified and implemented:\n\nStep #1: just send everything\n\nThe first routing sync scheme was very simple: nodes would request\nthat peers they connect to send them a complete \"dump\" of their entire\nrouting table. It worked well at the beginning but was expensive for\nboth peers and quickly became impractical.\n\nStep #2: synchronise channel announcements\n\nNew query messages where added to the LN protocol to improve routing\ntable sync: nodes can ask their peers for all their channel ids in a\ngiven block range, compare that list to their own channel ids and\nquery the ones they're missing (as well as related channel updates).\n\nNodes can also send a timestamp-based filter to their peers (\"only\nsend me  channel updates that match this timestamp filter\").\n\nIt's a nice improvement but there are still issues with nodes that are\noffline very often: they will be able to sync their channel\nannouncements, but not their channel updates.\n\nSuppose that at T0 a node has 1000 channel updates that are outdated.\nIt comes back online, starts syncing its routing table, and goes\noffline after a few minutes. It now has 900 channel updates that are\noutdated.\nAt T1 = T0 + 8 hours it comes back online again. If it uses T0 to\nfilter out channel updates, it will never receive the info it is\nmissing for its 900 outdated channel updates. Using our \"last time I\nwas online at\" timestamp as a gossip filter does not work here.\n\n=> Proposed solution: timestamp-based channel updates sync\n\nWe need a better method for syncing channel updates. And it is not\nreally a set reconciliation problem (like syncing channel\nannouncements for example): we\u2019re not missing items, we\u2019re missing\nupdates for existing items.\n\nSo I propose to extend query parameters to include channel update timestamps:\n\nWhen A connects to B, it ask for a list of [channel id (8 bytes)|\nchannel update timestamp #1 (4 bytes)| channel update timestamp #2 (4\nbytes)] in a given [start_height, number_of_blocks] block range\n\nB replies with a list of [channel id (8 bytes)| channel update\ntimestamp #1 (4 bytes)| channel update timestamp #2 (4 bytes)]\n\nA checks its local routing table, and sends a query that includes a\nlist of [channel id (8 bytes) | flag (1 byte)], where flag is a\ncombination of\nsend me the channel announcement for this channel id\nsend me the channel update #1 for this channel id\nsend me the channel update #2 for this channel id\n\nB replies with the requested items.\n\nThis will allow B to know very quickly how far behind it is, and\ndisplay a \u201csync progress\u201d indicator as it receives the items it\nrequested.\n\nWe\u2019ve been testing this strategy on our mobile wallet for a few weeks\nand so far our test results are positive: it fixes the issue we had\nwhen  local routing tables were missing a lot of \u201ctemporarily\ndisabled\u201d channel updates. And it\u2019s fairly easy to support these new\nqueries for implementations that already support channel range\nqueries."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-10-05T08:16:34",
                "message_text_only": "Good Morning Fabrice,\n\nWithout objecting to the rest of your email (which I have not read and thought about extensively):\n\n>And it is not\n> really a set reconciliation problem (like syncing channel\n> announcements for example): we\u2019re not missing items, we\u2019re missing\n> updates for existing items.\n\nIt may be reduced to a set reconciliation problem if we consider the timestamp and enable/disable state of channel updates as part of an item, i.e. a channel update of 111:1:1 at 2018-10-04 state=enabled is not the same as a channel update of 111:1:1 at 2018-10-05 state=disabled.\n\nThen both sides can use standard set reconciliation algorithms, and for channel updates of the same short channel ID, we simply drop all items except the one with latest timestamp.\n\nThe above idea might be less efficient than your proposed extension.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Fabrice Drouin",
                "date": "2018-10-12T08:58:41",
                "message_text_only": "Hi Zmn,\n\n> It may be reduced to a set reconciliation problem if we consider the timestamp and enable/disable state of channel updates as part of an item, i.e. a channel update of 111:1:1 at 2018-10-04 state=enabled is not the same as a channel update of 111:1:1 at 2018-10-05 state=disabled.\n>\n> Then both sides can use standard set reconciliation algorithms, and for channel updates of the same short channel ID, we simply drop all items except the one with latest timestamp.\n>\n> The above idea might be less efficient than your proposed extension.\n\nYes there may be some way use the structure of channel_update messages\nto transpose this into a set reconciliation problem, and use smarter\ntools like IBLTs. But we would need to have a good estimate for the\nnumber of differences between the local and remote sets. This would be\nthe really hard part I think, and probably even harder to get right\nwith channel_updates than with channel_announcements. I had a quick\nlook at how this type of sync issue is handled in different contexts\nand my impression is that exchanging and and comparing timestamps\nwould be the most natural solution ?\n\nBut mostly my point is that I think we missed something with the\ncurrent channel queries, so first I would like to know if other people\nagree with that :) and propose something that is close to what we have\ntoday, should be easy to implement if you already support channel\nqueries, and should fix the issue that I think we have.\n\nThanks,\nFabrice"
            }
        ],
        "thread_summary": {
            "title": "Proposal for syncing channel updates",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Fabrice Drouin",
                "ZmnSCPxj"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 8601
        }
    },
    {
        "title": "[Lightning-dev] DDoS attacks in the Lightning Network",
        "thread_messages": [
            {
                "author": "Christian Allen",
                "date": "2018-10-09T11:25:42",
                "message_text_only": "Hi,\n\nI am researching on, if I can create nodes and channels by a machine\nlearning algorithm, in lightning, such that weaknesses in the network are\nremoved.\n\nFor example, can we develop such a ML algorithm, which would prevent a DDoS\n(distributed denial of service) attack on the lightning network?\n\nAny thoughts on this would be appreciated.\n\nThanks,\nChristian\n\u1427\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181009/2db76ee8/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "DDoS attacks in the Lightning Network",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Allen"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 548
        }
    },
    {
        "title": "[Lightning-dev] Splicing Proposal: Feedback please!",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-10-10T03:45:43",
                "message_text_only": "Hi all!\n\n        We've had increasing numbers of c-lightning users get upset they\ncan't open multiple channels, so I guess we're most motivated to allow\nsplicing of existing channels.  Hence this rough proposal.\n\nFor simplicity, I've chosen to only allow a single splice at a time.\nIt's still complex :(\n\nFeedback welcome!\n--\nSplice Negotiation:\n\n1. type: 40 (`splice_add_input`) (`option_splice`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`8`: `satoshis`]\n   * [`32`: `prevtxid`]\n   * [`4`: `prevtxoutnum`]\n   * [`2`: `scriptlen`]\n   * [`scriptlen`: `scriptpubkey`]\n\n1. type: 41 (`splice_add_output`) (`option_splice`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`8`: `satoshis`]\n   * [`2`: `scriptlen`]\n   * [`scriptlen`: `outscript`]\n\n1. type: 42 (`splice_all_added`) (`option_splice`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`4`:`feerate_per_kw`]\n   * [`4`:`minimum_depth`]\n\nEach side sends 0 or more `splice_add_input` and 0 or more\n`splice_add_output` followed by `spice_all_added` to complete the splice\nproposal.  This is done either to initiate a splice, or to respond to a\n`splice_*` from the other party.\n\n`splice_add_input` is checked for the following:\n- must not be during a current splice\n- scriptpubkey is empty, or of form 'HASH160 <20-byte-script-hash> EQUAL'\n- `satoshis` doesn't wrap on addition.\n- MAY check that it matches outpoint specified (sig will simply be\n  invalid if so), and that outpoint is segwit.\n\n`splice_add_output` is checked for the following:\n- must not be during a current splice\n- `satoshis` is less than or equal to amount owing to proposer, minus\n  current reserve, and greater than or equal to `dust_limit_satoshis` we\n  sent in our open_channel/accept_channel ,sg.\n- script is one of the approved forms as it is for `shutdown`.\n\nFIXME: Do we disallow splice-out if they specified\n       option_upfront_shutdown_script?\n\n`splice_all_added` is checked for the following:\n- average of `feerate_per_kw` by both sides (round down) is sufficient.\n- average of `feerate_per_kw` by both sides not grossly excessive, if we're\n  paying some of the fees (see below!)\n- both sides can afford the fees from their post-splice funds (see\n  Verification Changes below)\n- maximum of the two `minimum_depth` is not grossly excessive.\n- There is at least one splice_add_input or splice_add_output.\n\nSplice negotiation, like closing negotiation, does not have persistent\nstate.  Reconnecting forgets previous negotiation.\n\n\nSplice Signing\n--------------\n\nOnce `splice_all_added` is both sent and received, we need to create and\nsign both the splice tx itself, and the first commitment transaction\nwhich spends it (but not in that order!).\n\n1. One input spends the current funding tx output.\n2. There is one additional input for each splice_add_input.\n3. One output creates the new funding tx.\n4. There is one additional output for each splice_add_output.\n5. The entire transaction is sorted into BIP69 order.\n6. The feerate is the sum of the two `feerate_per_kw` divided by 2,\n   rounded down.\n\n1. type: 43 (`splice_commitment_signature`) (`option_splice`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`64`:`commitment_signature`]\n   * [`2`:`num_htlcs`]\n   * [`num_htlcs*64`:`htlc_signature`]\n\n1. type: 44 (`splice_signature`) (`option_splice`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`64`:`splice_signature`]\n\n1. type: 45 (`splice_witness`) (`option_splice`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`2`: `num_witness_elements`\n   * [`2`:`len`]\n   * [`len`:`witnesses`]\n\n`witnesses` itself is serialized as `num_witness_elements` of:\n* `2`:`len`\n* `len`: `witness_element`\n\nEach side sends `splice_commitment_signature` and waits to receive and\nverify the other side's `splice_commitment_signature` before sending\n`splice_signature` and `splice_witness` for each `splice_add_input` it\nproposed, in BIP69 input order.\n\nOnce a node has sent `splice_commitment_signature` it should remember\nthe splice proposal across reconnects.  Once it has both sent\n`splice_signature`, the splice is locked in.\n\n\nSplice Announcement\n-------------------\n\nWe have to tell the network about the new channel, otherwise there will\nbe a distruption when it sees the old funding transaction spent.  This\nis inevitable for older nodes who won't understand splicing anyway.\n\nWe can't send out a `channel_announcement` or `channel_update` for the\nnew channel until after the new funding transaction has 6 confirmations,\nso we append to the existing `channel_update` for the original channel,\nusing a new `message_flags` field:\n\n| Bit Position  | Name                      | Field                            |\n| ------------- | ------------------------- | -------------------------------- |\n| 0             | `option_channel_htlc_max` | `htlc_maximum_msat`              |\n| 1             | `option_channel_moving`   | `moving_txid                     |\n\nThe `channel_update` gains the following field:\n    * [`32`: moving_txid`] (option_channel_moving)\n\nIf a current `channel_update` for a closing channel contains\n`option_channel_moving` a node SHOULD ignore the channel close for at\nleast 100 blocks iff spent by `moving_txid`.\n\nA node SHOULD immediately forward a `channel_update` it sees containing\n`option_channel_moving` if neither previous `channel_update` for the\nchannel contains `option_channel_moving`.\n\nEach side of the splice can send these unilaterally, and SHOULD allow a\nfew minutes for propagation (remember, average propagation from old\nnodes is still 30 seconds) prior to broadcast of the splice transaction.\n\n\nMessage Changes During Splicing\n-------------------------------\nOnce you've sent `splice_commitment_signature` each commitment\ntransaction is duplicated: one spends the old funding transaction, one\nspends the splice transaction:\n\n1. type: 39 (`closing_signed`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`8`:`fee_satoshis`]\n   * [`64`:`signature`]\n   * [`64`:`splice_signature`] (`option_splice`)\n\n1. type: 132 (`commitment_signed`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`64`:`signature`]\n   * [`2`:`num_htlcs`]\n   * [`num_htlcs*64`:`htlc_signature`]\n   * [`num_htlcs*64`:`htlc_splice_signature`] (`option_splice`)\n\nIf a reconnection occurs between between sending and receiving\n`splice_commitment_signature`) the peer's status is uncertain (similarly\nfor closing).  This we have a new field in `channel_reestablish` to flag\nthat we consider ourselves to be splicing:\n\n1. type: 136 (`channel_reestablish`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`8`:`next_local_commitment_number`]\n   * [`8`:`next_remote_revocation_number`]\n   * [`32`:`your_last_per_commitment_secret`] (`option_data_loss_protect`)\n   * [`33`:`my_current_per_commitment_point`] (`option_data_loss_protect`)\n   * [`32`:`splice_txid`] (`option_splice`)\n\nThe splice_txid field indicates that this side considers itself to be\nsplicing.\n\nThe sender:\n- if it has sent `splice_commitment_signature` and not sent the corresponding\n  `splice_closed`, MUST set `splice_txid` to the txid of the splice tx.\n   - Otherwise MUST NOT.\n\nThe recipient:\n- if it has sent `splice_commitment_signature` and not sent the corresponding\n  `splice_closed`:\n  - if `splice_txid` does not exist or does not match the current splice:\n    - SHOULD fail the channel\n  - otherwise:\n    - MUST retransmit `splice_signature`\n- otherwise:\n  - if `splice_txid` field exists and is not all zeroes:\n    - MUST send `splice_closed`\n\n\nValidation Changes During Splicing\n----------------------------------\nWe track \"post-splice\" values as well as current values during\nsplicing.\n\nThe post-splice reserve is 1% of post-splice capcacity (rounded down).\n\nThe fees for the splicing transaction itself are divided into parts by\nthe number of `splice_add_input` plus `splice_add_output`, rounded up.\nEach side pays as many parts as it proposed `splice_add_input` plus\n`splice_add_output`.\n\n(So if Alice proposes two and Bob proposes one, and the total fee is 1000\nsatoshi, each part is 334 satoshi: Alice pays 668 and Bob pays 334.)\n\nEach side's post-splice funds are debited their `splice_add_output`\namounts, and credited their `splice_add_input` amounts, a debited the\nsplice tx fees.  If any debiting occurs, the funds must be above the\npost-splice reserve (ie. you can have below reserve, but you can't spend\nif you're below reserve).\n\nAll update_add_htlc must be valid for the *both* the current and\npost-splice balances.\n\nCompleting Splicing\n-------------------\nOnce you've seen both side's `minimum_depth` confirmations of the splice\ntransaction (ie. the maximum of the two `minimum_depth` values), you can\ncomplete the splice by sending:\n\n1. type: 46 (`splice_closed`) (`option_splice`)\n2. data:\n   * [`32`:`channel_id`]\n\nOnce you've sent and received `splice_closed` you can send\n`announcement_signatures` for the new channel as per normal rules (ie. 6\nconfirmations, `announce_channel` bit set).\n\nIn addition, you can forget everything about the old channel (including\nold HTLCs and revocation requirements)."
            },
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2018-10-10T22:42:18",
                "message_text_only": "Dear Rusty,\n\nthanks for the initiative. You suggested in your paragraph \"messages\nchanges during splicing\" during splicing to duplicate each commitment\ntransaction. One which spends the old funding tx and one which spends the\nspliced tx. I believe this can be simplified. Though I think my workflow\npretty much resembles what you have written in \"Splice Signing\" from point\n1. to 6. Maybe I might have misunderstood some parts of your suggestion.\n\nI will not write this down as formal as your proposal as I believe we are\ncurrently in the feedback and discussion phase. Maybe you already had\n\"those details\" that I am suggesting in mind. In that case sorry for my\nmail.\n\nSo let us take the example of Splicing in:\n* The situation before splicing is that we have one output in our funding\ntx that is being spent with each commitment tx. (actually if the channel\nwas spliced before we have more inputs but that should not change anything)\n* Splice in would create one additional output that can be spent in future\ncommitment tx.\n* I propose while splicing in this output should be spent by a special\ncommitment tx which goes to the funder of the splicing operation. This\nshould happen before the actual funding takes place. The other commitment\ntx spending the original output continues to operate (assuring non blocking\nsplice in operation).\n* Once we have enough confirmations we merge the channels (either\nautomatically or with the next channel update). A new commitment tx is\nbeing created which now spends each output of each of the two funding tx\nand assigns the channel balance to the channel partners accordingly to the\ntwo independent channels. The old commitment txs are being invalidated.\n* The disadvantage is that while splicing is not completed and if the\nfunder of the splicing tx is trying to publish an old commitment tx the\nnode will only be punished by sending all the funds of the first funding tx\nto the partner as the special commitment tx of the 2nd output has no newer\nstate yet.\n\nI believe splicing out is even safer:\n* One just creates a spent of the funding tx which has two outputs. One\noutput goes to the recipient of the splice out operation and the second\noutput acts as a new funding transaction for the newly spliced channel.\nOnce signatures for the new commitment transaction are exchanged (basically\nfollowing the protocol to open a channel) the splicing operation can be\nbroadcasted.\n* The old channel MUST NOT be used anymore but the new channel can be\noperational right away without blockchain confirmation. In case someone\ntries to publish an old state of the old channel it will be a double spent\nof the splicing operation and in the worst case will be punished and the\nsplicing was not successful. if one publishes an old state of the new\nchannel everything will just work as normal even if the funding tx is not\nyet mined. It could only be replaced with an old state of the previous\nchannel (which as we saw is not a larger risk than the usual operation of a\nlightning node)\n\nAs mentioned maybe you had this workflow already in your mind but I don't\nsee why we need to send around all the messages twice with my workflow. We\nonly need to maintain double state but only until it is fair / safe to do\nso. I would also believe that with my approach it should be possible (but\nnot really necessary) to have multiple splicing operations in parallel.\n\nOne other question: What happens to the short_channel_id of a channel to\nwhich founds have been spliced in?\n\nbest Rene\n\nOn Wed, Oct 10, 2018 at 5:46 AM Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> Hi all!\n>\n>         We've had increasing numbers of c-lightning users get upset they\n> can't open multiple channels, so I guess we're most motivated to allow\n> splicing of existing channels.  Hence this rough proposal.\n>\n> For simplicity, I've chosen to only allow a single splice at a time.\n> It's still complex :(\n>\n> Feedback welcome!\n> --\n> Splice Negotiation:\n>\n> 1. type: 40 (`splice_add_input`) (`option_splice`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`8`: `satoshis`]\n>    * [`32`: `prevtxid`]\n>    * [`4`: `prevtxoutnum`]\n>    * [`2`: `scriptlen`]\n>    * [`scriptlen`: `scriptpubkey`]\n>\n> 1. type: 41 (`splice_add_output`) (`option_splice`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`8`: `satoshis`]\n>    * [`2`: `scriptlen`]\n>    * [`scriptlen`: `outscript`]\n>\n> 1. type: 42 (`splice_all_added`) (`option_splice`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`4`:`feerate_per_kw`]\n>    * [`4`:`minimum_depth`]\n>\n> Each side sends 0 or more `splice_add_input` and 0 or more\n> `splice_add_output` followed by `spice_all_added` to complete the splice\n> proposal.  This is done either to initiate a splice, or to respond to a\n> `splice_*` from the other party.\n>\n> `splice_add_input` is checked for the following:\n> - must not be during a current splice\n> - scriptpubkey is empty, or of form 'HASH160 <20-byte-script-hash> EQUAL'\n> - `satoshis` doesn't wrap on addition.\n> - MAY check that it matches outpoint specified (sig will simply be\n>   invalid if so), and that outpoint is segwit.\n>\n> `splice_add_output` is checked for the following:\n> - must not be during a current splice\n> - `satoshis` is less than or equal to amount owing to proposer, minus\n>   current reserve, and greater than or equal to `dust_limit_satoshis` we\n>   sent in our open_channel/accept_channel ,sg.\n> - script is one of the approved forms as it is for `shutdown`.\n>\n> FIXME: Do we disallow splice-out if they specified\n>        option_upfront_shutdown_script?\n>\n> `splice_all_added` is checked for the following:\n> - average of `feerate_per_kw` by both sides (round down) is sufficient.\n> - average of `feerate_per_kw` by both sides not grossly excessive, if we're\n>   paying some of the fees (see below!)\n> - both sides can afford the fees from their post-splice funds (see\n>   Verification Changes below)\n> - maximum of the two `minimum_depth` is not grossly excessive.\n> - There is at least one splice_add_input or splice_add_output.\n>\n> Splice negotiation, like closing negotiation, does not have persistent\n> state.  Reconnecting forgets previous negotiation.\n>\n>\n> Splice Signing\n> --------------\n>\n> Once `splice_all_added` is both sent and received, we need to create and\n> sign both the splice tx itself, and the first commitment transaction\n> which spends it (but not in that order!).\n>\n> 1. One input spends the current funding tx output.\n> 2. There is one additional input for each splice_add_input.\n> 3. One output creates the new funding tx.\n> 4. There is one additional output for each splice_add_output.\n> 5. The entire transaction is sorted into BIP69 order.\n> 6. The feerate is the sum of the two `feerate_per_kw` divided by 2,\n>    rounded down.\n>\n> 1. type: 43 (`splice_commitment_signature`) (`option_splice`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`64`:`commitment_signature`]\n>    * [`2`:`num_htlcs`]\n>    * [`num_htlcs*64`:`htlc_signature`]\n>\n> 1. type: 44 (`splice_signature`) (`option_splice`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`64`:`splice_signature`]\n>\n> 1. type: 45 (`splice_witness`) (`option_splice`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`2`: `num_witness_elements`\n>    * [`2`:`len`]\n>    * [`len`:`witnesses`]\n>\n> `witnesses` itself is serialized as `num_witness_elements` of:\n> * `2`:`len`\n> * `len`: `witness_element`\n>\n> Each side sends `splice_commitment_signature` and waits to receive and\n> verify the other side's `splice_commitment_signature` before sending\n> `splice_signature` and `splice_witness` for each `splice_add_input` it\n> proposed, in BIP69 input order.\n>\n> Once a node has sent `splice_commitment_signature` it should remember\n> the splice proposal across reconnects.  Once it has both sent\n> `splice_signature`, the splice is locked in.\n>\n>\n> Splice Announcement\n> -------------------\n>\n> We have to tell the network about the new channel, otherwise there will\n> be a distruption when it sees the old funding transaction spent.  This\n> is inevitable for older nodes who won't understand splicing anyway.\n>\n> We can't send out a `channel_announcement` or `channel_update` for the\n> new channel until after the new funding transaction has 6 confirmations,\n> so we append to the existing `channel_update` for the original channel,\n> using a new `message_flags` field:\n>\n> | Bit Position  | Name                      | Field\n>     |\n> | ------------- | ------------------------- |\n> -------------------------------- |\n> | 0             | `option_channel_htlc_max` | `htlc_maximum_msat`\n>     |\n> | 1             | `option_channel_moving`   | `moving_txid\n>      |\n>\n> The `channel_update` gains the following field:\n>     * [`32`: moving_txid`] (option_channel_moving)\n>\n> If a current `channel_update` for a closing channel contains\n> `option_channel_moving` a node SHOULD ignore the channel close for at\n> least 100 blocks iff spent by `moving_txid`.\n>\n> A node SHOULD immediately forward a `channel_update` it sees containing\n> `option_channel_moving` if neither previous `channel_update` for the\n> channel contains `option_channel_moving`.\n>\n> Each side of the splice can send these unilaterally, and SHOULD allow a\n> few minutes for propagation (remember, average propagation from old\n> nodes is still 30 seconds) prior to broadcast of the splice transaction.\n>\n>\n> Message Changes During Splicing\n> -------------------------------\n> Once you've sent `splice_commitment_signature` each commitment\n> transaction is duplicated: one spends the old funding transaction, one\n> spends the splice transaction:\n>\n> 1. type: 39 (`closing_signed`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`8`:`fee_satoshis`]\n>    * [`64`:`signature`]\n>    * [`64`:`splice_signature`] (`option_splice`)\n>\n> 1. type: 132 (`commitment_signed`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`64`:`signature`]\n>    * [`2`:`num_htlcs`]\n>    * [`num_htlcs*64`:`htlc_signature`]\n>    * [`num_htlcs*64`:`htlc_splice_signature`] (`option_splice`)\n>\n> If a reconnection occurs between between sending and receiving\n> `splice_commitment_signature`) the peer's status is uncertain (similarly\n> for closing).  This we have a new field in `channel_reestablish` to flag\n> that we consider ourselves to be splicing:\n>\n> 1. type: 136 (`channel_reestablish`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`8`:`next_local_commitment_number`]\n>    * [`8`:`next_remote_revocation_number`]\n>    * [`32`:`your_last_per_commitment_secret`] (`option_data_loss_protect`)\n>    * [`33`:`my_current_per_commitment_point`] (`option_data_loss_protect`)\n>    * [`32`:`splice_txid`] (`option_splice`)\n>\n> The splice_txid field indicates that this side considers itself to be\n> splicing.\n>\n> The sender:\n> - if it has sent `splice_commitment_signature` and not sent the\n> corresponding\n>   `splice_closed`, MUST set `splice_txid` to the txid of the splice tx.\n>    - Otherwise MUST NOT.\n>\n> The recipient:\n> - if it has sent `splice_commitment_signature` and not sent the\n> corresponding\n>   `splice_closed`:\n>   - if `splice_txid` does not exist or does not match the current splice:\n>     - SHOULD fail the channel\n>   - otherwise:\n>     - MUST retransmit `splice_signature`\n> - otherwise:\n>   - if `splice_txid` field exists and is not all zeroes:\n>     - MUST send `splice_closed`\n>\n>\n> Validation Changes During Splicing\n> ----------------------------------\n> We track \"post-splice\" values as well as current values during\n> splicing.\n>\n> The post-splice reserve is 1% of post-splice capcacity (rounded down).\n>\n> The fees for the splicing transaction itself are divided into parts by\n> the number of `splice_add_input` plus `splice_add_output`, rounded up.\n> Each side pays as many parts as it proposed `splice_add_input` plus\n> `splice_add_output`.\n>\n> (So if Alice proposes two and Bob proposes one, and the total fee is 1000\n> satoshi, each part is 334 satoshi: Alice pays 668 and Bob pays 334.)\n>\n> Each side's post-splice funds are debited their `splice_add_output`\n> amounts, and credited their `splice_add_input` amounts, a debited the\n> splice tx fees.  If any debiting occurs, the funds must be above the\n> post-splice reserve (ie. you can have below reserve, but you can't spend\n> if you're below reserve).\n>\n> All update_add_htlc must be valid for the *both* the current and\n> post-splice balances.\n>\n> Completing Splicing\n> -------------------\n> Once you've seen both side's `minimum_depth` confirmations of the splice\n> transaction (ie. the maximum of the two `minimum_depth` values), you can\n> complete the splice by sending:\n>\n> 1. type: 46 (`splice_closed`) (`option_splice`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>\n> Once you've sent and received `splice_closed` you can send\n> `announcement_signatures` for the new channel as per normal rules (ie. 6\n> confirmations, `announce_channel` bit set).\n>\n> In addition, you can forget everything about the old channel (including\n> old HTLCs and revocation requirements).\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n\n\n-- \nhttps://www.rene-pickhardt.de\n\nSkype: rene.pickhardt\n\nmobile: +49 (0)176 5762 3618\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181011/d0a500b9/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-10-11T00:32:46",
                "message_text_only": "Ren\u00e9 Pickhardt <r.pickhardt at googlemail.com> writes:\n> So let us take the example of Splicing in:\n> * The situation before splicing is that we have one output in our funding\n> tx that is being spent with each commitment tx. (actually if the channel\n> was spliced before we have more inputs but that should not change anything)\n> * Splice in would create one additional output that can be spent in future\n> commitment tx.\n> * I propose while splicing in this output should be spent by a special\n> commitment tx which goes to the funder of the splicing operation. This\n> should happen before the actual funding takes place. The other commitment\n> tx spending the original output continues to operate (assuring non blocking\n> splice in operation).\n> * Once we have enough confirmations we merge the channels (either\n> automatically or with the next channel update). A new commitment tx is\n> being created which now spends each output of each of the two funding tx\n> and assigns the channel balance to the channel partners accordingly to the\n> two independent channels. The old commitment txs are being invalidated.\n> * The disadvantage is that while splicing is not completed and if the\n> funder of the splicing tx is trying to publish an old commitment tx the\n> node will only be punished by sending all the funds of the first funding tx\n> to the partner as the special commitment tx of the 2nd output has no newer\n> state yet.\n\nYes, this is the alternative method; produce a parallel funding tx\n(which only needs to support a single revocation, or could even be done\nby a long timeout) and then join them when it reaches the agreed depth.\n\nIt has some elegance; particularly because one side doesn't have to do\nany validation or store anything until it's about to splice in.  You get\nasked for a key and signature, you produce a new one, and sign whatever\ntx they want.  They hand you back the tx and the key you used once it's\nburied far enough, and you check the tx is indeed buried and the output\nis the script you're expecting, then you flip the commitment tx.\n\nBut I chose chose not to do this because every transaction commitment\nforever will require 2 signatures, and doesn't allow us to forget old\nrevocation information.\n\nAnd it has some strange side-effects: onchain this looks like two\nchannels; do we gossip about both?  We have to figure the limit on\nsplice-in to make sure the commitment tx stays under 400kSipa.\n\n> I believe splicing out is even safer:\n> * One just creates a spent of the funding tx which has two outputs. One\n> output goes to the recipient of the splice out operation and the second\n> output acts as a new funding transaction for the newly spliced channel.\n> Once signatures for the new commitment transaction are exchanged (basically\n> following the protocol to open a channel) the splicing operation can be\n> broadcasted.\n>\n> * The old channel MUST NOT be used anymore but the new channel can be\n> operational right away without blockchain confirmation. In case someone\n> tries to publish an old state of the old channel it will be a double spent\n> of the splicing operation and in the worst case will be punished and the\n> splicing was not successful.\n>\n>  if one publishes an old state of the new\n> channel everything will just work as normal even if the funding tx is not\n> yet mined. It could only be replaced with an old state of the previous\n> channel (which as we saw is not a larger risk than the usual operation of a\n> lightning node)\n\nRight, you're relying on CPFP pushing through the splice-out tx if it\ngets stuck.  This requires that we check carefully for standardness and\nother constraints which might prevent this; for example, we can't allow\nmore than 20 (?) of these in a row without being sufficiently buried\nsince I think that's where CPFP calculations top out.\n\n> As mentioned maybe you had this workflow already in your mind but I don't\n> see why we need to send around all the messages twice with my workflow. We\n> only need to maintain double state but only until it is fair / safe to do\n> so. I would also believe that with my approach it should be possible (but\n> not really necessary) to have multiple splicing operations in parallel.\n\nThe extra sigs are only needed in transition, though; once splicing is\nover the channel looks exactly like a newly created one, which is nice.\n\n> One other question: What happens to the short_channel_id of a channel to\n> which founds have been spliced in?\n\nIn the parallel splice world, they look like two channels.  In my\nproposal it looks like a new channel, with a channel_update to make sure\nmodern nodes know that the transition is happening.\n\nCheers,\nRusty."
            },
            {
                "author": "Christian Decker",
                "date": "2018-10-11T17:33:48",
                "message_text_only": "On Thu, Oct 11, 2018 at 3:40 AM Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> > * Once we have enough confirmations we merge the channels (either\n> > automatically or with the next channel update). A new commitment tx is\n> > being created which now spends each output of each of the two funding tx\n> > and assigns the channel balance to the channel partners accordingly to\n> the\n> > two independent channels. The old commitment txs are being invalidated.\n> > * The disadvantage is that while splicing is not completed and if the\n> > funder of the splicing tx is trying to publish an old commitment tx the\n> > node will only be punished by sending all the funds of the first funding\n> tx\n> > to the partner as the special commitment tx of the 2nd output has no\n> newer\n> > state yet.\n>\n> Yes, this is the alternative method; produce a parallel funding tx\n> (which only needs to support a single revocation, or could even be done\n> by a long timeout) and then join them when it reaches the agreed depth.\n>\n> It has some elegance; particularly because one side doesn't have to do\n> any validation or store anything until it's about to splice in.  You get\n> asked for a key and signature, you produce a new one, and sign whatever\n> tx they want.  They hand you back the tx and the key you used once it's\n> buried far enough, and you check the tx is indeed buried and the output\n> is the script you're expecting, then you flip the commitment tx.\n>\n> But I chose chose not to do this because every transaction commitment\n> forever will require 2 signatures, and doesn't allow us to forget old\n> revocation information.\n>\n> And it has some strange side-effects: onchain this looks like two\n> channels; do we gossip about both?  We have to figure the limit on\n> splice-in to make sure the commitment tx stays under 400kSipa.\n>\n\nThis is a lot closer to my original proposal for splicing, and I\nstill like it a lot more since the transition from old to new\nchannel is bascially atomic (not having to update state on both\npre-splice and post-splice version). The new funds will remain\nunavailable for the same time, and since we allow only one\nconcurrent splice in your proposal we don't even lose any\nadditional time regarding the splice-outs.\n\nSo pulling the splice_add_input and splice_add_output up to\nsignal the intent of adding funds to a splice. Splice_all_added\nis then used to start moving the funds to a pre-allocated 2-of-2\noutput where the funds can mature. Once the funds are\nmatured (e.g., 6 confirmations) we can start the transition: both\nparties claim the funding output, and the pre-allocated funds, to\ncreate a new funding tx which is immediately broadcast, and we\nflip over to the new channel state. No need to keep parallel\nstate and then disambiguating which one it was.\n\nThe downsides of this is that we now have 2 on-chain\ntransactions (pre-allocation and re-open), and splice-outs are no\nlonger immediate if we have a splice-in in the changeset as well.\nThe latter can be remediatet with one more reanchor that just\nconsiders splice-ins that were proposed.\n\n\n\n>\n> > I believe splicing out is even safer:\n> > * One just creates a spent of the funding tx which has two outputs. One\n> > output goes to the recipient of the splice out operation and the second\n> > output acts as a new funding transaction for the newly spliced channel.\n> > Once signatures for the new commitment transaction are exchanged\n> (basically\n> > following the protocol to open a channel) the splicing operation can be\n> > broadcasted.\n> >\n> > * The old channel MUST NOT be used anymore but the new channel can be\n> > operational right away without blockchain confirmation. In case someone\n> > tries to publish an old state of the old channel it will be a double\n> spent\n> > of the splicing operation and in the worst case will be punished and the\n> > splicing was not successful.\n> >\n> >  if one publishes an old state of the new\n> > channel everything will just work as normal even if the funding tx is not\n> > yet mined. It could only be replaced with an old state of the previous\n> > channel (which as we saw is not a larger risk than the usual operation\n> of a\n> > lightning node)\n>\n> Right, you're relying on CPFP pushing through the splice-out tx if it\n> gets stuck.  This requires that we check carefully for standardness and\n> other constraints which might prevent this; for example, we can't allow\n> more than 20 (?) of these in a row without being sufficiently buried\n> since I think that's where CPFP calculations top out.\n>\n\nWe shouldn't allow more than one pending splice operation anyway, as\nstated in your proposal initially. We are already critically reliant on our\ntransaction being confirmed on-chain, so I don't see this as much of an\nadded issue.\n\n\n> > As mentioned maybe you had this workflow already in your mind but I don't\n> > see why we need to send around all the messages twice with my workflow.\n> We\n> > only need to maintain double state but only until it is fair / safe to do\n> > so. I would also believe that with my approach it should be possible (but\n> > not really necessary) to have multiple splicing operations in parallel.\n>\n> The extra sigs are only needed in transition, though; once splicing is\n> over the channel looks exactly like a newly created one, which is nice.\n>\n\nI'm less worried about the bandwidth overhead, rather the\nparallel state updates are error prone and there might be\ncorner-cases that we simply don't see right now. Having parallel\nstate-updates just for the sake of saving some on-chain\nfees (fees that we'd spend in purely on-chain cases anyway) has a\ndirect impact on the channel state machine.\n\n\n> > One other question: What happens to the short_channel_id of a channel to\n> > which founds have been spliced in?\n>\n> In the parallel splice world, they look like two channels.  In my\n> proposal it looks like a new channel, with a channel_update to make sure\n> modern nodes know that the transition is happening.\n>\n\nWith the pre-allocation the final effect is the same, we've just\npulled some of the waiting time above the re-anchoring and added\none more TX.\n\n\nThis is one of the cases where a simpler solution (relatively\nspeaking ^^) is to be preferred imho, allowing for future\niterations.\n\nCheers,\nChristian\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181011/f7fa9632/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-10-12T03:30:12",
                "message_text_only": "Good morning Rusty and Christian and list,\n\n> This is one of the cases where a simpler solution (relatively\n> speaking ^^) is to be preferred imho, allowing for future\n> iterations.\n\nI would basically agree here, with the further proviso that I think splice is not quite as priority as AMP, decorrelation, or watchtowers.\n\nThe simpler solution has the drawback of more transactions onchain, but massively reduces the complexity of maintaining parallel state updates.  Parallel updates would increase greatly our need to test the feature in various conditions (and specify also in the formal spec what possible failure modes are and how they should be recovered, as a basic safety for users of Lightning).\n\nOf course, the same course of thought is what lead to onchain transaction bloat in the first place.\n\nSplicing features might be versioned, with the possibility of better splicing mechanisms being defined in later BOLT specs.  This can allow us to iterate somewhat and start with the simpler-but-more-onchain-txes splicev1 feature, possibly getting replaced with a more thought-out-and-planned splicev2 feature with parallel updates (and careful analysis of possible failures in parallel updates and how we should recover from them).  The drawback is that this is further complexity later on by having to possibly support multiple splicing mechanisms (but if we assign completely separate feature bits, it may be possible for pragmatic implementations to eventually stop signalling the ability to splice using older splicing feature versions in favor of newer splicing feature versions).\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181012/ad5e2132/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-10-12T04:21:01",
                "message_text_only": "Christian Decker <decker.christian at gmail.com> writes:\n> On Thu, Oct 11, 2018 at 3:40 AM Rusty Russell <rusty at rustcorp.com.au> wrote:\n>\n>> > * Once we have enough confirmations we merge the channels (either\n>> > automatically or with the next channel update). A new commitment tx is\n>> > being created which now spends each output of each of the two funding tx\n>> > and assigns the channel balance to the channel partners accordingly to\n>> the\n>> > two independent channels. The old commitment txs are being invalidated.\n>> > * The disadvantage is that while splicing is not completed and if the\n>> > funder of the splicing tx is trying to publish an old commitment tx the\n>> > node will only be punished by sending all the funds of the first funding\n>> tx\n>> > to the partner as the special commitment tx of the 2nd output has no\n>> newer\n>> > state yet.\n>>\n>> Yes, this is the alternative method; produce a parallel funding tx\n>> (which only needs to support a single revocation, or could even be done\n>> by a long timeout) and then join them when it reaches the agreed depth.\n>>\n>> It has some elegance; particularly because one side doesn't have to do\n>> any validation or store anything until it's about to splice in.  You get\n>> asked for a key and signature, you produce a new one, and sign whatever\n>> tx they want.  They hand you back the tx and the key you used once it's\n>> buried far enough, and you check the tx is indeed buried and the output\n>> is the script you're expecting, then you flip the commitment tx.\n>>\n>> But I chose chose not to do this because every transaction commitment\n>> forever will require 2 signatures, and doesn't allow us to forget old\n>> revocation information.\n>>\n>> And it has some strange side-effects: onchain this looks like two\n>> channels; do we gossip about both?  We have to figure the limit on\n>> splice-in to make sure the commitment tx stays under 400kSipa.\n>>\n>\n> This is a lot closer to my original proposal for splicing, and I\n> still like it a lot more since the transition from old to new\n> channel is bascially atomic (not having to update state on both\n> pre-splice and post-splice version). The new funds will remain\n> unavailable for the same time, and since we allow only one\n> concurrent splice in your proposal we don't even lose any\n> additional time regarding the splice-outs.\n>\n> So pulling the splice_add_input and splice_add_output up to\n> signal the intent of adding funds to a splice. Splice_all_added\n> is then used to start moving the funds to a pre-allocated 2-of-2\n> output where the funds can mature. Once the funds are\n> matured (e.g., 6 confirmations) we can start the transition: both\n> parties claim the funding output, and the pre-allocated funds, to\n> create a new funding tx which is immediately broadcast, and we\n> flip over to the new channel state. No need to keep parallel\n> state and then disambiguating which one it was.\n\nIf we're going to do side splice-in like this, I would use a very\ndifferent protocol: the reason for this protocol was to treat splice-in\nand splice-out the same, and inline splice-in requires wait time.  Since\nsplice-out doesn't, we don't need this at all.\n\nIt would look much more like:\n\n1. Prepare any output with script of specific form. eg:\n        OP_DEPTH 3 OP_EQUAL OP_IF\n                <funding_pubkey1> <funding_pubkey2> OP_CHECKMULTISIG\n        OP_ELSE\n                <blockheight> OP_CHECKLOCKTIMEVERIFY OP_DROP\n                <myrescue_pubkey> OP_CHECKSIG\n        OP_ENDIF\n\n1. type: 40 (`splice_in`) (`option_splice`)\n2. data:\n   * [`32`:`channel_id`]\n   * [`8`: `satoshis`]\n   * [`32`: `txid`]\n   * [`4`: `txoutnum`]\n   * [`4`: `blockheight`]\n   * [`33`: `myrescue_pubkey`]\n\n1. type: 137 (`update_splice_in_accept`) (`option_splice`)\n   data:\n   * [`32`:`channel_id`]\n   * [`32`: `txid`]\n   * [`4`: `txoutnum`]\n\n1. type: 138 (`update_splice_in_reject`) (`option_splice`)\n   data:\n   * [`32`:`channel_id`]\n   * [`32`: `txid`]\n   * [`2`:`len`]\n   * [`len`:`errorstr`]\n\nThe recipient of `splice_in` checks that it's happy with the\n`blockheight` (far enough in future).  Once it sees the tx referred to\nburied to its own `minimum_depth`, it checks output is what they\nclaimed, then sends `update_splice_in_accept`; it's followed up\n`commitment_signed` like normal, but from this point onwards, all\ncommitment txs signatures have one extra sig.\n\nSimilarly, splice-out:\n\n1. type: 139 (`update_splice_out`) (`option_splice`)\n   * [`32`:`channel_id`]\n   * [`8`: `satoshis`]\n   * [`2`: `scriptlen`]\n   * [`scriptlen`: `outscript`]\n\nThe recipient checks that the output script is standard, and the amount\ncan be afforded by the other side.  From then on, each commitment tx has\na new output.\n\nNote this doesn't put the splice out on the blockchain!\n\n1. type: 140 (`propose_reopen`) (`option_splice`)\n   * [`32`:`channel_id`]\n   * [`4`:`feerate_per_kw`]\n   * [`33`:`funding_pubkey`]\n\nThis is initiates a mutually-agreed broadcast of the current state: all\ninputs (original and spliced), all spliced outputs, and a funding-style\n2x2 which has all the remaining funds.  Call this a 'reopen tx'.\n\nThis must be done with no outstanding commitments, like closing tx\nnegotiation, and it's a back-and-forth until both sides agree on\nfeerate.  Then you send:\n\n1. type: 141 (`reopen_accept`) (`option_splice`)\n   * [`32`:`channel_id`]\n   * [`4`:`feerate_per_kw`]\n   * [`64`: `new_commitment_sig`]\n\nOnce you've received and sent this, you're ready to sign the reopen tx:\n\n1. type: 142 (`reopen`) (`option_splice`)\n   * [`32`:`channel_id`]\n   * [`64`: `reopen_commitment_sig`]\n\nWe need similar 'what happens on reconnect at various points' logic to\nthe previous one <handwave>.\n\nOnce you've sent and received the `reopen`, you can broadcast the reopen\ntx at will and start updating again.  If we recommend that public\nchannels reuse their old `funding_pubkey` then that means that we should\nalso have gossip continuity for upgraded nodes, and don't need the\nprevious channel_update hack.\n\nWe could add a new `reopen_locked` message which indicates that both\nsides are happy with the reopen depth, if we don't want to allow reopens\nback-to-back?\n\n> This is one of the cases where a simpler solution (relatively\n> speaking ^^) is to be preferred imho, allowing for future\n> iterations.\n\nUnless we can have both :)\n\nCheers,\nRusty."
            },
            {
                "author": "Rusty Russell",
                "date": "2018-10-16T22:30:15",
                "message_text_only": "Rusty Russell <rusty at rustcorp.com.au> writes:\n> If we're going to do side splice-in like this, I would use a very\n> different protocol: the reason for this protocol was to treat splice-in\n> and splice-out the same, and inline splice-in requires wait time.  Since\n> splice-out doesn't, we don't need this at all.\n>\n> It would look much more like:\n>\n> 1. Prepare any output with script of specific form. eg:\n>         OP_DEPTH 3 OP_EQUAL OP_IF\n>                 <funding_pubkey1> <funding_pubkey2> OP_CHECKMULTISIG\n>         OP_ELSE\n>                 <blockheight> OP_CHECKLOCKTIMEVERIFY OP_DROP\n>                 <myrescue_pubkey> OP_CHECKSIG\n>         OP_ENDIF\n>\n> 1. type: 40 (`splice_in`) (`option_splice`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`8`: `satoshis`]\n>    * [`32`: `txid`]\n>    * [`4`: `txoutnum`]\n>    * [`4`: `blockheight`]\n>    * [`33`: `myrescue_pubkey`]\n>\n> 1. type: 137 (`update_splice_in_accept`) (`option_splice`)\n>    data:\n>    * [`32`:`channel_id`]\n>    * [`32`: `txid`]\n>    * [`4`: `txoutnum`]\n>\n> 1. type: 138 (`update_splice_in_reject`) (`option_splice`)\n>    data:\n>    * [`32`:`channel_id`]\n>    * [`32`: `txid`]\n>    * [`2`:`len`]\n>    * [`len`:`errorstr`]\n>\n> The recipient of `splice_in` checks that it's happy with the\n> `blockheight` (far enough in future).  Once it sees the tx referred to\n> buried to its own `minimum_depth`, it checks output is what they\n> claimed, then sends `update_splice_in_accept`; it's followed up\n> `commitment_signed` like normal, but from this point onwards, all\n> commitment txs signatures have one extra sig.\n\nLisa started asking pointed questions, and so I noticed that parallel\nsplice doesn't work with Poon-Dryja channels.\n\nThe counterparty can spend the old funding txout with a revoked spend.\nSure, I can take all the money from that, but what about the spliced\ninput?\n\nI came up with increasingly elaborate workarounds, but nothing stuck.\n\nBack to Plan A...\nRusty."
            },
            {
                "author": "lisa neigut",
                "date": "2018-10-17T01:09:02",
                "message_text_only": "To add some context to this, if you start accepting HTLC's for the new\nbalance after the parallel commitment is made, but before the re-anchor is\nburied, there's the potential for a race condition between a unilateral\nclose (or any revoked commitment transaction) and the re-anchoring\ncommitment transaction, that spends the 'pre-committed' UTXO of splicing in\nfunds and the original funding transaction.\n\nYou can get around this by waiting until both the pre-commitment UTXO and\nthe re-anchor have cleared a minimum depth before accepting HTLC's for the\nnew balance totals, but that's twice as long of a wait as the first,\nsynchronized re-commitment scheme that Rusty originally proposed.\n\nIt also makes leaving the original funding transaction 'exposed' (ie Rene's\nversion of parallel splice) untenable, as there's always the risk of an old\nstate being published to consume that input. This foobars your current HTLC\ncommitments.\n\nOn Tue, Oct 16, 2018 at 3:31 PM Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> Rusty Russell <rusty at rustcorp.com.au> writes:\n> > If we're going to do side splice-in like this, I would use a very\n> > different protocol: the reason for this protocol was to treat splice-in\n> > and splice-out the same, and inline splice-in requires wait time.  Since\n> > splice-out doesn't, we don't need this at all.\n> >\n> > It would look much more like:\n> >\n> > 1. Prepare any output with script of specific form. eg:\n> >         OP_DEPTH 3 OP_EQUAL OP_IF\n> >                 <funding_pubkey1> <funding_pubkey2> OP_CHECKMULTISIG\n> >         OP_ELSE\n> >                 <blockheight> OP_CHECKLOCKTIMEVERIFY OP_DROP\n> >                 <myrescue_pubkey> OP_CHECKSIG\n> >         OP_ENDIF\n> >\n> > 1. type: 40 (`splice_in`) (`option_splice`)\n> > 2. data:\n> >    * [`32`:`channel_id`]\n> >    * [`8`: `satoshis`]\n> >    * [`32`: `txid`]\n> >    * [`4`: `txoutnum`]\n> >    * [`4`: `blockheight`]\n> >    * [`33`: `myrescue_pubkey`]\n> >\n> > 1. type: 137 (`update_splice_in_accept`) (`option_splice`)\n> >    data:\n> >    * [`32`:`channel_id`]\n> >    * [`32`: `txid`]\n> >    * [`4`: `txoutnum`]\n> >\n> > 1. type: 138 (`update_splice_in_reject`) (`option_splice`)\n> >    data:\n> >    * [`32`:`channel_id`]\n> >    * [`32`: `txid`]\n> >    * [`2`:`len`]\n> >    * [`len`:`errorstr`]\n> >\n> > The recipient of `splice_in` checks that it's happy with the\n> > `blockheight` (far enough in future).  Once it sees the tx referred to\n> > buried to its own `minimum_depth`, it checks output is what they\n> > claimed, then sends `update_splice_in_accept`; it's followed up\n> > `commitment_signed` like normal, but from this point onwards, all\n> > commitment txs signatures have one extra sig.\n>\n> Lisa started asking pointed questions, and so I noticed that parallel\n> splice doesn't work with Poon-Dryja channels.\n>\n> The counterparty can spend the old funding txout with a revoked spend.\n> Sure, I can take all the money from that, but what about the spliced\n> input?\n>\n> I came up with increasingly elaborate workarounds, but nothing stuck.\n>\n> Back to Plan A...\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181016/6855b1ec/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-10-17T05:00:15",
                "message_text_only": "Good morning lisa,\n\nThis is a good observation.\n\nBefore, I'd already considered the rationale, for why channels have a single 2-of-2 UTXO as funding output.  And it seems I should have considered this, prior to accepting the \"parallel\" construction as feasible.\n\nFor sake of posterity, I leave the below writeup as a tangential to the design of splice (and to the design of Lightning having a single 2-of-2 UTXOs):\n\n# 0-conf is Unsafe, Yet Lightning is Safe; Why?\n\nTo accept a 0-conf transaction output, is known to be unsafe.  Replace-by-fee is always a possibility, regardless of whether the transaction opts in to RBF or not: a rational miner will always accept the higher feerate, disregarding any \"opt-in\" flag that is set or not set on the transaction.  Thus we reject any advice that claims that 0-conf is tenable, even for tiny amounts.\n\nYet when viewed solely in terms of transactions, Lightning protocol uses transactions that are not on any block (are kept offchain).  Since they are not in a block, they are indistinguishable from 0-conf transactions, which are accepted by the receiver, yet are also not on any block.  One might argue the distinction, that a \"real\" 0-conf transaction exists on some mempool somewhere, and thus has a chance to be on a block in the future, but mempools have no consensus, and the existence of a transaction on some mempool is not a safe assurance of it existing in the mempool of the next winning miner.\n\nSo why is Lightning safe, when 0-conf transactions are in general not safe?\n\nAgain, we should focus on why 0-conf transactions in general are not safe: transaction replacement.  Thus, 0-conf transactions can be made safe, if you are somehow able to ensure that replacement transactions cannot be made.\n\nFor example, if you are part of an n-of-n federation that signs the transaction, you can always safely accept a 0-conf transaction from that federation paying only to you, because you can always veto any replacement (by simply refusing to sign) that is not in your interests.\n\nThis is in fact how Lightning works: a 2-of-2 federation (the channel counterparties) are the signatories of the 0-conf transactions that are the commitment transactions of the Lightning protocol.  Replacement of the commitment transactions is strictly guided by the protocol; both sides have veto rights, since the source transaction output is 2-of-2.\n\nThus, Lightning, though it uses 0-conf transactions, is safe, because it prevents the replacement of a 0-conf transaction without the receiver allowing it, by the simple expedient of including the receiver in the 2-of-2 multisig guarding its single funding TXO.\n\n##  The Implications for Splice Proposals\n\nSome splice proposals involve creating the equivalent of multiple funding TXOs for a single channel.  Such constructions are unsafe-by-default on Poon-Dryja.\n\nIn reality, every commitment transaction (or update transaction in Decker-Osuntokun-Russell) is replaceable by any other commitment (or update) transaction for that channel.  Under Poon-Dryja older transactions are revoked (and hence one side risks loss of their collateral) while under Decker-Osuntokun-Russell older transactions may be \"gainsaid\" (i.e. newer update transactions may be reanchored to consume the TXO of the older update transaction, thus preventing that update from truly being committed to).\n\nThis is relevant since before a splice, the channel has a single funding TXO, while after the splice, the channel has multiple.\n\nIn particular, a commitment (or update) transaction, that has multiple inputs (to consume the multiple funding TXOs), can be replaced with a commitment (or update) transaction that was created before the splice.  Under Poon-Dryja, such a commitment transaction may be revoked, but this leaves the other funding TXOs unuseable.  Under Decker-Osuntokun-Russell, as long as the sequence number is preserved across the splice, it is possible for a later update transaction with multiple inputs to simply gainsay the old single-input update with the new multiple-input update transaction. (I suppose, that this is another advantage that Decker-Osuntokun-Russell has).\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Wednesday, October 17, 2018 9:09 AM, lisa neigut <niftynei at gmail.com> wrote:\n\n> To add some context to this, if you start accepting HTLC's for the new balance after the parallel commitment is made, but before the re-anchor is buried, there's the potential for a race condition between a unilateral close (or any revoked commitment transaction) and the re-anchoring commitment transaction, that spends the 'pre-committed' UTXO of splicing in funds and the original funding transaction.\n>\n> You can get around this by waiting until both the pre-commitment UTXO and the re-anchor have cleared a minimum depth before accepting HTLC's for the new balance totals, but that's twice as long of a wait as the first, synchronized re-commitment scheme that Rusty originally proposed.\n>\n> It also makes leaving the original funding transaction 'exposed' (ie Rene's version of parallel splice) untenable, as there's always the risk of an old state being published to consume that input. This foobars your current HTLC commitments.\n>\n> On Tue, Oct 16, 2018 at 3:31 PM Rusty Russell <rusty at rustcorp.com.au> wrote:\n>\n>> Rusty Russell <rusty at rustcorp.com.au> writes:\n>>> If we're going to do side splice-in like this, I would use a very\n>>> different protocol: the reason for this protocol was to treat splice-in\n>>> and splice-out the same, and inline splice-in requires wait time.  Since\n>>> splice-out doesn't, we don't need this at all.\n>>>\n>>> It would look much more like:\n>>>\n>>> 1. Prepare any output with script of specific form. eg:\n>>>         OP_DEPTH 3 OP_EQUAL OP_IF\n>>>                 <funding_pubkey1> <funding_pubkey2> OP_CHECKMULTISIG\n>>>         OP_ELSE\n>>>                 <blockheight> OP_CHECKLOCKTIMEVERIFY OP_DROP\n>>>                 <myrescue_pubkey> OP_CHECKSIG\n>>>         OP_ENDIF\n>>>\n>>> 1. type: 40 (`splice_in`) (`option_splice`)\n>>> 2. data:\n>>>    * [`32`:`channel_id`]\n>>>    * [`8`: `satoshis`]\n>>>    * [`32`: `txid`]\n>>>    * [`4`: `txoutnum`]\n>>>    * [`4`: `blockheight`]\n>>>    * [`33`: `myrescue_pubkey`]\n>>>\n>>> 1. type: 137 (`update_splice_in_accept`) (`option_splice`)\n>>>    data:\n>>>    * [`32`:`channel_id`]\n>>>    * [`32`: `txid`]\n>>>    * [`4`: `txoutnum`]\n>>>\n>>> 1. type: 138 (`update_splice_in_reject`) (`option_splice`)\n>>>    data:\n>>>    * [`32`:`channel_id`]\n>>>    * [`32`: `txid`]\n>>>    * [`2`:`len`]\n>>>    * [`len`:`errorstr`]\n>>>\n>>> The recipient of `splice_in` checks that it's happy with the\n>>> `blockheight` (far enough in future).  Once it sees the tx referred to\n>>> buried to its own `minimum_depth`, it checks output is what they\n>>> claimed, then sends `update_splice_in_accept`; it's followed up\n>>> `commitment_signed` like normal, but from this point onwards, all\n>>> commitment txs signatures have one extra sig.\n>>\n>> Lisa started asking pointed questions, and so I noticed that parallel\n>> splice doesn't work with Poon-Dryja channels.\n>>\n>> The counterparty can spend the old funding txout with a revoked spend.\n>> Sure, I can take all the money from that, but what about the spliced\n>> input?\n>>\n>> I came up with increasingly elaborate workarounds, but nothing stuck.\n>>\n>> Back to Plan A...\n>> Rusty.\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181017/aa172a58/attachment-0001.html>"
            },
            {
                "author": "Conner Fromknecht",
                "date": "2018-10-19T03:04:59",
                "message_text_only": "Good evening all,\n\nThank you Rusty for starting us down this path :) and to ZmnSCPxj and Lisa\nfor\nyour thoughts. I think this narrows down the design space considerably!\n\nIn light of this, and if I'm following along, it seems our hand is forced in\nsplicing via a single on-chain transaction. In my book, this is preferable\nanyway. I'd much rather push complexity off-chain than having to do a\nmutli-stage splicing pipeline.\n\n> To add some context to this, if you start accepting HTLC's for the new\nbalance\n> after the parallel commitment is made, but before the re-anchor is buried,\n> there's the potential for a race condition between a unilateral close (or\nany\n> revoked commitment transaction) and the re-anchoring commitment\ntransaction,\n> that spends the 'pre-committed' UTXO of splicing in funds and the original\n> funding transaction\n\nIndeed, I'm not aware of any splicing mechanism that enables off-chain use\nof\nspliced-in funds before the new funding output confirms. Even in the async,\nsingle-txn case, the new funds cannot be spent until the new funding output\nconfirms sufficiently.\n\n>From my POV, the desired properties of a splice are:\n 1. non-blocking (asynchronous) usage of the channel\n 2. single on-chain txn\n 3. ability to RBF (have multiple pending splices)\n\nOf these, it seems we've solidified 1 and 2. I understand the desire to not\ntackle RBF on the first attempt given the additional complexity.  However, I\ndo believe there are ways we can proceed in which our first attempt largely\ncoincides with supporting it in the future.\n\nWith that in mind, here are some thoughts on the proposals above.\n\n## RBF and Multiple Splices\n\n> 1. type: 132 (`commitment_signed`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`64`:`signature`]\n>    * [`2`:`num_htlcs`]\n>    * [`num_htlcs*64`:`htlc_signature`]\n>    * [`num_htlcs*64`:`htlc_splice_signature`] (`option_splice`)\n\nThis will overflow the maximum message size of 65535 bytes for num_htlcs >\n511.\n\nI would propose sending a distinct message, which references the\n`active_channel_id` and a `splice_channel_id` for the pending splice:\n\n1. type: XXX (`commitment_splice_signed`) (`option_splice`)\n2. data:\n   * [`32`:`active_channel_id`]\n   * [`32`:`splice_channel_id`]\n   * [`64`:`signature`]\n   * [`2`:`num_htlcs`]\n   * [`num_htlcs*64`:`htlc_signature`]\n\nThis more directly addresses handling multiple pending splices, as well as\npreventing us from running into any size constraints. The purpose of\nincluding the `active_channel_id` would be to remote node locate the\nspliced channel, since it may not be populated indexes containing\nactive channels. If we don't want to include this, the existing message\ncan be used without modification.\n\n> We shouldn't allow more than one pending splice operation anyway, as\n> stated in your proposal initially. We are already critically reliant on\nour\n> transaction being confirmed on-chain, so I don't see this as much of an\n> added issue.\n\nIMO there's no reason to limit ourselves to one pending splice at the\nmessage\nlevel. I think it'd be an oversight to not to plan ahead with RBF in mind,\ngiven that funding transactions have gone unconfirmed precisely because of\nimproperly chosen fee rates. Arguably, funding flow should be extended to\nsupport this as well.\n\nCPFP works, though it's more wasteful than resigning and I'd prefer only to\ndo\nso out of necessity, rather than relying on it. CPFP is nice because it\ndoesn't\nrequire interaction, though we are already assuming the other party to be\nonline during the splice (unlike unilateral closes).\n\nAdding a splice-reject message/error code should be sufficient to allow\nimplementations to signal that their local tolerance for number of pending\nsplices has been reached. It's likely we'd all start with getting one splice\nworking, but then the messages won't need to modified if we want to\nimplement\nadditional pending splices via RBF.\n\nA node that wants to RBF but receives a reject can then proceed with CPFP\nas a\nlast resort.\n\nAre there any downsides I'm overlooking with this approach?\n\n> | Bit Position  | Name                      | Field\n      |\n> | ------------- | ------------------------- |\n-------------------------------- |\n> | 0             | `option_channel_htlc_max` | `htlc_maximum_msat`\n      |\n> | 1             | `option_channel_moving`   | `moving_txid\n     |\n>\n> The `channel_update` gains the following field:\n>     * [`32`: moving_txid`] (option_channel_moving)\n\nDo we actually need to send the `moving_txid` via a channel update? I think\nit's\nenough for both parties to send `channel_update`s with the\n`option_channel_moving` bit set, and continue to keep the channel in our\nrouting\ntable.\n\nIf we receive later receive two `channel_update`s whose `short_channel_id`s\nreference the spending transaction (and the node pubkeys are the same), we\nassume the splice was successful and that this channel has been subsumed. I\nthink this works so long as the spending transaction doesn't contain\nmultiple\nfunding outputs, though I think the current proposal is fallible to this as\nwell.\n\nTo me, this proposal has the benefit of not bloating gossip bandwidth with\nan\nextra field that would need to parsed indefinitely, and gracefully\nsupporting\nRBF down the road. Otherwise we'd need to gossip and store each potential\ntxid.\n\nWith regards to forwarding, both `short_channel_id`s would be accepted by\nthe\nsplicers for up to 100 blocks (after splice confirm?), at which point they\ncan\nboth forget the prior `short_channel_id`.\n\n## Shachain\n\n> I thought about restarting the revocation sequence, but it seems like\n> that only saves a tiny amount since we only store log(N) entries.  We\n> can drop old HTLC info post-splice though, and (after some delay for\n> obscurity) tell watchtowers to drop old entries I think.\n\nI agree the additional state isn't too burdensome, and that we would still\nbe\nable to drop watchtower state after some delay as you mentioned.\n\nOn one hand, it does seem like the opportune time to remove such state if\ndesired.\n\nOTOH, it is _really_ nice from an atomicity perspective that the current\nchannel and (potentially) N pending channels can be revoked using a single\ncommitment secret and message. Doing so would mean we don't have to\nmodify the `revoke_and_ack` or `channel_reestablish` messages. The receiver\nwould just apply the commitment secrets/points to the current channel and\nany\npending splices.\n\n## Misc\n\n> Any reason to now make the splicing_add_* messages allow one to add\nseveral\n> inputs in a single message? Given \"acceptable\" constraints for how large\nthe\n> witness and pkScripts can be, we can easily enforce an upper limit on the\n> number of inputs/outputs to add.\n\nYes, I prefer this simplification.\n\n> Additionally, as the size of the channel is either expanding or\ncontracting,\n> both sides should be allowed to modify things like the CSV param, reserve,\n> max accepted htlc's, max htlc size, etc. Many of these parameters like the\n> CSV value should scale with the size of the channel, not allowing these\n> parameters to be re-negotiated could result in odd scenarios like still\n> maintain a 1 week CSV when the channel size has dipped from 1 BTC to 100k\n> satoshis.\n\nAgreed!\n\n> These all seem marginal to me.  I think if we start hitting max values,\n> we should discuss increasing them.\n\nDoesn't this defeat the goal of firewalling funds against individual channel\nfailures?\n\n>>> One thing that I think we should lift from the multiple funding output\n>>> approach is the \"pre seating of inputs\". This is cool as it would allow\n>>> clients to generate addresses, that others could deposit to, and then\nhave\n>>> be spliced directly into the channel. Public derivation can be used,\nalong\n>>> with a script template to do it non-interactively, with the clients\npicking\n>>> up these deposits, and initiating a splice in as needed.\n>>\n>> How about this restatement?\n>>\n>> 1.  Each channel has two public-key-derivation paths (BIP32) to create\nonchain\n>> addresses.  One for each side of the channel.\n>> 2.  The base of the above is actually a combined private-public keypair\nof both\n>> sides (e.g. created via MuSig or some other protocol).  Thus the\naddresses\n>> require cooperation of both parties to spend.\n>> 3.  When somebody sends to one of the onchain addresses in the path,\ntheir\n>> client detects this.\n>> 4.  The client updates the current transaction state, such that the new\ncommit\n>> transaction has two inputs ( the original channel transaction and the\nnew UTXO).\n>>\n>> The above seems unsafe without trust in the other peer, as, the other\npeer can\n>> simply refuse to create the new commit transaction.  Since the address\nrequires\n>> both parties to spend, the money cannot be spent and there is no backoff\n>> transaction that can be used.  But maybe you can describe some mechanism\nto\n>> ensure this, if this is what is meant instead?\n>\n> This could easily be solved by making the destination address a Taproot\n> address, which by default is just a 2-of-2, but in the uncooperative\n> case it can reveal the script it commits to, which is just a timelocked\n> refund that requires a single-sig. The only problem with this is that\n> the refund would be non-interactive, and so the entirety of the funds,\n> that may be from a third-party, need to be claimed by one endpoint,\n> i.e., there is no splitting the funds in case of an uncollaborative\n> refund. Not sure how important that is though, since I don't think\n> third-party funds will come from unrelated parties, e.g., most of these\n> funds will come from an on-chain wallet that is under the control of\n> either parties so the refund should go back to that party anyway.\n\nThis can be accomplished similarly by having either (or both) party\npublishing a\nstatic address or publicly derivable address specific to the channel,\nderived\nfrom their HD seed.\n\nArguably, the address should perhaps be global, so that it can outlive the\nlifetime of the channel, i.e. as soon as the first person deposits and a\nsplice\nis initiated, is the address still valid for the new channel if new keys are\nused? Similarly, the channel could be closed and the funds locked until\nthe timeout if the peer disappears.\n\nRegardless, both approaches can be made to have equivalent amounts of\n[non-]interactivity. However, the recipient isn't burdened in spending by\n1) interaction with the channel peer, or 2) an absolute timeout if 1 fails,\ngiving the receiver more flexibility if they wish to not commit the received\nfunds to a splice. It also benefits from smaller witness sizes, a larger\nanonymity set, etc.\n\nIn general, using a 2-of-2+timeout to stage funds for splicing doesn't offer\nthat much IMO. It seems the primary purpose is to prevent the funds from\nbeing\ndouble spent during the splice, but observe that this is still possible if\nthe\ntimeout matures, perhaps because the splice doesn't confirm in a timely\nmanner.\n\nAcknowledging this, detecting double-spent inputs is still required for full\ncorrectness. By implementing it, either party is free to propose arbitrary\ninputs for a splice, which I believe reduces complexity in the long run.\n\nSplice out,\nConner\n\nOn Tue, Oct 16, 2018 at 10:00 PM ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning lisa,\n>\n> This is a good observation.\n>\n> Before, I'd already considered the rationale, for why channels have a\n> single 2-of-2 UTXO as funding output.  And it seems I should have\n> considered this, prior to accepting the \"parallel\" construction as feasible.\n>\n> For sake of posterity, I leave the below writeup as a tangential to the\n> design of splice (and to the design of Lightning having a single 2-of-2\n> UTXOs):\n>\n> # 0-conf is Unsafe, Yet Lightning is Safe; Why?\n>\n> To accept a 0-conf transaction output, is known to be unsafe.\n> Replace-by-fee is always a possibility, regardless of whether the\n> transaction opts in to RBF or not: a rational miner will always accept the\n> higher feerate, disregarding any \"opt-in\" flag that is set or not set on\n> the transaction.  Thus we reject any advice that claims that 0-conf is\n> tenable, even for tiny amounts.\n>\n> Yet when viewed solely in terms of transactions, Lightning protocol uses\n> transactions that are not on any block (are kept offchain).  Since they are\n> not in a block, they are indistinguishable from 0-conf transactions, which\n> are accepted by the receiver, yet are also not on any block.  One might\n> argue the distinction, that a \"real\" 0-conf transaction exists on some\n> mempool somewhere, and thus has a chance to be on a block in the future,\n> but mempools have no consensus, and the existence of a transaction on some\n> mempool is not a safe assurance of it existing in the mempool of the next\n> winning miner.\n>\n> So why is Lightning safe, when 0-conf transactions are in general not safe?\n>\n> Again, we should focus on why 0-conf transactions in general are not safe:\n> transaction replacement.  Thus, 0-conf transactions can be made safe, if\n> you are somehow able to ensure that replacement transactions cannot be made.\n>\n> For example, if you are part of an n-of-n federation that signs the\n> transaction, you can always safely accept a 0-conf transaction from that\n> federation paying only to you, because you can always veto any replacement\n> (by simply refusing to sign) that is not in your interests.\n>\n> This is in fact how Lightning works: a 2-of-2 federation (the channel\n> counterparties) are the signatories of the 0-conf transactions that are the\n> commitment transactions of the Lightning protocol.  Replacement of the\n> commitment transactions is strictly guided by the protocol; both sides have\n> veto rights, since the source transaction output is 2-of-2.\n>\n> Thus, Lightning, though it uses 0-conf transactions, is safe, because it\n> prevents the replacement of a 0-conf transaction without the receiver\n> allowing it, by the simple expedient of including the receiver in the\n> 2-of-2 multisig guarding its single funding TXO.\n>\n> ##  The Implications for Splice Proposals\n>\n> Some splice proposals involve creating the equivalent of multiple funding\n> TXOs for a single channel.  Such constructions are unsafe-by-default on\n> Poon-Dryja.\n>\n> In reality, every commitment transaction (or update transaction in\n> Decker-Osuntokun-Russell) is replaceable by any other commitment (or\n> update) transaction for that channel.  Under Poon-Dryja older transactions\n> are revoked (and hence one side risks loss of their collateral) while under\n> Decker-Osuntokun-Russell older transactions may be \"gainsaid\" (i.e. newer\n> update transactions may be reanchored to consume the TXO of the older\n> update transaction, thus preventing that update from truly being committed\n> to).\n>\n> This is relevant since before a splice, the channel has a single funding\n> TXO, while after the splice, the channel has multiple.\n>\n> In particular, a commitment (or update) transaction, that has multiple\n> inputs (to consume the multiple funding TXOs), can be replaced with a\n> commitment (or update) transaction that was created before the splice.\n> Under Poon-Dryja, such a commitment transaction may be revoked, but this\n> leaves the other funding TXOs unuseable.  Under Decker-Osuntokun-Russell,\n> as long as the sequence number is preserved across the splice, it is\n> possible for a later update transaction with multiple inputs to simply\n> gainsay the old single-input update with the new multiple-input update\n> transaction. (I suppose, that this is another advantage that\n> Decker-Osuntokun-Russell has).\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> Sent with ProtonMail <https://protonmail.com> Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Wednesday, October 17, 2018 9:09 AM, lisa neigut <niftynei at gmail.com>\n> wrote:\n>\n> To add some context to this, if you start accepting HTLC's for the new\n> balance after the parallel commitment is made, but before the re-anchor is\n> buried, there's the potential for a race condition between a unilateral\n> close (or any revoked commitment transaction) and the re-anchoring\n> commitment transaction, that spends the 'pre-committed' UTXO of splicing in\n> funds and the original funding transaction.\n>\n> You can get around this by waiting until both the pre-commitment UTXO and\n> the re-anchor have cleared a minimum depth before accepting HTLC's for the\n> new balance totals, but that's twice as long of a wait as the first,\n> synchronized re-commitment scheme that Rusty originally proposed.\n>\n> It also makes leaving the original funding transaction 'exposed' (ie\n> Rene's version of parallel splice) untenable, as there's always the risk of\n> an old state being published to consume that input. This foobars your\n> current HTLC commitments.\n>\n> On Tue, Oct 16, 2018 at 3:31 PM Rusty Russell <rusty at rustcorp.com.au>\n> wrote:\n>\n>> Rusty Russell <rusty at rustcorp.com.au> writes:\n>> > If we're going to do side splice-in like this, I would use a very\n>> > different protocol: the reason for this protocol was to treat splice-in\n>> > and splice-out the same, and inline splice-in requires wait time.  Since\n>> > splice-out doesn't, we don't need this at all.\n>> >\n>> > It would look much more like:\n>> >\n>> > 1. Prepare any output with script of specific form. eg:\n>> >         OP_DEPTH 3 OP_EQUAL OP_IF\n>> >                 <funding_pubkey1> <funding_pubkey2> OP_CHECKMULTISIG\n>> >         OP_ELSE\n>> >                 <blockheight> OP_CHECKLOCKTIMEVERIFY OP_DROP\n>> >                 <myrescue_pubkey> OP_CHECKSIG\n>> >         OP_ENDIF\n>> >\n>> > 1. type: 40 (`splice_in`) (`option_splice`)\n>> > 2. data:\n>> >    * [`32`:`channel_id`]\n>> >    * [`8`: `satoshis`]\n>> >    * [`32`: `txid`]\n>> >    * [`4`: `txoutnum`]\n>> >    * [`4`: `blockheight`]\n>> >    * [`33`: `myrescue_pubkey`]\n>> >\n>> > 1. type: 137 (`update_splice_in_accept`) (`option_splice`)\n>> >    data:\n>> >    * [`32`:`channel_id`]\n>> >    * [`32`: `txid`]\n>> >    * [`4`: `txoutnum`]\n>> >\n>> > 1. type: 138 (`update_splice_in_reject`) (`option_splice`)\n>> >    data:\n>> >    * [`32`:`channel_id`]\n>> >    * [`32`: `txid`]\n>> >    * [`2`:`len`]\n>> >    * [`len`:`errorstr`]\n>> >\n>> > The recipient of `splice_in` checks that it's happy with the\n>> > `blockheight` (far enough in future).  Once it sees the tx referred to\n>> > buried to its own `minimum_depth`, it checks output is what they\n>> > claimed, then sends `update_splice_in_accept`; it's followed up\n>> > `commitment_signed` like normal, but from this point onwards, all\n>> > commitment txs signatures have one extra sig.\n>>\n>> Lisa started asking pointed questions, and so I noticed that parallel\n>> splice doesn't work with Poon-Dryja channels.\n>>\n>> The counterparty can spend the old funding txout with a revoked spend.\n>> Sure, I can take all the money from that, but what about the spliced\n>> input?\n>>\n>> I came up with increasingly elaborate workarounds, but nothing stuck.\n>>\n>> Back to Plan A...\n>> Rusty.\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181018/d57ce11c/attachment-0001.html>"
            },
            {
                "author": "Conner Fromknecht",
                "date": "2018-10-23T05:16:13",
                "message_text_only": "Good evening lightning-dev,\n\n> If we receive later receive two `channel_update`s whose\n`short_channel_id`s\n> reference the spending transaction (and the node pubkeys are the same), we\n> assume the splice was successful and that this channel has been subsumed.\nI\n> think this works so long as the spending transaction doesn't contain\nmultiple\n> funding outputs, though I think the current proposal is fallible to this\nas\n> well.\n\nThought about this some more. The main difference seems to be whether the\ngossiped data is forward or backward looking. By forward looking, I mean\nthat we\ngossip where the splice will move to, and backward looking gossips where the\nsplice moved from.\n\nIf we want to make the original proposal work w/ multiple funding outputs on\none splice, I think it can be accomplished by sending the funding outpoint\nas\nopposed to just the txid. For the backward looking proposal, the\n`channel_update`\ncould be modified to include the `short_channel_id` of the prior funding\noutput.\nIMO we probably want to include the extra specificity even if we don't plan\nto\nhave multiple funding outputs on a commitment implemented tomorrow, since\noutputs are what we truly care about.\n\nOf the two, it still seems like the backward looking approach results in\nless\ngossiped data since are able to reference a single confirmed output by\nlocation\n(8 bytes), instead of N unconfirmed outputs by outpoint (N*34 bytes).\n\nAnother advantage I see with the backward looking splice announcments is\nthat\nthey can be properly verified before forwarding to the network by examining\nthe\nchannel lineage. In contrast, one can't be sure if the outpoint in a\nforward looking\nannouncement will ever confirm, or even if it spends from the original\nchannel point\nunless one also has the transaction. Until a splice does confirm, a node has\nto store multiple potential splice outpoints. Seeing this, it seems to me\nthat\nbackward looking announcements are less susceptible to abuse and DOS in\nthis regard.\n\nThoughts?\n\nCheers,\nConner\n\nOn Thu, Oct 18, 2018 at 8:04 PM Conner Fromknecht\n<conner at lightning.engineering> wrote:\n\n> Good evening all,\n>\n> Thank you Rusty for starting us down this path :) and to ZmnSCPxj and Lisa\n> for\n> your thoughts. I think this narrows down the design space considerably!\n>\n> In light of this, and if I'm following along, it seems our hand is forced\n> in\n> splicing via a single on-chain transaction. In my book, this is preferable\n> anyway. I'd much rather push complexity off-chain than having to do a\n> mutli-stage splicing pipeline.\n>\n> > To add some context to this, if you start accepting HTLC's for the new\n> balance\n> > after the parallel commitment is made, but before the re-anchor is\n> buried,\n> > there's the potential for a race condition between a unilateral close\n> (or any\n> > revoked commitment transaction) and the re-anchoring commitment\n> transaction,\n> > that spends the 'pre-committed' UTXO of splicing in funds and the\n> original\n> > funding transaction\n>\n> Indeed, I'm not aware of any splicing mechanism that enables off-chain use\n> of\n> spliced-in funds before the new funding output confirms. Even in the async,\n> single-txn case, the new funds cannot be spent until the new funding output\n> confirms sufficiently.\n>\n> From my POV, the desired properties of a splice are:\n>  1. non-blocking (asynchronous) usage of the channel\n>  2. single on-chain txn\n>  3. ability to RBF (have multiple pending splices)\n>\n> Of these, it seems we've solidified 1 and 2. I understand the desire to not\n> tackle RBF on the first attempt given the additional complexity.  However,\n> I\n> do believe there are ways we can proceed in which our first attempt largely\n> coincides with supporting it in the future.\n>\n> With that in mind, here are some thoughts on the proposals above.\n>\n> ## RBF and Multiple Splices\n>\n> > 1. type: 132 (`commitment_signed`)\n> > 2. data:\n> >    * [`32`:`channel_id`]\n> >    * [`64`:`signature`]\n> >    * [`2`:`num_htlcs`]\n> >    * [`num_htlcs*64`:`htlc_signature`]\n> >    * [`num_htlcs*64`:`htlc_splice_signature`] (`option_splice`)\n>\n> This will overflow the maximum message size of 65535 bytes for num_htlcs >\n> 511.\n>\n> I would propose sending a distinct message, which references the\n> `active_channel_id` and a `splice_channel_id` for the pending splice:\n>\n> 1. type: XXX (`commitment_splice_signed`) (`option_splice`)\n> 2. data:\n>    * [`32`:`active_channel_id`]\n>    * [`32`:`splice_channel_id`]\n>    * [`64`:`signature`]\n>    * [`2`:`num_htlcs`]\n>    * [`num_htlcs*64`:`htlc_signature`]\n>\n> This more directly addresses handling multiple pending splices, as well as\n> preventing us from running into any size constraints. The purpose of\n> including the `active_channel_id` would be to remote node locate the\n> spliced channel, since it may not be populated indexes containing\n> active channels. If we don't want to include this, the existing message\n> can be used without modification.\n>\n> > We shouldn't allow more than one pending splice operation anyway, as\n> > stated in your proposal initially. We are already critically reliant on\n> our\n> > transaction being confirmed on-chain, so I don't see this as much of an\n> > added issue.\n>\n> IMO there's no reason to limit ourselves to one pending splice at the\n> message\n> level. I think it'd be an oversight to not to plan ahead with RBF in mind,\n> given that funding transactions have gone unconfirmed precisely because of\n> improperly chosen fee rates. Arguably, funding flow should be extended to\n> support this as well.\n>\n> CPFP works, though it's more wasteful than resigning and I'd prefer only\n> to do\n> so out of necessity, rather than relying on it. CPFP is nice because it\n> doesn't\n> require interaction, though we are already assuming the other party to be\n> online during the splice (unlike unilateral closes).\n>\n> Adding a splice-reject message/error code should be sufficient to allow\n> implementations to signal that their local tolerance for number of pending\n> splices has been reached. It's likely we'd all start with getting one\n> splice\n> working, but then the messages won't need to modified if we want to\n> implement\n> additional pending splices via RBF.\n>\n> A node that wants to RBF but receives a reject can then proceed with CPFP\n> as a\n> last resort.\n>\n> Are there any downsides I'm overlooking with this approach?\n>\n> > | Bit Position  | Name                      | Field\n>       |\n> > | ------------- | ------------------------- |\n> -------------------------------- |\n> > | 0             | `option_channel_htlc_max` | `htlc_maximum_msat`\n>       |\n> > | 1             | `option_channel_moving`   | `moving_txid\n>        |\n> >\n> > The `channel_update` gains the following field:\n> >     * [`32`: moving_txid`] (option_channel_moving)\n>\n> Do we actually need to send the `moving_txid` via a channel update? I\n> think it's\n> enough for both parties to send `channel_update`s with the\n> `option_channel_moving` bit set, and continue to keep the channel in our\n> routing\n> table.\n>\n> If we receive later receive two `channel_update`s whose `short_channel_id`s\n> reference the spending transaction (and the node pubkeys are the same), we\n> assume the splice was successful and that this channel has been subsumed. I\n> think this works so long as the spending transaction doesn't contain\n> multiple\n> funding outputs, though I think the current proposal is fallible to this as\n> well.\n>\n> To me, this proposal has the benefit of not bloating gossip bandwidth with\n> an\n> extra field that would need to parsed indefinitely, and gracefully\n> supporting\n> RBF down the road. Otherwise we'd need to gossip and store each potential\n> txid.\n>\n> With regards to forwarding, both `short_channel_id`s would be accepted by\n> the\n> splicers for up to 100 blocks (after splice confirm?), at which point they\n> can\n> both forget the prior `short_channel_id`.\n>\n> ## Shachain\n>\n> > I thought about restarting the revocation sequence, but it seems like\n> > that only saves a tiny amount since we only store log(N) entries.  We\n> > can drop old HTLC info post-splice though, and (after some delay for\n> > obscurity) tell watchtowers to drop old entries I think.\n>\n> I agree the additional state isn't too burdensome, and that we would still\n> be\n> able to drop watchtower state after some delay as you mentioned.\n>\n> On one hand, it does seem like the opportune time to remove such state if\n> desired.\n>\n> OTOH, it is _really_ nice from an atomicity perspective that the current\n> channel and (potentially) N pending channels can be revoked using a single\n> commitment secret and message. Doing so would mean we don't have to\n> modify the `revoke_and_ack` or `channel_reestablish` messages. The receiver\n> would just apply the commitment secrets/points to the current channel and\n> any\n> pending splices.\n>\n> ## Misc\n>\n> > Any reason to now make the splicing_add_* messages allow one to add\n> several\n> > inputs in a single message? Given \"acceptable\" constraints for how large\n> the\n> > witness and pkScripts can be, we can easily enforce an upper limit on the\n> > number of inputs/outputs to add.\n>\n> Yes, I prefer this simplification.\n>\n> > Additionally, as the size of the channel is either expanding or\n> contracting,\n> > both sides should be allowed to modify things like the CSV param,\n> reserve,\n> > max accepted htlc's, max htlc size, etc. Many of these parameters like\n> the\n> > CSV value should scale with the size of the channel, not allowing these\n> > parameters to be re-negotiated could result in odd scenarios like still\n> > maintain a 1 week CSV when the channel size has dipped from 1 BTC to 100k\n> > satoshis.\n>\n> Agreed!\n>\n> > These all seem marginal to me.  I think if we start hitting max values,\n> > we should discuss increasing them.\n>\n> Doesn't this defeat the goal of firewalling funds against individual\n> channel\n> failures?\n>\n> >>> One thing that I think we should lift from the multiple funding output\n> >>> approach is the \"pre seating of inputs\". This is cool as it would allow\n> >>> clients to generate addresses, that others could deposit to, and then\n> have\n> >>> be spliced directly into the channel. Public derivation can be used,\n> along\n> >>> with a script template to do it non-interactively, with the clients\n> picking\n> >>> up these deposits, and initiating a splice in as needed.\n> >>\n> >> How about this restatement?\n> >>\n> >> 1.  Each channel has two public-key-derivation paths (BIP32) to create\n> onchain\n> >> addresses.  One for each side of the channel.\n> >> 2.  The base of the above is actually a combined private-public keypair\n> of both\n> >> sides (e.g. created via MuSig or some other protocol).  Thus the\n> addresses\n> >> require cooperation of both parties to spend.\n> >> 3.  When somebody sends to one of the onchain addresses in the path,\n> their\n> >> client detects this.\n> >> 4.  The client updates the current transaction state, such that the new\n> commit\n> >> transaction has two inputs ( the original channel transaction and the\n> new UTXO).\n> >>\n> >> The above seems unsafe without trust in the other peer, as, the other\n> peer can\n> >> simply refuse to create the new commit transaction.  Since the address\n> requires\n> >> both parties to spend, the money cannot be spent and there is no backoff\n> >> transaction that can be used.  But maybe you can describe some\n> mechanism to\n> >> ensure this, if this is what is meant instead?\n> >\n> > This could easily be solved by making the destination address a Taproot\n> > address, which by default is just a 2-of-2, but in the uncooperative\n> > case it can reveal the script it commits to, which is just a timelocked\n> > refund that requires a single-sig. The only problem with this is that\n> > the refund would be non-interactive, and so the entirety of the funds,\n> > that may be from a third-party, need to be claimed by one endpoint,\n> > i.e., there is no splitting the funds in case of an uncollaborative\n> > refund. Not sure how important that is though, since I don't think\n> > third-party funds will come from unrelated parties, e.g., most of these\n> > funds will come from an on-chain wallet that is under the control of\n> > either parties so the refund should go back to that party anyway.\n>\n> This can be accomplished similarly by having either (or both) party\n> publishing a\n> static address or publicly derivable address specific to the channel,\n> derived\n> from their HD seed.\n>\n> Arguably, the address should perhaps be global, so that it can outlive the\n> lifetime of the channel, i.e. as soon as the first person deposits and a\n> splice\n> is initiated, is the address still valid for the new channel if new keys\n> are\n> used? Similarly, the channel could be closed and the funds locked until\n> the timeout if the peer disappears.\n>\n> Regardless, both approaches can be made to have equivalent amounts of\n> [non-]interactivity. However, the recipient isn't burdened in spending by\n> 1) interaction with the channel peer, or 2) an absolute timeout if 1 fails,\n> giving the receiver more flexibility if they wish to not commit the\n> received\n> funds to a splice. It also benefits from smaller witness sizes, a larger\n> anonymity set, etc.\n>\n> In general, using a 2-of-2+timeout to stage funds for splicing doesn't\n> offer\n> that much IMO. It seems the primary purpose is to prevent the funds from\n> being\n> double spent during the splice, but observe that this is still possible if\n> the\n> timeout matures, perhaps because the splice doesn't confirm in a timely\n> manner.\n>\n> Acknowledging this, detecting double-spent inputs is still required for\n> full\n> correctness. By implementing it, either party is free to propose arbitrary\n> inputs for a splice, which I believe reduces complexity in the long run.\n>\n> Splice out,\n> Conner\n>\n> On Tue, Oct 16, 2018 at 10:00 PM ZmnSCPxj via Lightning-dev <\n> lightning-dev at lists.linuxfoundation.org> wrote:\n>\n>> Good morning lisa,\n>>\n>> This is a good observation.\n>>\n>> Before, I'd already considered the rationale, for why channels have a\n>> single 2-of-2 UTXO as funding output.  And it seems I should have\n>> considered this, prior to accepting the \"parallel\" construction as feasible.\n>>\n>> For sake of posterity, I leave the below writeup as a tangential to the\n>> design of splice (and to the design of Lightning having a single 2-of-2\n>> UTXOs):\n>>\n>> # 0-conf is Unsafe, Yet Lightning is Safe; Why?\n>>\n>> To accept a 0-conf transaction output, is known to be unsafe.\n>> Replace-by-fee is always a possibility, regardless of whether the\n>> transaction opts in to RBF or not: a rational miner will always accept the\n>> higher feerate, disregarding any \"opt-in\" flag that is set or not set on\n>> the transaction.  Thus we reject any advice that claims that 0-conf is\n>> tenable, even for tiny amounts.\n>>\n>> Yet when viewed solely in terms of transactions, Lightning protocol uses\n>> transactions that are not on any block (are kept offchain).  Since they are\n>> not in a block, they are indistinguishable from 0-conf transactions, which\n>> are accepted by the receiver, yet are also not on any block.  One might\n>> argue the distinction, that a \"real\" 0-conf transaction exists on some\n>> mempool somewhere, and thus has a chance to be on a block in the future,\n>> but mempools have no consensus, and the existence of a transaction on some\n>> mempool is not a safe assurance of it existing in the mempool of the next\n>> winning miner.\n>>\n>> So why is Lightning safe, when 0-conf transactions are in general not\n>> safe?\n>>\n>> Again, we should focus on why 0-conf transactions in general are not\n>> safe: transaction replacement.  Thus, 0-conf transactions can be made safe,\n>> if you are somehow able to ensure that replacement transactions cannot be\n>> made.\n>>\n>> For example, if you are part of an n-of-n federation that signs the\n>> transaction, you can always safely accept a 0-conf transaction from that\n>> federation paying only to you, because you can always veto any replacement\n>> (by simply refusing to sign) that is not in your interests.\n>>\n>> This is in fact how Lightning works: a 2-of-2 federation (the channel\n>> counterparties) are the signatories of the 0-conf transactions that are the\n>> commitment transactions of the Lightning protocol.  Replacement of the\n>> commitment transactions is strictly guided by the protocol; both sides have\n>> veto rights, since the source transaction output is 2-of-2.\n>>\n>> Thus, Lightning, though it uses 0-conf transactions, is safe, because it\n>> prevents the replacement of a 0-conf transaction without the receiver\n>> allowing it, by the simple expedient of including the receiver in the\n>> 2-of-2 multisig guarding its single funding TXO.\n>>\n>> ##  The Implications for Splice Proposals\n>>\n>> Some splice proposals involve creating the equivalent of multiple funding\n>> TXOs for a single channel.  Such constructions are unsafe-by-default on\n>> Poon-Dryja.\n>>\n>> In reality, every commitment transaction (or update transaction in\n>> Decker-Osuntokun-Russell) is replaceable by any other commitment (or\n>> update) transaction for that channel.  Under Poon-Dryja older transactions\n>> are revoked (and hence one side risks loss of their collateral) while under\n>> Decker-Osuntokun-Russell older transactions may be \"gainsaid\" (i.e. newer\n>> update transactions may be reanchored to consume the TXO of the older\n>> update transaction, thus preventing that update from truly being committed\n>> to).\n>>\n>> This is relevant since before a splice, the channel has a single funding\n>> TXO, while after the splice, the channel has multiple.\n>>\n>> In particular, a commitment (or update) transaction, that has multiple\n>> inputs (to consume the multiple funding TXOs), can be replaced with a\n>> commitment (or update) transaction that was created before the splice.\n>> Under Poon-Dryja, such a commitment transaction may be revoked, but this\n>> leaves the other funding TXOs unuseable.  Under Decker-Osuntokun-Russell,\n>> as long as the sequence number is preserved across the splice, it is\n>> possible for a later update transaction with multiple inputs to simply\n>> gainsay the old single-input update with the new multiple-input update\n>> transaction. (I suppose, that this is another advantage that\n>> Decker-Osuntokun-Russell has).\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>>\n>> Sent with ProtonMail <https://protonmail.com> Secure Email.\n>>\n>> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>> On Wednesday, October 17, 2018 9:09 AM, lisa neigut <niftynei at gmail.com>\n>> wrote:\n>>\n>> To add some context to this, if you start accepting HTLC's for the new\n>> balance after the parallel commitment is made, but before the re-anchor is\n>> buried, there's the potential for a race condition between a unilateral\n>> close (or any revoked commitment transaction) and the re-anchoring\n>> commitment transaction, that spends the 'pre-committed' UTXO of splicing in\n>> funds and the original funding transaction.\n>>\n>> You can get around this by waiting until both the pre-commitment UTXO and\n>> the re-anchor have cleared a minimum depth before accepting HTLC's for the\n>> new balance totals, but that's twice as long of a wait as the first,\n>> synchronized re-commitment scheme that Rusty originally proposed.\n>>\n>> It also makes leaving the original funding transaction 'exposed' (ie\n>> Rene's version of parallel splice) untenable, as there's always the risk of\n>> an old state being published to consume that input. This foobars your\n>> current HTLC commitments.\n>>\n>> On Tue, Oct 16, 2018 at 3:31 PM Rusty Russell <rusty at rustcorp.com.au>\n>> wrote:\n>>\n>>> Rusty Russell <rusty at rustcorp.com.au> writes:\n>>> > If we're going to do side splice-in like this, I would use a very\n>>> > different protocol: the reason for this protocol was to treat splice-in\n>>> > and splice-out the same, and inline splice-in requires wait time.\n>>> Since\n>>> > splice-out doesn't, we don't need this at all.\n>>> >\n>>> > It would look much more like:\n>>> >\n>>> > 1. Prepare any output with script of specific form. eg:\n>>> >         OP_DEPTH 3 OP_EQUAL OP_IF\n>>> >                 <funding_pubkey1> <funding_pubkey2> OP_CHECKMULTISIG\n>>> >         OP_ELSE\n>>> >                 <blockheight> OP_CHECKLOCKTIMEVERIFY OP_DROP\n>>> >                 <myrescue_pubkey> OP_CHECKSIG\n>>> >         OP_ENDIF\n>>> >\n>>> > 1. type: 40 (`splice_in`) (`option_splice`)\n>>> > 2. data:\n>>> >    * [`32`:`channel_id`]\n>>> >    * [`8`: `satoshis`]\n>>> >    * [`32`: `txid`]\n>>> >    * [`4`: `txoutnum`]\n>>> >    * [`4`: `blockheight`]\n>>> >    * [`33`: `myrescue_pubkey`]\n>>> >\n>>> > 1. type: 137 (`update_splice_in_accept`) (`option_splice`)\n>>> >    data:\n>>> >    * [`32`:`channel_id`]\n>>> >    * [`32`: `txid`]\n>>> >    * [`4`: `txoutnum`]\n>>> >\n>>> > 1. type: 138 (`update_splice_in_reject`) (`option_splice`)\n>>> >    data:\n>>> >    * [`32`:`channel_id`]\n>>> >    * [`32`: `txid`]\n>>> >    * [`2`:`len`]\n>>> >    * [`len`:`errorstr`]\n>>> >\n>>> > The recipient of `splice_in` checks that it's happy with the\n>>> > `blockheight` (far enough in future).  Once it sees the tx referred to\n>>> > buried to its own `minimum_depth`, it checks output is what they\n>>> > claimed, then sends `update_splice_in_accept`; it's followed up\n>>> > `commitment_signed` like normal, but from this point onwards, all\n>>> > commitment txs signatures have one extra sig.\n>>>\n>>> Lisa started asking pointed questions, and so I noticed that parallel\n>>> splice doesn't work with Poon-Dryja channels.\n>>>\n>>> The counterparty can spend the old funding txout with a revoked spend.\n>>> Sure, I can take all the money from that, but what about the spliced\n>>> input?\n>>>\n>>> I came up with increasingly elaborate workarounds, but nothing stuck.\n>>>\n>>> Back to Plan A...\n>>> Rusty.\n>>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181022/337246c7/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-10-24T06:36:52",
                "message_text_only": "Conner Fromknecht <conner at lightning.engineering> writes:\n> In light of this, and if I'm following along, it seems our hand is forced in\n> splicing via a single on-chain transaction. In my book, this is preferable\n> anyway. I'd much rather push complexity off-chain than having to do a\n> mutli-stage splicing pipeline.\n\nAgreed.  As Christian pointed out, at least our design space is reduced now?\n\n> I would propose sending a distinct message, which references the\n> `active_channel_id` and a `splice_channel_id` for the pending splice:\n>\n> 1. type: XXX (`commitment_splice_signed`) (`option_splice`)\n> 2. data:\n>    * [`32`:`active_channel_id`]\n>    * [`32`:`splice_channel_id`]\n>    * [`64`:`signature`]\n>    * [`2`:`num_htlcs`]\n>    * [`num_htlcs*64`:`htlc_signature`]\n>\n> This more directly addresses handling multiple pending splices, as well as\n> preventing us from running into any size constraints. The purpose of\n> including the `active_channel_id` would be to remote node locate the\n> spliced channel, since it may not be populated indexes containing\n> active channels. If we don't want to include this, the existing message\n> can be used without modification.\n\nYes, I like this!  I don't think the `splice_channel_id` helps us much,\nsince we need to wait we receive all pending commitement_splice_signed\nbefore sending revoke_and_ack, and I think we should simply insist they\nbe in splice order which makes implementation easier (simple counter).\n\n>> We shouldn't allow more than one pending splice operation anyway, as\n>> stated in your proposal initially. We are already critically reliant on\n> our\n>> transaction being confirmed on-chain, so I don't see this as much of an\n>> added issue.\n>\n> IMO there's no reason to limit ourselves to one pending splice at the\n> message\n> level. I think it'd be an oversight to not to plan ahead with RBF in mind,\n> given that funding transactions have gone unconfirmed precisely because of\n> improperly chosen fee rates. Arguably, funding flow should be extended to\n> support this as well.\n\nGood reminder re: RBF and funding.  I've put this on the brainstorming\nlist with your name next to it ;)\n\n> Adding a splice-reject message/error code should be sufficient to allow\n> implementations to signal that their local tolerance for number of pending\n> splices has been reached. It's likely we'd all start with getting one splice\n> working, but then the messages won't need to modified if we want to\n> implement\n> additional pending splices via RBF.\n>\n> A node that wants to RBF but receives a reject can then proceed with CPFP\n> as a\n> last resort.\n>\n> Are there any downsides I'm overlooking with this approach?\n\nNo, I think you've covered it.\n\n>> | Bit Position  | Name                      | Field\n>       |\n>> | ------------- | ------------------------- |\n> -------------------------------- |\n>> | 0             | `option_channel_htlc_max` | `htlc_maximum_msat`\n>       |\n>> | 1             | `option_channel_moving`   | `moving_txid\n>      |\n>>\n>> The `channel_update` gains the following field:\n>>     * [`32`: moving_txid`] (option_channel_moving)\n>\n> Do we actually need to send the `moving_txid` via a channel update? I think\n> it's\n> enough for both parties to send `channel_update`s with the\n> `option_channel_moving` bit set, and continue to keep the channel in our\n> routing\n> table.\n\nIt helps because they can't broadcast the new channel for 6 confirms.\nOTOH, that's probably not too long to wait.\n\n> If we receive later receive two `channel_update`s whose `short_channel_id`s\n> reference the spending transaction (and the node pubkeys are the same), we\n> assume the splice was successful and that this channel has been\n> subsumed.\n\nSo rule would be: if we've seen both channel_updates with\noption_channel_moving set, we remember the txid which closed it, and\nstart a 100-block countdown the \"real close\".  If we\na (valid) channel_announce for that closing tx with same node pubkeys,\nwe simply delete the 100-block countdown.\n\n> I\n> think this works so long as the spending transaction doesn't contain\n> multiple\n> funding outputs, though I think the current proposal is fallible to this as\n> well.\n\nI think variant above works even in that case?\n\n> To me, this proposal has the benefit of not bloating gossip bandwidth with\n> an\n> extra field that would need to parsed indefinitely, and gracefully\n> supporting\n> RBF down the road. Otherwise we'd need to gossip and store each potential\n> txid.\n>\n> With regards to forwarding, both `short_channel_id`s would be accepted by\n> the\n> splicers for up to 100 blocks (after splice confirm?), at which point they\n> can\n> both forget the prior `short_channel_id`.\n\nTechnically, the need to remember for some grace period after they\nannounce the block.  We have a similar recommendation for old fee\nvalues, though it's soft.  100 seems overkill.\n\nI think we can assume gossip will propagate widely within 6 blocks and\nsay they should accept it at least up to 6 blocks after announcing?  Or\n1 hour, though I prefer using the blockchain as a clock in general.\n\n> ## Shachain\n>\n>> I thought about restarting the revocation sequence, but it seems like\n>> that only saves a tiny amount since we only store log(N) entries.  We\n>> can drop old HTLC info post-splice though, and (after some delay for\n>> obscurity) tell watchtowers to drop old entries I think.\n>\n> I agree the additional state isn't too burdensome, and that we would still\n> be\n> able to drop watchtower state after some delay as you mentioned.\n>\n> On one hand, it does seem like the opportune time to remove such state if\n> desired.\n>\n> OTOH, it is _really_ nice from an atomicity perspective that the current\n> channel and (potentially) N pending channels can be revoked using a single\n> commitment secret and message. Doing so would mean we don't have to\n> modify the `revoke_and_ack` or `channel_reestablish` messages. The receiver\n> would just apply the commitment secrets/points to the current channel and\n> any\n> pending splices.\n\nAgreed; on balance, it's fine to avoid reset.\n\n> ## Misc\n>\n>> Any reason to now make the splicing_add_* messages allow one to add\n> several\n>> inputs in a single message? Given \"acceptable\" constraints for how large\n> the\n>> witness and pkScripts can be, we can easily enforce an upper limit on the\n>> number of inputs/outputs to add.\n>\n> Yes, I prefer this simplification.\n\nJust harder to write the spec that way :) I'll come up with something.\n\n>> Additionally, as the size of the channel is either expanding or\n> contracting,\n>> both sides should be allowed to modify things like the CSV param, reserve,\n>> max accepted htlc's, max htlc size, etc. Many of these parameters like the\n>> CSV value should scale with the size of the channel, not allowing these\n>> parameters to be re-negotiated could result in odd scenarios like still\n>> maintain a 1 week CSV when the channel size has dipped from 1 BTC to 100k\n>> satoshis.\n>\n> Agreed!\n\n\"CSV should scale with value\" seems like voodoo, though.  It make us\nfeel better that we're being conservative with large amounts of money,\nbut it makes no sense from a time-value-of-money perspective.  Sure,\nbigger amounts are more important, but it's also more painful to have\nthem locked up.\n\nI'd really like most of these parameters to go away, rather than\nintroducing YA negotiation pain point.  See other post.\n\n>> These all seem marginal to me.  I think if we start hitting max values,\n>> we should discuss increasing them.\n>\n> Doesn't this defeat the goal of firewalling funds against individual channel\n> failures?\n\nThat's kind of true, but you should be more concerned about node\nfailure, and thus diversify your channels between different nodes.\nThat's better for everyone.\n\n> Splice out,\n> Conner\n\nNice touch :)\n\nCheers,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-10-19T02:40:10",
                "message_text_only": "Hi Rusty et al,\n\nWould this work?\n\nGlossary\n--------\n\nOld funding output - the TXO that the channel uses pre-splice.  This must be a SegWit 2-of-2.\n\nNew funding output - the TXO that the channel will use post-splice.  This must be a SegWit 2-of-2.\n\nOld commitment transaction - a Poon-Dryja-revocable commitment transaction that consumes the old funding output.\n\nNew commitment transaction - a Poon-Dryja-revocable commitment transaction that consumes the new funding output.\n\nSpliced input - a TXO wholly controlled solely by one channel party, which is intended for splicing into the channel.  This must be SegWit.\n\nSplicing transaction - a transaction that consumes the old funding output and one or more spliced inputs, and outputs the new funding output.\n\noldfunding --> [splicing]--> newfunding\n                 /\\\n                 ||\n    splicedin  ==++\n\nSplice Preparation Protocol\n---------------------------\n\n1.  Both sides provide a list of spliced inputs.  They confirm that the transactions are either confirmed or on their mempool.\n2.  Both sides maintain a separate pair of division of their money.  One pair is the amount of money that can be currently used during the splice, and is initialized to the current state of the channel (money-during-splice).  The other pair is the amount of money each has that will be added after the splice is confirmed (money-added-to-splice).\n3.  Both sides generate (but do not provide signatures or broadcast) the splicing transaction.\n4.  Both sides sign the new commitment transaction of the opposing side (which spends the new funding transaction of the splicing transaction).\n5.  Both sides now sign the splicing transaction, providing signatures for their nominated spliced inputs, and broadcast the fully signed splicing transaction.\n\nOperation During Splice\n-----------------------\n\nWhile the splicing transaction is not sufficiently confirmed but is validly in their mempool or confirmed lightly, the channel is in \"currently splicing\" mode and changes to commitment transactions can be changed only according to these rules:\n\n1.  Both old commitment transactions and new commitment transactions are updated in parallel.\n2.  Each side can only use money that is theirs during the splice (money-during-splice) to offer HTLCs.  They cannot use spliced-in money yet to offer HTLCs.\n\nFailure Modes\n-------------\n\nIf the splicing transaction becomes invalidated from the mempool, and was not confirmed/included in the block, then the splice has failed.  Both sides should inform this splice failure to the other.\n\n1.  If any old commitment transaction was spent to invalidate the splice transaction, then the channel has closed and both sides drop to tracking the channel closure as unilateral close.\n2.  Otherwise, the splicing transaction became invalidated either due to a spend of any spliced input, or by invalidation of spliced input via transaction replacement (RBF).  In this case, the protocol moves to splice failure.\n\nSplice Failure\n--------------\n\n1.  One side notices the splice failure and claims that the splice has failed.\n2.  The other side monitors its own mempool for invalidation of the splicing transaction, with a timeout.\n3.  If the other side also notices the splice failure, then both sides can drop the (money-added-to-splice) and revert back to the pre-splice channel.  Spliced inputs should be considered by their owner to be spendable again for other onchain purposes.\n3.  Otherwise if the other side times out without seeing the splicing transaction getting invalidated, it will publish the latest old commitment transaction and the latest new commitment transaction and consider the channel as closing and tracking it as a unilateral close, checking for either the old funding output or the new funding output to be spent.\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Wednesday, October 17, 2018 6:30 AM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> Rusty Russell rusty at rustcorp.com.au writes:\n>\n> > If we're going to do side splice-in like this, I would use a very\n> > different protocol: the reason for this protocol was to treat splice-in\n> > and splice-out the same, and inline splice-in requires wait time. Since\n> > splice-out doesn't, we don't need this at all.\n> > It would look much more like:\n> >\n> > 1.  Prepare any output with script of specific form. eg:\n> >     OP_DEPTH 3 OP_EQUAL OP_IF\n> >     <funding_pubkey1> <funding_pubkey2> OP_CHECKMULTISIG\n> >     OP_ELSE\n> >     <blockheight> OP_CHECKLOCKTIMEVERIFY OP_DROP\n> >     <myrescue_pubkey> OP_CHECKSIG\n> >     OP_ENDIF\n> >\n> > 2.  type: 40 (`splice_in`) (`option_splice`)\n> >\n> > 3.  data:\n> >     -   [`32`:`channel_id`]\n> >     -   [`8`: `satoshis`]\n> >     -   [`32`: `txid`]\n> >     -   [`4`: `txoutnum`]\n> >     -   [`4`: `blockheight`]\n> >     -   [`33`: `myrescue_pubkey`]\n> > 4.  type: 137 (`update_splice_in_accept`) (`option_splice`)\n> >     data:\n> >     -   [`32`:`channel_id`]\n> >     -   [`32`: `txid`]\n> >     -   [`4`: `txoutnum`]\n> > 5.  type: 138 (`update_splice_in_reject`) (`option_splice`)\n> >     data:\n> >     -   [`32`:`channel_id`]\n> >     -   [`32`: `txid`]\n> >     -   [`2`:`len`]\n> >     -   [`len`:`errorstr`]\n> >\n> > The recipient of `splice_in` checks that it's happy with the\n> > `blockheight` (far enough in future). Once it sees the tx referred to\n> > buried to its own `minimum_depth`, it checks output is what they\n> > claimed, then sends `update_splice_in_accept`; it's followed up\n> > `commitment_signed` like normal, but from this point onwards, all\n> > commitment txs signatures have one extra sig.\n>\n> Lisa started asking pointed questions, and so I noticed that parallel\n> splice doesn't work with Poon-Dryja channels.\n>\n> The counterparty can spend the old funding txout with a revoked spend.\n> Sure, I can take all the money from that, but what about the spliced\n> input?\n>\n> I came up with increasingly elaborate workarounds, but nothing stuck.\n>\n> Back to Plan A...\n> Rusty.\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-10-11T04:39:28",
                "message_text_only": "Good morning Rusty,\n\nIn BOLT #2 we currently impose a 2^24 satoshi limit on total channel capacity.  Is splicing intended to allow violation of this limit? I do not see it mentioned in the proposal. Can I splice 21 million bitcoins on a 1-satoshi channel?\n\nIt may be good to start brainstorming possible failure modes during splice, and how to recover, and also to indicate the expected behavior in the proposal, as I believe these will be the points where splicing must be designed most precisely. What happens when a splice is ongoing and the communication gets disconnected?  What happens when some channel failure occurs during splicing and we are forced to drop onchain?  And so on.\n\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Wednesday, October 10, 2018 11:45 AM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> Hi all!\n>\n> We've had increasing numbers of c-lightning users get upset they\n> can't open multiple channels, so I guess we're most motivated to allow\n> splicing of existing channels. Hence this rough proposal.\n>\n> For simplicity, I've chosen to only allow a single splice at a time.\n> It's still complex :(\n>\n> Feedback welcome!\n>\n> --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> Splice Negotiation:\n>\n> 1.  type: 40 (`splice_add_input`) (`option_splice`)\n> 2.  data:\n>     -   [`32`:`channel_id`]\n>     -   [`8`: `satoshis`]\n>     -   [`32`: `prevtxid`]\n>     -   [`4`: `prevtxoutnum`]\n>     -   [`2`: `scriptlen`]\n>     -   [`scriptlen`: `scriptpubkey`]\n> 3.  type: 41 (`splice_add_output`) (`option_splice`)\n> 4.  data:\n>     -   [`32`:`channel_id`]\n>     -   [`8`: `satoshis`]\n>     -   [`2`: `scriptlen`]\n>     -   [`scriptlen`: `outscript`]\n> 5.  type: 42 (`splice_all_added`) (`option_splice`)\n> 6.  data:\n>     -   [`32`:`channel_id`]\n>     -   [`4`:`feerate_per_kw`]\n>     -   [`4`:`minimum_depth`]\n>\n>         Each side sends 0 or more `splice_add_input` and 0 or more\n>         `splice_add_output` followed by `spice_all_added` to complete the splice\n>         proposal. This is done either to initiate a splice, or to respond to a\n>         `splice_*` from the other party.\n>\n>         `splice_add_input` is checked for the following:\n>\n>\n> -   must not be during a current splice\n>\n> -   scriptpubkey is empty, or of form 'HASH160 <20-byte-script-hash> EQUAL'\n>\n> -   `satoshis` doesn't wrap on addition.\n>\n> -   MAY check that it matches outpoint specified (sig will simply be\n>     invalid if so), and that outpoint is segwit.\n>\n>     `splice_add_output` is checked for the following:\n>\n> -   must not be during a current splice\n>\n> -   `satoshis` is less than or equal to amount owing to proposer, minus\n>     current reserve, and greater than or equal to `dust_limit_satoshis` we\n>     sent in our open_channel/accept_channel ,sg.\n>\n> -   script is one of the approved forms as it is for `shutdown`.\n>\n>     FIXME: Do we disallow splice-out if they specified\n>     option_upfront_shutdown_script?\n>\n>     `splice_all_added` is checked for the following:\n>\n> -   average of `feerate_per_kw` by both sides (round down) is sufficient.\n>\n> -   average of `feerate_per_kw` by both sides not grossly excessive, if we're\n>     paying some of the fees (see below!)\n>\n> -   both sides can afford the fees from their post-splice funds (see\n>     Verification Changes below)\n>\n> -   maximum of the two `minimum_depth` is not grossly excessive.\n>\n> -   There is at least one splice_add_input or splice_add_output.\n>\n>     Splice negotiation, like closing negotiation, does not have persistent\n>     state. Reconnecting forgets previous negotiation.\n>\n>     Splice Signing\n>\n>\n> Once`splice_all_added` is both sent and received, we need to create and\n> sign both the splice tx itself, and the first commitment transaction\n> which spends it (but not in that order!).\n>\n> 1.  One input spends the current funding tx output.\n> 2.  There is one additional input for each splice_add_input.\n> 3.  One output creates the new funding tx.\n> 4.  There is one additional output for each splice_add_output.\n> 5.  The entire transaction is sorted into BIP69 order.\n> 6.  The feerate is the sum of the two `feerate_per_kw` divided by 2,\n>     rounded down.\n>\n> 7.  type: 43 (`splice_commitment_signature`) (`option_splice`)\n> 8.  data:\n>     -   [`32`:`channel_id`]\n>     -   [`64`:`commitment_signature`]\n>     -   [`2`:`num_htlcs`]\n>     -   [`num_htlcs*64`:`htlc_signature`]\n> 9.  type: 44 (`splice_signature`) (`option_splice`)\n> 10.  data:\n>     -   [`32`:`channel_id`]\n>     -   [`64`:`splice_signature`]\n> 11.  type: 45 (`splice_witness`) (`option_splice`)\n> 12.  data:\n>     -   [`32`:`channel_id`]\n>     -   [`2`: `num_witness_elements`\n>     -   [`2`:`len`]\n>     -   [`len`:`witnesses`]\n>\n>         `witnesses` itself is serialized as `num_witness_elements` of:\n>\n>\n> -   `2`:`len`\n> -   `len`: `witness_element`\n>\n>     Each side sends `splice_commitment_signature` and waits to receive and\n>     verify the other side's `splice_commitment_signature` before sending\n>     `splice_signature` and `splice_witness` for each `splice_add_input` it\n>     proposed, in BIP69 input order.\n>\n>     Once a node has sent `splice_commitment_signature` it should remember\n>     the splice proposal across reconnects. Once it has both sent\n>     `splice_signature`, the splice is locked in.\n>\n>     Splice Announcement\n>\n>\n> We have to tell the network about the new channel, otherwise there will\n> be a distruption when it sees the old funding transaction spent. This\n> is inevitable for older nodes who won't understand splicing anyway.\n>\n> We can't send out a `channel_announcement` or `channel_update` for the\n> new channel until after the new funding transaction has 6 confirmations,\n> so we append to the existing `channel_update` for the original channel,\n> using a new `message_flags` field:\n>\n> Bit Position\n>\n> Name\n>\n> Field\n>\n> 0\n>\n> `option_channel_htlc_max`\n>\n> `htlc_maximum_msat`\n>\n> 1\n>\n> `option_channel_moving`\n>\n> `moving_txid\n>\n> The`channel_update` gains the following field:\n> * [`32`: moving_txid`] (option_channel_moving) If a current`channel_update`for a closing channel contains`option_channel_moving`a node SHOULD ignore the channel close for at least 100 blocks iff spent by`moving_txid`. A node SHOULD immediately forward a`channel_update`it sees containing`option_channel_moving`if neither previous`channel_update`for the channel contains`option_channel_moving`.\n>\n> Each side of the splice can send these unilaterally, and SHOULD allow a\n> few minutes for propagation (remember, average propagation from old\n> nodes is still 30 seconds) prior to broadcast of the splice transaction.\n>\n> Message Changes During Splicing\n>\n> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> Once you've sent `splice_commitment_signature` each commitment\n> transaction is duplicated: one spends the old funding transaction, one\n> spends the splice transaction:\n>\n> 1.  type: 39 (`closing_signed`)\n> 2.  data:\n>     -   [`32`:`channel_id`]\n>     -   [`8`:`fee_satoshis`]\n>     -   [`64`:`signature`]\n>     -   [`64`:`splice_signature`] (`option_splice`)\n> 3.  type: 132 (`commitment_signed`)\n> 4.  data:\n>     -   [`32`:`channel_id`]\n>     -   [`64`:`signature`]\n>     -   [`2`:`num_htlcs`]\n>     -   [`num_htlcs*64`:`htlc_signature`]\n>     -   [`num_htlcs*64`:`htlc_splice_signature`] (`option_splice`)\n>\n>         If a reconnection occurs between between sending and receiving\n>         `splice_commitment_signature`) the peer's status is uncertain (similarly\n>         for closing). This we have a new field in `channel_reestablish` to flag\n>         that we consider ourselves to be splicing:\n>\n> 5.  type: 136 (`channel_reestablish`)\n> 6.  data:\n>     -   [`32`:`channel_id`]\n>     -   [`8`:`next_local_commitment_number`]\n>     -   [`8`:`next_remote_revocation_number`]\n>     -   [`32`:`your_last_per_commitment_secret`] (`option_data_loss_protect`)\n>     -   [`33`:`my_current_per_commitment_point`] (`option_data_loss_protect`)\n>     -   [`32`:`splice_txid`] (`option_splice`)\n>\n>         The splice_txid field indicates that this side considers itself to be\n>         splicing.\n>\n>         The sender:\n>\n>\n> -   if it has sent `splice_commitment_signature` and not sent the corresponding\n>     `splice_closed`, MUST set `splice_txid` to the txid of the splice tx.\n>     -   Otherwise MUST NOT.\n>\n>         The recipient:\n>\n> -   if it has sent `splice_commitment_signature` and not sent the corresponding\n>     `splice_closed`:\n>     -   if `splice_txid` does not exist or does not match the current splice:\n>         -   SHOULD fail the channel\n>     -   otherwise:\n>         -   MUST retransmit `splice_signature`\n> -   otherwise:\n>     -   if `splice_txid` field exists and is not all zeroes:\n>         -   MUST send `splice_closed`\n>\n>             Validation Changes During Splicing\n>\n>\n> We track \"post-splice\" values as well as current values during\n> splicing.\n>\n> The post-splice reserve is 1% of post-splice capcacity (rounded down).\n>\n> The fees for the splicing transaction itself are divided into parts by\n> the number of `splice_add_input` plus `splice_add_output`, rounded up.\n> Each side pays as many parts as it proposed `splice_add_input` plus\n> `splice_add_output`.\n>\n> (So if Alice proposes two and Bob proposes one, and the total fee is 1000\n> satoshi, each part is 334 satoshi: Alice pays 668 and Bob pays 334.)\n>\n> Each side's post-splice funds are debited their `splice_add_output`\n> amounts, and credited their `splice_add_input` amounts, a debited the\n> splice tx fees. If any debiting occurs, the funds must be above the\n> post-splice reserve (ie. you can have below reserve, but you can't spend\n> if you're below reserve).\n>\n> All update_add_htlc must be valid for the both the current and\n> post-splice balances.\n>\n> Completing Splicing\n>\n> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> Once you've seen both side's `minimum_depth` confirmations of the splice\n> transaction (ie. the maximum of the two `minimum_depth` values), you can\n> complete the splice by sending:\n>\n> 1.  type: 46 (`splice_closed`) (`option_splice`)\n> 2.  data:\n>     -   [`32`:`channel_id`]\n>\n>         Once you've sent and received `splice_closed` you can send\n>         `announcement_signatures` for the new channel as per normal rules (ie. 6\n>         confirmations, `announce_channel` bit set).\n>\n>         In addition, you can forget everything about the old channel (including\n>         old HTLCs and revocation requirements).\n>\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-10-12T04:23:57",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n> Good morning Rusty,\n>\n> In BOLT #2 we currently impose a 2^24 satoshi limit on total channel capacity.  Is splicing intended to allow violation of this limit? I do not see it mentioned in the proposal. Can I splice 21 million bitcoins on a 1-satoshi channel?\n\nGood question!  I think that's the kind of thing we should consider\ncarefully at the Summit.\n\n> It may be good to start brainstorming possible failure modes during splice, and how to recover, and also to indicate the expected behavior in the proposal, as I believe these will be the points where splicing must be designed most precisely. What happens when a splice is ongoing and the communication gets disconnected?  What happens when some channel failure occurs during splicing and we are forced to drop onchain?  And so on.\n\nAgreed, but we're now debating two fairly different methods for\nsplicing.  Once we've decided on that, we can try to design the\nproposals themselves.\n\nThanks,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-10-12T06:13:49",
                "message_text_only": "Good morning Rusty,\n\n>\n> > It may be good to start brainstorming possible failure modes during splice, and how to recover, and also to indicate the expected behavior in the proposal, as I believe these will be the points where splicing must be designed most precisely. What happens when a splice is ongoing and the communication gets disconnected? What happens when some channel failure occurs during splicing and we are forced to drop onchain? And so on.\n>\n> Agreed, but we're now debating two fairly different methods for\n> splicing. Once we've decided on that, we can try to design the\n> proposals themselves.\n\nI would suggest more to consider the simpler method, despite its larger onchain footprint (which is galling), but mostly because I do not see splicing as being as important as AMP or watchtowers (and payment decorrelation seems to affect how AMP can be implemented, so its priority also goes up).  So I think getting *some* splicing design out would be better even if imperfect.  Others may disagree on priority.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-10-15T19:04:46",
                "message_text_only": "> I would suggest more to consider the simpler method, despite its larger\n> onchain footprint (which is galling),\n\nThe on-chain footprint is a shame, and also it gets worse if we start to\nallow multiple pending splices. Also the lack of a non-blocking splice in is\na big draw back IMO.\n\n> but mostly because I do not see splicing as being as important as AMP or\n> watchtowers (and payment decorrelation seems to affect how AMP can be\n> implemented, so its priority also goes up).\n\nMost of what you mention here have _very_ different deployment timelines and\nsynchronization requirements across clients. For example, splicing is a link\nlevel change and can start to be rolled out immediately. Decorrelation on\nthe other hand, is a _network_ level change, and would take a considerable\namount of time to reach widespread deployment as it essentially splits the\nrouble paths in the network until all/most are upgraded.\n\nIf you think any of these items is a higher priority than splicing then you\ncan simply start working on them! There's no agency that prescribes what\nshould and shouldn't be pursued or developed, just your willingness to\nwrite some code.\n\nOne thing that I think we should lift from the multiple funding output\napproach is the \"pre seating of inputs\". This is cool as it would allow\nclients to generate addresses, that others could deposit to, and then have\nbe spliced directly into the channel. Public derivation can be used, along\nwith a script template to do it non-interactively, with the clients picking\nup these deposits, and initiating a splice in as needed.\n\n-- Laolu\n\n\n\nOn Thu, Oct 11, 2018 at 11:14 PM ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Rusty,\n>\n> >\n> > > It may be good to start brainstorming possible failure modes during\n> splice, and how to recover, and also to indicate the expected behavior in\n> the proposal, as I believe these will be the points where splicing must be\n> designed most precisely. What happens when a splice is ongoing and the\n> communication gets disconnected? What happens when some channel failure\n> occurs during splicing and we are forced to drop onchain? And so on.\n> >\n> > Agreed, but we're now debating two fairly different methods for\n> > splicing. Once we've decided on that, we can try to design the\n> > proposals themselves.\n>\n> I would suggest more to consider the simpler method, despite its larger\n> onchain footprint (which is galling), but mostly because I do not see\n> splicing as being as important as AMP or watchtowers (and payment\n> decorrelation seems to affect how AMP can be implemented, so its priority\n> also goes up).  So I think getting *some* splicing design out would be\n> better even if imperfect.  Others may disagree on priority.\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181015/dca18600/attachment.html>"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-10-15T19:04:23",
                "message_text_only": "Hi Rusty,\n\nHappy to get the splicing train rolling!\n\n> We've had increasing numbers of c-lightning users get upset they can't\n> open multiple channels, so I guess we're most motivated to allow splicing\nof\n> existing channels\n\nSplicing isn't a substitute for allowing multiple channels. Multiple\nchannels allow nodes to:\n\n  * create distinct channels with distinct acceptance policies.\n  * create a mix of public and non-advertised channels with a node.\n  * be able to send more than the (current) max HTLC amount\n    using various flavors of AMP.\n  * get past the (current) max channel size value\n  * allow a link to carry more HTLCs (due to the current super low max HTLC\n    values) given the additional HTLC pressure that\n    AMP may produce (alternative is a commitment fan out)\n\nIs there a fundamental reason that CL will never allow nodes to create\nmultiple channels? It seems unnecessarily limiting.\n\n> Splice Negotiation:\n\nAny reason to now make the splicing_add_* messages allow one to add several\ninputs in a single message? Given \"acceptable\" constraints for how large the\nwitness and pkScripts can be, we can easily enforce an upper limit on the\nnumber of inputs/outputs to add.\n\nI like that the intro messages have already been designed with the\nconcurrent case in mind beyond a simpler propose/accept flow. However is\nthere any reason why it doesn't also allow either side to fully re-negotiate\n_all_ the funding details? Splicing is a good opportunity to garbage collect\nthe prior revocation state, and also free up obsolete space in watch towers.\nAdditionally, as the size of the channel is either expanding or contracting,\nboth sides should be allowed to modify things like the CSV param, reserve,\nmax accepted htlc's, max htlc size, etc. Many of these parameters like the\nCSV value should scale with the size of the channel, not allowing these\nparameters to be re-negotiated could result in odd scenarios like still\nmaintain a 1 week CSV when the channel size has dipped from 1 BTC to 100k\nsatoshis.\n\n> 1. type: 40 (`splice_add_input`) (`option_splice`)\n\nIn order to add nested p2sh inputs, we'll need to also expose the redeem\nscript here, or add additional fields to allow sides to set a sig script as\nwell as witness during the signing phase.\n\n> - scriptpubkey is empty, or of form 'HASH160 <20-byte-script-hash> EQUAL'\n\nSo no P2SH? :(\n\n>    * [`4`:`feerate_per_kw`]\n\nWhat fee rate is this? IMO we should do commitmentv2 before splicing as then\nwe can more or less do away with the initiator distinction and have most\nfees be ad hoc.\n\n> Splice Signing\n\nIt seems that we're missing some fields here if we're to allow the splicing\nof inputs to be done in a non-blocking manner. We'll need to send two\nrevocation points for the new commitment: one to allow it to be created, and\nanother to allow updates to proceed right after the signing is completed. In\nthis case we'll also need to update both commitments in tandem until the\nsplicing transaction has been sufficiently confirmed.\n\nAlso, what about change addresses? Are they to be explicitly specified as\nsplice outs?\n\n> 1. type: 43 (`splice_commitment_signature`) (`option_splice`)\n\nIt may be worth pointing out there that we're able to transfer all existing\nHTLCs over to the new commitment as additional context.\n\n> 1. type: 45 (`splice_witness`) (`option_splice`)\n\nShould also allow either side to specify the sig script here if we're to\nallow nested p2sh (which we should IMO!).\n\n>   * [`2`:`len`]\n>   * [`len`:`witnesses`]\n\nIs the extra length needed if all the witness elements themselves are length\ndelimited?\n\nIt isn't clear in the current draft, but I take it that the splice_signature\nis for the old multi-sig?\n\n> so we append to the existing `channel_update` for the original channel,\n> using a new `message_flags` field:\n\nIMO, we need to hold off on optional fields for now, until we revisit the\nformatting in order to actually get it right. As is now, all the optional\nfields are basically serial mandatory soft forks. So clients must understand\nthe prior in order to understand the following fields. Instead, we\nessentially need more of a map design.\n\n> The post-splice reserve is 1% of post-splice capcacity (rounded down).\n\nThis should be re-negotiated at time of splice creation, rather than a new\nhard coded value in the protocol.\n\n> In addition, you can forget everything about the old channel (including\n> old HTLCs and revocation requirements).\n\nWe still have the same shachain state however (if we don't allow new state\nto be exchanged during the start of the splicing scenario), correct?\n\n-- Laolu\n\n-- Laolu\n\n\nOn Tue, Oct 9, 2018 at 8:46 PM Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> Hi all!\n>\n>         We've had increasing numbers of c-lightning users get upset they\n> can't open multiple channels, so I guess we're most motivated to allow\n> splicing of existing channels.  Hence this rough proposal.\n>\n> For simplicity, I've chosen to only allow a single splice at a time.\n> It's still complex :(\n>\n> Feedback welcome!\n> --\n> Splice Negotiation:\n>\n> 1. type: 40 (`splice_add_input`) (`option_splice`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`8`: `satoshis`]\n>    * [`32`: `prevtxid`]\n>    * [`4`: `prevtxoutnum`]\n>    * [`2`: `scriptlen`]\n>    * [`scriptlen`: `scriptpubkey`]\n>\n> 1. type: 41 (`splice_add_output`) (`option_splice`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`8`: `satoshis`]\n>    * [`2`: `scriptlen`]\n>    * [`scriptlen`: `outscript`]\n>\n> 1. type: 42 (`splice_all_added`) (`option_splice`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`4`:`feerate_per_kw`]\n>    * [`4`:`minimum_depth`]\n>\n> Each side sends 0 or more `splice_add_input` and 0 or more\n> `splice_add_output` followed by `spice_all_added` to complete the splice\n> proposal.  This is done either to initiate a splice, or to respond to a\n> `splice_*` from the other party.\n>\n> `splice_add_input` is checked for the following:\n> - must not be during a current splice\n> - scriptpubkey is empty, or of form 'HASH160 <20-byte-script-hash> EQUAL'\n> - `satoshis` doesn't wrap on addition.\n> - MAY check that it matches outpoint specified (sig will simply be\n>   invalid if so), and that outpoint is segwit.\n>\n> `splice_add_output` is checked for the following:\n> - must not be during a current splice\n> - `satoshis` is less than or equal to amount owing to proposer, minus\n>   current reserve, and greater than or equal to `dust_limit_satoshis` we\n>   sent in our open_channel/accept_channel ,sg.\n> - script is one of the approved forms as it is for `shutdown`.\n>\n> FIXME: Do we disallow splice-out if they specified\n>        option_upfront_shutdown_script?\n>\n> `splice_all_added` is checked for the following:\n> - average of `feerate_per_kw` by both sides (round down) is sufficient.\n> - average of `feerate_per_kw` by both sides not grossly excessive, if we're\n>   paying some of the fees (see below!)\n> - both sides can afford the fees from their post-splice funds (see\n>   Verification Changes below)\n> - maximum of the two `minimum_depth` is not grossly excessive.\n> - There is at least one splice_add_input or splice_add_output.\n>\n> Splice negotiation, like closing negotiation, does not have persistent\n> state.  Reconnecting forgets previous negotiation.\n>\n>\n> Splice Signing\n> --------------\n>\n> Once `splice_all_added` is both sent and received, we need to create and\n> sign both the splice tx itself, and the first commitment transaction\n> which spends it (but not in that order!).\n>\n> 1. One input spends the current funding tx output.\n> 2. There is one additional input for each splice_add_input.\n> 3. One output creates the new funding tx.\n> 4. There is one additional output for each splice_add_output.\n> 5. The entire transaction is sorted into BIP69 order.\n> 6. The feerate is the sum of the two `feerate_per_kw` divided by 2,\n>    rounded down.\n>\n> 1. type: 43 (`splice_commitment_signature`) (`option_splice`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`64`:`commitment_signature`]\n>    * [`2`:`num_htlcs`]\n>    * [`num_htlcs*64`:`htlc_signature`]\n>\n> 1. type: 44 (`splice_signature`) (`option_splice`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`64`:`splice_signature`]\n>\n> 1. type: 45 (`splice_witness`) (`option_splice`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`2`: `num_witness_elements`\n>    * [`2`:`len`]\n>    * [`len`:`witnesses`]\n>\n> `witnesses` itself is serialized as `num_witness_elements` of:\n> * `2`:`len`\n> * `len`: `witness_element`\n>\n> Each side sends `splice_commitment_signature` and waits to receive and\n> verify the other side's `splice_commitment_signature` before sending\n> `splice_signature` and `splice_witness` for each `splice_add_input` it\n> proposed, in BIP69 input order.\n>\n> Once a node has sent `splice_commitment_signature` it should remember\n> the splice proposal across reconnects.  Once it has both sent\n> `splice_signature`, the splice is locked in.\n>\n>\n> Splice Announcement\n> -------------------\n>\n> We have to tell the network about the new channel, otherwise there will\n> be a distruption when it sees the old funding transaction spent.  This\n> is inevitable for older nodes who won't understand splicing anyway.\n>\n> We can't send out a `channel_announcement` or `channel_update` for the\n> new channel until after the new funding transaction has 6 confirmations,\n> so we append to the existing `channel_update` for the original channel,\n> using a new `message_flags` field:\n>\n> | Bit Position  | Name                      | Field\n>     |\n> | ------------- | ------------------------- |\n> -------------------------------- |\n> | 0             | `option_channel_htlc_max` | `htlc_maximum_msat`\n>     |\n> | 1             | `option_channel_moving`   | `moving_txid\n>      |\n>\n> The `channel_update` gains the following field:\n>     * [`32`: moving_txid`] (option_channel_moving)\n>\n> If a current `channel_update` for a closing channel contains\n> `option_channel_moving` a node SHOULD ignore the channel close for at\n> least 100 blocks iff spent by `moving_txid`.\n>\n> A node SHOULD immediately forward a `channel_update` it sees containing\n> `option_channel_moving` if neither previous `channel_update` for the\n> channel contains `option_channel_moving`.\n>\n> Each side of the splice can send these unilaterally, and SHOULD allow a\n> few minutes for propagation (remember, average propagation from old\n> nodes is still 30 seconds) prior to broadcast of the splice transaction.\n>\n>\n> Message Changes During Splicing\n> -------------------------------\n> Once you've sent `splice_commitment_signature` each commitment\n> transaction is duplicated: one spends the old funding transaction, one\n> spends the splice transaction:\n>\n> 1. type: 39 (`closing_signed`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`8`:`fee_satoshis`]\n>    * [`64`:`signature`]\n>    * [`64`:`splice_signature`] (`option_splice`)\n>\n> 1. type: 132 (`commitment_signed`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`64`:`signature`]\n>    * [`2`:`num_htlcs`]\n>    * [`num_htlcs*64`:`htlc_signature`]\n>    * [`num_htlcs*64`:`htlc_splice_signature`] (`option_splice`)\n>\n> If a reconnection occurs between between sending and receiving\n> `splice_commitment_signature`) the peer's status is uncertain (similarly\n> for closing).  This we have a new field in `channel_reestablish` to flag\n> that we consider ourselves to be splicing:\n>\n> 1. type: 136 (`channel_reestablish`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>    * [`8`:`next_local_commitment_number`]\n>    * [`8`:`next_remote_revocation_number`]\n>    * [`32`:`your_last_per_commitment_secret`] (`option_data_loss_protect`)\n>    * [`33`:`my_current_per_commitment_point`] (`option_data_loss_protect`)\n>    * [`32`:`splice_txid`] (`option_splice`)\n>\n> The splice_txid field indicates that this side considers itself to be\n> splicing.\n>\n> The sender:\n> - if it has sent `splice_commitment_signature` and not sent the\n> corresponding\n>   `splice_closed`, MUST set `splice_txid` to the txid of the splice tx.\n>    - Otherwise MUST NOT.\n>\n> The recipient:\n> - if it has sent `splice_commitment_signature` and not sent the\n> corresponding\n>   `splice_closed`:\n>   - if `splice_txid` does not exist or does not match the current splice:\n>     - SHOULD fail the channel\n>   - otherwise:\n>     - MUST retransmit `splice_signature`\n> - otherwise:\n>   - if `splice_txid` field exists and is not all zeroes:\n>     - MUST send `splice_closed`\n>\n>\n> Validation Changes During Splicing\n> ----------------------------------\n> We track \"post-splice\" values as well as current values during\n> splicing.\n>\n> The post-splice reserve is 1% of post-splice capcacity (rounded down).\n>\n> The fees for the splicing transaction itself are divided into parts by\n> the number of `splice_add_input` plus `splice_add_output`, rounded up.\n> Each side pays as many parts as it proposed `splice_add_input` plus\n> `splice_add_output`.\n>\n> (So if Alice proposes two and Bob proposes one, and the total fee is 1000\n> satoshi, each part is 334 satoshi: Alice pays 668 and Bob pays 334.)\n>\n> Each side's post-splice funds are debited their `splice_add_output`\n> amounts, and credited their `splice_add_input` amounts, a debited the\n> splice tx fees.  If any debiting occurs, the funds must be above the\n> post-splice reserve (ie. you can have below reserve, but you can't spend\n> if you're below reserve).\n>\n> All update_add_htlc must be valid for the *both* the current and\n> post-splice balances.\n>\n> Completing Splicing\n> -------------------\n> Once you've seen both side's `minimum_depth` confirmations of the splice\n> transaction (ie. the maximum of the two `minimum_depth` values), you can\n> complete the splice by sending:\n>\n> 1. type: 46 (`splice_closed`) (`option_splice`)\n> 2. data:\n>    * [`32`:`channel_id`]\n>\n> Once you've sent and received `splice_closed` you can send\n> `announcement_signatures` for the new channel as per normal rules (ie. 6\n> confirmations, `announce_channel` bit set).\n>\n> In addition, you can forget everything about the old channel (including\n> old HTLCs and revocation requirements).\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181015/493ab074/attachment-0001.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-10-15T19:35:31",
                "message_text_only": "Olaoluwa Osuntokun <laolu32 at gmail.com> writes:\n> Splicing isn't a substitute for allowing multiple channels. Multiple\n> channels allow nodes to:\n>\n>   * create distinct channels with distinct acceptance policies.\n>   * create a mix of public and non-advertised channels with a node.\n>   * be able to send more than the (current) max HTLC amount\n>     using various flavors of AMP.\n>   * get past the (current) max channel size value\n>   * allow a link to carry more HTLCs (due to the current super low max HTLC\n>     values) given the additional HTLC pressure that\n>     AMP may produce (alternative is a commitment fan out)\n\nWhile these are all good points, I think they are equally well served if\nby creating channels to other peers. This has the added benefit of\nreducing the node's reliance on a single peer. In fact it seems we are\ncurrently encouraging users to have a small number of fat channels that\nare manually maintained (dual-funding, splicing, multiple channels per\npeer), rather than making the default to create a diverse set of\nchannels that allow indirectly routed payments.\n\nInstead of obsessing about that one peer and hoping that that peer is\nonline when we need it, we should make routed payments a first-class\ncitizen. If we can route correctly and with confidence we can stop\nworrying about that one peer and our connectivity to it. On the other\nhand, if routing doesn't work, and people have to worry about that one\nchannel that connects them directly to the destination, then we're not\nmuch of a network, but rather a set of disjoint channels.\n\nUltimately users should stop caring about individual channels or peer\nrelationships, and multipath routing gets us a long way there. I'd\nreally like to have a wallet that'll just manage channels in the\nbackground and not expose those details to the users which just want to\nsend and receive payments, and we can start that now by de-emphasizing\nthe importance of the peer selection.\n\nRegards,\nChristian"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-10-16T04:33:57",
                "message_text_only": "Olaoluwa Osuntokun <laolu32 at gmail.com> writes:\n> Hi Rusty,\n>\n> Happy to get the splicing train rolling!\n>\n>> We've had increasing numbers of c-lightning users get upset they can't\n>> open multiple channels, so I guess we're most motivated to allow splicing\n> of\n>> existing channels\n>\n> Splicing isn't a substitute for allowing multiple channels. Multiple\n> channels allow nodes to:\n>\n>   * create distinct channels with distinct acceptance policies.\n>   * create a mix of public and non-advertised channels with a node.\n>   * be able to send more than the (current) max HTLC amount\n>     using various flavors of AMP.\n>   * get past the (current) max channel size value\n>   * allow a link to carry more HTLCs (due to the current super low max HTLC\n>     values) given the additional HTLC pressure that\n>     AMP may produce (alternative is a commitment fan out)\n\nThese all seem marginal to me.  I think if we start hitting max values,\nwe should discuss increasing them.\n\n> Is there a fundamental reason that CL will never allow nodes to create\n> multiple channels? It seems unnecessarily limiting.\n\nYeah, we have a daemon per peer.  It's really simple with 1 daemon, 1\nchannel.  My own fault: I was the one who insisted we mux multiple\nconnections over the same transport; if we'd gone for independent\nconnections our implementation would have been trivial.\n\n>> Splice Negotiation:\n>\n> Any reason to now make the splicing_add_* messages allow one to add several\n> inputs in a single message? Given \"acceptable\" constraints for how large the\n> witness and pkScripts can be, we can easily enforce an upper limit on the\n> number of inputs/outputs to add.\n\nMainly limitations of our descriptor language, TBH.  \n\n> I like that the intro messages have already been designed with the\n> concurrent case in mind beyond a simpler propose/accept flow. However is\n> there any reason why it doesn't also allow either side to fully re-negotiate\n> _all_ the funding details? Splicing is a good opportunity to garbage collect\n> the prior revocation state, and also free up obsolete space in watch towers.\n\nI thought about restarting the revocation sequence, but it seems like\nthat only saves a tiny amount since we only store log(N) entries.  We\ncan drop old HTLC info post-splice though, and (after some delay for\nobscurity) tell watchtowers to drop old entries I think.\n\n> Additionally, as the size of the channel is either expanding or contracting,\n> both sides should be allowed to modify things like the CSV param, reserve,\n> max accepted htlc's, max htlc size, etc. Many of these parameters like the\n> CSV value should scale with the size of the channel, not allowing these\n> parameters to be re-negotiated could result in odd scenarios like still\n> maintain a 1 week CSV when the channel size has dipped from 1 BTC to 100k\n> satoshis.\n\nYep, good idea!  I missed that.\n\nBrings up a side point about these values, which deserves its own\npost...\n\n>> 1. type: 40 (`splice_add_input`) (`option_splice`)\n>\n> In order to add nested p2sh inputs, we'll need to also expose the redeem\n> script here, or add additional fields to allow sides to set a sig script as\n> well as witness during the signing phase.\n>\n>> - scriptpubkey is empty, or of form 'HASH160 <20-byte-script-hash> EQUAL'\n>\n> So no P2SH? :(\n\nAnother omission, yeah, we'd want that too I think.\n\n>>    * [`4`:`feerate_per_kw`]\n>\n> What fee rate is this? IMO we should do commitmentv2 before splicing as then\n> we can more or less do away with the initiator distinction and have most\n> fees be ad hoc.\n\nWe're basically co-generating a tx here, just like shutdown, except it's\nfunding a new replacement channel.  Do we want to CPFP this one too?\n\n>> Splice Signing\n>\n> It seems that we're missing some fields here if we're to allow the splicing\n> of inputs to be done in a non-blocking manner. We'll need to send two\n> revocation points for the new commitment: one to allow it to be created, and\n> another to allow updates to proceed right after the signing is completed. In\n> this case we'll also need to update both commitments in tandem until the\n> splicing transaction has been sufficiently confirmed.\n\nI think we can use the existing revocation points for both.\n\n> Also, what about change addresses? Are they to be explicitly specified as\n> splice outs?\n\nThey'd be splice-outs, yeah.\n\n>> 1. type: 43 (`splice_commitment_signature`) (`option_splice`)\n>\n> It may be worth pointing out there that we're able to transfer all existing\n> HTLCs over to the new commitment as additional context.\n\nYeah, I think people missed that it was non-blocking like that.\n\n>> 1. type: 45 (`splice_witness`) (`option_splice`)\n>\n> Should also allow either side to specify the sig script here if we're to\n> allow nested p2sh (which we should IMO!).\n\nYep.\n\n>>   * [`2`:`len`]\n>>   * [`len`:`witnesses`]\n>\n> Is the extra length needed if all the witness elements themselves are length\n> delimited?\n\nYes, we always length-delimit fields so we can add options later.\n\n>\n> It isn't clear in the current draft, but I take it that the splice_signature\n> is for the old multi-sig?\n\nYes, that's the signature required to spend the old funding txout.\n\n>> so we append to the existing `channel_update` for the original channel,\n>> using a new `message_flags` field:\n>\n> IMO, we need to hold off on optional fields for now, until we revisit the\n> formatting in order to actually get it right. As is now, all the optional\n> fields are basically serial mandatory soft forks. So clients must understand\n> the prior in order to understand the following fields. Instead, we\n> essentially need more of a map design.\n\nYou need to add prior options to your wire parser, but that's usually\nthe most trivial part of handling them.  And they may waste space on the\nwire since we treat them as append-only, but OTOH it avoids\ncombinatorial testing explosion.\n\n>> The post-splice reserve is 1% of post-splice capcacity (rounded down).\n>\n> This should be re-negotiated at time of splice creation, rather than a new\n> hard coded value in the protocol.\n>\n>> In addition, you can forget everything about the old channel (including\n>> old HTLCs and revocation requirements).\n>\n> We still have the same shachain state however (if we don't allow new state\n> to be exchanged during the start of the splicing scenario), correct?\n\nYep.\n\nThanks,\nRusty.\n\n> -- Laolu\n>\n> -- Laolu\n\nPS, Damn, I always suspected there were multiple Roasbeefs, and we're simply\ndealing with the output of an advanced multiplexing protocol.  I present\nthe above as conclusive evidence of this thesis..."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-10-16T11:16:26",
                "message_text_only": "Good morning Laolu,\n\n> Is there a fundamental reason that CL will never allow nodes to create\n> multiple channels? It seems unnecessarily limiting.\n\nThe architecture of c-lightning assigns a separate process to each peer.  For simplicity this peer process handles only a single channel.  Some of the channel initiation and shutdown protocols are written \"directly\", i.e. if the BOLT spec says this must happen before that, we literally write in the C code this_function(); that_function();.  It would be possible  to change this architecture with significant difficulty.\n\nHowever personally I do not really see the need to create multiple channels to a single peer, or increase the capacity with a specific peer (via splice or dual-funding).  As Christian says in the other mail, this consideration, is that it becomes less a network and more of some channels to specific big businesses you transact with regularly.  But I suppose, that we will have to see how the network evolves eventually; perhaps the goal of decentralization is simply doomed regardless, and Lightning will indeed evolve into a set of channels you maintain to specific big businesses you regularly work with.\n\n>>    * [`4`:`feerate_per_kw`]\n>\n> What fee rate is this? IMO we should do commitmentv2 before splicing as then\n> we can more or less do away with the initiator distinction and have most\n> fees be ad hoc.\n\nI worry about doing away with initiator distinction, as I worry that an initiatee may be forced to pay fees they did not really voluntarily consider paying, when they are given funds on a channel initiated by someone else in exchange for funds on a separate channel; but this is probably a separate topic.\n\n>If you think any of these items is a higher priority than splicing then you\n>can simply start working on them! There's no agency that prescribes what\n>should and shouldn't be pursued or developed, just your willingness to\n>write some code.\n\nWhile true, for me personally I can only devote a limited amount of time to coding for Lightning, and thus I must always worry whether my priorities are even correct.  I find it very common that people want to prioritize splicing over AMP or watchtowers, which puzzles me, and I wonder if I am incorrect in my prioritization.\n\n> One thing that I think we should lift from the multiple funding output\n> approach is the \"pre seating of inputs\". This is cool as it would allow\n> clients to generate addresses, that others could deposit to, and then have\n> be spliced directly into the channel. Public derivation can be used, along\n> with a script template to do it non-interactively, with the clients picking\n> up these deposits, and initiating a splice in as needed.\n\nI am uncertain what this means in particular, but let me try to restate what you are talking about in other terms:\n\n1.  Each channel has two public-key-derivation paths (BIP32) to create onchain addresses.  One for each side of the channel.\n2.  When somebody sends to one of the onchain addresses in the path, their client detects this.\n3.  The client initiates a splice-in automatically from this UTXO paying to that address into the channel.\n\nIt seems to me naively that the above can be done by the client software without any modifications to the Lightning Network BOLT protocol, as long as the BOLT protocol is capable of supporting *some* splice-in operation, i.e. it seems to be something that a client software can implement as a feature without requiring a BOLT change.  Or is my above restatement different from what you are talking about?\n\nHow about this restatement?\n\n1.  Each channel has two public-key-derivation paths (BIP32) to create onchain addresses.  One for each side of the channel.\n2.  The base of the above is actually a combined private-public keypair of both sides (e.g. created via MuSig or some other protocol).  Thus the addresses require cooperation of both parties to spend.\n3.  When somebody sends to one of the onchain addresses in the path, their client detects this.\n4.  The client updates the current transaction state, such that the new commit transaction has two inputs ( the original channel transaction and the new UTXO).\n\nThe above seems unsafe without trust in the other peer, as, the other peer can simply refuse to create the new commit transaction.  Since the address requires both parties to spend, the money cannot be spent and there is no backoff transaction that can be used.  But maybe you can describe some mechanism to ensure this, if this is what is meant instead?\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181016/6cd470a5/attachment-0001.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-10-16T12:38:17",
                "message_text_only": "ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\nwrites:\n\n>> One thing that I think we should lift from the multiple funding output\n>> approach is the \"pre seating of inputs\". This is cool as it would allow\n>> clients to generate addresses, that others could deposit to, and then have\n>> be spliced directly into the channel. Public derivation can be used, along\n>> with a script template to do it non-interactively, with the clients picking\n>> up these deposits, and initiating a splice in as needed.\n>\n> I am uncertain what this means in particular, but let me try to\n> restate what you are talking about in other terms:\n>\n> 1.  Each channel has two public-key-derivation paths (BIP32) to create onchain addresses.  One for each side of the channel.\n> 2.  When somebody sends to one of the onchain addresses in the path, their client detects this.\n> 3.  The client initiates a splice-in automatically from this UTXO paying to that address into the channel.\n>\n> It seems to me naively that the above can be done by the client\n> software without any modifications to the Lightning Network BOLT\n> protocol, as long as the BOLT protocol is capable of supporting *some*\n> splice-in operation, i.e. it seems to be something that a client\n> software can implement as a feature without requiring a BOLT change.\n> Or is my above restatement different from what you are talking about?\n>\n> How about this restatement?\n>\n> 1.  Each channel has two public-key-derivation paths (BIP32) to create onchain addresses.  One for each side of the channel.\n> 2.  The base of the above is actually a combined private-public keypair of both sides (e.g. created via MuSig or some other protocol).  Thus the addresses require cooperation of both parties to spend.\n> 3.  When somebody sends to one of the onchain addresses in the path, their client detects this.\n> 4.  The client updates the current transaction state, such that the new commit transaction has two inputs ( the original channel transaction and the new UTXO).\n>\n> The above seems unsafe without trust in the other peer, as, the other\n> peer can simply refuse to create the new commit transaction.  Since\n> the address requires both parties to spend, the money cannot be spent\n> and there is no backoff transaction that can be used.  But maybe you\n> can describe some mechanism to ensure this, if this is what is meant\n> instead?\n\nThis could easily be solved by making the destination address a Taproot\naddress, which by default is just a 2-of-2, but in the uncooperative\ncase it can reveal the script it commits to, which is just a timelocked\nrefund that requires a single-sig. The only problem with this is that\nthe refund would be non-interactive, and so the entirety of the funds,\nthat may be from a third-party, need to be claimed by one endpoint,\ni.e., there is no splitting the funds in case of an uncollaborative\nrefund. Not sure how important that is though, since I don't think\nthird-party funds will come from unrelated parties, e.g., most of these\nfunds will come from an on-chain wallet that is under the control of\neither parties so the refund should go back to that party anyway.\n\nCheers,\nChristian"
            },
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2018-10-16T19:25:59",
                "message_text_only": ">\n> This is one of the cases where a simpler solution (relatively\n> speaking ^^) is to be preferred imho, allowing for future\n> iterations.\n>\n\nI think we should strive to splice in 1 on-chain tx, as if not the biggest\nbenefit really is lost compared to just closing and reopening the channel.\n\nComplexity wise I don't think it will be that much to gain from the 2-tx\nproposal as (if I understand the proposal correctly) there will be even\nmore transaction types with new scripts to code up and maintain.\n\nOn Tue, Oct 16, 2018 at 5:38 AM Christian Decker <decker.christian at gmail.com>\nwrote:\n\n> ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\n> writes:\n>\n> >> One thing that I think we should lift from the multiple funding output\n> >> approach is the \"pre seating of inputs\". This is cool as it would allow\n> >> clients to generate addresses, that others could deposit to, and then\n> have\n> >> be spliced directly into the channel. Public derivation can be used,\n> along\n> >> with a script template to do it non-interactively, with the clients\n> picking\n> >> up these deposits, and initiating a splice in as needed.\n> >\n> > I am uncertain what this means in particular, but let me try to\n> > restate what you are talking about in other terms:\n> >\n> > 1.  Each channel has two public-key-derivation paths (BIP32) to create\n> onchain addresses.  One for each side of the channel.\n> > 2.  When somebody sends to one of the onchain addresses in the path,\n> their client detects this.\n> > 3.  The client initiates a splice-in automatically from this UTXO paying\n> to that address into the channel.\n> >\n> > It seems to me naively that the above can be done by the client\n> > software without any modifications to the Lightning Network BOLT\n> > protocol, as long as the BOLT protocol is capable of supporting *some*\n> > splice-in operation, i.e. it seems to be something that a client\n> > software can implement as a feature without requiring a BOLT change.\n> > Or is my above restatement different from what you are talking about?\n> >\n> > How about this restatement?\n> >\n> > 1.  Each channel has two public-key-derivation paths (BIP32) to create\n> onchain addresses.  One for each side of the channel.\n> > 2.  The base of the above is actually a combined private-public keypair\n> of both sides (e.g. created via MuSig or some other protocol).  Thus the\n> addresses require cooperation of both parties to spend.\n> > 3.  When somebody sends to one of the onchain addresses in the path,\n> their client detects this.\n> > 4.  The client updates the current transaction state, such that the new\n> commit transaction has two inputs ( the original channel transaction and\n> the new UTXO).\n> >\n> > The above seems unsafe without trust in the other peer, as, the other\n> > peer can simply refuse to create the new commit transaction.  Since\n> > the address requires both parties to spend, the money cannot be spent\n> > and there is no backoff transaction that can be used.  But maybe you\n> > can describe some mechanism to ensure this, if this is what is meant\n> > instead?\n>\n> This could easily be solved by making the destination address a Taproot\n> address, which by default is just a 2-of-2, but in the uncooperative\n> case it can reveal the script it commits to, which is just a timelocked\n> refund that requires a single-sig. The only problem with this is that\n> the refund would be non-interactive, and so the entirety of the funds,\n> that may be from a third-party, need to be claimed by one endpoint,\n> i.e., there is no splitting the funds in case of an uncollaborative\n> refund. Not sure how important that is though, since I don't think\n> third-party funds will come from unrelated parties, e.g., most of these\n> funds will come from an on-chain wallet that is under the control of\n> either parties so the refund should go back to that party anyway.\n>\n> Cheers,\n> Christian\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181016/5a6baacf/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Splicing Proposal: Feedback please!",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Decker",
                "Conner Fromknecht",
                "lisa neigut",
                "Ren\u00e9 Pickhardt",
                "Johan Tor\u00e5s Halseth",
                "Rusty Russell",
                "Olaoluwa Osuntokun",
                "ZmnSCPxj"
            ],
            "messages_count": 23,
            "total_messages_chars_count": 163491
        }
    },
    {
        "title": "[Lightning-dev] eltoo: A Simplified update Mechanism for Lightning and Off-Chain Contracts",
        "thread_messages": [
            {
                "author": "Anthony Towns",
                "date": "2018-10-10T08:25:46",
                "message_text_only": "On Mon, Apr 30, 2018 at 05:41:38PM +0200, Christian Decker wrote:\n> eltoo is a drop-in replacement for the penalty based invalidation\n> mechanism that is used today in the Lightning specification. [...]\n\nMaybe this is obvious, but in case it's not, re: the locktime-based\nsequencing in eltoo:\n\n \"any number above 0.500 billion is interpreted as a UNIX timestamp, and\n  with a current timestamp of ~1.5 billion, that leaves about 1 billion\n  numbers that are interpreted as being in the past\"\n\nI think if you had a more than a 1B updates to your channel (50 updates\nper second for 4 months?) I think you could reset the locktime by rolling\nover to use new update keys. When unilaterally closing you'd need to\nuse an extra transaction on-chain to do that roll-over, but you'd save\na transaction if you did a cooperative close.\n\nie, rather than:\n\n  [funding] -> [coop close / re-fund] -> [update 23M] -> [HTLCs etc]\nor\n  [funding] -> [coop close / re-fund] -> [coop close]\n\nyou could have:\n  [funding] -> [update 1B] -> [update 23,310,561 with key2] -> [HTLCs]\nor\n  [funding] -> [coop close]\n\nYou could repeat this when you get another 1B updates, making unilateral\ncloses more painful, but keeping cooperative closes cheap.\n\nCheers,\naj"
            },
            {
                "author": "Christian Decker",
                "date": "2018-10-11T17:37:56",
                "message_text_only": "Thanks Anthony for pointing this out, I was not aware we could\nroll keypairs to reset the state numbers.\n\nI basically thought that 1billion updates is more than I would\never do, since with splice-in / splice-out operations we'd be\nre-anchoring on-chain on a regular basis anyway.\n\n\nOn Wed, Oct 10, 2018 at 10:25 AM Anthony Towns <aj at erisian.com.au> wrote:\n\n> On Mon, Apr 30, 2018 at 05:41:38PM +0200, Christian Decker wrote:\n> > eltoo is a drop-in replacement for the penalty based invalidation\n> > mechanism that is used today in the Lightning specification. [...]\n>\n> Maybe this is obvious, but in case it's not, re: the locktime-based\n> sequencing in eltoo:\n>\n>  \"any number above 0.500 billion is interpreted as a UNIX timestamp, and\n>   with a current timestamp of ~1.5 billion, that leaves about 1 billion\n>   numbers that are interpreted as being in the past\"\n>\n> I think if you had a more than a 1B updates to your channel (50 updates\n> per second for 4 months?) I think you could reset the locktime by rolling\n> over to use new update keys. When unilaterally closing you'd need to\n> use an extra transaction on-chain to do that roll-over, but you'd save\n> a transaction if you did a cooperative close.\n>\n> ie, rather than:\n>\n>   [funding] -> [coop close / re-fund] -> [update 23M] -> [HTLCs etc]\n> or\n>   [funding] -> [coop close / re-fund] -> [coop close]\n>\n> you could have:\n>   [funding] -> [update 1B] -> [update 23,310,561 with key2] -> [HTLCs]\n> or\n>   [funding] -> [coop close]\n>\n> You could repeat this when you get another 1B updates, making unilateral\n> closes more painful, but keeping cooperative closes cheap.\n>\n> Cheers,\n> aj\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181011/c03ad2ea/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-10-12T03:20:55",
                "message_text_only": "Another way would be to always have two update transactions, effectively creating a larger overall counter:\n\n[anchor] -> [update highbits] -> [update lobits] -> [settlement]\n\nWe normally update [update lobits] until it saturates.  If lobits saturates we increment [update highbits] and reset [update lobits] to the lowest valid value.\n\nThis will provide a single counter with 10^18 possible updates, which should be enough for a while even without reanchoring.\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Friday, October 12, 2018 1:37 AM, Christian Decker <decker.christian at gmail.com> wrote:\n\n> Thanks Anthony for pointing this out, I was not aware we could\n> roll keypairs to reset the state numbers.\n>\n> I basically thought that 1billion updates is more than I would\n> ever do, since with splice-in / splice-out operations we'd be\n> re-anchoring on-chain on a regular basis anyway.\n>\n> On Wed, Oct 10, 2018 at 10:25 AM Anthony Towns <aj at erisian.com.au> wrote:\n>\n>> On Mon, Apr 30, 2018 at 05:41:38PM +0200, Christian Decker wrote:\n>>> eltoo is a drop-in replacement for the penalty based invalidation\n>>> mechanism that is used today in the Lightning specification. [...]\n>>\n>> Maybe this is obvious, but in case it's not, re: the locktime-based\n>> sequencing in eltoo:\n>>\n>>  \"any number above 0.500 billion is interpreted as a UNIX timestamp, and\n>>   with a current timestamp of ~1.5 billion, that leaves about 1 billion\n>>   numbers that are interpreted as being in the past\"\n>>\n>> I think if you had a more than a 1B updates to your channel (50 updates\n>> per second for 4 months?) I think you could reset the locktime by rolling\n>> over to use new update keys. When unilaterally closing you'd need to\n>> use an extra transaction on-chain to do that roll-over, but you'd save\n>> a transaction if you did a cooperative close.\n>>\n>> ie, rather than:\n>>\n>>   [funding] -> [coop close / re-fund] -> [update 23M] -> [HTLCs etc]\n>> or\n>>   [funding] -> [coop close / re-fund] -> [coop close]\n>>\n>> you could have:\n>>   [funding] -> [update 1B] -> [update 23,310,561 with key2] -> [HTLCs]\n>> or\n>>   [funding] -> [coop close]\n>>\n>> You could repeat this when you get another 1B updates, making unilateral\n>> closes more painful, but keeping cooperative closes cheap.\n>>\n>> Cheers,\n>> aj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181012/259fb8da/attachment-0001.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-10-13T10:12:03",
                "message_text_only": "Great find ZmnSCPxj, we can also have an adaptive scheme here, in which we\nstart with a single update transaction, and then at ~90% of the available\nrange we add a second. This is starting to look a bit like the DMC\ninvalidation tree :-)\nBut realistically speaking I don't think 1B updates is going to be\nexhausted any time soon, but the adaptive strategy gets the best of\nboth worlds.\n\nCheers,\nChristian\n\nOn Fri, Oct 12, 2018 at 5:21 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Another way would be to always have two update transactions, effectively\n> creating a larger overall counter:\n>\n> [anchor] -> [update highbits] -> [update lobits] -> [settlement]\n>\n> We normally update [update lobits] until it saturates.  If lobits\n> saturates we increment [update highbits] and reset [update lobits] to the\n> lowest valid value.\n>\n> This will provide a single counter with 10^18 possible updates, which\n> should be enough for a while even without reanchoring.\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> Sent with ProtonMail <https://protonmail.com> Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Friday, October 12, 2018 1:37 AM, Christian Decker <\n> decker.christian at gmail.com> wrote:\n>\n> Thanks Anthony for pointing this out, I was not aware we could\n> roll keypairs to reset the state numbers.\n>\n> I basically thought that 1billion updates is more than I would\n> ever do, since with splice-in / splice-out operations we'd be\n> re-anchoring on-chain on a regular basis anyway.\n>\n>\n>\n> On Wed, Oct 10, 2018 at 10:25 AM Anthony Towns <aj at erisian.com.au> wrote:\n>\n>> On Mon, Apr 30, 2018 at 05:41:38PM +0200, Christian Decker wrote:\n>> > eltoo is a drop-in replacement for the penalty based invalidation\n>> > mechanism that is used today in the Lightning specification. [...]\n>>\n>> Maybe this is obvious, but in case it's not, re: the locktime-based\n>> sequencing in eltoo:\n>>\n>>  \"any number above 0.500 billion is interpreted as a UNIX timestamp, and\n>>   with a current timestamp of ~1.5 billion, that leaves about 1 billion\n>>   numbers that are interpreted as being in the past\"\n>>\n>> I think if you had a more than a 1B updates to your channel (50 updates\n>> per second for 4 months?) I think you could reset the locktime by rolling\n>> over to use new update keys. When unilaterally closing you'd need to\n>> use an extra transaction on-chain to do that roll-over, but you'd save\n>> a transaction if you did a cooperative close.\n>>\n>> ie, rather than:\n>>\n>>   [funding] -> [coop close / re-fund] -> [update 23M] -> [HTLCs etc]\n>> or\n>>   [funding] -> [coop close / re-fund] -> [coop close]\n>>\n>> you could have:\n>>   [funding] -> [update 1B] -> [update 23,310,561 with key2] -> [HTLCs]\n>> or\n>>   [funding] -> [coop close]\n>>\n>> You could repeat this when you get another 1B updates, making unilateral\n>> closes more painful, but keeping cooperative closes cheap.\n>>\n>> Cheers,\n>> aj\n>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181013/92190e1e/attachment.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2018-10-13T11:40:30",
                "message_text_only": "On 13 October 2018 7:12:03 pm GMT+09:00, Christian Decker <decker.christian at gmail.com> wrote:\n>Great find ZmnSCPxj, we can also have an adaptive scheme here, in which\n>we\n>start with a single update transaction, and then at ~90% of the\n>available\n>range we add a second. This is starting to look a bit like the DMC\n>invalidation tree :-)\n>But realistically speaking I don't think 1B updates is going to be\n>exhausted any time soon, but the adaptive strategy gets the best of\n>both worlds.\n>\n>Cheers,\n>Christian\n>\n>On Fri, Oct 12, 2018 at 5:21 AM ZmnSCPxj <ZmnSCPxj at protonmail.com>\n>wrote:\n>\n>> Another way would be to always have two update transactions,\n>effectively\n>> creating a larger overall counter:\n>>\n>> [anchor] -> [update highbits] -> [update lobits] -> [settlement]\n>>\n>> We normally update [update lobits] until it saturates.  If lobits\n>> saturates we increment [update highbits] and reset [update lobits] to\n>the\n>> lowest valid value.\n>>\n>> This will provide a single counter with 10^18 possible updates, which\n>> should be enough for a while even without reanchoring.\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>>\n>> Sent with ProtonMail <https://protonmail.com> Secure Email.\n>>\n>> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>> On Friday, October 12, 2018 1:37 AM, Christian Decker <\n>> decker.christian at gmail.com> wrote:\n>>\n>> Thanks Anthony for pointing this out, I was not aware we could\n>> roll keypairs to reset the state numbers.\n>>\n>> I basically thought that 1billion updates is more than I would\n>> ever do, since with splice-in / splice-out operations we'd be\n>> re-anchoring on-chain on a regular basis anyway.\n>>\n>>\n>>\n>> On Wed, Oct 10, 2018 at 10:25 AM Anthony Towns <aj at erisian.com.au>\n>wrote:\n>>\n>>> On Mon, Apr 30, 2018 at 05:41:38PM +0200, Christian Decker wrote:\n>>> > eltoo is a drop-in replacement for the penalty based invalidation\n>>> > mechanism that is used today in the Lightning specification. [...]\n>>>\n>>> Maybe this is obvious, but in case it's not, re: the locktime-based\n>>> sequencing in eltoo:\n>>>\n>>>  \"any number above 0.500 billion is interpreted as a UNIX timestamp,\n>and\n>>>   with a current timestamp of ~1.5 billion, that leaves about 1\n>billion\n>>>   numbers that are interpreted as being in the past\"\n>>>\n>>> I think if you had a more than a 1B updates to your channel (50\n>updates\n>>> per second for 4 months?) I think you could reset the locktime by\n>rolling\n>>> over to use new update keys. When unilaterally closing you'd need to\n>>> use an extra transaction on-chain to do that roll-over, but you'd\n>save\n>>> a transaction if you did a cooperative close.\n>>>\n>>> ie, rather than:\n>>>\n>>>   [funding] -> [coop close / re-fund] -> [update 23M] -> [HTLCs etc]\n>>> or\n>>>   [funding] -> [coop close / re-fund] -> [coop close]\n>>>\n>>> you could have:\n>>>   [funding] -> [update 1B] -> [update 23,310,561 with key2] ->\n>[HTLCs]\n>>> or\n>>>   [funding] -> [coop close]\n>>>\n>>> You could repeat this when you get another 1B updates, making\n>unilateral\n>>> closes more painful, but keeping cooperative closes cheap.\n>>>\n>>> Cheers,\n>>> aj\n>>>\n>>>\n>>\n\nHmm - the range grows by one every second though, so as long as you don't go through a billion updates per second, you can go to 100% of the range, knowing that by the time you have to increment, you'll have 115% of the original range available, meaning you never need more than two transactions (until locktime overflows anyway) for the commitment, even at 900MHz transaction rates...\n\nCheers,\naj\n\n-- \nSent from my phone."
            }
        ],
        "thread_summary": {
            "title": "eltoo: A Simplified update Mechanism for Lightning and Off-Chain Contracts",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Anthony Towns",
                "ZmnSCPxj",
                "Christian Decker"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 12232
        }
    },
    {
        "title": "[Lightning-dev] Commitment Transaction Format Update Proposals?",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-10-12T04:56:03",
                "message_text_only": "Hi all,\n\n        There have been a number of suggested changes to the commitment\ntransaction format:\n\n1. Rather than trying to agree on what fees will be in the future, we\n   should use an OP_TRUE-style output to allow CPFP (Roasbeef)\n2. The `remotepubkey` should be a BIP-32-style, to avoid the\n   option_data_loss_protect \"please tell me your current\n   per_commitment_point\" problem[1]\n3. The CLTV timeout should be symmetrical to avoid trying to game the\n   peer into closing. (Connor IIRC?).\n\nIt makes sense to combine these into a single `commitment_style2`\nfeature, rather than having a testing matrix of all these disabled and\nenabled.\n\nBOLT #2:\n\n- If `commitment_style2` negotiated, update_fee is a protocol error.\n\nThis mainly changes BOLT #3:\n\n- The feerate for commitment transactions is always 253 satoshi/Sipa.\n- Commitment tx always has a P2WSH OP_TRUE output of 1000 satoshi.\n- Fees, OP_TRUE are always paid by the initial funder, because it's simple,\n  unless they don't have funds (eg. push_msat can do this, unless we remove it?)\n- HTLC-timeout and HTLC-success txs sigs are \n  SIGHASH_ANYONECANPAY|SIGHASH_SINGLE, so you can Bring Your Own Fees.\n- `localpubkey`, `remotepubkey`, `local_htlcpubkey`,\n  `remote_htlcpubkey`, `local_delayedpubkey`, and `remote_delayedpubkey`\n  derivation now uses a two-stage unhardened BIP-32 derivation based on\n  the commitment number.  Two-stage because we can have 2^48 txs and\n  BIP-32 only supports 2^31: the first 17 bits are used to derive the\n  parent for the next 31 bits?\n- `to_self_delay` for both sides is the maximum of either the\n  `open_channel` or `accept_channel`.\n- `to_remote` is now a P2WSH of:\n        `to_self_delay` OP_CSV OP_DROP <remotepubkey> OP_CHECKSIG\n\nCheers,\nRusty.\n\n[1] I recently removed checking this field from c-lightning, as I\n    couldn't get it to reliably work under stress-test.  I may just have\n    a bug, but we could just fix the spec instead, then we can get our\n    funds back even if we never talk to the peer."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-10-12T06:19:31",
                "message_text_only": "Good morning Rusty and list,\n\n>\n> 1.  Rather than trying to agree on what fees will be in the future, we\n>     should use an OP_TRUE-style output to allow CPFP (Roasbeef)\n>\n\nMy understanding is that this would require some base-layer changes at Bitcoin level first?  At minimum IsStandard() modification, and I believe luke-jr suggested, to make a consensus rule that OP_TRUE would not be spendable beyond the block it appears in (i.e. it is used only for CPFP hooking) to reduce UTXO database size at lower layer.\n\nIt seems the other parts of this proposal, do not need this base-layer change; so, this may delay the other parts (but perhaps it is not at all an issue to delay the other parts of this proposal...?).\n\n> 3.  The CLTV timeout should be symmetrical to avoid trying to game the\n>     peer into closing. (Connor IIRC?).\n\nI know this has been discussed before, but I wonder the rationale for the original asymmetric design, and the rationale for the new symmetric design.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-10-12T06:36:57",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n> Good morning Rusty and list,\n>\n>>\n>> 1.  Rather than trying to agree on what fees will be in the future, we\n>>     should use an OP_TRUE-style output to allow CPFP (Roasbeef)\n>>\n>\n> My understanding is that this would require some base-layer changes at Bitcoin level first?  At minimum IsStandard() modification, and I believe luke-jr suggested, to make a consensus rule that OP_TRUE would not be spendable beyond the block it appears in (i.e. it is used only for CPFP hooking) to reduce UTXO database size at lower layer.\n\nIf you look further down, it's actually a P2WSH to \"OP_TRUE\".  Wastes\nsome space, but it works today.\n\n>> 3.  The CLTV timeout should be symmetrical to avoid trying to game the\n>>     peer into closing. (Connor IIRC?).\n>\n> I know this has been discussed before, but I wonder the rationale for the original asymmetric design, and the rationale for the new symmetric design.\n\nThe original design does the minimum necessary (you *must* have a\nto-yourself delay to give time for the penalty tx to work).  But, when\ncombined with fee asymmetry (funder pays), it can lead the fundee to not\ncare whether it forces the funder to perform a unilateral, or does a\ngraceful mutual close.\n\nIt's not a major issue, but aligning incentives (to mutual close) makes\nsense if we're changing other things I think.\n\nCheers,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-10-12T07:08:48",
                "message_text_only": "Sent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Friday, October 12, 2018 2:36 PM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> ZmnSCPxj ZmnSCPxj at protonmail.com writes:\n>\n> > Good morning Rusty and list,\n> >\n> > > 1.  Rather than trying to agree on what fees will be in the future, we\n> > >     should use an OP_TRUE-style output to allow CPFP (Roasbeef)\n> > >\n> >\n> > My understanding is that this would require some base-layer changes at Bitcoin level first? At minimum IsStandard() modification, and I believe luke-jr suggested, to make a consensus rule that OP_TRUE would not be spendable beyond the block it appears in (i.e. it is used only for CPFP hooking) to reduce UTXO database size at lower layer.\n>\n> If you look further down, it's actually a P2WSH to \"OP_TRUE\". Wastes\n> some space, but it works today.\n\nAh, I see.  This will change again if the luke-jr proposal pushes through?\n\nWill robots arise which will attempt to claim as many OP_TRUE outputs as they can find, claiming them afterwards during very-low-fee periods?\n\n>\n> > > 3.  The CLTV timeout should be symmetrical to avoid trying to game the\n> > >     peer into closing. (Connor IIRC?).\n> > >\n> >\n> > I know this has been discussed before, but I wonder the rationale for the original asymmetric design, and the rationale for the new symmetric design.\n>\n> The original design does the minimum necessary (youmust have a\n> to-yourself delay to give time for the penalty tx to work). But, when\n> combined with fee asymmetry (funder pays), it can lead the fundee to not\n> care whether it forces the funder to perform a unilateral, or does a\n> graceful mutual close.\n>\n> It's not a major issue, but aligning incentives (to mutual close) makes\n> sense if we're changing other things I think.\n>\n\nI understand.  I suppose this is minor improvement.  It is also enabled somewhat by item 1 above (OP_TRUE CPFP hook).  Currently, advantage of asymmetric is that the other side can CPFP the transaction.  Now, with both having a CSV delay, neither side can CPFP, but with the CPFP hook anyone (including robots which might want to opportunistically steal OP_TRUE outputs during low-fee eras) can CPFP the transaction.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-10-13T02:59:02",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n> Sent with ProtonMail Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Friday, October 12, 2018 2:36 PM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n>\n>> ZmnSCPxj ZmnSCPxj at protonmail.com writes:\n>>\n>> > Good morning Rusty and list,\n>> >\n>> > > 1.  Rather than trying to agree on what fees will be in the future, we\n>> > >     should use an OP_TRUE-style output to allow CPFP (Roasbeef)\n>> > >\n>> >\n>> > My understanding is that this would require some base-layer changes at Bitcoin level first? At minimum IsStandard() modification, and I believe luke-jr suggested, to make a consensus rule that OP_TRUE would not be spendable beyond the block it appears in (i.e. it is used only for CPFP hooking) to reduce UTXO database size at lower layer.\n>>\n>> If you look further down, it's actually a P2WSH to \"OP_TRUE\". Wastes\n>> some space, but it works today.\n>\n> Ah, I see.  This will change again if the luke-jr proposal pushes through?\n>\n> Will robots arise which will attempt to claim as many OP_TRUE outputs as they can find, claiming them afterwards during very-low-fee periods?\n\nI hope so!  It's our technique to avoid polluting the UTXO set.\n\nCheers,\nRusty."
            },
            {
                "author": "Fabrice Drouin",
                "date": "2018-10-18T11:28:31",
                "message_text_only": "Hello,\n\n> 1.  Rather than trying to agree on what fees will be in the future, we\n >     should use an OP_TRUE-style output to allow CPFP (Roasbeef)\n\nWe could also use SIGHASH_ANYONECANPAY|SIGHASH_SINGLE for HTLC txs, without\nadding the \"OP_TRUE\" output to the commitment transaction. We would still\nneed the update_fee message to manage onchain fees for the commit tx (but\nnot the HTLC txs) but there would be no reason anymore to refuse fee rates\nthat are too high and channels would not get closed anymore when there's a\nspike in onchain fees.\n\nCheers,\n\nFabrice\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181018/955aa508/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-10-19T10:42:31",
                "message_text_only": "Fabrice Drouin <fabrice.drouin at acinq.fr> writes:\n> Hello,\n>\n>> 1.  Rather than trying to agree on what fees will be in the future, we\n>  >     should use an OP_TRUE-style output to allow CPFP (Roasbeef)\n>\n> We could also use SIGHASH_ANYONECANPAY|SIGHASH_SINGLE for HTLC txs, without\n> adding the \"OP_TRUE\" output to the commitment transaction. We would still\n> need the update_fee message to manage onchain fees for the commit tx (but\n> not the HTLC txs) but there would be no reason anymore to refuse fee rates\n> that are too high and channels would not get closed anymore when there's a\n> spike in onchain fees.\n\nAgreed, that was in the details below:\n\n- HTLC-timeout and HTLC-success txs sigs are \n  SIGHASH_ANYONECANPAY|SIGHASH_SINGLE, so you can Bring Your Own Fees.\n\nThe only problem with these proposals is that it requires you have an\navailable UTXO to make the CPFP etc.\n\nCheers,\nRusty."
            },
            {
                "author": "Conner Fromknecht",
                "date": "2018-10-20T16:12:00",
                "message_text_only": "Good morning everyone,\n\n> We could also use SIGHASH_ANYONECANPAY|SIGHASH_SINGLE\n> for HTLC txs, without adding the \"OP_TRUE\"\n> output to the commitment transaction\n\nDoesn\u2019t this require a non-zero number of HTLCs on the commitment txn? We\nwould still require the OP_TRUE if there are no HTLCs, right?\n\n>From my recollection, HTLC txns with an absolute timeout won\u2019t be accepted\nin the mempool until the expiry has matured. So the commitment would have\nto be held until that time before it\u2019s descendants can bump the fee rate I\nthink.\n\nI agree that we should probably modify the HTLC sighashes regardless,\nthough I wonder if it is a standalone replacement for OP_TRUE.\n\n> 3. The CLTV timeout should be symmetrical to avoid\n> trying to game the peer into closing. (Connor IIRC?).\n\nI believe Jimpo proposed this :)\n\nBest,\nConner\n\nOn Fri, Oct 19, 2018 at 03:43 Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> Fabrice Drouin <fabrice.drouin at acinq.fr> writes:\n> > Hello,\n> >\n> >> 1.  Rather than trying to agree on what fees will be in the future, we\n> >  >     should use an OP_TRUE-style output to allow CPFP (Roasbeef)\n> >\n> > We could also use SIGHASH_ANYONECANPAY|SIGHASH_SINGLE for HTLC txs,\n> without\n> > adding the \"OP_TRUE\" output to the commitment transaction. We would still\n> > need the update_fee message to manage onchain fees for the commit tx (but\n> > not the HTLC txs) but there would be no reason anymore to refuse fee\n> rates\n> > that are too high and channels would not get closed anymore when there's\n> a\n> > spike in onchain fees.\n>\n> Agreed, that was in the details below:\n>\n> - HTLC-timeout and HTLC-success txs sigs are\n>   SIGHASH_ANYONECANPAY|SIGHASH_SINGLE, so you can Bring Your Own Fees.\n>\n> The only problem with these proposals is that it requires you have an\n> available UTXO to make the CPFP etc.\n>\n> Cheers,\n> Rusty.\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181020/a6c610be/attachment.html>"
            },
            {
                "author": "Jim Posen",
                "date": "2018-10-20T20:36:59",
                "message_text_only": "Instead of leaving an extra output for CPFP, is it not sufficient to just\nsign all inputs with ANYONECANPAY and expect the sender to make an exact\noutput for the fees input? It would require an extra tx assuming they don't\nalready have a properly sized UTXO handy (which they may!), but I believe\nCPFP would require that as well. Am I missing something?\n\nI'm a fan of the symmetric delays because it simplifies the game theory\nanalysis, but I don't think the delays need to be the same for both\nparticipants (max of `to_self_delay` for both sides), just that the delay\nis applied equally regardless of who publishes the commitment tx. Like your\n`to_self_delay` can be what I specify and vice versa, what's the reason for\ntaking the max?\n\n-jimpo\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181020/2771eeef/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-10-23T10:43:26",
                "message_text_only": "Jim Posen <jim.posen at gmail.com> writes:\n> Instead of leaving an extra output for CPFP, is it not sufficient to just\n> sign all inputs with ANYONECANPAY and expect the sender to make an exact\n> output for the fees input? It would require an extra tx assuming they don't\n> already have a properly sized UTXO handy (which they may!), but I believe\n> CPFP would require that as well. Am I missing something?\n\nYeah, that would change the txid which the HTLC txs rely on :(\n\n> I'm a fan of the symmetric delays because it simplifies the game theory\n> analysis, but I don't think the delays need to be the same for both\n> participants (max of `to_self_delay` for both sides), just that the delay\n> is applied equally regardless of who publishes the commitment tx. Like your\n> `to_self_delay` can be what I specify and vice versa, what's the reason for\n> taking the max?\n\nIf you don't take the max, you're back into the Game Theory.  Your delay\nis short, mine is long, so I want you to drop to chain please.\n\nAlso, there's a fairness argument: if you want me to suffer a long\ndelay, you should too.\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Commitment Transaction Format Update Proposals?",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Fabrice Drouin",
                "Conner Fromknecht",
                "Rusty Russell",
                "Jim Posen",
                "ZmnSCPxj"
            ],
            "messages_count": 10,
            "total_messages_chars_count": 13754
        }
    },
    {
        "title": "[Lightning-dev] RFC: simplifications and suggestions on open/accept limits.",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-10-17T03:22:41",
                "message_text_only": "Hi all,\n\n        Everywhere in the protocol where we negotiate, we've had\nproblems: what do you do if you can't agree?  In most cases, we've\nsettled on defacto generally-accepted values which aren't mentioned\nanywhere in the spec (I've skimmed codebases below, looked at defaults).\nI'd like to re-examine these in light of our real-life experience and\nsee if we can simplify them, or at least make suggestions:\n\nfunding_satoshis\n----------------\n\nc-lightning: must be >= 1000 (after reserve subtracted)\nEclair: must be >= 100000\nlnd: any\n\nSUGGESTION: At 253 satoshi/kSipa, and dust at 546, 1000 is too low to be\nsane (one output would always be dust).  Eclair seems pessimistic\nthough; Should we suggest that any channel under 3 x min(our_dust_limit,\ntheir_dust_limit) SHOULD be rejected as too small (ie. min is 546*3).\n\n\ndust_limit_satoshis\n-------------------\n\nc-lightning: gives 546, accepts any.\nEclair: gives 546 (configurable), accepts >= 546.\nlnd: gives 573, accepts any.\n\n(Note: eclair's check here is overzealous, but friendly).\n\nSUGGESTION: we have to make this variable in future anyway (IRL it\ndepends on min_relay_fee, which in turn depends on backlog...).\nI'd love to just pick a number :(\n\n\nmax_htlc_value_in_flight_msat\n-----------------------------\nc-lightning: gives U64_MAX, accepts >= 1000000.\nEclair: gives 5000000000, accepts any.\nlnd: gives capacity - reserve, accepts >= 5 * htlc_minimum_msat.\n\nSUGGESTION: maybe drop it (must be U64_MAX?).\n\n\nchannel_reserve_satoshis\n------------------------\n\nc-lightning: gives 1% (rounded down), accepts <= capacity - 1000000.\nEclair: gives 1% (?), accepts <= 5% (configurable)\nlnd: gives 1%, accepts <= 20%\n\nSUGGESTION: require it be 1% (rounded down).\n\n\nhtlc_minimum_msat\n-----------------\n\nc-lightning: gives 0, accepts up to 0.1% of channel capacity.\nEclair: gives 1, accepts any.\nlnd: gives 1000, accepts any.\n\nSUGGESTION: maybe drop it (ie. must be 0?)\n\n\nto_self_delay\n-------------\n\nc-lightning: gives 144, accepts <= 2016\nEclair: gives 144, accepts <= 2000\nlnd: gives 144-2016 (proportional to funding), accepts <= 10000\n\nSUGGESTION: require it to be <= 2016.  Weaker suggestion: make it 2016,\nor use lnd's proportional formula.\n\n\nmax_accepted_htlcs\n------------------\n\nc-lightning: gives 483, accepts > 0.\nEclair: gives 30, accepts any.\nlnd: gives 483, accepts >= 5\n\nSUGGESTION: not sure why Eclair limits.  Maybe make it 483?\n\n\nminimum_depth\n-------------\n\nc-lightning: gives 3, accepts <= 10.\nEclair: gives 3, accepts any.\nlnd: gives 3-6 (scaling with funding), accepts any.\n\nSUGGESTION: This field is only a suggestion anyway; you can always wait\nlonger before sending funding_locked.  Let's limit it to <= 6?\n\n\nAre there any other areas of hidden consensus should illuminate and may\nsimplify?\n\nThanks!\nRusty."
            },
            {
                "author": "Gert-Jaap Glasbergen",
                "date": "2018-10-30T10:56:13",
                "message_text_only": "Hi Rusty,\n\nI think your suggestion for funding_satoshis makes sense. Making a too\nsmall channel ends up being completely consumed by fees and in practice\nnot usable. \n\nAs for htlc_minimum_msat I would not feel good about it being dropped.\nIt is the only protection measure I saw in the standard against\nproducing trimmed HTLCs. In my view the safe default is to set it above\nthe dust limit to avoid it to get trimmed, and effectively end up\nrouting trusted in-flight payment, that can't be enforced on-chain. \n\nThere might be reasons to define this differently per client as per\neveryone's own views, but I don't think it is a good idea to remove\nthis behavior negotiation entirely, because it would effectively force\nany client to accept HTLCs of any minimum size.\n\nAs for minimum_depth, I think this default should be chain-dependant.\nGiven the standard describes the possibility to use different chains,\nlimiting this to a fixed number in the standard seems like a risky\nchoice. Given that it's optional that would mean anyone that wants to\nenforce a higher value would just stop supplying the field.\n\nYour e-mail made me think of another aspect that I wanted to raise. Not\nsure if this is appropriate in this thread or you suggest me to start a\nseparate one, so feel free to correct me in that.\n\nWhile evaluating the specification, we noticed there is no way to\nnegotiate the desire to not support sub-satoshi payments. You can\nnegotiate not to accept HLTCs or channel balances below 1000 msat, but\nthere's no way to negotiate you only accept multiples of 1000 msat\n(i.e. only whole satoshis). So even with a minimum of 1000 msat I am\nstill expected to route payments of 1291 msat, which contains a sub-\nsatoshi part.\n\nWould it be something to consider? Given the fact that any part below\n1000 msat cannot be enforced on-chain, I would prefer giving users the\nability to opt out of that. There currently is none.\n\nSo, either a transaction_min_msat_multiple (set to 1000 for only\naccepting whole satoshis) or accept_subsatoshi (1/0). The latter seems\nmore useful since you probably wouldn't give the former any other value\nthan either 1 or 1000.\n\nGert-Jaap.\n\n\nOn Wed, 2018-10-17 at 13:52 +1030, Rusty Russell wrote:\n> Hi all,\n> \n>         Everywhere in the protocol where we negotiate, we've had\n> problems: what do you do if you can't agree?  In most cases, we've\n> settled on defacto generally-accepted values which aren't mentioned\n> anywhere in the spec (I've skimmed codebases below, looked at defaults).\n> I'd like to re-examine these in light of our real-life experience and\n> see if we can simplify them, or at least make suggestions:\n> \n> funding_satoshis\n> ----------------\n> \n> c-lightning: must be >= 1000 (after reserve subtracted)\n> Eclair: must be >= 100000\n> lnd: any\n> \n> SUGGESTION: At 253 satoshi/kSipa, and dust at 546, 1000 is too low to be\n> sane (one output would always be dust).  Eclair seems pessimistic\n> though; Should we suggest that any channel under 3 x min(our_dust_limit,\n> their_dust_limit) SHOULD be rejected as too small (ie. min is 546*3).\n> \n> \n> dust_limit_satoshis\n> -------------------\n> \n> c-lightning: gives 546, accepts any.\n> Eclair: gives 546 (configurable), accepts >= 546.\n> lnd: gives 573, accepts any.\n> \n> (Note: eclair's check here is overzealous, but friendly).\n> \n> SUGGESTION: we have to make this variable in future anyway (IRL it\n> depends on min_relay_fee, which in turn depends on backlog...).\n> I'd love to just pick a number :(\n> \n> \n> max_htlc_value_in_flight_msat\n> -----------------------------\n> c-lightning: gives U64_MAX, accepts >= 1000000.\n> Eclair: gives 5000000000, accepts any.\n> lnd: gives capacity - reserve, accepts >= 5 * htlc_minimum_msat.\n> \n> SUGGESTION: maybe drop it (must be U64_MAX?).\n> \n> \n> channel_reserve_satoshis\n> ------------------------\n> \n> c-lightning: gives 1% (rounded down), accepts <= capacity - 1000000.\n> Eclair: gives 1% (?), accepts <= 5% (configurable)\n> lnd: gives 1%, accepts <= 20%\n> \n> SUGGESTION: require it be 1% (rounded down).\n> \n> \n> htlc_minimum_msat\n> -----------------\n> \n> c-lightning: gives 0, accepts up to 0.1% of channel capacity.\n> Eclair: gives 1, accepts any.\n> lnd: gives 1000, accepts any.\n> \n> SUGGESTION: maybe drop it (ie. must be 0?)\n> \n> \n> to_self_delay\n> -------------\n> \n> c-lightning: gives 144, accepts <= 2016\n> Eclair: gives 144, accepts <= 2000\n> lnd: gives 144-2016 (proportional to funding), accepts <= 10000\n> \n> SUGGESTION: require it to be <= 2016.  Weaker suggestion: make it 2016,\n> or use lnd's proportional formula.\n> \n> \n> max_accepted_htlcs\n> ------------------\n> \n> c-lightning: gives 483, accepts > 0.\n> Eclair: gives 30, accepts any.\n> lnd: gives 483, accepts >= 5\n> \n> SUGGESTION: not sure why Eclair limits.  Maybe make it 483?\n> \n> \n> minimum_depth\n> -------------\n> \n> c-lightning: gives 3, accepts <= 10.\n> Eclair: gives 3, accepts any.\n> lnd: gives 3-6 (scaling with funding), accepts any.\n> \n> SUGGESTION: This field is only a suggestion anyway; you can always wait\n> longer before sending funding_locked.  Let's limit it to <= 6?\n> \n> \n> Are there any other areas of hidden consensus should illuminate and may\n> simplify?\n> \n> Thanks!\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> \n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 659 bytes\nDesc: This is a digitally signed message part\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181030/1eeb9ab7/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "RFC: simplifications and suggestions on open/accept limits.",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Gert-Jaap Glasbergen"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 8482
        }
    },
    {
        "title": "[Lightning-dev] The problem of false positives for double spend attacks",
        "thread_messages": [
            {
                "author": "Margherita Favaretto",
                "date": "2018-10-23T22:18:00",
                "message_text_only": "Dear Lighning-dev group,\n\nI am Margherita Favaretto, a Master student of Cyber Security at the Technical University of Denamark (DTU). I'm currently in San Francisco for one month, to advance with my academic research on Lightning Network by taking part to the networking events that are happening here.\n\nMy research is focused on a remediation protocol for Lightning Network double-spend attacks. More in detail, my research wants to mitigate the problem of false positives (e.g. software errors). Today, attacking nodes get excluded from the network, without any distinction between a software bug or an \"Eve\" malicious node.\n\nThe solution, that I'm calling a \"trusted remediation\" gossip protocol, wants to solve: the identification of a false positive; the communication to other nodes; and the remediation payments mechanism. I would really appreciate an open feedback about the relevance of this issue, and which is the best way to be in contact with you.\n\nYour help would help me to focus my research on the right issues, and open a discussion about my assumptions and the related work that could help me. The goal is to give my contribution to this project and be actively part of the group as an independent researcher.\n\nAny thoughts/suggestions are really appreciated. I'm available for possible collaborations outside of this scope with people interested on this research topic.\n\nThank you in advance,\n\nMargherita Favaretto\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181023/d3f812f8/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-10-24T06:26:04",
                "message_text_only": "Good morning Margherita,\n\nThere are no possible double-spend attacks on Lightning Network.\n\nYou cannot double-spend your funds unless the other end of the channel agrees to the double-spending.  And what will happen is that the other end of the channel will in fact effectively lose money.  Assuming the other end is rational and has no interest in helping you, they would not agree to a double-spend.  If they are rational and are interested in helping you, they will ask for a invoice and give you the money using existing invoice-payment mechanisms.\n\nSo, please consider to focus on other things, like an atomic multipath protocol that supports contingent payment (pay for secret) protocol, or trustless watchtowers.  Or do you refer to publication of revoked commitment transactions?\n\nFurther, the \"trusted\" in \"trusted remediation\" is a severe negative and is unlikely to be accepted.\n\nIf the problem you are trying to solve, is the inadvertent publication of revoked commitment transactions, then the correct solution is not to have revocable transactions in the first place, i.e. eltoo.  While it can be argued that it would take time for needed features of eltoo to appear on the blockchain layer (SIGHASH_NOINPUT_UNSAFE), it would also take time to implement \"trusted remediation\", by which time the problem could be solved by switching over to eltoo.\n\nSincerely,\nAmkG\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Wednesday, October 24, 2018 6:18 AM, Margherita Favaretto <s170065 at student.dtu.dk> wrote:\n\n> Dear Lighning-dev group,\n>\n> I am Margherita Favaretto, a Master student of Cyber Security at the Technical University of Denamark (DTU). I'm currently in San Francisco for one month, to advance with my academic research on Lightning Network by taking part to the networking events that are happening here.\n>\n> My research is focused on a remediation protocol for Lightning Network double-spend attacks. More in detail, my research wants\n>\n> to mitigate the problem of false positives (e.g. software errors). Today, attacking nodes get\n>\n> excluded from the network, without any distinction between a software bug or an \"Eve\" malicious node.\n>\n> The solution, that I'm calling a \"trusted remediation\" gossip protocol, wants to solve: the\n>\n> identification of a false positive; the communication to other nodes; and the remediation payments mechanism.\n>\n> I would really appreciate an open feedback about the relevance of this issue, and which is the best way to be in contact with you.\n>\n> Your help would help me to focus my research on the right issues, and open a discussion about my assumptions and the related work that could help me. The goal is to give my contribution to this project and be actively part of the group as an independent researcher.\n>\n> Any thoughts/suggestions are really appreciated. I'm available for possible collaborations outside of this scope with people interested on this research topic.\n>\n> Thank you in advance,\n>\n> Margherita Favaretto\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181024/0f701dd5/attachment.html>"
            },
            {
                "author": "Alejandro Ranchal Pedrosa",
                "date": "2018-10-24T08:37:36",
                "message_text_only": "Hi Margherita,\n\n\ncan you be a bit more specific about what you mean by double-spend \nattacks?. A double-spend is not an attack that can be performed acting \nsolely on the Lightning Network, and as far as I know there are no nodes \nbeing banned because of this.\n\n\nIf there are nodes that are being banned for tampering or sending wrong \ninformation on the p2p Lightning Network (such as changing \nchannel_announcements or creating others that are wrong) is something I \nam not completely sure (maybe in some implementations? or is it \nspecified in BOLT). In any case, this is not a double-spending attack.\n\n\nBest,\n\n\nAlejandro.\n\n\nOn 24/10/2018 00:18, Margherita Favaretto wrote:\n> Dear Lighning-dev group,\n> I am Margherita Favaretto, a Master student of Cyber Security at the \n> Technical University of Denamark (DTU). I'm currently in San Francisco \n> for one month, to advance with my academic research on Lightning \n> Network by taking part to the networking events that are happening here.\n> My research is focused on a remediation protocol for Lightning Network \n> double-spend attacks. More in detail, my research wantsto mitigate the \n> problem of false positives (e.g. software errors). Today, attacking \n> nodes get excluded from the network, without any distinction between a \n> software bug or an \"Eve\" malicious node.\n> The solution, that I'm calling a \"trusted remediation\" gossip \n> protocol, wants to solve: the identification of a false positive; the \n> communication to other nodes; and the remediation payments mechanism. \n> I would really appreciate an open feedback about the relevance of this \n> issue, and which is the best way to be in contact with you.\n> Your help would help me to focus my research on the right issues, and \n> open a discussion about my assumptions and the related work that could \n> help me. The goal is to give my contribution to this project and be \n> actively part of the group as an independent researcher.\n> Any thoughts/suggestions are really appreciated. I'm available for \n> possible collaborations outside of this scope with people interested \n> on this research topic.\n> Thank you in advance,\n> Margherita Favaretto\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181024/1dc3765b/attachment.html>"
            },
            {
                "author": "Margherita Favaretto",
                "date": "2018-10-26T21:31:58",
                "message_text_only": "Good morning,\n\n\nThanks for the reply to my email and for the very helpful suggestions.\n\nEltoo is a very attractive solution and I've already spent the last days studying it.\n\n\nWith the regards of your queries, I\u2019m trying to solve the inadvertent publication of revoked commitment transactions, and a remediation that can avoid the channel termination penalty.\n\nMy solution aims to keep the remediation inside the Lightning network, avoiding time and cost of an additional on-chain transaction.\n\nI\u2019m looking forward to finding more into the Eltoo documentation, and the possibilities provided by contingent payments.\n\n\nMargherita\n\n________________________________\nDa: lightning-dev-bounces at lists.linuxfoundation.org <lightning-dev-bounces at lists.linuxfoundation.org> per conto di Alejandro Ranchal Pedrosa <alejandro.ranchal_pedrosa at etu.upmc.fr>\nInviato: mercoled\u00ec 24 ottobre 2018 10:37:36\nA: lightning-dev at lists.linuxfoundation.org\nOggetto: Re: [Lightning-dev] The problem of false positives for double spend attacks\n\n\nHi Margherita,\n\n\ncan you be a bit more specific about what you mean by double-spend attacks?. A double-spend is not an attack that can be performed acting solely on the Lightning Network, and as far as I know there are no nodes being banned because of this.\n\n\nIf there are nodes that are being banned for tampering or sending wrong information on the p2p Lightning Network (such as changing channel_announcements or creating others that are wrong) is something I am not completely sure (maybe in some implementations? or is it specified in BOLT). In any case, this is not a double-spending attack.\n\n\nBest,\n\n\nAlejandro.\n\n\nOn 24/10/2018 00:18, Margherita Favaretto wrote:\n\nDear Lighning-dev group,\n\nI am Margherita Favaretto, a Master student of Cyber Security at the Technical University of Denamark (DTU). I'm currently in San Francisco for one month, to advance with my academic research on Lightning Network by taking part to the networking events that are happening here.\n\nMy research is focused on a remediation protocol for Lightning Network double-spend attacks. More in detail, my research wants to mitigate the problem of false positives (e.g. software errors). Today, attacking nodes get excluded from the network, without any distinction between a software bug or an \"Eve\" malicious node.\n\nThe solution, that I'm calling a \"trusted remediation\" gossip protocol, wants to solve: the identification of a false positive; the communication to other nodes; and the remediation payments mechanism. I would really appreciate an open feedback about the relevance of this issue, and which is the best way to be in contact with you.\n\nYour help would help me to focus my research on the right issues, and open a discussion about my assumptions and the related work that could help me. The goal is to give my contribution to this project and be actively part of the group as an independent researcher.\n\nAny thoughts/suggestions are really appreciated. I'm available for possible collaborations outside of this scope with people interested on this research topic.\n\nThank you in advance,\n\nMargherita Favaretto\n\n\n\n\n\n\n_______________________________________________\nLightning-dev mailing list\nLightning-dev at lists.linuxfoundation.org<mailto:Lightning-dev at lists.linuxfoundation.org>\nhttps://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181026/182bd40d/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "The problem of false positives for double spend attacks",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Margherita Favaretto",
                "Alejandro Ranchal Pedrosa",
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 10955
        }
    },
    {
        "title": "[Lightning-dev] Wireshark plug-in for Lightning Network(BOLT) protocol",
        "thread_messages": [
            {
                "author": "tomokio203 at gmail.com",
                "date": "2018-10-26T10:39:40",
                "message_text_only": "Hello lightning network developers.\nNayuta team is developing Wireshark plug-in for Lightning Network(BOLT)\nprotocol.\nhttps://github.com/nayutaco/lightning-dissector\n\nIt\u2019s alpha version, but it can decode some BOLT message.\nCurrently, this software works for Nayuta\u2019s implementation(ptarmigan) and\n\u00c9clair.\nWhen ptarmigan is compiled with some option, it write out key information\nfile. This Wireshark plug-in decode packet using that file.\nWhen you use \u00c9clair, this software parse log file.\n\nThrough our development experience, interoperability test is time consuming\ntask.\nIf people can see communication log of BOLT message on same format (.pcap),\nit will be useful for interoperability test.\n\nOur proposal:\nEvery implementation has compile option which enable output key information\nfile.\n\nWe are glad if this project is useful for lightning network eco-system.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181026/cab82010/attachment.html>"
            },
            {
                "author": "Fabrice Drouin",
                "date": "2018-10-29T18:49:33",
                "message_text_only": "Nice work, thank you!\n\nOn Fri, 26 Oct 2018 at 17:37, <tomokio203 at gmail.com> wrote:\n>\n> Hello lightning network developers.\n> Nayuta team is developing Wireshark plug-in for Lightning Network(BOLT) protocol.\n> https://github.com/nayutaco/lightning-dissector\n>\n> It\u2019s alpha version, but it can decode some BOLT message.\n> Currently, this software works for Nayuta\u2019s implementation(ptarmigan) and \u00c9clair.\n> When ptarmigan is compiled with some option, it write out key information file. This Wireshark plug-in decode packet using that file.\n> When you use \u00c9clair, this software parse log file.\n>\n> Through our development experience, interoperability test is time consuming task.\n> If people can see communication log of BOLT message on same format (.pcap), it will be useful for interoperability test.\n>\n> Our proposal:\n> Every implementation has compile option which enable output key information file.\n>\n> We are glad if this project is useful for lightning network eco-system.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            }
        ],
        "thread_summary": {
            "title": "Wireshark plug-in for Lightning Network(BOLT) protocol",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "tomokio203 at gmail.com",
                "Fabrice Drouin"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 2220
        }
    },
    {
        "title": "[Lightning-dev] [RELEASE] c-lightning 0.6.2: The Consensus Loving Nasal Daemon",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-10-26T20:45:21",
                "message_text_only": "We're pleased to announce c-lightning 0.6.2, named by @practicalswift.\n\nhttps://github.com/ElementsProject/lightning/releases/tag/v0.6.2\nOR https://launchpad.net/~cdecker/+archive/ubuntu/clightning (SOON)\n\nWe HIGHLY RECOMMEND you upgrade to this release NOW; it will improve\noverall network health!\n\nHighlights for c-lightning users:\n\n* Invoices now contain an hint on a good incoming channel to use, for\n  more reliable payments (\"RouteBoost\").\n* listforwards command to show all forwarded HTLCs, and getinfo shows\n  total fees (both only from upgrade only)\n* Reduced logging spam at debug level.\n* A multitude of bugfixes which make things generally much nicer.\n\nHighlights for the network\n\n* We no longer spam our peers with dead channels.\n* Redundant gossip updates are completely eliminated.\n* We advertise htlc_maximum_msat for our channels as per recent BOLT update.\n\nInternal Improvements\n\n* Significant optimization in JSON command response.\n* connectd and hsmd are now part of the growing literate documentation effort.\n* Testsuite now uses flask to override bitcoind responses for testing.\n\nMore details can be found in the CHANGELOG:\n\nhttps://github.com/ElementsProject/lightning/blob/v0.6.2/CHANGELOG.md\n\nContributions\n-------------\n\nWe're grateful for all the bug reports and suggestions and your patience\nas we sometimes struggled to address them: please keep them coming!\n\nSince 0.6.1 we've had 239 commits from 13 different authors, 3 of whom were first-time c-lightning contributors:\n\n    @alan8325\n    Amin Shah Gilani\n    @trueserve\n\nThis is down from last release, but it was a much shorter timeline too!\n\nCheers,\nRusty, Christian and ZmnSCPxj."
            },
            {
                "author": "Rusty Russell",
                "date": "2018-10-27T00:54:02",
                "message_text_only": "Rusty Russell <rusty at rustcorp.com.au> writes:\n> We're pleased to announce c-lightning 0.6.2, named by @practicalswift.\n>\n> https://github.com/ElementsProject/lightning/releases/tag/v0.6.2\n> OR https://launchpad.net/~cdecker/+archive/ubuntu/clightning (SOON)\n\nSorry, https://launchpad.net/~lightningnetwork/+archive/ubuntu/ppa\n\n(Technically that's at -rc1, but the only difference is the tag and\nCHANGELOG.md change).\n\nCheers,\nRusty.\nPS.  Thanks to those who have already upgraded!"
            }
        ],
        "thread_summary": {
            "title": "c-lightning 0.6.2: The Consensus Loving Nasal Daemon",
            "categories": [
                "Lightning-dev",
                "RELEASE"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 2148
        }
    },
    {
        "title": "[Lightning-dev] Improving payment UX with low-latency route probing",
        "thread_messages": [
            {
                "author": "Fabrice Drouin",
                "date": "2018-10-31T17:28:58",
                "message_text_only": "Context\n======\n\nSent payments that remain pending, i.e. payments which have not yet\nbeen failed or fulfilled, are currently a major UX challenge for LN\nand a common source of complaints from end-users.\nWhy payments are not fulfilled quickly is not always easy to\ninvestigate, but we've seen problems caused by intermediate nodes\nwhich were stuck waiting for a revocation, and recipients who could\ntake a very long time to reply with a payment preimage.\nIt is already possible to partially mitigate this by disconnecting\nfrom a node that is taking too long to send a revocation (after 30\nseconds for example) and reconnecting immediately to the same node.\nThis way pending downstream HTLCs can be forgotten and the\ncorresponding upstream HTLCs failed.\n\nProposed changes\n===============\n\nIt should be possible to provide a faster \"proceed/try another route\"\nanswer to the sending node using probing with short timeout\nrequirements: before sending the actual payment it would first send a\n\"blank\" probe request, along the same route. This request would be\nsimilar to a payment request, with the same onion packet formatting\nand processing, with the additional requirements that if the next node\nin the route has not replied within the timeout period (typically a\nfew hundred milliseconds) then the current node will immediately send\nback an error message.\n\nThere could be several options for the probe request:\n- include the same amounts and fee constraints than the actual payment request.\n- include no amount information, in which case we're just trying to\n\"ping\" every node on the route.\n\nImplementation\n============\n\nI would like to discuss the possibility of implementing this with a \"0\nsatoshi\" payment request that the receiving node would generate along\nwith the real one. The sender would first try to \"pay\" the \"0 satoshi\"\nrequest using the route it computed with the actual payment\nparameters. I think that it would not require many changes to the\nexisting protocol and implementations.\nNot using the actual amount and fees means that the actual payment\ncould fail because of capacity issues but as long as this happens\nquickly, and it should since we checked first that all nodes on the\nroute are alive and responsive, it still is much better than \u201cstuck\u201d\npayments.\nAnd it would not help if a node decides to misbehave, but would not\nmake things worse than they are now (?)\n\nCheers,\nFabrice"
            }
        ],
        "thread_summary": {
            "title": "Improving payment UX with low-latency route probing",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Fabrice Drouin"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2399
        }
    },
    {
        "title": "[Lightning-dev] Recovering protocol for Lightning network",
        "thread_messages": [
            {
                "author": "Margherita Favaretto",
                "date": "2018-10-31T23:58:57",
                "message_text_only": "Good morning dev-lightning community,\n\nLast weekend, I had the opportunity to take part in \"LightningHackdayNYC\". It was an incredible event, thanks to all organizers, to all speakers and all people available to share all own knowledge.\nDiscussing with the people of the community, I could define better the problem that I'm focusing on and have some ideas for the solution.\nI've created a project on GitHub: https://github.com/margheritafav/LightningNetworkProject , where you could find a draft of my research, and also you are welcome to add your comments and feedback.\n\n\nTo recap, the aim of the project is realizing a recovering protocol for Lightning Network. As someone suggested me in the previous e-mails, Eltoo is already solving this problem in part. With Eltoo, the nodes are able to share the last status of the channel, so if one of the two nodes loses some information, it can simply ask to the other node to share the most recent status. Unfortunately, this mechanism doesn't include the case that the other node doesn't share the last transaction, but instead an older one, more favourable for own balance. My project aims to solve this particular issue and make the protocol more solid to face completely the case of a false positive node.\n\nIdea: The main idea of the design is using the other connected nodes as a back-up of own recent status.\nIf a node A is connected to a node B and a node C, for each transaction between A and B, A sends an encrypted information, regarding the last commitment transaction with B, to C. For each commitment transaction with C, A sends an encrypted information, regarding the last commitment transaction with C, to B.\nIn this way, if A loses the last transactions, she may ask the information to the other connected node and update the status.\n\nI think that this idea can solve the current lack in Eltoo and I'm planning to analyze more this solution in the next days. Any thoughts/suggestions are really appreciated to proceed in the wisest way and find a solution that can also cover all your needs. If someone of you is interested in this research, I'm available to share more details about the design of my idea and I'm open to discussion. Moreover, if someone is already working on this research topic, please not hesitate to write me for possible collaborations to work together.\n\n\nThank you in advance,\nMargherita Favaretto\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20181031/95a78dac/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Recovering protocol for Lightning network",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Margherita Favaretto"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2569
        }
    }
]