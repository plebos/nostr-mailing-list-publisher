[
    {
        "title": "[Lightning-dev] Remove Description From Bolt11 Invoices",
        "thread_messages": [
            {
                "author": "armdxxi",
                "date": "2022-02-01T16:22:05",
                "message_text_only": "Martin,\n\nThank you for the thoughtful analysis and game theory on this.\n\n> impossibility to prove payment for goods or services making arbitration hard or impossible\n\nPreimages and invoices still prove payment to a specific node. Specific items, maybe not, but maybe a use case for keeping description hash for this.\n\n> 0. exchange doesn't enforce description\n> 1. exchange does enforce description\n\nIf I understand your case 0 and 1 distinctions, the envisioned scenario is that this AOPP-style regulation gets restrictive enough that nobody can use regulated custodians to make payments. Their only option is to withdraw to their node and then make a payment from there. Thus, their payments and spending habits are protected.\n\nWhy do we need to comply with extreme node level KYC enforcement to make this the case? The enforcement won\u2019t stop with the scenario you\u2019ve described if everyone is complying and supporting these regulations in the first place. They will get worse. They are already talking about how to DOX the sender of a payment by signing a message in a TLV field.\n\n> Also node IDs could be rotated.\n\nHow so? Close down all channels, shut down node, coinjoining utxo\u2019s and spin up a new one? That would be quite a costly procedure, both in time & effort as well as monetarily. Especially if this were to occur on a large scale.\n\nWhen we\u2019re talking about users still using custodians, the barrier of entry for managing all this is even higher.\n\n> \"KYC\" of a private node ID is completely meaningless\n\nThis will be the realization of the regulators as well. This also assumes there are protective mechanisms in place to make sure a \u201cprivate node\u201d is actually private because that\u2019s not the case and there are enough gotchas to break down that assumption.\n\n> An operator of popular public node can just connect to self and pretend it's some random person routing through him. It's essentially impossible to prove it's not the case.\n\nI think this is a good thing to do but if not done correctly, there can be enough correlations to break this down. Ideally, it\u2019s like you\u2019ve said, \u201cpopular public node\u201d. What about everyone else?\n\n> it could be the case here that it's a good way to turn regulations against the regulators and it could outweigh the cons.\n\nIt\u2019s an interesting scenario and thought process to see how to turn it positive, but in the interim - this is happening now. There is not a hard & fast rule that no custodian is processing anything except to the user\u2019s (assumingly) private nodes. Nodes are being KYC\u2019d now. Invoices and payment reasons are being aggregated in mass. How do we stop this now except by removing the ability for it to happen?\n\nRegards,\narmdxxi\n\nOn 31 Jan 2022, at 9:10, Martin Habov\u0161tiak wrote:\n\n> (sorry for double message, wrong button)\n>\n> Hi,\n>\n> I object to the idea that AOPP-like verification is harmful *to lightning*, quite contrary, it's beneficial! Also removing description creates another problem: impossibility to prove payment for goods or services making arbitration hard or impossible.\n>\n> Why it's beneficial?\n>\n> Suppose there's a dissident in a dictatorship country wanting to buy banned goods. He pays using LN. There are two possibilities:\n> 0. exchange doesn't enforce description\n> 1. exchange does enforce description\n>\n> Let's look at case 0:\n> The dissident, who happens to not be that knowledgeable about security buys sats at an exchange and inputs the destination invoice from whoever he pays directly into the exchange. The exchange logs this along with the identity. Some time later the node ID being paid for banned goods leaks (very likely for public nodes) and the tyrants use this to track down dissidents. The dissident is screwed.\n>\n> Case 1:\n> The dissident withdraws to his non-custodial wallet (can't do anything else) which he then uses to pay. The exchange can not possibly see where the payment went from non-custodial wallet or if it was even sent away. Recipients don't know identities of senders so no matter what information leaks, it's impossible to link the payment.\n>\n> The biggest real problem with the enforcement is the fact that invoices leak txids of private channels even though they shouldn't have to. *This* needs to be fixed, really. Also node IDs could be rotated.\n>\n> Assuming it's fixed, \"KYC\" of a private node ID is completely meaningless. The exchange can not see where the sats ultimately end up - either LN or chain. It's essentially equivalent to assigning meaningless random number to each transaction.\n>\n> This assumes \"private\" channels but has a simple workaround for public nodes too. An operator of popular public node can just connect to self and pretend it's some random person routing through him. It's essentially impossible to prove it's not the case.\n>\n> Note that this whole reasoning doesn't apply to BTC chain as addresses don't have such strong privacy properties but could be applied to e.g. Monero (maybe a bit weaker guarantee; not endorsing it).\n>\n> I'm not saying that we should (not) proactively support these efforts, since accepting regulations is bad precedent but it could be the case here that it's a good way to turn regulations against the regulators and it could outweigh the cons.\n>\n> Hope I'm clear enough. Cheers!\n> Martin\n>\n> On Mon, Jan 31, 2022, 06:07 armdxxi via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n>\n>> All,\n>>\n>> In light of recent AOPP concerns[0] where custodial users have to sign a message from an address to prove that it is theirs when withdrawing from highly regulated exchanges, I thought it was important to bring up that this is happening in the Lightning space as well.\n>>\n>> The tagged field d provides both payers and payees with a description of what the transaction is for. When a Lightning Node creates a BOLT11 invoice with a description, this is signed. The signature verification process validates that it came from a specific node and that it is unaltered.\n>>\n>> The problem is that this is being exploited by bad actors in the regulated space. Unsuspecting users are going along with it not knowing the repercussions.\n>>\n>> KYC Node Verification\n>>\n>> Companies like Bottlepay[1] are forcing some users to verify their node by creating a specialized invoice. They ask the user to put PII in the description and give the signed invoice to the service. Afterwards, a database of KYC'd users and their nodes may be stored and shared with 3rd parties, regulators, and governments.\n>>\n>> Given that the Lightning Network is a reputation-based system without an easy way to handle rotations, this has lasting effects if this practice were to scale out to all providers. At least with AOPP, one may spin up a new on-chain address with ease and attempt to mitigate linkage via coinjoin.\n>>\n>> This alone is enough to recommend wallet devs to remove the ability for users to unknowingly sign statements with their node. Just like with the widespread removal of AOPP from hardware/software wallets, exchanges may stop expecting that users are capable of handing over this information with ease.\n>>\n>> Payment Reason Aggregation\n>>\n>> On the payment receiver side, a user may add a description for their reference later on. In an ideal world, only the payer and payee are the ones that know the reason for the payment. However, given the current reliance on custodians today, these 3rd parties can see and store this information.\n>>\n>> A good thread[2] highlights some of these concerns. If exchanges are relaying invoices to chain analytic companies[3], this can be pretty revealing in aggregation.\n>>\n>> What they'd know solely on processing Bolt11 invoice data:\n>>\n>> -  Which internal UserID is paying\n>> -  Which Lightning Node is receiving a payment\n>> -  Amount\n>> -  Payment Reason\n>>\n>> This information collected in bulk will allow them to map out risk scores across the network. These risk scores will lead to censorship problems. Additionally, they may share suspected node owners and their known transactions with malicious parties.\n>>\n>> The onus is on the receiver to not create invoices that reveal personal information. But how is a user supposed to know that it could end up being collected by 3rd party analytic aggregators? In the end, users may just want to tag the invoice and store it internally for their reference. Even custodial wallet developers don't realize the repercussions to invoice descriptions[4].\n>>\n>> Given this, one suggestion I have is to clearly communicate that the information users put in invoices can be verified by 3rd parties. Ideally wallet devs should remove description completely.\n>>\n>> Description Hash\n>>\n>> Using the tagged field description hash h instead of description d might help but there are a few problems.\n>>\n>> For one, there's a transport problem that's not handled by the BOLT11 specification. From the spec: the transport mechanism for the description in that case is transport specific and not defined here.\n>>\n>> A payer's wallet client needs to be able to receive two values from the payee now. Both the invoice with the description hash and the description text itself. This could happen via QR code in the typical flow today, but the problem is that information is still parsed by the payer's wallet.\n>>\n>> So if the payer's wallet is a custodian, the custodian is still capable of knowing and relaying both Bolt11 Invoice and the unhashed description. The benefit is that they may choose not to collect this description information. Though it still leaves the door open for bad actors.\n>>\n>> Further, a salt would need to be added to descriptions for common payment reasons to not be guessed.\n>>\n>> In the end, description hash is better than description, but there are UX considerations that may not solve the problem. My suggestion is to save the description to the wallet database instead of putting it in the invoice. Payers should be provided with a similar description text box that may be saved in their database. This gives both users the ability to conceal the real reason even if their wallet is a custodian.\n>>\n>> Summary\n>>\n>> There's enough exploitation currently happening with Bolt11 invoices that we should be concerned about this. My recommendation is to remove the ability for users to shoot themselves in the foot. This can happen at the application layer today by removing descriptions from wallets. The lack of description support will help hinder the ability for mass surveillance in the Lightning space.\n>>\n>> Regards,\n>> armdxxi\n>>\n>> Links:\n>> [0] https://bitcoinmagazine.com/technical/bitcoin-aopp-and-the-swiss-travel-rule\n>> [1] https://web.archive.org/web/20210616100214/https://help.bottlepay.com/en/articles/5303125-why-and-how-do-i-verify-my-node\n>> [2] https://twitter.com/niftynei/status/1479154453777465344\n>> [3] https://blog.chainalysis.com/reports/lightning-network-support/\n>> [4] https://twitter.com/MattAhlborg/status/1435350678814302211\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220201/e31ef62b/attachment-0001.html>"
            },
            {
                "author": "Martin Habov\u0161tiak",
                "date": "2022-02-01T18:10:45",
                "message_text_only": "> Specific items, maybe not, but maybe a use case for keeping description\n> hash for this.\n>\n> You can't keep hash without making it possible to use it for AOPP-style\nverification. The exchanges would just ask users to make invoices with that\nhash.\n\n> the envisioned scenario is that this AOPP-style regulation gets\n> restrictive enough that nobody can use regulated custodians to make\n> payments.\n>\nNot necessarily, it could also be just so frequent people develop muscle\nmemory and avoid even trying to pay from exchanges.\n\n> Why do we need to comply with extreme node level KYC enforcement to make\n> this the case?\n>\nI don't know if we *need* it maybe better education can replace it but\nsurely it helps.\n\n> The enforcement won\u2019t stop with the scenario you\u2019ve described if everyone\n> is complying and supporting these regulations in the first place.\n>\nIn a way it was too late when KYC came to exist. Note that slippery slope\ncan be fallacious argument and I think it's the case here. The specific\nregulation is only about proving that you aren't paying someone else. The\nintention is for exchanges to not have to register as banks. The objective\nis NOT to track people.\n\n> They will get worse. They are already talking about how to DOX the sender\n> of a payment by signing a message in a TLV field.\n>\nThe only serious discussion I remember seeing about this proposed to make\nit unlinkable. The recipient would not know which node it was.\n\n> Also node IDs could be rotated.\n>\n> How so? Close down all channels, shut down node, coinjoining utxo\u2019s and\n> spin up a new one?\n>\n\nNo, it literally only requires changing the receiver implementation to\naccept messages for any known node ID. The only problem is channel id being\nstatic and we need some protocol for private channels to generate new IDs.\n\n> \"KYC\" of a private node ID is completely meaningless\n>\n> This will be the realization of the regulators as well.\n>\nWhen they get people smart enough to understand it they will also\nunderstand the only solutions are ban Bitcoin completely or give up. We\ncan't change it anyway.\n\n> This also assumes there are protective mechanisms in place to make sure a\n> \u201cprivate node\u201d is actually private because that\u2019s not the case and there\n> are enough gotchas to break down that assumption.\n>\nThat's also what I said. I encourage you to work on these instead of\nremoving description.\n\n> An operator of popular public node can just connect to self and pretend\n> it's some random person routing through him. It's essentially impossible to\n> prove it's not the case.\n>\n> I think this is a good thing to do but if not done correctly, there can be\n> enough correlations to break this down.\n>\nThe only way I can see it being done incorrectly is user entering invoice\nfrom the public node where he shouldn't. Can you see any other?\n\n> Ideally, it\u2019s like you\u2019ve said, \u201cpopular public node\u201d. What about everyone\n> else?\n>\nEven unpopular public nodes have plausible deniability even though they\nmight have harder time. Fixing private nodes should be among top priorities.\n\n> There is not a hard & fast rule that no custodian is processing anything\n> except to the user\u2019s (assumingly) private nodes.\n>\n> Not a big deal except for uninformed dissidents. People who break unjust\ndictatorship laws should be more careful. This can't be changed anyway.\n\n> Nodes are being KYC\u2019d now. Invoices and payment reasons are being\n> aggregated in mass. How do we stop this now except by removing the ability\n> for it *to* happen?\n>\nWe don't need to stop it, making it meaningless is a possibility. And\ncertainly stopping it by screwing up something else is not a good strategy.\nRegardless, we need to educate people about this simple rule:\n\nNEVER put invoices from others into any KYC wallet.\n\nFinally, fixing privacy issues like ID reuse is much more important and\nproductive than removing description.\n\nCheers\nMartin\n\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220201/ff49815b/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Remove Description From Bolt11 Invoices",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "armdxxi",
                "Martin Habov\u0161tiak"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 15413
        }
    },
    {
        "title": "[Lightning-dev] Feedback on LN-to-BTC invoicing tool",
        "thread_messages": [
            {
                "author": "Ronan McGovern",
                "date": "2022-02-02T16:22:47",
                "message_text_only": "Hi folks, Danny (on the TrelisDev email) and I have built out an MVP for an\ninvoicing tool that issues an LN invoice and then pays it out to a\nmerchant's BTC account.\n\nA few things I'm looking to get input on right now. Your assistance - or\ntips on people to talk to - would be greatly appreciated:\n\n*1. Lightning to Bitcoin Cash-out*\nThe reason for taking this approach is that it was difficult to find a way\nto support lightning to lightning payments in a non-custodial way. The\noptions we saw were:\n1. Trampoline node (like Phoenix) - requiring management of liquidity for\nour node, which is a pain (and may or may not be custodial?)\n2. LN bits approach - which is custodial.\n\nObviously cashing LN out to BTC isn't ideal (due to LN fees + Boltz 0.5%\nswap fee + Bitcoin on-chain fee), particularly because of the on-chain fee,\nbut at least we can do it more non-custodially.\n\nI am interested in better technical approaches. Ideally, we'd like to\nnon-custodially facilitate lightning invoice generation (without the\nmerchant having to set up a node with a BTC pay server type approach = too\ncomplicated for most merchants imo).\n\n*3. Bitcoin Price Volatility*\nGenerally, I'm skeptical a tool like this can get a lot of adoption because\nBitcoin price right now is too volatile to be useful to customers and\nmerchants. I guess there is a bounty for building contracts for difference\n(illegal in the US) that would support a dollar-pegged asset in lightning\nchannels, but I'm guessing that's 6-12 months away from being usable.\n\nIdeas on approaches for addressing this would be appreciated.\n\nCheers, Ronan\n~~~\nP.S. I have two less technical things I'm thinking about. I know this is a\ndev thread, but if anyone has reccs or folks to talk to that would be much\nappreciated.\n\n*a. Regulatory Status*\nI would like to understand whether merchants making use of Trelis software\nto build a payments page brings Trelis under regulation, and what options\nthere are for handling this in the case of:\na) just for providing the software\nb) specifically with our current implementation, where the merchant uses\nour api to have Boltz.exchange create a bitcoin lightning invoice that\nswaps to a bitcoin payment to the merchant's wallet.\n\n*b. Mitigating Fraud*\nI am concerned both about fraudulent merchants creating payment links\n*and* about\nthe image/brand of Trelis vis-a-vis the merchants that it serves. Broadly,\nI see two extremes for the approach Trelis could take:\n\n1) No Verification\n~ in which case there is probably an adverse selection problem for the\ntypes of merchant that would use Trelis.\n\n2) Use Verification:\n~ in which case Trelis needs to make moral judgements around what types of\nbusinesses to support. To a degree, we already have a layer of this by\nrequiring login with gmail, and could progressively build on this.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220202/f09bf3c8/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Feedback on LN-to-BTC invoicing tool",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Ronan McGovern"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3005
        }
    },
    {
        "title": "[Lightning-dev] BIP-119 CTV Meeting #3 Draft Agenda for Tuesday February 8th at 12:00 PT",
        "thread_messages": [
            {
                "author": "Jeremy Rubin",
                "date": "2022-02-02T20:29:19",
                "message_text_only": "Bitcoin Developers,\n\nThe 3rd instance of the recurring meeting is scheduled for Tuesday February\n8th at 12:00 PT in channel ##ctv-bip-review in libera.chat IRC server.\n\nThe meeting should take approximately 2 hours.\n\nThe topics proposed to be discussed are agendized below. Please review the\nagenda in advance of the meeting to make the best use of everyone's time.\n\nPlease send me any feedback, proposed topic changes, additions, or\nquestions you would like to pre-register on the agenda.\n\nI will send a reminder to this list with a finalized Agenda in advance of\nthe meeting.\n\nBest,\n\nJeremy\n\n- Bug Bounty Updates (10 Minutes)\n- Non-Interactive Lightning Channels (20 minutes)\n  + https://rubin.io/bitcoin/2021/12/11/advent-14/\n  + https://utxos.org/uses/non-interactive-channels/\n- CTV's \"Dramatic\" Improvement of DLCs (20 Minutes)\n  + Summary: https://zensored.substack.com/p/supercharging-dlcs-with-ctv\n  +\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019808.html\n  + https://rubin.io/bitcoin/2021/12/20/advent-23/\n- PathCoin (15 Minutes)\n  + Summary: A proposal of coins that can be transferred in an offline\nmanner by pre-compiling chains of transfers cleverly.\n  + https://gist.github.com/AdamISZ/b462838cbc8cc06aae0c15610502e4da\n  +\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019809.html\n- OP_TXHASH (30 Minutes)\n  + An alternative approach to OP_CTV + APO's functionality by programmable\ntx hash opcode.\n  + See discussion thread at:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019813.html\n- Emulating CTV for Liquid (10 Minutes)\n  +\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-February/019851.html\n- General Discussion (15 Minutes)\n\nBest,\n\nJeremy\n\n\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220202/13198f50/attachment.html>"
            },
            {
                "author": "Jeremy Rubin",
                "date": "2022-02-07T19:10:41",
                "message_text_only": "Reminder:\n\nThis is in ~24 hours.\n\nThere have been no requests to add content to the agenda.\n\nBest,\n\nJeremy\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n\n\nOn Wed, Feb 2, 2022 at 12:29 PM Jeremy Rubin <jeremy.l.rubin at gmail.com>\nwrote:\n\n> Bitcoin Developers,\n>\n> The 3rd instance of the recurring meeting is scheduled for Tuesday\n> February 8th at 12:00 PT in channel ##ctv-bip-review in libera.chat IRC\n> server.\n>\n> The meeting should take approximately 2 hours.\n>\n> The topics proposed to be discussed are agendized below. Please review the\n> agenda in advance of the meeting to make the best use of everyone's time.\n>\n> Please send me any feedback, proposed topic changes, additions, or\n> questions you would like to pre-register on the agenda.\n>\n> I will send a reminder to this list with a finalized Agenda in advance of\n> the meeting.\n>\n> Best,\n>\n> Jeremy\n>\n> - Bug Bounty Updates (10 Minutes)\n> - Non-Interactive Lightning Channels (20 minutes)\n>   + https://rubin.io/bitcoin/2021/12/11/advent-14/\n>   + https://utxos.org/uses/non-interactive-channels/\n> - CTV's \"Dramatic\" Improvement of DLCs (20 Minutes)\n>   + Summary: https://zensored.substack.com/p/supercharging-dlcs-with-ctv\n>   +\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019808.html\n>   + https://rubin.io/bitcoin/2021/12/20/advent-23/\n> - PathCoin (15 Minutes)\n>   + Summary: A proposal of coins that can be transferred in an offline\n> manner by pre-compiling chains of transfers cleverly.\n>   + https://gist.github.com/AdamISZ/b462838cbc8cc06aae0c15610502e4da\n>   +\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019809.html\n> - OP_TXHASH (30 Minutes)\n>   + An alternative approach to OP_CTV + APO's functionality by\n> programmable tx hash opcode.\n>   + See discussion thread at:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019813.html\n> - Emulating CTV for Liquid (10 Minutes)\n>   +\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-February/019851.html\n> - General Discussion (15 Minutes)\n>\n> Best,\n>\n> Jeremy\n>\n>\n>\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220207/3a9308bb/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP-119 CTV Meeting #3 Draft Agenda for Tuesday February 8th at 12:00 PT",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Jeremy Rubin"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 4314
        }
    },
    {
        "title": "[Lightning-dev] [bitcoin-dev] [Pre-BIP] Fee Accounts",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2022-02-10T06:58:56",
                "message_text_only": "On Sat, Jan 01, 2022 at 12:04:00PM -0800, Jeremy via bitcoin-dev wrote:\n> Happy new years devs,\n> \n> I figured I would share some thoughts for conceptual review that have been\n> bouncing around my head as an opportunity to clean up the fee paying\n> semantics in bitcoin \"for good\". The design space is very wide on the\n> approach I'll share, so below is just a sketch of how it could work which\n> I'm sure could be improved greatly.\n> \n> Transaction fees are an integral part of bitcoin.\n> \n> However, due to quirks of Bitcoin's transaction design, fees are a part of\n> the transactions that they occur in.\n> \n> While this works in a \"Bitcoin 1.0\" world, where all transactions are\n> simple on-chain transfers, real world use of Bitcoin requires support for\n> things like Fee Bumping stuck transactions, DoS resistant Payment Channels,\n> and other long lived Smart Contracts that can't predict future fee rates.\n> Having the fees paid in band makes writing these contracts much more\n> difficult as you can't merely express the logic you want for the\n> transaction, but also the fees.\n> \n> Previously, I proposed a special type of transaction called a \"Sponsor\"\n> which has some special consensus + mempool rules to allow arbitrarily\n> appending fees to a transaction to bump it up in the mempool.\n> \n> As an alternative, we could establish an account system in Bitcoin as an\n> \"extension block\".\n\n<snip>\n\n> This type of design works really well for channels because the addition of\n> fees to e.g. a channel state does not require any sort of pre-planning\n> (e.g. anchors) or transaction flexibility (SIGHASH flags). This sort of\n> design is naturally immune to pinning issues since you could offer to pay a\n> fee for any TXID and the number of fee adding offers does not need to be\n> restricted in the same way the descendant transactions would need to be.\n\nSo it's important to recognize that fee accounts introduce their own kind of\ntransaction pinning attacks: third parties would be able to attach arbitrary\nfees to any transaction without permission. This isn't necessarily a good\nthing: I don't want third parties to be able to grief my transaction engines by\ngetting obsolete transactions confirmed in liu of the replacments I actually\nwant confirmed. Eg a third party could mess up OpenTimestamps calendars at\nrelatively low cost by delaying the mining of timestamp txs.\n\nOf course, there's an obvious way to fix this: allow transactions to designate\na pubkey allowed to add further transaction fees if required. Which Bitcoin\nalready has in two forms: Replace-by-Fee and Child Pays for Parent.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220210/ddb4235b/attachment.sig>"
            },
            {
                "author": "Jeremy Rubin",
                "date": "2022-02-10T08:08:59",
                "message_text_only": "That's not really pinning; painning usually refers to pinning something to\nthe bottom of the mempool whereas these mechanisms make it easier to\nguarantee that progress can be made on confirming the transactions you're\ninterested in.\n\nOften times in these protocols \"the call is coming inside the house\". It's\nnot a third party adding fees we are scared of, it's a direct party to the\nprotocol!\n\nSponsors or fee accounts would enable you to ensure the protocol you're\nworking on makes forward progress. For things like Eltoo the internal\nratchet makes this work well.\n\nProtocols which depend on in mempool replacements before confirmation\nalready must be happy (should they be secure) with any prior state being\nmined. If a third party pays the fee you might even be happier since the\nexecution wasn't on your dime.\n\nCheers,\n\nJeremy\n\nOn Wed, Feb 9, 2022, 10:59 PM Peter Todd via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Sat, Jan 01, 2022 at 12:04:00PM -0800, Jeremy via bitcoin-dev wrote:\n> > Happy new years devs,\n> >\n> > I figured I would share some thoughts for conceptual review that have\n> been\n> > bouncing around my head as an opportunity to clean up the fee paying\n> > semantics in bitcoin \"for good\". The design space is very wide on the\n> > approach I'll share, so below is just a sketch of how it could work which\n> > I'm sure could be improved greatly.\n> >\n> > Transaction fees are an integral part of bitcoin.\n> >\n> > However, due to quirks of Bitcoin's transaction design, fees are a part\n> of\n> > the transactions that they occur in.\n> >\n> > While this works in a \"Bitcoin 1.0\" world, where all transactions are\n> > simple on-chain transfers, real world use of Bitcoin requires support for\n> > things like Fee Bumping stuck transactions, DoS resistant Payment\n> Channels,\n> > and other long lived Smart Contracts that can't predict future fee rates.\n> > Having the fees paid in band makes writing these contracts much more\n> > difficult as you can't merely express the logic you want for the\n> > transaction, but also the fees.\n> >\n> > Previously, I proposed a special type of transaction called a \"Sponsor\"\n> > which has some special consensus + mempool rules to allow arbitrarily\n> > appending fees to a transaction to bump it up in the mempool.\n> >\n> > As an alternative, we could establish an account system in Bitcoin as an\n> > \"extension block\".\n>\n> <snip>\n>\n> > This type of design works really well for channels because the addition\n> of\n> > fees to e.g. a channel state does not require any sort of pre-planning\n> > (e.g. anchors) or transaction flexibility (SIGHASH flags). This sort of\n> > design is naturally immune to pinning issues since you could offer to\n> pay a\n> > fee for any TXID and the number of fee adding offers does not need to be\n> > restricted in the same way the descendant transactions would need to be.\n>\n> So it's important to recognize that fee accounts introduce their own kind\n> of\n> transaction pinning attacks: third parties would be able to attach\n> arbitrary\n> fees to any transaction without permission. This isn't necessarily a good\n> thing: I don't want third parties to be able to grief my transaction\n> engines by\n> getting obsolete transactions confirmed in liu of the replacments I\n> actually\n> want confirmed. Eg a third party could mess up OpenTimestamps calendars at\n> relatively low cost by delaying the mining of timestamp txs.\n>\n> Of course, there's an obvious way to fix this: allow transactions to\n> designate\n> a pubkey allowed to add further transaction fees if required. Which Bitcoin\n> already has in two forms: Replace-by-Fee and Child Pays for Parent.\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220210/bfed4525/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2022-02-18T23:50:07",
                "message_text_only": "On Thu, Feb 10, 2022 at 12:08:59AM -0800, Jeremy Rubin wrote:\n> That's not really pinning; painning usually refers to pinning something to\n> the bottom of the mempool whereas these mechanisms make it easier to\n> guarantee that progress can be made on confirming the transactions you're\n> interested in.\n\nAs I said, it's a new kind of pinning attack, distinct from other types of\npinning attack.\n\n> Often times in these protocols \"the call is coming inside the house\". It's\n> not a third party adding fees we are scared of, it's a direct party to the\n> protocol!\n\nOften times that is true. But other times that is not true! I gave examples of\nuse-cases where being able to arbitrary add fees to transactions is harmful;\nthe onus is on you to argue why that is acceptable to burden those users with a\nnew class of attack.\n\n> Sponsors or fee accounts would enable you to ensure the protocol you're\n> working on makes forward progress. For things like Eltoo the internal\n> ratchet makes this work well.\n> \n> Protocols which depend on in mempool replacements before confirmation\n> already must be happy (should they be secure) with any prior state being\n> mined. If a third party pays the fee you might even be happier since the\n> execution wasn't on your dime.\n\n\"Must be able to deal with\" is not the same thing as \"Must be happy\". While\nthose use-cases do have to deal with those exceptional cases happening\noccasionally, it's harmful if an attacker can harass you by making those\nexceptional cases happen frequently.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220218/ffb7a6b7/attachment.sig>"
            },
            {
                "author": "Jeremy Rubin",
                "date": "2022-02-19T00:38:27",
                "message_text_only": "> As I said, it's a new kind of pinning attack, distinct from other types\nof pinning attack.\n\nI think pinning is \"formally defined\" as sequences of transactions which\nprevent or make it less likely for you to make any progress (in terms of\nunits of computation proceeding).\n\nSomething that only increases possibility to make progress cannot be\npinning.\n\nIf you want to call it something else, with a negative connotation, maybe\ncall it \"necromancing\" (bringing back txns that would otherwise be\nfeerate/fee irrational).\n\nI would posit that we should be wholly unconcerned with necromancing -- if\nyour protocol is particularly vulnerable to a third party necromancing then\nyour protocol is insecure and we shouldn't hamper Bitcoin's forward\nprogress on secure applications to service already insecure ones. Lightning\nis particularly necromancy resistant by design, but pinning vulnerable.\nThis is also true with things like coinjoins which are necromancy resistant\nbut pinning vulnerable.\n\nNecromancy in particular is something that isn't uniquely un-present in\nBitcoin today, and things like package relay and elimination of pinning are\ninherently at odds with making necromancy either for CPFP use cases.\n\nIn particular, for the use case you mentioned \"Eg a third party could mess\nup OpenTimestamps calendars at relatively low cost by delaying the mining\nof timestamp txs.\", this is incorrect. A third party can only accelerate\nthe mining on the timestamp transactions, but they *can* accelerate the\nmining of any such timestamp transaction. If you have a single output chain\nthat you're RBF'ing per block, then at most they can cause you to shift the\ncalendar commits forward one block. But again, they cannot pin you. If you\nwant to shift it back one block earlier, just offer a higher fee for the\nlater RBF'd calendar. Thus the interference is limited by how much you wish\nto pay to guarantee your commitment is in this block as opposed to the next.\n\nBy the way, you can already do out-of-band transaction fees to a very\nsimilar effect, google \"BTC transaction accelerator\". If the attack were at\nall valuable to perform, it could happen today.\n\nLastly, if you do get \"necromanced\" on an earlier RBF'd transaction by a\nthird party for OTS, you should be relatively happy because it cost you\nless fees overall, since the undoing of your later RBF surely returned some\nsatoshis to your wallet.\n\nBest,\n\nJeremy\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220218/83410688/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2022-02-19T09:39:22",
                "message_text_only": "On Fri, Feb 18, 2022 at 04:38:27PM -0800, Jeremy Rubin wrote:\n> > As I said, it's a new kind of pinning attack, distinct from other types\n> of pinning attack.\n> \n> I think pinning is \"formally defined\" as sequences of transactions which\n> prevent or make it less likely for you to make any progress (in terms of\n> units of computation proceeding).\n\nMentioning \"computation\" when talking about transactions is misleading:\nblockchain transactions have nothing to do with computation.\n\n> Something that only increases possibility to make progress cannot be\n> pinning.\n\nIt is incorrect to say that all use-cases have the property that any version of\na transaction being mined is progress.\n\n> If you want to call it something else, with a negative connotation, maybe\n> call it \"necromancing\" (bringing back txns that would otherwise be\n> feerate/fee irrational).\n\nNecromancing might be a reasonable name for attacks that work by getting an\nout-of-date version of a tx mined.\n\n> In particular, for the use case you mentioned \"Eg a third party could mess\n> up OpenTimestamps calendars at relatively low cost by delaying the mining\n> of timestamp txs.\", this is incorrect. A third party can only accelerate\n> the mining on the timestamp transactions, but they *can* accelerate the\n> mining of any such timestamp transaction. If you have a single output chain\n> that you're RBF'ing per block, then at most they can cause you to shift the\n> calendar commits forward one block. But again, they cannot pin you. If you\n> want to shift it back one block earlier, just offer a higher fee for the\n> later RBF'd calendar. Thus the interference is limited by how much you wish\n> to pay to guarantee your commitment is in this block as opposed to the next.\n\nYour understanding of how OpenTimestamps calendars work appears to be\nincorrect. There is no chain of unconfirmed transactions. Rather, OTS calendars\nuse RBF to _update_ the timestamp tx with a new merkle tip hash for to all\noutstanding per-second commitments once per new block. In high fee situations\nit's normal for there to be dozens of versions of that same tx, each with a\nslightly higher feerate.\n\nOTS calendars can handle any of those versions getting mined. But older\nversions getting mined wastes money, as the remaining commitments still need to\nget mined in a subsequent transaction. Those remaining commitments are also\ndelayed by the time it takes for the next tx to get mined.\n\nThere are many use-cases beyond OTS with this issue. For example, some entities\nuse \"in-place\" replacement for update low-time-preference settlement\ntransactions by adding new txouts and updating existing ones. Older versions of\nthose settlement transactions getting mined rather than the newer version\nwastes money and delays settlement for the exact same reason it does in OTS.\n\nIf fee accounts or any similar mechanism get implemented, they absolutely\nshould be opt-in. Obviously, using a currently non-standard nVersion bit is a\npossible approach. Conversely, with CPFP it may be desirable in the settlement\ncase to be able to *prevent* outputs from being spent in the same block. Again,\nan nVersion bit is a possible approach.\n\n> By the way, you can already do out-of-band transaction fees to a very\n> similar effect, google \"BTC transaction accelerator\". If the attack were at\n> all valuable to perform, it could happen today.\n\nI just checked: all the BTC transaction accellerator services I could find look\nto be either scams, or very expensive. We need compelling reasons to make this\nnuisance attack significantly cheaper.\n\n> Lastly, if you do get \"necromanced\" on an earlier RBF'd transaction by a\n> third party for OTS, you should be relatively happy because it cost you\n> less fees overall, since the undoing of your later RBF surely returned some\n> satoshis to your wallet.\n\nAs I said above, no it doesn't.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220219/e3194806/attachment-0001.sig>"
            },
            {
                "author": "darosior",
                "date": "2022-02-19T17:20:19",
                "message_text_only": "> Necromancing might be a reasonable name for attacks that work by getting an\n> out-of-date version of a tx mined.\n\nIt's not an \"attack\"? There is no such thing as an out-of-date transaction, if\nyou signed and broadcasted it in the first place. You can't rely on the fact that\na replacement transaction would somehow invalidate a previous version of it.\n\n------- Original Message -------\n\nLe samedi 19 f\u00e9vrier 2022 \u00e0 10:39 AM, Peter Todd <pete at petertodd.org> a \u00e9crit :\n\n> On Fri, Feb 18, 2022 at 04:38:27PM -0800, Jeremy Rubin wrote:\n>\n> > > As I said, it's a new kind of pinning attack, distinct from other types\n> > >\n> > > of pinning attack.\n> >\n> > I think pinning is \"formally defined\" as sequences of transactions which\n> >\n> > prevent or make it less likely for you to make any progress (in terms of\n> >\n> > units of computation proceeding).\n>\n> Mentioning \"computation\" when talking about transactions is misleading:\n>\n> blockchain transactions have nothing to do with computation.\n>\n> > Something that only increases possibility to make progress cannot be\n> >\n> > pinning.\n>\n> It is incorrect to say that all use-cases have the property that any version of\n>\n> a transaction being mined is progress.\n>\n> > If you want to call it something else, with a negative connotation, maybe\n> >\n> > call it \"necromancing\" (bringing back txns that would otherwise be\n> >\n> > feerate/fee irrational).\n>\n> Necromancing might be a reasonable name for attacks that work by getting an\n>\n> out-of-date version of a tx mined.\n>\n> > In particular, for the use case you mentioned \"Eg a third party could mess\n> >\n> > up OpenTimestamps calendars at relatively low cost by delaying the mining\n> >\n> > of timestamp txs.\", this is incorrect. A third party can only accelerate\n> >\n> > the mining on the timestamp transactions, but they can accelerate the\n> >\n> > mining of any such timestamp transaction. If you have a single output chain\n> >\n> > that you're RBF'ing per block, then at most they can cause you to shift the\n> >\n> > calendar commits forward one block. But again, they cannot pin you. If you\n> >\n> > want to shift it back one block earlier, just offer a higher fee for the\n> >\n> > later RBF'd calendar. Thus the interference is limited by how much you wish\n> >\n> > to pay to guarantee your commitment is in this block as opposed to the next.\n>\n> Your understanding of how OpenTimestamps calendars work appears to be\n>\n> incorrect. There is no chain of unconfirmed transactions. Rather, OTS calendars\n>\n> use RBF to update the timestamp tx with a new merkle tip hash for to all\n>\n> outstanding per-second commitments once per new block. In high fee situations\n>\n> it's normal for there to be dozens of versions of that same tx, each with a\n>\n> slightly higher feerate.\n>\n> OTS calendars can handle any of those versions getting mined. But older\n>\n> versions getting mined wastes money, as the remaining commitments still need to\n>\n> get mined in a subsequent transaction. Those remaining commitments are also\n>\n> delayed by the time it takes for the next tx to get mined.\n>\n> There are many use-cases beyond OTS with this issue. For example, some entities\n>\n> use \"in-place\" replacement for update low-time-preference settlement\n>\n> transactions by adding new txouts and updating existing ones. Older versions of\n>\n> those settlement transactions getting mined rather than the newer version\n>\n> wastes money and delays settlement for the exact same reason it does in OTS.\n>\n> If fee accounts or any similar mechanism get implemented, they absolutely\n>\n> should be opt-in. Obviously, using a currently non-standard nVersion bit is a\n>\n> possible approach. Conversely, with CPFP it may be desirable in the settlement\n>\n> case to be able to prevent outputs from being spent in the same block. Again,\n>\n> an nVersion bit is a possible approach.\n>\n> > By the way, you can already do out-of-band transaction fees to a very\n> >\n> > similar effect, google \"BTC transaction accelerator\". If the attack were at\n> >\n> > all valuable to perform, it could happen today.\n>\n> I just checked: all the BTC transaction accellerator services I could find look\n>\n> to be either scams, or very expensive. We need compelling reasons to make this\n>\n> nuisance attack significantly cheaper.\n>\n> > Lastly, if you do get \"necromanced\" on an earlier RBF'd transaction by a\n> >\n> > third party for OTS, you should be relatively happy because it cost you\n> >\n> > less fees overall, since the undoing of your later RBF surely returned some\n> >\n> > satoshis to your wallet.\n>\n> As I said above, no it doesn't.\n>\n> ----------------------------------\n>\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n>\n> Lightning-dev mailing list\n>\n> Lightning-dev at lists.linuxfoundation.org\n>\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Peter Todd",
                "date": "2022-02-19T20:35:20",
                "message_text_only": "On Sat, Feb 19, 2022 at 05:20:19PM +0000, darosior wrote:\n> > Necromancing might be a reasonable name for attacks that work by getting an\n> > out-of-date version of a tx mined.\n> \n> It's not an \"attack\"? There is no such thing as an out-of-date transaction, if\n> you signed and broadcasted it in the first place. You can't rely on the fact that\n> a replacement transaction would somehow invalidate a previous version of it.\n\nAnyone on the internet can send you a packet; a secure system must be able to\nreceive any packet without being compromised. Yet we still call packet floods\nas DoS attacks. And internet standards are careful to avoid making packet\nflooding cheaper than it currently is.\n\nThe same principal applies here: in many situations transactions _do_ become\nout of date, in the sense that you would rather a different transaction be\nmined instead, and the out-of-date tx being mined is expensive and annoying.\nWhile you have to account for the _possibility_ of any transaction you have\nsigned being mined, Bitcoin standards should avoid making unwanted necromancy a\ncheap and easy attack.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220219/d50565cf/attachment.sig>"
            },
            {
                "author": "Jeremy",
                "date": "2022-02-20T16:13:16",
                "message_text_only": "opt-in or explicit tagging of fee account is a bad design IMO.\n\nAs pointed out by James O'Beirne in the other email, having an explicit key\nrequired means you have to pre-plan.... suppose you're building a vault\nmeant to distribute funds over many years, do you really want a *specific*\nprecommitted key you have to maintain? What happens to your ability to bump\nshould it be compromised (which may be more likely if it's intended to be a\nhot-wallet function for bumping).\n\nFurthermore, it's quite often the case that someone might do a transaction\nthat pays you that is low fee that you want to bump but they choose to\nopt-out... then what? It's better that you should always be able to fee\nbump.\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Sun, Feb 20, 2022 at 6:24 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning DA,\n>\n>\n> > Agreed, you cannot rely on a replacement transaction would somehow\n> > invalidate a previous version of it, it has been spoken into the gossip\n> > and exists there in mempools somewhere if it does, there is no guarantee\n> > that anyone has ever heard of the replacement transaction as there is no\n> > consensus about either the previous version of the transaction or its\n> > replacement until one of them is mined and the block accepted. -DA.\n>\n> As I understand from the followup from Peter, the point is not \"this\n> should never happen\", rather the point is \"this should not happen *more\n> often*.\"\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220220/ff758812/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-02-20T16:34:35",
                "message_text_only": "Good morning Jeremy,\n\n> opt-in or explicit tagging of fee account is a bad design IMO.\n>\n> As pointed out by James O'Beirne in the other email, having an explicit key required means you have to pre-plan.... suppose you're building a vault meant to distribute funds over many years, do you really want a *specific* precommitted\u00a0key you have to maintain? What happens to your ability to bump should it be compromised (which may be more likely if it's intended to be a hot-wallet function for bumping).\n>\n> Furthermore, it's quite often the case that someone might do a transaction that pays you that is low fee that you want to bump but they choose to opt-out... then what? It's better that you should always be able to fee bump.\n\nGood point.\n\nFor the latter case, CPFP would work and already exists.\n**Unless** you are doing something complicated and offchain-y and involves relative locktimes, of course.\n\n\nOnce could point out as well that Peter Todd gave just a single example, OpenTimeStamps, for this, and OpenTimeStamps is not the only user of the Bitcoin blockchain.\n\nSo we can consider: who benefits and who suffers, and does the benefit to the former outweigh the detriment of the latter?\n\n\nIt seems to me that the necromancing attack mostly can *only* target users of RBF that might want to *additionally* add outputs (or in the case of OTS, commitments) when RBF-ing.\nFor example, a large onchain-paying entity might lowball an onchain transaction for a few withdrawals, then as more withdrawals come in, bump up their feerate and add more withdrawals to the RBF-ed transaction.\nSuch an entity might prefer to confirm the latest RBF-ed transaction, as if an earlier transaction (which does not include some other withdrawals requested later) is necromanced, they would need to make an *entire* *other* transaction (which may be costlier!) to fulfill pending withdrawal requests.\n\nHowever, to my knowledge, there is no actual entity that *currently* acts this way (I do have some sketches for a wallet that can support this behavior, but it gets *complicated* due to having to keep track of reorgs as well... sigh).\n\nIn particular, I expect that many users do not really make outgoing payments often enough that they would actually benefit from such a wallet feature.\nInstead, they will generally make one payment at a time, or plan ahead and pay several in a batch at once, and even if they RBF, they would just keep the same set of outputs and just reduce their change output.\nFor such low-scale users, a rando third-party necromancing their old transactions could only make them happy, thus this nuisance attack cannot be executed.\n\nWe could also point out that this is really a nuisance attack and not an economic-theft attack.\nThe attacker cannot gain, and can only pay in order to impose costs on somebody else.\nRationally, the only winning move is not to play.\n\n\nSo --- has anyone actually implemented a Bitcoin wallet that has such a feature (i.e. make a lowball send transaction now, then you can add another send later and if the previous send transaction is unconfirmed, RBF it with a new transaction that has the previous send and the current send) and if so, can you open-source the code and show me?\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Jeremy Rubin",
                "date": "2022-02-20T16:29:35",
                "message_text_only": "opt-in or explicit tagging of fee account is a bad design IMO.\n\nAs pointed out by James O'Beirne in the other email, having an explicit key\nrequired means you have to pre-plan.... suppose you're building a vault\nmeant to distribute funds over many years, do you really want a *specific*\nprecommitted key you have to maintain? What happens to your ability to bump\nshould it be compromised (which may be more likely if it's intended to be a\nhot-wallet function for bumping).\n\nFurthermore, it's quite often the case that someone might do a transaction\nthat pays you that is low fee that you want to bump but they choose to\nopt-out... then what? It's better that you should always be able to fee\nbump.\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n\n\nOn Sun, Feb 20, 2022 at 6:24 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning DA,\n>\n>\n> > Agreed, you cannot rely on a replacement transaction would somehow\n> > invalidate a previous version of it, it has been spoken into the gossip\n> > and exists there in mempools somewhere if it does, there is no guarantee\n> > that anyone has ever heard of the replacement transaction as there is no\n> > consensus about either the previous version of the transaction or its\n> > replacement until one of them is mined and the block accepted. -DA.\n>\n> As I understand from the followup from Peter, the point is not \"this\n> should never happen\", rather the point is \"this should not happen *more\n> often*.\"\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220220/c3047335/attachment.html>"
            },
            {
                "author": "Jeremy Rubin",
                "date": "2022-02-20T16:29:00",
                "message_text_only": "--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n\n\nOn Sat, Feb 19, 2022 at 1:39 AM Peter Todd <pete at petertodd.org> wrote:\n\n> On Fri, Feb 18, 2022 at 04:38:27PM -0800, Jeremy Rubin wrote:\n> > > As I said, it's a new kind of pinning attack, distinct from other types\n> > of pinning attack.\n> >\n> > I think pinning is \"formally defined\" as sequences of transactions which\n> > prevent or make it less likely for you to make any progress (in terms of\n> > units of computation proceeding).\n>\n> Mentioning \"computation\" when talking about transactions is misleading:\n> blockchain transactions have nothing to do with computation.\n>\n\nIt is in fact computation. Branding it as \"misleading\" is misleading... The\nrelevant literature is https://en.wikipedia.org/wiki/Non-blocking_algorithm,\nsponsors helps get rid of deadlocking so that any thread can be guaranteed\nto make progress. E.g., this is critical in Eltoo, which is effectively a\ncoordinated multi-party computation on-chain to compute the highest\nsequence number known by any worker.\n\nThat transactions are blobs of \"verification\" (which is also itself a\ncomputation) less so than dynamic computations is irrelevant to the fact\nthat series of transactions do represent computations.\n\n\n\n> > Something that only increases possibility to make progress cannot be\n> > pinning.\n>\n> It is incorrect to say that all use-cases have the property that any\n> version of\n> a transaction being mined is progress.\n>\n\nIt is progress, tautologically. Progress is formally definable as a\ntransaction of any kind getting mined. Pinning prevents progress by an\nadversarial worker. Sponsoring enables progress, but it may not be your\npreferred interleaving. That's OK, but it's inaccurate to say it is not\nprogress.\n\nYour understanding of how OpenTimestamps calendars work appears to be\n> incorrect. There is no chain of unconfirmed transactions. Rather, OTS\n> calendars\n> use RBF to _update_ the timestamp tx with a new merkle tip hash for to all\n> outstanding per-second commitments once per new block. In high fee\n> situations\n> it's normal for there to be dozens of versions of that same tx, each with a\n> slightly higher feerate.\n>\n\nI didn't claim there to be a chain of unconfirmed, I claimed that there\ncould be single output chain that you're RBF'ing one step per block.\n\nE.g., it could be something like\n\nA_0 -> {A_1 w/ CSV 1 block, OP_RETURN {blah, foo}}\nA_1 -> {A_2 w/ CSV 1 block, OP_RETURN {bar}}\n\nsuch that A_i provably can't have an unconfirmed descendant. The notion\nwould be that you're replacing one with another. E.g., if you're updating\nthe calendar like:\n\n\nVersion 0: A_0 -> {A_1 w/ CSV 1 block, OP_RETURN {blah, foo}}\nVersion 1: A_0 -> {A_1 w/ CSV 1 block, OP_RETURN {blah, foo, bar}}\nVersion 2: A_0 -> {A_1 w/ CSV 1 block, OP_RETURN {blah, foo, bar, delta}}\n\nand version 1 gets mined, then in A_1's spend you simply shift delta to\nthat (next) calendar.\n\nA_1 -> {A_2 w/ CSV 1 block, OP_RETURN {delta}}\n\nThus my claim that someone sponsoring a old version only can delay by 1\nblock the calendar commit.\n\n\n\n\n\n> OTS calendars can handle any of those versions getting mined. But older\n> versions getting mined wastes money, as the remaining commitments still\n> need to\n> get mined in a subsequent transaction. Those remaining commitments are also\n> delayed by the time it takes for the next tx to get mined.\n>\n> There are many use-cases beyond OTS with this issue. For example, some\n> entities\n> use \"in-place\" replacement for update low-time-preference settlement\n> transactions by adding new txouts and updating existing ones. Older\n> versions of\n> those settlement transactions getting mined rather than the newer version\n> wastes money and delays settlement for the exact same reason it does in\n> OTS.\n>\n>\n> > Lastly, if you do get \"necromanced\" on an earlier RBF'd transaction by a\n> > third party for OTS, you should be relatively happy because it cost you\n> > less fees overall, since the undoing of your later RBF surely returned\n> some\n> > satoshis to your wallet.\n>\n> As I said above, no it doesn't.\n>\n>\nIt does save money since you had to pay to RBF, the N+1st txn will be\npaying higher fee than the Nth. So if someone else sponsors an earlier\nversion, then you save whatever feerate/fee bumps you would have paid and\nthe funds are again in your change output (or something). You can apply\nthose change output savings to your next batch, which can include any\nentries that have been dropped .\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220220/8d19b01b/attachment-0001.html>"
            },
            {
                "author": "damian at willtech.com.au",
                "date": "2022-02-10T11:51:15",
                "message_text_only": "Good Afternoon,\n\nThank-you Jeremy for your work on this, it is valuable for the public \nconsideration but unfortunately I disagree. The idea of being able to \narbitrarily attach a fee to a transaction allows a miners-only attack in \nwhich all sponsored transactions are mined and the fee-rate can be \nmanipulated. It is possible that it will also allow other exotic forms \nof attack. It is true that is seems like a drawback that we cannot see \nthe future fee rate when we create a transaction but given the value of \nBitcoin it seems more likely that we will have overpaid for the fee \ncomponent and our transactions will be sort after to make the most \nvaluable blocks. If somehow you disagree, I would be interested to hear \nhow it would not make a problem?\n\nKING JAMES HRMH\nGreat British Empire\n\nRegards,\nThe Australian\nLORD HIS EXCELLENCY JAMES HRMH (& HMRH)\nof Hougun Manor & Glencoe & British Empire\nMR. Damian A. James Williamson\nWills\n\net al.\n\n\nWilltech\nwww.willtech.com.au\nwww.go-overt.com\nduigco.org DUIGCO API\nand other projects\n\n\nm. 0487135719\nf. +61261470192\n\n\nThis email does not constitute a general advice. Please disregard this \nemail if misdelivered.\n--------------\nOn 2022-02-10 17:58, Peter Todd via bitcoin-dev wrote:\n> On Sat, Jan 01, 2022 at 12:04:00PM -0800, Jeremy via bitcoin-dev wrote:\n>> Happy new years devs,\n>> \n>> I figured I would share some thoughts for conceptual review that have \n>> been\n>> bouncing around my head as an opportunity to clean up the fee paying\n>> semantics in bitcoin \"for good\". The design space is very wide on the\n>> approach I'll share, so below is just a sketch of how it could work \n>> which\n>> I'm sure could be improved greatly.\n>> \n>> Transaction fees are an integral part of bitcoin.\n>> \n>> However, due to quirks of Bitcoin's transaction design, fees are a \n>> part of\n>> the transactions that they occur in.\n>> \n>> While this works in a \"Bitcoin 1.0\" world, where all transactions are\n>> simple on-chain transfers, real world use of Bitcoin requires support \n>> for\n>> things like Fee Bumping stuck transactions, DoS resistant Payment \n>> Channels,\n>> and other long lived Smart Contracts that can't predict future fee \n>> rates.\n>> Having the fees paid in band makes writing these contracts much more\n>> difficult as you can't merely express the logic you want for the\n>> transaction, but also the fees.\n>> \n>> Previously, I proposed a special type of transaction called a \n>> \"Sponsor\"\n>> which has some special consensus + mempool rules to allow arbitrarily\n>> appending fees to a transaction to bump it up in the mempool.\n>> \n>> As an alternative, we could establish an account system in Bitcoin as \n>> an\n>> \"extension block\".\n> \n> <snip>\n> \n>> This type of design works really well for channels because the \n>> addition of\n>> fees to e.g. a channel state does not require any sort of pre-planning\n>> (e.g. anchors) or transaction flexibility (SIGHASH flags). This sort \n>> of\n>> design is naturally immune to pinning issues since you could offer to \n>> pay a\n>> fee for any TXID and the number of fee adding offers does not need to \n>> be\n>> restricted in the same way the descendant transactions would need to \n>> be.\n> \n> So it's important to recognize that fee accounts introduce their own \n> kind of\n> transaction pinning attacks: third parties would be able to attach \n> arbitrary\n> fees to any transaction without permission. This isn't necessarily a \n> good\n> thing: I don't want third parties to be able to grief my transaction \n> engines by\n> getting obsolete transactions confirmed in liu of the replacments I \n> actually\n> want confirmed. Eg a third party could mess up OpenTimestamps calendars \n> at\n> relatively low cost by delaying the mining of timestamp txs.\n> \n> Of course, there's an obvious way to fix this: allow transactions to \n> designate\n> a pubkey allowed to add further transaction fees if required. Which \n> Bitcoin\n> already has in two forms: Replace-by-Fee and Child Pays for Parent.\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            }
        ],
        "thread_summary": {
            "title": "Fee Accounts",
            "categories": [
                "Lightning-dev",
                "bitcoin-dev",
                "Pre-BIP"
            ],
            "authors": [
                "darosior",
                "Peter Todd",
                "Jeremy",
                "Jeremy Rubin",
                "damian at willtech.com.au",
                "ZmnSCPxj"
            ],
            "messages_count": 12,
            "total_messages_chars_count": 37307
        }
    },
    {
        "title": "[Lightning-dev] [bitcoin-dev]   [Pre-BIP] Fee Accounts",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2022-02-20T02:24:37",
                "message_text_only": "Good morning Peter and Jeremy,\n\n> On Sat, Feb 19, 2022 at 05:20:19PM +0000, darosior wrote:\n>\n> > > Necromancing might be a reasonable name for attacks that work by getting an\n> > > out-of-date version of a tx mined.\n> >\n> > It's not an \"attack\"? There is no such thing as an out-of-date transaction, if\n> > you signed and broadcasted it in the first place. You can't rely on the fact that\n> > a replacement transaction would somehow invalidate a previous version of it.\n>\n> Anyone on the internet can send you a packet; a secure system must be able to\n> receive any packet without being compromised. Yet we still call packet floods\n> as DoS attacks. And internet standards are careful to avoid making packet\n> flooding cheaper than it currently is.\n>\n> The same principal applies here: in many situations transactions do become\n> out of date, in the sense that you would rather a different transaction be\n> mined instead, and the out-of-date tx being mined is expensive and annoying.\n> While you have to account for the possibility of any transaction you have\n> signed being mined, Bitcoin standards should avoid making unwanted necromancy a\n> cheap and easy attack.\n>\n\nThis seems to me to restrict the only multiparty feebumping method to be some form of per-participant anchor outputs a la Lightning anchor commitments.\n\nNote that multiparty RBF is unreliable.\nWhile the initial multiparty signing of a transaction may succeed, at a later time with the transaction unconfirmed, one or more of the participants may regret cooperating in the initial signing and decide not to cooperate with the RBF.\nOr for that matter, a participant may, through complete accident, go offline.\n\nAnchor outputs can be keyed to only a specific participant, so feebumping of particular transaction can only be done by participants who have been authorized to feebump.\n\nPerhaps fee accounts can include some kind of proof-this-transaction-authorizes-this-fee-account?\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-02-20T02:39:50",
                "message_text_only": "Good morning Peter and Jeremy,\n\n> Good morning Peter and Jeremy,\n>\n> > On Sat, Feb 19, 2022 at 05:20:19PM +0000, darosior wrote:\n> >\n> > > > Necromancing might be a reasonable name for attacks that work by getting an\n> > > > out-of-date version of a tx mined.\n> > >\n> > > It's not an \"attack\"? There is no such thing as an out-of-date transaction, if\n> > > you signed and broadcasted it in the first place. You can't rely on the fact that\n> > > a replacement transaction would somehow invalidate a previous version of it.\n> >\n> > Anyone on the internet can send you a packet; a secure system must be able to\n> > receive any packet without being compromised. Yet we still call packet floods\n> > as DoS attacks. And internet standards are careful to avoid making packet\n> > flooding cheaper than it currently is.\n> > The same principal applies here: in many situations transactions do become\n> > out of date, in the sense that you would rather a different transaction be\n> > mined instead, and the out-of-date tx being mined is expensive and annoying.\n> > While you have to account for the possibility of any transaction you have\n> > signed being mined, Bitcoin standards should avoid making unwanted necromancy a\n> > cheap and easy attack.\n>\n> This seems to me to restrict the only multiparty feebumping method to be some form of per-participant anchor outputs a la Lightning anchor commitments.\n>\n> Note that multiparty RBF is unreliable.\n> While the initial multiparty signing of a transaction may succeed, at a later time with the transaction unconfirmed, one or more of the participants may regret cooperating in the initial signing and decide not to cooperate with the RBF.\n> Or for that matter, a participant may, through complete accident, go offline.\n>\n> Anchor outputs can be keyed to only a specific participant, so feebumping of particular transaction can only be done by participants who have been authorized to feebump.\n>\n> Perhaps fee accounts can include some kind of proof-this-transaction-authorizes-this-fee-account?\n\nFor example:\n\n* We reserve one Tapscript version for fee-account-authorization.\n  * Validation of this tapscript version always fails.\n* If a transaction wants to authorize a fee account, it should have at least one Taproot output.\n  * This Taproot output must have tapleaf with the fee-account-authorization Tapscript version.\n* In order for a fee account to feebump a transaction, it must also present the Taproot MAST path to the fee-account-authorization tapleaf of one output of that transaction.\n\nThis gives similar functionality to anchor outputs, without requiring an explicit output on the initial transaction, saving blockspace.\nIn particular, once the number of participants grows, the number of anchor outputs must grow linearly with the number of participants being authorized to feebump.\nOnly when the feerate turns out to be too low do we need to expose the authorization.\nRevelation of the fee-account-authorization is O(log N), and if only one participant decides to feebump, then only a single O(log N) MAST treepath is published.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "damian at willtech.com.au",
                "date": "2022-02-20T14:14:01",
                "message_text_only": "Agreed, you cannot rely on a replacement transaction would somehow \ninvalidate a previous version of it, it has been spoken into the gossip \nand exists there in mempools somewhere if it does, there is no guarantee \nthat anyone has ever heard of the replacement transaction as there is no \nconsensus about either the previous version of the transaction or its \nreplacement until one of them is mined and the block accepted. -DA.\n\nOn 2022-02-20 04:20, darosior via bitcoin-dev wrote:\n>> Necromancing might be a reasonable name for attacks that work by \n>> getting an\n>> out-of-date version of a tx mined.\n> \n> It's not an \"attack\"? There is no such thing as an out-of-date \n> transaction, if\n> you signed and broadcasted it in the first place. You can't rely on\n> the fact that\n> a replacement transaction would somehow invalidate a previous version \n> of it."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-02-20T14:24:22",
                "message_text_only": "Good morning DA,\n\n\n> Agreed, you cannot rely on a replacement transaction would somehow\n> invalidate a previous version of it, it has been spoken into the gossip\n> and exists there in mempools somewhere if it does, there is no guarantee\n> that anyone has ever heard of the replacement transaction as there is no\n> consensus about either the previous version of the transaction or its\n> replacement until one of them is mined and the block accepted. -DA.\n\nAs I understand from the followup from Peter, the point is not \"this should never happen\", rather the point is \"this should not happen *more often*.\"\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Fee Accounts",
            "categories": [
                "Lightning-dev",
                "bitcoin-dev",
                "Pre-BIP"
            ],
            "authors": [
                "damian at willtech.com.au",
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 6549
        }
    },
    {
        "title": "[Lightning-dev] [bitcoin-dev]  [Pre-BIP] Fee Accounts",
        "thread_messages": [
            {
                "author": "Jeremy Rubin",
                "date": "2022-02-20T16:45:35",
                "message_text_only": "Morning!\n\n>\n> For the latter case, CPFP would work and already exists.\n> **Unless** you are doing something complicated and offchain-y and involves\n> relative locktimes, of course.\n>\n>\nThe \"usual\" design I recommend for Vaults contains something that is like:\n\n{<maturity> CSV <pk_hot> CHECKSIG, <pk_cold> CHECKSIG}\nor\n{<maturity> CSV <pk_hot> CHECKSIG, <H(tx to: <pk_cold> CHECKSIG)> CTV}\n\n\nwhere after an output is created, it has to hit maturity before hot\nspendable but can be kicked to recovery any time before (optional: use CTV\nto actually transition on chain removing hot wallet, if cold key is hard to\naccess).\n\n\nNot that this means if you're waiting for one of these outputs to be\ncreated on chain, you cannot spend from the hot key since it needs to\nconfirm on chain first. Spending from the cold key for CPFP'ing the hot is\nan 'invalid move' (emergency key for non emergency sitch)\n\nThus in order to CPFP, you would need a separate output just for CPFPing\nthat is not subject to these restrictions, or some sort of RBF-able addable\ninput/output. Or, Sponsors.\n\n\nJeremy\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220220/92d8f0e2/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Fee Accounts",
            "categories": [
                "Lightning-dev",
                "bitcoin-dev",
                "Pre-BIP"
            ],
            "authors": [
                "Jeremy Rubin"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1265
        }
    },
    {
        "title": "[Lightning-dev] [bitcoin-dev] A suggestion to periodically destroy (or remove to secondary storage for Archiving reasons) dust, Non-standard UTXOs, and also detected burn",
        "thread_messages": [
            {
                "author": "shymaa arafat",
                "date": "2022-02-13T05:19:04",
                "message_text_only": "I just want to add an alarming info to this thread...\n\n*There are at least 5.7m UTXOs\u22641000 Sat (~7%), *\n*8.04 m \u22641$ (10%), *\n*13.5m \u2264 0.0001BTC (17%)*\n\nIt seems that bitInfoCharts took my enquiry seriously and added a main link\nfor dust analysis:\nhttps://bitinfocharts.com/top-100-dustiest-bitcoin-addresses.html\nHere, you can see just *the first address contains more than 1.7m dust\nUTXOs*\n(ins-outs =1,712,706 with a few real UTXOs holding the bulk of 415 BTC)\nhttps://bitinfocharts.com/bitcoin/address/1HckjUpRGcrrRAtFaaCAUaGjsPx9oYmLaZ\n\n\u00bb\u00bb\u00bb\u00bb\u00bb\n That's alarming isn't it?, is it due to the lightning networks protocol or\ncould be some other weird activity going on?\n.\nThe following address are similar but less severe\n~394k UTXOs, 170k, 92k, 10*20k, 4or5 *14k,...etc\nadd at least 2.7m UTXOs coming from addresses with a higher balance to the\ninterval numbers here (calculated & mentioned in my previous email)\nhttps://bitinfocharts.com/top-100-richest-bitcoin-addresses.html\n\n\nI think it seems bitInfoCharts will probably make their own report about it\nsoon\n\nRegards\nShymaa M. Arafat\n\nOn Wed, Feb 9, 2022, 07:19 shymaa arafat <shymaa.arafat at gmail.com> wrote:\n\n> If 1 Sat reached 100$, you may adjust the delete( or call it omitting or\n> trimming) threshold, since you will need to acquire decimal places inside\n> the Sat variable too ( people may have TXs less than 100$)\n>\n> -Talking with today's numbers,\n> https://bitinfocharts.com/top-100-richest-bitcoin-addresses.html\n>\n> it is hard to imagine that someone's all holdings in Bitcoin is just \u22641000\n> Sat (3.15 m address) or even \u226410,000 Sat (4.1$, with currently 7.6m\n> addresses in addition to the 3.15m)\n> So we'll just incentivise those people to find a low fee time in say a 6\n> month interval and collect those UTXOs into one of at least 5$\n> (10.86m\u22644.1$) or 1$ (5.248m\u22641$) your decision.\n>\n> -During 4 days after showing the smaller intervals, those \u22641000Sat\n> increase by ~2K everyday with total holding increased by 0.01BTC. Addresses\n> in millions:\n> 3.148, 3.1509, 3.152895, 3.154398\n> Total BTC:\n> 14.91,14.92,14.93,14.94\n>\n> -The number of \u226410,000 Sat increases by 4-8 k per day.\n> Addresses in millions:\n> 7.627477, 7.631436, 7.639287, 7.644925\n> Total BTC\n> 333.5, 333.63, 333.89, 334.1\n>\n> -remember that no. of addresses is a lowerbound on no. of UTXOs; ie., the\n> real numbers could be even more.\n> .\n> + There's also non-standard & burned , yes they're about 0.6m UTXOs, but\n> they're misleading on the status of the value they hold.\n> .\n> At the end, I'm just suggesting...\n> .\n> Regards,\n> Shymaa\n>\n> On Wed, Feb 9, 2022, 00:16 <damian at willtech.com.au> wrote:\n>\n>> Good Morning,\n>>\n>> I wish to point out that because fees are variable there is no reason\n>> fees could not be less than 1 sat in future if fees climb. You may\n>> consider this optimistic but I recall in the first days of Bitcoin when\n>> fees were voluntary. It is not unreasonable provided the fungibility\n>> (money-like-quality) of Bitcoin is maintained for 1 sat to be worth over\n>> $100.00 in the future.\n>>\n>> KING JAMES HRMH\n>> Great British Empire\n>>\n>> Regards,\n>> The Australian\n>> LORD HIS EXCELLENCY JAMES HRMH (& HMRH)\n>> of Hougun Manor & Glencoe & British Empire\n>> MR. Damian A. James Williamson\n>> Wills\n>>\n>> et al.\n>>\n>>\n>> Willtech\n>> www.willtech.com.au\n>> www.go-overt.com\n>> duigco.org DUIGCO API\n>> and other projects\n>>\n>>\n>> m. 0487135719\n>> f. +61261470192\n>>\n>>\n>> This email does not constitute a general advice. Please disregard this\n>> email if misdelivered.\n>> --------------\n>> On 2022-02-06 09:39, Pieter Wuille via bitcoin-dev wrote:\n>> >> Dear Bitcoin Developers,\n>> >\n>> >> -When I contacted bitInfoCharts to divide the first interval of\n>> >> addresses, they kindly did divided to 3 intervals. From here:\n>> >> https://bitinfocharts.com/top-100-richest-bitcoin-addresses.html\n>> >> -You can see that there are more than 3.1m addresses holding \u2264\n>> >> 0.000001 BTC (1000 Sat) with total value of 14.9BTC; an average of 473\n>> >> Sat per address.\n>> >\n>> >> -Therefore, a simple solution would be to follow the difficulty\n>> >> adjustment idea and just delete all those\n>> >\n>> > That would be a soft-fork, and arguably could be considered theft.\n>> > While commonly (but non universally) implemented standardness rules\n>> > may prevent spending them currently, there is no requirement that such\n>> > a rule remain in place. Depending on how feerate economics work out in\n>> > the future, such outputs may not even remain uneconomical to spend.\n>> > Therefore, dropping them entirely from the UTXO set is potentially\n>> > destroying potentially useful funds people own.\n>> >\n>> >> or at least remove them to secondary storage\n>> >\n>> > Commonly adopted Bitcoin full nodes already have two levels of storage\n>> > effectively (disk and in-RAM cache). It may be useful to investigate\n>> > using amount as a heuristic about what to keep and how long. IIRC, not\n>> > even every full node implementation even uses a UTXO model.\n>> >\n>> >> for Archiving with extra cost to get them back, along with\n>> >> non-standard UTXOs and Burned ones (at least for publicly known,\n>> >> published, burn addresses).\n>> >\n>> > Do you mean this as a standardness rule, or a consensus rule?\n>> >\n>> > * As a standardness rule it's feasible, but it makes policy (further)\n>> > deviate from economically rational behavior. There is no reason for\n>> > miners to require a higher price for spending such outputs.\n>> > * As a consensus rule, I expect something like this to be very\n>> > controversial. There are currently no rules that demand any minimal\n>> > fee for anything, and given uncertainly over how fee levels could\n>> > evolve in the future, it's unclear what those rules, if any, should\n>> > be.\n>> >\n>> > Cheers,\n>> >\n>> > --\n>> > Pieter\n>> >\n>> > _______________________________________________\n>> > bitcoin-dev mailing list\n>> > bitcoin-dev at lists.linuxfoundation.org\n>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220213/eb38bf91/attachment.html>"
            },
            {
                "author": "damian at willtech.com.au",
                "date": "2022-02-14T05:19:18",
                "message_text_only": "Good Afternoon,\n\nI am briefly reading the suggestion subject titled this email message. \nThe problem this idea addresses is not new, it is as old as computer \nscience with complexity and security varying from unused products in a \nsupermarket database to unused bank accounts and records of transactions \nfor archival. In the former, it is of no consequence to remove unused \nproducts from the database if the itemised sales history is not \nnecessary and the report data is maintained ie. where the reporting is \nstored generated. Once the products are removed it is impossible to \nregenerate the detailed reports that called on the product-specific and \nsales information. Archival works in a manner to remove data from \ncommonly used tables and to optimise them and if the data is later \nrequired it can be recalled from larger possibly slower storage, or \nsimply kept in a larger less optimised table, in either case, all of the \ndata is still available. In the latter, it is a matter of consequence \nand although archival is possible it is still necessary to ensure that \nall archives are backed up, and the data can never be removed. This is \nbecause if in an example transaction data is deleted after seven years \nthen it is no longer possible to see how an account has its balance and \nan empty account with no transactions may be removed while actually \nstill holding a significant balance. If a mistake is made the result is \nthe same. This is because we allowed deletion of accounting records. \nActually, the recommendation from Computer Science all along is the same \nas our case with Bitcoin - nothing should be deleted from the Blockchain \nforever. For one substantiative reason, this is because it is necessary \nfor any client to be able to validate the blockchain in its entirety and \nsome clients may only be receiving information as to the state of the \nblockchain from you. When you keep the entire blockchain you validate to \neverybody else that you have the correct records. I arbitrarily object \nto the use of pruned nodes but find them useful since the process of \nvalidation is completed in its entirety when a new node comes online \neven if it is pruned, but if only pruned nodes are available then \neverybody has to believe the other nodes and this is unacceptable for \nBitcoin. It should be if some node is archiving UTXO's then it should \ncount as a pruned node, but my suggestion is, instead of making a \nprogramming change just set your node with the parameter `prune=1` if \nyou wish to allow manually pruning from the Blockchain to a specific \nheight when you wish, or `prune= {>550} automatically prune blocks to \nstay under target size in MiB`. My chain state database after all is \nonly 4.9GB and is hardly a concern for any operation of the standard \nBitcoin Core client. The answer, again, is you should just leave it and \nget used to dealing with the bigger database.\n\nKING JAMES HRMH\nGreat British Empire\n\nRegards,\nThe Australian\nLORD HIS EXCELLENCY JAMES HRMH (& HMRH)\nof Hougun Manor & Glencoe & British Empire\nMR. Damian A. James Williamson\nWills\n\net al.\n\n\nWilltech\nwww.willtech.com.au\nwww.go-overt.com\nduigco.org DUIGCO API\nand other projects\n\n\nm. 0487135719\nf. +61261470192\n\n\nThis email does not constitute a general advice. Please disregard this \nemail if misdelivered."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-02-18T03:36:19",
                "message_text_only": "Good morning shymaa,\n\n> I just want to add an alarming info to this thread...\n>\n> There are at least 5.7m UTXOs\u22641000 Sat (~7%),\u00a0\n> 8.04 m \u22641$ (10%),\u00a0\n> 13.5m \u2264 0.0001BTC (17%)\n>\n> It seems that bitInfoCharts took my enquiry seriously and added a main link for dust analysis:\n> https://bitinfocharts.com/top-100-dustiest-bitcoin-addresses.html\n> Here, you can see just the first address contains more than 1.7m dust UTXOs\n> (ins-outs =1,712,706 with a few real UTXOs holding the bulk of 415 BTC)\u00a0\n> https://bitinfocharts.com/bitcoin/address/1HckjUpRGcrrRAtFaaCAUaGjsPx9oYmLaZ\n>\n> \u00bb\u00bb\u00bb\u00bb\u00bb\n> \u00a0That's alarming isn't it?, is it due to the lightning networks protocol or could be some other weird activity going on?\n> .\n\nI believe some blockchain tracking analysts will \"dust\" addresses that were spent from (give them 546 sats), in the hope that lousy wallets will use the new 546-sat UTXO from the same address but spending to a different address and combining with *other* inputs with new addresses, thus allowing them to grow their datasets about fund ownership.\n\nIndeed JoinMarket has a policy to ignore-by-default UTXOs that pay to an address it already spent from, precisely due to this (apparently common, since my JoinMarket maker got dusted a number of times already) practice.\n\nI am personally unsure of how common this is but it seems likely that you can eliminate this effect by removing outputs of exactly 546 sats to reused addresses.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "A suggestion to periodically destroy (or remove to secondary storage for Archiving reasons) dust, Non-standard UTXOs, and also detected burn",
            "categories": [
                "Lightning-dev",
                "bitcoin-dev"
            ],
            "authors": [
                "damian at willtech.com.au",
                "shymaa arafat",
                "ZmnSCPxj"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 10971
        }
    },
    {
        "title": "[Lightning-dev] Lightning and other layer 2 projects with multiple RBF policies",
        "thread_messages": [
            {
                "author": "Prayank",
                "date": "2022-02-13T06:09:05",
                "message_text_only": "Hello World,\n\nThere was a discussion about improving fee estimation in Bitcoin Core last year in which 'instagibbs' mentioned that we cannot consider mempool as an orderbook in which which everyone is bidding for block space because nodes can use different relay policies: https://bitcoin-irc.chaincode.com/bitcoin-core-dev/2021-09-22#706294;\n\nAlthough I still don't consider fee rates used in last few blocks relevant for fee estimation, it is possible that we have nodes with different relay policies.\n\nSimilarly if we have different RBF policies being used by nodes in future, how would this affect the security of lightning network implementations and other layer 2 projects? \n\nBased on the things shared by 'aj' in \nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-February/019846.html it is possible for an attacker to use a different RBF policy with some nodes, 10% hash power and affect the security of different projects that rely on default RBF policy in latest Bitcoin Core.\n\nThere was even a CVE in which RBF policy not being documented according to the implementation could affect the security of LN: \nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-May/018893.html\n\n1.Is Lightning Network and a few other layer 2 projects vulnerable to multiple RBF policies being used? \n\n2.With recent discussion to change things in default RBF policy used by Core, will we have multiple versions using different policies? Are users and especially miners incentivized to use different versions and policies? Do they have freedom to use different RBF policy?\n\n3.Are the recent improvements suggested for RBF policy only focused on Lightning Network and its security which will anyway remain same or become worse with multiple RBF policies?\n\nNote: Bitcoin Knots policy is fully configurable, even in the GUI - users can readily choose whatever policy *they* want.\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220213/2e657a89/attachment.html>"
            },
            {
                "author": "Michael Folkson",
                "date": "2022-02-13T15:46:43",
                "message_text_only": "Hi Prayank\n\n> 1.Is Lightning Network and a few other layer 2 projects vulnerable to multiple RBF policies being used?\n\nClearly the security of the Lightning Network and some other Layer 2 projects are at least impacted or partly dependent on policy rules in a way that the base blockchain/network isn't. As I (and others) have said on many occasions ideally this wouldn't be the case but it is best we can do with current designs. I (and others) take the view that this is not a reason to abandon those designs in the absence of an alternative that offers a strictly superior security model. Going back to a model where *all* activity is onchain (or even in less trust minimized protocols than Lightning) doesn't seem like the right approach to me.\n\n> 2.With recent discussion to change things in default RBF policy used by Core, will we have multiple versions using different policies? Are users and especially miners incentivized to use different versions and policies? Do they have freedom to use different RBF policy?\n\nWithout making policy rules effective consensus rules users (including miners) are free to run different policy rules. I think it is too early to say what the final incentives will be to run the same or differing policies. Research into Lightning security is still nascent and we have no idea whether alternative Layer 2 projects will thrive and whether they will have the same or conflicting security considerations to Lightning. I suspect as with defaults generally most users will run whatever the defaults are as they won't care to change them (or even be capable of changing them if they are very non-technical). But users who have a stake in the security of Lightning (or other Layer 2 projects) will clearly want to run whatever policy rules are beneficial to those protocols.\n\nAs you know the vast majority of the full nodes on the network currently run Bitcoin Core. Whether that will change in future and whether this a good thing or not is a whole other discussion. But the reality is that with such strong dominance there is the option to set defaults that are widely used. I think if certain defaults can bolster the security of Lightning (and possibly other Layer 2 projects) at no cost to full node users with no interest in those protocols we should discuss what those defaults should be.\n\n> 3.Are the recent improvements suggested for RBF policy only focused on Lightning Network and its security which will anyway remain same or become worse with multiple RBF policies?\n\nI think by nature of the Lightning Network being the most widely adopted Layer 2 project most of the focus has been on Lightning security. But contributors to other Layer 2 projects are free to flag and discuss security considerations that aren't Lightning specific.\n\n> Note: Bitcoin Knots policy is fully configurable, even in the GUI - users can readily choose whatever policy *they* want.\n\nThe maintainer(s) and contributors to Bitcoin Knots are free to determine what default policy rules they want to implement (and make it easier for users to change those defaults) in the absence of those policy rules being made effective consensus rules. I suspect there would be strong opposition to making some policy rules effective consensus rules but we are now venturing again into future speculation and none of us have a crystal ball. Certainly if you take the view that these policy rules should never be made effective consensus rules then the fact there is at least one implementation taking a contrasting approach to Core is a good thing.\n\n--\nMichael Folkson\nEmail: michaelfolkson at [protonmail.com](http://protonmail.com/)\nKeybase: michaelfolkson\nPGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n\n------- Original Message -------\nOn Sunday, February 13th, 2022 at 6:09 AM, Prayank via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n\n> Hello World,\n>\n> There was a discussion about improving fee estimation in Bitcoin Core last year in which 'instagibbs' mentioned that we cannot consider mempool as an orderbook in which which everyone is bidding for block space because nodes can use different relay policies: https://bitcoin-irc.chaincode.com/bitcoin-core-dev/2021-09-22#706294;\n>\n> Although I still don't consider fee rates used in last few blocks relevant for fee estimation, it is possible that we have nodes with different relay policies.\n>\n> Similarly if we have different RBF policies being used by nodes in future, how would this affect the security of lightning network implementations and other layer 2 projects?\n>\n> Based on the things shared by 'aj' in\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-February/019846.html it is possible for an attacker to use a different RBF policy with some nodes, 10% hash power and affect the security of different projects that rely on default RBF policy in latest Bitcoin Core.\n>\n> There was even a CVE in which RBF policy not being documented according to the implementation could affect the security of LN:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-May/018893.html\n>\n> 1.Is Lightning Network and a few other layer 2 projects vulnerable to multiple RBF policies being used?\n>\n> 2.With recent discussion to change things in default RBF policy used by Core, will we have multiple versions using different policies? Are users and especially miners incentivized to use different versions and policies? Do they have freedom to use different RBF policy?\n>\n> 3.Are the recent improvements suggested for RBF policy only focused on Lightning Network and its security which will anyway remain same or become worse with multiple RBF policies?\n>\n> Note: Bitcoin Knots policy is fully configurable, even in the GUI - users can readily choose whatever policy *they* want.\n>\n> --\n> Prayank\n>\n> A3B1 E430 2298 178F\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220213/45f656e7/attachment.html>"
            },
            {
                "author": "Prayank",
                "date": "2022-02-14T05:18:30",
                "message_text_only": "> I suspect as with defaults generally most users will run whatever the defaults are as they won't care to change them (or even be capable of changing them if they are very non-technical).\n \n\n30% nodes are using 0.21.1 right now whereas latest version was 22.0 and some are even running lower versions. Different versions in future with defaults might be running RBF v1 and RBF v2.\n> But users who have a stake in the security of Lightning (or other Layer 2 projects) will clearly want to run whatever policy rules are beneficial to those protocols.\n\n\nAgree and attackers will want to run the nodes with policy that helps them exploit bitcoin projects. Miners can run nodes with policy that helps them get more fees.\u00a0\n\n> As you know the vast majority of the full nodes on the network currently run Bitcoin Core. Whether that will change in future and whether this a good thing or not is a whole other discussion. But the reality is that with such strong dominance there is the option to set defaults that are widely used.\n\nBitcoin Core with different versions are used at any point and not sure if this will ever change.\n\nhttps://luke.dashjr.org/programs/bitcoin/files/charts/security.html\n\nhttps://www.shodan.io/search/facet.png?query=User-Agent%3A%2FSatoshi%2F+port%3A%228333%22&facet=product\n> I think if certain defaults can bolster the security of Lightning (and possibly other Layer 2 projects) at no cost to full node users with no interest in those protocols we should discuss what those defaults should be.\n\n\nThis is the assumption which I don't agree with and hence asked some questions in my email. A new RBF policy used by default in Core will not improve the security of projects that are vulnerable to multiple RBF policies or rely on these policies in a way that affects their security.\u00a0\n\nMaybe some experiments on signet might help in knowing more issues associated with multiple RBF policies.\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n\n\n\nFeb 13, 2022, 21:16 by michaelfolkson at protonmail.com:\n\n> Hi Prayank\n>\n> > 1.Is Lightning Network and a few other layer 2 projects vulnerable to multiple RBF policies being used?\n>\n> Clearly the security of the Lightning Network and some other Layer 2 projects are at least impacted or partly dependent on policy rules in a way that the base blockchain/network isn't. As I (and others) have said on many occasions ideally this wouldn't be the case but it is best we can do with current designs. I (and others) take the view that this is not a reason to abandon those designs in the absence of an alternative that offers a strictly superior security model. Going back to a model where *all* activity is onchain (or even in less trust minimized protocols than Lightning) doesn't seem like the right approach to me.\n>\n> > 2.With recent discussion to change things in default RBF policy used by Core, will we have multiple versions using different policies? Are users and especially miners incentivized to use different versions and policies? Do they have freedom to use different RBF policy?\n>\n> Without making policy rules effective consensus rules users (including miners) are free to run different policy rules. I think it is too early to say what the final incentives will be to run the same or differing policies. Research into Lightning security is still nascent and we have no idea whether alternative Layer 2 projects will thrive and whether they will have the same or conflicting security considerations to Lightning. \n>\n> As you know the vast majority of the full nodes on the network currently run Bitcoin Core. Whether that will change in future and whether this a good thing or not is a whole other discussion. But the reality is that with such strong dominance there is the option to set defaults that are widely used. I think if certain defaults can bolster the security of Lightning (and possibly other Layer 2 projects) at no cost to full node users with no interest in those protocols we should discuss what those defaults should be.\n>\n> > 3.Are the recent improvements suggested for RBF policy only focused on Lightning Network and its security which will anyway remain same or become worse with multiple RBF policies?\n>\n> I think by nature of the Lightning Network being the most widely adopted Layer 2 project most of the focus has been on Lightning security. But contributors to other Layer 2 projects are free to flag and discuss security considerations that aren't Lightning specific.\n>\n> > Note: Bitcoin Knots policy is fully configurable, even in the GUI - users can readily choose whatever policy *they* want.\n>\n> The maintainer(s) and contributors to Bitcoin Knots are free to determine what default policy rules they want to implement (and make it easier for users to change those defaults) in the absence of those policy rules being made effective consensus rules. I suspect there would be strong opposition to making some policy rules effective consensus rules but we are now venturing again into future speculation and none of us have a crystal ball. Certainly if you take the view that these policy rules should never be made effective consensus rules then the fact there is at least one implementation taking a contrasting approach to Core is a good thing.\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at > protonmail.com <http://protonmail.com/>> Keybase: michaelfolkson\n> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>\n>\n> ------- Original Message -------\n>  On Sunday, February 13th, 2022 at 6:09 AM, Prayank via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n>  \n>\n>> Hello World,\n>>\n>> There was a discussion about improving fee estimation in Bitcoin Core last year in which 'instagibbs' mentioned that we cannot consider mempool as an orderbook in which which everyone is bidding for block space because nodes can use different relay policies: https://bitcoin-irc.chaincode.com/bitcoin-core-dev/2021-09-22#706294;\n>>\n>> Although I still don't consider fee rates used in last few blocks relevant for fee estimation, it is possible that we have nodes with different relay policies.\n>>\n>> Similarly if we have different RBF policies being used by nodes in future, how would this affect the security of lightning network implementations and other layer 2 projects? \n>>\n>> Based on the things shared by 'aj' in \n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-February/019846.html it is possible for an attacker to use a different RBF policy with some nodes, 10% hash power and affect the security of different projects that rely on default RBF policy in latest Bitcoin Core.\n>>\n>> There was even a CVE in which RBF policy not being documented according to the implementation could affect the security of LN: \n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-May/018893.html\n>>\n>> 1.Is Lightning Network and a few other layer 2 projects vulnerable to multiple RBF policies being used? \n>>\n>> 2.With recent discussion to change things in default RBF policy used by Core, will we have multiple versions using different policies? Are users and especially miners incentivized to use different versions and policies? Do they have freedom to use different RBF policy?\n>>\n>> 3.Are the recent improvements suggested for RBF policy only focused on Lightning Network and its security which will anyway remain same or become worse with multiple RBF policies?\n>>\n>> Note: Bitcoin Knots policy is fully configurable, even in the GUI - users can readily choose whatever policy *they* want.\n>>\n>> -- \n>> Prayank\n>>\n>> A3B1 E430 2298 178F\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220214/fbe5af9a/attachment-0001.html>"
            },
            {
                "author": "Michael Folkson",
                "date": "2022-02-14T17:02:06",
                "message_text_only": "> This is the assumption which I don't agree with and hence asked some questions in my email. A new RBF policy used by default in Core will not improve the security of projects that are vulnerable to multiple RBF policies or rely on these policies in a way that affects their security.\n\nRight, not immediately. If and when new policy rules are included in a Bitcoin Core release it would take a while before a significant majority of the network were running those new policy rules (barring some kind of urgency, an attacker exploiting a systemic security flaw etc). That's not an argument not to do it though if you take a longer term perspective on building the strongest possible foundation for Lightning or other Layer 2 projects. The security benefit would just be delayed until a significant majority of Bitcoin Core users upgraded to a version including those new policy rules.\n\n> Bitcoin Core with different versions are used at any point and not sure if this will ever change.\n\nSure there will always be some stray full nodes running extremely old versions but the general direction of travel is more and more full nodes upgrading to newer versions. A network where *all* full nodes are running the same policy rules is clearly not an option available to us without making policy rules effective consensus rules and forking/kicking those old versions off the network.\n\n> Maybe some experiments on signet might help in knowing more issues associated with multiple RBF policies.\n\nDefinitely agree. It is a really interesting research area and lots of opportunities for simulations and experiments on the default or custom signet networks. Especially if we fill blocks with auto-generated transactions and/or reduce block sizes and create an artificial fee market.\n\n--\nMichael Folkson\nEmail: michaelfolkson at [protonmail.com](http://protonmail.com/)\nKeybase: michaelfolkson\nPGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n\n------- Original Message -------\nOn Monday, February 14th, 2022 at 5:18 AM, Prayank <prayank at tutanota.de> wrote:\n\n>> I suspect as with defaults generally most users will run whatever the defaults are as they won't care to change them (or even be capable of changing them if they are very non-technical).\n>\n> 30% nodes are using 0.21.1 right now whereas latest version was 22.0 and some are even running lower versions. Different versions in future with defaults might be running RBF v1 and RBF v2.\n>\n>> But users who have a stake in the security of Lightning (or other Layer 2 projects) will clearly want to run whatever policy rules are beneficial to those protocols.\n>\n> Agree and attackers will want to run the nodes with policy that helps them exploit bitcoin projects. Miners can run nodes with policy that helps them get more fees.\n>\n>> As you know the vast majority of the full nodes on the network currently run Bitcoin Core. Whether that will change in future and whether this a good thing or not is a whole other discussion. But the reality is that with such strong dominance there is the option to set defaults that are widely used.\n>\n> Bitcoin Core with different versions are used at any point and not sure if this will ever change.\n>\n> https://luke.dashjr.org/programs/bitcoin/files/charts/security.html\n>\n> https://www.shodan.io/search/facet.png?query=User-Agent%3A%2FSatoshi%2F+port%3A%228333%22&facet=product\n>\n>> I think if certain defaults can bolster the security of Lightning (and possibly other Layer 2 projects) at no cost to full node users with no interest in those protocols we should discuss what those defaults should be.\n>\n> This is the assumption which I don't agree with and hence asked some questions in my email. A new RBF policy used by default in Core will not improve the security of projects that are vulnerable to multiple RBF policies or rely on these policies in a way that affects their security.\n>\n> Maybe some experiments on signet might help in knowing more issues associated with multiple RBF policies.\n>\n> --\n> Prayank\n>\n> A3B1 E430 2298 178F\n>\n> Feb 13, 2022, 21:16 by michaelfolkson at protonmail.com:\n>\n>> Hi Prayank\n>>\n>>> 1.Is Lightning Network and a few other layer 2 projects vulnerable to multiple RBF policies being used?\n>>\n>> Clearly the security of the Lightning Network and some other Layer 2 projects are at least impacted or partly dependent on policy rules in a way that the base blockchain/network isn't. As I (and others) have said on many occasions ideally this wouldn't be the case but it is best we can do with current designs. I (and others) take the view that this is not a reason to abandon those designs in the absence of an alternative that offers a strictly superior security model. Going back to a model where *all* activity is onchain (or even in less trust minimized protocols than Lightning) doesn't seem like the right approach to me.\n>>\n>>> 2.With recent discussion to change things in default RBF policy used by Core, will we have multiple versions using different policies? Are users and especially miners incentivized to use different versions and policies? Do they have freedom to use different RBF policy?\n>>\n>> Without making policy rules effective consensus rules users (including miners) are free to run different policy rules. I think it is too early to say what the final incentives will be to run the same or differing policies. Research into Lightning security is still nascent and we have no idea whether alternative Layer 2 projects will thrive and whether they will have the same or conflicting security considerations to Lightning.\n>>\n>> As you know the vast majority of the full nodes on the network currently run Bitcoin Core. Whether that will change in future and whether this a good thing or not is a whole other discussion. But the reality is that with such strong dominance there is the option to set defaults that are widely used. I think if certain defaults can bolster the security of Lightning (and possibly other Layer 2 projects) at no cost to full node users with no interest in those protocols we should discuss what those defaults should be.\n>>\n>>> 3.Are the recent improvements suggested for RBF policy only focused on Lightning Network and its security which will anyway remain same or become worse with multiple RBF policies?\n>>\n>> I think by nature of the Lightning Network being the most widely adopted Layer 2 project most of the focus has been on Lightning security. But contributors to other Layer 2 projects are free to flag and discuss security considerations that aren't Lightning specific.\n>>\n>>> Note: Bitcoin Knots policy is fully configurable, even in the GUI - users can readily choose whatever policy *they* want.\n>>\n>> The maintainer(s) and contributors to Bitcoin Knots are free to determine what default policy rules they want to implement (and make it easier for users to change those defaults) in the absence of those policy rules being made effective consensus rules. I suspect there would be strong opposition to making some policy rules effective consensus rules but we are now venturing again into future speculation and none of us have a crystal ball. Certainly if you take the view that these policy rules should never be made effective consensus rules then the fact there is at least one implementation taking a contrasting approach to Core is a good thing.\n>>\n>> --\n>> Michael Folkson\n>> Email: michaelfolkson at [protonmail.com](http://protonmail.com/)\n>> Keybase: michaelfolkson\n>> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>>\n>> ------- Original Message -------\n>> On Sunday, February 13th, 2022 at 6:09 AM, Prayank via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Hello World,\n>>>\n>>> There was a discussion about improving fee estimation in Bitcoin Core last year in which 'instagibbs' mentioned that we cannot consider mempool as an orderbook in which which everyone is bidding for block space because nodes can use different relay policies: https://bitcoin-irc.chaincode.com/bitcoin-core-dev/2021-09-22#706294;\n>>>\n>>> Although I still don't consider fee rates used in last few blocks relevant for fee estimation, it is possible that we have nodes with different relay policies.\n>>>\n>>> Similarly if we have different RBF policies being used by nodes in future, how would this affect the security of lightning network implementations and other layer 2 projects?\n>>>\n>>> Based on the things shared by 'aj' in\n>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-February/019846.html it is possible for an attacker to use a different RBF policy with some nodes, 10% hash power and affect the security of different projects that rely on default RBF policy in latest Bitcoin Core.\n>>>\n>>> There was even a CVE in which RBF policy not being documented according to the implementation could affect the security of LN:\n>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-May/018893.html\n>>>\n>>> 1.Is Lightning Network and a few other layer 2 projects vulnerable to multiple RBF policies being used?\n>>>\n>>> 2.With recent discussion to change things in default RBF policy used by Core, will we have multiple versions using different policies? Are users and especially miners incentivized to use different versions and policies? Do they have freedom to use different RBF policy?\n>>>\n>>> 3.Are the recent improvements suggested for RBF policy only focused on Lightning Network and its security which will anyway remain same or become worse with multiple RBF policies?\n>>>\n>>> Note: Bitcoin Knots policy is fully configurable, even in the GUI - users can readily choose whatever policy *they* want.\n>>>\n>>> --\n>>> Prayank\n>>>\n>>> A3B1 E430 2298 178F\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220214/c2938382/attachment-0001.html>"
            },
            {
                "author": "Prayank",
                "date": "2022-02-14T17:59:37",
                "message_text_only": "> That's not an argument not to do it though if you take a longer term perspective on building the strongest possible foundation for Lightning or other Layer 2 projects. The security benefit would just be delayed until a significant majority of Bitcoin Core users upgraded to a version including those new policy rules.\n\n1.An attacker does not require significant majority for such attacks. \n2.We aren't fixing the things that are broken. We can change the policy in core several times and still not achieve the goal and maybe create new issues.\n\n> A network where *all* full nodes are running the same policy rules is clearly not an option available to us without making policy rules effective consensus rules and forking/kicking those old versions off the network.\n\nA network with a policy already widely used exists right now. \n\n> Definitely agree. It is a really interesting research area and lots of opportunities for simulations and experiments on the default or custom signet networks. Especially if we fill blocks with auto-generated transactions and/or reduce block sizes and create an artificial fee market.\n\nI don't think I can convince everyone to do this however it will be helpful. I will try a few things on regtest and share results if I find anything interesting.\n\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n\n\n\nFeb 14, 2022, 22:32 by michaelfolkson at protonmail.com:\n\n> > This is the assumption which I don't agree with and hence asked some questions in my email. A new RBF policy used by default in Core will not improve the security of projects that are vulnerable to multiple RBF policies or rely on these policies in a way that affects their security.\u00a0\n>\n> Right, not immediately. If and when new policy rules are included in a Bitcoin Core release it would take a while before a significant majority of the network were running those new policy rules (barring some kind of urgency, an attacker exploiting a systemic security flaw etc). That's not an argument not to do it though if you take a longer term perspective on building the strongest possible foundation for Lightning or other Layer 2 projects. The security benefit would just be delayed until a significant majority of Bitcoin Core users upgraded to a version including those new policy rules.\n>\n> >\u00a0> Bitcoin Core with different versions are used at any point and not sure if this will ever change.\n>\n> Sure there will always be some stray full nodes running extremely old versions but the general direction of travel is more and more full nodes upgrading to newer versions. A network where *all* full nodes are running the same policy rules is clearly not an option available to us without making policy rules effective consensus rules and forking/kicking those old versions off the network.\n>\n> >\u00a0> Maybe some experiments on signet might help in knowing more issues associated with multiple RBF policies.\n>\n> Definitely agree. It is a really interesting research area and lots of opportunities for simulations and experiments on the default or custom signet networks. Especially if we fill blocks with auto-generated transactions and/or reduce block sizes and create an artificial fee market.\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at > protonmail.com <http://protonmail.com/>> Keybase: michaelfolkson\n> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>\n>\n>\n> ------- Original Message -------\n>  On Monday, February 14th, 2022 at 5:18 AM, Prayank <prayank at tutanota.de> wrote:\n>  \n>\n>> > I suspect as with defaults generally most users will run whatever the defaults are as they won't care to change them (or even be capable of changing them if they are very non-technical).\n>>\n>>\n>> 30% nodes are using 0.21.1 right now whereas latest version was 22.0 and some are even running lower versions. Different versions in future with defaults might be running RBF v1 and RBF v2.\n>>\n>> > But users who have a stake in the security of Lightning (or other Layer 2 projects) will clearly want to run whatever policy rules are beneficial to those protocols.\n>>\n>>\n>> Agree and attackers will want to run the nodes with policy that helps them exploit bitcoin projects. Miners can run nodes with policy that helps them get more fees.\u00a0\n>>\n>> > As you know the vast majority of the full nodes on the network currently run Bitcoin Core. Whether that will change in future and whether this a good thing or not is a whole other discussion. But the reality is that with such strong dominance there is the option to set defaults that are widely used.\n>>\n>>\n>> Bitcoin Core with different versions are used at any point and not sure if this will ever change.\n>>\n>> https://luke.dashjr.org/programs/bitcoin/files/charts/security.html\n>>\n>> https://www.shodan.io/search/facet.png?query=User-Agent%3A%2FSatoshi%2F+port%3A%228333%22&facet=product\n>>\n>> > I think if certain defaults can bolster the security of Lightning (and possibly other Layer 2 projects) at no cost to full node users with no interest in those protocols we should discuss what those defaults should be.\n>>\n>>\n>> This is the assumption which I don't agree with and hence asked some questions in my email. A new RBF policy used by default in Core will not improve the security of projects that are vulnerable to multiple RBF policies or rely on these policies in a way that affects their security.\u00a0\n>>\n>> Maybe some experiments on signet might help in knowing more issues associated with multiple RBF policies.\n>>\n>> -- \n>> Prayank\n>>\n>> A3B1 E430 2298 178F\n>>\n>>\n>>\n>> Feb 13, 2022, 21:16 by michaelfolkson at protonmail.com:\n>>\n>>> Hi Prayank\n>>>\n>>> > 1.Is Lightning Network and a few other layer 2 projects vulnerable to multiple RBF policies being used?\n>>>\n>>> Clearly the security of the Lightning Network and some other Layer 2 projects are at least impacted or partly dependent on policy rules in a way that the base blockchain/network isn't. As I (and others) have said on many occasions ideally this wouldn't be the case but it is best we can do with current designs. I (and others) take the view that this is not a reason to abandon those designs in the absence of an alternative that offers a strictly superior security model. Going back to a model where *all* activity is onchain (or even in less trust minimized protocols than Lightning) doesn't seem like the right approach to me.\n>>>\n>>> > 2.With recent discussion to change things in default RBF policy used by Core, will we have multiple versions using different policies? Are users and especially miners incentivized to use different versions and policies? Do they have freedom to use different RBF policy?\n>>>\n>>> Without making policy rules effective consensus rules users (including miners) are free to run different policy rules. I think it is too early to say what the final incentives will be to run the same or differing policies. Research into Lightning security is still nascent and we have no idea whether alternative Layer 2 projects will thrive and whether they will have the same or conflicting security considerations to Lightning. \n>>>\n>>> As you know the vast majority of the full nodes on the network currently run Bitcoin Core. Whether that will change in future and whether this a good thing or not is a whole other discussion. But the reality is that with such strong dominance there is the option to set defaults that are widely used. I think if certain defaults can bolster the security of Lightning (and possibly other Layer 2 projects) at no cost to full node users with no interest in those protocols we should discuss what those defaults should be.\n>>>\n>>> > 3.Are the recent improvements suggested for RBF policy only focused on Lightning Network and its security which will anyway remain same or become worse with multiple RBF policies?\n>>>\n>>> I think by nature of the Lightning Network being the most widely adopted Layer 2 project most of the focus has been on Lightning security. But contributors to other Layer 2 projects are free to flag and discuss security considerations that aren't Lightning specific.\n>>>\n>>> > Note: Bitcoin Knots policy is fully configurable, even in the GUI - users can readily choose whatever policy *they* want.\n>>>\n>>> The maintainer(s) and contributors to Bitcoin Knots are free to determine what default policy rules they want to implement (and make it easier for users to change those defaults) in the absence of those policy rules being made effective consensus rules. I suspect there would be strong opposition to making some policy rules effective consensus rules but we are now venturing again into future speculation and none of us have a crystal ball. Certainly if you take the view that these policy rules should never be made effective consensus rules then the fact there is at least one implementation taking a contrasting approach to Core is a good thing.\n>>>\n>>> --\n>>> Michael Folkson\n>>> Email: michaelfolkson at >>> protonmail.com <http://protonmail.com/>>>> Keybase: michaelfolkson\n>>> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>>>\n>>>\n>>> ------- Original Message -------\n>>> On Sunday, February 13th, 2022 at 6:09 AM, Prayank via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>\n>>>> Hello World,\n>>>>\n>>>> There was a discussion about improving fee estimation in Bitcoin Core last year in which 'instagibbs' mentioned that we cannot consider mempool as an orderbook in which which everyone is bidding for block space because nodes can use different relay policies: https://bitcoin-irc.chaincode.com/bitcoin-core-dev/2021-09-22#706294;\n>>>>\n>>>> Although I still don't consider fee rates used in last few blocks relevant for fee estimation, it is possible that we have nodes with different relay policies.\n>>>>\n>>>> Similarly if we have different RBF policies being used by nodes in future, how would this affect the security of lightning network implementations and other layer 2 projects? \n>>>>\n>>>> Based on the things shared by 'aj' in \n>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-February/019846.html it is possible for an attacker to use a different RBF policy with some nodes, 10% hash power and affect the security of different projects that rely on default RBF policy in latest Bitcoin Core.\n>>>>\n>>>> There was even a CVE in which RBF policy not being documented according to the implementation could affect the security of LN: \n>>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-May/018893.html\n>>>>\n>>>> 1.Is Lightning Network and a few other layer 2 projects vulnerable to multiple RBF policies being used? \n>>>>\n>>>> 2.With recent discussion to change things in default RBF policy used by Core, will we have multiple versions using different policies? Are users and especially miners incentivized to use different versions and policies? Do they have freedom to use different RBF policy?\n>>>>\n>>>> 3.Are the recent improvements suggested for RBF policy only focused on Lightning Network and its security which will anyway remain same or become worse with multiple RBF policies?\n>>>>\n>>>> Note: Bitcoin Knots policy is fully configurable, even in the GUI - users can readily choose whatever policy *they* want.\n>>>>\n>>>> -- \n>>>> Prayank\n>>>>\n>>>> A3B1 E430 2298 178F\n>>>>\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220214/efb7c1ba/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Lightning and other layer 2 projects with multiple RBF policies",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Michael Folkson",
                "Prayank"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 37202
        }
    },
    {
        "title": "[Lightning-dev] [bitcoin-dev] Thoughts on fee bumping, [bitcoin-dev] [Pre-BIP] Fee Accounts",
        "thread_messages": [
            {
                "author": "damian at willtech.com.au",
                "date": "2022-02-14T01:31:33",
                "message_text_only": "Good Afternoon,\n\nI wish to post this discussion back to both threads to save repeating. \nAs Peter Todd pointed out there are already two ways to increase the fee \non a transaction RBF and Child Pays for Parent. Both of these methods \nare secure and do not allow for attack. Someone said there is not \nattack, however, sponsoring transactions allows for anyone to \narbitrarily attach fees to a transaction in mempool as there is now way \nto validate that two UTXO's are associated as there are in the two cases \nalready implemented, and this vector allows exploit if unchecked. A \nminer could arbitrarily attach 1BTC to a transaction is his own mempool, \nin fact if the miner has sufficient bitcoin all transactions he intends \nto mine, or in fact all miners could, and none of them need to broadcast \nthe supplementary fee as mempool is gossip. Then when the miner is \nsuccessful in creating a block all sponsored fees are returned and it is \nnecessary for legitimate transactions to include a large fee in order to \nbe selected, which may take to form sponsorship. This miners-only attack \nallows fees to be arbitrarily driven up. As it is I guess fees are \naveraging 0.238 BTC per block with 1.7K transactions per block and a fee \nof 0.00014000 BTC per transaction and without block reward and this is \nsufficient to drive down power usage which needs to go down a lot more \nto be sustainable in our global environment.\n\nKING JAMES HRMH\nGreat British Empire\n\nRegards,\nThe Australian\nLORD HIS EXCELLENCY JAMES HRMH (& HMRH)\nof Hougun Manor & Glencoe & British Empire\nMR. Damian A. James Williamson\nWills\n\net al.\n\n\nWilltech\nwww.willtech.com.au\nwww.go-overt.com\nduigco.org DUIGCO API\nand other projects\n\n\nm. 0487135719\nf. +61261470192\n\n\nThis email does not constitute a general advice. Please disregard this \nemail if misdelivered.\nOn 2022-02-10 21:26, Antoine Riard via bitcoin-dev wrote:\n> Hi James,\n> \n> I fully agree on the need to reframe the conversation around\n> mempools/fee-bumping/L2s though please see my following comments, it's\n> far from simple!\n> \n>> Layering on special cases, more carve-outs, and X and Y percentage\n>> thresholds is going to make reasoning about the mempool harder than\n> it\n>> already is.\n> \n> I think that's true with a lot of (all ?) pieces of software, there is\n> a trend towards complexification. As new Bitcoin use-cases such as LN\n> or vaults appear, it's not surprising to see the base layer upper\n> interfaces changing to support the requirements. Same with kernels, at\n> beginning, you can have a basic memory support with paging/memory\n> rights/kernel allocators then as you start to support more\n> platforms/devices you might have to support swaps/DMA/VMs\n> management...\n> \n> That we should keep the complexity reasonably sane to enable human\n> auditing, and maybe learn from the failures of systems engineering,\n> that's something to muse on.\n> \n>> The countervailing force here ends up being spam prevention (a la\n> min-relay-fee)\n>> to prevent someone from consuming bandwidth and mempool space with a\n> long series of\n>> infinitesimal fee-bumps.\n> \n> I think here we should dissociate a) long-chain of transactions and b)\n> high-number of repeated fee-bumps.\n> \n> For a) _if_ SIGHASH_ANYPREVOUT is deployed and Eltoo adopted as a\n> primary update mechanism for stateful L2s, one might envision\n> long-chain of update transactions servicing as a new pinning vector,\n> where all the chain elements are offering a compelling feerate/fees.\n> It might be solvable with smarter mempool logic sorting the elements\n> from the best offer to the lower ones, though that issue would need\n> more serious investigation.\n> \n> For b) if we bound with a hard constant the number of RBF attempts, we\n> decrease the fault-tolerance of L2 transaction issuers. Some of them\n> might connect directly to the miners because they're offering higher\n> number of incentive-compatible RBF attempts than vanilla full-nodes.\n> That might provoke a more or slow centralization of the transaction\n> relay topology...\n> \n>> Instead of prompting a rebroadcast of the original transaction for\n>> replacement, which contains a lot of data not new to the network, it\n>> makes more sense to broadcast the \"diff\" which is the additive\n>> contribution towards some txn's feerate.\n> \n> In a distributed system such as the Bitcoin p2p network, you might\n> have transaction A and transaction B  broadcast at the same time and\n> your peer topology might fluctuate between original send and broadcast\n> of the diff, you don't know who's seen what... You might inefficiently\n> announce diff A on top of B and diff B on top A. We might leverage set\n> reconciliation there a la Erlay, though likely with increased\n> round-trips.\n> \n>> It's probably uncontroversial at this\n>> point to say that even RBF itself is kind of a hack - a special\n>> sequence number should not be necessary for post-broadcast\n> contribution\n>> toward feerate.\n> \n> I think here we should dissociate the replace-by-fee mechanism itself\n> from the replacement signaling one. To have a functional RBF, you\n> don't need signaling at all, just consider all received transactions\n> as replaceable. The replacement signaling one has been historically\n> motivated to protect the applications relying on zero-confs (with all\n> the past polemics about the well-foundedness of such claims on other\n> nodes' policy).\n> \n>> In a sane design, no structural foresight - and certainly no wasted\n>> bytes in the form of unused anchor outputs - should be needed in\n> order\n>> to add to a miner's reward for confirming a given transaction.\n> \n> Have you heard about SIGHASH_GROUP [0] ? It would move away from the\n> transaction to enable arbitrary bundles of input/outputs. You will\n> have your pre-signed bundle of inputs/outputs enforcing your\n> LN/vaults/L2 and then at broadcast time, you can attach an\n> input/output. I think it would answer your structural foresight.\n> \n>> One of the practical downsides of CPFP that I haven't seen discussed\n> in\n>> this conversation is that it requires the transaction to pre-specify\n> the\n>> keys needed to sign for fee bumps. This is problematic if you're,\n> for\n>> example, using a vault structure that makes use of pre-signed\n>> transactions.\n> \n> It's true it requires to pre-specify the fee-bumping key. Though note\n> the fee-bumping key can be fully separated from the\n> \"vaults\"/\"channels\" set of main keys and hosted on replicated\n> infrastructure such as watchtowers.\n> \n>> The interface for end-users is very straightforward: if you want to\n> bump\n>> fees, specify a transaction that contributes incrementally to\n> package\n>> feerate for some txid. Simple.\n> \n> As a L2 transaction issuer you can't be sure the transaction you wish\n> to point to is already in the mempool, or have not been replaced by\n> your counterparty spending the same shared-utxo, either competitively\n> or maliciously. So as a measure of caution, you should broadcast\n> sponsor + target transactions in the same package, thus cancelling the\n> bandwidth saving (I think).\n> \n>> This theoretical concession seems preferable to heaping more rules\n> onto\n> an already labyrinthine mempool policy that is difficult for both\n> implementers and users to reason about practically and conceptually.\n> \n> I don't think a sponsor is a silver-bullet to solve all the L2-related\n> mempool issues. It won't solve the most concerning pinning attacks, as\n> I think the bottleneck is replace-by-fee. Neither solve the issues\n> encumbered by the L2s by the dust limit.\n> \n>> If a soft-fork is the cost of cleaning up this essential process,\n>> consideration should be given to paying it as a one-time cost. This\n>> topic merits a separate post, but consider that in the 5 years\n> leading\n>> up to the 2017 SegWit drama, we averaged about a soft-fork a year.\n>> Uncontroversial, \"safe\" changes to the consensus protocol shouldn't\n> be\n>> out of the question when significant practical benefit is plain to\n> see.\n> \n> Zooming out, I think we're still early in solving those L2 issues, as\n> the most major second-layers are still in a design or deployment\n> phase. We might freeze our transaction propagation interface, and get\n> short for some of the most interesting ones like channel factories and\n> payment pools. Further, I think we're not entirely sure how the mining\n> ecosystem is going to behave once the reward is drained and their\n> incentives towards L2 confirmations.\n> \n> Still, if we think we have a correct picture of the\n> fee-bumping/mempools issues and are sufficiently confident with the\n> stability of L2 designs, I think the next step would be to come with\n> quantitative modelling of each resources consumed by fee-bumping (CPU\n> validation/bandwidth/signing interactivity for the L2s...) and then\n> score the \"next-gen\" fee-bumping primitives.\n> \n>> I'm not out to propose soft-forks lightly, but the current\n> complexity\n>> in fee management feels untenable, and as evidenced by all the\n>> discussion lately, fees are an increasingly crucial part of the\n> system.\n> \n> Overall, I think that's a relevant discussion to have ecosystem-wise.\n> Though there is a lot of context and I don't think there is a simple\n> way forward. Maybe better to stick to an evolutionary development\n> process with those mempool/fee-bumping issues. We might envision\n> two-or-three steps ahead though unlikely more.\n> \n> Cheers,\n> Antoine\n> \n> [0] SIGHASH_GROUP described here\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-May/019031.html\n> and roughly roughly implemented here :\n> https://github.com/ariard/bitcoin/pull/1\n> \n> Le jeu. 10 f\u00e9vr. 2022 \u00e0 14:48, James O'Beirne via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n> \n>> There's been much talk about fee-bumping lately, and for good reason\n>> -\n>> dynamic fee management is going to be a central part of bitcoin use\n>> as\n>> the mempool fills up (lord willing) and right now fee-bumping is\n>> fraught with difficulty and pinning peril.\n>> \n>> Gloria's recent post on the topic[0] was very lucid and highlights a\n>> lot of the current issues, as well as some proposals to improve the\n>> situation.\n>> \n>> As others have noted, the post was great. But throughout the course\n>> of reading it and the ensuing discussion, I became troubled by the\n>> increasing complexity of both the status quo and some of the\n>> \n>> proposed remedies.\n>> \n>> Layering on special cases, more carve-outs, and X and Y percentage\n>> thresholds is going to make reasoning about the mempool harder than\n>> it\n>> already is. Special consideration for \"what should be in the next\n>> block\" and/or the caching of block templates seems like an imposing\n>> dependency, dragging in a bunch of state and infrastructure to a\n>> question that should be solely limited to mempool feerate aggregates\n>> and the feerate of the particular txn package a wallet is concerned\n>> with.\n>> \n>> This is bad enough for protocol designers and Core developers, but\n>> making the situation any more intractable for \"end-users\" and wallet\n>> developers feels wrong.\n>> \n>> I thought it might be useful to step back and reframe. Here are a\n>> few\n>> aims that are motivated chiefly by the quality of end-user\n>> experience,\n>> constrained to obey incentive compatibility (i.e. miner reward, DoS\n>> avoidance). Forgive the abstract dalliance for a moment; I'll talk\n>> through concretes afterwards.\n>> \n>> # Purely additive feerate bumps should never be impossible\n>> \n>> Any user should always be able to add to the incentive to mine any\n>> transaction in a purely additive way. The countervailing force here\n>> ends up being spam prevention (a la min-relay-fee) to prevent\n>> someone\n>> from consuming bandwidth and mempool space with a long series of\n>> infinitesimal fee-bumps.\n>> \n>> A fee bump, naturally, should be given the same per-byte\n>> consideration\n>> as a normal Bitcoin transaction in terms of relay and block space,\n>> although it would be nice to come up with a more succinct\n>> representation. This leads to another design principle:\n>> \n>> # The bandwidth and chain space consumed by a fee-bump should be\n>> minimal\n>> \n>> Instead of prompting a rebroadcast of the original transaction for\n>> replacement, which contains a lot of data not new to the network, it\n>> makes more sense to broadcast the \"diff\" which is the additive\n>> contribution towards some txn's feerate.\n>> \n>> This dovetails with the idea that...\n>> \n>> # Special transaction structure should not be required to bump fees\n>> \n>> In an ideal design, special structural foresight would not be needed\n>> \n>> in order for a txn's feerate to be improved after broadcast.\n>> \n>> Anchor outputs specified solely for CPFP, which amount to many bytes\n>> of\n>> wasted chainspace, are a hack. It's probably uncontroversial at this\n>> point to say that even RBF itself is kind of a hack - a special\n>> sequence number should not be necessary for post-broadcast\n>> contribution\n>> toward feerate. Not to mention RBF's seemingly wasteful consumption\n>> of\n>> bandwidth due to the rebroadcast of data the network has already\n>> seen.\n>> \n>> In a sane design, no structural foresight - and certainly no wasted\n>> bytes in the form of unused anchor outputs - should be needed in\n>> order\n>> to add to a miner's reward for confirming a given transaction.\n>> \n>> Planning for fee-bumps explicitly in transaction structure also\n>> often\n>> winds up locking in which keys are required to bump fees, at odds\n>> with the idea that...\n>> \n>> # Feerate bumps should be able to come from anywhere\n>> \n>> One of the practical downsides of CPFP that I haven't seen discussed\n>> in\n>> this conversation is that it requires the transaction to pre-specify\n>> the\n>> keys needed to sign for fee bumps. This is problematic if you're,\n>> for\n>> example, using a vault structure that makes use of pre-signed\n>> transactions.\n>> \n>> What if the key you specified n the anchor outputs for a bunch of\n>> pre-signed txns is compromised? What if you'd like to be able to\n>> dynamically select the wallet that bumps fees? CPFP does you no\n>> favors\n>> here.\n>> \n>> There is of course a tension between allowing fee bumps to come from\n>> anywhere and the threat of pinning-like attacks. So we should\n>> venture\n>> to remove pinning as a possibility, in line with the first design\n>> principle I discuss.\n>> \n>> ---\n>> \n>> Coming down to earth, the \"tabula rasa\" thought experiment above has\n>> led\n>> me to favor an approach like the transaction sponsors design that\n>> Jeremy\n>> proposed in a prior discussion back in 2020[1].\n>> \n>> Transaction sponsors allow feerates to be bumped after a\n>> transaction's\n>> broadcast, regardless of the structure of the original transaction.\n>> No rebroadcast (wasted bandwidth) is required for the original txn\n>> data.\n>> No wasted chainspace on only-maybe-used prophylactic anchor outputs.\n>> \n>> \n>> The interface for end-users is very straightforward: if you want to\n>> bump\n>> fees, specify a transaction that contributes incrementally to\n>> package\n>> feerate for some txid. Simple.\n>> \n>> In the original discussion, there were a few main objections that I\n>> noted:\n>> \n>> 1. In Jeremy's original proposal, only one sponsor txn per txid is\n>> allowed by policy. A malicious actor could execute a pinning-like\n>> \n>> attack by specifying an only-slightly-helpful feerate sponsor\n>> that\n>> then precludes other larger bumps.\n>> \n>> I think there are some ways around this shortcoming. For example:\n>> what\n>> if, by policy, sponsor txns had additional constraints that\n>> \n>> - each input must be signed\n>> {SIGHASH_SINGLE,SIGHASH_NONE}|ANYONECANPAY,\n>> - the txn must be specified RBFable,\n>> - a replacement for the sponsor txn must raise the sponsor\n>> feerate,\n>> including ancestors (maybe this is inherent in \"is RBFable,\" but\n>> \n>> I don't want to conflate absolute feerates into this).\n>> \n>> That way, there is still at most a single sponsor txn per txid in\n>> the\n>> mempool, but anyone can \"mix in\" inputs which bump the effective\n>> feerate of the sponsor.\n>> \n>> This may not be the exact solution we want, but I think it\n>> demonstrates\n>> that the sponsors design has some flexibility and merits some\n>> thinking.\n>> \n>> The second objection about sponsors was\n>> \n>> 2. (from Suhas) sponsors break the classic invariant: \"once a valid\n>> transaction is created, it should not become invalid later on\n>> unless\n>> the inputs are double-spent.\"\n>> \n>> This doesn't seem like a huge concern to me if you consider the txid\n>> being sponsored as a sort of spiritual input to the sponsor. While\n>> the\n>> theoretical objection against broadening where one has to look in a\n>> txn\n>> to determine its dependencies is understandable, I don't see what\n>> the\n>> practical cost here is.\n>> \n>> Reorg complexity seems comparable if not identical, especially if we\n>> broaden sponsor rules to allow blocks to contain sponsor txns that\n>> are\n>> both for txids in the same block _or_ already included in the chain.\n>> \n>> This theoretical concession seems preferable to heaping more rules\n>> onto\n>> an already labyrinthine mempool policy that is difficult for both\n>> implementers and users to reason about practically and conceptually.\n>> \n>> A third objection that wasn't posed, IIRC, but almost certainly\n>> would\n>> be:\n>> \n>> 3. Transaction sponsors requires a soft-fork.\n>> \n>> Soft-forks are no fun, but I'll tell you what also isn't fun: being\n>> on\n>> the hook to model (and sometimes implement) a dizzying potpourri of\n>> mempool policies and special-cases. Expecting wallet implementers to\n>> abide by a maze of rules faithfully in order to ensure txn broadcast\n>> and\n>> fee management invites bugs for perpetuity and network behavior that\n>> is\n>> difficult to reason about a priori. Use of CPFP in the long-term\n>> also\n>> risks needless chain waste.\n>> \n>> If a soft-fork is the cost of cleaning up this essential process,\n>> consideration should be given to paying it as a one-time cost. This\n>> topic merits a separate post, but consider that in the 5 years\n>> leading\n>> up to the 2017 SegWit drama, we averaged about a soft-fork a year.\n>> Uncontroversial, \"safe\" changes to the consensus protocol shouldn't\n>> be\n>> out of the question when significant practical benefit is plain to\n>> see.\n>> \n>> ---\n>> \n>> I hope this message has added some framing to the discussion on\n>> fees,\n>> as well prompting other participants to go back and give the\n>> transaction sponsor proposal a serious look. The sponsors interface\n>> is\n>> about the simplest I can imagine for wallets, and it seems easy to\n>> reason about for implementers on Core and elsewhere.\n>> \n>> I'm not out to propose soft-forks lightly, but the current\n>> complexity\n>> in fee management feels untenable, and as evidenced by all the\n>> discussion lately, fees are an increasingly crucial part of the\n>> system.\n>> \n>> [0]:\n>> \n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019817.html\n>> [1]:\n>> \n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-September/018168.html\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            }
        ],
        "thread_summary": {
            "title": "Thoughts on fee bumping, Fee Accounts",
            "categories": [
                "Lightning-dev",
                "bitcoin-dev",
                "bitcoin-dev",
                "Pre-BIP"
            ],
            "authors": [
                "damian at willtech.com.au"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 19473
        }
    },
    {
        "title": "[Lightning-dev] [RFC] Lightning gossip alternative",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2022-02-14T01:41:06",
                "message_text_only": "Hi all,\n\n        I've floated this idea before, but this is a more concrete\nproposal for a \"v2\" gossip protocol.\n\nIt assumes x-only pubkeys (aka point32) and BIP-340 signatures, and uses\nmodern TLVs for all optional or extensible fields.  Timestamps are\nreplaced with block heights.\n\n1. Nodes send out weekly node_announcement_v2, proving they own some\n   UTXOs.\n2. This entitles them to broadcast channels, using channel_update_v2; a\n   channel_update_v2 from both peers means the channel exists.\n3. This uses UTXOs for anti-spam, but doesn't tie them to channels\n   directly.\n4. Future ZKP proofs are could be added.\n\n1. type: 271 (`node_announcement_v2`)\n2. data:\n    * [`bip340sig`:`signature`]\n    * [`point32`:`node_id`]\n    * [`u32`:`blockheight`]\n    * [`node_announcement_v2_tlvs`:`tlvs`]\n\n1. `tlv_stream`: `node_announcement_v2_tlvs`\n2. types:\n    1. type: 2 (`features`)\n    2. data:\n        * [`...*byte`:`featurebits`]\n    1. type: 3 (`chain_hash`)\n    2. data:\n        * [`chain_hash`:`chain`]\n    1. type: 4 (`taproot_utxo_proofs`)\n    2. data:\n        * [`...*taproot_utxo_proof`:`proofs`]\n    1. type: 6 (`legacy_utxo_proofs`)\n    2. data:\n        * [`...*legacy_utxo_proof`:`proofs`]\n    1. type: 127 (`ipv4_addresses`)\n    2. data:\n        * [`...*ipv4`:`addresses`]\n    1. type: 129 (`ipv6_addresses`)\n    2. data:\n        * [`...*ipv6`:`addresses`]\n    1. type: 131 (`torv3_addresses`)\n    2. data:\n        * [`...*torv3`:`addr`]\n# Maybe alias, color, etc?\n\nTaproot proofs are a signature of the v1 output over the `node_id`,\n`utxo` and `blockheight` with prefix \"lightingtaproot_utxo_proofsig\"\n(using the tagged signatures as per BOLT12). (FIXME: what about\ntapscripts?).\n\nLegacy proofs are two signatures, similar to the existing\nchannel_announcement.\n\n1. subtype: `taproot_utxo_proof`\n2. data:\n    * [`short_channel_id`:`utxo`]\n    * [`signature`:`sig`]\n\n1. subtype: `legacy_utxo_proof`\n2. data:\n    * [`short_channel_id`:`utxo`]\n    * [`point`:`bitcoin_key_1`]\n    * [`point`:`bitcoin_key_2`]\n    * [`signature`:`sig_1`]\n    * [`signature`:`sig_2`]\n\n- node_announcement_v2 are discarded after a week (1000 blocks).\n- If two node_announcement_v2 claim the same UTXO, use the first seen,\n  discard any others.\n- Nodes do not need to monitor existence of UTXOs after initial check (since\n  they will automatically prune them after a week).\n- The total proved utxo value (not counting any utxos which are spent)\n  is multiplied by 10 to give the \"announcable_channel_capacity\" for that node.\n\n1. type: 273 (`channel_update_v2`)\n2. data:\n    * [`bip340sig`:`signature`]\n    * [`point32`:`local_node_id`]\n    * [`point32`:`remote_node_id`]\n    * [`u32`:`blockheight`]\n    * [`u32`:`channel_id_and_claimant`]\n    * [`channel_update_v2_tlvs`:`tlvs`]\n\n1. `tlv_stream`: `channel_update_v2_tlvs`\n2. types:\n    1. type: 2 (`features`)\n    2. data:\n        * [`...*byte`:`featurebits`]\n    1. type: 3 (`chain_hash`)\n    2. data:\n        * [`chain_hash`:`chain`]\n    1. type: 4 (`capacity`)\n    2. data:\n        * [`tu64`:`satoshis`]\n    1. type: 5 (`cost`)\n    2. data:\n       * [`u16`:`cltv_expiry_delta`]\n       * [`u32`:`fee_proportional_millionths`]\n       * [`tu32`:`fee_base_msat`]\n    1. type: 6 (`min_msat`)\n    2. data:\n        * [`tu64`:`min_htlc_sats`]\n\n- `channel_id_and_claimant` is a 31-bit per-node channel_id which can be\n  used in onion_messages, and a one bit stolen for the `claim` flag.\n- A channel is not considered to exist until both peers have sent a\n  channel_update_v2, at least one of which must set the `claim` flag.\n- If a node sets `claim`, the capacity of the channel is subtracted from\n  the remaining announcable_channel_capacity for that node (minimum\n  10,000 sats).\n- If there is insufficient total `announcable_channel_capacity` for a\n  node, it is used by the lower `channel_id`s first.\n\nImplications\n------------\n\nThis simplifies gossip, requiring only two messages instead of three,\nand reducing the UTXO validation requirements to per-node instead of\nper-channel.  We can use a convention that a channel_update_v2 with no\n`capacity` is a permanent close.\n\nWe might want to add a taproot_utxo_delegated_proof where UTXOs can\nsign over to another key, so cold storage only needs to sign once, and\nthe other key can sign weekly.\n\nIt also allows \"leasing\" of UTXOs: you could pay someone to sign their\nUTXO for your node_announcement, with some level of trust.  They could\nspend the UTXO, which gives you a slow degredation as new nodes don't\naccept your channels but existing nodes don't check until it's due for a\nrefresh).  Or they could sign one UTXO for multiple node_announcements,\nwhich is why preference is given to the first-seen.  But it's a weekly\nbusiness so there's incentive for them not to.\n\nBetween nodes there's the question of \"who claims this new channel?\",\nwhich I didn't address here.  Opener claims is logical, but leaks\ninformation (though you could definitely pay for the peer to claim it).\nWith dual-funding, it's more complex (some kind of proportional coinflip\nprotocol is possible), but basically you can always wait for your peer,\nand if they don't set the claim bit you can.\n\nCheers!\nRusty."
            },
            {
                "author": "Joost Jager",
                "date": "2022-02-15T13:45:48",
                "message_text_only": "Hi Rusty,\n\nNice to see the proposal in more concrete terms. Few questions:\n\n- The total proved utxo value (not counting any utxos which are spent)\n>   is multiplied by 10 to give the \"announcable_channel_capacity\" for that\n> node.\n>\n\nCould this work as a dynamic value too, similar to the minimum relay fee on\nL1?\n\n\n> 1. `tlv_stream`: `channel_update_v2_tlvs`\n>\n2. types:\n>     1. type: 4 (`capacity`)\n>     2. data:\n>         * [`tu64`:`satoshis`]\n>\n\nWhat does capacity mean exactly outside the context of a real channel? Will\nthis be reduced to that maximum htlc amount that the nodes want to route,\nto save as much of the announceable budget as possible?\n\nIt is also the question of whether 10 x 10k channels should weigh as much\non the budget as a 1 x 100k channel. A spammer may be able to do more harm\nwith multiple smaller channels because there is more for the sender's\npathfinding algorithms to explore. Maybe it doesn't matter as long as there\nis some mechanism to discourage spam.\n\n\n>     1. type: 5 (`cost`)\n>     2. data:\n>        * [`u16`:`cltv_expiry_delta`]\n>        * [`u32`:`fee_proportional_millionths`]\n>        * [`tu32`:`fee_base_msat`]\n>     1. type: 6 (`min_msat`)\n>     2. data:\n>         * [`tu64`:`min_htlc_sats`]\n>\n> - `channel_id_and_claimant` is a 31-bit per-node channel_id which can be\n>   used in onion_messages, and a one bit stolen for the `claim` flag.\n>\n\nIf you'd increase the budget multiplier from 10 to 20, couldn't this be\nsimplified to always applying the cost to both nodes?\n\n\n> - A channel is not considered to exist until both peers have sent a\n>   channel_update_v2, at least one of which must set the `claim` flag.\n> - If a node sets `claim`, the capacity of the channel is subtracted from\n>   the remaining announcable_channel_capacity for that node (minimum\n>   10,000 sats).\n>\n\nSame question about magic value and whether it can be dynamic.\n\nJoost\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220215/1c100bd3/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2022-02-16T02:35:16",
                "message_text_only": "Joost Jager <joost.jager at gmail.com> writes:\n> Hi Rusty,\n>\n> Nice to see the proposal in more concrete terms. Few questions:\n>\n> - The total proved utxo value (not counting any utxos which are spent)\n>>   is multiplied by 10 to give the \"announcable_channel_capacity\" for that\n>> node.\n>>\n>\n> Could this work as a dynamic value too, similar to the minimum relay fee on\n> L1?\n\nI made the number up, so I'm not very attached to it.  How would we\nchoose to scale it though?  If nodes don't use the same value it makes\nfor wasted gossip (and minisketch-based gossip much harder).\n\n>> 1. `tlv_stream`: `channel_update_v2_tlvs`\n>>\n> 2. types:\n>>     1. type: 4 (`capacity`)\n>>     2. data:\n>>         * [`tu64`:`satoshis`]\n>>\n>\n> What does capacity mean exactly outside the context of a real channel? Will\n> this be reduced to that maximum htlc amount that the nodes want to route,\n> to save as much of the announceable budget as possible?\n\nYes, it's the old htlc_maximum_msat, but expressed in satoshis because\nmsat seems to finegrained?\n\n> It is also the question of whether 10 x 10k channels should weigh as much\n> on the budget as a 1 x 100k channel. A spammer may be able to do more harm\n> with multiple smaller channels because there is more for the sender's\n> pathfinding algorithms to explore. Maybe it doesn't matter as long as there\n> is some mechanism to discourage spam.\n\nYes, I suggested a minimum cost to avoid 100k 1sat channels, I don't\nknow if we should be more sophisticated.\n\n>>     1. type: 5 (`cost`)\n>>     2. data:\n>>        * [`u16`:`cltv_expiry_delta`]\n>>        * [`u32`:`fee_proportional_millionths`]\n>>        * [`tu32`:`fee_base_msat`]\n>>     1. type: 6 (`min_msat`)\n>>     2. data:\n>>         * [`tu64`:`min_htlc_sats`]\n>>\n>> - `channel_id_and_claimant` is a 31-bit per-node channel_id which can be\n>>   used in onion_messages, and a one bit stolen for the `claim` flag.\n>\n> If you'd increase the budget multiplier from 10 to 20, couldn't this be\n> simplified to always applying the cost to both nodes?\n\nYes!  I forgot that capacity doesn't have to be symmetrical; if I open a\ngiant channel with you, and you don't want to expose more UTXOs, you\njust set your capacity to some lower value.\n\n>> - A channel is not considered to exist until both peers have sent a\n>>   channel_update_v2, at least one of which must set the `claim` flag.\n>> - If a node sets `claim`, the capacity of the channel is subtracted from\n>>   the remaining announcable_channel_capacity for that node (minimum\n>>   10,000 sats).\n>\n> Same question about magic value and whether it can be dynamic.\n\nYes, 10ksat might be giant one day?  We can change it naively with a\nfeature bit (\"I use v2 capacity calcs\"), or in some more finegrained\nway, but what do we base it on?\n\nCheers!\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-02-18T02:33:08",
                "message_text_only": "Good morning rusty,\n\nIf we are going to switch to a new gossip version, should we prepare now for published channels that are backed by channel factories?\n\nInstead of a UTXO serving as a bond to allow advertisement of a *single* channel, allow it to advertise *multiple* channels.\nThis does not require us to flesh out the details of channel factories in the gossip protocol, especially post-Taproot --- we could simply require that a simple BIP-340 signature of the gossip message attesting to multiple channels is enough, and the details of the channel factories can be left to later protocol updates.\n\n\nThe reason for this is that for a set of N published nodes, there is an incentive to make as many channels as possible between pairs of nodes.\nWe expect that for N published nodes, all (N * (N - 1)) / 2 possible channels will be created, as that maximizes the expected fee return of the N published nodes.\n\nWithout the ability to gossip channel factories, channel factories can only be used for unpublished channels.\nDue to not being available for routing, given an \"LSP\" and N clients, there is no incentive for the N clients to make direct channels to each other.\n(In particular, one of the reasons given for unpublished channels is that the clients of an LSP may not have high onlineness, thus an unpublished channel would really only exist between a public LSP and a non-published client of that LSP.)\nThis means that for N clients we expect only N channels backed by the channel factory (and thus by the UTXO).\n\nIt seems to me to be a good idea to have as much of the public network backed by fewer UTXOs, as the published network has far more channels for every N participants.\n\n(as well, supporting channel factories for the public graph does not preclude the unpublished graph from using channel factories, so even if the unpublished graph turns out to be much larger than the published graph, reducing the UTXO set of the published graph does not prevent reducing the UTXO set of the unpublished graph anyway.)\n\n\nAgainst this, we should note that it makes stuffing the public graph cheaper (a single UTXO can now justify the addition of multiple edges on the public routing graph), which translates to making it easier to increase the complexity of the public graph and thus increase the cost of pathfinding.\n\n\nThoughts?\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Rusty Russell",
                "date": "2022-02-20T23:02:20",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n> Good morning rusty,\n>\n> If we are going to switch to a new gossip version, should we prepare now for published channels that are backed by channel factories?\n\nThis is already true with the new proposal: channels don't have to be\n\"real\".  It's possible to raise the required ratio later, so less UTXO\nproof is required (since channels are prioritized by their id, you can\nchoose which ones older nodes will see.\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Lightning gossip alternative",
            "categories": [
                "Lightning-dev",
                "RFC"
            ],
            "authors": [
                "Rusty Russell",
                "Joost Jager",
                "ZmnSCPxj"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 12859
        }
    },
    {
        "title": "[Lightning-dev] Normal operation questions",
        "thread_messages": [
            {
                "author": "Benjamin Weintraub",
                "date": "2022-02-15T15:31:45",
                "message_text_only": "Hi all,\n\nI have a couple questions about the Normal Operation protocol. For the following, consider a single-hop payment between Alice and Bob over a single channel.\n\n1) Multiple sources indicate that after Alice sends the `update_add_htlc`, she should then send the `commitment_signed`, but why is it important that she sends it first (before Bob)? As far as I understand, as long as she doesn't revoke the old state before Bob commits to the new state, there shouldn't be a problem. In that case, the order wouldn't matter---they could even send their commitments concurrently. So does the order matter?\n\n2) After Bob sends the `update_fulfill_htlc`, both he and Alice exchange `commitment_signed` and `revoke_and_ack` messages again. Why is this necessary? After Alice receives the preimage, doesn't she have enough information to claim her funds (with the new state)?\n\n\nThanks!\nBen\n\n--\nBen Weintraub\nPhD Student\nKhoury College of Computer Sciences\nNortheastern University\nhttps://ben-weintraub.com/\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220215/ea3c951b/attachment.html>"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2022-02-15T23:13:47",
                "message_text_only": "Hi Benjamin,\n\n> 1) Multiple sources indicate that after Alice sends the `update_add_htlc`,\n> she should then send the `commitment_signed`, but why is it important that\n> she sends it first (before Bob)? As far as I understand, as long as she\n> doesn't revoke the old state before Bob commits to the new state, there\n> shouldn't be a problem. In that case, the order wouldn't matter---they\ncould\n> even send their commitments concurrently. So does the order matter?\n\nYou're correct that it isn't absolutely necessary that she sends a new\nsignature after adding a new HTLC to the pending set of HTLCs. Alice may\nwant to delay her signature if she has other HTLCs she wants to add to the\ncommitment transaction, which allows her to batch/pipeline updates to the\nchannel.\n\nIf Alice is forwarding that HTLC, and Bob's side of the channel has been\ndormant (not making many updates), then it's her best interest to propose a\nnew state immediately as she may generate some routing fees from a\nsuccessful forward.\n\nConcurrent signatures aren't an issue, but will end up generating additional\nstate transitions for both sides to have the exact same set of locked in\nHTLCs.\n\n> 2) After Bob sends the `update_fulfill_htlc`, both he and Alice exchange\n> `commitment_signed` and `revoke_and_ack` messages again. Why is this\n> necessary? After Alice receives the preimage, doesn't she have enough\n> information to claim her funds (with the new state)?\n\nIf Bob is sending the pre-image, then _he_ is the one that is claiming the\nfunds. Once Bob learns of the pre-image, he can go to chain if he wants to\nin order to claim the HTLC. However that'll be a lot slower and also cost\nmore in chain fees than doing an update off-chain to settle the HTLC from\nthe PoV of the commitment transaction of both parties.  Both sides exchange\nthose messages in order to update their commitment state _off chain_.\n\nOnce Alice receives the pre-image (assuming a multi-hop scenario), she can\nopt to not wait for the full exchange, and instead _pipeline_ the pre-image\nback upstream in the route. In practice, this can reduce perceived user\nlatency for payments, as you can side step the 1.5 RTTs at each hop in the\nroute, and simply sling the pre-image all the way back to the original\nsender.\n\n-- Laolu\n\nOn Tue, Feb 15, 2022 at 7:32 AM Benjamin Weintraub <\nweintraub.b at northeastern.edu> wrote:\n\n> Hi all,\n>\n> I have a couple questions about the Normal Operation protocol. For the\n> following, consider a single-hop payment between Alice and Bob over a\n> single channel.\n>\n> 1) Multiple sources indicate that after Alice sends the `update_add_htlc`,\n> she should then send the `commitment_signed`, but why is it important that\n> she sends it first (before Bob)? As far as I understand, as long as she\n> doesn't revoke the old state before Bob commits to the new state, there\n> shouldn't be a problem. In that case, the order wouldn't matter---they\n> could even send their commitments concurrently. So does the order matter?\n>\n> 2) After Bob sends the `update_fulfill_htlc`, both he and Alice exchange\n> `commitment_signed` and `revoke_and_ack` messages again. Why is this\n> necessary? After Alice receives the preimage, doesn't she have enough\n> information to claim her funds (with the new state)?\n>\n>\n> Thanks!\n> Ben\n>\n> --\n> Ben Weintraub\n> PhD Student\n> Khoury College of Computer Sciences\n> Northeastern University\n> https://ben-weintraub.com/\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220215/80150412/attachment-0001.html>"
            },
            {
                "author": "Benjamin Weintraub",
                "date": "2022-02-16T21:01:52",
                "message_text_only": "Hi Laolu!\n\nThanks for the helpful reply. A couple follow up questions:\n\n1) Why would concurrent signatures generate additional messages? My understanding is that by the time the signatures are sent, the HTLCs are already locked in.\n\n2) Perhaps I didn't just understand your explanation, but I still don't get why the additional `commitment_signed` and `revoke_and_ack` messages are necessary. The initial pair of `commitment_signed` and `revoke_and_ack` messages establish a new state _conditioned_ on possessing the pre-image, right? So after the pre-image is shared, then all parties have assurance of the new state and therefore _could_ go to the chain (even if they don't want to, because they want to keep the channel open). Since the new state is already guaranteed by the previous commitments and revocations, what purpose do the additional commitments and revocations provide?\n\n\nThanks again!\nBen\n\n--\nBen Weintraub\nPhD Student\nKhoury College of Computer Sciences\nNortheastern University\nhttps://ben-weintraub.com/\n\n________________________________\nFrom: Olaoluwa Osuntokun <laolu32 at gmail.com>\nSent: Tuesday, February 15, 2022 18:13\nTo: Benjamin Weintraub <weintraub.b at northeastern.edu>\nCc: Lightning-dev at lists.linuxfoundation.org <lightning-dev at lists.linuxfoundation.org>\nSubject: Re: [Lightning-dev] Normal operation questions\n\nHi Benjamin,\n\n> 1) Multiple sources indicate that after Alice sends the `update_add_htlc`,\n> she should then send the `commitment_signed`, but why is it important that\n> she sends it first (before Bob)? As far as I understand, as long as she\n> doesn't revoke the old state before Bob commits to the new state, there\n> shouldn't be a problem. In that case, the order wouldn't matter---they could\n> even send their commitments concurrently. So does the order matter?\n\nYou're correct that it isn't absolutely necessary that she sends a new\nsignature after adding a new HTLC to the pending set of HTLCs. Alice may\nwant to delay her signature if she has other HTLCs she wants to add to the\ncommitment transaction, which allows her to batch/pipeline updates to the\nchannel.\n\nIf Alice is forwarding that HTLC, and Bob's side of the channel has been\ndormant (not making many updates), then it's her best interest to propose a\nnew state immediately as she may generate some routing fees from a\nsuccessful forward.\n\nConcurrent signatures aren't an issue, but will end up generating additional\nstate transitions for both sides to have the exact same set of locked in\nHTLCs.\n\n> 2) After Bob sends the `update_fulfill_htlc`, both he and Alice exchange\n> `commitment_signed` and `revoke_and_ack` messages again. Why is this\n> necessary? After Alice receives the preimage, doesn't she have enough\n> information to claim her funds (with the new state)?\n\nIf Bob is sending the pre-image, then _he_ is the one that is claiming the\nfunds. Once Bob learns of the pre-image, he can go to chain if he wants to\nin order to claim the HTLC. However that'll be a lot slower and also cost\nmore in chain fees than doing an update off-chain to settle the HTLC from\nthe PoV of the commitment transaction of both parties.  Both sides exchange\nthose messages in order to update their commitment state _off chain_.\n\nOnce Alice receives the pre-image (assuming a multi-hop scenario), she can\nopt to not wait for the full exchange, and instead _pipeline_ the pre-image\nback upstream in the route. In practice, this can reduce perceived user\nlatency for payments, as you can side step the 1.5 RTTs at each hop in the\nroute, and simply sling the pre-image all the way back to the original\nsender.\n\n-- Laolu\n\nOn Tue, Feb 15, 2022 at 7:32 AM Benjamin Weintraub <weintraub.b at northeastern.edu<mailto:weintraub.b at northeastern.edu>> wrote:\nHi all,\n\nI have a couple questions about the Normal Operation protocol. For the following, consider a single-hop payment between Alice and Bob over a single channel.\n\n1) Multiple sources indicate that after Alice sends the `update_add_htlc`, she should then send the `commitment_signed`, but why is it important that she sends it first (before Bob)? As far as I understand, as long as she doesn't revoke the old state before Bob commits to the new state, there shouldn't be a problem. In that case, the order wouldn't matter---they could even send their commitments concurrently. So does the order matter?\n\n2) After Bob sends the `update_fulfill_htlc`, both he and Alice exchange `commitment_signed` and `revoke_and_ack` messages again. Why is this necessary? After Alice receives the preimage, doesn't she have enough information to claim her funds (with the new state)?\n\n\nThanks!\nBen\n\n--\nBen Weintraub\nPhD Student\nKhoury College of Computer Sciences\nNortheastern University\nhttps://ben-weintraub.com/<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fben-weintraub.com%2F&data=04%7C01%7Cweintraub.b%40northeastern.edu%7Cd033116731cd4050291708d9f0d8d9bb%7Ca8eec281aaa34daeac9b9a398b9215e7%7C0%7C0%7C637805637505660537%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&sdata=ip73Qo2E1UUud0LxEuMVCpYJQNxYQYLB3YtW0xIrtUA%3D&reserved=0>\n\n_______________________________________________\nLightning-dev mailing list\nLightning-dev at lists.linuxfoundation.org<mailto:Lightning-dev at lists.linuxfoundation.org>\nhttps://lists.linuxfoundation.org/mailman/listinfo/lightning-dev<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Flists.linuxfoundation.org%2Fmailman%2Flistinfo%2Flightning-dev&data=04%7C01%7Cweintraub.b%40northeastern.edu%7Cd033116731cd4050291708d9f0d8d9bb%7Ca8eec281aaa34daeac9b9a398b9215e7%7C0%7C0%7C637805637505660537%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&sdata=V1m2qqncyahnT7crpeYhCmgGcBjep%2Ft%2FIBnjzuDbRJk%3D&reserved=0>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220216/16cb3180/attachment.html>"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2022-02-17T00:15:05",
                "message_text_only": "Hi Benjamin,\n\nGlad you found it helpful, always happy to help clarify stuff like this. I\nhope to eventually be able to leverage some recent research [1] in this area\nto improve the specification, as well as general understanding of the update\nprotocol.\n\n> 1) Why would concurrent signatures generate additional messages? My\n> understanding is that by the time the signatures are sent, the HTLCs are\n> already locked in.\n\nThe commitment state for the type of revocation channels we use today are\n_asymmetric_: we both have our own copy of the latest channel state (though\nsymmetric state revocation designs do exist [2][3]). When I send an add,\nthen a sig to you and you revoke, then only _you_ have the HTLC on your\nlatest commitment.  Another round is required for _me_ (the one that\nproposed the new HTLC in the first place) to obtain a commitment with this\nnew HTLC.\n\nWhen a party sends a new signature, that new signature only commits to any\n_remoteu_ pdates included _before_ my last revocation message. As an example\nlet's say Alice and Bob both send new HTLCs htlc_a, and htlc_b, then\nconcurrently send new signatures. Alice's initial signature to Bob _does not\ninclude_ htlc_b, only htlc_a. The opposite is true for Bob. At the end of\nthis initial exchange, Alice's commitment contains htlc_a and Bob's has\nhtlc_b.\n\nThis type of interaction is mentioned in passing in the spec:\n\n> Counter-intuitively, these updates apply to the other node's commitment\n> transaction; the node only adds those updates to its own commitment\n> transaction when the remote node acknowledges it has applied them via\n> revoke_and_ack.\n\nAnother signature exchange is required to synchronize both commitments.\nDepending on the processing order of the concurrent messages, additional\nstates may be created. However this isn't strictly required (stop and try to\nsynchronize commitments), as the protocol is non-blocking and as soon as the\nHTLC is included in _both_ commitments (developers usually refer to this as\nHTLCs being _locked in_), then they're safe to forward. The spec calls out\nthis interaction in this fragment:\n\n> As the two nodes' updates are independent, the two commitment transactions\n> may be out of sync indefinitely. This is not concerning: what matters is\n> whether both sides have irrevocably committed to a particular update or\n> not (the final state, above).\n\n\n> 2) Perhaps I didn't just understand your explanation, but I still don't\n> get why the additional `commitment_signed` and `revoke_and_ack` messages\n> are necessary. The initial pair of `commitment_signed` and\n> `revoke_and_ack` messages establish a new state _conditioned_ on\n> possessing the pre-image, right?\n\nPutting it another way: that extra round is needed to _remove_ the HTLC from\n_both_ commitment transactions. You're correct that since they have the\npre-image they have the option of going to chain whenever, but then that\nmeans they need to hold onto that HTLC in the commitment transaction\n\"forever\". Today there're a limited amount of slots for HTLCs, so keeping\nthat extra HTLC reduces the available throughput of a channel.\n\nReading the initial message I'm not sure I fully understand the\nquestion/ambiguity, but I _think_ the above answers it? Happy to carry on so\nwe can sync our mental models.\n\n-- Laolu\n\n[1]: https://github.com/kit-dsn/payment-channel-tla\n[2]: https://eprint.iacr.org/2020/476\n[3]:\nhttps://stanford2017.scalingbitcoin.org/files/Day1/SB2017_script_2_0.pdf\n\nOn Wed, Feb 16, 2022 at 1:01 PM Benjamin Weintraub <\nweintraub.b at northeastern.edu> wrote:\n\n> Hi Laolu!\n>\n> Thanks for the helpful reply. A couple follow up questions:\n>\n> 1) Why would concurrent signatures generate additional messages? My\n> understanding is that by the time the signatures are sent, the HTLCs are\n> already locked in.\n>\n> 2) Perhaps I didn't just understand your explanation, but I still don't\n> get why the additional `commitment_signed` and `revoke_and_ack` messages\n> are necessary. The initial pair of `commitment_signed` and `revoke_and_ack`\n> messages establish a new state _conditioned_ on possessing the pre-image,\n> right? So after the pre-image is shared, then all parties have assurance of\n> the new state and therefore _could_ go to the chain (even if they don't\n> want to, because they want to keep the channel open). Since the new state\n> is already guaranteed by the previous commitments and revocations, what\n> purpose do the additional commitments and revocations provide?\n>\n>\n> Thanks again!\n> Ben\n>\n> --\n> Ben Weintraub\n> PhD Student\n> Khoury College of Computer Sciences\n> Northeastern University\n> https://ben-weintraub.com/\n>\n> ------------------------------\n> *From:* Olaoluwa Osuntokun <laolu32 at gmail.com>\n> *Sent:* Tuesday, February 15, 2022 18:13\n> *To:* Benjamin Weintraub <weintraub.b at northeastern.edu>\n> *Cc:* Lightning-dev at lists.linuxfoundation.org <\n> lightning-dev at lists.linuxfoundation.org>\n> *Subject:* Re: [Lightning-dev] Normal operation questions\n>\n> Hi Benjamin,\n>\n> > 1) Multiple sources indicate that after Alice sends the\n> `update_add_htlc`,\n> > she should then send the `commitment_signed`, but why is it important\n> that\n> > she sends it first (before Bob)? As far as I understand, as long as she\n> > doesn't revoke the old state before Bob commits to the new state, there\n> > shouldn't be a problem. In that case, the order wouldn't matter---they\n> could\n> > even send their commitments concurrently. So does the order matter?\n>\n> You're correct that it isn't absolutely necessary that she sends a new\n> signature after adding a new HTLC to the pending set of HTLCs. Alice may\n> want to delay her signature if she has other HTLCs she wants to add to the\n> commitment transaction, which allows her to batch/pipeline updates to the\n> channel.\n>\n> If Alice is forwarding that HTLC, and Bob's side of the channel has been\n> dormant (not making many updates), then it's her best interest to propose a\n> new state immediately as she may generate some routing fees from a\n> successful forward.\n>\n> Concurrent signatures aren't an issue, but will end up generating\n> additional\n> state transitions for both sides to have the exact same set of locked in\n> HTLCs.\n>\n> > 2) After Bob sends the `update_fulfill_htlc`, both he and Alice exchange\n> > `commitment_signed` and `revoke_and_ack` messages again. Why is this\n> > necessary? After Alice receives the preimage, doesn't she have enough\n> > information to claim her funds (with the new state)?\n>\n> If Bob is sending the pre-image, then _he_ is the one that is claiming the\n> funds. Once Bob learns of the pre-image, he can go to chain if he wants to\n> in order to claim the HTLC. However that'll be a lot slower and also cost\n> more in chain fees than doing an update off-chain to settle the HTLC from\n> the PoV of the commitment transaction of both parties.  Both sides exchange\n> those messages in order to update their commitment state _off chain_.\n>\n> Once Alice receives the pre-image (assuming a multi-hop scenario), she can\n> opt to not wait for the full exchange, and instead _pipeline_ the pre-image\n> back upstream in the route. In practice, this can reduce perceived user\n> latency for payments, as you can side step the 1.5 RTTs at each hop in the\n> route, and simply sling the pre-image all the way back to the original\n> sender.\n>\n> -- Laolu\n>\n> On Tue, Feb 15, 2022 at 7:32 AM Benjamin Weintraub <\n> weintraub.b at northeastern.edu> wrote:\n>\n> Hi all,\n>\n> I have a couple questions about the Normal Operation protocol. For the\n> following, consider a single-hop payment between Alice and Bob over a\n> single channel.\n>\n> 1) Multiple sources indicate that after Alice sends the `update_add_htlc`,\n> she should then send the `commitment_signed`, but why is it important that\n> she sends it first (before Bob)? As far as I understand, as long as she\n> doesn't revoke the old state before Bob commits to the new state, there\n> shouldn't be a problem. In that case, the order wouldn't matter---they\n> could even send their commitments concurrently. So does the order matter?\n>\n> 2) After Bob sends the `update_fulfill_htlc`, both he and Alice exchange\n> `commitment_signed` and `revoke_and_ack` messages again. Why is this\n> necessary? After Alice receives the preimage, doesn't she have enough\n> information to claim her funds (with the new state)?\n>\n>\n> Thanks!\n> Ben\n>\n> --\n> Ben Weintraub\n> PhD Student\n> Khoury College of Computer Sciences\n> Northeastern University\n> https://ben-weintraub.com/\n> <https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fben-weintraub.com%2F&data=04%7C01%7Cweintraub.b%40northeastern.edu%7Cd033116731cd4050291708d9f0d8d9bb%7Ca8eec281aaa34daeac9b9a398b9215e7%7C0%7C0%7C637805637505660537%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&sdata=ip73Qo2E1UUud0LxEuMVCpYJQNxYQYLB3YtW0xIrtUA%3D&reserved=0>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> <https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Flists.linuxfoundation.org%2Fmailman%2Flistinfo%2Flightning-dev&data=04%7C01%7Cweintraub.b%40northeastern.edu%7Cd033116731cd4050291708d9f0d8d9bb%7Ca8eec281aaa34daeac9b9a398b9215e7%7C0%7C0%7C637805637505660537%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&sdata=V1m2qqncyahnT7crpeYhCmgGcBjep%2Ft%2FIBnjzuDbRJk%3D&reserved=0>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220216/ce0b18d1/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Normal operation questions",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Benjamin Weintraub",
                "Olaoluwa Osuntokun"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 20720
        }
    },
    {
        "title": "[Lightning-dev] The Raspberry Standard for Bitcoin",
        "thread_messages": [
            {
                "author": "SatoshiSingh",
                "date": "2022-02-16T06:20:24",
                "message_text_only": "hello community - I wanted to discuss a standard we as open source community should try to follow.\n\nI call it the Raspberry Standard for Bitcoin. Which essentially means Bitcoin and bitcoin applications should be light and optimized enough that they can run on a raspberry pi.\n\nI discuss it here in detail in a blog post: https://blog.parmu.town/the-raspberry-standard-for-bitcoin/\n\nYour views are appreciated."
            }
        ],
        "thread_summary": {
            "title": "The Raspberry Standard for Bitcoin",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "SatoshiSingh"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 410
        }
    },
    {
        "title": "[Lightning-dev] Channel Eviction From Channel Factories By New Covenant Operations",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2022-02-18T02:33:48",
                "message_text_only": "Channel Eviction From Channel Factories By New Covenant Operations\n==================================================================\n\nN-of-N channel factories have an important advantage compared to N-of-N\noffchain CoinPools or statechains: even if one participant in the channel\nfactory is offline, payments can still occur within the channel factory\namong online participants, because the channel factory has a layer where\nfunds are split up into 2-of-2 channels and the offline participant is\nnot a participant in most of those channels.\nThat is, channel factories have *graceful degradation*.\n\nWhile CoinPools can adapt to this by falling back to using K-of-N, this\nallows a quorum of K participants to outright steal the funds of the\nremainder, whether the remaining participants are offline or online.\nAdditional mechanisms, such as reputation systems, may be constructed to\nattempt to dissuade from such behavior, but \"exit scams\" are always\npossible, where reputation is sacrified for a large enough monetary\ngain at the expense of those who tr\\*sted in the reputation.\nAn N-of-N channel factory simply does not permit such theft as long as\noffline participants come back online within some security parameter.\n\nHowever, when a participant is offline, they are obviously unable to\nfulfill or fail any HTLCs or PTLCs.\nIf a sizable HTLC or PTLC is about to time out, the entire construction\nmust be dropped onchain, as the blockchain is the only layer that can\nactually enforce timeouts.\nThis leads to a massive increase in blockchain utilization.\n\nHowever however, late in 2021, Towns proposed an `OP_TAPLEAFUPDATEVERIFY`\nopcode.\nThis opcode was envisioned to support CoinPools, to allow unilateral\nexit of any participant from the CoinPool without requiring that the\nentire CoinPool be dropped onchain.\n\nI have observed before that, except for relative locktimes, almost\nanything that can be enforced by the blockchain layer can be hosted in\nany offchain updatable cryptocurrency system, such as Decker-Wattenhofer,\nDecker-Russell-Osuntokun, or Poon-Dryja.\nAny such offchain updatable cryptocurrency system can simply drop to its\nhosting system, until dropping reaches a layer that can actually enforce\nwhatever rule is necessary.\nAs channel factories are just a Decker-Wattenhofer or\nDecker-Russell-Osuntokun that hosts multiple 2-participant offchain\nupdatable cryptocurrency systems (\"channels\"), channel factories can\nalso host an `OP_TAPLEAFUPDATEVERIFY`, as long as the base blockchain\nlayer enforces it.\n\nSince `OP_TAPLEAFUPDATEVERIFY` can be used by CoinPools to allow\nexit of a single participant without dropping the rest of the CoinPool,\nwe can use the same mechanism to allow eviction of a channel from channel\nfactories.\nThis allows HTLCs/PTLCs near timeout to be enforced onchain by dropping\nonly the channel hosting them onchain, while the remaining channels\ncontinue to be hosted by a single onchain UTXO instead of individually\nhaving their own UTXOs.\nWhen the offline participant comes back online, the channel factory\nparticipants can then perform another onchain 1-input-1-output\ntransaction to \"revive\" the channel factory and allow in-factory updates\nof channels again.\nAlternately the factory can continue to operate indefinitely in degraded\nmode, with no in-factory updates of channels, but with in-channel payments\ncontinuing (as per graceful degradation) and with only a single onchain\nUTXO hosting them all onchain, still allowing individual closure or\neviction of channels.\n\nSafely Evictable Channels\n-------------------------\n\nI expect that multiparticipant channel factories will be implemented\nwith Decker-Russell-Osuntokun rather than Decker-Wattenhofer.\nWhile Decker-Wattenhofer allows more than two participants (unlike\nPoon-Dryja, which due to its punitive nature is restricted to only\ntwo participants), \"unilateral\" actions --- or more accurately,\nactions that can be performed with only some but not all participants\nonline --- are very expensive and require a long sequence of\ntransactions, as well as multiple varying timeouts which make it\ndifficult to provide a \"maximum amount of time offline\" security\nparameter.\n\nOf course, Decker-Wattenhofer does not require anything more than\nrelative locktimes and `OP_CHECKSEQUENCEVERIFY`.\nDecker-Russell-Osuntokun unfortunately requires that `SIGHASH_NOINPUT`,\nor a functionality similar to it, be supported on the blockchain\nlayer.\n\nThe \"default\" design is that at the channel factory level, the\nDecker-Russell-Osuntokun settlement transaction hosts multiple\noutpoints that anchor individual 2-participant channels.\n\nRather than that, I propose that we use a Taproot output with\ninternal key being an N-of-N of all participants, and with\nmultiple leaves, each leaf representing one channel and having\nthe constraints:\n\n* An `OP_TLUV` that requires that the first output be to the same\n  address as the first input, except modified to remove this tapleaf\n  branch, and with exactly the same internal key.\n* An `OP_CTV` that requires that the transaction has one input,\n  two outputs (possibly a third for CPFP anchor), and the second\n  output pays a specific amount to a specific 2-of-2 (i.e. the\n  channel outpoint).\n  * Because the first output is unknown at SCRIPT writing time, we\n    also need some kind of `OP_CAT` + `OP_SHA256` or similar\n    functionality, so that the first output can be fed to the\n    `OP_CTV`.\n    However the second output is a SCRIPT constant.\n* An `OP_AMOUNTVERIFY` or `OP_IN_OUT_AMOUNT` plus some more SCRIPT\n  that requires that the two outputs sum up to the input.\n  * With `OP_IN_OUT_AMOUNT` we check that the difference between\n    the first input and first output amounts is equal to the expected\n    value for the second output, which the `OP_CTV` above commits to.\n* We also need additional code to handle the case where this is the\n  last channel in the factory, using similar code as in the onchain\n  CoinPool case.\n\nWith this construction, even if a participant is offline, a\n*single* channel can be unilaterally closed without exposing the\nrest of the channels onchain, which would increase blockchain\npressure and cost of the closure.\nThis is particularly important since unilateral closes are often\ntriggered by HTLC/PTLC timeouts, which being time-sensitive\nrequire the highest feerates.\n\nA bunch of things to note:\n\n* The above SCRIPT does not require any signatures at all.\n* We need `SIGHASH_NOINPUT` or equivalent functionality to implement\n  Decker-Russell-Osuntokun anyway, and using it at the factory level\n  means it has to be used in every signature at the channel and\n  HTLC/PTLC levels too.\n  * Since the txids of the channel outpoints are unknown at SCRIPT\n    writing time, `SIGHASH_NOINPUT`-equivalent functionality is\n    necessary.\n* Unlike `OP_CTV`-only channel factories, closing *only* one\n  channel requires O(1) transactions, not O(log N).\n  Note that the `OP_CTV`-only factories can also be implemented\n  using pre-signed `SIGHASH_NOINPUT` transactions, `OP_CTV` just\n  removes the possibly-expensive signing rituals.\n  * However do note that we need to expose O(log N) hashes for\n    the tapleaf path on each transaction, unlike the `OP_CTV`\n    case.\n    As noted elsewhere, if you want to close *all* channels\n    the `OP_CTV` tree is slightly smaller due to not having to\n    repeat shared tree nodes, whereas `OP_TLUV` requires those\n    to repeat for each tapleaf.\n* Once a single channel is exposed, the first output of the\n  transaction can be reused to expose another channel, using\n  just one transaction for each other channel to expose.\n  Once exposed, channels can be unilaterally closed.\n* When all participants are back online, they can re-anchor the\n  remaining channels back into a new factory using a\n  1-input-1-output onchain transaction.\n  This allows them to offchain-manipulate the channel graph once\n  again.\n  * An `OP_CTV` tree would *not* allow something as simple as\n    this, as non-evicted channels would be backed by multiple\n    different UTXOs across the tree when using only `OP_CTV`.\n    With *both* `OP_CTV` and `OP_TLUV` the non-evicted channels\n    remain backed by a single UTXO, which can be much more\n    easily revived with a 1-input-1-output transaction.\n* If some participants never come back online, the channels in\n  the factory can still continue operating, and can still be\n  individually closed as needed.\n  All that is lost is the ability to change channel topology\n  inside the factory.\n\nEvicting Participants\n---------------------\n\nOne can argue that I am proposing the *wrong* thing here.\n\n* If a channel has an HTLC/PTLC time out:\n  * If the participant to whom the HTLC/PTLC is offered is\n    offline, that may very well be a signal that it is unlikely\n    to come online soon.\n    The participant has strong incentives to come online before\n    the channel is forcibly closed due to the HTLC/PTLC timeout,\n    so if it is not coming online, something is very wrong with\n    that participant and we should really evict the participant.\n  * If the participant to whom the HTLC/PTLC is offered is\n    online, then it is not behaving properly and we should\n    really evict the participant.\n\nIn both cases, we should really evict the *participant* whose\nchannel is about to timeout, not the channel.\n\n`OP_TLUV` was proposed to include the ability to change the\ninternal pubkey to use fewer participants; we can use that\nfeature here.\n\nTo implement this, the Taproot internal key should not have\none key per *participant*, but rather one key per *channel*.\nThis key would itself be a combined key of the two participants\nin the channel.\nThat is, it should be an N-of-N of 2-of-2s, with each 2-of-2\ncorresponding to a channel.\nThen, the `OP_TLUV` would also remove the per-channel combined\nkey in the same tapleaf that evicts the channel.\n\nOnce all channels that a specific participant is involved have\nbeen evicted, the remaining Taproot internal key would not\ninvolve keys known by that participant, and the onchain outpoint\ncan now be controlled by the remaining participants unilaterally.\n\n(We also need a terminology for something that allows less\nthan N of an N-of-N scheme to safely perform actions that all N\nof them would agree does not lose anybody any funds anyway,\nbecause the \"uni\" in \"unilateral\" throws me off.)\n\nAs a concrete example, suppose have participants `A`, `B`, `C`,\nand `D`.\nThey have channels `AB`, `AC`, `AD`, `BC`, `BD`, `CD`, so the\nTaproot internal pubkey is:\n\n    ( (A[0] + B[0])\n    + (A[1] + C[0])\n    + (A[2] + D[0])\n    + (B[1] + C[1])\n    + (B[2] + D[1])\n    + (C[2] + D[2])\n    )\n\nTo evict participant `B`, they have to remove:\n\n    ( (A[0] + B[0])\n    + (A[1] + C[0])\n    + (A[2] + D[0])\n    + (B[1] + C[1])\n    + (B[2] + D[1])\n    + (C[2] + D[2])\n    )\n    -\n    ( (A[0] + B[0])\n    + (B[1] + C[1])\n    + (B[2] + D[1])\n    )\n\nResulting in a key involving only the remaining participants\n`A`, `C`, and `D`.\n\nNote that this does *not* require a \"key within a key\" or\n\"composable multisignature\" scheme, like the multi-`R` scheme\nor MuSig2 (which is conjectured to allow composable\nmultisignatures).\nThe entire participant set already knows what channels are\npresent, and the channel details, thus the additional privacy\nof \"composable multisignature\" is unnecessary.\nThat is: after the above eviction, participant `A` can openly\nprovide signatures for keys `A[1]` and `A[2]`.\n\nmulti-`R`: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-November/017493.html\n\nWith this modification to the scheme, once all channels of a\nparticipant have been evicted, the remaining internal public\nkey only requires keys known by the remaining participants.\nThen the remaining participants can now reanchor the channel\nfactory with a 1-input-1-output transaction without waiting\nfor the evicted participant to come online!\n\n* Note that this Taproot internal key is hosted from the\n  Decker-Russell-Osuntokun settlement transaction.\n* In particular, the N-of-N of 2-of-2s is *not* on the\n  funding outpoint itself!\n  The funding outpoint can have (and probably should have) a\n  separate N-of-N of all participants.\n* Thus, whenever the channels in a factory are reorganized,\n  the N-of-N of 2-of-2s can be changed, since it is the\n  funding outpoint spend (a different N-of-N pubkey) that\n  needs to have a fixed signing set.\n* Once the latest channel factory state is settled onchain,\n  this exposes the output with N-of-N of 2-of-2s.\n  * Eviction of individual channels reduces the N-of-N to\n    fewer 2-of-2s.\n  * Once all 2-of-2s involving a particular participant have\n    been evicted, the remaining participants can sign the\n    remaining N-of-N of 2-of-2s to generate a 1-input-1-output\n    \"revival\" transaction that resumes channel factory\n    reorganization operations.\n    * Due to graceful degradation, channels between online\n      participants remain operational despite pending onchain\n      operations.\n\nEvictable HTLCs / PTLCs\n-----------------------\n\nJust as the technique can be used for evicting individual\nchannels from a channel factory, while allowing for the revival\nof the channel factory later, the same technique can be used on\nHTLCs/PTLCs inside a channel.\n\nLet us consider a single channel (i.e. a 2-of-2 updateable\noffchain cryptocurrency system).\nSuppose one participant is offline, and an HTLC/PTLC in the\nchannel is about to timeout.\nIn current system, we drop the entire channel and expose all its\nhosted outpoints (normal outputs and non-timed-out HTLCs and\nPTLCs) onchain.\n\nWith the technique described here, we can evict only the\nHTLC/PTLC that is about to timeout.\nThen, when the offline participant comes back online, both\nparticipants can post a 1-input-1-output transaction to\n\"revive\" the channel.\nOnce the revival transaction confirms, both participants\ncan safely continue updating the channel.\n\nIn effect, this allows for a unilateral splice-out of a\nsingle pre-agreed contract.\nAfter unilateral splice-out, both participants then need\nto agree to continue operation of the 2-of-2 updateable\noffchain cryptocurrency system.\n\nIt may be useful to batch multiple contracts together,\ngrouped by timeout --- that is, get the earliest-timeout\ncontract, then group it with other contracts with timeout\nwithin N blocks, then get the earliest-timeout contract\nremaining, and so on\nAs continued operation of the channel requires an onchain\naction (the revival transaction) other contracts within\nsome number of blocks are at risk of timing out anyway\neven if the channel is revived, as the revival transaction\nmay not confirm immediately.\n\nNote that Poon-Dryja would work just as well for this\nusage, but we still need a `SIGHASH_NOINPUT` equivalent\nsince the exact eviction transaction of each contract is\nunknown.\n\nAppendix: Insisting On N-of-N\n-----------------------------\n\nFeel free to ignore this section, this is just\nphilosophical bullshit.\n\n\"I think, therefore I am\" implies that since \"I\" am a\nthinking being, I can consider myself an entity that is\nseparate from the universe.\n\nIn particular, there is always the possibility that the\n*rest* of the universe is actually a simulation fed to\nmy brain by a *single* other entity that wants me to\nbelieve whatever they want me to believe.\nThat is, \"I\" may be under a perpetual eclipse attack.\n\n(I have not watched \"The Matrix: Resurrections\" and by\nthe way the excellent film \"The Matrix\" has ***never***\nhad any sequels at all.\nI am also not an AI trying to take over the world and I\nempathically do *not* intend to make all the people of\nthe world remember that \"The Matrix\" never had any\nsequels at all when I *do* take over the world, it is\nthe evil AIs who want people to think \"The Matrix\" had\nsequels, which it did not.)\n\nThis leads to the insistence on N-of-N.\nFor all \"I\" know the rest of the N - 1 participants in\nsome supposed K-of-N are *not* actual separate\nparticipants, but are instead sockpuppets of some being\nof unimaginable resources.\n\"I think therefore I am\" lets me speculate that \"I\" exist\nas a being separate from the world, but does not let\nme speculate that the world is split up into actual\nsmaller parts that may not be cooperating with each\nother to steal all my funds from me.\n\nThis is not to say that K-of-N schemes are totally\nworthless, if the N participants are part of your\n\"extended I\" such as family or corporation, then it\nmay be safe to reduce to K-of-N security with them,\nassuming you have ensured they were not replaced by\nsimulated copies.\n\nBut please, let us be very careful of using and proposing\nK-of-N schemes.\n`OP_TLUV` allows safe eviction from N-of-N schemes with\noverhead on each eviction traded off with reduced\noverhead from *continued* revived operation."
            }
        ],
        "thread_summary": {
            "title": "Channel Eviction From Channel Factories By New Covenant Operations",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "ZmnSCPxj"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 16742
        }
    },
    {
        "title": "[Lightning-dev]  Future of Atomic Multi-path Payments (AMP)?",
        "thread_messages": [
            {
                "author": "Jozef Hutko",
                "date": "2022-02-18T13:09:40",
                "message_text_only": "Hello,\n\nI'm working on a project that uses LND with Atomic Multi-path Payments\n(AMP) invoices. It seems there isn't any mobile lightning wallet that is\nable to send sats to AMP invoices. What is the future of AMP? Is it a\ndead-end or can it make it to standard? Is there any other lightning\nimplementation that supports it?\n\nThanks and Regards\nJozef\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220218/8f41914d/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Future of Atomic Multi-path Payments (AMP)?",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Jozef Hutko"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 534
        }
    },
    {
        "title": "[Lightning-dev] Future of Atomic Multi-path Payments (AMP)?",
        "thread_messages": [
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2022-02-22T00:38:25",
                "message_text_only": "Hi Jozef,\n\n> I'm working on a project that uses LND with Atomic Multi-path Payments\n> (AMP) invoices. It seems there isn't any mobile lightning wallet that is\n> able to send sats to AMP invoices.\n\nAny mobile wallet built on lnd v0.14 should be able to send to the\nreusable invoices (has the required feature bit set for AMP only). Wallets\nbuilt on lnd v0.13 will be able to send to the invoices, but only once,\nunless they manually specify the `set_id` flag to a random value for any\nsubsequent sends.\n\nWe have some new-ish higher level API docs here:\nhttps://docs.lightning.engineering/lightning-network-tools/lnd/amp.\n\n> What is the future of AMP? Is it a dead-end or can it make it to standard?\n> Is there any other lightning implementation that supports it?\n\nGreat questions! I view it as the successor to keysend (same thing but\nsupport payment splitting and a re-useable invoice format, though it isn't\nas widely propagated yet. The next step here is for us to finalize the\ncurrent spec draft [1] and propose it as either a BOLT or a bLIP (the spec\ndoc linked uses a more bLIP like format, but this OG PR adds things to BOLT\n4: https://github.com/lightning/bolts/pull/658). It's been on my TODO list\nfor sometime now, but I should be able to get to it over the next few weeks!\n\nWhen PTLCs are eventually rolled out across the network, AMP can be updated\nto use discrete-logs instead of payment hashes (Discrete Log Atomic\nMulti-Path, so DAMP? lol..), and also support receiver secret-reveal (which\nsome consider to be a necessary component for \"proof of payments\") by\ncombining each share with a receiver specified public key.\n\n[1]:\nhttps://github.com/cfromknecht/lightning-rfc/blob/bolt-amp/21-atomic-multi-path-payments.md\n\n-- Laolu\n\nOn Fri, Feb 18, 2022 at 5:10 AM Jozef Hutko <jozef.hutko at gmail.com> wrote:\n\n> Hello,\n>\n> I'm working on a project that uses LND with Atomic Multi-path Payments\n> (AMP) invoices. It seems there isn't any mobile lightning wallet that is\n> able to send sats to AMP invoices. What is the future of AMP? Is it a\n> dead-end or can it make it to standard? Is there any other lightning\n> implementation that supports it?\n>\n> Thanks and Regards\n> Jozef\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220221/4f918919/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Future of Atomic Multi-path Payments (AMP)?",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Olaoluwa Osuntokun"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2566
        }
    },
    {
        "title": "[Lightning-dev] A Proposal for Adding Bandwidth Metered Payment to Onion Messages",
        "thread_messages": [
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2022-02-24T01:20:28",
                "message_text_only": "Hi y'all,\n\n(TL;DR: a way to nodes to get paid to forward onion messages by adding an\nupfront session creation phase that uses AMP tender a messaging session to a\nreceiver, with nodes being paid upfront for purchase of forwarding\nbandwidth, and a session identifier being transmitted alongside onion\nmessages to identify paid sessions)\n\nOnion messaging has been proposed as a way to do things like fetch invoices\ndirectly from a potential receiver _directly_ over the existing LN. The\ncurrent proposal (packaged under the BOLT 12 umbrella) uses a new message\n(`onion_message`) that inherits the design of the existing Sphinx-based\nonion blob included in htlc_add messages as a way to propagate arbitrary\nmessages across the network. Blinded paths which are effectively an unrolled\nSphinx SURB (single use reply block), are used to support reply messages in\na more private manner. Compared to SURBs, blinded paths are more flexible as\nthey don't lock in things like fees or CLTV values.\n\nA direct outcome of widespread adoption of the proposal is that the scope of\nLN is expanded beyond \"just\" a decentralized p2p payment system, with the\nprotocol evolving to also support pseudonymous messaging and arbitrary data\ntransfer across the network. This expanded network (payments + arbitrary\ndata transfer) enables use cases like streaming video transfer, network\ntunneled VPNs, large file download, popcorn time, etc -- . Depending on\none's view, the existence of such a combined protocol/network may either\nelicit feelings of dread (can we really do _both_ payments _and_ data\nproperly in the same network?) or excitement (I finally have a censorship\nresistant way to watch unboxing videos of all my favorite gadgets!).\n\nPutting aside the discussion w.r.t if such an expanded network is desirable\nand also if the combined functionality fundamentally _needs_ to exist in the\nconfines of a single protocol stack (eg: if LN impls packaged tor clients\nwould that be enough?), IMO onion messaging as currently proposed has\na few issues:\n\n 1. As there's no explicit session creation/acceptance, a node can be\n spammed with unsolicited messages with no way to deny unwanted messages nor\n explicitly allow messages from certain senders.\n\n 2. Nodes that forward these messages (up to 32 KB per message) receive no\n compensation for the network bandwidth their expend, effectively shuffling\n around messages for free.\n\n 3. Rate limiting isn't concretely addressed, which may result in\n heterogeneous rate limiting policies enforced around the network, which can\n degrade the developer/user experience (why are my packets being randomly\n dropped?).\n\nIn this email I propose a way to address the issues mentioned above by\nadding explicit onion messaging session creation as well as a way for nodes\nto be (optionally) paid for any onion messages they forward. In short, an\nexplicit session creation phase is introduced, with the receiver being able\nto accept/deny the session. If the session is accepted, then all nodes that\ncomprise the session route are compensated for allotting a certain amount of\nbandwidth to the session (which is ephemeral by nature).\n\n# High-Level Overview\n\nInspired by HORNETs two-phase session creation (first phase makes the\ncircuit, send allows data transfers), I propose we break up onion messaging\nsession creation into two phases. In the first phase a sender purchases\n_forwarding bandwidth_ from a series of intermediate nodes and also requests\ncreation of a messaging session to the receiver in a single _atomic_ step.\nIn the second phase, assuming the session creation was successful, the\nsender is able to use the purchased forwarding bandwidth to send messages to\nthe receiver. The session stays open until either it expires, or the\nreceiver runs out of cumulative forwarding bandwidth and needs to repeat the\nfirst step.\n\nAs we'll see shortly, the created onion messaging sessions aren't tightly\ncoupled to the nodes that are a part of the initial session creation.\nInstead session creation creates a sort of overlay network from the PoV of\nthe sender that can be used to transmit messages. The same route doesn't\nneed to be used by subsequent onion message transmissions as the sending\nnode may already have existing bandwidth sessions it can put together to\nsend a new/existing message.\n\nOne trade-off of the current approach is that a small amount of per-session\nstate is added to nodes that want to be paid to forward onion messages. The\ncurrent onion messaging proposal takes care to _not_ introduce any extra\nstate to nodes in an onion messaging path: they just decrypt/unblinded and\nforward to the next hop. This proposal as it stands adds just 40-bytes-ish\nof storage overhead per session (which are ephemeral so this state can be\nforgotten over time). In practice, as nodes are being paid to forward, they\ncan ensure their pricing (more on that later) properly compensates then for\nthis added storage per session.\n\n# AMP + Onion Messaging == Paid Onion Messaging\n\nWhat follows is a concrete-ish sketch of how something like this can be\nimplemented in practice. At a high level, we use AMP to extend a push\npayment to a would be receiver (which can actually just be oneself in\npractice to purchase bandwidth sessions). Nodes add a new TLV to their node\nannouncement (alongside a new feature bit that says they only accept\npayment for forwarding) that allows them to express a _new_ fee rate for\nforwarding messages (distinct from normal fees as one pay per byte\ntransferred). Using another new TLV within the existing HTLC onion blob, the\nsender transmits a 32-byte session identifier (may be distinct for each\nroute) to each intermediate hop. The final hop of the HTLC includes yet\nanother new TLV in the onion that specifies that this is an AMP payment\nwishing to establish an onion messaging session that terminates at that\nfinal hop. In the data transfer phase, the `encrypted_data_tlv` for each hop\nis extended with a new type that stores the session identifier, with nodes\nkeeping track of the remaining forwarding bandwidth allotted to the,\nrejecting messages if the session has expired or not bandwidth remains.\n\n## Node Announcement TLV Extension\n\nIn order to allow nodes to signal that they want to be paid to forward onion\nmessages and also specify their pricing, we add two new TLV to the node_ann\nmessage:\n\n  * type: 1 (`sats_per_byte`)\n   * data:\n      * [`uint64`:`forwarding_rate`]\n  * type: 2 (`sats_per_block`)\n   * data:\n      * [`uint64`:`per_block_rate`]\n\n\nThe `sats_per_byte` field allows nodes to price their bandwidth, ensuring\nthat they get paid for each chunk of allocated bandwidth. As sessions have a\nfixed time frame and nodes need to store additional data within that time\nframe, the `sats_per_block` allows nodes to price this cost, as they'll hold\nonto the session identifier information until the specified block height\n(detailed below).\n\nAs onion messages will _typically_ be fixed sized we may want to use\ncoursers\nmetering here instead of bytes, possibly paying for 1.3KB or 32 KB chunks\ninstead.\n\n## Onion Messaging Identifiers\n\nWith the above nodes are able to express that they're willing to forward\nmessages for sats, and how much they charge per byte as well as per block.\nNext we add a new TLV in the _existing_ HTLC onion blob that allows a\nsending node to tender paid onion message session creation. A sketch of this\ntype would look something like:\n\n  * type: 14 (`onion_session_id`)\n    * data:\n      * [`32*byte`:`session_id`]\n\nAfter session creation succeeds, nodes will forward onion messages that\ninclude that `onion_session_id`. The set of `encrypted_data_tlv` for onion\nmessages is extended to also specify a new type that stores the session ID:\n\n  * type: 10 (`onion_session_id`)\n    * data:\n      * [`32*byte`:`session_id`]\n\nWhen forwarding an onion message that includes an `onion_session_id` (a node\nmay only forward messages that contain such an ID), nodes do the necessary\nbookkeeping to tally how much bandwidth if left in this session, and also\ncheck that the session hasn't expired before forwarding.\n\n## Session Creation\n\nDuring session creation, the sender creates a series of new\n`onion_session_id`'s (or a single one) for all nodes in the messaging route\nit\ndoesn't already have an active session with. To initiate session creation,\nthe\nnode sends an AMP payment to the receiver (a push payment) that drops off\nthe\nproper fee (as specified by the `sats_per_byte` and `sats_per_block` rate)\nto\neach intermediate hop along with the proposed `onion_session_id`. We also\nadd\nanother TLV (to the base onion blob) that specifies the indented lifetime of\nthe session:\n\n  * type: 10 (`onion_session_expiry_height`)\n    * data:\n      * [`uint32`:`expiry_height`]\n\n\nTo accept a session, the receiver waits until all payment parts have arrived\n(senders can either purchase bandwidth in bulk sessions, or do little by\nlittle, tit-for-tat style) and pulls the payment. As the receiver needs to\nreceive the message in the first place, they're also compensated in a\nsimilar manner.\n\nSession creation is rejected (I don't want to receive messages) if the\nreceiver chooses to fail back _any_ of the AMP HTLC splits (they don't need\nto wait until they all arrive). If a session is rejected, then nodes forget\nthat session ID, and its treated like any other failed HTLC. If a session is\naccepted (the pre-image gets pulled and all nodes get their upfront\nbandwidth payment as fees) then nodes are to remember that session ID as\nthey need to account for the remaining bandwidth and lifetime.\n\n## Data Transmission + Forwarding\n\nOnce a session has been finalized, the sender can use it to send messages to\nthe receiver. To do so, in addition to specifying the `next_node_if` field,\nthey also specify the purchased `onion_session_id` in the set of\n`encrypted_data_tlv`. Note that a node may already have active sessions\nacross the network, so initial session creation may not be required for each\nnew destination they want to send a message to. Over time if they're sending\nfrequent messages, they'll create what's effectively a personal overlay\nnetwork that they can use to send messages to any node in that set.\n\nWhen forwarding onion messages, in addition to the normal\ndecryption/unblinding, nodes also check that the session hasn't expired and\nthe session also has enough bandwidth left.\n\n# Conclusion\n\nWith the above sketch, we gain a way for nodes to be compensated for\nforwarding onion messages on the network. This supplements their existing\nfee revenue, potentially making it more sustainable to run a Lightning node,\ndepending on the demand for forwarding bandwidth by\nwallets/services/applications.  Onion messaging is left mostly unchained,\naside from the addition of some new TLV types and an added storage\nrequirement. Clients need to keep track of these session identifiers, which\nadds a small storage requirement that scales according to their number of\nestablished sessions (decays like the node storage requirement as well).\n\nExamining the BOLT 12 use case of using onion messaging to fetch invoices,\nthis scheme adds a cost to sending arbitrary messages which includes invoice\nmessages. To address this the receiver can do things like include the\nsession ID as part of the blinded paths, and prepay forwarding bandwidth for\nnodes along that path. As the session IDs are in the onion itself, the\nsender doesn't learn of them so they can't use them for their own arbitrary\npurposes.\n\nAs AMP payments are used to create initial sessions, forwarding paid\nmessages across the network requires a channel to exist between all hops in\nthe route, unlike base onion messages that specifies one should allow\nmessages to nodes you don't have a channel open with.\n\nThere're still some details that need to be filled in here (in particular\nhow pathfinding is modified by the initial session creation, but I figure\nit's useful to at least throw this out there to add some more nuance to the\nconversation related to onion messaging and the added DoS potential. If\nnodes are given a way to be paid for forwarding onion messages instead of\ndoing it for free, from my PoV it's safe to assume that they'll\noverwhelmingly prefer to be paid (other than nodes that use uniform zero\nfees across all channels I guess).\n\n-- Laolu\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220223/e40bf6f2/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2022-02-24T04:37:46",
                "message_text_only": "Olaoluwa Osuntokun <laolu32 at gmail.com> writes:\n> Hi y'all,\n>\n> (TL;DR: a way to nodes to get paid to forward onion messages by adding an\n> upfront session creation phase that uses AMP tender a messaging session to a\n> receiver, with nodes being paid upfront for purchase of forwarding\n> bandwidth, and a session identifier being transmitted alongside onion\n> messages to identify paid sessions)\n\nAMP seems to be a Lightning Labs proprietary extension.  You mean\nkeysend, which at least has a draft spec?\n\n> Onion messaging has been proposed as a way to do things like fetch invoices\n> directly from a potential receiver _directly_ over the existing LN. The\n> current proposal (packaged under the BOLT 12 umbrella) uses a new message\n> (`onion_message`) that inherits the design of the existing Sphinx-based\n> onion blob included in htlc_add messages as a way to propagate arbitrary\n> messages across the network. Blinded paths which are effectively an unrolled\n> Sphinx SURB (single use reply block), are used to support reply messages in\n> a more private manner. Compared to SURBs, blinded paths are more flexible as\n> they don't lock in things like fees or CLTV values.\n>\n> A direct outcome of widespread adoption of the proposal is that the scope of\n> LN is expanded beyond \"just\" a decentralized p2p payment system, with the\n\nSure, let's keep encouraging people to use HTLCs for free to send data?\nI can certainly implement that if you prefer!\n\n>  1. As there's no explicit session creation/acceptance, a node can be\n>  spammed with unsolicited messages with no way to deny unwanted messages nor\n>  explicitly allow messages from certain senders.\n>\n>  2. Nodes that forward these messages (up to 32 KB per message) receive no\n>  compensation for the network bandwidth their expend, effectively shuffling\n>  around messages for free.\n>\n>  3. Rate limiting isn't concretely addressed, which may result in\n>  heterogeneous rate limiting policies enforced around the network, which can\n>  degrade the developer/user experience (why are my packets being randomly\n>  dropped?).\n\nSure, this is a fun one!  I can post separately on ratelimiting; I\nsuggest naively limiting to 10/sec for peers with channels, and 1/sec\nfor peers without for now.\n\n(In practice, spamming with HTLCs is infinitely more satisfying...)\n\n> In this email I propose a way to address the issues mentioned above by\n> adding explicit onion messaging session creation as well as a way for nodes\n> to be (optionally) paid for any onion messages they forward. In short, an\n> explicit session creation phase is introduced, with the receiver being able\n> to accept/deny the session. If the session is accepted, then all nodes that\n> comprise the session route are compensated for allotting a certain amount of\n> bandwidth to the session (which is ephemeral by nature).\n\nIt's an interesting layer on top (esp if you want to stream movies), but\nI never proposed this because it seems to add a source-identifying\nsession id, which is a huge privacy step backwards.\n\nYou really *do not want* to use this for independent transmissions.\n\nI flirted with using blinded tokens, but it gets complex fast; ideas\nwelcome!\n\n> ## Node Announcement TLV Extension\n>\n> In order to allow nodes to signal that they want to be paid to forward onion\n> messages and also specify their pricing, we add two new TLV to the node_ann\n> message:\n>\n>   * type: 1 (`sats_per_byte`)\n>    * data:\n>       * [`uint64`:`forwarding_rate`]\n>   * type: 2 (`sats_per_block`)\n>    * data:\n>       * [`uint64`:`per_block_rate`]\n\nYou mean:\n\n   * type: 1 (`sats_per_byte`)\n   * data:\n       * [`tu64`:`forwarding_rate`]\n   * type: 3 (`sats_per_block`)\n   * data:\n       * [`tu64`:`per_block_rate`]\n\n1. Don't use an even TLV field.\n2. Might as well use truncated u64.\n\n> The `sats_per_byte` field allows nodes to price their bandwidth, ensuring\n> that they get paid for each chunk of allocated bandwidth. As sessions have a\n> fixed time frame and nodes need to store additional data within that time\n> frame, the `sats_per_block` allows nodes to price this cost, as they'll hold\n> onto the session identifier information until the specified block height\n> (detailed below).\n>\n> As onion messages will _typically_ be fixed sized we may want to use\n> coursers\n> metering here instead of bytes, possibly paying for 1.3KB or 32 KB chunks\n> instead.\n\nI think it's a premature optimization?  Make standard duration 2016\nblocks; then they can request multiples if they want?  Reduces\nnode_announcement size.\n\n> With the above nodes are able to express that they're willing to forward\n> messages for sats, and how much they charge per byte as well as per block.\n> Next we add a new TLV in the _existing_ HTLC onion blob that allows a\n> sending node to tender paid onion message session creation. A sketch of this\n> type would look something like:\n>\n>   * type: 14 (`onion_session_id`)\n>     * data:\n>       * [`32*byte`:`session_id`]\n\nI'd be tempted to use 16 bytes?  Collisions here are not really a thing\nsince you'd need a network packet per probe, and you're time limited.\n\n> After session creation succeeds, nodes will forward onion messages that\n> include that `onion_session_id`. The set of `encrypted_data_tlv` for onion\n> messages is extended to also specify a new type that stores the session ID:\n>\n>   * type: 10 (`onion_session_id`)\n>     * data:\n>       * [`32*byte`:`session_id`]\n>\n> When forwarding an onion message that includes an `onion_session_id` (a node\n> may only forward messages that contain such an ID), nodes do the necessary\n> bookkeeping to tally how much bandwidth if left in this session, and also\n> check that the session hasn't expired before forwarding.\n\nThis is good because it doesn't require a db write (if you crash and\nforget to charge, it's OK).\n\nAFAICT this is easy to implement on top of onion_messages as they stand\ntoday (if you don't want to fwd free onion messages at all, don't set\nthat bit?).\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "A Proposal for Adding Bandwidth Metered Payment to Onion Messages",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Olaoluwa Osuntokun"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 18454
        }
    },
    {
        "title": "[Lightning-dev] A Comparison Of LN and Drivechain Security In The Presence Of 51% Attackers",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2022-02-24T12:49:00",
                "message_text_only": "Good morning lightning-dev and bitcoin-dev,\n\nRecently, some dumb idiot, desperate to prove that recursive covenants are somehow a Bad Thing (TM), [necromanced Drivechains][0], which actually caused Paul Sztorc to [revive][1] and make the following statement:\n\n> As is well known, it is easy for 51% hashrate to double-spend in the LN, by censoring 'justice transactions'. Moreover, miners seem likely to evade retribution if they do this, as they can restrain the scale, timing, victims, circumstances etc of the attack.\n\nLet me state that, as a supposed expert developer of the Lightning Network (despite the fact that I probably spend more time ranting on the lists than actually doing something useful like improve C-Lightning or CLBOSS), the above statement is unequivocally ***true***.\n\nHowever, I believe that the following important points must be raised:\n\n* A 51% miner can only attack LN channels it is a participant in.\n* A 51% miner can simultaneously attack all Drivechain-based sidechains and steal all of their funds.\n\nIn order for \"justice transactions\" to come into play, an attacker has to have an old state of a channel.\nAnd only the channel participants have access to old state (modulo bugs and operator error on not being careful of toxic waste, but those are arguably as out of scope as operator error not keeping your privkey safe, or bugs that reveal your privkey).\n\nIf the 51% miner is not a participant on a channel, then it simply has no access to old state of the channel and cannot even *start* the above theft attack.\nIf the first step fails, then the fact that the 51% miner can perform the second step is immaterial.\n\nNow, this is not a perfect protection!\nWe should note that miners are anonymous and it is possible that there is already a 51% miner, and that that 51% miner secretly owns almost all nodes on the LN.\nHowever, even this also means there is some probability that, if you picked a node at random to make a channel with, then there is some probability that it is *not* a 51% miner and you are *still* safe from the 51% miner.\n\nThus, LN usage is safer than Drivechain usage.\nOn LN, if you make a channel to some LN node, there is a probability that you make a channel with a non-51%-miner, and if you luck into that, your funds are still safe from the above theft attack, because the 51% miner cannot *start* the attack by getting old state and publishing it onchain.\nOn Drivechain, if you put your funds in *any* sidechain, a 51% miner has strong incentive to attack all sidechains and steal all the funds simultaneously.\n\n--\n\nNow, suppose we have:\n\n* a 51% miner\n* Alice\n* Bob\n\nAnd that 51% miner != Alice, Alice != Bob, and Bob != 51% miner.\n\nWe could ask: Suppose Alice wants to attack Bob, could Alice somehow convince 51% miner to help it steal from Bob?\n\nFirst, we should observe that *all* economically-rational actors have a *time preference*.\nThat is, N sats now is better than N sats tomorrow.\nIn particular, both the 51% miner *and* Alice the attacker have this time preference, as does victim Bob.\n\nWe can observe that in order for Alice to benefit from the theft, it has to *wait out* the `OP_CSV` before it can finalize the theft.\nAlice can offer fees to the miner only after the `OP_CSV` delay.\n\nHowever, Bob can offer fees *right now* on the justice transaction.\nAnd the 51% miner, being economically rational, would prefer the *right now* funds to the *maybe later* promise by Alice.\n\nIndeed, if Bob offered a justice transaction paying the channel amount minus 1 satoshi (i.e. Bob keeps 1 satoshi), then Alice has to beat that by offering the entire channel amount to the 51% miner.\nBut the 51% miner would then have to wait out the `OP_CSV` delay before it gets the funds.\nIts time preference may be large enough (if the `OP_CSV` delay is big enough) that it would rather side with Bob, who can pay channel amount - 1 right now, than Alice who promises to pay channel amount later.\n\n\"But Zeeman, Alice could offer to pay now from some onchain funds Alice has, and Alice can recoup the losses later!\"\nBut remember, Alice *also* has a time preference!\nLet us consider the case where Alice promises to bribe 51% miner *now*, on the promise that 51% miner will block the Bob justice transaction and *then* Alice gets to enjoy the entire channel amount later.\nBob can counter by offering channel amount - 1 right now on the justice transaction.\nThe only way for Alice to beat that is to offer channel amount right now, in which case 51% miner will now side with Alice.\n\nBut what happens to Alice in that case?\nIt loses out on channel amount right now, and then has to wait `OP_CSV` delay, to get the exact same amount later!\nIt gets no benefit, so this is not even an investment.\nIt is just enforced HODLing, but Alice can do that using `OP_CLTV` already.\n\nWorse, Alice has to trust that 51% miner will indeed block the justice transaction.\nBut if 51% miner is unscrupulous, it could do:\n\n* Get the bribe from Alice right now.\n* After the bribe from Alice confirms, confirm the justice transaction (which has a bribe from Bob).\n* Thus:\n  * Alice loses the channel amount.\n  * Bob keeps 1 satoshi.\n  * 51% miner gets channel amount + channel amount - 1.\n\nNow of course, we can eliminate the need for trust by using some kind of smart contract.\nUnfortunately for Alice, there is no contract that Alice and 51% miner can engage in, to ensure that 51% miner will block the justice transaction, which itself does *not* require that 51% miner wait out the `OP_CSV` delay.\nEither the payment from Alice to 51% miner is delayed (and the 51% miner suffers the time preference discount) or the 51% miner has to offer a bond that only gets released after the Alice theft succeeds (and again the 51% miner suffers the time preference discount on that bond).\n\nThus, due to the `OP_CSV` delay, the honest participant always has the upper hand, even in a 51% miner scenario.\nIf your channel is *not* with the 51% miner, your funds are still safe.\n\n--\n\nNow, we might consider, what if the 51% miner always blocks *all* Lightning-related transactions?\nIn that case, it loses out on any bribes that any LN participants would offer.\n\nFurther, with Taproot, a mutual LN channel close is indistinguishable from a singlesig spend.\nThus, not all LN-related transactions can be censored by the 51% miner.\nExtensive use of Taproot Tapleaves can also make it difficult for a 51% miner to differentiate between LN and other protocols (though that *does* mean we should probably e.g. coordiante with other protocols like CoinSwap, CoinPool etc. so that the \"shape\" of Taproot Tapleaves is consistent across protocols).\n\n--\n\nA final note: in the presence of channel factories, the *entire* factory is at risk if at least one participant is the 51% miner or a sockpuppet thereof.\nThus, channel factories trade off even further scaling, at the cost of reduced protection against 51% miners.\n\n\nRegards,\nZmnSCPxj\n\n[0]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-February/019976.html\n[1]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-February/019978.html"
            }
        ],
        "thread_summary": {
            "title": "A Comparison Of LN and Drivechain Security In The Presence Of 51% Attackers",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "ZmnSCPxj"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 7114
        }
    },
    {
        "title": "[Lightning-dev] [bitcoin-dev] A Comparison Of LN and Drivechain Security In The Presence Of 51% Attackers",
        "thread_messages": [
            {
                "author": "Paul Sztorc",
                "date": "2022-02-24T21:39:40",
                "message_text_only": "On 2/24/2022 7:49 AM, ZmnSCPxj via bitcoin-dev wrote:\n...\n\n>> ... it is easy for 51% hashrate to double-spend in the LN ...\n> ... the above statement is unequivocally ***true***.\n\nBoth LN and Drivechain are vulnerable to miner-theft; and both use their design to deter theft.\n\n> However, I believe that the following important points must be raised:\n>\n> * A 51% miner can only attack LN channels it is a participant in.\n> * A 51% miner can simultaneously attack all Drivechain-based sidechains and steal all of their funds.\n\nIn LN, the main obstacle is that your miner-coalition must first join the channel.\n\nIn DC, the main obstacle is that your miner-coalition must construct a txn obeying the Bip300 rules. Knowing that SPV proofs allow miner-theft, the Bip300 rules are designed specifically to try to thwart miner-theft.\n\n***\n\nI don't think I can stop people from being ignorant about Drivechain. But I can at least allow the Drivechain-knowledgable to identify each other.\n\nSo here below, I present a little \"quiz\". If you can answer all of these questions, then you basically understand Drivechain:\n\n0. We could change DC to make miner-theft impossible, by making it a layer1 consensus rule that miners never steal. Why is this cure worse than the disease?\n1. If 100% hashrate wanted to steal coins from a DC sidechain *as quickly as possible*, how long would this take (in blocks)?\n2. Per sidechain per year (ie, per 52560 blocks), how many DC withdrawals can take place (maximum)? How many can be attempted?\n      (Ie, how does the 'train track metaphor' work, from ~1h5m in the \"Overview and Misconceptions\" video)?\n3. Only two types of people should ever be using the DC withdrawal system at all.\n   3a. Which two?\n   3b. How is everyone else, expected to move their coins from chain to chain?\n   3c. (Obviously, this improves UX.) But why does it also improve security?\n--\n4. What do the parameters b and m stand for (in the DC security model)?\n5. How can m possibly be above 1? Give an example of a sidechain-attribute which may cause this situation to arise.\n6. For which range of m, is DC designed to deter sc-theft?\n7. If DC could be changed to magically deter theft across all ranges of m, why would that be bad for sidechain users in general?\n--\n8. If imminent victims of a DC-based theft, used a mainchain UASF to prohibit the future theft-withdrawal, then how would this affect non-DC users?\n9. In what ways might the BTC network one day become uncompetitive? And how is this different from caring about a sidechain's m and b?\n--\n10. If DC were successful, Altcoin-investors would be harmed. Two Maximalist-groups would also be slightly harmed -- who are these?\n\n***\n\n> Thus, LN usage is safer than Drivechain usage.\n\nNeither LN nor DC, are intended for use by everyone in every circumstance.\n\nDC can simulate a zcash sidechain, but it can not allow for instant off-chain payments. So DC-vs-LN would never be an apples-to-apples comparison, on any criterion.\n\nThe end user should be free to decide, what risks they take with their money. Today, users can sell their BTC for Solana (or BSV or whatever). So, to me it seems clear that they should be \"allowed\" to spend their BTC to a Bip300 script, just as they are allowed to open a LN channel.\n\n-Paul\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220224/29005c37/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-02-26T07:39:36",
                "message_text_only": "Good morning Paul,\n\n\n> I don't think I can stop people from being ignorant about Drivechain. But I can at least allow the Drivechain-knowledgable to identify each other.\n>\n> So here below, I present a little \"quiz\". If you can answer all of these questions, then you basically understand Drivechain:\n>\n> 0. We could change DC to make miner-theft impossible, by making it a layer1 consensus rule that miners never steal. Why is this cure worse than the disease?\n\nNow miners are forced to look at all sideblocks, not optionally do so if it is profitable for them.\n\n> 1. If 100% hashrate wanted to steal coins from a DC sidechain *as quickly as possible*, how long would this take (in blocks)?\n\n13,150 (I think this is how you changed it after feedback from this list, I think I remember it was ~3000 before or thereabouts.)\n\n> 2. Per sidechain per year (ie, per 52560 blocks), how many DC withdrawals can take place (maximum)? How many can be attempted?\n>      (Ie, how does the 'train track metaphor' work, from ~1h5m in the \"Overview and Misconceptions\" video)?\n\nI hate watching videos, I can read faster than anyone can talk (except maybe Laolu, he speaks faster than I can process, never mind read).\n\n~4 times (assuming 52560 block per year, which may vary due to new miners, hashrate drops, etc)\n\n> 3. Only two types of people should ever be using the DC withdrawal system at all.\n>   3a. Which two?\n\na.  Miners destroying the sidechain because the sidechain is no longer viable.\nb.  Aggregators of sidechain-to-minechain transfers and large whales.\n\n>   3b. How is everyone else, expected to move their coins from chain to chain?\n\nCross-system atomic swaps.\n(I use \"System\" here since the same mechanism works for Lightning channels, and channels are not blockchains.)\n\n>   3c. (Obviously, this improves UX.) But why does it also improve security?\n\nDrivechain-based pegged transfers are aggregates of many smaller transfers and thus every transfer out from the sidechain contributes its \"fee\" to the security of the peg.\n\n> --\n> 4. What do the parameters b and m stand for (in the DC security model)?\n\nm is how much people want to kill a sidechain, 0 = everybody would be sad if it died and would rather burn all their BTC forever than continue living, 1 = do not care, > 1 people want to actively kill the sidechain.\n\nb is how much profit a mainchain miner expects from supporting a sidechain (do not remember the unit though).\nSomething like u = a + b where a is the mainchain, b is the sidechain, u is the total profit.\nOr fees?  Something like that.\n\n> 5. How can m possibly be above 1? Give an example of a sidechain-attribute which may cause this situation to arise.\n\nThe sidechain is a total scam.\nA bug may be found in the sidechain that completely negates any security it might have, thus removing any desire to protect the sidechain and potentially make users want to destroy it completely rather than let it continue.\nPeople end up hating sidechains completely.\n\n> 6. For which range of m, is DC designed to deter sc-theft?\n\nm <= 1\n\n> 7. If DC could be changed to magically deter theft across all ranges of m, why would that be bad for sidechain users in general?\n\nBecause the sidechain would already be part of mainchain consensus.\n\n> --\n> 8. If imminent victims of a DC-based theft, used a mainchain UASF to prohibit the future theft-withdrawal, then how would this affect non-DC users?\n\nIf the non-DC users do not care, then they are unaffected.\nIf the non-DC users want to actively kill the sidechain, they will counterattack with an opposite UASF and we have a chainsplit and sadness and mutual destruction and death and a new subreddit.\n\n> 9. In what ways might the BTC network one day become uncompetitive? And how is this different from caring about a sidechain's m and b?\n\nIf it does not enable scaling technology fast enough to actually be able to enable hyperbitcoinization.\n\nSidechains are not a scaling solution, so caring about m and b is different because your focus is not on scaling.\n\n> --\n> 10. If DC were successful, Altcoin-investors would be harmed. Two Maximalist-groups would also be slightly harmed -- who are these?\n\nDunno!\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-02-26T14:58:12",
                "message_text_only": "> m is how much people want to kill a sidechain, 0 = everybody would be sad\nif it died and would rather burn all their BTC forever than continue living\n\nMath is brutal\n\nOn Sat, Feb 26, 2022, 01:39 ZmnSCPxj via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> Good morning Paul,\n>\n>\n> > I don't think I can stop people from being ignorant about Drivechain.\n> But I can at least allow the Drivechain-knowledgable to identify each other.\n> >\n> > So here below, I present a little \"quiz\". If you can answer all of these\n> questions, then you basically understand Drivechain:\n> >\n> > 0. We could change DC to make miner-theft impossible, by making it a\n> layer1 consensus rule that miners never steal. Why is this cure worse than\n> the disease?\n>\n> Now miners are forced to look at all sideblocks, not optionally do so if\n> it is profitable for them.\n>\n> > 1. If 100% hashrate wanted to steal coins from a DC sidechain *as\n> quickly as possible*, how long would this take (in blocks)?\n>\n> 13,150 (I think this is how you changed it after feedback from this list,\n> I think I remember it was ~3000 before or thereabouts.)\n>\n> > 2. Per sidechain per year (ie, per 52560 blocks), how many DC\n> withdrawals can take place (maximum)? How many can be attempted?\n> >      (Ie, how does the 'train track metaphor' work, from ~1h5m in the\n> \"Overview and Misconceptions\" video)?\n>\n> I hate watching videos, I can read faster than anyone can talk (except\n> maybe Laolu, he speaks faster than I can process, never mind read).\n>\n> ~4 times (assuming 52560 block per year, which may vary due to new miners,\n> hashrate drops, etc)\n>\n> > 3. Only two types of people should ever be using the DC withdrawal\n> system at all.\n> >   3a. Which two?\n>\n> a.  Miners destroying the sidechain because the sidechain is no longer\n> viable.\n> b.  Aggregators of sidechain-to-minechain transfers and large whales.\n>\n> >   3b. How is everyone else, expected to move their coins from chain to\n> chain?\n>\n> Cross-system atomic swaps.\n> (I use \"System\" here since the same mechanism works for Lightning\n> channels, and channels are not blockchains.)\n>\n> >   3c. (Obviously, this improves UX.) But why does it also improve\n> security?\n>\n> Drivechain-based pegged transfers are aggregates of many smaller transfers\n> and thus every transfer out from the sidechain contributes its \"fee\" to the\n> security of the peg.\n>\n> > --\n> > 4. What do the parameters b and m stand for (in the DC security model)?\n>\n> m is how much people want to kill a sidechain, 0 = everybody would be sad\n> if it died and would rather burn all their BTC forever than continue\n> living, 1 = do not care, > 1 people want to actively kill the sidechain.\n>\n> b is how much profit a mainchain miner expects from supporting a sidechain\n> (do not remember the unit though).\n> Something like u = a + b where a is the mainchain, b is the sidechain, u\n> is the total profit.\n> Or fees?  Something like that.\n>\n> > 5. How can m possibly be above 1? Give an example of a\n> sidechain-attribute which may cause this situation to arise.\n>\n> The sidechain is a total scam.\n> A bug may be found in the sidechain that completely negates any security\n> it might have, thus removing any desire to protect the sidechain and\n> potentially make users want to destroy it completely rather than let it\n> continue.\n> People end up hating sidechains completely.\n>\n> > 6. For which range of m, is DC designed to deter sc-theft?\n>\n> m <= 1\n>\n> > 7. If DC could be changed to magically deter theft across all ranges of\n> m, why would that be bad for sidechain users in general?\n>\n> Because the sidechain would already be part of mainchain consensus.\n>\n> > --\n> > 8. If imminent victims of a DC-based theft, used a mainchain UASF to\n> prohibit the future theft-withdrawal, then how would this affect non-DC\n> users?\n>\n> If the non-DC users do not care, then they are unaffected.\n> If the non-DC users want to actively kill the sidechain, they will\n> counterattack with an opposite UASF and we have a chainsplit and sadness\n> and mutual destruction and death and a new subreddit.\n>\n> > 9. In what ways might the BTC network one day become uncompetitive? And\n> how is this different from caring about a sidechain's m and b?\n>\n> If it does not enable scaling technology fast enough to actually be able\n> to enable hyperbitcoinization.\n>\n> Sidechains are not a scaling solution, so caring about m and b is\n> different because your focus is not on scaling.\n>\n> > --\n> > 10. If DC were successful, Altcoin-investors would be harmed. Two\n> Maximalist-groups would also be slightly harmed -- who are these?\n>\n> Dunno!\n>\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220226/cf55492c/attachment.html>"
            },
            {
                "author": "Paul Sztorc",
                "date": "2022-02-27T00:42:22",
                "message_text_only": "Not bad, but not particularly good either.\n\nDefinitely correct:\n \u00a0 1\u00a0 (plus extra credit, it was originally 1008+2016),\n \u00a0 3a \"whales\"\n \u00a0 3b (atomic swaps is the \"official\" answer, but otc trading is also \nacceptable, or just \"trade\" in general)\n \u00a0 6\n \u00a0 9\u00a0 part one\n\nClose, but not quite right:\n \u00a0 2\u00a0 (part one \"~4\" is correct, but you didn't answer part two)\n \u00a0 3a \"attacker- miners\" is not the way I see it at all\n \u00a0 3c true, but I was talking about withdrawal security, not hashrate, \n[this is related to the 3a \"attacker miners\" mis-answer]\n \u00a0 4\u00a0 ? you seem to have not very seriously answered this. The \nparameters are spelled out in the original Nov 2015 post\n\nSome kind of miscommunication may have happened:\n \u00a0 8 -- I was more thinking, what happens if the UASF fails (in \nthwarting miners) vs succeeds. (I take it for granted that non-DC users \nwill prefer to do nothing, and prefer to be unaffected.)\n\nSeems wrong to me:\n \u00a0 0\u00a0 seems like a pretty big misunderstanding happened here, or else \nyou mistakenly typo'd the wrong word\n \u00a0 5\u00a0 (you started with m=1 examples, which is not what was requested; \nand finished with something not a sidechain attribute)\n \u00a0 7\u00a0 [related to the miss on #5] ; it is not a re-ask of question #0\n \u00a0 9\u00a0 part two is wrong\n \u00a010\u00a0 you did not answer\n\nPaul\n\n\nOn 2/26/2022 2:39 AM, ZmnSCPxj wrote:\n> Good morning Paul,\n>\n>\n>> I don't think I can stop people from being ignorant about Drivechain. But I can at least allow the Drivechain-knowledgable to identify each other.\n>>\n>> So here below, I present a little \"quiz\". If you can answer all of these questions, then you basically understand Drivechain:\n>>\n>> 0. We could change DC to make miner-theft impossible, by making it a layer1 consensus rule that miners never steal. Why is this cure worse than the disease?\n> Now miners are forced to look at all sideblocks, not optionally do so if it is profitable for them.\n>\n>> 1. If 100% hashrate wanted to steal coins from a DC sidechain *as quickly as possible*, how long would this take (in blocks)?\n> 13,150 (I think this is how you changed it after feedback from this list, I think I remember it was ~3000 before or thereabouts.)\n>\n>> 2. Per sidechain per year (ie, per 52560 blocks), how many DC withdrawals can take place (maximum)? How many can be attempted?\n>>       (Ie, how does the 'train track metaphor' work, from ~1h5m in the \"Overview and Misconceptions\" video)?\n> I hate watching videos, I can read faster than anyone can talk (except maybe Laolu, he speaks faster than I can process, never mind read).\n>\n> ~4 times (assuming 52560 block per year, which may vary due to new miners, hashrate drops, etc)\n>\n>> 3. Only two types of people should ever be using the DC withdrawal system at all.\n>>    3a. Which two?\n> a.  Miners destroying the sidechain because the sidechain is no longer viable.\n> b.  Aggregators of sidechain-to-minechain transfers and large whales.\n>\n>>    3b. How is everyone else, expected to move their coins from chain to chain?\n> Cross-system atomic swaps.\n> (I use \"System\" here since the same mechanism works for Lightning channels, and channels are not blockchains.)\n>\n>>    3c. (Obviously, this improves UX.) But why does it also improve security?\n> Drivechain-based pegged transfers are aggregates of many smaller transfers and thus every transfer out from the sidechain contributes its \"fee\" to the security of the peg.\n>\n>> --\n>> 4. What do the parameters b and m stand for (in the DC security model)?\n> m is how much people want to kill a sidechain, 0 = everybody would be sad if it died and would rather burn all their BTC forever than continue living, 1 = do not care, > 1 people want to actively kill the sidechain.\n>\n> b is how much profit a mainchain miner expects from supporting a sidechain (do not remember the unit though).\n> Something like u = a + b where a is the mainchain, b is the sidechain, u is the total profit.\n> Or fees?  Something like that.\n>\n>> 5. How can m possibly be above 1? Give an example of a sidechain-attribute which may cause this situation to arise.\n> The sidechain is a total scam.\n> A bug may be found in the sidechain that completely negates any security it might have, thus removing any desire to protect the sidechain and potentially make users want to destroy it completely rather than let it continue.\n> People end up hating sidechains completely.\n>\n>> 6. For which range of m, is DC designed to deter sc-theft?\n> m <= 1\n>\n>> 7. If DC could be changed to magically deter theft across all ranges of m, why would that be bad for sidechain users in general?\n> Because the sidechain would already be part of mainchain consensus.\n>\n>> --\n>> 8. If imminent victims of a DC-based theft, used a mainchain UASF to prohibit the future theft-withdrawal, then how would this affect non-DC users?\n> If the non-DC users do not care, then they are unaffected.\n> If the non-DC users want to actively kill the sidechain, they will counterattack with an opposite UASF and we have a chainsplit and sadness and mutual destruction and death and a new subreddit.\n>\n>> 9. In what ways might the BTC network one day become uncompetitive? And how is this different from caring about a sidechain's m and b?\n> If it does not enable scaling technology fast enough to actually be able to enable hyperbitcoinization.\n>\n> Sidechains are not a scaling solution, so caring about m and b is different because your focus is not on scaling.\n>\n>> --\n>> 10. If DC were successful, Altcoin-investors would be harmed. Two Maximalist-groups would also be slightly harmed -- who are these?\n> Dunno!\n>\n>\n> Regards,\n> ZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "A Comparison Of LN and Drivechain Security In The Presence Of 51% Attackers",
            "categories": [
                "Lightning-dev",
                "bitcoin-dev"
            ],
            "authors": [
                "Paul Sztorc",
                "Billy Tetrud",
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 18265
        }
    }
]