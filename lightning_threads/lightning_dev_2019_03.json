[
    {
        "title": "[Lightning-dev] [RELEASE] c-lightning v0.7.0: \"Actually an Altcoin\"",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2019-03-01T21:47:51",
                "message_text_only": "We're pleased to announce c-lightning 0.7, named by Mark Beckwith.\n\n        https://github.com/ElementsProject/lightning/releases/tag/v0.7.0\n\nHighlights for Users\n--------------------\n\n* Plugins are here, with frameworks for C, Python and Go! Write your own\n  cool extensions!\n* Much better pay implementation (a plugin!) will folllow route hints,\n  give ongoing paystatus.\n* All amount parameters take 'msat', 'sat', or 'btc' to avoid\n  satoshi/millisatoshi confusion.\n* If your node ran out of memory with gossipd consuming 100% CPU, that\n  and several other crashes are fixed!\n* Reproducible builds for Ubuntu, based on Ubuntu 18.04.1.\n\nHighlights for the network\n--------------------------\n\n* option_dataloss_protect fixed and reenabled for everyone.\n* We accept some known lnd protocol oddities rather than spitting the dummy and closing the channel.\n* You can no longer make unpayable \"wumbo\" invoices.\n\nMore details can be found in the\n\n        https://github.com/ElementsProject/lightning/blob/v0.7.0/CHANGELOG.md\n\nContributions\n-------------\n\nWe're grateful for all the bug reports and suggestions and your patience\nas we sometimes struggled to address them: please keep them coming!\n\nSince 0.6.3 we've had 284 commits from 16 different authors, 5 of whom\nwere first-time c-lightning contributors:\n\n    Alekos Filini\n    fanquake\n    Michael Schmoock\n    Rene Pickhardt\n    @wailo\n\nThat's comparable with the last release, but in 7 weeks instead of 10: kudos!\n\nCheers,\nRusty, Christian and ZmnSCPxj.\n\nad4b60dde249692d0fbf446436427528cb91f1acbb03a052928714d0d0037493  release/clightning-v0.7.0-Fedora-28-amd64.tar.gz\n302aad864ba48be1d41a4787e32be4759b1a44985be20da868a3e25fe412061f  release/clightning-v0.7.0-Ubuntu-16.04-i386.tar.gz\n2da679f55cbe1cec6fee9b32c0943ddde3a19c6605d81e52807921bbca6d2fe1  release/clightning-v0.7.0-Ubuntu-18.04.tar.xz\n448022c2433cbf19bbd0f726344b0500c0c21ee5cc2291edf6b622f094cb3a15  release/clightning-v0.7.0.zip\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 832 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190302/6a95cc0e/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "c-lightning v0.7.0: \"Actually an Altcoin\"",
            "categories": [
                "Lightning-dev",
                "RELEASE"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2224
        }
    },
    {
        "title": "[Lightning-dev] Just in Time Routing (JIT-Routing) and a channel rebalancing heuristic as an add on for improved routing success in BOLT 1.0",
        "thread_messages": [
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2019-03-05T13:47:18",
                "message_text_only": "Hey everyone,\n\nIn this mail I introduce the Just in Time Routing schema (aka JIT Routing).\nIts main idea is to mitigate the disadvantages from our current source\nbased routing (i.e.: guessing a route that will work in the sense that it\nhas enough liquidity in each channel) and make the routing process a little\nbit more like the best effort routing that we know from IP-forwarding. As\nfar as I know this will not decrease the privacy of the nodes. As part of\nthis Routing scheme nodes need to be able to quickly rebalance their\nchannels. Thus in this mail I also propose a heuristic for doing this\nefficiently which I have implemented and seems to provide pretty good\nresults. Obviously the heuristic should be tested with the help of a\nsimulation. I did not have the chance to do that yet. Partly also because I\nam lacking a proper dataset and I don't want to do this on artificial data.\n\nThe advantages of JIT Routing are:\n* it is possible to do now without any protocol modification. In particular\nno modifications of the onions are necessary.\n* routing nodes can already easily implement it. By implementing it they\nwill increase the routing success even for nodes which are running older\nimplementations\n* it seems to be logically equivalent to AMP Routing. In particular its\nproperties will also help base AMP once it is part of the protocol.\n* local channel balance information along the route can now be part of the\npath finding process while not decreasing the privacy by sharing\ninformation about channel balances with others. In fact the privacy of\nnodes is even being increased.\n\nThe disadvantages seem:\n* it might economically not be incentivized for a routing node in every\nsituation. Theoretically it can even happen that a node pays a fee in order\nto use this technique but can't earn the routing fee as the onion fails\nlater. Nodes can implement risk management strategies to mitigate this\nissue.\n* The routing process might take a longer time as it starts sub routing\nprocesses.\n* While doing JIT routing the capacity for channels should be reserved even\nbefore HTLCs are set up (to prevent hostile recursive chains of rebalancing\noperations)\n\nObviously routing single big payments is a challenge for the lightning\nnetwork. During the developer summit in Adelaide we have agreed to put Base\nAMP to BOLT 1.1. To review Base AMP the idea is basically after receiving a\npayment hash to create several onions on various routes to the recipient.\nWhile Base AMP in theory can find the maxflow / min cut and achieve maximum\nliquidity it is not clear yet how well Base AMP will really work.\n\nWhile it has been shown that smaller payments have a higher chance to be\nrouted successfully there is the downside that we have more payments which\nincreases the likelihood that any one of those payment eventually fails. As\nfar as I know there have not been any studies researching this fact. Also\nthe fact remains that Base AMP is still a source base routing protocol\nputting the sender into a tough spot as it has to guess which routes might\nwork.\n\nHow to JIT Routing?\n\nFor the BOLTs we basically need one Recommendation (in fact even today\nnodes can do this without this explicit recommendation, but I would suggest\nto add the recommendation):\n\nIf a node cannot forward an incoming HTLC because the node has not enough\nfunds on the outgoing channel the node MAY pause the routing process and\ntry to rebalance the channel that misses liquidity. If it isn't able to\nrebalance the channel it should fail the onion sending back an insufficient\nwire funds error `temporary_channel_failure`\n\nLet us consider the following Graph and situation for an example:\n\n  100 / 110     80 / 200\nS ----------> B --------> R\n              \\         /\n        80/200  \\     /  100/200\n                  \\ /\n                             T\n\nMeaning we have the following channels:\nS ---> B capacity: 110   A funds: 100  B funds:  10\nB ---> R capacity: 200   B funds:  80  R funds: 120\nB ---> T capacity: 200   B funds:  80  T funds: 120\nT ---> R capacity: 200   T funds: 100  R funds: 100\n\nLet us assume S wants to send a payment of 90 to R. With this distribution\nof funds this will not work with a single route S ---> B ---> R as the\nchannel B--->R can only forward 78 (taking the channel reserve of 1% into\nconsideration)\n\nNow with Base AMP after a protocol update this would be resolved by making\ntwo onions forwarding for example 45 each. Also S would have to pay more\nrouting fees as the basefee of B will be charged twice.\n\nOnion 1: S ---> B ---> R\nOnion 2: S ---> B ---> T ---> R\n\nHowever it is S again who has to guess how the problems with the liquidity\nare it does not know how B has spread its funds between R and T (and\npotentially other channels)\n\nWith the above recommendation in place B can create a different onion with\nlets say moving 50 from the B---> T channel to the B ---> R channel\nresulting in the following situation:\n\n  100 / 110     130 / 200\nS ----------> B --------> R\n              \\         /\n        30/200  \\     /  50/200\n                  \\ /\n                             T\n\nMeaning we have the following channels:\nS ---> B capacity: 110   A funds: 100  B funds:  10\nB ---> R capacity: 200   B funds: 130  R funds:  70\nB ---> T capacity: 200   B funds:  30  T funds: 170\nT ---> R capacity: 200   T funds:  50  R funds: 150\n\nNow B can easily pass the original onion with a value of 90 which was\ndesigned for the route S ---> B ---> R\n\nObviously there can also be issues when B tries to rebalance their channels\nas the attempted event of rebalancing might trigger another JIT operation\nat another node (potentially making a later stage of the original onion\nharder to be forwarded). Also B does not have full information about the\nT---> R channel. Yet B has more information about B's neighbourhood than S\ndoes as B knows which channels are liquid and how many paths exist between\nthe endpoints of those channels. This B should be able to make a more\neducated decision as the originator node S. Since B would only do a\nrebalancing if the routing fees for the rebalancing are cheaper than the\nfees they collect (and other nodes would do the same) the risk for and\ninfinit cascade of rebalancing operations should be mitigated. Also the\ntotal CLTV for the rebalancing operation should be smaller than the\noriginal onion.  A sender of the onion could obviously start with larger\ncltv_deltas to allow routing nodes to have some buffer. This is also good\nin the sense of shadow routing as described in the BOLTs.\n\nAnother problem that might arise is the question if the routing node is\nable to quickly compute rebalancing paths. I have been working on a\nc-lightning plugin for rebalancing over the weekend (it is actually when I\ncame up with the idea of JIT routing). Currently I use the following\npromising heuristic for rebalancing:\nI look at the friend of a friend network of the node that wants to\nrebalance channels. This network consists of alle channel partners of the\nnode and their channels. This will in particular have all triangles and\nrectangles of the lightning network that the node that wants to rebalance\nis part of. Now I remove the node that wants to rebalance from the friend\nof the friend network. The resulting graph should always stay pretty small.\nIn a regular small world network the friend of a friend graph consists of\nroughly 10k nodes. In particular after pruning nodes with degree 1 (which\ncan't be used to rebalance on this subgraph) we have a pretty small\nnetwork. After extracting this subnetwork (which for general operation\ncould always be maintained while gossip messages are coming in) the\ncomputation to suggest several hundred rebalancing cycles and even ordering\nthem by price takes less than 1 second on my machine.\nSo far I have been pretty successful finding several (cheap!) rebalancing\nsuggestions in this network from my lightning node (which has about 40\nchannels)\n\nI will release the code for the rebalancing schema soon but I wanted to\nhave the idea already out in order to get more feedback while working on\nthis.\n\nbest Rene\n\n\n\n\n\n-- \nhttps://www.rene-pickhardt.de\n\nSkype: rene.pickhardt\n\nmobile: +49 (0)176 5762 3618\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190305/8ed84b9d/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-06T10:38:27",
                "message_text_only": "Good morning Rene,\n\nThe base idea is good at first glance.\n\nHowever, let us consider this situation:\n\n\n          0.1   1.0\n        A --------- B\n    1.5 |         / 0.5\n        |        /\n        |       /\n        |      /\n        |     /\n        |    /\n        |   /\n        |  /\n    0.5 | / 0.75\n        C\n\n\nA must pay B, 1.0 BTC.\n\nA knows the exact state of AB and AC channels, but only knows that BC has total 1.25 capacity.\n\nA sends via route A->C->B.\nIt knows that it has sufficient capacity in AC.\nIt also knows that the total capacity in CB has a chance of transferring 1.0BTC.\n\nSo what happens (let us assume Lightning fees are negligible).\n\n1.  A locks 1.0 in AC in an HTLC.\n2.  C cannot forward since it has only 0.75 in CB.\n    It initiates a rebalance.\n3.  C notices it has 0.5 BTC in AC.\n    It can transfer 0.25BTC from AC to CB to be able to get 1.0 in CB that it can forward.\n    So it routes 0.25 BTC via C->A->B->C.\n4.  C locks 0.25 in CA in an HTLC.\n5.  A cannot forward the C->A->B->C payment since it only has 0.1BTC in AB.\n    It initiates a rebalance.\n6.  A notices it has 0.5 BTC in AC (1.0 is currently locked in an HTLC, leaving it 0.5BTC).\n    It can transfer 0.15BTC in AC to AB to be able to get 0.25 in AC that it can forward.\n    So it routes 0.15 BTC via A->C->B->C.\n7.  A locks 0.15 in AC in an HTLC.\n8.  C is now in a bind.\n    If it forwards the 0.15 BTC, then it will still fail the earlier A->C->B 1.0 payment.\n    This is because it will lose 0.15 BTC from its side here, leading to 0.6 BTC, then receive 0.25 BTC from the rebalance, only having 0.85 BTC.\n    If it does not forward, A is unable to rebalance and fails the rebalance of C, which fails the original payment from A->C->B.\n\nThus it seems to me, that precisely because of the lack of a global view, such kinds of complicated HTLC networks will form, then still lead to payment failure.\n\n--\n\nPerhaps it is better to consider that a high-level payment failure requires failure of all possible routes.\n>From that point of view, a failure of a single payment attempt is not a big deal.\n\n--\n\nWith that said, it may still be valuable to try doing this.\nIt will massively increase the complexity in c-lightning.\nWe would need a new persistent db table (meaning not in Python, at least until we make c-lightning into a bus connecting its actual running components that send commands to each other via the same bus that external commands and plugins use).\n\nThen we can evaluate a small network of such nodes on mainnet LN and see how often rebalance failures occur.\n\nRegards,\nZmnSCPxj\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Tuesday, March 5, 2019 9:47 PM, Ren\u00e9 Pickhardt via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n\n> Hey everyone,\n>\n> In this mail I introduce the Just in Time Routing schema (aka JIT Routing). Its main idea is to mitigate the disadvantages from our current source based routing (i.e.: guessing a route that will work in the sense that it has enough liquidity in each channel) and make the routing process a little bit more like the best effort routing that we know from IP-forwarding. As far as I know this will not decrease the privacy of the nodes. As part of this Routing scheme nodes need to be able to quickly rebalance their channels.\u00a0Thus in this mail I also propose a heuristic for doing this efficiently which I have implemented and seems to provide pretty good results. Obviously the heuristic should be tested with the help of a simulation. I did not have the chance to do that yet. Partly also because I am lacking a proper dataset and I don't want to do this on artificial data.\n>\n> The advantages of JIT Routing are:\n> *\u00a0it is possible to do now without any protocol modification. In particular no modifications of the onions are necessary.\n> * routing nodes can already easily implement it. By implementing it they will increase the routing success even for nodes which are running older implementations\n> * it seems to be logically equivalent to AMP Routing. In particular its properties will also help base AMP once it is part of the protocol.\n> * local channel balance information along the route can now be part of the path finding process while not decreasing the privacy by sharing information about channel balances with others. In fact the privacy of nodes is even being increased.\u00a0\n>\n> The disadvantages seem:\u00a0\n> * it might economically not be incentivized for a routing node in every situation. Theoretically it can even happen that a node pays a fee in order to use this technique but can't earn the routing fee as the onion fails later. Nodes can implement risk management strategies to mitigate this issue.\n> * The routing process might take a longer time as it starts sub routing processes.\u00a0\u00a0\n> * While doing JIT routing the capacity for channels should be reserved even before HTLCs are set up (to prevent hostile recursive chains of rebalancing operations)\n>\n> Obviously routing single big payments is a challenge for the lightning network. During the developer summit in Adelaide we have agreed to put Base AMP to BOLT 1.1. To review Base AMP the idea is basically after receiving a payment hash to create several onions on various routes to the recipient. While Base AMP in theory can find the maxflow / min cut and achieve maximum liquidity it is not clear yet how well Base AMP will really work.\n>\n> While it has been shown that smaller payments have a higher chance to be routed successfully there is the downside that we have more payments which increases the likelihood that any one of those payment eventually fails. As far as I know there have not been any studies researching this fact. Also the fact remains that Base AMP is still a source base routing protocol putting the sender into a tough spot as it has to guess which routes might work.\n>\n> How to JIT Routing?\n>\n> For the BOLTs we basically need one Recommendation (in fact even today nodes can do this without this explicit recommendation, but I would suggest to add the recommendation):\u00a0\n>\n> If a node cannot forward an incoming HTLC because the node has not enough funds on the outgoing channel the node MAY pause the routing process and try to rebalance the channel that misses liquidity. If it isn't able to rebalance the channel it should fail the onion sending back an insufficient wire funds error `temporary_channel_failure`\n>\n> Let us consider the following Graph and situation for an example:\u00a0\n>\n> \u00a0 100 / 110\u00a0 \u00a0 \u00a080 / 200\n> S ----------> B --------> R\n> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0/\n> \u00a0 \u00a0 \u00a0 \u00a0 80/200\u00a0 \\\u00a0 \u00a0 \u00a0/\u00a0 100/200\n> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \\ /\u00a0\n> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0T\n>\n> Meaning we have the following channels:\n> S ---> B capacity: 110\u00a0 \u00a0A funds: 100\u00a0 B funds:\u00a0 10\n> B ---> R capacity: 200\u00a0 \u00a0B funds:\u00a0 80\u00a0 R funds: 120\n> B ---> T capacity: 200\u00a0 \u00a0B funds:\u00a0 80\u00a0 T funds: 120\n> T ---> R capacity: 200\u00a0 \u00a0T funds: 100\u00a0 R funds: 100\n>\n> Let us assume S wants to send a payment of 90 to R. With this distribution of funds this will not work with a single route S ---> B ---> R as the channel B--->R can only forward 78 (taking the channel reserve of 1% into consideration)\n>\n> Now with Base AMP after a protocol update this would be resolved by making two onions forwarding for example 45 each. Also S would have to pay more routing fees as the basefee of B will be charged twice.\u00a0\n>\n> Onion 1: S ---> B ---> R\n> Onion 2: S ---> B ---> T ---> R\n>\n> However it is S again who has to guess how the problems with the liquidity are it does not know how B has spread its funds between R and T (and potentially other channels)\n>\n> With the above recommendation in place B can create a different onion with lets say moving 50 from the B---> T channel to the B ---> R channel resulting in the following situation:\u00a0\n>\n> \u00a0 100 / 110\u00a0 \u00a0 \u00a0130 / 200\n> S ----------> B --------> R\n> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0/\n> \u00a0 \u00a0 \u00a0 \u00a0 30/200\u00a0 \\\u00a0 \u00a0 \u00a0/\u00a0 50/200\n> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \\ /\u00a0\n> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0T\n>\n> Meaning we have the following channels:\n> S ---> B capacity: 110\u00a0 \u00a0A funds: 100\u00a0 B funds:\u00a0 10\n> B ---> R capacity: 200\u00a0 \u00a0B funds: 130\u00a0 R funds:\u00a0 70\n> B ---> T capacity: 200\u00a0 \u00a0B funds:\u00a0 30\u00a0 T funds: 170\n> T ---> R capacity: 200\u00a0 \u00a0T funds:\u00a0 50\u00a0 R funds: 150\n>\n> Now B can easily pass the original onion with a value of 90 which was designed for the route S ---> B ---> R\n>\n> Obviously there can also be issues when B tries to rebalance their channels as the attempted event of rebalancing might trigger another JIT operation at another node (potentially making a later stage of the original onion harder to be forwarded). Also B does not have full information about the T---> R channel. Yet B has more information about B's neighbourhood than S does as B knows which channels are liquid and how many paths exist between the endpoints of those channels. This B should be able to make a more educated decision as the originator node S. Since B would only do a rebalancing if the routing fees for the rebalancing are cheaper than the fees they collect (and other nodes would do the same) the risk for and infinit cascade of rebalancing operations should be mitigated. Also the total CLTV for the rebalancing operation should be smaller than the original onion.\u00a0 A sender of the onion could obviously start with larger cltv_deltas to allow routing nodes to have some buffer. This is also good in the sense of shadow routing as described in the BOLTs.\u00a0\n>\n> Another problem that might arise is the question if the routing node is able to quickly compute rebalancing paths. I have been working on a c-lightning plugin for rebalancing over the weekend (it is actually when I came up with the idea of JIT routing). Currently I use the following promising heuristic for rebalancing:\n> I look at the friend of a friend network of the node that wants to rebalance channels. This network consists of alle channel partners of the node and their channels. This will in particular have all triangles and rectangles of the lightning network that the node that wants to rebalance is part of. Now I remove the node that wants to rebalance from the friend of the friend network. The resulting graph should always stay pretty small. In a regular small world network the friend of a friend graph consists of roughly 10k nodes. In particular after pruning nodes with degree 1 (which can't be used to rebalance on this subgraph) we have a pretty small network. After extracting this subnetwork (which for general operation could always be maintained while gossip messages are coming in) the computation to suggest several hundred rebalancing cycles and even ordering them by price takes less than 1 second on my machine.\u00a0\n> So far I have been pretty successful finding several (cheap!) rebalancing suggestions in this network from my lightning node (which has about 40 channels)\u00a0\n>\n> I will release the code for the rebalancing schema soon but I wanted to have the idea already out in order to get more feedback while working on this.\u00a0\n>\n> best Rene\n>\n> \u00a0\n>\n> --\n> https://www.rene-pickhardt.de\n>\n> Skype: rene.pickhardt\u00a0\n>\n> mobile: +49 (0)176 5762 3618"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-14T11:44:42",
                "message_text_only": "Good morning Rene and list,\n\nLet us consider then the rule *when* a rebalancing would be beneficial to the node.\n\nThe node is offered a fee amount (`offered_fee_amount`) for the forwarding.\nIt knows that, under current channel states, it will definitely have to fail and earn 0 fees.\n\nIf it engages in JIT-routing, it must pay some fee (`rebalancing_fee_amount`) for the rebalancing operation.\nBut even if it successfully forwards its hop, it is still possible that the route will fail anyway and it will earn 0 fees.\n\nSo let us consider the probability of success (`success_rate`), a value between 0 to 1.0.\nThis is the estimated probability that we will succeed the route after we forward it.\n\nWe should only engage in JIT-routing if:\n\n    offered_fee_amount * success_rate - rebalancing_fee_amount > 0\n\nThe LHS of the subtraction is the expected earning, while the RHS of the subtraction is the expected cost.\nThe above is trivial accounting for determining net earnings.\n\nThe fee amounts are trivially computable.\nPresumably the rebalancing code can compute the fee given a particular rebalance path, and thus can provide `rebalancing_fee_amount`.\n\nThe `success_rate` can be computed statically from some node data.\nBetter, is for the node to start with this precomputed static information, but augment this over time with its own experienced `success_rate` for all forwards.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Ariel Lorenzo-Luaces",
                "date": "2019-03-14T13:08:11",
                "message_text_only": "Hello Rene, ZmnSCPxj, and list\u00a0\n\n\nI really like the proposal and I'm sure it's the correct way forward for reducing payment failures and increasing privacy (through mitigating probing based network analysis)\u00a0\n\n\nHowever I am concerned that this proposal could introduce a vulnerability to a spoofed-payment attack.\u00a0\n\n\nAn adversary could create a malicious payment that's guaranteed to fail, for free. Any intermediary nodes on the path of the payment before it fails could lose fees due to rebalancing if the rebalancing path's success is not dependent on the original payment's success.\u00a0\n\n\nCould anyone speak to this and confirm whether it would be possible for the rebalancing step to reuse the original payment hash? If this is possible then it should explicitly be included in this proposal.\u00a0\n\n\nIf reusing the payment hash is not possible on the routing path then JIT routing would need some other mitigation for the spoofed-payment attack.\u00a0\n\n\nCheers\u00a0\n\n\nAriel Lorenzo-Luaces\u00a0\n\n\n\n\nOn Mar 14, 2019, 7:45 AM, at 7:45 AM, ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n>Good morning Rene and list,\n>\n>Let us consider then the rule *when* a rebalancing would be beneficial\n>to the node.\n>\n>The node is offered a fee amount (`offered_fee_amount`) for the\n>forwarding.\n>It knows that, under current channel states, it will definitely have to\n>fail and earn 0 fees.\n>\n>If it engages in JIT-routing, it must pay some fee\n>(`rebalancing_fee_amount`) for the rebalancing operation.\n>But even if it successfully forwards its hop, it is still possible that\n>the route will fail anyway and it will earn 0 fees.\n>\n>So let us consider the probability of success (`success_rate`), a value\n>between 0 to 1.0.\n>This is the estimated probability that we will succeed the route after\n>we forward it.\n>\n>We should only engage in JIT-routing if:\n>\n>    offered_fee_amount * success_rate - rebalancing_fee_amount > 0\n>\n>The LHS of the subtraction is the expected earning, while the RHS of\n>the subtraction is the expected cost.\n>The above is trivial accounting for determining net earnings.\n>\n>The fee amounts are trivially computable.\n>Presumably the rebalancing code can compute the fee given a particular\n>rebalance path, and thus can provide `rebalancing_fee_amount`.\n>\n>The `success_rate` can be computed statically from some node data.\n>Better, is for the node to start with this precomputed static\n>information, but augment this over time with its own experienced\n>`success_rate` for all forwards.\n>\n>Regards,\n>ZmnSCPxj\n>_______________________________________________\n>Lightning-dev mailing list\n>Lightning-dev at lists.linuxfoundation.org\n>https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190314/5243cc1d/attachment.html>"
            },
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2019-03-14T22:18:26",
                "message_text_only": "Hey everyone,\n\nI am glad the suggestion is being picked up. At this time I want to respond\nto two of the concerns that have been thrown in. I have some other comments\nand ideas but would like to hold them back so that we can have more people\njoining the discussion without bias also this mail will already be quite\nlong.\n\nZmnSCPxj suggested to introduce a `success_rate` for JIT routing. While\nthis success_rate can obviously only be estimated or configured I would\nadvice against including this to the protocol. As I mentioned before I\nsuggested to include JIT Routing as a MAY Recommendation so it is up to the\nnode to decide if it cannot earn `offered_fee_amount` to engage in the\nJIT-rebalancing operation. A node operator might be willing in general to\nto pay a fee for rebalancing even if there is not an outstanding routing\nevent taking place. So even while `rebalancing_fee_amount` >\n`offered_fee_amount` the node could see the offered_fee_amount as a\ndiscount for the planned rebalancing amount. We don't know that and I\nhonestly believe that the protocol should not make economical decisions for\nthe node. In any case rebalancing will overall increase the likelihood for\nsuccessful routing but it makes sense to defer the rebalancing operation to\na moment in which the liquidity is actually needed.\n\nRegarding Ariels suggestion about reusing the payment hash with JIT Routing\nI have some more thoughts:\nReusing the payment hash indeed seems like a good idea. However it produces\nsome technical issues which in my opinion can all be mitigated. it is just\na question with these challenges if it is worthwhile doing it?\n\nI have drawn several situations and tried to construct an example in which\nusing the same payment hash for the JIT-rebalancing would result in a\nsevere problem with the payment process in the sense that it would be\ncompromised or somebody could steal funds. It could however be a privacy\nissue as more nodes are being aware of the same payment (but that is also\nthe case with base-AMP)\nI was not able to construct such a situation (under the assumption that the\nrebalancing amount does not exceed the original payment amount). My feeling\n(though I have not done this yet) is that one should be able to proof that\ntaking the same payment hash would always work and in fact create a\nsituation in which at least the rebalancing only takes place if the entire\npayment was routed successfully.\n\nAssuming someone will be able to proof that using the same payment hash for\nJIT Routing is not an issue we still run into another problem (which I\nbelieve can be fixed with another MUST rule but comes with quite some\nimplementation overhead.)\n\nThe deadlock problem when doing JIT Routing with the same payment hash:\nWhen using the same payment hash there will be two htlc's (potentially of\ndifferent amounts) in opposing directions on the same channel (or in the\nlnd case maybe between separate channels between the same two peers).\nUnluckily without a novel rule this can produce a deadlock.\n\nAs an example take the situation from my initial email with an additional\nrecipient R1:\n\n  100 / 110     80 / 200      150/180\nS ----------> B --------> R ----------> R1\n              \\         /\n        80/200  \\     /  100/200\n                  \\ /\n                             T\n\nMeaning we have the following channels:\nS ---> B capacity: 110   A funds: 100  B funds:  10\nB ---> R capacity: 200   B funds:  80  R funds: 120\nB ---> T capacity: 200   B funds:  80  T funds: 120\nT ---> R capacity: 200   T funds: 100  R funds: 100\nR ---> R1 capacity: 180   R funds: 150  R1 funds: 30\n\nneglecting fees the following htlcs would be offered\n1.) S-->B amount: 90\n2.) B-->T amount:50\n3.) T-->R amount:50\n4.) R-->B amount: 50\n5.) B-->R amount: 90 (difficult to set up before 4. settles)\n6.) R-->R1 amount: 90\n\nwhile 1,5 and 6 are the original path 2,3,4 are the JIT rebalancing.\n\nWe see that in this situation using the same preimage results in a problem.\nSince the rebalancing is not settled R will not accept the 5th htlc (B--->R\namount: 90) as there is not enough liquidity on B's side producing a\ndeadlock\nHowever since the same payment hash is used it is save to combine the 4th\nand 5th htlc to have the following situation:\n\n1.) S-->B amount: 90\n2.) B-->T amount:50\n3.) T-->R amount:50\n4.) R-->B will be removed or settled or replaced by the 5th htlcs with a\ndifferent amount (90 - 50)\n5.) B-->R amount: 40\n6.) R-->R1 amount: 90\n\nNote that while theoretically it seems tempting to just have two htlc\noutputs as the second node could always claim the htlc if the first claims\ntheirs. However this will not work onchain as potentially more funds are\nspend than exist.\n\nTherefor we need a MUST-rule to fix the deadlock problem (which could\nprobably also be formulated in a symmetric way):\nIf a node N offers an htlc to a partner with an amount x from whom the node\nalready received an htlc y (where y is smaller than x) the nodes must\ncreate a new channel state discarding the old htlc but having a new offer\nfrom N with the amount x-y.\n\nThis decreases the liquidity bound in the routing process, enables for a\ncritical channel to be rebalanced several times during several JIT\noperations and keeps the onchain footprint low as there are less htlc\noutputs.\n\nAlso as mentioned above it seems crucial that the rebalancing amount must\nnot exceed the original payment amount if the payment hash is being reused.\nImagine there was no R1 and R was actually the final destination and B\ndecides to rebalance an amount larger than necessary (which could not\nhappen in our setup). R could release the preimage before setting up the\nfinal htlc from R back to B to fulfill the rebalancing request. This could\nalso happen if T was the final recipient (which R would not now!)\n\nThe only way how I see that this problem can be mitigated is by introducing\nthe following rule (morally even as a MUST rule)\nIf a node decides to engage in JIT Routing using the same payment hash as\nthe incoming htlc it SHOULD NOT rebalance an amount higher than the\nincoming HTLCs. If it rebalances with a new payment hash it MAY use an\narbitrary amount.\nRational: (as described above)\n\nAnother problem while reusing the payment hash is that in this situation\nthe node who issued the invoice could be involved in a rebalancing act and\ndecline an htlc as the amount is not sufficient for the invoice. Therefor\nwe would have to set either the base-AMP feature flag or create a new one\nfor JIT-routing which would signal that there are more htlc's coming which\nneed to be combined to forward an onion.\n\nIn order to avoid this complex aggregation of htlcs we could also see this\nprocess as a local AMP right a way saying that a node instead of forwarding\nthe onion MAY do a local base-AMP to the next recipient.\n\nSo in my opinion this suggestions to reuse the payment hash is not only\nreasonable but actually desirable in particular if we can proof that it is\nnot a problem and if we agree that we can mitigate the technical challenges\nwhich I described in this mail.\n\nBest regards Rene\n\n\nOn Thu, Mar 14, 2019 at 2:08 PM Ariel Lorenzo-Luaces <arielluaces at gmail.com>\nwrote:\n\n> Hello Rene, ZmnSCPxj, and list\n>\n>\n> I really like the proposal and I'm sure it's the correct way forward for\n> reducing payment failures and increasing privacy (through mitigating\n> probing based network analysis)\n>\n>\n> However I am concerned that this proposal could introduce a vulnerability\n> to a spoofed-payment attack.\n>\n>\n> An adversary could create a malicious payment that's guaranteed to fail,\n> for free. Any intermediary nodes on the path of the payment before it fails\n> could lose fees due to rebalancing if the rebalancing path's success is not\n> dependent on the original payment's success.\n>\n>\n> Could anyone speak to this and confirm whether it would be possible for\n> the rebalancing step to reuse the original payment hash? If this is\n> possible then it should explicitly be included in this proposal.\n>\n>\n> If reusing the payment hash is not possible on the routing path then JIT\n> routing would need some other mitigation for the spoofed-payment attack.\n>\n>\n> Cheers\n>\n>\n> Ariel Lorenzo-Luaces\n>\n>\n> On Mar 14, 2019, at 7:45 AM, ZmnSCPxj via Lightning-dev <\n> lightning-dev at lists.linuxfoundation.org> wrote:\n>>\n>> Good morning Rene and list,\n>>\n>> Let us consider then the rule *when* a rebalancing would be beneficial to the node.\n>>\n>> The node is offered a fee amount (`offered_fee_amount`) for the forwarding.\n>> It knows that, under current channel states, it will definitely have to fail and earn 0 fees.\n>>\n>> If it engages in JIT-routing, it must pay some fee (`rebalancing_fee_amount`) for the rebalancing operation.\n>> But even if it successfully forwards its hop, it is still possible that the route will fail anyway and it will earn 0 fees.\n>>\n>> So let us consider the probability of success (`success_rate`), a value between 0 to 1.0.\n>> This is the estimated probability that we will succeed the route after we forward it.\n>>\n>> We should only engage in JIT-routing if:\n>>\n>>     offered_fee_amount * success_rate - rebalancing_fee_amount > 0\n>>\n>> The LHS of the subtraction is the expected earning, while the RHS of the subtraction is the expected cost.\n>> The above is trivial accounting for determining net earnings.\n>>\n>> The fee amounts are trivially computable.\n>> Presumably the rebalancing code can compute the fee given a particular rebalance path, and thus can provide `rebalancing_fee_amount`.\n>>\n>> The `success_rate` can be computed statically from some node data.\n>> Better, is for the node to start with this precomputed static information, but augment this over time with its own experienced `success_rate` for all forwards.\n>>\n>> Regards,\n>> ZmnSCPxj\n>> ------------------------------\n>>\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n\n\n-- \nhttps://www.rene-pickhardt.de\n\nSkype: rene.pickhardt\n\nmobile: +49 (0)176 5762 3618\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190314/35731641/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-18T04:18:53",
                "message_text_only": "Good morning Rene and Ariel,\n\n\n\n> Hey everyone,\u00a0\n>\n> I am glad the suggestion is being picked up. At this time I want to respond to two of the concerns that have been thrown in. I have some other comments and ideas but would like to hold them back so that we can have more people joining the discussion without bias also this mail will already be quite long.\n>\n> ZmnSCPxj suggested to introduce a `success_rate` for JIT routing. While this success_rate can obviously only be estimated or configured I would advice against including this to the protocol. As I mentioned before I suggested to include JIT Routing as a MAY Recommendation so it is up to the node to decide if it cannot earn `offered_fee_amount` to engage in the JIT-rebalancing operation.\n\nI think it is beyond the scope of the protocol specs to specify this.\nHowever, we should remember that it is not the protocol specs that is running on the actual network, but actual implementations.\nThus the exact rule may need discussion nevertheless, as it may affect the ability to attack actual implementations on the network.\n\n> A node operator might be willing in general to to pay a fee for rebalancing even if there is not an outstanding routing event taking place. So even while `rebalancing_fee_amount` > `offered_fee_amount` the node could see the offered_fee_amount as a discount for the planned rebalancing amount. We don't know that and I honestly believe that the protocol should not make economical decisions for the node. In any case rebalancing will overall increase the likelihood for successful routing but it makes sense to defer the rebalancing operation to a moment in which the liquidity is actually needed.\u00a0\n>\n> Regarding Ariels suggestion about reusing the payment hash with JIT Routing I have some more thoughts:\n> Reusing the payment hash indeed seems like a good idea. However it produces some technical issues which in my opinion can all be mitigated. it is just a question with these challenges if it is worthwhile doing it?\n>\n> I have drawn several situations and tried to construct an example in which using the same payment hash for the JIT-rebalancing would result in a severe problem with the payment process in the sense that it would be compromised or somebody could steal funds. It could however be a privacy issue as more nodes are being aware of the same payment (but that is also the case with base-AMP)\u00a0\n\nThis would be fixable when we switch to points and scalars (from hashes and preimages) and enable route decorrelation, just as it would improve base-AMP.\n\n> I was not able to construct such a situation (under the assumption that the rebalancing amount does not exceed the original payment amount). My feeling (though I have not done this yet) is that one should be able to proof that taking the same payment hash would always work and in fact create a situation in which at least the rebalancing only takes place if the entire payment was routed successfully.\u00a0\n>\n> Assuming someone will be able to proof that using the same payment hash for JIT Routing is not an issue we still run into another problem (which I believe can be fixed with another MUST rule but comes with quite some implementation overhead.)\n>\n> The deadlock problem when doing JIT Routing with the same payment hash:\u00a0\n> When using the same payment hash there will be two htlc's (potentially of different amounts) in opposing directions on the same channel (or in the lnd case maybe between separate channels between the same two peers). Unluckily without a novel rule this can produce a deadlock.\u00a0\n>\n> As an example take the situation from my initial email with an additional recipient R1:\u00a0\n>\n> \u00a0 100 / 110\u00a0 \u00a0 \u00a080 / 200\u00a0 \u00a0 \u00a0 150/180\n> S ----------> B --------> R ----------> R1\n> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0/\n> \u00a0 \u00a0 \u00a0 \u00a0 80/200\u00a0 \\\u00a0 \u00a0 \u00a0/\u00a0 100/200\n> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \\ /\u00a0\n> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0T\n>\n> Meaning we have the following channels:\n> S ---> B capacity: 110\u00a0 \u00a0A funds: 100\u00a0 B funds:\u00a0 10\n> B ---> R capacity: 200\u00a0 \u00a0B funds:\u00a0 80\u00a0 R funds: 120\n> B ---> T capacity: 200\u00a0 \u00a0B funds:\u00a0 80\u00a0 T funds: 120\n> T ---> R capacity: 200\u00a0 \u00a0T funds: 100\u00a0 R funds: 100\u00a0\n> R ---> R1 capacity: 180\u00a0 \u00a0R funds: 150\u00a0 R1 funds: 30\u00a0\n>\n> neglecting fees the following htlcs would be offered\n> 1.) S-->B amount: 90\n> 2.) B-->T amount:50\n> 3.) T-->R amount:50\n> 4.) R-->B amount: 50\n> 5.) B-->R amount: 90 (difficult to set up before 4. settles)\n> 6.) R-->R1 amount: 90\u00a0\n>\n> while 1,5 and 6 are the original path 2,3,4 are the JIT rebalancing.\u00a0\n>\n> We see that in this situation using the same preimage results in a problem. Since the rebalancing is not settled R will not accept the 5th htlc (B--->R amount: 90) as there is not enough liquidity on B's side producing a deadlock\n> However since the same payment hash is used it is save to combine the 4th and 5th htlc to have the following situation:\u00a0\n>\n> 1.) S-->B amount: 90\n> 2.) B-->T amount:50\n> 3.) T-->R amount:50\n> 4.) R-->B will be removed or settled or replaced by the 5th htlcs with a different amount (90 - 50)\n> 5.) B-->R amount: 40\u00a0\n> 6.) R-->R1 amount: 90\u00a0\n>\n> Note that while theoretically it seems tempting to just have two htlc outputs as the second node could always claim the htlc if the first claims theirs. However this will not work onchain as potentially more funds are spend than exist.\n>\n> Therefor we need a MUST-rule to fix the deadlock problem (which could probably also be formulated in a symmetric way):\u00a0\n> If a node N offers an htlc to a partner with an amount x from whom the node already received an htlc y (where y is smaller than x) the nodes must create a new channel state discarding the old htlc but having a new offer from N with the amount x-y.\n\nOr more clearly:\n\n* Given two nodes A and B:\n  * If B has already offered an HTLC with hash `h` and value `y`, AND A offers an HTLC with hash `h` and value `x` such that `x > y`:\n    * The previous HTLC from B to A with value `y` is replaced with a new HTLC from A to B with value `x - y`.\n    * The value owned by A is deducted by `x - y` instead of `x`.\n      * Normal checks for capacity in A side should check `x - y`.\n    * The value `y` is returned to ownership of B.\n    * B performs forwarding normally with the value `x` as the amount to continue forwarding, or as payment if it is the final node.\n\nNote that the overall effect on the route would be as if there were a \"local bass amplifier\" from the node that performs the JIT-routing.\nIt also is nearer to a \"JIT routing\" than a \"JIT rebalancing\".\n\nThis also complicates the database needed to chain HTLCs together (particularly in c-lightning).\nWe would have to connect the outgoing HTLC to two incoming HTLCs.\n\nHowever this probably needs a feature bit.\nIf one side does not support this feature, it will `error` in response to an attempt to forward where the available capacity is greater than the available capacity.\nThis `error` will cause the channel to be closed unilaterally.\n\nIn a decorrelation world, this will still work, but `B` now knows that a JIT local bass amplifier was done.\n\n>\n> This decreases the liquidity bound in the routing process, enables for a critical channel to be rebalanced several times during several JIT operations and keeps the onchain footprint low as there are less htlc outputs.\u00a0\n>\n> Also as mentioned above it seems crucial that the rebalancing amount must not exceed the original payment amount if the payment hash is being reused. Imagine there was no R1 and R was actually the final destination and B decides to rebalance an amount larger than necessary (which could not happen in our setup). R could release the preimage before setting up the final htlc from R back to B to fulfill the rebalancing request. This could also happen if T was the final recipient (which R would not now!)\n\nBut what about for invoices with no particular amount?\nSince the invoice has no particular amount, the recipient will assume that any offered value is correct.\n\nSo suppose we have that `R` is the recipient.\nIn that case, the rebalancing attempt by B looks like a small offer.\nSince `R` knows the preimage, it can grab the value.\n\nNote in particular that lnd is known to have this behavior (I know the preimage, I will take the coins and ignore the onion packet).\nIn this case it would be loss of lnd to do so, since it will get the smaller rebalance value rather than the full payment to be forwarded.\nGood thing we are both c-lightning developers.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-21T06:56:14",
                "message_text_only": "Good morning all,\n\nI have been thinking further about JIT-Routing.\n\nParticularly, the extension of Rene of the idea from Ariel, to use the same payment hash (payment point in the future).\n\nI observe that this effectively creates a sort of \"local bass amplifier\" multipath payment.\n\n>From this idea, also:\n\n> > If a node N offers an htlc to a partner with an amount x from whom the node already received an htlc y (where y is smaller than x) the nodes must create a new channel state discarding the old htlc but having a new offer from N with the amount x-y.\n\nI think we should consider also the possibility of multiple HTLCs \"y\" above.\nFor instance, the node may not have enough liquidity in any single channel to fulfill the forward, or even augment its channel(s) to that node from a single other channel.\nHowever the node may have multiple channels, which in aggregate may have enough liquidity to fulfill the forward on the channel(s) to the next node in the onion hop.\n\nImplementation-wise, it means:\n\n1.  An outgoing HTLC may need to be associated with multiple incoming HTLCs.\n2.  An incoming payment may need to be associated with multiple incoming HTLCs (this is a prerequisite of all forms of multipath payment, whether bass amplifier or AMP).\n3.  An outgoing HTLC may need to be deleted, and all its associated incoming HTLCs re-associated to either a new outgoing HTLC or an incoming payment.\n3.1.  Multiple such outgoing HTLCs may be deleted in a single step, and all their incoming HTLCs will be re-assocaited.\n\nIn future, when moving to points/scalars, we need to reveal for each HTLC we want to reverse, the total decorrelation secret that makes them each claimable by knowledge of the point, of the new HTLC we want to reverse.\n\n---\n\nBut first, let us consider, is there a need for JIT-Routing?\n\nI have always held that failure of a single routing attempt is not very important, as multiple routing attempts can be performed in sequence, and as long as any *single* attempt completes, then the payment succeeds.\n\nHowever, in a world where some kind of multipart payment (whether bass amplifier or AMP) is in frequent use, this changes.\nA failure of a single routing attempt may delay the completion of a multipart payment, as it means that the source has to retry that branch of the multipart payment.\nIn short, *all* attempts must succeed for a multipart payment to succeed.\n\nIt would be nice if we can perform re-routing in order to help multipart payments succeed without so much coordination at the source.\nThis is why Rendezvous Routing is of interest to me, since (naively) it seems to me that re-routing is possible with Rendezvous.\n\nHowever, it seems that JIT-Routing, as modified by Rene based on idea of Ariel, does much of what Rendezvous Routing would do for re-routing.\n(Rendezvous Routing is still independently of value for privacy of receivers as well as moving fee payment from senders to receivers in the \"withdrawal from custodial wallet\" case.)\n\nSo I think this JIT-Routing would synergize quite well with bass amplifier and AMP.\nIt effectively allows forwarding nodes to independently split a forwarding attempt across multiple paths, without participation of source.\n\n--\n\nNow, we can also consider how to better support JIT-Routing.\n\nI observe that in C-Lightning, the high-level `pay` command provides a `maxfeepercent` argument.\nC-Lightning considers \"fee\" here as \"anything we send out beyond the face value of the invoice\".\nCurrently, in addition to capping fees, it is also used to do small overpayments at the receiver.\n\nNow of course an intermediate node will only do JIT-Routing if the cost of rebalancing is less than the fee it receives for that forward.\nSo one thing the source node can do, to help JIT-routing, is to overpay fees at each intermediate node a little.\nObviously this overpayment should be capped by the overall `maxfeepercent`.\nThis improves the probability that it is practical for an intermediate node to do JIT-routing.\n\n--\n\nI now put forward the most radical idea of all.\n\n*Multipart payment support is **not necessary** if we have widespread JIT-Routing support.*\n\nThe motivating problem for proposing AMP, and its improvement bass amplifier, is to simplify user experience by not having the user consider the balance of each channel.\nInstead, ideally the user only cares about the total spendable balance they have, without a care about how it is distributed in its channels.\nI observe that this is an extremely local condition.\n\nI also observe that a core insight in JIT-Routing is that an intermediate node knows more about its local conditions than the source node.\n\nSo from the start, the source node can start its thinking as if it is an intermediate node.\n\nThus, if the source node wants to make a payment of 1mBTC, but has 1.5mBTC scattered in various channels, it can act as if it is forwarding 1mBTC.\nThen it can perform the conditional rebalances in the modified JIT-Routing to consolidate the needed liquidity in a single channel.\nThen it can initiate the payment, using the modified JIT-Routing \"reverse the HTLC polarity\" feature.\n\nThus, this fixes the motivating problem for AMP.\nBut in addition, it provides benefits since it implies that intermediate nodes themselves can effectively split payments without coordination with either the source or destination.\nThus it provides a mechanism for \"local payment splitting\", that very well removes the need for a higher-level payment-splitting mechanism.\n\nThank you very much Rene for this idea and Ariel for pushing this idea in this direction!\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-22T11:42:56",
                "message_text_only": "Good morning list,\n\nI have been thinking of JIT-Routing in the context of unidirectional channels, as for example in Eclair Mobile.\nNow of course unidirectional-only nodes as in Eclair Mobile cannot forward and cannot be intermediate nodes.\nHowever, as I pointed out in previous email, the same JIT-Routing can be used also when the node is the ultimate source of the payment.\n\nThe original formulation, which requires a separate, completed rebalance, before performing a payment, cannot be used in unidirectional mode.\nIt requires that the channel to be boosted by the rebalance, must first receive the value, which is disallowed in unidirectional mode.\n\nHowever, the Luaces-Pickhardt JIT-Routing, which has a conditional rebalance, does not require that the channel receive.\nSo it seems to me, that the Luaces-Pickhardt JIT-Routing can work with Eclair.\n\nLet us consider the following history:\n\n1.  An Eclair Mobile client creates a 1mBTC channel.\n2.  The client successfully pays an unrelated payment of 0.5 mBTC.\n3.  The client has to make another payment of 0.6 mBTC, to be passed by this channel.\n    The client has another channel which can pay out the needed 0.15mBTC (additional 0.05mBTC needed for the channel reserve).\n4.  The second payment passes.\n\nIn the below sequence of states, A is the Eclair Mobile client node, while B is the counterparty.\n\n1.  A = 1.0, B = 0.0 ; starting state.\n2.  A = 0.5, B = 0.0, A->HTLC->B = 0.5 ; client offers payment in #2 above.\n3.  A = 0.5, B = 0.5 ; payee accepts payment.\n4.  A = 0.5, B = 0.35, B->HTLC->A = 0.15 ; the rebalance from another channel of A, initiated by #3 above.\n5.  A = 0.05, B = 0.5, A->HTLC->B = 0.45 ; HTLC polarity reversed by A offering an HTLC of 0.6 BTC (the new mechanism proposed by Rene).\n6.  A = 0.05, B = 0.95 ; payee accepts payment.\n\nAs can be seen from above, A will never have an increase in its money.\n\nThus, the new Luaces-Pickhardt formulation of JIT-Routing, which requires the new \"reverse HTLC polarity\" mechanism to reuse the same hash as the actual payment, should be safe for unidirectional Eclair Mobile nodes.\n\nLet us consider the following sequence of events:\n\n1.  An Eclair Mobile client creates a 1mBTC channel.\n2.  The client successfully pays an unrelated payment of 0.5 mBTC.\n3.  The client has to make another payment of 0.6 mBTC, to be passed by this channel.\n    The client has another channel which can pay out the needed 0.15mBTC (additional 0.05mBTC needed for the channel reserve).\n4.  The second payment fails.\n\nThen the sequence of states is:\n\n1.  A = 1.0, B = 0.0 ; starting state.\n2.  A = 0.5, B = 0.0, A->HTLC->B = 0.5 ; client offers payment in #2 above.\n3.  A = 0.5, B = 0.5 ; payee accepts payment.\n4.  A = 0.5, B = 0.35, B->HTLC->A = 0.15 ; the rebalance from another channel of A, initiated by #3 above.\n5.  A = 0.05, B = 0.5, A->HTLC->B = 0.45 ; HTLC polarity reversed by A offering an HTLC of 0.6 BTC (the new mechanism proposed by Rene).\n6.  A = 0.5, B = 0.5 ; payment fails.\n\nNow in the above, the only state that has A own less money than in a later state is state 5.\nHowever, even if we are at state 6, and B replays state 5, B cannot claim the A->HTLC->B (if it had the hash, it would have claimed the HTLC instead of failing it), so it will revert back to A when it times out.\nThis is the same as existing cases of payment failure in Eclair Mobile, so presumably if it has a problem here, it would have a problem in existing Eclair Mobile unidirectional channels.\n\nThus, it should be safe to use the Luaces-Pickhardt JIT-Routing in unidirectional-only nodes, even if the original Pickhardt JIT-Routing is unsafe for unidirectional-only nodes.\n\nThus this is a plausible replacement for all forms of multipart payments.\nIn effect, instead of a multipart payment being decided by the source to the destination, we have each hop, including the source, deciding to split or not split the payment according to how much fee it has to devote to rebalance attempts.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Ariel Lorenzo-Luaces",
                "date": "2019-03-25T11:52:25",
                "message_text_only": "Good morning list\n\nI have been thinking about how JIT-Routing can allow the network to be more private and scalable than it currently is today. Rene has mentioned that JIT-Routing allows channel balance information to affect pathing decisions without the source node being aware. I would take this further and suggest that JIT-Routing can allow routing over sub-paths that are only visible to neighbour nodes and are entirely hidden from the source node or plublic view.\n\nAn intermediate route node could decide for any reason to re-route a payment through any subset of nodes to arrive at the next hop. This is similar to Rene's local AMP idea where friend-of-a-friend nodes are used. But instead this system could allow arbitraryly long paths to the next hop by finding a new sub-route and re-layering the onion packet with the new sub-route prepended.\n\nThe same pre-image would be used and this process would be completely invisible to the next hop (original next hop, not the new next hop in the sub-route, I would instead call those the sub-hops).\n\nIt's unfortunate that the intermediate nodes along the sub-route would be aware that a sub-route is being attempted because they could observe extra hop packets prepended to the minimum twenty and I don't see of a way to fix this. But maybe it doesn't need fixing since the original twenty encryption layers are arguably private enough.\n\nThe sub-route could also employ base AMP since the same pre-image is used. The next hop node would still never even know that a subroute was attempted if no \"wait for more payments\" flag is added to the per_hop field and we implement the \"wait for timeout if HTLC is less than amt_to_forward\" rule.\n\nPublic nodes could advertise channels which don't actually exist directly but are instead hidden paths that the source node doesn't need to know or care about. The fees advertised for these aggregate-channels would be the aggregate fees expected from the sub-route.\n\nI think the biggest gain from this system is that the network can be more abstract. This abstraction allows all possible subsets of public nodes to be a clique since all subsets of nodes can be maximally connected with aggregate-channels as long as the entire network is well connected.\n\nThis new property of the network could allow a source node to select a random privacy-clique and rely on payments to be routed along aggregate-channels without the source node needing to compute or even know the exact sub-routes. Futhermore, the source node could exclusively download and listen to the privacy-clique and ignore the rest of the network structure thus reducing the burden of keeping up to date network information.\n\nCheers\nAriel Lorenzo-Luaces\n\n\nOn Mar 22, 2019, 4:44 AM, at 4:44 AM, ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n>Good morning list,\n>\n>I have been thinking of JIT-Routing in the context of unidirectional\n>channels, as for example in Eclair Mobile.\n>Now of course unidirectional-only nodes as in Eclair Mobile cannot\n>forward and cannot be intermediate nodes.\n>However, as I pointed out in previous email, the same JIT-Routing can\n>be used also when the node is the ultimate source of the payment.\n>\n>The original formulation, which requires a separate, completed\n>rebalance, before performing a payment, cannot be used in\n>unidirectional mode.\n>It requires that the channel to be boosted by the rebalance, must first\n>receive the value, which is disallowed in unidirectional mode.\n>\n>However, the Luaces-Pickhardt JIT-Routing, which has a conditional\n>rebalance, does not require that the channel receive.\n>So it seems to me, that the Luaces-Pickhardt JIT-Routing can work with\n>Eclair.\n>\n>Let us consider the following history:\n>\n>1.  An Eclair Mobile client creates a 1mBTC channel.\n>2.  The client successfully pays an unrelated payment of 0.5 mBTC.\n>3.  The client has to make another payment of 0.6 mBTC, to be passed by\n>this channel.\n>The client has another channel which can pay out the needed 0.15mBTC\n>(additional 0.05mBTC needed for the channel reserve).\n>4.  The second payment passes.\n>\n>In the below sequence of states, A is the Eclair Mobile client node,\n>while B is the counterparty.\n>\n>1.  A = 1.0, B = 0.0 ; starting state.\n>2.  A = 0.5, B = 0.0, A->HTLC->B = 0.5 ; client offers payment in #2\n>above.\n>3.  A = 0.5, B = 0.5 ; payee accepts payment.\n>4.  A = 0.5, B = 0.35, B->HTLC->A = 0.15 ; the rebalance from another\n>channel of A, initiated by #3 above.\n>5.  A = 0.05, B = 0.5, A->HTLC->B = 0.45 ; HTLC polarity reversed by A\n>offering an HTLC of 0.6 BTC (the new mechanism proposed by Rene).\n>6.  A = 0.05, B = 0.95 ; payee accepts payment.\n>\n>As can be seen from above, A will never have an increase in its money.\n>\n>Thus, the new Luaces-Pickhardt formulation of JIT-Routing, which\n>requires the new \"reverse HTLC polarity\" mechanism to reuse the same\n>hash as the actual payment, should be safe for unidirectional Eclair\n>Mobile nodes.\n>\n>Let us consider the following sequence of events:\n>\n>1.  An Eclair Mobile client creates a 1mBTC channel.\n>2.  The client successfully pays an unrelated payment of 0.5 mBTC.\n>3.  The client has to make another payment of 0.6 mBTC, to be passed by\n>this channel.\n>The client has another channel which can pay out the needed 0.15mBTC\n>(additional 0.05mBTC needed for the channel reserve).\n>4.  The second payment fails.\n>\n>Then the sequence of states is:\n>\n>1.  A = 1.0, B = 0.0 ; starting state.\n>2.  A = 0.5, B = 0.0, A->HTLC->B = 0.5 ; client offers payment in #2\n>above.\n>3.  A = 0.5, B = 0.5 ; payee accepts payment.\n>4.  A = 0.5, B = 0.35, B->HTLC->A = 0.15 ; the rebalance from another\n>channel of A, initiated by #3 above.\n>5.  A = 0.05, B = 0.5, A->HTLC->B = 0.45 ; HTLC polarity reversed by A\n>offering an HTLC of 0.6 BTC (the new mechanism proposed by Rene).\n>6.  A = 0.5, B = 0.5 ; payment fails.\n>\n>Now in the above, the only state that has A own less money than in a\n>later state is state 5.\n>However, even if we are at state 6, and B replays state 5, B cannot\n>claim the A->HTLC->B (if it had the hash, it would have claimed the\n>HTLC instead of failing it), so it will revert back to A when it times\n>out.\n>This is the same as existing cases of payment failure in Eclair Mobile,\n>so presumably if it has a problem here, it would have a problem in\n>existing Eclair Mobile unidirectional channels.\n>\n>Thus, it should be safe to use the Luaces-Pickhardt JIT-Routing in\n>unidirectional-only nodes, even if the original Pickhardt JIT-Routing\n>is unsafe for unidirectional-only nodes.\n>\n>Thus this is a plausible replacement for all forms of multipart\n>payments.\n>In effect, instead of a multipart payment being decided by the source\n>to the destination, we have each hop, including the source, deciding to\n>split or not split the payment according to how much fee it has to\n>devote to rebalance attempts.\n>\n>Regards,\n>ZmnSCPxj\n>_______________________________________________\n>Lightning-dev mailing list\n>Lightning-dev at lists.linuxfoundation.org\n>https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190325/51dca3aa/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-26T03:26:27",
                "message_text_only": "Good morning Ariel and Rene and list,\n\nI have started to consider how best to attack the modified Luaces-Pickhardt JIT-Routing, which reuses the same payment hash as the message to forward.\n(In the case where JIT-Routing is used by the ultimate source of a payment, the payment hash of the invoice being paid.)\n\nAnd it seems that, unless hop routes are given more time than their reported `cltv_delta`, then either:\n\n1.  JIT-Routing cannot be done since the rebalancing requires more blocks than is allocated to the hop,\n2.  OR, JIT-Routing is done despite the lack of blocks, at the major risk of possibly getting attacked by fooling around with lock times.\n\nDecorrelation could remove the risk in #2.\n\n--\n\nSo let us consider the below simple network graph:\n\n\n    A ----- B ----- D ----- E\n            |       |\n            |       |\n            +-- C --+\n\nLet us pretend that C-Lightning has taken over the world and that everyone uses a sensible 14-block `cltv_delta`.\n\nThe node B receives an onion from A, with the specs:\n\n1.  A offers an HTLC to B with value 1001 msat, and timelocked in 70 blocks from now.\n2.  B should offer an HTLC to D with value 1000 msat, and timelocked in 56 blocks from now.\n\nAs it happens, B has not enough money in channel B-D, but can augment it with money from B-C by rebalancing.\n\nIf it's the original Pickhardt JIT-Routing, then B takes on the risk that a later hop in the onion will fail, however it can complete the rebalancing without caring about the timelocks of the \"actual\" route.\n\nHowever, if we reuse the payment preimage, and use the \"reverse the polarity\" operation proposed by Pickhardt in response to Luaces, then we need to respect the timelocks.\nIn particular, even the rebalance nodes C and D will impose `cltv_delta`.\nNote that C and D have 14 blocks each, but what is allocated to B is only 14 blocks for itself.\n\nSuppose we consider --- since the \"reverse the polarity\" operation means there are HTLCs from B->D and B->C->D, then it should be safe to have the B->C->D->B path have a longer timelock on the first HTLC; the B->D direct HTLC would still allow B to claim the money from A.\nSo B would do:\n\n1.  It receives the onion from A and finds it has insufficient capacity on B-D channel.\n2.  It creates a new onion B->C->D->B, with timelocks:\n    a. D->B now+56 (this will be reversed into a B->D HTLC with timelock now+56)\n    b. C->D now+70\n    c. B->C now+84\n3.  B sends the above onion, using the same payment hash as the original onion.\n\nNow suppose A, D, and C are actually controlled by an evil person Eve.\nEve knows the original onion and in particular knows the original payment hash and preimage.\nIn addition, it knows the condition of channels B-C and B-D.\n\nSo Eve attacks as below:\n\n1.  C stalls until now+71.\n    a.  The original A->N HTLC (with timeout now+70) is invalidated.\n    b.  The B->C HTLC (with timeout now+84) is still valid.\n2.  C claims the amount in the B->C HTLC.\n    Even if B refuses, C can always settle it onchain.\n\nNow of course B might not choose the specific C controlled by Eve in the rebalance.\nBut note that D can keep failing incoming HTLCs from all nodes until either B selects the C that Eve controls, or B gives up (in which case Eve loses nothing anyway).\n\nSo B cannot safely use the \"reverse the polarity\" operation, unless the onion gives it much more time than its `cltv_delta` declares.\nBut if nodes boost their `cltv_delta`s, then it also becomes impossible to JIT-route.\nAnd if we give each hop node more than their declared `cltv_delta`, then that increases the risk on the source node (since the total time it gives to all hop nodes is the maximum amount of time that its money could be locked in the worst case).\n\nA similar attack on D can be mounted (by B, C, and E) if we adjust the timelocks in the opposite direction.\n\nIn conclusion, the \"reverse the polarity\" operation is not feasible for JIT-Routing.\nInstead, the hop node B needs to incur the entire risk in rebalancing.\nIt also means that the JIT-Routing technique cannot be used by unidirectional-only implementations like Eclair Mobile.\n\n--\n\n> An intermediate route node could decide for any reason to re-route a payment through any subset of nodes to arrive at the next hop. This is similar to Rene's local AMP idea where friend-of-a-friend nodes are used. But instead this system could allow arbitraryly long paths to the next hop by finding a new sub-route and re-layering the onion packet with the new sub-route prepended.\n\nThis requires \"Rendezvous Routing\", which cdecker and cjp are working on; there is something something math involved.\nIn particular it requires switching to some other point in the onion encryption; sorry, I am not enough of a mathist to tell you what that means.\n\nThe problem with this is again that timelocks need to be respected.\nIf a hop node cannot find a route that fits its own time risk and the time risk allocated to it by the source payer.\n\nRegards,\nZmnSCPxj\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Just in Time Routing (JIT-Routing) and a channel rebalancing heuristic as an add on for improved routing success in BOLT 1.0",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Ren\u00e9 Pickhardt",
                "Ariel Lorenzo-Luaces",
                "ZmnSCPxj"
            ],
            "messages_count": 10,
            "total_messages_chars_count": 64426
        }
    },
    {
        "title": "[Lightning-dev] More thoughts on NOINPUT safety",
        "thread_messages": [
            {
                "author": "Anthony Towns",
                "date": "2019-03-13T01:41:43",
                "message_text_only": "Hi all,\n\nThe following has some more thoughts on trying to make a NOINPUT\nimplementation as safe as possible for the Bitcoin ecosystem.\n\nOne interesting property of NOINPUT usage like in eltoo is that it\nactually reintroduces the possibility of third-party malleability to\ntransactions -- ie, you publish transactions to the blockchain (tx A,\nwhich is spent by tx B, which is spent by tx C), and someone can come\nalong and change A or B so that C is no longer valid). The way this works\nis due to eltoo's use of NOINPUT to \"skip intermediate states\". If you\npublish to the blockchain:\n\n      funding tx -> state 3 -> state 4[NOINPUT] -> state 5[NOINPUT] -> finish\n\nthen in the event of a reorg, state 4 could be dropped, state 5's\ninputs adjusted to refer to state 3 instead (the sig remains valid\ndue to NOINPUT, so this can be done by anyone not just holders of some\nprivate key), and finish would no longer be a valid tx (because the new\n\"state 5\" tx has different inputs so a different txid, and finish uses\nSIGHASH_ALL for the signature so committed to state 5's original txid).\n\nThere is a safety measure here though: if the \"finish\" transaction is\nitself a NOINPUT tx, and has a a CSV delay (this is the case in eltoo;\nthe CSV delay is there to give time for a hypothetical state 6 to be\npublished), then the only way to have a problem is for some SIGHASH_ALL tx\nthat spends finish, and a reorg deeper than the CSV delay (so that state\n4 can be dropped, state 5 and finish can be altered). Since the CSV delay\nis chosen by the participants, the above is still a possible scenario\nin eltoo, though, and it means there's some risk for someone accepting\nbitcoins that result from a non-cooperative close of an eltoo channel.\n\n\nBeyond that, I think NOINPUT has two fundamental ways to cause problems\nfor the people doing NOINPUT sigs:\n\n 1) your signature gets applied to a unexpectedly different\n    script, perhaps making it look like you've being dealing\n    with some blacklisted entity. OP_MASK and similar solves\n    this.\n\n 2) your signature is applied to some transaction and works\n    perfectly; but then someone else sends money to the same address\n    and reuses your prior signature to forward it on to the same\n    destination, without your consent\n\nI still like OP_MASK as a solution to (1), but I can't convince myself that\nthe problem it solves is particularly realistic; it doesn't apply to\naddress blacklists, because for OP_MASK to make the signature invalid\nthe address has to be different, and you could just short circuit the\nwhole thing by sending money from a blacklisted address to the target's\npersonal address directly. Further, if the sig's been seen on chain\nbefore, that's probably good evidence that someone's messing with you;\nand if it hasn't been seen on chain before, how is anyone going to tell\nit's your sig to blame you for it?\n\nI still wonder if there isn't a real problem hiding somewhere here,\nbut if so, I'm not seeing it.\n\nFor the second case, that seems a little more concerning. The nightmare\nscenario is maybe something like:\n\n * naive users do silly things with NOINPUT signatures, and end up\n   losing funds due to replays like the above\n\n * initial source of funds was some major exchange, who decide it's\n   cheaper to refund the lost funds than deal with the customer complaints\n\n * the lost funds end up costing enough that major exchanges just outright\n   ban sending funds to any address capable of NOINPUT, which also bans\n   all taproot/schnorr addresses\n\nThat's not super likely to happen by chance: NOINPUT sigs will commit\nto the value being spent, so to lose money, you (Alice) have to have\ndone a NOINPUT sig spending a coin sent to your address X, to someone\n(Bob) and then have to have a coin with the exact same value sent from\nsomeone else again (Carol) to your address X (or if you did a script\npath NOINPUT spend, to some related address Y with a script that uses the same\nkey). But because it involves losing money to others, bad actors might\ntrick people into having it happen more often than chance (or well\nwritten software) would normally allow.\n\nThat \"nightmare\" could be stopped at either the first step or the\nlast step:\n\n * if we \"tag\" addresses that can be spent via NOINPUT then having an\n   exchange ban those addresses doesn't also impact regular\n   taproot/schnorr addresses, though it does mean you can tell when\n   someone is using a protocol like eltoo that might need to make use\n   of NOINPUT signatures.  This way exchanges and wallets could simply\n   not provide NOINPUT capable addresses in the first place normally,\n   and issue very large warnings when asked to send money to one. That's\n   not a problem for eltoo, because all the NOINPUT-capable address eltoo\n   needs are internal parts of the protocol, and are spent automatically.\n\n * or we could make it so NOINPUT signatures aren't replayable on\n   different transactions, at least by third parties. one way of doing\n   this might be to require NOINPUT signatures always be accompanied by a\n   non-NOINPUT signature (presumably for a different public key, or there\n   would be no point). This would prevent NOINPUT key-path spends, you'd\n   always have to use the taproot script-path for a NOINPUT signature so\n   that you could specify both public keys, and would also increase the\n   witness size due to needing two signatures and specifying an additional\n   public key -- this would increase the cost in fees by about 25% compared\n   to a plain key-path spend.\n\nConversely, this \"nightmare\" scenario *can't* be stopped if we allow\nkey-path spending of (untagged) taproot addresses with NOINPUT signatures:\nexchanges could not distinguish such addresses from regular addresses, and\nthe only way to prevent the signature from applying to two tx's with the\nsame value and address would be for the sig to commit to info from the tx.\n\nIt seems like there's one big choice then:\n\n - just ignore this concern\n\n - drop NOINPUT from normal taproot key path spending\n\nIf we drop NOINPUT from taproot key path spending, then we can do NOINPUT\nas a logically separate upgrade to taproot, rather than it needing to\nbe done at the same time.  There's two ways we could do proceed:\n\n - introduce a new NOINPUT-capable scriptPubKey format (ie, \"tag\"\n   NOINPUT spendable addresses); either a different length segwit v1\n   output, or a different segwit version entirely. Using version \"16\" in\n   this scenario might be appealing: we could reserve all v16 addresses\n   for \"not intended to be used by humans directly\" and update BIP 173\n   to say these aren't even something you should use bech32 to represent.\n\n - alternatively, we could require every script to have a valid signature\n   that commits to the input. In that case, you could do eltoo with a\n   script like either:\n\n        <A> CHECKSIGVERIFY <B> CHECKSIG\n     or <P> CHECKSIGVERIFY <Q> CHECKSIG\n\n   where A is Alice's key and B is Bob's key, P is muSig(A,B) and Q is\n   a key they both know the private key for. In the first case, Alice\n   would give Bob a NOINPUT sig for the tx, and when Bob wanted to publish\n   Bob would just do a SIGHASH_ALL sig with his own key. In the second,\n   Alice and Bob would share partial NOINPUT sigs of the tx with P, and\n   finish that when they wanted to publish.\n\n   This is a bit more costly than a key path spend: you have to reveal\n   the taproot point to do a script (+33B) and you have two signatures\n   instead of one (+65B) and you have to reveal two keys as well\n   (+66B), plus some script overhead. If we did the <P,Q> variant,\n   we could provide a \"PUSH_TAPROOT_KEY\" opcode that would just push\n   the taproot key to stack, saving 33B from pushing P as a literal,\n   but you can't do much better than that. All in all, it'd be about 25%\n   overhead in order to prevent cheating. [0]\n\nI think that output tagging doesn't provide a workable defense against the\nthird party malleability via a deeper-than-the-CSV-delay reorg mentioned\nearlier; but requiring a non-NOINPUT sig does: you'd have to replace\nthe non-NOINPUT sig to make state 5 spend state 3 instead of state 4,\nand only the holders of the appropriate private key can do that.\n\n\nIn any event, if we get some experience with NOINPUT in practice, we can\nreconsider whether NOINPUT key path spends are a good idea when we do\nthe next segwit version -- both cross-input signature aggregation and\ngraftroot will need an upgrade anyway.\n\n(Also, note that, at least for eltoo, all of the above only applies to\nnon-cooperative closes: the funding tx's txid is known from the start,\nso you can always arrange to spend it via SIGHASH_ALL, so it doesn't\nneed to be tagged, and a cooperative/mutual close of the channel will\nstill just be a simple key path spend)\n\n\nAnyway, presented for your consideration.\n\n\nFWIW, I don't have a strong opinion here yet, but:\n\n - I'm still inclined to err on the side of putting more safety\n   measures in for NOINPUT, rather than fewer\n\n - the \"must have a sig that commits to the input tx\" seems like it\n   should be pretty safe, not too expensive, and keeps taproot's privacy\n   benefits in the cases where you end up needing to use NOINPUT\n\nCheers,\naj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-13T06:41:47",
                "message_text_only": "Good morning aj,\n\nFirst off, I have little to no idea of the issues at the lower-level Bitcoin.\n\nIn any case ---\n\n> -   alternatively, we could require every script to have a valid signature\n>     that commits to the input. In that case, you could do eltoo with a\n>     script like either:\n>\n>     <A> CHECKSIGVERIFY <B> CHECKSIG\n>     or <P> CHECKSIGVERIFY <Q> CHECKSIG\n>\n>\n> where A is Alice's key and B is Bob's key, P is muSig(A,B) and Q is\n> a key they both know the private key for. In the first case, Alice\n> would give Bob a NOINPUT sig for the tx, and when Bob wanted to publish\n> Bob would just do a SIGHASH_ALL sig with his own key. In the second,\n> Alice and Bob would share partial NOINPUT sigs of the tx with P, and\n> finish that when they wanted to publish.\n>\n> This is a bit more costly than a key path spend: you have to reveal\n> the taproot point to do a script (+33B) and you have two signatures\n> instead of one (+65B) and you have to reveal two keys as well\n> (+66B), plus some script overhead. If we did the <P,Q> variant,\n> we could provide a \"PUSH_TAPROOT_KEY\" opcode that would just push\n> the taproot key to stack, saving 33B from pushing P as a literal,\n> but you can't do much better than that. All in all, it'd be about 25%\n> overhead in order to prevent cheating. [0]\n>\n> I think that output tagging doesn't provide a workable defense against the\n> third party malleability via a deeper-than-the-CSV-delay reorg mentioned\n> earlier; but requiring a non-NOINPUT sig does: you'd have to replace\n> the non-NOINPUT sig to make state 5 spend state 3 instead of state 4,\n> and only the holders of the appropriate private key can do that.\n\nAt my point of view, if a NONINPUT sig is restricted and cannot be used to spend an \"ordinary\" 2-of-2, this is output tagging regardless of exact mechanism.\nSo the restriction to add a non-NOINPUT sig in addition to a NOINPUT sig is still output tagging, as a cooperative close would still reveal that the output is not a 2-of-2.\n\nIdeally, historical data of whether onchain coin was used in Lightning or not should be revealed as little as possible.\nSo in a cooperative close (which we hope, to be a common case), ideally the spend should look no different from an ordinary 2-of-2 spend.\nOf course if the channel is published on Lightning, those who participated in Lightning at the time will learn of it, but at least the effort to remember this information is on those who want to remember this fact.\n\nNow, this can be worked around by adding a \"kickoff\" transaction that spends the eltoo setup transaction.\nThe eltoo setup transaction outputs to an ordinary 2-of-2.\nThe kickoff outputs to an output that allows NOINPUT.\nThen the rest of the protocol anchors on top of the kickoff.\n\nThe kickoff is kept offchain, until a non-cooperative close is needed.\nOf course, as it is not a NOINPUT itself, it must need onchain fees attached to it.\nThis of course complicates fees, as we know.\nAlternately maybe the kickoff can be signed with `SIGHASH_SINGLE | SIGHASH_ANYONECANPAY` so that it is possible to add a fee-paying UTXO to it.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Anthony Towns",
                "date": "2019-03-13T11:10:50",
                "message_text_only": "On Wed, Mar 13, 2019 at 06:41:47AM +0000, ZmnSCPxj via Lightning-dev wrote:\n> > -   alternatively, we could require every script to have a valid signature\n> >     that commits to the input. In that case, you could do eltoo with a\n> >     script like either:\n> >     <A> CHECKSIGVERIFY <B> CHECKSIG\n> >     or <P> CHECKSIGVERIFY <Q> CHECKSIG\n> > where A is Alice's key and B is Bob's key, P is muSig(A,B) and Q is\n> > a key they both know the private key for. In the first case, Alice\n> > would give Bob a NOINPUT sig for the tx, and when Bob wanted to publish\n> > Bob would just do a SIGHASH_ALL sig with his own key. In the second,\n> > Alice and Bob would share partial NOINPUT sigs of the tx with P, and\n> > finish that when they wanted to publish.\n> At my point of view, if a NONINPUT sig is restricted and cannot be\n> used to spend an \"ordinary\" 2-of-2, this is output tagging regardless\n> of exact mechanism.\n\nWith taproot, you could always do the 2-of-2 spend without revealing a\nscript at all, let alone that it was meant to be NOINPUT capable. The\nsetup I'm thinking of in this scenario is something like:\n\n  0) my key is A, your key is B, we want to setup an eltoo channel\n\n  1) post a funding tx to the blockchain, spending money to an address\n     P = muSig(A,B)\n\n  2) we cycle through a bunch of states from 0..N, with \"0\" being the\n     refund state we establish before publishing the funding tx to\n     the blockchain. each state essentially has two corresponding tx's,\n     and update tx and a settlement tx.\n\n  3) the update tx for state k spends to an output Qk which is a\n     taproot address Qk = P + H(P,Sk)*G where Sk is the eltoo ratchet\n     condition:\n        Sk = (5e8+k+1) CLTV A CHECKDLS_NOINPUT B CHECKDLS_NOINPUT_VERIFY\n\n     we establish two partial signatures for update state k, one which\n     is a partial signature spending the funding tx with key P and\n     SIGHASH_ALL, the other is a NOINPUT signature via A (for you) and\n     via B (for me) with locktime set to (k+5e8), so that we can spend\n     any earlier state's update tx's, but not itself or any later\n     state's update tx's.\n\n  4) for each state we have also have a settlement transaction,\n     Sk, which spends update tx k, to outputs corresponding to the state\n     of the channel, after a relative timelock delay.\n\n     we have two partial signatures for this transaction too, one with\n     SIGHASH_ALL assuming that we directly spent the funding tx with\n     update state k (so the input txid is known), via the key path with\n     key Qk; the other SIGHASH_NOINPUT via the Sk path. both partially\n     signed tx's have nSequence set to the required relative timelock\n     delay.\n\n  5) if you're using scriptless scripts to do HTLCs, you'll need to\n     allow for NOINPUT sigs when claiming funds as well (and update\n     the partial signatures for the non-NOINPUT cases if you want to\n     maximise privacy), which is a bit fiddly\n\n  6) when closing the channel the process is then:\n\n       - if you're in contact with the other party, negotiate a new\n         key path spend of the funding tx, publish it, and you're done.\n\n       - otherwise, if the funding tx hasn't been spent, post the latest\n         update tx you know about, using the \"spend the funding tx via\n\t key path\" partial signature\n\n       - otherwise, trace the children of the funding tx, so you can see\n         the most recent published state:\n\t   - if that's newer than the latest state you know about, your\n\t     info is out of date (restored from an old backup?), and you\n\t     have to wait for your counterparty to post the settlement tx\n\t   - if it's equal to the latest state you know about, wait\n\t   - if it's older than the latest state, post the latest update\n\t     tx (via the NOINPUT script path sig), and wait\n\n       - once the CSV delay for the latest update tx has expired, post\n\t the corresponding settlement tx (key path if the update tx\n\t spent the funding tx, NOINPUT if the update tx spent an earlier\n\t update tx)\n\n       - once the settlement tx is posted, claim your funds\n\nSo the cases look like:\n\n   mutual close:\n     funding tx -> claimed funds\n\n     -- only see one key via muSig, single signature, SIGHASH_ALL\n     -- if there are active HTLCs when closing the channel, and they\n        timeout, then the claiming tx will likely be one-in, one-out,\n\tSIGHASH_ALL, with a locktime, which may be unusual enough to\n\tindicate a lightning channel.\n\n   unilateral close, no cheating: \n     funding tx -> update N -> settlement N -> claimed funds\n\n     -- update N is probably SINGLE|ANYONECANPAY, so chain analysis\n        of accompanying inputs might reveal who closed the channel\n     -- settlement N has relative timelock\n     -- claimed funds may have timelocks if they claim active HTLCs via\n        the refund path\n     -- no NOINPUT signatures needed, and all signatures use the key path\n        so don't reveal any scripts\n\n   unilateral close, attempted cheating:\n     funding tx -> update K -> update N -> settlement N -> claimed funds\n\n     -- update K, update N are probably SINGLE|ANYONECANPAY, so chain\n        analysis might reveal the identity of both sides of the channel \n     -- update N and settlement N both use NOINPUT signatures and\n        reveal CLTV script that looks like eltoo\n     -- update N has timelock set\n     -- settlement N has a relative timelock\n     -- claimed funds may have timelocks if they claim active HTLCs via\n        the refund path\n\n     Notes:\n      * cheating isn't 100% accurate: could be due to someone having to\n        restore from an old backup\n\n      * you could end up with:\n\n          funding tx -> update K -> update W -> update N\n\t             -> settlement N -> claimed funds\n\n\tif someone restored from an old backup and posted K, a watchtower\n\thad a newer but not current state W, and finally you posted\n\tstate N directly. with multiple watchtowers you might have more\n\tintermediate states' update tx's posted. afaics it has similar\n\tprivacy results to the 2-update-tx case.\n\n> So the restriction to add a non-NOINPUT sig in addition to a NOINPUT sig is still output tagging, as a cooperative close would still reveal that the output is not a 2-of-2.\n\nWith the above setup, you don't discover that NOINPUT was possible unless it\nis actually needed because someone cheated.\n\nAs long as you're using muSig key path spending for a cooperative close,\nyou're not even revealing the output is 2-of-2, let alone a weird\n2-of-2 variant.\n\n> Ideally, historical data of whether onchain coin was used in Lightning or not should be revealed as little as possible.\n> So in a cooperative close (which we hope, to be a common case), ideally the spend should look no different from an ordinary 2-of-2 spend.\n\nWith taproot, the goal is it shouldn't look different from an ordinary\n\"pay to public key\" spend, and I think that's pretty achievable.\n\n> Of course if the channel is published on Lightning, those who participated in Lightning at the time will learn of it, but at least the effort to remember this information is on those who want to remember this fact.\n\nWell, presumaby lightning will continue to support private channels that\ndon't get published, and the concern's definitely valid for them!\n\n> Now, this can be worked around by adding a \"kickoff\" transaction that spends the eltoo setup transaction.\n> The eltoo setup transaction outputs to an ordinary 2-of-2.\n> The kickoff outputs to an output that allows NOINPUT.\n> Then the rest of the protocol anchors on top of the kickoff.\n> [...]\n\nI think this is possible too, but I think the scheme I describe above\nis superior: iit means calculating a few more signatures each update,\nbut keeps more information off chain, which is better for privacy, and\nprobably cheaper (unless you have very high-frequency channel updates?).\n\nCheers,\naj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-14T05:22:59",
                "message_text_only": "Good morning aj,\n\nWhen reading through your original post I saw you mentioned something about output tagging somehow conflicting with Taproot, so I assumed Taproot is not useable in this case.\nHowever, it is probably more likely that I simply misunderstood what you said, so if you can definitively say that it would be possible to hide the clause \"or a NOINPUT sig from A with a non-NOINPUT sig from B\" behind a Taproot then I am fine.\n\nMinor pointless reactions:\n\n> 5.  if you're using scriptless scripts to do HTLCs, you'll need to\n>     allow for NOINPUT sigs when claiming funds as well (and update\n>     the partial signatures for the non-NOINPUT cases if you want to\n>     maximise privacy), which is a bit fiddly\n\nIf I remember accurately, we do not allow bilateral/cooperative close when HTLC is in-flight.\nHowever, I notice that later you point out that a non-cheating unilateral close does not need NOINPUT, so I suppose. the above thought applies to that case.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Anthony Towns",
                "date": "2019-03-14T07:24:56",
                "message_text_only": "On Thu, Mar 14, 2019 at 05:22:59AM +0000, ZmnSCPxj via Lightning-dev wrote:\n> When reading through your original post I saw you mentioned something about output tagging somehow conflicting with Taproot, so I assumed Taproot is not useable in this case.\n\nI'm thinking of tagged outputs as \"taproot plus\" (ie, plus noinput),\nso if you used a tagged output, you could do everything normal taproot\naddress could, but also do noinput sigs for them.\n\nSo you might have:\n\n   funding tx -> cooperative claim\n\n   funding tx -> update 3 [TAGGED] -> settlement 3 -> claim\n\n   funding tx -> update 3 [TAGGED] -> \n                 update 4 [TAGGED,NOINPUT] -> \n\t\t settlement 4 [TAGGED,NOINPUT] -> \n\t\t claim [NOINPUT]\n\nIn the cooperative case, no output tagging needed.\n\nFor the unilateral case, you need to tag all the update tx's, because\nthey *could* be spend by a later update with a NOINPUT sig, and if\nthat actually happens, then the settlement tx also needs to use a\nNOINPUT sig, and if you're using scriptless scripts to resolve HTLCs,\nclaiming/refunding the HTLCs needs a partially-pre-signed tx which also\nneeds to be a NOINPUT sig, meaning the settlement tx also needs to be\ntagged in that case.\n\nYou'd only need the script path for the last case where there actually\nare multiple updates, but because you have to have a tagged output in the\nsecond case anyway, maybe you've already lost privacy and always using\nNOINPUT and the script path for update and settlement tx's would be fine.\n\n> However, it is probably more likely that I simply misunderstood what you said, so if you can definitively say that it would be possible to hide the clause \"or a NOINPUT sig from A with a non-NOINPUT sig from B\" behind a Taproot then I am fine.\n\nYeah, that's my thinking.\n\n> Minor pointless reactions:\n> > 5.  if you're using scriptless scripts to do HTLCs, you'll need to\n> >     allow for NOINPUT sigs when claiming funds as well (and update\n> >     the partial signatures for the non-NOINPUT cases if you want to\n> >     maximise privacy), which is a bit fiddly\n> If I remember accurately, we do not allow bilateral/cooperative close when HTLC is in-flight.\n> However, I notice that later you point out that a non-cheating unilateral close does not need NOINPUT, so I suppose. the above thought applies to that case.\n\nYeah, exactly.\n\nTrying to maximise privacy there has the disadvantage that you have to\ndo a new signature for every in-flight HTLC every time you update the\nstate, which could be a lot of signatures for very active channels.\n\nCheers,\naj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-14T07:55:20",
                "message_text_only": "Good morning aj,\n\n>\n> Trying to maximise privacy there has the disadvantage that you have to\n> do a new signature for every in-flight HTLC every time you update the\n> state, which could be a lot of signatures for very active channels.\n\nIf I remember accurately this is already true for current Poon-Dryja channels in BOLT 1.0, so at least it is not a degradation of performance.\nIt does make this modified form of Decker-Russell-Osuntokun much less attractive for use with DLC as the Fulgurite effort would like, but the Fulgurite effort already mitigates this by splitting a channel into two sub-channels (one for high-activity LN payments, one for rare-activity DLC bets) anyway.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Christian Decker",
                "date": "2019-03-14T12:00:56",
                "message_text_only": "Anthony Towns <aj at erisian.com.au> writes:\n> I'm thinking of tagged outputs as \"taproot plus\" (ie, plus noinput),\n> so if you used a tagged output, you could do everything normal taproot\n> address could, but also do noinput sigs for them.\n>\n> So you might have:\n>\n>    funding tx -> cooperative claim\n>\n>    funding tx -> update 3 [TAGGED] -> settlement 3 -> claim\n>\n>    funding tx -> update 3 [TAGGED] -> \n>                  update 4 [TAGGED,NOINPUT] -> \n> \t\t settlement 4 [TAGGED,NOINPUT] -> \n> \t\t claim [NOINPUT]\n>\n> In the cooperative case, no output tagging needed.\n\nI might be missing something here, but how do you bind update 3 to the\nfunding tx output, when that output is not tagged? Do we keep each\nupdate in multiple separate states, one bound to the funding tx output\nand another signed with noinput? If that's the case we just doubled our\nstorage and communication requirements for very little gain. An\nalternative is to add a trigger transaction that needs to be published\nin a unilateral case, but that'd increase our on-chain footprint."
            },
            {
                "author": "Anthony Towns",
                "date": "2019-03-18T06:38:56",
                "message_text_only": "On Thu, Mar 14, 2019 at 01:00:56PM +0100, Christian Decker wrote:\n> Anthony Towns <aj at erisian.com.au> writes:\n> > I'm thinking of tagged outputs as \"taproot plus\" (ie, plus noinput),\n> > so if you used a tagged output, you could do everything normal taproot\n> > address could, but also do noinput sigs for them.\n> > So you might have:\n> >    funding tx -> cooperative claim\n> >    funding tx -> update 3 [TAGGED] -> settlement 3 -> claim\n> >    funding tx -> update 3 [TAGGED] -> \n> >                  update 4 [TAGGED,NOINPUT] -> \n> > \t\t settlement 4 [TAGGED,NOINPUT] -> \n> > \t\t claim [NOINPUT]\n> > In the cooperative case, no output tagging needed.\n> I might be missing something here, but how do you bind update 3 to the\n> funding tx output, when that output is not tagged? Do we keep each\n> update in multiple separate states, one bound to the funding tx output\n> and another signed with noinput?\n\nI don't know that \"separate states\" is a great description -- until it\nhits the blockchain \"update N\" is a template that can be filled out in a\nvariety of ways -- in the above the ways are:\n - with a NOINPUT sig and a previous \"update\" tx as its input\n - or with a SINGLE|ANYONECANPAY sig and the funding tx as input\n\nThe important thing is that approach means two sigs for each update tx.\nThe above also has two sigs for each settlement tx (and likewise two sigs\nfor each HTLC claim if using scriptless scripts) -- one using NOINPUT\nin case multiple update tx's make it to the blockchain, and one assuming\neverything works as expected that can just use direct key path spending.\n\nI think you can do SINGLE,ANYCANPAY and combine multiple channel closures\nif you're directly spending the funding tx, but can't do that if you're\nusing a NOINPUT sig, because the NOINPUT sig would commit to the tx's\nlocktime and different channel's states will generally have different\nlocktimes. You still probably want SINGLE,ANYCANPAY in that case so you\ncan bump fees though.\n\n> If that's the case we just doubled our\n> storage and communication requirements for very little gain.\n\nThere's three potential gains:\n * it lets us make a safer version of NOINPUT\n * it makes the common paths give fewer hints that you're using eltoo\n * it puts less data/computation load on the blockchain\n\nWith tagged outputs your update tx already indicates you're maybe going\nto use NOINPUT, so that probably already gives away that you're using\neltoo, so, at least with output tagging, the second benefit probably\ndoesn't exist. Using a key path spend (without a script) is probably\ngoing to be cheaper on the blockchain though.\n\nBut while I think output tagging is probably better than nothing,\nrequiring a non-NOINPUT signature seems a better approach to me. With\nthat one, having a dedicated sig for the normal \"publish the latest\nstate spending the funding tx\" case, reduces a unilateral close to only\nbeing special due to the settlement tx having a relative timelock, and\nthe various tx's using SINGLE|ANYCANPAY, which seems like a win. In that\nscenario, just using a single sig is much cheaper than revealing a taproot\npoint, a pubkey or two, and using two sigs and a CLTV check of course.\n\nIt does goes from 1+n signatures per update today to 4+n signatures,\nif you're using scriptless scripts. If you don't mind revealing the\nHTLCs are HTLCs, and could do them with actual scripts, that reduces to\n4 signatures. You could reduce it to 2 signatures by also always posting\n\"funding tx -> update 0 -> update N -> settlement N\", or you could reduce\nit to 2+2/k signatures by only doing the non-NOINPUT sigs for every k'th\nstate (or no more often than every t seconds or similar).\n\n> An\n> alternative is to add a trigger transaction that needs to be published\n> in a unilateral case, but that'd increase our on-chain footprint.\n\n(The above essentially uses update tx's as optional trigger tx's)\n\nAlso, I'd expect the extra latency introduced by the interactive signing\nprotocol for muSig would be more of a hit (share the nonce hash, share\nthe nonce, calculate the sig). Particularly if you're doing multiparty\nchannels with many participants, rather than just two.\n\nCheers,\naj"
            },
            {
                "author": "Rusty Russell",
                "date": "2019-03-20T00:22:05",
                "message_text_only": "Anthony Towns <aj at erisian.com.au> writes:\n> If you publish to the blockchain:\n...\n> 4 can be dropped, state 5 and finish can be altered). Since the CSV delay\n> is chosen by the participants, the above is still a possible scenario\n> in eltoo, though, and it means there's some risk for someone accepting\n> bitcoins that result from a non-cooperative close of an eltoo channel.\n\nAJ, this was a meandering random walk which shed very little light.\n\nI don't find the differentiation between malicious and non-malicious\ndouble-spends convincing.  Even if you trust A, you already have to\nworry about person-who-sent-the-coins-to-A.  This expands that set to be\n\"miner who mined coins sent-to-A\", but it's very hard to see what\ndifference that makes to how you'd handle coins from A.\n\n> Beyond that, I think NOINPUT has two fundamental ways to cause problems\n> for the people doing NOINPUT sigs:\n>\n>  1) your signature gets applied to a unexpectedly different\n>     script, perhaps making it look like you've being dealing\n>     with some blacklisted entity. OP_MASK and similar solves\n>     this.\n\n... followed by two paragraphs describing how it's not a \"fundamental\nway to cause problems\" that you (or I) can see.\n\n> For the second case, that seems a little more concerning. The nightmare\n> scenario is maybe something like:\n>\n>  * naive users do silly things with NOINPUT signatures, and end up\n>    losing funds due to replays like the above\n\nAs we've never seen with SIGHASH_NONE?\n\n>  * initial source of funds was some major exchange, who decide it's\n>    cheaper to refund the lost funds than deal with the customer complaints\n>\n>  * the lost funds end up costing enough that major exchanges just outright\n>    ban sending funds to any address capable of NOINPUT, which also bans\n>    all taproot/schnorr addresses\n\nI don't find this remotely credible.\n\n> FWIW, I don't have a strong opinion here yet, but:\n>\n>  - I'm still inclined to err on the side of putting more safety\n>    measures in for NOINPUT, rather than fewer\n\nIn theory, sure.  But not feel-good and complex \"safety measures\" which\ndon't actually help in practical failure scenarios.\n\n>  - the \"must have a sig that commits to the input tx\" seems like it\n>    should be pretty safe, not too expensive, and keeps taproot's privacy\n>    benefits in the cases where you end up needing to use NOINPUT\n\nIf this is considered necessary, can it be a standardness rule rather\nthan consensus?\n\nThanks,\nRusty."
            },
            {
                "author": "Rusty Russell",
                "date": "2019-03-20T03:33:55",
                "message_text_only": "Sorry AJ, my prior email was not constructive :(\n\nI consider the \"my software reused my keys\" the most reasonable attack\nscenario, though still small compared to other lightning attack surfaces.\n\nBut I understand the general wariness of third-parties reusing\nSIGHASH_NOINPUT signatures.\n\nSince \"must have a non-SIGHASH_NOINPUT\" rule addresses the first reuse\nscenario (as well as the second), I'd be content with that proposal.\nFuture segwit versions may choose to relax it.[1]\n\nCheers,\nRusty.\n[1] Must be consensus, not standardness; my prev suggestion was bogus.\n\nRusty Russell <rusty at rustcorp.com.au> writes:\n> Anthony Towns <aj at erisian.com.au> writes:\n>> If you publish to the blockchain:\n> ...\n>> 4 can be dropped, state 5 and finish can be altered). Since the CSV delay\n>> is chosen by the participants, the above is still a possible scenario\n>> in eltoo, though, and it means there's some risk for someone accepting\n>> bitcoins that result from a non-cooperative close of an eltoo channel.\n>\n> AJ, this was a meandering random walk which shed very little light.\n>\n> I don't find the differentiation between malicious and non-malicious\n> double-spends convincing.  Even if you trust A, you already have to\n> worry about person-who-sent-the-coins-to-A.  This expands that set to be\n> \"miner who mined coins sent-to-A\", but it's very hard to see what\n> difference that makes to how you'd handle coins from A.\n>\n>> Beyond that, I think NOINPUT has two fundamental ways to cause problems\n>> for the people doing NOINPUT sigs:\n>>\n>>  1) your signature gets applied to a unexpectedly different\n>>     script, perhaps making it look like you've being dealing\n>>     with some blacklisted entity. OP_MASK and similar solves\n>>     this.\n>\n> ... followed by two paragraphs describing how it's not a \"fundamental\n> way to cause problems\" that you (or I) can see.\n>\n>> For the second case, that seems a little more concerning. The nightmare\n>> scenario is maybe something like:\n>>\n>>  * naive users do silly things with NOINPUT signatures, and end up\n>>    losing funds due to replays like the above\n>\n> As we've never seen with SIGHASH_NONE?\n>\n>>  * initial source of funds was some major exchange, who decide it's\n>>    cheaper to refund the lost funds than deal with the customer complaints\n>>\n>>  * the lost funds end up costing enough that major exchanges just outright\n>>    ban sending funds to any address capable of NOINPUT, which also bans\n>>    all taproot/schnorr addresses\n>\n> I don't find this remotely credible.\n>\n>> FWIW, I don't have a strong opinion here yet, but:\n>>\n>>  - I'm still inclined to err on the side of putting more safety\n>>    measures in for NOINPUT, rather than fewer\n>\n> In theory, sure.  But not feel-good and complex \"safety measures\" which\n> don't actually help in practical failure scenarios.\n>\n>>  - the \"must have a sig that commits to the input tx\" seems like it\n>>    should be pretty safe, not too expensive, and keeps taproot's privacy\n>>    benefits in the cases where you end up needing to use NOINPUT\n>\n> If this is considered necessary, can it be a standardness rule rather\n> than consensus?\n>\n> Thanks,\n> Rusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-20T07:38:22",
                "message_text_only": "Hi all,\n\n> Since \"must have a non-SIGHASH_NOINPUT\" rule addresses the first reuse\n> scenario (as well as the second), I'd be content with that proposal.\n\nHow would this work with watchtowers?\n\nAs I understand it, the current plan for eltoo watchtowers would be to store both `SIGHASH_NOINPUT` signatures from both sides in the blob sent to the watchtower.\n\nThen the watchtower can always attach this to whatever is the tipmost available on the chain of transactions.\n\nHowever, if one of the signatures MUST be non-`SIGHASH_NOINPUT` --- how does the watchtower create such a non-`SIGHASH_NOINPUT` signature?\n\nRegards,\nZmnSCPxj\n\n\n> Future segwit versions may choose to relax it.[1]\n>\n> Cheers,\n> Rusty.\n> [1] Must be consensus, not standardness; my prev suggestion was bogus.\n>\n> Rusty Russell rusty at rustcorp.com.au writes:\n>\n> > Anthony Towns aj at erisian.com.au writes:\n> >\n> > > If you publish to the blockchain:\n> > > ...\n> > > 4 can be dropped, state 5 and finish can be altered). Since the CSV delay\n> > > is chosen by the participants, the above is still a possible scenario\n> > > in eltoo, though, and it means there's some risk for someone accepting\n> > > bitcoins that result from a non-cooperative close of an eltoo channel.\n> >\n> > AJ, this was a meandering random walk which shed very little light.\n> > I don't find the differentiation between malicious and non-malicious\n> > double-spends convincing. Even if you trust A, you already have to\n> > worry about person-who-sent-the-coins-to-A. This expands that set to be\n> > \"miner who mined coins sent-to-A\", but it's very hard to see what\n> > difference that makes to how you'd handle coins from A.\n> >\n> > > Beyond that, I think NOINPUT has two fundamental ways to cause problems\n> > > for the people doing NOINPUT sigs:\n> > >\n> > > 1.  your signature gets applied to a unexpectedly different\n> > >     script, perhaps making it look like you've being dealing\n> > >     with some blacklisted entity. OP_MASK and similar solves\n> > >     this.\n> > >\n> >\n> > ... followed by two paragraphs describing how it's not a \"fundamental\n> > way to cause problems\" that you (or I) can see.\n> >\n> > > For the second case, that seems a little more concerning. The nightmare\n> > > scenario is maybe something like:\n> > >\n> > > -   naive users do silly things with NOINPUT signatures, and end up\n> > >     losing funds due to replays like the above\n> > >\n> >\n> > As we've never seen with SIGHASH_NONE?\n> >\n> > > -   initial source of funds was some major exchange, who decide it's\n> > >     cheaper to refund the lost funds than deal with the customer complaints\n> > >\n> > > -   the lost funds end up costing enough that major exchanges just outright\n> > >     ban sending funds to any address capable of NOINPUT, which also bans\n> > >     all taproot/schnorr addresses\n> > >\n> >\n> > I don't find this remotely credible.\n> >\n> > > FWIW, I don't have a strong opinion here yet, but:\n> > >\n> > > -   I'm still inclined to err on the side of putting more safety\n> > >     measures in for NOINPUT, rather than fewer\n> > >\n> >\n> > In theory, sure. But not feel-good and complex \"safety measures\" which\n> > don't actually help in practical failure scenarios.\n> >\n> > > -   the \"must have a sig that commits to the input tx\" seems like it\n> > >     should be pretty safe, not too expensive, and keeps taproot's privacy\n> > >     benefits in the cases where you end up needing to use NOINPUT\n> > >\n> >\n> > If this is considered necessary, can it be a standardness rule rather\n> > than consensus?\n> > Thanks,\n> > Rusty.\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-20T08:07:00",
                "message_text_only": "Hi aj,\n\nRe-reading again, I think perhaps I was massively confused by this:\n\n> - alternatively, we could require every script to have a valid signature\n> that commits to the input. In that case, you could do eltoo with a\n> script like either:\n>\n> <A> CHECKSIGVERIFY <B> CHECKSIG\n> or <P> CHECKSIGVERIFY <Q> CHECKSIG\n>\n>\n> where A is Alice's key and B is Bob's key, P is muSig(A,B) and Q is\n> a key they both know the private key for. In the first case, Alice\n> would give Bob a NOINPUT sig for the tx, and when Bob wanted to publish\n> Bob would just do a SIGHASH_ALL sig with his own key. In the second,\n> Alice and Bob would share partial NOINPUT sigs of the tx with P, and\n> finish that when they wanted to publish.\n\nDo you mean that *either* of the above two scripts is OK, *or* do you mean they are alternatives within a single MAST or `OP_IF`?\n\nIf you mean that *either* of the above two scripts is OK, then this script:\n\n    <muSig(A,B)> CHECKVERIFY <Q> CHECKSIG\n\nshould probably be used for Watchtower-compatibility.\n\nWhen creating a new state, both A and B would cooperatively sign with `muSig(A,B)` with a `SIGHASH_NOINPUT` that ensures the state transaction is correct.\nThen they somehow derive or share the private key to `Q`.\n\nIn the blob sent to Watchtower, A (or B) includes the `SIGHASH_NOINPUT` as well as the `q` private key.\nWould it be safe for Watchtower to know that?\n\nNote that the above `Q` would need to be the same in the \"state\" trunk of the Decker-Russell-Osuntokun construction.\n\nSo, building this, our initial setup transaction pays out to script:\n\n    <muSig(A_u,B_u)> CHECKVERIFY <Q> CHECKSIG\n\nThen each update transaction pays out to:\n\n    OP_IF\n        <csv_delta> OP_CSV OP_DROP\n        <muSig(A_si,B_si)> OP_CHECKSIGVERIFY <Q> OP_CHECKSIG\n    OP_ELSE\n        <i> OP_CHECKLOCKTIMEVERIFY OP_DROP\n        <muSig(A_u,B_u)> OP_CHECKSIGVERIFY <Q> OP_CHECKSIG\n    OP_ENDIF\n\nThe `SIGHASH_NOINPUT` signature for `muSig(A_u,B_u)` would then be sufficient to unlock the setup transaction, or any update transaction with lower `nLockTime`.\nThe watchtower would then have to generate the signature for `Q`, committing to a particular UTXO.\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Wednesday, March 20, 2019 3:38 PM, ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n\n> Hi all,\n>\n> > Since \"must have a non-SIGHASH_NOINPUT\" rule addresses the first reuse\n> > scenario (as well as the second), I'd be content with that proposal.\n>\n> How would this work with watchtowers?\n>\n> As I understand it, the current plan for eltoo watchtowers would be to store both `SIGHASH_NOINPUT` signatures from both sides in the blob sent to the watchtower.\n>\n> Then the watchtower can always attach this to whatever is the tipmost available on the chain of transactions.\n>\n> However, if one of the signatures MUST be non-`SIGHASH_NOINPUT` --- how does the watchtower create such a non-`SIGHASH_NOINPUT` signature?\n>\n> Regards,\n> ZmnSCPxj\n>\n> > Future segwit versions may choose to relax it.[1]\n> > Cheers,\n> > Rusty.\n> > [1] Must be consensus, not standardness; my prev suggestion was bogus.\n> > Rusty Russell rusty at rustcorp.com.au writes:\n> >\n> > > Anthony Towns aj at erisian.com.au writes:\n> > >\n> > > > If you publish to the blockchain:\n> > > > ...\n> > > > 4 can be dropped, state 5 and finish can be altered). Since the CSV delay\n> > > > is chosen by the participants, the above is still a possible scenario\n> > > > in eltoo, though, and it means there's some risk for someone accepting\n> > > > bitcoins that result from a non-cooperative close of an eltoo channel.\n> > >\n> > > AJ, this was a meandering random walk which shed very little light.\n> > > I don't find the differentiation between malicious and non-malicious\n> > > double-spends convincing. Even if you trust A, you already have to\n> > > worry about person-who-sent-the-coins-to-A. This expands that set to be\n> > > \"miner who mined coins sent-to-A\", but it's very hard to see what\n> > > difference that makes to how you'd handle coins from A.\n> > >\n> > > > Beyond that, I think NOINPUT has two fundamental ways to cause problems\n> > > > for the people doing NOINPUT sigs:\n> > > >\n> > > > 1.  your signature gets applied to a unexpectedly different\n> > > >     script, perhaps making it look like you've being dealing\n> > > >     with some blacklisted entity. OP_MASK and similar solves\n> > > >     this.\n> > > >\n> > >\n> > > ... followed by two paragraphs describing how it's not a \"fundamental\n> > > way to cause problems\" that you (or I) can see.\n> > >\n> > > > For the second case, that seems a little more concerning. The nightmare\n> > > > scenario is maybe something like:\n> > > >\n> > > > -   naive users do silly things with NOINPUT signatures, and end up\n> > > >     losing funds due to replays like the above\n> > > >\n> > >\n> > > As we've never seen with SIGHASH_NONE?\n> > >\n> > > > -   initial source of funds was some major exchange, who decide it's\n> > > >     cheaper to refund the lost funds than deal with the customer complaints\n> > > >\n> > > > -   the lost funds end up costing enough that major exchanges just outright\n> > > >     ban sending funds to any address capable of NOINPUT, which also bans\n> > > >     all taproot/schnorr addresses\n> > > >\n> > >\n> > > I don't find this remotely credible.\n> > >\n> > > > FWIW, I don't have a strong opinion here yet, but:\n> > > >\n> > > > -   I'm still inclined to err on the side of putting more safety\n> > > >     measures in for NOINPUT, rather than fewer\n> > > >\n> > >\n> > > In theory, sure. But not feel-good and complex \"safety measures\" which\n> > > don't actually help in practical failure scenarios.\n> > >\n> > > > -   the \"must have a sig that commits to the input tx\" seems like it\n> > > >     should be pretty safe, not too expensive, and keeps taproot's privacy\n> > > >     benefits in the cases where you end up needing to use NOINPUT\n> > > >\n> > >\n> > > If this is considered necessary, can it be a standardness rule rather\n> > > than consensus?\n> > > Thanks,\n> > > Rusty.\n> >\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Anthony Towns",
                "date": "2019-03-21T09:06:14",
                "message_text_only": "On Wed, Mar 20, 2019 at 08:07:00AM +0000, ZmnSCPxj via Lightning-dev wrote:\n> Re-reading again, I think perhaps I was massively confused by this:\n> > that commits to the input. In that case, you could do eltoo with a\n> > script like either:\n> > <A> CHECKSIGVERIFY <B> CHECKSIG\n> > or <P> CHECKSIGVERIFY <Q> CHECKSIG\n> Do you mean that *either* of the above two scripts is OK, *or* do you mean they are alternatives within a single MAST or `OP_IF`?\n\nI meant \"either of the two scripts is okay\".\n\n> In the blob sent to Watchtower, A (or B) includes the `SIGHASH_NOINPUT` as well as the `q` private key.\n> Would it be safe for Watchtower to know that?\n\nI think so. From Alice/Bob's point-of-view, the NOINPUT sig ensures they\ncontrol their money; and from the network's point-of-view (or at least\nthat part of the network that thinks NOINPUT is unsafe) the Q private\nkey being shared makes the tx no worse than a 1-of-n multisig setup,\nwhich has to be dealt with anyway.\n\n> Then each update transaction pays out to:\n>     OP_IF\n>         <csv_delta> OP_CSV OP_DROP\n>         <muSig(A_si,B_si)> OP_CHECKSIGVERIFY <Q> OP_CHECKSIG\n>     OP_ELSE\n>         <i> OP_CHECKLOCKTIMEVERIFY OP_DROP\n>         <muSig(A_u,B_u)> OP_CHECKSIGVERIFY <Q> OP_CHECKSIG\n>     OP_ENDIF\n\nYeah.\n\nI think we could potentially make that shorter still:\n\n   IF OP_CODESEPARATOR <i> OP_CHECKLOCKTIMEVERIFY OP_DROP ENDIF\n   <muSig(A_u,B_u)> OP_CHECKDLSVERIFY <Q> OP_CHECKDLS\n\nSigning with NOINPUT,NOSCRIPT and codeseparatorpos=1 enforces CLTV\nand allows binding to any prior update tx -- so works for an update tx\nspending previous update txs; while signing with codeseparatorpos=-1\nand NOINPUT but committing to the script code and nSequence (for the\nCSV delay) allows binding to only that update tx -- so works for the\nsettlement tx. That's two pubkeys, two sigs, and the taproot point\nreveal.\n\nCheers,\naj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-21T10:05:09",
                "message_text_only": "Good morning aj,\n\n> > Then each update transaction pays out to:\n> > OP_IF\n> > <csv_delta> OP_CSV OP_DROP\n> > <muSig(A_si,B_si)> OP_CHECKSIGVERIFY <Q> OP_CHECKSIG\n> > OP_ELSE\n> > <i> OP_CHECKLOCKTIMEVERIFY OP_DROP\n> > <muSig(A_u,B_u)> OP_CHECKSIGVERIFY <Q> OP_CHECKSIG\n> > OP_ENDIF\n>\n> Yeah.\n>\n> I think we could potentially make that shorter still:\n>\n> IF OP_CODESEPARATOR <i> OP_CHECKLOCKTIMEVERIFY OP_DROP ENDIF\n> <muSig(A_u,B_u)> OP_CHECKDLSVERIFY <Q> OP_CHECKDLS\n>\n> Signing with NOINPUT,NOSCRIPT and codeseparatorpos=1 enforces CLTV\n> and allows binding to any prior update tx -- so works for an update tx\n> spending previous update txs; while signing with codeseparatorpos=-1\n> and NOINPUT but committing to the script code and nSequence (for the\n> CSV delay) allows binding to only that update tx -- so works for the\n> settlement tx. That's two pubkeys, two sigs, and the taproot point\n> reveal.\n\n\nActually, the shared keys are different in the two branches above.\nThe \"update\" branch (which has no `OP_CSV`) uses the same constant `A_u` and `B_u` points.\nThe \"state commit\" branch (which has `OP_CSV`) uses different `A_si` and `B_si` points depending on `i` (state/sequence number).\n\nAlso, I cannot understand `OP_CODESEPARATOR`, please no.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Anthony Towns",
                "date": "2019-03-21T11:55:22",
                "message_text_only": "On Thu, Mar 21, 2019 at 10:05:09AM +0000, ZmnSCPxj wrote:\n> > IF OP_CODESEPARATOR <i> OP_CHECKLOCKTIMEVERIFY OP_DROP ENDIF\n> > <muSig(A_u,B_u)> OP_CHECKDLSVERIFY <Q> OP_CHECKDLS\n> > Signing with NOINPUT,NOSCRIPT and codeseparatorpos=1 enforces CLTV\n> > and allows binding to any prior update tx -- so works for an update tx\n> > spending previous update txs; while signing with codeseparatorpos=-1\n> > and NOINPUT but committing to the script code and nSequence (for the\n> > CSV delay) allows binding to only that update tx -- so works for the\n> > settlement tx. That's two pubkeys, two sigs, and the taproot point\n> > reveal.\n> \n> Actually, the shared keys are different in the two branches above.\n\nYes, if you're not committing to the script code you need the separate\nkeys as otherwise any settlement transaction could be used with any\nupdate transaction. \n\nIf you are committing to the script code, though, then each settlement\nsig is already only usable with the corresponding update tx, so you\ndon't need to roll the keys. But you do need to make it so that the\nupdate sig requires the CLTV; one way to do that is using codeseparator\nto distinguish between the two cases.\n\n> Also, I cannot understand `OP_CODESEPARATOR`, please no.\n\nIf codeseparator is too scary, you could probably also just always\nrequire the locktime (ie for settlmenet txs as well as update txs), ie:\n\n  OP_CHECKLOCKTIMEVERIFY OP_DROP\n  <muSig(A_u,B_u)> OP_CHECKDLSVERIFY <Q> OP_CHECKDLS\n\nand have update txs set their timelock; and settlement txs set a absolute\ntimelock, relative timelock via sequence, and commit to the script code.\n\n(Note that both those approaches (with and without codesep) assume there's\nsome flag that allows you to commit to the scriptcode even though you're\nnot committing to your input tx (and possibly not committing to the\nscriptpubkey). BIP118 doesn't have that flexibility, so the A_s_i and\nB_s_i key rolling is necessary)\n\nCheers,\naj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-22T01:59:14",
                "message_text_only": "Good morning aj,\n>\n> If you are committing to the script code, though, then each settlement\n> sig is already only usable with the corresponding update tx, so you\n> don't need to roll the keys. But you do need to make it so that the\n> update sig requires the CLTV; one way to do that is using codeseparator\n> to distinguish between the two cases.\n>\n> > Also, I cannot understand `OP_CODESEPARATOR`, please no.\n>\n> If codeseparator is too scary, you could probably also just always\n> require the locktime (ie for settlmenet txs as well as update txs), ie:\n>\n> OP_CHECKLOCKTIMEVERIFY OP_DROP\n> <muSig(A_u,B_u)> OP_CHECKDLSVERIFY <Q> OP_CHECKDLS\n>\n> and have update txs set their timelock; and settlement txs set a absolute\n> timelock, relative timelock via sequence, and commit to the script code.\n>\n> (Note that both those approaches (with and without codesep) assume there's\n> some flag that allows you to commit to the scriptcode even though you're\n> not committing to your input tx (and possibly not committing to the\n> scriptpubkey). BIP118 doesn't have that flexibility, so the A_s_i and\n> B_s_i key rolling is necessary)\n\nI think the issue I have here is the lack of `OP_CSV` in the settlement branch.\n\nConsider a channel with offchain transactions update-1, settlement-1, update-2, and settlement-2.\nIf update-1 is placed onchain, update-1 is also immediately spendable by settlement-1.\nBut settlement-1 cannot be spent by update-2 and thus the invalidation of older state fails.\n\nThe `OP_CSV` in the settlement branch of the update transaction outputs exists to allow later update transactions have higher priority over settlement transactions.\n\nTo ensure that a settlement signature can only take the settlement branch, we need a distinct public key for the branch, so at least `A_s` and `B_s` without rolling them for each `i`, if we use `nLockTime` on the settlement transactions and enforce it with `OP_CHECKLOCKTIMEVERIFY`.\nIt might be possible to do this with `OP_CODESEPARATOR`, but we do need the `OP_CSV` in the settlement branch.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Anthony Towns",
                "date": "2019-03-22T02:58:46",
                "message_text_only": "On Fri, Mar 22, 2019 at 01:59:14AM +0000, ZmnSCPxj wrote:\n> > If codeseparator is too scary, you could probably also just always\n> > require the locktime (ie for settlmenet txs as well as update txs), ie:\n> > OP_CHECKLOCKTIMEVERIFY OP_DROP\n> > <muSig(A_u,B_u)> OP_CHECKDLSVERIFY <Q> OP_CHECKDLS\n> > and have update txs set their timelock; and settlement txs set a absolute\n> > timelock, relative timelock via sequence, and commit to the script code.\n> \n> I think the issue I have here is the lack of `OP_CSV` in the settlement branch.\n\nYou can enforce the relative timelock in the settlement branch simply\nby refusing to sign a settlement tx that doesn't have the timelock set;\nthe OP_CSV is redundant.\n\n> Consider a channel with offchain transactions update-1, settlement-1, update-2, and settlement-2.\n> If update-1 is placed onchain, update-1 is also immediately spendable by settlement-1.\n\nsettlement-1 was signed by you, and when you signed it you ensured that\nnsequence was set as per BIP-68, and NOINPUT sigs commit to nsequence,\nso if anyone changed that after the fact the sig isn't valid. Because\nBIP-68 is enforced by consensus, update-1 isn't immediately spendable\nby settlement-1.\n\nCheers,\naj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-22T07:46:28",
                "message_text_only": "Good morning aj,\n\nI understand.\nLooks like that makes sense.\nIt seems possible to use this, then, together with watchtowers.\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Friday, March 22, 2019 10:58 AM, Anthony Towns <aj at erisian.com.au> wrote:\n\n> On Fri, Mar 22, 2019 at 01:59:14AM +0000, ZmnSCPxj wrote:\n>\n> > > If codeseparator is too scary, you could probably also just always\n> > > require the locktime (ie for settlmenet txs as well as update txs), ie:\n> > > OP_CHECKLOCKTIMEVERIFY OP_DROP\n> > > <muSig(A_u,B_u)> OP_CHECKDLSVERIFY <Q> OP_CHECKDLS\n> > > and have update txs set their timelock; and settlement txs set a absolute\n> > > timelock, relative timelock via sequence, and commit to the script code.\n> >\n> > I think the issue I have here is the lack of `OP_CSV` in the settlement branch.\n>\n> You can enforce the relative timelock in the settlement branch simply\n> by refusing to sign a settlement tx that doesn't have the timelock set;\n> the OP_CSV is redundant.\n>\n> > Consider a channel with offchain transactions update-1, settlement-1, update-2, and settlement-2.\n> > If update-1 is placed onchain, update-1 is also immediately spendable by settlement-1.\n>\n> settlement-1 was signed by you, and when you signed it you ensured that\n> nsequence was set as per BIP-68, and NOINPUT sigs commit to nsequence,\n> so if anyone changed that after the fact the sig isn't valid. Because\n> BIP-68 is enforced by consensus, update-1 isn't immediately spendable\n> by settlement-1.\n>\n> Cheers,\n> aj"
            }
        ],
        "thread_summary": {
            "title": "More thoughts on NOINPUT safety",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Anthony Towns",
                "Rusty Russell",
                "Christian Decker",
                "ZmnSCPxj"
            ],
            "messages_count": 18,
            "total_messages_chars_count": 55197
        }
    },
    {
        "title": "[Lightning-dev] [bitcoin-dev]  More thoughts on NOINPUT safety",
        "thread_messages": [
            {
                "author": "Johnson Lau",
                "date": "2019-03-21T08:37:54",
                "message_text_only": "> On 20 Mar 2019, at 4:07 PM, ZmnSCPxj via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Hi aj,\n> \n> Re-reading again, I think perhaps I was massively confused by this:\n> \n>> - alternatively, we could require every script to have a valid signature\n>> that commits to the input. In that case, you could do eltoo with a\n>> script like either:\n>> \n>> <A> CHECKSIGVERIFY <B> CHECKSIG\n>> or <P> CHECKSIGVERIFY <Q> CHECKSIG\n>> \n>> \n>> where A is Alice's key and B is Bob's key, P is muSig(A,B) and Q is\n>> a key they both know the private key for. In the first case, Alice\n>> would give Bob a NOINPUT sig for the tx, and when Bob wanted to publish\n>> Bob would just do a SIGHASH_ALL sig with his own key. In the second,\n>> Alice and Bob would share partial NOINPUT sigs of the tx with P, and\n>> finish that when they wanted to publish.\n> \n> Do you mean that *either* of the above two scripts is OK, *or* do you mean they are alternatives within a single MAST or `OP_IF`?\n> \n\nIt means either.\n\nIf you use <A> CHECKSIGVERIFY <B> CHECKSIG style, A and B will exchange the NOINPUT sig, and they will add the required non-NOINPUT sig when needed.\n\nIf you use <muSig(A,B)> CHECKVERIFY <Q> CHECKSIG, A and B will co-sign the muSig(A,B) with NOINPUT. They will also share the private key of Q, so they could produce a non-NOINPUT sig when needed.\n\nThe first style is slightly easier as it doesn\u2019t need muSig. But with 3 or more parties, the second style is more efficient.\n\nHowever, if you use watchtower, you have to use the second style. That means you need to share the private key for Q with the watchtower, That also means the watchtower will have the ability to reply the NOINPU muSig. But it is still strictly better than anyone-can-replay.\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190321/7a2ef867/attachment.html>"
            },
            {
                "author": "Johnson Lau",
                "date": "2019-03-22T04:23:28",
                "message_text_only": "> On 22 Mar 2019, at 9:59 AM, ZmnSCPxj via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Good morning aj,\n>> \n>> If you are committing to the script code, though, then each settlement\n>> sig is already only usable with the corresponding update tx, so you\n>> don't need to roll the keys. But you do need to make it so that the\n>> update sig requires the CLTV; one way to do that is using codeseparator\n>> to distinguish between the two cases.\n>> \n>>> Also, I cannot understand `OP_CODESEPARATOR`, please no.\n>> \n>> If codeseparator is too scary, you could probably also just always\n>> require the locktime (ie for settlmenet txs as well as update txs), ie:\n>> \n>> OP_CHECKLOCKTIMEVERIFY OP_DROP\n>> <muSig(A_u,B_u)> OP_CHECKDLSVERIFY <Q> OP_CHECKDLS\n>> \n>> and have update txs set their timelock; and settlement txs set a absolute\n>> timelock, relative timelock via sequence, and commit to the script code.\n>> \n>> (Note that both those approaches (with and without codesep) assume there's\n>> some flag that allows you to commit to the scriptcode even though you're\n>> not committing to your input tx (and possibly not committing to the\n>> scriptpubkey). BIP118 doesn't have that flexibility, so the A_s_i and\n>> B_s_i key rolling is necessary)\n> \n> I think the issue I have here is the lack of `OP_CSV` in the settlement branch.\n> \n> Consider a channel with offchain transactions update-1, settlement-1, update-2, and settlement-2.\n> If update-1 is placed onchain, update-1 is also immediately spendable by settlement-1.\n> But settlement-1 cannot be spent by update-2 and thus the invalidation of older state fails.\n> \n> The `OP_CSV` in the settlement branch of the update transaction outputs exists to allow later update transactions have higher priority over settlement transactions.\n> \n> To ensure that a settlement signature can only take the settlement branch, we need a distinct public key for the branch, so at least `A_s` and `B_s` without rolling them for each `i`, if we use `nLockTime` on the settlement transactions and enforce it with `OP_CHECKLOCKTIMEVERIFY`.\n> It might be possible to do this with `OP_CODESEPARATOR`, but we do need the `OP_CSV` in the settlement branch.\n> \n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n\nOP_CSV (BIP112) is not needed. Only BIP68 relative-time is needed.\n\nWith this script:\n\n<t> OP_CHECKLOCKTIMEVERIFY OP_DROP <muSig(A,B)> OP_CHECKSIGVERIFY <Q> OP_CHECKSIG\n\nFor update purpose, A and B will co-sign the muSig with nLockTime = t, not committing to the scriptCode, and no BIP68 lock time\n\nFor settlement purpose, A and B will co-sign the muSig with nLockTime = t, committing to the scriptCode, and with an agreed BIP68 locktime\n\nWithout committing to the scriptCode and BIP68 lock time, the update sig could be bind to any previous update tx immediately.\n\nOTOH, the settlement sig will only bind to a specific update tx (thought scriptCode), and only after the relative locktime is passed.\n\nThe eltoo paper is wrong about using OP_CSV. That\u2019s a common mistake even for experienced bitcoin developer. OP_CSV is needed only if one party could single handedly decide the relative-lock-time. However, this is not the case here as it is a muSig.\n\n(With some risks of distracting the discussion, please note that even this script: <t> OP_CHECKLOCKTIMEVERIFY OP_DROP <A> OP_CHECKSIGVERIFY <B> OP_CHECKSIG doesn\u2019t need OP_CSV, despite not using muSig. It is because the 2 sigs must use the same relative locktime, or the tx is invalid.)\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190322/3337a8f8/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "More thoughts on NOINPUT safety",
            "categories": [
                "Lightning-dev",
                "bitcoin-dev"
            ],
            "authors": [
                "Johnson Lau"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 5845
        }
    },
    {
        "title": "[Lightning-dev] Fee structure",
        "thread_messages": [
            {
                "author": "John-John Markstedt",
                "date": "2019-03-13T14:55:10",
                "message_text_only": "I\u2019ve been thinking about the current fee structure I believe it may be\nproblematic\nas there is no inherent way to incentive balanced channels.\n\nThis may be a bit far down the road as there are more direct problems\nthat need to be addressed first. However if you all believe there might be\nsome\nmerit in this line of thinking I can spend some more time formalizing a\nmore proper\nimplementable proposal and run some simulations to verify it\u2019s impact on\nthroughput\nand robustness.\n\nAlthough there are methods to balance channels it would be beneficial if the\nfee could reflect the state in which the channel is left.\n\nCurrently the fee is only proportional to the liquidity used, not the state\nof the channel.\n\nSuppose there exists a channel between Alice and Bob with 10 million\nsatoshis in it.\nTwo payments, [image: P_{1}] and [image: P_{2}] are routed through the\nchannel from Bob to Alice.\nBoth use the same amount of liquidity, 3,500,000 satoshis each, but they\nstart from\ntwo different initial states [image: B_{1}] and [image: B_3].\n\n[image: protocol_upgrade.png]\n\nThe two payments would incur the same fee,\n\n[image: F_{P_1 P_2} = F_B + (3,500,000 * F_R / 1,000,000)]\n\nbut leave the channels in completely different states.[image: P_1] at [image:\nB_2] and [image: P_2] at [image: B_4].\nIt is of course possible to reset the channel price after [image: P_1] to\nbe more expensive,\nbut suppose a third larger payment [image: P_3] going from [image:\nB_1] to [image:\nB_4] would still run\ninto this problem.\n\nIt is possible to limit the maximum allowed payment, to say 1/5 of the\ntotal channel\ncapacity, so a fee could be broadcast between payments. However\nthat would reduce possible transacting parties in the network, limiting\nconnectivity.\n\nIf the price structure was a scheme of brackets instead, where the cost\ndepend on the channel position, these issues may be resolved.\nEach satoshi in the channel may be seen as a different bracket, with a\ndifferent price for each\nsatoshi moved. The channels would then broadcast a cost function instead of\nthe fixed fee.\n\n[image: fee_scheme.png]\n\n>From the cost function the fee may be retrieved by calculating the area\nunder the graphs.\nSome deterministic way to round the fee to whole satoshis and some way to\nverify the\nfunction is formulated correctly must be defined.\n\nThe fees for [image: P_1], [image: P_2] would be very different with this\nbrackets method.\n\n[image: F_{P_1} = F_{B} + \\int_{B_1}^{B_2} f(x) dx = F_B + 13,502,153,930\n\\mu S]\n\n[image: F_{P_2} = F_{B} + \\int_{B_3}^{B_4} f(x) dx = F_B + 88,984,850,361\n\\mu S]\n\nHere the fees are much larger for the payment that unbalances the channel\nthan the\npayment that balances it.\n\nBrackets would incentivize payments to route in such a way to keep channels\nbalanced which may lead to higher throughput.\n\nThis method clearly has some headaches accompanying it. It may be\nunnecessarily complex and\nwould requires deterministic ways to calculate integrals over multiple\nsystems. There might be better\nways to solve this problem and there might be problems with this approach\nI\u2019m unaware of.\nAnyway, some small tweaks in the protocol may lead to a much healthier\nnetwork which\nmay be worthy of exploration.\n\nBest regards,\nJohn-John Markstedt\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190313/578d131f/attachment.html>"
            },
            {
                "author": "Andrea RASPITZU",
                "date": "2019-03-13T17:06:17",
                "message_text_only": "Good morning John-John,\n\nThe current version of the spec uses source routing and that requires the\nsending node to attach the fees to the payment when is sent out, if the\nonion carries the wrong amount of fees for a channel the intermediate node\nshould reply with a channel_update message containing the actual fees. It\nseems to me that you are binding the fees of a channel to its actual state\nbut that would require to re-broadcast a channel_update for every payment\nthat traverse the channel, so in short for every payment there would be an\nupdate being gossiped on the network and that's unpractical.\n\nCheers, Andrea.\n\nLe mer. 13 mars 2019 \u00e0 15:55, John-John Markstedt <john-john at markstedts.org>\na \u00e9crit :\n\n> I\u2019ve been thinking about the current fee structure I believe it may be\n> problematic\n> as there is no inherent way to incentive balanced channels.\n>\n> This may be a bit far down the road as there are more direct problems\n> that need to be addressed first. However if you all believe there might be\n> some\n> merit in this line of thinking I can spend some more time formalizing a\n> more proper\n> implementable proposal and run some simulations to verify it\u2019s impact on\n> throughput\n> and robustness.\n>\n> Although there are methods to balance channels it would be beneficial if\n> the\n> fee could reflect the state in which the channel is left.\n>\n> Currently the fee is only proportional to the liquidity used, not the\n> state of the channel.\n>\n> Suppose there exists a channel between Alice and Bob with 10 million\n> satoshis in it.\n> Two payments, [image: P_{1}] and [image: P_{2}] are routed through the\n> channel from Bob to Alice.\n> Both use the same amount of liquidity, 3,500,000 satoshis each, but they\n> start from\n> two different initial states [image: B_{1}] and [image: B_3].\n>\n> [image: protocol_upgrade.png]\n>\n> The two payments would incur the same fee,\n>\n> [image: F_{P_1 P_2} = F_B + (3,500,000 * F_R / 1,000,000)]\n>\n> but leave the channels in completely different states.[image: P_1] at [image:\n> B_2] and [image: P_2] at [image: B_4].\n> It is of course possible to reset the channel price after [image: P_1] to\n> be more expensive,\n> but suppose a third larger payment [image: P_3] going from [image: B_1]\n> to [image: B_4] would still run\n> into this problem.\n>\n> It is possible to limit the maximum allowed payment, to say 1/5 of the\n> total channel\n> capacity, so a fee could be broadcast between payments. However\n> that would reduce possible transacting parties in the network, limiting\n> connectivity.\n>\n> If the price structure was a scheme of brackets instead, where the cost\n> depend on the channel position, these issues may be resolved.\n> Each satoshi in the channel may be seen as a different bracket, with a\n> different price for each\n> satoshi moved. The channels would then broadcast a cost function instead\n> of the fixed fee.\n>\n> [image: fee_scheme.png]\n>\n> From the cost function the fee may be retrieved by calculating the area\n> under the graphs.\n> Some deterministic way to round the fee to whole satoshis and some way to\n> verify the\n> function is formulated correctly must be defined.\n>\n> The fees for [image: P_1], [image: P_2] would be very different with this\n> brackets method.\n>\n> [image: F_{P_1} = F_{B} + \\int_{B_1}^{B_2} f(x) dx = F_B + 13,502,153,930\n> \\mu S]\n>\n> [image: F_{P_2} = F_{B} + \\int_{B_3}^{B_4} f(x) dx = F_B + 88,984,850,361\n> \\mu S]\n>\n> Here the fees are much larger for the payment that unbalances the channel\n> than the\n> payment that balances it.\n>\n> Brackets would incentivize payments to route in such a way to keep channels\n> balanced which may lead to higher throughput.\n>\n> This method clearly has some headaches accompanying it. It may be\n> unnecessarily complex and\n> would requires deterministic ways to calculate integrals over multiple\n> systems. There might be better\n> ways to solve this problem and there might be problems with this approach\n> I\u2019m unaware of.\n> Anyway, some small tweaks in the protocol may lead to a much healthier\n> network which\n> may be worthy of exploration.\n>\n> Best regards,\n> John-John Markstedt\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190313/2062da41/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-14T05:40:16",
                "message_text_only": "Good morning John-John and Andrea,\n\n>\n> The current version of the spec uses source routing and that requires the sending node to attach the fees to the payment when is sent out, if the onion carries the wrong amount of fees for a channel the intermediate node should reply with a channel_update message containing the actual fees. It seems to me that you are binding the fees of a channel to its actual state but that would require to re-broadcast a channel_update for every payment that traverse the channel, so in short for every payment there would be an update being gossiped on the network and that's unpractical.\n\nThis is also very leaky.\nMonitors can use the timing of `channel_update` to guess the source and destination of every payment.\n\nIf a node wishes to maintain balance on its own channels, it can simply scale its feerate depending on the channel state.\nIf it is already very unbalanced away from the node (the node owns less than half the capacity), then it increases the feerate.\nIf it is already very unbalanced towards the node, then it decreases the feerate.\n\nThis is already possible within the protocol.\nCare must be taken that `channel_update` is not spammed, which potentially leaks information about payments passing through the node.\nA simple heuristic would be to have a random schedule of checking the channel current state, sending a `channel_update` if the feerate should be changed, then sleeping for a random number of seconds before checking again.\nThis will get you reasonably close to what you want, without too much leakage of payments going through you.\n\n\n--\n\nThat said, I see not much point in insisting on channel balance.\nWhile channel balance is aesthetically pleasing, it actually has little benefit to the network.\nAlways consider that there is almost always an alternate path, and the alternate path may have balance in the opposite direction, thus achieving \"balance in the large\" even if your channels are imbalanced in one way and the other.\nThis strikes me as focusing too much on \"balance in the small\".\n\nJIT Routing from rpickhardt is more sensible as it attempts to rebalance only if it would benefit the node to perform the rebalancing.\n(It is more accurately named \"JIT rebalancing\" actually)\nThe alternative for the node if it does not rebalance the channel would be to fail the forwarding attempt.\nBy attempting the rebalance if the time and fee available is good enough, the node benefits as it increases the possibility of earning money (as long as a later part of the route does not fail).\nIt also relatively directly benefits the network, as it improves the probability of routing success (though this is tempered by the fact that in a fully-functional LN a single routing failure is a very minor event that usually does not prevent failure in-the-large).\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "John-John Markstedt",
                "date": "2019-03-14T07:58:18",
                "message_text_only": "Good morning Andrea and ZmnSCPxj,\n\nI wrongly assumed the channel balances needed to be known anyway to create\na route. I see\nnow why that is not the case and why it would scale horribly, in fact it\nscales no better than\nlayer 1 as everyone needs to be notified of every payment. It would also\ndefeat effort\nof keeping payments private.\nThis is clearly the wrong line of thinking.\n\nThis is already possible within the protocol.\n> Care must be taken that `channel_update` is not spammed, which potentially\n> leaks information about payments passing through the node.\n> A simple heuristic would be to have a random schedule of checking the\n> channel current state, sending a `channel_update` if the feerate should be\n> changed, then sleeping for a random number of seconds before checking again.\n> This will get you reasonably close to what you want, without too much\n> leakage of payments going through you.\n>\n\nThat would not regard the size of the payments though? A payment leaving\nthe balance at the far end would pay the same proportional fee as one close\nto the middle.\nAgain fixing that issue by broadcasting each balance change wouldn't scale\nwell and run in the aforementioned leakage so is really a moot point.\n\nI don't see setting the fee only regarding the initial state as obviously\nbeneficial to a routing node, anyway it would indeed be interesting to see\nif\na node utilizing such a strategy, all else being equal, would outperform a\nnode not using it. I will implement something along this line\nand see it that's the case or not.\n\nJIT Routing from rpickhardt is more sensible as it attempts to rebalance\n> only if it would benefit the node to perform the rebalancing.\n> (It is more accurately named \"JIT rebalancing\" actually)\n>\n\nI will have another closer look at the JIT Routing emails.\n\n-\n\nThanks both of you for taking the time to respond and pointing out the\nclear flaws in this idea.\n\nBest regards,\nJohn-John Markstedt\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190314/1844dbf3/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-14T08:03:43",
                "message_text_only": "Good morning John-John,\n\n> That would not regard the size of the payments though? A payment leaving the balance at the far end would pay the same proportional fee as one close to the middle.\n\n\"Proportional\" means the fee paid is greater if the payment being forwarded is greater.\nThat is what \"proportional\" means.\n\nAssuming your current balance on the channel is \"perfect\", in order for a payment passing through you to massively upset that balance, that payment must be large in value relative to the channel capacity.\n\nAnd the proportional fee is larger if the payment is larger.\n\nSo it *perfectly* regards the size of the payments.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "John-John Markstedt",
                "date": "2019-03-14T08:28:12",
                "message_text_only": "> > That would not regard the size of the payments though? A payment leaving\n> the balance at the far end would pay the same proportional fee as one close\n> to the middle.\n>\n> \"Proportional\" means the fee paid is greater if the payment being\n> forwarded is greater.\n> That is what \"proportional\" means.\n>\n\nMy initial point was that the fee would be proportionally higher for every\nsatoshi used closer to the far end of the channel.\nSo the fee would proportional to the state of the channel in addition to\nthe size of the payment.\n\nBest regards,\nJohn-John Markstedt\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190314/9a407bcd/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-14T11:16:12",
                "message_text_only": "Good morning John-John,\n\n\n> > > That would not regard the size of the payments though? A payment leaving the balance at the far end would pay the same proportional fee as one close to the middle.\n> >\n> > \"Proportional\" means the fee paid is greater if the payment being forwarded is greater.\n> > That is what \"proportional\" means.\n>\n> My initial point was that the fee would be proportionally higher for every satoshi used closer to the far end of the channel.\n> So the fee would proportional to the state of the channel in addition to the size of the payment.\n\nBut the final state of the channel has a subtractive relationship from the payment size.\nSo I fear we have largely fallen into an argument on exact semantics and mathematical models that may not be particularly relevant to pragmatic use of LN.\n\nThe \"standard\" solution to balance concerns and manipulations of fee structure has, I think, been \"just make the proportional feerate itself proportional to how much the other side owns on the channel\".\nRegardless of whatever mathematical model you use, in the long run this will achieve your goal of a balanced channel anyway, whatever inaccuracy it may have in the short term.\n\nAgain, JIT Routing is superior to this anyway, as you have direct evidence that rebalancing would be beneficial to you under the current network conditions.\nBalance is not always beneficial: consider a balanced channel containing 0.75 mBTC on both sides, that cannot serve a forwarding request for 1.0 mBTC in either direction.\nJIT Routing handles that case by simply transferring at least 0.25mBTC from some other channel, then serving the forwarding request.\n\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "John-John Markstedt",
                "date": "2019-03-14T15:09:51",
                "message_text_only": "God afternoon ZmnSCPxj,\n\nSorry if I was being a bit pedantic,\n\nI just want to be clear that I agree with both yours and Andrea's\narguments\nin the initial responses and I see now why the idea doesn't make much sense\nat all\nin terms of scale and privacy.\n\n> > My initial point was that the fee would be proportionally higher for\nevery satoshi used closer to the far end of the channel.\n> > So the fee would proportional to the state of the channel in addition\nto the size of the payment.\n>\n\n> But the final state of the channel has a subtractive relationship from the\n> payment size.\n> So I fear we have largely fallen into an argument on exact semantics and\n> mathematical models that may not be particularly relevant to pragmatic use\n> of LN.\n>\n\nI'm not trying to argue here as I agree with you it's not practical, I just\nwanted to clarify as we seemed\nto be talking passed each other on that particular point.\n\nBest regards\nJohn-John Markstedt\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190314/07a76f08/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Fee structure",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Andrea RASPITZU",
                "ZmnSCPxj",
                "John-John Markstedt"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 17079
        }
    },
    {
        "title": "[Lightning-dev] [RFC] option_static_remotekey",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2019-03-14T23:55:02",
                "message_text_only": "Hi all!\n\n        Roasbeef suggested we split up option_simplified_commitment,\nsince it is fairly ambitious.  In particular, he wanted the static\nremote_key feature ASAP, and Christian agreed.\n\nI chose to add the fairly trivial symmetric output to this, as it\naffects the same output, and resolves the gaming around \"no, you close\nplease, no you close\"...\n\nNo PR yet, but you can see it here:\n\n        https://github.com/rustyrussell/lightning-rfc/commit/c5adc5ae19b29b0d8947a9d3acf181134e7dc352\n\nAnd pasted below for inline commentry:\n\ncommit c5adc5ae19b29b0d8947a9d3acf181134e7dc352\nAuthor: Rusty Russell <rusty at rustcorp.com.au>\nDate:   Fri Mar 15 10:02:28 2019 +1030\n\n    option_static_remotekey: first draft.\n    \n    This separates out the symmetric CTLV and static remotekey changes\n    from the more ambitious option_simplified_commitment (which also\n    included pushme outputs and bring-your-own-fee for HTLC outputs).\n    \n    This is a much simpler stepping stone, and resolves one immediate\n    problem.\n    \n    Suggested-by: @roasbeef\n    Signed-off-by: Rusty Russell <rusty at rustcorp.com.au>\n\ndiff --git a/.aspell.en.pws b/.aspell.en.pws\nindex b1a1ad3..20664f2 100644\n--- a/.aspell.en.pws\n+++ b/.aspell.en.pws\n@@ -330,3 +330,4 @@ zlib\n ZLIB\n APIs\n duplicative\n+remotekey\ndiff --git a/02-peer-protocol.md b/02-peer-protocol.md\nindex e377f3f..d6fc760 100644\n--- a/02-peer-protocol.md\n+++ b/02-peer-protocol.md\n@@ -356,6 +356,12 @@ This message introduces the `channel_id` to identify the channel. It's derived f\n \n #### Requirements\n \n+Both peers:\n+  - if `option_static_remotekey` was negotiated:\n+    - `option_static_remotekey` applies to all commitment transactions\n+  - otherwise:\n+    - `option_static_remotekey` does not apply to any commitment transactions\n+\n The sender MUST set:\n   - `channel_id` by exclusive-OR of the `funding_txid` and the `funding_output_index` from the `funding_created` message.\n   - `signature` to the valid signature, using its `funding_pubkey` for the initial commitment transaction, as defined in [BOLT #3](03-transactions.md#commitment-transaction).\n@@ -367,6 +373,12 @@ The recipient:\n   - on receipt of a valid `funding_signed`:\n     - SHOULD broadcast the funding transaction.\n \n+#### Rationale\n+\n+We decide on `option_static_remotekey` at this point when we first have to generate the commitment\n+transaction.  Even if a later reconnection does not negotiate this parameter, this channel will honor it.\n+This simplifies channel state, particularly penalty transaction handling.\n+\n ### The `funding_locked` Message\n \n This message indicates that the funding transaction has reached the `minimum_depth` asked for in `accept_channel`. Once both nodes have sent this, the channel enters normal operating mode.\n@@ -1107,7 +1119,7 @@ messages are), they are independent of requirements here.\n    * [`32`:`channel_id`]\n    * [`8`:`next_local_commitment_number`]\n    * [`8`:`next_remote_revocation_number`]\n-   * [`32`:`your_last_per_commitment_secret`] (option_data_loss_protect)\n+   * [`32`:`your_last_per_commitment_secret`] (option_data_loss_protect option_static_remotekey)\n    * [`33`:`my_current_per_commitment_point`] (option_data_loss_protect)\n \n `next_local_commitment_number`: A commitment number is a 48-bit\n@@ -1156,12 +1168,14 @@ The sending node:\n   next `commitment_signed` it expects to receive.\n   - MUST set `next_remote_revocation_number` to the commitment number of the\n   next `revoke_and_ack` message it expects to receive.\n-  - if it supports `option_data_loss_protect`:\n+  - if it supports `option_data_loss_protect` or `option_static_remotekey`:\n     - if `next_remote_revocation_number` equals 0:\n       - MUST set `your_last_per_commitment_secret` to all zeroes\n     - otherwise:\n       - MUST set `your_last_per_commitment_secret` to the last `per_commitment_secret`\n     it received\n+  - if `option_static_remotekey`` applies to the commitment transaction:\n+\t- MUST NOT include `my_current_per_commitment_point`.\n \n A node:\n   - if `next_local_commitment_number` is 1 in both the `channel_reestablish` it\n@@ -1195,8 +1209,17 @@ A node:\n       - SHOULD fail the channel.\n \n  A receiving node:\n-  - if it supports `option_data_loss_protect`, AND the `option_data_loss_protect`\n-  fields are present:\n+  - if `option_static_remotekey` applies to the commitment transaction:\n+    - if `next_remote_revocation_number` is greater than expected above, AND\n+    `your_last_per_commitment_secret` is correct for that\n+    `next_remote_revocation_number` minus 1:\n+      - MUST NOT broadcast its commitment transaction.\n+      - SHOULD fail the channel.\n+    - otherwise:\n+\t  - if `your_last_per_commitment_secret` does not match the expected values:\n+        - SHOULD fail the channel.\n+  - otherwise, if it supports `option_data_loss_protect`, AND the `option_data_loss_protect`\n+    fields are present:\n     - if `next_remote_revocation_number` is greater than expected above, AND\n     `your_last_per_commitment_secret` is correct for that\n     `next_remote_revocation_number` minus 1:\n@@ -1288,6 +1311,13 @@ is valid. However, this also means the fallen-behind node has revealed this\n fact (though not provably: it could be lying), and the other node could use this to\n broadcast a previous state.\n \n+`option_static_remotekey` removes the changing `to_remote` key,\n+so the `my_current_per_commitment_point` is unnecessary and thus\n+removed, but the disclosure of previous secret still allows\n+fall-behind detection.  An implementation can offer both, however, and\n+fall back to the `option_data_loss_protect` behavior if\n+`option_simplified_commitment` is not negotiated.\n+\n # Authors\n \n [ FIXME: Insert Author List ]\ndiff --git a/03-transactions.md b/03-transactions.md\nindex 087b673..9ff2b05 100644\n--- a/03-transactions.md\n+++ b/03-transactions.md\n@@ -90,6 +90,8 @@ To allow an opportunity for penalty transactions, in case of a revoked commitmen\n The reason for the separate transaction stage for HTLC outputs is so that HTLCs can timeout or be fulfilled even though they are within the `to_self_delay` delay.\n Otherwise, the required minimum timeout on HTLCs is lengthened by this delay, causing longer timeouts for HTLCs traversing the network.\n \n+If `option_static_remotekey` applies to the commitment transaction, then the `to_self_delay` used for all transactions is the greater of the `to_self_delay` sent by each peer.  Otherwise, each peer sends the `to_self_delay` to be used for the other peer's commitment and HTLC transactions.\n+\n The amounts for each output MUST be rounded down to whole satoshis. If this amount, minus the fees for the HTLC transaction, is less than the `dust_limit_satoshis` set by the owner of the commitment transaction, the output MUST NOT be produced (thus the funds add to fees).\n \n #### `to_local` Output\n@@ -117,7 +119,22 @@ If a revoked commitment transaction is published, the other party can spend this\n \n #### `to_remote` Output\n \n-This output sends funds to the other peer and thus is a simple P2WPKH to `remotepubkey`.\n+This output sends funds to the other peer, thus is not encumbered by a\n+revocation private key.\n+\n+If `option_static_remotekey` applies to the commitment transaction, the `to_remote` output is delayed similarly to the `to_local` output, and is to a fixed key:\n+\n+    `to_self_delay`\n+    OP_CSV\n+    OP_DROP\n+    <remote_pubkey>\n+    OP_CHECKSIG\n+\n+The output is spent by a transaction with `nSequence` field set to `to_self_delay` (which can only be valid after that duration has passed) and witness:\n+\n+    <remote_sig>\n+\n+Otherwise, this output is a simple P2WPKH to `remotepubkey`.\n \n #### Offered HTLC Outputs\n \n@@ -316,7 +333,8 @@ Thus, a simplified formula for *expected weight* is used, which assumes:\n \n This yields the following *expected weights* (details of the computation in [Appendix A](#appendix-a-expected-weights)):\n \n-    Commitment weight:   724 + 172 * num-untrimmed-htlc-outputs\n+    Commitment weight (no option_static_remotekey): 724 + 172 * num-untrimmed-htlc-outputs\n+    Commitment weight (option_static_remotekey: 772 + 172 * num-untrimmed-htlc-outputs\n     HTLC-timeout weight: 663\n     HTLC-success weight: 703\n \n@@ -334,14 +352,14 @@ The fee for an HTLC-success transaction:\n \n The base fee for a commitment transaction:\n   - MUST be calculated to match:\n-    1. Start with `weight` = 724.\n+    1. Start with `weight` = 772 (`option_static_remotekey`) or 724.\n     2. For each committed HTLC, if that output is not trimmed as specified in\n     [Trimmed Outputs](#trimmed-outputs), add 172 to `weight`.\n     3. Multiply `feerate_per_kw` by `weight`, divide by 1000 (rounding down).\n \n #### Example\n \n-For example, suppose there is a `feerate_per_kw` of 5000, a `dust_limit_satoshis` of 546 satoshis, and a commitment transaction with:\n+For example, suppose `option_static_remotekey` was not negotiated, and there is a `feerate_per_kw` of 5000, a `dust_limit_satoshis` of 546 satoshis, and a commitment transaction with:\n * two offered HTLCs of 5000000 and 1000000 millisatoshis (5000 and 1000 satoshis)\n * two received HTLCs of 7000000 and 800000 millisatoshis (7000 and 800 satoshis)\n \n@@ -371,9 +389,12 @@ fee (which adds the 1000 and 800 satoshi HTLCs that would make dust\n outputs) is 7140 satoshi. The final fee may be even higher if the\n `to_local` or `to_remote` outputs fall below `dust_limit_satoshis`.\n \n+(If `option_static_remotekey` was negotiated, the weight would be 1116,\n+ and the fee would be 5580 satoshis).\n+\n ### Fee Payment\n \n-Base commitment transaction fees are extracted from the funder's amount; if that amount is insufficient, the entire amount of the funder's output is used.\n+Base commitment transaction fees and amounts for `to_local_pushme` and `to_remote_pushme` outputs are extracted from the funder's amount; if that amount is insufficient, the entire amount of the funder's output is used.\n \n Note that after the fee amount is subtracted from the to-funder output,\n that output may be below `dust_limit_satoshis`, and thus will also\n@@ -411,9 +432,9 @@ committed HTLCs:\n \n ## Key Derivation\n \n-Each commitment transaction uses a unique set of keys: `localpubkey` and `remotepubkey`.\n+Each commitment transaction uses a unique `localpubkey`, and a `remotepubkey`.\n The HTLC-success and HTLC-timeout transactions use `local_delayedpubkey` and `revocationpubkey`.\n-These are changed for every transaction based on the `per_commitment_point`.\n+These are changed for every transaction based on the `per_commitment_point`, with the exception of `remotepubkey` if `option_static_remotekey` is negotiated.\n \n The reason for key change is so that trustless watching for revoked\n transactions can be outsourced. Such a _watcher_ should not be able to\n@@ -426,8 +447,9 @@ avoid storage of every commitment transaction, a _watcher_ can be given the\n the scripts required for the penalty transaction; thus, a _watcher_ need only be\n given (and store) the signatures for each penalty input.\n \n-Changing the `localpubkey` and `remotepubkey` every time ensures that commitment\n-transaction ID cannot be guessed; every commitment transaction uses an ID\n+Changing the `localpubkey` every time ensures that commitment\n+transaction ID cannot be guessed except in the trivial case where there is no\n+`to_local` output, as every commitment transaction uses an ID\n in its output script. Splitting the `local_delayedpubkey`, which is required for\n the penalty transaction, allows it to be shared with the _watcher_ without\n revealing `localpubkey`; even if both peers use the same _watcher_, nothing is revealed.\n@@ -441,14 +463,13 @@ For efficiency, keys are generated from a series of per-commitment secrets\n that are generated from a single seed, which allows the receiver to compactly\n store them (see [below](#efficient-per-commitment-secret-storage)).\n \n-### `localpubkey`, `remotepubkey`, `local_htlcpubkey`, `remote_htlcpubkey`, `local_delayedpubkey`, and `remote_delayedpubkey` Derivation\n+### `localpubkey`, `local_htlcpubkey`, `remote_htlcpubkey`, `local_delayedpubkey`, and `remote_delayedpubkey` Derivation\n \n These pubkeys are simply generated by addition from their base points:\n \n \tpubkey = basepoint + SHA256(per_commitment_point || basepoint) * G\n \n The `localpubkey` uses the local node's `payment_basepoint`;\n-the `remotepubkey` uses the remote node's `payment_basepoint`;\n the `local_htlcpubkey` uses the local node's `htlc_basepoint`;\n the `remote_htlcpubkey` uses the remote node's `htlc_basepoint`;\n the `local_delayedpubkey` uses the local node's `delayed_payment_basepoint`;\n@@ -459,6 +480,19 @@ secrets are known (i.e. the private keys corresponding to `localpubkey`, `local_\n \n     privkey = basepoint_secret + SHA256(per_commitment_point || basepoint)\n \n+### `remotepubkey` Derivation\n+\n+If `option_static_remotekey` is negotiated the `remotepubkey` is simply the\n+remote node's `payment_basepoint`, otherwise it is calculated as above using\n+the remote node's `payment_basepoint`.\n+\n+The simplified derivation means that a node can spend a commitment\n+transaction even if it has lost data and doesn't know the\n+corresponding `payment_basepoint`.  A watchtower could correlate\n+transactions given to it which only have a `to_remote` output if it\n+sees one of them onchain, but such transactions do not need any\n+enforcement and should not be handed to a watchtower.\n+\n ### `revocationpubkey` Derivation\n \n The `revocationpubkey` is a blinded key: when the local node wishes to create a new\n@@ -644,12 +678,17 @@ The *expected weight* of a commitment transaction is calculated as follows:\n \t\t- var_int: 1 byte (pk_script length)\n \t\t- pk_script (p2wsh): 34 bytes\n \n-\toutput_paying_to_remote: 31 bytes\n+\toutput_paying_to_remote (no option_static_remotekey): 31 bytes\n \t\t- value: 8 bytes\n \t\t- var_int: 1 byte (pk_script length)\n \t\t- pk_script (p2wpkh): 22 bytes\n \n-\t htlc_output: 43 bytes\n+\toutput_paying_to_remote (option_static_remotekey): 43 bytes\n+\t\t- value: 8 bytes\n+\t\t- var_int: 1 byte (pk_script length)\n+\t\t- pk_script (p2wsh): 34 bytes\n+\n+\thtlc_output: 43 bytes\n \t\t- value: 8 bytes\n \t\t- var_int: 1 byte (pk_script length)\n \t\t- pk_script (p2wsh): 34 bytes\n@@ -658,7 +697,7 @@ The *expected weight* of a commitment transaction is calculated as follows:\n \t\t- flag: 1 byte\n \t\t- marker: 1 byte\n \n-\t commitment_transaction: 125 + 43 * num-htlc-outputs bytes\n+\t commitment_transaction (no option_static_remotekey): 125 + 43 * num-htlc-outputs bytes\n \t\t- version: 4 bytes\n \t\t- witness_header <---- part of the witness data\n \t\t- count_tx_in: 1 byte\n@@ -671,15 +710,30 @@ The *expected weight* of a commitment transaction is calculated as follows:\n \t\t\t....htlc_output's...\n \t\t- lock_time: 4 bytes\n \n+\t commitment_transaction (option_static_remotekey): 137 + 43 * num-htlc-outputs bytes\n+\t\t- version: 4 bytes\n+\t\t- witness_header <---- part of the witness data\n+\t\t- count_tx_in: 1 byte\n+\t\t- tx_in: 41 bytes\n+\t\t\tfunding_input\n+\t\t- count_tx_out: 1 byte\n+\t\t- tx_out: 86 + 43 * num-htlc-outputs bytes\n+\t\t\toutput_paying_to_remote,\n+\t\t\toutput_paying_to_local,\n+\t\t\t....htlc_output's...\n+\t\t- lock_time: 4 bytes\n+\n Multiplying non-witness data by 4 results in a weight of:\n \n-\t// 500 + 172 * num-htlc-outputs weight\n+\t// 500 + 172 * num-htlc-outputs weight (no option_static_remotekey)\n+\t// 548 + 172 * num-htlc-outputs weight (option_static_remotekey)\n \tcommitment_transaction_weight = 4 * commitment_transaction\n \n \t// 224 weight\n \twitness_weight = witness_header + witness\n \n-\toverall_weight = 500 + 172 * num-htlc-outputs + 224 weight\n+\toverall_weight (no option_static_remotekey) = 500 + 172 * num-htlc-outputs + 224 weight\n+\toverall_weight (option_static_remotekey) = 548 + 172 * num-htlc-outputs + 224 weight\n \n ## Expected Weight of HTLC-timeout and HTLC-success Transactions\n \ndiff --git a/05-onchain.md b/05-onchain.md\nindex bed7d45..a454d05 100644\n--- a/05-onchain.md\n+++ b/05-onchain.md\n@@ -89,21 +89,25 @@ trigger any action.\n # Commitment Transaction\n \n The local and remote nodes each hold a *commitment transaction*. Each of these\n-commitment transactions has four types of outputs:\n+commitment transactions has six types of outputs:\n \n 1. _local node's main output_: Zero or one output, to pay to the *local node's*\n-commitment pubkey.\n+delayed pubkey.\n 2. _remote node's main output_: Zero or one output, to pay to the *remote node's*\n-commitment pubkey.\n+pubkey.\n 3. _local node's offered HTLCs_: Zero or more pending payments (*HTLCs*), to pay\n the *remote node* in return for a payment preimage.\n 4. _remote node's offered HTLCs_: Zero or more pending payments (*HTLCs*), to\n pay the *local node* in return for a payment preimage.\n \n To incentivize the local and remote nodes to cooperate, an `OP_CHECKSEQUENCEVERIFY`\n-relative timeout encumbers the *local node's outputs* (in the *local node's\n+relative timeout encumbers some outputs: the *local node's outputs* (in the *local node's\n commitment transaction*) and the *remote node's outputs* (in the *remote node's\n-commitment transaction*). So for example, if the local node publishes its\n+commitment transaction*). If `option_static_remotekey` applies\n+to the commitment transaction, then the *to_remote* output of each commitment is\n+identically encumbered, for fairness.\n+\n+Without `option_static_remotekey`, if the local node publishes its\n commitment transaction, it will have to wait to claim its own funds,\n whereas the remote node will have immediate access to its own funds. As a\n consequence, the two commitment transactions are not identical, but they are\ndiff --git a/09-features.md b/09-features.md\nindex d06fcff..5e62127 100644\n--- a/09-features.md\n+++ b/09-features.md\n@@ -26,6 +26,7 @@ These flags may only be used in the `init` message:\n | 3  | `initial_routing_sync` | Indicates that the sending node needs a complete routing information dump | [BOLT #7](07-routing-gossip.md#initial-sync) |\n | 4/5  | `option_upfront_shutdown_script` | Commits to a shutdown scriptpubkey when opening channel | [BOLT #2](02-peer-protocol.md#the-open_channel-message) |\n | 6/7  | `gossip_queries`           | More sophisticated gossip control | [BOLT #7](07-routing-gossip.md#query-messages) |\n+| 38/39| `option_static_remotekey`   | Static key for remote output, symmetric delays | [BOLT #3](03-transactions.md) |\n \n ## Assigned `globalfeatures` flags"
            }
        ],
        "thread_summary": {
            "title": "option_static_remotekey",
            "categories": [
                "Lightning-dev",
                "RFC"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 18323
        }
    },
    {
        "title": "[Lightning-dev] Potential Privacy issue with dual funded channels",
        "thread_messages": [
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2019-03-15T15:29:10",
                "message_text_only": "Hey everyone,\n\nduring the spec meeting we have discussed intensively about dual funded\nchannels and potential game theory with the fees however I now believe that\nwe missed out another important crucial part which is the privacy of the\nnode providing liquidity.\n\nWhile I have not seen a concrete example for a channel establishment\nprotocol that supports dual funded channels I have seen this proposal (\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001532.html\n)  for advertising channel liquidity which assumed that the `open_channel`\nmessage would be modified as follows:\n\n`open_channel`:\nnew feature flag (channel_flags): option_liquidity_buy [2nd least\nsignificant bit]\npush_msat: set to fee payment for requested liquidity\n[8 liquidity_msat_request]: (option_liquidity_buy) amount of dual funding\nrequested at channel open\n\n...\n\nIf a node cannot provide the liquidity requested in `open_channel`, it must\nreturn an error.\n\nWith such a protocol I could now (basically only at the cost of internet\ntraffic) probe a lower bound for the amount of BTC available by a node that\nallows for dual funded channels and abort the channel establishing process\nat some time before I ever spend / lock any of my own bitcoin.\n\nAs I can even participate in the peer protocol without having a single\nchannel open this situation seems to be even more severe.\n\nI don't have a clear suggestion how to mitigate against this. One general\npotential idea / solution would be to make spamming / probing more\nexpensive. For example we could require the person to open a channel first\nand then ask the partner to splice something in (meaning we don't allow for\none tx dual funded channels). In that case the node requesting liquidity\nhad to do an onchain tx. also the requests to splice in can be identified\nand the person who feels to be probed can choose to fail the channel. I am\nnot happy with my barrier as it would still be able to relatively cheaply\nabuse this and we run into a whole bunch of game theory about fees again.\n\nAs the lightning network seems very keen to provide strong privacy to its\nusers (c.f.: onion routing, keeping channel balances private, encrypted\ntransport layer,...)  I thought it is worthwhile pointing out the problem\nwith the privacy for dual funded channels even though I don't have a\nconcrete solution yet.\n\nbest Rene\n\n\n-- \nhttps://www.rene-pickhardt.de\n\nSkype: rene.pickhardt\n\nmobile: +49 (0)176 5762 3618\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190315/6ff1782a/attachment.html>"
            },
            {
                "author": "lisa neigut",
                "date": "2019-03-15T16:29:42",
                "message_text_only": "Hello Rene,\n\nThis is a legitimate concern. Thank you for raising it.\n\nI have three suggestions for how to mitigate this. The first is to return a\nnon-specific error message which, while in the aggregate might be used to\napproximate a nodes\u2019 uncommitted  balance, would at least offer plausible\ndeniability to the exact cause for the failure.\n\nThe second proposal is in a similar vein. A node might add a privately held\nrandomization vector, which would return an error to any open channel\nrequest with probability p. Thus an attacker wishing to ascertain a nodes\nbalance would not know with any certainty if the request they sent failed\nbecause of a lack of available liquidity or for some other non-related\nreason.\n\nFinally, and perhaps most compellingly, rather than return an error, the\nopen channel should  always succeed, but for any value at or below the\nrequested liquidity amount. The opening channel balance agreed upon between\nthe two nodes would then be adjusted to reflect the \u201ccorrect\u201d amount of\npush_msat for the actual amount of funding_satoshi contributed by the\naccepter (i.e. zero if the accepter node sends accept_channel2 with a\nfunding_satoshi balance of zero). If the amount of liquidity offered up by\nthe accepter is unacceptable to the opener, then they may choose to fail\nthe channel opening negotiation.\n\nThis third proposal, combined with a randomization vector (i.e with\nprobability p you always offer an amount less than the proposed amount)\nwould remove some of the certainty around a nodes unconfirmed balance. As\nwith channel balances, however, there is always the possibility of a\nprobabilistic attack i.e. lots of open channel requests sent over a short\nperiod of time that would give an attacker a reasonable approximation of\nyour nodes available balance. A node could mitigate this by including an\nexponential backoff for open channel requests from any one node,\nessentially rate limiting the number of open channel requests that it will\naccept from a single peer, or peers globally.\n\nA node may also choose to set a policy around what it considers reasonable\nliquidity requests from a peer (i.e. no more than 0.05 BTC from any peer),\nwhich would further limit their exposure on the upper end of information\ngathering.\n\nFinally, as this liquidity feature is optional, any node who is truly\ninterested in preserving the privacy of their funds may continue to\nestablish channels the old fashioned way, i.e. via out of band negotiation\nwith other, trusted node operators.\n\nCheers,\nLisa\n\n\n\n\n\nOn Fri, Mar 15, 2019 at 08:29 Ren\u00e9 Pickhardt via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Hey everyone,\n>\n> during the spec meeting we have discussed intensively about dual funded\n> channels and potential game theory with the fees however I now believe that\n> we missed out another important crucial part which is the privacy of the\n> node providing liquidity.\n>\n> While I have not seen a concrete example for a channel establishment\n> protocol that supports dual funded channels I have seen this proposal (\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001532.html\n> )  for advertising channel liquidity which assumed that the `open_channel`\n> message would be modified as follows:\n>\n> `open_channel`:\n> new feature flag (channel_flags): option_liquidity_buy [2nd least\n> significant bit]\n> push_msat: set to fee payment for requested liquidity\n> [8 liquidity_msat_request]: (option_liquidity_buy) amount of dual funding\n> requested at channel open\n>\n> ...\n>\n> If a node cannot provide the liquidity requested in `open_channel`, it must\n> return an error.\n>\n> With such a protocol I could now (basically only at the cost of internet\n> traffic) probe a lower bound for the amount of BTC available by a node that\n> allows for dual funded channels and abort the channel establishing process\n> at some time before I ever spend / lock any of my own bitcoin.\n>\n> As I can even participate in the peer protocol without having a single\n> channel open this situation seems to be even more severe.\n>\n> I don't have a clear suggestion how to mitigate against this. One general\n> potential idea / solution would be to make spamming / probing more\n> expensive. For example we could require the person to open a channel first\n> and then ask the partner to splice something in (meaning we don't allow for\n> one tx dual funded channels). In that case the node requesting liquidity\n> had to do an onchain tx. also the requests to splice in can be identified\n> and the person who feels to be probed can choose to fail the channel. I am\n> not happy with my barrier as it would still be able to relatively cheaply\n> abuse this and we run into a whole bunch of game theory about fees again.\n>\n> As the lightning network seems very keen to provide strong privacy to its\n> users (c.f.: onion routing, keeping channel balances private, encrypted\n> transport layer,...)  I thought it is worthwhile pointing out the problem\n> with the privacy for dual funded channels even though I don't have a\n> concrete solution yet.\n>\n> best Rene\n>\n>\n> --\n> https://www.rene-pickhardt.de\n>\n> Skype: rene.pickhardt\n>\n> mobile: +49 (0)176 5762 3618\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190315/29fea470/attachment-0001.html>"
            },
            {
                "author": "Omar Shibli",
                "date": "2019-03-15T19:55:02",
                "message_text_only": "Hello Rene,\n\nSorry for hijacking this thread, but I would suggest another route to\ntackle privacy and liquidity issues in general.\n\nAt the moment, it seems that there are no taking advantage of off-chain\nsettlement protocols, the idea is based on Schnorr signatures. The general\ntheme is build programable multi sig contracts based on aggregation of\nsignatures.\n\nIt's very powerful, and simple model, that will allow variety of\nfunding combinations.\n\nThe general diagram:\n\nN inputs -> M outputs , N = a1s1 + a2s2 ... , M = b1s2 + b2s2\n... (simplified incomplete formulas for clarity)\n\na1 - input amount , s1 - signature.. same to b1, b2....\n\nThe main advantage of this communication method that all transactions could\nbe done offline with trusted Oracle, optionally all data could be blinded\nfrom oracle PoV for optimal privacy and maximal effect principle of least\nauthority through minimal visibility to third party participants.\n\nRegards,\nOmar\n\n\n\n\n\n\n\n\n\nOn Fri, Mar 15, 2019 at 6:29 PM lisa neigut <niftynei at gmail.com> wrote:\n\n> Hello Rene,\n>\n> This is a legitimate concern. Thank you for raising it.\n>\n> I have three suggestions for how to mitigate this. The first is to return\n> a non-specific error message which, while in the aggregate might be used to\n> approximate a nodes\u2019 uncommitted  balance, would at least offer plausible\n> deniability to the exact cause for the failure.\n>\n> The second proposal is in a similar vein. A node might add a privately\n> held randomization vector, which would return an error to any open channel\n> request with probability p. Thus an attacker wishing to ascertain a nodes\n> balance would not know with any certainty if the request they sent failed\n> because of a lack of available liquidity or for some other non-related\n> reason.\n>\n> Finally, and perhaps most compellingly, rather than return an error, the\n> open channel should  always succeed, but for any value at or below the\n> requested liquidity amount. The opening channel balance agreed upon between\n> the two nodes would then be adjusted to reflect the \u201ccorrect\u201d amount of\n> push_msat for the actual amount of funding_satoshi contributed by the\n> accepter (i.e. zero if the accepter node sends accept_channel2 with a\n> funding_satoshi balance of zero). If the amount of liquidity offered up by\n> the accepter is unacceptable to the opener, then they may choose to fail\n> the channel opening negotiation.\n>\n> This third proposal, combined with a randomization vector (i.e with\n> probability p you always offer an amount less than the proposed amount)\n> would remove some of the certainty around a nodes unconfirmed balance. As\n> with channel balances, however, there is always the possibility of a\n> probabilistic attack i.e. lots of open channel requests sent over a short\n> period of time that would give an attacker a reasonable approximation of\n> your nodes available balance. A node could mitigate this by including an\n> exponential backoff for open channel requests from any one node,\n> essentially rate limiting the number of open channel requests that it will\n> accept from a single peer, or peers globally.\n>\n> A node may also choose to set a policy around what it considers reasonable\n> liquidity requests from a peer (i.e. no more than 0.05 BTC from any peer),\n> which would further limit their exposure on the upper end of information\n> gathering.\n>\n> Finally, as this liquidity feature is optional, any node who is truly\n> interested in preserving the privacy of their funds may continue to\n> establish channels the old fashioned way, i.e. via out of band negotiation\n> with other, trusted node operators.\n>\n> Cheers,\n> Lisa\n>\n>\n>\n>\n>\n> On Fri, Mar 15, 2019 at 08:29 Ren\u00e9 Pickhardt via Lightning-dev <\n> lightning-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hey everyone,\n>>\n>> during the spec meeting we have discussed intensively about dual funded\n>> channels and potential game theory with the fees however I now believe that\n>> we missed out another important crucial part which is the privacy of the\n>> node providing liquidity.\n>>\n>> While I have not seen a concrete example for a channel establishment\n>> protocol that supports dual funded channels I have seen this proposal (\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-November/001532.html\n>> )  for advertising channel liquidity which assumed that the `open_channel`\n>> message would be modified as follows:\n>>\n>> `open_channel`:\n>> new feature flag (channel_flags): option_liquidity_buy [2nd least\n>> significant bit]\n>> push_msat: set to fee payment for requested liquidity\n>> [8 liquidity_msat_request]: (option_liquidity_buy) amount of dual funding\n>> requested at channel open\n>>\n>> ...\n>>\n>> If a node cannot provide the liquidity requested in `open_channel`, it must\n>> return an error.\n>>\n>> With such a protocol I could now (basically only at the cost of internet\n>> traffic) probe a lower bound for the amount of BTC available by a node that\n>> allows for dual funded channels and abort the channel establishing process\n>> at some time before I ever spend / lock any of my own bitcoin.\n>>\n>> As I can even participate in the peer protocol without having a single\n>> channel open this situation seems to be even more severe.\n>>\n>> I don't have a clear suggestion how to mitigate against this. One general\n>> potential idea / solution would be to make spamming / probing more\n>> expensive. For example we could require the person to open a channel first\n>> and then ask the partner to splice something in (meaning we don't allow for\n>> one tx dual funded channels). In that case the node requesting liquidity\n>> had to do an onchain tx. also the requests to splice in can be identified\n>> and the person who feels to be probed can choose to fail the channel. I am\n>> not happy with my barrier as it would still be able to relatively cheaply\n>> abuse this and we run into a whole bunch of game theory about fees again.\n>>\n>> As the lightning network seems very keen to provide strong privacy to its\n>> users (c.f.: onion routing, keeping channel balances private, encrypted\n>> transport layer,...)  I thought it is worthwhile pointing out the problem\n>> with the privacy for dual funded channels even though I don't have a\n>> concrete solution yet.\n>>\n>> best Rene\n>>\n>>\n>> --\n>> https://www.rene-pickhardt.de\n>>\n>> Skype: rene.pickhardt\n>>\n>> mobile: +49 (0)176 5762 3618\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190315/8761f6a8/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Potential Privacy issue with dual funded channels",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "lisa neigut",
                "Ren\u00e9 Pickhardt",
                "Omar Shibli"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 15159
        }
    },
    {
        "title": "[Lightning-dev] [META] Mailing list move",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2019-03-16T04:45:55",
                "message_text_only": "Hi all,\n\n        Linux Foundation (who graciously host this list for us) is\ndeprecating their mailing list infrastructure (mailman2 is unmaintained,\napparently v3 is a mess), and migrating lists to groups.io.  Apparently\nthis is the direction that bitcoin-dev is heading.\n\nUnless people raise concerns, I expect this list to follow, within the\nweek.  If you want to unsubscribe before then, please do so.\n\nCheers,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-18T07:23:07",
                "message_text_only": "Is there anything I need to do if I want to remain on lightning-dev?\nOr is this automatic as long as I do not unsubscribe?\n\nRegards,\nZmnSCPxj\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Saturday, March 16, 2019 12:45 PM, Rusty Russell <rusty at blockstream.com> wrote:\n\n> Hi all,\n>\n> Linux Foundation (who graciously host this list for us) is\n> deprecating their mailing list infrastructure (mailman2 is unmaintained,\n> apparently v3 is a mess), and migrating lists to groups.io. Apparently\n> this is the direction that bitcoin-dev is heading.\n>\n> Unless people raise concerns, I expect this list to follow, within the\n> week. If you want to unsubscribe before then, please do so.\n>\n> Cheers,\n> Rusty.\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Omar Shibli",
                "date": "2019-03-18T17:11:48",
                "message_text_only": "So what to do? I registered there, how to stay subscribed to both mailing\nlists, please.\n\nOn Mon, Mar 18, 2019 at 9:23 AM ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Is there anything I need to do if I want to remain on lightning-dev?\n> Or is this automatic as long as I do not unsubscribe?\n>\n> Regards,\n> ZmnSCPxj\n>\n> Sent with ProtonMail Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Saturday, March 16, 2019 12:45 PM, Rusty Russell <rusty at blockstream.com>\n> wrote:\n>\n> > Hi all,\n> >\n> > Linux Foundation (who graciously host this list for us) is\n> > deprecating their mailing list infrastructure (mailman2 is unmaintained,\n> > apparently v3 is a mess), and migrating lists to groups.io. Apparently\n> > this is the direction that bitcoin-dev is heading.\n> >\n> > Unless people raise concerns, I expect this list to follow, within the\n> > week. If you want to unsubscribe before then, please do so.\n> >\n> > Cheers,\n> > Rusty.\n> >\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190318/fefd5a76/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2019-03-18T22:18:35",
                "message_text_only": "Yes, you shouldn't notice anything, and don't need to do anything.\n\nCheers,\nRusty.\n\nOn Mon, Mar 18, 2019, 17:53 ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Is there anything I need to do if I want to remain on lightning-dev?\n> Or is this automatic as long as I do not unsubscribe?\n>\n> Regards,\n> ZmnSCPxj\n>\n> Sent with ProtonMail Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Saturday, March 16, 2019 12:45 PM, Rusty Russell <rusty at blockstream.com>\n> wrote:\n>\n> > Hi all,\n> >\n> > Linux Foundation (who graciously host this list for us) is\n> > deprecating their mailing list infrastructure (mailman2 is unmaintained,\n> > apparently v3 is a mess), and migrating lists to groups.io. Apparently\n> > this is the direction that bitcoin-dev is heading.\n> >\n> > Unless people raise concerns, I expect this list to follow, within the\n> > week. If you want to unsubscribe before then, please do so.\n> >\n> > Cheers,\n> > Rusty.\n> >\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190319/1667a404/attachment.html>"
            },
            {
                "author": "Omar Shibli",
                "date": "2019-03-20T05:57:51",
                "message_text_only": "Cool cool.\n\nBest,\nOmar\n\nOn Tue, Mar 19, 2019 at 4:57 AM Rusty Russell <rusty at blockstream.io> wrote:\n\n> Yes, you shouldn't notice anything, and don't need to do anything.\n>\n> Cheers,\n> Rusty.\n>\n> On Mon, Mar 18, 2019, 17:53 ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n>> Is there anything I need to do if I want to remain on lightning-dev?\n>> Or is this automatic as long as I do not unsubscribe?\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>> Sent with ProtonMail Secure Email.\n>>\n>> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>> On Saturday, March 16, 2019 12:45 PM, Rusty Russell <\n>> rusty at blockstream.com> wrote:\n>>\n>> > Hi all,\n>> >\n>> > Linux Foundation (who graciously host this list for us) is\n>> > deprecating their mailing list infrastructure (mailman2 is unmaintained,\n>> > apparently v3 is a mess), and migrating lists to groups.io. Apparently\n>> > this is the direction that bitcoin-dev is heading.\n>> >\n>> > Unless people raise concerns, I expect this list to follow, within the\n>> > week. If you want to unsubscribe before then, please do so.\n>> >\n>> > Cheers,\n>> > Rusty.\n>> >\n>> > Lightning-dev mailing list\n>> > Lightning-dev at lists.linuxfoundation.org\n>> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>>\n>> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190320/6f60868d/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Mailing list move",
            "categories": [
                "Lightning-dev",
                "META"
            ],
            "authors": [
                "Rusty Russell",
                "Omar Shibli",
                "ZmnSCPxj"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 5689
        }
    },
    {
        "title": "[Lightning-dev] I just released more than 200 slides trying to give an Overview of BOLT 1.0 for beginners. Feedback welcome!",
        "thread_messages": [
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2019-03-20T19:12:02",
                "message_text_only": "Hey everyone,\n\nas you know I am just a mathematician and not a cryptographer by training\nwho is interested and amazed by the Lightning Network Protocol. I joined\nthis open source effort pretty late (in the beginning of 2018) and tried to\ncatch up ever since. At that time reading the BOLTs (despite the fact that\nRusty had his helpful blog articles) was really hard for me.\n\nOver the past year - especially due to your help and open ears - I was able\nto catch up by a lot. Yesterday I held a 4 hour workshop giving an\nextensive overview about the Lightning Network and BOLT 1.0.\n\nI decided to open source the slides to give something (hopefully useful)\nback to the community. To the best of my knowledge this is the most\nextensive overview of the BOLTs in form of slides and I also tried to\nrestructure the content in the hope of making it easier to approach fo\nnewbies like I was a year ago.\n\nPlease feel free to fork the slides on the google doc address:\nhttps://docs.google.com/presentation/d/1-eyceLlSmcLpbPJLzj6_CnVYQdo1AUP3y5XD716U-Lg\n\nI uploaded the pdf version of the slides at\nhttps://commons.wikimedia.org/wiki/File:Introduction_to_the_Lightning_Network_Protocol_and_the_Basics_of_Lightning_Technology_(BOLT_aka_Lightning-rfc).pdf\n\nObviously I am very happy if you have suggestions how the slides could be\nimproved even further. Probably I will still have some mistakes with them.\nBut maybe you have more comments on a meta level about the structure or\ndetail level or visualizations...\n\nTherefor I will be happy if you send back a pdf with comments. I also share\na commentable version with this mailinglist on google docs:\nhttps://docs.google.com/presentation/d/1YCKZzE53xjnBndl3U0uy1-bHO4Y0rlAwgrnujzef1sY\n\n\nI will present the slides next time on chaincodelabs lightning residency in\nlate june where - as far as I know - the talks will also be recorded. So\nany feedback before then will be highly appreciated.\n\nWhile this mail was note particularly about development I hope it is not\nconsidered offtopic. In case you do so I apologize for any inconvenience.\n\nWith kind Regards Rene\n\n\n-- \nhttps://www.rene-pickhardt.de\n\nSkype: rene.pickhardt\n\nmobile: +49 (0)176 5762 3618\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190320/7817d7be/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "I just released more than 200 slides trying to give an Overview of BOLT 1.0 for beginners. Feedback welcome!",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Ren\u00e9 Pickhardt"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2367
        }
    },
    {
        "title": "[Lightning-dev] Outsourcing route computation with trampoline payments",
        "thread_messages": [
            {
                "author": "Pierre",
                "date": "2019-03-28T22:24:46",
                "message_text_only": "Hello List,\n\nI think we can use the upcoming \"Multi-frame sphinx onion format\" [1]\nto trustlessly outsource the computation of payment routes.\n\nA sends a payment to an intermediate node N, and in the onion payload,\nA provides the actual destination D of the payment and the amount. N\nthen has to find a route to D and make a payment himself. Of course D\nmay be yet another intermediate node, and so on. The fact that we can\nmake several \"trampoline hops\" preserves the privacy characteristics\nthat we already have.\n\nIntermediate nodes have an incentive to cooperate because they are\npart of the route and will earn fees. As a nice side effect, it also\ncreates an incentive for \"routing nodes\" to participate in the gossip,\nwhich they are lacking currently.\n\nThis could significantly lessen the load on (lite) sending nodes both\non the memory/bandwidth side (they would only need to know a smallish\nneighborhood) and on the cpu side (intermediate nodes would run the\nactual route computation).\n\nAs Christian pointed out, one downside is that fee computation would\nhave to be pessimistic (he also came up with the name trampoline!).\n\nCheers,\n\nPierre-Marie\n\n[1] https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-February/001875.html"
            },
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2019-03-29T05:36:36",
                "message_text_only": "Dear Pierre-Marie and fellow lightning developers,\n\nI really like that suggestion. In the context of JIT routing I was\ntinkering about the same idea (is it possible for sending nodes to only\nknow a small part of the network - for example the friend of a friend\nnetwork - to save Hardware / gossip bandwidth requirements) but I was\nthinking about a different solution which I want to drop in here. (I\nbelieve yours is better though)\n\nMy thought was to use rendez-vous routing. This would mean the sender would\nhave to provide a rendez vous point from his local (friend of a friend?)\nnetwork and the recipient provides a route to him/herself. Only the\nrecipient has to know the entire network topology.\n\nOne problem with rendez vous routing is of course that the routing fails if\nthe route from the rendez vous point does not work. This again could be\nmitigated with JIT routing.\n\nIn the context of JIT routing it also makes sense to \"overpay\" fees so that\nJIT nodes could rebalance without loss. Making my solution also\nprobabilistic with the fees. The fact that this pattern of probabilistic\nfees occurs for the second time now leads me to the following 2 more\ngeneral ideas (maybe we should start a new thread if we discuss them to\nstay on topic here) that might help with routing.\n\n1.) A different fee mechanism. Let us (only as a radical thought\nexperiment) assume we drop the privacy of the final amount in routing. A\nsending node could offer a fee for successful routing. Every routing node\ncould decide how much fee it would collect for forwarding. Nodes could try\nto collect larger fees than the min they announce but that lowers the\nprobably for the payment to be successful. Even more radical: Nodes would\nnot even have to announce min fees anymore. Turning routing and fees to a\nreal interactive market\n\n2.) A virtual hierarchical address space. Maybe we should start thinking\nabout the creation of a semantic overlynetwork / address space for nodes\nsimilar to IP. This would allow any node to just have a pruned network view\nbut still make smart routing decisions. Obviously we would have to find a\nway to assign virtual network addresses to nodes which might be hard.\n\nThe second suggestion would be of particular interest in your case if N\nalso did not know the entire network and has to decide to whom to to\nforward for the final destination D.\n\nSorry for \"hijacking\" your suggestion and throwing so many new ideas but in\nmy mind this seems all very connected /related.\n\nBest Rene\n\n\nPierre <pm+lists at acinq.fr> schrieb am Do., 28. M\u00e4rz 2019, 23:25:\n\n> Hello List,\n>\n> I think we can use the upcoming \"Multi-frame sphinx onion format\" [1]\n> to trustlessly outsource the computation of payment routes.\n>\n> A sends a payment to an intermediate node N, and in the onion payload,\n> A provides the actual destination D of the payment and the amount. N\n> then has to find a route to D and make a payment himself. Of course D\n> may be yet another intermediate node, and so on. The fact that we can\n> make several \"trampoline hops\" preserves the privacy characteristics\n> that we already have.\n>\n> Intermediate nodes have an incentive to cooperate because they are\n> part of the route and will earn fees. As a nice side effect, it also\n> creates an incentive for \"routing nodes\" to participate in the gossip,\n> which they are lacking currently.\n>\n> This could significantly lessen the load on (lite) sending nodes both\n> on the memory/bandwidth side (they would only need to know a smallish\n> neighborhood) and on the cpu side (intermediate nodes would run the\n> actual route computation).\n>\n> As Christian pointed out, one downside is that fee computation would\n> have to be pessimistic (he also came up with the name trampoline!).\n>\n> Cheers,\n>\n> Pierre-Marie\n>\n> [1]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-February/001875.html\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190329/b604fc57/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Outsourcing route computation with trampoline payments",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Ren\u00e9 Pickhardt",
                "Pierre"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 5482
        }
    },
    {
        "title": "[Lightning-dev] Routemap scaling (was: Just in Time Routing (JIT-Routing) and a channel rebalancing heuristic as an add on for improved routing success in BOLT 1.0)",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-29T04:51:23",
                "message_text_only": "Good morning Ariel,\n\nI am forking this thread as my reply is not at all related to the JIT-Routing.\n\n\nSent with ProtonMail Secure Email.\n\n> Public nodes could advertise channels which don't actually exist directly but are instead hidden paths that the source node doesn't need to know or care about. The fees advertised for these aggregate-channels would be the aggregate fees expected from the sub-route.\n\nNonexistent channels (i.e. channels that do not have some backing UTXO in the Bitcoin blockchain) are not safe to propagate on the network since they are trivially spammable (i.e. can generate a large number of fake channels to waste network bandwidth).\n\n> I think the biggest gain from this system is that the network can be more abstract. This abstraction allows all possible subsets of public nodes to be a clique since all subsets of nodes can be maximally connected with aggregate-channels as long as the entire network is well connected.\n> This new property of the network could allow a source node to select a random privacy-clique and rely on payments to be routed along aggregate-channels without the source node needing to compute or even know the exact sub-routes. Futhermore, the source node could exclusively download and listen to the privacy-clique and ignore the rest of the network structure thus reducing the burden of keeping up to date network information.\n\nLet me suggest something else.\n\nAs the LN grows, the public routemap becomes larger and larger, until keeping them in a fast in-memory data structure becomes infeasible on cheap hardware.\nIn all likelihood, at some point in the future, users will want to be able to limit the memory consumed by implementations for routemaps.\n\nSo, some pruning heuristic is needed, to reduce the resource usage of large routemaps.\n\nA good pruning heuristic is \"channel capacity\", which can be checked onchain (the value of the UTXO backing the channel is the channel capacity).\nIt is good to keep channels with large capacity in the routemap, because such large channels are more likely to successfully route a payment than smaller channels.\nSo it is reasonable to delete channels with low capacity when the routemap memory is becoming close to full.\n\nIt seems to me that s/aggregate-channel/high-capacity-channel/g in your idea would still work.\nIn effect, the high-capacity channel is very likely to successfully route in either direction.\nBut if by chance it falls into a state where it is unable to route in one direction or other, the intermediate node has other, lower-capacity channels that it can use JIT-Routing with to improve the directionality of the high-capacity channel.\nNothing in the JIT-Routing idea requires that the rebalancing loop is small, only that a loop exists.\n\nNodes still need to track their direct channels (so they are implicitly always in the routemap).\nBut payee nodes making BOLT1 invoices could also provide `r` routes in the invoice, with the given routes being from nodes with high-capacity channels, so that even if the intermediate channels are pruned due to low capacity, it is possible to get paid.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2019-03-29T05:54:01",
                "message_text_only": "Dear ZmnSCPxj and fellow lightning developers,\n\nI want to point out two things and make a suggestion for a new gossip\nmessage.\n\nA good pruning heuristic is \"channel capacity\", which can be checked\n> onchain (the value of the UTXO backing the channel is the channel capacity).\n> It is good to keep channels with large capacity in the routemap, because\n> such large channels are more likely to successfully route a payment than\n> smaller channels.\n> So it is reasonable to delete channels with low capacity when the routemap\n> memory is becoming close to full.\n>\n\nIntuitively (without simulation). I encourage to make that process not\ndeerministic but rather probabilistic. It would be good if everyone had a\ndifferent set of channels. (which is somewhat achieved with everyone\nkeeping their local view)\n\nNodes still need to track their direct channels (so they are implicitly\n> always in the routemap).\n>\n\nI strongly advice that the local view should be extended. Every node should\nalways track their friends of a friend network. Maybe we could even create\na new gossip query message `query_ask_egonetwork` that asks for the\negonetwork of a node (the egonetwork are all the direct friends of a node\ntogether with their friendships) every node knows at least the nodes in\ntheir ego network and over time also the edges between them.\n\nIf I was interested in my friend of a friend network I could just send the\n`query_ask_egonetwork` message to all my peers.\n\nBest Rene\n\n\n\n\n\n\nBut payee nodes making BOLT1 invoices could also provide `r` routes in the\n> invoice, with the given routes being from nodes with high-capacity\n> channels, so that even if the intermediate channels are pruned due to low\n> capacity, it is possible to get paid.\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190329/33d0bd13/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-03-29T08:47:15",
                "message_text_only": "Good morning Rene,\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Friday, March 29, 2019 1:54 PM, Ren\u00e9 Pickhardt <r.pickhardt at googlemail.com> wrote:\n\n> Dear ZmnSCPxj and fellow lightning developers,\n>\n> I want to point out two things and make a suggestion for a new gossip message.\u00a0\n>\n> > A good pruning heuristic is \"channel capacity\", which can be checked onchain (the value of the UTXO backing the channel is the channel capacity).\n> > It is good to keep channels with large capacity in the routemap, because such large channels are more likely to successfully route a payment than smaller channels.\n> > So it is reasonable to delete channels with low capacity when the routemap memory is becoming close to full.\n>\n> Intuitively (without simulation). I encourage to make that process not deerministic but rather probabilistic. It would be good if everyone had a different set of channels. (which is somewhat achieved with everyone keeping their local view)\u00a0\n\nAt a software engineer point-of-view, probabilistic can be difficult to test.\nThis can be made deterministic by including an RNG seed in the input to this code.\n\nHowever, let me propose instead, in combination with your later thought:\n\n>\n> > Nodes still need to track their direct channels (so they are implicitly always in the routemap).\n>\n> I strongly advice that the local view should be extended. Every node should always track their friends of a friend network.\n\nPerhaps the pruning rule can be modified to include *distance from self* in addition to channel capacity.\nThe nearer the channel is, the more likely it is retained.\nThe further, the less likely.\nThe larger the channel is, the more likely it is retained.\nThe smaller, the less likely.\n\nThe capacity divided by the distance can be used as a sorting key, and if pruning is needed, the smallest \"score\" is pruned until the routemap fits.\n\nThis will lead to everyone having a different set of channels, while being likely to track their friend-of-friend network compared to more distant nodes.\n\nOf course, the pruning itself would affect the distance of the channel to the \"self\" node.\nSo determinism may be difficult to achieve here anyway.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2019-03-29T09:18:11",
                "message_text_only": "Good morning ZmnSCPxj,\n\nMaybe I oversee something - in that case sorry for spamming the list - but\nI don't understand how you could know the distance from yourself if you\ndon't know the entire topology? (unless u use it on the pruned view as you\nsuggested)\n\nOn the other hand querying for a certain depth would be possible with the\nsuggested `query ask egonetwork` in case for depth 3 one would have to peer\nwith the nodes from the friend of a friend network.\n\nBest Rene\n\n\nZmnSCPxj <ZmnSCPxj at protonmail.com> schrieb am Fr., 29. M\u00e4rz 2019, 09:47:\n\n> Good morning Rene,\n>\n>\n> Sent with ProtonMail Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Friday, March 29, 2019 1:54 PM, Ren\u00e9 Pickhardt <\n> r.pickhardt at googlemail.com> wrote:\n>\n> > Dear ZmnSCPxj and fellow lightning developers,\n> >\n> > I want to point out two things and make a suggestion for a new gossip\n> message.\n> >\n> > > A good pruning heuristic is \"channel capacity\", which can be checked\n> onchain (the value of the UTXO backing the channel is the channel capacity).\n> > > It is good to keep channels with large capacity in the routemap,\n> because such large channels are more likely to successfully route a payment\n> than smaller channels.\n> > > So it is reasonable to delete channels with low capacity when the\n> routemap memory is becoming close to full.\n> >\n> > Intuitively (without simulation). I encourage to make that process not\n> deerministic but rather probabilistic. It would be good if everyone had a\n> different set of channels. (which is somewhat achieved with everyone\n> keeping their local view)\n>\n> At a software engineer point-of-view, probabilistic can be difficult to\n> test.\n> This can be made deterministic by including an RNG seed in the input to\n> this code.\n>\n> However, let me propose instead, in combination with your later thought:\n>\n> >\n> > > Nodes still need to track their direct channels (so they are\n> implicitly always in the routemap).\n> >\n> > I strongly advice that the local view should be extended. Every node\n> should always track their friends of a friend network.\n>\n> Perhaps the pruning rule can be modified to include *distance from self*\n> in addition to channel capacity.\n> The nearer the channel is, the more likely it is retained.\n> The further, the less likely.\n> The larger the channel is, the more likely it is retained.\n> The smaller, the less likely.\n>\n> The capacity divided by the distance can be used as a sorting key, and if\n> pruning is needed, the smallest \"score\" is pruned until the routemap fits.\n>\n> This will lead to everyone having a different set of channels, while being\n> likely to track their friend-of-friend network compared to more distant\n> nodes.\n>\n> Of course, the pruning itself would affect the distance of the channel to\n> the \"self\" node.\n> So determinism may be difficult to achieve here anyway.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190329/54ccc4a4/attachment.html>"
            },
            {
                "author": "Ariel Luaces",
                "date": "2019-03-29T14:21:12",
                "message_text_only": "> I am forking this thread as my reply is not at all related to the JIT-Routing.\n\nSorry I think my last reply was also getting off subject as well.\nThank you for forking the thread\n\n> Nonexistent channels (i.e. channels that do not have some backing UTXO in the Bitcoin blockchain) are not safe to propagate on the network since they are trivially spammable (i.e. can generate a large number of fake channels to waste network bandwidth).\n\nI hadn't considered the effect this gossip would have on the network.\nDefinitely nodes should not trust one another to tell the truth about\nnonexistent channels.\n\nThe source node could blindly allow intermediate nodes to create\nsub-routes to the next hop.\nBut I wouldn't favor this blind routing idea because fee calculations\nwould be a complete guesses.\n\n> A good pruning heuristic is \"channel capacity\", which can be checked onchain (the value of the UTXO backing the channel is the channel capacity).\n> It is good to keep channels with large capacity in the routemap, because such large channels are more likely to successfully route a payment than smaller channels.\n> So it is reasonable to delete channels with low capacity when the routemap memory is becoming close to full.\n\nI'm generally concerned about these heuristics because any time nodes\ncan game a heuristic they will be expected to do so.\nGaming a heuristic can be good or bad depending on the side-effects.\nOne side effect of the \"channel capacity\" heuristic is more reliable\npayments but another side effect is that low capacity (but possibly\nreliable) channels are neglected.\n\n> It seems to me that s/aggregate-channel/high-capacity-channel/g in your idea would still work.\n> In effect, the high-capacity channel is very likely to successfully route in either direction.\n> But if by chance it falls into a state where it is unable to route in one direction or other, the intermediate node has other, lower-capacity channels that it can use JIT-Routing with to improve the directionality of the high-capacity channel.\n> Nothing in the JIT-Routing idea requires that the rebalancing loop is small, only that a loop exists.\n>\n> Nodes still need to track their direct channels (so they are implicitly always in the routemap).\n> But payee nodes making BOLT1 invoices could also provide `r` routes in the invoice, with the given routes being from nodes with high-capacity channels, so that even if the intermediate channels are pruned due to low capacity, it is possible to get paid.\n\nWithout low capacity channels spontaneous payments would not work. Or\nthey would depend on asking for an invoice under the hood.\nIt feels to me that at some point, someone with complete knowledge of\nthe network needs to be employed.\n\nCheers\nAriel Lorenzo-Luaces"
            },
            {
                "author": "Ariel Lorenzo-Luaces",
                "date": "2019-03-30T04:47:53",
                "message_text_only": "> I am forking this thread as my reply is not at all related to the JIT-Routing.\n\nSorry I think my last reply was also getting off subject as well.\nThank you for forking the thread\n\n> Nonexistent channels (i.e. channels that do not have some backing UTXO in the Bitcoin blockchain) are not safe to propagate on the network since they are trivially spammable (i.e. can generate a large number of fake channels to waste network bandwidth).\n\nI hadn't considered the effect this gossip would have on the network.\nDefinitely nodes should not trust one another to tell the truth about\nnonexistent channels.\n\nThe source node could blindly allow intermediate nodes to create\nsub-routes to the next hop.\nBut I wouldn't favor this blind routing idea because fee calculations\nwould be a complete guesses.\n\n> A good pruning heuristic is \"channel capacity\", which can be checked onchain (the value of the UTXO backing the channel is the channel capacity).\n> It is good to keep channels with large capacity in the routemap, because such large channels are more likely to successfully route a payment than smaller channels.\n> So it is reasonable to delete channels with low capacity when the routemap memory is becoming close to full.\n\nI'm generally concerned about these heuristics because any time nodes\ncan game a heuristic they will be expected to do so.\nGaming a heuristic can be good or bad depending on the side-effects.\nOne side effect of the \"channel capacity\" heuristic is more reliable\npayments but another side effect is that low capacity (but possibly\nreliable) channels are neglected.\n\n> It seems to me that s/aggregate-channel/high-capacity-channel/g in your idea would still work.\n> In effect, the high-capacity channel is very likely to successfully route in either direction.\n> But if by chance it falls into a state where it is unable to route in one direction or other, the intermediate node has other, lower-capacity channels that it can use JIT-Routing with to improve the directionality of the high-capacity channel.\n> Nothing in the JIT-Routing idea requires that the rebalancing loop is small, only that a loop exists.\n>\n> Nodes still need to track their direct channels (so they are implicitly always in the routemap).\n> But payee nodes making BOLT1 invoices could also provide `r` routes in the invoice, with the given routes being from nodes with high-capacity channels, so that even if the intermediate channels are pruned due to low capacity, it is possible to get paid.\n\nWithout low capacity channels spontaneous payments would not work. Or\nthey would depend on asking for an invoice under the hood.\nIt feels to me that at some point, someone with complete knowledge of\nthe network needs to be employed.\n\nCheers\nAriel Lorenzo-Luaces\n\nOn Mar 28, 2019, 9:51 PM, at 9:51 PM, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>Good morning Ariel,\n>\n>I am forking this thread as my reply is not at all related to the\n>JIT-Routing.\n>\n>\n>Sent with ProtonMail Secure Email.\n>\n>> Public nodes could advertise channels which don't actually exist\n>directly but are instead hidden paths that the source node doesn't need\n>to know or care about. The fees advertised for these aggregate-channels\n>would be the aggregate fees expected from the sub-route.\n>\n>Nonexistent channels (i.e. channels that do not have some backing UTXO\n>in the Bitcoin blockchain) are not safe to propagate on the network\n>since they are trivially spammable (i.e. can generate a large number of\n>fake channels to waste network bandwidth).\n>\n>> I think the biggest gain from this system is that the network can be\n>more abstract. This abstraction allows all possible subsets of public\n>nodes to be a clique since all subsets of nodes can be maximally\n>connected with aggregate-channels as long as the entire network is well\n>connected.\n>> This new property of the network could allow a source node to select\n>a random privacy-clique and rely on payments to be routed along\n>aggregate-channels without the source node needing to compute or even\n>know the exact sub-routes. Futhermore, the source node could\n>exclusively download and listen to the privacy-clique and ignore the\n>rest of the network structure thus reducing the burden of keeping up to\n>date network information.\n>\n>Let me suggest something else.\n>\n>As the LN grows, the public routemap becomes larger and larger, until\n>keeping them in a fast in-memory data structure becomes infeasible on\n>cheap hardware.\n>In all likelihood, at some point in the future, users will want to be\n>able to limit the memory consumed by implementations for routemaps.\n>\n>So, some pruning heuristic is needed, to reduce the resource usage of\n>large routemaps.\n>\n>A good pruning heuristic is \"channel capacity\", which can be checked\n>onchain (the value of the UTXO backing the channel is the channel\n>capacity).\n>It is good to keep channels with large capacity in the routemap,\n>because such large channels are more likely to successfully route a\n>payment than smaller channels.\n>So it is reasonable to delete channels with low capacity when the\n>routemap memory is becoming close to full.\n>\n>It seems to me that s/aggregate-channel/high-capacity-channel/g in your\n>idea would still work.\n>In effect, the high-capacity channel is very likely to successfully\n>route in either direction.\n>But if by chance it falls into a state where it is unable to route in\n>one direction or other, the intermediate node has other, lower-capacity\n>channels that it can use JIT-Routing with to improve the directionality\n>of the high-capacity channel.\n>Nothing in the JIT-Routing idea requires that the rebalancing loop is\n>small, only that a loop exists.\n>\n>Nodes still need to track their direct channels (so they are implicitly\n>always in the routemap).\n>But payee nodes making BOLT1 invoices could also provide `r` routes in\n>the invoice, with the given routes being from nodes with high-capacity\n>channels, so that even if the intermediate channels are pruned due to\n>low capacity, it is possible to get paid.\n>\n>Regards,\n>ZmnSCPxj"
            },
            {
                "author": "Ariel Luaces",
                "date": "2019-03-30T18:28:04",
                "message_text_only": "> I am forking this thread as my reply is not at all related to the JIT-Routing.\n\nSorry I think my last reply was also getting off subject as well.\nThank you for forking the thread\n\n> Nonexistent channels (i.e. channels that do not have some backing UTXO in the Bitcoin blockchain) are not safe to propagate on the network since they are trivially spammable (i.e. can generate a large number of fake channels to waste network bandwidth).\n\nI hadn't considered the effect this gossip would have on the network.\nDefinitely nodes should not trust one another to tell the truth about\nnonexistent channels.\n\nThe source node could blindly allow intermediate nodes to create\nsub-routes to the next hop.\nBut I wouldn't favor this blind routing idea because fee calculations\nwould be a complete guess.\n\n> A good pruning heuristic is \"channel capacity\", which can be checked onchain (the value of the UTXO backing the channel is the channel capacity).\n> It is good to keep channels with large capacity in the routemap, because such large channels are more likely to successfully route a payment than smaller channels.\n> So it is reasonable to delete channels with low capacity when the routemap memory is becoming close to full.\n\nI'm generally concerned about these heuristics because any time nodes\ncan game a heuristic they will be expected to do so.\nGaming a heuristic can be good or bad depending on the side-effects.\nOne side effect of the \"channel capacity\" heuristic is more reliable\npayments but another side effect is that low capacity (but possibly\nreliable) channels are neglected\n\n> It seems to me that s/aggregate-channel/high-capacity-channel/g in your idea would still work.\n> In effect, the high-capacity channel is very likely to successfully route in either direction.\n> But if by chance it falls into a state where it is unable to route in one direction or other, the intermediate node has other, lower-capacity channels that it can use JIT-Routing with to improve the directionality of the high-capacity channel.\n> Nothing in the JIT-Routing idea requires that the rebalancing loop is small, only that a loop exists.\n>\n> Nodes still need to track their direct channels (so they are implicitly always in the routemap).\n> But payee nodes making BOLT1 invoices could also provide `r` routes in the invoice, with the given routes being from nodes with high-capacity channels, so that even if the intermediate channels are pruned due to low capacity, it is possible to get paid.\n\nWithout low capacity channels spontaneous payments would not work. Or\nthey would depend on asking for an invoice under the hood.\nIt feels to me that at some point, someone with complete knowledge of\nthe network needs to eb employed.\n\nCheers\nAriel Lorenzo-Luaces"
            },
            {
                "author": "m.a.holden",
                "date": "2019-03-30T16:44:46",
                "message_text_only": "Hi ZmnSCPxj & Ren\u00e9.\n\nOne way you could have both determinism and encourage a diverse distribution of network maps is to treat it as a spatial indexing problem, where the space we use is the lexicographical space of the node ids (or hashes of), borrowing some similarities from DHTs.\n\nIf for example, we take a quadtree, you can take the 2 most-significant bits of the public key hash, which would put your node into one of 4 buckets. Nodes could advertise a feature bit indicating that they are committed to keeping the entire routemap of the bucket which matches their own public key hash, which would be all of the nodes in the same bucket - and all of the channels with one or both of their endpoints in the bucket.\n\nI'd estimate that with a quadtree, information held by each node could be reduced to about 40% of that of the parent node in the quadtree, although the real amounts would depend on such things as autopilot defaults (ie, how many channels you open to nodes within your bucket versus channels to nodes in other buckets). Nodes could decide their own bucket capacities on which they wish to spill and reduce the amount of gossip by taking the 2 next most significant bits of the PKH, and could go several layers deep.\n\nA node which needs to make a payment to another node within its bucket should be able to do so without querying (unless there are no routes with the required capacity). If making a payment to another bucket, then there would still exist a decent number of channels in the local routemap to nodes in those other buckets, and these nodes could be queried to find the second half of a route to the destination, or could use JIT routing for the second half, assuming the first half of the route can be selected from the local routemap.\n\nIn terms of relating this to \"locality\" in the geographical sense, one could create a convention where each bucket represents an approximate physical location. The globe can be spatially-indexed as a quadtree by taking a tetrahedral map projection (eg, Lee conformal projection[1]). The 4 equalateral triangles of the tetrahedron can be infinitely split again into 4 smaller equal-sized equalateral triangles for however many layers deep the quadtree might be. With this, it might be possible to have a convention where there is a relation between the lexicographical space and the geographical space, and wallet software would essentially brute force a private key to put you into the corresponding bucket to your physical location (trivial for the small number of bits we're talking about). Routing would be improved for local trade because you would have the entire local topology stored, and would only need to query when making payment at distance. (This may raise some privacy concerns which would need discussing.)\n\nOne issue is that it would result in a very unbalanced tree given that population is dense in some areas and sparse in others. To overcome this, instead of using a conformal or equal-area projection, we might be able to use an equal-population-per-area projection, which I had never heard of such projection before but have found some research in regards to producing them[2]. Nodes would need to agree on the projection in order for this to work, but the work could be done once and the results open sourced and shared between the implementations.\n\nAutopilot implementations might also need adjusting to consider distance too. As a starting point I would suggest a geometric distribution, where half of opened channels should be within the same bucket, a quarter should be to sibling buckets, and an eight to cousin buckets, etc. This would result in increased probability of routing and reduced querying for local payments - paying your local coffee shop should be query-free - and payments to the other side of the world might require increased querying.\n\nThere are also privacy considerations if nodes indicate their approximate locations which would need discussing. What do you think?\n\nAlso, this method does not need the be the exclusive way in which gossip is communicated between nodes, and one might also combine with something like ZmnSCPxj has suggested, for gossiping about the highest capacity nodes. It might be also possible to share information about the highest capacity channels in a bucket too.\n\n[1]:https://en.wikipedia.org/wiki/Lee_conformal_world_in_a_tetrahedron\n[2]:https://www.pnas.org/content/101/20/7499.full\n\n(PS, sorry for the separate thread, LML will not let me subscribe to the list)\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190330/0441d5ab/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Routemap scaling (was: Just in Time Routing (JIT-Routing) and a channel rebalancing heuristic as an add on for improved routing success in BOLT 1.0)",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Ariel Luaces",
                "Ren\u00e9 Pickhardt",
                "Ariel Lorenzo-Luaces",
                "m.a.holden",
                "ZmnSCPxj"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 26761
        }
    },
    {
        "title": "[Lightning-dev] Eltoo in a tree",
        "thread_messages": [
            {
                "author": "Hossein Amin",
                "date": "2019-03-29T08:43:48",
                "message_text_only": "An idea for optimization on Eltoo. \nhttps://bitcointalk.org/index.php?topic+AD0-5125586\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application+AC8-pgp-signature\nSize: 488 bytes\nDesc: This is a digitally signed message part\nURL: <http:+AC8ALw-lists.linuxfoundation.org+AC8-pipermail+AC8-lightning-dev+AC8-attachments+AC8-20190329+AC8-8c9b9c4b+AC8-attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Eltoo in a tree",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Hossein Amin"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 422
        }
    }
]