[
    {
        "title": "[Lightning-dev] Sphinx Rendezvous Update",
        "thread_messages": [
            {
                "author": "Christian Decker",
                "date": "2020-03-02T11:39:49",
                "message_text_only": "Hi Bastien,\n\nthanks for verifying my proposal, and I do share your concerns regarding\nprivacy leaks (how many hops are encoded in the onion) and success ratio\nif a payment is based on a fixed (partial) path.\n\n> I believe this makes it quite usable in Bolt 11 invoices, without blowing up\n> the size of the QR code (but more experimentation is needed on that).\n\nIt becomes a tradeoff of how small you want your onion to be, and how\nmany hops the partial onion can have. For longer partial onions we're\ngetting close to the current full onion size, but I expect most partial\nonion to be close to the network diameter of ~6 (excluding degerenate\nchains). So the example below with 5 hops seemed realistic, and dropping\nthe legacy format in favor of TLVs we can get a couple of bytes back as\nwell.\n\n>> As an example such an onion, with 5 legacy hops (65 byte each) results\n>> in a 325 + 66 bytes onion, and we save 975 bytes.\n>\n> While having flexibility when choosing the length of the prefill\n> stream feels nice, wouldn't it be safer to impose a fixed size to\n> avoid any kind of heuristic at `RV` to try to guess how many hops\n> there are between him and the recipient?\n\nI'm currently just using the maximum size, which is an obvious privacy\nleak, but I'm also planning on exposing the size to be prefilled, and\nhence cropped out when compressing, when generating. Ideally we'd have a\ncouple of presets, i.e., 1/4, 2/4, 3/4, and adhere to them, randomizing\nwhich one we pick.\n\nHaving smaller partial onions would enable my stretch goal of being able\nto chain multiple partial onions, though that might be a useless\nachievement to unlock xD\n\n>> Compute a shared secret using a random ephemeral private key and\n>> `RV`s public key, and then generate a prefill-key\n>\n>\n> While implementing, I felt that the part about the shared secret used\n> to generate the prefill stream is a bit blurry (your proposal on\n> Github doesn't phrase it the same way). I think it's important to\n> stress that this secret is derived from both `ephkey` and `RV`'s\n> private key, so that `RV+1` can't compute the same stream.\n\nI noticed the same while implementing the decompress stage, which\nrequires the node ID from `RV` during generation, and performs ECDH +\nHKDF with the `RV` node private and the ephemeral key in the *next*\nonion, i.e., the one extracted from the payload itself. This is\nnecessary since the ephemeral key on the incoming onion, which delivered\nthe partial onion in its payload is not controlled by the partial onion\ncreator, while the one in the partial onion is.\n\nThis means that the ephemeral key in the partial onion is used twice:\n\n - Once by `RV` to generate the obfuscation stream to fill in the gap\n - As part of the reconstructed onion, processed by `RV+1` to decode the\n   onion.\n\nI'm convinced this is secure and doesn't leak information since\notherwise transporting the ephemeral key publicly would be insecure\n(`RV+1` can't generate the obfuscation secret used to fill in the gap\nwithout access to `RV`s private key), and the ephemeral key is only\ntransmitted in cleartext once (from `RV` to `RV+1`), otherwise it is\nhidden in the outer onion.\n\n> Another thing that may be worth mentioning is error forwarding. Since\n> the recipient generated the onion, `RV` won't have the shared secrets\n> (that's by design). So it's expected that payment errors won't be\n> readable by `RV`, but it's probably a good idea if `RV` returns an\n> indication to the sender that the payment failed *after* the\n> rendezvous point.\n\nIndeed, this is pretty much by design, since otherwise the sender could\nprovoke errors, e.g., consuming all of `RV`s outgoing capacity with\nprobes to get back temporary channel failure errors for the channel that\nwas encoded in the partial onion, and then do that iteratively until we\nhave identified the real destination which we weren't supposed to learn.\n\nSo any error beyond `RV` should be treated by the sender as \"rendez-vous\nfailed, discard partial onion\".\n\n> An important side-note is that your proposal is really quick and\n> simple to implement from the existing Sphinx code. I have made ASCII\n> diagrams of the scheme (see [1]).  This may help readers visualize it\n> more easily.\n\nI quickly skimmed the drawings and they're very nice to understand how\nregions overlap, that was my main problem with the whole sphinx\nconstruction, so thanks for taking the time :+1:\n\n> It still has the issue that each hop's amount/cltv is fixed at invoice\n> generation time by the recipient. That means MPP cannot be used, and\n> if any channel along the path updates their fee the partial onion\n> becomes invalid (unless you overpay the fees).\n>\n> Trampoline should be able to address that since it provides more\n> freedom to each trampoline node to find an efficient way to forward to\n> the next trampoline.  It's not yet obvious to me how I can mix these\n> two proposals to make it work though.  I'll spend more time\n> experimenting with that.\n\nTrue, I think rendez-vous routing have some use-cases, but routing in\nthe public network seems a bit brittle. It is definitely not MPP\ncompliant since the sphinx constructions says that each shared secret\nshould be blacklisted after use, and if we were to use the partial onion\non multiple path we'd be bound to use the same shared secret for the\nsubpaths contained in the partial onion.\n\nI've been mostly thinking about systems in which you can guarantee\nstability, e.g., in a subnetwork controlled by the recipient, but to\nhide any internal routing decisions. That'd be similar to a supercharged\nrouting hint basically, without revealing the internal structure.\n\nCheers,\nChristian"
            }
        ],
        "thread_summary": {
            "title": "Sphinx Rendezvous Update",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Decker"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 5643
        }
    },
    {
        "title": "[Lightning-dev] Superbolt Proposal - a professionally run LN subset delivering superior UX",
        "thread_messages": [
            {
                "author": "Robert Allen",
                "date": "2020-03-03T01:19:18",
                "message_text_only": "Superbolt Proposal\n\n*Introduction*\n\nCurrently, the LN user experience is far from retail ready.\nInbound/outbound channel liquidity issues and node dropouts mean that many\npayment attempts will not succeed.\n\nI have spent some time thinking through these issues and believe a BOLT\nspecification which would enforce a stricter set of rules for nodes to\nfollow and which would ensure sufficient liquidity, uptime and channel\nrebalancing automation would move the needle greatly in the direction of a\nUX which could go mainstream. If LN is currently resulting in many \u201cgutter\nballs,\u201d Superbolt would be like bowling with bumpers. This BOLT would be\noptional for LN nodes to use or not depending on whether they wish to\nparticipate in the Superbolt network directly.\n\n*The Problem*\n\nIn Christian Decker\u2019s talk\n<https://www.youtube.com/watch?time_continue=1&v=HtU7ZlxvLL4&feature=emb_logo>\nat The Lightning Conference (Berlin, October 2019) he presented some\nfrustrating statistics from a study he conducted to test payment routing\nsuccess/failure on Lightning Network (LN) using payment probes. Some of the\nsalient points:\n\n\n   1.\n\n   48% of payment probes failed to find a payment path to the targeted\n   node. This is likely because either the node itself was offline or a\n   connecting node along the path was offline.\n   2.\n\n   Ignoring the 48% of unreachable nodes, payment success rate is 66% on\n   the first payment attempt. With multiple retries for the payment, success\n   rates reach about 80%. This means that even for nodes which are available\n   and reachable, 20% of payments are not able to complete. This is not good.\n   3.\n\n   Stuck payments (initiated but not completed) because a node died along\n   the path occurred at approximately 0.19%.\n\n\nIt should go without saying that a payment network which works less than\n50% of the time presents a user experience which will never catch on with\nthe vast majority of the total addressable market. If you are flipping a\ncoin every time you attempt to use a payment method, you will quickly\nabandon this method for one which works reliably.\n\nTo make matters worse, I believe Christian was attempting to route\nmicropayments for his testing of the network, so the above numbers may\nactually be optimistic when you factor in attempting to route larger\npayments (even just a few hundred dollars worth of BTC). For example, a\nroute may be found for the desired payment but if there is insufficient\nliquidity on one of those hops (either due to insufficient channel capacity\nor because of inbound/outbound liquidity issues), then the payment will\nfail.\n\nIn summary, there are two fundamental problems with LN as it is currently\nfunctioning:\n\n   1.\n\n   Connectivity: Node uptime and connectivity to the broader network are\n   both insufficient to guarantee payment success.\n   2.\n\n   Throughput: Node channel capacity is frequently insufficient due to low\n   total capacity and/or inbound/outbound liquidity snags.\n\n\n*Proposal*\n\nI am proposing an LN BOLT, called Superbolt Network (SBN). Conceptually,\nthis might be analogous to an \u201celectrical grid\u201d for LN. SBN would enforce\nand/or automate the following:\n\n\n   1.\n\n   Liquidity: Distinct and uniform LN node classes with commensurate total\n   node and per channel liquidity requirements. To begin, two node classes are\n   proposed.\n   1.\n\n      Routing Node (RN) - 4 BTC total node capacity, 4 x 1 BTC channels\n      (0.5 BTC per side) to other RNs, 8 x 0.5 BTC (0.25 BTC per side) channels\n      to ANs. 3 of 4 RN connections should be with shared peers (i.e.\nA => B => C\n      => A) while the 4th connection should be with an RN without\nshared peers to\n      ensure the network is sufficiently connected.\n      2.\n\n      Access Node (AN) - 1 BTC total node capacity, 2 x 0.5 BTC channels\n      (0.25 BTC per side) to RNs. 10 x 0.1 BTC channels (0.05 BTC per side) to\n      regular LN wallets/individual users/etc. RNs should be peers to allow off\n      chain rebalancing via circular payments.\n      3.\n\n      Please note: Additional node classes (larger or smaller) may be\n      beneficial to network performance. However, to maintain sufficient\n      decentralization, it may be beneficial to have a maximum node\n      capitalization limit.\n      2.\n\n   Uptime: Nodes would be required to maintain uptime to the network of at\n   least 99% availability. Nodes which fall below this requirement for a\n   determined period of time would be ostracised by the rest of the network\n   and perhaps eventually excised completely from SBN. I believe we could use\n   chanfitness <https://github.com/lightningnetwork/lnd/pull/3332> from lnd\n   v0.9.0-beta\n   <https://blog.lightning.engineering/announcement/2020/01/22/lnd-v0.9.html>\n   and add some logic to check for fitness and then some scripting to\n   automatically route around bad nodes.\n   3.\n\n   Channel balancing: To ensure that channels do not become stuck from\n   inbound/outbound liquidity snags, the protocol would include some scripting\n   to automate channel rebalancing via \u201ccircular payments\u201d and Loop.\n   4.\n\n   Attestation: Any LN node which claims to meet the requirements to be\n   included in SBN would be rated by a randomized subset of the SBN network\n   and the inquiring node would receive cryptographically signed attestation\n   that the node is either valid or invalid.\n   5.\n\n   Uniform fee: Payments sent on the network would be subject to a flat fee\n   regardless of hops involved in routing the payment.\n\n\n*Why?*\n\nGiven the above, anyone using SBN/LN/BTC would have a close to 100%\nguarantee that their payment would be successfully routed from any given\nSBN Access Node to any other SBN Access Node up to a reasonable\nnetwork-defined maximum (perhaps 0.025 BTC ~= $215 with BTC at $8600). We\ncan be confident of this because:\n\n\n   1.\n\n   Channel capacity is sufficient such that any one payment is an order of\n   magnitude smaller than the nearest chokepoint (0.25 BTC outbound from AN to\n   RN while maximum payment would be 0.025 BTC). I haven\u2019t done the hard math\n   on this, but my intuition tells me that the probability of all participants\n   connected to any given AN attempting to route payments from said AN at the\n   same time would approach 0%.\n   2.\n\n   In the event that an AN or RN node channel capacity becomes unbalanced\n   (i.e. Node A = 0 BTC, Node B = 1 BTC in given channel), Channels should\n   frequently be able to use circular payments\n   <https://github.com/lightningnetwork/lnd/pull/3736> to unstick capacity\n   given that nodes are sufficiently connected with common piers. In the event\n   that off-chain rebalancing is impossible, Loop\n   <https://github.com/lightninglabs/loop> may be used. Ideally, both\n   approaches would be automated such that rebalancing occurs if node\n   liquidity is stuck in either direction beyond some threshold (say <25% of\n   total channel capacity).\n   3.\n\n   Nodes are incentivized to stay online ready to route payments and\n   ostracized for insufficient uptime.\n\n\nThe user experience I envision with this protocol would be one where a user\nwould go to pay with Lightning and look for the Superbolt logo and know\nwith near certainty that they will be able to make the payment. This is the\nexperience today with processors like Visa and Mastercard and it seems\nunlikely that LN will achieve similar levels of reliability unless some\nadditional requirements such as those proposed here are added to the LN/BTC\nstack.\n\n\nI would very much appreciate input on this idea.\n\n-- \nBest,\n\nRobert\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200302/22a74f46/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-03-03T05:07:47",
                "message_text_only": "Good morning Robert,\n\nUnfortunately, this proposal is basically a proposal to split the network into a central network of specially-chosen nodes surrounded by second-class and third-class nodes that are utterly dependent on the central network, which I personally find disturbing.\n\nOf course, it may be that this is already where the network is heading, which is sad.\nGravity exists, and is difficult to resist against; yet as long as I remain standing on my own two legs (since I am human, I possess two legs), I resist gravity.\n\nIn any case, other than that, here are some more thoughts:\n\n> it may be beneficial to have a maximum node capitalization limit.\n\nThis is trivially worked around by running multiple virtual nodes, say on the same machine but behind different Tor .onion addresses.\nThen any benefit you get would be a mirage.\nIf you go through with this, I suggest that such limits not be imposed anyway, as it is trivial to get around them.\n\nDisallowing Tor .onion addresses would be bad as well: it should be allowed that some high-liquidity nodes have their privacy protected if needed.\n\n> 5.  Attestation: Any LN node which claims to meet the requirements to be included in SBN would be rated by a randomized subset of the SBN network and the inquiring node would receive cryptographically signed attestation that the node is either valid or invalid.\n\nHow would you bootstrap this SBN?\nWho are the first members of the SBN, and why should they let, say, furries join the SBN by attesting to them?\nIf the first members all hate furries (and everybody hates furries, after all, why do you think the Cats movie bombed?) then even a random subset of those first SBN members will not attest to any furries, because furries are ew.\n\nNote that we already have attestation to the liquidity of a node, by having the node publish its channels, since channels are attested on the blockchain, whose blocks are attested economically (i.e. a sufficiently rich furry can always create channels on the blockchain, because censorship-resistant).\nWhat is missing is a censorship-resistant attestation of the ***uptime*** of a node.\n\nNow of course, a furry might manage to get through by at least first hiding the fact that it is a furry, but once discovered, a \"randomly-selected\" subset of the SBN would then counter-attest that the furry is actually only 98.9% up, revoking its membership from the SBN.\nThis gets worse if the furry was using its open public IP rather than sensibly using a Tor .onion address (which means that, for the protection of furry and non-furry alike, we must support Tor .onion addresses for SBN members).\n\nWhich brings up the next topic: how does the \"random selection\" work?\nIt might be doable to use entropy from the onchain block IDs, assuming miners are not willing to increase the difficulty of their work further by biasing their blocks against those furries (which all miners also hate, because everybody hates furries).\nBut that means there has to be some authoritative set of SBN members (from which a deterministic algorithm would choose a subset), and there would need to be consensus on what that set of SBN members ***is*** as well, and how to keep around this data of who all the SBN members are, and so on.\nThis starts to look like a tiny federated / proof-of-stake blockchain, which we would like to avoid because blockchains have bad scaling, though I suppose this might be acceptable if the only transactions are removal and adding of SBN members.\nWhat would the block rate be, and who are the genesis SBN members (and are any of them furries)?\nHow bad will this get a decade from now, and how many will be using SPV for this set-of-SBN-members federated blockchain?\n\n> 2.  Ignoring the 48% of unreachable nodes, payment success rate is 66% on the first payment attempt. With multiple retries for the payment, success rates reach about 80%. This means that even for nodes which are available and reachable, 20% of payments are not able to complete. This is not good.\n\nI note that, as I understood the presentation, the data-gathering model was that every node had an equal chance of being the payee.\n\nHowever, we should note that not every public node expects to be a payee at all times, and that for nodes with a brisk business on Lightning, their success chances are, as I understand it, higher.\nThus the actual experience is better than the dire numbers suggested in the presentation.\nOf course, I have no numbers or data to present here.\n\nIn general, if you are expecting a payment over Lightning, you will generally arrange to make this as smooth as possible, and will ensure you have incoming liquidity, that your node was actually up during the time you expect a payment, and so on (you have a strong incentive to do so, because you like money); whereas the model used was that everybody gets a  payment (that they cannot claim because the payment hash was a random number) and not everyone has their nodes online all the time with incoming liquidity in all channels with peers that are also alive.\nThus, I expect the actual experience to be higher: in short, the data from cdecker establishes a lower bound on the expected user experience, not an upper bound, because it just randomly took everyone as a possible target.\n\n--\n\nSo let me counterpropose that:\n\n* What we are missing is a censorship-free way to attest to uptime.\n* Liquidity is visible onchain.\n* You are already going to need a blockchain anyway to anchor your funds.\n\nSo:\n\n* Nodes that want to declare themselves as members of SBN sign the current block.\n  * These nodes put their signatures in OpenTimeStamps for the *next* block.\n  * When somebody asks \"what is your uptime???\" they show the signatures they have that are attested on OpenTimeStamps.\n    * The asker will disbelieve them unless the set of signatures attested on OpenTimeStamps is large enough.\n      For example, it could require that the node, to be believed as a member of SBN, to show 99 signatures within the last 100 blocks as having been attested on OpenTimeStamps.\n* To be accepted as an SBN member, your node needs only to give these proofs to anyone who asks:\n  * Proof that it has liquidity --- which it already does by the current gossip system.\n  * Proof that it has high uptime --- by the above mechanism.\n\nThis assumes OpenTimeStamps does not hate furries, or that you can hide your furry-ness from OpenTimeStamps.\nI believe it is possible to hide furry-ness: my understanding is that it is commitments, and not their openings, that is received by the OpenTimeStamps server.\nThus, an SBN wannabe self-attests: they publish their onlineness to OpenTimeStamps, they do not ask somebody \"please tell everyone else that I am not a furry\".\n\nAs well, we can replace OpenTimeStamps with some other attestation mechanism that publishes attestations, at cost, onchain, though we should be careful to design one with very low onchain footprint.\nUsing OpenTimeStamps may make the OpenTimeStamps server an attractive target for attacks, and distributing this risk is needed.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Robert Allen",
                "date": "2020-03-10T01:52:14",
                "message_text_only": "Hello ZmnSCPxj,\n\nHow did you know that I'm a closet furry?! ;) I'm shaking in my\nonesie right now...\n\nIt is definitely not my goal to split the network up but rather to provide\nsome guide rails to help ensure usability and decentralization. I also\nagree 100% that Tor nodes are a must for LN.\n\nIn terms of maximum node size for SBN, I do feel that it would be\nbeneficial to the decentralization of the network to have that in place (if\nit worked as intended) but also understand the scenario you outline where\nmany nodes could be spun up on the same machine. Perhaps a better (and\nactually enforceable) approach would be to require that all RNs commit 0.5\nBTC per channel (1 BTC total per channel) with a minimum of 4 channels. So,\na larger node could have many more than 4 channels assuming each channel\nmeets the liquidity requirement. This wouldn't help to further\ndecentralization but would at least ensure uniform channel liquidity. It\nseems that just as the one computer one vote idea with BTC didn't pan out,\nthere is a similar problem here that may be insurmountable.\n\nYour suggestion for self-attestation using OpenTimeStamps is really\nbrilliant and elegant. I don't see any reason why this shouldn't work. I do\nthink it would be better to extend the minimum number of self-attestations\nto perhaps 7 days worth of blocks (so that a node cannot easily\njoin/exit/rejoin SBN). I'm also wondering if it would make sense to add\nOpenTimeStamps servers to all SBN nodes and then use some kind of random\nelection function such that for each block all attestations would be sent\nto the elected server and published to BTC (thus ensuring the lowest\npossible fee vs. using a redundant approach with multiple OTS servers). If\nthe election is sufficiently random, it would seem to be very difficult to\ncoordinate an attack where a furry's attestation would be excluded from a\nblock for more than some very small number (well bellow putting them in\ndanger of being excluded from the network for insufficient uptime).\n\nI reworked the proposal with the OpenTimeStamps approach and published it\non GitHub <https://github.com/robertwilliamallen/superbolt>. ZmnSCPxj and\nanyone else who finds this proposal to be interesting is invited to come\nand add their ideas to the mix.\n\nI also see some similarities to this proposal and Lightning Service\nProviders (LSPs) as written about by Roy Sheinfeld here:\nhttps://medium.com/breez-technology/introducing-lightning-service-providers-fe9fb1665d5f.\nDon't know if he's in this group, but would really enjoy connecting with\nhim to discuss if he is.\n\nBest,\nRobert\n\nOn Mon, Mar 2, 2020 at 9:07 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Robert,\n>\n> Unfortunately, this proposal is basically a proposal to split the network\n> into a central network of specially-chosen nodes surrounded by second-class\n> and third-class nodes that are utterly dependent on the central network,\n> which I personally find disturbing.\n>\n> Of course, it may be that this is already where the network is heading,\n> which is sad.\n> Gravity exists, and is difficult to resist against; yet as long as I\n> remain standing on my own two legs (since I am human, I possess two legs),\n> I resist gravity.\n>\n> In any case, other than that, here are some more thoughts:\n>\n> > it may be beneficial to have a maximum node capitalization limit.\n>\n> This is trivially worked around by running multiple virtual nodes, say on\n> the same machine but behind different Tor .onion addresses.\n> Then any benefit you get would be a mirage.\n> If you go through with this, I suggest that such limits not be imposed\n> anyway, as it is trivial to get around them.\n>\n> Disallowing Tor .onion addresses would be bad as well: it should be\n> allowed that some high-liquidity nodes have their privacy protected if\n> needed.\n>\n> > 5.  Attestation: Any LN node which claims to meet the requirements to be\n> included in SBN would be rated by a randomized subset of the SBN network\n> and the inquiring node would receive cryptographically signed attestation\n> that the node is either valid or invalid.\n>\n> How would you bootstrap this SBN?\n> Who are the first members of the SBN, and why should they let, say,\n> furries join the SBN by attesting to them?\n> If the first members all hate furries (and everybody hates furries, after\n> all, why do you think the Cats movie bombed?) then even a random subset of\n> those first SBN members will not attest to any furries, because furries are\n> ew.\n>\n> Note that we already have attestation to the liquidity of a node, by\n> having the node publish its channels, since channels are attested on the\n> blockchain, whose blocks are attested economically (i.e. a sufficiently\n> rich furry can always create channels on the blockchain, because\n> censorship-resistant).\n> What is missing is a censorship-resistant attestation of the ***uptime***\n> of a node.\n>\n> Now of course, a furry might manage to get through by at least first\n> hiding the fact that it is a furry, but once discovered, a\n> \"randomly-selected\" subset of the SBN would then counter-attest that the\n> furry is actually only 98.9% up, revoking its membership from the SBN.\n> This gets worse if the furry was using its open public IP rather than\n> sensibly using a Tor .onion address (which means that, for the protection\n> of furry and non-furry alike, we must support Tor .onion addresses for SBN\n> members).\n>\n> Which brings up the next topic: how does the \"random selection\" work?\n> It might be doable to use entropy from the onchain block IDs, assuming\n> miners are not willing to increase the difficulty of their work further by\n> biasing their blocks against those furries (which all miners also hate,\n> because everybody hates furries).\n> But that means there has to be some authoritative set of SBN members (from\n> which a deterministic algorithm would choose a subset), and there would\n> need to be consensus on what that set of SBN members ***is*** as well, and\n> how to keep around this data of who all the SBN members are, and so on.\n> This starts to look like a tiny federated / proof-of-stake blockchain,\n> which we would like to avoid because blockchains have bad scaling, though I\n> suppose this might be acceptable if the only transactions are removal and\n> adding of SBN members.\n> What would the block rate be, and who are the genesis SBN members (and are\n> any of them furries)?\n> How bad will this get a decade from now, and how many will be using SPV\n> for this set-of-SBN-members federated blockchain?\n>\n> > 2.  Ignoring the 48% of unreachable nodes, payment success rate is 66%\n> on the first payment attempt. With multiple retries for the payment,\n> success rates reach about 80%. This means that even for nodes which are\n> available and reachable, 20% of payments are not able to complete. This is\n> not good.\n>\n> I note that, as I understood the presentation, the data-gathering model\n> was that every node had an equal chance of being the payee.\n>\n> However, we should note that not every public node expects to be a payee\n> at all times, and that for nodes with a brisk business on Lightning, their\n> success chances are, as I understand it, higher.\n> Thus the actual experience is better than the dire numbers suggested in\n> the presentation.\n> Of course, I have no numbers or data to present here.\n>\n> In general, if you are expecting a payment over Lightning, you will\n> generally arrange to make this as smooth as possible, and will ensure you\n> have incoming liquidity, that your node was actually up during the time you\n> expect a payment, and so on (you have a strong incentive to do so, because\n> you like money); whereas the model used was that everybody gets a  payment\n> (that they cannot claim because the payment hash was a random number) and\n> not everyone has their nodes online all the time with incoming liquidity in\n> all channels with peers that are also alive.\n> Thus, I expect the actual experience to be higher: in short, the data from\n> cdecker establishes a lower bound on the expected user experience, not an\n> upper bound, because it just randomly took everyone as a possible target.\n>\n> --\n>\n> So let me counterpropose that:\n>\n> * What we are missing is a censorship-free way to attest to uptime.\n> * Liquidity is visible onchain.\n> * You are already going to need a blockchain anyway to anchor your funds.\n>\n> So:\n>\n> * Nodes that want to declare themselves as members of SBN sign the current\n> block.\n>   * These nodes put their signatures in OpenTimeStamps for the *next*\n> block.\n>   * When somebody asks \"what is your uptime???\" they show the signatures\n> they have that are attested on OpenTimeStamps.\n>     * The asker will disbelieve them unless the set of signatures attested\n> on OpenTimeStamps is large enough.\n>       For example, it could require that the node, to be believed as a\n> member of SBN, to show 99 signatures within the last 100 blocks as having\n> been attested on OpenTimeStamps.\n> * To be accepted as an SBN member, your node needs only to give these\n> proofs to anyone who asks:\n>   * Proof that it has liquidity --- which it already does by the current\n> gossip system.\n>   * Proof that it has high uptime --- by the above mechanism.\n>\n> This assumes OpenTimeStamps does not hate furries, or that you can hide\n> your furry-ness from OpenTimeStamps.\n> I believe it is possible to hide furry-ness: my understanding is that it\n> is commitments, and not their openings, that is received by the\n> OpenTimeStamps server.\n> Thus, an SBN wannabe self-attests: they publish their onlineness to\n> OpenTimeStamps, they do not ask somebody \"please tell everyone else that I\n> am not a furry\".\n>\n> As well, we can replace OpenTimeStamps with some other attestation\n> mechanism that publishes attestations, at cost, onchain, though we should\n> be careful to design one with very low onchain footprint.\n> Using OpenTimeStamps may make the OpenTimeStamps server an attractive\n> target for attacks, and distributing this risk is needed.\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n\n-- \nBest,\n\nRobert Allen\nExecutive Producer\nBitcoin and Friends\nbtcandfriends.com\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200309/33d45be9/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-03-10T12:10:54",
                "message_text_only": "Good morning Robert,\n\n> How did you know that I'm a closet furry?! ;) I'm shaking in my onesie\u00a0right\u00a0now...\n\nIt was so obvious, my furdar was picking up your furriness just from parsing the individual bytes arising from your email server.\n\n> It is definitely not my goal to split the network up but rather to provide some guide rails to help ensure usability and decentralization. I also agree 100% that Tor nodes are a must for LN.\n>\n> In terms of maximum node size for SBN, I do feel that it would be beneficial to the decentralization of the network to have that in place (if it worked as intended) but also understand the scenario you outline where many nodes could be spun up on the same machine. Perhaps a better (and actually enforceable) approach would be to require that all RNs commit 0.5 BTC per channel (1 BTC total per channel) with a minimum of 4 channels. So, a larger node could have many more than 4 channels assuming each channel meets the liquidity requirement. This wouldn't help to further decentralization but would at least ensure uniform channel liquidity. It seems that just as the one computer one vote idea with BTC didn't pan out, there is a similar problem here that may be insurmountable.\n>\n> Your suggestion for self-attestation using OpenTimeStamps is really brilliant and elegant. I don't see any reason why this shouldn't work. I do think it would be better to extend the minimum number of self-attestations to perhaps 7 days worth of blocks (so that a node cannot easily join/exit/rejoin SBN). I'm also wondering if it would make sense to add OpenTimeStamps servers to all SBN nodes and then use some kind of random election function such that for each block all attestations would be sent to the elected server and published to BTC (thus ensuring the lowest possible fee vs. using a redundant approach with multiple OTS servers). If the election is sufficiently random, it would seem to be very difficult to coordinate an attack where a furry's attestation would be excluded from a block for more than some very small number (well bellow putting them in danger of being excluded from the network for insufficient uptime).\u00a0\n\nUnfortunately for the poor fool who came up with that proposal, it suffers from \"what you measure is what you get\".\nSpecifically, it measures node uptime, but not node correct behavior, and it is node correct behavior (i.e. making an effort to actually forward) that you want; what this proposal does is measure node uptime, which *correlates with* but *is not exactly identical to* node correct behavior.\n\nI find that most furries are more able to understand this with a fable, so let me present the issue of \"what you measure is what you get\" in fable form.\n\nOnce upon a time, the government of London, seeking to reduce the rat problem of the city, decided to delegate the problem to the private sector, by offering to pay an amount for every rat tail provided by the citizenry.\nAt first this seemed to work well, but eventually the rat infestation came back with a vengeance, even as the coffers of the city government were continuously emptied by the rat-tail program.\nEventually an extensive investigation by the government officials uncovered the existence of *rat farms*, where private individuals grew rats (and where well-fed healthy rats sometimes escaped from, leading to worse rat infestations than before) for their lucrative tails.\n\nThis shows the issue: what they measured was *the number of rat tails shown*, not *the reduction of rats in the city*, and so they got shown a lot of rat tails (at the expense of actively increasing the number of rats in the city, since they were now being grown in rat farms).\n\nSimilarly, I could attack the SBN by having a cheap RaspPi (or maybe Arduino) continuously attesting its uptime, but not actually running any Lightning node software, so that paths through my pathetic RaspPi \"node\" will always fail.\nWith enough cheap RaspPis and some HODLed funds in 2-of-2s (where both pubkeys are mine anyway), I can ensure that most of SBN is composed of my \"nodes\" and make it worthless.\n\nAgainst this, we can observe that the blockchain layer itself is ultimately protected by the economics of mining.\nThus, the blockchain security cannot be better than economically-infeasible security, and Lightning, as it is anchored to the blockchain, also cannot get better than economically-infeasible security.\nIf attesting its own uptime is expensive enough, then every additional node that I fake is going to be an additional expense, and it may become impractical for me to take over the entire SBN unless I work honestly and actually forward payments and earn fees from it (in much the same way that a miner could always just mine empty blocks and make the blockchain layer worthless, but it is impractical for them to do so since they would earn less compared to a miner who honestly adds new transactions to the blocks and thereby earn fees from those).\n\n(the above does not protect against running multiple nodes to get around any per-node limit, by the way; if running one honestly-forwarding node is at all lucrative, running more honestly-forwarding nodes should be more lucrative.\nthus, the above only protects against nodes that are not honestly-forwarding, but cannot protect against multiple honestly-forwarding nodes being run by the same entity to get around per-node limits you might impose)\n\nFurther, adding more OTS-like servers may still allow a minority OTS-server to effectively censor hated furries like you.\nRemember, we now require that SBN-nodes have 99% uptime by showing 99 proof-of-uptime entries in the last 100 blocks.\nIf I have enough OTS-servers to comprise at least 2% of all OTS-servers, then I can force you, you furry, to have at most 98% uptime recorded onchain, thus effectively censoring you from the SBN.\nThis might be helped by adding some salting of some kind, and having OTS-server protocol to accept any blinded commitments that will only be opened after they are actually committed onchain, though.\n\nAlternately, groups of independent citizens can just put a fund in a k-of-n address and always continuously spend that k-of-n address to itself on every block, with the proof-of-uptimes of the group embedded in a Merkle tree committed to in the `R` of the signature (i.e. sign-to-contract).\nWith Schnorr this allows the k-of-n to be hidden in a single signature as well, though the signing ritual would have to be significantly more complex (I have not considered the proper signing ritual) to ensure that the generated `R` indeed commits to the Merkle tree root of the group uptime proofs, and k-of-n requires a complicated setup, and k-of-n is susceptible to majority takeover (i.e. it can be spent without your key, thus not your coins) and sybilling.\nThis may also combine well with the need to make proof-of-uptime expensive (else it would be cheap to take over SBN).\nThough of course our colleagues over in bitcoin-dev will cry over the blockchain bloat such a scheme would have, you spoony furry, that is precisely why furries should be censored.\n\n(taking the above offchain is possible, but the entire point of doing the above onchain is that it proves onlineness, whereas offchain does not prove that anything is online at each block, only at the blocks where the offchain system is pushed onchain.)\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Robert Allen",
                "date": "2020-03-18T21:51:48",
                "message_text_only": "On Tue, Mar 10, 2020 at 5:11 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Robert,\n>\n> > How did you know that I'm a closet furry?! ;) I'm shaking in my\n> onesie right now...\n>\n> It was so obvious, my furdar was picking up your furriness just from\n> parsing the individual bytes arising from your email server.\n\n\n> > It is definitely not my goal to split the network up but rather to\n> provide some guide rails to help ensure usability and decentralization. I\n> also agree 100% that Tor nodes are a must for LN.\n> >\n> > In terms of maximum node size for SBN, I do feel that it would be\n> beneficial to the decentralization of the network to have that in place (if\n> it worked as intended) but also understand the scenario you outline where\n> many nodes could be spun up on the same machine. Perhaps a better (and\n> actually enforceable) approach would be to require that all RNs commit 0.5\n> BTC per channel (1 BTC total per channel) with a minimum of 4 channels. So,\n> a larger node could have many more than 4 channels assuming each channel\n> meets the liquidity requirement. This wouldn't help to further\n> decentralization but would at least ensure uniform channel liquidity. It\n> seems that just as the one computer one vote idea with BTC didn't pan out,\n> there is a similar problem here that may be insurmountable.\n> >\n> > Your suggestion for self-attestation using OpenTimeStamps is really\n> brilliant and elegant. I don't see any reason why this shouldn't work. I do\n> think it would be better to extend the minimum number of self-attestations\n> to perhaps 7 days worth of blocks (so that a node cannot easily\n> join/exit/rejoin SBN). I'm also wondering if it would make sense to add\n> OpenTimeStamps servers to all SBN nodes and then use some kind of random\n> election function such that for each block all attestations would be sent\n> to the elected server and published to BTC (thus ensuring the lowest\n> possible fee vs. using a redundant approach with multiple OTS servers). If\n> the election is sufficiently random, it would seem to be very difficult to\n> coordinate an attack where a furry's attestation would be excluded from a\n> block for more than some very small number (well bellow putting them in\n> danger of being excluded from the network for insufficient uptime).\n>\n> Unfortunately for the poor fool who came up with that proposal, it suffers\n> from \"what you measure is what you get\".\n> Specifically, it measures node uptime, but not node correct behavior, and\n> it is node correct behavior (i.e. making an effort to actually forward)\n> that you want; what this proposal does is measure node uptime, which\n> *correlates with* but *is not exactly identical to* node correct behavior.\n>\n> I find that most furries are more able to understand this with a fable, so\n> let me present the issue of \"what you measure is what you get\" in fable\n> form.\n>\n> Once upon a time, the government of London, seeking to reduce the rat\n> problem of the city, decided to delegate the problem to the private sector,\n> by offering to pay an amount for every rat tail provided by the citizenry.\n> At first this seemed to work well, but eventually the rat infestation came\n> back with a vengeance, even as the coffers of the city government were\n> continuously emptied by the rat-tail program.\n> Eventually an extensive investigation by the government officials\n> uncovered the existence of *rat farms*, where private individuals grew rats\n> (and where well-fed healthy rats sometimes escaped from, leading to worse\n> rat infestations than before) for their lucrative tails.\n>\n\nI was familiar with this story. Also a great reminder of the dangers of\ngovernment \"solutions\" in general.\n\n\n>\n> This shows the issue: what they measured was *the number of rat tails\n> shown*, not *the reduction of rats in the city*, and so they got shown a\n> lot of rat tails (at the expense of actively increasing the number of rats\n> in the city, since they were now being grown in rat farms).\n>\n> Similarly, I could attack the SBN by having a cheap RaspPi (or maybe\n> Arduino) continuously attesting its uptime, but not actually running any\n> Lightning node software, so that paths through my pathetic RaspPi \"node\"\n> will always fail.\n> With enough cheap RaspPis and some HODLed funds in 2-of-2s (where both\n> pubkeys are mine anyway), I can ensure that most of SBN is composed of my\n> \"nodes\" and make it worthless.\n>\n\nI guess it wasn't explicit in my proposal, but the intention is for SBN\nnodes to be LN nodes. Thus, in order to be accepted into SBN, your node\nwould have to run the LN software. Is there a way to set up an LN node,\nconnect to other nodes, and then not allow routing of payments through your\nnode? If so, then I don't believe SBN would be any more in danger of this\nscenario than vanilla LN.\n\n\n> Against this, we can observe that the blockchain layer itself is\n> ultimately protected by the economics of mining.\n> Thus, the blockchain security cannot be better than\n> economically-infeasible security, and Lightning, as it is anchored to the\n> blockchain, also cannot get better than economically-infeasible security.\n> If attesting its own uptime is expensive enough, then every additional\n> node that I fake is going to be an additional expense, and it may become\n> impractical for me to take over the entire SBN unless I work honestly and\n> actually forward payments and earn fees from it (in much the same way that\n> a miner could always just mine empty blocks and make the blockchain layer\n> worthless, but it is impractical for them to do so since they would earn\n> less compared to a miner who honestly adds new transactions to the blocks\n> and thereby earn fees from those).\n>\n\nYes, it would be expensive both in server costs and in cost-of-capital\nlocked up in nodes. I believe incentives are aligned correctly.\n\n\n>\n> (the above does not protect against running multiple nodes to get around\n> any per-node limit, by the way; if running one honestly-forwarding node is\n> at all lucrative, running more honestly-forwarding nodes should be more\n> lucrative.\n> thus, the above only protects against nodes that are not\n> honestly-forwarding, but cannot protect against multiple\n> honestly-forwarding nodes being run by the same entity to get around\n> per-node limits you might impose)\n>\n\nYou've convinced me that node liquidity limits do not make sense. I am\nmoving instead to minimum node capacity requirements with no maximum number\nof channels or capacity limits.\n\n\n> Further, adding more OTS-like servers may still allow a minority\n> OTS-server to effectively censor hated furries like you.\n> Remember, we now require that SBN-nodes have 99% uptime by showing 99\n> proof-of-uptime entries in the last 100 blocks.\n> If I have enough OTS-servers to comprise at least 2% of all OTS-servers,\n> then I can force you, you furry, to have at most 98% uptime recorded\n> onchain, thus effectively censoring you from the SBN.\n> This might be helped by adding some salting of some kind, and having\n> OTS-server protocol to accept any blinded commitments that will only be\n> opened after they are actually committed onchain, though.\n>\n\nI like the sound of blinded commitments. Any suggestions for where to read\nup on this approach?\n\n\n>\n> Alternately, groups of independent citizens can just put a fund in a\n> k-of-n address and always continuously spend that k-of-n address to itself\n> on every block, with the proof-of-uptimes of the group embedded in a Merkle\n> tree committed to in the `R` of the signature (i.e. sign-to-contract).\n> With Schnorr this allows the k-of-n to be hidden in a single signature as\n> well, though the signing ritual would have to be significantly more complex\n> (I have not considered the proper signing ritual) to ensure that the\n> generated `R` indeed commits to the Merkle tree root of the group uptime\n> proofs, and k-of-n requires a complicated setup, and k-of-n is susceptible\n> to majority takeover (i.e. it can be spent without your key, thus not your\n> coins) and sybilling.\n> This may also combine well with the need to make proof-of-uptime expensive\n> (else it would be cheap to take over SBN).\n> Though of course our colleagues over in bitcoin-dev will cry over the\n> blockchain bloat such a scheme would have, you spoony furry, that is\n> precisely why furries should be censored.\n>\n>\nHow would this approach differ from the OTS server setup? OTS is using\nMerkle trees no?\n\n(taking the above offchain is possible, but the entire point of doing the\n> above onchain is that it proves onlineness, whereas offchain does not prove\n> that anything is online at each block, only at the blocks where the\n> offchain system is pushed onchain.)\n>\n> Regards,\n> ZmnSCPxj\n>\n\nBest,\n\nRobert\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200318/7041ecbf/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-03-18T23:35:56",
                "message_text_only": "Good morning Robert,\n\n\n> > This shows the issue: what they measured was *the number of rat tails shown*, not *the reduction of rats in the city*, and so they got shown a lot of rat tails (at the expense of actively increasing the number of rats in the city, since they were now being grown in rat farms).\n> >\n> > Similarly, I could attack the SBN by having a cheap RaspPi (or maybe Arduino) continuously attesting its uptime, but not actually running any Lightning node software, so that paths through my pathetic RaspPi \"node\" will always fail.\n> > With enough cheap RaspPis and some HODLed funds in 2-of-2s (where both pubkeys are mine anyway), I can ensure that most of SBN is composed of my \"nodes\" and make it worthless.\n>\n> I guess it wasn't explicit in my proposal, but the intention is for SBN nodes to be LN nodes. Thus, in order to be accepted into SBN, your node would have to run the LN software. Is there a way to set up an LN node, connect to other nodes, and then not allow routing of payments through your node? If so, then I don't believe SBN would be any more in danger of this scenario than vanilla LN.\u00a0\n\nAnyone who can update the software can easily create a faked node that appears to have completely legit channels to one or more real nodes.\nBasically, I would just write a little bit of signing code using the node secret of a real node I control, put up a UTXO somewhere with a new ephemeral key I control plus the node id of my real node, and voila I can have a non-working \"channel\" that attests to a non-working \"node\" on the LN, and I can make that non-working \"node\" attest its uptime over SBN using a cheap 5mBTC RaspPi.\nI can make the \"channel\" UTXO almost as secure as my hardware-wallet-locked funds by making the non-working \"node\" id be a key from my hardware wallet, and then this fund is no more than me HODLing BTC onchain with my hardware wallet (channels are 2-of-2 so even if my real node is compromised and its private key stolen, the funds in my non-working \"channel\" are still protected by my hardware wallet key).\nI can easily run a few real nodes, over Tor .onion services, on a single low-end server, and then have them attest to non-working \"channels\" attesting to a few non-working \"nodes\" on the LN, and then run a simple SBN self-attestation daemon on the RaspPi to attest the faked \"nodes\" on the SBN.\nSince the SBN is intended to interconnect to the LN, the real nodes do not need to have a lot of capitalization themselves or be on the SBN, so for example I could have one or two real node on the SBN and a few throwaway real nodes with little capitalization, interconnected with channels to the faked node.\n\nI might do this, for example, if Roger Ver suddenly offers me a few hundred BTC (not BCH, sorry) to attack the SBN and reduce its UX to not much better than the LN.\n\n>\n> > Against this, we can observe that the blockchain layer itself is ultimately protected by the economics of mining.\n> > Thus, the blockchain security cannot be better than economically-infeasible security, and Lightning, as it is anchored to the blockchain, also cannot get better than economically-infeasible security.\n> > If attesting its own uptime is expensive enough, then every additional node that I fake is going to be an additional expense, and it may become impractical for me to take over the entire SBN unless I work honestly and actually forward payments and earn fees from it (in much the same way that a miner could always just mine empty blocks and make the blockchain layer worthless, but it is impractical for them to do so since they would earn less compared to a miner who honestly adds new transactions to the blocks and thereby earn fees from those).\n>\n> Yes, it would be expensive both in server costs and in cost-of-capital locked up in nodes. I believe incentives are aligned correctly.\n\nYes, but it might not be enough --- we want SBN attestation itself to be a cost, and thus SBN might want to charge higher than current feerates for premium reliable service.\n\n\n> > Further, adding more OTS-like servers may still allow a minority OTS-server to effectively censor hated furries like you.\n> > Remember, we now require that SBN-nodes have 99% uptime by showing 99 proof-of-uptime entries in the last 100 blocks.\n> > If I have enough OTS-servers to comprise at least 2% of all OTS-servers, then I can force you, you furry, to have at most 98% uptime recorded onchain, thus effectively censoring you from the SBN.\n> > This might be helped by adding some salting of some kind, and having OTS-server protocol to accept any blinded commitments that will only be opened after they are actually committed onchain, though.\n>\n> I like the sound of blinded commitments. Any suggestions for where to read up on this approach?\u00a0\n\nGenerally when we say \"commitment\" that is a cryptographic commitment scheme, commitments *are* blinded already.\nThey are cryptographically blinding and cryptographically binding (you have a choice between: information-theoretic blinding and computationally-infeasible binding, or computationally-infeasible blinding and information-theoretic binding).\nThe issue is if an OTS-server demands to see the opening of a commitment before adding it to their Merkle trees (for example, if it becomes expensive to hire an OTS-server, they might offer a discount for this).\n\nBasically a comnitment can be as simple as a hash of a salt plus the information you are committing to.\nIf the OTS-server demands to see the preimage before adding the hash, then we have a problem because the OTS-server can now filter depending on the information it sees in the preimage.\n\nWhat we need to do is basically have every SBN node insist on using an OTS-server that does not demand the opening of the commitment, just accepts the commitment (which is already blinded).\n\n\n> \u00a0\n>\n> > Alternately, groups of independent citizens can just put a fund in a k-of-n address and always continuously spend that k-of-n address to itself on every block, with the proof-of-uptimes of the group embedded in a Merkle tree committed to in the `R` of the signature (i.e. sign-to-contract).\n> > With Schnorr this allows the k-of-n to be hidden in a single signature as well, though the signing ritual would have to be significantly more complex (I have not considered the proper signing ritual) to ensure that the generated `R` indeed commits to the Merkle tree root of the group uptime proofs, and k-of-n requires a complicated setup, and k-of-n is susceptible to majority takeover (i.e. it can be spent without your key, thus not your coins) and sybilling.\n> > This may also combine well with the need to make proof-of-uptime expensive (else it would be cheap to take over SBN).\n> > Though of course our colleagues over in bitcoin-dev will cry over the blockchain bloat such a scheme would have, you spoony furry, that is precisely why furries should be censored.\n>\n> How would this approach differ from the OTS server setup? OTS is using Merkle trees no?\n\n*Currently* the single OTS server available is, well, a single server run by a single individual, Peter Todd, with Peter shouldering all the (very tiny) expenses of running that server.\nIf you make the reliability of SBN dependent on this single server, it paints a big target on the single OTS server and its operator, which is bad.\n\nIf instead anyone can run an SBN attestation server, this would use roughly the same technologies (blockchain-embedded Merkle trees of commitments) but would be distributed at least, and follow the principle of Risk Sharing (at the cost of increased blockchain usage).\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Superbolt Proposal - a professionally run LN subset delivering superior UX",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Robert Allen",
                "ZmnSCPxj"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 48998
        }
    },
    {
        "title": "[Lightning-dev] Locking of funds by both parties in HTLC to enforce penalty",
        "thread_messages": [
            {
                "author": "Subhra Mazumdar",
                "date": "2020-03-06T05:58:36",
                "message_text_only": "Hi,\n      I was reading the paper by Poon and Dryja on Bitcoin Lightning\nNetwork and was going through the construction of HTLC. Suppose 2 parties A\nand B have a channel with each party locking 0.5 BTC. Suppose A wants to\ntransfer 0.1 BTC to B contingent to the knowledge of R : H=h(R) produced\nwithin a locktime of say t days. So the script output for A is -\n1. 0.4 BTC to A\n2. 0.5 BTC to B\n3. 0.1 BTC locked in HTLC between A & B.\nWhy we cannot set the terms as say 0.4 BTC to A, 0.2 BTC to B and 0.4 BTC\nto HTLC, where HTLC output can follow either of the paths - If B produces R\nwithin t days then it gets back 0.4 BTC else after t days A can broadcast\nwith 0.4 BTC going to the A? This prevents B from not responding (and\ninduce possibly griefing attack across a longer path by withholding the\nsolution) since it will lose out 0.3 BTC. What can be the problem if the\nterms of HTLC itself tries to enforce a penalty on the counterparty?\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200306/6350cd37/attachment.html>"
            },
            {
                "author": "Lloyd Fournier",
                "date": "2020-03-06T06:30:27",
                "message_text_only": "Hi Subhra,\n\nAfaik, the only problem is the one you identified, it doesn't work across\nmultiple hops but only for the final hop. This penalty idea is the basis\nfor doing atomc swaps fairly:\nhttps://coblox.tech/docs/financial_crypto19.pdf\n\nLL\nOn Fri, Mar 6, 2020 at 4:58 PM Subhra Mazumdar <\nsubhra.mazumdar1993 at gmail.com> wrote:\n\n> Hi,\n>       I was reading the paper by Poon and Dryja on Bitcoin Lightning\n> Network and was going through the construction of HTLC. Suppose 2 parties A\n> and B have a channel with each party locking 0.5 BTC. Suppose A wants to\n> transfer 0.1 BTC to B contingent to the knowledge of R : H=h(R) produced\n> within a locktime of say t days. So the script output for A is -\n> 1. 0.4 BTC to A\n> 2. 0.5 BTC to B\n> 3. 0.1 BTC locked in HTLC between A & B.\n> Why we cannot set the terms as say 0.4 BTC to A, 0.2 BTC to B and 0.4 BTC\n> to HTLC, where HTLC output can follow either of the paths - If B produces R\n> within t days then it gets back 0.4 BTC else after t days A can broadcast\n> with 0.4 BTC going to the A? This prevents B from not responding (and\n> induce possibly griefing attack across a longer path by withholding the\n> solution) since it will lose out 0.3 BTC. What can be the problem if the\n> terms of HTLC itself tries to enforce a penalty on the counterparty?\n>\n> --\n> Yours sincerely,\n> Subhra Mazumdar.\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200306/41465743/attachment.html>"
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-03-06T06:34:29",
                "message_text_only": "But wont the decision of penalty be based on what incoming contract expects\nfrom a node ? Suppose there is a contract between A and B and then B and C,\nwhere A wants to transfer money to C. So if it is the case that A impose\npenalty on B using its local HTLC, won't B put the same clause on C as well\nso that in case C misbehaves it is able to spool out the penalty for the\nrest of the path from C itself ?\n\nOn Fri, Mar 6, 2020 at 12:00 PM Lloyd Fournier <lloyd.fourn at gmail.com>\nwrote:\n\n> Hi Subhra,\n>\n> Afaik, the only problem is the one you identified, it doesn't work across\n> multiple hops but only for the final hop. This penalty idea is the basis\n> for doing atomc swaps fairly:\n> https://coblox.tech/docs/financial_crypto19.pdf\n>\n> LL\n> On Fri, Mar 6, 2020 at 4:58 PM Subhra Mazumdar <\n> subhra.mazumdar1993 at gmail.com> wrote:\n>\n>> Hi,\n>>       I was reading the paper by Poon and Dryja on Bitcoin Lightning\n>> Network and was going through the construction of HTLC. Suppose 2 parties A\n>> and B have a channel with each party locking 0.5 BTC. Suppose A wants to\n>> transfer 0.1 BTC to B contingent to the knowledge of R : H=h(R) produced\n>> within a locktime of say t days. So the script output for A is -\n>> 1. 0.4 BTC to A\n>> 2. 0.5 BTC to B\n>> 3. 0.1 BTC locked in HTLC between A & B.\n>> Why we cannot set the terms as say 0.4 BTC to A, 0.2 BTC to B and 0.4 BTC\n>> to HTLC, where HTLC output can follow either of the paths - If B produces R\n>> within t days then it gets back 0.4 BTC else after t days A can broadcast\n>> with 0.4 BTC going to the A? This prevents B from not responding (and\n>> induce possibly griefing attack across a longer path by withholding the\n>> solution) since it will lose out 0.3 BTC. What can be the problem if the\n>> terms of HTLC itself tries to enforce a penalty on the counterparty?\n>>\n>> --\n>> Yours sincerely,\n>> Subhra Mazumdar.\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200306/85f11fb8/attachment.html>"
            },
            {
                "author": "Lloyd Fournier",
                "date": "2020-03-06T06:46:24",
                "message_text_only": "If you can atomically set up both those penalties atomically then that\nwould be a big breakthrough. It looks impossible. The problem is one will\nbe set up before the other and it is only fair if both are set up at the\nsame time.\n\nLL\n\nOn Fri, Mar 6, 2020 at 5:34 PM Subhra Mazumdar <\nsubhra.mazumdar1993 at gmail.com> wrote:\n\n> But wont the decision of penalty be based on what incoming contract\n> expects from a node ? Suppose there is a contract between A and B and then\n> B and C, where A wants to transfer money to C. So if it is the case that A\n> impose penalty on B using its local HTLC, won't B put the same clause on C\n> as well so that in case C misbehaves it is able to spool out the penalty\n> for the rest of the path from C itself ?\n>\n> On Fri, Mar 6, 2020 at 12:00 PM Lloyd Fournier <lloyd.fourn at gmail.com>\n> wrote:\n>\n>> Hi Subhra,\n>>\n>> Afaik, the only problem is the one you identified, it doesn't work across\n>> multiple hops but only for the final hop. This penalty idea is the basis\n>> for doing atomc swaps fairly:\n>> https://coblox.tech/docs/financial_crypto19.pdf\n>>\n>> LL\n>> On Fri, Mar 6, 2020 at 4:58 PM Subhra Mazumdar <\n>> subhra.mazumdar1993 at gmail.com> wrote:\n>>\n>>> Hi,\n>>>       I was reading the paper by Poon and Dryja on Bitcoin Lightning\n>>> Network and was going through the construction of HTLC. Suppose 2 parties A\n>>> and B have a channel with each party locking 0.5 BTC. Suppose A wants to\n>>> transfer 0.1 BTC to B contingent to the knowledge of R : H=h(R) produced\n>>> within a locktime of say t days. So the script output for A is -\n>>> 1. 0.4 BTC to A\n>>> 2. 0.5 BTC to B\n>>> 3. 0.1 BTC locked in HTLC between A & B.\n>>> Why we cannot set the terms as say 0.4 BTC to A, 0.2 BTC to B and 0.4\n>>> BTC to HTLC, where HTLC output can follow either of the paths - If B\n>>> produces R within t days then it gets back 0.4 BTC else after t days A can\n>>> broadcast with 0.4 BTC going to the A? This prevents B from not responding\n>>> (and induce possibly griefing attack across a longer path by withholding\n>>> the solution) since it will lose out 0.3 BTC. What can be the problem if\n>>> the terms of HTLC itself tries to enforce a penalty on the counterparty?\n>>>\n>>> --\n>>> Yours sincerely,\n>>> Subhra Mazumdar.\n>>>\n>>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>>\n>\n> --\n> Yours sincerely,\n> Subhra Mazumdar.\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200306/d4a9eca8/attachment-0001.html>"
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-03-06T07:03:20",
                "message_text_only": "Can you send the draft on fair atomic swap? Also the scenario stated in the\npdf you have shared is based on exchange of asset. But here I am not trying\nto work on different ledger A to B and B to A. Here it deals with just\nsimple transfer of funds from A to B. So whatever HTLC A establishes with\nB, is it not the case where just one HTLC from A to B is enough? Why do we\nneed another HTLC to be established from B to A ?  To clarify this, we have\ntwo situation -\n1. HTLC A & B (on channel AB): both A and B lock say 0.1 BTC each i.e. 0.2\nBTC\n2. HTLC A&B (on channel AB) : A locks 0.1 BTC, HTLC B&A (on channel BA): B\nlocks 0.1 BTC\n\nPardon me if I am wrong but I am still confused why situation 1 will not be\npossible ?\n\nOn Fri, Mar 6, 2020 at 12:00 PM Lloyd Fournier <lloyd.fourn at gmail.com>\nwrote:\n\n> Hi Subhra,\n>\n> Afaik, the only problem is the one you identified, it doesn't work across\n> multiple hops but only for the final hop. This penalty idea is the basis\n> for doing atomc swaps fairly:\n> https://coblox.tech/docs/financial_crypto19.pdf\n>\n> LL\n> On Fri, Mar 6, 2020 at 4:58 PM Subhra Mazumdar <\n> subhra.mazumdar1993 at gmail.com> wrote:\n>\n>> Hi,\n>>       I was reading the paper by Poon and Dryja on Bitcoin Lightning\n>> Network and was going through the construction of HTLC. Suppose 2 parties A\n>> and B have a channel with each party locking 0.5 BTC. Suppose A wants to\n>> transfer 0.1 BTC to B contingent to the knowledge of R : H=h(R) produced\n>> within a locktime of say t days. So the script output for A is -\n>> 1. 0.4 BTC to A\n>> 2. 0.5 BTC to B\n>> 3. 0.1 BTC locked in HTLC between A & B.\n>> Why we cannot set the terms as say 0.4 BTC to A, 0.2 BTC to B and 0.4 BTC\n>> to HTLC, where HTLC output can follow either of the paths - If B produces R\n>> within t days then it gets back 0.4 BTC else after t days A can broadcast\n>> with 0.4 BTC going to the A? This prevents B from not responding (and\n>> induce possibly griefing attack across a longer path by withholding the\n>> solution) since it will lose out 0.3 BTC. What can be the problem if the\n>> terms of HTLC itself tries to enforce a penalty on the counterparty?\n>>\n>> --\n>> Yours sincerely,\n>> Subhra Mazumdar.\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200306/0f0cf04d/attachment.html>"
            },
            {
                "author": "Lloyd Fournier",
                "date": "2020-03-06T07:22:41",
                "message_text_only": "> Why do we need another HTLC to be established from B to A ?\n\nWe don't. This wasn't what I was saying. The atomic swap example was just\nto show that your idea does exist in a different context. An atomic swap\ncan be viewed as a payment A -> B -> A where B switches the currency.\n\n> Pardon me if I am wrong but I am still confused why situation 1 will not\nbe possible ?\n\nIt is possible. In A -> B, A is able to punish B for not revealing secret.\nThe problem is with A -> B -> C, the HTLCs need to be set up from left to\nright, A can't punish B for not revealing secret because he doesn't know\nit. B cannot set up the HTLC to C before having the HTLC from A. So it\ndoesn't work -- or at least that's the conventional conclusion. To\nsummarise:\n\nA -> B : punishment works\nA -> B -> A: punishment works\nA -> B -> C: it can't work (we think)\n\nLL\n\nOn Fri, Mar 6, 2020 at 6:03 PM Subhra Mazumdar <\nsubhra.mazumdar1993 at gmail.com> wrote:\n\n> Can you send the draft on fair atomic swap? Also the scenario stated in\n> the pdf you have shared is based on exchange of asset. But here I am not\n> trying to work on different ledger A to B and B to A. Here it deals with\n> just simple transfer of funds from A to B. So whatever HTLC A establishes\n> with B, is it not the case where just one HTLC from A to B is enough? Why\n> do we need another HTLC to be established from B to A ?  To clarify this,\n> we have two situation -\n> 1. HTLC A & B (on channel AB): both A and B lock say 0.1 BTC each i.e. 0.2\n> BTC\n> 2. HTLC A&B (on channel AB) : A locks 0.1 BTC, HTLC B&A (on channel BA): B\n> locks 0.1 BTC\n>\n> Pardon me if I am wrong but I am still confused why situation 1 will not\n> be possible ?\n>\n> On Fri, Mar 6, 2020 at 12:00 PM Lloyd Fournier <lloyd.fourn at gmail.com>\n> wrote:\n>\n>> Hi Subhra,\n>>\n>> Afaik, the only problem is the one you identified, it doesn't work across\n>> multiple hops but only for the final hop. This penalty idea is the basis\n>> for doing atomc swaps fairly:\n>> https://coblox.tech/docs/financial_crypto19.pdf\n>>\n>> LL\n>> On Fri, Mar 6, 2020 at 4:58 PM Subhra Mazumdar <\n>> subhra.mazumdar1993 at gmail.com> wrote:\n>>\n>>> Hi,\n>>>       I was reading the paper by Poon and Dryja on Bitcoin Lightning\n>>> Network and was going through the construction of HTLC. Suppose 2 parties A\n>>> and B have a channel with each party locking 0.5 BTC. Suppose A wants to\n>>> transfer 0.1 BTC to B contingent to the knowledge of R : H=h(R) produced\n>>> within a locktime of say t days. So the script output for A is -\n>>> 1. 0.4 BTC to A\n>>> 2. 0.5 BTC to B\n>>> 3. 0.1 BTC locked in HTLC between A & B.\n>>> Why we cannot set the terms as say 0.4 BTC to A, 0.2 BTC to B and 0.4\n>>> BTC to HTLC, where HTLC output can follow either of the paths - If B\n>>> produces R within t days then it gets back 0.4 BTC else after t days A can\n>>> broadcast with 0.4 BTC going to the A? This prevents B from not responding\n>>> (and induce possibly griefing attack across a longer path by withholding\n>>> the solution) since it will lose out 0.3 BTC. What can be the problem if\n>>> the terms of HTLC itself tries to enforce a penalty on the counterparty?\n>>>\n>>> --\n>>> Yours sincerely,\n>>> Subhra Mazumdar.\n>>>\n>>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>>\n>\n> --\n> Yours sincerely,\n> Subhra Mazumdar.\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200306/a36dadce/attachment.html>"
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-03-06T07:33:58",
                "message_text_only": "So that means if we follow a right to left approach for establishing HTLC\ni.e. from B to C first then A to B, is there a chance? But I guess that's\ndoesn't sound logical. Also the point raised by you is valid. B can never\nbe punished if it is not possessing the secret at the point of\nestablishment of HTLC. So in that case this becomes a challenge, A to B , B\nto A atomicity. What if A to B HTLC is established but B to A there is no\ncontract.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200306/7f5dd937/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Locking of funds by both parties in HTLC to enforce penalty",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Subhra Mazumdar",
                "Lloyd Fournier"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 14778
        }
    },
    {
        "title": "[Lightning-dev] Refunds without offers",
        "thread_messages": [
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2020-03-06T16:45:07",
                "message_text_only": "# Refunds without offers\n\n## Context\nDisclaimers: Sorry in advance if these ideas were discussed in some\nother threads and\ndiscarded or something.\n\npayer=alice\npayee=bob\n\nHi all,\n\nin https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-November/002276.html\nrusty proposes a way to deal with refunds, but I wonder if refunds in\nlightning can be solved in a more general way that doesn't require\nimplementations to support all the features included in the offers\nbolt proposal while that's in progress.\n\nWhat follows is a simplified analysis and a series of incremental\ndesign proposals to solve the problem.\nSome of them satisfying new requirements.\nSome of them kind of orthogonal to each other\n\n## Analysis\n\nLet's summarize some requirements that seem to be taken into account\nin that proposal:\n\nA) We want the payer to prove it was her who paid to the payee.\n\nWhether that is enough for the payee to proceed with a refund or not\nis out of the scope\nof this proposal, it depends on the business and the situation.\n\nB) We don't want the payer to need to reveal its node's id to proof she paid\n\nThat would partially defeat the purpose of using onion routing for\npayments in the first place.\n\nC) If a refund occurs, the payee must be able to prove it occurred.\n\n## Design\n\nLet's assume the payee has an http server url to process refunds he\nconsiders to be legitimate beyond the proof of payment.\nFor the purpose of this document, it is assumed the payee always\naccepts refunds as legitimate provided requirement A is met in the\npayer's request.\n\n### Design D1: Optionally provide a refund_pk field in the hop_payload\nto the payee\n\nA naive approach at the http server could get the following arguments:\n\n- refund_invoice (this kind of breaks requirement B, although not necessarily)\n- payment_hash (so that the payee can identify the claimed refund)\n- payment_preimage\n- refund_signature (this signs both payment_hash and the payment_hash\n  in refund_invoice)\n\nThe public key (refund_pk) for the refund_signature could be simply\noptionally transmitted in the hop_payload to the payee.\nInvoices could use a bit to signal whether they will read this\nrefund_pk field or not.\n\nBut by default, a refund_invoice reveals your node id as a payer,\nsomething you didn't need to do before and breaks requirement B.\nThere's ways around it like rendezvous payments.\n\n### Design D2: No invoice needed for refund\n\nAnother option could be to directly replace refund_invoice with a\nrefund_onion argument plus a refund_payment_hash to be signed with\nrefund_signature.\n\nThe refund_payment_hash argument is needed when using refund_onion\nargument instead of refund_invoice, since the payee has no invoice to\nread the hash from.\n\nThis way, the payer asking for a refund doesn't reveal its own node\nid, and the route used to pay could be reused backwards without it being\nrevealed to the payee (other routes are possible too).\n\nThe payee doesn't even need to calculate any route since it is\nprovided to him without being him able to see anything beyond what he\nneeds to know to pay to one of his channels by following the onion received,\nand what payment_hash he is paying to and needs to store,\nto be able to prove he refunded the payer when he needs to\n(requirement C).\n\nThis should be compatible with trampoline payments provided they\nrequire the payee to be a trampoline-compatible node.\n\n### Design D3: Ephemeral merkle key for the payee's onion\n\nThe payer knows the ephemeral key for the payee and all the components\nneeded to calculate it before sending any onion to any of her channels' node.\nBut that's only for the payee to decrypt, not for the payer to sign.\n\nIn other words, the ephemeral key for the onion destined for the payer and that\npayment_hash is calculated by f_ephemeral(payee_pk, more_stuff).\n\nf_ephemeral(payee_pk, more_stuff) could be replaced with:\ng_ephemeral(payee_pk, refund_pk, more_stuff)\n\nThis can be done in a way in which all the previous properties, that is:\n\n- payer can still privately communicate with payee by encrypting to\n  g_ephemeral instead of f_ephemeral.\n- payee doesn't know payer's id\n\nBut adding the properties:\n\n- payer can prove she was the payer by revealing a merkle tree to the\npayee with:\n  + The result of g_ephemeral as the root of the tree\n  + payee_pk in a specific position of the tree\n  + refund_pk in a specific position of the tree\n  + more_stuff is allowed in the rest of the tree\n\nThe payer transmitting refund_pk only when it's needed removes the\nneed for refund_pk in the hop_payload to the payee.\n\n### Design D4: No need for http server\n\nThe http server answering refund requests shouldn't be needed given the\npayee already runs a lightning node with id known to the payer and a\nworking route just used to pay him.\n\nJust like in D1, all the argument required to execute a refund could\nbe simply transmitted in the hop_payload to the payee.\n\nBut refund_onion could get very large, we're talking onion_packet\nlarge, not single hop_payload large.\n\nThe refund_onion data could be implicitly contained in the filler of\nhop_payloads,\ninstead of in the individual hop_payload directed to the payee.\n\nWhen calculating the route, the payer could act like it is a payment\nto itself composed of 2 payments: the actual payment and the refund payment.\n\nThey have different payment hashes, but that's fine as long as they\nboth fit into the same onion_packet.\n\nAs examples with 20 fixed sized legacy `hop_data` payloads:\n\n- the payment could have 10 hops and the refund 10 hops\n- the payment could have 15 hops and the refund 5 hops\n- the payment could have 5 hops and the refund 15 hops\n\n### Design D5: Back to the past's limits\n\nBut that last limitation isn't practical, especially since most\npayments won't actually need a refund. So D4 doesn't seem like an\nimprovement.\n\nPerhaps another way to remove the need for the http server (or some\nother server) is having the payer request a refund to the payee by\ndoing a new payment (any amount) with, again, extra payload with the\nrefund request data. But the refund_onion may not fit there.\n\nI don't like this option much either, I think my favorite option here is D3.\n\n## Questions\n\n- Does this make any sense to you?\n- How could this be improved?\n- Do you have better ideas for refunds?"
            }
        ],
        "thread_summary": {
            "title": "Refunds without offers",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Jorge Tim\u00f3n"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 6276
        }
    },
    {
        "title": "[Lightning-dev] A proposal for up-front payments.",
        "thread_messages": [
            {
                "author": "Joost Jager",
                "date": "2020-03-09T12:45:24",
                "message_text_only": "On Thu, Feb 20, 2020 at 4:22 AM Anthony Towns <aj at erisian.com.au> wrote:\n\n> On Tue, Feb 18, 2020 at 10:23:29AM +0100, Joost Jager wrote:\n> > A different way of mitigating this is to reverse the direction in which\n> the\n> > bond is paid. So instead of paying to offer an htlc, nodes need to pay to\n> > receive an htlc. This sounds counterintuitive, but for the described\n> jamming\n> > attack there is also an attacker node at the end of the route. The\n> attacker\n> > still pays.\n>\n> I think this makes a lot of sense. I think the way it would end up working\n> is that the further the route extends, the greater the payments are, so:\n>\n>   A -> B   : B sends A 1msat per minute\n>   A -> B -> C : C sends B 2msat per minute, B forwards 1msat/min to A\n>   A -> B -> C -> D : D sends C 3 msat, etc\n>   A -> B -> C -> D -> E : E sends D 4 msat, etc\n>\n> so each node is receiving +1 msat/minute, except for the last one, who's\n> paying n msat/minute, where n is the number of hops to have gotten up to\n> the last one. There's the obvious privacy issue there, with fairly\n> obvious ways to fudge around it, I think.\n>\n\nYes, that is definitely a good point. Otherwise the attacker can hold the\nhtlc at the end of the route and pay the hold fee to its predecessor. The\nhold fee will propagate  back to the first node (and increase along the\nway). The first node is also owned by the attacker. Meaning there again is\nno cost for the attacker to jam the channel.\n\nIn the mean time, I've been jamming channels on testnet myself. See what\npathfinding changes are needed to do it efficiently and check out the\neffect. There was the expected outcome of a channel being jammed for as\nlong as I wanted. But I also learned something else:\n\nTraversing a path takes time, especially if the path is optimized for\nmaximum length and contains loops. In particular when some of the nodes\nand/or network connections are slow, the total round-trip from the sender\npoint of view can get seriously long. Even if the final node immediately\nfails the htlc, the nodes at the start of the path still see their outgoing\nhtlcs being held for quite some time.\n\nWhat this means is that the channel jamming attack can also be executed\nwithout the attacker controlling the final node. The attacker can construct\nlong routes for which it doesn't matter where they end. Suppose it takes 1\nminute for the htlc to be released again on the channel that is targeted\n(the round trip from the targeted channel to the final node). The attacker\njust needs to launch htlcs at a rate higher than one per minute to\n(eventually) saturate the channel. In my experiment, I launched many htlcs\nconcurrently, which seemed to make the total latency even longer. Probably\nbecause those htlcs then start competing for limited resources at the route\nhops.\n\nThis variation does require more action from the attacker. They need to\nkeep refreshing htlcs that return back to them. Therefore it may be easier\nto address this with some form of rate limiting, although that has its own\ndownsides.\n\nJoost\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200309/d26ea327/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "A proposal for up-front payments.",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Joost Jager"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3223
        }
    },
    {
        "title": "[Lightning-dev] [DRAFT] BOLT 13(?): WatchTower protocol",
        "thread_messages": [
            {
                "author": "Sergi Delgado Segura",
                "date": "2020-03-09T17:49:47",
                "message_text_only": "Hi all,\n\nI've been working on a revision to BOLT13's proposal with the comments\nreceived over the list (h/t Rusty and Antoine), and from conversations with\ndifferent people from the community at Advancing Bitcoin and over email\nthis last weeks.\n\nThis revision includes user accounts, payment methods, and message signing,\nas well as improvements over the original proposal.\n\nOn top of that, there are a few things I'd love to add in a future revision:\n\n- Proofs of storage for subscription renewals in s similar fashion to Dead\nMen's Button (h/t Joost Jager).\n- Recognition codes for a more private approach to subscriptions (thanks\nZmnSCPxj for the extensive discussion over the last week).\n\nAs the last time, there's a list discussion topics at the end, with things\nI'd love to hear your opinion on.\n\nBest,\n\nPS: The documents can also be found at https://github.com/sr-gi/bolt13\n\n----\n\n# Watchtower protocol specification (BOLT DRAFT REV.1)\n\n## Overview\n\nAll off-chain protocols assume the user remains online and synchronised\nwith the network. To alleviate this assumption, customers can hire a third\nparty watching service (a.k.a Watchtower) to watch the blockchain and\nrespond to channel breaches on their behalf.\n\nAt a high level, every time there is a new transfer in the client's\nlightning channel, the client sends the Watchtower an encrypted penalty\ntransaction and a transaction locator. Internally, the Watchtower maps the\ntransaction locator to the encrypted penalty transaction. If there is a\nbreach in the lightning channel, the Watchtower can identify it with the\nlocator, and use the commitment transaction ID to compute the decryption\nkey. With the decryption key, the tower decrypt the encrypted penalty\ntransaction and broadcast it to the network. Therefore, the Watchtower does\nnot learn any information about the client's channel unless there is a\nchannel breach (channel-privacy).\n\nDue to replace-by-revocation Lightning channels, the client should send\ndata to the Watchtower for every new update in the channel, otherwise the\nWatchtower cannot respond to all potential breaches.\n\nFinally, optional extensions can be offered by the Watchtower to provide\nstronger guarantees to the client, such as a signed receipt for every new\njob. The rationale for the receipt is to build an _accountable_ Watchtower\nas the customer can later use it as publicly verifiable evidence if the\nWatchtower fails to protect them.\n\nThe scope of this document includes:\n\n- A protocol for client/server communication.\n- A payment protocol between the customer and Watchtower.\n- How to build appointments for the Watchtower, including key/locator\nderivation and data encryption.\n- A format for the signed receipt.\n\nThe scope of this bolt does not include:\n\n - Watchtower server discovery.\n\nFor the rest of this document we will use server/tower and client/Lightning\nnode indistinguishably.\n\n## Table of Contents\n* [Watchtower discovery](#watchtower-discovery)\n* [Watchtower services](#watchtower-discovery)\n* [Basic Service](#basic-service)\n* [Extensions](#extensions)\n* [User authentication](#user-authentication-and-subscriptions)\n* [The `register_top_up` message](#the-register_top_up-message)\n* [The `subscription_details` message](#the-subscription_details-message)\n* [Sending appointments to the tower](#sending-appointments-to-the-tower)\n  * [The `add_update_appointment`\nmessage](#the-add_update_appointment-message)\n  * [The `appointment_accepted` message](#the-appointment_accepted-message)\n  * [The `appointment_rejected` message](#the-appointment_rejected-message)\n* [Deleting appointments](#deleting-appointments)\n* [The `delete_appointment` message](#the-delete_appointment-message)\n* [The `deletion_accepted` message](#the-deletion_accepted-message)\n* [The `deletion_rejected` message](#the-deletion_rejected-message)\n* [Transaction Locator and Encryption\nKey](#transaction-locator-and-encryption-key)\n* [Encryption Algorithms and\nParameters](#encryption-algorithms-and-parameters)\n* [Payment Modes](#payment-modes)\n* [Data serialisation and signing](#data-serialisation-and-signing)\n* [No compression of penalty\ntransaction](#no-compression-of-penalty-transaction)\n* [Attacks on towers](#attacks-on-towers)\n\n## Watchtower discovery\n\nWe have not defined how a client can find a list of servers to hire yet. We\nassume the client has found a server and the server is offering a watching\nservice.\n\n## Watchtower services\n\n### Basic Service\nThe customer can hire the Watchtower to watch for breaches on the\nblockchain and relay a penalty transaction on their behalf. The customer\nreceives an acknowledgement when the Watchtower has accepted the job, but\nthe hiring protocol does not guarantee the transaction inclusion.\n\n### Extensions\nExtensions build on top of the basic service and are optionally provided by\nthe tower. Different extensions can be offered by the tower. For now we are\ndefining a single type of extension: `accountability`.\n\n#### `accountability`\n\nA Watchtower provides a signed receipt to the customer. This is considered\nreputational accountability as the customer has publicly verifiable\ncryptographic evidence the Watchtower was hired. The receipt can be used to\nprove the Watchtower did not relay the penalty transaction on their behalf\nand/or request a refund.\n\n## User authentication and subscriptions\n\nUpon establishing the first connection with the tower, the client needs to\nregister a public key. The registration aims to give the user access to the\ntower's services:\n\n+-------+                                     +-------+\n|   A   |--(1)--         register        ---->|   B   |\n|       |<-(2)---  subscription_details  -----|       |\n+-------+                                     +-------+\n\n- where node A is 'client' and node B is 'server'\n\n### The `register_top_up` message\nThe `register_top_up` message contains the information required to start\nthe registration of a new public key with the tower, or to top up an\nexisting one.\n\n1. type: ? (`register_top_up`)\n2. data:\n   * [`point`:`public_key`]\n   * [`u32`: `appointment_slots`]\n   * [`u32`: `subscription_period`]\n\n#### Rationale\n\nWe define appointment (in a lack of a better word) as how the Watchtower is\nhired by a client for its watching services. Every a client updates the\nstate of one of his channels, he will send an appointment containing\ninformation related to the update. Check [Sending appointments to the\ntower](#sending-appointments-to-the-tower) for more on this.\n\n#### Requirements\n\nThe client:\n\n- MUST set `public_key` to the public key he wants to register or top up.\n- MUST set `appointment_slots` to the appointment slots he is requesting.\n- MUST set `subscription_period` to the number of blocks he is asking the\ntower to watch for channel breaches.\n\nUpon receiving a `register_top_up` message, the server:\n\n- MUST reply with a `subscription_details` message.\n\n### The `subscription_details` message\n\nThe `subscription_details` message contains information regarding the\nsubscription the tower is offering to the client, including the\nsubscription payment request if necessary.\n\n1. type: ? (`subscription_details`)\n2. data:\n* [`u16`: `appointment_max_size`]\n* [`u32`: `amount_msat`]\n3. tlvs: `wt_subscription_tlvs`\n4. types:\n1. type: 1 (`subscription_invoice`)\n2. data:\n* [`tu16*byte`: `invoice`]\n\n#### Requirements\n\nThe server:\n\n* MUST receive a `register_top_up` message before sending\n`subscription_details`.\n* MUST set `appointment_max_size` to the maximum size allowed for a single\nappointment.\n* MUST set `amount_msat` to the amount to be paid by the user for the\nservice.\n* MAY include `subscription_invoice` if it is offering a non-altruistic\nservice. If so:\n* MUST set `invoice` to a [BOLT11](\nhttps://github.com/lightningnetwork/lightning-rfc/blob/master/11-payment-encoding.md)\ninvoice.\n\nThe user:\n\n* MUST have sent `register_top_up` before receiving a\n`subscription_details` message.\n\nIf `subscription_invoice` is set:\n\n* MAY pay the [BOLT11](\nhttps://github.com/lightningnetwork/lightning-rfc/blob/master/11-payment-encoding.md)\n`invoice`.\n\n#### Rationale\n\nUser authentication with the tower is required to allow interaction with\nthe tower beyond simply sending channel updates (like requesting, updating\nor deleting channel updates). Authentication is also required to account\nfor the amount of data the client is sending to the tower, so subscriptions\nmodels can be properly defined.\n\nThe mechanism used to authenticate users by the tower is based on message\nsigning and public key recovery. During the registration phase the user\nwill request a public key registration with the tower (`public_key`).\n\n`appointment_slots` and `subscription_period` are requested by the user to\nreduce the number of messages exchanged by the two parties whilst allowing\nfor high customisation. Otherwise the tower will need to inform the user of\nwhat type of services he can apply for.\n\n`appointment_max_size` defines what is the maximum size of an appointment.\nThe tower is effectively charging for storage over time, so if an\nappointment exceeds `appointment_max_size` it will be counted as\n`ceil(len(appointment)/appointment_max_size)`.\n\nOnce the user is registered, the tower will be able to identify him by\ndoing EC recovery on his signed requests. Message signing and EC recover is\nperformed using the current approach followed by [lnd and\nc-lightning](#data-serialisation-and-signing).\n\nIf a user has filled all his appointment slots, or need to keep the data in\nthe tower for longer than the `subscription_period`, he may need to top up\nhis subscription.\n\nFor now we have only defined `subscription_invoice` as payment method.\nOther payment methods can be defined as tlv in the future.\n\n## Sending appointments to the tower\n\nOnce the client is registered, he can start sending appointments to the\ntower:\n\n+-------+                                     +-------+\n|   A   |--(1)--- add_update_appointment ---->|   B   |\n|       |<-(2)---   accepted/rejected    -----|       |\n+-------+                                     +-------+\n\n- where node A is 'client' and node B is 'server'\n\n### The `add_update_appointment` message\n\nThis message contains all the information regarding an appointment between\nthe client and the server.\n\n1. type: ? (`add_update_appointment`)\n2. data:\n   * [`16*byte`:`locator`]\n   * [`u16`: `encrypted_blob_len`]\n   * [`encrypted_blob_len*byte`:`encrypted_blob`]\n   * [`u16`: `signature_len`]\n* [`signature_len*byte`: `user_signature`]\n3. tlvs: `wt_accountability_tlvs`\n4. types:\n1. type: 1 (`user_evidence`)\n2. data:\n* [`u64 `:`to_self_delay`]\n\n#### Requirements\n\nThe client:\n\n* MUST set `locator` as specified in [Transaction Locator and Encryption\nKey](#transaction-locator-and-encryption-key).\n* MUST set `encrypted_blob` to the encryption of the `penalty_transaction`\nas specified in [Transaction Locator and Encryption\nKey](#transaction-locator-and-encryption-key).\n* MUST set `encrypted_blob_len` to the length of `encrypted_blob`.\n* MUST set `user_signature ` to the appointment signature.\n* MUST set `signature_len` to the length of `user_signature`.\n* MAY set `to_self_delay` to the `to_self_delay` requested by the client to\nits peer.\n\nThe server:\n\n* MUST compute `public_key` by performing EC recover.\n* MUST reject the appointment if the recovered `public_key` does not match\nwith any of the registered ones.\n* MAY reject the appointment if `encrypted_blob` has unreasonable size.\n\nIf `accountability` is being offered and `to_self_delay` can be found in\n`add_update_appointment`:\n\n* MUST reject the appointment if `to_self_delay` is too small.\n* MAY accept the appointment otherwise.\n\nIf the server accepts the appointment:\n\n* MUST send an `appointment_accepted` message.\n\nIf the server rejects the appointment:\n\n* MUST send an `appointment_rejected` message.\n\n\n#### Signing appointment requests\n\nAppointment request must be arranged as follows while serialised for\nsigning:\n\nlocator | encrypted_blob | to_self_delay\n\n`to_self_delay` will only be included if it is also included in the\nrequest.\n\nThe signature must be performed following [Data serialisation and\nsigning](#data-serialisation-and-signing).\n\n#### Rationale\n\nUsers must have preregistered before they can hire the Watchtower, as\ndiscussed in [User authentication](#user-authentication-and-subscriptions).\nAppointments from non-registered users are therefore rejected.\n\nA client may need to update an appointment after having sent it to the\ntower (for instance to update the fee, change the outputs, etc). The same\nmessage can be used to add new appointments or to update existing ones. If\ntwo appointments from the same user share a `locator`, the tower should\ninterpret that as an update and override the oldest. `locators` are\n`128-bit` values so unintended collisions within the same user should be\nnegligible.\n\nThe `encrypted_blob` size depends on the encrypted commitment transaction\nsize and the block size of the chosen cipher. Arbitrarily small/big\ntransaction are invalid, meaning that arbitrarily small/big\n`encrypted_blob`s will, therefore, also be invalid.\n\nThe `encrypted_blob` have to be larger than (or equal to):\n\n`cipher_block_size * ceil(minimum_viable_transaction_size /\ncipher_block_size)`\n\nand smaller than (or equal to):\n\n`cipher_block_size * ceil(maximum_viable_transaction_size /\ncipher_block_size`)\n\n`minimum_viable_transaction_size` and `maximum_viable_transaction_size`\nrefer to the minimum/maximum size required to create a valid transaction.\n\n`encrypted_blob`s outside those boundaries cannot contain valid\ntransactions, so they should be rejected.\n\nA tower should broadcast the penalty transaction right after a breach is\nseen, but should be also able to bump the fee if necessary. If\n`to_self_delay` is smaller than expected, then it can lead the tower to\nfail.\n\n### The `appointment_accepted` message\n\nThis message contains information about the acceptance of an appointment by\nthe Watchtower.\n\n1. type: ? (`appointment_accepted `)\n2. data:\n   * [`16*byte `:`locator`]\n   * [`u32`: `start_block`]\n3. tlvs: `wt_accountability_tlvs`\n4. types:\n1. type: 2 (`receipt_signature`)\n2. data:\n* [`tu16*byte`: `tower_signature`]\n\nThe server:\n\n* MUST receive `add_update_appointment` before sending an\n`appointment_accepted` message.\n* MUST set the `locator` to match the one received in\n`add_update_appointment`.\n* MUST set `start_block` to the block height where the tower will start\nlooking for breaches.\n\nIf `accountability` is being offered and `add_update_appointment` contained\n`to_self_delay`:\n\n* MUST create a receipt of the appointment.\n* MUST set `tower_signature` to the signature of the receipt as defined in\n[Data serialisation and signing](#data-serialisation-and-signing).\n\nThe client:\n\n* MUST fail the connection  if `locator` does not match any of locators the\npreviously sent to the server.\n\n#### Appointment receipt format\n\nData must be arranged in the following order to create the receipt:\n\nlocator | encrypted_blob | to_self_delay | user_signature | start_block\n\nThe receipt must be signed following [Data serialisation and\nsigning](#data-serialisation-and-signing).\n\n#### Rationale\n\n`start_block` is set by the tower so the user knows when the channel update\nwill be covered.\n\nWe assume the tower has a well-known public key and the user is aware of\nit. The receipt contains, mainly, the information provided by the user. The\nWatchtower will need to sign the receipt to provide evidence of agreement.\n\nThe `user_signature` is included in the receipt to link both the client\nrequest and the server response. Otherwise, the tower could sign a receipt\nwith different data that the one sent by the user, and the user would have\nno way to prove whether that's true or not. By signing the customer\nsignature the tower creates evidence of what the user sent, since the tower\ncannot forge the client's signature.\n\n### The `appointment_rejected` message\n\nThis message contains information about the rejection of an appointment by\nthe Watchtower.\n\n1. type: ? (`appointment_rejected `)\n2. data:\n   * [`16*byte `:`locator`]\n   * [`u16`: `rcode`]\n   * [`u16`: `reason_len`\n   * [`reason_len*byte`: `reason`]\n\nThe server:\n\n* MUST receive `add_update_appointment` before sending an\n`appointment_rejected` message.\n* MUST set the `locator` to match the one received in\n`add_update_appointment`.\n* MUST set `rcode` to the rejection code.\n* MAY set an empty `reason` field.\n* MUST set `reason_len` to length of `reason`.\n\n#### Rationale\n\nThe `appointment_rejected` message follows the approach taken by the\n`error` message defined in [BOLT#1](\nhttps://github.com/lightningnetwork/lightning-rfc/blob/master/01-messaging.md#the-error-message):\nerror codes are mandatory, whereas reasons are optional and implementation\ndependant.\n\n## Deleting appointments\n\nA client may want to delete appointments from the tower after a breach, or\nclosing a channel:\n\n+-------+                                    +-------+\n|   A   |--(1)---   delete_appointment  ---->|   B   |\n|       |<-(2)---   accepted/rejected   -----|       |\n+-------+                                    +-------+\n\n- where node A is 'client' and node B is 'server'\n\n### The `delete_appointment` message\n\n1. type: ? (`delete_appointment`)\n2. data:\n   * [`16*byte `:`locator`]\n   * [`u16`: `signature_len`]\n* [`signature_len*byte`: `user_signature`]\n\nThe user:\n\n* MUST set `locator` as specified in [Transaction Locator and Encryption\nKey](#transaction-locator-and-encryption-key).\n* MUST set `user_signature` to the signature of the deletion request.\n* MUST set `signature_len` to the length of `user_signature`.\n\nThe server:\n\n* MUST compute `public_key` by performing EC recover.\n* If the recovered `public_key` has an associated appointment with locator\nmatching `locator`:\n* MUST delete the appointment and send `deletion_accepted`.\n* Otherwise:\n* MUST reject the deletion request and send `deletion_rejected`.\n\n\n#### Signing deletion requests\n\nDeletion requests must contain a signature of the following message:\n\n\"Delete appointment <locator>\"\n\nwhere `<locator>` MUST match `locator`.\n\nThe signature must be performed following [Data serialisation and\nsigning](#data-serialisation-and-signing).\n\n#### Rationale\n\nFreeing expired appointment from the tower (after a channel clousure or\nbreach) should be beneficial for both parties. From the tower side, it\nallows to reduce the load and free space, for the user side, it recovers\nspace that was used by expired appointments, so it can be used to back up\nnew channel updates.\n\n### The `deletion_accepted` message\n\nThis message contains information about the acceptance of an appointment\ndeletion by the Watchtower.\n\n1. type: ? (`deletion_accepted`)\n2. data:\n   * [`16*byte `:`locator`]\n3. tlvs: `wt_accountability_tlvs`\n4. types:\n1. type: 2 (`receipt_signature`)\n2. data:\n* [`tu16*byte`: `tower_signature`]\n\nThe server:\n\n* MUST receive `delete_appointment` before sending an `deletion_accepted`\nmessage.\n* MUST set the `locator` to match the one received in `delete_appointment`.\n\nIf `accountability` is being offered it was requested for the appointment\nappointment:\n\n* MUST set `tower_signature` to the signature of `user_signature` as\nspecified following [Data serialisation and\nsigning](#data-serialisation-and-signing).\n\nThe client:\n\n* MUST fail the connection  if `locator` does not match the `locator` from\n`delete_appointment`.\n\n\n### The `deletion_rejected` message\n\nThis message contains information about the rejection of an appointment\ndeletion by the Watchtower.\n\n1. type: ? (`deletion_rejected`)\n2. data:\n   * [`16*byte `:`locator`]\n   * [`u16`: `rcode`]\n   * [`u16`: `reason_len`\n   * [`reason_len*byte`: `reason`]\n\nThe server:\n\n* MUST receive `delete_appointment` before sending an `deletion_rejected`\nmessage.\n* MUST set the `locator` to match the one received in `delete_appointment`.\n* MUST set `rcode` to the rejection code.\n* MAY set and empty `reason` field.\n* MUST set `reason_len` to length of `reason`.\n\n#### Rationale\n\nDeletion rejection should include cases like the appointment cannot be\nfound for the requesting user (either because it never existed, or because\nit was already deleted).\nThe same approach as for `appointment_rejected` error messages is followed\nhere.\n\n## Transaction Locator and Encryption Key\n\nImplementations MUST compute the `locator`, `encryption_key` and\n`encryption_iv` from the commitment transaction as defined below:\n\n- `locator`: first half of the commitment transaction id\n(`commitment_txid(0,16]`)\n- `encryption_key `: Hash of the commitment transaction id\n(`SHA256(commitment_txid)`)\n- `encryption_iv`: A 12-byte long 0\n(`'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'`)\n\n\nThe server relies on both the encryption key and iv to decrypt the penalty\ntransaction. Furthermore, the transaction locator helps the Watchtower\nidentify a breach transaction on the blockchain.\n\n## Encryption Algorithms and Parameters\n\nUsers and servers MUST use [ChaCha20-Poly1305](\nhttps://tools.ietf.org/html/rfc7539) to encrypt / decrypt blobs.\n\nSample code (python) for the client to prepare the `encrypted_blob`:\n\nfrom hashlib import sha256\nfrom binascii import hexlify\nfrom cryptography.hazmat.primitives.ciphers.aead import ChaCha20Poly1305\n\ndef encrypt(penalty_tx, commitment_txid):\n# The SHA256 of the commitment txid is used as secret key, and 0 (12-byte\nlong) as nonce.\n  sk = sha256(commitment_txid).digest()\n  nonce = bytearray(12)\n\n  # Encrypt the data\n  cipher = ChaCha20Poly1305(sk)\n  encrypted_blob = cipher.encrypt(nonce=nonce, data=penalty_tx,\nassociated_data=None)\n  encrypted_blob = hexlify(encrypted_blob).decode(\"utf8\")\n\n  return encrypted_blob\n\n## Payment modes\n\nThe three most common ways of paying a tower are:\n\n**On-chain bounty**. An additional output is created in the penalty\ntransaction that will reward the Watchtower.\n\n**Micropayments**. A small payment is sent to the Watchtower for every new\njob (e.g. over the lightning network).\n\n**Subscription**. Watchtower is periodically rewarded / paid for their\nservice to the customer. (e.g. over the lightning network or fiat\nsubscription).\n\nThe bounty approach has the benefit of paying the tower only if the job is\ndone, but lets the customer hire many Watchtowers and only one Watchtower\nwill be rewarded upon collecting the bounty (O(N) storage for each tower).\nOn top of that, the onchain bounty allows a network-wise DoS attack for\nfree. However, it also has the benefit of allowing fee-bumping via CPFP by\nincluding an output dedicated to the tower.\n\nThe micropayment approach can be achieved using the same method as the\nsubscription approach but setting the `appointment_slots` to one. Both\nmicropayments and subscriptions are favourable for a Watchtower.\n\nThe ideal approach could be something in between. The tower is paid via a\nsubscription to cover the storage costs and making DoS attacks having a\nfinancial cost. On top of that, the penalty transactions can include an\noutput for the tower so\nthe tower is encouraged to watch for beaches whilst allowing fee-bumping.\n\n## Data serialisation and signing\n\nRequest and receipts are serialised in big-endian, concatenating their\nvalues in the given order if they contain more than one value (as is the\ncase of the appointment receipt). The signature algorithm follows the\napproach developed by lnd and currently implemented by both lnd and\nc-lightning [#specinatweet](\nhttps://twitter.com/rusty_twit/status/1182102005914800128):\n\nSignatures are [zbase32 encoded](\nhttps://philzimmermann.com/docs/human-oriented-base-32-encoding.txt) and\nare performed over the sha256d of the message prefixed by `\"Lightning\nSigned Message:\"`, that is:\n\nzbase32(SigRec(SHA256(SHA256(\"Lightning Signed Message:\" +\nserialised_data))))\n\nFor example, for a deletion request of appointment identified by locator\n`4a5e1e4baab89f3a32518a88c3bc87f6`, the structure will be:\n\nzbase32(SigRec(SHA256(SHA256(\"Lightning Signed Message:Delete appointment\n4a5e1e4baab89f3a32518a88c3bc87f6))))\n\n## No compression of penalty transaction\n\nThe storage requirements for a Watchtower can be reduced (linearly) by\nimplementing [shachain](\nhttps://github.com/rustyrussell/ccan/blob/master/ccan/crypto/shachain/design.txt),\ntherefore storing the parts required to build the transaction and the\ncorresponding signing key instead of the full transaction. For now, we have\ndecided to keep the hiring protocol simple. Storage is relatively cheap and\nwe can revisit this standard if it becomes a problem.\n\n## Attacks on towers\nThere are three main factors that define how easy is, for a malicious user,\nto attack a tower: the `cost` of hiring the tower, the level of user\n`privacy` achieved by the service, and who has `access` to the tower's\nservices.\n\nThe most vulnerable Watchtower will, therefore, be a cheap, public, and\ncompletely privacy preserving tower. Privacy being our mail goal, we've\ndefined parts of this BOLT to prevent cheap attacks, such as favouring\nsubscriptions over single appointments. Here's an example of what\nsubscriptions try to protect from:\n\n### Locator reuse attack\n\nGiven a locator `l`, a tower that provides a per-appointment hiring service\n(appointments can be bought one by one), and complete privacy (no\nregistration), a malicious user could:\n\n* Send `n` appointments to the tower, all identified by `l`\n* Trigger a breach by sending a single old commitment (`txfee`)\n\nThe tower will need to store all appointments, since it has no clue which\nof them is the valid one (if any). On the other hand, the cost for the\nattacker will only be `n * appointment_cost + txfee`.\n\nUpon detection a breach, the tower will need to decrypt and analyse `n`\ntransactions and left with the decision of what of them to broadcast (if\nany).\n\nUsing subscriptions, the tower will only store a single appointment, since\nall appointments with the same `l` will be seen as updates. An attacker\nwill need `n` different subscriptions to attempt the same attack. Assuming\na subscription has a minimum size of `m` appointments (`m >> 1`), the cost\nfor the attacker will be `n * m * appointment_cost + txfee`.\n\nCheck [Trustless WatchTowers?](\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2018-April/001203.html)\nfor more on this.\n\n[ADD MORE ATTACKS]\n\n## FIXMES\n\n- Define a proper tower discovery.\n- None of the message types have been defined (they have been left with ?).\n- Define errors (transient vs permanently).\n- Extend attacks on towers\n\n## DISCUSS\n\n- The tower may also need to reply with `appointment_slots` during the\nregistration phase so a minimum amount of appointments are paid for. Check\n[Attacks on towers](#attacks-on-towers). Therefore hiring the tower for a\nsingle appointment may be problematic.\n- Signature on the deletion acceptance by the server may not be necessary.\n- Appointment deletion can be performed in bulk, by allowing sending more\nthan one appointment at a time. That could result in a privacy leak though,\nsince the tower will be able to link what appointments belonged to the same\nchannel.\n- Recognition codes, by ZmnSCPxj, may help here.\n- Separate register and top up so proofs can be used for top ups, in a\nsimilar way to [Dead Men's Button](\nhttps://github.com/joostjager/deadmensbutton)\n\n-- \nSergi.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200309/574d66d1/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "BOLT 13(?): WatchTower protocol",
            "categories": [
                "Lightning-dev",
                "DRAFT"
            ],
            "authors": [
                "Sergi Delgado Segura"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 27432
        }
    },
    {
        "title": "[Lightning-dev] Blind paths revisited",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2020-03-10T00:19:03",
                "message_text_only": "I recently hit a dead-end on rendezvous routing; the single-use\nrequirement is a showstopper for offers (which are supposed to be static\nand reusable).\n\nFortunately, t-bast has a scheme for blinded paths (see\nhttps://gist.github.com/t-bast/9972bfe9523bb18395bdedb8dc691faf ) so\nI've been examining that more closely.  I think it can be simplified\nto use more standard primitives.\n\nThe problem: Alice wants to present Mallory with a path (Carol, Bob,\nAlice) for which he can create an onion, which is obscured in some way,\nbut can be unobscured by the various nodes.  Mallory should be forced to\nuse the entire path.\n\nAlice can give Mallory two ECDH blobs to place inside the per-hop\npayload to establish shared secrets with Bob and Carol.  But crucially,\nBob needs the secret *before* he can unwrap the onion, so the ECDH\nblob for the next peer needs to be sent alongside the onion itself.\n\nt-bast proposed using the secret to XOR the scid, but Christian\nsuggested it's more powerful to encrypt a general payload.\n\nWhat does this leave us with?\n\n1. A new invoice letter `b`.  Encodes\n   1 or more pubkey/feebase/feeprop/cltvdelta/features/encblob.\n\n2. An additional (tlv of course) field to update_add_htlc, `blinding`.\n\n3. New `tlv_payload` field `encblob` (varlen).\n\n4. ECDH on incoming `blinding` to get a shared secret which tells\n   this node how to tweak its nodeid to decrypt onion, and also how to\n   decrypt `encblob`.  This gives a tlv, which presumably contains\n   `short_channel_id` as well as `blinding`.\n\n5. Use `blinding` for the next update_add_htlc.\n\n6. If you get an error from downstream and you sent `blinding`, turn it\n   into your own error for maximum obfuscation.  Perhaps a new\n   \"blinded_path_error\"?  Obviously does not include a channel_update :)\n\nSo, if you get an invoice `b`, with path starting at (known) Carol:\n\n        Carol/1/1/9/\"\"/enc1\n          Bob'/1/1/9/\"\"/enc2\n            [Optional: decoy hops...]\n\nPayer constructs the onion to get to Carol as normal, then:\n\n        Carol: No `blinding` in incoming HTLC, but once it decrypts the\n               onion, she sees `encblob` (value enc1).  Uses first 32\n               bytes of `enc1` as `blinding`: do ECDH to get SS1, uses\n               SS1 to decrypt rest to get next scid and `blinding`, send\n               `blinding` with update_add_htlc to Bob.\n\n        Bob: Gets `blinding` from update_add_htlc. ECDH -> SS2.  Tweak\n               own key with SS2 to decode onion.  Use SS2 to decrypt\n               `enc2` to get next scid and blinding.  Send `blinding`\n               with update_add_htlc to Alice.\n\n        Alice: Gets `blinding` from update_add_htlc. ECDH -> SS3.  Tweak\n               own key with SS3 to decode onion.  If it put in decoy\n               hops, this onion won't be terminal, but otherwise it can\n               be treated as terminal iff `blinding` is the expected value\n               for this invoice.\n\nNote that this means no payment secret is necessary, since the incoming\n`blinding` serves the same purpose.  If we wanted to, we could (ab)use\npayment_secret as the first 32-bytes to put in Carol's enc1 (i.e. it's\nthe ECDH for Carol to decrypt enc1).\n\nThoughts?\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-03-10T12:14:58",
                "message_text_only": "Good morning Rusty, et al.,\n\n\n> Note that this means no payment secret is necessary, since the incoming\n> `blinding` serves the same purpose. If we wanted to, we could (ab)use\n> payment_secret as the first 32-bytes to put in Carol's enc1 (i.e. it's\n> the ECDH for Carol to decrypt enc1).\n\nI confess to not reading everything in detail, but it seems to me that, with payment point + scalar and path decorrelation, we need to establish a secret with each hop anyway (the blinding scalar for path decorrelation), so if you need a secret per hop, possibly this could be reused as well?\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Rusty Russell",
                "date": "2020-03-10T23:05:57",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n> Good morning Rusty, et al.,\n>\n>\n>> Note that this means no payment secret is necessary, since the incoming\n>> `blinding` serves the same purpose. If we wanted to, we could (ab)use\n>> payment_secret as the first 32-bytes to put in Carol's enc1 (i.e. it's\n>> the ECDH for Carol to decrypt enc1).\n>\n> I confess to not reading everything in detail, but it seems to me that, with payment point + scalar and path decorrelation, we need to establish a secret with each hop anyway (the blinding scalar for path decorrelation), so if you need a secret per hop, possibly this could be reused as well?\n\nIndeed, this could be used the same way, though for that secret it can\nsimply be placed inside the onion rather than passed alongside.\n\nCheers,\nRusty."
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2020-03-11T16:27:39",
                "message_text_only": "Good morning list,\n\nThanks Rusty for following up on this, I'm glad it may be useful for offers!\nI certainly want this as well for wallet users' privacy.\n\nI have gathered my proposal in a better format than my previous gist here:\nhttps://github.com/lightningnetwork/lightning-rfc/blob/route-blinding/proposals/route-blinding.md\n\nYou will note that I've been able to simplify the scheme a bit compared to\nmy\ngist. It's now very clear that this is exactly the same kind of secrets\nderivation than what Sphinx does. I still have things I want to add to the\nproposal, but at least the crypto part should be ready to review (and I\nthink\nit does need more eyes on it).\n\nFeel free to add comments directly on the branch commits, it may be easier\nto\nreview that way. Let me know if you think I should turn it into a draft PR\nto\nfacilitate discussions. It kept it vague on some specific parts on purpose\n(such as invoice fields, encrypted blob format); we will learn from early\nprototype implementations and enrich the proposal as we go.\n\nA few comments on your previous mails. I have removed the (ab)use of\n`payment_secret`, but I think your comment on using the `blinding` to\nreplace\nit would not work because that blinding is known by the next-to-last node\n(which computes it and forwards it to the final node).\nThe goal of `payment_secret` is explicitly to avoid having the next-to-last\nnode\ndiscover it to prevent him from probing. But I think that you didn't plan on\ndoing the blinding the same way I'm doing it, which may explain the\ndifference.\n\nAs for ZmnSCPxj's suggestion, I think there is the same kind of issue.\nThe secrets we establish with anonymous multi-hops locks are between the\n*sender*\nand each of the hops. In the route blinding case, what we're adding are\nsecrets\nbetween the *recipient* and the hops, and we don't want the sender to be\nable to\ninfluence those. It's a kind of reverse Sphinx. So I'm not sure yet the\nrecipient\ncould safely contribute to those secrets, but maybe we'll find a nice trick\nin\nthe future!\n\nCheers,\nBastien\n\nLe mer. 11 mars 2020 \u00e0 00:22, Rusty Russell <rusty at rustcorp.com.au> a\n\u00e9crit :\n\n> ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n> > Good morning Rusty, et al.,\n> >\n> >\n> >> Note that this means no payment secret is necessary, since the incoming\n> >> `blinding` serves the same purpose. If we wanted to, we could (ab)use\n> >> payment_secret as the first 32-bytes to put in Carol's enc1 (i.e. it's\n> >> the ECDH for Carol to decrypt enc1).\n> >\n> > I confess to not reading everything in detail, but it seems to me that,\n> with payment point + scalar and path decorrelation, we need to establish a\n> secret with each hop anyway (the blinding scalar for path decorrelation),\n> so if you need a secret per hop, possibly this could be reused as well?\n>\n> Indeed, this could be used the same way, though for that secret it can\n> simply be placed inside the onion rather than passed alongside.\n>\n> Cheers,\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200311/959e4614/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-03-13T00:42:16",
                "message_text_only": "Good morning tbast, rusty, and list,\n\n\n> As for ZmnSCPxj's suggestion, I think there is the same kind of issue.\n> The secrets we establish with anonymous multi-hops locks are between the *sender*\n> and each of the hops. In the route blinding case, what we're adding are secrets\n> between the *recipient* and the hops, and we don't want the sender to be able to\n> influence those. It's a kind of reverse Sphinx. So I'm not sure yet the recipient\n> could safely contribute to those secrets, but maybe we'll find a nice trick in\n> the future!\n\nNot quite?\n\nThe recipient knows the secrets from the first recipient-selected-hop to itself, and, if it knows the payment scalar, can subtract those secrets from the receiver scalar.\nThus the sender only has to arrange to deliver the payment point to the first recipient-selected-hop, the rest of the recipient-selected-hops will add their blinding scalars (which come from the recipient), and the final recipient can linearly deduct those.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2020-03-13T08:57:41",
                "message_text_only": "Good morning ZmnSCPxj,\n\nOk I see what you mean. In that case it would be slightly different from\nthe current path blinding proposal.\nThe recipient would need to give the sender all the blinding points for\neach hop in the blinded path.\nCurrently the recipient only gives one blinding point and then each node in\nthe blinded path is able to\ncompute the next blinding point and send it to the next node.\n\nThis may work, but I think it deserves a closer look. The security\nassumptions in multi-hop locks is that\nthe sender can choose every secret from a random distribution. If instead\nthese secrets are provided by\nthe recipient, this may open up some attack vectors on the sender. Maybe\nthe sender can tweak each\nrecipient secret with a secret of its own, but one would need to write the\nexact maths down to verify that\nit works end-to-end.\n\nI'm not saying it's impossible, I'm just saying that it's not trivial at\nall and the devil is in the details ;)\n\nCheers,\nBastien\n\nLe ven. 13 mars 2020 \u00e0 01:42, ZmnSCPxj <ZmnSCPxj at protonmail.com> a \u00e9crit :\n\n> Good morning tbast, rusty, and list,\n>\n>\n> > As for ZmnSCPxj's suggestion, I think there is the same kind of issue.\n> > The secrets we establish with anonymous multi-hops locks are between the\n> *sender*\n> > and each of the hops. In the route blinding case, what we're adding are\n> secrets\n> > between the *recipient* and the hops, and we don't want the sender to be\n> able to\n> > influence those. It's a kind of reverse Sphinx. So I'm not sure yet the\n> recipient\n> > could safely contribute to those secrets, but maybe we'll find a nice\n> trick in\n> > the future!\n>\n> Not quite?\n>\n> The recipient knows the secrets from the first recipient-selected-hop to\n> itself, and, if it knows the payment scalar, can subtract those secrets\n> from the receiver scalar.\n> Thus the sender only has to arrange to deliver the payment point to the\n> first recipient-selected-hop, the rest of the recipient-selected-hops will\n> add their blinding scalars (which come from the recipient), and the final\n> recipient can linearly deduct those.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200313/4f7865b8/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-03-16T00:06:12",
                "message_text_only": "Good morning Bastien,\n\n> Good morning ZmnSCPxj,\n>\n> Ok I see what you mean. In that case it would be slightly different from the current path blinding proposal.\n> The recipient would need to give the sender all the blinding points for each hop in the blinded path.\n> Currently the recipient only gives one blinding point and then each node in the blinded path is able to\n> compute the next blinding point and send it to the next node.\n>\n> This may work, but I think it deserves a closer look. The security assumptions in multi-hop locks is that\n> the sender can choose every secret from a random distribution. If instead these secrets are provided by\n> the recipient, this may open up some attack vectors on the sender. Maybe the sender can tweak each\n> recipient secret with a secret of its own, but one would need to write the exact maths down to verify that\n> it works end-to-end.\n\n\nNot every secret is chosen by the sender --- the final target payment scalar comes from the receiver, after all, and if the payee can somehow attack the sender if multiple scalars are given, then the payee can also attack the sender if a single scalar is given, because linearity.\nWhether the final receiver secret is a single scalar, or multiple scalars summed together, seems to be immaterial.\n\nSo for example if the payment point + scalar is (N, n), then as usual the sender creates blinding scalars s0 s1 s2 and creates an initial PTLC that requests for (s0 + s1 + s2) * G + N, each hop the sender select subtracts some s[i], then the rendezvous point receives just N.\nThen the rendezvous unwraps the receiver-side onion, which reveals a path with blinding scalars r0 r1 r2, each subsequent receiver-selected path subtracts some r[i] until the receiver receives a PTLC asking for the scalar behind N - (r0 + r1 + r2) * G.\nSince the receiver knows n such that N = n * G, and knows all the r[i], it can claim that PTLC.\n\nThus the sender can treat the rendezvous point as the \"real\" receiver, with an abnormally high `final_cltv_expiry`, and of course the receiver is now the one paying for the fees deducted by each hop the receiver chose (i.e. the sender is obligated to deliver the agreed funds only up to the rendezvous node).\nAs far as the sender is concerned, the payment point + scalar is N = n * G, not N - (r0 + r1 + r2) * G = n - r0 - r1 - r2.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Blind paths revisited",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Bastien TEINTURIER",
                "ZmnSCPxj"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 13565
        }
    },
    {
        "title": "[Lightning-dev] Difference between ignoring htlc request due to wrong payment hash vs refusing to release preimage in LND",
        "thread_messages": [
            {
                "author": "Subhra Mazumdar",
                "date": "2020-03-24T08:06:00",
                "message_text_only": "Hi,\n    I was just playing around with LND and established a channel between 2\nparties A and B. When sending a payment to B via HTLC, B adds an invoice\nand over here I used a different payment hash for A for sendpayment with a\ndelta of 144 blocks. The error I got on initiating send payment is\n\"incorrect or unknown payment details\". So what is exactly happening here?\nIs B ignoring any formation of HTLC between them? I hope in this case no\nmoney gets locked in this case. Then how can one mimic griefing attack\nscenario (B refusing to release the correct preimage) in LND?\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200324/b4aa8561/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-03-24T08:27:27",
                "message_text_only": "Good morning Subhra,\n\n> Hi,\n> \u00a0\u00a0\u00a0 I was just playing around with LND and established a channel between 2 parties A and B. When sending a payment to B via HTLC, B adds an invoice and over here I used a different payment hash for A for sendpayment with a delta of 144 blocks. The error I got on initiating send payment is \"incorrect or unknown payment details\". So what is exactly happening here? Is B ignoring any formation of HTLC between them?\n\nA and B form an HTLC in them, to the point that it is \"irrevocably committed\".\nIt is a recommendation of BOLT spec that you pretty much do not do anything until an incoming HTLC reaches \"irrevocably committed\" state.\n\nThen, B looks at the HTLC data.\nIf B knows the preimage to the payment hash, it claims the HTLC immediately as soon as it is irrevocably committed.\n\nIf B does not know the preimage, it checks if there is forwarding data.\nIf there is no forwarding data (B is the final hop) then B responds with \"incorrect or unknown payment details\", then A waits for the channel state to advance so that the HTLC getting removed reaches \"irrevocably committed\", then reports the failure to the user.\n\n> I hope in this case no money gets locked in this case.\n\nMoney got locked temporarily int the HTLC, but was freed very soon afterwards, as fast as B and A can advance the channel state (which is limited by your hardware and network speeds).\n\n\n> Then how can one mimic griefing attack scenario (B refusing to release the correct preimage) in LND?\n\nYou may need to modify LND code directly, or ask LND devs if there are any such hooks available.\n\nIn C-Lightning, you will have to install a plugin, devise some way for the plugin to know of what payment hash you want to grief, then have the plugin hook into `htlc_accepted`.\nIn `htlc_accepted` handler, if the incoming HTLC has a payment hash matching what you want to grief, you then perform a `waitblockheight` command to wait for the target block height you want to grief for, then return from the `htlc_accepted` handler.\n(This can be complicated by the exact language you use to implement the plugin, remember the plugin should be async so it should still respond with `{\"result\":\"continue\"}` immediately to other incoming `htlc_accepted` as normal, if you implement the plugin in Python the Python C-Lightning plugin library should \"just work\" as far as I know as it transforms the Python into an async language, but ask cdecker for that; but if you have a sufficiently monadic framework for asynchronicity (a la Javascript `Promise`/Haskell `IO`) it should work like that.)\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-03-24T08:56:05",
                "message_text_only": "Thanks ZmnSCPxj. Just a clarification on the idea proposed so that means\nhere B needs to delay the HTLC acceptance?  Pardon my knowledge on\nc-lightning, but what exactly happens upon htlc_acceptance? Release of\npreimage or just an acknowledgment by B reaching to the point of\nirrevocably committed?\n\nOn Tue, Mar 24, 2020 at 1:57 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Subhra,\n>\n> > Hi,\n> >     I was just playing around with LND and established a channel between\n> 2 parties A and B. When sending a payment to B via HTLC, B adds an invoice\n> and over here I used a different payment hash for A for sendpayment with a\n> delta of 144 blocks. The error I got on initiating send payment is\n> \"incorrect or unknown payment details\". So what is exactly happening here?\n> Is B ignoring any formation of HTLC between them?\n>\n> A and B form an HTLC in them, to the point that it is \"irrevocably\n> committed\".\n> It is a recommendation of BOLT spec that you pretty much do not do\n> anything until an incoming HTLC reaches \"irrevocably committed\" state.\n>\n> Then, B looks at the HTLC data.\n> If B knows the preimage to the payment hash, it claims the HTLC\n> immediately as soon as it is irrevocably committed.\n>\n> If B does not know the preimage, it checks if there is forwarding data.\n> If there is no forwarding data (B is the final hop) then B responds with\n> \"incorrect or unknown payment details\", then A waits for the channel state\n> to advance so that the HTLC getting removed reaches \"irrevocably\n> committed\", then reports the failure to the user.\n>\n> > I hope in this case no money gets locked in this case.\n>\n> Money got locked temporarily int the HTLC, but was freed very soon\n> afterwards, as fast as B and A can advance the channel state (which is\n> limited by your hardware and network speeds).\n>\n>\n> > Then how can one mimic griefing attack scenario (B refusing to release\n> the correct preimage) in LND?\n>\n> You may need to modify LND code directly, or ask LND devs if there are any\n> such hooks available.\n>\n> In C-Lightning, you will have to install a plugin, devise some way for the\n> plugin to know of what payment hash you want to grief, then have the plugin\n> hook into `htlc_accepted`.\n> In `htlc_accepted` handler, if the incoming HTLC has a payment hash\n> matching what you want to grief, you then perform a `waitblockheight`\n> command to wait for the target block height you want to grief for, then\n> return from the `htlc_accepted` handler.\n> (This can be complicated by the exact language you use to implement the\n> plugin, remember the plugin should be async so it should still respond with\n> `{\"result\":\"continue\"}` immediately to other incoming `htlc_accepted` as\n> normal, if you implement the plugin in Python the Python C-Lightning plugin\n> library should \"just work\" as far as I know as it transforms the Python\n> into an async language, but ask cdecker for that; but if you have a\n> sufficiently monadic framework for asynchronicity (a la Javascript\n> `Promise`/Haskell `IO`) it should work like that.)\n>\n> Regards,\n> ZmnSCPxj\n>\n\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200324/2abe534f/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-03-24T11:15:34",
                "message_text_only": "Good morning Subhra,\n\n> Thanks ZmnSCPxj. Just a clarification on the idea proposed so that means here B needs to delay the HTLC acceptance?\u00a0 Pardon my knowledge on c-lightning, but what exactly happens upon htlc_acceptance? Release of preimage or just an acknowledgment by B reaching to the point of irrevocably committed?\u00a0\u00a0\n\nThis event is emitted when an incoming HTLC is irrevocably committed.\nThis is a hook, and what happens will depend on what the hook returns:\n\n* It returns `{\"result\":\"continue\"}`: normal processing of the HTLC (forward, fail, or claim as normal operation).\n* It returns `{\"result\":\"fail\", \"failure_message\": \"2002\"}`: fail the HTLC with the given failure message, failure message is a hex-encoded failure blob, see BOLT 4 for how.\n* It returns `{\"result\": \"resolve\", \"payment_key\": \"0000000000000000000000000000000000000000000000000000000000000000\"}`: claim the HTLC regardless of whether it is a forward or terminates here, the given `payment_key` is the 64-hex-digits encoding of the preimage.\n\nFor the most part, for purposes of griefing, you can just delay the default `{\"result\":\"continue\"}` for as long as you want to grief the payment, this will work for both forwards and payment receives correctly, except griefed.\n\nSee [our docs](https://lightning.readthedocs.io/PLUGINS.html#htlc-accepted) for more.\n\nRegards,\nZmnSCPxj\n\n>\n> On Tue, Mar 24, 2020 at 1:57 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n> > Good morning Subhra,\n> >\n> > > Hi,\n> > > \u00a0\u00a0\u00a0 I was just playing around with LND and established a channel between 2 parties A and B. When sending a payment to B via HTLC, B adds an invoice and over here I used a different payment hash for A for sendpayment with a delta of 144 blocks. The error I got on initiating send payment is \"incorrect or unknown payment details\". So what is exactly happening here? Is B ignoring any formation of HTLC between them?\n> >\n> > A and B form an HTLC in them, to the point that it is \"irrevocably committed\".\n> > It is a recommendation of BOLT spec that you pretty much do not do anything until an incoming HTLC reaches \"irrevocably committed\" state.\n> >\n> > Then, B looks at the HTLC data.\n> > If B knows the preimage to the payment hash, it claims the HTLC immediately as soon as it is irrevocably committed.\n> >\n> > If B does not know the preimage, it checks if there is forwarding data.\n> > If there is no forwarding data (B is the final hop) then B responds with \"incorrect or unknown payment details\", then A waits for the channel state to advance so that the HTLC getting removed reaches \"irrevocably committed\", then reports the failure to the user.\n> >\n> > > I hope in this case no money gets locked in this case.\n> >\n> > Money got locked temporarily int the HTLC, but was freed very soon afterwards, as fast as B and A can advance the channel state (which is limited by your hardware and network speeds).\n> >\n> > > Then how can one mimic griefing attack scenario (B refusing to release the correct preimage) in LND?\n> >\n> > You may need to modify LND code directly, or ask LND devs if there are any such hooks available.\n> >\n> > In C-Lightning, you will have to install a plugin, devise some way for the plugin to know of what payment hash you want to grief, then have the plugin hook into `htlc_accepted`.\n> > In `htlc_accepted` handler, if the incoming HTLC has a payment hash matching what you want to grief, you then perform a `waitblockheight` command to wait for the target block height you want to grief for, then return from the `htlc_accepted` handler.\n> > (This can be complicated by the exact language you use to implement the plugin, remember the plugin should be async so it should still respond with `{\"result\":\"continue\"}` immediately to other incoming `htlc_accepted` as normal, if you implement the plugin in Python the Python C-Lightning plugin library should \"just work\" as far as I know as it transforms the Python into an async language, but ask cdecker for that; but if you have a sufficiently monadic framework for asynchronicity (a la Javascript `Promise`/Haskell `IO`) it should work like that.)\n> >\n> > Regards,\n> > ZmnSCPxj\n>\n> --\n> Yours sincerely,\n> Subhra Mazumdar."
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-03-24T09:06:28",
                "message_text_only": "Another question related to the paper https://arxiv.org/abs/2003.00003.\nOver here, it is stated in page 13, \"Surge of unresolved HTLCs while\nprobing: Recalling steps 5-7 in Figure 4, each probe sets up a chain of\nirredeemable HTLCs (since a matching preimage would have to be\nbrute-forced). Eventually, running multiple probes over the same channels\nwill escrow its funds in these HTLCs, effectively DOSing the probe route\nand forcing the nodes to wait until the HTLCs time out before being able to\nforward other payments. This is an issue we encountered over and over\nduring 4.2 and 4.3, often giving us one shot at probing before having to\nwait multiple hours for the HTLCs to expire. This is also why we chose the\nchannels leading up to our final target to have a much higher balance, so\nthat we would have enough..\" So there was no matching preimage with\nreceiver as per Fig 4. So that means in the route say A->B->C->D, if D\ndoesn't have a matching preimage and suppose C->D uses lock time of 144\nblocks, B->C 288 blocks and A->B uses a locktime of 432 blocks, so won't be\nthe case funds in A->B and B->C still remains locked for the mentioned\nlocktime? I know this is not the definition of griefing attack but then can\nthis possibly mimic the situation where receiver denies having the correct\npreimage?\n\nOn Tue, Mar 24, 2020 at 1:57 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Subhra,\n>\n> > Hi,\n> >     I was just playing around with LND and established a channel between\n> 2 parties A and B. When sending a payment to B via HTLC, B adds an invoice\n> and over here I used a different payment hash for A for sendpayment with a\n> delta of 144 blocks. The error I got on initiating send payment is\n> \"incorrect or unknown payment details\". So what is exactly happening here?\n> Is B ignoring any formation of HTLC between them?\n>\n> A and B form an HTLC in them, to the point that it is \"irrevocably\n> committed\".\n> It is a recommendation of BOLT spec that you pretty much do not do\n> anything until an incoming HTLC reaches \"irrevocably committed\" state.\n>\n> Then, B looks at the HTLC data.\n> If B knows the preimage to the payment hash, it claims the HTLC\n> immediately as soon as it is irrevocably committed.\n>\n> If B does not know the preimage, it checks if there is forwarding data.\n> If there is no forwarding data (B is the final hop) then B responds with\n> \"incorrect or unknown payment details\", then A waits for the channel state\n> to advance so that the HTLC getting removed reaches \"irrevocably\n> committed\", then reports the failure to the user.\n>\n> > I hope in this case no money gets locked in this case.\n>\n> Money got locked temporarily int the HTLC, but was freed very soon\n> afterwards, as fast as B and A can advance the channel state (which is\n> limited by your hardware and network speeds).\n>\n>\n> > Then how can one mimic griefing attack scenario (B refusing to release\n> the correct preimage) in LND?\n>\n> You may need to modify LND code directly, or ask LND devs if there are any\n> such hooks available.\n>\n> In C-Lightning, you will have to install a plugin, devise some way for the\n> plugin to know of what payment hash you want to grief, then have the plugin\n> hook into `htlc_accepted`.\n> In `htlc_accepted` handler, if the incoming HTLC has a payment hash\n> matching what you want to grief, you then perform a `waitblockheight`\n> command to wait for the target block height you want to grief for, then\n> return from the `htlc_accepted` handler.\n> (This can be complicated by the exact language you use to implement the\n> plugin, remember the plugin should be async so it should still respond with\n> `{\"result\":\"continue\"}` immediately to other incoming `htlc_accepted` as\n> normal, if you implement the plugin in Python the Python C-Lightning plugin\n> library should \"just work\" as far as I know as it transforms the Python\n> into an async language, but ask cdecker for that; but if you have a\n> sufficiently monadic framework for asynchronicity (a la Javascript\n> `Promise`/Haskell `IO`) it should work like that.)\n>\n> Regards,\n> ZmnSCPxj\n>\n\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200324/92fb1048/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-03-24T11:27:32",
                "message_text_only": "Good morning Subhra,\n\n> Another question related to the paper https://arxiv.org/abs/2003.00003. Over here, it is stated in page 13, \"Surge of unresolved HTLCs while probing: Recalling steps 5-7 in Figure 4, each probe sets up a chain of irredeemable HTLCs (since a matching preimage would have to be brute-forced). Eventually, running multiple probes over the same channels will escrow its funds in these HTLCs, effectively DOSing the probe route and forcing the nodes to wait until the HTLCs time out before being able to forward other payments. This is an issue we encountered over and over during 4.2 and 4.3, often giving us one shot at probing before having to wait multiple hours for the HTLCs to expire. This is also why we chose the channels leading up to our final target to have a much higher balance, so that we would have enough..\" So there was no matching preimage with receiver as per Fig 4. So that means in the route say A->B->C->D, if D doesn't have a matching preimage and suppose C->D uses lock time of 144 blocks, B->C 288 blocks and A->B uses a locktime of 432 blocks, so won't be the case funds in A->B and B->C still remains locked for the mentioned locktime?\n\nIt is helpful to remember that inside a channel, every contract has an implicit branch \"if both of us in this channel agree, we can spend this contract funds any way we want\".\n\nThis is because every contract is dependent on a transaction spending from a 2-of-2, and both parties can always sign a new 2-of-2 transaction without that contract --- it is just that both have to agree to do this.\n\nIn case of a reported failure, the receiving node in the channel basically says \"just between the two of us, I will not be able to claim this HTLC using the hashlock branch anyway because <BOLT 4 failure code reason>, so this will inevitably be claimable to you in the timelock anyway, so we might as well just agree to re-assign the HTLC funds back to you right now\".\n\nThe sending node is then willing to sign off on this outside-of-the-contract agreement, since it lets it get the funds back before the timelock expires, and to reuse those funds otherwise.\n\nThus, even if D griefs up to 143 blocks it wants, at the 144th block C can report immediately back to B and then A with the above failure mechanism.\n\nB and C are incentivized to do this quickly since it would allow the funds to be reused again in a different, probably-will-not-be-griefed near-future payment, which might earn them fees in the future.\n\nThus if B and C are not controlled by the A+D conglomerate then they have no incentive to extend the griefing attack further.\n\nOf course, if either B or C is offline at the time, then the new state where the HTLC is removed out-of-contract is not possible to sign with both parties.\n\n> I know this is not the definition of griefing attack but then can this possibly mimic the situation where receiver denies having the correct preimage?\n\nNo, since B and C are incentivized to report this immediately in order to free up the funds in order for them to forward \"soon\".\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Subhra Mazumdar",
                "date": "2020-03-24T16:15:21",
                "message_text_only": "Hi ZmnSCPxj,\n      Thank you for the explanation. So I went through BOLT 04\nspecification and quoting a few error possibilities:\n\nAn *intermediate hop* MUST NOT, but the *final node*:\n\n   - if the payment_secret doesn't match the expected value for that\n   payment_hash, or the payment_secret is required and is not present:\n      - MUST fail the HTLC.\n      - MUST return an incorrect_or_unknown_payment_details error.\n   - if the payment hash is unknown:\n      - MUST fail the HTLC.\n      - MUST return an incorrect_or_unknown_payment_details error.\n      So it is the final node which is expected to fail the htlc in these 2\n   cases. But then what if final node denies revealing the secret?  Say in the\n   scenario A->B->C->D, D doesn't reveal the secret. So in such a case, what\n   is C supposed to do? Shall it resort to condition no. 1( secret doesn't\n   match), generate an error message and unlock funds of A->B and B->C as soon\n   as possible?\n\n\nOn Tue, Mar 24, 2020 at 4:57 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Subhra,\n>\n> > Another question related to the paper https://arxiv.org/abs/2003.00003.\n> Over here, it is stated in page 13, \"Surge of unresolved HTLCs while\n> probing: Recalling steps 5-7 in Figure 4, each probe sets up a chain of\n> irredeemable HTLCs (since a matching preimage would have to be\n> brute-forced). Eventually, running multiple probes over the same channels\n> will escrow its funds in these HTLCs, effectively DOSing the probe route\n> and forcing the nodes to wait until the HTLCs time out before being able to\n> forward other payments. This is an issue we encountered over and over\n> during 4.2 and 4.3, often giving us one shot at probing before having to\n> wait multiple hours for the HTLCs to expire. This is also why we chose the\n> channels leading up to our final target to have a much higher balance, so\n> that we would have enough..\" So there was no matching preimage with\n> receiver as per Fig 4. So that means in the route say A->B->C->D, if D\n> doesn't have a matching preimage and suppose C->D uses lock time of 144\n> blocks, B->C 288 blocks and A->B uses a locktime of 432 blocks, so won't be\n> the case funds in A->B and B->C still remains locked for the mentioned\n> locktime?\n>\n> It is helpful to remember that inside a channel, every contract has an\n> implicit branch \"if both of us in this channel agree, we can spend this\n> contract funds any way we want\".\n>\n> This is because every contract is dependent on a transaction spending from\n> a 2-of-2, and both parties can always sign a new 2-of-2 transaction without\n> that contract --- it is just that both have to agree to do this.\n>\n> In case of a reported failure, the receiving node in the channel basically\n> says \"just between the two of us, I will not be able to claim this HTLC\n> using the hashlock branch anyway because <BOLT 4 failure code reason>, so\n> this will inevitably be claimable to you in the timelock anyway, so we\n> might as well just agree to re-assign the HTLC funds back to you right now\".\n>\n> The sending node is then willing to sign off on this\n> outside-of-the-contract agreement, since it lets it get the funds back\n> before the timelock expires, and to reuse those funds otherwise.\n>\n> Thus, even if D griefs up to 143 blocks it wants, at the 144th block C can\n> report immediately back to B and then A with the above failure mechanism.\n>\n> B and C are incentivized to do this quickly since it would allow the funds\n> to be reused again in a different, probably-will-not-be-griefed near-future\n> payment, which might earn them fees in the future.\n>\n> Thus if B and C are not controlled by the A+D conglomerate then they have\n> no incentive to extend the griefing attack further.\n>\n> Of course, if either B or C is offline at the time, then the new state\n> where the HTLC is removed out-of-contract is not possible to sign with both\n> parties.\n>\n> > I know this is not the definition of griefing attack but then can this\n> possibly mimic the situation where receiver denies having the correct\n> preimage?\n>\n> No, since B and C are incentivized to report this immediately in order to\n> free up the funds in order for them to forward \"soon\".\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n\n-- \nYours sincerely,\nSubhra Mazumdar.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200324/35fd7ef7/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Difference between ignoring htlc request due to wrong payment hash vs refusing to release preimage in LND",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Subhra Mazumdar",
                "ZmnSCPxj"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 22724
        }
    },
    {
        "title": "[Lightning-dev] Anchor Outputs Spec & Implementation Progress",
        "thread_messages": [
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2020-03-30T19:00:12",
                "message_text_only": "Hi y'all,\n\nWe've been discussing the current state of the spec and implementation\nreadiness of anchor outputs for a few week now on IRC. As detailed\nconversations are at times difficult to have on IRC, and there's no true\nhistory, I figured I'd start a new discussion thread where we can hammer out\nthe final details.\n\nFirst, on the current state of implementation. Anchor outputs are now fully\nsupported in the master branch of lnd. A user can opt into this new format\nby specifying a new command line parameter: --protocol.anchors (off by\ndefault).  Nodes running with this flag will use the feature bit 1337 for\nnegotiation. We didn't use the range above 65k, as we realized that would\nresult in rather large init messages. This feature will be included in our\nupcoming 0.10 release, which will be entering the release mandate phase in\nthe next week or two. We also plan to add an entry in the wiki declaring our\nusage of this feature bit.\n\nAnchors in lnd implement the spec as is currently defined: two anchors at\nall times, with each anchor utilizing 330 satoshis.\n\nDuring the last spec meeting, the following concerns were raised about\nhaving two anchors at all times (compared to one and re-using the to_remote)\noutput:\n\n  1. two anchors adds extra bytes to the commitment transaction, increasing\nthe\n     fee burden for force closing\n  2. two anchors pollutes the UTXO set, so instead one anchor (for the force\n     closing party) should be present, while the other party re-uses their\n     to_remote output for this purpose\n\nIn response to the first concern: it is indeed the case that these new\ncommitments are more expensive, but they're only _slightly_ so. The new\ndefault commitment weight is as if there're two HTLCs at all times on the\ncommitment transaction. Adding in the extra anchor cost (660 satoshis) is a\nfalse equivalence as both parties are able to recover these funds if they\nchose. It's also the case that force cases in the ideal case are only due to\nnodes needing to go on-chain to sweep HTLCs, so the extra bytes may be\ndwarfed by several HTLCs, particularly in a post MPP/AMP world. The extra\ncost may seem large (relatively) when looking at a 1 sat/byte commitment\ntransaction. However, fees today in the system are on the rise, and if one\nis actually in a situation where they need to resolve HTLCs on chain,\nthey'll likely require a fee rate higher than 1 sat/byte to have their\ncommitment confirm in a timely manner.\n\nOn the topic of UTXO bloat, IMO re-purposing the to_remote output as an\nanchor is arguably _worse_, as only a single party in the channel is able to\nspend that output in order to remove its impact on the UTXO set. On the\nother hand, using two anchors (with their special scripts) allows _anyone_\nto sweep these outputs several blocks after the commitment transaction has\nconfirmed. In order to cover the case where the remote party has no balance,\nbut a single incoming HTLC, the channel initiator must either create a new\nanchor output for this special case (creating a new type of ad-hoc reserve),\nor always create a to_remote output for the other party (donating the 330\nsatoshis).  The first option reduces down to having two anchors once again,\nwhile the second option creates an output which is likely uneconomical to\nsweep in isolation (compared to anchors which can be swept globally in the\nsystem taking advantage of the input aggregation savings).\n\nThe final factor to consider is if we wish to properly re-introduce a CSV\ndelay to the to_remote party in an attempt to remedy some game theoretical\nissues w.r.t forcing one party to close early without a cost to the\ninstigator. In the past we made some headway in this direction, but then\nreverted our changes as we discoverers some previously unknown gaming\nvectors even with a symmetrical delay. If we keep two anchor as is, then we\nleave this thread open to a comprehensive solution, as the dual anchor\nformat is fully decoupled from the rest of the commitment.\n\nCircling back to our implementation, we're ready to deploy what we have as\nis.  In the future, if the scheme changes, then we'll be able to easily\nupdate all our users, as we're also concurrently working on a dynamic\ncommitment update protocol. By dynamic I mean that users will be able to\nupdate their commitment type on the fly, compared to being locked into a\ncommitment type when the channel opens as is today.\n\nWould love to hear y'alls thoughts on the two primary concerns laid out\nabove, and my response to them, thanks!\n\n-- Laolu\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200330/466a001f/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Anchor Outputs Spec & Implementation Progress",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Olaoluwa Osuntokun"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4700
        }
    }
]