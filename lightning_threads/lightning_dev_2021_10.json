[
    {
        "title": "[Lightning-dev] [bitcoin-dev]  Removing the Dust Limit",
        "thread_messages": [
            {
                "author": "Erik Aronesty",
                "date": "2021-10-01T13:40:06",
                "message_text_only": "mostly thinking out loud\n\nsuppose there is a \"lightweight\" node:\n\n1. ignores utxo's below the dust limit\n2. doesn't validate dust tx\n3. still validates POW, other tx, etc.\n\nthese nodes could possibly get forked - accepting a series of valid,\nmined blocks where there is an invalid but ignored dust tx, however\nthis attack seems every bit as expensive as a 51% attack\n\nOn Fri, Oct 1, 2021 at 3:45 AM Pieter Wuille via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Jumping in late to this thread.\n>\n> I very much agree with how David Harding presents things, with a few comments inline.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Sunday, August 8th, 2021 at 5:51 PM, David A. Harding via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> > > 1.  it's not our business what outputs people want to create\n> >\n> > Every additional output added to the UTXO set increases the amount of\n> > work full nodes need to do to validate new transactions. For miners\n> > for whom fast validation of new blocks can significantly affect their\n> > revenue, larger UTXO sets increase their costs and so contributes\n> > towards centralization of mining.\n> > Allowing 0-value or 1-sat outputs minimizes the cost for polluting the\n> > UTXO set during periods of low feerates.\n> > If your stuff is going to slow down my node and possibly reduce my\n> > censorship resistance, how is that not my business?\n>\n> Indeed - UTXO set size is an externality that unfortunately Bitcoin's consensus rules fail to account\n> for. Having a relay policy that avoids at the very least economically irrational behavior makes\n> perfect sense to me.\n>\n> It's also not obvious how consensus rules could deal with this, as you don't want consensus rules\n> with hardcoded prices/feerates. There are possibilities with designs like transactions getting\n> a size/weight bonus/penalty, but that's both very hardforky, and hard to get right without\n> introducing bad incentives.\n>\n> > > 2.  dust outputs can be used in various authentication/delegation smart\n> > >     contracts\n> >\n> > > 3.  dust sized htlcs in lightning (\n> > >     https://bitcoin.stackexchange.com/questions/46730/can-you-send-amounts-that-would-typically-be-considered-dust-through-the-light)\n> > >     force channels to operate in a semi-trusted mode\n> >\n> > > 4.  thinly divisible colored coin protocols might make use of sats as value\n> > >     markers for transactions.\n>\n> My personal, and possibly controversial, opinion is that colored coin protocols have no business being on the Bitcoin chain, possibly\n> beyond committing to an occasional batched state update or so. Both because there is little benefit for tokens with a trusted\n> issuer already, and because it competes with using Bitcoin for BTC - the token that pays for its security (at least as long as\n> the subsidy doesn't run out).\n>\n> Of course, personal opinions are no reason to dictate what people should or can use the chain for, but I do think it's reason to\n> voice hesitancy to worsening the system's scalability properties only to benefit what I consider misguided use.\n>\n> > > 5.  should we ever do confidential transactions we can't prevent it without\n> > >     compromising privacy / allowed transfers\n> >\n> > I'm not an expert, but it seems to me that you can do that with range\n> > proofs. The range proof for >dust doesn't need to become part of the\n> > block chain, it can be relay only.\n>\n> Yeah, range proofs have a non-hidden range; the lower bound can be nonzero, which could be required as part of a relay policy.\n>\n> Cheers,\n>\n> --\n> Pieter\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-10-07T04:52:01",
                "message_text_only": "Good morning e,\n\n> mostly thinking out loud\n>\n> suppose there is a \"lightweight\" node:\n>\n> 1.  ignores utxo's below the dust limit\n> 2.  doesn't validate dust tx\n> 3.  still validates POW, other tx, etc.\n>\n>     these nodes could possibly get forked - accepting a series of valid,\n>     mined blocks where there is an invalid but ignored dust tx, however\n>     this attack seems every bit as expensive as a 51% attack\n\nHow would such a node treat a transaction that spends multiple dust UTXOs and creates a single non-dust UTXO out of them (after fees)?\nIs it valid (to such a node) or not?\n\nI presume from #1 it never stores dust UTXOs, so the node cannot know if the UTXO being spent by such a tx is spending dust, or trying to spend an already-spent TXO, or even inventing a TXO out of `/dev/random`.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "shymaa arafat",
                "date": "2021-10-08T07:44:59",
                "message_text_only": "The suggested idea I was replying to is to make all dust TXs invalid by\nsome nodes. I suggested a compromise by keeping them in secondary storage\nfor full nodes, and in a separate Merkle Tree for bridge servers.\n-In bridge servers they won't increase any worstcase, on the contrary this\nwill enhance the performance even if slightly.\n-In full nodes, and since they will usually appear in clusters, they will\nbe fetched rarely (either by a dust sweeping action, or a malicious\nattacker)\nIn both cases as a batch\n-To not exhaust the node with DoS(as the reply mentioned)one may think of\nuploading the whole dust partition if they were called more than certain\nthreshold (say more than 1 Tx in a block)\n-and then keep them there for \"a while\", but as a separate partition too to\nexclude them from any caching mechanism after that block.\n-The \"while\" could be a tuned parameter.\n-Take care that the more dust is sweeped, the less dust to remain in the\nUTXO set; as users are already much dis-incentivised to create more.\n.\nThanks for allowing the reply\n\nOn Thu, Oct 7, 2021, 16:43 ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n>\n>\n> > I don't know what brings up sorting here, unless as an example.\n>\n> Yes, it is an example: quicksort is bad for network-facing applications\n> because its ***worst-case behavior*** is bad.\n> Bitcoin is a network-facing application, and similarly, ***worst-case\n> behavior*** being bad is something that would strongly discourage\n> particular approaches.\n> Your proposal risks bad ***worst-case behavior***.\n>\n> > Anyways, I was comparing to rejecting them completely, not to keeping\n> them in one set. In addition, those dust sweep Transactions will probably\n> be a dust sweep and thus contain so many inputs which \"maybe\" makes 1-one\n> disk visit  to fetch all their hashes at once, 2-from a smaller subset with\n> max size 5-10% the UTXO set, justifiable.\n>\n> Do not consider the ***average case*** where a block is composed of only a\n> few dust sweep transactions and most transactions are normal,\n> non-dust-sweep transactions.\n>\n> Instead, consider the ***worst case*** where ***all*** transactions in a\n> block are dust sweep transactions, because that is what attackers will use.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211008/91bd7b81/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-10-08T10:38:50",
                "message_text_only": "Good morning shymaa,\n\n> The suggested idea I was replying to is to make all dust TXs invalid by some nodes.\n\nIs this supposed to be consensus change or not?\nWhy \"some\" nodes and not all?\n\nI think the important bit is for full nodes.\nNon-full-nodes already work at reduced security; what is important is the security-efficiency tradeoff.\n\n> I suggested a compromise by keeping them in secondary storage for full nodes, and in a separate Merkle Tree for bridge servers.\n> -In bridge servers they won't increase any worstcase, on the contrary this will enhance the performance even if slightly.\n> -In full nodes, and since they will usually appear in clusters, they will be fetched rarely (either by a dust sweeping action, or a malicious attacker)\n> In both cases as a batch\n> -To not exhaust the node with DoS(as the reply mentioned)one may think of uploading the whole dust partition if they were called more than certain threshold (say more than 1 Tx in a block)\u00a0\u00a0\n> -and then keep them there for \"a while\", but as a separate partition too to exclude them from any caching mechanism after that block.\n> -The \"while\" could be a tuned parameter.\n\nAssuming you meant \"dust tx is considered invalid by all nodes\".\n\n* Block has no dust sweep\n  * With dust rejected: only non-dust outputs are accessed.\n  * With dust in secondary storage: only non-dust outputs are accessed.\n* Block has some dust sweeps\n  * With dust rejected: only non-dust outputs are accessed, block is rejected.\n  * With dust in secondary storage: some data is loaded from secondary storage.\n* Block is composed of only dust sweeps\n  * With dust rejected: only non-dust outputs are accessed, block is rejected.\n  * With dust in secondary storage: significant increase in processing to load large secondary storage in memory,\n\nSo I fail to see how the proposal ever reduces processing compared to the idea of just outright making all dust txs invalid and rejecting the block.\nPerhaps you are trying to explain some other mechanism than what I understood?\n\nIt is helpful to think in terms always of worst-case behavior when considering resistance against attacks.\n\n> -Take care that the more dust is sweeped, the less dust to remain in the UTXO set; as users are already much dis-incentivised to create more.\n\nBut creation of dust is also as easy as sweeping them, and nothing really prevents a block from *both* creating *and* sweeping dust, e.g. a block composed of 1-input-1-output transactions, unless you want to describe some kind of restriction here?\n\nSuch a degenerate block would hit your secondary storage double: one to read, and one to overwrite and add new entries; if the storage is large then the index structure you use also is large and updates can be expensive there as well.\n\n\nAgain, I am looking solely at fullnode efficiency here, meaning all rules validated and all transactions validated, not validating and simply accepting some transactions as valid is a degradation of security from full validation to SPV validation.\nNow of course in practice modern Bitcoin is hard to attack with *only* mining hashpower as there are so many fullnodes that an SPV node would be easily able to find the \"True\" history of the chain.\nHowever, as I understand it that proporty of fullnodes protecting against attacks on SPV nodes only exists due to fullnodes being cheap to keep online; if the cost of fullnodes in the **worst case** (***not*** average, please stop talking about average case) increases then it may become feasible for miners to attack SPV nodes.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-10-08T22:47:11",
                "message_text_only": "Good morning Pieter,\n\n> Indeed - UTXO set size is an externality that unfortunately Bitcoin's consensus rules fail to account\n> for. Having a relay policy that avoids at the very least economically irrational behavior makes\n> perfect sense to me.\n>\n> It's also not obvious how consensus rules could deal with this, as you don't want consensus rules\n> with hardcoded prices/feerates. There are possibilities with designs like transactions getting\n> a size/weight bonus/penalty, but that's both very hardforky, and hard to get right without\n> introducing bad incentives.\n\nWhy is a +weight malus *very* hardforky?\n\nSuppose a new version of a node adds, say, +20 sipa per output of a transaction (in order to economically discourage the creation of additional outputs in the UTXO set).\nOlder versions would see the block as being lower weight than usual, but as the consensus rule is \"smaller than 4Msipa\" they should still accept any block acceptable to newer versions.\n\nIt seems to me that only a -weight bonus is hardforky (but then xref SegWit and its -weight bonus on inputs).\n\nI suppose the effect is primarily felt on mining nodes?\nMiners might refuse to activate such a fork, as they would see fewer transactions per block on average?\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Removing the Dust Limit",
            "categories": [
                "Lightning-dev",
                "bitcoin-dev"
            ],
            "authors": [
                "Erik Aronesty",
                "shymaa arafat",
                "ZmnSCPxj"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 11833
        }
    },
    {
        "title": "[Lightning-dev] [bitcoin-dev]    Removing the Dust Limit",
        "thread_messages": [
            {
                "author": "LORD HIS EXCELLENCY JAMES HRMH",
                "date": "2021-10-07T08:17:40",
                "message_text_only": "Good Afternoon,\n\nReturning to this subject, there should be no restriction to the value of utxo's that keep in one's own wallet as change can be created in any value. With obvious intent, the wallet should avoid creating utxo's below the current dust limit at the time the transaction is created but it cannot guarantee it.\n\nThe wallet should avoid including utxo's that by weight sat/KB are more expensive to include that their value at the time a transaction is created, ie. do not include utxo's in a transaction that lower the input value after fees for automatic utxo selection, however, perhaps consider this is valid for manual utxo selection since it is in every example 'my money' and I can spend some of it if I decide.\n\nThere is no discipline in complaining that the dust set of utxo's slows down the process of block validation during mining. Every conceivable computerised business bears the expense of the cost of a database transaction. The actual answer to this genuine business concern of database speed is to build a faster database.\n\nIt is correct knowledge to know that the Bitcoin protocol cannot speculate as to the future but we can. The case exists where it is conceivable for example, that the transaction fee is paid only for the first utxo inclusion in a transaction due to changes to the calculation of block-size. There are other easily plausible examples where the inclusion of what is today considered dust may not be ill-considered.\n\nKING JAMES HRMH\nGreat British Empire\n\nRegards,\nThe Australian\nLORD HIS EXCELLENCY JAMES HRMH (& HMRH)\nof Hougun Manor & Glencoe & British Empire\nMR. Damian A. James Williamson\nWills\n\net al.\n\n\nWilltech\nwww.willtech.com.au\nwww.go-overt.com\nduigco.org DUIGCO API\nand other projects\n\n\nm. 0487135719\nf. +61261470192\n\n\nThis email does not constitute a general advice. Please disregard this email if misdelivered.\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211007/c2aee87a/attachment-0001.html>"
            },
            {
                "author": "LORD HIS EXCELLENCY JAMES HRMH",
                "date": "2021-10-07T08:34:17",
                "message_text_only": "Good Afternoon,\n\nThe underlying consideration is the same concerning the handling of 1c and 2c coins in an economy. Although you may argue the cost of counting those coins throughout the course of minting, drafting to banks, paying to bank customers, including in change, and at every handling counting, is less than the value of those coins, hpwever, the solution in traditional currency is to round the value of the transaction either per line of goods or per total before calculating the Grand Total, in which case the payment either from a non-utxo set of accumulation in a traditional account or, from a known series of denominations, is adjusted.\n\nIn the case of Bitcoin, the denominations available are effectively the utxo set and there is no effective way to round the transactions without accepting overpayments as valid, and with what consideration, in which case the protocol may avoid creating dust in change by sending the additional rounded amount that would otherwise be dust to the recipient.\n\nI suppose that this gets difficult where the transaction has multiple outputs and you could argue to distribute to all outputs as an overpayment. It is the same effectively as rounding to 10c.\n\nKING JAMES HRMH\nGreat British Empire\n\nRegards,\nThe Australian\nLORD HIS EXCELLENCY JAMES HRMH (& HMRH)\nof Hougun Manor & Glencoe & British Empire\nMR. Damian A. James Williamson\nWills\n\net al.\n\n\nWilltech\nwww.willtech.com.au\nwww.go-overt.com\nduigco.org DUIGCO API\nand other projects\n\n\nm. 0487135719\nf. +61261470192\n\n\nThis email does not constitute a general advice. Please disregard this email if misdelivered.\n\n\n________________________________\nFrom: LORD HIS EXCELLENCY JAMES HRMH <willtech at live.com.au>\nSent: Thursday, 7 October 2021 7:17 PM\nTo: Erik Aronesty <erik at q32.com>; ZmnSCPxj <ZmnSCPxj at protonmail.com>; Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\nCc: lightning-dev <lightning-dev at lists.linuxfoundation.org>\nSubject: Re: [bitcoin-dev] [Lightning-dev] Removing the Dust Limit\n\nGood Afternoon,\n\nReturning to this subject, there should be no restriction to the value of utxo's that keep in one's own wallet as change can be created in any value. With obvious intent, the wallet should avoid creating utxo's below the current dust limit at the time the transaction is created but it cannot guarantee it.\n\nThe wallet should avoid including utxo's that by weight sat/KB are more expensive to include that their value at the time a transaction is created, ie. do not include utxo's in a transaction that lower the input value after fees for automatic utxo selection, however, perhaps consider this is valid for manual utxo selection since it is in every example 'my money' and I can spend some of it if I decide.\n\nThere is no discipline in complaining that the dust set of utxo's slows down the process of block validation during mining. Every conceivable computerised business bears the expense of the cost of a database transaction. The actual answer to this genuine business concern of database speed is to build a faster database.\n\nIt is correct knowledge to know that the Bitcoin protocol cannot speculate as to the future but we can. The case exists where it is conceivable for example, that the transaction fee is paid only for the first utxo inclusion in a transaction due to changes to the calculation of block-size. There are other easily plausible examples where the inclusion of what is today considered dust may not be ill-considered.\n\nKING JAMES HRMH\nGreat British Empire\n\nRegards,\nThe Australian\nLORD HIS EXCELLENCY JAMES HRMH (& HMRH)\nof Hougun Manor & Glencoe & British Empire\nMR. Damian A. James Williamson\nWills\n\net al.\n\n\nWilltech\nwww.willtech.com.au\nwww.go-overt.com\nduigco.org DUIGCO API\nand other projects\n\n\nm. 0487135719\nf. +61261470192\n\n\nThis email does not constitute a general advice. Please disregard this email if misdelivered.\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211007/89937fd1/attachment.html>"
            },
            {
                "author": "LORD HIS EXCELLENCY JAMES HRMH",
                "date": "2021-10-07T10:35:16",
                "message_text_only": "Good Afternoon,\n\nFurther, if it is entirely necessary to prevent the creation of utxo's that are considered dust, and I am not by any means convinced, then it is simple to provide the most circumspect solution to transfer the value of any dust utxo that would be created in a transaction to the fee. I do not believe this answer is any more than robbery of the future value of the wallet as my wallet must be able to keep any change but if it is must then this is the answer.\n\nKING JAMES HRMH\nGreat British Empire\n\nRegards,\nThe Australian\nLORD HIS EXCELLENCY JAMES HRMH (& HMRH)\nof Hougun Manor & Glencoe & British Empire\nMR. Damian A. James Williamson\nWills\n\net al.\n\n\nWilltech\nwww.willtech.com.au\nwww.go-overt.com\nduigco.org DUIGCO API\nand other projects\n\n\nm. 0487135719\nf. +61261470192\n\n\nThis email does not constitute a general advice. Please disregard this email if misdelivered.\n________________________________\nFrom: LORD HIS EXCELLENCY JAMES HRMH <willtech at live.com.au>\nSent: Thursday, 7 October 2021 7:34 PM\nTo: Erik Aronesty <erik at q32.com>; ZmnSCPxj <ZmnSCPxj at protonmail.com>; Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\nCc: lightning-dev <lightning-dev at lists.linuxfoundation.org>\nSubject: Re: [bitcoin-dev] [Lightning-dev] Removing the Dust Limit\n\nGood Afternoon,\n\nThe underlying consideration is the same concerning the handling of 1c and 2c coins in an economy. Although you may argue the cost of counting those coins throughout the course of minting, drafting to banks, paying to bank customers, including in change, and at every handling counting, is less than the value of those coins, hpwever, the solution in traditional currency is to round the value of the transaction either per line of goods or per total before calculating the Grand Total, in which case the payment either from a non-utxo set of accumulation in a traditional account or, from a known series of denominations, is adjusted.\n\nIn the case of Bitcoin, the denominations available are effectively the utxo set and there is no effective way to round the transactions without accepting overpayments as valid, and with what consideration, in which case the protocol may avoid creating dust in change by sending the additional rounded amount that would otherwise be dust to the recipient.\n\nI suppose that this gets difficult where the transaction has multiple outputs and you could argue to distribute to all outputs as an overpayment. It is the same effectively as rounding to 10c.\n\nKING JAMES HRMH\nGreat British Empire\n\nRegards,\nThe Australian\nLORD HIS EXCELLENCY JAMES HRMH (& HMRH)\nof Hougun Manor & Glencoe & British Empire\nMR. Damian A. James Williamson\nWills\n\net al.\n\n\nWilltech\nwww.willtech.com.au\nwww.go-overt.com\nduigco.org DUIGCO API\nand other projects\n\n\nm. 0487135719\nf. +61261470192\n\n\nThis email does not constitute a general advice. Please disregard this email if misdelivered.\n\n\n________________________________\nFrom: LORD HIS EXCELLENCY JAMES HRMH <willtech at live.com.au>\nSent: Thursday, 7 October 2021 7:17 PM\nTo: Erik Aronesty <erik at q32.com>; ZmnSCPxj <ZmnSCPxj at protonmail.com>; Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\nCc: lightning-dev <lightning-dev at lists.linuxfoundation.org>\nSubject: Re: [bitcoin-dev] [Lightning-dev] Removing the Dust Limit\n\nGood Afternoon,\n\nReturning to this subject, there should be no restriction to the value of utxo's that keep in one's own wallet as change can be created in any value. With obvious intent, the wallet should avoid creating utxo's below the current dust limit at the time the transaction is created but it cannot guarantee it.\n\nThe wallet should avoid including utxo's that by weight sat/KB are more expensive to include that their value at the time a transaction is created, ie. do not include utxo's in a transaction that lower the input value after fees for automatic utxo selection, however, perhaps consider this is valid for manual utxo selection since it is in every example 'my money' and I can spend some of it if I decide.\n\nThere is no discipline in complaining that the dust set of utxo's slows down the process of block validation during mining. Every conceivable computerised business bears the expense of the cost of a database transaction. The actual answer to this genuine business concern of database speed is to build a faster database.\n\nIt is correct knowledge to know that the Bitcoin protocol cannot speculate as to the future but we can. The case exists where it is conceivable for example, that the transaction fee is paid only for the first utxo inclusion in a transaction due to changes to the calculation of block-size. There are other easily plausible examples where the inclusion of what is today considered dust may not be ill-considered.\n\nKING JAMES HRMH\nGreat British Empire\n\nRegards,\nThe Australian\nLORD HIS EXCELLENCY JAMES HRMH (& HMRH)\nof Hougun Manor & Glencoe & British Empire\nMR. Damian A. James Williamson\nWills\n\net al.\n\n\nWilltech\nwww.willtech.com.au\nwww.go-overt.com\nduigco.org DUIGCO API\nand other projects\n\n\nm. 0487135719\nf. +61261470192\n\n\nThis email does not constitute a general advice. Please disregard this email if misdelivered.\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211007/ad09e939/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Removing the Dust Limit",
            "categories": [
                "Lightning-dev",
                "bitcoin-dev"
            ],
            "authors": [
                "LORD HIS EXCELLENCY JAMES HRMH"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 11538
        }
    },
    {
        "title": "[Lightning-dev] Full Disclosure: CVE-2021-41591/ CVE-2021-41592 / CVE-2021-41593 \"Dust HTLC Exposure Considered Harmful\"",
        "thread_messages": [
            {
                "author": "Antoine Riard",
                "date": "2021-10-04T15:09:28",
                "message_text_only": "Hi,\n\nI'm writing a report to disclose specification-level vulnerabilities\naffecting the Lightning implementations.\n\nThe vulnerabilities are expected to be patched in:\n* Eclair: v0.6.2+ (CVE-2021-41591)\n* LND: v0.13.3+ (CVE-2021-41592)\n* LDK: v0.0.102 (not released as production software yet)\n\nThe vulnerabilities are also affecting c-lightning (CVE-2021-41593).\n\nThose vulnerabilities can be exploited in a wide range of attacks, going\nfrom fee blackmailing of node operators, burning liquidity of your\ncompeting LSPs or even stealing your counterparty channel balance if you\navail mining capabilities. Exercise of the vulnerability revealed that a\nmajority of the balance funds can be at loss.\n\nCredit to Eugene Siegel (Crypt-iQ) for reporting the trimmed-to-dust\nexploitation and multiple insights about attacks.\n\nThanks to Bastien Teinturier and Matt Corallo for numerous contributions\nabout mitigations development.\n\n# Problem\n\nThe current BOLT specification only requires Alice's `dust_limit_satoshis`\n(applied on Alice's commitment) to be under Alice's\n`channel_reserve_satoshis` (applied on Bob). As those 2 parameters are\nselectable by Alice, she can inflate the dust limit until reaching the\nimplementation-defined max value (e.g LND: 20% of chan capacity, LDK: 100%\nof chan capacity).\n\nAny in-flight incoming HTLC under Alice's dust limit will be converted as\nminer fees on Alice's commitment. This HTLC is deducted from Bob's balance\nand as such they're still owned by Bob, until resolution (i.e a RAA\nremoving the HTLC from Alice's commitment). This limitation only applies\nper-HTLC. No implementation enforces a limit on the sum of in-flight HTLCs\nburned as fees. Therefore, Alice is free to inflict a substantial loss to\nBob funds by publishing her commitment on-chain.\n\nIn-flight outgoing HTLC are also committed as fees on Bob's commitment if\nthey're under Bob's threshold. Alice can also exploit from this angle by\ncircular routing HTLCs until reaching Bob's\n`max_htlc_value_in_flight_msat`. Alice withholds HTLCs resolution until Bob\ngoes on-chain to timeout an offered HTLC or claim an accepted HTLC.\n\nDust HTLC processing can be also exploited at `update_fee` reception.\n\nAs the BOLT3's fees computation encompasses the negotiated feerate from\n`update_fee` for the 2nd-stage HTLC fees to decide if the HTLC must be\ntrimmed, the amount of balance at risk is a function of current mempool\nfeerates.\n\nThe maximum of funds at risk on a counterparty commitment is:\n\ncounterparty's `max_accepted_htlcs` * (`htlc_success_tx_kw` * opener's\n`feerate_per_kw` + counterparty's `dust_limit_satoshis`) + holder's\n`max_accepted_htlcs` * (`htlc_timeout_tx_kw` * opener's `feerate_per_kw` +\ncounterparty's `dust_limit_satoshis`)\n\nIf the opener is also the attacker, the negotiated feerate can be\nmanipulated beyond the \"honest\" mempool feerates only upper bounded\nimplementation-defined value (before fixes, LDK: 2 * high-feerate of our\nfee-estimator). If the opener is the victim, the negotiated feerate is\nstill a safety concern in case of spontaneous mempool spikes.\n\nNote, `anchors_zero_htlc_fee` channels are not affected by the feerate\ninflation as the trimmed-to-dust fee computation mechanism for 2nd-stage\nHTLC is removed. They're still at risk of the sum of the HTLCs under the\ndust limit being maliciously burned.\n\n# Solution\n\nA first mitigation is to verify the counterparty's announced\n`dust_limit_satoshis` at channel opening (`open_channel`/`accept_channel`)\nreception and reject if it's estimated too large (see #894)\n\nFor LDK, we choose the value of 660 satoshis as it's beyond the highest\ndust threshold enforced by Bitcoin Core (p2pkh: 546) with a margin of\nsafety. Propagation of Lightning time-sensitive transactions shouldn't be\naffected.\n\nA second mitigation is to define a new configurable limit\n`max_dust_htlc_exposure` and apply this one at incoming and outgoing of\nHTLC.\n\nFor LDK, we choose the value of 5 000 000 milli-satoshis as we gauged this\nvalue as a substantial loss for our class of users. Setting this too low\nmay prevent the sending or receipt of low-value HTLCs on high-traffic\nnodes. A node operator should fine-tune this value in function of what\nqualifies as an acceptable loss.\n\nWe would like to ensure that the node isn't suddenly exposed to\nsignificantly more trimmed balance if the feerate increases when we have\nseveral HTLCs pending which are near the dust limit.\n\nTo achieve this goal, we introduce a new `dust_buffer_feerate` defined as\nthe maximum of either 2530 sats per kWU or 125% of the current\n`feerate_per_kw` (implementation-defined values).\n\nThen, upon an incoming HTLC, if the HTLC's `amount_msat` is inferior to the\ncounterparty's `dust_limit_satoshis` plus the HTLC-timeout fee at the\n`dust_buffer_feerate`. If the `amount_msat` plus the\n`dust_balance_on_counterparty_tx` is superior to `max_dust_htlc_exposure`,\nthe HTLC should be failed once it's committed.\n\nUpon an outgoing HTLC, if the HTLC's `amount_msat` is inferior to the\ncounterparty's `dust_limit_satoshis`  plus the HTLC-success fee at the\n`dust_buffer_feerate`. If the `amount_msat` plus the\n`dust_balance_on_counterparty_tx` is superior to `max_dust_htlc_exposure`,\nthe HTLC should not be sent and fail without forwarding.\n\nThe check symmetry must also be applied on holder commitment transactions.\nSee PR #919 for more details.\n\nA last mitigation is ensuring that at `update_fee` reception, the pending\n`dust_balance` at the new proposed feerate isn't superior to\n`max_dust_htlc_exposure_msat`.\n\n# Background\n\nThe dust limit is a base layer policy stopping the relay of a transaction\nif one of its outputs is under a given threshold. The goal of this policy\nis to prevent the pollution of the UTXO set with low-value outputs and as\nsuch increase the amount of work done by full-nodes.\n\nLightning commitment transactions should be able to propagate at any point\nduring the channel lifetime to unilaterally enforce on-chain a balance. A\nLightning commitment transaction with one of its outputs below the dust\nlimit would fail to relay and thus jeopardizes funds safety.\n\nTo prevent this, BOLT2 requires counterparties to announce a\n`dust_limit_satoshis` during channel opening (at\n`open_channel`/`accept_channel` exchange). This `dust_limit_satoshis` must\nbe under the same party's `channel_reserve_satoshis`. This value is static\nfor the channel lifetime.\n\nDuring commitment signatures exchange, each counterparty's limit is applied\non each counterparty's commitment (e.g A's `dust_limit_satoshis` is applied\non A's commitment, though both A and B have to generate and sign the\ntransaction). An output below this limit is trimmed to fees and won't\nmaterialize on the commitment.\n\nThe specification didn't require that the `open_channel`/`accept_channel`\nreceiver verify that the announced `dust_limit_satoshis` isn't too large.\n\nThe specification didn't require that the sum of the dust HTLC committed as\nfees was verified against an upper bound.\n\n# Discovery\n\nVulnerabilities around our dust HTLC processing have been known for years\nby some LN developers/researchers.\n\nDuring Q1 2019, private discussions on the Rust-Lightning-side (LDK before\nmarketing rebranding) about potential safety risks around dust HTLC\nprocessing.\n\nIn November 2019, Rusty Russell (c-lightning) opened an issue against the\nspecification mentioning the lack of check of counterparty's dust limit\n(#696).\n\nIn May 2020, I published a high-level attack scenario \"Miners Dust\nInflation attacks on Lightning Network\", leveraging this lack.\n\nIn February 2021, I did a test of the first vulnerability against LND\nsoftware and successfully burnt the majority of the targeted node balance\nin fees. As it sounds to me like a check missing in the specification, I\nnotified CL/LND/Eclair/LDK maintainers. Mitigations started to be developed\non the LDK-side.\n\nIn July 2021, in the context of `option_dusty_htlcs_uncounted` discussions,\nEugene Spiegel (LND) reported on how to exploit the trimmed-to-dust\nmechanism at `update_fee` reception. Discussions followed on the best way\nto mitigate this new vector.\n\nDuring August 2021, mitigations were developed and released on the\nLDK-side. vulnerabilities were disclosed to other Lightning projects (Muun\nwallet, Electrum). From the LDK-side, a public disclosure date was proposed.\n\nStill during August 2021, the Bitcoin Core dust limit was actively\ndiscussed on the mailing list. Changes of this dust limit would have\naffected the ongoing development of the mitigations.\n\nWhile this report highlights the lack of well-defined communication process\nacross Lightning teams,  developers from 3 different implementations have\nactively participated in the vulnerabilities diagnostic and mitigations\ndevelopment of those long-standing specification issues affecting the whole\nLightning ecosystem.\n\nAll mistakes and opinions are my own and please verify any information\nreported.\n\n# Timeline\n\n* 2021-04-19: Working exploit of the vulnerability against LND,\nCL/LND/Eclair/LDK maintainers notified\n* 2021-07-21: Finding by Eugene Siegel on how to exploit the\ntrimmed-to-dust mechanism at `update_fee` reception\n* 2021-08-11: BOLT PR #894 opened by Bastien Teinturier, covering the lack\nof verification of counterparty per-HTLC `dust_limit_satoshis`\n* 2021-08-16: Mitigations developed in LDK, communication of a public\ndisclosure date\n* 2021-08-26: Notification to Muun wallet, non-affected\n* 2021-08-27: Notification to Electrum wallet\n* 2021-10-04: Full Disclosure of CVEs\n* 2021-10-04: Submit BOLT PR #919 covering the remaining vulnerabilities\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211004/9af032f2/attachment.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2021-10-04T15:57:13",
                "message_text_only": "On Monday 04 October 2021 15:09:28 Antoine Riard wrote:\n> Still during August 2021, the Bitcoin Core dust limit was actively\n> discussed on the mailing list. Changes of this dust limit would have\n> affected the ongoing development of the mitigations.\n\nThe \"dust limit\" is arbitrarily decided by each node, and cannot be relied \nupon for security at all. Expecting it to be a given default value is in \nitself a security vulnerability.\n\n\nP.S. It'd be nice if someone familiar with these could fill in \nhttps://en.bitcoin.it/wiki/CVEs"
            },
            {
                "author": "Antoine Riard",
                "date": "2021-10-04T16:14:20",
                "message_text_only": "> The \"dust limit\" is arbitrarily decided by each node, and cannot be\nrelied\nupon for security at all. Expecting it to be a given default value is in\nitself a security vulnerability\n\nReality is that an increasing number of funds are secured by assumptions\naround mempool behavior.\nAnd sadly that's going to increase with Lightning growth and deployment of\nother L2s.\n\nMaybe we could dry-up some policy rules in consensus like the dust limit\none :)\n\n\nLe lun. 4 oct. 2021 \u00e0 11:57, Luke Dashjr <luke at dashjr.org> a \u00e9crit :\n\n> On Monday 04 October 2021 15:09:28 Antoine Riard wrote:\n> > Still during August 2021, the Bitcoin Core dust limit was actively\n> > discussed on the mailing list. Changes of this dust limit would have\n> > affected the ongoing development of the mitigations.\n>\n> The \"dust limit\" is arbitrarily decided by each node, and cannot be relied\n> upon for security at all. Expecting it to be a given default value is in\n> itself a security vulnerability.\n>\n>\n> P.S. It'd be nice if someone familiar with these could fill in\n> https://en.bitcoin.it/wiki/CVEs\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211004/4f3f6154/attachment-0001.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2021-10-04T16:27:59",
                "message_text_only": "On Monday 04 October 2021 16:14:20 Antoine Riard wrote:\n> > The \"dust limit\" is arbitrarily decided by each node, and cannot be\n> > relied upon for security at all. Expecting it to be a given default value\n> > is in itself a security vulnerability\n>\n> Reality is that an increasing number of funds are secured by assumptions\n> around mempool behavior.\n\nIn other words, simply not secured.\n\n> And sadly that's going to increase with Lightning growth and deployment of\n> other L2s.\n\nL2s shouldn't build on flawed assumptions.\n\n> Maybe we could dry-up some policy rules in consensus like the dust limit\n> one :)\n\nNo thanks. Not sure that would even help (since policies can always be set to \na higher dust limit than any consensus rule)"
            },
            {
                "author": "Antoine Riard",
                "date": "2021-10-04T18:45:45",
                "message_text_only": "> In other words, simply not secured.\n\nHow do you define Bitcoin base-layer security ? How strong are the\nassumptions we're relying on the base-layer ?\nNot easy answers :/\n\n> L2s shouldn't build on flawed assumptions.\n\nWaiting for your proposal to scale Bitcoin payments relying on pure\nconsensus assumptions :)\n\n> No thanks. Not sure that would even help (since policies can always be\nset to\na higher dust limit than any consensus rule)\n\nSure. Policies can always be more restrictive. One of them could be to not\nrelay transactions at all. If widely-deployed, such policy would make the\nnetwork quite unusable....\n\nMore seriously, I think when we consider this policy discussion, we should\nhave more in mind the consequences of adopting a given policy or another\none.\nAs long as they're economically-compatible, they should be followed by an\neconomically rational node operator.\nI think we're already making that kind of social or economic assumption on\nthe user behavior w.r.t to full-node design. Blocks and transactions are\nrelayed for \"free\" today, not satoshis are received in exchange.\n\n\nLe lun. 4 oct. 2021 \u00e0 12:28, Luke Dashjr <luke at dashjr.org> a \u00e9crit :\n\n> On Monday 04 October 2021 16:14:20 Antoine Riard wrote:\n> > > The \"dust limit\" is arbitrarily decided by each node, and cannot be\n> > > relied upon for security at all. Expecting it to be a given default\n> value\n> > > is in itself a security vulnerability\n> >\n> > Reality is that an increasing number of funds are secured by assumptions\n> > around mempool behavior.\n>\n> In other words, simply not secured.\n>\n> > And sadly that's going to increase with Lightning growth and deployment\n> of\n> > other L2s.\n>\n> L2s shouldn't build on flawed assumptions.\n>\n> > Maybe we could dry-up some policy rules in consensus like the dust limit\n> > one :)\n>\n> No thanks. Not sure that would even help (since policies can always be set\n> to\n> a higher dust limit than any consensus rule)\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211004/30471001/attachment.html>"
            },
            {
                "author": "lisa neigut",
                "date": "2021-10-04T18:15:59",
                "message_text_only": "FYI the next version of c-lightning will contain the proposed\n`max_dust_htlc_exposure_msat` as outlined in #919\n<https://github.com/lightningnetwork/lightning-rfc/pull/919/files>; the\ngiven expected vulnerabilities patch table should have reflected this.\n\n> The vulnerabilities are expected to be patched in:\n> * Eclair: v0.6.2+ (CVE-2021-41591)\n> * LND: v0.13.3+ (CVE-2021-41592)\n> * LDK: v0.0.102 (not released as production software yet)\n\n* C-lightning v0.10.2 (CVE-2021-41593)\n\n\nLisa\n\nOn Mon, Oct 4, 2021 at 10:09 AM Antoine Riard <antoine.riard at gmail.com>\nwrote:\n\n> Hi,\n>\n> I'm writing a report to disclose specification-level vulnerabilities\n> affecting the Lightning implementations.\n>\n> The vulnerabilities are expected to be patched in:\n> * Eclair: v0.6.2+ (CVE-2021-41591)\n> * LND: v0.13.3+ (CVE-2021-41592)\n> * LDK: v0.0.102 (not released as production software yet)\n>\n> The vulnerabilities are also affecting c-lightning (CVE-2021-41593).\n>\n> Those vulnerabilities can be exploited in a wide range of attacks, going\n> from fee blackmailing of node operators, burning liquidity of your\n> competing LSPs or even stealing your counterparty channel balance if you\n> avail mining capabilities. Exercise of the vulnerability revealed that a\n> majority of the balance funds can be at loss.\n>\n> Credit to Eugene Siegel (Crypt-iQ) for reporting the trimmed-to-dust\n> exploitation and multiple insights about attacks.\n>\n> Thanks to Bastien Teinturier and Matt Corallo for numerous contributions\n> about mitigations development.\n>\n> # Problem\n>\n> The current BOLT specification only requires Alice's `dust_limit_satoshis`\n> (applied on Alice's commitment) to be under Alice's\n> `channel_reserve_satoshis` (applied on Bob). As those 2 parameters are\n> selectable by Alice, she can inflate the dust limit until reaching the\n> implementation-defined max value (e.g LND: 20% of chan capacity, LDK: 100%\n> of chan capacity).\n>\n> Any in-flight incoming HTLC under Alice's dust limit will be converted as\n> miner fees on Alice's commitment. This HTLC is deducted from Bob's balance\n> and as such they're still owned by Bob, until resolution (i.e a RAA\n> removing the HTLC from Alice's commitment). This limitation only applies\n> per-HTLC. No implementation enforces a limit on the sum of in-flight HTLCs\n> burned as fees. Therefore, Alice is free to inflict a substantial loss to\n> Bob funds by publishing her commitment on-chain.\n>\n> In-flight outgoing HTLC are also committed as fees on Bob's commitment if\n> they're under Bob's threshold. Alice can also exploit from this angle by\n> circular routing HTLCs until reaching Bob's\n> `max_htlc_value_in_flight_msat`. Alice withholds HTLCs resolution until Bob\n> goes on-chain to timeout an offered HTLC or claim an accepted HTLC.\n>\n> Dust HTLC processing can be also exploited at `update_fee` reception.\n>\n> As the BOLT3's fees computation encompasses the negotiated feerate from\n> `update_fee` for the 2nd-stage HTLC fees to decide if the HTLC must be\n> trimmed, the amount of balance at risk is a function of current mempool\n> feerates.\n>\n> The maximum of funds at risk on a counterparty commitment is:\n>\n> counterparty's `max_accepted_htlcs` * (`htlc_success_tx_kw` * opener's\n> `feerate_per_kw` + counterparty's `dust_limit_satoshis`) + holder's\n> `max_accepted_htlcs` * (`htlc_timeout_tx_kw` * opener's `feerate_per_kw` +\n> counterparty's `dust_limit_satoshis`)\n>\n> If the opener is also the attacker, the negotiated feerate can be\n> manipulated beyond the \"honest\" mempool feerates only upper bounded\n> implementation-defined value (before fixes, LDK: 2 * high-feerate of our\n> fee-estimator). If the opener is the victim, the negotiated feerate is\n> still a safety concern in case of spontaneous mempool spikes.\n>\n> Note, `anchors_zero_htlc_fee` channels are not affected by the feerate\n> inflation as the trimmed-to-dust fee computation mechanism for 2nd-stage\n> HTLC is removed. They're still at risk of the sum of the HTLCs under the\n> dust limit being maliciously burned.\n>\n> # Solution\n>\n> A first mitigation is to verify the counterparty's announced\n> `dust_limit_satoshis` at channel opening (`open_channel`/`accept_channel`)\n> reception and reject if it's estimated too large (see #894)\n>\n> For LDK, we choose the value of 660 satoshis as it's beyond the highest\n> dust threshold enforced by Bitcoin Core (p2pkh: 546) with a margin of\n> safety. Propagation of Lightning time-sensitive transactions shouldn't be\n> affected.\n>\n> A second mitigation is to define a new configurable limit\n> `max_dust_htlc_exposure` and apply this one at incoming and outgoing of\n> HTLC.\n>\n> For LDK, we choose the value of 5 000 000 milli-satoshis as we gauged this\n> value as a substantial loss for our class of users. Setting this too low\n> may prevent the sending or receipt of low-value HTLCs on high-traffic\n> nodes. A node operator should fine-tune this value in function of what\n> qualifies as an acceptable loss.\n>\n> We would like to ensure that the node isn't suddenly exposed to\n> significantly more trimmed balance if the feerate increases when we have\n> several HTLCs pending which are near the dust limit.\n>\n> To achieve this goal, we introduce a new `dust_buffer_feerate` defined as\n> the maximum of either 2530 sats per kWU or 125% of the current\n> `feerate_per_kw` (implementation-defined values).\n>\n> Then, upon an incoming HTLC, if the HTLC's `amount_msat` is inferior to\n> the counterparty's `dust_limit_satoshis` plus the HTLC-timeout fee at the\n> `dust_buffer_feerate`. If the `amount_msat` plus the\n> `dust_balance_on_counterparty_tx` is superior to `max_dust_htlc_exposure`,\n> the HTLC should be failed once it's committed.\n>\n> Upon an outgoing HTLC, if the HTLC's `amount_msat` is inferior to the\n> counterparty's `dust_limit_satoshis`  plus the HTLC-success fee at the\n> `dust_buffer_feerate`. If the `amount_msat` plus the\n> `dust_balance_on_counterparty_tx` is superior to `max_dust_htlc_exposure`,\n> the HTLC should not be sent and fail without forwarding.\n>\n> The check symmetry must also be applied on holder commitment transactions.\n> See PR #919 for more details.\n>\n> A last mitigation is ensuring that at `update_fee` reception, the pending\n> `dust_balance` at the new proposed feerate isn't superior to\n> `max_dust_htlc_exposure_msat`.\n>\n> # Background\n>\n> The dust limit is a base layer policy stopping the relay of a transaction\n> if one of its outputs is under a given threshold. The goal of this policy\n> is to prevent the pollution of the UTXO set with low-value outputs and as\n> such increase the amount of work done by full-nodes.\n>\n> Lightning commitment transactions should be able to propagate at any point\n> during the channel lifetime to unilaterally enforce on-chain a balance. A\n> Lightning commitment transaction with one of its outputs below the dust\n> limit would fail to relay and thus jeopardizes funds safety.\n>\n> To prevent this, BOLT2 requires counterparties to announce a\n> `dust_limit_satoshis` during channel opening (at\n> `open_channel`/`accept_channel` exchange). This `dust_limit_satoshis` must\n> be under the same party's `channel_reserve_satoshis`. This value is static\n> for the channel lifetime.\n>\n> During commitment signatures exchange, each counterparty's limit is\n> applied on each counterparty's commitment (e.g A's `dust_limit_satoshis` is\n> applied on A's commitment, though both A and B have to generate and sign\n> the transaction). An output below this limit is trimmed to fees and won't\n> materialize on the commitment.\n>\n> The specification didn't require that the `open_channel`/`accept_channel`\n> receiver verify that the announced `dust_limit_satoshis` isn't too large.\n>\n> The specification didn't require that the sum of the dust HTLC committed\n> as fees was verified against an upper bound.\n>\n> # Discovery\n>\n> Vulnerabilities around our dust HTLC processing have been known for years\n> by some LN developers/researchers.\n>\n> During Q1 2019, private discussions on the Rust-Lightning-side (LDK before\n> marketing rebranding) about potential safety risks around dust HTLC\n> processing.\n>\n> In November 2019, Rusty Russell (c-lightning) opened an issue against the\n> specification mentioning the lack of check of counterparty's dust limit\n> (#696).\n>\n> In May 2020, I published a high-level attack scenario \"Miners Dust\n> Inflation attacks on Lightning Network\", leveraging this lack.\n>\n> In February 2021, I did a test of the first vulnerability against LND\n> software and successfully burnt the majority of the targeted node balance\n> in fees. As it sounds to me like a check missing in the specification, I\n> notified CL/LND/Eclair/LDK maintainers. Mitigations started to be developed\n> on the LDK-side.\n>\n> In July 2021, in the context of `option_dusty_htlcs_uncounted`\n> discussions, Eugene Spiegel (LND) reported on how to exploit the\n> trimmed-to-dust mechanism at `update_fee` reception. Discussions followed\n> on the best way to mitigate this new vector.\n>\n> During August 2021, mitigations were developed and released on the\n> LDK-side. vulnerabilities were disclosed to other Lightning projects (Muun\n> wallet, Electrum). From the LDK-side, a public disclosure date was proposed.\n>\n> Still during August 2021, the Bitcoin Core dust limit was actively\n> discussed on the mailing list. Changes of this dust limit would have\n> affected the ongoing development of the mitigations.\n>\n> While this report highlights the lack of well-defined communication\n> process across Lightning teams,  developers from 3 different\n> implementations have actively participated in the vulnerabilities\n> diagnostic and mitigations development of those long-standing specification\n> issues affecting the whole Lightning ecosystem.\n>\n> All mistakes and opinions are my own and please verify any information\n> reported.\n>\n> # Timeline\n>\n> * 2021-04-19: Working exploit of the vulnerability against LND,\n> CL/LND/Eclair/LDK maintainers notified\n> * 2021-07-21: Finding by Eugene Siegel on how to exploit the\n> trimmed-to-dust mechanism at `update_fee` reception\n> * 2021-08-11: BOLT PR #894 opened by Bastien Teinturier, covering the lack\n> of verification of counterparty per-HTLC `dust_limit_satoshis`\n> * 2021-08-16: Mitigations developed in LDK, communication of a public\n> disclosure date\n> * 2021-08-26: Notification to Muun wallet, non-affected\n> * 2021-08-27: Notification to Electrum wallet\n> * 2021-10-04: Full Disclosure of CVEs\n> * 2021-10-04: Submit BOLT PR #919 covering the remaining vulnerabilities\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211004/8cba7b8d/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2021-10-04T18:50:55",
                "message_text_only": "> * C-lightning v0.10.2 (CVE-2021-41593)\n\nThanks I was unsure about the exact version number. I'll update the CVE\nquickly.\n\nLe lun. 4 oct. 2021 \u00e0 14:16, lisa neigut <niftynei at gmail.com> a \u00e9crit :\n\n> FYI the next version of c-lightning will contain the proposed\n> `max_dust_htlc_exposure_msat` as outlined in #919\n> <https://github.com/lightningnetwork/lightning-rfc/pull/919/files>; the\n> given expected vulnerabilities patch table should have reflected this.\n>\n> > The vulnerabilities are expected to be patched in:\n> > * Eclair: v0.6.2+ (CVE-2021-41591)\n> > * LND: v0.13.3+ (CVE-2021-41592)\n> > * LDK: v0.0.102 (not released as production software yet)\n>\n> * C-lightning v0.10.2 (CVE-2021-41593)\n>\n>\n> Lisa\n>\n> On Mon, Oct 4, 2021 at 10:09 AM Antoine Riard <antoine.riard at gmail.com>\n> wrote:\n>\n>> Hi,\n>>\n>> I'm writing a report to disclose specification-level vulnerabilities\n>> affecting the Lightning implementations.\n>>\n>> The vulnerabilities are expected to be patched in:\n>> * Eclair: v0.6.2+ (CVE-2021-41591)\n>> * LND: v0.13.3+ (CVE-2021-41592)\n>> * LDK: v0.0.102 (not released as production software yet)\n>>\n>> The vulnerabilities are also affecting c-lightning (CVE-2021-41593).\n>>\n>> Those vulnerabilities can be exploited in a wide range of attacks, going\n>> from fee blackmailing of node operators, burning liquidity of your\n>> competing LSPs or even stealing your counterparty channel balance if you\n>> avail mining capabilities. Exercise of the vulnerability revealed that a\n>> majority of the balance funds can be at loss.\n>>\n>> Credit to Eugene Siegel (Crypt-iQ) for reporting the trimmed-to-dust\n>> exploitation and multiple insights about attacks.\n>>\n>> Thanks to Bastien Teinturier and Matt Corallo for numerous contributions\n>> about mitigations development.\n>>\n>> # Problem\n>>\n>> The current BOLT specification only requires Alice's\n>> `dust_limit_satoshis` (applied on Alice's commitment) to be under Alice's\n>> `channel_reserve_satoshis` (applied on Bob). As those 2 parameters are\n>> selectable by Alice, she can inflate the dust limit until reaching the\n>> implementation-defined max value (e.g LND: 20% of chan capacity, LDK: 100%\n>> of chan capacity).\n>>\n>> Any in-flight incoming HTLC under Alice's dust limit will be converted as\n>> miner fees on Alice's commitment. This HTLC is deducted from Bob's balance\n>> and as such they're still owned by Bob, until resolution (i.e a RAA\n>> removing the HTLC from Alice's commitment). This limitation only applies\n>> per-HTLC. No implementation enforces a limit on the sum of in-flight HTLCs\n>> burned as fees. Therefore, Alice is free to inflict a substantial loss to\n>> Bob funds by publishing her commitment on-chain.\n>>\n>> In-flight outgoing HTLC are also committed as fees on Bob's commitment if\n>> they're under Bob's threshold. Alice can also exploit from this angle by\n>> circular routing HTLCs until reaching Bob's\n>> `max_htlc_value_in_flight_msat`. Alice withholds HTLCs resolution until Bob\n>> goes on-chain to timeout an offered HTLC or claim an accepted HTLC.\n>>\n>> Dust HTLC processing can be also exploited at `update_fee` reception.\n>>\n>> As the BOLT3's fees computation encompasses the negotiated feerate from\n>> `update_fee` for the 2nd-stage HTLC fees to decide if the HTLC must be\n>> trimmed, the amount of balance at risk is a function of current mempool\n>> feerates.\n>>\n>> The maximum of funds at risk on a counterparty commitment is:\n>>\n>> counterparty's `max_accepted_htlcs` * (`htlc_success_tx_kw` * opener's\n>> `feerate_per_kw` + counterparty's `dust_limit_satoshis`) + holder's\n>> `max_accepted_htlcs` * (`htlc_timeout_tx_kw` * opener's `feerate_per_kw` +\n>> counterparty's `dust_limit_satoshis`)\n>>\n>> If the opener is also the attacker, the negotiated feerate can be\n>> manipulated beyond the \"honest\" mempool feerates only upper bounded\n>> implementation-defined value (before fixes, LDK: 2 * high-feerate of our\n>> fee-estimator). If the opener is the victim, the negotiated feerate is\n>> still a safety concern in case of spontaneous mempool spikes.\n>>\n>> Note, `anchors_zero_htlc_fee` channels are not affected by the feerate\n>> inflation as the trimmed-to-dust fee computation mechanism for 2nd-stage\n>> HTLC is removed. They're still at risk of the sum of the HTLCs under the\n>> dust limit being maliciously burned.\n>>\n>> # Solution\n>>\n>> A first mitigation is to verify the counterparty's announced\n>> `dust_limit_satoshis` at channel opening (`open_channel`/`accept_channel`)\n>> reception and reject if it's estimated too large (see #894)\n>>\n>> For LDK, we choose the value of 660 satoshis as it's beyond the highest\n>> dust threshold enforced by Bitcoin Core (p2pkh: 546) with a margin of\n>> safety. Propagation of Lightning time-sensitive transactions shouldn't be\n>> affected.\n>>\n>> A second mitigation is to define a new configurable limit\n>> `max_dust_htlc_exposure` and apply this one at incoming and outgoing of\n>> HTLC.\n>>\n>> For LDK, we choose the value of 5 000 000 milli-satoshis as we gauged\n>> this value as a substantial loss for our class of users. Setting this too\n>> low may prevent the sending or receipt of low-value HTLCs on high-traffic\n>> nodes. A node operator should fine-tune this value in function of what\n>> qualifies as an acceptable loss.\n>>\n>> We would like to ensure that the node isn't suddenly exposed to\n>> significantly more trimmed balance if the feerate increases when we have\n>> several HTLCs pending which are near the dust limit.\n>>\n>> To achieve this goal, we introduce a new `dust_buffer_feerate` defined as\n>> the maximum of either 2530 sats per kWU or 125% of the current\n>> `feerate_per_kw` (implementation-defined values).\n>>\n>> Then, upon an incoming HTLC, if the HTLC's `amount_msat` is inferior to\n>> the counterparty's `dust_limit_satoshis` plus the HTLC-timeout fee at the\n>> `dust_buffer_feerate`. If the `amount_msat` plus the\n>> `dust_balance_on_counterparty_tx` is superior to `max_dust_htlc_exposure`,\n>> the HTLC should be failed once it's committed.\n>>\n>> Upon an outgoing HTLC, if the HTLC's `amount_msat` is inferior to the\n>> counterparty's `dust_limit_satoshis`  plus the HTLC-success fee at the\n>> `dust_buffer_feerate`. If the `amount_msat` plus the\n>> `dust_balance_on_counterparty_tx` is superior to `max_dust_htlc_exposure`,\n>> the HTLC should not be sent and fail without forwarding.\n>>\n>> The check symmetry must also be applied on holder commitment\n>> transactions. See PR #919 for more details.\n>>\n>> A last mitigation is ensuring that at `update_fee` reception, the pending\n>> `dust_balance` at the new proposed feerate isn't superior to\n>> `max_dust_htlc_exposure_msat`.\n>>\n>> # Background\n>>\n>> The dust limit is a base layer policy stopping the relay of a transaction\n>> if one of its outputs is under a given threshold. The goal of this policy\n>> is to prevent the pollution of the UTXO set with low-value outputs and as\n>> such increase the amount of work done by full-nodes.\n>>\n>> Lightning commitment transactions should be able to propagate at any\n>> point during the channel lifetime to unilaterally enforce on-chain a\n>> balance. A Lightning commitment transaction with one of its outputs below\n>> the dust limit would fail to relay and thus jeopardizes funds safety.\n>>\n>> To prevent this, BOLT2 requires counterparties to announce a\n>> `dust_limit_satoshis` during channel opening (at\n>> `open_channel`/`accept_channel` exchange). This `dust_limit_satoshis` must\n>> be under the same party's `channel_reserve_satoshis`. This value is static\n>> for the channel lifetime.\n>>\n>> During commitment signatures exchange, each counterparty's limit is\n>> applied on each counterparty's commitment (e.g A's `dust_limit_satoshis` is\n>> applied on A's commitment, though both A and B have to generate and sign\n>> the transaction). An output below this limit is trimmed to fees and won't\n>> materialize on the commitment.\n>>\n>> The specification didn't require that the `open_channel`/`accept_channel`\n>> receiver verify that the announced `dust_limit_satoshis` isn't too large.\n>>\n>> The specification didn't require that the sum of the dust HTLC committed\n>> as fees was verified against an upper bound.\n>>\n>> # Discovery\n>>\n>> Vulnerabilities around our dust HTLC processing have been known for years\n>> by some LN developers/researchers.\n>>\n>> During Q1 2019, private discussions on the Rust-Lightning-side (LDK\n>> before marketing rebranding) about potential safety risks around dust HTLC\n>> processing.\n>>\n>> In November 2019, Rusty Russell (c-lightning) opened an issue against the\n>> specification mentioning the lack of check of counterparty's dust limit\n>> (#696).\n>>\n>> In May 2020, I published a high-level attack scenario \"Miners Dust\n>> Inflation attacks on Lightning Network\", leveraging this lack.\n>>\n>> In February 2021, I did a test of the first vulnerability against LND\n>> software and successfully burnt the majority of the targeted node balance\n>> in fees. As it sounds to me like a check missing in the specification, I\n>> notified CL/LND/Eclair/LDK maintainers. Mitigations started to be developed\n>> on the LDK-side.\n>>\n>> In July 2021, in the context of `option_dusty_htlcs_uncounted`\n>> discussions, Eugene Spiegel (LND) reported on how to exploit the\n>> trimmed-to-dust mechanism at `update_fee` reception. Discussions followed\n>> on the best way to mitigate this new vector.\n>>\n>> During August 2021, mitigations were developed and released on the\n>> LDK-side. vulnerabilities were disclosed to other Lightning projects (Muun\n>> wallet, Electrum). From the LDK-side, a public disclosure date was proposed.\n>>\n>> Still during August 2021, the Bitcoin Core dust limit was actively\n>> discussed on the mailing list. Changes of this dust limit would have\n>> affected the ongoing development of the mitigations.\n>>\n>> While this report highlights the lack of well-defined communication\n>> process across Lightning teams,  developers from 3 different\n>> implementations have actively participated in the vulnerabilities\n>> diagnostic and mitigations development of those long-standing specification\n>> issues affecting the whole Lightning ecosystem.\n>>\n>> All mistakes and opinions are my own and please verify any information\n>> reported.\n>>\n>> # Timeline\n>>\n>> * 2021-04-19: Working exploit of the vulnerability against LND,\n>> CL/LND/Eclair/LDK maintainers notified\n>> * 2021-07-21: Finding by Eugene Siegel on how to exploit the\n>> trimmed-to-dust mechanism at `update_fee` reception\n>> * 2021-08-11: BOLT PR #894 opened by Bastien Teinturier, covering the\n>> lack of verification of counterparty per-HTLC `dust_limit_satoshis`\n>> * 2021-08-16: Mitigations developed in LDK, communication of a public\n>> disclosure date\n>> * 2021-08-26: Notification to Muun wallet, non-affected\n>> * 2021-08-27: Notification to Electrum wallet\n>> * 2021-10-04: Full Disclosure of CVEs\n>> * 2021-10-04: Submit BOLT PR #919 covering the remaining vulnerabilities\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211004/7a56a20b/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2021-10-04T19:11:59",
                "message_text_only": "I've been informed by Mitre, the correct CVE assignment:\n* c-lightning : CVE-2021-41592\n* lnd: CVE-2021-41593\n\nNot the assignement disclosed in the initial mail.\n\nLe lun. 4 oct. 2021 \u00e0 11:09, Antoine Riard <antoine.riard at gmail.com> a\n\u00e9crit :\n\n> Hi,\n>\n> I'm writing a report to disclose specification-level vulnerabilities\n> affecting the Lightning implementations.\n>\n> The vulnerabilities are expected to be patched in:\n> * Eclair: v0.6.2+ (CVE-2021-41591)\n> * LND: v0.13.3+ (CVE-2021-41592)\n> * LDK: v0.0.102 (not released as production software yet)\n>\n> The vulnerabilities are also affecting c-lightning (CVE-2021-41593).\n>\n> Those vulnerabilities can be exploited in a wide range of attacks, going\n> from fee blackmailing of node operators, burning liquidity of your\n> competing LSPs or even stealing your counterparty channel balance if you\n> avail mining capabilities. Exercise of the vulnerability revealed that a\n> majority of the balance funds can be at loss.\n>\n> Credit to Eugene Siegel (Crypt-iQ) for reporting the trimmed-to-dust\n> exploitation and multiple insights about attacks.\n>\n> Thanks to Bastien Teinturier and Matt Corallo for numerous contributions\n> about mitigations development.\n>\n> # Problem\n>\n> The current BOLT specification only requires Alice's `dust_limit_satoshis`\n> (applied on Alice's commitment) to be under Alice's\n> `channel_reserve_satoshis` (applied on Bob). As those 2 parameters are\n> selectable by Alice, she can inflate the dust limit until reaching the\n> implementation-defined max value (e.g LND: 20% of chan capacity, LDK: 100%\n> of chan capacity).\n>\n> Any in-flight incoming HTLC under Alice's dust limit will be converted as\n> miner fees on Alice's commitment. This HTLC is deducted from Bob's balance\n> and as such they're still owned by Bob, until resolution (i.e a RAA\n> removing the HTLC from Alice's commitment). This limitation only applies\n> per-HTLC. No implementation enforces a limit on the sum of in-flight HTLCs\n> burned as fees. Therefore, Alice is free to inflict a substantial loss to\n> Bob funds by publishing her commitment on-chain.\n>\n> In-flight outgoing HTLC are also committed as fees on Bob's commitment if\n> they're under Bob's threshold. Alice can also exploit from this angle by\n> circular routing HTLCs until reaching Bob's\n> `max_htlc_value_in_flight_msat`. Alice withholds HTLCs resolution until Bob\n> goes on-chain to timeout an offered HTLC or claim an accepted HTLC.\n>\n> Dust HTLC processing can be also exploited at `update_fee` reception.\n>\n> As the BOLT3's fees computation encompasses the negotiated feerate from\n> `update_fee` for the 2nd-stage HTLC fees to decide if the HTLC must be\n> trimmed, the amount of balance at risk is a function of current mempool\n> feerates.\n>\n> The maximum of funds at risk on a counterparty commitment is:\n>\n> counterparty's `max_accepted_htlcs` * (`htlc_success_tx_kw` * opener's\n> `feerate_per_kw` + counterparty's `dust_limit_satoshis`) + holder's\n> `max_accepted_htlcs` * (`htlc_timeout_tx_kw` * opener's `feerate_per_kw` +\n> counterparty's `dust_limit_satoshis`)\n>\n> If the opener is also the attacker, the negotiated feerate can be\n> manipulated beyond the \"honest\" mempool feerates only upper bounded\n> implementation-defined value (before fixes, LDK: 2 * high-feerate of our\n> fee-estimator). If the opener is the victim, the negotiated feerate is\n> still a safety concern in case of spontaneous mempool spikes.\n>\n> Note, `anchors_zero_htlc_fee` channels are not affected by the feerate\n> inflation as the trimmed-to-dust fee computation mechanism for 2nd-stage\n> HTLC is removed. They're still at risk of the sum of the HTLCs under the\n> dust limit being maliciously burned.\n>\n> # Solution\n>\n> A first mitigation is to verify the counterparty's announced\n> `dust_limit_satoshis` at channel opening (`open_channel`/`accept_channel`)\n> reception and reject if it's estimated too large (see #894)\n>\n> For LDK, we choose the value of 660 satoshis as it's beyond the highest\n> dust threshold enforced by Bitcoin Core (p2pkh: 546) with a margin of\n> safety. Propagation of Lightning time-sensitive transactions shouldn't be\n> affected.\n>\n> A second mitigation is to define a new configurable limit\n> `max_dust_htlc_exposure` and apply this one at incoming and outgoing of\n> HTLC.\n>\n> For LDK, we choose the value of 5 000 000 milli-satoshis as we gauged this\n> value as a substantial loss for our class of users. Setting this too low\n> may prevent the sending or receipt of low-value HTLCs on high-traffic\n> nodes. A node operator should fine-tune this value in function of what\n> qualifies as an acceptable loss.\n>\n> We would like to ensure that the node isn't suddenly exposed to\n> significantly more trimmed balance if the feerate increases when we have\n> several HTLCs pending which are near the dust limit.\n>\n> To achieve this goal, we introduce a new `dust_buffer_feerate` defined as\n> the maximum of either 2530 sats per kWU or 125% of the current\n> `feerate_per_kw` (implementation-defined values).\n>\n> Then, upon an incoming HTLC, if the HTLC's `amount_msat` is inferior to\n> the counterparty's `dust_limit_satoshis` plus the HTLC-timeout fee at the\n> `dust_buffer_feerate`. If the `amount_msat` plus the\n> `dust_balance_on_counterparty_tx` is superior to `max_dust_htlc_exposure`,\n> the HTLC should be failed once it's committed.\n>\n> Upon an outgoing HTLC, if the HTLC's `amount_msat` is inferior to the\n> counterparty's `dust_limit_satoshis`  plus the HTLC-success fee at the\n> `dust_buffer_feerate`. If the `amount_msat` plus the\n> `dust_balance_on_counterparty_tx` is superior to `max_dust_htlc_exposure`,\n> the HTLC should not be sent and fail without forwarding.\n>\n> The check symmetry must also be applied on holder commitment transactions.\n> See PR #919 for more details.\n>\n> A last mitigation is ensuring that at `update_fee` reception, the pending\n> `dust_balance` at the new proposed feerate isn't superior to\n> `max_dust_htlc_exposure_msat`.\n>\n> # Background\n>\n> The dust limit is a base layer policy stopping the relay of a transaction\n> if one of its outputs is under a given threshold. The goal of this policy\n> is to prevent the pollution of the UTXO set with low-value outputs and as\n> such increase the amount of work done by full-nodes.\n>\n> Lightning commitment transactions should be able to propagate at any point\n> during the channel lifetime to unilaterally enforce on-chain a balance. A\n> Lightning commitment transaction with one of its outputs below the dust\n> limit would fail to relay and thus jeopardizes funds safety.\n>\n> To prevent this, BOLT2 requires counterparties to announce a\n> `dust_limit_satoshis` during channel opening (at\n> `open_channel`/`accept_channel` exchange). This `dust_limit_satoshis` must\n> be under the same party's `channel_reserve_satoshis`. This value is static\n> for the channel lifetime.\n>\n> During commitment signatures exchange, each counterparty's limit is\n> applied on each counterparty's commitment (e.g A's `dust_limit_satoshis` is\n> applied on A's commitment, though both A and B have to generate and sign\n> the transaction). An output below this limit is trimmed to fees and won't\n> materialize on the commitment.\n>\n> The specification didn't require that the `open_channel`/`accept_channel`\n> receiver verify that the announced `dust_limit_satoshis` isn't too large.\n>\n> The specification didn't require that the sum of the dust HTLC committed\n> as fees was verified against an upper bound.\n>\n> # Discovery\n>\n> Vulnerabilities around our dust HTLC processing have been known for years\n> by some LN developers/researchers.\n>\n> During Q1 2019, private discussions on the Rust-Lightning-side (LDK before\n> marketing rebranding) about potential safety risks around dust HTLC\n> processing.\n>\n> In November 2019, Rusty Russell (c-lightning) opened an issue against the\n> specification mentioning the lack of check of counterparty's dust limit\n> (#696).\n>\n> In May 2020, I published a high-level attack scenario \"Miners Dust\n> Inflation attacks on Lightning Network\", leveraging this lack.\n>\n> In February 2021, I did a test of the first vulnerability against LND\n> software and successfully burnt the majority of the targeted node balance\n> in fees. As it sounds to me like a check missing in the specification, I\n> notified CL/LND/Eclair/LDK maintainers. Mitigations started to be developed\n> on the LDK-side.\n>\n> In July 2021, in the context of `option_dusty_htlcs_uncounted`\n> discussions, Eugene Spiegel (LND) reported on how to exploit the\n> trimmed-to-dust mechanism at `update_fee` reception. Discussions followed\n> on the best way to mitigate this new vector.\n>\n> During August 2021, mitigations were developed and released on the\n> LDK-side. vulnerabilities were disclosed to other Lightning projects (Muun\n> wallet, Electrum). From the LDK-side, a public disclosure date was proposed.\n>\n> Still during August 2021, the Bitcoin Core dust limit was actively\n> discussed on the mailing list. Changes of this dust limit would have\n> affected the ongoing development of the mitigations.\n>\n> While this report highlights the lack of well-defined communication\n> process across Lightning teams,  developers from 3 different\n> implementations have actively participated in the vulnerabilities\n> diagnostic and mitigations development of those long-standing specification\n> issues affecting the whole Lightning ecosystem.\n>\n> All mistakes and opinions are my own and please verify any information\n> reported.\n>\n> # Timeline\n>\n> * 2021-04-19: Working exploit of the vulnerability against LND,\n> CL/LND/Eclair/LDK maintainers notified\n> * 2021-07-21: Finding by Eugene Siegel on how to exploit the\n> trimmed-to-dust mechanism at `update_fee` reception\n> * 2021-08-11: BOLT PR #894 opened by Bastien Teinturier, covering the lack\n> of verification of counterparty per-HTLC `dust_limit_satoshis`\n> * 2021-08-16: Mitigations developed in LDK, communication of a public\n> disclosure date\n> * 2021-08-26: Notification to Muun wallet, non-affected\n> * 2021-08-27: Notification to Electrum wallet\n> * 2021-10-04: Full Disclosure of CVEs\n> * 2021-10-04: Submit BOLT PR #919 covering the remaining vulnerabilities\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211004/30c51399/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Full Disclosure: CVE-2021-41591/ CVE-2021-41592 / CVE-2021-41593 \"Dust HTLC Exposure Considered Harmful\"",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "lisa neigut",
                "Luke Dashjr",
                "Antoine Riard"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 47054
        }
    },
    {
        "title": "[Lightning-dev] Fast Forwards By Channel-in-Channel Construction, Or: Spillman-Decker-Wattenhofer-Poon-Dryja-Towns",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2021-10-06T00:09:11",
                "message_text_only": "Introduction\n============\n\nIn some direct discussions with me, ajtowns recently came up with a fairly interesting perspective on implementing Fast Forwards, which I thought deserved its own writeup.\n\nThe idea by aj is basically having two CSV-variant Spillman unidirectional channels hosted by a Poon-Dryja construction, similar to the proposed Duplex channels by Decker-Wattenhofer.\nThe main insight from aj is: why do we need to chain transactions for Fast Forwards, when we can use a channel-like construction for it instead, using two unidirectional channels?\n\nReview: Spillman Channels and Variants\n======================================\n\nIf you are a Bitcoin OG feel free to skip this section; it is intended for newer devs who may have never heard of Spillman channel scheme (and its variants).\nOtherwise, or if you would like a refresher, feel free to read on.\n\nThe Spillman channel, and its variants, are all unidirectional: there is a fixed payer and a fixed payee.\nThe `nLockTime`-based variants also have a maximum lifetime.\n\n* To open:\n  * The payer creates, but does not sign or broadcast, an initial funding transaction, with a funding transaction output that is a simple 2-of-2 between payer and payee, but does *not* sign the transaction.\n  * The payer generates a backout transaction that has a future `nLockTime` agreed upon and signs it.\n  * The payee signs the backout transaction and gives the signature to the payer.\n  * The payer signs and broadcasts the funding transaction.\n  * Both payer and payee wait for deep confirmation of the funding transaction.\n* To pay:\n  * The payer generates a new version of the offchain transaction, giving more funds to the payee and less to the payer than the previous version.\n  * The offchain transactions have no `nLockTime`!\n  * The payer signs the transaction and hands it and its signature over to the payee.\n  * The payee keeps the transaction and the payer signature.\n* To close:\n  * At any time before the timeout, the payee can sign the last offchain transaction and broadcast it, closing the channel.\n  * The payee has every incentive to use the latest offchain transaction, since the channel is unidirectional the latest transaction is always going to give it more money than every earlier transaction.\n  * At the timeout, the payer can recover all of their funds using the backout transaction.\n\nSpillman channels as described are vulnerable to tx malleation, which is fixed in SegWit and later, but at this time we already have Poon-Dryja, which is better than Spillman in most respects.\n\n`CLTV` Spillman Variant\n-----------------------\n\nTo avoid tx malleation, instead of a presigned backout transaction, the 2-of-2 between payer and payee can instead be a SCRIPT with the logic:\n\n* Any of the following:\n  * Payer signature and Payee signature.\n  * Payer signature and CLTV of the timeout.\n\nThis is mostly a historical footnote, since tx signature malleation is no longer an issue if you use only SegWit, but it is helpful to remember the general form of the above SCRIPT logic.\n\n`nSequence` and `CSV` Spillman Variants\n---------------------------------------\n\nAn issue with classic Spillman is that it has a fixed absolute timeout.\nOnce the lifetime is reached, even if the payer still has capacity on their side, the channel still has to be closed before the absolute timeout.\n\nWith the new post-BIP68 semantics for `nSequence` (i.e. relative lock time), however, it is possible to use a relative locktime in order to lift the fixed channel lifetime.\nWith this, the channel can be kept open indefinitely, though it would still end up losing all utility once the payer has exhausted all capacity on their side.\nHowever, as long as the payer still has capacity, there is no need to close the channel just because of an absolute pre-agreed timeout.\n\nTo implement this variant using `nSequence`, we need to insert a \"kickoff\" transaction between the funding transaction output and the offchain transaction that splits the funds between the payer and payee:\n\n* To open:\n  * The payer creates, but does not sign or broadcast, a funding transaction with a funding transaction paying out to a plain 2-of-2 between payer and payee.\n  * The payer and payee create and sign, and exchange signatures for, a \"kickoff\" transaction.\n    This is a 1-input-1-output tx that spends the funding TXO and pays to another 2-of-2 between payer and payee.\n  * The kickoff transaction is completely signed at this point and both payer and payee have complete signatures.\n  * The payer creates a backout transaction that spends the kickof transaction output, with an agreed-upon `nSequence` time.\n  * The payee signs the backout transaction and hands the signature to the payer.\n  * The payer signs and broadcasts the funding transaction.\n* To pay:\n  * The payer creates a new version of the offchain transaction, which spends the kickoff transaction output (instead of the funding transaction output as in classic `nSequence` Spillman channels), giving more funds to the payee and less to itself than previous versions.\n  * The offchain transaction has no `nSequence`!\n  * The payer signs the transaction and hands it and its signature to the payee.\n  * The payee keeps the transaction and the payer signature.\n* To close:\n  * Either the payer or the payee broadcasts the kickoff transaction.\n    * The payee has to respond by signing the latest offchain transaction and broadcasting it.\n    * Similar to the `nLockTime` variant, the payee has every incentive to use the latest state, as that is the one with most money to it.\n    * If the payee does not respond, the payer uses the backout transaction to recover all their funds.\n\nSimilarly to the `nLockTime` variant, it is possible to instead use a `CSV` SCRIPT at the kickoff transaction output instead of a backout transaction, using the SCRIPT logic:\n\n* Any of the following:\n  * Payer signature and payee signature.\n  * Payer signature and `CSV` of the timeout.\n\nThe above `CSV` variant is less useful as it does not fix malleation issues: the kickoff transaction is still vulnerable to malleation!\nHowever, we *must* keep the above SCRIPT logic in mind in later discussion.\n\nReview: Decker-Wattenhofer Duplex Micropayment Channels\n=======================================================\n\nAgain, if you are a Bitcoin OG and can still remember this, skip.\nIf not, or you cannot remember details anymore, do read on.\n\nThe Decker-Wattenhofer paper proposes a *bidirectional* channel.\nIt is constructed by using a bidirectional channel mechanism with some major drawbacks, mitigating those drawbacks by using `CSV` Spilman variants.\n\nBasically:\n\n* It uses a bidirectional channel mechanism, which I call decrementing-`nSequence` (the paper has no particular label for the mechanism, just describes it).\n  * The bidirectional channel mechanism has a limited and *very small* number of updates.\n  * There is no absolute timeout, only a small limit on the number of updates.\n  * The relative locktimes are potentially very high.\n  * The window for being offline is small (very small compared to the worst-case relative locktime)!\n* The above bidirectional channel mechanism is chained multiple times.\n  * This ameliorates the *very small* number of updates:\n    * Earlier mechanisms are only updated once the later mechanism has run out of updates.\n    * Updating an earlier mechanism resets the number of updates allowed for every later mechanism.\n    * The effect is that the number of updates of each stage is multiplied together for the total number of updates of the chain of mechanisms.\n    * This raises the small number of updates, at the cost of increasing the worst-case relative locktime.\n* The final bidirectional channel mechanism in the chain hosts two `nSequence`/`CSV` Spillman variant channels.\n  * This is the \"Duplex\" part in the title.\n\nI will not be discussing the decrementing-`nSequence` mechanism in detail, you can see e.g. https://reddit.com/r/Bitcoin/comments/et841o/technical_more_channel_mechanisms/ for more.\n\nNow, since the bidirectional decrementing-`nSequence` mechanism uses `nSequence`, *obviously*, it too, like the `nSequence`/`CSV` variants of Spillman, requires a kickoff transaction.\nThe kickoff transaction is what starts the relative timeout.\nThus, each such mechanism has *two* transactions, a kickoff, and a \"state\" transaction.\n\n*However*, an important insight of Decker-Wattenhofer is:\n\n* The \"state\" transaction of the previous stage in the chain of mechanisms serves as the \"kickoff\" of the current stage of the chain.\n\nThus, even when chained together, we only need **one** actual kickoff transaction, the one at the start of the entire chain of constructions.\nEven at the duplex `nSequence`/`CSV` Spillman variants at the end of the cosntruction, the last decrementing-`nSequence` stage serves as the kickoff of both duplex Spillman variants.\n\nThus, a general principle is that:\n\n* The \"state\" of a previous stage in a chain of mechanisms can *also* serve as the \"kickoff\" of a kickoff-requiring later stage.\n\nPoon-Dryja And Fast Forwards\n============================\n\nNow, let us review Poon-Dryja, which *obviously* is not necessary since you are on lightning-dev and can compute shachains in your sleep.\n\nSo let me point out how the SCRIPT of a revocable output, owned by the local node, in Poon-Dryja looks like:\n\n* Any of the following:\n  * Local revocation-key signature and remote signature.\n    * The local is the one who holds the revocation key, until the transaction is revoked, at which point local hands over the revocation key to the remote.\n  * Local signature and `CSV` of the timeout.\n\n***OR***, before the state is revoked and only the local node knows the revocation key, in effect:\n\n* Any of the following:\n  * Local signature and remote signature.\n  * Local signature and `CSV` of the timeout.\n\nNow let us do `s/Local/Payer/` and `s/remote/payee/`:\n\n* Any of the following:\n  * Payer signature and payee signature.\n  * Payer signature and `CSV` of the timeout.\n\nAnd would you look at that, we got the script in the `CSV` Spillman variant!\n\nIn short, until a particular Poon-Dryja commitment transaction is revoked, the commitment transaction output can be used to host a `CSV` Spillman variant.\n\nAnd the Poon-Dryja commitment transaction can *also* serve as the kickoff of a Spillman `CSV` variant channel!\n\nTypically, a Poon-Dryja commitment transaction will have two \"main\" outputs, one for each counterparty.\nThis is the to-local and to-remote output.\nIn Fast Forwards I proposed that the to-remote output, which currently just requires \"remote signature\", should be modified to use:\n\n* Any of the following:\n  * Local revocation-key signature and remote signature.\n  * Remote signature and `CSV` timeout.\n\nThen, the to-remote output also has the same schema as a Spillman `CSV` variant, with `payer = remote`.\n\nThus, we *can* in fact use the Poon-Dryja commitment transaction as a kickoff transaction for duplex Spillman channels, like in Decker-Wattenhofer Duplex Micropayment Channels.\n\nWhy Poon-Dryja + `CSV`-Spillman?\n--------------------------------\n\nNow, Poon-Dryja is superior to all variants of Spillman, *except* in one aspect: latency.\n\nPoon-Dryja is bidirectional, unlike Spillman, and it requires only one transaction for unilateral closes (ignoring HTLCs, anyway).\nThis is unlike Spillman that is unidirectional, and whose `CSV` variant requires a kickoff followed by a state transaction in a unilateral close.\n\nHowever, Poon-Dryja requires exchanging signatures and revocation keys at each state update, which requires 1.5 roundtrips at minimum.\n\nSpillman in all variants requires only the payer to send a single signature, and that is sufficient: the payee does not need to send back *any* data.\nThus, Spillman updates require 0.5 roundtrips.\n\nFast Forwards as I originally proposed are also 0.5 roundtrips, however they involve creating a long chain of HTLC-hosting transactions.\naj suggested that this chain of transactions be shortened by the use of Spillman variant channels, thus improving onchain footprint in the case of unilateral closure.\n\nHTLC Failure\n============\n\nBut an important reason for needing Poon-Dryja bidirectionality is that HTLCs can fail.\n\nWhen we offer an HTLC to a counterparty, that is a unidiretional operation - the HTLC is not *yet* owned by the counterparty, but is \"more owned\" than just \"completely unowned\" --- until the timeout expires, the counterparty has the possibility of claiming the HTLC amount.\nAnd once the counterparty is able to claim the HTLC, it is now definitely owned by the counterparty.\nBoth operations are from us to the counterparty, and thus safely unidirectional.\n\nHowever, if the counterparty ultimately fails the HTLC before timeout, it needs to somehow refund the HTLC back to us.\nAnd this requires bidirectionality.\n\nSince there is a Duplex mechanism, there is the possibility to refund by using the *counterparty* end of the channel, sending back an HTLC of equal value to allow refunds.\n\nThis refund HTLC has to have a *higher* timeout than the HTLC that is being failed.\nThis is because if the HTLC being refunded is invalidly claimed by the counterparty using the hashlock branch after they failed it, we need time to claim the refund HTLC, so the refund HTLC has to have a higher timeout.\n\nAgainst the above, we should note:\n\n* The counterparty might not have sufficient capacity on *their* Spillman channels to refund, so we have to waste a Poon-Dryja update.\n* The counterparty cannot have keys offline, as it has to sign the Spillman channel update as the payer, thus removing the nice ability of Fast Forwards to be used for semi-offline receipts.\n  * Cancelling an HTLC at a keys-offline receiver may be necessary in case of multipart payments, where some parts reach the receiver but the payer is unable to find a payment solution for the rest of the amount and simply gives up; the receiver would want the HTLC capacity to be freed up as much as possible for other payment attempts.\n\nAn alternate idea by aj is to simply have *another* revocation key, this one for individual HTLCs.\nThis is *not* stored in a shachain, but instead stored with each historical HTLC (in much the same way that current historical HTLCs have to be kept until channel closure, since they contain non-derivable cryptographic data).\n\nSo for example, we are local and we offered an HTLC to the counterparty, the HTLC output looks like:\n\n* Any of the following:\n  * Local revocation-key signature and remote signature.\n  * Local signature and remote signature and `CLTV` of timeout (will be spent via HTLC-timeout transaction).\n  * Local signature and remote signature and preimage of hash (will be spent via a new HTLC-success-reversible transaction).\n\nThe HTLC-timeout transaction will have the same output as current HTLC-timeout, and the remote will provide a signature for it to the local.\nThe new HTLC-sucess-reversible is new here, and has the following output:\n\n* Any of the following:\n  * Remote HTLC-revocation-key signature and local signature.\n  * Remote signature and `CSV` of `to_self_delay`.\n\nFor the counterparty (remote) to fail the HTLC, it has to hand over the HTLC-revocation-key to us (local).\nThen if we need to drop the latest state onchain, we can wait for the HTLC to timeout and reclaim via the HTLC-timeout transaction.\nAnd if the remote tries to claim the HTLC erroneously after they failed the HTLC, they have given us the HTLC-revocaiton-key and we can claim the output immediately by ourselves without waiting.\n\nNow, suppose the remote wants to be able to bring privkeys offline.\nIt can generate the HTLC-revocation-key separately from the privkeys.\nIn fact, for every receive, it *must* generate a fresh HTLC-revocation-key, especially since the payer might later retry the same HTLC hash.\n\nOnce an incoming HTLC has been failed or claimed by the remote, it can throw away the HTLC-revocation-key --- it is us, the local, that has to remember it!\nIf an HTLC with the same hash and timeout is created again, the remote has to generate a fresh HTLC-revocation-key for it.\n\nOf course, since the remote has to provide us with pubkeys of the HTLC-revocation-key, that does imply more than 0.5 round trips, losing the Fast property.\nThis may be acceptable for privkey-offline receivers, but does imply that this protocol variation would be dispreferred at forwarding nodes, which want the Fast part of Fast Forwards, not its privkey-offline-receiver part.\nForwarding nodes would prefer the \"refund HTLC\" method instead, which allows for fast failures, and move the slow Poon-Dryja update to a less latency-sensitive periodic reset of the Spillman channels.\n\nNow since the privkey-offline receiver generates the HTLC-revocation-key by itself, we might worry that this allows the \"online\" part of the privkey-offline receiver to fail an HTLC aftr it has released the preimage to the counterparty.\nHowever, we should note that the \"online\" part of the receiver already knows the preimage, and can release it without being paid anyway; thus, this is not a degradation of security.\n\nWhy Spillmanize?\n----------------\n\nThe original Fast Forwards writeup uses a chain of transactions for each HTLC, relying on periodic Poon-Dryja updates to keep the number of transactions down.\nThis has bad implications for the number of transactions hitting onchain in case of unilateral close.\n\nBy terminating at Spillman channels instead, we reduce the number of transactions that have to hit onchain to a constant amount, instead of chaining multiple of them.\n\nIndeed, one can argue that if we see chains of transactions, like on typical onchain wallet behavior, we should always wonder if we can \"cut-through\" them using some kind of channel mechanism!\n\nConclusion\n==========\n\nBy this additional mechanism incorporating ideas from Spillman, Decker-Wattenhofer, Poon-Dryja Fast Forwards, and novel ideas from Towns, we can propose a new protocol for fast forwards that reduces the number of transactions that hit onchain in case of unilateral closes, relative to he original Fast Forwards proposal, while retaining its recently-discovered ability (from Fournier) to be useful for privkey-offline receivers."
            }
        ],
        "thread_summary": {
            "title": "Fast Forwards By Channel-in-Channel Construction, Or: Spillman-Decker-Wattenhofer-Poon-Dryja-Towns",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "ZmnSCPxj"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 18252
        }
    },
    {
        "title": "[Lightning-dev] Removing lnd's source code from the Lightning specs repository",
        "thread_messages": [
            {
                "author": "Fabrice Drouin",
                "date": "2021-10-08T15:24:24",
                "message_text_only": "Hello,\n\nWhen you navigate to https://github.com/lightningnetwork/ you find\n- the Lightning Network white paper\n- the Lightning Network specifications\n- and ... the source code for lnd!\n\nThis has been an anomaly for years, which has created some confusion\nbetween Lightning the open-source protocol and Lightning Labs, one of\nthe companies specifying and implementing this protocol, but we didn't\ndo anything about it.\n\nI believe that was a mistake: a few days ago, Arcane Research\npublished a fairly detailed report on the state of the Lightning\nNetwork: https://twitter.com/ArcaneResearch/status/1445442967582302213.\nThey obviously did some real work there, and seem to imply that their\nreport was vetted by Open Node and Lightning Labs.\n\nYet in the first version that they published you\u2019ll find this:\n\n\"Lightning Labs, founded in 2016, has developed the reference client\nfor the Lightning Network called Lightning Network Daemon (LND)....\nThey also maintain the network standards documents (BOLTs)\nrepository.\"\n\nThey changed it because we told them that it was wrong, but the fact\nthat in 2021 people who took time do do proper research, interviews,\n... can still misunderstand that badly how the Lightning developers\ncommunity works means that we ourselves badly underestimated how\nconfusing mixing the open-source specs for Lightning and the source\ncode for one of its implementations can be.\n\nTo be clear, I'm not blaming Arcane Research that much for thinking\nthat an implementation of an open-source protocol that is hosted with\nthe white paper and specs for that protocol is a \"reference\"\nimplementation, and thinking that since Lightning Labs maintains lnd\nthen they probably maintain the other stuff too. The problem is how\nthat information is published.\n\nSo I'm proposing that lnd's source code be removed from\nhttps://github.com/lightningnetwork/ (and moved to\nhttps://github.com/lightninglabs for example, with the rest of their\nLightning tools, but it's up to Lightning Labs).\n\nThanks,\n\nFabrice"
            },
            {
                "author": "Andr\u00e9s G. Aragoneses",
                "date": "2021-10-11T05:25:33",
                "message_text_only": "Completely agree with this. How to move this forward? Set up a vote? What\nwould be the reasoning for not moving it?\n\nOn Fri, 8 Oct 2021 at 23:25, Fabrice Drouin <fabrice.drouin at acinq.fr> wrote:\n\n> Hello,\n>\n> When you navigate to https://github.com/lightningnetwork/ you find\n> - the Lightning Network white paper\n> - the Lightning Network specifications\n> - and ... the source code for lnd!\n>\n> This has been an anomaly for years, which has created some confusion\n> between Lightning the open-source protocol and Lightning Labs, one of\n> the companies specifying and implementing this protocol, but we didn't\n> do anything about it.\n>\n> I believe that was a mistake: a few days ago, Arcane Research\n> published a fairly detailed report on the state of the Lightning\n> Network: https://twitter.com/ArcaneResearch/status/1445442967582302213.\n> They obviously did some real work there, and seem to imply that their\n> report was vetted by Open Node and Lightning Labs.\n>\n> Yet in the first version that they published you\u2019ll find this:\n>\n> \"Lightning Labs, founded in 2016, has developed the reference client\n> for the Lightning Network called Lightning Network Daemon (LND)....\n> They also maintain the network standards documents (BOLTs)\n> repository.\"\n>\n> They changed it because we told them that it was wrong, but the fact\n> that in 2021 people who took time do do proper research, interviews,\n> ... can still misunderstand that badly how the Lightning developers\n> community works means that we ourselves badly underestimated how\n> confusing mixing the open-source specs for Lightning and the source\n> code for one of its implementations can be.\n>\n> To be clear, I'm not blaming Arcane Research that much for thinking\n> that an implementation of an open-source protocol that is hosted with\n> the white paper and specs for that protocol is a \"reference\"\n> implementation, and thinking that since Lightning Labs maintains lnd\n> then they probably maintain the other stuff too. The problem is how\n> that information is published.\n>\n> So I'm proposing that lnd's source code be removed from\n> https://github.com/lightningnetwork/ (and moved to\n> https://github.com/lightninglabs for example, with the rest of their\n> Lightning tools, but it's up to Lightning Labs).\n>\n> Thanks,\n>\n> Fabrice\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211011/6d0c920c/attachment.html>"
            },
            {
                "author": "Bryan Bishop",
                "date": "2021-10-11T12:29:08",
                "message_text_only": "On Mon, Oct 11, 2021 at 12:25 AM Andr\u00e9s G. Aragoneses <knocte at gmail.com>\nwrote:\n\n> Completely agree with this. How to move this forward? Set up a vote? What\n> would be the reasoning for not moving it?\n>\n\nOne consideration is broken links, which can be solved by a soft note in a\nREADME somewhere.\n\n- Bryan\nhttps://twitter.com/kanzure\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211011/637bf2d4/attachment.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2021-10-11T18:58:28",
                "message_text_only": "On 10/11/21 05:29, Bryan Bishop wrote:\n> On Mon, Oct 11, 2021 at 12:25 AM Andr\u00e9s G. Aragoneses <knocte at gmail.com <mailto:knocte at gmail.com>> \n> wrote:\n> \n>     Completely agree with this. How to move this forward? Set up a vote? What would be the reasoning\n>     for not moving it?\n> \n> \n> One consideration is broken links, which can be solved by a soft note in a README somewhere.\n> \n> - Bryan\n> https://twitter.com/kanzure <https://twitter.com/kanzure>\n\nI believe the Github \"move repository\" feature makes all old links auto-redirects, so I'd hope this \nwouldn't happen. This information is at least a few years old, however.\n\nMatt"
            },
            {
                "author": "Martin Habov\u0161tiak",
                "date": "2021-10-11T23:13:50",
                "message_text_only": "I can confirm I moved a repository few months ago and all links kept\nworking fine.\n\nOn Mon, Oct 11, 2021, 20:58 Matt Corallo <lf-lists at mattcorallo.com> wrote:\n\n>\n>\n> On 10/11/21 05:29, Bryan Bishop wrote:\n> > On Mon, Oct 11, 2021 at 12:25 AM Andr\u00e9s G. Aragoneses <knocte at gmail.com\n> <mailto:knocte at gmail.com>>\n> > wrote:\n> >\n> >     Completely agree with this. How to move this forward? Set up a vote?\n> What would be the reasoning\n> >     for not moving it?\n> >\n> >\n> > One consideration is broken links, which can be solved by a soft note in\n> a README somewhere.\n> >\n> > - Bryan\n> > https://twitter.com/kanzure <https://twitter.com/kanzure>\n>\n> I believe the Github \"move repository\" feature makes all old links\n> auto-redirects, so I'd hope this\n> wouldn't happen. This information is at least a few years old, however.\n>\n> Matt\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211012/3182a097/attachment.html>"
            },
            {
                "author": "Fabrice Drouin",
                "date": "2021-10-12T07:23:47",
                "message_text_only": "On Tue, 12 Oct 2021 at 01:14, Martin Habov\u0161tiak\n<martin.habovstiak at gmail.com> wrote:\n>\n> I can confirm I moved a repository few months ago and all links kept working fine.\n>\n\nYes, github makes it really easy, and you keep your issues, PRs,\nstars, .. depending on your dev/packaging you may need to rename\npackages (something java/scala/... devs have to do from time to time)\nbut it's also very simple.\n\nThe issue here is not technical.\n\nFabrice"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2021-10-12T19:57:15",
                "message_text_only": "Hi Fabrice,\n\n> I believe that was a mistake: a few days ago, Arcane Research published a\n> fairly detailed report on the state of the Lightning Network:\n> https://twitter.com/ArcaneResearch/status/1445442967582302213.  They\n> obviously did some real work there, and seem to imply that their report\n> was vetted by Open Node and Lightning Labs.\n\nAppreciate the hard work from Arcane on putting together this report. That\nsaid, our role wasn't to review the entire report, but instead to provide\nfeedback on questions they had. Had we reviewed the section in question, we\nwould have spotted those errors and told the authors to fix them. Mistakes\nhappen, and we're glad it got corrected.\n\nAlso note that lnd has _never_ referred to itself as the \"reference\"\nimplementation.  A few years ago some other implementations adopted that\ntitle themselves, but have since adopted softer language.\n\n> So I'm proposing that lnd's source code be removed from\n> https://github.com/lightningnetwork/ (and moved to\n> https://github.com/lightninglabs for example, with the rest of their\n> Lightning tools, but it's up to Lightning Labs).\n\nI think it's worth briefly revisiting a bit of history here w.r.t the github\norg in question. In the beginning, the lightningnetwork github org was\ncreated by Joseph, and the lightningnetwork/paper repo was added, the\nmanuscript that kicked off this entire thing. Later lightningnetwork/lnd was\ncreated where we started to work on an initial implementation (before the\nBOLTs in their current form existed), and we were added as owners.\nEventually we (devs of current impls) all met up in Milan and decided to\nconverge on a single specification, thus we added the BOLTs to the same\nrepo, despite it being used for lnd and knowingly so.\n\nWe purposefully made a _new_ lightninglabs github org as we wanted to keep\nlnd, the implementation distinct from any of our future commercial\nproducts/services. To this day, we've architected all our paid products to\nbe built _on top_ of lnd, rather than within it. As a result, users always\nopt into these services.\n\nAs it seems the primary grievance here is collocating an implementation of\nLightning along with the _specification_ of the protocol, and given that the\nspec was added last, how about we move the spec to an independent repo owned\nby the community? I currently have github.com/lightning, and would be happy\nto donate it to the community, or we could create a new org like\n\"lightning-specs\" or something similar. We could then move the spec (the\nBOLTs and also potentially the bLIPs since some devs want it to be within\nits own repo) there, and have it be the home for any other\ncommunity-backed/owned projects.  I think the creation of a new github\norganization would also be a good opportunity to further formalize the set\nof stakeholders and the general process related to the evolution of\nLightning the protocol.\n\nThoughts?\n\n-- Laolu\n\nOn Fri, Oct 8, 2021 at 5:25 PM Fabrice Drouin <fabrice.drouin at acinq.fr>\nwrote:\n\n> Hello,\n>\n> When you navigate to https://github.com/lightningnetwork/ you find\n> - the Lightning Network white paper\n> - the Lightning Network specifications\n> - and ... the source code for lnd!\n>\n> This has been an anomaly for years, which has created some confusion\n> between Lightning the open-source protocol and Lightning Labs, one of\n> the companies specifying and implementing this protocol, but we didn't\n> do anything about it.\n>\n> I believe that was a mistake: a few days ago, Arcane Research\n> published a fairly detailed report on the state of the Lightning\n> Network: https://twitter.com/ArcaneResearch/status/1445442967582302213.\n> They obviously did some real work there, and seem to imply that their\n> report was vetted by Open Node and Lightning Labs.\n>\n> Yet in the first version that they published you\u2019ll find this:\n>\n> \"Lightning Labs, founded in 2016, has developed the reference client\n> for the Lightning Network called Lightning Network Daemon (LND)....\n> They also maintain the network standards documents (BOLTs)\n> repository.\"\n>\n> They changed it because we told them that it was wrong, but the fact\n> that in 2021 people who took time do do proper research, interviews,\n> ... can still misunderstand that badly how the Lightning developers\n> community works means that we ourselves badly underestimated how\n> confusing mixing the open-source specs for Lightning and the source\n> code for one of its implementations can be.\n>\n> To be clear, I'm not blaming Arcane Research that much for thinking\n> that an implementation of an open-source protocol that is hosted with\n> the white paper and specs for that protocol is a \"reference\"\n> implementation, and thinking that since Lightning Labs maintains lnd\n> then they probably maintain the other stuff too. The problem is how\n> that information is published.\n>\n> So I'm proposing that lnd's source code be removed from\n> https://github.com/lightningnetwork/ (and moved to\n> https://github.com/lightninglabs for example, with the rest of their\n> Lightning tools, but it's up to Lightning Labs).\n>\n> Thanks,\n>\n> Fabrice\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211012/53ceba64/attachment.html>"
            },
            {
                "author": "Damian Mee",
                "date": "2021-10-12T22:48:09",
                "message_text_only": "While I don't partake in the conversations too often, I just want to say I\nstrongly support Olaoluwa suggestion.  AFAIAA there's a lot of automations,\ndependencies, dockerfiles, or direct links to files that rely on the\nlocation of lnd github repo, and I'm sure not all of it would be able to\nhandle Github redirect gracefully.  While accessing spec is mostly a\nhuman/browser activity, where dealing with redirects is much easier.\n\nPlus, github.com/lightning/spec, github.com/lightning/bolts, and/or\ngithub.com/lightning/rfc would all be trivial to remember, and quick to\ntype.\n\nOn Tue, Oct 12, 2021 at 2:57 PM Olaoluwa Osuntokun <laolu32 at gmail.com>\nwrote:\n\n> Hi Fabrice,\n>\n> > I believe that was a mistake: a few days ago, Arcane Research published a\n> > fairly detailed report on the state of the Lightning Network:\n> > https://twitter.com/ArcaneResearch/status/1445442967582302213.  They\n> > obviously did some real work there, and seem to imply that their report\n> > was vetted by Open Node and Lightning Labs.\n>\n> Appreciate the hard work from Arcane on putting together this report. That\n> said, our role wasn't to review the entire report, but instead to provide\n> feedback on questions they had. Had we reviewed the section in question, we\n> would have spotted those errors and told the authors to fix them. Mistakes\n> happen, and we're glad it got corrected.\n>\n> Also note that lnd has _never_ referred to itself as the \"reference\"\n> implementation.  A few years ago some other implementations adopted that\n> title themselves, but have since adopted softer language.\n>\n> > So I'm proposing that lnd's source code be removed from\n> > https://github.com/lightningnetwork/ (and moved to\n> > https://github.com/lightninglabs for example, with the rest of their\n> > Lightning tools, but it's up to Lightning Labs).\n>\n> I think it's worth briefly revisiting a bit of history here w.r.t the\n> github\n> org in question. In the beginning, the lightningnetwork github org was\n> created by Joseph, and the lightningnetwork/paper repo was added, the\n> manuscript that kicked off this entire thing. Later lightningnetwork/lnd\n> was\n> created where we started to work on an initial implementation (before the\n> BOLTs in their current form existed), and we were added as owners.\n> Eventually we (devs of current impls) all met up in Milan and decided to\n> converge on a single specification, thus we added the BOLTs to the same\n> repo, despite it being used for lnd and knowingly so.\n>\n> We purposefully made a _new_ lightninglabs github org as we wanted to keep\n> lnd, the implementation distinct from any of our future commercial\n> products/services. To this day, we've architected all our paid products to\n> be built _on top_ of lnd, rather than within it. As a result, users always\n> opt into these services.\n>\n> As it seems the primary grievance here is collocating an implementation of\n> Lightning along with the _specification_ of the protocol, and given that\n> the\n> spec was added last, how about we move the spec to an independent repo\n> owned\n> by the community? I currently have github.com/lightning, and would be\n> happy\n> to donate it to the community, or we could create a new org like\n> \"lightning-specs\" or something similar. We could then move the spec (the\n> BOLTs and also potentially the bLIPs since some devs want it to be within\n> its own repo) there, and have it be the home for any other\n> community-backed/owned projects.  I think the creation of a new github\n> organization would also be a good opportunity to further formalize the set\n> of stakeholders and the general process related to the evolution of\n> Lightning the protocol.\n>\n> Thoughts?\n>\n> -- Laolu\n>\n> On Fri, Oct 8, 2021 at 5:25 PM Fabrice Drouin <fabrice.drouin at acinq.fr>\n> wrote:\n>\n>> Hello,\n>>\n>> When you navigate to https://github.com/lightningnetwork/ you find\n>> - the Lightning Network white paper\n>> - the Lightning Network specifications\n>> - and ... the source code for lnd!\n>>\n>> This has been an anomaly for years, which has created some confusion\n>> between Lightning the open-source protocol and Lightning Labs, one of\n>> the companies specifying and implementing this protocol, but we didn't\n>> do anything about it.\n>>\n>> I believe that was a mistake: a few days ago, Arcane Research\n>> published a fairly detailed report on the state of the Lightning\n>> Network: https://twitter.com/ArcaneResearch/status/1445442967582302213.\n>> They obviously did some real work there, and seem to imply that their\n>> report was vetted by Open Node and Lightning Labs.\n>>\n>> Yet in the first version that they published you\u2019ll find this:\n>>\n>> \"Lightning Labs, founded in 2016, has developed the reference client\n>> for the Lightning Network called Lightning Network Daemon (LND)....\n>> They also maintain the network standards documents (BOLTs)\n>> repository.\"\n>>\n>> They changed it because we told them that it was wrong, but the fact\n>> that in 2021 people who took time do do proper research, interviews,\n>> ... can still misunderstand that badly how the Lightning developers\n>> community works means that we ourselves badly underestimated how\n>> confusing mixing the open-source specs for Lightning and the source\n>> code for one of its implementations can be.\n>>\n>> To be clear, I'm not blaming Arcane Research that much for thinking\n>> that an implementation of an open-source protocol that is hosted with\n>> the white paper and specs for that protocol is a \"reference\"\n>> implementation, and thinking that since Lightning Labs maintains lnd\n>> then they probably maintain the other stuff too. The problem is how\n>> that information is published.\n>>\n>> So I'm proposing that lnd's source code be removed from\n>> https://github.com/lightningnetwork/ (and moved to\n>> https://github.com/lightninglabs for example, with the rest of their\n>> Lightning tools, but it's up to Lightning Labs).\n>>\n>> Thanks,\n>>\n>> Fabrice\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211012/ec257326/attachment-0001.html>"
            },
            {
                "author": "lisa neigut",
                "date": "2021-10-12T23:03:52",
                "message_text_only": "Love the idea of moving the specs etc to github.com/lightning, thanks so\nmuch for generously offering to donate this Laolu. Strong ACK from me.\n\nGiven how difficult the existing org is wrt ownership etc, moving to a new\none makes a lot of sense to me.\n\nThanks Fabrice for bringing this up so we could discuss it and get a better\nunderstanding of the difficulties with the existing situation.\n\n- nifty\n\nOn Wed, Oct 13, 2021 at 00:48 Damian Mee <btc at meedamian.com> wrote:\n\n> While I don't partake in the conversations too often, I just want to say I\n> strongly support Olaoluwa suggestion.  AFAIAA there's a lot of automations,\n> dependencies, dockerfiles, or direct links to files that rely on the\n> location of lnd github repo, and I'm sure not all of it would be able to\n> handle Github redirect gracefully.  While accessing spec is mostly a\n> human/browser activity, where dealing with redirects is much easier.\n>\n> Plus, github.com/lightning/spec, github.com/lightning/bolts, and/or\n> github.com/lightning/rfc would all be trivial to remember, and quick to\n> type.\n>\n> On Tue, Oct 12, 2021 at 2:57 PM Olaoluwa Osuntokun <laolu32 at gmail.com>\n> wrote:\n>\n>> Hi Fabrice,\n>>\n>> > I believe that was a mistake: a few days ago, Arcane Research published\n>> a\n>> > fairly detailed report on the state of the Lightning Network:\n>> > https://twitter.com/ArcaneResearch/status/1445442967582302213.  They\n>> > obviously did some real work there, and seem to imply that their report\n>> > was vetted by Open Node and Lightning Labs.\n>>\n>> Appreciate the hard work from Arcane on putting together this report. That\n>> said, our role wasn't to review the entire report, but instead to provide\n>> feedback on questions they had. Had we reviewed the section in question,\n>> we\n>> would have spotted those errors and told the authors to fix them. Mistakes\n>> happen, and we're glad it got corrected.\n>>\n>> Also note that lnd has _never_ referred to itself as the \"reference\"\n>> implementation.  A few years ago some other implementations adopted that\n>> title themselves, but have since adopted softer language.\n>>\n>> > So I'm proposing that lnd's source code be removed from\n>> > https://github.com/lightningnetwork/ (and moved to\n>> > https://github.com/lightninglabs for example, with the rest of their\n>> > Lightning tools, but it's up to Lightning Labs).\n>>\n>> I think it's worth briefly revisiting a bit of history here w.r.t the\n>> github\n>> org in question. In the beginning, the lightningnetwork github org was\n>> created by Joseph, and the lightningnetwork/paper repo was added, the\n>> manuscript that kicked off this entire thing. Later lightningnetwork/lnd\n>> was\n>> created where we started to work on an initial implementation (before the\n>> BOLTs in their current form existed), and we were added as owners.\n>> Eventually we (devs of current impls) all met up in Milan and decided to\n>> converge on a single specification, thus we added the BOLTs to the same\n>> repo, despite it being used for lnd and knowingly so.\n>>\n>> We purposefully made a _new_ lightninglabs github org as we wanted to keep\n>> lnd, the implementation distinct from any of our future commercial\n>> products/services. To this day, we've architected all our paid products to\n>> be built _on top_ of lnd, rather than within it. As a result, users always\n>> opt into these services.\n>>\n>> As it seems the primary grievance here is collocating an implementation of\n>> Lightning along with the _specification_ of the protocol, and given that\n>> the\n>> spec was added last, how about we move the spec to an independent repo\n>> owned\n>> by the community? I currently have github.com/lightning, and would be\n>> happy\n>> to donate it to the community, or we could create a new org like\n>> \"lightning-specs\" or something similar. We could then move the spec (the\n>> BOLTs and also potentially the bLIPs since some devs want it to be within\n>> its own repo) there, and have it be the home for any other\n>> community-backed/owned projects.  I think the creation of a new github\n>> organization would also be a good opportunity to further formalize the set\n>> of stakeholders and the general process related to the evolution of\n>> Lightning the protocol.\n>>\n>> Thoughts?\n>>\n>> -- Laolu\n>>\n>> On Fri, Oct 8, 2021 at 5:25 PM Fabrice Drouin <fabrice.drouin at acinq.fr>\n>> wrote:\n>>\n>>> Hello,\n>>>\n>>> When you navigate to https://github.com/lightningnetwork/ you find\n>>> - the Lightning Network white paper\n>>> - the Lightning Network specifications\n>>> - and ... the source code for lnd!\n>>>\n>>> This has been an anomaly for years, which has created some confusion\n>>> between Lightning the open-source protocol and Lightning Labs, one of\n>>> the companies specifying and implementing this protocol, but we didn't\n>>> do anything about it.\n>>>\n>>> I believe that was a mistake: a few days ago, Arcane Research\n>>> published a fairly detailed report on the state of the Lightning\n>>> Network: https://twitter.com/ArcaneResearch/status/1445442967582302213.\n>>> They obviously did some real work there, and seem to imply that their\n>>> report was vetted by Open Node and Lightning Labs.\n>>>\n>>> Yet in the first version that they published you\u2019ll find this:\n>>>\n>>> \"Lightning Labs, founded in 2016, has developed the reference client\n>>> for the Lightning Network called Lightning Network Daemon (LND)....\n>>> They also maintain the network standards documents (BOLTs)\n>>> repository.\"\n>>>\n>>> They changed it because we told them that it was wrong, but the fact\n>>> that in 2021 people who took time do do proper research, interviews,\n>>> ... can still misunderstand that badly how the Lightning developers\n>>> community works means that we ourselves badly underestimated how\n>>> confusing mixing the open-source specs for Lightning and the source\n>>> code for one of its implementations can be.\n>>>\n>>> To be clear, I'm not blaming Arcane Research that much for thinking\n>>> that an implementation of an open-source protocol that is hosted with\n>>> the white paper and specs for that protocol is a \"reference\"\n>>> implementation, and thinking that since Lightning Labs maintains lnd\n>>> then they probably maintain the other stuff too. The problem is how\n>>> that information is published.\n>>>\n>>> So I'm proposing that lnd's source code be removed from\n>>> https://github.com/lightningnetwork/ (and moved to\n>>> https://github.com/lightninglabs for example, with the rest of their\n>>> Lightning tools, but it's up to Lightning Labs).\n>>>\n>>> Thanks,\n>>>\n>>> Fabrice\n>>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211013/ceeabee8/attachment.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2021-10-13T01:59:08",
                "message_text_only": "On 10/12/21 12:57, Olaoluwa Osuntokun wrote:\n> Hi Fabrice,\n> \n>  > I believe that was a mistake: a few days ago, Arcane Research published a\n>  > fairly detailed report on the state of the Lightning Network:\n>  > https://twitter.com/ArcaneResearch/status/1445442967582302213 \n> <https://twitter.com/ArcaneResearch/status/1445442967582302213>.\u00a0 They\n>  > obviously did some real work there, and seem to imply that their report\n>  > was vetted by Open Node and Lightning Labs.\n> \n> Appreciate the hard work from Arcane on putting together this report. That\n> said, our role wasn't to review the entire report, but instead to provide\n> feedback on questions they had. Had we reviewed the section in question, we\n> would have spotted those errors and told the authors to fix them. Mistakes\n> happen, and we're glad it got corrected.\n> \n> Also note that lnd has _never_ referred to itself as the \"reference\"\n> implementation.\u00a0 A few years ago some other implementations adopted that\n> title themselves, but have since adopted softer language.\n> \n>  > So I'm proposing that lnd's source code be removed from\n>  > https://github.com/lightningnetwork/ <https://github.com/lightningnetwork/> (and moved to\n>  > https://github.com/lightninglabs <https://github.com/lightninglabs> for example, with the rest of \n> their\n>  > Lightning tools, but it's up to Lightning Labs).\n> \n> I think it's worth briefly revisiting a bit of history here w.r.t the github\n> org in question. In the beginning, the lightningnetwork github org was\n> created by Joseph, and the lightningnetwork/paper repo was added, the\n> manuscript that kicked off this entire thing. Later lightningnetwork/lnd was\n> created where we started to work on an initial implementation (before the\n> BOLTs in their current form existed), and we were added as owners.\n> Eventually we (devs of current impls) all met up in Milan and decided to\n> converge on a single specification, thus we added the BOLTs to the same\n> repo, despite it being used for lnd and knowingly so.\n> \n> We purposefully made a _new_ lightninglabs github org as we wanted to keep\n> lnd, the implementation distinct from any of our future commercial\n> products/services. To this day, we've architected all our paid products to\n> be built _on top_ of lnd, rather than within it. As a result, users always\n> opt into these services.\n> \n> As it seems the primary grievance here is collocating an implementation of\n> Lightning along with the _specification_ of the protocol, and given that the\n> spec was added last, how about we move the spec to an independent repo owned\n> by the community? I currently have github.com/lightning <http://github.com/lightning>, and would be \n> happy\n> to donate it to the community, or we could create a new org like\n> \"lightning-specs\" or something similar. We could then move the spec (the\n> BOLTs and also potentially the bLIPs since some devs want it to be within\n> its own repo) there, and have it be the home for any other\n> community-backed/owned projects.\u00a0 I think the creation of a new github\n> organization would also be a good opportunity to further formalize the set\n> of stakeholders and the general process related to the evolution of\n> Lightning the protocol.\n> \n> Thoughts?\n\nNo super strong opinion on where things end up, but roughly agree they should be separate. In other \nwords, this proposal sounds good to me, want to set it up?\n\nMatt\n\n_______________________________________________\nLightning-dev mailing list\nLightning-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Fabrice Drouin",
                "date": "2021-10-15T08:49:36",
                "message_text_only": "On Tue, 12 Oct 2021 at 21:57, Olaoluwa Osuntokun <laolu32 at gmail.com> wrote:\n> Also note that lnd has _never_ referred to itself as the \"reference\"\n> implementation.  A few years ago some other implementations adopted that\n> title themselves, but have since adopted softer language.\n\nI don't remember that but if you're referring to c-lightning it was\nthe first lightning implementation, and the only one for a while, so\nin a way it was a \"reference\" at the time ?\nOr it could have been a reference to their policy of \"implementing the\nspec, all the spec and nothing but the spec\"  ?\n\n> I think it's worth briefly revisiting a bit of history here w.r.t the github\n> org in question. In the beginning, the lightningnetwork github org was\n> created by Joseph, and the lightningnetwork/paper repo was added, the\n> manuscript that kicked off this entire thing. Later lightningnetwork/lnd was\n> created where we started to work on an initial implementation (before the\n> BOLTs in their current form existed), and we were added as owners.\n> Eventually we (devs of current impls) all met up in Milan and decided to\n> converge on a single specification, thus we added the BOLTs to the same\n> repo, despite it being used for lnd and knowingly so.\n\nYes, work on c-lightning then eclair then lnd all began a long time\nbefore the BOLTs process was implemented, and we all set up repos,\naccounts...\nI agree that we all inherited things  from the \"pre-BOLTS\" era and\nchanging them will create some friction but I still believe it should\nbe done. You also mentioned potential admin rights issues on the\ncurrent specs repos which would be solved by moving them to a new\nclean repo.\n\n> As it seems the primary grievance here is collocating an implementation of\n> Lightning along with the _specification_ of the protocol, and given that the\n> spec was added last, how about we move the spec to an independent repo owned\n> by the community? I currently have github.com/lightning, and would be happy\n> to donate it to the community, or we could create a new org like\n> \"lightning-specs\" or something similar.\n\nSounds great! github.com/lightning is nice (and I like Damian's idea\nof using github.com/lightning/bolts) and seems to please everyone so\nit looks that we have a plan!\n\nFabrice"
            }
        ],
        "thread_summary": {
            "title": "Removing lnd's source code from the Lightning specs repository",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Damian Mee",
                "Matt Corallo",
                "Fabrice Drouin",
                "Andr\u00e9s G. Aragoneses",
                "lisa neigut",
                "Olaoluwa Osuntokun",
                "Bryan Bishop",
                "Martin Habov\u0161tiak"
            ],
            "messages_count": 11,
            "total_messages_chars_count": 32624
        }
    },
    {
        "title": "[Lightning-dev] Lightning over taproot with PTLCs",
        "thread_messages": [
            {
                "author": "Anthony Towns",
                "date": "2021-10-09T01:12:07",
                "message_text_only": "Hi all,\n\nHere's my proposal for replacing BOLT#2 and BOLT#3 to take advantage of\ntaproot and implement PTLCs. \n\nIt's particularly inspired by ZmnSCPxj's thoughts from Dec 2019 [0], and\nsome of his and Lloyd Fournier's posts since then (which are listed in\nreferences) -- in particular, I think those allow us to drop the latency\nfor forwarding a payment *massively* (though refunding a payment still\nrequires roundtrips), and also support receiving via a mostly offline\nlightning wallet, which seems kinda cool.\n\nI somehow hadn't realised it prior to a conversation with @brian_trollz\nvia twitter DM, but I think switching to PTLCs, even without eltoo,\nmeans that there's no longer any need to permanently store old payment\ninfo in order to recover the entirety of the channel's funds. (Some brute\nforce is required to recover the timeout info, but in my testing I think\nthat's about 0.05 seconds of work per ptlc output via python+libsecp256k1)\n\nThis doesn't require any soft-forks, so I think we could start work on\nit immediately, and the above benefits actually seem pretty worth it,\neven ignoring any privacy/efficiency benefits from doing taproot key\npath spends and forwarding PTLCs.\n\nI've sketched up the musig/musig2 parts for the \"balance\" transactions\nin python [1] and tested it a little on signet [2], which I think is\nenough to convince me that this is implementable. There'll be a bit of\npreliminary work needed in actually defining specs/BIPs for musig and\nmusig2 and adaptor signatures, I think.\n\nAnyway, details follow. They're also up on github as a gist [3] if that\nfloats your boat.\n\n[0] https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-December/002375.html\n\n[1] https://github.com/ajtowns/bitcoin/blob/202109-ptlc-lnpenalty/test/functional/feature_ln_ptlc.py\n\n[2] The balance transaction (spending the funding tx and with outputs\n    being Alice's and Bob's channel balance is at):\n    https://explorer.bc-2.jp/tx/ba58d99dfaad83e105a0de1a9becfcf8eaf897aaaada54bd7b08134ff579997c?input:0&expand\n\n[3] https://gist.github.com/ajtowns/12f58fa8a4dc9f136ed04ca2584816a2/\n\nGoals\n=====\n\n1. Support HTLCs\n2. Support PTLCs\n3. Minimise long-term data storage requirements\n4. Minimise latency when forwarding payments\n5. Minimise latency when refunding payments\n6. Support offline receiving\n7. Minimise on-chain footprint\n8. Minimise ability for third-parties to analyse\n\nSetup\n=====\n\nWe have two participants in the channel, Alice and Bob. They each have\nbip32 private keys, a and b, and share the corresponding xpubs A and B\nwith each other.\n\nMusig\n-----\n\nWe will use musig to combine the keys, where P = musig(A,B) = H(A,B,1)*A\n+ H(A,B,2)*B. We'll talk about subkeys of P, eg P/4/5/6, which are\ncalculated by taking subkeys of the input and then applying musig,\neg P/4/5/6 = musig(A/4/5/6, B/4/5/6). (Note that we don't use hardened\npaths anywhere)\n\nMusig2\n------\n\nWe'll use musig2 to sign for these keys, that is both parties will\npre-share two nonce points each, NA1, NA2, NB1, NB2, and the nonce will be\ncalculated as: R=(NA1+NB1)+k(NA2+NB2), where k=Hash(P,NA1,NA2,NB1,NB2,m),\nwhere P is the pubkey that will be signing and m is the message to be\nsigned. Note that NA1, NA2, NB1, NB2 can be calculated and shared prior\nto knowing what message will be signed.\n\nThe partial sig by A for a message m with nonce R as above is calculated as:\n\n    sa = (na1+k*na2) + H(R,A+B,m)*a\n\nwhere na1, na2, and a are the secrets generating NA1, NA2 and A respectively.\nCalculating the corresponding partial signature for B,\n\n    sb = (nb1+k*nb2) + H(R,A+B,m)*b\n\ngives a valid signature (R,sa+sb) for (A+B):\n\n    (sa+sb)G = R + H(R,A+B,m)*(A+B)\n\nNote that BIP340 sepcifies x-only pubkeys, so A+B and R implicitly have\neven y, however since those values are caluclated via musig and musig2\nrespectively, this cannot be ensured in advance. Instead, if we find:\n\n    H(A,B,1)*A + H(A,B,2)*B\n\ndoes not have even y, we calculate:\n\n    P = (-H(A,B,1))*A + (-H(A,B,2))*B\n\ninstead, which will have even y. Similarly, if (NA1+NB1+k(NA2+NB2)) does\nnot have even y, when signing, we replace each partial nonce by its negation,\neg: sa = -(na1+k*na2) + H(R,A+B,m).\n\nAdaptor Sigs\n------------\n\nAn adaptor signature for P for secret X is calculated as:\n\n    s = r + H(R+X, P, m)*p\n\nwhich gives:\n\n    (s+x)G = (R+X) + H(R+X, P, m)*P\n\nso that (R+X,s+x) is a valid signature by P of m, and the preimage for\nX can be calculated as the difference between the published sig and the\nadaptor sig, x=(s+x)-(s).\n\nNote that if R+X does not have even Y, we will need to negate both R and X,\nand the recovered secret preimage will be -x instead of x.\n\nRevocable Secrets\n-----------------\n\nAlice and Bob have shachain secrets RA(n) and RB(n) respectively,\nand second level shachain secrets RA2(n,i) and RB2(n,i), with n and i\ncounting up from 0 to a maximum.\n\nSummary\n=======\n\nWe'll introduce four layers of transactions:\n\n 1. The funding transaction - used to establish the channel, provides\n    the utxo backing the channel while the channel is open.\n 2. The balance transaction - tracks the funding transaction, contains\n    a \"balance\" output for each of the participants.\n 3. The inflight transactions - spends a balance output from the balance\n    transaction and provides outputs for any inflight htlc/ptlc transactions.\n 4. Layered transactions - spends inflight htlc/ptlc outputs by revealing\n    the preimage, while still allowing for the penalty path.\n\nFunding transaction\n===================\n\nThe funding transaction simply pays to P/0/f via taproot, where f starts\nat 0 and increases any time the funding transaction is updated onchain\n(eg when splicing funds in or out).\n\nBalance transaction\n===================\n\nThe balance transaction spends the funding transaction, and has two\noutputs, one for Alice's balance and one for Bob's balance (omitting a\nzero/dust balance).\n\nWe count the number of balance updates, starting at 0, and call it \"n\".\n\"n\" is encoded in the transaction locktime and the input nsequence, so\nif a balance transaction appears on chain, \"n\" can be decoded from the\nnsequence and locktime.\n\nAlice's balance is paid to an address with internal pubkey P/1/n/0\nand a script path of \"<A/1/n> CHECKSIGVERIFY <D> CSV\" where D is\nAlice's to_self_delay. Bob's balance is similar, with internal pubkey\nP/1/n/1.\n\nIn order to update to a new balance transaction, the process is as follows.\nFirst, nonces are exchanged in advance:\n\n  Alice:\n    Generates a nonce pair NA1, NA2 derived from RA(n). Shares this with\n    Bob.\n  Bob:\n    Generates a nonce pair NB1, NB2 derived from RB(n). Shares this with\n    Alice.\n\nThen, presuming Alice initiates the update:\n\n  Alice:\n    Generates deterministic nonce pair, DA1, DA2. Combines this with\n    Bob's NB1, NB2 nonce pair.  Generates partial signature for nonce\n    (DA, NB) for the transaction. Sends DA1 and DA2 and the partial\n    signature to Bob.\n\n  Bob:\n    Checks the partial signature is valid. Updates to the new balance\n    transaction. Generates a nonce pair, DB1, DB2, and gnerates a partial\n    signature for the balance transaction for nonce (NA, DB). Sends DB1,\n    DB2, and the partial signature to Alice. Generates a new revocable\n    secret RB(n+1). Revokes the previous secret RB(n) and sends the\n    details of both to Alice.\n\n  Alice:\n    Checks the partial signature is valid. Updates to the new balance\n    transaction. Checks the secret revocation info is correct and stores\n    it. Generates a new revocable secret RA(n+1). Revokes the previous\n    secret RA(n) and sends the details of both to Bob.\n\n  Bob:\n    Checks the secret revocation info is correct an stores it.\n\nThis means that both Alice and Bob have the same balance transaction here\n(with the same txid) but have different signatures for it (and thus\ndiffering wtxids).\n\nBecause updating the balance transaction involves two round trips\nbefore Bob can be sure Alice cannot use the old state, we move all the\ntransaction information to the inflight transactions, which we will be\nable to update immediately, without requiring a round trip at all.\n\nNote that if Bob publishes the signature for an old state, then the\nsignature is:\n\n   s = ((DA1+NB1) + k(DA2+NB2)) + H(R,A+B,m)(a+b)\n\nbut Alice can calculate the secrets for both DA1 and DA2 (she generated\nthose deterministically herself in the first place), and NB1 and NB2 (she\nhas the secret revocation information, and verified that it correctly\ngenerated the nonces Bob was using), which allows her to calculate Bob's\nprivate key using modular arithmetic:\n\n   b = H(R,P,m) / (s - (DA1+NB1) - b(DA2+NB2)) - a\n\nwhich means she can then directly sign without Bob's assistance, allowing\nher to claim any funds.\n\nInflight and Layered Transactions\n=================================\n\nWe construct two inflight transactions on top of the current balance\ntransaction, one spending Alice's balance, and one spending Bob's balance.\n\nWe will use \"i\" to represent the number of times a given inflight\ntransaction has been updated for the nth update to the balance\ntransaction.\n\nAt any time Alice can update the inflight transaction spending her balance\nto transfer funds towards Bob, either by updating the balances directly,\nor adding a htlc/ptlc entry to conditionally transfer funds to Bob. (And\nconversely for Bob)\n\nWe will define RP=musig(A/2/n/i, RB2(n,i)).\n\nThe inflight transaction spending Alice's balance can have multiple\ntypes of outputs:\n\n * Alice's remaining balance: pays directly to A/2/n/i\n\n * Bob's remaining balances: pays to RP/2 with script path\n   \"<B/2/n/i> CHECKSIGVERIFY <D> CSV\"\n\n * An htlc paying to Bob: pays to RP/2/k with script paths:\n   + \"LENGTH 32 EQUALVERIFY HASH160 <X> EQUALVERIFY <B/2/n/i/k> CHECKSIGVERIFY <A/2/n/i/k> CHECKSIG\"\n   + \"<A/2/n/i/k/1> CHECKSIGVERIFY <T> CLTV\"\n\n * A ptlc paying to Bob: pays to RP/2/k with script paths:\n   + \"<B/2/n/i/k> CHECKSIG NOTIF <T> CLTV DROP ENDIF <A/2/n/i/k> CHECKSIG\"\n\nAny outputs that would be zero or dust are not included.\n\nNote that we number each currently inflight transaction by \"k\",\nstarting at 0. The same htlc/ptlc may have a different value for k\nbetween different inflight transactions.\n\nThe inflight transation's locktime is set to the current block\nheight. This enables brute force searching for the locktime of any\ninflight ptlcs (so that in a penalty scenario when the other party posts\nan out of date inflight transaction, you can search through a small\nnumber of possible timeout values simply by not sending any ptlcs with\na timeout more that L blocks in the future).\n\nThe balance input's nsequence is used to encode the value of the lower\n24 bits of i in the same way the balance transaction's fund input's\nnsequence encodes the upper 24 bits of n.\n\nThe layered transaction will spend the htlc/ptlc outputs, with an\nANYONECANPAY|SINGLE signature by Alice using the A/2/n/i/k path.\nThe output committed to is:\n\n * pays to RP/3/k with script path:\n   + <B/3/n/i/k> CHECKSIGVERIFY <D> CSV\n\nwith no absolute or relative locktime.\n\nTo update the inflight transaction spending Alice's balance as well as\nany dependent layered transactions, the process is as follows:\n\n  Bob:\n    Generates a second level revocable secret, RB2(n,i) and sends Alice\n    the corresponding point, PB2. Calculates a nonce pair, NB1, NB2, and\n    sends that to Alice. This is done in advance.\n\n  Alice:\n    Calculates the new inflight transaction. Calculates new nonces NA1,\n    NA2, and partially signs the spend of her balance via the key path,\n    with musig2 nonces NA1, NB1, NA2, NB2. For each inflight htlc,\n    Alice provides a signature via A/2/n/i/k. For each inflight ptlc,\n    Alice provides an adaptor signature via the A/2/n/i/k/0 path that\n    is conditional on the ptlc's point.\n\n  Bob:\n    Bob verifies the new proposed inflight state and each of the\n    signatures. Bob may now rely on the new state. Bob revokes their\n    prior secret, RB2(n, i-1), and sends a new point/nonce pair (PB2',\n    NB1', NB2') to Alice to prepare for the next round.\n\nNote that Bob could stream multiple point/nonce pairs in advance,\nallowing Alice to do multiple inflight tx updates within the time taken\nfor a roundtrip.\n\nAlice can unilaterally do the following safely:\n\n 1. transfer from Alice's balance to Bob's balance\n 2. accept that a htlc/ptlc succeeded, removing the corresponding output\n    and allocating the funds associated with it directly to Bob's balance\n 3. introduce a htlc/ptlc, spending funds from Alice's balance\n\nHowever refunding/cancelling a htlc/ptlc requires a two-phase commit\nwith 1.5 round trips:\n\n - Bob proposes refunding a htlc/ptlc\n - Alice agrees and sends a partial signature for the new transaction\n   with the htlc/ptlc funds transferred back to her balance,\n - Bob records the new transaction, and revokes the earlier second\n   level secret RB2(n, i-1).\n - Alice verifies the revocation, and can safely treat the funds as\n   refunded (and thus refund back to the original payer, eg).\n\nThe advantage of doing this over negotiating a new balance transaction\nis that only the second level revocation secrets need to be online,\nallowing for operation by semi-offline lightning nodes (ie, having the\nchannel private key and first level revocation secrets offline). Such\nsemi-offline nodes risk losing funds in the \"inflight\" transaction\n(either by revealing the second level revocation secrets or by simply\ndata loss of the current inflight/layered transactions) but do not risk\nlosing or spending funds in their own output of the balance transaction.\n\nThis means the funds locked in Alice's balance can be spent in the\nfollowing ways:\n\n * Alice can claim them directly if Bob does not post the inflight\n   transaction before the delay expires, via the script balance output's\n   script path. Alice gets the entire balance in this case.\n\n * Bob can post a revoked inflight transaction, for which Alice knows the\n   secret for RB(n,i). In this case Alice recovers the value of i from\n   the nsequence (using brute force for the upper bits if she has\n   provided more than 16M updates of the inflight tx for any given\n   balance transaction), and then calculates the secret key for PB,\n   and hence PB/2/k and PB/3/k, at which point she can claim every\n   output via a key path spend, even if Bob posts some or all of the\n   layered transactions. Alice gets the entire balance in this case\n   (though spends more on fees).\n\n * Bob can post a current inflight transaction, along with layered\n   transactions for any of the inflight htlc/ptlcs for which he knows the\n   corresponding preimage, allowing Alice to recover the preimages from\n   the on-chain spends immediately. Alice can claim her balance output and\n   any timed out funds immediately as well. Bob can finish claiming his\n   balance and any claimed htlc/ptlc funds after the delay has finished.\n\nNote that Bob never shares his signature to spend Alice's balance prior\nto posting the inflight transaction, so Alice can never post an inflight\ntransaction that spends her own balance.\n\nThe cases where Alice may have difficulty claiming funds is Bob posts\na revoked inflight transaction (possibly spending a revoked balance\ntransaction) are:\n\n * if the inflight transaction contains a htlc output, then if Alice\n   has not retained the old htlc details (the hash160 and the timeout)\n   she will not be able to reconstruct the script path, and thus will\n   not be able to calculate the TapTweak to sign for the key path.\n   However if Bob attempts to claim the output (via the pre-signed\n   layered transaction), that will reveal the information she was missing,\n   and she can immediately claim the funds via the layered transaction\n   output, prior to Bob being able to spend that output.\n\n * if the inflight transaction contains a ptlc output, then if Alice\n   has not retained the old ptlc details (the point and the timeout)\n   she will not trivially be able to reconstruct the script path,\n   which includes the timeout. However, presuming the timeout was\n   within 5000 blocks, then the only possible timeouts are the inflight\n   tx's nlocktime+i with 0<i<=5000, and she will only need to calculate\n   5000*k cases and match the corresponding scriptPubKeys to exhaustively\n   enumerate every possible ptlc output, which should take under a minute,\n   and be easily achievable. In addition, if Bob attempts to claim the\n   funds, he will reveal the script path, and Alice will be either able\n   to claim the inflight output directly or the layered output.\n\nMisc\n====\n\nIn order to transition from BOLT#3 format to this proposal, an onchain\ntransaction is required, as the \"revocable signatures\" arrangement cannot\nbe mimicked via the existing 2-of-2 CHECKMULTISIG output.\n\nTo allow splicing in/out, it may be important to maintain multiple\nconcurrent funding transactions (paying to P/0/f and P/0/f+1 eg),\nwhich then requires maintaining multiple current balance transactions\n(paying to P/1/n/* and P/1/n+1/x eg) and likewise multiple current\ninflight/layered transactions. This will require ensuring the states\nfor all those transactions are synchoronised when verifying upates,\nand requires sharing multiple nonces for signing (eg RA(n) and RA(n+1)\nand RB2(n,i), and RB2(n+1,i)).\n\nFees for the balance and inflight transactions must be considered upfront,\nand paid for from the channel balance (or perhaps via additional anchor\noutputs that allocate more than the dust threshold and are immediately\nspendable). Fees for the layered transactions however can (and must)\nbe provided by whoever is attempting to claim the funds.\n\nBob having a current inflight transaction spending Alice's balance is\nadvantageous to Alice as Bob posting the inflight transaction allows\nher to immediately claim her balance, rather than having to wait for\nthe delay to complete.\n\nIf two nodes agree to only forward ptlcs in future, then updating the\nfunding transaction (to P/0/f+1 eg) and ignoring any proposed inflight\ntransactions that include htlc outputs is enough to ensure that all htlc\nrecords can be forgotten without risking any part of the channel balance\nbeing unclaimable.\n\nThis does not support option_static_remotekey, but compensates for that\nby allowing balances to be recovered with only the channel setup data\neven if all revocation data is lost.\n\n\nReferences\n==========\n\nHopefully the above includes enough explanation to be understood on its own,\nbut here's references for a bunch of the concepts.\n\n * musig: https://blockstream.com/2018/01/23/en-musig-key-aggregation-schnorr-signatures/\n\n * musig2: https://medium.com/blockstream/musig2-simple-two-round-schnorr-multisignatures-bf9582e99295\n\n * adaptor sigs: https://github.com/ElementsProject/scriptless-scripts/blob/master/md/atomic-swap.md\n\n * fast forwards [ZmnSCPxj]\n    https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-April/001986.html\n    https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-May/003043.html\n    https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-October/003265.html\n\n * revocable signatures [LLFourn]\n    https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-August/002785.html"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-10-09T01:49:38",
                "message_text_only": "Good morning aj,\n\n>     In order to transition from BOLT#3 format to this proposal, an onchain\n>     transaction is required, as the \"revocable signatures\" arrangement cannot\n>     be mimicked via the existing 2-of-2 CHECKMULTISIG output.\n\nA transaction is required, but I believe it is not necessary to put it *onchain* (at the cost of implementation complexity in the drop-onchain case).\n\nAn existing channel can \"simply\" sign a transitioning transaction from the current BOLT3 to your new scheme, and then invalidate the last valid commitment transactions (i.e. exchange revocation secrets) in the BOLT3 scheme.\nThe transitioning transaction can simply be kept offchain and its output used as the funding outpoint of all \"internal\" (to the two counterparties directly in the channel) states.\n\nThis general idea would work for all transitions *from* Poon-Dryja, I believe.\nIt may be possible with Decker-Russell-Osuntokun I think (give the transitioning transaction the next sequence `nLockTime` number), but the `SIGHASH_NOINPUT`ness and (maybe?) the `CSV` infects the mechanism being transitioned to, so this technique may be too complicated for transitioning *from* Decker-Russell-Osuntokun to some hypothetical future offchain updatable cryptocurrency system that does not need (or want) `SIGHASH_NOINPUT`.\n\nThis has the advantage of maintaining the historical longevity of the channel.\nMany pathfinding and autopilot heuristics use channel lifetime as a positive indicator of desirability, thus an *onchain* transitioning transaction is undesirable as that marks a closure of the previous channel.\nAnd the exact scheme of channels between forwarding nodes are not particularly the business of anyone else anyway.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Anthony Towns",
                "date": "2021-10-09T02:15:19",
                "message_text_only": "On Sat, Oct 09, 2021 at 01:49:38AM +0000, ZmnSCPxj wrote:\n> A transaction is required, but I believe it is not necessary to put it *onchain* (at the cost of implementation complexity in the drop-onchain case).\n\nThe trick with that is that if you don't put it on chain, you need\nto calculate the fees for it in advance so that they'll be sufficient\nwhen you do want to put it on chain, *and* you can't update it without\ngoing onchain, because there's no way to revoke old off-chain funding\ntransactions.\n\n> This has the advantage of maintaining the historical longevity of the channel.\n> Many pathfinding and autopilot heuristics use channel lifetime as a positive indicator of desirability,\n\nMaybe that's a good reason for routing nodes to do shadow channels as\na matter of course -- call the currently established channel between\nAlice and Bob \"C1\", and leave it as bolt#3 based, but establish a new\ntaproot based channel C2 also between Alice and Bob. Don't advertise C2\n(making it a shadow channel), just say that C1 now supports PTLCs, but\nsecretly commit to those PTLCs to C2 instead C1. Once the C2 funding tx\nis buried enough, start advertising C2 instead taking advantage of its\nnow sufficiently buried funding transaction, and convert C1 to a shadow\nchannel instead.\n\nIn particular, that setup allows you to splice funds into or out of the\nshadow channel while retaining the positive longevity heuristics of the\npublic channel.\n\nCheers,\naj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-10-09T02:27:37",
                "message_text_only": "Good morning aj,\n\n> On Sat, Oct 09, 2021 at 01:49:38AM +0000, ZmnSCPxj wrote:\n>\n> > A transaction is required, but I believe it is not necessary to put it onchain (at the cost of implementation complexity in the drop-onchain case).\n>\n> The trick with that is that if you don't put it on chain, you need\n> to calculate the fees for it in advance so that they'll be sufficient\n> when you do want to put it on chain, and you can't update it without\n> going onchain, because there's no way to revoke old off-chain funding\n> transactions.\n\nYes, onchain fees, right?\n\n*Assuming* CPFP is acceptable, then fees for the commitment tx on the new scheme (or whatever equivalent in the transitioned-to mechanism is) would pay for the transitioning transaction, so fees paying for the transitioning transaction can still be adjusted at the transitioned-to updatable mechanism.\nThis probably assumes that the transaction package relay problem is fixed at the base layer though.\n\n>\n> > This has the advantage of maintaining the historical longevity of the channel.\n> > Many pathfinding and autopilot heuristics use channel lifetime as a positive indicator of desirability,\n>\n> Maybe that's a good reason for routing nodes to do shadow channels as\n> a matter of course -- call the currently established channel between\n> Alice and Bob \"C1\", and leave it as bolt#3 based, but establish a new\n> taproot based channel C2 also between Alice and Bob. Don't advertise C2\n> (making it a shadow channel), just say that C1 now supports PTLCs, but\n> secretly commit to those PTLCs to C2 instead C1. Once the C2 funding tx\n> is buried enough, start advertising C2 instead taking advantage of its\n> now sufficiently buried funding transaction, and convert C1 to a shadow\n> channel instead.\n>\n> In particular, that setup allows you to splice funds into or out of the\n> shadow channel while retaining the positive longevity heuristics of the\n> public channel.\n\nRequires two UTXOs, though, I think?\n\nHow about just adding a gossip message \"this new short-channel-id is the same as this old short-channel-id, use the new-short-channel-id to validate it but treat the age as that of the old short-channel-id\"?\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Jonas Nick",
                "date": "2021-10-09T12:21:03",
                "message_text_only": "Hi,\n\nit seems like parts of this proposal rely on deterministic nonces in MuSig.\nGenerally, this is insecure unless combined with heavy machinery that proves\ncorrectness of the nonce derivation in zero knowledge. If one signer uses\ndeterministic nonces and another signer uses random nonces, then two signing\nsessions will have different challenge hashes which results in nonce reuse by\nthe first signer [0]. Is there a countermeasure against this attack in the\nproposal? What are the inputs to the function that derive DA1, DA2? Is the\nassumption that a signer will not sign the same message more than once?\n\nIt may be worth pointing out that an adaptor signature scheme can not treat\nMuSig2 as a black box as indicated in the \"Adaptor Signatures\" section [1]. In\nparticular, generally the secret X must be input to the hash function that\ngenerates nonce coefficient k. Otherwise, an attacker can grind through\nchallenge hashes by varying X without affecting the aggregate nonce and produce\na forgery. For the same reason, the message m is included in hash function\ninputs of k. However, taking X into account when computing k shouldn't be an\nissue for protocols making use of adaptor signatures because k does not need to\nbe determined before signing time and X is required to be known at that point\nanyway.\n\n[0] https://medium.com/blockstream/musig-dn-schnorr-multisignatures-with-verifiably-deterministic-nonces-27424b5df9d6\n     See \"The attack works as follows.\"\n[1] MuSig2 adaptor signature issue: https://github.com/ElementsProject/scriptless-scripts/issues/23,\n     PR: https://github.com/ElementsProject/scriptless-scripts/pull/24"
            },
            {
                "author": "Anthony Towns",
                "date": "2021-10-09T13:59:39",
                "message_text_only": "On Sat, Oct 09, 2021 at 12:21:03PM +0000, Jonas Nick wrote:\n> it seems like parts of this proposal rely on deterministic nonces in MuSig.\n\nThe \"deterministic\" nonces are combined with \"recoverable\" nonces via\nmusig2, so I think that part is a red-herring?\n\nThey're \"deterministic\" in the sense that the person who generated the\nnonce needs to be able to recover the secret/dlog for the nonce later,\nwithout having to store unique randomness for it. Thinking about it,\nI think you could make the \"deterministic\" nonce secrets be\n\n   H( private-key, msg, other-party's-nonce-pair, 1 )\n   H( private-key, msg, other-party's-nonce-pair, 2 )\n\nbecause you only need to recover the secret if the other party posts a\nsig for a revoked transaction, in which case you can lookup their nonce\ndirectly anyway. And you're choosing your \"deterministic\" nonce after\nknowing what their (\"revocable\") nonce is, so can include it in the hash.\n\nAs far as the revocable nonce goes, you should only be generating a\nsingle signature based on that, since that's used to finish things off\nand post the tx on chain.\n\n> Generally, this is insecure unless combined with heavy machinery that proves\n> correctness of the nonce derivation in zero knowledge. If one signer uses\n> deterministic nonces and another signer uses random nonces, then two signing\n> sessions will have different challenge hashes which results in nonce reuse by\n> the first signer [0]. Is there a countermeasure against this attack in the\n> proposal? What are the inputs to the function that derive DA1, DA2? Is the\n> assumption that a signer will not sign the same message more than once?\n\nI had been thinking DA1,DA2 = f(seed,n) where n increases each round, but I\nthink the above would work and be an improvement. ie:\n\n   Bob has a shachain based secret generator, producing secrets s_0 to\n   s_(2**48). If you've seen s_0 to s_n, you only need to keep O(log(n))\n   of those values to regenerate all of them.\n\n   Bob generates RB1_n and RB2_n as H(s_n, 1)*G and H(s_n, 2)*G and sends\n   those values to Alice.\n\n   Alice determines the message (ie, the transaction), and sets da1_n\n   and da2_n as H(A_priv, msg, RB1_n, RB2_n, 1) and H(A_priv, msg, RB1_n,\n   RB2_n, 2). She then calculates k=H(da1_n, da2_n, RB1_n, RB2_n), and\n   signs for her nonce which da1_n+k*da2_n, and sends da1_n*G and\n   da2_n*G and the partial signature to Bob.\n\n   Bob checks and records Alice's musig2 derivation and partial signature,\n   but does not sign himself.\n\n   _If_ Bob wants to close the channel and publish the tx, he completes\n   the signature by signing with nonce RB1_n + k*RB2_n.\n\nIf you can convince Bob to close the channel repeatedly, using the\nsame nonce pair, then he'll have problems -- but if you can do that,\nyou can probably trick him into closing the channel with old state,\nwhich gives him the same problems by design... Or that's my take.\n\n> It may be worth pointing out that an adaptor signature scheme can not treat\n> MuSig2 as a black box as indicated in the \"Adaptor Signatures\" section [1].\n\nHmm, you had me panicking that I'd been describing how to combine the\ntwo despite having decided it wasn't necessary to combine them... :)\n\n(I figured doing musig for k ptlcs for every update would get old fast --\nif you maxed the channel out with ~400 inflight ptlcs you'd be exchanging\n~800 nonces for every update. OTOH, I guess that's the only thing you'd\nbe saving, and the cost is ~176 bytes of extra witness data per ptlc...\nHmm...)\n\nCheers,\naj"
            },
            {
                "author": "Jonas Nick",
                "date": "2021-10-10T18:01:55",
                "message_text_only": "> H( private-key, msg, other-party's-nonce-pair, 1 )\n\nThat should work. I had thought that other-party's-nonce-pair would be unique\nunknown randomness, but I can see now that it can be rederived from RA(n) or\nRB(n).\n\n > Hmm, you had me panicking that I'd been describing how to combine the\n > two despite having decided it wasn't necessary to combine them...\n\nAh, should have read that part more closely. The proposal uses the single sig\nadaptor sig variant."
            },
            {
                "author": "Lloyd Fournier",
                "date": "2021-10-11T06:05:05",
                "message_text_only": "Hey aj,\n\nThis is awesome work. My line of research on \"witness asymmetric channels\"\nessentially ended up in a dead end because I couldn't see how they were\nmuch better than naive PTLC lightning. The idea I really liked from it was\n\"revocable signatures\". I hoped someone would eventually figure out what to\ndo with them. Looks like you've done that!\n\nI also didn't make the connection to how revocable signatures actually\nsolves the constant size storage problem. I knew it could make the protocol\nin \"generalized payment channels\" [1] only require constant size which was\nthe target of the idea but I hadn't considered that lightning already\nsuffers from this problem so it can be applied more generally.\n\nThe other big breakthrough you made is showing how you can do concurrent\nnon-interactive payment forwarding by using a refined version of Z's fast\nforward idea. In my mind the most practical way to make FF work on\nPoon-Dryja channels was to do it asymmetrically [3] but this meant that if\na payment was sent the other way you'd have to do a 3 phase commit first.\nWith your idea as long as you have balance to spare in your balance output\nyou can always forward a payment in one message. A nice speed boost for\nbusy routing nodes.\n\n### Scorched earth punishment\n\nAnother thing that I'd like to mention is that using revocable signatures\nenables scorched earth punishments [2]. The key you reveal when you post a\nrevoked state does not have to be limited to your channel -- it could be\nused in multiple channels allowing the wronged party to take coins from all\ntheir channels with the perpetrator. Furthermore, a lightning service\nprovider that offers channels with the same channel key to all their\ncustomers is putting up all their coins in all their existing channels as\ntheir good behaviour bond rather than just the coins they have in the\nchannels they have with you.\n\nFor many users this will be sufficient to go without a \"watchtower\" to do\npunishments for them. They know if the LSP takes their coins with a revoked\nstate whenever they come back online they can punish the LSP by revealing\ntheir static channel key to everyone. They can even do this weeks or months\nafter the theft assuming the LSP is still operating with the same key.\n\nSome people feel this idea is too spicy but I prefer it to introducing a\ntrusted third party for people that cannot be online all the time.\n\n[1] https://eprint.iacr.org/2020/476.pdf\n[2]\nhttps://github.com/LLFourn/witness-asymmetric-channel#scorched-earth-punishments\n[3]\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2021-June/003045.html\n\nSome queries below:\n\nOn Sat, 9 Oct 2021 at 12:12, Anthony Towns <aj at erisian.com.au> wrote:\n\n>\n> We will use \"i\" to represent the number of times a given inflight\n> transaction has been updated for the nth update to the balance\n> transaction.\n>\n> At any time Alice can update the inflight transaction spending her balance\n> to transfer funds towards Bob, either by updating the balances directly,\n> or adding a htlc/ptlc entry to conditionally transfer funds to Bob. (And\n> conversely for Bob)\n>\n> We will define RP=musig(A/2/n/i, RB2(n,i)).\n>\n> The inflight transaction spending Alice's balance can have multiple\n> types of outputs:\n>\n>  * Alice's remaining balance: pays directly to A/2/n/i\n>\n>  * Bob's remaining balances: pays to RP/2 with script path\n>    \"<B/2/n/i> CHECKSIGVERIFY <D> CSV\"\n>\n>  * An htlc paying to Bob: pays to RP/2/k with script paths:\n>    + \"LENGTH 32 EQUALVERIFY HASH160 <X> EQUALVERIFY <B/2/n/i/k>\n> CHECKSIGVERIFY <A/2/n/i/k> CHECKSIG\"\n>    + \"<A/2/n/i/k/1> CHECKSIGVERIFY <T> CLTV\"\n>\n>  * A ptlc paying to Bob: pays to RP/2/k with script paths:\n>    + \"<B/2/n/i/k> CHECKSIG NOTIF <T> CLTV DROP ENDIF <A/2/n/i/k> CHECKSIG\"\n>\n> Any outputs that would be zero or dust are not included.\n>\n> Note that we number each currently inflight transaction by \"k\",\n> starting at 0. The same htlc/ptlc may have a different value for k\n> between different inflight transactions.\n>\n\nCan you expand on why \"k\" is needed in addition to \"n\" and \"i\". k sounds\nlike the same thing as i to me.\n\nAlso what does RP/2/k notation imply given the definition of RP you gave\nabove?\n\n\n>  * if the inflight transaction contains a ptlc output, then if Alice\n>    has not retained the old ptlc details (the point and the timeout)\n>    she will not trivially be able to reconstruct the script path,\n>    which includes the timeout. However, presuming the timeout was\n>    within 5000 blocks, then the only possible timeouts are the inflight\n>    tx's nlocktime+i with 0<i<=5000, and she will only need to calculate\n>    5000*k cases and match the corresponding scriptPubKeys to exhaustively\n>    enumerate every possible ptlc output, which should take under a minute,\n>    and be easily achievable. In addition, if Bob attempts to claim the\n>    funds, he will reveal the script path, and Alice will be either able\n>    to claim the inflight output directly or the layered output.\n>\n\nWhat about just doing a scriptless PTLC to avoid this (just CSV input of\npresigned tx)? The cost is pre-sharing more nonces per PTLC message.\n\nThis does not support option_static_remotekey, but compensates for that\n> by allowing balances to be recovered with only the channel setup data\n> even if all revocation data is lost.\n>\n\nThis is rather big drawback but is this really the case? Can't \"in-flight\"\ntransactions send the balance of the remote party to their unencumbered\nstatic remote key? Since there is no \"in-flight\" transaction just after you\ncreate a new balance tx you can just sign a \"good will\" in-flight tx\nwhenever you create a new balance tx that sends all the coins to your\nstatic key. Of course, your counterparty has no incentive to broadcast this\nwhen they close the channel but we can just specify that as part of the\nprotocol you broadcast this anyway (even if it gives you nothing). It's no\nskin off their back.\nOk so what about the fee for the \"good will\" tx? Well let's say it is a\nspecial case and just pays for itself with a reasonable fee. The \"good\nwill\" tx is low time preference and can be CPFP easily if you haven't lost\nyour state. If you have lost your state then this is much better than\nnothing.\n\nCheers,\n\nLL\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211011/a619e4b8/attachment-0001.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2021-10-12T03:26:58",
                "message_text_only": "On Mon, Oct 11, 2021 at 05:05:05PM +1100, Lloyd Fournier wrote:\n> ### Scorched earth punishment\n> Another thing that I'd like to mention is that using revocable signatures\n> enables scorched earth punishments [2]. \n\nI kind-of think it'd be more interesting to simulate eltoo's behaviour.\nIf Alice's current state has balances (A, B) and P in in-flight\npayments, and Bob posts an earlier state with (A', B') and P' (so A+B+P\n= A'+B'+P'), then maybe Alice's justice transaction should pay:\n\n   A+P + max(0, B'-B)*0.1 to Alice\n   B-f - max(0, B'-B)*0.1 to Bob\n\n(where \"f\" is the justice transaction fees)\n\nIdea being that in an ideal world there wouldn't be a hole in your pocket\nthat lets all your coins fall out, but in the event that there is such\na hole, it's a *nicer* world if the people who find your coins give them\nback to you out of the kindness of their heart.\n\n>     Note that we number each currently inflight transaction by \"k\",\n>     starting at 0. The same htlc/ptlc may have a different value for k\n>     between different inflight transactions.\n> Can you expand on why \"k\" is needed in addition to \"n\" and \"i\". k sounds like\n> the same thing as i to me.\n\n\"k\" is used to distinguish the inflight payments (htlcs/ptlcs), not the\ninflight state (which is \"i\").\n\n> Also what does RP/2/k notation imply given the definition of RP you gave above?\n\nI defined earlier that if P=musig(A,B) then P/x/y = musig(A/x/y,B/x/y);\nso RP/2/k = musig(A/2/n/i/2/k,RB2(n,i)/2/k).\n\n>     \u00a0* if the inflight transaction contains a ptlc output, [...]\n> What about just doing a scriptless PTLC to avoid this (just CSV input of\n> presigned tx)? The cost is pre-sharing more nonces per PTLC message.\n\nPrecisely that reason. Means you have to share \"k+1\" nonce pairs in\nadvance of every inflight tx update. Not a show stopper, just seemed\nlike a headache. (It's already a scriptless-script, this would let you\nuse a key path spend instead of a script path spend)\n\n>     This does not support option_static_remotekey, but compensates for that\n>     by allowing balances to be recovered with only the channel setup data\n>     even if all revocation data is lost.\n> This is rather big drawback but is this really the case? Can't \"in-flight\"\n> transactions send the balance of the remote party to their unencumbered static\n> remote key?\n\nThey could, but there's no guarantee that there is an inflight\ntransaction, or that the other party will post it for you. In those case,\nyou have to be able to redeem your output from the balance tx directly,\nand if you can do that, might as well have every possible address be\nderived differently to minimise the amount of information any third\nparties could glean.\n\nCheers,\naj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-10-12T04:18:37",
                "message_text_only": "Good morning aj,\n\n> On Mon, Oct 11, 2021 at 05:05:05PM +1100, Lloyd Fournier wrote:\n>\n> > ### Scorched earth punishment\n> >\n> > Another thing that I'd like to mention is that using revocable signatures\n> > enables scorched earth punishments [2].\n>\n> I kind-of think it'd be more interesting to simulate eltoo's behaviour.\n> If Alice's current state has balances (A, B) and P in in-flight\n> payments, and Bob posts an earlier state with (A', B') and P' (so A+B+P\n> = A'+B'+P'), then maybe Alice's justice transaction should pay:\n>\n> A+P + max(0, B'-B)*0.1 to Alice\n> B-f - max(0, B'-B)*0.1 to Bob\n>\n> (where \"f\" is the justice transaction fees)\n>\n> Idea being that in an ideal world there wouldn't be a hole in your pocket\n> that lets all your coins fall out, but in the event that there is such\n> a hole, it's a nicer world if the people who find your coins give them\n> back to you out of the kindness of their heart.\n\nThis may model closer to \"two tits for a tat\" strategy.\n\n\"Tit for tat\" is optimum in iterated prisoner dilemma assuming mistakes never happen; however, in the real world we know quite well that we may injure another person by complete accident.\nThe usual practice in the real world is that the injured person will accept an apology *once*, but a repeat will tend to make people assume you are hostile and switch them over to tit for tat.\nThis overall strategy is then \"two tits for a tat\", you are (in practice) given one chance and then you are expected to be very careful in interacting with that person to keep being in their good graces.\n\nSo, if what you propose is widespread, then a theft attempt is costless: you can try using old state, and your victim will, on finding it, instead just use what they think is the latest state.\nThus, merely attempting the theft is costless (modulo onchain fees, which may be enough punishment in this case?).\n\nHowever, if we assume that in practice a lot of \"theft attempts\" are really people not taking RAID systems and database replication seriously and getting punished by the trickster god Murphy, then your proposal would actually be better, and if theft is unlikely enough to succeed, then even a costless theft attempt would still be worthless (and onchain fees will bite you anyway).\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Anthony Towns",
                "date": "2021-10-12T04:48:56",
                "message_text_only": "On Tue, Oct 12, 2021 at 04:18:37AM +0000, ZmnSCPxj via Lightning-dev wrote:\n> > A+P + max(0, B'-B)*0.1 to Alice\n> > B-f - max(0, B'-B)*0.1 to Bob\n\n> So, if what you propose is widespread, then a theft attempt is costless: \n\nThat's what the \"max\" part prevents -- if your current balance is B and\nyou try to claim an old state with B' > B for a profit of B'-B, Alice\nwill instead take 10% of that value.\n\n(Except maybe all the funds they were trying to steal were in P' rather\nthan B'; so better might have been \"A+P + max(0, min(B'+P'-B)*0.1, B)\")\n\nEltoo would enable costless theft attempts (ignoring fees), particularly\nfor multiparty channels/factories, of course, so getting the game theory\nright in advance of that seems worth the effort anyway.\n\nCheers,\naj"
            },
            {
                "author": "Anthony Towns",
                "date": "2021-10-11T06:29:51",
                "message_text_only": "On Sat, Oct 09, 2021 at 11:12:07AM +1000, Anthony Towns wrote:\n>  2. The balance transaction - tracks the funding transaction, contains\n>     a \"balance\" output for each of the participants.\n>  3. The inflight transactions - spends a balance output from the balance\n>     transaction and provides outputs for any inflight htlc/ptlc transactions.\n>  4. Layered transactions - spends inflight htlc/ptlc outputs by revealing\n>     the preimage, while still allowing for the penalty path.\n\nI don't think the layering here quite works: if Alice forwarded a payment\nto Bob, with timeout T, then the only way she can be sure that she can\neither reclaim the funds or know the preimage by time T is to close the\nchannel on-chain at time T-to_self_delay.\n\nAny time later than that, say T-to_self_delay+x+1, would allow Bob to\npost the inflight tx at T+x (prior to Alice being able to claim her\nbalance directly due to the to_self_delay) and then immediately post the\nlayered transaction (4, above) revealing the preimage, and preventing\nAlice from claiming the refund.\n\nCheers,\naj"
            },
            {
                "author": "Lloyd Fournier",
                "date": "2021-10-11T10:23:19",
                "message_text_only": "On Mon, 11 Oct 2021 at 17:30, Anthony Towns <aj at erisian.com.au> wrote:\n\n>\n> I don't think the layering here quite works: if Alice forwarded a payment\n> to Bob, with timeout T, then the only way she can be sure that she can\n> either reclaim the funds or know the preimage by time T is to close the\n> channel on-chain at time T-to_self_delay.\n>\n> Any time later than that, say T-to_self_delay+x+1, would allow Bob to\n> post the inflight tx at T+x (prior to Alice being able to claim her\n> balance directly due to the to_self_delay) and then immediately post the\n> layered transaction (4, above) revealing the preimage, and preventing\n> Alice from claiming the refund.\n>\n\nThis problem may not be as bad as it seems. Recall that the issue in eltoo\nis worse because you are delayed both when you are offering and receiving\nthe HTLC. In this one you are only delayed on offered HTLC.\n\nAdjust the protocol so that you reciprocate the in-flight txs. So when I\noffer you a HTLC you first forward it and then lazily send me the signature\nfor the inflight tx. Therefore I dont have to wait to get the HTLC on chain\nand don\u2019t have to close the channel early.\n\nSo against a malicious node you have to go on chain to_self_delay earlier\nthan usual but if both are honest you don\u2019t have to. The problem with eltoo\nis that we don\u2019t know how to achieve this even if both parties are honest\niirc.\n\nLL\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211011/270d3661/attachment.html>"
            },
            {
                "author": "Lloyd Fournier",
                "date": "2021-10-11T21:12:14",
                "message_text_only": "On Mon, 11 Oct 2021 at 9:23 pm, Lloyd Fournier <lloyd.fourn at gmail.com>\nwrote:\n\n>\n> Adjust the protocol so that you reciprocate the in-flight txs. So when I\n> offer you a HTLC you first forward it and then lazily send me the signature\n> for the inflight tx. Therefore I dont have to wait to get the HTLC on chain\n> and don\u2019t have to close the channel early.\n>\n> So against a malicious node you have to go on chain to_self_delay earlier\n> than usual but if both are honest you don\u2019t have to. The problem with eltoo\n> is that we don\u2019t know how to achieve this even if both parties are honest\n> iirc.\n>\n\nErr never mind that won\u2019t work. Sending in-flights to both parties makes no\nsense because they can be stale of course.\n\nLL\n\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211012/603c793a/attachment.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2021-10-12T03:08:21",
                "message_text_only": "On Mon, Oct 11, 2021 at 09:23:19PM +1100, Lloyd Fournier wrote:\n> On Mon, 11 Oct 2021 at 17:30, Anthony Towns <aj at erisian.com.au> wrote:\n>     I don't think the layering here quite works: if Alice forwarded a payment\n>     to Bob, with timeout T, then the only way she can be sure that she can\n>     either reclaim the funds or know the preimage by time T is to close the\n>     channel on-chain at time T-to_self_delay.\n> This problem may not be as bad as it seems.\n\nMaybe you can break it down a little bit further. Consider *three*\ndelays:\n\n 1) refund delay: how long you have before a payment attempt starts\n    getting refunded\n\n 2) channel recovery delay: how long you have to recover from node\n    failure to prevent an old state being committed to, potentially losing\n    your entire channel balance\n\n 3) payment recovery delay: how long you have to recover from node\n    failure to prevent losing funds due to a forwarded payment (eg,\n    Carol claimed the payment, while Alice claimed the refund, leaving\n    Bob out of pocket)\n\n(Note that if you allow payments up to the total channel balance, there's\nnot really any meaningful distinction between (2) and (3), at least in\nthe worst case)\n\nWith layered transactions, (2) and (3) are different -- if Bob's node\nfails near the timeout, then both Alice and Carol drop to the blockchain,\nand Carol knows the preimage, Bob may have as little as the channel\n\"delay\" parameter to extract the preimage from Carol's layered commitment\ntx to be able to post a layered commitment on top of Alice's unilateral\nclose to avoid being out of pocket.\n\n(Note that that's a worst case -- Carol would normally reveal the preimage\nonchain earlier than just before the timeout, giving Bob more time to\nrecover his node and claim the funds from Alice)\n\nIf you're willing to accept that \"worst case\" happening more often, I\nthink you could then retain the low latency forwarding, by having the\ntransaction structure be:\n\ncommitment tx\n  input:\n     funding tx\n  outputs:\n     Alice's balance\n     (others)\n\nlow-latency inflight tx:\n  input:\n    Alice's balance\n  output:\n    (1) or (2)\n    Alice's remaining balance\n\nBob claim:\n  input:\n    (1) [<payment-recovery-delay> CSV bob CHECKSIG]\n  output:\n    [<bob-revoke> checksigverify <alice> checksig\n     ifdup notif <channel-recovery-delay> csv endif]\n\nToo-slow:\n  input:\n    (2) [<payment-timeout> CLTV alice CHECKSIG]\n  output:\n    Alice\n\nThe idea being:\n\n * Alice sends the low-latency inflight tx which Bob then forwards\n   immediately.\n\n * Bob then tries to update the base channel state with Alice, so both\n   sides have a commitment to the new payment, and the low-latency\n   inflight tx is voided (since it's based on a revoked channel state)\n   If this succeeds, everything is fine as usual.\n\n * If Alice is unavailable to confirm that update, Bob closes the\n   channel prior to (payment-timeout - payment-recover-delay), and posts\n   \"Bob claim\". After an additional pyment recovery delay (and prior\n   to payment-timeout) Bob posts Bob claim, ensuring that the only way\n   Alice can claim the funds is if he had posted a revoked state.\n\n * In this case, Alice has at least one payment-recovery-delay period\n   prior to the payment-timeout to notice the transaction onchain and\n   recover the preimage.\n\n * If Bob posted the low-latency inflight tx later than\n   (payment-timeout - payment-recovery-delay) then Alice will have\n   payment-recovery-delay time to notice and post the \"too-slow\" tx and\n   claim the funds via the timeout path.\n\n * If Bob posted a revoked state, Alice can also claim the funds via\n   Bob claim, provided she notices within the channel-recovery-delay\n\nThat only allows one low-latency payment to be inflight though, which I'm\nnot sure is that interesting... It's also kinda complicated, and doesn't\ncover both the low-latency and offline cases, which is disappointing...\n\nCheers,\naj"
            },
            {
                "author": "Lloyd Fournier",
                "date": "2021-10-13T04:15:14",
                "message_text_only": "On Tue, 12 Oct 2021 at 14:08, Anthony Towns <aj at erisian.com.au> wrote:\n\n>\n> If you're willing to accept that \"worst case\" happening more often, I\n> think you could then retain the low latency forwarding, by having the\n> transaction structure be:\n>\n> commitment tx\n>   input:\n>      funding tx\n>   outputs:\n>      Alice's balance\n>      (others)\n>\n> low-latency inflight tx:\n>   input:\n>     Alice's balance\n>   output:\n>     (1) or (2)\n>     Alice's remaining balance\n>\n> Bob claim:\n>   input:\n>     (1) [<payment-recovery-delay> CSV bob CHECKSIG]\n>   output:\n>     [<bob-revoke> checksigverify <alice> checksig\n>      ifdup notif <channel-recovery-delay> csv endif]\n>\n> Too-slow:\n>   input:\n>     (2) [<payment-timeout> CLTV alice CHECKSIG]\n>   output:\n>     Alice\n>\n> The idea being:\n>\n>  * Alice sends the low-latency inflight tx which Bob then forwards\n>    immediately.\n>\n>  * Bob then tries to update the base channel state with Alice, so both\n>    sides have a commitment to the new payment, and the low-latency\n>    inflight tx is voided (since it's based on a revoked channel state)\n>    If this succeeds, everything is fine as usual.\n>\n>  * If Alice is unavailable to confirm that update, Bob closes the\n>    channel prior to (payment-timeout - payment-recover-delay), and posts\n>    \"Bob claim\". After an additional pyment recovery delay (and prior\n>    to payment-timeout) Bob posts Bob claim, ensuring that the only way\n>    Alice can claim the funds is if he had posted a revoked state.\n>\n>  * In this case, Alice has at least one payment-recovery-delay period\n>    prior to the payment-timeout to notice the transaction onchain and\n>    recover the preimage.\n>\n>  * If Bob posted the low-latency inflight tx later than\n>    (payment-timeout - payment-recovery-delay) then Alice will have\n>    payment-recovery-delay time to notice and post the \"too-slow\" tx and\n>    claim the funds via the timeout path.\n>\n>  * If Bob posted a revoked state, Alice can also claim the funds via\n>    Bob claim, provided she notices within the channel-recovery-delay\n>\n\nIn my mind your \"update the base channel state\" idea seems to fix\neverything by itself. So at T - to_self_delay (or a bit before) you say to\nyour counterparty \"can we lift this HTLC out of your in-flight tx into the\n'balance tx' (which will go back to naming a 'commitment tx' since it\ndoesn't just have balance outputs anymore) so I can use it too? --\notherwise I'll have to close the channel on chain now to force you to\nreveal it to me on time?\". If they agree, after the revocation and new\ncommit tx everything is back to (tx symmetric) Poon-Dryja so no need for\nextra CSVs. Am I missing something?\n\nI realise this kills some of the elegance of your original protocol and\nadds quite a bit of complexity but I think it retains the important\nproperties.\n\n\n> That only allows one low-latency payment to be inflight though, which I'm\n> not sure is that interesting... It's also kinda complicated, and doesn't\n> cover both the low-latency and offline cases, which is disappointing...\n>\n>\nIt seems to me lazily lifting the HTLCs into the commitment tx would allow\nas many low-latency payments as you want to be in-flight. You would\nprobably just lift them all up to the commitment tx if you lift one. I\nthink in the case of nodes that want to keep channel keys offline, having\nto go on-chain at T - to_self_delay is not a disaster since it will likely\nonly be the payment receiver who has their keys offline i.e. the merchant\nor end user. So only the last hop would go on chain if the user fails to\nclaim payment as per usual (just to_self_delay earlier than usual).\n\nCheers,\n\nLL\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211013/f94a9551/attachment.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2021-10-19T04:16:13",
                "message_text_only": "On Wed, Oct 13, 2021 at 03:15:14PM +1100, Lloyd Fournier wrote:\n>     If you're willing to accept that \"worst case\" happening more often, I\n>     think you could then retain the low latency forwarding, by having the\n>     transaction structure be:\n\nSo the idea here is that we have two channel parameters:\n\n   PD - the payment delay or payment timeout delta, say 40 blocks\n   RD - the channel recovery delay, say 2016 blocks\n\nand the idea is that if you publish an old state, I have the longer delay\n(RD) to correct that; *but* if the currently active state includes a\npayment that I've forwarded to you, I may only have the shorter delay\n(PD) in order to forward the payment claim details back in order to\navoid being out of pocket.\n\nThe goal is to keep that working while also allowing me to tell you about\na payment to you in such a way that you can safely forward it on *without*\nan additional round-trip back to me (to acknowledge that you've received\nit and that I've received your acknowledgement).\n\nIt's not really a super-important goal; it could shave off 50% of\nthe time to accept a ln tx when everything goes right, and there's no\nbottlenecks elsewhere in the implementation, but it can't do anything\nmore than that, and doesn't help the really slow cases when things go\nwrong. Mostly, I just find it interesting.\n\nSuppose that a payment is forwarded from Alice to Bob, Carol and finally\nreaches Dave. Alice/Bob and Carol/Dave are both colocated in a data centre\nand have high bandwidth and have 1ms (rtt) latency, but Bob/Carol are\non different continents (but not via tor) and have 100ms (rtt) latency.\n\nWith 1.5 round-trips before forwarding, we'd get:\n\n  t=0     Alice tells Bob\n  t=1.5   Bob tells Carol\n  t=151.5 Carol tells Dave\n  t=153   Dave reveals the secret to Carol\n  t=153.5 Carol reveals the secret to Bob\n  t=203.5 Bob reveals the secret to Alice\n  t=204   Alice knows the secret!\n\nThat's how things work now, with \"X tells Y\" being:\n\n  X->Y: update_add_htlc, commitment_signed\n  Y->X: commitment_signed, revoke_and_ack\n  X->Y: revoke_and_ack\n\nand \"X reveals the secret to Y\" being:\n\n  X->Y: update_fulfill_htlc\n\nHowever, if we could do it optimally we would have:\n\n  t=0     Alice tells Bob about the payment\n  t=0.5   Bob tells Carol about the payment\n  t=50.5  Carol tells Dave about the payment\n  t=51    Dave accepts the payment and tells Carol the secret\n  t=51.5  Carol accepts the payment and tells Bob the secret\n  t=101.5 Bob accepts the payment and tells Alice the secret\n  t=102   Alice knows the secret!\n\nLooking just at Bob/Carol we might also have the underlying commitment\nstate updates:\n\n  t=50.5  Carol acks the payment to Bob (commitment_signed,\n          revoke_and_ack)\n  t=100.5 Bob acks Carol's ack, revoking old state (revoke_and_ack)\n  t=150.5 Carol's safe with the new state including the payment\n\n  t=51.5  Carol reveals the secret and signs a new updated state\n          (update_fulfill_htlc, commitmnt_signed)\n  t=101.5 Bob acks receipt of the secret (commitment_signed,\n          revoke_and_ack)\n  t=151.5 Carol's safe with the new state with an increased balance\n          (revoke_and_ack)\n  t=201.5 Bob's state is up to date\n\nNote that the first of those doesn't complete until well after Alice\nwould know the secret in an optimal construction; and that as described\nthe second upate overlaps the first, which might not be particularly\ndesirable.\n\n> In my mind your \"update the base channel state\" idea seems to fix everything by\n> itself.\n\nYeah -- if you're willing to do 1.5 round-trips (and thanks to musig2 this\ndoesn't blow out to 2.5 (?) round-trips) that does solve everything. The\nchallenge is to do it in 0.5 round-trips. :)\n\n> So at T - to_self_delay (or a bit before) you say to your counterparty\n> \"can we lift this HTLC out of your in-flight tx into the 'balance tx' (which\n> will go back to naming a 'commitment tx' since it doesn't just have balance\n> outputs anymore) so I can use it too? -- otherwise I'll have to close the\n> channel on chain now to force you to reveal it to me on time?\". If they agree,\n> after the revocation and new commit tx everything is back to (tx symmetric)\n> Poon-Dryja so no need for extra CSVs.\n\nMaybe? So the idea is that:\n\n 1) Bob gets a \"low-latency\" tx that spends Alice's balance and has a\n    bunch of outputs for really recent payments\n 2) In normal conditions, in 5 or 10 or 30 seconds, Alice/Bob renegotiate\n    the base commitment to move those payments out of the \"low-latency\"\n    tx\n 3) In abnormal conditions, with an active forwarded \"low-latency\" tx and\n    communications failure of length up to \"PD\", Alice closes the channel\n    on chain.\n 4) Bob then has \"PD\" period to post the \"low-latency\" tx, if he\n    doesn't, Alice can do a layered claim of her balance preventing Bob\n    from oing so.\n 5) If Bob does post his \"low-latency\" tx, then he'll also need to reveal\n    secrets prior to the payment timeout.\n\nSo taking the payment timeout as T, then he'll have to post the\nlow-latency tx (4) and reveal the secret (5) no later than T, which\nmeans he'll be upset if Alice drops to the chain later than T-PD, and\nAlice won't do that unless comms failure begins at T-2*PD.\n\nThat means that:\n\n * Alice should not propose and Bob should not accept a low-latency\n   payment if T < now+2*PD\n\n * Alice should drop the commitment tx on-chain no later than T-PD,\n   Bob should drop the commitment and low-latency txs on chain prior\n   to T (Alice to ensure she can timeout any payments, Bob to ensure\n   he can claim any payments prior to Alice timing them out)\n\n * Alice should reserve her balance asap (at time T) if Bob does not\n   post the low-latency transaction\n\n * ... and not much else?\n\n> I realise this kills some of the elegance of your original protocol and adds\n> quite a bit of complexity but I think it retains the important properties.\n\nI think the only complexity it actually adds is that Alice needs to\nbe able to prevent Bob from posting the \"low-latency\" tx if he doesn't\nreact within \"PD\" -- which is just a signature from Bob allowing her to\nspend the output with nSequence set to \"PD\"?\n\nSince it's putting payments back into the commitment tx, it also makes\nit more separable -- you could stick it behind a feature bit so nodes\ncan just not implement low-latency payments, particularly if they're\nnot usually forwarding payments, or are only connected to nearby nodes\nanyway...\n\n(I don't think that approach works for \"offline\" peers, though, because\nthey'd need to be able to post the low-latency tx within the \"PD\" delay,\nand can't do that because they're offline)\n\nCheers,\naj"
            },
            {
                "author": "Anthony Towns",
                "date": "2021-10-19T06:26:50",
                "message_text_only": "On Sat, Oct 09, 2021 at 11:12:07AM +1000, Anthony Towns wrote:\n> Here's my proposal for replacing BOLT#2 and BOLT#3 to take advantage of\n> taproot and implement PTLCs. \n\nI think the conclusion from the discussions at the in-person LN summit\nwas to split these features up an implement them gradually. I think that\nwould look like:\n\n 1) taproot funding/anchor output\n    benefits:\n     * LN utxos just look normal, so better privacy\n     * mutual closes also look normal, and only need one sig and no\n       script, better privacy and lower fees\n     * doesn't require updating any HTLC scripts\n    complexities:\n     * requires implementing musig/musig2/similar for mutual\n       closes and signing commitment txs\n     * affects gossip, which wants to link channels with utxos so needs\n       to understand the new utxo format\n     * affects splicing -- maybe it's literally an update to the\n       splicing spec, and takes effect only when you open new channels\n       or splice existing ones?\n\n 2) update commitment outputs to taproot\n    benefits:\n     * slightly cheaper unilateral closes, maybe more private?\n    complexities:\n     * just need to support taproot script path spends\n\n 3) PTLC outputs\n    benefits:\n     * has a different \"hash\" at every hop, arguably better privacy\n     * can easily do cool things with points/secrets that would require\n       zkp's to do with hashes/secrets\n     * no need to remember PTLCs indefinitely in case of old \n    complexities:\n     * needs a routing feature bit\n     * not usable unless lots of the network upgrades to support PTLCs\n     * requires implementing adaptor signatures\n\n 4) symmetric commitment tx (revocation via signature info)\n    benefits:\n     * reduces complexity of layered txs?\n     * reduces gamesmanship of who posts the commitment tx?\n     * enables low-latency/offline payments?\n    complexities:\n     * requires careful nonce management?\n\n 5) low-latency payments?\n    benefits:\n     * for payments that have no problems, halves the time to complete\n     * the latency introduced by synchronous commitment updates doesn't\n       matter for successful payments, so peer protocol can be simplified\n    complexities:\n     * ?\n\n 6) offline receipt?\n\n 7) eltoo channels?\n\n 8) eltoo factories?\n\nCheers,\naj"
            }
        ],
        "thread_summary": {
            "title": "Lightning over taproot with PTLCs",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Anthony Towns",
                "Lloyd Fournier",
                "Jonas Nick",
                "ZmnSCPxj"
            ],
            "messages_count": 18,
            "total_messages_chars_count": 62456
        }
    },
    {
        "title": "[Lightning-dev] Inherited IDs - A safer, more powerful alternative to BIP-118 (ANYPREVOUT) for scaling Bitcoin",
        "thread_messages": [
            {
                "author": "jlspc",
                "date": "2021-10-10T22:03:38",
                "message_text_only": "Response to email from Anthony Towns sent on 20210918 at 11:37:40 UTC\n==============================================\naj,\n\nThanks for taking the time to go through my paper on inherited IDs (IIDs). Also, thanks for your concise and accurate description of the IID proposal and the 2Stage channel protocol. I'm glad you feel the 2Stage protocol might be better than eltoo for a two-party channel.\n\nI want to address other parts of the paper that were obviously not as clear, as they led to two important misunderstandings.\n\nFirst, there is the issue of the use of an operator in the \"timeout trees\", \"update-forest\" and \"challenge-and-response\" factory protocols. While those protocols do include a party that is designated as the \"operator\", the operator is in no way a trusted party. While it's true that one would prefer an operator that follows the protocol fully and promptly, as that would allow one to keep the protocol off-chain, the operator can never take funds or prevent others from obtaining the funds that are due to them. In fact, this is exactly analogous to the selection of the party with whom one shares a two-party lightning channel. If one views lightning as being trust-free, then one will also view \"timeout trees\", \"update-forest\" and \"challenge-and-response\" to be trust-free.\n\nSecond, there is the question of whether or not IIDs can be simulated with anyprevout. I don't believe that they can. Consider for example the case where Alice has an on-chain funding transaction F1 with output F1:0 that will be spent by a (currently off-chain) transaction F2 with output F2:0 that will be spent by a settlement transaction S. Assume further that there is an on-chain control transaction C1 with output C1:0 owned by untrusted operator O, where C1:0 will be spent by a (currently off-chain) transaction C2 with output C2:0 that may, in certain cases, also be spent by S. In particular, assume F1 puts a covenant on F2 such that F2 puts a covenant on S, where the covenant on S can be met by either: A) waiting a CSV delay of one time unit (defined to be long enough to allow a party with a competing transaction to put that competing transaction on-chain first) and then spending only F2:0 (where F2:0 is referenced via IID) and giving ownership of S:0 to Alice, or B) waiting until a CLV reaches time T_lock and then spending both F2:0 and C2:0 (where F2:0 and C2:0 are referenced via IIDs).\n\nAssume that after Alice put F1 on-chain she wants to transfer ownership of the output S:0 to Bob without having to put F2 or S on-chain. She can do this with IIDs as follows. First, Alice asks the untrusted operator O to put C2 on-chain where C2 puts a covenant on S that forces S to spend both F2:0 and C2:0 (where F2:0 and C2:0 are referenced via IIDs) and to give ownership of S:0 to Bob (by making it spendable using Bob's public key).\n\nThere are two cases. First, if O promptly puts the desired C2 on-chain, then Alice and Bob can wait until T_lock (while putting nothing else on-chain), at which point Bob can be assured that he owns S:0 (as any attempt by Alice to spend S:0 by meetiing the covenant using case A above can be thwarted by Bob putting S on-chain first using case B above). Second, if O puts a different C2 on-chain, or fails to put any C2 on-chain promptly, Alice can reclaim her funds by putting F2 on-chain, waiting one time window, and then putting S on-chain using case A above.\n\nThus, IIDs provide a trust-free means for Alice to transfer funds from F1 to a party that is unknown to Alice when she puts F1 on-chain. I see two problems in tryinig to use anyprevout to achieve the same result. First, I don't know of any mechanism by which Alice can create a covenant that F2 puts on S which implements case B above. In some other settings, I can understand how one could use unique single-use keys in place of IID outputs. However, in this setting I don't see how to define a covenant that F2 puts on S that in case B forces the other input to spend C2:0, as signatures that are evaluated in spending F2:0 don't commit to the output scripts of other inputs to S. Second, and more fundamentally, even if one could define a covenant that F2 puts on S in case B forcing the other input to be signed by a single-use key owned by O, that still wouldn't unconditionally transfer ownership to Bob (without putting F2 and S on-chain). That's because in order to have single-use keys play the role of IIDs, they have to truly be single-use and there is no way Bob can know that O won't just sign some other S' that competes with S and sends S':0 to O, thus stealing the funds. Please let me know if I've missed something here.\n\nThe example above isn't very useful, as it doesn't cut down on the number of on-chain transactions required to transfer ownership from Alice to Bob. However, it does capture the core functionality that IIDs provide that (I believe) anyprevout does not provide. This functionality is exactly what enables \"update-forest\" and \"challenge-and-response\" to allow a single on-chain transaction to transfer ownership of thousands or millions of channels in a trust-free manner, thus accomplishing with one on-chain transaction what would have required thousands or millions of anyprevout transactions (at least as far as I can tell). This is exactly the power of IIDs that I was referring to, and I found surprising that this power was actually the result of restricting how a signed transaction can be used (as compared to a signed transaction that uses anyprevout).\n\nI hope clearing up these two misunderstandings is enough to pique your interest in reading the \"timeout trees\", \"update-forest\" and \"challenge-and-response\" protocols in more detail, as I'd be interested in your expert opinion on them.\n\nMy remaining comments are minor compared to the previous ones.\n* Regarding the worst-case delay for eltoo-2party vs. 2Stage, I agree that there is no single agreed upon model for analyzing this and opinions may differ. In any case, I think that if one had a nearly-expired HTLC (or if one is setting the lock time for an HTLC) and one could choose between eltoo-2party, where the other party could have thousands or millions of transactions competing with your settlement transaction, and 2Stage, where the other party can have at most one competing transaction, some would prefer 2Stage.\n* In comparing eltoo-2party and 2Stage, I was surprised that you didn't consider 2Stage's elimination of watchtowers for one or both parties as being an advantage. I had through that would be a big win in practice.\n* Regarding footnote 13's description of OP_CODESEPARATOR, I realize that that footnote does not capture the change made in taproot. I addressed that issue on p. 54 (and explained it in footnote 43), as footnote 13 was designed to explain OP_CODESEPARATOR to those not already familiar with it, while p. 54 was designed for the experts.\n* Regarding the new address type for floating transactions mentioned in the paper, thanks for the correction. I'll remove this from the next version.\n\nIn summary, the paper shows that:\n1) IIDs can be used to eliminate watchtowers for one or both parties in a two-party channel (2Stage),\n2) IIDs can be used to create factories that allow very large numbers of new users to obtain bitcoin in a watchtower-free and trust-free manner (timeout trees),\n3) IIDs support trust-free factories with unbounded numbers of parties (and channels) that allow the channels to be bought and sold by anyone, including parties not originally in the factory, with a single on-chain transaction, and\n4) IIDs achieve these results while using a more constrained, and thus safer, change to Bitcoin than the support for floating transactions.\n\nAre these results of interest?\n\nThanks,\nJohn\n\nSent with [ProtonMail](https://protonmail.com/) Secure Email.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211010/ef8682ee/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Inherited IDs - A safer, more powerful alternative to BIP-118 (ANYPREVOUT) for scaling Bitcoin",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "jlspc"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 8015
        }
    },
    {
        "title": "[Lightning-dev] Block Header commit (c93824e)",
        "thread_messages": [
            {
                "author": "Skyler Saleebyan",
                "date": "2021-10-12T06:01:33",
                "message_text_only": "Hi everyone,\n\nRecently there was a commit to change pings from including random data to\nnow including state data: the most recent bitcoin block header.\n\nhttps://github.com/lightningnetwork/lnd/pull/5621\n\nI was wondering if there was a discussion around the possible risks for\ncontinuously broadcasting your most recent state to the network. Are there\nno counterparty risks associated with this or is the attack surface just\ntoo small/unrealistic outside edge cases?\n\nIf I were to just spitball a couple of ideas (and would welcome other\nexamples), with this data I would wonder if:\na) you could use block header update delays to de-anonymize/identify/locate\nnodes by using update times/uncle blocks/fingerprinting attacks\nb) any counterparty risks exist from an attacker node pretending to be on\nthe same block as an out of date node\n\nIf the security story around this update has been discussed in detail I'd\nlove to know where to read more.\n\nThanks,\nSkyler S.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211012/4091ada2/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Block Header commit (c93824e)",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Skyler Saleebyan"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1145
        }
    },
    {
        "title": "[Lightning-dev] Issue assets on lightning",
        "thread_messages": [
            {
                "author": "Prayank",
                "date": "2021-10-12T08:39:50",
                "message_text_only": "Hello everyone,\n\nI wanted to know few things related to asset issuance on lightning:\n\n1.Is it possible to issue assets on LN right now? If yes, what's the process and is it as easy as few commands in liquid:\u00a0https://help.blockstream.com/hc/en-us/articles/900005127583-How-do-I-issue-an-asset-on-Liquid-\n\n2.If no, is anyone working or planning to work on it?\n\n3.I had read few things about Omni BOLT which could solve this problem but not sure about status of project and development:\u00a0https://github.com/omnilaboratory/OmniBOLT-spec\n\nFew use cases for tokens on lightning:\n\n1.DEX2.Stablecoins3.Liquidity: If projects could incentivize users with native tokens that are associated with the project on every LN channel opened it would improve liquidity.\n\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211012/ae443565/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-10-13T03:59:45",
                "message_text_only": "Good morning Prayank,\n\n> Hello everyone,\n>\n> I wanted to know few things related to asset issuance on lightning:\n>\n> 1.Is it possible to issue assets on LN right now? If yes, what's the process and is it as easy as few commands in liquid:\u00a0https://help.blockstream.com/hc/en-us/articles/900005127583-How-do-I-issue-an-asset-on-Liquid-\n>\n> 2.If no, is anyone working or planning to work on it?\n>\n> 3.I had read few things about Omni BOLT which could solve this problem but not sure about status of project and development:\u00a0https://github.com/omnilaboratory/OmniBOLT-spec\n>\n> Few use cases for tokens on lightning:\n>\n> 1.DEX\n> 2.Stablecoins\n> 3.Liquidity: If projects could incentivize users with native tokens that are associated with the project on every LN channel opened it would improve liquidity.\n\nI heard before that the RGB colored coin project had plans to be compatible with Lightning so that channels could be denominated in an issued asset.\n\nMost plans for colored coins on Lightning generally assume that each channel has just a single asset, as that seems to be simpler, at least as a start.\nHowever, this complicates the use of such channels for forwarding, as we would like to restrict channel gossip to channels that *any* node can easily prove actually exist as a UTXO onchain.\nThus, colored coins would need to somehow be provable as existing to *any* node (or at least those that support colored coins somehow) on the LN.\n\nBlockstream I believe has plans to include support for Liquid-issued assets in C-Lightning somehow; C-Lightning already supports running on top of Liquid instead of directly on the Bitcoin blockchain layer (but still uses Bitcoin for the channel asset type).\n\nGenerally, the assumption is that there would be a Lightning Network where channels have different asset types, and you can forward via any channel, suffering some kind of asset conversion fee if you have a hop where the incoming asset is different from the outgoing asset.\n\n\nHowever, do note that some years ago I pointed out that swaps between two *different* assets are a form of very lousy American Call Option: https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-December/001752.html\n\nDue to this, issued assets may not be usable on Lightning after all, even if someone makes the work to make non-Bitcoin assets on Lightning channels.\n\nI am unaware of any actual decent solutions to the American Call Option problem, but it has been a few years since then and someone might have come up with a solution by now (we hope, maybe).\nI believe CJP had a trust-requiring solution: https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-May/001292.html and https://bitonic.nl/public/slowdown_prevention.pdf\nHere is a paper which requires Ethereum (I have not read it because it required Ethereum): https://eprint.iacr.org/2019/896.pdf\n\nIt may be possible to use Barrier Escrows: https://suredbits.com/payment-points-implementing-barrier-escrows/\nBarrier Escrows are still trusted (and I think they can serve as the RM role in the CJP paper?) to operate correctly, but the exact use of their service is blinded to them.\nOf course, any single participant of a multi-participant protocol can probably unblind the Barrier Escrow, so still not a perfectly trustless solution.\n\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Prayank",
                "date": "2021-10-15T14:47:56",
                "message_text_only": "Good morning ZmnSCPxj,\n\n> I heard before that the RGB colored coin project had plans to be compatible with Lightning so that channels could be denominated in an issued asset.\n\nRGB will address lot of things but I was wondering if such things should exist in LN implementations by default. Example: If we had two ways to issue assets LA1 and LA2, the user can issue asset using a command: lightning-cli -named issueassets -type=LA1 -number=1000\n\n> Blockstream I believe has plans to include support for Liquid-issued assets in C-Lightning somehow; C-Lightning already supports running on top of Liquid instead of directly on the Bitcoin blockchain layer (but still uses Bitcoin for the channel asset type)\n\nThis is interesting.\n\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-December/001752.html\n\nStill trying to understand this problem and possible solutions. Interesting email though (TIL), thanks for sharing the link. Found related things explained Suredbits blog as well.\n\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n\n\n\nOct 13, 2021, 09:29 by ZmnSCPxj at protonmail.com:\n\n> Good morning Prayank,\n>\n>> Hello everyone,\n>>\n>> I wanted to know few things related to asset issuance on lightning:\n>>\n>> 1.Is it possible to issue assets on LN right now? If yes, what's the process and is it as easy as few commands in liquid:\u00a0https://help.blockstream.com/hc/en-us/articles/900005127583-How-do-I-issue-an-asset-on-Liquid-\n>>\n>> 2.If no, is anyone working or planning to work on it?\n>>\n>> 3.I had read few things about Omni BOLT which could solve this problem but not sure about status of project and development:\u00a0https://github.com/omnilaboratory/OmniBOLT-spec\n>>\n>> Few use cases for tokens on lightning:\n>>\n>> 1.DEX\n>> 2.Stablecoins\n>> 3.Liquidity: If projects could incentivize users with native tokens that are associated with the project on every LN channel opened it would improve liquidity.\n>>\n>\n> I heard before that the RGB colored coin project had plans to be compatible with Lightning so that channels could be denominated in an issued asset.\n>\n> Most plans for colored coins on Lightning generally assume that each channel has just a single asset, as that seems to be simpler, at least as a start.\n> However, this complicates the use of such channels for forwarding, as we would like to restrict channel gossip to channels that *any* node can easily prove actually exist as a UTXO onchain.\n> Thus, colored coins would need to somehow be provable as existing to *any* node (or at least those that support colored coins somehow) on the LN.\n>\n> Blockstream I believe has plans to include support for Liquid-issued assets in C-Lightning somehow; C-Lightning already supports running on top of Liquid instead of directly on the Bitcoin blockchain layer (but still uses Bitcoin for the channel asset type).\n>\n> Generally, the assumption is that there would be a Lightning Network where channels have different asset types, and you can forward via any channel, suffering some kind of asset conversion fee if you have a hop where the incoming asset is different from the outgoing asset.\n>\n>\n> However, do note that some years ago I pointed out that swaps between two *different* assets are a form of very lousy American Call Option: https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-December/001752.html\n>\n> Due to this, issued assets may not be usable on Lightning after all, even if someone makes the work to make non-Bitcoin assets on Lightning channels.\n>\n> I am unaware of any actual decent solutions to the American Call Option problem, but it has been a few years since then and someone might have come up with a solution by now (we hope, maybe).\n> I believe CJP had a trust-requiring solution: https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-May/001292.html and https://bitonic.nl/public/slowdown_prevention.pdf\n> Here is a paper which requires Ethereum (I have not read it because it required Ethereum): https://eprint.iacr.org/2019/896.pdf\n>\n> It may be possible to use Barrier Escrows: https://suredbits.com/payment-points-implementing-barrier-escrows/\n> Barrier Escrows are still trusted (and I think they can serve as the RM role in the CJP paper?) to operate correctly, but the exact use of their service is blinded to them.\n> Of course, any single participant of a multi-participant protocol can probably unblind the Barrier Escrow, so still not a perfectly trustless solution.\n>\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211015/f1c3b8f4/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-10-15T14:59:31",
                "message_text_only": "Good morning Prayank,\n\n\n> > https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-December/001752.html\n>\n> Still trying to understand this problem and possible solutions. Interesting email though (TIL), thanks for sharing the link. Found related things explained Suredbits blog as well.\n\n\nWe can argue that the above problem is really just the \"failed HTLCs are free and HODL invoices are free\" problem, magnified by the fact that as an exchange, and with most cryptocurrency assets being very volatile, exchange rate changes can be exploited to leak economic power from exchange nodes.\n\nSo, fixing the \"free HOLD invoices\" problem, such as creating a ***palatable*** upfront payment scheme, should also fix the American Call Option problem.\n\nOn the other hand, if we cannot create an upfront payment scheme and are forced to solve the \"free HODL invoices\" problem by other means, then we may need to solve the American Call Option problem separately.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Issue assets on lightning",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Prayank",
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 9911
        }
    },
    {
        "title": "[Lightning-dev] A Mobile Lightning User Goes to Pay a Mobile Lightning User...",
        "thread_messages": [
            {
                "author": "Matt Corallo",
                "date": "2021-10-13T04:44:21",
                "message_text_only": "I'm sure most of y'all are familiar with this problem by now - a lightning user on a phone trying to \npay another lightning user on a phone requires some amount of coordination to ensure the sender and \nrecipient are, roughly, online at the same time.\n\nInvoices provide this somewhat today by requiring the recipient provide some live-ish data to the \nsender with their phone in their hand.\n\nBut for some reason those pesky users keep wanting to use lightning for tips, or at least accept \npayment on their phones without keeping them unlocked with the lightning app open on the foreground \n24/7.\n\nThere's a few things live today which make progress towards this goal, but don't quite get there \n(and mostly aren't trying to solve this problem, but are worth mentioning):\n\n  * just have the recipient use a custodial product/run a full lightning node at home on an RPi.\n    Obviously this has some pretty substantial drawbacks, I'm not sure I even need to list them, but \nthe \"just require the recipient use a custodial service\" is what Twitter ended up shipping with for \nlightning tipping, and we should all probably feel ashamed that they felt the need to do that.\n\n  * Blockstream Greenlight.\n    This change the online-requirements model - with the keys on your phone/elsewhere you still have \nto have your phone online with the same requirements as running a full lightning node. It just means \nfewer resources on that device.\n\n  * use keysend/AMP/whatever.\n    This is great for tips, but only half the story. Sender goes to send a keysend payment, gets to \none hop before the recipient, and then a day later the recipient comes online to find the payment \nlong-since timed out and failed backwards. Or you could use a long CLTV on the payment to make sure \nthe recipient has time to claim it, which is basically a DoS on the lightning network's capacity, \none that may eventually be fixed, breaking your payments, and which is just generally antisocial. \nStill, my understanding is some folks do this today cause its the only option for a mobile device.\n\n  * lnurl\n    ...is a great way to get an invoice, presumably from a trusted LSP for the recipient, trusting \nthem to not give the same invoice twice, but doesn't help the recipient receive the payment, they \nstill need to be online, unless...\n\n  * have a fully-trusted LSP that accepts payments and forwards them later\n    this is also fine, where its practical, I guess, but I'd hope we can do better. Worse, as far as \nI understand the places where this is practical are becoming fewer and fewer as the regulatory \nuncertainty clears and everyone realizes the regulatory overhead of this is...well you might as well \nstart applying for that banking charter now.\n\n  * have an untrusted LSP that sends you a notification to open the app when a payment is received\n    Several lightning apps do this today, and its somewhat of a stop-gap but does help. On platforms \nwhere the app gets some meager CPU time in response to a notification, this can even fully solve the \nproblem by claiming the HTLC in response to the notification pushed out-of-band. Sadly, the refrain \nI've heard repeatedly is, these days, on both Android and especially iOS, you can't even rely on a \nmicrosecond of CPU time in response to a notification. The OS fully expects your app to run code \nonly when its on and in the foreground, unless you're a VoIP app you're screwed. Relying on the user \nto open the app immediately when they receive a notification is...fine, I guess, absent a better \nidea it seems like the best we've got today, but I'm not sure you'd find a UX designer who would \n*suggest* this :).\n\n\nBut what would it take to do better? What follows is a simple straw-man, but something that's \nborderline practical today and may at least generate a few ideas. It comes in two variants\n\nIf we accept the lnurl trust model of \"a third-party I can give a list of pre-signed invoices, which \nI trust to never provide an invoice twice, but otherwise is untrusted\", then we could do something \nlike this:\n\nStep 1. Tipper gets an invoice from the lnurl endpoint they wish to pay, which contains some \n\"recipient is behind an LSP and rarely online, act accordingly\" flag.\n\nStep 2. Tipper sender sends a HTLC with a long CLTV timeout to their own LSP with instructions \nsaying \"when you get an onion message telling you nonce B, forward this HTLC, until then, just sit \non it\". The LSP accepts this HTLC but does not forward it and is generally okay with the long CLTV \ndelta because it would otherwise just be the users' balance anyway - if they want to encumber their \nown funds forever, no harm done.\n   Note that if tipper is online regularly they can skip this step and move on.\n\nStep 3. The Tipper sends an onion message to recipient's LSP saying \"hey, when recipient is online \nagain, use the included reply path to send nonce B to my LSP\".\n\n- sender can now safely go offline -\n\nStep 4. When the Recipient comes online, their LSP sends the reply to the Tipper's LSP,\n\nStep 5. causing the Tipper's LSP to (finally) forward the original HTLC, which the Recipient receives.\n\nYou'll note that this solution, unlike simply sending a high-CLTV HTLC, does not encumber funds for \nany extended period of time except for the original sender, who wants to send the funds off \nelsewhere anyway. Nor does it rely on any parties who can at any point run away with the funds (or \nreasonably be construed as custodians for the funds). Further, this solution does not rely on the \nsender deanonymizing themselves to the recipient (or even informing the recipient who the senders' \nLSP is).\n\nNote that lnurl here could be replaced with BOLT 12 if BOLT 12 gets some flag indicating the Tipper \nshould ask an LSP for the invoice.\n\nBut, okay, so the lnurl model of a trusted party not reusing invoices so that the Recipient's LSP \ncannot just steal all funds after the first claim kinda really sucks, how do we do better?\n\nThe Obvious (tm) solution here is PTLCs - just have the sender always add some random nonce * G to \nthe PTLC they're paying and send the recipient a random nonce in the onion. I'd generally suggest we \njust go ahead and do this for every PTLC payment, cause why not? Now the sender and the lnurl \nendpoint have to collude to steal the funds, but, like, the sender could always just give the lnurl \nendpoint the money. I'd love suggestions for fixing this short of PTLCs, but its not immediately \nobvious to me that this is possible.\n\nThanks to Steve for pushing on the \"how does a let users get tips in lightning\" issue, various \npeople for giving him feedback and the relayed to me, AJ for the PTLC proposal, and Rusty for \ntireless drum-beating on onion messages and BOLT 12.\n\nMatt"
            },
            {
                "author": "Andr\u00e9s G. Aragoneses",
                "date": "2021-10-13T05:08:51",
                "message_text_only": "Hello Matt, can you clarify what you mean with this particular paragraph?:\n\nBut for some reason those pesky users keep wanting to use lightning for\n> tips, or at least accept\n> payment on their phones without keeping them unlocked with the lightning\n> app open on the foreground\n> 24/7.\n\n\nSo the use case here is more narrow? You mean that the recipient is a\nmobile user that has his phone locked?\nJust so I understand better what the problem is.\n\n\nOn Wed, 13 Oct 2021 at 12:44, Matt Corallo <lf-lists at mattcorallo.com> wrote:\n\n> I'm sure most of y'all are familiar with this problem by now - a lightning\n> user on a phone trying to\n> pay another lightning user on a phone requires some amount of coordination\n> to ensure the sender and\n> recipient are, roughly, online at the same time.\n>\n> Invoices provide this somewhat today by requiring the recipient provide\n> some live-ish data to the\n> sender with their phone in their hand.\n>\n> But for some reason those pesky users keep wanting to use lightning for\n> tips, or at least accept\n> payment on their phones without keeping them unlocked with the lightning\n> app open on the foreground\n> 24/7.\n>\n> There's a few things live today which make progress towards this goal, but\n> don't quite get there\n> (and mostly aren't trying to solve this problem, but are worth mentioning):\n>\n>   * just have the recipient use a custodial product/run a full lightning\n> node at home on an RPi.\n>     Obviously this has some pretty substantial drawbacks, I'm not sure I\n> even need to list them, but\n> the \"just require the recipient use a custodial service\" is what Twitter\n> ended up shipping with for\n> lightning tipping, and we should all probably feel ashamed that they felt\n> the need to do that.\n>\n>   * Blockstream Greenlight.\n>     This change the online-requirements model - with the keys on your\n> phone/elsewhere you still have\n> to have your phone online with the same requirements as running a full\n> lightning node. It just means\n> fewer resources on that device.\n>\n>   * use keysend/AMP/whatever.\n>     This is great for tips, but only half the story. Sender goes to send a\n> keysend payment, gets to\n> one hop before the recipient, and then a day later the recipient comes\n> online to find the payment\n> long-since timed out and failed backwards. Or you could use a long CLTV on\n> the payment to make sure\n> the recipient has time to claim it, which is basically a DoS on the\n> lightning network's capacity,\n> one that may eventually be fixed, breaking your payments, and which is\n> just generally antisocial.\n> Still, my understanding is some folks do this today cause its the only\n> option for a mobile device.\n>\n>   * lnurl\n>     ...is a great way to get an invoice, presumably from a trusted LSP for\n> the recipient, trusting\n> them to not give the same invoice twice, but doesn't help the recipient\n> receive the payment, they\n> still need to be online, unless...\n>\n>   * have a fully-trusted LSP that accepts payments and forwards them later\n>     this is also fine, where its practical, I guess, but I'd hope we can\n> do better. Worse, as far as\n> I understand the places where this is practical are becoming fewer and\n> fewer as the regulatory\n> uncertainty clears and everyone realizes the regulatory overhead of this\n> is...well you might as well\n> start applying for that banking charter now.\n>\n>   * have an untrusted LSP that sends you a notification to open the app\n> when a payment is received\n>     Several lightning apps do this today, and its somewhat of a stop-gap\n> but does help. On platforms\n> where the app gets some meager CPU time in response to a notification,\n> this can even fully solve the\n> problem by claiming the HTLC in response to the notification pushed\n> out-of-band. Sadly, the refrain\n> I've heard repeatedly is, these days, on both Android and especially iOS,\n> you can't even rely on a\n> microsecond of CPU time in response to a notification. The OS fully\n> expects your app to run code\n> only when its on and in the foreground, unless you're a VoIP app you're\n> screwed. Relying on the user\n> to open the app immediately when they receive a notification is...fine, I\n> guess, absent a better\n> idea it seems like the best we've got today, but I'm not sure you'd find a\n> UX designer who would\n> *suggest* this :).\n>\n>\n> But what would it take to do better? What follows is a simple straw-man,\n> but something that's\n> borderline practical today and may at least generate a few ideas. It comes\n> in two variants\n>\n> If we accept the lnurl trust model of \"a third-party I can give a list of\n> pre-signed invoices, which\n> I trust to never provide an invoice twice, but otherwise is untrusted\",\n> then we could do something\n> like this:\n>\n> Step 1. Tipper gets an invoice from the lnurl endpoint they wish to pay,\n> which contains some\n> \"recipient is behind an LSP and rarely online, act accordingly\" flag.\n>\n> Step 2. Tipper sender sends a HTLC with a long CLTV timeout to their own\n> LSP with instructions\n> saying \"when you get an onion message telling you nonce B, forward this\n> HTLC, until then, just sit\n> on it\". The LSP accepts this HTLC but does not forward it and is generally\n> okay with the long CLTV\n> delta because it would otherwise just be the users' balance anyway - if\n> they want to encumber their\n> own funds forever, no harm done.\n>    Note that if tipper is online regularly they can skip this step and\n> move on.\n>\n> Step 3. The Tipper sends an onion message to recipient's LSP saying \"hey,\n> when recipient is online\n> again, use the included reply path to send nonce B to my LSP\".\n>\n> - sender can now safely go offline -\n>\n> Step 4. When the Recipient comes online, their LSP sends the reply to the\n> Tipper's LSP,\n>\n> Step 5. causing the Tipper's LSP to (finally) forward the original HTLC,\n> which the Recipient receives.\n>\n> You'll note that this solution, unlike simply sending a high-CLTV HTLC,\n> does not encumber funds for\n> any extended period of time except for the original sender, who wants to\n> send the funds off\n> elsewhere anyway. Nor does it rely on any parties who can at any point run\n> away with the funds (or\n> reasonably be construed as custodians for the funds). Further, this\n> solution does not rely on the\n> sender deanonymizing themselves to the recipient (or even informing the\n> recipient who the senders'\n> LSP is).\n>\n> Note that lnurl here could be replaced with BOLT 12 if BOLT 12 gets some\n> flag indicating the Tipper\n> should ask an LSP for the invoice.\n>\n> But, okay, so the lnurl model of a trusted party not reusing invoices so\n> that the Recipient's LSP\n> cannot just steal all funds after the first claim kinda really sucks, how\n> do we do better?\n>\n> The Obvious (tm) solution here is PTLCs - just have the sender always add\n> some random nonce * G to\n> the PTLC they're paying and send the recipient a random nonce in the\n> onion. I'd generally suggest we\n> just go ahead and do this for every PTLC payment, cause why not? Now the\n> sender and the lnurl\n> endpoint have to collude to steal the funds, but, like, the sender could\n> always just give the lnurl\n> endpoint the money. I'd love suggestions for fixing this short of PTLCs,\n> but its not immediately\n> obvious to me that this is possible.\n>\n> Thanks to Steve for pushing on the \"how does a let users get tips in\n> lightning\" issue, various\n> people for giving him feedback and the relayed to me, AJ for the PTLC\n> proposal, and Rusty for\n> tireless drum-beating on onion messages and BOLT 12.\n>\n> Matt\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211013/d180dac7/attachment.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2021-10-13T05:13:53",
                "message_text_only": "On 10/12/21 22:08, Andr\u00e9s G. Aragoneses wrote:\n> Hello Matt, can you clarify what you mean with this particular paragraph?:\n> \n>     But for some reason those pesky users keep wanting to use lightning for tips, or at least accept\n>     payment on their phones without keeping them unlocked with the lightning app open on the foreground\n>     24/7.\n> \n> \n> So the use case here is more narrow? You mean that the recipient is a mobile user that has his phone \n> locked?\n> Just so I understand better what the problem is.\n\nYes, but not just locked, just \"doesn't have the lightning app open and in the foreground when a \npayment comes in\".  See this paragraph:\n\n>      \u00a0 \u00a0 Several lightning apps do this today, and its somewhat of a stop-gap but does help. On\n>     platforms\n>     where the app gets some meager CPU time in response to a notification, this can even fully solve\n>     the\n>     problem by claiming the HTLC in response to the notification pushed out-of-band. Sadly, the refrain\n>     I've heard repeatedly is, these days, on both Android and especially iOS, you can't even rely on a\n>     microsecond of CPU time in response to a notification. The OS fully expects your app to run code\n>     only when its on and in the foreground, unless you're a VoIP app you're screwed. Relying on the\n>     user\n>     to open the app immediately when they receive a notification is...fine, I guess, absent a better\n>     idea it seems like the best we've got today, but I'm not sure you'd find a UX designer who would\n>     *suggest* this :)."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-10-13T09:58:40",
                "message_text_only": "Good morning Matt,\n\n\n>     The Obvious (tm) solution here is PTLCs - just have the sender always add some random nonce * G to\n>     the PTLC they're paying and send the recipient a random nonce in the onion. I'd generally suggest we\n>     just go ahead and do this for every PTLC payment, cause why not? Now the sender and the lnurl\n>     endpoint have to collude to steal the funds, but, like, the sender could always just give the lnurl\n>     endpoint the money. I'd love suggestions for fixing this short of PTLCs, but its not immediately\n>     obvious to me that this is possible.\n\nUse two hashes in an HTLC instead of one, where the second hash is from a preimage the sender generates, and which the sender sends (encrypted via onion) to the receiver.\nYou might want to do this anyway in HTLC-land, consider that we have a `payment_secret` in invoices, the second hash could replace that, and provide similar protection to what `payment_secret` provides (i.e. resistance against forwarding nodes probing; the information in both cases is private to the ultimate sender and ultimate reeceiver).\n\nIn addition, I suspect (but have not worked out yet) that this would allow some kind of Barrier Escrow-like mechanism while still in HTLC-land.\n\nOtherwise, just PTLC, man, everyone wants PTLC.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Matt Corallo",
                "date": "2021-10-13T16:57:57",
                "message_text_only": "On 10/13/21 02:58, ZmnSCPxj wrote:\n> Good morning Matt,\n> \n> \n>>      The Obvious (tm) solution here is PTLCs - just have the sender always add some random nonce * G to\n>>      the PTLC they're paying and send the recipient a random nonce in the onion. I'd generally suggest we\n>>      just go ahead and do this for every PTLC payment, cause why not? Now the sender and the lnurl\n>>      endpoint have to collude to steal the funds, but, like, the sender could always just give the lnurl\n>>      endpoint the money. I'd love suggestions for fixing this short of PTLCs, but its not immediately\n>>      obvious to me that this is possible.\n> \n> Use two hashes in an HTLC instead of one, where the second hash is from a preimage the sender generates, and which the sender sends (encrypted via onion) to the receiver.\n> You might want to do this anyway in HTLC-land, consider that we have a `payment_secret` in invoices, the second hash could replace that, and provide similar protection to what `payment_secret` provides (i.e. resistance against forwarding nodes probing; the information in both cases is private to the ultimate sender and ultimate reeceiver).\n\nYes, you could create a construction which does this, sure, but I'm not sure how you'd do this \nwithout informing every hop along the path that this is going on, and adapting each hop to handle \nthis as well. I suppose I should have been more clear with the requirements, or can you clarify \nsomewhat what your proposed construction is?\n\nIf you're gonna adapt every node in the path, you might as well just use PTLC.\n\nMatt"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-10-14T00:20:15",
                "message_text_only": "Good morning Matt,\n\n> On 10/13/21 02:58, ZmnSCPxj wrote:\n>\n> > Good morning Matt,\n> >\n> > >      The Obvious (tm) solution here is PTLCs - just have the sender always add some random nonce * G to\n> > >      the PTLC they're paying and send the recipient a random nonce in the onion. I'd generally suggest we\n> > >      just go ahead and do this for every PTLC payment, cause why not? Now the sender and the lnurl\n> > >      endpoint have to collude to steal the funds, but, like, the sender could always just give the lnurl\n> > >      endpoint the money. I'd love suggestions for fixing this short of PTLCs, but its not immediately\n> > >      obvious to me that this is possible.\n> > >\n> >\n> > Use two hashes in an HTLC instead of one, where the second hash is from a preimage the sender generates, and which the sender sends (encrypted via onion) to the receiver.\n> > You might want to do this anyway in HTLC-land, consider that we have a `payment_secret` in invoices, the second hash could replace that, and provide similar protection to what `payment_secret` provides (i.e. resistance against forwarding nodes probing; the information in both cases is private to the ultimate sender and ultimate reeceiver).\n>\n> Yes, you could create a construction which does this, sure, but I'm not sure how you'd do this\n> without informing every hop along the path that this is going on, and adapting each hop to handle\n> this as well. I suppose I should have been more clear with the requirements, or can you clarify\n> somewhat what your proposed construction is?\n\nJust that: two hashes instead of one.\nMake *every* HTLC on LN use two hashes, even for current \"online RPi user pays online RPi user\" --- just use the `payment_secret` for the preimage of the second hash, the sender needs to send it anyway.\n\n>\n> If you're gonna adapt every node in the path, you might as well just use PTLC.\n\nCorrect, we should just do PTLCs now.\n(Basically, my proposal was just a strawman to say \"we should just do PTLCs now\")\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2021-10-19T11:51:38",
                "message_text_only": "Hi Matt,\n\nI like this proposal, it's a net improvement compared to hodling HTLCs\nat the recipient's LSP. With onion messages, we do have all the tools we\nneed to build this. I don't think we can do much better than that anyway\nif we want to keep payments fully non-custodial. This will be combined\nwith notifications to try to get the recipient to go online asap.\n\nOne thing to note is that the senders also need to come online while\nthe payment isn't settled, otherwise there is a risk they'll lose their\nchannels. If the sender's LSP receives the preimage but the sender does\nnot come online, the sender's LSP will have to force-close to claim the\nHTLC on-chain when it gets close to the timeout.\n\nDefinitely not a show-stopper, just an implementation detail to keep in\nmind.\n\nBastien\n\nLe jeu. 14 oct. 2021 \u00e0 02:20, ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n> Good morning Matt,\n>\n> > On 10/13/21 02:58, ZmnSCPxj wrote:\n> >\n> > > Good morning Matt,\n> > >\n> > > >      The Obvious (tm) solution here is PTLCs - just have the sender\n> always add some random nonce * G to\n> > > >      the PTLC they're paying and send the recipient a random nonce\n> in the onion. I'd generally suggest we\n> > > >      just go ahead and do this for every PTLC payment, cause why\n> not? Now the sender and the lnurl\n> > > >      endpoint have to collude to steal the funds, but, like, the\n> sender could always just give the lnurl\n> > > >      endpoint the money. I'd love suggestions for fixing this short\n> of PTLCs, but its not immediately\n> > > >      obvious to me that this is possible.\n> > > >\n> > >\n> > > Use two hashes in an HTLC instead of one, where the second hash is\n> from a preimage the sender generates, and which the sender sends (encrypted\n> via onion) to the receiver.\n> > > You might want to do this anyway in HTLC-land, consider that we have a\n> `payment_secret` in invoices, the second hash could replace that, and\n> provide similar protection to what `payment_secret` provides (i.e.\n> resistance against forwarding nodes probing; the information in both cases\n> is private to the ultimate sender and ultimate reeceiver).\n> >\n> > Yes, you could create a construction which does this, sure, but I'm not\n> sure how you'd do this\n> > without informing every hop along the path that this is going on, and\n> adapting each hop to handle\n> > this as well. I suppose I should have been more clear with the\n> requirements, or can you clarify\n> > somewhat what your proposed construction is?\n>\n> Just that: two hashes instead of one.\n> Make *every* HTLC on LN use two hashes, even for current \"online RPi user\n> pays online RPi user\" --- just use the `payment_secret` for the preimage of\n> the second hash, the sender needs to send it anyway.\n>\n> >\n> > If you're gonna adapt every node in the path, you might as well just use\n> PTLC.\n>\n> Correct, we should just do PTLCs now.\n> (Basically, my proposal was just a strawman to say \"we should just do\n> PTLCs now\")\n>\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211019/8844e3dc/attachment.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2021-10-20T19:16:34",
                "message_text_only": "> On Oct 19, 2021, at 04:51, Bastien TEINTURIER <bastien at acinq.fr> wrote:\n> \n> I like this proposal, it's a net improvement compared to hodling HTLCs\n> at the recipient's LSP. With onion messages, we do have all the tools we\n> need to build this. I don't think we can do much better than that anyway\n> if we want to keep payments fully non-custodial. This will be combined\n> with notifications to try to get the recipient to go online asap.\n\nThanks! \n\n> One thing to note is that the senders also need to come online while\n> the payment isn't settled, otherwise there is a risk they'll lose their\n> channels. If the sender's LSP receives the preimage but the sender does\n> not come online, the sender's LSP will have to force-close to claim the\n> HTLC on-chain when it gets close to the timeout.\n\nYep. I was imagining a huge CLTV on that hop (and maybe some way of having a first-hop-set CLTV at hops after that, I don\u2019t recall if it\u2019s allowed, but it should be for this). That way at least the sender has a week/month to go online and clear the HTLC, subject to the usual LSP liquidity requirements of course.\n\n> Definitely not a show-stopper, just an implementation detail to keep in\n> mind.\n> \n> Bastien\n> \n>> Le jeu. 14 oct. 2021 \u00e0 02:20, ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> a \u00e9crit :\n>> Good morning Matt,\n>> \n>> > On 10/13/21 02:58, ZmnSCPxj wrote:\n>> >\n>> > > Good morning Matt,\n>> > >\n>> > > >      The Obvious (tm) solution here is PTLCs - just have the sender always add some random nonce * G to\n>> > > >      the PTLC they're paying and send the recipient a random nonce in the onion. I'd generally suggest we\n>> > > >      just go ahead and do this for every PTLC payment, cause why not? Now the sender and the lnurl\n>> > > >      endpoint have to collude to steal the funds, but, like, the sender could always just give the lnurl\n>> > > >      endpoint the money. I'd love suggestions for fixing this short of PTLCs, but its not immediately\n>> > > >      obvious to me that this is possible.\n>> > > >\n>> > >\n>> > > Use two hashes in an HTLC instead of one, where the second hash is from a preimage the sender generates, and which the sender sends (encrypted via onion) to the receiver.\n>> > > You might want to do this anyway in HTLC-land, consider that we have a `payment_secret` in invoices, the second hash could replace that, and provide similar protection to what `payment_secret` provides (i.e. resistance against forwarding nodes probing; the information in both cases is private to the ultimate sender and ultimate reeceiver).\n>> >\n>> > Yes, you could create a construction which does this, sure, but I'm not sure how you'd do this\n>> > without informing every hop along the path that this is going on, and adapting each hop to handle\n>> > this as well. I suppose I should have been more clear with the requirements, or can you clarify\n>> > somewhat what your proposed construction is?\n>> \n>> Just that: two hashes instead of one.\n>> Make *every* HTLC on LN use two hashes, even for current \"online RPi user pays online RPi user\" --- just use the `payment_secret` for the preimage of the second hash, the sender needs to send it anyway.\n>> \n>> >\n>> > If you're gonna adapt every node in the path, you might as well just use PTLC.\n>> \n>> Correct, we should just do PTLCs now.\n>> (Basically, my proposal was just a strawman to say \"we should just do PTLCs now\")\n>> \n>> \n>> Regards,\n>> ZmnSCPxj\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211020/27738a31/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "A Mobile Lightning User Goes to Pay a Mobile Lightning User...",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Bastien TEINTURIER",
                "Andr\u00e9s G. Aragoneses",
                "Matt Corallo",
                "ZmnSCPxj"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 28323
        }
    },
    {
        "title": "[Lightning-dev] Deriving channel keys deterministically from seed, musig, and channel establishment v2",
        "thread_messages": [
            {
                "author": "Lloyd Fournier",
                "date": "2021-10-13T07:04:46",
                "message_text_only": "Hi SomberNight,\n\nI started a similar discussion less than a year ago on the list. The idea I\nput forward works fine with MuSig and taproot.\n\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2020-December/002907.html\n\nThe idea was considered for channel establishment v2 but in the end there\nwere various objections to it becoming specified as it forces\nimplementations to handle keys in a certain way. You can still do it\ninformally though by fixing your funding pubkey to be derived from the\nDiffie-Hellman key of the two node ids. This makes the funding public keys\na (secret) deterministic function of the two node ids without making a\nprivacy leak.\n\nFWIW I still think this is a good idea but in hindsight I think the\nobjections to it being mandatory are valid.\n\nCheers,\n\nLL\n\nOn Sat, 18 Sept 2021 at 02:14, SomberNight via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Hi all,\n>\n> TL;DR: an approach is described how to derive channel keys\n> deterministically that allows certain forms of recovery from just\n> a seed, that works today. This approach however will no longer work\n> with e.g. MuSig key aggregation in the future. An idea for a proposal\n> is given how the channel-open flow (e.g. as part of channel v2) could be\n> changed to make a similar approach work independent of key aggregation.\n>\n> -----\n>\n> While implementing anchor output support in Electrum, we have realised\n> one difficulty is to do with the remote-force-close case where the\n> to_remote output is no longer a simple p2wpkh.\n>\n> Currently, pre-anchor-support, Electrum sets option_static_remotekey\n> to required (feature bit 12), and we restrict lightning usage to wallets\n> that derive p2wpkh addresses, and payment_basepoint is set\n> to a bip32-derived pubkey that corresponds to a wallet address.\n> Hence, if a user were to restore from seed words, and their channel\n> counterparty force closed their channel, the to_remote output of the\n> broadcast commitment tx would directly pay to the user's wallet.\n> That is, in many typical scenarios, funds are not lost when restoring\n> from seed.\n>\n> (Also, if we are the channel-funder/opener, it is easy to find the\n> funding transaction, just by testing txs in the wallet history.\n> Further, for the cases we are the channel-funder/opener,\n> there is a setting to put an OP_RETURN in the funding tx, which stores\n> the nodeid of the counterparty, allowing us to identify who to contact\n> to get the channel closed.\n> Also, we are (ab)using dataloss_protect to ask the remote\n> to force-close when restoring from seed, so the user does not even have\n> to wait for an arbitrarily long time.)\n>\n> With anchors, the to_remote is now a p2wsh that involves a CSV,\n> and we cannot easily make this script correspond to a wallet address,\n> i.e. we lose the property that the remote-force-close pays directly\n> to a wallet address.\n>\n> So, the problem we would like to solve, is:\n> - having seed words\n> - having access to blockchain data\n> - somehow having identified our channel counterparties (node IDs),\n>   and our channels with them (funding outpoints)\n> - and assuming we can get the remote to do a force-close\n> --> we would like to be able to spend the to_remote output\n>\n> Solutions:\n>\n> 1) Naively, we could just derive a static key to be used as\n> payment_basepoint, reused between all our channels, and watch the\n> single resulting p2wsh script on-chain.\n> Clearly this has terrible privacy implications.\n>\n> 2) Or, we could derive a new bip32 chain/sequence of pubkeys\n> used as payment_basepoint for channels, and watch these p2wsh scripts,\n> with a gap limit.\n> Particularly the gap limit part makes this undesirable though\n> (just consider having more than \"gap limit\" channels open and restoring\n> from seed).\n>\n> Instead, it seems desirable to see whether we can extract some entropy\n> from the blockchain, and use that as a nonce to be combined with a\n> static private secret derived from our seed.\n> We could extract data either from the funding tx, or from the\n> remote-commitment-transaction that spent the funding output.\n>\n> 3) We exploit the fact that the funding output uses a\n> 2of2 OP_CHECKMULTISIG script composed of the funding pubkeys of\n> each party. The funding pubkey itself can be used as a nonce, and\n> it can be recovered from the witness of the commitment tx.\n> The privkey for payment_basepoint can then be derived as e.g.\n> hash(bip32_derive(seed, HARDCODED_PATH) + funding_pubkey).\n>\n> In fact (3) is not novel at all: eclair has been deriving\n> all their channel keys like this [0] for some time, from\n> a static seed-based secret combined with the funding_pubkey as nonce,\n> and generating the funding_privkey from ~os.urandom.\n>\n> Electrum will likely use (3) at least for the payment_basepoint,\n> as part of adapting to anchors.\n>\n> -----\n>\n> Note that the idea (3) relies on recovering the funding_pubkey from\n> the witness of the spending transaction, which will break in the future\n> if the funding script is changed to e.g. a p2tr that uses musig.\n>\n> Crucially, note that all the approach needs is some blockchain-visible\n> nonce that is already known at the time we need to construct the\n> open_channel message (as we want to be able to derive some of the keys\n> that are sent as part of the open_channel message\n> (e.g. payment_basepoint) from it).\n> As long as the funding output uses a 2of2 OP_CHECKMULTISIG,\n> the local funding_pubkey fits the bill.\n>\n> Note that irrespective of any restrictions on the script used in\n> the funding output, we could use the funding scriptPubKey/address as\n> the nonce, if the open_channel/accept_channel messages were\n> split into two.\n> For example, instead of the single round of open_channel/accept_channel,\n> there could be two rounds:\n> - an open_channel_part1, where the peers exchange only\n>   the funding_pubkey (and the other non-pubkey fields), and\n> - an open_channel_part2, where the rest of the pubkeys are sent\n> This way the peers would learn what the funding address would be after\n> the first round finishes, and could potentially use that to derive\n> their other channel keys (needed for round 2).\n>\n> So, to arrive at my point, I would like to ask whether people think\n> such a change - or something similar - might be useful, and if so,\n> whether it could/should be incorporated to the current\n> channel establishment v2 proposal [1].\n> If there is agreement that this would be useful, a spec change\n> would be most useful before changing the 2of2 multisig script.\n>\n> Regards,\n> ghost43 (SomberNight)\n>\n>\n> [0]: https://github.com/ACINQ/eclair/pull/1097\n> [1]: https://github.com/lightningnetwork/lightning-rfc/pull/851\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211013/390ec20d/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Deriving channel keys deterministically from seed, musig, and channel establishment v2",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Lloyd Fournier"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 7069
        }
    },
    {
        "title": "[Lightning-dev] In-protocol liquidity probing and channel jamming mitigation",
        "thread_messages": [
            {
                "author": "Joost Jager",
                "date": "2021-10-14T07:48:27",
                "message_text_only": "A practice that is widely applied by lightning wallets is to probe routes\nwith an unknown payment hash before making the actual payment. Probing\nyields an accurate routing fee that can be shown to the user before\nexecution of the payment.\n\nThe downside of this style of probing is that for a short period of time,\nliquidity is locked up. Not just the sender's liquidity, but also liquidity\nof nodes along the route. And if the probe gets stuck for whatever reason,\nthat short period may become longer.\n\nBut does this lock up serve a purpose at all? Suppose there would be a\nliquidity probing protocol message similar to `update_add_htlc`\n(`probe_htlc`?) that would skip the whole channel update machinery and is\nonly forwarded to the next hop if the link would be able to carry the htlc.\nWon't this work as well as the current probing without the downsides? Nodes\ncan obviously reject these probes because they are distinguishable from\nreal payments (contrary to unknown hash probing where everything looks the\nsame). However if they do so, senders won't use that route and the routing\nnode misses out on routing fees.\n\nAnother problem of the lightning network is its susceptibility to channel\njamming. Multiple options have been proposed (see also\nhttps://github.com/t-bast/lightning-docs/blob/master/spam-prevention.md),\nbut they all come with downsides.\n\nPersonally I incline towards solutions that involve deterring the attacker\nby making them pay actual satoshis. Lightning itself is payment system and\nit seems that paying for the payments is a natural solution to the problem.\nSeveral iterations of this idea have been proposed. One of my own that\nbuilds on an earlier idea by t-bast is described in\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2021-February/002958.html\n.\n\nThe main criticism that this proposal has received is that it deteriorates\nthe user experience for honest users when multiple payment routes need to\nbe attempted. Every attempt will have a cost, so the user will see its\nbalance going down by only just trying to make the payment. How bad this is\ndepends on the attempt failure rate. I expect this rate to become really\nlow as the network matures and senders hold routing nodes to high\nstandards. Others however think otherwise and consider a series of failed\nattempts part of a healthy system.\n\nCustodial wallets could probably just swallow the cost for failures. They\ntypically use one pathfinding system for all their users and are therefore\nable to collect a lot of information on routing node performance. This is\nlikely to decrease the payment failure rate to an acceptably low level.\n\nFor non-custodial nodes, this may be different. They have to map out the\ngood routing nodes  all by themselves and this exploration will bear a cost.\n\nSo how would things work out with a combination of both of the proposals\ndescribed in this mail? First we make probing free (free as in no liquidity\nlocked up) and then we'll require senders to pay for failed payment\nattempts too. Failed payment attempts after a successful probe should be\nextremely rate, so doesn't this fix the ux issue with upfront fees?\n\nJoost\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211014/04750627/attachment.html>"
            },
            {
                "author": "Owen Gunden",
                "date": "2021-10-15T13:55:29",
                "message_text_only": "On Thu, Oct 14, 2021 at 09:48:27AM +0200, Joost Jager wrote:\n> So how would things work out with a combination of both of the\n> proposals described in this mail? First we make probing free (free as\n> in no liquidity locked up) and then we'll require senders to pay for\n> failed payment attempts too. Failed payment attempts after a\n> successful probe should be extremely rate, so doesn't this fix the ux\n> issue with upfront fees?\n\nWhy couldn't a malicious routing node (or group of colluding routing\nnodes) succeed the probe and then fail the payment in order to collect\nthe failed payment fee?"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-10-15T14:29:15",
                "message_text_only": "Good morning Owen,\n\n> On Thu, Oct 14, 2021 at 09:48:27AM +0200, Joost Jager wrote:\n>\n> > So how would things work out with a combination of both of the\n> > proposals described in this mail? First we make probing free (free as\n> > in no liquidity locked up) and then we'll require senders to pay for\n> > failed payment attempts too. Failed payment attempts after a\n> > successful probe should be extremely rate, so doesn't this fix the ux\n> > issue with upfront fees?\n>\n> Why couldn't a malicious routing node (or group of colluding routing\n> nodes) succeed the probe and then fail the payment in order to collect\n> the failed payment fee?\n\nGood observation!\n\nI propose substantially the same thing here: https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-September/003256.html\n\nIn that proposal, I wrote:\n\n> Another thought is: Does the forwarding node have an incentive to lie?\n> Suppose the next hop is alive but the forwarding node has insufficient capacity towards the next hop.\n> Then the forwarding node can lie and claim it can still resolve the HTLC, in the hope that a few milliseconds later, when the actual HTLC arrives, the capacity towards the next hop has changed.\n> Thus, even if the capacity now is insufficient, the forwarding node has an incentive to lie and claim sufficient capacity.\n>\n> Against the above, we can mitigate this by accepting \"no\" from *any* node along the path, but only accepting \"yes\" from the actual payee.\n\nWe already have a mechanism to send an onion and get back an \"error\" reply; the reply can be identified by the sender as arising from any node along the path, or at the destination.\nBasically, we simply reuse this mechanism:\n\n* Do not need an HTLC with this onion.\n* Only accept a \"everything is OK\" result from the destination.\n* Accept a \"sorry cannot forward\" from *any* node along the path.\n\nThus, a malicious node cannot succeed the probe --- the probe has to reach the destination.\n\nNow the malicious forwarding node could be colluding with the destination, but presumably the destination wants to *actually* get paid, so we expect that, economically, it has no incentive to cooperate with the malicious node to *fail* the actual payment later just to extract a tiny failure fee.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Joost Jager",
                "date": "2021-10-15T14:44:06",
                "message_text_only": ">\n> > On Thu, Oct 14, 2021 at 09:48:27AM +0200, Joost Jager wrote:\n> >\n> > > So how would things work out with a combination of both of the\n> > > proposals described in this mail? First we make probing free (free as\n> > > in no liquidity locked up) and then we'll require senders to pay for\n> > > failed payment attempts too. Failed payment attempts after a\n> > > successful probe should be extremely rate, so doesn't this fix the ux\n> > > issue with upfront fees?\n> >\n> > Why couldn't a malicious routing node (or group of colluding routing\n> > nodes) succeed the probe and then fail the payment in order to collect\n> > the failed payment fee?\n>\n> Good observation!\n>\n> I propose substantially the same thing here:\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-September/003256.html\n\n\nI totally missed that thread, but it is indeed the same thing including the\nnotion that it may make upfront payments palatable! Contains some great\nadditional ideas too.\n\nJoost\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211015/342fb320/attachment.html>"
            },
            {
                "author": "Owen Gunden",
                "date": "2021-10-15T17:50:06",
                "message_text_only": "On Fri, Oct 15, 2021 at 02:29:15PM +0000, ZmnSCPxj wrote:\n> I propose substantially the same thing here:\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-September/003256.html\n>\n> In that proposal, I wrote:\n>\n> > Another thought is: Does the forwarding node have an incentive to\n> > lie?\n> > Suppose the next hop is alive but the forwarding node has\n> > insufficient capacity towards the next hop.\n> > Then the forwarding node can lie and claim it can still resolve the\n> > HTLC, in the hope that a few milliseconds later, when the actual\n> > HTLC arrives, the capacity towards the next hop has changed.\n> > Thus, even if the capacity now is insufficient, the forwarding node\n> > has an incentive to lie and claim sufficient capacity.\n\nUnder Joost's proposal, there's even more of an incentive to lie: sats\nto be had.\n\n> > Against the above, we can mitigate this by accepting \"no\" from *any*\n> > node along the path, but only accepting \"yes\" from the actual payee.\n\nThis doesn't really help if all the routers along the way are lying and\nsaying 'yes'. Only the payee's 'yes' is meaningful, and she doesn't have\nenough information to know if the routers were lying or not.\n\nI think the actual enforcement mechanism is (also from your proposal\nZmn):\n\n> > Presumably, when a node receives a question, it checks if the asking\n> > node has sufficient capacity towards it first, and if not, fails the\n> > channel between them, since obviously the asking node is not\n> > behaving according to protocol and is buggy.\n\nBut I'm not sure the incentives align for this tattling on your neighbor.\n\nLet's take an example A -> B -> C -> D\n\nA sends a probe towards D. B doesn't have sufficient liquidity to send\nto C. But B is a liar. B says 'yes'.\n\nC now notes that B is lying, but is faced with the dilemma:\n\n \"I could either say 'no' because I can plainly see that B is lying, or\n I could say 'yes' and get some free sats from the failed payment (or\n via the hope of a successful payment from a capacity increase in the\n intervening milliseconds).\"\n\nSo C decides it's in his interest to keep the lie going. D, the payee,\ncan't tell that it's a lie when it reaches her.\n\nIf C did want to tattle, it's important that he be able to do so in a\nway that blames B instead of himself, otherwise payers will assume\n(incorrectly, and to C's detriment) that the liquidity deficit is with C\nrather than B.\n\nMaybe Joost's suggestion of using a simple reputation scheme would work."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-10-15T22:51:37",
                "message_text_only": "Good morning Owen,\n\n> C now notes that B is lying, but is faced with the dilemma:\n>\n> \"I could either say 'no' because I can plainly see that B is lying, or\n> I could say 'yes' and get some free sats from the failed payment (or\n> via the hope of a successful payment from a capacity increase in the\n> intervening milliseconds).\"\n\nNote that if B cannot forward an HTLC to C later, then C cannot have a failed payment and thus cannot earn any money from the upfront payment scheme; thus, at least that part of the incentive is impossible.\n\nOn the other hand, there is still a positive incentive for continuing the lie --- later, maybe the capacity becomes OK and C could earn both the upfront fee and the success fee.\n\n> So C decides it's in his interest to keep the lie going. D, the payee,\n> can't tell that it's a lie when it reaches her.\n>\n> If C did want to tattle, it's important that he be able to do so in a\n> way that blames B instead of himself, otherwise payers will assume\n> (incorrectly, and to C's detriment) that the liquidity deficit is with C\n> rather than B.\n\nThat is certainly quite possible to do.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Joost Jager",
                "date": "2021-10-19T07:20:50",
                "message_text_only": "There could be some corners where the incentives may not work out 100%, but\nI doubt that any routing node would bother exploiting this. Especially\nbecause there could always be that reputation scheme at the sender side\nwhich may cost the routing node a lot more in lost routing fees than the\nmarginal gain from the upfront payment.\n\nAnother option is that nodes that don't care to be secretive about their\nchannel balances could include the actual balance in a probe failed\nmessage. Related: https://github.com/lightningnetwork/lightning-rfc/pull/695\n\nOverall it seems that htlc-less probes are an improvement to what we\ncurrently have. Immediate advantages include a reduction of the load on\nnodes by cutting out the channel update machinery, better ux (faster\nprobes) and no locked up liquidity. On the longer term it opens up the\noption to charge for failed payments so that we finally have an answer to\nchannel jamming.\n\nZmnSCPxj, as first person to propose the idea (I think?), would you be\ninterested in opening a draft PR on the spec repository that outlines the\nnew message(s) that we'd need and continue detailing from there?\n\nJoost\n\nOn Sat, Oct 16, 2021 at 12:51 AM ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Owen,\n>\n> > C now notes that B is lying, but is faced with the dilemma:\n> >\n> > \"I could either say 'no' because I can plainly see that B is lying, or\n> > I could say 'yes' and get some free sats from the failed payment (or\n> > via the hope of a successful payment from a capacity increase in the\n> > intervening milliseconds).\"\n>\n> Note that if B cannot forward an HTLC to C later, then C cannot have a\n> failed payment and thus cannot earn any money from the upfront payment\n> scheme; thus, at least that part of the incentive is impossible.\n>\n> On the other hand, there is still a positive incentive for continuing the\n> lie --- later, maybe the capacity becomes OK and C could earn both the\n> upfront fee and the success fee.\n>\n> > So C decides it's in his interest to keep the lie going. D, the payee,\n> > can't tell that it's a lie when it reaches her.\n> >\n> > If C did want to tattle, it's important that he be able to do so in a\n> > way that blames B instead of himself, otherwise payers will assume\n> > (incorrectly, and to C's detriment) that the liquidity deficit is with C\n> > rather than B.\n>\n> That is certainly quite possible to do.\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211019/dd316d31/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-10-19T11:38:43",
                "message_text_only": "Good morning Joost,\n\n> There could be some corners where the incentives may not work out 100%, but I doubt that any routing node would bother exploiting this. Especially because there could always be that reputation scheme at the sender side which may cost the routing node a lot more in lost routing fees than the marginal gain from the upfront payment.\n>\n> Another option is that nodes that don't care to be secretive about their channel balances could include the actual balance in a probe failed message. Related:\u00a0https://github.com/lightningnetwork/lightning-rfc/pull/695\n>\n> Overall it seems that htlc-less probes are an improvement to what we currently have. Immediate advantages include a reduction of the load on nodes by cutting out the channel update machinery, better ux (faster probes) and no locked up liquidity. On the longer term it opens up the option to charge for failed payments so that we finally have an answer to channel jamming.\n\nOne can argue that if you are hoping that forwarding nodes will not exploit this, you can also hope that forwarding nodes will not perform channel-jamming attacks.\nAs I noted before, channel jamming attacks will never be performed by payers or payees --- they have an incentive to complete the transaction and earn gains from trade.\nChannel jamming attacks are performed by large forwarding nodes on their smaller competitors, since having 100 capacity on large versus 10 capacity on the smaller competitor is worse than having 89 capacity on the large versus 0 capacity on the smaller competitor.\n\nOn the other hand, perhaps it is at this point that we should start computing the exact incentives, hmm.\n\n--\n\nA thing to note is that any node along a path can disrupt an onion response by the simple expedient of XORing it with random stuff, or even just a non-0 constant.\nThis may allow for an additional attack vector.\n\nSuppose I am a forwarding node and I receive a probe request, and it turns out the next hop lacks capacity right now.\nI could incite the next hop to lie by forwarding the probe request to the next hop despite the lack of capacity.\n\nIf the next hop responds immediately, I can then corrupt the return onion.\nPresumably if the next hop responded immediately it was reporting my lie to the sender.\nBy corrupting the return onion the ultimate sender is unable to determine *which* node along the route failed, and I can hope that the reputation penalty to my competitor forwarding nodes along the path compensates for the reputation hit I personally suffer.\n\nIf the next hop takes some time before responding, then possibly it colluded with me to lie about the capacity on our channel (i.e. it actually went ahead and forwarded to the next hop despite knowing I lied).\nThen I could faithfully onion-encrypt the response and send it back to the ultimate sender.\n\n\nTo mitigate against the above attack:\n\n* If a forwarding node gets a probe request for an amount that the asker is *currently* unable to give anyway:\n  * The forwarding node should still forward the probe request.\n  * On response, however, it replaces the response with its own report that the previous hop was a dirty liar.\n  * Note that the asker is the one who has full control over their funds in the channel, so the asker cannot later claim \"but the network latency mixed up our messages!\" --- the asker knows when it does `update_add_htlc` to reduce its capacity, so it should know it has the capacity or not.\n\n\nNow, if we are going to add a message \"the previous hop was a dirty liar\" then we should ask if a forwarding node would want to make a false accusation.\n\n* Suppose the previous hop has sufficient capacity and asked us if we have our own capacity.\n* Does the current hop have any incentive to falsely accuse the previous hop?\n  * No: if it did, then the sender would not try their channel again in the close future, thus leading to lower fee earnings.\n\n\n> ZmnSCPxj, as first person to propose the idea (I think?), would you be interested in opening a draft PR on the spec repository that outlines the new message(s) that we'd need and continue detailing from there?\n\nIt might end up not happening given the stuff I juggle randomly, so feel free to start it.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Joost Jager",
                "date": "2021-10-15T14:29:47",
                "message_text_only": "On Fri, Oct 15, 2021 at 4:21 PM Owen Gunden <ogunden at phauna.org> wrote:\n\n> On Thu, Oct 14, 2021 at 09:48:27AM +0200, Joost Jager wrote:\n> > So how would things work out with a combination of both of the\n> > proposals described in this mail? First we make probing free (free as\n> > in no liquidity locked up) and then we'll require senders to pay for\n> > failed payment attempts too. Failed payment attempts after a\n> > successful probe should be extremely rate, so doesn't this fix the ux\n> > issue with upfront fees?\n>\n> Why couldn't a malicious routing node (or group of colluding routing\n> nodes) succeed the probe and then fail the payment in order to collect\n> the failed payment fee?\n>\n\nYes they could, but senders should be really suspicious when this happens.\nIt could happen occasionally because balances may have shifted in between\nprobe and payment. But if it keeps happening they may want to ban this\nrouting node for a long time. This may disincentivize the routing node\nenough to respond honestly to probes.\n\nJoost\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211015/a7713880/attachment.html>"
            },
            {
                "author": "Joost Jager",
                "date": "2021-10-21T08:33:55",
                "message_text_only": "A potential downside of a dedicated probe message is that it could be used\nfor free messaging on lightning by including additional data in the payload\nfor the recipient. Free messaging is already possible today via htlcs, but\na probe message would lower the cost to do so because the sender doesn't\nneed to lock up liquidity for it. This probably increases the spam\npotential. I am wondering if it is possible to design the probe message so\nthat it is useless for anything other than probing. I guess it is hard\nbecause it would still have that obfuscated 1300 bytes block with the\nremaining part of the route in it and nodes can't see whether there is\nother meaningful data at the end.\n\nOn Thu, Oct 14, 2021 at 9:48 AM Joost Jager <joost.jager at gmail.com> wrote:\n\n> A practice that is widely applied by lightning wallets is to probe routes\n> with an unknown payment hash before making the actual payment. Probing\n> yields an accurate routing fee that can be shown to the user before\n> execution of the payment.\n>\n> The downside of this style of probing is that for a short period of time,\n> liquidity is locked up. Not just the sender's liquidity, but also liquidity\n> of nodes along the route. And if the probe gets stuck for whatever reason,\n> that short period may become longer.\n>\n> But does this lock up serve a purpose at all? Suppose there would be a\n> liquidity probing protocol message similar to `update_add_htlc`\n> (`probe_htlc`?) that would skip the whole channel update machinery and is\n> only forwarded to the next hop if the link would be able to carry the htlc.\n> Won't this work as well as the current probing without the downsides? Nodes\n> can obviously reject these probes because they are distinguishable from\n> real payments (contrary to unknown hash probing where everything looks the\n> same). However if they do so, senders won't use that route and the routing\n> node misses out on routing fees.\n>\n> Another problem of the lightning network is its susceptibility to channel\n> jamming. Multiple options have been proposed (see also\n> https://github.com/t-bast/lightning-docs/blob/master/spam-prevention.md),\n> but they all come with downsides.\n>\n> Personally I incline towards solutions that involve deterring the attacker\n> by making them pay actual satoshis. Lightning itself is payment system and\n> it seems that paying for the payments is a natural solution to the problem.\n> Several iterations of this idea have been proposed. One of my own that\n> builds on an earlier idea by t-bast is described in\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-February/002958.html\n> .\n>\n> The main criticism that this proposal has received is that it deteriorates\n> the user experience for honest users when multiple payment routes need to\n> be attempted. Every attempt will have a cost, so the user will see its\n> balance going down by only just trying to make the payment. How bad this is\n> depends on the attempt failure rate. I expect this rate to become really\n> low as the network matures and senders hold routing nodes to high\n> standards. Others however think otherwise and consider a series of failed\n> attempts part of a healthy system.\n>\n> Custodial wallets could probably just swallow the cost for failures. They\n> typically use one pathfinding system for all their users and are therefore\n> able to collect a lot of information on routing node performance. This is\n> likely to decrease the payment failure rate to an acceptably low level.\n>\n> For non-custodial nodes, this may be different. They have to map out the\n> good routing nodes  all by themselves and this exploration will bear a cost.\n>\n> So how would things work out with a combination of both of the proposals\n> described in this mail? First we make probing free (free as in no liquidity\n> locked up) and then we'll require senders to pay for failed payment\n> attempts too. Failed payment attempts after a successful probe should be\n> extremely rate, so doesn't this fix the ux issue with upfront fees?\n>\n> Joost\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211021/2730142c/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-10-21T10:00:05",
                "message_text_only": "Good morning Joost,\n\n> A potential downside of a dedicated probe message is that it could be used for free messaging on lightning by including additional data in the payload for the recipient. Free messaging is already possible today via htlcs, but a probe message would lower the cost to do so because the sender doesn't need to lock up liquidity for it. This probably increases the spam potential. I am wondering if it is possible to design the probe message so that it is useless for anything other than probing. I guess it is hard because it would still have that obfuscated 1300 bytes block with the remaining part of the route in it and nodes can't see whether there is other meaningful data at the end.\n\nFor the probe, the onion max size does not *need* to be 1300, we could reduce the size to make it less useable for *remote* messaging.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Joost Jager",
                "date": "2021-10-21T12:55:30",
                "message_text_only": "On Thu, Oct 21, 2021 at 12:00 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Joost,\n>\n> > A potential downside of a dedicated probe message is that it could be\n> used for free messaging on lightning by including additional data in the\n> payload for the recipient. Free messaging is already possible today via\n> htlcs, but a probe message would lower the cost to do so because the sender\n> doesn't need to lock up liquidity for it. This probably increases the spam\n> potential. I am wondering if it is possible to design the probe message so\n> that it is useless for anything other than probing. I guess it is hard\n> because it would still have that obfuscated 1300 bytes block with the\n> remaining part of the route in it and nodes can't see whether there is\n> other meaningful data at the end.\n>\n> For the probe, the onion max size does not *need* to be 1300, we could\n> reduce the size to make it less useable for *remote* messaging.\n>\n\nYes, maybe it can be reduced a bit. But if we want to support 27 hops like\nwe do for payments, there will be quite some space left for messaging on\nreal routes which are mostly much shorter.\n\nJoost\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211021/ac8545c8/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-10-21T15:01:05",
                "message_text_only": "Good morning Joost,\n\n> On Thu, Oct 21, 2021 at 12:00 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n> > Good morning Joost,\n> >\n> > > A potential downside of a dedicated probe message is that it could be used for free messaging on lightning by including additional data in the payload for the recipient. Free messaging is already possible today via htlcs, but a probe message would lower the cost to do so because the sender doesn't need to lock up liquidity for it. This probably increases the spam potential. I am wondering if it is possible to design the probe message so that it is useless for anything other than probing. I guess it is hard because it would still have that obfuscated 1300 bytes block with the remaining part of the route in it and nodes can't see whether there is other meaningful data at the end.\n> >\n> > For the probe, the onion max size does not *need* to be 1300, we could reduce the size to make it less useable for *remote* messaging.\n>\n> Yes, maybe it can be reduced a bit. But if we want to support 27 hops like we do for payments, there will be quite some space left for messaging on real routes which are mostly much shorter.\n\nDoes six degrees of separation not apply for the LN?\nI assume it would --- presumably some mathist can actually check the actual network diameter?\n\nIn particular, forwarding nodes have an incentive to shorten the degree of separation, at least to popular nodes, by building channels to those, so I presume the degrees of separation will remain low.\nI expect something like 10 hops would work reasonably well...?\n\n(Longer routes greatly compound their expected failure rate as well, so no reasonable payer would prefer longer routes if a shorter route would do)\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "In-protocol liquidity probing and channel jamming mitigation",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Joost Jager",
                "Owen Gunden",
                "ZmnSCPxj"
            ],
            "messages_count": 13,
            "total_messages_chars_count": 27381
        }
    },
    {
        "title": "[Lightning-dev] c-lightning discord community",
        "thread_messages": [
            {
                "author": "lisa neigut",
                "date": "2021-10-19T12:11:01",
                "message_text_only": "FYI c-lightning now has a discord server for general questions, dev-chats,\nand community support.\n\nYou can join it here: https://discord.gg/WW56GGHavu\n\nWe're also still on Telegram at https://t.me/lightningd and IRC at\n#c-lightning on the libera.chat node.\n\n~nifty\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211019/5ff75c67/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "c-lightning discord community",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "lisa neigut"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 449
        }
    },
    {
        "title": "[Lightning-dev] Ask First, Shoot (PTLC/HTLC) Later",
        "thread_messages": [
            {
                "author": "Joost Jager",
                "date": "2021-10-21T07:28:42",
                "message_text_only": ">If it is a multipart and we have the preimage, wait for all the parts to\narrive, then say yes to all of them.\n\nWithout actual reservations made in the channels, is this going to work?\nFor example: a 10M payment and a route that contains a channel with only 5M\nbalance. The sender's multi-path algorithm will try to split and send the\nfirst 5M. Then they'll do the second 5M, but because there is no actual\nreservation, the second 5M seems to be passing alright through the\nbottleneck channel too. When the payment is then executed, it will fail.\n\nOr do nodes keep track of all the unresolved probes and deduct the total\namount from the available balance? Of course only for the available balance\nfor probes. When a real htlc comes through, outstanding probes are ignored.\nAlthough the problem with that could be that someone can spam you with\nprobes so that your available 'probe' balance is zero and you'll receive no\nreal traffic anymore.\n\nPerhaps an alternative is to let senders attach a random identifier to a\nprobe. For multi-part probes, each probe will carry the same identifier.\nRouting nodes will deduct the outstanding probe amounts from the available\nbalance, but only for probes within the same group (same id). That way each\nprobe(group) is isolated from everything else that is going on.\n\nJoost\n\nOn Wed, Sep 29, 2021 at 5:40 AM ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning list,\n>\n> While discussing something tangentially related with aj, I wondered this:\n>\n> > Why do we shoot an HTLC first and then ask the question \"can you\n> actually resolve this?\" later?\n>\n> Why not something like this instead?\n>\n> * For a payer:\n>   * Generate a path.\n>   * Ask first hop if it can resolve an HTLC with those specs (passing the\n> encrypted onion).\n>   * If first hop says \"yes\", actually do the `update_add_htlc` dance.\n>     Otherwise try again.\n> * For a forwarder:\n>   * If anybody asks \"can you resolve this path\" (getting an encrypted\n> onion):\n>     * Decrypt one layer to learn the next hop.\n>     * Check if the next hop is alive and we have the capacity towards it,\n> if not, answer no.\n>     * Ask next hop if it can resolve the next onion layer.\n>     * Return the response from the next hop.\n> * For a payee:\n>   * If anybody asks \"can you resolve this path\":\n>     * If it is not a multipart and we have the preimage, say yes.\n>     * If it is a multipart and we have the preimage, wait for all the\n> parts to arrive, then say yes to all of them.\n>     * Otherwise say no.\n>\n> Now, the most obvious reason against this, that comes to mind, is that\n> this is a potential DoS vector.\n> Random node can trigger a lot of network activity by asking random stuff\n> of random nodes.\n> Asking the question is free, after all.\n>\n> However, we should note that sending *actual* HTLCs is a similar DoS\n> vector **today**.\n> This is still \"free\" in that the asker has no need to pay fees for failed\n> HTLCs; they just lose the opportunity cost of the amount being locked up in\n> the HTLCs.\n> And presumably the opportunity cost is low since Lightning forwarding\n> earnings are so tiny.\n>\n> One way to mitigate against this is to make generating an onion costly but\n> validating and decrypting it cheap.\n> We could use an encryption scheme that is more computationally expensive\n> to encrypt but cheap to decrypt, for example.\n> Or we could require proof-of-work on the onion: each unwrapped onion\n> layer, when hashed, has to have a hash that is less than some threshold\n> (this scales according to the number of hops in the onion, as well).\n> Ultimate askers need to grind the shared secret until the onion layer hash\n> achieves the target.\n>\n> Obviously just because you asked a few milliseconds ago if a path is\n> viable does not mean that the path *remains* viable right now when you\n> actually send out an HTLC, but presumably that risk is now lessened.\n> Unexpected shutdowns or loss of connectivity has to appear in a smaller\n> and shorter time frame to negatively affect intermediate nodes.\n>\n> Another thought is: Does the forwarding node have an incentive to lie?\n> Suppose the next hop is alive but the forwarding node has insufficient\n> capacity towards the next hop.\n> Then the forwarding node can lie and claim it can still resolve the HTLC,\n> in the hope that a few milliseconds later, when the actual HTLC arrives,\n> the capacity towards the next hop has changed.\n> Thus, even if the capacity now is insufficient, the forwarding node has an\n> incentive to lie and claim sufficient capacity.\n>\n> Against the above, we can mitigate this by accepting \"no\" from *any* node\n> along the path, but only accepting \"yes\" from the actual payee.\n> We already have a mechanism where any node along a route can report a\n> forwarding or other payment error, and the sender is able to identify which\n> node along the path raised it.\n> Thus, the payer can identify which node along the route responded with a\n> \"yes\", and check that it definitely reached the payee.\n> Presumably, when a node receives a question, it checks if the asking node\n> has sufficient capacity towards it first, and if not, fails the channel\n> between them, since obviously the asking node is not behaving according to\n> protocol and is buggy.\n>\n> Now, this can be used to probe capacities, for free, but again --- we\n> already *have* probing capacities, for free, today, by just using random\n> hashes.\n>\n>\n>\n> Why is this advantageous at all?\n>\n> One reason for doing this is that it improves payment latency.\n> Some paths *will* fail, because there is no single consistent view of the\n> network and its capacity (which is impossible due to others also possibly\n> sending out via the same forwarding nodes you are using, and besides, even\n> if such a view could be made to exist, it would be dangerously\n> anti-privacy).\n> This mechanism does not require that intermediate nodes respond with a\n> signature and wait for a replied signature *before* they forward the onion\n> to the next hop; when they are *just* asking, there is no HTLC involved, no\n> updates to the channel state, and the question can be forwarded as soon as\n> we can check locally.\n> Further, in the current mechanism where we shoot HTLCs first and ask\n> questions later, failures also require 1.5 roundtrips due to sharing\n> signatures; with the \"just ask first\" phase there is no need for round\n> trips to respond to questions.\n>\n> Basically, we replace multiple round trips per hop in case of a failure\n> along a route, with a single large round trip from the payer to the failure\n> point.\n> In case of a success we just add more latency, but as we move to more\n> multipath payments, perhaps it becomes more advantageous, since the\n> probability of a particular sub-path failing is now higher?\n>\n> More importantly, by allowing to ask first, we reduce the probability that\n> HTLCs made in good faith --- i.e. those that are fully intended to reach a\n> destination and be resolved --- it may now be more palatable to charge for\n> failing actual HTLCs.\n> Since we expect that HTLC failures due to a node or channel failing along\n> the way is lessened compared to today, because the sender *asks* first\n> before *shooting* the HTLC, then the effect of charging for failing\n> *actual* HTLCs is lessened, possibly to a more acceptable level.\n>\n>\n> So, to lightning-dev --- is this a decent idea at all?\n> Note that in particular this is something that requires a whole-network\n> upgrade, as intermediate nodes have to upgrade as well.\n>\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211021/aac2de10/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Ask First, Shoot (PTLC/HTLC) Later",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Joost Jager"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 7944
        }
    }
]