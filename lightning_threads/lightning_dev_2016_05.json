[
    {
        "title": "[Lightning-dev] Fwd: Re: Routing & Beacons",
        "thread_messages": [
            {
                "author": "laurentmt",
                "date": "2016-05-01T16:26:50",
                "message_text_only": "Thanks for the information. Indeed, it raises questions but this is\nexactly why I find the subject so interesting :)\n\nWRT the update of routing tables, let me try to summarize my\nunderstanding with this scenario:\n\n1/ Landmark nodes periodically send a message to their neighbours (every\n30s ?). This message initiates a new temporal frame (symbolized by\ncounter embedded in the message and sequentially increased by the\nlandmark node).\n2/ When a node receives the first message associated to a new temporal\nframe for a given landmark, it waits for a delay before forwarding the\nmessage to its own neighbours (it gives a chance to receive the same\nmessage from a better route).\nAfter this delay has elapsed, the node computes the best route to the\nlandmark node and forward the message (information defining the temporal\nframe + best route to landmark node) to its neighbours.\n3/ Every node repeats the same process (step 2).\n\nWhen the process has completed, every node knows the best route to/from\na given landmark.\nWhen a node needs to send a payment, the receiver sends her its best\nroutes to each landmark node. Therefore the sender is able to compute\nthe best route to reach the receiver and onion routing is possible.\n\nRandom remarks / questions:\n\n- Agreed that the \"base+per-satoshi\" fee model creates a difficulty to\ndefine the best route.\n  I don't know if I'm right, but I see the base fee as a way to say \"I\ndon't want to transfer amounts lower than X satoshis\" (the base fee\nmakes them economically unviable).\n  So, as you wrote, a solution may be a set of nominal values and the\nforwarding of a set of best routes (a route for each range of amounts\nbetween 2 nominal values).\n\n- A shower thought: with this model, fees seem conceptually associated\nto the node and there's no distinction related to the direction of the\npayment (sending or receiving).\n  A different model would be to associate fees to individual payment\nchannels (with a different fee defined for sending and receiving on this\nchannel).\n  It means that for a given landmark, a node would forward 2 best routes\n(for sending/receiving payments to/from the landmark).\n  That may be useful to cope with unbalanced channels because it allows\nthe node to signal that, for instance, it's ok to receive payments on a\ngiven route but sending payments is not encouraged.\n\n- Would it be useful to have simulations ? (that may be an interesting\nside project on my hand).\n\nlaurent\n\nLe 26/04/2016 02:43, Rusty Russell a \u00e9crit :\n> laurentmt <laurentmt145 at gmail.com> writes:\n>> Hi Rusty,\n>>\n>> If I'm correct, it means that on a given period all payments go through\n>> the selected beacons nodes ?\n> \n> To a first approximation, yes (obviously, if the route would go in and\n> out the same channel, it can be eliminated, but that's statistically\n> unlikely for a well-connected beacon).\n> \n> BTW, the literature seems to use the term \"landmarks\", so I'm trying to stop\n> saying \"beacons\" :)\n> \n>> I ask this because some protocols like the pulse protocol are also based\n>> on beacons to update the routing tables but they don't require that all\n>> \"messages\" go through the beacons. \"Messages\" go through the first\n>> common ancestor of source and target in the spanning tree associated to\n>> the selected beacon.\n>>\n>> The main drawback with this approach is that the source doesn't know the\n>> route beforehand... The main advantage is that it puts less \"pressure\"\n>> on the beacons.\n> \n> Yes, I'd really like something better, but the beacon/landmark idea is\n> simple, enables a one-pass communication for the route (here's a QR code\n> on how to reach me from N landmarks), and doesn't require the receiver\n> to know the buyer's location.\n> \n>> Another question: have you already decided on an update strategy for the\n>> routing tables?\n> \n> No, I haven't.  Thoughts welcome :)\n> \n>> As I understand the problem, there's 2 variables which determine the\n>> best route:\n>>\n>> - capacity of channels at time t (max number of bitcoins I can transfer\n>> through a given channel). It determines if a route can be used to\n>> transfer the amount.\n>>\n>> - fees charged by nodes. It determines the best route.\n>>\n>> Capacity is likely the most dynamic of the two variables. Do you\n>> consider capacity as an information stored in the routing tables (but it\n>> may be very challenging to keep tables up to date) or is it checked \"in\n>> live\" when the payment is propagated ?\n> \n> My base assumption is that payments are generally smaller than channel\n> capacity, i.e. micropayments.  Also, the route map itself is fairly\n> static, and in fact could be fully known to a node: the pricing\n> information is dynamic and needs careful thought.\n> \n> You want a payment to Just Work most of the time; getting routefails and\n> forcing retries should be unusual.\n> \n> My current idea (beyond a prototype where every node chats on IRC\n> indicating their current routes and prices) is that:\n> \n> 1) Prices are indicated as base + per-satoshi cost.\n> 2) Nodes are ratelimited on their pricing updates (say, once every 30\n>    seconds, perhaps with some burst capacity).\n> \n> I'm also considering that price changes phase in over time, indicating\n> how they change over time from some base (eg. \"increase by .01 satoshi\n> every second from X until Y\").  My concern is that slight price changes\n> may cause massive changes in terms of traffic (once a parallel route\n> becomes cheaper), so that makes sense.  Some ratelimiting is definitely\n> necessary because competition may well cause such route-flap.\n> \n> And note that base+per-satoshi means \"best route\" selection depends on\n> the value you're sending, so a handful of nominal values are probably\n> required (so there may be different \"best routes\" for each one).\n> \n> There's also the question of how to handle false advertising.  Ideally,\n> you should be able to broadcast the response from a node which refuses\n> to route your payment.  That gets a little complicated with onioning: it\n> would have to sign the hash of the onion, HTLC and the routefail\n> message, which would be checked by the previous node and encrypted,\n> onioned all the way back to the source.  If one node signs a invalid\n> message, that can be broadcast and the node blacklisted.  The sender can\n> reveal the onion at that point and the decode key, and show that the\n> node refused to route.  It can then be temporarily blacklisted.\n> \n> Sorry if this raises more questions than answers!\n> \n> Cheers,\n> Rusty.\n>"
            },
            {
                "author": "Rusty Russell",
                "date": "2016-05-02T23:27:56",
                "message_text_only": "laurentmt <laurentmt145 at gmail.com> writes:\n> Thanks for the information. Indeed, it raises questions but this is\n> exactly why I find the subject so interesting :)\n>\n> WRT the update of routing tables, let me try to summarize my\n> understanding with this scenario:\n>\n> 1/ Landmark nodes periodically send a message to their neighbours (every\n> 30s ?). This message initiates a new temporal frame (symbolized by\n> counter embedded in the message and sequentially increased by the\n> landmark node).\n\nTechnically, the landmark would ve a channel; it's just easier to select\non that basis (since channels exist in the blockchain, you can prove it\nexisted prior to landmark selection).\n\nBut your idea of temporal framing is new to me.\n\nI had considered that we simply limit a single hop to advertising every\n30 seconds, and you only re-broadcast if it's the best.  That requires\nmaintaining a little state for each hop you rebroadcast.\n\n> 2/ When a node receives the first message associated to a new temporal\n> frame for a given landmark, it waits for a delay before forwarding the\n> message to its own neighbours (it gives a chance to receive the same\n> message from a better route).\n\nHmm, I'm not sure how to calibrate that delay though?  If everyone is\ndelaying it's not clear that you'll hear about the better route, is it?\n\n> After this delay has elapsed, the node computes the best route to the\n> landmark node and forward the message (information defining the temporal\n> frame + best route to landmark node) to its neighbours.\n> 3/ Every node repeats the same process (step 2).\n>\n> When the process has completed, every node knows the best route to/from\n> a given landmark.\n> When a node needs to send a payment, the receiver sends her its best\n> routes to each landmark node. Therefore the sender is able to compute\n> the best route to reach the receiver and onion routing is possible.\n\ns/to each landmark/from each landmark/\n\n> Random remarks / questions:\n>\n> - Agreed that the \"base+per-satoshi\" fee model creates a difficulty to\n> define the best route.\n>   I don't know if I'm right, but I see the base fee as a way to say \"I\n> don't want to transfer amounts lower than X satoshis\" (the base fee\n> makes them economically unviable).\n>   So, as you wrote, a solution may be a set of nominal values and the\n> forwarding of a set of best routes (a route for each range of amounts\n> between 2 nominal values).\n\nYes, I think so.\n\n> - A shower thought: with this model, fees seem conceptually associated\n> to the node and there's no distinction related to the direction of the\n> payment (sending or receiving).\n>   A different model would be to associate fees to individual payment\n> channels (with a different fee defined for sending and receiving on this\n> channel).\n\nYes; if landmarks are channels, then I think it falls out naturally.\n\nThere's a related question on how fees are collected: simplest is that\nthe node pushing the HTLC into the channel collects the fee.  This\nimplies that they unilaterally set the fee for that direction.\n\nBut I wonder about weird fee games where one side charges far more than\nthe other; are they completely independent or do they negotiate?  My gut\nfeeling is that it all works out: if the You->Me direction is popular\ntoday and you're making a mint, I'll be doing well from the Me->next-hop\nchannels too.\n\n>   It means that for a given landmark, a node would forward 2 best routes\n> (for sending/receiving payments to/from the landmark).\n>   That may be useful to cope with unbalanced channels because it allows\n> the node to signal that, for instance, it's ok to receive payments on a\n> given route but sending payments is not encouraged.\n\nDefinitely need asymmetry for balancing.\n\n> - Would it be useful to have simulations ? (that may be an interesting\n> side project on my hand).\n\nThis could well offer some insight.\n\nAnthony Towns (added to To) did some simulations, but other than a\nsimple YouTube video I'm not aware of any published results.\n\nCheers,\nRusty."
            },
            {
                "author": "laurentmt",
                "date": "2016-05-04T16:00:46",
                "message_text_only": "Le 03/05/2016 01:27, Rusty Russell a \u00e9crit :\n> laurentmt <laurentmt145 at gmail.com> writes:\n>> Thanks for the information. Indeed, it raises questions but this is\n>> exactly why I find the subject so interesting :)\n>>\n>> WRT the update of routing tables, let me try to summarize my\n>> understanding with this scenario:\n>>\n>> 1/ Landmark nodes periodically send a message to their neighbours (every\n>> 30s ?). This message initiates a new temporal frame (symbolized by\n>> counter embedded in the message and sequentially increased by the\n>> landmark node).\n> \n> Technically, the landmark would ve a channel; it's just easier to select\n> on that basis (since channels exist in the blockchain, you can prove it\n> existed prior to landmark selection).\n> \n> But your idea of temporal framing is new to me.\n\nActually, the process described in my previous message is directly\ninspired from the Pulse Protocol I was citing in my first email (a\n\"pulse\" is the periodic message sent by landmark nodes to update routing\ntables). While this protocol was designed for a very different goal\n(routing on \"multi-hop wireless infrastructures\"), there may be\ninteresting ideas for LN routing. This paper\n(http://www.cs.jhu.edu/~dholmer/600.647/papers/pulse_infrastructure_access.pdf)\nshould be much better than explanations sent with my crappy english. :D\n\n> \n> I had considered that we simply limit a single hop to advertising every\n> 30 seconds, and you only re-broadcast if it's the best.  That requires\n> maintaining a little state for each hop you rebroadcast.\n> \n>> 2/ When a node receives the first message associated to a new temporal\n>> frame for a given landmark, it waits for a delay before forwarding the\n>> message to its own neighbours (it gives a chance to receive the same\n>> message from a better route).\n> \n> Hmm, I'm not sure how to calibrate that delay though?  If everyone is\n> delaying it's not clear that you'll hear about the better route, is it?\n> \n\nAgreed. Another constraint is related to the topology of the network\n(more especially to its diameter). Time required to propagate the\nmessage to the full network should be much lower than the period of the\nmechanism (30s).\n\nThere's clearly a trade-off to be made. Delay should be long enough to\nmaximize the probability that you hear about the best route but short\nenough to ensure fast propagation of the message across the network.\n\n\n>> After this delay has elapsed, the node computes the best route to the\n>> landmark node and forward the message (information defining the temporal\n>> frame + best route to landmark node) to its neighbours.\n>> 3/ Every node repeats the same process (step 2).\n>>\n>> When the process has completed, every node knows the best route to/from\n>> a given landmark.\n>> When a node needs to send a payment, the receiver sends her its best\n>> routes to each landmark node. Therefore the sender is able to compute\n>> the best route to reach the receiver and onion routing is possible.\n> \n> s/to each landmark/from each landmark/\n\nYes ! The route to the landmark wouldn't be very useful :)\n\n> \n>> Random remarks / questions:\n>>\n>> - Agreed that the \"base+per-satoshi\" fee model creates a difficulty to\n>> define the best route.\n>>   I don't know if I'm right, but I see the base fee as a way to say \"I\n>> don't want to transfer amounts lower than X satoshis\" (the base fee\n>> makes them economically unviable).\n>>   So, as you wrote, a solution may be a set of nominal values and the\n>> forwarding of a set of best routes (a route for each range of amounts\n>> between 2 nominal values).\n> \n> Yes, I think so.\n> \n>> - A shower thought: with this model, fees seem conceptually associated\n>> to the node and there's no distinction related to the direction of the\n>> payment (sending or receiving).\n>>   A different model would be to associate fees to individual payment\n>> channels (with a different fee defined for sending and receiving on this\n>> channel).\n> \n> Yes; if landmarks are channels, then I think it falls out naturally.\n> \n> There's a related question on how fees are collected: simplest is that\n> the node pushing the HTLC into the channel collects the fee.  This\n> implies that they unilaterally set the fee for that direction.\n> \n> But I wonder about weird fee games where one side charges far more than\n> the other; are they completely independent or do they negotiate?  My gut\n> feeling is that it all works out: if the You->Me direction is popular\n> today and you're making a mint, I'll be doing well from the Me->next-hop\n> channels too.\n> \n\nInteresting. My initial thought was that each side of a channel may\ncharge a fee for the use of the channel because it allows each one to\nsignal its (dis)agreement for the use of the channel in a specific\ndirection.\n\nBut it makes the implementation more complex and your observation\nhighlights that it can be achieved differently. For instance, if I\npropose the unbalanced route (Me-->You), you may signal your\n\"disagreement\" by deciding to charge a higher fee for the next hop and\nin some cases it may lead you to forward another route as the best route.\n\n\n>>   It means that for a given landmark, a node would forward 2 best routes\n>> (for sending/receiving payments to/from the landmark).\n>>   That may be useful to cope with unbalanced channels because it allows\n>> the node to signal that, for instance, it's ok to receive payments on a\n>> given route but sending payments is not encouraged.\n> \n> Definitely need asymmetry for balancing.\n> \n>> - Would it be useful to have simulations ? (that may be an interesting\n>> side project on my hand).\n> \n> This could well offer some insight.\n> \n> Anthony Towns (added to To) did some simulations, but other than a\n> simple YouTube video I'm not aware of any published results.\n>\n> Cheers,\n> Rusty.\n> \n\nlaurent"
            }
        ],
        "thread_summary": {
            "title": "Fwd: Re: Routing & Beacons",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "laurentmt"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 16293
        }
    },
    {
        "title": "[Lightning-dev] Oversize preimage attack.",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2016-05-02T05:07:22",
                "message_text_only": "Hi all!\n\n   I'm about to modify the HTLC scripts for the first time in a while to\nprepend: \"OP_SIZE 32 OP_EQUALVERIFY\".  It means that even timing out an\nHTLC requires a 32 byte value (say, all-zeroes), but it's the simplest\nand shortest change.\n\n   Without this, the length of a scriptsig which redeems a transaction\nwas ill-defined.  The wire protocol requires a 32-byte R preimage to\nredeem a HTLC, but there was no such on-chain restriction.  An attacker\ncould create an HTLC which requires a different-size preimage to redeem,\nthen drop the commit tx to the blockchain and redeem it.  A node\ncouldn't use that preimage via the wire protocol.\n\n   Or require a 110k preimage to redeem, drop to the blockchain, then\nredeem it by sending direct to a miner.  A node trying to use that\npreimage would create a non-standard transaction, which may not\npropagate.  Similarly with an almost 4MB preimage which requires you\nto grind out a tiny signature to redeem in a tx small enough...\n\n   I'm also dropping the per-side HTLC limit from 1500 to 450 in BOLT\n#2.  This means that a single \"steal\" transaction which spends all the\ninputs is still under 400k cost (thanks segwit!), simplifying the\nprotocol.\n\nCheers,\nRusty."
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2016-05-02T21:48:19",
                "message_text_only": ">\n>  Or require a 110k preimage to redeem, drop to the blockchain, then\n> redeem it by sending direct to a miner.  A node trying to use that\n> preimage would create a non-standard transaction, which may not\n> propagate.  Similarly with an almost 4MB preimage which requires you\n> to grind out a tiny signature to redeem in a tx small enough...\n>\n\nSegwit's witness program validation logic ensures that each element of the\npassed witness stack is less-than-or-equal-to the maximum script element\nsize (520 bytes). This check is enforced before execution itself.\nTherefore, even without the additional OP_SIZE check, Script will enforce a\nceiling on the pre-image size.\n\nWe've also recently made such an observation, resulting in a modification\nto our scripts similar to the one you've detailed. Thanks for sounding the\nalarm with this mailing-list post!\n\nBest,\nLaolu\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20160502/fef7092a/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2016-05-02T23:39:10",
                "message_text_only": "Olaoluwa Osuntokun <laolu32 at gmail.com> writes:\n>>  Or require a 110k preimage to redeem, drop to the blockchain, then\n>> redeem it by sending direct to a miner.  A node trying to use that\n>> preimage would create a non-standard transaction, which may not\n>> propagate.  Similarly with an almost 4MB preimage which requires you\n>> to grind out a tiny signature to redeem in a tx small enough...\n>>\n>\n> Segwit's witness program validation logic ensures that each element of the\n> passed witness stack is less-than-or-equal-to the maximum script element\n> size (520 bytes). This check is enforced before execution itself.\n> Therefore, even without the additional OP_SIZE check, Script will enforce a\n> ceiling on the pre-image size.\n\nRight!  I'd missed MAX_SCRIPT_ELEMENT_SIZE, thanks.\n\n> We've also recently made such an observation, resulting in a modification\n> to our scripts similar to the one you've detailed. Thanks for sounding the\n> alarm with this mailing-list post!\n\nHmm, are there any other issues you've come across?  Every time I find\nsomething like this I worry what else we've missed :(\n\nThanks!\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Oversize preimage attack.",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Olaoluwa Osuntokun"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 3383
        }
    },
    {
        "title": "[Lightning-dev] Channel refill",
        "thread_messages": [
            {
                "author": "Kumaigorodskiy Anton",
                "date": "2016-05-09T16:45:07",
                "message_text_only": "As far as I understand LN has some edge cases such as:\n\n-- one can't receive a single payment which is larger than what is currently locked in a channel (this is the most limiting one). -- a variation of the first case: one can issue a large number of small invoices which in total exceed current channel capacity so not all of them could be paid. -- obviously one can't make payments once their side of channel balance reaches zero. \n\nThe answer currently is to just open another channel (or transfer bitcoins directly) but what if \"channel refill\" procedure could be implemented? \n\nIt could work almost as \"open anchor\" procedure but not quite: -- the same pair of commit_key's is used resulting in a second utxo on anchor address. -- a separate \"refill commitment tx\" is created which does not invalidate current \"main commitment tx\". -- once on-chain refill tx reaches required depth a new \"main commitment tx\" is created which takes into account new utxo and old \"main commitment tx\" as well as \"refill commitment tx\" are invalidated. \n\nOne advantage of refill over new channel creation is that overall channel capacity would grow each time so after a number of refills no more of them may be needed for a long time. \t\t \t   \t\t  \n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20160509/69000807/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2016-05-09T20:30:54",
                "message_text_only": "Kumaigorodskiy Anton <anton.kumaigorodskiy at outlook.com> writes:\n> As far as I understand LN has some edge cases such as:\n>\n> -- one can't receive a single payment which is larger than what is currently locked in a channel (this is the most limiting one). -- a variation of the first case: one can issue a large number of small invoices which in total exceed current channel capacity so not all of them could be paid. -- obviously one can't make payments once their side of channel balance reaches zero. \n>\n> The answer currently is to just open another channel (or transfer bitcoins directly) but what if \"channel refill\" procedure could be implemented? \n>\n> It could work almost as \"open anchor\" procedure but not quite: -- the same pair of commit_key's is used resulting in a second utxo on anchor address. -- a separate \"refill commitment tx\" is created which does not invalidate current \"main commitment tx\". -- once on-chain refill tx reaches required depth a new \"main commitment tx\" is created which takes into account new utxo and old \"main commitment tx\" as well as \"refill commitment tx\" are invalidated. \n>\n> One advantage of refill over new channel creation is that overall channel capacity would grow each time so after a number of refills no more of them may be needed for a long time. \t\t \t   \t\t  \n\nYes, this definitely a good idea.  I've been calling it \"re-anchoring\",\nas it's more general than refilling the channel.  The new funding\ntransaction would spend the old one, plus some additional input(s).\n\nFor the duration, signatures are provided for both the old funding\ntransaction and the new one.  When the new one is deep enough, the old\nsignatures can be dropped.\n\nThis is also how you would pay non-lightning bitcoin addresses: the new\nfunding transaction spends the old one, has one output to the address\nand one to the 2of2.\n\nI imagine reanchoring will be the first extension once we get the basics\nsorted out.\n\nThanks!\nRusty."
            },
            {
                "author": "mr. gnosteek",
                "date": "2016-05-10T04:48:38",
                "message_text_only": "dear all forward thinking who are near Ukraine,\nthere gonna be the meeting with Lightning team this Thursday in Kyiv!!!\n\n2016-05-09 23:30 GMT+03:00 Rusty Russell <rusty at rustcorp.com.au>:\n\n> Kumaigorodskiy Anton <anton.kumaigorodskiy at outlook.com> writes:\n> > As far as I understand LN has some edge cases such as:\n> >\n> > -- one can't receive a single payment which is larger than what is\n> currently locked in a channel (this is the most limiting one). -- a\n> variation of the first case: one can issue a large number of small invoices\n> which in total exceed current channel capacity so not all of them could be\n> paid. -- obviously one can't make payments once their side of channel\n> balance reaches zero.\n> >\n> > The answer currently is to just open another channel (or transfer\n> bitcoins directly) but what if \"channel refill\" procedure could be\n> implemented?\n> >\n> > It could work almost as \"open anchor\" procedure but not quite: -- the\n> same pair of commit_key's is used resulting in a second utxo on anchor\n> address. -- a separate \"refill commitment tx\" is created which does not\n> invalidate current \"main commitment tx\". -- once on-chain refill tx reaches\n> required depth a new \"main commitment tx\" is created which takes into\n> account new utxo and old \"main commitment tx\" as well as \"refill commitment\n> tx\" are invalidated.\n> >\n> > One advantage of refill over new channel creation is that overall\n> channel capacity would grow each time so after a number of refills no more\n> of them may be needed for a long time.\n>\n> Yes, this definitely a good idea.  I've been calling it \"re-anchoring\",\n> as it's more general than refilling the channel.  The new funding\n> transaction would spend the old one, plus some additional input(s).\n>\n> For the duration, signatures are provided for both the old funding\n> transaction and the new one.  When the new one is deep enough, the old\n> signatures can be dropped.\n>\n> This is also how you would pay non-lightning bitcoin addresses: the new\n> funding transaction spends the old one, has one output to the address\n> and one to the 2of2.\n>\n> I imagine reanchoring will be the first extension once we get the basics\n> sorted out.\n>\n> Thanks!\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20160510/43505474/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Channel refill",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Kumaigorodskiy Anton",
                "mr. gnosteek"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 5959
        }
    },
    {
        "title": "[Lightning-dev] BOLT #2: wire protocol: YA acknowledgement change.",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2016-05-17T07:06:37",
                "message_text_only": "\"This time for sure!\"\n\nOK, there's another revision to the 02-wire-protocol.md draft; this time\nI implemented a protocol simulator to make sure it's reasonable.  As a\nbonus, it spits out timing diagrams!\n\nThe summary is that we don't need acknowledgement numbers; the\nrevocation reply gives us everything we need.  The draft expresses it in\nterms of local & remote commitment transactions, and acked and non-acked\nchangesets for both.\n\nBasically, the revocation reply is the moment at which you add incoming\nchanges (\"unacked\") to the other side (as \"acked\").  It seems to work\npretty well in all the corner cases, and it's wire-optimal AFAICT.\n\nI've aimed for a layman's writeup here:\n\n  https://medium.com/@rusty_lightning/lightning-inter-node-protocol-a-primer-c642816c8b8#.8skw6hfar\n\nThe spec is here:\n\nhttps://github.com/rustyrussell/lightning-rfc/blob/master/bolts/02-wire-protocol.md\n\nAnd tests are here:\n\n  https://github.com/ElementsProject/lightning/blob/test-protocol/test/test_protocol.c\n  https://github.com/ElementsProject/lightning/tree/test-protocol/test/commits\n\nFeedback certainly welcome!\nRusty."
            },
            {
                "author": "Pierre",
                "date": "2016-05-18T17:46:44",
                "message_text_only": "I like it! Let's hope it will suit everyone and we can converge on\nsomething soon.\n\nFWIW I was able to independently implement a toy version of the\nprotocol and pass your scripted tests [*] so I guess there are no\nobvious issues (duh). Maybe it could be the first step towards a LN\nnonreg test set?\n\nJust one thing about the \"nocommitwait\", I wonder why you make it\noptional in your test: why would you forbid the sending of two\nsuccessive commits, given that the more permissive approach is\nperfectly well defined?\n\nCheers,\nPierre\n\nPS: what does YA mean?\n\n[*] For those interested:\nhttps://gist.github.com/pm47/0c87329dbc5d43d35857e5ba3a20400c"
            },
            {
                "author": "Rusty Russell",
                "date": "2016-05-23T21:26:00",
                "message_text_only": "Pierre <pm+lists at acinq.fr> writes:\n> I like it! Let's hope it will suit everyone and we can converge on\n> something soon.\n>\n> FWIW I was able to independently implement a toy version of the\n> protocol and pass your scripted tests [*] so I guess there are no\n> obvious issues (duh). Maybe it could be the first step towards a LN\n> nonreg test set?\n\nGreat!  That's a really good idea.  Eventually I'd like to have some\n\"canned conversations\" to go with the BOLTs for testing against.\n\n> Just one thing about the \"nocommitwait\", I wonder why you make it\n> optional in your test: why would you forbid the sending of two\n> successive commits, given that the more permissive approach is\n> perfectly well defined?\n\nBecause it's a little simpler if you don't let yourself do multiple\nin-flight commits.  You only need one set of outstanding changes, rather\nthan keeping them for every commit.  This code makes doubly-sure that is\ntrue (it is true in my C implementation).\n\n> PS: what does YA mean?\n\nYet Another.  I found a pretty good description on Wikipedia:\n\n  Among programmers, yet another (often abbreviated ya, Ya or YA in the\n  initial part of an acronym) is an idiomatic qualifier in the name of a\n  computer program, organisation, or event that is confessedly\n  unoriginal.\n\n  Stephen C. Johnson is credited with establishing the naming convention\n  in the late 1970s when he named his compiler-compiler yacc (Yet\n  Another Compiler-Compiler), since he felt there were already numerous\n  compiler-compilers in circulation at the time.\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "BOLT #2: wire protocol: YA acknowledgement change.",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Pierre"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 3313
        }
    },
    {
        "title": "[Lightning-dev] Updated commitment design + Release thunder.network",
        "thread_messages": [
            {
                "author": "Mats Jerratsch",
                "date": "2016-05-17T13:58:17",
                "message_text_only": "Hey everybody,\n\nUsing SegWit, I thought of a more elegant way to solve the coupling problem between revocation delay and payment timeouts. ( https://lists.linuxfoundation.org/pipermail/lightning-dev/2015-November/000339.html and following)\n\nA basic schema with one included payment can be seen here:\n\nhttps://raw.githubusercontent.com/blockchain/thunder/master/docs/dual-tx-diagram.png\n\nThe idea is that each payment and each refund does not directly pay to their respective owner, but to a intermediate 2-of-2 transaction. For redeeming a payment, one has to also use R to broadcast Redeem-TX, for broadcasting Refund-TX one has to wait the agreed refund time. Having broadcasted the additional transaction, one basically *secured* the funds, under the premise that one has not cheated by using an old commitment transaction. If he did cheated though, the other party can claim all funds directly from the commitment outputs or from the Redeem-TX outputs.\n\nThis makes it possible to set revocation delay and payment timeouts to completely separate values (if it is not obvious why this was not possible before, I suggest reading the thread linked above).\n\nNow there are two downsides to this approach:\n\n(1) Clearing a payment on the blockchain is more expensive. Because we have an additional transaction for each payment, fees for redeeming the payment are higher. One has to take into account the fee for the additional transaction when producing the outputs for the commitment transaction. However, as most channels will not get settled on the blockchain anyways, this is a minor issue.\n\n(2) Updating the commitment transaction, one has produce and send a new signature for each currently included payment. For channels that have lots of uncleared payments for a long time this might be problematic, however, uncleared payments are undesirable for many reasons and adding disincentives for delaying the clearing process is on the TODO anyways.\n\nHowever, having a clean solution to the problem of high refund times (>30d) and low revocation times (<3d) is more important in the long run. \n\nThis means adding a few more fields to the way a new commitment status is negotiated, you can see the full exchange thunder is using here:\nhttps://github.com/matsjj/lightning/blob/master/communications/high/%5BTN%5DPaymentNegotiation.md\n\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n\nAlso, following the tradition of the other releases here on the mailing list I like to bring it over here more formally.\n\nthunder.network is a full lightning network implementation, based on my ongoing development for the past 15 months. The software is now at a point where it can be actively used and also integrated into other projects. If you have not tried the wallet out and made a basic payment, feel invited to start up two instances and try it out. \n\nThe implementation already uses CSV and will utilize SegWit (in progress). It\u2019s a small change, about 250 LoC[1]. The intention is to build as trustless a system as possible. SegWit was not prioritized any higher than it is since it will be awhile before it can be utilized for any mainnet system. \n\nThis release contains two executables, a node and a wallet, and they both use the same library. \nThe node is a passive participant of the network. On startup the user can specify which nodes to build payment channels with. It will broadcast its existence into the network, such that other peers can also build payment channels with it. If you do want to start up the node, make sure you forwarded port 2204, such that you can receive incoming connections.\n\nThe wallet is the counterpart, an active participants. The wallet is used to make and receive payments, but it will not broadcast its existence. Once we have RP routing sorted out, it will not broadcast anything anymore (for routing it still broadcasts any payment channel it has). It also provides some GUI as an example and for easier usage. \n\nBy default wallet and nodes do not communicate with the bitcoin network yet, as this makes it easier to debug and to try out. If you want to use testcoins, toggle the setting in Constants. Also, if you do want to see which messages are sent under the hood, toggle EncryptionProcessorImpl.OUTPUT_MESSAGE.\n\n\nBoth, Node and Wallet software can be downloaded at\nhttps://github.com/blockchain/thundernetwork/releases\n\nFurther information can be found at\nhttps://github.com/blockchain/thundernetwork\nhttps://blockchain.com/thunder\n\nCheers!\n\n[1]\nhttps://github.com/blockchain/thunder/commit/e9132c9f30719f430385e88cc1c04d7611b5dfd0\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20160517/d9d64c5a/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2016-05-26T06:41:20",
                "message_text_only": "Mats Jerratsch via Lightning-dev <lightning-dev at lists.linuxfoundation.org> writes:\n> Hey everybody,\n>\n> Using SegWit, I thought of a more elegant way to solve the coupling problem between revocation delay and payment timeouts. ( https://lists.linuxfoundation.org/pipermail/lightning-dev/2015-November/000339.html and following)\n\nHi Mats!\n\n> A basic schema with one included payment can be seen here:\n>\n> https://raw.githubusercontent.com/blockchain/thunder/master/docs/dual-tx-diagram.png\n>\n> The idea is that each payment and each refund does not directly pay to their respective owner, but to a intermediate 2-of-2 transaction. For redeeming a payment, one has to also use R to broadcast Redeem-TX, for broadcasting Refund-TX one has to wait the agreed refund time. Having broadcasted the additional transaction, one basically *secured* the funds, under the premise that one has not cheated by using an old commitment transaction. If he did cheated though, the other party can claim all funds directly from the commitment outputs or from the Redeem-TX outputs.\n>\n> This makes it possible to set revocation delay and payment timeouts to completely separate values (if it is not obvious why this was not possible before, I suggest reading the thread linked above).\n>\n> Now there are two downsides to this approach:\n>\n> (1) Clearing a payment on the blockchain is more expensive. Because we have an additional transaction for each payment, fees for redeeming the payment are higher. One has to take into account the fee for the additional transaction when producing the outputs for the commitment transaction. However, as most channels will not get settled on the blockchain anyways, this is a minor issue.\n>\n> (2) Updating the commitment transaction, one has produce and send a new signature for each currently included payment. For channels that have lots of uncleared payments for a long time this might be problematic, however, uncleared payments are undesirable for many reasons and adding disincentives for delaying the clearing process is on the TODO anyways.\n>\n> However, having a clean solution to the problem of high refund times (>30d) and low revocation times (<3d) is more important in the long run. \n\nAt first I wasn't sure that anyone would really set 30 day CSV delays.\nI'm not sure that I want my funds locked for 30 days, or even to deal\nwith a node which indicates it's likely to be offline for anything like\nthat long.\n\nBut I'm wrong.  If you're just an occasional end-user, this might make\nperfect sense to ask for a 30 day timeout as an alternative to\noutsourcing enforcement.  And since it's a private arrangement between\ntwo nodes, it could easily be added as an option.\n\nThe main downside I see is the slight additional complexity for the\non-chain case, so I really like the idea of making it an option.\n\n> Also, following the tradition of the other releases here on the mailing list I like to bring it over here more formally.\n\nThis deserves a mail of its own!  I like to see release announcements,\nand I know the subscribers do.\n\n> Both, Node and Wallet software can be downloaded at\n> https://github.com/blockchain/thundernetwork/releases\n>\n> Further information can be found at\n> https://github.com/blockchain/thundernetwork\n> https://blockchain.com/thunder\n\nCongratulations!\nRusty."
            },
            {
                "author": "Mats Jerratsch",
                "date": "2016-05-30T08:56:44",
                "message_text_only": ">> A basic schema with one included payment can be seen here:\n>> \n>> https://raw.githubusercontent.com/blockchain/thunder/master/docs/dual-tx-diagram.png\n>> \n>> The idea is that each payment and each refund does not directly pay to their respective owner, but to a intermediate 2-of-2 transaction. For redeeming a payment, one has to also use R to broadcast Redeem-TX, for broadcasting Refund-TX one has to wait the agreed refund time. Having broadcasted the additional transaction, one basically *secured* the funds, under the premise that one has not cheated by using an old commitment transaction. If he did cheated though, the other party can claim all funds directly from the commitment outputs or from the Redeem-TX outputs.\n>> \n>> This makes it possible to set revocation delay and payment timeouts to completely separate values (if it is not obvious why this was not possible before, I suggest reading the thread linked above).\n>> \n>> Now there are two downsides to this approach:\n>> \n>> (1) Clearing a payment on the blockchain is more expensive. Because we have an additional transaction for each payment, fees for redeeming the payment are higher. One has to take into account the fee for the additional transaction when producing the outputs for the commitment transaction. However, as most channels will not get settled on the blockchain anyways, this is a minor issue.\n>> \n>> (2) Updating the commitment transaction, one has produce and send a new signature for each currently included payment. For channels that have lots of uncleared payments for a long time this might be problematic, however, uncleared payments are undesirable for many reasons and adding disincentives for delaying the clearing process is on the TODO anyways.\n>> \n>> However, having a clean solution to the problem of high refund times (>30d) and low revocation times (<3d) is more important in the long run.\n> \n> At first I wasn't sure that anyone would really set 30 day CSV delays.\n> I'm not sure that I want my funds locked for 30 days, or even to deal\n> with a node which indicates it's likely to be offline for anything like\n> that long.\n> \n> But I'm wrong.  If you're just an occasional end-user, this might make\n> perfect sense to ask for a 30 day timeout as an alternative to\n> outsourcing enforcement.  And since it's a private arrangement between\n> two nodes, it could easily be added as an option.\n> \n> The main downside I see is the slight additional complexity for the\n> on-chain case, so I really like the idea of making it an option.\n\nYes exactly, this high of a revocation timeout is not for 24/7 nodes, but rather to ease problems for endusers when adopting to this new way of transacting.\n\nKeep in mind though that only the revocation value is a private arrangement.\nThe dual-tx approach is backward compatible, meaning it is possible relaying payments with the old setup, with the cost of using long refund times. It is not possible to relay a payment that is optimised for dual-tx over hops that don\u2019t support it, because they would deduct their usual refund-time (often between 1-2 days per hop), leaving no room for the rest of the route.\n\nYes when having multiple payments with different timeouts one has to keep track of when to broadcast which transaction, but this is similar to the current approach. It does make it significantly harder to transact sub-dust amounts though. For a 1 satoshi payments one would often pay >500 satoshi for claiming it on-chain.\n\nWhat we can do, however, is to use the old schema for these low-amount payments, given that a long clearance time isn\u2019t that much of a problem for these either way.\n\nCheers\nMats\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20160530/188f3b8d/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 842 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20160530/188f3b8d/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Updated commitment design + Release thunder.network",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Mats Jerratsch"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 12185
        }
    },
    {
        "title": "[Lightning-dev] Lightning C prototype v0.3: \"Nakamoto's Genesis Coins\"",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2016-05-26T06:55:27",
                "message_text_only": "Hi all,\n\n\tThanks to Braydon Fuller, who as a new contributor got to name\nthe release.\n\n\tThis release is mainly under-the-covers changes.  It's still\njust two nodes talking to each other, but the protocol is fully\ndocumented[1].\n\n * Segregated witness is used for transactions, and is required.\n * The wire protocol is now fully async, as per latest BOLT#2[2]\n * All the onchain cases (stealing, unilateral close, mutual close)\n   handled as per the onchain draft[3]\n * Many internal improvements and cleanups.\n\n\tThere is still very little testing and many known bugs: 100\nFIXMEs at current count!\n\nPlans for the next release:\n\t- Simple routing and announcing\n        - Persistent storage\n\nFor a guide to the source, see:\n\n\thttps://github.com/ElementsProject/lightning/blob/master/HACKING.md\n\nCheers!\nRusty.\n[1] https://github.com/rustyrussell/lightning-rfc\n[2] https://github.com/rustyrussell/lightning-rfc/blob/master/bolts/02-wire-protocol.md\n[3] https://github.com/rustyrussell/lightning-rfc/blob/master/early-drafts/onchain.md"
            }
        ],
        "thread_summary": {
            "title": "Lightning C prototype v0.3: \"Nakamoto's Genesis Coins\"",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1030
        }
    },
    {
        "title": "[Lightning-dev] Multi-party channels",
        "thread_messages": [
            {
                "author": "Tier Nolan",
                "date": "2016-05-27T20:38:40",
                "message_text_only": "Hubs on the Lightning network require a large amount of capital.  If a hub\nwants to be able to send 1 BTC to N customers, then it needs to create N\nchannels and lock 1BTC in each of them.\n\nThis creates an economy of scale effect for hubs.  Hubs with more capital\ncan support larger channels and/or more customers.  If the de facto barrier\nto entry for hubs is high enough, then the number of hubs will be small,\nmaking cartel formation easier.\n\nWith multi-party channels, a hub could share its capital between multiple\ncustomers.\n\nI think it should be possible to shoehorn multi-party channels as a soft\nfork, but makes it harder to explain the concept.  For this post, I will\nassume a hard-fork and any rule change can be used.\n\n*** Basic Multiparty Channels ***\n\nA basic multi-party channel requires all participants to sign each state\nupdate.\n\nEach state update would incorporate the index number of the state.  This\nallows states to be ordered.  They would also have a unique channel id.\n\nAssuming everyone is honest, a channel would operate as follows.\n\n<channel established by multiple participants and timeout agreed>\n\n<state update 1, signed by all participants>\n<state update 2, signed by all participants>\n\n<state update M, signed by all participants>\n\n<channel times out - closes are now allowed>\n\n<someone publishes a state update, signed by all but signed again (twice)\nby the broadcaster>\n\n<outputs unspendable for 24 hours>\n\nIf the broadcaster didn't publish the most recent state update, then\nanother participant is allowed to broadcast a later update.  If this is\nincluded in a block within the 24 hour window, then it overwrites the\noriginal state update (and starts another 24 hour timeout).\n\nThis is the main hard fork bit, the state update is a transaction that is\nincluded in the block chain.  Unlike normal transactions, state updates can\nbe overwritten within 24 hours.  Locking the transaction outputs during\nthat time means that this is safe.\n\nSince each broadcaster has to sign their broadcast, it is possible to\ndetermine who is to blame for broadcasting an expired state update.\n\nThey could lose their contribution to the channel as with normal lightning\nnetwork channels.\n\nThis creates an incentive for all parties to broadcast only the most recent\nstate.\n\nThis system require signatures from all the parties for all state updates\nand updates are impossible while any of the parties are offline (or\nuncooperative).\n\n*** Flexible Multiparty Channels ***\n\nA better system is that state updates require the signatures of parties who\nlose out due to the state update only.  Unless a state update decreases a\nparticipant's holdings, that participant is not required to sign the update.\n\nFor efficiency, the hub could be a special member that must sign all\nupdates.  It is assumed that the hub is online all the time.\n\nUntil the channel times out, only the hub can broadcast the final state of\nthe channel.  After that point, any of the participants would be allowed to\nbroadcast to close the channel.  This prevents a participant from closing a\nchannel that everyone else wants to keep open.\n\nAs before the outputs from the channel would be locked for 24 hours to give\nparticipants a chance to challenge the final state.\n\nParticipants would have the option of broadcasting the latest state that\nthey signed.  A challenge is only allowed if the participant has less\nholdings in the final state than in the latest one that they signed.\n\nThe hub could then respond with a later state that the participant signed.\nIf the hub broadcasts that proof of fraud, then the participant would lose\ntheir money (or vice versa, if the hub tried to steal their money).\n\nSince each fraud step causes a participant to be kicked from the channel,\neventually, it should settle on the actual honest final state and in most\ncases, hubs would be honest anyway.\n\nThe state updates could work like a blockchain with previous pointers.\nThis means that if a participant signs state n, it is also signing all\nstates below state n.\n\nParties would download the entire state chain from the hub whenever they\ncome online and verify that it is a valid history.  If the hub signs states\non more than than 1 fork, then the hub would lose its deposit.\n\nIf the hub is honest, then the close step should be reasonably fast.  Fraud\nclaim timeouts could be handled in parallel too.\n\nIt should be possible to set things up so that the channel is mostly\neternal.  Parties could be added and removed from the channel without it\nhaving to be closed.  This would require some kind of on-chain activity\nthough unless the withdrawal is handled by moving to another channel.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20160527/ce86e199/attachment.html>"
            },
            {
                "author": "Mats Jerratsch",
                "date": "2016-05-30T09:01:33",
                "message_text_only": "Thats a cool idea! Instead of directed 1-to-1 payment channels, it would rather look like a cloud with multiple parties connected.\n\nApart from the (*huge*) added complexity and engineering work to make that happen, I see another problem with it though.\n\nIn case a participant cheats and broadcasts an old channel transaction - how do you determine the correct payout to the other participants?\n\nSay there are 5 parties, each contributing 1 BTC.\nNow after numerous payments, we end up in a state where Alice gets 4 BTC and B-E get 0.25 each. If one of the party now broadcasts an old transaction which held the initial state, how could you possibly make the blockchain cognitive to the correct payout? And what would be a correct payout to begin with?\n\nIs it:\n\nA: 4.0625\nB: 0.3125\nC: 0.3125\nD: 0.3125\nE: nothing (cheated)\n\nso splitting up the balance of the cheating party equally, or is it more correct to split it proportionally?\n\n\nThe only way how I see this working right now is returning back to the schema of decreasing nLocktime with each update. It would make broadcasting old states impossible, as the current state has a lower nLocktime. It also means returning to very limited lifetime per channel though (you talked about timeout, is that what you meant?). With so many parties involved, it would lead to drastically increased on-chain activity (or very high refund timeouts where you can\u2019t access your money).\n\nIt seems like you have it all thought out already, can you go into a bit more detail on your proposal? :)\nI\u2019m also interested in how exactly you would make it work, with only needing the spending party to resign the transaction. (which I cannot think of how to work out combined with the nLocktime-approach)\n\nCheers!\nMats\n> \n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 842 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20160530/f8dd3cc6/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Multi-party channels",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Tier Nolan",
                "Mats Jerratsch"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 6887
        }
    }
]