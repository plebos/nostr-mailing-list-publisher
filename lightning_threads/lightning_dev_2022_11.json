[
    {
        "title": "[Lightning-dev] Fat Errors",
        "thread_messages": [
            {
                "author": "Joost Jager",
                "date": "2022-11-01T21:09:27",
                "message_text_only": "Hey Rusty,\n\nGreat to hear that you want to try to implement the proposal. I can polish\nmy golang proof of concept code a bit and share if that's useful? It's just\ndoing the calculation in isolation. My next step after that would be to see\nwhat it looks like integrated in lnd.\n\n16 hops sounds fine to me too, but in general I am not too concerned about\nthe size of the message. Maybe a scheme is possible where the sender\nsignals the max number of hops, trading off size against privacy. Probably\nan unnecessary complication though.\n\nI remember the prepay scheme, but sounds quite a bit more invasive than\njust touching encode/relay/decode of the failure message. You also won't\nhave the timing information to identify slow nodes on the path.\n\nJoost.\n\nOn Tue, Oct 25, 2022 at 9:58 PM Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> Joost Jager <joost.jager at gmail.com> writes:\n> > Hi list,\n> >\n> > I wanted to get back to a long-standing issue in Lightning: gaps in error\n> > attribution. I've posted about this before back in 2019 [1].\n>\n> Hi Joost!\n>\n>         Thanks for writing this up fully.  Core lightning also doesn't\n> penalize properly, because of the attribution problem: solving this lets\n> us penalize a channel, at least.\n>\n>         I want to implement this too, to make sure I understand it\n> correctly, but having read it twice it seems reasonable.\n>\n>         How about 16 hops?  It's the closest power of 2 to the legacy hop\n> limit, and makes this 4.5k for payloads and hmacs.\n>\n>         There is, however, a completely different possibility if we want\n> to use a pre-pay scheme, which I think I've described previously.  You\n> send N sats and a secp point; every chained secret returned earns the\n> forwarder 1 sat[1].  The answers of course are placed in each layer of\n> the onion.  You know how far the onion got based on how much money you\n> got back on failure[2], though the error message may be corrupted.\n>\n> Cheers,\n> Rusty.\n> [1] Simplest is truncate the point to a new secret key.  Each node would\n>     apply a tweak for decorrelation ofc.\n> [2] The best scheme is that you don't get paid unless the next node\n>     decrypts, actually, but that needs more thought.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221101/2872425f/attachment.html>"
            },
            {
                "author": "Thomas HUET",
                "date": "2022-11-03T15:12:00",
                "message_text_only": "Hi Joost,\n\nThis is a very interesting proposal that elegantly solves the problem, with\nhowever a very significant size increase. I can see two ways to keep the\nsize small:\n- Each node just adds its hmac in a naive way, without deleting any part of\nthe message to relay. You seem to have disqualified this option because it\nincreases the size of the relayed message but I think it merits more\nconsideration. It is much simpler and the size only grows linearly with the\nlength of the route. An intermediate node could try to infer its position\nrelative to the failing node (which should not be the recipient) but\nwithout knowing the original message size (which can easily be randomized\nby the final node), is that really such a problem? It may be but I would\nargue it's a good trade-off.\n- If we really want to keep the constant size property, as you've suggested\nwe could use a low limit on the number of nodes. I would put the limit even\nlower, at 8 or less. We could still use longer routes but we would only get\nhmacs for the first 8 hops and revert to the legacy system if the failure\nhappens after the first 8 hops. That way we keep the size low and 8 hops\nshould be good enough for 99% of the payments, and even when there are more\nhops we would know that the first 7 hops are clean.\n\nThanks again for your contribution, I hope we'll soon be able to attribute\nfailures trustlessly.\n\nThomas\n\nLe mar. 1 nov. 2022 \u00e0 22:10, Joost Jager <joost.jager at gmail.com> a \u00e9crit :\n\n> Hey Rusty,\n>\n> Great to hear that you want to try to implement the proposal. I can polish\n> my golang proof of concept code a bit and share if that's useful? It's just\n> doing the calculation in isolation. My next step after that would be to see\n> what it looks like integrated in lnd.\n>\n> 16 hops sounds fine to me too, but in general I am not too concerned about\n> the size of the message. Maybe a scheme is possible where the sender\n> signals the max number of hops, trading off size against privacy. Probably\n> an unnecessary complication though.\n>\n> I remember the prepay scheme, but sounds quite a bit more invasive than\n> just touching encode/relay/decode of the failure message. You also won't\n> have the timing information to identify slow nodes on the path.\n>\n> Joost.\n>\n> On Tue, Oct 25, 2022 at 9:58 PM Rusty Russell <rusty at rustcorp.com.au>\n> wrote:\n>\n>> Joost Jager <joost.jager at gmail.com> writes:\n>> > Hi list,\n>> >\n>> > I wanted to get back to a long-standing issue in Lightning: gaps in\n>> error\n>> > attribution. I've posted about this before back in 2019 [1].\n>>\n>> Hi Joost!\n>>\n>>         Thanks for writing this up fully.  Core lightning also doesn't\n>> penalize properly, because of the attribution problem: solving this lets\n>> us penalize a channel, at least.\n>>\n>>         I want to implement this too, to make sure I understand it\n>> correctly, but having read it twice it seems reasonable.\n>>\n>>         How about 16 hops?  It's the closest power of 2 to the legacy hop\n>> limit, and makes this 4.5k for payloads and hmacs.\n>>\n>>         There is, however, a completely different possibility if we want\n>> to use a pre-pay scheme, which I think I've described previously.  You\n>> send N sats and a secp point; every chained secret returned earns the\n>> forwarder 1 sat[1].  The answers of course are placed in each layer of\n>> the onion.  You know how far the onion got based on how much money you\n>> got back on failure[2], though the error message may be corrupted.\n>>\n>> Cheers,\n>> Rusty.\n>> [1] Simplest is truncate the point to a new secret key.  Each node would\n>>     apply a tweak for decorrelation ofc.\n>> [2] The best scheme is that you don't get paid unless the next node\n>>     decrypts, actually, but that needs more thought.\n>>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221103/ddb54b9c/attachment.html>"
            },
            {
                "author": "Joost Jager",
                "date": "2022-11-04T06:53:53",
                "message_text_only": "Hi Thomas,\n\nThis is a very interesting proposal that elegantly solves the problem, with\n> however a very significant size increase. I can see two ways to keep the\n> size small:\n> - Each node just adds its hmac in a naive way, without deleting any part\n> of the message to relay. You seem to have disqualified this option because\n> it increases the size of the relayed message but I think it merits more\n> consideration. It is much simpler and the size only grows linearly with the\n> length of the route. An intermediate node could try to infer its position\n> relative to the failing node (which should not be the recipient) but\n> without knowing the original message size (which can easily be randomized\n> by the final node), is that really such a problem? It may be but I would\n> argue it's a good trade-off.\n>\n\nThat would definitely make the solution a lot simpler. I think that\nincreasing the message length still does leak some information, even with\nrandomization by the final node. For example if you know the minimum\nmessage length including random bytes produced by the final node, and a\nrouting node sees this length, they must be the second-last hop. I tried to\ncome up with something that stays within the current privacy guarantees,\nbut it's fair to question the trade-off.\n\nAn advantage of the naive hmac append is also that each node can add a\nvariable (tlv?) payload. In the fixed size proposal that isn't possible\nbecause nodes need to know exactly how many bytes to sign to cover a number\nof downstream hop payloads, and some form of signaling would be required to\nadd flexibility to that. A variable payload makes it easier to add\nextensions later on. It also helps with the randomization of the length.\nAnd intermediate nodes could choose to add some random bytes too in a\notherwise unused tlv record.\n\n\n> - If we really want to keep the constant size property, as you've\n> suggested we could use a low limit on the number of nodes. I would put the\n> limit even lower, at 8 or less. We could still use longer routes but we\n> would only get hmacs for the first 8 hops and revert to the legacy system\n> if the failure happens after the first 8 hops. That way we keep the size\n> low and 8 hops should be good enough for 99% of the payments, and even when\n> there are more hops we would know that the first 7 hops are clean.\n>\n\nSounds like a useful middle road. Each hop will just shift hmacs and the\nones further than 8 hops away will be shifted out completely. Yes, not bad.\n\nThe question that is still unanswered for me is how problematic a full size\nfat error of 12 kb would really be. Of course small is better than big, but\nwondering if there would be an actual degradation of the ux or other\nsignificant negative effects in practice.\n\nJoost\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221104/da7bb3e1/attachment.html>"
            },
            {
                "author": "Joost Jager",
                "date": "2022-11-10T15:24:28",
                "message_text_only": "Pushed a golang implementation of the fat errors here:\nhttps://github.com/lightningnetwork/lightning-onion/pull/60\n\nJoost.\n\nOn Wed, Oct 19, 2022 at 1:12 PM Joost Jager <joost.jager at gmail.com> wrote:\n\n> Hi list,\n>\n> I wanted to get back to a long-standing issue in Lightning: gaps in error\n> attribution. I've posted about this before back in 2019 [1].\n>\n> Error attribution is important to properly penalize nodes after a payment\n> failure occurs. The goal of the penalty is to give the next attempt a\n> better chance at succeeding. In the happy failure flow, the sender is able\n> to determine the origin of the failure and penalizes a single node or pair\n> of nodes.\n>\n> Unfortunately it is possible for nodes on the route to hide themselves. If\n> they return random data as the failure message, the sender won't know where\n> the failure happened. Some senders then penalize all nodes that were part\n> of the route [4][5]. This may exclude perfectly reliable nodes from being\n> used for future payments. Other senders penalize no nodes at all [6][7],\n> which allows the offending node to keep the disruption going.\n>\n> A special case of this is a final node sending back random data. Senders\n> that penalize all nodes will keep looking for alternative routes. But\n> because each alternative route still ends with that same final node, the\n> sender will ultimately penalize all of its peers and possibly a lot of the\n> rest of the network too.\n>\n> I can think of various reasons for exploiting this weakness. One is just\n> plain grievance for whatever reason. Another one is to attract more traffic\n> by getting competing routing nodes penalized. Or the goal could be to\n> sufficiently mess up reputation tracking of a specific sender node to make\n> it hard for that node to make further payments.\n>\n> Related to this are delays in the path. A node can delay propagating back\n> a failure message and the sender won't be able to determine which node did\n> it.\n>\n> The link at the top of this post [1] describes a way to address both\n> unreadable failure messages as well as delays by letting each node on the\n> route append a timestamp and hmac to the failure message. The great\n> challenge is to do this in such a way that nodes don\u2019t learn their position\n> in the path.\n>\n> I'm revisiting this idea, and have prototyped various ways to implement\n> it. In the remainder of this post, I will describe the variant that I\n> thought works best (so far).\n>\n> # Failure message format\n>\n> The basic idea of the new format is to let each node (not just the error\n> source) commit to the failure message when it passes it back by adding an\n> hmac. The sender verifies all hmacs upon receipt of the failure message.\n> This makes it impossible for any of the nodes to modify the failure message\n> without revealing that they might have played a part in the modification.\n> It won\u2019t be possible for the sender to pinpoint an exact node, because\n> either end of a communication channel may have modified the message.\n> Pinpointing a pair of nodes however is good enough, and is commonly done\n> for regular onion failures too.\n>\n> On the highest level, the new failure message consists of three parts:\n>\n> `message` (var len) | `payloads` (fixed len) | `hmacs` (fixed len)\n>\n> * `message` is the standard onion failure message as described in [2], but\n> without the hmac. The hmac is now part of `hmacs` and doesn't need to be\n> repeated.\n>\n> * `payloads` is a fixed length array that contains space for each node\n> (`hop_payload`) on the route to add data to return to the sender. Ideally\n> the contents and size of `hop_payload` is signaled so that future\n> extensions don\u2019t require all nodes to upgrade. For now, we\u2019ll assume the\n> following 9-byte format:\n>\n>   `is_final` (1 byte) | `duration` (8 bytes)\n>\n>   `is_final` indicates whether this node is the failure source. The sender\n> uses `is_final` to determine when to stop the decryption/verification\n> process.\n>\n>   `duration` is the time in milliseconds that the node held the htlc. By\n> observing the series of reported durations, the sender is able to pinpoint\n> a delay down to a pair of nodes.\n>\n>   The `hop_payload` is repeated 27 times (the maximum route length).\n>\n>   Every hop shifts `payloads` 9 bytes to the right and puts its own\n> `hop_payload` in the 9 left-most bytes.\n>\n> * `hmacs` is a fixed length array where nodes add their hmacs as the\n> failure message travels back to the sender.\n>\n>   To keep things simple, I'll describe the format as if the maximum route\n> length was only three hops (instead of 27):\n>\n>   `hmac_0_2` | `hmac_0_1`| `hmac_0_0`| `hmac_1_1`| `hmac_1_0`| `hmac_2_0`\n>\n>   Because nodes don't know their position in the path, it's unclear to\n> them what part of the failure message they are supposed to include in the\n> hmac. They can't just include everything, because if part of that data is\n> deleted later (to keep the message size fixed) it opens up the possibility\n> for nodes to blame others.\n>\n>   The solution here is to provide hmacs for all possible positions. The\n> last node that updated `hmacs` added `hmac_0_2`, `hmac_0_1` and `hmac_0_0`\n> to the block. Each hmac corresponds to a presumed position in the path,\n> where `hmac_0_2` is for the longest path (2 downstream hops) and `hmac_0_0`\n> for the shortest (node is the error source).\n>\n>   `hmac_x_y` is the hmac added by node x (counted from the node that is\n> currently handling the failure message) assuming that this node is y hops\n> away from the final node.\n>\n> Before an hop adds its hmacs, it first deletes some of the previous hmacs.\n> This keeps the failure message at a fixed length. The removed hmacs are the\n> ones that cannot be useful anymore. If node 0 adds itself, the former node\n> 0 (now node 1) cannot be at the first position anymore. The former node 1\n> (now node 2) cannot be at the second position anymore. The former node 2\n> cannot be the source of the error anymore and isn\u2019t represented in the\n> failure message any longer. The corresponding hmacs (the now non-existent\n> `hmac_0_2`, `hmac_1_1` and `hmac_2_0`) are deleted by node 0.\n>\n> Deleting the useless data reduces the number of hmacs (and roughly the\n> total failure message size) to half.\n>\n> The delete operation transform the fields above to:\n>\n> <empty> | <empty> | <empty> | `hmac_0_1`| `hmac_0_0`| `hmac_1_0`\n>\n> The exact data that is included in each hmac is:\n>   * `message`\n>   * the node\u2019s own `hop_payload` and a set of downstream `hop_payload`s,\n> depending on assumed position\n>   * a set of downstream node hmacs, depending on assumed position\n>\n> For example `hmac_0_1` is based on:\n>\n> `message` | `hop_payload[0]` | `hop_payload[1]` | `hmac_1_0`\n>\n> If the node that is currently handling the failure message is one hop away\n> from the final node, it needs to cover its own `hop_payload[0]`, the final\n> node `hop_payload[1]` and the final node hmac `hmac_1_0`.\n>\n> A longer path is committed to in `hmac_0_2`:\n>\n> `message` | `hop_payload[0]` | `hop_payload[1]` | `hop_payload[2]` |\n> `hmac_1_1` | `hmac_2_0`\n>\n> The current node is two hops away from the final node. It needs to cover\n> its own `hop_payload[0]` as well as `hop_payload[1]` and `hop_payload[2]`\n> for the next and final hops. Additionally it covers the next hop `hmac_1_1`\n> and final hop `hmac_2_0`, which correspond to the positions of those nodes\n> in the path that is assumed for `hmac_0_2`.\n>\n> With this information, the sender is able to verify the longest chain of\n> hmacs until it encounters a `hop_payload` with `is_final` set.\n>\n> If any of the nodes messes with any byte in the failure message, the\n> sender is always able to determine a pair of nodes that the offending node\n> is part of. This statement can be verified through reasoning, but to be\n> sure I also tested it with code. I\u2019ve simulated a malicious node that\n> modifies a byte of the failure message at index x and observed the error\n> source as determined by the sender. For every x, the sender reports the\n> same correct pair.\n>\n> # Size\n>\n> The obvious downside of the scheme above is the size. Given a maximum of\n> 27 hops, the `hmacs` block contains 27+26+25+...+1=378 hmacs of 32 bytes\n> each. This makes for a total size of 12 KB.\n>\n> It could be the case though that it is not possible to devise a more\n> compact scheme that also preserves the existing privacy guarantees. I know\n> that smart people have spent time on this problem, but nonetheless no\n> better solution has come up in the past years. A proof of its non-existence\n> would be interesting for sure.\n>\n> I personally think the size increase is justified to fix this\n> vulnerability in Lightning. Also if failures are expected to become more\n> rare going forward, size becomes less relevant to the overall operation of\n> the network.\n>\n> Another option is to reduce the maximum number of hops. It is questionable\n> whether 27 hops are really needed in practice, and such long routes also\n> contribute to latency and capital lock up. If for example the new failure\n> message could only be used with routes up to 10 hops, the total number of\n> hmacs would drop from 378 to 55. This makes for a total message size of\n> about 2 KB.\n>\n> # Signaling\n>\n> For backwards compatibility nodes need to know what algorithm they should\n> run to generate or transform the failure message. This can be signaled by\n> the sender via a tlv onion field. A failure message format signaling\n> mechanism is also discussed in the context of long failure messages [3].\n> The failure message described in this post could be just another version.\n>\n> Additionally, intermediate nodes need to advertise their capability to\n> transform the new format through a feature bit.\n>\n> # Delayed successes\n>\n> It\u2019s not just failures that can be delayed. Successes can too. In that\n> case, there is no failure message to improve. It could be an option to add\n> the same `payloads` and `hmacs` blocks to the `update_fulfill_htlc` message.\n>\n> [1]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-June/002015.html\n> [2]\n> https://github.com/lightning/bolts/blob/master/04-onion-routing.md#returning-errors\n> [3] https://github.com/lightning/bolts/pull/1021\n> [4]\n> https://github.com/lightningnetwork/lnd/blob/4fbd608b734f348d7e79fbfc7feaecc5c6c33a90/routing/result_interpretation.go#L419\n> [5]\n>\n> https://github.com/ACINQ/eclair/blob/a0433aa0c027c9be618c5afe18e7f91642a7f372/eclair-core/src/main/scala/fr/acinq/eclair/payment/PaymentEvents.scala#L221\n> [6]\n> https://github.com/ElementsProject/lightning/blob/62bfed9a8df8731be44ba4e86afb08a5d28a4442/plugins/libplugin-pay.c#L1461\n> [7]\n> https://github.com/lightningdevkit/rust-lightning/blob/e61f3a238a70cbac87209e223b7c396108a49b97/lightning-invoice/src/payment.rs#L682\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221110/985e7b0a/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Fat Errors",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Joost Jager",
                "Thomas HUET"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 20429
        }
    },
    {
        "title": "[Lightning-dev] Dynamic Commitments Part 2: Taprooty Edition",
        "thread_messages": [
            {
                "author": "Matt Corallo",
                "date": "2022-11-01T22:59:08",
                "message_text_only": "Right, I kinda assume let's figure that out when we get PTLCs? There's also the channel-upgrade work \nthat has been around for a while. Once we do that we can probably define a new type for PTLCs in \n\"normal\" channels.\n\nAdding two types adds a bunch of complexity right now, and it would be effectively dead code that \nwe're not likely to get right unless we have an immediate use/test for it. It is a good point, \nthough, and something implementors should likely keep in mind when writing code.\n\nMatt\n\nOn 10/28/22 12:35 AM, Johan Tor\u00e5s Halseth wrote:\n> Hi, Matt.\n> \n> You're correct, I made the suggestion mainly because it would open up for PTLCs (or other future \n> features) in today's channels.\n> \n> Having the existing network close and reopen new channels would really slow the adoption of new \n> channel features I reckon.\n> \n> And I don't think it adds much complexity compared to the adapter approach.\n> \n> - Johan\n> \n> On Thu, Oct 27, 2022 at 4:54 PM Matt Corallo <lf-lists at mattcorallo.com \n> <mailto:lf-lists at mattcorallo.com>> wrote:\n> \n>     I\u2019m not sure I understand this - is there much reason to want taproot commitment outputs? I mean\n>     they\u2019re cool, and witnesses are a bit smaller, which is nice I guess, but they\u2019re not providing\n>     materially new features, AFAIU. Taproot funding, on the other hand, provides a Bitcoin-wide\n>     privacy improvement as well the potential future ability of channel participants to use multisig\n>     for their own channel funds transparently.\n> \n>     Sure, if we\u2019re doing taproot funding outputs we should probably just do it for the commitment\n>     outputs as well, because why not (and it\u2019s a prereq for PTLCs). But trying to split them up\n>     seems like added complexity \u201cjust because\u201d? I suppose it tees us up for eventual PTLC support in\n>     todays channels, but we can also consider that separately when we get to that point, IMO.\n> \n>     Am I missing some important utility of taproot commitment transaction outputs?\n> \n>     Matt\n> \n>>     On Oct 27, 2022, at 02:17, Johan Tor\u00e5s Halseth <johanth at gmail.com <mailto:johanth at gmail.com>>\n>>     wrote:\n>>\n>>     \ufeff\n>>     Hi, Laolu.\n>>\n>>     I think it could be worth considering dividing the taprootyness of a channel into two:\n>>     1) taproot funding output\n>>     2) taproot commitment outputs\n>>\n>>     That way we could upgrade existing channels only on the commitment level, not needing to close\n>>     or re-anchor the channels using an adapter in order to get many of the taproot benefits.\n>>\n>>     New channels would use taproot multisig (musig2) for the funding output.\n>>\n>>     This seems to be less disruptive to the existing network, and we could get features enabled by\n>>     taproot to larger parts of the network quicker. And to me this seems to carry less complexity\n>>     (and closing fees) than an adapter.\n>>\n>>     One caveat is that this wouldn't work (I think) for Eltoo channels, as the funding output\n>>     would not be plain multisig anymore.\n>>\n>>     - Johan\n>>\n>>     On Sat, Mar 26, 2022 at 1:27 AM Antoine Riard <antoine.riard at gmail.com\n>>     <mailto:antoine.riard at gmail.com>> wrote:\n>>\n>>         Hi Laolu,\n>>\n>>         Thanks for the proposal, quick feedback.\n>>\n>>         > It *is* still the case that _ultimately_ the two transactions to close the\n>>         > old segwit v0 funding output, and re-open the channel with a new segwit v1\n>>         > funding output are unavoidable. However this adapter commitment lets peers\n>>         > _defer_ these two transactions until closing time.\n>>\n>>         I think there is one downside coming with adapter commitment, which is the uncertainty of\n>>         the fee overhead at the closing time. Instead of closing your segwit v0 channel _now_ with\n>>         known fees, when your commitment is empty of time-sensitive HTLCs, you're taking the risk\n>>         of closing during fees spikes, due a move triggered by your counterparty, when you might\n>>         have HTLCs at stake.\n>>\n>>         It might be more economically rational for a LN node operator to pay the upgrade cost now\n>>         if they wish\u00a0 to benefit from the taproot upgrade early, especially if long-term we expect\n>>         block fees to increase, or wait when there is a \"normal\" cooperative closing.\n>>\n>>         So it's unclear to me what the economic gain of adapter commitments ?\n>>\n>>         > In the remainder of this mail, I'll describe an alternative\n>>         > approach that would allow upgrading nearly all channel/commitment related\n>>         > values (dust limit, max in flight, etc), which is inspired by the way the\n>>         > Raft consensus protocol handles configuration/member changes.\n>>\n>>         Long-term, I think we'll likely need a consensus protocol anyway for multi-party\n>>         constructions (channel factories/payment pools). AFAIU this proposal doesn't aim to roll\n>>         out a full-fledged consensus protocol *now* though it could be wise to ensure what we're\n>>         building slowly moves in this direction. Less critical code to maintain across bitcoin\n>>         codebases/toolchains.\n>>\n>>         > The role of the signature it to prevent \"spoofing\" by one of the parties\n>>         > (authenticate the param change), and also it serves to convince a party that\n>>         > they actually sent a prior commitment propose update during the\n>>         > retransmission phase.\n>>\n>>         What's the purpose of data origin authentication if we assume only two-parties running\n>>         over Noise_XK ?\n>>\n>>         I think it's already a security property we have. Though if we think we're going to reuse\n>>         these dynamic upgrades for N counterparties communicating through a coordinator, yes I\n>>         think it's useful.\n>>\n>>         > In the past, when ideas like this were brought up, some were concerned that\n>>         > it wouldn't really be possible to do this type of updates while existing\n>>         > HTLCs were in flight (hence some of the ideas to clear out the commitment\n>>         > beforehand).\n>>\n>>         The dynamic upgrade might serve in an emergency context where we don't have the leisury to\n>>         wait for the settlement of the pending HTLCs. The timing of those ones might be beyond the\n>>         coordination of link counterparties. Thus, we have to allow upgrade of non-empty\n>>         commitments (and if there are undesirable interferences between new commitment types and\n>>         HTLCs/PTLCs present, deal case-by-case).\n>>\n>>         Antoine\n>>\n>>         Le\u00a0jeu. 24 mars 2022 \u00e0\u00a018:53, Olaoluwa Osuntokun <laolu32 at gmail.com\n>>         <mailto:laolu32 at gmail.com>> a \u00e9crit\u00a0:\n>>\n>>             Hi y'all,\n>>\n>>             ## Dynamic Commitments Retrospective\n>>\n>>             Two years-ish ago I made a mailing list post on some ideas re dynamic\n>>             commitments [1], and how the concept can be used to allow us to upgrade\n>>             channel types on the fly, and also remove pesky hard coded limits like the\n>>             483 HTLC in-flight limit that's present today. Back then my main target was\n>>             upgrading all the existing channels over to the anchor output commitment\n>>             variant, so the core internal routing network would be more resilient in a\n>>             persistent high fee environment (which hasn't really happened over the past\n>>             2 years for various reasons tbh). Fast forward to today, and with taproot\n>>             now active on mainnet, and some initial design work/sketches for\n>>             taproot-native channels underway, I figure it would be good to bump this\n>>             concept as it gives us a way to upgrade all 80k+ public channels to taproot\n>>             without any on chain transactions.\n>>\n>>             ## Updating Across Witness Versions w/ Adapter Commitments\n>>\n>>             In my original mail, I incorrectly concluded that the dynamic commitments\n>>             concept would only really work within the confines of a \"static\" multi-sig\n>>             output, meaning that it couldn't be used to help channels upgrade to future\n>>             segwit witness versions.\u00a0 Thankfully this reply [2] by ZmnSCPxj, outlined a\n>>             way to achieve this in practice. At a high level he proposes an \"adaptor\n>>             commitment\" (similar to the kickoff transaction in eltoo/duplex), which is\n>>             basically an upgrade transaction that spends one witness version type, and\n>>             produces an output with the next (upgraded) type. In the context of\n>>             converting from segwit v0 to v1 (taproot), two peers would collaboratively\n>>             create a new adapter commitment that spends the old v0 multi-sig output, and\n>>             produces a _new_ v1 multi-sig output. The new commitment transaction would\n>>             then be anchored using this new output.\n>>\n>>             Here's a rough sequence diagram of the before and after state to better\n>>             convey the concept:\n>>\n>>             \u00a0 * Before: fundingOutputV0 -> commitmentTransaction\n>>\n>>             \u00a0 * After fundingOutputV0 -> fundingOutputV1 (the adapter) ->\n>>             \u00a0 \u00a0 commitmentTransaction\n>>\n>>             It *is* still the case that _ultimately_ the two transactions to close the\n>>             old segwit v0 funding output, and re-open the channel with a new segwit v1\n>>             funding output are unavoidable. However this adapter commitment lets peers\n>>             _defer_ these two transactions until closing time. When force closing two\n>>             transactions need to be confirmed before the commitment outputs can be\n>>             resolved. However, for co-op close, you can just spend the v0 output, and\n>>             deliver to the relevant P2TR outputs. The adapter commitment can leverage\n>>             sighash anyonecanpay to let both parties (assuming it's symmetric) attach\n>>             additional inputs for fees (to avoid introducing the old update_fee related\n>>             static fee issues), or alternatively inherit the anchor output pattern at\n>>             this level.\n>>\n>>             ## Existing Dynamic Commitments Proposals\n>>\n>>             Assuming this concept holds up, then we need an actual concrete protocol to\n>>             allow for dynamic commitment updates. Last year, Rusty made a spec PR\n>>             outlining a way to upgrade the commitment type (leveraging the new\n>>             commitment type feature bits) upon channel re-establish [3]. The proposal\n>>             relies on another message that both sides send (`stfu`) to clear the\n>>             commitment (similar to the shutdown semantics) before the switch over\n>>             happens. However as this is tied to the channel re-establish flow, it\n>>             doesn't allow both sides to do things like only allow your peer to attach N\n>>             HTLCs to start with, slowing increasing their allotted slots and possibly\n>>             reducing them (TCP AIMD style).\n>>\n>>             ## A Two-Phase Dynamic Commitment Update Protocol\n>>\n>>             IMO if we're adding in a way to do commitment/channel upgrades, then it may\n>>             be worthwhile to go with a more generalized, but slightly more involved\n>>             route instead. In the remainder of this mail, I'll describe an alternative\n>>             approach that would allow upgrading nearly all channel/commitment related\n>>             values (dust limit, max in flight, etc), which is inspired by the way the\n>>             Raft consensus protocol handles configuration/member changes.\n>>\n>>             For those that aren't aware, Raft is a consensus protocol analogous to Paxos\n>>             (but isn't byzantine fault tolerant out of the box) that was designed as a\n>>             more understandable alternative to Paxos for a pedagogical environment.\n>>             Typically the algorithm is run in the context of a fixed cluster with N\n>>             machines, but supports adding/removing machines from the cluster with a\n>>             configuration update protocol. At a high level the way this works is that a\n>>             new config is sent to the leader, with the leader synchronizing the config\n>>             change with the other members of the cluster. Once a majority threshold is\n>>             reached, the leader then commits the config change with the acknowledged\n>>             parties using the new config (basically a two phase commit). I'm skipping\n>>             over some edge cases here that can arise if the new nodes participate\n>>             consensus too early, which can cause a split majority leading to two leaders\n>>             being elected.\n>>\n>>             Applying this to the LN context is a bit simpler than a generalized\n>>             protocol, as we typically just have two parties involved. The initiator is\n>>             already naturally a \"leader\" in our context, as they're the only ones that\n>>             can do things like trigger fee updates.\n>>\n>>             ### Message Structure\n>>\n>>             At a high level I propose we introduce two new messages, with the fields\n>>             looking something like this for `commitment_update_propose`:\n>>             \u00a0* type: 0 (`channel_id`)\n>>             \u00a0 \u00a0* value: [`32*byte`:`chan_id`]\n>>             \u00a0* type: 1 (`propose_sig`)\n>>             \u00a0 \u00a0* value: [`64*byte`:`sig`]\n>>             \u00a0* type: 2 (`update_payload`)\n>>             \u00a0 \u00a0* value: [`*byte`:`tlv_payload`]\n>>\n>>             and this `commitment_update_apply`:\n>>             \u00a0* type: 0 (`channel_id`)\n>>             \u00a0 \u00a0* value: [`32*byte`:`chan_id`]\n>>             \u00a0* type: 1 (`local_propose`)\n>>             \u00a0 \u00a0* value: [`*byte`:`commitment_update_propose`]\n>>             \u00a0* type: 2 (`remote_propose`)\n>>             \u00a0 \u00a0* value: [`*byte`:`commitment_update_propose`]\n>>\n>>             ### Protocol Flow\n>>\n>>             The core idea here is that either party can propose a commitment/channel\n>>             param update, but only the initiator can actually apply it. The\n>>             `commitment_update_propose` encodes the new set of updates, with a signature\n>>             covering the TLV blob for the new params (more on why that's needed later).\n>>             The `commitment_update_apply` includes up to _two_\n>>             `commitment_update_propose` messages (one for the initiator and one for the\n>>             responder, as nested TLV messages). The `commitment_update_propose` message\n>>             would be treated like any other `update_*` message, in that it takes a new\n>>             commitment signature to properly commit/apply it.\n>>\n>>             The normal flow takes the form of both sides sending a\n>>             `commitment_update_propose` message, with the initiator finally committing\n>>             both by sending a `commitment_update_apply` message. In the event that only\n>>             the responder wants to apply a param change/update, then the initiator can\n>>             reply immediately with a `commitment_update_apply` message that doesn't\n>>             include a param change for their commitment (or they just echo the\n>>             parameters if they're acceptable).\n>>\n>>             ### Handling Retransmissions\n>>\n>>             The role of the signature it to prevent \"spoofing\" by one of the parties\n>>             (authenticate the param change), and also it serves to convince a party that\n>>             they actually sent a prior commitment propose update during the\n>>             retransmission phase. As the `commitment_update_propose` message would be\n>>             retransmitted like any other message, if the initiator attempts to commit\n>>             the update but the connection dies, they'll retransmit it as normal along\n>>             with their latest signature.\n>>\n>>             ### Nested TLV Param Generality\n>>\n>>             The messages as sketched out here just have an opaque nested TLV field which\n>>             makes it extensible to add in other things like tweaking the total number of\n>>             max HTLCs, the current dust values, min/max HTLCs, etc (all things that are\n>>             currently hard coded for the lifetime of the channel). An initial target\n>>             would likely just be a `chan_type` field, with future feature bits governing\n>>             _what_ type of commitment updates both parties understand in the future.\n>>\n>>             In the past, when ideas like this were brought up, some were concerned that\n>>             it wouldn't really be possible to do this type of updates while existing\n>>             HTLCs were in flight (hence some of the ideas to clear out the commitment\n>>             beforehand). I don't see a reason why this fundamentally _shouldn't_ be\n>>             allowed, as from the point of view of the channel update state machine, all\n>>             updates (adds/removes) get applied as normal, but with this _new_ commitment\n>>             type/params. The main edge case we'll need to consider is cases where the\n>>             new params make older HTLCs invalid for some reason.\n>>\n>>             ## Conclusion\n>>\n>>             Using the adapter commitment idea combined with a protocol for updating\n>>             commitments on the fly, would potentially allow us to update all 80k+ segwit\n>>             v0 channels to the base level of taprooty channels without any on chain\n>>             transactions. The two transactions (open+close) must happen eventually, but\n>>             by holding another layer of spends off-chain we can defer them (potentially\n>>             indefinitely, as we have channels today that have been opened for over a\n>>             year).\n>>\n>>             Deploying a generalised on-the-fly dynamic commitment update protocol gives\n>>             us a tool to future proof the _existing_ anchored multi-sig outputs in the\n>>             chain, and also a way to remove many of the hard coded parameters we have\n>>             today in the protocol. One overly inflexible parameter we have today in the\n>>             network is the 483 HTLC limit. Allowing this value to float would allow\n>>             peers to apply similar congestion avoidance algorithm that are used in TCP\n>>             today, and also give us a way to protect the network against future\n>>             unforeseen widespread policy changes (like a raising of the dust limit).\n>>\n>>             -- Laolu\n>>\n>>             [1]: https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-July/002763.html\n>>             <https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-July/002763.html>\n>>             [2]: https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-July/002770.html\n>>             <https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-July/002770.html>\n>>             [3]: https://github.com/lightning/bolts/pull/868\n>>             <https://github.com/lightning/bolts/pull/868>\n>>             _______________________________________________\n>>             Lightning-dev mailing list\n>>             Lightning-dev at lists.linuxfoundation.org <mailto:Lightning-dev at lists.linuxfoundation.org>\n>>             https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>             <https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev>\n>>\n>>         _______________________________________________\n>>         Lightning-dev mailing list\n>>         Lightning-dev at lists.linuxfoundation.org <mailto:Lightning-dev at lists.linuxfoundation.org>\n>>         https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>         <https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev>\n>>\n>>     _______________________________________________\n>>     Lightning-dev mailing list\n>>     Lightning-dev at lists.linuxfoundation.org <mailto:Lightning-dev at lists.linuxfoundation.org>\n>>     https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>     <https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev>\n> \n> \n> On Thu, Oct 27, 2022 at 4:54 PM Matt Corallo <lf-lists at mattcorallo.com \n> <mailto:lf-lists at mattcorallo.com>> wrote:\n> \n>     I\u2019m not sure I understand this - is there much reason to want taproot commitment outputs? I mean\n>     they\u2019re cool, and witnesses are a bit smaller, which is nice I guess, but they\u2019re not providing\n>     materially new features, AFAIU. Taproot funding, on the other hand, provides a Bitcoin-wide\n>     privacy improvement as well the potential future ability of channel participants to use multisig\n>     for their own channel funds transparently.\n> \n>     Sure, if we\u2019re doing taproot funding outputs we should probably just do it for the commitment\n>     outputs as well, because why not (and it\u2019s a prereq for PTLCs). But trying to split them up\n>     seems like added complexity \u201cjust because\u201d? I suppose it tees us up for eventual PTLC support in\n>     todays channels, but we can also consider that separately when we get to that point, IMO.\n> \n>     Am I missing some important utility of taproot commitment transaction outputs?\n> \n>     Matt\n> \n>>     On Oct 27, 2022, at 02:17, Johan Tor\u00e5s Halseth <johanth at gmail.com <mailto:johanth at gmail.com>>\n>>     wrote:\n>>\n>>     \ufeff\n>>     Hi, Laolu.\n>>\n>>     I think it could be worth considering dividing the taprootyness of a channel into two:\n>>     1) taproot funding output\n>>     2) taproot commitment outputs\n>>\n>>     That way we could upgrade existing channels only on the commitment level, not needing to close\n>>     or re-anchor the channels using an adapter in order to get many of the taproot benefits.\n>>\n>>     New channels would use taproot multisig (musig2) for the funding output.\n>>\n>>     This seems to be less disruptive to the existing network, and we could get features enabled by\n>>     taproot to larger parts of the network quicker. And to me this seems to carry less complexity\n>>     (and closing fees) than an adapter.\n>>\n>>     One caveat is that this wouldn't work (I think) for Eltoo channels, as the funding output\n>>     would not be plain multisig anymore.\n>>\n>>     - Johan\n>>\n>>     On Sat, Mar 26, 2022 at 1:27 AM Antoine Riard <antoine.riard at gmail.com\n>>     <mailto:antoine.riard at gmail.com>> wrote:\n>>\n>>         Hi Laolu,\n>>\n>>         Thanks for the proposal, quick feedback.\n>>\n>>         > It *is* still the case that _ultimately_ the two transactions to close the\n>>         > old segwit v0 funding output, and re-open the channel with a new segwit v1\n>>         > funding output are unavoidable. However this adapter commitment lets peers\n>>         > _defer_ these two transactions until closing time.\n>>\n>>         I think there is one downside coming with adapter commitment, which is the uncertainty of\n>>         the fee overhead at the closing time. Instead of closing your segwit v0 channel _now_ with\n>>         known fees, when your commitment is empty of time-sensitive HTLCs, you're taking the risk\n>>         of closing during fees spikes, due a move triggered by your counterparty, when you might\n>>         have HTLCs at stake.\n>>\n>>         It might be more economically rational for a LN node operator to pay the upgrade cost now\n>>         if they wish\u00a0 to benefit from the taproot upgrade early, especially if long-term we expect\n>>         block fees to increase, or wait when there is a \"normal\" cooperative closing.\n>>\n>>         So it's unclear to me what the economic gain of adapter commitments ?\n>>\n>>         > In the remainder of this mail, I'll describe an alternative\n>>         > approach that would allow upgrading nearly all channel/commitment related\n>>         > values (dust limit, max in flight, etc), which is inspired by the way the\n>>         > Raft consensus protocol handles configuration/member changes.\n>>\n>>         Long-term, I think we'll likely need a consensus protocol anyway for multi-party\n>>         constructions (channel factories/payment pools). AFAIU this proposal doesn't aim to roll\n>>         out a full-fledged consensus protocol *now* though it could be wise to ensure what we're\n>>         building slowly moves in this direction. Less critical code to maintain across bitcoin\n>>         codebases/toolchains.\n>>\n>>         > The role of the signature it to prevent \"spoofing\" by one of the parties\n>>         > (authenticate the param change), and also it serves to convince a party that\n>>         > they actually sent a prior commitment propose update during the\n>>         > retransmission phase.\n>>\n>>         What's the purpose of data origin authentication if we assume only two-parties running\n>>         over Noise_XK ?\n>>\n>>         I think it's already a security property we have. Though if we think we're going to reuse\n>>         these dynamic upgrades for N counterparties communicating through a coordinator, yes I\n>>         think it's useful.\n>>\n>>         > In the past, when ideas like this were brought up, some were concerned that\n>>         > it wouldn't really be possible to do this type of updates while existing\n>>         > HTLCs were in flight (hence some of the ideas to clear out the commitment\n>>         > beforehand).\n>>\n>>         The dynamic upgrade might serve in an emergency context where we don't have the leisury to\n>>         wait for the settlement of the pending HTLCs. The timing of those ones might be beyond the\n>>         coordination of link counterparties. Thus, we have to allow upgrade of non-empty\n>>         commitments (and if there are undesirable interferences between new commitment types and\n>>         HTLCs/PTLCs present, deal case-by-case).\n>>\n>>         Antoine\n>>\n>>         Le\u00a0jeu. 24 mars 2022 \u00e0\u00a018:53, Olaoluwa Osuntokun <laolu32 at gmail.com\n>>         <mailto:laolu32 at gmail.com>> a \u00e9crit\u00a0:\n>>\n>>             Hi y'all,\n>>\n>>             ## Dynamic Commitments Retrospective\n>>\n>>             Two years-ish ago I made a mailing list post on some ideas re dynamic\n>>             commitments [1], and how the concept can be used to allow us to upgrade\n>>             channel types on the fly, and also remove pesky hard coded limits like the\n>>             483 HTLC in-flight limit that's present today. Back then my main target was\n>>             upgrading all the existing channels over to the anchor output commitment\n>>             variant, so the core internal routing network would be more resilient in a\n>>             persistent high fee environment (which hasn't really happened over the past\n>>             2 years for various reasons tbh). Fast forward to today, and with taproot\n>>             now active on mainnet, and some initial design work/sketches for\n>>             taproot-native channels underway, I figure it would be good to bump this\n>>             concept as it gives us a way to upgrade all 80k+ public channels to taproot\n>>             without any on chain transactions.\n>>\n>>             ## Updating Across Witness Versions w/ Adapter Commitments\n>>\n>>             In my original mail, I incorrectly concluded that the dynamic commitments\n>>             concept would only really work within the confines of a \"static\" multi-sig\n>>             output, meaning that it couldn't be used to help channels upgrade to future\n>>             segwit witness versions.\u00a0 Thankfully this reply [2] by ZmnSCPxj, outlined a\n>>             way to achieve this in practice. At a high level he proposes an \"adaptor\n>>             commitment\" (similar to the kickoff transaction in eltoo/duplex), which is\n>>             basically an upgrade transaction that spends one witness version type, and\n>>             produces an output with the next (upgraded) type. In the context of\n>>             converting from segwit v0 to v1 (taproot), two peers would collaboratively\n>>             create a new adapter commitment that spends the old v0 multi-sig output, and\n>>             produces a _new_ v1 multi-sig output. The new commitment transaction would\n>>             then be anchored using this new output.\n>>\n>>             Here's a rough sequence diagram of the before and after state to better\n>>             convey the concept:\n>>\n>>             \u00a0 * Before: fundingOutputV0 -> commitmentTransaction\n>>\n>>             \u00a0 * After fundingOutputV0 -> fundingOutputV1 (the adapter) ->\n>>             \u00a0 \u00a0 commitmentTransaction\n>>\n>>             It *is* still the case that _ultimately_ the two transactions to close the\n>>             old segwit v0 funding output, and re-open the channel with a new segwit v1\n>>             funding output are unavoidable. However this adapter commitment lets peers\n>>             _defer_ these two transactions until closing time. When force closing two\n>>             transactions need to be confirmed before the commitment outputs can be\n>>             resolved. However, for co-op close, you can just spend the v0 output, and\n>>             deliver to the relevant P2TR outputs. The adapter commitment can leverage\n>>             sighash anyonecanpay to let both parties (assuming it's symmetric) attach\n>>             additional inputs for fees (to avoid introducing the old update_fee related\n>>             static fee issues), or alternatively inherit the anchor output pattern at\n>>             this level.\n>>\n>>             ## Existing Dynamic Commitments Proposals\n>>\n>>             Assuming this concept holds up, then we need an actual concrete protocol to\n>>             allow for dynamic commitment updates. Last year, Rusty made a spec PR\n>>             outlining a way to upgrade the commitment type (leveraging the new\n>>             commitment type feature bits) upon channel re-establish [3]. The proposal\n>>             relies on another message that both sides send (`stfu`) to clear the\n>>             commitment (similar to the shutdown semantics) before the switch over\n>>             happens. However as this is tied to the channel re-establish flow, it\n>>             doesn't allow both sides to do things like only allow your peer to attach N\n>>             HTLCs to start with, slowing increasing their allotted slots and possibly\n>>             reducing them (TCP AIMD style).\n>>\n>>             ## A Two-Phase Dynamic Commitment Update Protocol\n>>\n>>             IMO if we're adding in a way to do commitment/channel upgrades, then it may\n>>             be worthwhile to go with a more generalized, but slightly more involved\n>>             route instead. In the remainder of this mail, I'll describe an alternative\n>>             approach that would allow upgrading nearly all channel/commitment related\n>>             values (dust limit, max in flight, etc), which is inspired by the way the\n>>             Raft consensus protocol handles configuration/member changes.\n>>\n>>             For those that aren't aware, Raft is a consensus protocol analogous to Paxos\n>>             (but isn't byzantine fault tolerant out of the box) that was designed as a\n>>             more understandable alternative to Paxos for a pedagogical environment.\n>>             Typically the algorithm is run in the context of a fixed cluster with N\n>>             machines, but supports adding/removing machines from the cluster with a\n>>             configuration update protocol. At a high level the way this works is that a\n>>             new config is sent to the leader, with the leader synchronizing the config\n>>             change with the other members of the cluster. Once a majority threshold is\n>>             reached, the leader then commits the config change with the acknowledged\n>>             parties using the new config (basically a two phase commit). I'm skipping\n>>             over some edge cases here that can arise if the new nodes participate\n>>             consensus too early, which can cause a split majority leading to two leaders\n>>             being elected.\n>>\n>>             Applying this to the LN context is a bit simpler than a generalized\n>>             protocol, as we typically just have two parties involved. The initiator is\n>>             already naturally a \"leader\" in our context, as they're the only ones that\n>>             can do things like trigger fee updates.\n>>\n>>             ### Message Structure\n>>\n>>             At a high level I propose we introduce two new messages, with the fields\n>>             looking something like this for `commitment_update_propose`:\n>>             \u00a0* type: 0 (`channel_id`)\n>>             \u00a0 \u00a0* value: [`32*byte`:`chan_id`]\n>>             \u00a0* type: 1 (`propose_sig`)\n>>             \u00a0 \u00a0* value: [`64*byte`:`sig`]\n>>             \u00a0* type: 2 (`update_payload`)\n>>             \u00a0 \u00a0* value: [`*byte`:`tlv_payload`]\n>>\n>>             and this `commitment_update_apply`:\n>>             \u00a0* type: 0 (`channel_id`)\n>>             \u00a0 \u00a0* value: [`32*byte`:`chan_id`]\n>>             \u00a0* type: 1 (`local_propose`)\n>>             \u00a0 \u00a0* value: [`*byte`:`commitment_update_propose`]\n>>             \u00a0* type: 2 (`remote_propose`)\n>>             \u00a0 \u00a0* value: [`*byte`:`commitment_update_propose`]\n>>\n>>             ### Protocol Flow\n>>\n>>             The core idea here is that either party can propose a commitment/channel\n>>             param update, but only the initiator can actually apply it. The\n>>             `commitment_update_propose` encodes the new set of updates, with a signature\n>>             covering the TLV blob for the new params (more on why that's needed later).\n>>             The `commitment_update_apply` includes up to _two_\n>>             `commitment_update_propose` messages (one for the initiator and one for the\n>>             responder, as nested TLV messages). The `commitment_update_propose` message\n>>             would be treated like any other `update_*` message, in that it takes a new\n>>             commitment signature to properly commit/apply it.\n>>\n>>             The normal flow takes the form of both sides sending a\n>>             `commitment_update_propose` message, with the initiator finally committing\n>>             both by sending a `commitment_update_apply` message. In the event that only\n>>             the responder wants to apply a param change/update, then the initiator can\n>>             reply immediately with a `commitment_update_apply` message that doesn't\n>>             include a param change for their commitment (or they just echo the\n>>             parameters if they're acceptable).\n>>\n>>             ### Handling Retransmissions\n>>\n>>             The role of the signature it to prevent \"spoofing\" by one of the parties\n>>             (authenticate the param change), and also it serves to convince a party that\n>>             they actually sent a prior commitment propose update during the\n>>             retransmission phase. As the `commitment_update_propose` message would be\n>>             retransmitted like any other message, if the initiator attempts to commit\n>>             the update but the connection dies, they'll retransmit it as normal along\n>>             with their latest signature.\n>>\n>>             ### Nested TLV Param Generality\n>>\n>>             The messages as sketched out here just have an opaque nested TLV field which\n>>             makes it extensible to add in other things like tweaking the total number of\n>>             max HTLCs, the current dust values, min/max HTLCs, etc (all things that are\n>>             currently hard coded for the lifetime of the channel). An initial target\n>>             would likely just be a `chan_type` field, with future feature bits governing\n>>             _what_ type of commitment updates both parties understand in the future.\n>>\n>>             In the past, when ideas like this were brought up, some were concerned that\n>>             it wouldn't really be possible to do this type of updates while existing\n>>             HTLCs were in flight (hence some of the ideas to clear out the commitment\n>>             beforehand). I don't see a reason why this fundamentally _shouldn't_ be\n>>             allowed, as from the point of view of the channel update state machine, all\n>>             updates (adds/removes) get applied as normal, but with this _new_ commitment\n>>             type/params. The main edge case we'll need to consider is cases where the\n>>             new params make older HTLCs invalid for some reason.\n>>\n>>             ## Conclusion\n>>\n>>             Using the adapter commitment idea combined with a protocol for updating\n>>             commitments on the fly, would potentially allow us to update all 80k+ segwit\n>>             v0 channels to the base level of taprooty channels without any on chain\n>>             transactions. The two transactions (open+close) must happen eventually, but\n>>             by holding another layer of spends off-chain we can defer them (potentially\n>>             indefinitely, as we have channels today that have been opened for over a\n>>             year).\n>>\n>>             Deploying a generalised on-the-fly dynamic commitment update protocol gives\n>>             us a tool to future proof the _existing_ anchored multi-sig outputs in the\n>>             chain, and also a way to remove many of the hard coded parameters we have\n>>             today in the protocol. One overly inflexible parameter we have today in the\n>>             network is the 483 HTLC limit. Allowing this value to float would allow\n>>             peers to apply similar congestion avoidance algorithm that are used in TCP\n>>             today, and also give us a way to protect the network against future\n>>             unforeseen widespread policy changes (like a raising of the dust limit).\n>>\n>>             -- Laolu\n>>\n>>             [1]: https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-July/002763.html\n>>             <https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-July/002763.html>\n>>             [2]: https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-July/002770.html\n>>             <https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-July/002770.html>\n>>             [3]: https://github.com/lightning/bolts/pull/868\n>>             <https://github.com/lightning/bolts/pull/868>\n>>             _______________________________________________\n>>             Lightning-dev mailing list\n>>             Lightning-dev at lists.linuxfoundation.org <mailto:Lightning-dev at lists.linuxfoundation.org>\n>>             https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>             <https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev>\n>>\n>>         _______________________________________________\n>>         Lightning-dev mailing list\n>>         Lightning-dev at lists.linuxfoundation.org <mailto:Lightning-dev at lists.linuxfoundation.org>\n>>         https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>         <https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev>\n>>\n>>     _______________________________________________\n>>     Lightning-dev mailing list\n>>     Lightning-dev at lists.linuxfoundation.org <mailto:Lightning-dev at lists.linuxfoundation.org>\n>>     https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>     <https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev>\n>"
            }
        ],
        "thread_summary": {
            "title": "Dynamic Commitments Part 2: Taprooty Edition",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Matt Corallo"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 39295
        }
    },
    {
        "title": "[Lightning-dev] Watchtower-Free Lightning Channels For Casual Users",
        "thread_messages": [
            {
                "author": "Bastien TEINTURIER",
                "date": "2022-11-02T16:37:36",
                "message_text_only": "Good morning John,\n\n> As a result, once the dedicated user decides to splice out some channel\nfunds, the dedicated user cannot access those funds until some time *after*\nthe casual user has been online (provided the protocol is trust-free).\n\nThe trick here is that the dedicated user *always* has a splice-out tx\navailable, they don't need to to wait for the casual user to reconnect.\nAt every update of the channel, the casual user will sign a splice tx\nthat lets the dedicated user get some of their funds back in case the\ncasual user goes offline for a long duration. But that splice tx will\nindeed be csv-delayed.\n\nMost of the time those splice-out txs will simply be discarded the next\ntime the channel is updated, but it gives the dedicated user a guarantee\nthat they're able to get some funds back easily without closing the\nchannel if they need it.\n\n> Given this observation, what if the protocol were changed so that,\ninstead of pre-signing a splice transaction, the casual user always checks\nin with the dedicated user whenever they check the blockchain? At such a\ncheck-in, if the dedicated user wants to splice out some channel funds,\nthey send the casual user a splice transaction which splices out some of\nthe funds to the dedicated user without requiring a to_self delay. The\ncasual user then signs the splice transaction and returns the signature as\npart of the check-in.\n\nYes, that is something we'll have as well. On the LSP side, we'll most\nlikely try to get the mobile user to connect and negotiate a splice-out\nwithout any delays. If the mobile user doesn't connect, then we'll use\nthe pre-signed delayed splice-out we have from the latest channel state\nupdate.\n\nSorry if this is very hand-wavy, we haven't worked on the details yet,\nbut at a high-level, this is the kind of flexibility we'd like to have.\n\n> However, if we eventually get to the point where the blockchain is\nhighly-contested and fees are high, it may no longer be worth paying the\nfees to put a splice transaction on-chain unless a large amount of capital\nis at stake for a long period of time.\n\nThat's true, we're currently using the assumption that fees will be high\nbut there will be regular opportunities to get txs confirmed at a lower\nfeerate because of random fluctuations in mempool congestion. If that\ndoesn't happen, funds will most likely be idle and we won't use those\nsplices very often.\n\nCheers,\nBastien\n\nLe lun. 31 oct. 2022 \u00e0 01:20, jlspc <jlspc at protonmail.com> a \u00e9crit :\n\n> Hi Bastien,\n>\n> Thanks for your detailed response.\n>\n> I see how the use of a pre-signed \"splice\" transaction that allows the dedicated user to obtain some of their capital creates an inherent trade-off between the dedicated user's capital efficiency and the casual user's ability to be offline for an extended period of time.\n>\n> In order for the use of a pre-signed splice transaction to be safe, the casual user has to check the blockchain and see the splice transaction before it can be spent by the dedicated user (in order to revoke it if needed). As a result, once the dedicated user decides to splice out some channel funds, the dedicated user cannot access those funds until some time *after* the casual user has been online (provided the protocol is trust-free).\n>\n> Given this observation, what if the protocol were changed so that, instead of pre-signing a splice transaction, the casual user always checks in with the dedicated user whenever they check the blockchain? At such a check-in, if the dedicated user wants to splice out some channel funds, they send the casual user a splice transaction which splices out some of the funds to the dedicated user without requiring a to_self delay. The casual user then signs the splice transaction and returns the signature as part of the check-in.\n>\n> This approach has a couple potential advantages:\n> 1) It allows the dedicated user to splice out funds as soon as the casual user comes online (rather than sometime after the casual user comes online, as shown above). Therefore, the use of capital is made more efficient.\n> 2) It allows the splice transaction to pay fees based on the current fee rate, rather than a pre-calculated fee rate.\n>\n> It does have some potential disadvantages:\n> 1) It requires the casual user to stay online long enough to complete the roundtrip of sending a check-in message to the dedicated user, getting the splice message to sign, signing it, and sending the signature back to the dedicated user.\n> 2) It assumes that the casual user checks the blockchain themselves, rather than using a watchtower service.\n> 3) It requires the dedicated user to decide at the time of the check-in whether or not to perform the splice, as the splice transaction cannot be revoked.\n>\n> In any case, using a check-in and a non-revokable splice transaction appears to have some advantages in terms of capital efficiency. It's also somewhat more compatible with the WF protocol, as the delay for the dedicated user to obtain spliced-out funds is dependent on the actual time until the casual user next comes online, rather than the worst-case delay until the casual user comes online. This could be a big difference if the casual user is typically online every day, but doesn't want the burden of having to be online every day (or every week). I'm interested in your thoughts on this.\n>\n> Finally, I understand that the ability to quickly splice out channel funds to improve capital efficiency is critical in the current environment. However, if we eventually get to the point where the blockchain is highly-contested and fees are high, it may no longer be worth paying the fees to put a splice transaction on-chain unless a large amount of capital is at stake for a long period of time.\n>\n> Regards,\n> John\n>\n>\n>\n>\n> Sent with Proton Mail <https://proton.me/> secure email.\n>\n> ------- Original Message -------\n> On Monday, October 24th, 2022 at 2:50 AM, Bastien TEINTURIER <\n> bastien at acinq.fr> wrote:\n>\n> Hi John,\n>\n> > My understanding of the current Lightning protocol is that users specify\n> a to_self_delay safety parameter which is typically about 2 weeks and that\n> they pay for routing, but not for their partner's cost-of-capital. Is that\n> correct?\n> >\n> > If it is, then when a dedicated user (DLU) partners with a casual user\n> (CLU), the DLU can only move liquidity to another Lightning channel by\n> either:\n> > 1) getting the CLU to sign a cooperative close transaction that enables\n> (or directly implements) the desired movement of funds, or\n> > 2) putting a non-cooperative close transaction on-chain and waiting\n> approximately 2 weeks (based on the to_self_delay parameter set by the CLU)\n> before moving the liquidity.\n>\n> That's correct, but that's something we intend to change to let LSPs\n> re-allocate their liquidity more frequently and more efficiently.\n>\n> We don't have a fully specified proposal yet, but by leveraging a\n> mechanism similar to splicing [1], mobile users would pre-sign a\n> transaction that keeps the channel open, but lets the LSP get their\n> balance (or part of it) out non-interactively. This would be used by\n> LSPs if the user isn't using their channel actively enough and the LSP\n> is low on available liquidity for other, more active users.\n>\n> This transaction would need to be revokable and must be delayed, since\n> we still need the user to be able to punish malicious LSPs, but ideally\n> (from the LSP's point of view) that delay should be at most 1 week, which\n> forces users to regularly check the blockchain (which isn't ideal).\n>\n> It really is a trade-off to be able to lower the fees LSPs make users\n> pay for liquidity, because LSPs know they can move it cheaply when it\n> becomes necessary. I can see a future where users chose their trade-off:\n> pay more to be able to go offline for longer periods or pay less but\n> check the blockchain regularly. The same LSP could offer both features,\n> if they're able to price them correctly (which isn't trivial).\n>\n> > My intuition is that in the long run, the cost of bitcoin capital will\n> be very low, as it is an inherently deflationary monetary unit (and thus\n> its value should increase with time). If this is correct, the long term\n> cost-of-capital charges should be very low.\n>\n> I'm not convinced by that...even though the value of capital increases\n> with time, liquidity providers will compete to earn more return on their\n> locked capital. If one liquidity provider is able to use their capital\n> more efficiently than another, they will be able to offer lower prices\n> to their customers to a point that isn't economically viable for the\n> other, less efficient liquidity provider?\n>\n> Since lightning doesn't allow any form of fractional reserve, the total\n> available capital needs to be split between all existing users of the\n> system, which is very inconvenient when trying to onboard a high number\n> of new users.\n>\n> This is very theoretical though, I have absolutely no idea how those\n> dynamics will actually play out, but it will be interesting to watch it\n> unfold.\n>\n> Cheers,\n> Bastien\n>\n> [1] https://github.com/lightning/bolts/pull/863\n>\n> Le mer. 12 oct. 2022 \u00e0 02:11, jlspc <jlspc at protonmail.com> a \u00e9crit :\n>\n>>\n>> Hey Bastien,\n>>\n>> Thanks for your reply.\n>>\n>> Responses are in-line below:\n>>\n>> > Hey John,\n>> >\n>> > Thanks for sharing, this is very interesting.\n>> >\n>> > There is a good insight here that we can remove the intermediate\n>> > HTLC-timeout transaction for outgoing payments because we are the\n>> > origin of that payment (and thus don't need to quickly claim the\n>> > HTLC on-chain to then relay that failure to a matching incoming HTLC).\n>> >\n>> > More generally, you have perfectly identified that most of the\n>> > complexity of today's transactions come from the need to ensure that\n>> > a failing/malicious downstream channel doesn't negatively impact\n>> > honest upstream channels when relaying payments, and that some of this\n>> > complexity can be lifted when nodes don't relay payments.\n>>\n>> Thanks!\n>>\n>> > However, my main criticism of your proposal is that liquidity isn't free.\n>> > While your improvements are great from the CLU's point of view, I'm not\n>> > sure they're acceptable for the DLU. The main (probably only) job of an\n>> > LSP (DLU in your terminology) is to efficiently allocate their liquidity.\n>> > In order to do so, they must be able to quickly move liquidity from where\n>> > it's unused to where it may be better used. That means closely watching\n>> > the demand for block space and doing on-chain transactions when fees are\n>> > low (to open/close channels, splice funds in/out [1], make peer swaps [2],\n>> > etc). With your proposal, DLUs won't be able to quickly move liquidity\n>> > around, so the only way to make up for this is to charge the CLU for the\n>> > loss of expected revenue. I'm afraid that the amount DLUs would need to\n>> > charge CLUs will be prohibitively expensive for most CLUs.\n>> >\n>> > I'm curious to get your feedback on that point.\n>>\n>> I really appreciate your insight here. I'm just an interested observer who doesn't have experience with creating and deploying Lightning nodes, so I'm sure you have a better understanding of the current costs and trade-offs than I do.\n>>\n>> My understanding of the current Lightning protocol is that users specify a to_self_delay safety parameter which is typically about 2 weeks and that they pay for routing, but not for their partner's cost-of-capital. Is that correct?\n>>\n>> If it is, then when a dedicated user (DLU) partners with a casual user (CLU), the DLU can only move liquidity to another Lightning channel by either:\n>> 1) getting the CLU to sign a cooperative close transaction that enables (or directly implements) the desired movement of funds, or\n>> 2) putting a non-cooperative close transaction on-chain and waiting approximately 2 weeks (based on the to_self_delay parameter set by the CLU) before moving the liquidity.\n>>\n>> In contrast, with the Watchtower-Free (WF) protocol, the DLU could only move liquidity to another Lightning channel by either:\n>> 1) getting the CLU to sign a cooperative close transaction that enables (or directly implements), the desired movement of funds, or\n>> 2) putting a non-cooperative close transaction on-chain and waiting approximately 1-3 months (based on the I_L parameter set by the CLU) before moving the liquidity.\n>> In case 1), it would make sense for the DLU to refund the remaining portion of CLU's cost-of-capital pre-payment to the CLU, as that capital is now being made available to the DLU. This was not proposed in the paper, but it should probably be added.\n>>\n>> With this change (namely refunding the remainder of the cost-of-capital pre-payment), it seems like the only disadvantage of the WF protocol to the DLU is the larger delay (1-3 months vs. 2 weeks). Do you feel increasing the delay from 2 weeks to 1 month is prohibitive?\n>>\n>> My intuition is that in the long run, the cost of bitcoin capital will be very low, as it is an inherently deflationary monetary unit (and thus its value should increase with time). If this is correct, the long term cost-of-capital charges should be very low.\n>>\n>> What are your thoughts on this?\n>>\n>> Thanks,\n>> John\n>>\n>> > Thanks again for sharing, and for the inherited IDs [3] proposal as well!\n>> >\n>> > Bastien\n>> >\n>> > [1] <a href=\"https://github.com/lightning/bolts/pull/863\">https://github.com/lightning/bolts/pull/863</a>\n>> > [2] <a href=\"https://www.peerswap.dev/\">https://www.peerswap.dev/</a>\n>> > [3] <a href=\"https://github.com/JohnLaw2/btc-iids\">https://github.com/JohnLaw2/btc-iids</a>\n>>\n>>\n>> Sent with Proton Mail <https://proton.me/> secure email.\n>>\n>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221102/854dbdd6/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Watchtower-Free Lightning Channels For Casual Users",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Bastien TEINTURIER"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 13902
        }
    },
    {
        "title": "[Lightning-dev] Agent-Based Fee Setting in Payment Channel Networks",
        "thread_messages": [
            {
                "author": "Mojtaba Tefagh",
                "date": "2022-11-03T07:12:56",
                "message_text_only": "An HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221103/84997b21/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Agent-Based Fee Setting in Payment Channel Networks",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Mojtaba Tefagh"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 144
        }
    },
    {
        "title": "[Lightning-dev] [bitcoin-dev] Taro: A Taproot Asset Representation Overlay",
        "thread_messages": [
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2022-11-03T09:26:05",
                "message_text_only": "Hi,\n\nI wanted to chime in on the \"teleport\" feature explained by Ruben, as I\nthink exploring something similar for Taro could be super useful in an LN\nsetting.\n\nIn today's Taro, to transfer tokens you have to spend a UTXO, and present a\nproof showing that there are tokens committed to in the output you are\nspending. Let's say this UTXO is 'utxo:0'.\n\nIn contrast, to spend teleported tokens, you would still spend utxo:0, but\nyou would only have to present a proof that _some txout_ on-chain have\ncommitted tokens to utxo:0.\n\nAs Ruben points out, this makes it possible to send tokens to an already\nspent TXO, essentially burning the tokens.\n\nHowever, it opens up some exciting possibilities IMO. You can in essence\nuse this to \"re-fill\" UTXOs with tokens, which is very interesting for LN\nchannels:\n\n- You could \"add\" tokens to your already open channels. The only thing\nneeded is for the channel participants to be presented the proof that\ntokens were sent to the funding output, and they can update their\ncommitment transaction to start spending these tokens.\n- You can \"top-up\" all your channels in a single on-chain tx. Since a\nsingle output can commit tokens to several UTXOs, you could with a single\non-chain transaction add tokens to many channels without opening and\nclosing them.\n\nRGB also has the ability to \"blind\" the UTXO that tokens get teleported to,\nhiding the recipient UTXO. This is cool, since I could withdraw tokens from\nan exchange directly into my LN channel, without revealing my channel UTXO.\n\nI found the explanation of the teleport feature in this blog post pretty\ngood:\nhttps://medium.com/@FedericoTenga/understanding-rgb-protocol-7dc7819d3059\n\n- Johan\n\nOn Sun, Apr 10, 2022 at 6:52 PM Ruben Somsen <rsomsen at gmail.com> wrote:\n\n> Hi Laolu,\n>\n> >happy to hear that someone was actually able to extract enough details\n> from the RGB devs/docs to be able to analyze it properly\n>\n> Actually, even though I eventually puzzled everything together, this did\n> not go well for me either. There is a ton of documentation, but it's a maze\n> of unhelpful details, and none of it clearly maps out the fundamental\n> design. I was also disappointed by the poor response I received when asking\n> questions, and I ended up getting chastised for helping others understand\n> it and pointing out potential flaws[1][2][3].Given my experience, I think\n> the project is not in great shape, so the decision to rebuild from scratch\n> seems right to me.\n>\n> That said, in my opinion the above should not factor into the decision of\n> whether RGB should be credited in the Taro documentation. The design\n> clearly precedes (and seems to have inspired) Taro, so in my opinion this\n> should be acknowledged. Also, the people that are responsible for the\n> current shape of RGB aren't the people who originated the idea, so it would\n> not be fair to the originators either (Peter Todd, Alekos Filini, Giacomo\n> Zucco).\n>\n> >assets can be burnt if a user doesn't supply a valid witness\n>\n> I am in agreement with what you said, but it is not clear to me whether we\n> are on the same page. What I tried to say was that it does not make sense\n> to build scripting support into Taro, because you can't actually do\n> anything interesting with it due to this limitation. The only type of smart\n> contract you can build is one where you limit what the owner (as defined by\n> Bitcoin's script) can do with their own Taro tokens, or else he will burn\n> them \u2013 not very useful. Anything involving a conditional transfer of\n> ownership to either A or B (i.e. any meaningful type of script) won't work.\n> Do you see what I mean, or should I elaborate further?\n>\n> >TAPLEAF_UPDATE_VERIFY can actually be used to further _bind_ Taro transitions\n> at the Bitcoin level, without Bitcoin explicitly needing to be aware\n>\n> That is conceptually quite interesting. So theoretically you could get\n> Bitcoin covenants to enforce certain spending conditions on Taro assets.\n> Not sure how practical that ends up being, but intriguing to consider.\n>\n> >asset issuer to do a \"re-genesis\"\n>\n> Yes, RGB suggested the same thing, and this can work under some\n> circumstances, but note that this won't help for tokens that aim to have a\n> publicly audited supply, as the proof that a token was legitimately\n> re-issued is the history of the previous token (so you'd actually be making\n> things worse, as now everyone has to verify it). And of course the idea\n> also requires the issuer to be active, which may not always be the case.\n>\n> >I'm not familiar with how the RGB \"teleport\" technique works [...] Can\n> you point me to a coherent explanation of the technique\n>\n> To my knowledge no good explanation exists. \"Teleporting\" is just what I\n> thought was a good way of describing it. Basically, in your design when\n> Alice wants to send a Taro token to Bob, Alice has to spend her own output,\n> make a new output for Bob, and make a change output for herself. Inside the\n> Taro tree you'll then point to the index of Bob's output in order to assign\n> the tokens to his new output. Instead of pointing to the index, you could\n> point to the outpoint (txid, index) of an existing UTXO owned by Bob, thus\n> \"teleporting\" the Taro tokens to this UTXO. This saves on-chain space, as\n> now you don't have to create a new output for Bob (but now you have to\n> ensure Bob doesn't spend from this output while you're simultaneously\n> sending tokens to it, as I mentioned in my previous post, as this would\n> destroy the tokens).\n>\n> The above also reminds me of another potential issue which you need to be\n> aware of, if you're not already. Similar to my comment about how the\n> location of the Taro tree inside the taproot tree needs to be deterministic\n> for the verifier, the output in which you place the Taro tree also needs to\n> be. If it's not, then you can commit to a different Taro tree in each\n> output of the transaction, allowing you to secretly fork the history.\n>\n> Hope this helps.\n>\n> Cheers,\n> Ruben\n>\n> [1] https://twitter.com/SomsenRuben/status/1397267261619064836\n> [2] https://twitter.com/SomsenRuben/status/1397559406565462017\n> [3] https://twitter.com/afilini/status/1397484341236797441\n>\n> On Fri, Apr 8, 2022 at 7:48 PM Olaoluwa Osuntokun <laolu32 at gmail.com>\n> wrote:\n>\n>> (this might be a double post as it ran into the size limit)\n>>\n>> Hi Ruben,\n>>\n>> Thanks! I don't really consider things final until we have a good set of\n>> test\n>> vectors in the final set, after which we'd start to transition the set of\n>> documents beyond the draft state.\n>>\n>> > Seeing as there's a large amount of overlap with RGB, a protocol which\n>> I have\n>> > examined quite extensively, I believe some of the issues I uncovered in\n>> that\n>> > project also apply here.\n>>\n>> I'm happy to hear that someone was actually able to extract enough\n>> details from\n>> the RGB devs/docs to be able to analyze it properly! In the past I tried\n>> to ask\n>> their developers questions about how things like transfers worked[1][2],\n>> but it\n>> seemed either people didn't know, or they hadn't finished the core design\n>> (large TBD sections) as they were working on adding other components to\n>> create\n>> a \"new new Internet\".\n>>\n>> > Furthermore, the Taro script is not enforced by Bitcoin, meaning those\n>> who\n>> > control the Bitcoin script can always choose to ignore the Taro script\n>> and\n>> > destroy the Taro assets as a result.\n>>\n>> This is correct, as a result in most contexts, an incentive exists for the\n>> holder of an asset to observe the Taro validation rules as otherwise,\n>> their\n>> assets are burnt in the process from the PoV of asset verifiers. In the\n>> single\n>> party case things are pretty straight forward, but more care needs to be\n>> taken\n>> in cases where one attempts to express partial application and permits\n>> anyone\n>> to spend a UTXO in question.\n>>\n>> By strongly binding all assets to Bitcoin UTXOs, we resolve issues\n>> related to\n>> double spending or duplicate assets, but needs to mind the fact that\n>> assets can\n>> be burnt if a user doesn't supply a valid witness. There're likely ways\n>> to get\n>> around this by lessening the binding to Bitcoin UTXO's, but then the\n>> system\n>> would need to be able to collect, retain and order all the set of possible\n>> spends, essentially requiring a parallel network. The core of the system\n>> as it\n>> stands today is pretty simple (which was an explicit design goal to avoid\n>> getting forever distracted by the large design space), with a minimal\n>> implementation being relatively compact given all the Bitcoin\n>> context/design\n>> re-use.\n>>\n>> Also one cool trait of the way commitments are designed is that the Taro\n>> commitment impact the final derived taproot output key. As a result,\n>> potential\n>> Script extensions like TAPLEAF_UPDATE_VERIFY can actually be used to\n>> further\n>> _bind_ Taro transitions at the Bitcoin level, without Bitcoin explicitly\n>> needing to be aware of the Taro rules. In short, covenants can allow\n>> Bitcoin\n>> Script to bind Taro state transitions, without any of the logic bleeding\n>> over,\n>> as the covenant just checks for a certain output key, which is a function\n>> of\n>> the Taro commitment being present.\n>>\n>> > There are two possible designs here: a.) The token history remains\n>> separate \u2013\n>> > Dave receives Alice's 2 tokens, Bob's tokens are split and he receives\n>> 2 (or\n>> > 3 from Bob 1 from Alice).  b.) The token history gets merged \u2013 Dave\n>> receives\n>> > 4 tokens (linking the new output with both Alice and Bob's history).\n>>\n>> Mechanically, with respect to the way the change/UTXOs work in the\n>> system, both\n>> are expressible: Dave can chose to merge them into a single UTXO (with the\n>> appropriate witnesses included for each of them), or Dave can keep them\n>> distinct in the asset tree. You're correct in that asset issuers may opt\n>> to\n>> issue assets in denominations vs allowing them to be fully divisible.\n>> Ultimately, the compatibility with the LN layer will be the primary way\n>> to keep\n>> asset histories compressed, without relying on another trust model, or\n>> relying\n>> on the incentive of an asset issuer to do a \"re-genesis\" which would\n>> effectively re-create assets in a supply-preserving manner (burn N units,\n>> then\n>> produce a new genesis outpoint for N units). Alternatively,\n>> implementations can\n>> also chose to utilize a checkpointing system similar to what some Bitcoin\n>> full\n>> node clients do today.\n>>\n>> >  is that you end up with a linked transaction graph, just like in\n>> Bitcoin\n>>\n>> This is correct, the protocol doesn't claim to achieve better privacy\n>> guarantees than the base chain. However inheriting this transaction graph\n>> model\n>> imo makes it easier for existing Bitcoin developers to interact with the\n>> system, and all the data structures are very familiar tooling wise.\n>> However any\n>> privacy enhancing protocol used for on-chain top-level Bitcoin UTXOs can\n>> also\n>> be applied to Taro, so people can use things like coinswap and coinjoin,\n>> along\n>> with LN to shed prior coin lineages.\n>>\n>> > This implies the location of the Taro tree inside the taproot tree is\n>> not\n>> > fixed. What needs to be prevented here is that a taproot tree contains\n>> more\n>> > than one Taro tree, as that would enable the owner of the commitment to\n>> show\n>> > different histories to different people.\n>>\n>> Great observation, I patched a similar issue much earlier in the design\n>> process\n>> by strongly binding all signatures to a prevOut super-set (so the outpoint\n>> along with the unique key apth down into the tree), which prevents\n>> duplicating\n>> the asset across outputs, as signature verification would fail.\n>>\n>> In terms of achieving this level of binding within the Taro tree itself,\n>> I can\n>> think of three options:\n>>\n>>   1. Require the Taro commitment to be in the first/last position within\n>> the\n>>   (fully sorted?) Tapscript tree, and also require its sibling to be the\n>> hash\n>>   of some set string (all zeroes or w/e). We'd require the sibling to the\n>> empty\n>>   as the tapscript hashes are sorted before hashing so you sort of lose\n>> that\n>>   final ordering information.\n>>\n>>   2. Include the position of the Taro commitment within the tapscript tree\n>>   within the sighash digest (basically the way the single input in the\n>> virtual\n>>   transaction is created from the TLV structure).\n>>\n>>   3. Include the position of the Taro commitment within the tapscript\n>> tree as\n>>   part of the message that's hashed to derive asset IDs.\n>>\n>> AFAICT, #1 resolves the issue entirely, #2 renders transfers outside of\n>> the\n>> canonical history invalid, and #2 minds hte asset ID to the initial\n>> position\n>> meaning you can track a canonical lineage from the very start.\n>>\n>> > Finally, let me conclude with two questions. Could you clarify the\n>> purpose of\n>> > the sparse merkle tree in your design?\n>>\n>> Sure, it does a few things:\n>>\n>>   * Non-inclusion proofs so I can do things like prove to your I'm no\n>> longer\n>>     committing to my 1-of-1 holographic beefzard card when we swap.\n>>\n>>   * The key/tree structure means that the tree is history independent,\n>> meaning\n>>     that if you and I insert the same things into the tree in a different\n>>     order, we'll get the same root hash. This is useful for things like\n>>     tracking all the issuance events for a given asset, or allowing two\n>>     entities to sync their knowledge/history of a single asset, or a set\n>> of\n>>     assets.\n>>\n>>   * Each asset/script mapping to a unique location within the tree means\n>> it's\n>>     easy to ensure uniqueness of certain items/commitments (not possible\n>> to\n>>     commit to the same asset ID twice in the tree as an example).\n>>\n>>   * The merkle-sum trait means I that validation is made simpler, as you\n>> just\n>>     check that the input+output commitment sum to the same value, and I\n>> can\n>>     also verify that if we're swapping, then you aren't committing to more\n>>     units that exist (so I make sure I don't get an invalid split).\n>>\n>> > And the second question \u2013 when transferring Taro token ownership from\n>> one\n>> > Bitcoin UTXO to another, do you generate a new UTXO for the recipient\n>> or do\n>> > you support the ability to \"teleport\" the tokens to an existing UTXO\n>> like how\n>> > RGB does it? If the latter, have you given consideration to timing\n>> issues\n>> > that might occur when someone sends tokens to an existing UTXO that\n>> > simultaneously happens to get spent by the owner?\n>>\n>> So for interactive transfers, the UTXOs generated as just the ones part\n>> of the\n>> MIMO transaction. When sending via the address format, a new non-dust\n>> output is\n>> created which holds the new commitment, and uses an internal key provided\n>> by\n>> the receiver, so only they can move the UTXO. Admittedly, I'm not\n>> familiar with\n>> how the RGB \"teleport\" technique works, I checked out some slide decks a\n>> while\n>> back, but they were mostly about all the new components they were\n>> creating and\n>> their milestone of 1 million lines of code. Can you point me to a coherent\n>> explanation of the technique? I'd love to compare/contrast so we can\n>> analyze\n>> the diff tradeoffs being made here.\n>>\n>> Thanks for an initial round of feedback/analysis, I'll be updating the\n>> draft\n>> over the next few days to better spell things out and particularly that\n>> commitment/sighash uniqueness trait.\n>>\n>> -- Laolu\n>>\n>> [1]:\n>> https://twitter.com/roasbeef/status/1330654936074371073?s=20&t=feV0kWAjJ6MTQlFm06tSxA\n>> [2]:\n>> https://twitter.com/roasbeef/status/1330692571736117249?s=20&t=feV0kWAjJ6MTQlFm06tSxA\n>>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221103/a53b523d/attachment-0001.html>"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2022-11-05T00:35:53",
                "message_text_only": "Hi Johan,\n\nI haven't really been able to find a precise technical explanation of the\n\"utxo teleport\" scheme, but after thinking about your example use cases a\nbit, I don't think the scheme is actually sound. Consider that the scheme\nattempts to target transmitting \"ownership\" to a UTXO. However, by the time\nthat transaction hits the chain, the UTXO may no longer exist. At that\npoint, what happens to the asset? Is it burned? Can you retry it again? Does\nit go back to the sender?\n\nAs a concrete example, imagine I have a channel open, and give you an\naddress to \"teleport\" some additional assets to it. You take that addr, then\nmake a transaction to commit to the transfer. However, the block before you\ncommit to the transfer, my channel closes for w/e reason. As a result, when\nthe transaction committing to the UTXO (blinded or not), hits the chain, the\nUTXO no longer exists. Alternatively, imagine the things happen in the\nexpected order, but then a re-org occurs, and my channel close is mined in a\nblock before the transfer. Ultimately, as a normal Bitcoin transaction isn't\nused as a serialization point, the scheme seems to lack a necessary total\nordering to ensure safety.\n\nIf we look at Taro's state transition model in contrast, everything is fully\nbound to a single synchronization point: a normal Bitcoin transaction with\ninputs consumed and outputs created. All transfers, just like Bitcoin\ntransactions, end up consuming assets from the set of inputs, and\nre-creating them with a different distribution with the set of outputs. As a\nresult, Taro transfers inherit the same re-org safety traits as regular\nBitcoin transactions. It also isn't possible to send to something that won't\nultimately exist, as sends create new outputs just like Bitcoin\ntransactions.\n\nTaro's state transition model also means anything you can do today with\nBitcoin/LN also apply. As an example, it would be possible for you to\nwithdrawn from your exchange into a Loop In address (on chain to off chain\nswap), and have everything work as expected, with you topping off your\nchannel. Stuff like splicing, and other interactive transaction construction\nschemes (atomic swaps, MIMO swaps, on chain auctions, etc) also just work.\n\nIgnoring the ordering issue I mentioned above, I don't think this is a great\nmodel for anchoring assets in channels either. With Taro, when you make the\nchannel, you know how many assets are committed since they're all committed\nto in the funding output when the channel is created. However, let's say we\ndo teleporting instead: at which point would we recognize the new asset\n\"deposits\"? What if we close before a pending deposits confirms, how can one\nregain those funds? Once again you lose the serialization of events/actions\nthe blockchain provides. I think you'd also run into similar issues when you\nstart to think about how these would even be advertised on a hypothetical\ngossip network.\n\nI think one other drawback of the teleport model iiuc is that: it either\nrequires an OP_RETURN, or additional out of band synchronization to complete\nthe transfer. Since it needs to commit to w/e hash description of the\nteleport, it either needs to use an OP_RETURN (so the receiver can see the\non chain action), or the sender needs to contact the receiver to initiate\nthe resolution of the transfer (details committed to in a change addr or\nw/e).\n\nWith Taro, sending to an address creates an on-chain taproot output just\nlike sending to a P2TR address. The creation of the output directly creates\nthe new asset anchor/output as well, which allows the receiver to look for\nthat address on chain just like a normal on chain transaction. To 3rd party\nobservers, it just looks like a normal P2TR transfer. In order to finalize\nthe receipt of the asset, the receiver needs to obtain the relevant\nprovenance proofs, which can be obtained from a multi-verse gRPC/HTTP\nservice keyed by the input outpoint and output index. In short, the send\nprocess is fully async, with the sender and receiver using the blockchain\nitself as a synchronization point like a normal Bitcoin wallet.\n\n-- Laolu\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221104/354c256b/attachment.html>"
            },
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2022-11-07T13:51:12",
                "message_text_only": "Hi Laolu,\n\nYeah, that is definitely the main downside, as Ruben also mentioned:\ntokens are \"burned\" if they get sent to an already spent UTXO, and\nthere is no way to block those transfers.\n\nAnd I do agree with your concern about losing the blockchain as the\nmain synchronization point, that seems indeed to be a prerequisite for\nmaking the scheme safe in terms of re-orgs and asynchronicity.\n\nI do think the scheme itself is sound though (maybe not off-chain, see\nbelow): it prevents double spending and as long as the clients adhere\nto the \"rule\" of not sending to a spent UTXO you'll be fine (if not\nyour tokens will be burned, the same way as if you don't satisfy the\nTaro script when spending).\n\nThinking more about the examples you gave, I think you are right it\nwon't easily be compatible with LN channels though:\nIf you want to refill an existing channel with tokens, you need the\nchannel counterparties to start signing new commitments that include\nspending the newly sent tokens. A problem arises however, if the\nchannel is force-closed with a pre-existing commitment from before the\ntoken transfer took place. Since this commitment will be spending the\nfunding UTXO, but not the new tokens, the tokens will be burned. And\nthat seems to be harder to deal with (Eltoo style channels could be an\navenue to explore, if one could override the broadcasted commitment).\n\nTl;dr: I think you're right, the scheme is not compatible with LN.\n\n- Johan\n\n\nOn Sat, Nov 5, 2022 at 1:36 AM Olaoluwa Osuntokun <laolu32 at gmail.com> wrote:\n>\n> Hi Johan,\n>\n> I haven't really been able to find a precise technical explanation of the\n> \"utxo teleport\" scheme, but after thinking about your example use cases a\n> bit, I don't think the scheme is actually sound. Consider that the scheme\n> attempts to target transmitting \"ownership\" to a UTXO. However, by the time\n> that transaction hits the chain, the UTXO may no longer exist. At that\n> point, what happens to the asset? Is it burned? Can you retry it again? Does\n> it go back to the sender?\n>\n> As a concrete example, imagine I have a channel open, and give you an\n> address to \"teleport\" some additional assets to it. You take that addr, then\n> make a transaction to commit to the transfer. However, the block before you\n> commit to the transfer, my channel closes for w/e reason. As a result, when\n> the transaction committing to the UTXO (blinded or not), hits the chain, the\n> UTXO no longer exists. Alternatively, imagine the things happen in the\n> expected order, but then a re-org occurs, and my channel close is mined in a\n> block before the transfer. Ultimately, as a normal Bitcoin transaction isn't\n> used as a serialization point, the scheme seems to lack a necessary total\n> ordering to ensure safety.\n>\n> If we look at Taro's state transition model in contrast, everything is fully\n> bound to a single synchronization point: a normal Bitcoin transaction with\n> inputs consumed and outputs created. All transfers, just like Bitcoin\n> transactions, end up consuming assets from the set of inputs, and\n> re-creating them with a different distribution with the set of outputs. As a\n> result, Taro transfers inherit the same re-org safety traits as regular\n> Bitcoin transactions. It also isn't possible to send to something that won't\n> ultimately exist, as sends create new outputs just like Bitcoin\n> transactions.\n>\n> Taro's state transition model also means anything you can do today with\n> Bitcoin/LN also apply. As an example, it would be possible for you to\n> withdrawn from your exchange into a Loop In address (on chain to off chain\n> swap), and have everything work as expected, with you topping off your\n> channel. Stuff like splicing, and other interactive transaction construction\n> schemes (atomic swaps, MIMO swaps, on chain auctions, etc) also just work.\n>\n> Ignoring the ordering issue I mentioned above, I don't think this is a great\n> model for anchoring assets in channels either. With Taro, when you make the\n> channel, you know how many assets are committed since they're all committed\n> to in the funding output when the channel is created. However, let's say we\n> do teleporting instead: at which point would we recognize the new asset\n> \"deposits\"? What if we close before a pending deposits confirms, how can one\n> regain those funds? Once again you lose the serialization of events/actions\n> the blockchain provides. I think you'd also run into similar issues when you\n> start to think about how these would even be advertised on a hypothetical\n> gossip network.\n>\n> I think one other drawback of the teleport model iiuc is that: it either\n> requires an OP_RETURN, or additional out of band synchronization to complete\n> the transfer. Since it needs to commit to w/e hash description of the\n> teleport, it either needs to use an OP_RETURN (so the receiver can see the\n> on chain action), or the sender needs to contact the receiver to initiate\n> the resolution of the transfer (details committed to in a change addr or\n> w/e).\n>\n> With Taro, sending to an address creates an on-chain taproot output just\n> like sending to a P2TR address. The creation of the output directly creates\n> the new asset anchor/output as well, which allows the receiver to look for\n> that address on chain just like a normal on chain transaction. To 3rd party\n> observers, it just looks like a normal P2TR transfer. In order to finalize\n> the receipt of the asset, the receiver needs to obtain the relevant\n> provenance proofs, which can be obtained from a multi-verse gRPC/HTTP\n> service keyed by the input outpoint and output index. In short, the send\n> process is fully async, with the sender and receiver using the blockchain\n> itself as a synchronization point like a normal Bitcoin wallet.\n>\n> -- Laolu"
            }
        ],
        "thread_summary": {
            "title": "Taro: A Taproot Asset Representation Overlay",
            "categories": [
                "Lightning-dev",
                "bitcoin-dev"
            ],
            "authors": [
                "Olaoluwa Osuntokun",
                "Johan Tor\u00e5s Halseth"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 26120
        }
    },
    {
        "title": "[Lightning-dev] Unjamming lightning (new research paper)",
        "thread_messages": [
            {
                "author": "Clara Shikhelman",
                "date": "2022-11-03T17:24:26",
                "message_text_only": "Hi list,\n\nWe would like to share with you our recent research on jamming in\nLightning. We propose a combination of unconditional (~ upfront) fees and\nlocal reputation to fight jamming. We believe this can be a basis for an\nefficient and practical solution that can be implemented in the foreseeable\nfuture.\n\nThe full paper is available [1].\n\nWe classify jams into quick (resolve in seconds, mimicking honest payments)\nand slow (remain in-flight for hours or days). Fees disincentivize an\nattack where quick jams are constantly resolved and sent again. Reputation,\nin turn, allows nodes to deprioritize peers who consistently forward slow\njams.\n\nWe believe that our proposal is practical and efficient. In particular, we\nhave shown that the additional (unconditional) fees can be relatively low\n(as low as 2% of the total fee) to fully compensate jamming victims for the\nlost routing revenue. Moreover, the total unconditional fee paid for all\nfailed attempts stays low even if the failure rate is reasonably high. This\nmeans that the UX burden of paying for failed attempts is also low. A\nstraightforward PoC implementation [2] demonstrates one approach to\nimplementing the fee-related aspect of our proposal.\n\nFurther sections provide more details on our approach and results.\n\n# Jamming\n\nAs a reminder, jamming is a DoS attack where a malicious sender initiates\npayments (jams) but delays finalizing them, blocking channels along the\nroute until the jams are resolved. Jamming may target liquidity or payment\nslots.\n\nWe distinguish between quick and slow jamming. Quick jamming implies that\njams are failed and re-sent every few seconds, making them hardly\ndistinguishable from honest failing payments. In slow jamming, jams remain\nin-flight for hours.\n\n# Unconditional fees\n\nWe propose unconditional fees to discourage quick jamming. Currently, jams\nare free because routing nodes don\u2019t charge for failed payment attempts.\nWith unconditional fees, however, jamming is no longer free.\n\nOur simulations indicate that unconditional fees don\u2019t have to be too high.\nUnder certain assumptions about the honest payment flow, a fee increase by\njust 2% (paid upfront) fully compensates a routing node under attack. Our\nsimulator is open-source [3]. A PoC implementation demonstrates one\napproach to implementing unconditional fees and only requires minor changes\n[2].\n\nWe have also considered the UX implications of paying for failed attempts.\nWe have concluded that this should not be a deal-breaker, as the total\nunconditional fee paid stays low even if the failure rate is reasonably\nhigh (even as high as 50%). Privacy and incentives are also discussed in\nthe paper.\n\n# Reputation\n\nFees are not very effective in preventing slow jamming: this type of attack\nrequires only a few jams, therefore, fees would have to be too high to be\neffective. Instead, we address slow jamming using local reputation.\n\nAs per our proposal, nodes keep track of their peers\u2019 past behavior. A\nrouting node considers its peer \u201cgood\u201d if it only forwards honest payments\nthat resolve quickly and bring sufficient fee revenue. A peer that forwards\njams, in contrast, loses reputation. Payments endorsed by a high-reputation\npeer are forwarded on the best efforts basis, while other (\u201chigh-risk\u201d)\npayments can only use a predefined quota of liquidity and slots. Unless the\nattacker has built up a reputation in advance, it cannot fully jam a\nchannel with at least some liquidity allocated exclusively to low-risk\npayments. Nodes parameterize their channels according to their risk\ntolerance.\n\n# Alternatives and Future Work\n\nIn this work, we strive for a systematic approach. First, we list five\nproperties a potential mitigation strategy should have: effectiveness,\nincentive compatibility, user experience, privacy and security, and ease of\nimplementation. Then, we go over the design decisions to be made when\nconstructing a countermeasure against jamming. Based on the desired\ncriteria and the available options, we converge on a solution.\n\nMultiple approaches to jamming mitigation have been discussed on this list\nand elsewhere. Many of them may well be worth exploring, such as\nresolution-time-dependent fee amounts or stake certificates for reputation\nbuilding. However, we believe that our solution strikes a good balance: it\naddresses the problem in question and is relatively straightforward to\nimplement.\n\nWe would love to bring this idea closer to implementation, and we plan to\ndiscuss it over the next spec meeting [4] (Monday, 2022-11-07). We\u2019d\ngreatly appreciate your feedback!\n\nKind regards,\n\nSergei and Clara\n\n[1] -\nhttps://github.com/s-tikhomirov/ln-jamming-simulator/blob/master/unjamming-lightning.pdf\n\n\n[2] - https://github.com/sr-gi/rust-lightning/commit/ce606)\n\n[3] - https://github.com/s-tikhomirov/ln-jamming-simulator\n[4] - https://github.com/lightning/bolts/issues/1038\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221103/9ca4e3af/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-11-06T23:27:44",
                "message_text_only": "Hi Clara, Sergei\n\nCongrats for the paper!\n\nHere are a few in-flight thoughts browsing the paper.\n\nOn introducing a general framework for evaluating attack mitigations, I\nthink this is relevant as scarce resources wastes, of which jamming is a\nsubcase is echoed multiple times not only in Lightning, but in multiple\nother L2 protocols. For Lightning: at channel peer selection, or for any\nmulti-party operation like a dual-funded or splicing, the timevalue of the\nUTXOs committed can be wasted by a lazy or malicious counterparty. For\nCoinjoin/Swaps: again UTXO opportunity cost can be wasted, or a swap HTLC\nholded for nothing. I hold the hope that any solution we can nurture for\njamming could be reused and refined in other Bitcoin \"decentralized\nfinancial networks\".\n\nOn the framework for mitigation evaluation, there are few other dimensions\nwe have considered in the past with Gleb for our research that could be\nrelevant to integrate. One is \"centralization\", the solution shouldn't\ncentralize sensibly the LN ecosystem around any of its actors: LSP,\nLightning Wallet Providers (e.g watchtower or Greenlight-style infra) or\nrouting node, where centralization could be defined in terms of \"market\nentry cost\" for new incumbents. \"Protocol evolvability\" could be another\none, as we don't want a solution rendering the design and operations of\nthings like offline-receive, trampoline, negative fees, etc harder.\n\"Ecosystem impacts\" was one more category we thought about, e.g introducing\na mass mempool congestion vector (one of the versions of Stakes\nCertificates did it...).\n\nFor the dimensions of your evaluation framework, the \"effectiveness\" sounds\nto be understood as attacker-centric. However few times after in the paper,\nthe viewpoint of the routing nodes sounds to be adopted (\"compensating them\nfor the financial damage of jamming\", \"breakeven point n\"). If this\ndistinction is real, the first way would be more searching for a\ngame-theory equilibrium whereas much damage is inflicted to the attacker.\nThe second one would be more to ensure a compensation for the loss income\nfor the routing nodes. I believe the first approach is limited as the\nattacker's resources could overwhelm the victim's economic sustainability,\nand rationality might be uneconomic. Maybe those two approaches could be\ncombined, in the sense that loss income compensation should only be borne\nby \"identified\" attackers, however this doesn't sound the direction taken\nby unconditional fees.\n\nAbout \"incentive compatibility\", one element valuable to integrate is how\nmuch the existence of scoring algorithms allows the routing nodes to adopt\n\"honest behaviors\" and high-level of service availability. I don't know if\na jamming solution can be devised without considerations of the inner\nworkings of routing/scoring algorithms, and so far every LN implementation\nhas its own cooking.\n\nOn the structure of the monetary strategy, I think there could be a\nsolution to implement a proof-of-burn, where the fee is captured in a\ncommitment output sending to a provably unspendable output. Theoretically,\nit's interesting as \"unburning\" the fee is dependent on counterparty\ncooperation, the one potentially encumbering the jamming risk.\nProof-of-work \"fee\" has been discussed in the past by LN devs, however it\nwas quickly dismissed, as it would give an edge to the attacker who is able\nto gather ASICs farms while completely burning the batteries of LN mobile\nclients. It has also been widely discussed to make the fees conditional on\neither outgoing HTLC CLTV value or effective duration. For effective\nduration, an upfront fee shard could be paid after each clock tick (either\nepoch or block-based).\n\nOn the structure of reputation strategy, I think one interesting missing\npoint to me is the blurring of the local/global reputation definition in\nLightning. At least maybe in a way traditionally defined in P2P\nlitterature. Reputation could be enforced on the HTLC sender, as we've\naimed with Stakes Certificates. The upstream peer reputation is not\naccounted for at all. I think it's an open question if the reputation score\nof a routing node could be exported across nodes (a behavior that one could\nexpect if you assume web-of-trust, as the current LN network topology is\nheavily based on). On the statement, that attaching reputation to payment\ncontradicts the LN's privacy-focused goal, I would say it's a light one in\nregards to the state of cryptography tools like blinded signature, known\nsince the 80s.\n\nOn the analysis of the unconditional fee, I think my main objection would\nbe the lack of integration of the time uncertainty of the honest use-cases,\nmaking it hard to classify between quick and slow jamming. As you say \"The\nborderline between quick and slow jamming depends on a subjective\ndefinition of the maximal honest payment resolution delay\" An attacker\nshould hold all its HTLC jamming for a duration of \"maximal honest payment\nresolution delay\" minus 1. Without even scoping L2s protocol like swaps or\nhold-invoice where the effective duration might hold for a few blocks,\nmodern flows like offline receive where the user has to take manual actions\nto settle the HTLC could far extend beyond a few seconds. To develop my\npoint, fair compensation could aim for the most optimistic flow of\nshort-held 0.1s payment, however a routing policy could qualify as honest\npayment resolution delay duration of as much as a few minutes. This\ndiscrepancy could be exploited by an attacker to inflict an asymmetric\ndamage to the routing nodes. Of course, one fix could be to scale up the\nunconditional fee amount in function of the maximal honest payment\nresolution delay accepted by the routing node policy\". I wonder if it would\nbe suitable in terms of UX.\n\nFor a routing node, there is the uncertainty of downstream payment path\nhops, responsible for some failures, I don't know if it's currently\naccounted for in the evaluation of the unconditional fee. If the\nunconditional fee paid downstream is too high, there is a moral hazard for\nthe routing node, they can pocket the fee, depending how much they're\npenalized by the sender scoring algorithm.\n\nOn the analysis of the reputation mechanism, there is one recursive issue:\nyou might constrain the incoming HTLC traffic of your peers, even if\nthey're all honest. Let's say you assign K slots and L satoshis of\nliquidity to your upstream peer Carioll, Caroll must know divide by (K, L)\nby two to Alice and Bob, even if Alice and Bob each can offer (K, L) of\nhonest HTLC traffic.\n\nFurther, there is also the attack timing asymmetries, in the sense that a\nhigh-reputation score might have been earned in period of low-congestion,\nand consumed during period of high-congestion, so it sounds to me\nreputation should be quantitative rather to introduce a low-risk/high-risk\nbinary framework, to account for proportionality. This proportionality\nissue is a hard thing, especially if I would like concretely to address\npayments with intentionally delayed resolutions in a non-cooperative-only\nway.\n\nLastly, I wonder if there is not some conceptual issue with the chaining of\nunconditional fee and local reputation. As I understand the distinction\nbetween quick/slow jamming is based on this idea of maximal honest payment\nresolution delay. However, the bypass of this upper bound is only known\n_after_ the HTLC forward, and as such it sounds to me the strategie regime\n(unconditional fee/local reputation) under which a HTLC forward should be\nevaluated is dependent on the knowledge of a future event.\n\nBest,\nAntoine\n\nLe jeu. 3 nov. 2022 \u00e0 13:25, Clara Shikhelman <clara.shikhelman at gmail.com>\na \u00e9crit :\n\n> Hi list,\n>\n> We would like to share with you our recent research on jamming in\n> Lightning. We propose a combination of unconditional (~ upfront) fees and\n> local reputation to fight jamming. We believe this can be a basis for an\n> efficient and practical solution that can be implemented in the foreseeable\n> future.\n>\n> The full paper is available [1].\n>\n> We classify jams into quick (resolve in seconds, mimicking honest\n> payments) and slow (remain in-flight for hours or days). Fees\n> disincentivize an attack where quick jams are constantly resolved and sent\n> again. Reputation, in turn, allows nodes to deprioritize peers who\n> consistently forward slow jams.\n>\n> We believe that our proposal is practical and efficient. In particular, we\n> have shown that the additional (unconditional) fees can be relatively low\n> (as low as 2% of the total fee) to fully compensate jamming victims for the\n> lost routing revenue. Moreover, the total unconditional fee paid for all\n> failed attempts stays low even if the failure rate is reasonably high. This\n> means that the UX burden of paying for failed attempts is also low. A\n> straightforward PoC implementation [2] demonstrates one approach to\n> implementing the fee-related aspect of our proposal.\n>\n> Further sections provide more details on our approach and results.\n>\n> # Jamming\n>\n> As a reminder, jamming is a DoS attack where a malicious sender initiates\n> payments (jams) but delays finalizing them, blocking channels along the\n> route until the jams are resolved. Jamming may target liquidity or payment\n> slots.\n>\n> We distinguish between quick and slow jamming. Quick jamming implies that\n> jams are failed and re-sent every few seconds, making them hardly\n> distinguishable from honest failing payments. In slow jamming, jams remain\n> in-flight for hours.\n>\n> # Unconditional fees\n>\n> We propose unconditional fees to discourage quick jamming. Currently, jams\n> are free because routing nodes don\u2019t charge for failed payment attempts.\n> With unconditional fees, however, jamming is no longer free.\n>\n> Our simulations indicate that unconditional fees don\u2019t have to be too\n> high. Under certain assumptions about the honest payment flow, a fee\n> increase by just 2% (paid upfront) fully compensates a routing node under\n> attack. Our simulator is open-source [3]. A PoC implementation demonstrates\n> one approach to implementing unconditional fees and only requires minor\n> changes [2].\n>\n> We have also considered the UX implications of paying for failed attempts.\n> We have concluded that this should not be a deal-breaker, as the total\n> unconditional fee paid stays low even if the failure rate is reasonably\n> high (even as high as 50%). Privacy and incentives are also discussed in\n> the paper.\n>\n> # Reputation\n>\n> Fees are not very effective in preventing slow jamming: this type of\n> attack requires only a few jams, therefore, fees would have to be too high\n> to be effective. Instead, we address slow jamming using local reputation.\n>\n> As per our proposal, nodes keep track of their peers\u2019 past behavior. A\n> routing node considers its peer \u201cgood\u201d if it only forwards honest payments\n> that resolve quickly and bring sufficient fee revenue. A peer that forwards\n> jams, in contrast, loses reputation. Payments endorsed by a high-reputation\n> peer are forwarded on the best efforts basis, while other (\u201chigh-risk\u201d)\n> payments can only use a predefined quota of liquidity and slots. Unless the\n> attacker has built up a reputation in advance, it cannot fully jam a\n> channel with at least some liquidity allocated exclusively to low-risk\n> payments. Nodes parameterize their channels according to their risk\n> tolerance.\n>\n> # Alternatives and Future Work\n>\n> In this work, we strive for a systematic approach. First, we list five\n> properties a potential mitigation strategy should have: effectiveness,\n> incentive compatibility, user experience, privacy and security, and ease of\n> implementation. Then, we go over the design decisions to be made when\n> constructing a countermeasure against jamming. Based on the desired\n> criteria and the available options, we converge on a solution.\n>\n> Multiple approaches to jamming mitigation have been discussed on this list\n> and elsewhere. Many of them may well be worth exploring, such as\n> resolution-time-dependent fee amounts or stake certificates for reputation\n> building. However, we believe that our solution strikes a good balance: it\n> addresses the problem in question and is relatively straightforward to\n> implement.\n>\n> We would love to bring this idea closer to implementation, and we plan to\n> discuss it over the next spec meeting [4] (Monday, 2022-11-07). We\u2019d\n> greatly appreciate your feedback!\n>\n> Kind regards,\n>\n> Sergei and Clara\n>\n> [1] -\n> https://github.com/s-tikhomirov/ln-jamming-simulator/blob/master/unjamming-lightning.pdf\n>\n>\n> [2] - https://github.com/sr-gi/rust-lightning/commit/ce606)\n>\n> [3] - https://github.com/s-tikhomirov/ln-jamming-simulator\n> [4] - https://github.com/lightning/bolts/issues/1038\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221106/55593583/attachment-0001.html>"
            },
            {
                "author": "Clara Shikhelman",
                "date": "2022-11-07T18:22:40",
                "message_text_only": "Hi Antoine,\n\nThank you for the detailed response!\n\n\n\n> On the framework for mitigation evaluation, there are few other dimensions\n> we have considered in the past with Gleb for our research that could be\n> relevant to integrate. One is \"centralization\", the solution shouldn't\n> centralize sensibly the LN ecosystem around any of its actors: LSP,\n> Lightning Wallet Providers (e.g watchtower or Greenlight-style infra) or\n> routing node, where centralization could be defined in terms of \"market\n> entry cost\" for new incumbents. \"Protocol evolvability\" could be another\n> one, as we don't want a solution rendering the design and operations of\n> things like offline-receive, trampoline, negative fees, etc harder.\n> \"Ecosystem impacts\" was one more category we thought about, e.g introducing\n> a mass mempool congestion vector (one of the versions of Stakes\n> Certificates did it...).\n>\n\nThese are indeed important dimensions. I think that our solution gets \u201cgood\nmarks\u201d in all of them, but this should definitely be stated explicitly in\nthe future.\n\n\n> For the dimensions of your evaluation framework, the \"effectiveness\"\n> sounds to be understood as attacker-centric. However few times after in the\n> paper, the viewpoint of the routing nodes sounds to be adopted\n> (\"compensating them for the financial damage of jamming\", \"breakeven point\n> n\"). If this distinction is real, the first way would be more searching for\n> a game-theory equilibrium whereas much damage is inflicted to the attacker.\n> The second one would be more to ensure a compensation for the loss income\n> for the routing nodes. I believe the first approach is limited as the\n> attacker's resources could overwhelm the victim's economic sustainability,\n> and rationality might be uneconomic. Maybe those two approaches could be\n> combined, in the sense that loss income compensation should only be borne\n> by \"identified\" attackers, however this doesn't sound the direction taken\n> by unconditional fees.\n>\n\nThe effectiveness evaluation does have a few facets. From the attacker's\nviewpoint, it might be that mitigation makes the attack impossible,\ndifficult, or expensive. From the victim's point of view, we can talk about\nprotection, compensation, or any combination of the two. Of course, the\nbest outcome is when the attack is impossible. As this is oftentimes not\nsomething we can do, we have to choose one of the other outcomes.\n\n\n> About \"incentive compatibility\", one element valuable to integrate is how\n> much the existence of scoring algorithms allows the routing nodes to adopt\n> \"honest behaviors\" and high-level of service availability. I don't know if\n> a jamming solution can be devised without considerations of the inner\n> workings of routing/scoring algorithms, and so far every LN implementation\n> has its own cooking.\n>\n\nWe focused on the most basic incentive of not failing transactions that\ncould have been forwarded. I'll be happy to discuss other potential\npitfalls if you have something in mind.\n\n\n>\n> On the structure of the monetary strategy, I think there could be a\n> solution to implement a proof-of-burn, where the fee is captured in a\n> commitment output sending to a provably unspendable output. Theoretically,\n> it's interesting as \"unburning\" the fee is dependent on counterparty\n> cooperation, the one potentially encumbering the jamming risk.\n> Proof-of-work \"fee\" has been discussed in the past by LN devs, however it\n> was quickly dismissed, as it would give an edge to the attacker who is able\n> to gather ASICs farms while completely burning the batteries of LN mobile\n> clients. It has also been widely discussed to make the fees conditional on\n> either outgoing HTLC CLTV value or effective duration. For effective\n> duration, an upfront fee shard could be paid after each clock tick (either\n> epoch or block-based).\n>\n\nThe main problem with proof of burn or PoW is that it does not compensate\nthe victim, we write this explicitly in the newer version of the paper.\nThanks for this comment, we will add further details on previous\ndiscussions.\n\n\n> On the structure of reputation strategy, I think one interesting missing\n> point to me is the blurring of the local/global reputation definition in\n> Lightning. At least maybe in a way traditionally defined in P2P\n> litterature. Reputation could be enforced on the HTLC sender, as we've\n> aimed with Stakes Certificates. The upstream peer reputation is not\n> accounted for at all. I think it's an open question if the reputation score\n> of a routing node could be exported across nodes (a behavior that one could\n> expect if you assume web-of-trust, as the current LN network topology is\n> heavily based on). On the statement, that attaching reputation to payment\n> contradicts the LN's privacy-focused goal, I would say it's a light one in\n> regards to the state of cryptography tools like blinded signature, known\n> since the 80s.\n>\n\nI think that further research on assigning the blame to the sender is of\ninterest, but as we don't have this right now, it would be good to work\nwith the available tools.\n\n\n> On the analysis of the unconditional fee, I think my main objection would\n> be the lack of integration of the time uncertainty of the honest use-cases,\n> making it hard to classify between quick and slow jamming. As you say \"The\n> borderline between quick and slow jamming depends on a subjective\n> definition of the maximal honest payment resolution delay\" An attacker\n> should hold all its HTLC jamming for a duration of \"maximal honest payment\n> resolution delay\" minus 1. Without even scoping L2s protocol like swaps or\n> hold-invoice where the effective duration might hold for a few blocks,\n> modern flows like offline receive where the user has to take manual actions\n> to settle the HTLC could far extend beyond a few seconds. To develop my\n> point, fair compensation could aim for the most optimistic flow of\n> short-held 0.1s payment, however a routing policy could qualify as honest\n> payment resolution delay duration of as much as a few minutes. This\n> discrepancy could be exploited by an attacker to inflict an asymmetric\n> damage to the routing nodes. Of course, one fix could be to scale up the\n> unconditional fee amount in function of the maximal honest payment\n> resolution delay accepted by the routing node policy\". I wonder if it would\n> be suitable in terms of UX.\n>\n\nFor special use cases, where Alice and Bob agree that HTLCs can wait for a\nlong time over the channel, they can agree that this would not change their\nreputation with the other party. If Alice decides to knowingly forward to\nBob an HTLC that will not resolve quickly, without agreeing on this\nbeforehand, this is a problem and should be solved through the reputation\nsystem.\n\n\n> For a routing node, there is the uncertainty of downstream payment path\n> hops, responsible for some failures, I don't know if it's currently\n> accounted for in the evaluation of the unconditional fee. If the\n> unconditional fee paid downstream is too high, there is a moral hazard for\n> the routing node, they can pocket the fee, depending how much they're\n> penalized by the sender scoring algorithm.\n>\n\nThis is addressed in inequality 5 in the paper.\nIn general, routing algorithms should avoid nodes and channels that\nregularly fail their payments. This is true beyond the scope of upfront\nfees, and as the upfront fees are rather low, this wouldn't be the main\nmotivation for avoiding \u201cbad\u201d nodes.\n\n\n\n> On the analysis of the reputation mechanism, there is one recursive issue:\n> you might constrain the incoming HTLC traffic of your peers, even if\n> they're all honest. Let's say you assign K slots and L satoshis of\n> liquidity to your upstream peer Carioll, Caroll must know divide by (K, L)\n> by two to Alice and Bob, even if Alice and Bob each can offer (K, L) of\n> honest HTLC traffic.\n>\n\nAre we the only node sending anything to Carol? If this is the case, our\nchannel is Carol's bottleneck, and indeed whichever limit we choose will be\nthe limit she will have to handle (this is a bit of \"min-cut max-flow\"\nproblem for Carol, where our channel is her min-cut)\n\n\n> Further, there is also the attack timing asymmetries, in the sense that a\n> high-reputation score might have been earned in period of low-congestion,\n> and consumed during period of high-congestion, so it sounds to me\n> reputation should be quantitative rather to introduce a low-risk/high-risk\n> binary framework, to account for proportionality. This proportionality\n> issue is a hard thing, especially if I would like concretely to address\n> payments with intentionally delayed resolutions in a non-cooperative-only\n> way.\n>\n\nAs reputation policy is determined on the level of an individual node, it\ncould be that some will choose to take into account congestion.\n\n\n> Lastly, I wonder if there is not some conceptual issue with the chaining\n> of unconditional fee and local reputation. As I understand the distinction\n> between quick/slow jamming is based on this idea of maximal honest payment\n> resolution delay. However, the bypass of this upper bound is only known\n> _after_ the HTLC forward, and as such it sounds to me the strategie regime\n> (unconditional fee/local reputation) under which a HTLC forward should be\n> evaluated is dependent on the knowledge of a future event.\n>\n\nWe use reputation as part of a continuous game. You don't gain or lose high\nreputation based on one HTLC, you evaluate based on the continuous behavior\nof the node. The unconditional fee is always charged.\n\n\nThanks again,\nClara\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221107/6ca7c2c0/attachment-0001.html>"
            },
            {
                "author": "Thomas HUET",
                "date": "2022-11-08T14:22:41",
                "message_text_only": "Hi,\n\nI agree that the local reputation solution is very promising (I'm less\nconvinced about the unconditional fee as it changes a core principle of the\nnetwork which means that we'll never reach consensus on it). What I really\nlike about it is that it's quite simple and can be quickly deployed without\neven needing to coordinate with others or upgrade the network.\nI had a similar idea but your solution adds a \"I endorse this payment\" bit\nwhich I think can make the method a lot more effective (and unfortunately\nbreaks the \"can be deployed without upgrading the network\" but I think it's\nworth it). However if we change the protocol, we may as well make it a\ncontinuous risk score instead of a binary low/high-risk. Also, having only\ntwo classes (high and low-risk) protects the the low-risk class but makes\nthe high-risk class even easier to attack, having a continuous policy\nshould mitigate this problem.\nAnd while I agree with the general idea of throttling based on a local\nreputation, I think we need more work to find a good formula to compute\nthis reputation. I don't have a good formula myself but relying on \"A\nsatoshis per second\" doesn't seem wise. There are huge disparities between\nnodes and even for a given node, traffic is fluctuating a lot. I think a\nmore reliable indicator would be the proportion of successful payments.\nThe beauty of this solution is that we don't need a standardized formula\nfor reputation, everyone can use its own. However getting a good one is\nhard so we need a default recommandation.\n\nThanks for your work.\nThomas\n\nLe lun. 7 nov. 2022 \u00e0 19:23, Clara Shikhelman <clara.shikhelman at gmail.com>\na \u00e9crit :\n\n> Hi Antoine,\n>\n> Thank you for the detailed response!\n>\n>\n>\n>> On the framework for mitigation evaluation, there are few other\n>> dimensions we have considered in the past with Gleb for our research that\n>> could be relevant to integrate. One is \"centralization\", the solution\n>> shouldn't centralize sensibly the LN ecosystem around any of its actors:\n>> LSP, Lightning Wallet Providers (e.g watchtower or Greenlight-style infra)\n>> or routing node, where centralization could be defined in terms of \"market\n>> entry cost\" for new incumbents. \"Protocol evolvability\" could be another\n>> one, as we don't want a solution rendering the design and operations of\n>> things like offline-receive, trampoline, negative fees, etc harder.\n>> \"Ecosystem impacts\" was one more category we thought about, e.g introducing\n>> a mass mempool congestion vector (one of the versions of Stakes\n>> Certificates did it...).\n>>\n>\n> These are indeed important dimensions. I think that our solution gets\n> \u201cgood marks\u201d in all of them, but this should definitely be stated\n> explicitly in the future.\n>\n>\n>> For the dimensions of your evaluation framework, the \"effectiveness\"\n>> sounds to be understood as attacker-centric. However few times after in the\n>> paper, the viewpoint of the routing nodes sounds to be adopted\n>> (\"compensating them for the financial damage of jamming\", \"breakeven point\n>> n\"). If this distinction is real, the first way would be more searching for\n>> a game-theory equilibrium whereas much damage is inflicted to the attacker.\n>> The second one would be more to ensure a compensation for the loss income\n>> for the routing nodes. I believe the first approach is limited as the\n>> attacker's resources could overwhelm the victim's economic sustainability,\n>> and rationality might be uneconomic. Maybe those two approaches could be\n>> combined, in the sense that loss income compensation should only be borne\n>> by \"identified\" attackers, however this doesn't sound the direction taken\n>> by unconditional fees.\n>>\n>\n> The effectiveness evaluation does have a few facets. From the attacker's\n> viewpoint, it might be that mitigation makes the attack impossible,\n> difficult, or expensive. From the victim's point of view, we can talk about\n> protection, compensation, or any combination of the two. Of course, the\n> best outcome is when the attack is impossible. As this is oftentimes not\n> something we can do, we have to choose one of the other outcomes.\n>\n>\n>> About \"incentive compatibility\", one element valuable to integrate is how\n>> much the existence of scoring algorithms allows the routing nodes to adopt\n>> \"honest behaviors\" and high-level of service availability. I don't know if\n>> a jamming solution can be devised without considerations of the inner\n>> workings of routing/scoring algorithms, and so far every LN implementation\n>> has its own cooking.\n>>\n>\n> We focused on the most basic incentive of not failing transactions that\n> could have been forwarded. I'll be happy to discuss other potential\n> pitfalls if you have something in mind.\n>\n>\n>>\n>> On the structure of the monetary strategy, I think there could be a\n>> solution to implement a proof-of-burn, where the fee is captured in a\n>> commitment output sending to a provably unspendable output. Theoretically,\n>> it's interesting as \"unburning\" the fee is dependent on counterparty\n>> cooperation, the one potentially encumbering the jamming risk.\n>> Proof-of-work \"fee\" has been discussed in the past by LN devs, however it\n>> was quickly dismissed, as it would give an edge to the attacker who is able\n>> to gather ASICs farms while completely burning the batteries of LN mobile\n>> clients. It has also been widely discussed to make the fees conditional on\n>> either outgoing HTLC CLTV value or effective duration. For effective\n>> duration, an upfront fee shard could be paid after each clock tick (either\n>> epoch or block-based).\n>>\n>\n> The main problem with proof of burn or PoW is that it does not compensate\n> the victim, we write this explicitly in the newer version of the paper.\n> Thanks for this comment, we will add further details on previous\n> discussions.\n>\n>\n>> On the structure of reputation strategy, I think one interesting missing\n>> point to me is the blurring of the local/global reputation definition in\n>> Lightning. At least maybe in a way traditionally defined in P2P\n>> litterature. Reputation could be enforced on the HTLC sender, as we've\n>> aimed with Stakes Certificates. The upstream peer reputation is not\n>> accounted for at all. I think it's an open question if the reputation score\n>> of a routing node could be exported across nodes (a behavior that one could\n>> expect if you assume web-of-trust, as the current LN network topology is\n>> heavily based on). On the statement, that attaching reputation to payment\n>> contradicts the LN's privacy-focused goal, I would say it's a light one in\n>> regards to the state of cryptography tools like blinded signature, known\n>> since the 80s.\n>>\n>\n> I think that further research on assigning the blame to the sender is of\n> interest, but as we don't have this right now, it would be good to work\n> with the available tools.\n>\n>\n>> On the analysis of the unconditional fee, I think my main objection would\n>> be the lack of integration of the time uncertainty of the honest use-cases,\n>> making it hard to classify between quick and slow jamming. As you say \"The\n>> borderline between quick and slow jamming depends on a subjective\n>> definition of the maximal honest payment resolution delay\" An attacker\n>> should hold all its HTLC jamming for a duration of \"maximal honest payment\n>> resolution delay\" minus 1. Without even scoping L2s protocol like swaps or\n>> hold-invoice where the effective duration might hold for a few blocks,\n>> modern flows like offline receive where the user has to take manual actions\n>> to settle the HTLC could far extend beyond a few seconds. To develop my\n>> point, fair compensation could aim for the most optimistic flow of\n>> short-held 0.1s payment, however a routing policy could qualify as honest\n>> payment resolution delay duration of as much as a few minutes. This\n>> discrepancy could be exploited by an attacker to inflict an asymmetric\n>> damage to the routing nodes. Of course, one fix could be to scale up the\n>> unconditional fee amount in function of the maximal honest payment\n>> resolution delay accepted by the routing node policy\". I wonder if it would\n>> be suitable in terms of UX.\n>>\n>\n> For special use cases, where Alice and Bob agree that HTLCs can wait for a\n> long time over the channel, they can agree that this would not change their\n> reputation with the other party. If Alice decides to knowingly forward to\n> Bob an HTLC that will not resolve quickly, without agreeing on this\n> beforehand, this is a problem and should be solved through the reputation\n> system.\n>\n>\n>> For a routing node, there is the uncertainty of downstream payment path\n>> hops, responsible for some failures, I don't know if it's currently\n>> accounted for in the evaluation of the unconditional fee. If the\n>> unconditional fee paid downstream is too high, there is a moral hazard for\n>> the routing node, they can pocket the fee, depending how much they're\n>> penalized by the sender scoring algorithm.\n>>\n>\n> This is addressed in inequality 5 in the paper.\n> In general, routing algorithms should avoid nodes and channels that\n> regularly fail their payments. This is true beyond the scope of upfront\n> fees, and as the upfront fees are rather low, this wouldn't be the main\n> motivation for avoiding \u201cbad\u201d nodes.\n>\n>\n>\n>> On the analysis of the reputation mechanism, there is one recursive\n>> issue: you might constrain the incoming HTLC traffic of your peers, even if\n>> they're all honest. Let's say you assign K slots and L satoshis of\n>> liquidity to your upstream peer Carioll, Caroll must know divide by (K, L)\n>> by two to Alice and Bob, even if Alice and Bob each can offer (K, L) of\n>> honest HTLC traffic.\n>>\n>\n> Are we the only node sending anything to Carol? If this is the case, our\n> channel is Carol's bottleneck, and indeed whichever limit we choose will be\n> the limit she will have to handle (this is a bit of \"min-cut max-flow\"\n> problem for Carol, where our channel is her min-cut)\n>\n>\n>> Further, there is also the attack timing asymmetries, in the sense that a\n>> high-reputation score might have been earned in period of low-congestion,\n>> and consumed during period of high-congestion, so it sounds to me\n>> reputation should be quantitative rather to introduce a low-risk/high-risk\n>> binary framework, to account for proportionality. This proportionality\n>> issue is a hard thing, especially if I would like concretely to address\n>> payments with intentionally delayed resolutions in a non-cooperative-only\n>> way.\n>>\n>\n> As reputation policy is determined on the level of an individual node, it\n> could be that some will choose to take into account congestion.\n>\n>\n>> Lastly, I wonder if there is not some conceptual issue with the chaining\n>> of unconditional fee and local reputation. As I understand the distinction\n>> between quick/slow jamming is based on this idea of maximal honest payment\n>> resolution delay. However, the bypass of this upper bound is only known\n>> _after_ the HTLC forward, and as such it sounds to me the strategie regime\n>> (unconditional fee/local reputation) under which a HTLC forward should be\n>> evaluated is dependent on the knowledge of a future event.\n>>\n>\n> We use reputation as part of a continuous game. You don't gain or lose\n> high reputation based on one HTLC, you evaluate based on the continuous\n> behavior of the node. The unconditional fee is always charged.\n>\n>\n> Thanks again,\n> Clara\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221108/dc506636/attachment-0001.html>"
            },
            {
                "author": "Clara Shikhelman",
                "date": "2022-11-09T17:06:03",
                "message_text_only": "Hi,\n\nThanks for your comments!\n\n (I'm less convinced about the unconditional fee as it changes a core\n> principle of the network which means that we'll never reach consensus on\n> it).\n>\n\nI think this is a core principle that opens the network to several attacks\nand should be changed. Furthermore, there will be nothing stopping nodes\nfrom setting their unconditional fee to zero, if they wish to take the risk.\n\n\n>  However if we change the protocol, we may as well make it a continuous\n> risk score instead of a binary low/high-risk. Also, having only two classes\n> (high and low-risk) protects the the low-risk class but makes the high-risk\n> class even easier to attack, having a continuous policy should mitigate\n> this problem.\n>\n\nCould you elaborate on how having more than two classes help? It seems to\nme that if you have a limit on the resources, you are easier to jam anyway.\nThe main advantage of having two classes is that it's simpler.\n\n\n> And while I agree with the general idea of throttling based on a local\n> reputation, I think we need more work to find a good formula to compute\n> this reputation. I don't have a good formula myself but relying on \"A\n> satoshis per second\" doesn't seem wise. There are huge disparities between\n> nodes and even for a given node, traffic is fluctuating a lot. I think a\n> more reliable indicator would be the proportion of successful payments.\n>\n\nIt is important that gaining a good reputation would be difficult. For\nexample, if I only need a high proportion of successful payments, I can\njust send a single one and gain a 100% success rate. Maybe a better wording\nwould be \"X satoshis in fees during a time period of Y\"\n\n\n> The beauty of this solution is that we don't need a standardized formula\n> for reputation, everyone can use its own. However getting a good one is\n> hard so we need a default recommandation.\n>\n\nAs different nodes have different needs and different risk preferences, I'm\nslightly hesitant to give a general default. We can think about different\nprofiles and offer several options.\n\n\nThanks again,\nClara\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221109/99eed428/attachment.html>"
            },
            {
                "author": "Clara Shikhelman",
                "date": "2022-11-10T18:35:07",
                "message_text_only": "Hi all,\n\nWe are planning a call to discuss this proposal further. It will be on\nMonday the 14th, at 7 pm UTC here:\nhttps://meet.jit.si/UnjammingLN\n\nPlease let me know if this conflicts with any other Bitcoin event.\n\nHope to see you all there!\n\nOn Thu, Nov 3, 2022 at 1:25 PM Clara Shikhelman <clara.shikhelman at gmail.com>\nwrote:\n\n> Hi list,\n>\n> We would like to share with you our recent research on jamming in\n> Lightning. We propose a combination of unconditional (~ upfront) fees and\n> local reputation to fight jamming. We believe this can be a basis for an\n> efficient and practical solution that can be implemented in the foreseeable\n> future.\n>\n> The full paper is available [1].\n>\n> We classify jams into quick (resolve in seconds, mimicking honest\n> payments) and slow (remain in-flight for hours or days). Fees\n> disincentivize an attack where quick jams are constantly resolved and sent\n> again. Reputation, in turn, allows nodes to deprioritize peers who\n> consistently forward slow jams.\n>\n> We believe that our proposal is practical and efficient. In particular, we\n> have shown that the additional (unconditional) fees can be relatively low\n> (as low as 2% of the total fee) to fully compensate jamming victims for the\n> lost routing revenue. Moreover, the total unconditional fee paid for all\n> failed attempts stays low even if the failure rate is reasonably high. This\n> means that the UX burden of paying for failed attempts is also low. A\n> straightforward PoC implementation [2] demonstrates one approach to\n> implementing the fee-related aspect of our proposal.\n>\n> Further sections provide more details on our approach and results.\n>\n> # Jamming\n>\n> As a reminder, jamming is a DoS attack where a malicious sender initiates\n> payments (jams) but delays finalizing them, blocking channels along the\n> route until the jams are resolved. Jamming may target liquidity or payment\n> slots.\n>\n> We distinguish between quick and slow jamming. Quick jamming implies that\n> jams are failed and re-sent every few seconds, making them hardly\n> distinguishable from honest failing payments. In slow jamming, jams remain\n> in-flight for hours.\n>\n> # Unconditional fees\n>\n> We propose unconditional fees to discourage quick jamming. Currently, jams\n> are free because routing nodes don\u2019t charge for failed payment attempts.\n> With unconditional fees, however, jamming is no longer free.\n>\n> Our simulations indicate that unconditional fees don\u2019t have to be too\n> high. Under certain assumptions about the honest payment flow, a fee\n> increase by just 2% (paid upfront) fully compensates a routing node under\n> attack. Our simulator is open-source [3]. A PoC implementation demonstrates\n> one approach to implementing unconditional fees and only requires minor\n> changes [2].\n>\n> We have also considered the UX implications of paying for failed attempts.\n> We have concluded that this should not be a deal-breaker, as the total\n> unconditional fee paid stays low even if the failure rate is reasonably\n> high (even as high as 50%). Privacy and incentives are also discussed in\n> the paper.\n>\n> # Reputation\n>\n> Fees are not very effective in preventing slow jamming: this type of\n> attack requires only a few jams, therefore, fees would have to be too high\n> to be effective. Instead, we address slow jamming using local reputation.\n>\n> As per our proposal, nodes keep track of their peers\u2019 past behavior. A\n> routing node considers its peer \u201cgood\u201d if it only forwards honest payments\n> that resolve quickly and bring sufficient fee revenue. A peer that forwards\n> jams, in contrast, loses reputation. Payments endorsed by a high-reputation\n> peer are forwarded on the best efforts basis, while other (\u201chigh-risk\u201d)\n> payments can only use a predefined quota of liquidity and slots. Unless the\n> attacker has built up a reputation in advance, it cannot fully jam a\n> channel with at least some liquidity allocated exclusively to low-risk\n> payments. Nodes parameterize their channels according to their risk\n> tolerance.\n>\n> # Alternatives and Future Work\n>\n> In this work, we strive for a systematic approach. First, we list five\n> properties a potential mitigation strategy should have: effectiveness,\n> incentive compatibility, user experience, privacy and security, and ease of\n> implementation. Then, we go over the design decisions to be made when\n> constructing a countermeasure against jamming. Based on the desired\n> criteria and the available options, we converge on a solution.\n>\n> Multiple approaches to jamming mitigation have been discussed on this list\n> and elsewhere. Many of them may well be worth exploring, such as\n> resolution-time-dependent fee amounts or stake certificates for reputation\n> building. However, we believe that our solution strikes a good balance: it\n> addresses the problem in question and is relatively straightforward to\n> implement.\n>\n> We would love to bring this idea closer to implementation, and we plan to\n> discuss it over the next spec meeting [4] (Monday, 2022-11-07). We\u2019d\n> greatly appreciate your feedback!\n>\n> Kind regards,\n>\n> Sergei and Clara\n>\n> [1] -\n> https://github.com/s-tikhomirov/ln-jamming-simulator/blob/master/unjamming-lightning.pdf\n>\n>\n> [2] - https://github.com/sr-gi/rust-lightning/commit/ce606)\n>\n> [3] - https://github.com/s-tikhomirov/ln-jamming-simulator\n> [4] - https://github.com/lightning/bolts/issues/1038\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221110/81c7cd16/attachment-0001.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2022-11-14T21:38:44",
                "message_text_only": "An HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221114/da565ea5/attachment.html>"
            },
            {
                "author": "Clara Shikhelman",
                "date": "2022-11-15T20:09:15",
                "message_text_only": "Thanks to everyone that came to the meeting, it was a great conversation\nand gave us a lot to think about!\n\nMatt \u2013 I don't know that I agree with \"... upfront payments kinda kill the\nlightning UX ...\". I think that upfront fees are almost essential, even\noutside the context of jamming. This also helps with probing, general spam,\nand other aspects. Furthermore, I think that the UX is very explainable,\nand in general nodes shouldn't be motivated to send a lot of failed\npayments, and should adopt better routing strategies.\n\nAbout Rusty's suggestions, I plan to look at it again, but if I\nremember correctly, there are privacy issues there.\n\nI agree that we should tread carefully and not rush into things, let's keep\ndiscussing this. I'll try to set up another meeting sometime soon.\n\nOn Mon, Nov 14, 2022 at 4:39 PM Matt Corallo <lf-lists at mattcorallo.com>\nwrote:\n\n> Thanks for committing all the time today. I\u2019m much happier with (binary,\n> not-so-)local reputation than I was in the past, at least as better than\n> other reputation systems.\n>\n> I believe you\u2019ve stated a few times that local reputation by itself is far\n> from sufficient and that\u2019s why we need upfront payments. Intuitively this\n> makes sense to me but I\u2019m sure you have more data to back that up. It\u2019s\n> come up a few times that upfront payments kinda kill the lightning UX if\n> they\u2019re at all nontrivial. Just restating here to make sure we\u2019re on the\n> same page.\n>\n> One thing I think we need to research more is how this compares to Rusty\u2019s\n> old proof-of-channel-closure idea. Philosophically it\u2019s quite nice to\n> punish the one holding an HTLC over punishing the sender, especially in a\n> world where people are getting options in USD<->BTC through HTLCs or\n> sending to mobile nodes that sit on payments. Practically I\u2019m not sure if\n> there\u2019s a strong need to worry about a large hub sitting on HTLCs to jam\n> instead of a sender  being involved, but having zero mitigation against it\n> also seems wrong.\n>\n> As always I\u2019m a bit dubious of doing something, especially that required\n> network-wide upgrade, until we\u2019re confident it\u2019s the right direction. Even\n> binary HTLC reputation flags, I think, carry a very large privacy cost so\n> it\u2019s strongly worth exploring every alternative before we commit.\n>\n> Matt\n>\n> On Nov 10, 2022, at 10:35, Clara Shikhelman <clara.shikhelman at gmail.com>\n> wrote:\n>\n> \ufeff\n> Hi all,\n>\n> We are planning a call to discuss this proposal further. It will be on\n> Monday the 14th, at 7 pm UTC here:\n> https://meet.jit.si/UnjammingLN\n>\n> Please let me know if this conflicts with any other Bitcoin event.\n>\n> Hope to see you all there!\n>\n> On Thu, Nov 3, 2022 at 1:25 PM Clara Shikhelman <\n> clara.shikhelman at gmail.com> wrote:\n>\n>> Hi list,\n>>\n>> We would like to share with you our recent research on jamming in\n>> Lightning. We propose a combination of unconditional (~ upfront) fees and\n>> local reputation to fight jamming. We believe this can be a basis for an\n>> efficient and practical solution that can be implemented in the foreseeable\n>> future.\n>>\n>> The full paper is available [1].\n>>\n>> We classify jams into quick (resolve in seconds, mimicking honest\n>> payments) and slow (remain in-flight for hours or days). Fees\n>> disincentivize an attack where quick jams are constantly resolved and sent\n>> again. Reputation, in turn, allows nodes to deprioritize peers who\n>> consistently forward slow jams.\n>>\n>> We believe that our proposal is practical and efficient. In particular,\n>> we have shown that the additional (unconditional) fees can be relatively\n>> low (as low as 2% of the total fee) to fully compensate jamming victims for\n>> the lost routing revenue. Moreover, the total unconditional fee paid for\n>> all failed attempts stays low even if the failure rate is reasonably high.\n>> This means that the UX burden of paying for failed attempts is also low. A\n>> straightforward PoC implementation [2] demonstrates one approach to\n>> implementing the fee-related aspect of our proposal.\n>>\n>> Further sections provide more details on our approach and results.\n>>\n>> # Jamming\n>>\n>> As a reminder, jamming is a DoS attack where a malicious sender initiates\n>> payments (jams) but delays finalizing them, blocking channels along the\n>> route until the jams are resolved. Jamming may target liquidity or payment\n>> slots.\n>>\n>> We distinguish between quick and slow jamming. Quick jamming implies that\n>> jams are failed and re-sent every few seconds, making them hardly\n>> distinguishable from honest failing payments. In slow jamming, jams remain\n>> in-flight for hours.\n>>\n>> # Unconditional fees\n>>\n>> We propose unconditional fees to discourage quick jamming. Currently,\n>> jams are free because routing nodes don\u2019t charge for failed payment\n>> attempts. With unconditional fees, however, jamming is no longer free.\n>>\n>> Our simulations indicate that unconditional fees don\u2019t have to be too\n>> high. Under certain assumptions about the honest payment flow, a fee\n>> increase by just 2% (paid upfront) fully compensates a routing node under\n>> attack. Our simulator is open-source [3]. A PoC implementation demonstrates\n>> one approach to implementing unconditional fees and only requires minor\n>> changes [2].\n>>\n>> We have also considered the UX implications of paying for failed\n>> attempts. We have concluded that this should not be a deal-breaker, as the\n>> total unconditional fee paid stays low even if the failure rate is\n>> reasonably high (even as high as 50%). Privacy and incentives are also\n>> discussed in the paper.\n>>\n>> # Reputation\n>>\n>> Fees are not very effective in preventing slow jamming: this type of\n>> attack requires only a few jams, therefore, fees would have to be too high\n>> to be effective. Instead, we address slow jamming using local reputation.\n>>\n>> As per our proposal, nodes keep track of their peers\u2019 past behavior. A\n>> routing node considers its peer \u201cgood\u201d if it only forwards honest payments\n>> that resolve quickly and bring sufficient fee revenue. A peer that forwards\n>> jams, in contrast, loses reputation. Payments endorsed by a high-reputation\n>> peer are forwarded on the best efforts basis, while other (\u201chigh-risk\u201d)\n>> payments can only use a predefined quota of liquidity and slots. Unless the\n>> attacker has built up a reputation in advance, it cannot fully jam a\n>> channel with at least some liquidity allocated exclusively to low-risk\n>> payments. Nodes parameterize their channels according to their risk\n>> tolerance.\n>>\n>> # Alternatives and Future Work\n>>\n>> In this work, we strive for a systematic approach. First, we list five\n>> properties a potential mitigation strategy should have: effectiveness,\n>> incentive compatibility, user experience, privacy and security, and ease of\n>> implementation. Then, we go over the design decisions to be made when\n>> constructing a countermeasure against jamming. Based on the desired\n>> criteria and the available options, we converge on a solution.\n>>\n>> Multiple approaches to jamming mitigation have been discussed on this\n>> list and elsewhere. Many of them may well be worth exploring, such as\n>> resolution-time-dependent fee amounts or stake certificates for reputation\n>> building. However, we believe that our solution strikes a good balance: it\n>> addresses the problem in question and is relatively straightforward to\n>> implement.\n>>\n>> We would love to bring this idea closer to implementation, and we plan to\n>> discuss it over the next spec meeting [4] (Monday, 2022-11-07). We\u2019d\n>> greatly appreciate your feedback!\n>>\n>> Kind regards,\n>>\n>> Sergei and Clara\n>>\n>> [1] -\n>> https://github.com/s-tikhomirov/ln-jamming-simulator/blob/master/unjamming-lightning.pdf\n>>\n>>\n>> [2] - https://github.com/sr-gi/rust-lightning/commit/ce606)\n>>\n>> [3] - https://github.com/s-tikhomirov/ln-jamming-simulator\n>> [4] - https://github.com/lightning/bolts/issues/1038\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221115/e71ebd57/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Unjamming lightning (new research paper)",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Clara Shikhelman",
                "Thomas HUET",
                "Antoine Riard",
                "Matt Corallo"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 56356
        }
    },
    {
        "title": "[Lightning-dev] A pragmatic, unsatisfying work-around for anchor outputs fee-bumping reserve requirements",
        "thread_messages": [
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2022-11-05T00:51:55",
                "message_text_only": "Hi tbast,\n\nFWIW, we haven't had _too_ many issues with the additional constraints\nanchor channels bring. Initially users had to deal w/ the UTXO reserve, but\nthen sort of accepted the trade-off for the safety that actually being able\nto dynamically bump the fee on your commitment transaction and HTLCs. We're\nalso able to re-target the fee level of second level spends on the fly, and\neven aggregate them into distinct fee buckets.\n\nHowever, I can imagine that if an implementation doesn't have its own\nwallet, then things can be a bit more difficult, as stuff like the bitcoind\nwallet may not expose the APIs one needs to do things like CPFP properly.\nlnd has its own wallet (btcwallet), which is what has allowed us to adopt\ndefault P2TR addresses everywhere so quickly (tho ofc we inherit additional\nmaintenance costs).\n\n> Correctly managing this fee-bumping reserve involves a lot of complex\n> decisions and dynamic risk assessment, because in worst-case scenarios, a\n> node may need to fee-bump thousands of HTLC transactions in a short period\n> of time.\n\nIMO these new considerations aren't any worse than needing to predict the\nfuture fee schedule of the chain to ensure that you can force close in a\ntimely manner when you need to. Re fee bumping thousands of HTLCs: anchor\nlets them all be batched in the same transaction, which reduces fees and\nalso the worst-case on-chain force close footprint.\n\n> each node can simply sign multiple versions of the HTLC transactions at\n> various feerates\n\nI'm not sure this can be mapped super cleanly to taproot channels that use\nmusig2. Today in the spec draft/impl, both sides maintain a pair of nonces\n(one for each commitment transaction). If they need to sign N different\nversions, then they also need to exchange N nonces, both during the initial\nfunding process, and also each time a new commitment transaction is created.\nMo signatures means mo transaction latency. Also how would retransmitting be\nhandled? By sending distinct valid signatures for a given fee rate, you're\neffectively creating _even more_ commitments one needs to watch to be able\nto play once they potentially hit the chain.\n\nUltimately, I'm not sure why implementations that have already rolled out\nanchors by default, and have a satisfactory policy for ensuring fee bumping\nUTXOs are available at all times would implement this. It's just yet another\noption defined in the spec, and prescribes a more restrictive solution to\nwhat's already possible: being able to dynamically fee bump commitment\ntransactions, and aggregate second level spends.\n\n-- Laolu\n\nOn Thu, Oct 27, 2022 at 6:51 AM Bastien TEINTURIER <bastien at acinq.fr> wrote:\n\n> Good morning list,\n>\n> The lightning network transaction format was updated to leverage CPFP\n> carve-out and allow nodes to set fees at broadcast time, using a feature\n> called anchor outputs [1].\n>\n> While desirable, this change brought a whole new set of challenges, by\n> requiring nodes to maintain a reserve of available utxos for fee-bumping.\n> Correctly managing this fee-bumping reserve involves a lot of complex\n> decisions and dynamic risk assessment, because in worst-case scenarios,\n> a node may need to fee-bump thousands of HTLC transactions in a short\n> period of time.\n>\n> This is especially frustrating because HTLC transactions should not need\n> external inputs, as the whole value of the HTLC is already provided in\n> its input, which means we could in theory \"simply\" decrease the amount of\n> the corresponding output to set the fees to any desired value. However,\n> we can't do this safely because it doesn't work well with the revocation\n> mechanism, unless we find fancy new sighash flags to add to bitcoin.\n> See [2] for a longer rant on this issue.\n>\n> A very low tech and unsatisfying solution exists, which is what I'm\n> proposing today: each node can simply sign multiple versions of the\n> HTLC transactions at various feerates, and at broadcast time if you're\n> lucky you'll have a pre-signed transaction that approximately matches\n> the feerate you want, so you don't need to add inputs from your fee\n> bumping reserve. This reduces the requirements on your on-chain wallet\n> and simplifies transaction management logic. I believe that it's a\n> pragmatic approach, even though not very elegant, to increase funds\n> safety for existing node operators and wallets. I opened a spec PR\n> that is currently chasing concept ACKs before I refine it [3].\n>\n> Please let me know what you think, and if this is something that you\n> would like your implementation to provide.\n>\n> Thanks,\n> Bastien\n>\n> [1] https://github.com/lightning/bolts/pull/688\n> [2] https://github.com/lightning/bolts/issues/845\n> [3] https://github.com/lightning/bolts/pull/1036\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221104/9a1cfeb2/attachment.html>"
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2022-11-07T08:56:17",
                "message_text_only": "Hey laolu,\n\nThanks for your feedback.\n\n> However, I can imagine that if an implementation doesn't have its own\n> wallet, then things can be a bit more difficult, as stuff like the\nbitcoind\n> wallet may not expose the APIs one needs to do things like CPFP properly.\n\nI don't think this is only an issue of wallet management though. I would\nbet that most node operators today don't have a good enough utxo reserve\nto actually provide safety against a malicious attacker once mempool\nbacklog starts filling up. Eclair isn't really limited by bitcoind APIs\nhere, but rather by BIP 125 rules, which creates the same issues for\nlnd's internal wallet.\n\nThe reason we're not seeing issues today is only because there is no\nmalicious behavior on the network, but when that happens, there will\nbe issues (remember, the turkey thinks everything is fine and really\nlikes that guy who comes everyday to feed it, until Thanksgiving comes).\n\nThe issue I'm most concerned with is an attacker filling your outgoing\nHTLC slots with HTLCs that timeout at blocks N+1, N+2, ..., N+483. It's\nnot trivial to batch those HTLCs because they all have different cltv\nexpiries. If you're low on utxo count, you only have two choices:\n\n1. Re-create a batched transaction at every block to include more utxos\n2. Create trees of unconfirmed transactions where the change output of\none HTLC tx is the funding input of another HTLC tx\n\nWith option 1, you'll need to increase the overall feerate at every\nblock to match RBF rules, which means you'll end up greatly overpaying\nthe fees once you've RBF-ed a hundred times or more...\n\nWith option 2, it's even worse, because HTLCs that timeout earlier end\nup closer to the root of tree. It will be prohibitively costly to RBF\nthem because BIP 125 will force you to pay a huge fee for replacing a\nhigh number of unconfirmed descendants. Your only option is to CPFP at\none of the leaves of the tree, which is going to be very costly as well\nbecause it requires setting a high feerate to the *whole* tree, even\nthough it could contain many HTLCs that still have time available before\nthe cltv-expiry-delta ends.\n\nThe attacker may also regularly claim HTLCs one-by-one by revealing the\npreimage just to invalidate your whole batched transaction or tree of\nunconfirmed transactions, requiring you to rebuild it at every block and\nwait one more block before getting transactions confirmed (until you\nreach the point where the attacker can also claim all HTLC outputs and\nyour only solution is a scorched-earth strategy).\n\nBoth options end up with the node operator greatly overpaying fees when\nfighting a relatively smart attacker (which means the node operator is\nactually losing money).\n\nAlso, this is a fairly complex bit of logic to implement, which depends\non bitcoin node's relaying policies and is really hard to test against\nenough malicious scenarios. It's thus very likely to have subtle bugs.\n\nThis class of attacks are why eclair's default are very conservative:\n\n* 30 accepted HTLCs instead of 483\n* 144 blocks of cltv-expiry-delta\n\nI'm afraid this is the only way to tip the odds in the favor of the\nhonest node operators with the current protocol. It's very frustrating\nthough!\n\nAs for Taproot compatibility, this is perfectly doable: if we're able\nto share one nonce, we can just share multiple every time. If we're\nable to watch one transaction, we're able to watch multiple. It's more\ncostly, but it's not a fundamental limitation.\n\nI'm more concerned about limitations of this proposal to tackle dusty\nHTLCs kind of attacks and the complexity it introduces, as was raised\nin the comments of the spec PR [1]. Granted, this isn't a very *good*\nproposal, but it's an attempt at raising awareness that we probably\nneed to do *something* to get slightly better funds safety.\n\nThanks,\nBastien\n\n[1] https://github.com/lightning/bolts/pull/1036\n\nLe sam. 5 nov. 2022 \u00e0 01:52, Olaoluwa Osuntokun <laolu32 at gmail.com> a \u00e9crit\n:\n>\n> Hi tbast,\n>\n> FWIW, we haven't had _too_ many issues with the additional constraints\n> anchor channels bring. Initially users had to deal w/ the UTXO reserve,\nbut\n> then sort of accepted the trade-off for the safety that actually being\nable\n> to dynamically bump the fee on your commitment transaction and HTLCs.\nWe're\n> also able to re-target the fee level of second level spends on the fly,\nand\n> even aggregate them into distinct fee buckets.\n>\n> However, I can imagine that if an implementation doesn't have its own\n> wallet, then things can be a bit more difficult, as stuff like the\nbitcoind\n> wallet may not expose the APIs one needs to do things like CPFP properly.\n> lnd has its own wallet (btcwallet), which is what has allowed us to adopt\n> default P2TR addresses everywhere so quickly (tho ofc we inherit\nadditional\n> maintenance costs).\n>\n> > Correctly managing this fee-bumping reserve involves a lot of complex\n> > decisions and dynamic risk assessment, because in worst-case scenarios,\na\n> > node may need to fee-bump thousands of HTLC transactions in a short\nperiod\n> > of time.\n>\n> IMO these new considerations aren't any worse than needing to predict the\n> future fee schedule of the chain to ensure that you can force close in a\n> timely manner when you need to. Re fee bumping thousands of HTLCs: anchor\n> lets them all be batched in the same transaction, which reduces fees and\n> also the worst-case on-chain force close footprint.\n>\n> > each node can simply sign multiple versions of the HTLC transactions at\n> > various feerates\n>\n> I'm not sure this can be mapped super cleanly to taproot channels that use\n> musig2. Today in the spec draft/impl, both sides maintain a pair of nonces\n> (one for each commitment transaction). If they need to sign N different\n> versions, then they also need to exchange N nonces, both during the\ninitial\n> funding process, and also each time a new commitment transaction is\ncreated.\n> Mo signatures means mo transaction latency. Also how would retransmitting\nbe\n> handled? By sending distinct valid signatures for a given fee rate, you're\n> effectively creating _even more_ commitments one needs to watch to be able\n> to play once they potentially hit the chain.\n>\n> Ultimately, I'm not sure why implementations that have already rolled out\n> anchors by default, and have a satisfactory policy for ensuring fee\nbumping\n> UTXOs are available at all times would implement this. It's just yet\nanother\n> option defined in the spec, and prescribes a more restrictive solution to\n> what's already possible: being able to dynamically fee bump commitment\n> transactions, and aggregate second level spends.\n>\n> -- Laolu\n>\n> On Thu, Oct 27, 2022 at 6:51 AM Bastien TEINTURIER <bastien at acinq.fr>\nwrote:\n>>\n>> Good morning list,\n>>\n>> The lightning network transaction format was updated to leverage CPFP\n>> carve-out and allow nodes to set fees at broadcast time, using a feature\n>> called anchor outputs [1].\n>>\n>> While desirable, this change brought a whole new set of challenges, by\n>> requiring nodes to maintain a reserve of available utxos for fee-bumping.\n>> Correctly managing this fee-bumping reserve involves a lot of complex\n>> decisions and dynamic risk assessment, because in worst-case scenarios,\n>> a node may need to fee-bump thousands of HTLC transactions in a short\n>> period of time.\n>>\n>> This is especially frustrating because HTLC transactions should not need\n>> external inputs, as the whole value of the HTLC is already provided in\n>> its input, which means we could in theory \"simply\" decrease the amount of\n>> the corresponding output to set the fees to any desired value. However,\n>> we can't do this safely because it doesn't work well with the revocation\n>> mechanism, unless we find fancy new sighash flags to add to bitcoin.\n>> See [2] for a longer rant on this issue.\n>>\n>> A very low tech and unsatisfying solution exists, which is what I'm\n>> proposing today: each node can simply sign multiple versions of the\n>> HTLC transactions at various feerates, and at broadcast time if you're\n>> lucky you'll have a pre-signed transaction that approximately matches\n>> the feerate you want, so you don't need to add inputs from your fee\n>> bumping reserve. This reduces the requirements on your on-chain wallet\n>> and simplifies transaction management logic. I believe that it's a\n>> pragmatic approach, even though not very elegant, to increase funds\n>> safety for existing node operators and wallets. I opened a spec PR\n>> that is currently chasing concept ACKs before I refine it [3].\n>>\n>> Please let me know what you think, and if this is something that you\n>> would like your implementation to provide.\n>>\n>> Thanks,\n>> Bastien\n>>\n>> [1] https://github.com/lightning/bolts/pull/688\n>> [2] https://github.com/lightning/bolts/issues/845\n>> [3] https://github.com/lightning/bolts/pull/1036\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221107/890d4429/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "A pragmatic, unsatisfying work-around for anchor outputs fee-bumping reserve requirements",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Bastien TEINTURIER",
                "Olaoluwa Osuntokun"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 14311
        }
    },
    {
        "title": "[Lightning-dev] Mitigating Channel Jamming with Reputation Credentials: a Protocol Sketch",
        "thread_messages": [
            {
                "author": "Antoine Riard",
                "date": "2022-11-21T04:01:24",
                "message_text_only": "Hi LN Devs,\n\ntl;dr A formalization of a reputation-based scheme to solve channel jamming\nis proposed. The system relies on \"credentials\" issued by routing hops and\nrequested to be attached to each HTLC forward request. The \"credentials\"\ncan be used by a reputation algorithm to reward/punish payment senders and\nallocate channel liquidity resources efficiently. The \"credentials\"\ninitial distribution can be bootstrapped leveraging one-time upfront fees\npaid toward the routing hops. Afterwards, the \"credentials\" subsequent\ndistribution can rely on previous HTLC traffic.\n\nA protocol description can be found here, with few extensions already to\nthe BOLTs:\n\nhttps://github.com/lightning/bolts/pull/1043\n\nThere is also a work-in-progress proof-of-concept in LDK (on top of our\ncoming soon^TM  HTLC intercepting API):\n\nhttps://github.com/lightningdevkit/rust-lightning/pull/1848\n\nThis work builds on previous reputation-scheme research [0] [1]. It also\nintegrates the more recent proposals of upfront fees as a straightforward\nmechanism to bootstrap the reputation system. Bootstrapping the system with\nmore economically cost-effective privacy-preserving UTXO ownership proofs\nnot only add another layer of engineering complexity, there is still a\nproof size vs proof generation/validation trade-off to arbiter between ZKP\ncryptosystems.\n\nRather to seek for a game-theory equilibrium defined as a breakeven point\nas in the latest unconditional fee research [2], this proposal aims to use\nreputation credentials to allow HTLC traffic-shaping. This not only should\nprotect against jamming situations (either malicious\nor spontaneous) but also allow active HTLC traffic-shaping, where a routing\nhop can allow extended channel liquidity lockups based on accumulated\nreputation (e.g for hold-invoices). This is also a reduced overhead cost,\nas upfront fees are only paid at bootstrap, or when the HTLC forward\nbehavior can be qualified as \"whitewashing\" from the routing hop viewpoint.\n\nIt should be noted, this current reputation-credential architectural\nframework assumes credentials distribution at the endpoint of the network.\nHowever, the framework should be flexible enough for the credentials to be\nharvested by the LSPs, and then distributed in a secondary fashion to their\nspokes, when they need it, or even attached transparently thanks to\ntrampoline. So one design intuition, there is no strong attachment of the\nreputation to the endpoint HTLC sender, even if the protocol is described\nin a \"flat\" view for now.\n\nLet's evaluate quickly this mitigation proposal against a few criterias\nemerged from recent research.\n\nThe mitigation is effective, in the sense a routing hop can apply a\nproportional relationship between the acquisition of the reputation and the\namount of liquidity resources credited in function of said reputation. In a\nperiod of steady state, the reputation acquisition cost can be downgraded\nto 0. In periods of channel congestion, the reputation credentials to\nliquidity units translation can be severed, in the limit of routing hop\nacceptable competitiveness.\n\nThe mitigation is incentive-compatible, if the credentials are not honored\nby their issuers, the HTLC senders can evict them from the routing network\nview for a while. The successful usage of credentials can lead to more\ncredentials allocated for longer and more capacity-intensive channel\nlockups. In case of HTLC failure, the failure source could be forgiven by\nrouting hops to maintain the worthiness of the sender credentials.\n\nThe mitigation can be made transparent from the user, as the credentials\nharvesting can be done automatically from a pre-allocated budget, similar\nto the fee-bumping reserves requirement introduced by anchor output. At the\nend of today, if we take modern browsers as an example, the average user\ndoesn't check manually the TLS certificates (for what they're worth...).\n\nThe mitigation can conserve high-level privacy, as the usage of blinded\nsignature (or another equivalent cryptosystem breaking signature/message\nlinking) should allow the credentials issued during a preliminary phase to\nbe undistinguishable during the redeem/usage phase. New CPU/memory DoS\nvectors due to the credentials processing should be watched out.\n\nAbout the ease of implementation, there are few protocol messages to\nmodify, a HTLC intercepting API is assumed as supported by the\nimplementation, onion messages support is also implied, landing EC blinded\nsignature in libsecp256k1-zkp shouldn't be a big deal, routing algorithms\nadaptations might be more serious but still reasonable. The\n\"credentials-to-liquidity\" allocation algorithms are likely the new real\nbeast, though I don't think any reputation scheme can spare them.\n\nThere could be a concern about the centralization inertia introduced by a\nreputation system.  Intuitively, the argument can be made that any\nhistorical tracking (such as routing buckets) favor established LN\nincumbents at the gain of efficiency. A counter-argument can be made, a new\nrouting hop can lower the acquisition cost of its issued credentials to\nattract more HTLC traffic (accepting higher jamming risk).\n\nOn the ecosystem impacts, it should be studied that this proposal would\nimpact things like inbound channel routing fees [3], ratecard [4] or\nflow-control valve [5] and the whole liquidity toolchain. Hopefully, we\ndon't significantly restrain the design space for future LN protocol\nupgrades.\n\nOn the proposal modularity and flexibility, each routing node has oversight\non its routing policy, acquisition methods, credentials to liquidity rate.\nNew acquisition methods can be experimented or deployed when ready, e.g\nstakes certificates with only e2e upgrade. The credentials themselves could\nhave \"innate\" expiration time if we use things like short-lived ZKP [6].\nThe credentials framework can be extended beyond solving jamming, as a\ngeneralized risk-management framework for Bitcoin decentralized financial\nnetwork, e.g transaction signature exchange ordering in multi-party\ntransactions [7] or finding reliable Coinjoin counterparties.\n\nFeedback welcome.\n\nCheers,\nAntoine\n\n[0]\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2020-November/002884.html\n[1]\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2022-August/003673.html\n[2]\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2022-November/003740.html\n[3]\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2022-July/003643.html\n[4]\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2022-September/003685.html\n[5]\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2022-September/003686.html\n[6] https://eprint.iacr.org/2022/190.pdf\n[7] https://github.com/lightning/bolts/pull/851#issuecomment-1290727242\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221120/2a736ba2/attachment.html>"
            },
            {
                "author": "Clara Shikhelman",
                "date": "2022-11-21T18:15:38",
                "message_text_only": "Dear Antoine and list,\n\nI think that another call to discuss jamming would be great. I would\nsuggest making it a repeating call every 2 weeks, starting from Monday the\n28th at 7 pm UTC.\n\nAntoine - Thank you for your work!\nI have a few questions to better understand the details.\n\n1. Are the tokens transferable between users? For example, if Ned is a\nrouting node, and Alice has some of their tokens, can she give these tokens\nto Bob?\nIf yes - could this lead to the creation of a secondary market?\nIf no - will that slow down the transaction flow that a new node can send?\n\n2. Do you have a recommended policy for the creation of tokens and their\nuse? Ideally, there will be a policy that would mitigate both slow and\nquick jamming, without harming usability too much.\n\n3. You write \"the reputation credentials to liquidity units translation can\nbe severed\" - does this mean that the value of the token changes? Is that\nin the spirit of changing the fees in a channel?\nIf this is the case, can't a routing node \"trick\" a user into buying many\ntokens and then bring the price up?\n\n4. How would these tokens work with blinded paths and other\nprivacy-preserving suggestions?\n\nThanks again,\nClara\n\nOn Sun, Nov 20, 2022 at 11:01 PM Antoine Riard <antoine.riard at gmail.com>\nwrote:\n\n> Hi LN Devs,\n>\n> tl;dr A formalization of a reputation-based scheme to solve channel\n> jamming is proposed. The system relies on \"credentials\" issued by routing\n> hops and requested to be attached to each HTLC forward request. The\n> \"credentials\" can be used by a reputation algorithm to reward/punish\n> payment senders and allocate channel liquidity resources efficiently. The\n> \"credentials\"  initial distribution can be bootstrapped leveraging one-time\n> upfront fees paid toward the routing hops. Afterwards, the \"credentials\"\n> subsequent distribution can rely on previous HTLC traffic.\n>\n> A protocol description can be found here, with few extensions already to\n> the BOLTs:\n>\n> https://github.com/lightning/bolts/pull/1043\n>\n> There is also a work-in-progress proof-of-concept in LDK (on top of our\n> coming soon^TM  HTLC intercepting API):\n>\n> https://github.com/lightningdevkit/rust-lightning/pull/1848\n>\n> This work builds on previous reputation-scheme research [0] [1]. It also\n> integrates the more recent proposals of upfront fees as a straightforward\n> mechanism to bootstrap the reputation system. Bootstrapping the system with\n> more economically cost-effective privacy-preserving UTXO ownership proofs\n> not only add another layer of engineering complexity, there is still a\n> proof size vs proof generation/validation trade-off to arbiter between ZKP\n> cryptosystems.\n>\n> Rather to seek for a game-theory equilibrium defined as a breakeven point\n> as in the latest unconditional fee research [2], this proposal aims to use\n> reputation credentials to allow HTLC traffic-shaping. This not only should\n> protect against jamming situations (either malicious\n> or spontaneous) but also allow active HTLC traffic-shaping, where a\n> routing hop can allow extended channel liquidity lockups based on\n> accumulated reputation (e.g for hold-invoices). This is also a reduced\n> overhead cost, as upfront fees are only paid at bootstrap, or when the HTLC\n> forward behavior can be qualified as \"whitewashing\" from the routing hop\n> viewpoint.\n>\n> It should be noted, this current reputation-credential architectural\n> framework assumes credentials distribution at the endpoint of the network.\n> However, the framework should be flexible enough for the credentials to be\n> harvested by the LSPs, and then distributed in a secondary fashion to their\n> spokes, when they need it, or even attached transparently thanks to\n> trampoline. So one design intuition, there is no strong attachment of the\n> reputation to the endpoint HTLC sender, even if the protocol is described\n> in a \"flat\" view for now.\n>\n> Let's evaluate quickly this mitigation proposal against a few criterias\n> emerged from recent research.\n>\n> The mitigation is effective, in the sense a routing hop can apply a\n> proportional relationship between the acquisition of the reputation and the\n> amount of liquidity resources credited in function of said reputation. In a\n> period of steady state, the reputation acquisition cost can be downgraded\n> to 0. In periods of channel congestion, the reputation credentials to\n> liquidity units translation can be severed, in the limit of routing hop\n> acceptable competitiveness.\n>\n> The mitigation is incentive-compatible, if the credentials are not honored\n> by their issuers, the HTLC senders can evict them from the routing network\n> view for a while. The successful usage of credentials can lead to more\n> credentials allocated for longer and more capacity-intensive channel\n> lockups. In case of HTLC failure, the failure source could be forgiven by\n> routing hops to maintain the worthiness of the sender credentials.\n>\n> The mitigation can be made transparent from the user, as the credentials\n> harvesting can be done automatically from a pre-allocated budget, similar\n> to the fee-bumping reserves requirement introduced by anchor output. At the\n> end of today, if we take modern browsers as an example, the average user\n> doesn't check manually the TLS certificates (for what they're worth...).\n>\n> The mitigation can conserve high-level privacy, as the usage of blinded\n> signature (or another equivalent cryptosystem breaking signature/message\n> linking) should allow the credentials issued during a preliminary phase to\n> be undistinguishable during the redeem/usage phase. New CPU/memory DoS\n> vectors due to the credentials processing should be watched out.\n>\n> About the ease of implementation, there are few protocol messages to\n> modify, a HTLC intercepting API is assumed as supported by the\n> implementation, onion messages support is also implied, landing EC blinded\n> signature in libsecp256k1-zkp shouldn't be a big deal, routing algorithms\n> adaptations might be more serious but still reasonable. The\n> \"credentials-to-liquidity\" allocation algorithms are likely the new real\n> beast, though I don't think any reputation scheme can spare them.\n>\n> There could be a concern about the centralization inertia introduced by a\n> reputation system.  Intuitively, the argument can be made that any\n> historical tracking (such as routing buckets) favor established LN\n> incumbents at the gain of efficiency. A counter-argument can be made, a new\n> routing hop can lower the acquisition cost of its issued credentials to\n> attract more HTLC traffic (accepting higher jamming risk).\n>\n> On the ecosystem impacts, it should be studied that this proposal would\n> impact things like inbound channel routing fees [3], ratecard [4] or\n> flow-control valve [5] and the whole liquidity toolchain. Hopefully, we\n> don't significantly restrain the design space for future LN protocol\n> upgrades.\n>\n> On the proposal modularity and flexibility, each routing node has\n> oversight on its routing policy, acquisition methods, credentials to\n> liquidity rate. New acquisition methods can be experimented or deployed\n> when ready, e.g stakes certificates with only e2e upgrade. The credentials\n> themselves could have \"innate\" expiration time if we use things like\n> short-lived ZKP [6]. The credentials framework can be extended beyond\n> solving jamming, as a generalized risk-management framework for Bitcoin\n> decentralized financial network, e.g transaction signature exchange\n> ordering in multi-party transactions [7] or finding reliable Coinjoin\n> counterparties.\n>\n> Feedback welcome.\n>\n> Cheers,\n> Antoine\n>\n> [0]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-November/002884.html\n> [1]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-August/003673.html\n> [2]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-November/003740.html\n> [3]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-July/003643.html\n> [4]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-September/003685.html\n> [5]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-September/003686.html\n> [6] https://eprint.iacr.org/2022/190.pdf\n> [7] https://github.com/lightning/bolts/pull/851#issuecomment-1290727242\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221121/ae6ba7de/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-11-22T00:26:22",
                "message_text_only": "Hi Clara,\n\nThanks for reading!\n\n> I think that another call to discuss jamming would be great. I would\n> suggest making it a repeating call every 2 weeks, starting from Monday the\n> 28th at 7 pm UTC.\n\nCool to take the initiative, the schedule works for me, however this slot\nmight conflict with the Core Lightning engineering call ? I remember we\nmoved the LDK meeting time from 7pm to 5pm, as we had folks willing to\nattend both.\n\n> 1. Are the tokens transferable between users? For example, if Ned is a\n> routing node, and Alice has some of their tokens, can she give these\ntokens\n> to Bob?\n> If yes - could this lead to the creation of a secondary market?\n> If no - will that slow down the transaction flow that a new node can send?\n\nCurrent version of the proposal, there is nothing preventing the tokens to\nbe transferred between the users, Alice can give these tokens to Bob. We\ncould make them binding to the prover, by requesting a new round where\nAlice registers a pubkey towards Ned, and all tokens should be\ncounter-authenticated by Ned at forward. Ned would flag out the\ndouble-usage of tokens, ideally in a ZKP-way. Still I think this would\nnever prevent Alice from sharing her key material with Bob. So I'm not sure\nwe can prevent a secondary-market, and it might be even more valuable if we\nwould like LSPs to collect tokens for their spokes nodes to simplify UX.\n\nThat said, beyond unlinkability between the blinded message and the\ncleartext tokens/signatures, I think all the properties should be open to\nmore research.\n\n> 2. Do you have a recommended policy for the creation of tokens and their\n> use? Ideally, there will be a policy that would mitigate both slow and\n> quick jamming, without harming usability too much.\n\nIf by recommend policy, you mean the set of algorithms that should guide\nthe token quantity, rate issuance, token acquisition cost, and the\nadaptations in function of the local channel congestion, or even the\ngossips of the other routing nodes, not at all. Just intuition, I think a\nsimple model should start from enforcing a proportionality between token\nacquisition costs and the available channels liquidity, then you can add\nmore factors in function of your risk model.\n\nAbout the slow/quick jamming distinction, I still believe a good\nanti-jamming solution should aim to solve things in a continuous fashion,\nrather than a discrete one. That way binds better to the reality of\ndiffering hold time Lightning HTLC: simple payment, offline receive,\nhold-invoice,  swaps, etc...\n\n> 3. You write \"the reputation credentials to liquidity units translation\ncan\n> be severed\" - does this mean that the value of the token changes? Is that\n> in the spirit of changing the fees in a channel?\n> If this is the case, can't a routing node \"trick\" a user into buying many\n> tokens and then bring the price up?\n\nYes, the \"liquidity value\" of the tokens is currently left as a floating\nparameter. This is a good question if it should be fixed and only the\nrouting fees should fluctuate in function of channel congestion, or\nfloating e.g when the global quantity of tokens are required to re-dilute\ntheir current values to maintain some proportion between acquisition cost\nand available liquidity.\n\nFor sure, a routing node could \"trick\" a user into buying many tokens and\nthen break the promise of not only bringing the price up but also plainly\nreject HTLC forward requests satisfying the announced routing policy.\nThough note the user's routing algorithms could penalize in retorsion the\nnode, if the routing policy gossiped isn't respected.\n\n> 4. How would these tokens work with blinded paths and other\n> privacy-preserving suggestions?\n\nPrimarily, the tokens could use the new onion messages and blinded paths\nfor the dissemination and renewal rounds. Current design assumes they're\nattached to the HTLC during forward along the payment path, though I think\none design alternative could be completely detached, and the HTLC onion\njust contains a ref to the tokens.\n\n\nZooming out, after submitting this proposal to the mailing list yesterday,\nI thought how much a token/credentials system bootstrapped on pre-paid fees\nshould be classified into monetary strategy or a reputation-based strategy,\nand it turns out as there is an acquisition cost associated to the tokens,\nin fact it might belong more to the monetary strategy classification. So I\nwonder now if the usage of the reputation in the proposal title isn't\nmisleading and if a \"breakeven point\" isn't still implied (\"the\nproportionality\" seeked). From a history of ideas standpoint, a\nreputation-based strategy was more the Stakes Certificate solution\noriginally proposed in 2020. Though this proposal reuses the liquidity\nunits/credit score introduced there.\n\nI think more and more we should have a \"two-tier\" mitigation strategy,\nwhere the base tier is strictly defined in \"pure fees\" terms, and then\nlayered on top of a reputation system. A routing node could deviate from\nthe zero risk \"pure fees\" ones to increase its routing fees returns, by\nrelying more on assumptions like \"Past HTLC senders behave well if there is\na proportionality between reputation cost and amount of liquidity resources\nallocated in function of said-reputation\".\n\nLooking forward to pursuing discussions during calls!\n\nBest,\nAntoine\n\nLe lun. 21 nov. 2022 \u00e0 13:16, Clara Shikhelman <clara.shikhelman at gmail.com>\na \u00e9crit :\n\n> Dear Antoine and list,\n>\n> I think that another call to discuss jamming would be great. I would\n> suggest making it a repeating call every 2 weeks, starting from Monday the\n> 28th at 7 pm UTC.\n>\n> Antoine - Thank you for your work!\n> I have a few questions to better understand the details.\n>\n> 1. Are the tokens transferable between users? For example, if Ned is a\n> routing node, and Alice has some of their tokens, can she give these tokens\n> to Bob?\n> If yes - could this lead to the creation of a secondary market?\n> If no - will that slow down the transaction flow that a new node can send?\n>\n> 2. Do you have a recommended policy for the creation of tokens and their\n> use? Ideally, there will be a policy that would mitigate both slow and\n> quick jamming, without harming usability too much.\n>\n> 3. You write \"the reputation credentials to liquidity units translation\n> can be severed\" - does this mean that the value of the token changes? Is\n> that in the spirit of changing the fees in a channel?\n> If this is the case, can't a routing node \"trick\" a user into buying many\n> tokens and then bring the price up?\n>\n> 4. How would these tokens work with blinded paths and other\n> privacy-preserving suggestions?\n>\n> Thanks again,\n> Clara\n>\n> On Sun, Nov 20, 2022 at 11:01 PM Antoine Riard <antoine.riard at gmail.com>\n> wrote:\n>\n>> Hi LN Devs,\n>>\n>> tl;dr A formalization of a reputation-based scheme to solve channel\n>> jamming is proposed. The system relies on \"credentials\" issued by routing\n>> hops and requested to be attached to each HTLC forward request. The\n>> \"credentials\" can be used by a reputation algorithm to reward/punish\n>> payment senders and allocate channel liquidity resources efficiently. The\n>> \"credentials\"  initial distribution can be bootstrapped leveraging one-time\n>> upfront fees paid toward the routing hops. Afterwards, the \"credentials\"\n>> subsequent distribution can rely on previous HTLC traffic.\n>>\n>> A protocol description can be found here, with few extensions already to\n>> the BOLTs:\n>>\n>> https://github.com/lightning/bolts/pull/1043\n>>\n>> There is also a work-in-progress proof-of-concept in LDK (on top of our\n>> coming soon^TM  HTLC intercepting API):\n>>\n>> https://github.com/lightningdevkit/rust-lightning/pull/1848\n>>\n>> This work builds on previous reputation-scheme research [0] [1]. It also\n>> integrates the more recent proposals of upfront fees as a straightforward\n>> mechanism to bootstrap the reputation system. Bootstrapping the system with\n>> more economically cost-effective privacy-preserving UTXO ownership proofs\n>> not only add another layer of engineering complexity, there is still a\n>> proof size vs proof generation/validation trade-off to arbiter between ZKP\n>> cryptosystems.\n>>\n>> Rather to seek for a game-theory equilibrium defined as a breakeven point\n>> as in the latest unconditional fee research [2], this proposal aims to use\n>> reputation credentials to allow HTLC traffic-shaping. This not only should\n>> protect against jamming situations (either malicious\n>> or spontaneous) but also allow active HTLC traffic-shaping, where a\n>> routing hop can allow extended channel liquidity lockups based on\n>> accumulated reputation (e.g for hold-invoices). This is also a reduced\n>> overhead cost, as upfront fees are only paid at bootstrap, or when the HTLC\n>> forward behavior can be qualified as \"whitewashing\" from the routing hop\n>> viewpoint.\n>>\n>> It should be noted, this current reputation-credential architectural\n>> framework assumes credentials distribution at the endpoint of the network.\n>> However, the framework should be flexible enough for the credentials to be\n>> harvested by the LSPs, and then distributed in a secondary fashion to their\n>> spokes, when they need it, or even attached transparently thanks to\n>> trampoline. So one design intuition, there is no strong attachment of the\n>> reputation to the endpoint HTLC sender, even if the protocol is described\n>> in a \"flat\" view for now.\n>>\n>> Let's evaluate quickly this mitigation proposal against a few criterias\n>> emerged from recent research.\n>>\n>> The mitigation is effective, in the sense a routing hop can apply a\n>> proportional relationship between the acquisition of the reputation and the\n>> amount of liquidity resources credited in function of said reputation. In a\n>> period of steady state, the reputation acquisition cost can be downgraded\n>> to 0. In periods of channel congestion, the reputation credentials to\n>> liquidity units translation can be severed, in the limit of routing hop\n>> acceptable competitiveness.\n>>\n>> The mitigation is incentive-compatible, if the credentials are not\n>> honored by their issuers, the HTLC senders can evict them from the routing\n>> network view for a while. The successful usage of credentials can lead to\n>> more credentials allocated for longer and more capacity-intensive channel\n>> lockups. In case of HTLC failure, the failure source could be forgiven by\n>> routing hops to maintain the worthiness of the sender credentials.\n>>\n>> The mitigation can be made transparent from the user, as the credentials\n>> harvesting can be done automatically from a pre-allocated budget, similar\n>> to the fee-bumping reserves requirement introduced by anchor output. At the\n>> end of today, if we take modern browsers as an example, the average user\n>> doesn't check manually the TLS certificates (for what they're worth...).\n>>\n>> The mitigation can conserve high-level privacy, as the usage of blinded\n>> signature (or another equivalent cryptosystem breaking signature/message\n>> linking) should allow the credentials issued during a preliminary phase to\n>> be undistinguishable during the redeem/usage phase. New CPU/memory DoS\n>> vectors due to the credentials processing should be watched out.\n>>\n>> About the ease of implementation, there are few protocol messages to\n>> modify, a HTLC intercepting API is assumed as supported by the\n>> implementation, onion messages support is also implied, landing EC blinded\n>> signature in libsecp256k1-zkp shouldn't be a big deal, routing algorithms\n>> adaptations might be more serious but still reasonable. The\n>> \"credentials-to-liquidity\" allocation algorithms are likely the new real\n>> beast, though I don't think any reputation scheme can spare them.\n>>\n>> There could be a concern about the centralization inertia introduced by a\n>> reputation system.  Intuitively, the argument can be made that any\n>> historical tracking (such as routing buckets) favor established LN\n>> incumbents at the gain of efficiency. A counter-argument can be made, a new\n>> routing hop can lower the acquisition cost of its issued credentials to\n>> attract more HTLC traffic (accepting higher jamming risk).\n>>\n>> On the ecosystem impacts, it should be studied that this proposal would\n>> impact things like inbound channel routing fees [3], ratecard [4] or\n>> flow-control valve [5] and the whole liquidity toolchain. Hopefully, we\n>> don't significantly restrain the design space for future LN protocol\n>> upgrades.\n>>\n>> On the proposal modularity and flexibility, each routing node has\n>> oversight on its routing policy, acquisition methods, credentials to\n>> liquidity rate. New acquisition methods can be experimented or deployed\n>> when ready, e.g stakes certificates with only e2e upgrade. The credentials\n>> themselves could have \"innate\" expiration time if we use things like\n>> short-lived ZKP [6]. The credentials framework can be extended beyond\n>> solving jamming, as a generalized risk-management framework for Bitcoin\n>> decentralized financial network, e.g transaction signature exchange\n>> ordering in multi-party transactions [7] or finding reliable Coinjoin\n>> counterparties.\n>>\n>> Feedback welcome.\n>>\n>> Cheers,\n>> Antoine\n>>\n>> [0]\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-November/002884.html\n>> [1]\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-August/003673.html\n>> [2]\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-November/003740.html\n>> [3]\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-July/003643.html\n>> [4]\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-September/003685.html\n>> [5]\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-September/003686.html\n>> [6] https://eprint.iacr.org/2022/190.pdf\n>> [7] https://github.com/lightning/bolts/pull/851#issuecomment-1290727242\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221121/d1e83ac2/attachment-0001.html>"
            },
            {
                "author": "Clara Shikhelman",
                "date": "2022-11-22T20:54:04",
                "message_text_only": "Dear All,\n\nIf the call time (Monday the 28th at 7 pm UTC) doesn't work out for you,\nplease reach out!\n\nThanks for your quick and detailed response, Antoine.\n\nIf by recommend policy, you mean the set of algorithms that should guide\n> the token quantity, rate issuance, token acquisition cost, and the\n> adaptations in function of the local channel congestion, or even the\n> gossips of the other routing nodes, not at all.\n>\n\nDo you have a timeline in mind for presenting such a policy?\n\nLooking forward to discussing this further over the phone call, will make\nsome inquiries to make sure the time works for most people.\n\nBest,\nClara\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221122/8760f2a6/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-11-23T01:13:06",
                "message_text_only": "Hi Clara,\n\nShared the mail on #lightning-dev Libera chat to get more feedback on\nschedule.\n\n> Do you have a timeline in mind for presenting such a policy?\n\nSee the comments on the BOLT #1043  PR, for now I'm thinking more to refine\nthe proposed credentials architectural framework.\nI think dynamic routing policy in function of channel congestion rate, and\nyou combine that with reputation to do active risk-management are far more\nadvanced questions.\n\nBest,\nAntoine\n\nLe mar. 22 nov. 2022 \u00e0 15:54, Clara Shikhelman <clara.shikhelman at gmail.com>\na \u00e9crit :\n\n> Dear All,\n>\n> If the call time (Monday the 28th at 7 pm UTC) doesn't work out for you,\n> please reach out!\n>\n> Thanks for your quick and detailed response, Antoine.\n>\n> If by recommend policy, you mean the set of algorithms that should guide\n>> the token quantity, rate issuance, token acquisition cost, and the\n>> adaptations in function of the local channel congestion, or even the\n>> gossips of the other routing nodes, not at all.\n>>\n>\n> Do you have a timeline in mind for presenting such a policy?\n>\n> Looking forward to discussing this further over the phone call, will make\n> some inquiries to make sure the time works for most people.\n>\n> Best,\n> Clara\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221122/11bab8b0/attachment.html>"
            },
            {
                "author": "Clara Shikhelman",
                "date": "2022-11-23T15:59:56",
                "message_text_only": "Hi Antoine,\n\nTo discuss your proposed solution in detail, I think that some kind of\nrecommended policy is needed. If presenting one is a low priority, and\nwaiting for other things, my main concern is that it will just never happen\n(\"any decade now\" kind of situation).\n\nBest,\nClara\n\nOn Tue, Nov 22, 2022 at 8:13 PM Antoine Riard <antoine.riard at gmail.com>\nwrote:\n\n> Hi Clara,\n>\n> Shared the mail on #lightning-dev Libera chat to get more feedback on\n> schedule.\n>\n> > Do you have a timeline in mind for presenting such a policy?\n>\n> See the comments on the BOLT #1043  PR, for now I'm thinking more to\n> refine the proposed credentials architectural framework.\n> I think dynamic routing policy in function of channel congestion rate, and\n> you combine that with reputation to do active risk-management are far more\n> advanced questions.\n>\n> Best,\n> Antoine\n>\n> Le mar. 22 nov. 2022 \u00e0 15:54, Clara Shikhelman <clara.shikhelman at gmail.com>\n> a \u00e9crit :\n>\n>> Dear All,\n>>\n>> If the call time (Monday the 28th at 7 pm UTC) doesn't work out for you,\n>> please reach out!\n>>\n>> Thanks for your quick and detailed response, Antoine.\n>>\n>> If by recommend policy, you mean the set of algorithms that should guide\n>>> the token quantity, rate issuance, token acquisition cost, and the\n>>> adaptations in function of the local channel congestion, or even the\n>>> gossips of the other routing nodes, not at all.\n>>>\n>>\n>> Do you have a timeline in mind for presenting such a policy?\n>>\n>> Looking forward to discussing this further over the phone call, will make\n>> some inquiries to make sure the time works for most people.\n>>\n>> Best,\n>> Clara\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221123/ba980de5/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-11-24T02:48:06",
                "message_text_only": "Hi Clara,\n\nI think the simplest recommended policy you can devise is credential shown\nto the routing hop should cover for full routing fees, therefore the\nrouting hop benefits from a zero-jamming risk situation. Then you can\nappreciate the \"liquidity value\" credentials requested in function of your\nlocal channel congestion rate, or even network data. Increasing your\nreturns in exchange of higher risk exposure. And even more, you can lay on\ntop a reputation layer, where the reputation scores are fully fungible\nagainst monetary credentials, in the acceptance of a HTLC forward request.\n\nSo I think I agree with you a recommended policy is needed, let's just\nstart with a simple one! And refine it with time once we sense we have\nsolid foundations.\n\nBest,\nAntoine\n\n\nLe mer. 23 nov. 2022 \u00e0 11:00, Clara Shikhelman <clara.shikhelman at gmail.com>\na \u00e9crit :\n\n> Hi Antoine,\n>\n> To discuss your proposed solution in detail, I think that some kind of\n> recommended policy is needed. If presenting one is a low priority, and\n> waiting for other things, my main concern is that it will just never happen\n> (\"any decade now\" kind of situation).\n>\n> Best,\n> Clara\n>\n> On Tue, Nov 22, 2022 at 8:13 PM Antoine Riard <antoine.riard at gmail.com>\n> wrote:\n>\n>> Hi Clara,\n>>\n>> Shared the mail on #lightning-dev Libera chat to get more feedback on\n>> schedule.\n>>\n>> > Do you have a timeline in mind for presenting such a policy?\n>>\n>> See the comments on the BOLT #1043  PR, for now I'm thinking more to\n>> refine the proposed credentials architectural framework.\n>> I think dynamic routing policy in function of channel congestion rate,\n>> and you combine that with reputation to do active risk-management are far\n>> more advanced questions.\n>>\n>> Best,\n>> Antoine\n>>\n>> Le mar. 22 nov. 2022 \u00e0 15:54, Clara Shikhelman <\n>> clara.shikhelman at gmail.com> a \u00e9crit :\n>>\n>>> Dear All,\n>>>\n>>> If the call time (Monday the 28th at 7 pm UTC) doesn't work out for you,\n>>> please reach out!\n>>>\n>>> Thanks for your quick and detailed response, Antoine.\n>>>\n>>> If by recommend policy, you mean the set of algorithms that should guide\n>>>> the token quantity, rate issuance, token acquisition cost, and the\n>>>> adaptations in function of the local channel congestion, or even the\n>>>> gossips of the other routing nodes, not at all.\n>>>>\n>>>\n>>> Do you have a timeline in mind for presenting such a policy?\n>>>\n>>> Looking forward to discussing this further over the phone call, will\n>>> make some inquiries to make sure the time works for most people.\n>>>\n>>> Best,\n>>> Clara\n>>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221123/4dfcbdf3/attachment.html>"
            },
            {
                "author": "Clara Shikhelman",
                "date": "2022-11-24T14:44:55",
                "message_text_only": "Hi Antoine,\n\nIt sounds like unconditional fees cover most of what this policy does,\nwithout the extra risks that come from creating a new token. Is there a\nclear benefit to using a token compared to unconditional fees and\nlocal reputation?\n\nBest,\nClara\n\nOn Wed, Nov 23, 2022 at 9:48 PM Antoine Riard <antoine.riard at gmail.com>\nwrote:\n\n> Hi Clara,\n>\n> I think the simplest recommended policy you can devise is credential shown\n> to the routing hop should cover for full routing fees, therefore the\n> routing hop benefits from a zero-jamming risk situation. Then you can\n> appreciate the \"liquidity value\" credentials requested in function of your\n> local channel congestion rate, or even network data. Increasing your\n> returns in exchange of higher risk exposure. And even more, you can lay on\n> top a reputation layer, where the reputation scores are fully fungible\n> against monetary credentials, in the acceptance of a HTLC forward request.\n>\n> So I think I agree with you a recommended policy is needed, let's just\n> start with a simple one! And refine it with time once we sense we have\n> solid foundations.\n>\n> Best,\n> Antoine\n>\n>\n> Le mer. 23 nov. 2022 \u00e0 11:00, Clara Shikhelman <clara.shikhelman at gmail.com>\n> a \u00e9crit :\n>\n>> Hi Antoine,\n>>\n>> To discuss your proposed solution in detail, I think that some kind of\n>> recommended policy is needed. If presenting one is a low priority, and\n>> waiting for other things, my main concern is that it will just never happen\n>> (\"any decade now\" kind of situation).\n>>\n>> Best,\n>> Clara\n>>\n>> On Tue, Nov 22, 2022 at 8:13 PM Antoine Riard <antoine.riard at gmail.com>\n>> wrote:\n>>\n>>> Hi Clara,\n>>>\n>>> Shared the mail on #lightning-dev Libera chat to get more feedback on\n>>> schedule.\n>>>\n>>> > Do you have a timeline in mind for presenting such a policy?\n>>>\n>>> See the comments on the BOLT #1043  PR, for now I'm thinking more to\n>>> refine the proposed credentials architectural framework.\n>>> I think dynamic routing policy in function of channel congestion rate,\n>>> and you combine that with reputation to do active risk-management are far\n>>> more advanced questions.\n>>>\n>>> Best,\n>>> Antoine\n>>>\n>>> Le mar. 22 nov. 2022 \u00e0 15:54, Clara Shikhelman <\n>>> clara.shikhelman at gmail.com> a \u00e9crit :\n>>>\n>>>> Dear All,\n>>>>\n>>>> If the call time (Monday the 28th at 7 pm UTC) doesn't work out for\n>>>> you, please reach out!\n>>>>\n>>>> Thanks for your quick and detailed response, Antoine.\n>>>>\n>>>> If by recommend policy, you mean the set of algorithms that should\n>>>>> guide the token quantity, rate issuance, token acquisition cost, and the\n>>>>> adaptations in function of the local channel congestion, or even the\n>>>>> gossips of the other routing nodes, not at all.\n>>>>>\n>>>>\n>>>> Do you have a timeline in mind for presenting such a policy?\n>>>>\n>>>> Looking forward to discussing this further over the phone call, will\n>>>> make some inquiries to make sure the time works for most people.\n>>>>\n>>>> Best,\n>>>> Clara\n>>>>\n>>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221124/ae8ebfc1/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-11-25T02:21:54",
                "message_text_only": "Hi Clara,\n\nThe main benefit of this \"staking\"/reputational credentials is to save on\nunconditional fees paid by HTLC senders. They benefit from their past HTLC\nrouting success in terms of more credentials allocated to them, and as such\nminimize the overhead cost of their future HTLC sends, or allow them to\nlock liquidity for longer periods. From a routing node viewpoint, a 0-risk\nHTLC forwarding acceptance can be maintained by requesting strict binding\nbetween credentials acquisition cost and channel liquidity routed. If\nhigher returns are seeked, the ratio credentials to liquidity can be\nadjusted, of course coming with higher risks, and I think this is where the\nmodel built for the current unconditional fees proposal could be useful (if\nwe integrate the channel congestion rate factor, I believe).\n\nOn top of this monetary paradigm, we can layer a \"pure reputation\" system,\nwhere in function of the quality of the identities (e.g\nproof-of-utxo-ownership), HTLC senders are allocated more significant\nliquidity slots. Here, the real bottleneck is the cryptosystem, i.e proving\na UTXO ownership without revealing any other information. The rationale of\nthis \"pure reputation\" system, we could even save more in\nupfront/unconditional fees in the steady state of the network (however such\na probabilistic model breaks hard in presence of attackers).\n\nBest,\nAntoine\n\nLe jeu. 24 nov. 2022 \u00e0 09:45, Clara Shikhelman <clara.shikhelman at gmail.com>\na \u00e9crit :\n\n> Hi Antoine,\n>\n> It sounds like unconditional fees cover most of what this policy does,\n> without the extra risks that come from creating a new token. Is there a\n> clear benefit to using a token compared to unconditional fees and\n> local reputation?\n>\n> Best,\n> Clara\n>\n> On Wed, Nov 23, 2022 at 9:48 PM Antoine Riard <antoine.riard at gmail.com>\n> wrote:\n>\n>> Hi Clara,\n>>\n>> I think the simplest recommended policy you can devise is credential\n>> shown to the routing hop should cover for full routing fees, therefore the\n>> routing hop benefits from a zero-jamming risk situation. Then you can\n>> appreciate the \"liquidity value\" credentials requested in function of your\n>> local channel congestion rate, or even network data. Increasing your\n>> returns in exchange of higher risk exposure. And even more, you can lay on\n>> top a reputation layer, where the reputation scores are fully fungible\n>> against monetary credentials, in the acceptance of a HTLC forward request.\n>>\n>> So I think I agree with you a recommended policy is needed, let's just\n>> start with a simple one! And refine it with time once we sense we have\n>> solid foundations.\n>>\n>> Best,\n>> Antoine\n>>\n>>\n>> Le mer. 23 nov. 2022 \u00e0 11:00, Clara Shikhelman <\n>> clara.shikhelman at gmail.com> a \u00e9crit :\n>>\n>>> Hi Antoine,\n>>>\n>>> To discuss your proposed solution in detail, I think that some kind of\n>>> recommended policy is needed. If presenting one is a low priority, and\n>>> waiting for other things, my main concern is that it will just never happen\n>>> (\"any decade now\" kind of situation).\n>>>\n>>> Best,\n>>> Clara\n>>>\n>>> On Tue, Nov 22, 2022 at 8:13 PM Antoine Riard <antoine.riard at gmail.com>\n>>> wrote:\n>>>\n>>>> Hi Clara,\n>>>>\n>>>> Shared the mail on #lightning-dev Libera chat to get more feedback on\n>>>> schedule.\n>>>>\n>>>> > Do you have a timeline in mind for presenting such a policy?\n>>>>\n>>>> See the comments on the BOLT #1043  PR, for now I'm thinking more to\n>>>> refine the proposed credentials architectural framework.\n>>>> I think dynamic routing policy in function of channel congestion rate,\n>>>> and you combine that with reputation to do active risk-management are far\n>>>> more advanced questions.\n>>>>\n>>>> Best,\n>>>> Antoine\n>>>>\n>>>> Le mar. 22 nov. 2022 \u00e0 15:54, Clara Shikhelman <\n>>>> clara.shikhelman at gmail.com> a \u00e9crit :\n>>>>\n>>>>> Dear All,\n>>>>>\n>>>>> If the call time (Monday the 28th at 7 pm UTC) doesn't work out for\n>>>>> you, please reach out!\n>>>>>\n>>>>> Thanks for your quick and detailed response, Antoine.\n>>>>>\n>>>>> If by recommend policy, you mean the set of algorithms that should\n>>>>>> guide the token quantity, rate issuance, token acquisition cost, and the\n>>>>>> adaptations in function of the local channel congestion, or even the\n>>>>>> gossips of the other routing nodes, not at all.\n>>>>>>\n>>>>>\n>>>>> Do you have a timeline in mind for presenting such a policy?\n>>>>>\n>>>>> Looking forward to discussing this further over the phone call, will\n>>>>> make some inquiries to make sure the time works for most people.\n>>>>>\n>>>>> Best,\n>>>>> Clara\n>>>>>\n>>>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221124/e87d5d27/attachment-0001.html>"
            },
            {
                "author": "Clara Shikhelman",
                "date": "2022-11-25T15:40:11",
                "message_text_only": "Cool, thanks for that.\n\nHave you done any work on the economic aspects of the new tokens and their\nsecondary markets?\n\nOn Thu, Nov 24, 2022, 21:22 Antoine Riard <antoine.riard at gmail.com> wrote:\n\n> Hi Clara,\n>\n> The main benefit of this \"staking\"/reputational credentials is to save on\n> unconditional fees paid by HTLC senders. They benefit from their past HTLC\n> routing success in terms of more credentials allocated to them, and as such\n> minimize the overhead cost of their future HTLC sends, or allow them to\n> lock liquidity for longer periods. From a routing node viewpoint, a 0-risk\n> HTLC forwarding acceptance can be maintained by requesting strict binding\n> between credentials acquisition cost and channel liquidity routed. If\n> higher returns are seeked, the ratio credentials to liquidity can be\n> adjusted, of course coming with higher risks, and I think this is where the\n> model built for the current unconditional fees proposal could be useful (if\n> we integrate the channel congestion rate factor, I believe).\n>\n> On top of this monetary paradigm, we can layer a \"pure reputation\" system,\n> where in function of the quality of the identities (e.g\n> proof-of-utxo-ownership), HTLC senders are allocated more significant\n> liquidity slots. Here, the real bottleneck is the cryptosystem, i.e proving\n> a UTXO ownership without revealing any other information. The rationale of\n> this \"pure reputation\" system, we could even save more in\n> upfront/unconditional fees in the steady state of the network (however such\n> a probabilistic model breaks hard in presence of attackers).\n>\n> Best,\n> Antoine\n>\n> Le jeu. 24 nov. 2022 \u00e0 09:45, Clara Shikhelman <clara.shikhelman at gmail.com>\n> a \u00e9crit :\n>\n>> Hi Antoine,\n>>\n>> It sounds like unconditional fees cover most of what this policy does,\n>> without the extra risks that come from creating a new token. Is there a\n>> clear benefit to using a token compared to unconditional fees and\n>> local reputation?\n>>\n>> Best,\n>> Clara\n>>\n>> On Wed, Nov 23, 2022 at 9:48 PM Antoine Riard <antoine.riard at gmail.com>\n>> wrote:\n>>\n>>> Hi Clara,\n>>>\n>>> I think the simplest recommended policy you can devise is credential\n>>> shown to the routing hop should cover for full routing fees, therefore the\n>>> routing hop benefits from a zero-jamming risk situation. Then you can\n>>> appreciate the \"liquidity value\" credentials requested in function of your\n>>> local channel congestion rate, or even network data. Increasing your\n>>> returns in exchange of higher risk exposure. And even more, you can lay on\n>>> top a reputation layer, where the reputation scores are fully fungible\n>>> against monetary credentials, in the acceptance of a HTLC forward request.\n>>>\n>>> So I think I agree with you a recommended policy is needed, let's just\n>>> start with a simple one! And refine it with time once we sense we have\n>>> solid foundations.\n>>>\n>>> Best,\n>>> Antoine\n>>>\n>>>\n>>> Le mer. 23 nov. 2022 \u00e0 11:00, Clara Shikhelman <\n>>> clara.shikhelman at gmail.com> a \u00e9crit :\n>>>\n>>>> Hi Antoine,\n>>>>\n>>>> To discuss your proposed solution in detail, I think that some kind of\n>>>> recommended policy is needed. If presenting one is a low priority, and\n>>>> waiting for other things, my main concern is that it will just never happen\n>>>> (\"any decade now\" kind of situation).\n>>>>\n>>>> Best,\n>>>> Clara\n>>>>\n>>>> On Tue, Nov 22, 2022 at 8:13 PM Antoine Riard <antoine.riard at gmail.com>\n>>>> wrote:\n>>>>\n>>>>> Hi Clara,\n>>>>>\n>>>>> Shared the mail on #lightning-dev Libera chat to get more feedback on\n>>>>> schedule.\n>>>>>\n>>>>> > Do you have a timeline in mind for presenting such a policy?\n>>>>>\n>>>>> See the comments on the BOLT #1043  PR, for now I'm thinking more to\n>>>>> refine the proposed credentials architectural framework.\n>>>>> I think dynamic routing policy in function of channel congestion rate,\n>>>>> and you combine that with reputation to do active risk-management are far\n>>>>> more advanced questions.\n>>>>>\n>>>>> Best,\n>>>>> Antoine\n>>>>>\n>>>>> Le mar. 22 nov. 2022 \u00e0 15:54, Clara Shikhelman <\n>>>>> clara.shikhelman at gmail.com> a \u00e9crit :\n>>>>>\n>>>>>> Dear All,\n>>>>>>\n>>>>>> If the call time (Monday the 28th at 7 pm UTC) doesn't work out for\n>>>>>> you, please reach out!\n>>>>>>\n>>>>>> Thanks for your quick and detailed response, Antoine.\n>>>>>>\n>>>>>> If by recommend policy, you mean the set of algorithms that should\n>>>>>>> guide the token quantity, rate issuance, token acquisition cost, and the\n>>>>>>> adaptations in function of the local channel congestion, or even the\n>>>>>>> gossips of the other routing nodes, not at all.\n>>>>>>>\n>>>>>>\n>>>>>> Do you have a timeline in mind for presenting such a policy?\n>>>>>>\n>>>>>> Looking forward to discussing this further over the phone call, will\n>>>>>> make some inquiries to make sure the time works for most people.\n>>>>>>\n>>>>>> Best,\n>>>>>> Clara\n>>>>>>\n>>>>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221125/831d4b21/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-11-26T02:23:39",
                "message_text_only": "Hi Clara,\n\n> Have you done any work on the economic aspects of the new tokens and their\n> secondary markets?\n\nAbout the economic aspects, while I think 0-risk HTLC forwarding acceptance\nwould require credentials cost to perfectly bind to the routing fees, in an\nopen market like the LN routing one it is expected routing hops to bump the\nliquidity value of their credentials. As such increase their forwarded HTLC\ntraffic volume, until the failure rate downgrades their routing income\nbeyond their opportunity costs. How the market of HTLC senders would react\nto the liquidity value bump of their credentials, and how a routing node\nshould pick up this bump to reach their income target is a good research\nquestion, I think.\n\nAbout secondary-markets, the credentials themselves are subject to the\nclassic double-spend problem. E.g, Alice can transfer her \"Ned\" credentials\nboth to Bob and Caroll, without any of them getting knowledge of the\nduplication. So it could be expected secondary markets to only happen\nbetween LSP and their spokes (where \"trust\" relationships already exist),\nas such harder to formalize.\n\nBest,\nAntoine\n\nLe ven. 25 nov. 2022 \u00e0 10:40, Clara Shikhelman <clara.shikhelman at gmail.com>\na \u00e9crit :\n\n> Cool, thanks for that.\n>\n> Have you done any work on the economic aspects of the new tokens and their\n> secondary markets?\n>\n> On Thu, Nov 24, 2022, 21:22 Antoine Riard <antoine.riard at gmail.com> wrote:\n>\n>> Hi Clara,\n>>\n>> The main benefit of this \"staking\"/reputational credentials is to save on\n>> unconditional fees paid by HTLC senders. They benefit from their past HTLC\n>> routing success in terms of more credentials allocated to them, and as such\n>> minimize the overhead cost of their future HTLC sends, or allow them to\n>> lock liquidity for longer periods. From a routing node viewpoint, a 0-risk\n>> HTLC forwarding acceptance can be maintained by requesting strict binding\n>> between credentials acquisition cost and channel liquidity routed. If\n>> higher returns are seeked, the ratio credentials to liquidity can be\n>> adjusted, of course coming with higher risks, and I think this is where the\n>> model built for the current unconditional fees proposal could be useful (if\n>> we integrate the channel congestion rate factor, I believe).\n>>\n>> On top of this monetary paradigm, we can layer a \"pure reputation\"\n>> system, where in function of the quality of the identities (e.g\n>> proof-of-utxo-ownership), HTLC senders are allocated more significant\n>> liquidity slots. Here, the real bottleneck is the cryptosystem, i.e proving\n>> a UTXO ownership without revealing any other information. The rationale of\n>> this \"pure reputation\" system, we could even save more in\n>> upfront/unconditional fees in the steady state of the network (however such\n>> a probabilistic model breaks hard in presence of attackers).\n>>\n>> Best,\n>> Antoine\n>>\n>> Le jeu. 24 nov. 2022 \u00e0 09:45, Clara Shikhelman <\n>> clara.shikhelman at gmail.com> a \u00e9crit :\n>>\n>>> Hi Antoine,\n>>>\n>>> It sounds like unconditional fees cover most of what this policy does,\n>>> without the extra risks that come from creating a new token. Is there a\n>>> clear benefit to using a token compared to unconditional fees and\n>>> local reputation?\n>>>\n>>> Best,\n>>> Clara\n>>>\n>>> On Wed, Nov 23, 2022 at 9:48 PM Antoine Riard <antoine.riard at gmail.com>\n>>> wrote:\n>>>\n>>>> Hi Clara,\n>>>>\n>>>> I think the simplest recommended policy you can devise is credential\n>>>> shown to the routing hop should cover for full routing fees, therefore the\n>>>> routing hop benefits from a zero-jamming risk situation. Then you can\n>>>> appreciate the \"liquidity value\" credentials requested in function of your\n>>>> local channel congestion rate, or even network data. Increasing your\n>>>> returns in exchange of higher risk exposure. And even more, you can lay on\n>>>> top a reputation layer, where the reputation scores are fully fungible\n>>>> against monetary credentials, in the acceptance of a HTLC forward request.\n>>>>\n>>>> So I think I agree with you a recommended policy is needed, let's just\n>>>> start with a simple one! And refine it with time once we sense we have\n>>>> solid foundations.\n>>>>\n>>>> Best,\n>>>> Antoine\n>>>>\n>>>>\n>>>> Le mer. 23 nov. 2022 \u00e0 11:00, Clara Shikhelman <\n>>>> clara.shikhelman at gmail.com> a \u00e9crit :\n>>>>\n>>>>> Hi Antoine,\n>>>>>\n>>>>> To discuss your proposed solution in detail, I think that some kind of\n>>>>> recommended policy is needed. If presenting one is a low priority, and\n>>>>> waiting for other things, my main concern is that it will just never happen\n>>>>> (\"any decade now\" kind of situation).\n>>>>>\n>>>>> Best,\n>>>>> Clara\n>>>>>\n>>>>> On Tue, Nov 22, 2022 at 8:13 PM Antoine Riard <antoine.riard at gmail.com>\n>>>>> wrote:\n>>>>>\n>>>>>> Hi Clara,\n>>>>>>\n>>>>>> Shared the mail on #lightning-dev Libera chat to get more feedback on\n>>>>>> schedule.\n>>>>>>\n>>>>>> > Do you have a timeline in mind for presenting such a policy?\n>>>>>>\n>>>>>> See the comments on the BOLT #1043  PR, for now I'm thinking more to\n>>>>>> refine the proposed credentials architectural framework.\n>>>>>> I think dynamic routing policy in function of channel congestion\n>>>>>> rate, and you combine that with reputation to do active risk-management are\n>>>>>> far more advanced questions.\n>>>>>>\n>>>>>> Best,\n>>>>>> Antoine\n>>>>>>\n>>>>>> Le mar. 22 nov. 2022 \u00e0 15:54, Clara Shikhelman <\n>>>>>> clara.shikhelman at gmail.com> a \u00e9crit :\n>>>>>>\n>>>>>>> Dear All,\n>>>>>>>\n>>>>>>> If the call time (Monday the 28th at 7 pm UTC) doesn't work out for\n>>>>>>> you, please reach out!\n>>>>>>>\n>>>>>>> Thanks for your quick and detailed response, Antoine.\n>>>>>>>\n>>>>>>> If by recommend policy, you mean the set of algorithms that should\n>>>>>>>> guide the token quantity, rate issuance, token acquisition cost, and the\n>>>>>>>> adaptations in function of the local channel congestion, or even the\n>>>>>>>> gossips of the other routing nodes, not at all.\n>>>>>>>>\n>>>>>>>\n>>>>>>> Do you have a timeline in mind for presenting such a policy?\n>>>>>>>\n>>>>>>> Looking forward to discussing this further over the phone call, will\n>>>>>>> make some inquiries to make sure the time works for most people.\n>>>>>>>\n>>>>>>> Best,\n>>>>>>> Clara\n>>>>>>>\n>>>>>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221125/92d4609c/attachment-0001.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2022-11-26T20:48:49",
                "message_text_only": "On 2022-11-21 14:26, Antoine Riard wrote:\n>> Clara Shikhelman wrote:\n>> 4. How would these tokens work with blinded paths and other\n>> privacy-preserving suggestions?\n> \n> Primarily, the tokens could use the new onion messages and blinded\n> paths for the dissemination and renewal rounds. Current design assumes\n> they're attached to the HTLC during forward along the payment path,\n> though I think one design alternative could be completely detached,\n> and the HTLC onion just contains a ref to the tokens.\n\nI'm not sure I understand this answer, so I'll explain in my own words \nand kindly ask that you tell me if I'm wrong or missing something \nimportant.\n\nIf Alice wants to pay Zed using a blinded path where Zed chooses \nterminal channels W->X->Y->Zed, then Zed will need to provide to Alice \nthe encrypted credential tokens for X, and Y.  In theory, if Alice \ncontrols node Y, she can prevent the HTLC from settling and so waste the \nvalue of Zed's provided tokens for node X.  However, Alice shouldn't \nknow where Zed's node is in the LN topography and can't be assured that \nhe'll forward through her secondary node, so the attack is uncertain to \nwork.  The attack may also have a cost---Alice may need to buy \ncredential tokens for node W and the hops leading to it from her primary \nnode---with that cost mitigating the chance of the attack and the \nlikelihood that it would be profitable.\n\nThank you both for the interesting proposal and the insightful \nquestions!,\n\n-Dave"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-11-28T18:48:52",
                "message_text_only": "Hi Dave,\n\nI think the issue you're describing about credential tampering by\nintermediary nodes is correct. If Alice controls Y along the path\nW->X->Y->Zed, she can waste the credentials value provided. Indeed, this\nissue generalizes for any classic payment path, where a routing node can\nwaste the senders  credentials allocated on the downstream hops.\n\nAs discussed on the corresponding BOLT proposal, \"staking/reputational\"\ncredentials are probably be dependent on fat errors to assign payment path\nfailure correctly:\nhttps://github.com/lightning/bolts/pull/1043#discussion_r1029938977\n(even further in the case of blinded path, the senders might need another\nround with the recipient to share a subset of the fat error).\n\nNote the usage of blinded path in the aforementioned comment is about\nsending back fresh credentials if the HTLC succeeds. One alternative is to\nuse the per-hop shared secret and wrap them in the return HTLC onion.\nAnother alternative, a blinded onion route could be registered at HTLC\nforward phase, and this blinded path is leveraged for the fresh credentials\nrefill (I think the quantity of credentials could be a privacy-leak itself,\nthat you would like to mask).\n\nBest,\nAntoine\n\nLe sam. 26 nov. 2022 \u00e0 15:48, David A. Harding <dave at dtrt.org> a \u00e9crit :\n\n> On 2022-11-21 14:26, Antoine Riard wrote:\n> >> Clara Shikhelman wrote:\n> >> 4. How would these tokens work with blinded paths and other\n> >> privacy-preserving suggestions?\n> >\n> > Primarily, the tokens could use the new onion messages and blinded\n> > paths for the dissemination and renewal rounds. Current design assumes\n> > they're attached to the HTLC during forward along the payment path,\n> > though I think one design alternative could be completely detached,\n> > and the HTLC onion just contains a ref to the tokens.\n>\n> I'm not sure I understand this answer, so I'll explain in my own words\n> and kindly ask that you tell me if I'm wrong or missing something\n> important.\n>\n> If Alice wants to pay Zed using a blinded path where Zed chooses\n> terminal channels W->X->Y->Zed, then Zed will need to provide to Alice\n> the encrypted credential tokens for X, and Y.  In theory, if Alice\n> controls node Y, she can prevent the HTLC from settling and so waste the\n> value of Zed's provided tokens for node X.  However, Alice shouldn't\n> know where Zed's node is in the LN topography and can't be assured that\n> he'll forward through her secondary node, so the attack is uncertain to\n> work.  The attack may also have a cost---Alice may need to buy\n> credential tokens for node W and the hops leading to it from her primary\n> node---with that cost mitigating the chance of the attack and the\n> likelihood that it would be profitable.\n>\n> Thank you both for the interesting proposal and the insightful\n> questions!,\n>\n> -Dave\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221128/58fc4c69/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-11-25T23:12:08",
                "message_text_only": "Good morning Antoine,\n\n> It should be noted, this current reputation-credential architectural framework assumes credentials distribution at the endpoint of the network. However, the framework should be flexible enough for the credentials to be harvested by the LSPs, and then distributed in a secondary fashion to their spokes, when they need it, or even attached transparently thanks to trampoline. So one design intuition, there is no strong attachment of the reputation to the endpoint HTLC sender, even if the protocol is described in a \"flat\" view for now.\n\nThis seems incorrect.\n\nIf I am an LSP, and I know my competitor LSP distributes their credentials, then I can simply apply to be a spoke on my competitor and then make several payments to my node, which I then jam up.\nThis reduces the reputation of my competitor LSP.\n\nThis is even worse if my competitor LSP attaches their credentials on trampolines, I do not even need to apply to be a spoke on my competitor that way.\n\nThus in both cases the competitor LSP needs to have a similar way of ensuring that their spokes / trampoline requesters are not also trying to jam *them* in order to drain their reputation.\nThus all reputation still rests with ultimate senders, who have to convince LSPs to sell their reputation to them, because they might secretly be competitor LSPs who have incentive to drain their reputation.\n\nIf the price of sold reputation is too high, then it is no different from upfront fees.\n\nIf the price of sold reputation is too low, then I can drain the reputation of competitor LSPs.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "David A. Harding",
                "date": "2022-11-27T16:34:57",
                "message_text_only": "On 2022-11-25 13:12, ZmnSCPxj via Lightning-dev wrote:\n> If I am an LSP, and I know my competitor LSP distributes their\n> credentials, then I can simply apply to be a spoke on my competitor\n> and then make several payments to my node, which I then jam up.\n> This reduces the reputation of my competitor LSP.\n\nI don't think this how Riard's credentials work.  The credential tokens \nare blinded, so forwarding nodes can't use them to determine the origin \nof the payment---thus they can't assign blame.\n\nAs I understand them, credential tokens prevent DoS by each token only \nallowing the one-time creation of a single HTLC, so any failed payment \nreduces the sender's supply of tokens.  That means, if Mallory becomes a \nclient of Bob's and Bob lets Mallory use some of his tokens, Mallory can \ndestroy those tokens.  Although that's bad for Bob, he can easily limit \nthe damage by not giving Mallory more tokens after too many failures.  \nIf Bob obtained his tokens at a low cost (e.g. by sending many payments \nthat were successful and receiving back >100% of the tokens he used to \nmake those payments) and if Alice has to pay a similar or greater cost \nto become a client of Bob's (e.g. onchain channel open costs), then the \nattack should not be economically rational.\n\n> This is even worse if my competitor LSP attaches their credentials on\n> trampolines, I do not even need to apply to be a spoke on my\n> competitor that way.\n\nI think the analysis for trampolines is the same: as long as Bob only \nattaches credential tokens to trampoline payments where he knows the \norigin has paid a cost (or will need to pay a cost) to abuse his \nservice, he can prevent any attack from becoming economically rational.\n\n> Thus all reputation still rests with ultimate senders, who have to\n> convince LSPs to sell their reputation to them, because they might\n> secretly be competitor LSPs who have incentive to drain their\n> reputation.\n> \n> If the price of sold reputation is too high, then it is no different\n> from upfront fees.\n> \n> If the price of sold reputation is too low, then I can drain the\n> reputation of competitor LSPs.\n\nI think the statement at the top about reputation resting with ultimate \nsenders is true but two conditionals below it are not quite right.  If \nan LSP helps many clients make successful payments, those clients may \n(at no additional cost to them beyond the forwarding fees they already \npaid) receive more credential tokens than they'll ever need.  By \nallowing the LSP to instead use those tokens for other clients \n(\"harvesting\" them), it's possible for those later clients to avoid \npaying for credential tokens---this is equivalent to free upfront fees.  \nAs long as the LSP can prevent a client from using too many tokens, and \nrequires the client pay other inescapable costs, then it shouldn't be \npossible for a competitor to substantially drain the token capital of a \nLSP without losing a substantial amount of its own money.\n\n-Dave"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-11-28T11:50:45",
                "message_text_only": "Good morning David,\n\n> On 2022-11-25 13:12, ZmnSCPxj via Lightning-dev wrote:\n> \n> > If I am an LSP, and I know my competitor LSP distributes their\n> > credentials, then I can simply apply to be a spoke on my competitor\n> > and then make several payments to my node, which I then jam up.\n> > This reduces the reputation of my competitor LSP.\n> \n> \n> I don't think this how Riard's credentials work. The credential tokens\n> are blinded, so forwarding nodes can't use them to determine the origin\n> of the payment---thus they can't assign blame.\n> \n> As I understand them, credential tokens prevent DoS by each token only\n> allowing the one-time creation of a single HTLC, so any failed payment\n> reduces the sender's supply of tokens. That means, if Mallory becomes a\n> client of Bob's and Bob lets Mallory use some of his tokens, Mallory can\n> destroy those tokens. Although that's bad for Bob, he can easily limit\n> the damage by not giving Mallory more tokens after too many failures.\n> If Bob obtained his tokens at a low cost (e.g. by sending many payments\n> that were successful and receiving back >100% of the tokens he used to\n> \n> make those payments) and if Alice has to pay a similar or greater cost\n> to become a client of Bob's (e.g. onchain channel open costs), then the\n> attack should not be economically rational.\n\nThe usual response is to subsequently attack the mitigation, this is a general technique that works on pretty much anything.\n\nMallory can run multiple nodes.\nMallory can then initially buy a small number of tokens.\nThen Mallory sends payments back and forth ensuring success, receiving back >100% tokens used.\nThis gives Mallory a large number of tokens.\n\nFinally, Mallory launches a wide attack on the network by using its harvested tokens (from the >100% token return from successful payment resolution), trading off reputation for whatever they might gain by attacking the LN.\n\nUnless forwarding nodes charge a large fee on successful resolution of payments, such that the >100% return on tokens is equal to the cost of buying the extra tokens \"fresh\", then this makes launching the attack cheaper.\n\n\n> > Thus all reputation still rests with ultimate senders, who have to\n> > convince LSPs to sell their reputation to them, because they might\n> > secretly be competitor LSPs who have incentive to drain their\n> > reputation.\n> > \n> > If the price of sold reputation is too high, then it is no different\n> > from upfront fees.\n> > \n> > If the price of sold reputation is too low, then I can drain the\n> > reputation of competitor LSPs.\n> \n> \n> I think the statement at the top about reputation resting with ultimate\n> senders is true but two conditionals below it are not quite right. If\n> an LSP helps many clients make successful payments, those clients may\n> (at no additional cost to them beyond the forwarding fees they already\n> paid) receive more credential tokens than they'll ever need. By\n> allowing the LSP to instead use those tokens for other clients\n> (\"harvesting\" them), it's possible for those later clients to avoid\n> paying for credential tokens---this is equivalent to free upfront fees.\n> As long as the LSP can prevent a client from using too many tokens, and\n> requires the client pay other inescapable costs, then it shouldn't be\n> possible for a competitor to substantially drain the token capital of a\n> LSP without losing a substantial amount of its own money.\n\nIt is helpful to consider that jamming attacks require that jamming attackers tie up their funds on Lightning too.\nSo while a jamming attacker can impose opportunity costs on the rest of the network, it also sacrifices opportunity to instead use the same funds in forwarding.\nThus a jamming attacker can impose costs on others by also losing a substantial amount (in terms of lost opportunity to instead use the same locked funds to earn forwarding fees), meaning that if you are going to make that argument, then the original problem was already solved by its own structure.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Michael Folkson",
                "date": "2022-11-26T10:52:54",
                "message_text_only": "Hi Antoine\n\nI've got a lot to catch up on re channel jamming but just to say I'm deeply skeptical about attempting to embed a reputation layer or reputation credentials into the Lightning protocol. Admittedly I'm somewhat of a curious amateur in the field of reputation systems but a number of people (me included) have had to look into reputation systems in the past for projects/startups they were working on and centralized\u200b\u200b reputation systems are absolute minefields to manage effectively though some corporations do manage it. Decentralized reputation systems baked into a protocol is just a step too far. All you need is one edge case where the attacker can ensure an innocent party is blamed and the reputation system falls apart. The protocol developer is in the position of assessing who is telling the truth out of two opposing viewpoints on Reddit etc.\n\nI do think reputation systems will play a key part in a future Lightning Network (to some extent they already are with sites like 1ML and Amboss) but they won't be managed by protocol devs, they will be managed by multiple flavors of companies and projects (hopefully open source but most likely closed source too, for profit, non-profit etc) who are free to use whatever metrics and weigh those metrics however they like. The protocol just can't afford to expand into areas where there is case by case judgment and statistical analysis required. It will become bloated, ineffective and put protocol developers in the position of deciding who ultimately receives routing fees rather than just enabling payments can get from A to B. Identity is easier, you either control a private key or you don't. Reputation is much more difficult, there will be some attacks where a probabilistic assessment will need to be made on who the perpetrator of the attack was. You don't add that to the (already long) list of protocol developers' responsibilities.\n\nSo feel free to continue to explore reputation and reputation systems but a strong warning that this is likely not solved at the protocol level. Decisions protocol developers make will impact what data can be collected and how easy that data is to collect (there are already some tricky trade-offs with regards to privacy, routing success and transparency for when things go wrong) but beyond that protocol developers should leave it to others. I've included some links to some additional reading on reputation systems in case you are interested.\n\nThanks\nMichael\n\n[0]: https://www.amazon.com/Building-Reputation-Systems-Randy-Farmer/dp/059615979X/\n[1]: https://medium.com/openbazaarproject/decentralized-reputation-in-openbazaar-1a577fac5175\n[2]: https://www.bitrated.com/faq\n\n--\nMichael Folkson\nEmail: michaelfolkson at [protonmail.com](http://protonmail.com/)\nKeybase: michaelfolkson\nPGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n\n------- Original Message -------\nOn Monday, November 21st, 2022 at 06:01, Antoine Riard <antoine.riard at gmail.com> wrote:\n\n> Hi LN Devs,\n>\n> tl;dr A formalization of a reputation-based scheme to solve channel jamming is proposed. The system relies on \"credentials\" issued by routing hops and requested to be attached to each HTLC forward request. The \"credentials\" can be used by a reputation algorithm to reward/punish payment senders and allocate channel liquidity resources efficiently. The \"credentials\" initial distribution can be bootstrapped leveraging one-time upfront fees paid toward the routing hops. Afterwards, the \"credentials\" subsequent distribution can rely on previous HTLC traffic.\n>\n> A protocol description can be found here, with few extensions already to the BOLTs:\n>\n> https://github.com/lightning/bolts/pull/1043\n>\n> There is also a work-in-progress proof-of-concept in LDK (on top of our coming soon^TM HTLC intercepting API):\n>\n> https://github.com/lightningdevkit/rust-lightning/pull/1848\n>\n> This work builds on previous reputation-scheme research [0] [1]. It also integrates the more recent proposals of upfront fees as a straightforward mechanism to bootstrap the reputation system. Bootstrapping the system with more economically cost-effective privacy-preserving UTXO ownership proofs not only add another layer of engineering complexity, there is still a proof size vs proof generation/validation trade-off to arbiter between ZKP cryptosystems.\n>\n> Rather to seek for a game-theory equilibrium defined as a breakeven point as in the latest unconditional fee research [2], this proposal aims to use reputation credentials to allow HTLC traffic-shaping. This not only should protect against jamming situations (either malicious\n> or spontaneous) but also allow active HTLC traffic-shaping, where a routing hop can allow extended channel liquidity lockups based on accumulated reputation (e.g for hold-invoices). This is also a reduced overhead cost, as upfront fees are only paid at bootstrap, or when the HTLC forward behavior can be qualified as \"whitewashing\" from the routing hop viewpoint.\n>\n> It should be noted, this current reputation-credential architectural framework assumes credentials distribution at the endpoint of the network. However, the framework should be flexible enough for the credentials to be harvested by the LSPs, and then distributed in a secondary fashion to their spokes, when they need it, or even attached transparently thanks to trampoline. So one design intuition, there is no strong attachment of the reputation to the endpoint HTLC sender, even if the protocol is described in a \"flat\" view for now.\n>\n> Let's evaluate quickly this mitigation proposal against a few criterias emerged from recent research.\n>\n> The mitigation is effective, in the sense a routing hop can apply a proportional relationship between the acquisition of the reputation and the amount of liquidity resources credited in function of said reputation. In a period of steady state, the reputation acquisition cost can be downgraded to 0. In periods of channel congestion, the reputation credentials to liquidity units translation can be severed, in the limit of routing hop acceptable competitiveness.\n>\n> The mitigation is incentive-compatible, if the credentials are not honored by their issuers, the HTLC senders can evict them from the routing network view for a while. The successful usage of credentials can lead to more credentials allocated for longer and more capacity-intensive channel lockups. In case of HTLC failure, the failure source could be forgiven by routing hops to maintain the worthiness of the sender credentials.\n>\n> The mitigation can be made transparent from the user, as the credentials harvesting can be done automatically from a pre-allocated budget, similar to the fee-bumping reserves requirement introduced by anchor output. At the end of today, if we take modern browsers as an example, the average user doesn't check manually the TLS certificates (for what they're worth...).\n>\n> The mitigation can conserve high-level privacy, as the usage of blinded signature (or another equivalent cryptosystem breaking signature/message linking) should allow the credentials issued during a preliminary phase to be undistinguishable during the redeem/usage phase. New CPU/memory DoS vectors due to the credentials processing should be watched out.\n>\n> About the ease of implementation, there are few protocol messages to modify, a HTLC intercepting API is assumed as supported by the implementation, onion messages support is also implied, landing EC blinded signature in libsecp256k1-zkp shouldn't be a big deal, routing algorithms adaptations might be more serious but still reasonable. The \"credentials-to-liquidity\" allocation algorithms are likely the new real beast, though I don't think any reputation scheme can spare them.\n>\n> There could be a concern about the centralization inertia introduced by a reputation system. Intuitively, the argument can be made that any historical tracking (such as routing buckets) favor established LN incumbents at the gain of efficiency. A counter-argument can be made, a new routing hop can lower the acquisition cost of its issued credentials to attract more HTLC traffic (accepting higher jamming risk).\n>\n> On the ecosystem impacts, it should be studied that this proposal would impact things like inbound channel routing fees [3], ratecard [4] or flow-control valve [5] and the whole liquidity toolchain. Hopefully, we don't significantly restrain the design space for future LN protocol upgrades.\n>\n> On the proposal modularity and flexibility, each routing node has oversight on its routing policy, acquisition methods, credentials to liquidity rate. New acquisition methods can be experimented or deployed when ready, e.g stakes certificates with only e2e upgrade. The credentials themselves could have \"innate\" expiration time if we use things like short-lived ZKP [6]. The credentials framework can be extended beyond solving jamming, as a generalized risk-management framework for Bitcoin decentralized financial network, e.g transaction signature exchange ordering in multi-party transactions [7] or finding reliable Coinjoin counterparties.\n>\n> Feedback welcome.\n>\n> Cheers,\n> Antoine\n>\n> [0] https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-November/002884.html\n> [1] https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-August/003673.html\n> [2] https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-November/003740.html\n> [3] https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-July/003643.html\n> [4] https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-September/003685.html\n> [5] https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-September/003686.html\n> [6] https://eprint.iacr.org/2022/190.pdf\n> [7] https://github.com/lightning/bolts/pull/851#issuecomment-1290727242\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221126/0a8f484f/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-11-28T21:34:10",
                "message_text_only": "Hi Michael,\n\nThanks for the feedback,\n\nOn the first point, I think it should be underscored how much this proposed\ncredential system, while labeled a reputational one, belongs more to a\nmonetary strategy (after the fact should be called \"staking\" credentials).\nIndeed, there is a direct link between the credentials and a cost expressed\nin satoshis. Therefore, in case of loopholes in the system damages are\neffectively borne by the routing hops, without throwing the whole system\ndown. Note, the default policy should be some 0-risk HTLC forward\nacceptance.\n\nOn the second point, we already have today's reputation systems in\nLightning, namely the routing algorithms keeping track of the performance\nof the routing hops, and their liquidity. That information is used in a\ncontinuous fashion to improve payment-path building. And while those\nalgorithms are doing probabilistic estimation of the balance distribution,\nthe proposed credential system is not all relying on past statistics for\nits effectiveness (as long as the node operators are requiring credentials\nof worthiness equivalent to routing fees).\n\nOn the third point, the protocol defer to the node operators all the\ndecisions on the credential acquisition costs, expiration height, binding\nwith liquidity units, or even allow additional routing policy checks.\nFlexibility is offered to the node operators, without the protocol\ndevelopers trying to do any \"centralized\" decision on the cost of the\ncredentials or whatever.\n\n>From my understanding, the critics you're raising, while potentially\ncorrect for the reputation systems links you're including, does not bind to\nany concrete point of my proposal. I hope you'll take time to browse the\nproposal as detailed more in depth here:\nhttps://github.com/lightning/bolts/pull/1043\n\nBest,\nAntoine\n\nLe sam. 26 nov. 2022 \u00e0 05:53, Michael Folkson <michaelfolkson at protonmail.com>\na \u00e9crit :\n\n> Hi Antoine\n>\n> I've got a lot to catch up on re channel jamming but just to say I'm\n> deeply skeptical about attempting to embed a reputation layer or reputation\n> credentials into the Lightning protocol. Admittedly I'm somewhat of a\n> curious amateur in the field of reputation systems but a number of people\n> (me included) have had to look into reputation systems in the past for\n> projects/startups they were working on and *centralized\u200b*\u200b reputation\n> systems are absolute minefields to manage effectively though some\n> corporations do manage it. Decentralized reputation systems baked into a\n> protocol is just a step too far. All you need is one edge case where the\n> attacker can ensure an innocent party is blamed and the reputation system\n> falls apart. The protocol developer is in the position of assessing who is\n> telling the truth out of two opposing viewpoints on Reddit etc.\n>\n> I do think reputation systems will play a key part in a future Lightning\n> Network (to some extent they already are with sites like 1ML and Amboss)\n> but they won't be managed by protocol devs, they will be managed by\n> multiple flavors of companies and projects (hopefully open source but most\n> likely closed source too, for profit, non-profit etc) who are free to use\n> whatever metrics and weigh those metrics however they like. The protocol\n> just can't afford to expand into areas where there is case by case judgment\n> and statistical analysis required. It will become bloated, ineffective and\n> put protocol developers in the position of deciding who ultimately receives\n> routing fees rather than just enabling payments can get from A to B.\n> Identity is easier, you either control a private key or you don't.\n> Reputation is much more difficult, there will be some attacks where a\n> probabilistic assessment will need to be made on who the perpetrator of the\n> attack was. You don't add that to the (already long) list of protocol\n> developers' responsibilities.\n>\n> So feel free to continue to explore reputation and reputation systems but\n> a strong warning that this is likely not solved at the protocol level.\n> Decisions protocol developers make will impact what data can be collected\n> and how easy that data is to collect (there are already some tricky\n> trade-offs with regards to privacy, routing success and transparency for\n> when things go wrong) but beyond that protocol developers should leave it\n> to others. I've included some links to some additional reading on\n> reputation systems in case you are interested.\n>\n> Thanks\n> Michael\n>\n> [0]:\n> https://www.amazon.com/Building-Reputation-Systems-Randy-Farmer/dp/059615979X/\n> [1]:\n> https://medium.com/openbazaarproject/decentralized-reputation-in-openbazaar-1a577fac5175\n> [2]: https://www.bitrated.com/faq\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> Keybase: michaelfolkson\n> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>\n> ------- Original Message -------\n> On Monday, November 21st, 2022 at 06:01, Antoine Riard <\n> antoine.riard at gmail.com> wrote:\n>\n> Hi LN Devs,\n>\n> tl;dr A formalization of a reputation-based scheme to solve channel\n> jamming is proposed. The system relies on \"credentials\" issued by routing\n> hops and requested to be attached to each HTLC forward request. The\n> \"credentials\" can be used by a reputation algorithm to reward/punish\n> payment senders and allocate channel liquidity resources efficiently. The\n> \"credentials\" initial distribution can be bootstrapped leveraging one-time\n> upfront fees paid toward the routing hops. Afterwards, the \"credentials\"\n> subsequent distribution can rely on previous HTLC traffic.\n>\n> A protocol description can be found here, with few extensions already to\n> the BOLTs:\n>\n> https://github.com/lightning/bolts/pull/1043\n>\n> There is also a work-in-progress proof-of-concept in LDK (on top of our\n> coming soon^TM HTLC intercepting API):\n>\n> https://github.com/lightningdevkit/rust-lightning/pull/1848\n>\n> This work builds on previous reputation-scheme research [0] [1]. It also\n> integrates the more recent proposals of upfront fees as a straightforward\n> mechanism to bootstrap the reputation system. Bootstrapping the system with\n> more economically cost-effective privacy-preserving UTXO ownership proofs\n> not only add another layer of engineering complexity, there is still a\n> proof size vs proof generation/validation trade-off to arbiter between ZKP\n> cryptosystems.\n>\n> Rather to seek for a game-theory equilibrium defined as a breakeven point\n> as in the latest unconditional fee research [2], this proposal aims to use\n> reputation credentials to allow HTLC traffic-shaping. This not only should\n> protect against jamming situations (either malicious\n> or spontaneous) but also allow active HTLC traffic-shaping, where a\n> routing hop can allow extended channel liquidity lockups based on\n> accumulated reputation (e.g for hold-invoices). This is also a reduced\n> overhead cost, as upfront fees are only paid at bootstrap, or when the HTLC\n> forward behavior can be qualified as \"whitewashing\" from the routing hop\n> viewpoint.\n>\n> It should be noted, this current reputation-credential architectural\n> framework assumes credentials distribution at the endpoint of the network.\n> However, the framework should be flexible enough for the credentials to be\n> harvested by the LSPs, and then distributed in a secondary fashion to their\n> spokes, when they need it, or even attached transparently thanks to\n> trampoline. So one design intuition, there is no strong attachment of the\n> reputation to the endpoint HTLC sender, even if the protocol is described\n> in a \"flat\" view for now.\n>\n> Let's evaluate quickly this mitigation proposal against a few criterias\n> emerged from recent research.\n>\n> The mitigation is effective, in the sense a routing hop can apply a\n> proportional relationship between the acquisition of the reputation and the\n> amount of liquidity resources credited in function of said reputation. In a\n> period of steady state, the reputation acquisition cost can be downgraded\n> to 0. In periods of channel congestion, the reputation credentials to\n> liquidity units translation can be severed, in the limit of routing hop\n> acceptable competitiveness.\n>\n> The mitigation is incentive-compatible, if the credentials are not honored\n> by their issuers, the HTLC senders can evict them from the routing network\n> view for a while. The successful usage of credentials can lead to more\n> credentials allocated for longer and more capacity-intensive channel\n> lockups. In case of HTLC failure, the failure source could be forgiven by\n> routing hops to maintain the worthiness of the sender credentials.\n>\n> The mitigation can be made transparent from the user, as the credentials\n> harvesting can be done automatically from a pre-allocated budget, similar\n> to the fee-bumping reserves requirement introduced by anchor output. At the\n> end of today, if we take modern browsers as an example, the average user\n> doesn't check manually the TLS certificates (for what they're worth...).\n>\n> The mitigation can conserve high-level privacy, as the usage of blinded\n> signature (or another equivalent cryptosystem breaking signature/message\n> linking) should allow the credentials issued during a preliminary phase to\n> be undistinguishable during the redeem/usage phase. New CPU/memory DoS\n> vectors due to the credentials processing should be watched out.\n>\n> About the ease of implementation, there are few protocol messages to\n> modify, a HTLC intercepting API is assumed as supported by the\n> implementation, onion messages support is also implied, landing EC blinded\n> signature in libsecp256k1-zkp shouldn't be a big deal, routing algorithms\n> adaptations might be more serious but still reasonable. The\n> \"credentials-to-liquidity\" allocation algorithms are likely the new real\n> beast, though I don't think any reputation scheme can spare them.\n>\n> There could be a concern about the centralization inertia introduced by a\n> reputation system. Intuitively, the argument can be made that any\n> historical tracking (such as routing buckets) favor established LN\n> incumbents at the gain of efficiency. A counter-argument can be made, a new\n> routing hop can lower the acquisition cost of its issued credentials to\n> attract more HTLC traffic (accepting higher jamming risk).\n>\n> On the ecosystem impacts, it should be studied that this proposal would\n> impact things like inbound channel routing fees [3], ratecard [4] or\n> flow-control valve [5] and the whole liquidity toolchain. Hopefully, we\n> don't significantly restrain the design space for future LN protocol\n> upgrades.\n>\n> On the proposal modularity and flexibility, each routing node has\n> oversight on its routing policy, acquisition methods, credentials to\n> liquidity rate. New acquisition methods can be experimented or deployed\n> when ready, e.g stakes certificates with only e2e upgrade. The credentials\n> themselves could have \"innate\" expiration time if we use things like\n> short-lived ZKP [6]. The credentials framework can be extended beyond\n> solving jamming, as a generalized risk-management framework for Bitcoin\n> decentralized financial network, e.g transaction signature exchange\n> ordering in multi-party transactions [7] or finding reliable Coinjoin\n> counterparties.\n>\n> Feedback welcome.\n>\n> Cheers,\n> Antoine\n>\n> [0]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-November/002884.html\n> [1]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-August/003673.html\n> [2]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-November/003740.html\n> [3]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-July/003643.html\n> [4]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-September/003685.html\n> [5]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-September/003686.html\n> [6] https://eprint.iacr.org/2022/190.pdf\n> [7] https://github.com/lightning/bolts/pull/851#issuecomment-1290727242\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221128/31dea565/attachment-0001.html>"
            },
            {
                "author": "Michael Folkson",
                "date": "2022-11-29T16:25:31",
                "message_text_only": "> Therefore, in case of loopholes in the system damages are effectively borne by the routing hops, without throwing the whole system down.\n\nI'm not sure why harming routing nodes is any less of a concern than harming the experience of say edge nodes when introducing game-able systems with uncertainty over the edge cases. Especially when iteration of that system might never lead to a solution we are happy with. A whack-a-mole type thing where plugging one hole creates another hole.\n\n> On the second point, we already have today's reputation systems in Lightning, namely the routing algorithms keeping track of the performance of the routing hops, and their liquidity.\n\nI was under the impression that routing algorithms weren't part of the Lightning protocol spec (BOLTs)? Each Lightning implementation could ship with totally different default routing algorithms (perhaps already do?) and it wouldn't matter. There is no cross implementation compatibility issue with how each Lightning node selects channel counterparties, how it selects routes for payments and tracks which routes did and didn't work.\n\n> On the third point, the protocol defer to the node operators all the decisions on the credential acquisition costs, expiration height, binding with liquidity units, or even allow additional routing policy checks.\n\nI guess we're back into the world of setting defaults and options here that we've just been through with mempoolfullrbf :) If say a LDK user wants to opt into using this reputation system then that's their prerogative assuming it is merged into say a LDK release. Personally I would want to opt out of this reputation system and do my own assessments of reputations of Lightning nodes and risks I was taking. At least until a point when I was comfortable with it which I may never be.\n\n> I hope you'll take time to browse the proposal as detailed more in depth here:https://github.com/lightning/bolts/pull/1043\n\nSure I'll take a look. But recall I am worried about edge cases and ways for an attacker to game a reputation system which requires me to get to your level of understanding of channel jamming attacks (which will take me a while given you've written a book [0] about them with Gleb). And I suspect even you and Gleb wouldn't be confident saying that you understand all the edge cases of jamming attacks let alone the edge cases of gaming a reputation layer on top.\n\nAs I said in my previous post I think this is an interesting area and I can see why you are exploring reputation. Just very skeptical that this is a thing that is ever part of the protocol, is used by all of the major Lightning implementations, is on by default in all those Lightning implementations etc. And even if it was I would want to opt out of it.\n\nThanks\nMichael\n\n[0]: https://jamming-dev.github.io/book/\n\n--\nMichael Folkson\nEmail: michaelfolkson at [protonmail.com](http://protonmail.com/)\nKeybase: michaelfolkson\nPGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n\n------- Original Message -------\nOn Monday, November 28th, 2022 at 23:34, Antoine Riard <antoine.riard at gmail.com> wrote:\n\n> Hi Michael,\n>\n> Thanks for the feedback,\n>\n> On the first point, I think it should be underscored how much this proposed credential system, while labeled a reputational one, belongs more to a monetary strategy (after the fact should be called \"staking\" credentials). Indeed, there is a direct link between the credentials and a cost expressed in satoshis. Therefore, in case of loopholes in the system damages are effectively borne by the routing hops, without throwing the whole system down. Note, the default policy should be some 0-risk HTLC forward acceptance.\n>\n> On the second point, we already have today's reputation systems in Lightning, namely the routing algorithms keeping track of the performance of the routing hops, and their liquidity. That information is used in a continuous fashion to improve payment-path building. And while those algorithms are doing probabilistic estimation of the balance distribution, the proposed credential system is not all relying on past statistics for its effectiveness (as long as the node operators are requiring credentials of worthiness equivalent to routing fees).\n>\n> On the third point, the protocol defer to the node operators all the decisions on the credential acquisition costs, expiration height, binding with liquidity units, or even allow additional routing policy checks. Flexibility is offered to the node operators, without the protocol developers trying to do any \"centralized\" decision on the cost of the credentials or whatever.\n>\n> From my understanding, the critics you're raising, while potentially correct for the reputation systems links you're including, does not bind to any concrete point of my proposal. I hope you'll take time to browse the proposal as detailed more in depth here: https://github.com/lightning/bolts/pull/1043\n>\n> Best,\n> Antoine\n>\n> Le sam. 26 nov. 2022 \u00e0 05:53, Michael Folkson <michaelfolkson at protonmail.com> a \u00e9crit :\n>\n>> Hi Antoine\n>>\n>> I've got a lot to catch up on re channel jamming but just to say I'm deeply skeptical about attempting to embed a reputation layer or reputation credentials into the Lightning protocol. Admittedly I'm somewhat of a curious amateur in the field of reputation systems but a number of people (me included) have had to look into reputation systems in the past for projects/startups they were working on and centralized\u200b\u200b reputation systems are absolute minefields to manage effectively though some corporations do manage it. Decentralized reputation systems baked into a protocol is just a step too far. All you need is one edge case where the attacker can ensure an innocent party is blamed and the reputation system falls apart. The protocol developer is in the position of assessing who is telling the truth out of two opposing viewpoints on Reddit etc.\n>>\n>> I do think reputation systems will play a key part in a future Lightning Network (to some extent they already are with sites like 1ML and Amboss) but they won't be managed by protocol devs, they will be managed by multiple flavors of companies and projects (hopefully open source but most likely closed source too, for profit, non-profit etc) who are free to use whatever metrics and weigh those metrics however they like. The protocol just can't afford to expand into areas where there is case by case judgment and statistical analysis required. It will become bloated, ineffective and put protocol developers in the position of deciding who ultimately receives routing fees rather than just enabling payments can get from A to B. Identity is easier, you either control a private key or you don't. Reputation is much more difficult, there will be some attacks where a probabilistic assessment will need to be made on who the perpetrator of the attack was. You don't add that to the (already long) list of protocol developers' responsibilities.\n>>\n>> So feel free to continue to explore reputation and reputation systems but a strong warning that this is likely not solved at the protocol level. Decisions protocol developers make will impact what data can be collected and how easy that data is to collect (there are already some tricky trade-offs with regards to privacy, routing success and transparency for when things go wrong) but beyond that protocol developers should leave it to others. I've included some links to some additional reading on reputation systems in case you are interested.\n>>\n>> Thanks\n>> Michael\n>>\n>> [0]: https://www.amazon.com/Building-Reputation-Systems-Randy-Farmer/dp/059615979X/\n>> [1]: https://medium.com/openbazaarproject/decentralized-reputation-in-openbazaar-1a577fac5175\n>> [2]: https://www.bitrated.com/faq\n>>\n>> --\n>> Michael Folkson\n>> Email: michaelfolkson at [protonmail.com](http://protonmail.com/)\n>> Keybase: michaelfolkson\n>> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>>\n>> ------- Original Message -------\n>> On Monday, November 21st, 2022 at 06:01, Antoine Riard <antoine.riard at gmail.com> wrote:\n>>\n>>> Hi LN Devs,\n>>>\n>>> tl;dr A formalization of a reputation-based scheme to solve channel jamming is proposed. The system relies on \"credentials\" issued by routing hops and requested to be attached to each HTLC forward request. The \"credentials\" can be used by a reputation algorithm to reward/punish payment senders and allocate channel liquidity resources efficiently. The \"credentials\" initial distribution can be bootstrapped leveraging one-time upfront fees paid toward the routing hops. Afterwards, the \"credentials\" subsequent distribution can rely on previous HTLC traffic.\n>>>\n>>> A protocol description can be found here, with few extensions already to the BOLTs:\n>>>\n>>> https://github.com/lightning/bolts/pull/1043\n>>>\n>>> There is also a work-in-progress proof-of-concept in LDK (on top of our coming soon^TM HTLC intercepting API):\n>>>\n>>> https://github.com/lightningdevkit/rust-lightning/pull/1848\n>>>\n>>> This work builds on previous reputation-scheme research [0] [1]. It also integrates the more recent proposals of upfront fees as a straightforward mechanism to bootstrap the reputation system. Bootstrapping the system with more economically cost-effective privacy-preserving UTXO ownership proofs not only add another layer of engineering complexity, there is still a proof size vs proof generation/validation trade-off to arbiter between ZKP cryptosystems.\n>>>\n>>> Rather to seek for a game-theory equilibrium defined as a breakeven point as in the latest unconditional fee research [2], this proposal aims to use reputation credentials to allow HTLC traffic-shaping. This not only should protect against jamming situations (either malicious\n>>> or spontaneous) but also allow active HTLC traffic-shaping, where a routing hop can allow extended channel liquidity lockups based on accumulated reputation (e.g for hold-invoices). This is also a reduced overhead cost, as upfront fees are only paid at bootstrap, or when the HTLC forward behavior can be qualified as \"whitewashing\" from the routing hop viewpoint.\n>>>\n>>> It should be noted, this current reputation-credential architectural framework assumes credentials distribution at the endpoint of the network. However, the framework should be flexible enough for the credentials to be harvested by the LSPs, and then distributed in a secondary fashion to their spokes, when they need it, or even attached transparently thanks to trampoline. So one design intuition, there is no strong attachment of the reputation to the endpoint HTLC sender, even if the protocol is described in a \"flat\" view for now.\n>>>\n>>> Let's evaluate quickly this mitigation proposal against a few criterias emerged from recent research.\n>>>\n>>> The mitigation is effective, in the sense a routing hop can apply a proportional relationship between the acquisition of the reputation and the amount of liquidity resources credited in function of said reputation. In a period of steady state, the reputation acquisition cost can be downgraded to 0. In periods of channel congestion, the reputation credentials to liquidity units translation can be severed, in the limit of routing hop acceptable competitiveness.\n>>>\n>>> The mitigation is incentive-compatible, if the credentials are not honored by their issuers, the HTLC senders can evict them from the routing network view for a while. The successful usage of credentials can lead to more credentials allocated for longer and more capacity-intensive channel lockups. In case of HTLC failure, the failure source could be forgiven by routing hops to maintain the worthiness of the sender credentials.\n>>>\n>>> The mitigation can be made transparent from the user, as the credentials harvesting can be done automatically from a pre-allocated budget, similar to the fee-bumping reserves requirement introduced by anchor output. At the end of today, if we take modern browsers as an example, the average user doesn't check manually the TLS certificates (for what they're worth...).\n>>>\n>>> The mitigation can conserve high-level privacy, as the usage of blinded signature (or another equivalent cryptosystem breaking signature/message linking) should allow the credentials issued during a preliminary phase to be undistinguishable during the redeem/usage phase. New CPU/memory DoS vectors due to the credentials processing should be watched out.\n>>>\n>>> About the ease of implementation, there are few protocol messages to modify, a HTLC intercepting API is assumed as supported by the implementation, onion messages support is also implied, landing EC blinded signature in libsecp256k1-zkp shouldn't be a big deal, routing algorithms adaptations might be more serious but still reasonable. The \"credentials-to-liquidity\" allocation algorithms are likely the new real beast, though I don't think any reputation scheme can spare them.\n>>>\n>>> There could be a concern about the centralization inertia introduced by a reputation system. Intuitively, the argument can be made that any historical tracking (such as routing buckets) favor established LN incumbents at the gain of efficiency. A counter-argument can be made, a new routing hop can lower the acquisition cost of its issued credentials to attract more HTLC traffic (accepting higher jamming risk).\n>>>\n>>> On the ecosystem impacts, it should be studied that this proposal would impact things like inbound channel routing fees [3], ratecard [4] or flow-control valve [5] and the whole liquidity toolchain. Hopefully, we don't significantly restrain the design space for future LN protocol upgrades.\n>>>\n>>> On the proposal modularity and flexibility, each routing node has oversight on its routing policy, acquisition methods, credentials to liquidity rate. New acquisition methods can be experimented or deployed when ready, e.g stakes certificates with only e2e upgrade. The credentials themselves could have \"innate\" expiration time if we use things like short-lived ZKP [6]. The credentials framework can be extended beyond solving jamming, as a generalized risk-management framework for Bitcoin decentralized financial network, e.g transaction signature exchange ordering in multi-party transactions [7] or finding reliable Coinjoin counterparties.\n>>>\n>>> Feedback welcome.\n>>>\n>>> Cheers,\n>>> Antoine\n>>>\n>>> [0] https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-November/002884.html\n>>> [1] https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-August/003673.html\n>>> [2] https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-November/003740.html\n>>> [3] https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-July/003643.html\n>>> [4] https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-September/003685.html\n>>> [5] https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-September/003686.html\n>>> [6] https://eprint.iacr.org/2022/190.pdf\n>>> [7] https://github.com/lightning/bolts/pull/851#issuecomment-1290727242\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221129/31453b05/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-11-30T04:07:41",
                "message_text_only": "Hi Michael,\n\n\n> I'm not sure why harming routing nodes is any less of a concern than harming the experience of say edge nodes when introducing game-able systems with uncertainty over the edge cases. Especially when iteration of that system might never lead to a solution we are happy with. A whack-a-mole type thing where plugging one hole creates another hole.\n\nThe \"staking/reputational\" credential system I'm devising allows a\nrouting hop to adopt a 0-risk HTLC forwarding acceptance policy.\nIndeed, one can pick up the credential acquisition cost to be equal to\nthe routing fees, the routing hop is always paid\nin advance for the HTLC forward. Exploitable deviation of this\n\"0-risk\" policy should be considered as implementation bugs.\n\nIf you can point me precisely where the current proposal is broken or\nif you can raise concrete safety risks, we can correct them. As the\nthread name said, the protocol is at the stage of a sketch, and it\ndoesn't pretend more.\n\n> I was under the impression that routing algorithms weren't part of the Lightning protocol spec (BOLTs)? Each Lightning implementation could ship with totally different default routing algorithms (perhaps a> lready do?) and it wouldn't matter. There is no cross implementation compatibility issue with how each Lightning node selects channel counterparties, how it selects routes for payments and tracks which routes did and didn't work.\n\nThis is a correct statement. As you were raising a future concern than\n\"protocol developers [could be] in the position of deciding who\nultimately receives routing fees\", reality today they're already. Of\ncourse, anyone can come up with a new routing\nalgorithm suiting better their needs, than the default one (at least\nfor LDK we just have a generic `Score` interface). Doing so, they\nwould probably have to become themselves \"protocol developer\" so we\nmight be back to step one. To qualify more\nthe root concern, at least one I can understand, I think you're\nsaying, is that routing algorithms should be far more under scrutiny\nof the community, as they do have a major influence on the state of\nthe LN market/\"economy\".\n\n> I guess we're back into the world of setting defaults and options here that we've just been through with mempoolfullrbf :) If say a LDK user wants to opt into using this reputation system then that's their>  prerogative assuming it is merged into say a LDK release. Personally I would want to opt out of this reputation system and do my own assessments of reputations of Lightning nodes and risks I was taking. A> t least until a point when I was comfortable with it which I may never be.\n\nAll I can say LDK is many light-years ahead of Core in term of\nflexibility (while acknowledging system philosophy difference between\nlayers), and I think any jamming mitigation strategy should be its own\nindependent module (as current PoC is doing, see\nLDK #1848), what we can do best to lower opt out cost for the user.\nBeyond, if you have further questions on this proposed credentials\nsystem to clarify the proposal and what is confusing you I'm\nlistening.\n\n> Sure I'll take a look. But recall I am worried about edge cases and ways for an attacker to game a reputation system which requires me to get to your level of understanding of channel jamming attacks (whic> h will take me a while given you've written a book [0] about them with Gleb). And I suspect even you and Gleb wouldn't be confident saying that you understand all the edge cases of jamming attacks let alon> e the edge cases of gaming a reputation layer on top.\n\nAnd with regards to hypothetical edge cases, best we can do in this\ndirection is flesh out a protocol sketch, ask for wide community\nfeedback, try to break it ourselves, integrate the lessons piece by\npiece, propose a new iteration, and doing it over\nand over until we reach a level of consistency and soundness\nconvincing as many stakeholders as we can in the community. If you can\nthink about a better process for Bitcoin protocol development, I'll\nlet you lead by example.\n\n> As I said in my previous post I think this is an interesting area and I can see why you are exploring reputation. Just very skeptical that this is a thing that is ever part of the protocol, is used by all > of the major Lightning implementations, is on by default in all those Lightning implementations etc. And even if it was I would want to opt out of it.\n\nWorst-case scenario if this proposal is never adopted, I hope we would\nhave learnt a lot on channel jamming and Lightning liquidity flows as\na community. One is better attached to the process, rather than the\noutcome.\n\nBest,\nAntoine\n\n\nLe mar. 29 nov. 2022 \u00e0 11:25, Michael Folkson <michaelfolkson at protonmail.com>\na \u00e9crit :\n\n> > Therefore, in case of loopholes in the system damages are effectively\n> borne by the routing hops, without throwing the whole system down.\n>\n> I'm not sure why harming routing nodes is any less of a concern than\n> harming the experience of say edge nodes when introducing game-able systems\n> with uncertainty over the edge cases. Especially when iteration of that\n> system might never lead to a solution we are happy with. A whack-a-mole\n> type thing where plugging one hole creates another hole.\n>\n> > On the second point, we already have today's reputation systems in\n> Lightning, namely the routing algorithms keeping track of the performance\n> of the routing hops, and their liquidity.\n>\n> I was under the impression that routing algorithms weren't part of the\n> Lightning protocol spec (BOLTs)? Each Lightning implementation could ship\n> with totally different default routing algorithms (perhaps already do?) and\n> it wouldn't matter. There is no cross implementation compatibility issue\n> with how each Lightning node selects channel counterparties, how it selects\n> routes for payments and tracks which routes did and didn't work.\n>\n> > On the third point, the protocol defer to the node operators all the\n> decisions on the credential acquisition costs, expiration height, binding\n> with liquidity units, or even allow additional routing policy checks.\n>\n> I guess we're back into the world of setting defaults and options here\n> that we've just been through with mempoolfullrbf :) If say a LDK user wants\n> to opt into using this reputation system then that's their prerogative\n> assuming it is merged into say a LDK release. Personally I would want to\n> opt out of this reputation system and do my own assessments of reputations\n> of Lightning nodes and risks I was taking. At least until a point when I\n> was comfortable with it which I may never be.\n>\n> > I hope you'll take time to browse the proposal as detailed more in\n> depth here: https://github.com/lightning/bolts/pull/1043\n>\n> Sure I'll take a look. But recall I am worried about edge cases and ways\n> for an attacker to game a reputation system which requires me to get to\n> your level of understanding of channel jamming attacks (which will take me\n> a while given you've written a book [0] about them with Gleb). And I\n> suspect even you and Gleb wouldn't be confident saying that you understand\n> all the edge cases of jamming attacks let alone the edge cases of gaming a\n> reputation layer on top.\n>\n> As I said in my previous post I think this is an interesting area and I\n> can see why you are exploring reputation. Just very skeptical that this is\n> a thing that is ever part of the protocol, is used by all of the major\n> Lightning implementations, is on by default in all those Lightning\n> implementations etc. And even if it was I would want to opt out of it.\n>\n> Thanks\n> Michael\n>\n> [0]: https://jamming-dev.github.io/book/\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> Keybase: michaelfolkson\n> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>\n> ------- Original Message -------\n> On Monday, November 28th, 2022 at 23:34, Antoine Riard <\n> antoine.riard at gmail.com> wrote:\n>\n> Hi Michael,\n>\n> Thanks for the feedback,\n>\n> On the first point, I think it should be underscored how much this\n> proposed credential system, while labeled a reputational one, belongs more\n> to a monetary strategy (after the fact should be called \"staking\"\n> credentials). Indeed, there is a direct link between the credentials and a\n> cost expressed in satoshis. Therefore, in case of loopholes in the system\n> damages are effectively borne by the routing hops, without throwing the\n> whole system down. Note, the default policy should be some 0-risk HTLC\n> forward acceptance.\n>\n> On the second point, we already have today's reputation systems in\n> Lightning, namely the routing algorithms keeping track of the performance\n> of the routing hops, and their liquidity. That information is used in a\n> continuous fashion to improve payment-path building. And while those\n> algorithms are doing probabilistic estimation of the balance distribution,\n> the proposed credential system is not all relying on past statistics for\n> its effectiveness (as long as the node operators are requiring credentials\n> of worthiness equivalent to routing fees).\n>\n> On the third point, the protocol defer to the node operators all the\n> decisions on the credential acquisition costs, expiration height, binding\n> with liquidity units, or even allow additional routing policy checks.\n> Flexibility is offered to the node operators, without the protocol\n> developers trying to do any \"centralized\" decision on the cost of the\n> credentials or whatever.\n>\n> From my understanding, the critics you're raising, while potentially\n> correct for the reputation systems links you're including, does not bind to\n> any concrete point of my proposal. I hope you'll take time to browse the\n> proposal as detailed more in depth here:\n> https://github.com/lightning/bolts/pull/1043\n>\n> Best,\n> Antoine\n>\n> Le sam. 26 nov. 2022 \u00e0 05:53, Michael Folkson <\n> michaelfolkson at protonmail.com> a \u00e9crit :\n>\n>> Hi Antoine\n>>\n>> I've got a lot to catch up on re channel jamming but just to say I'm\n>> deeply skeptical about attempting to embed a reputation layer or reputation\n>> credentials into the Lightning protocol. Admittedly I'm somewhat of a\n>> curious amateur in the field of reputation systems but a number of people\n>> (me included) have had to look into reputation systems in the past for\n>> projects/startups they were working on and *centralized\u200b*\u200b reputation\n>> systems are absolute minefields to manage effectively though some\n>> corporations do manage it. Decentralized reputation systems baked into a\n>> protocol is just a step too far. All you need is one edge case where the\n>> attacker can ensure an innocent party is blamed and the reputation system\n>> falls apart. The protocol developer is in the position of assessing who is\n>> telling the truth out of two opposing viewpoints on Reddit etc.\n>>\n>> I do think reputation systems will play a key part in a future Lightning\n>> Network (to some extent they already are with sites like 1ML and Amboss)\n>> but they won't be managed by protocol devs, they will be managed by\n>> multiple flavors of companies and projects (hopefully open source but most\n>> likely closed source too, for profit, non-profit etc) who are free to use\n>> whatever metrics and weigh those metrics however they like. The protocol\n>> just can't afford to expand into areas where there is case by case judgment\n>> and statistical analysis required. It will become bloated, ineffective and\n>> put protocol developers in the position of deciding who ultimately receives\n>> routing fees rather than just enabling payments can get from A to B.\n>> Identity is easier, you either control a private key or you don't.\n>> Reputation is much more difficult, there will be some attacks where a\n>> probabilistic assessment will need to be made on who the perpetrator of the\n>> attack was. You don't add that to the (already long) list of protocol\n>> developers' responsibilities.\n>>\n>> So feel free to continue to explore reputation and reputation systems but\n>> a strong warning that this is likely not solved at the protocol level.\n>> Decisions protocol developers make will impact what data can be collected\n>> and how easy that data is to collect (there are already some tricky\n>> trade-offs with regards to privacy, routing success and transparency for\n>> when things go wrong) but beyond that protocol developers should leave it\n>> to others. I've included some links to some additional reading on\n>> reputation systems in case you are interested.\n>>\n>> Thanks\n>> Michael\n>>\n>> [0]:\n>> https://www.amazon.com/Building-Reputation-Systems-Randy-Farmer/dp/059615979X/\n>> [1]:\n>> https://medium.com/openbazaarproject/decentralized-reputation-in-openbazaar-1a577fac5175\n>> [2]: https://www.bitrated.com/faq\n>>\n>> --\n>> Michael Folkson\n>> Email: michaelfolkson at protonmail.com\n>> Keybase: michaelfolkson\n>> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>>\n>> ------- Original Message -------\n>> On Monday, November 21st, 2022 at 06:01, Antoine Riard <\n>> antoine.riard at gmail.com> wrote:\n>>\n>> Hi LN Devs,\n>>\n>> tl;dr A formalization of a reputation-based scheme to solve channel\n>> jamming is proposed. The system relies on \"credentials\" issued by routing\n>> hops and requested to be attached to each HTLC forward request. The\n>> \"credentials\" can be used by a reputation algorithm to reward/punish\n>> payment senders and allocate channel liquidity resources efficiently. The\n>> \"credentials\" initial distribution can be bootstrapped leveraging one-time\n>> upfront fees paid toward the routing hops. Afterwards, the \"credentials\"\n>> subsequent distribution can rely on previous HTLC traffic.\n>>\n>> A protocol description can be found here, with few extensions already to\n>> the BOLTs:\n>>\n>> https://github.com/lightning/bolts/pull/1043\n>>\n>> There is also a work-in-progress proof-of-concept in LDK (on top of our\n>> coming soon^TM HTLC intercepting API):\n>>\n>> https://github.com/lightningdevkit/rust-lightning/pull/1848\n>>\n>> This work builds on previous reputation-scheme research [0] [1]. It also\n>> integrates the more recent proposals of upfront fees as a straightforward\n>> mechanism to bootstrap the reputation system. Bootstrapping the system with\n>> more economically cost-effective privacy-preserving UTXO ownership proofs\n>> not only add another layer of engineering complexity, there is still a\n>> proof size vs proof generation/validation trade-off to arbiter between ZKP\n>> cryptosystems.\n>>\n>> Rather to seek for a game-theory equilibrium defined as a breakeven point\n>> as in the latest unconditional fee research [2], this proposal aims to use\n>> reputation credentials to allow HTLC traffic-shaping. This not only should\n>> protect against jamming situations (either malicious\n>> or spontaneous) but also allow active HTLC traffic-shaping, where a\n>> routing hop can allow extended channel liquidity lockups based on\n>> accumulated reputation (e.g for hold-invoices). This is also a reduced\n>> overhead cost, as upfront fees are only paid at bootstrap, or when the HTLC\n>> forward behavior can be qualified as \"whitewashing\" from the routing hop\n>> viewpoint.\n>>\n>> It should be noted, this current reputation-credential architectural\n>> framework assumes credentials distribution at the endpoint of the network.\n>> However, the framework should be flexible enough for the credentials to be\n>> harvested by the LSPs, and then distributed in a secondary fashion to their\n>> spokes, when they need it, or even attached transparently thanks to\n>> trampoline. So one design intuition, there is no strong attachment of the\n>> reputation to the endpoint HTLC sender, even if the protocol is described\n>> in a \"flat\" view for now.\n>>\n>> Let's evaluate quickly this mitigation proposal against a few criterias\n>> emerged from recent research.\n>>\n>> The mitigation is effective, in the sense a routing hop can apply a\n>> proportional relationship between the acquisition of the reputation and the\n>> amount of liquidity resources credited in function of said reputation. In a\n>> period of steady state, the reputation acquisition cost can be downgraded\n>> to 0. In periods of channel congestion, the reputation credentials to\n>> liquidity units translation can be severed, in the limit of routing hop\n>> acceptable competitiveness.\n>>\n>> The mitigation is incentive-compatible, if the credentials are not\n>> honored by their issuers, the HTLC senders can evict them from the routing\n>> network view for a while. The successful usage of credentials can lead to\n>> more credentials allocated for longer and more capacity-intensive channel\n>> lockups. In case of HTLC failure, the failure source could be forgiven by\n>> routing hops to maintain the worthiness of the sender credentials.\n>>\n>> The mitigation can be made transparent from the user, as the credentials\n>> harvesting can be done automatically from a pre-allocated budget, similar\n>> to the fee-bumping reserves requirement introduced by anchor output. At the\n>> end of today, if we take modern browsers as an example, the average user\n>> doesn't check manually the TLS certificates (for what they're worth...).\n>>\n>> The mitigation can conserve high-level privacy, as the usage of blinded\n>> signature (or another equivalent cryptosystem breaking signature/message\n>> linking) should allow the credentials issued during a preliminary phase to\n>> be undistinguishable during the redeem/usage phase. New CPU/memory DoS\n>> vectors due to the credentials processing should be watched out.\n>>\n>> About the ease of implementation, there are few protocol messages to\n>> modify, a HTLC intercepting API is assumed as supported by the\n>> implementation, onion messages support is also implied, landing EC blinded\n>> signature in libsecp256k1-zkp shouldn't be a big deal, routing algorithms\n>> adaptations might be more serious but still reasonable. The\n>> \"credentials-to-liquidity\" allocation algorithms are likely the new real\n>> beast, though I don't think any reputation scheme can spare them.\n>>\n>> There could be a concern about the centralization inertia introduced by a\n>> reputation system. Intuitively, the argument can be made that any\n>> historical tracking (such as routing buckets) favor established LN\n>> incumbents at the gain of efficiency. A counter-argument can be made, a new\n>> routing hop can lower the acquisition cost of its issued credentials to\n>> attract more HTLC traffic (accepting higher jamming risk).\n>>\n>> On the ecosystem impacts, it should be studied that this proposal would\n>> impact things like inbound channel routing fees [3], ratecard [4] or\n>> flow-control valve [5] and the whole liquidity toolchain. Hopefully, we\n>> don't significantly restrain the design space for future LN protocol\n>> upgrades.\n>>\n>> On the proposal modularity and flexibility, each routing node has\n>> oversight on its routing policy, acquisition methods, credentials to\n>> liquidity rate. New acquisition methods can be experimented or deployed\n>> when ready, e.g stakes certificates with only e2e upgrade. The credentials\n>> themselves could have \"innate\" expiration time if we use things like\n>> short-lived ZKP [6]. The credentials framework can be extended beyond\n>> solving jamming, as a generalized risk-management framework for Bitcoin\n>> decentralized financial network, e.g transaction signature exchange\n>> ordering in multi-party transactions [7] or finding reliable Coinjoin\n>> counterparties.\n>>\n>> Feedback welcome.\n>>\n>> Cheers,\n>> Antoine\n>>\n>> [0]\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-November/002884.html\n>> [1]\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-August/003673.html\n>> [2]\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-November/003740.html\n>> [3]\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-July/003643.html\n>> [4]\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-September/003685.html\n>> [5]\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-September/003686.html\n>> [6] https://eprint.iacr.org/2022/190.pdf\n>> [7] https://github.com/lightning/bolts/pull/851#issuecomment-1290727242\n>>\n>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221129/b2f3c432/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Mitigating Channel Jamming with Reputation Credentials: a Protocol Sketch",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Antoine Riard",
                "Michael Folkson",
                "Clara Shikhelman",
                "David A. Harding",
                "ZmnSCPxj"
            ],
            "messages_count": 20,
            "total_messages_chars_count": 126847
        }
    },
    {
        "title": "[Lightning-dev] Jamming mitigation call",
        "thread_messages": [
            {
                "author": "Clara Shikhelman",
                "date": "2022-11-28T02:47:33",
                "message_text_only": "Hi all,\n\nIn light of recent conversations ([1],[2]), the agenda for the call\ntomorrow (Monday the 28th, 7 pm UTC) is roughly the following:\n\n1. Overview of solutions under discussion\n2. Reputation (local/tokens)\n3. Fees\n\nThis is the link to the call: https://meet.jit.si/UnjammingLN\n\nSee you there,\nClara\n\n[1]\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2022-November/003740.html\n[2]\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2022-November/003754.html\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20221127/34df5384/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Jamming mitigation call",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Clara Shikhelman"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 666
        }
    }
]