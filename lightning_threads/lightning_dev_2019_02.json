[
    {
        "title": "[Lightning-dev] Revocations with OP_CSFS & signed sequence commitments",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2019-02-01T05:15:17",
                "message_text_only": "Good morning James,\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Thursday, January 31, 2019 6:31 AM, James Chiang <james.chiangwu at gmail.com> wrote:\n\n> Dear all,\n> \u00a0I am trying to understand how channel commitment transactions can be revoked with op_checksigfromstack(msg, sig, key) and signed sequence commitments.\n>\n> I understand that a commitment c(n, randomness) \u00a0is signed by both parties for each state, and that this signature can be verified with op_csfs(c, sig(A+B), key(A+B)). The sequence n is incremented for each new state.\n>\n> Given the most recent commitment sequence signature (from both parties) and the sequence commitment opening (n++, r), an output script of an older, revoked commitment transaction can verify that a newer signed commitment sequence exists by examining:\n>\n> -   op_checksigfromstack(c++, sig(A+B), key(A+B))\u00a0\n> -   c++ == commitment(n++, r)\n>\n> However, it must also have information about its own sequence number n, so it can verify that this is indeed lower than n++ (current). How is sequence number n committed to the nth commitment tx and accessible on-stack during script evaluation?\n\n>From what little I understand, I imagine that \"n++\" here is a SCRIPT input (such that any \"n < n++\" must be given).\nThen the SCRIPT itself contains the \"n\" it has.\n\nSo the SCRIPT above is lacking the check:\n\n    n < n++\n\nwhich I suppose can be done via\n\nOP_DUP <n> OP_GERATERTHAN OP_VERIFY\n\n\nThus `n` is embedded in the SCRIPT directly as a constant.\nNow the script itself is committed via P2WSH, and the output SCRIPT is committed to in the SIGHASH algorithm used.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "James Chiang",
                "date": "2019-02-01T09:01:20",
                "message_text_only": "Good morning ZmnSCPxj,\n Many thanks for your answers, those are greatly appreciated!\n\nMay I follow-up with the following questions related to <n> being in the\noutput script of the nth commitment transaction as you described, which is\nrequired so the inequality n++ ?> n can be evaluated during the sweep of\nthe revoked nth state.\n\n   - Does this not imply that n & n++ will necessarily be revealed during a\n   unilateral close?\n   - The Stanford presentation: \"The # of updates is hidden in case of a\n   unilateral broadcast.\"\n\nThe following slide from Olaoluwa describes a prior sequence number\ncommitment being embedded in the commitment output:\n\n   -\n   https://docs.google.com/presentation/d/14NuX5LTDSmmfYbAn0NupuXnXpfoZE0nXsG7CjzPXdlA/edit#slide=id.g2f288a09cf_0_2\n\nHow can the arguments for the evaluation of n++ ?>n be supplied without\nrevealing either commitment sequence numbers?\n\nRegarding Olaoluwa's proposal (slide linked above), I don't follow how the\nprior commitment opening and embedding of the commitment in the output\nscript contributes to this, any commitment needs its pre-image revealed,\nthereby revealing n ... what am I missing?\n\nKind regards,\n\nJames\n\nOn Fri, Feb 1, 2019 at 6:15 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning James,\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Thursday, January 31, 2019 6:31 AM, James Chiang <\n> james.chiangwu at gmail.com> wrote:\n>\n> > Dear all,\n> >  I am trying to understand how channel commitment transactions can be\n> revoked with op_checksigfromstack(msg, sig, key) and signed sequence\n> commitments.\n> >\n> > I understand that a commitment c(n, randomness)  is signed by both\n> parties for each state, and that this signature can be verified with\n> op_csfs(c, sig(A+B), key(A+B)). The sequence n is incremented for each new\n> state.\n> >\n> > Given the most recent commitment sequence signature (from both parties)\n> and the sequence commitment opening (n++, r), an output script of an older,\n> revoked commitment transaction can verify that a newer signed commitment\n> sequence exists by examining:\n> >\n> > -   op_checksigfromstack(c++, sig(A+B), key(A+B))\n> > -   c++ == commitment(n++, r)\n> >\n> > However, it must also have information about its own sequence number n,\n> so it can verify that this is indeed lower than n++ (current). How is\n> sequence number n committed to the nth commitment tx and accessible\n> on-stack during script evaluation?\n>\n> From what little I understand, I imagine that \"n++\" here is a SCRIPT input\n> (such that any \"n < n++\" must be given).\n> Then the SCRIPT itself contains the \"n\" it has.\n>\n> So the SCRIPT above is lacking the check:\n>\n>     n < n++\n>\n> which I suppose can be done via\n>\n> OP_DUP <n> OP_GERATERTHAN OP_VERIFY\n>\n>\n> Thus `n` is embedded in the SCRIPT directly as a constant.\n> Now the script itself is committed via P2WSH, and the output SCRIPT is\n> committed to in the SIGHASH algorithm used.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190201/6d3b26fe/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-02-01T09:33:53",
                "message_text_only": "Good morning,\n\nThe Stamford presentation points to BOLT #3, but this obfuscates the sequence number by XOR.\nUnfortunately this cannot result in an obfuscated number where `<` operation is sensible.\n\nAn idea would be to *add* an obfuscating number.\nFor instance, suppose the `n` field is 64-bit and we decide that 2^63 updates should be enough for anyone.\nThen at channel setup time, both sides would select a 2^63 number as base for update `n = 0`.\nSo for example, suppose we select the random number `m` at the start of the channel setup.\nWhat we publish in-script is `m + n`.\nThe next number would be `m + n + 1`, and so on.\nThis allows comparison of sequence numbers, while obscuring the number of updates.\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Thursday, January 31, 2019 6:31 AM, James Chiang <james.chiangwu at gmail.com> wrote:\n\n> Dear all,\n> \u00a0I am trying to understand how channel commitment transactions can be revoked with op_checksigfromstack(msg, sig, key) and signed sequence commitments.\n>\n> I understand that a commitment c(n, randomness) \u00a0is signed by both parties for each state, and that this signature can be verified with op_csfs(c, sig(A+B), key(A+B)). The sequence n is incremented for each new state.\n>\n> Given the most recent commitment sequence signature (from both parties) and the sequence commitment opening (n++, r), an output script of an older, revoked commitment transaction can verify that a newer signed commitment sequence exists by examining:\n>\n> -   op_checksigfromstack(c++, sig(A+B), key(A+B))\u00a0\n> -   c++ == commitment(n++, r)\n>\n> However, it must also have information about its own sequence number n, so it can verify that this is indeed lower than n++ (current). How is sequence number n committed to the nth commitment tx and accessible on-stack during script evaluation?\n>\n> I learned about this concept from Johnson Lao's and Roasbeef's Talk from Scaling Bitcoin at Stanford:\n> https://scalingbitcoin.org/stanford2017/Day1/SB2017_script_2_0.pdf\u00a0\n>\n> Any pointers would be very much appreciated.\n> Kind regards,\n>\n> James"
            },
            {
                "author": "James Chiang",
                "date": "2019-02-01T10:18:44",
                "message_text_only": "Hello ZmnSCPxj,\n\nSo you suggest obfuscating the initial `n=0` with an initial pre-negotiated\nm, and applying some kind of deterministic step to this obscured initial\nstate number. Potentially the deterministic sequence step sizes could be\ndetermined via pre-negotiated parameters which also obscure the number of\nstates between most current and broadcast...\n\n   - m + a*n\n   - (m, a pre-negotiated)\n   - (Though this would affect # of possible updates.)\n\nVery cool, thanks so much for your answer(s)!\n\nKind regards,\n\nJames\n\n\n\n\nOn Fri, Feb 1, 2019 at 10:34 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning,\n>\n> The Stamford presentation points to BOLT #3, but this obfuscates the\n> sequence number by XOR.\n> Unfortunately this cannot result in an obfuscated number where `<`\n> operation is sensible.\n>\n> An idea would be to *add* an obfuscating number.\n> For instance, suppose the `n` field is 64-bit and we decide that 2^63\n> updates should be enough for anyone.\n> Then at channel setup time, both sides would select a 2^63 number as base\n> for update `n = 0`.\n> So for example, suppose we select the random number `m` at the start of\n> the channel setup.\n> What we publish in-script is `m + n`.\n> The next number would be `m + n + 1`, and so on.\n> This allows comparison of sequence numbers, while obscuring the number of\n> updates.\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> Sent with ProtonMail Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Thursday, January 31, 2019 6:31 AM, James Chiang <\n> james.chiangwu at gmail.com> wrote:\n>\n> > Dear all,\n> >  I am trying to understand how channel commitment transactions can be\n> revoked with op_checksigfromstack(msg, sig, key) and signed sequence\n> commitments.\n> >\n> > I understand that a commitment c(n, randomness)  is signed by both\n> parties for each state, and that this signature can be verified with\n> op_csfs(c, sig(A+B), key(A+B)). The sequence n is incremented for each new\n> state.\n> >\n> > Given the most recent commitment sequence signature (from both parties)\n> and the sequence commitment opening (n++, r), an output script of an older,\n> revoked commitment transaction can verify that a newer signed commitment\n> sequence exists by examining:\n> >\n> > -   op_checksigfromstack(c++, sig(A+B), key(A+B))\n> > -   c++ == commitment(n++, r)\n> >\n> > However, it must also have information about its own sequence number n,\n> so it can verify that this is indeed lower than n++ (current). How is\n> sequence number n committed to the nth commitment tx and accessible\n> on-stack during script evaluation?\n> >\n> > I learned about this concept from Johnson Lao's and Roasbeef's Talk from\n> Scaling Bitcoin at Stanford:\n> > https://scalingbitcoin.org/stanford2017/Day1/SB2017_script_2_0.pdf\n> >\n> > Any pointers would be very much appreciated.\n> > Kind regards,\n> >\n> > James\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190201/ad635740/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-02-04T04:07:01",
                "message_text_only": "Good morning James,\n\nIt is helpful to also remember that the only requirement be that the sequence number be monotonically increasing.\nThere is no requirement that the step size be *the same* at every update.\n\nNote however that the step size being anything other than 1 is not very useful as long as the blinding initial number `m` is truly selected at random.\nThat should be sufficient to blind the actual number of updates.\n\nRegards,\nZmnSCPxj\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Friday, February 1, 2019 6:18 PM, James Chiang <james.chiangwu at gmail.com> wrote:\n\n> Hello ZmnSCPxj,\n>\n> So you suggest obfuscating the initial `n=0` with an initial pre-negotiated m, and applying some kind of deterministic step to this obscured initial state number. Potentially the deterministic sequence step sizes could be determined via pre-negotiated parameters which also obscure the number of states between most current and broadcast...\n>\n> -   m + a*n\u00a0\n> -   (m, a pre-negotiated)\n> -   (Though this would affect # of possible updates.)\n>\n> Very cool, thanks so much for your answer(s)!\n>\n> Kind regards,\n>\n> James\n>\n> On Fri, Feb 1, 2019 at 10:34 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n> > Good morning,\n> >\n> > The Stamford presentation points to BOLT #3, but this obfuscates the sequence number by XOR.\n> > Unfortunately this cannot result in an obfuscated number where `<` operation is sensible.\n> >\n> > An idea would be to *add* an obfuscating number.\n> > For instance, suppose the `n` field is 64-bit and we decide that 2^63 updates should be enough for anyone.\n> > Then at channel setup time, both sides would select a 2^63 number as base for update `n = 0`.\n> > So for example, suppose we select the random number `m` at the start of the channel setup.\n> > What we publish in-script is `m + n`.\n> > The next number would be `m + n + 1`, and so on.\n> > This allows comparison of sequence numbers, while obscuring the number of updates.\n> >\n> > Regards,\n> > ZmnSCPxj\n> >\n> > Sent with ProtonMail Secure Email.\n> >\n> > \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> > On Thursday, January 31, 2019 6:31 AM, James Chiang <james.chiangwu at gmail.com> wrote:\n> >\n> > > Dear all,\n> > > \u00a0I am trying to understand how channel commitment transactions can be revoked with op_checksigfromstack(msg, sig, key) and signed sequence commitments.\n> > >\n> > > I understand that a commitment c(n, randomness) \u00a0is signed by both parties for each state, and that this signature can be verified with op_csfs(c, sig(A+B), key(A+B)). The sequence n is incremented for each new state.\n> > >\n> > > Given the most recent commitment sequence signature (from both parties) and the sequence commitment opening (n++, r), an output script of an older, revoked commitment transaction can verify that a newer signed commitment sequence exists by examining:\n> > >\n> > > -\u00a0 \u00a0op_checksigfromstack(c++, sig(A+B), key(A+B))\u00a0\n> > > -\u00a0 \u00a0c++ == commitment(n++, r)\n> > >\n> > > However, it must also have information about its own sequence number n, so it can verify that this is indeed lower than n++ (current). How is sequence number n committed to the nth commitment tx and accessible on-stack during script evaluation?\n> > >\n> > > I learned about this concept from Johnson Lao's and Roasbeef's Talk from Scaling Bitcoin at Stanford:\n> > > https://scalingbitcoin.org/stanford2017/Day1/SB2017_script_2_0.pdf\u00a0\n> > >\n> > > Any pointers would be very much appreciated.\n> > > Kind regards,\n> > >\n> > > James"
            }
        ],
        "thread_summary": {
            "title": "Revocations with OP_CSFS & signed sequence commitments",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "James Chiang",
                "ZmnSCPxj"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 13391
        }
    },
    {
        "title": "[Lightning-dev] SURBs as a Solution for Protocol-Level Payment ACKs",
        "thread_messages": [
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2019-02-08T01:19:13",
                "message_text_only": "Hi y'all,\n\nRecently we've started to do more design work related to the Sphinx packet\n(EOB format, rendezvous protocol). This prompted me to re-visit the original\nSphinx paper to refresh my memory w.r.t some of the finer details of the\nprotocol.  While I was re-reading the paper, I realized that we may be able\nto use use SURBs (single-use-reply-blocks) to implement a \"payment ACK\" for\neach sent HTLC.\n\n(it's worth mentioning that switching to HORNET down the line would solve\nthis problem as well since the receiver already gets a multi-use backwards\nroute that they can use to send information back to the receiver)\n\nRight now HTLC routing is mainly a game of \"send and hope it arrives\", as\nyou have no clear indication of the _arrival_ of an HTLC at the destination.\nInstead, you only receive a protocol level message if the HTLC failed for\nw/e reason, or if it was successfully redeemed.  As part of BOLT 1.1, it was\nagreed upon that we should implement some sort of \"payment ACK\" feature. A\npayment ACK scheme is strongly desired as it:\n\n  * Allows the sender to actually know when a payment has reached the\n    receiver which is useful for many higher level protocols. Atm, the\n    sender is unable to distinguish an HTLC being \"black holed\" from one\n    that's actually reached the sender, and they're just holding on to it.\n  * AMP implementations would be aided by being able to receive feedback on\n    successfully routed splits. If we're able to have the receiver ACK each\n    partial payment, then implementations can more aggressively split\n    payments as they're able to gain assurance that the first 2 BTC of 5\n    total have actually reached the sender, and weren't black holed.\n  * Enforcing and relying on ACKs may also thwart silly games receivers\n    might play, claiming that the HTLC \"didn't actually arrive\".\n\nSome also call this feature a \"soft error\" as a possible implementation\nmight to re-use the existing onion error protocol we've deployed today.  For\nreference, in order to send back errors back long the route in a way that\ndoesn't reveal the sender of the HTLC to the receiver (or any of the\nintermediate nodes) we re-use the shared secret each hop has derived, and\nonion wrap a MAC'd error to the sender. Each hop can't actually check that\nthey've received a well formed error, but the sender is able to attribute an\nerror to a node in the route based on which shared secret they're able to\ncheck the MAC with.\n\nThe original Sphinx packet format has a way for the receiver to send a\nmessage back to the sender. This was originally envisioned to allow the\nreceiver to send a replay email/message back to the sender without knowing\nwho they were, and also in a manner that was bit-wise indistinguishable from\na regular forwarded packet. This is called a SURB or \"single use reply\nblock\". A SURB is composed of: a pre-crafted sphinx packet for the\n\"backwards route\" (which can be distinct from the forwards route), the first\nhop of the backwards route, and finally a symmetric key to use when\nencrypting the reply.\n\nWhen we more or less settled on using Sphinx, we started to remove things\nthat we didn't have a clear use for at the time. Two things that were\nremoved were the original end-to-end payload, and also the SURB. Removing\nthe payload made the packet size smaller, and it didn't seem realistic to\ngive _each_ hop a SURB to send reply back.\n\nIn order to implement payment ACKs, we can have the sender craft a SURB (for\nthe ACK), and mark the receipt of the SURB as the payment ACK itself.\nCreating and processing a SURB is identical to the regular HTLC packets we\nuse today. As a result, the code impact to the code sphinx packet logic is\nminimal. We'd then also re-introduce the e2e payload so we can carry the\nSURB in the forward direction (HLTC add). The backwards packet would also\nhave a payload of random bytes with the same size as a regular packet to\nmake them look identical on the wire.\n\nThis payload can further be put to use in order to implement streaming or\nsubscription payments in a way. Since we must add a payload for in order to\nsend/reply look the same, we can also piggy back some useful additional\ndata. Each time a payment is sent, the receiver can use the extra payload to\nstack on details such as:\n  * A new invoice to pay for the metered service being paid for.\n  * An invoice along with a deadline for when this must be paid, lest the\n    subscription service expire.\n  * Details of lightning-native API\n  * etc, etc\n\nIMO, this approach is better than a potential client-server payment\nnegotiation protocol as it doesn't require any additional servers along side\nthe node, also maintains sender anonymity, and doesn't rely on any sort of\nPKI.\n\n>From the prospective of packet-analysis, errors today are identifiable due\nto the packet size (though we do pad them out to avoid being able to\ndistinguish some errors from others on the wide). SURBs on the other hand,\nhave the same profile as regular HTLC adds since they use the same Sphinx\npacket format.  Unlike the wrapped onion errors, intermediate nodes are also\nable to validate the integrity of the payment ACK as they'll check the\nper-hop\nMAC as normal. Additionally, the replies naturally create cover traffic as\nthey look like regular payments.\n\nOne down side is that this would essentially double the size of HTLC\nmessages on the network today, as they need to also carry SURB.  Most\ncandidates for possible rendezvous schemes to deploy would also increase the\npacket size if up to 20 hops it be allowed in both directions.  We also\n(from my PoV), don't really have a feel on how much of an issue the 1.2KB\nHTLC packet size is today in the network.\n\nBy re-introducing SURBs, we have an opportunity to cleanly solve the payment\nACK issue, re-use a component of our favorite thing in Lightning, enable\nprotocol-level streaming/subscription payments and also make replies\nindistinguishable-ish from regular payments.\n\nThoughts?\n\n-- Laolu\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190207/77cde3d7/attachment.html>"
            },
            {
                "author": "Kulpreet Singh",
                "date": "2019-02-11T21:03:43",
                "message_text_only": "Hi Laolu,\n\nUsing the SURB approach to ACK payments definitely seems like a\nsensible approach for all the reasons you listed.\n\nI think this might be a good opportunity to think of an implicit ACK\nmechanism too. It might not be useful in the immediate future, but\ncould reduce some traffic in the long run, especially for streaming\nuse cases.\n\nI am assuming that streaming payments will encode payment sequence\nnumbers in the EOB or some place else.\n\nThe simple idea being: An ACK for paymentN implicitly ACKs payment1,\npayment2 and so on up to paymentN-1 and including paymentN.\n\nImplicit ACKs will help build streaming apps without increased traffic\ncarrying ACK packets for each sub cent payment.\n\nWith implicit ACKs available at LN layer, application libraries and\nframeworks can develop streaming payment protocols that play around\nwith ACK window size etc.\n\nFor one off payments, the streaming sequence number is not set and\nimplicit ACKing is not triggered.\n\nJust a suggestion, knowing quite well I am not aware of all the\ncomplications involved.\n\nKulpreet\n\n\n\nKulpreet\n\n\nOn Fri, 8 Feb 2019 at 02:20, Olaoluwa Osuntokun <laolu32 at gmail.com> wrote:\n>\n> Hi y'all,\n>\n> Recently we've started to do more design work related to the Sphinx packet\n> (EOB format, rendezvous protocol). This prompted me to re-visit the original\n> Sphinx paper to refresh my memory w.r.t some of the finer details of the\n> protocol.  While I was re-reading the paper, I realized that we may be able\n> to use use SURBs (single-use-reply-blocks) to implement a \"payment ACK\" for\n> each sent HTLC.\n>\n> (it's worth mentioning that switching to HORNET down the line would solve\n> this problem as well since the receiver already gets a multi-use backwards\n> route that they can use to send information back to the receiver)\n>\n> Right now HTLC routing is mainly a game of \"send and hope it arrives\", as\n> you have no clear indication of the _arrival_ of an HTLC at the destination.\n> Instead, you only receive a protocol level message if the HTLC failed for\n> w/e reason, or if it was successfully redeemed.  As part of BOLT 1.1, it was\n> agreed upon that we should implement some sort of \"payment ACK\" feature. A\n> payment ACK scheme is strongly desired as it:\n>\n>   * Allows the sender to actually know when a payment has reached the\n>     receiver which is useful for many higher level protocols. Atm, the\n>     sender is unable to distinguish an HTLC being \"black holed\" from one\n>     that's actually reached the sender, and they're just holding on to it.\n>   * AMP implementations would be aided by being able to receive feedback on\n>     successfully routed splits. If we're able to have the receiver ACK each\n>     partial payment, then implementations can more aggressively split\n>     payments as they're able to gain assurance that the first 2 BTC of 5\n>     total have actually reached the sender, and weren't black holed.\n>   * Enforcing and relying on ACKs may also thwart silly games receivers\n>     might play, claiming that the HTLC \"didn't actually arrive\".\n>\n> Some also call this feature a \"soft error\" as a possible implementation\n> might to re-use the existing onion error protocol we've deployed today.  For\n> reference, in order to send back errors back long the route in a way that\n> doesn't reveal the sender of the HTLC to the receiver (or any of the\n> intermediate nodes) we re-use the shared secret each hop has derived, and\n> onion wrap a MAC'd error to the sender. Each hop can't actually check that\n> they've received a well formed error, but the sender is able to attribute an\n> error to a node in the route based on which shared secret they're able to\n> check the MAC with.\n>\n> The original Sphinx packet format has a way for the receiver to send a\n> message back to the sender. This was originally envisioned to allow the\n> receiver to send a replay email/message back to the sender without knowing\n> who they were, and also in a manner that was bit-wise indistinguishable from\n> a regular forwarded packet. This is called a SURB or \"single use reply\n> block\". A SURB is composed of: a pre-crafted sphinx packet for the\n> \"backwards route\" (which can be distinct from the forwards route), the first\n> hop of the backwards route, and finally a symmetric key to use when\n> encrypting the reply.\n>\n> When we more or less settled on using Sphinx, we started to remove things\n> that we didn't have a clear use for at the time. Two things that were\n> removed were the original end-to-end payload, and also the SURB. Removing\n> the payload made the packet size smaller, and it didn't seem realistic to\n> give _each_ hop a SURB to send reply back.\n>\n> In order to implement payment ACKs, we can have the sender craft a SURB (for\n> the ACK), and mark the receipt of the SURB as the payment ACK itself.\n> Creating and processing a SURB is identical to the regular HTLC packets we\n> use today. As a result, the code impact to the code sphinx packet logic is\n> minimal. We'd then also re-introduce the e2e payload so we can carry the\n> SURB in the forward direction (HLTC add). The backwards packet would also\n> have a payload of random bytes with the same size as a regular packet to\n> make them look identical on the wire.\n>\n> This payload can further be put to use in order to implement streaming or\n> subscription payments in a way. Since we must add a payload for in order to\n> send/reply look the same, we can also piggy back some useful additional\n> data. Each time a payment is sent, the receiver can use the extra payload to\n> stack on details such as:\n>   * A new invoice to pay for the metered service being paid for.\n>   * An invoice along with a deadline for when this must be paid, lest the\n>     subscription service expire.\n>   * Details of lightning-native API\n>   * etc, etc\n>\n> IMO, this approach is better than a potential client-server payment\n> negotiation protocol as it doesn't require any additional servers along side\n> the node, also maintains sender anonymity, and doesn't rely on any sort of\n> PKI.\n>\n> From the prospective of packet-analysis, errors today are identifiable due\n> to the packet size (though we do pad them out to avoid being able to\n> distinguish some errors from others on the wide). SURBs on the other hand,\n> have the same profile as regular HTLC adds since they use the same Sphinx\n> packet format.  Unlike the wrapped onion errors, intermediate nodes are also\n> able to validate the integrity of the payment ACK as they'll check the per-hop\n> MAC as normal. Additionally, the replies naturally create cover traffic as\n> they look like regular payments.\n>\n> One down side is that this would essentially double the size of HTLC\n> messages on the network today, as they need to also carry SURB.  Most\n> candidates for possible rendezvous schemes to deploy would also increase the\n> packet size if up to 20 hops it be allowed in both directions.  We also\n> (from my PoV), don't really have a feel on how much of an issue the 1.2KB\n> HTLC packet size is today in the network.\n>\n> By re-introducing SURBs, we have an opportunity to cleanly solve the payment\n> ACK issue, re-use a component of our favorite thing in Lightning, enable\n> protocol-level streaming/subscription payments and also make replies\n> indistinguishable-ish from regular payments.\n>\n> Thoughts?\n>\n> -- Laolu\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Rusty Russell",
                "date": "2019-02-19T00:50:25",
                "message_text_only": "Olaoluwa Osuntokun <laolu32 at gmail.com> writes:\n> Hi y'all,\n>\n> Recently we've started to do more design work related to the Sphinx packet\n> (EOB format, rendezvous protocol). This prompted me to re-visit the original\n> Sphinx paper to refresh my memory w.r.t some of the finer details of the\n> protocol.  While I was re-reading the paper, I realized that we may be able\n> to use use SURBs (single-use-reply-blocks) to implement a \"payment ACK\" for\n> each sent HTLC.\n>\n> (it's worth mentioning that switching to HORNET down the line would solve\n> this problem as well since the receiver already gets a multi-use backwards\n> route that they can use to send information back to the receiver)\n\nI think HORNET is a better way forward for soft errors, since using the\nsame circuit is *way* more reliable (Christian indicated most probe\nfailures are due to disconnected nodes, not capacity).\n\nI'd like to see us work towards that instead, at least in baby steps.\n\n> Right now HTLC routing is mainly a game of \"send and hope it arrives\", as\n> you have no clear indication of the _arrival_ of an HTLC at the destination.\n> Instead, you only receive a protocol level message if the HTLC failed for\n> w/e reason, or if it was successfully redeemed.  As part of BOLT 1.1, it was\n> agreed upon that we should implement some sort of \"payment ACK\" feature. A\n> payment ACK scheme is strongly desired as it:\n>\n>   * Allows the sender to actually know when a payment has reached the\n>     receiver which is useful for many higher level protocols. Atm, the\n>     sender is unable to distinguish an HTLC being \"black holed\" from one\n>     that's actually reached the sender, and they're just holding on to it.\n\nAgreed, though in the long run we'll have to do something about that.\n\n>   * AMP implementations would be aided by being able to receive feedback on\n>     successfully routed splits. If we're able to have the receiver ACK each\n>     partial payment, then implementations can more aggressively split\n>     payments as they're able to gain assurance that the first 2 BTC of 5\n>     total have actually reached the sender, and weren't black holed.\n\nYes, I suspect this will quickly get messy.  Sender wants longer\ntimeouts for AMP, network definitely doesn't.  In my current draft I\nchose 60 seconds for the timeout, but that's a compromise.\n\n>   * Enforcing and relying on ACKs may also thwart silly games receivers\n>     might play, claiming that the HTLC \"didn't actually arrive\".\n\nAnd general debugging and diag as the network gets larger.\n\n> Some also call this feature a \"soft error\" as a possible implementation\n> might to re-use the existing onion error protocol we've deployed today.  For\n> reference, in order to send back errors back long the route in a way that\n> doesn't reveal the sender of the HTLC to the receiver (or any of the\n> intermediate nodes) we re-use the shared secret each hop has derived, and\n> onion wrap a MAC'd error to the sender. Each hop can't actually check that\n> they've received a well formed error, but the sender is able to attribute an\n> error to a node in the route based on which shared secret they're able to\n> check the MAC with.\n\nEither way, someone should spec that :)\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "SURBs as a Solution for Protocol-Level Payment ACKs",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Olaoluwa Osuntokun",
                "Kulpreet Singh"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 16881
        }
    },
    {
        "title": "[Lightning-dev] Extending Associated Data in the Sphinx Packet to Cover All Payment Details",
        "thread_messages": [
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2019-02-08T02:57:21",
                "message_text_only": "Hi y'all,\n\nI'm not sure how good defenses are on implementations other than lnd, but\nall implementations *should* be keeping a Sphinx reply cache of the past\nshared secrets they know of [1]. If a node comes across an identical shared\nsecret of that in the cache, then they should reject that packet. Otherwise,\nit's possible for an adversary to inject a stale packet back into the\nnetwork in order to observe the propagation of the packet through the\nnetwork. This is referred to as a \"replay\" attack, and is a de-anonymization\nvector.\n\nTypically mix nets enforce some sort of session lifetime identifier to allow\nnodes to garbage collect their old shared secrets state, otherwise it grows\nindefinitely. As our messages are actually payments with a clear expiration\ndate (the absolute CLTV), we can use this as the lifetime of a payment\ncircuit session. The sphinx packet construction allows some optional\nplaintext data to be authenticated along side the packet. In the current\nprotocol we use this to bing the payment hash along with the packet. The\nrationale is that in order for me to accept the packet, the attacker must\nuse the _same_ payment hash.  If the pre-image has already been revealed,\nthen the \"victim\" can instantly pull the payment, attaching a  cost to a\nreplay attempt.\n\nHowever, since the CLTV isn't also authenticated, then it's possible to\nattempt to inject a new HTLC with a fresher CLTV. If the node isn't keeping\naround all pre-images, then they might forward this since it passes the\nregular expiry tests. If we instead extend the associated data payload to\ncover the CLTV as well, then this binds the adversary to using the same CLTV\ndetails. As a result, the \"victim\" node will reject the HTLC since it has\nalready expired. Continuing down this line, if we progressively add more\npayment details, for example the HTLC amount, then this forces the adversary\nto commit the same amount as the original HTLC, potentially making the\nprobing vector more expensive (as they're likely to lose the funds on\nattempt).\n\nIf this were to be deployed, then we can do it by using a new packet version\nin the Sphinx packet. Nodes that come across this new version (signalled by\na global feature bit) would then know to include the extra information in\nthe AD for their MAC check. While we're at it, we should also actually\n*commit* to the packet version. Right now nodes can swap out the version to\nanything they want, potentially causing another node to reject the packet.\nThis should also be added to the AD to ensure the packet can't be modified\nwithout another node detecting it.\n\nLonger term, we may end up with _all_ payment details in the Sphinx packet.\nThe only thing outside in the update_add_htlc message would be link level\ndetails such as the HTLC ID.\n\nThoughts?\n\n[1]:\nhttps://github.com/lightningnetwork/lightning-onion/blob/master/replaylog.go\n\n-- Laolu\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190207/895c8f9c/attachment.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2019-02-08T11:13:05",
                "message_text_only": "Hi Laolu,\n\nthanks for bringing this up. I think committing to more data might be\nnice, but I have some reservations re signaling in the onion packet\nversion. But let's start at the top:\n\n> However, since the CLTV isn't also authenticated, then it's possible\n> to attempt to inject a new HTLC with a fresher CLTV. If the node isn't\n> keeping around all pre-images, then they might forward this since it\n> passes the regular expiry tests. If we instead extend the associated\n> data payload to cover the CLTV as well, then this binds the adversary\n> to using the same CLTV details.\n\nThe CLTV is actually committed to indirectly through the outgoing CLTV\nvalue in the onion payload itself (both for intermediate hops and final\nhops). For intermediate hops we will refuse any forward that has a CLTV\nvalue for the next leg that is not far enough in the future based on the\nincoming CLTV value. Notice that the values we commit to are not deltas,\nbut absolute values. This means that a node needs to keep a cache of\nshared secrets used until the `outgoing_cltv_value` from the onion dips\nbelow `incoming_cltv_value - cltv_expiry_delta`). Any replay attempt\nafter that will result in the first hop (adjacent to the attacker) to\nreject the HTLC with an `incorrect_cltv_expiry` error.\n\nThat being said I'm happy to add more information to the AD, but it may\nneed to be rolled out differently from what you describe.\n\n> If this were to be deployed, then we can do it by using a new packet version\n> in the Sphinx packet. Nodes that come across this new version (signalled by\n> a global feature bit) would then know to include the extra information in\n> the AD for their MAC check.\n\nThis will not really work if the route contains any node that does not\nunderstand the new version of the packet. The node prior to the\nnon-upgraded node would have to downgrade the packet version from v1 to\nv0 understood by the non-upgraded node, which could be done via an\ninstruction in the per-hop payload itself, but the non-upgraded node\nwould not have any way of learning that it needs to upgrade the packet\nversion to v1 again. This means we can use v1 up to the first node that\ndoesn't understand v1 and have a permanent downgrade for the rest of the\nroute.\n\nWe might get away with signalling this in the payload itself, but that\ninverts the processing of the onion into parse and interpret the payload\nbefore checking the HMAC, which I can already hear cryptographers groan\nabout :-)\n\n> While we're at it, we should also actually *commit* to the packet\n> version. Right now nodes can swap out the version to anything they\n> want, potentially causing another node to reject the packet.  This\n> should also be added to the AD to ensure the packet can't be modified\n> without another node detecting it.\n\nI don't think this is really useful. If a node wants to cause us to\nreject a packet it can just tamper with anything in the payload and\nwe'll fail with an HMAC failure. The version really is just a hint as to\nhow we should process the packet, and if tampered with it'll just cause\nus to reject, similarly to when the attacker modifies the ephemeral key.\n\n> Longer term, we may end up with _all_ payment details in the Sphinx packet.\n\nAgreed, we can also just use the serialized HTLC output, since that is\nthe on-chain representation of the payment, and therefore has to include\nall relevant details :-)\n\nCheers,\nChristian"
            }
        ],
        "thread_summary": {
            "title": "Extending Associated Data in the Sphinx Packet to Cover All Payment Details",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Olaoluwa Osuntokun",
                "Christian Decker"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 6467
        }
    },
    {
        "title": "[Lightning-dev] WIP pull requests for feature bit unification and TLV bits",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2019-02-12T06:12:45",
                "message_text_only": "Hi all,\n\n        Finally tried to write up the feature bit changes:\n\n        https://github.com/lightningnetwork/lightning-rfc/pull/571\n\nAnd also start on TLV definition for the onion:\n\n        https://github.com/lightningnetwork/lightning-rfc/pull/572\n\nFeature bits:\n-------------\n\n1. Rename local/global to peer/channel.\n2. Both get sent in node_announcment (you can look for peers with\n   specific things)\n3. channel gets sent in channel_announcement (you know you can't send\n   though channels with unknown even bits).\n\nI also took a stab at assigning all the 1.1 bits from the wiki.\n\nTLVs:\n-----\n\n1. General requirements and format (1 byte type, var_int length).\n2. Took a stab at defining switch_chain, switch_ephkey and\n   multi_part_payment.\n\nAlso added a `9` field to BOLT11 to flag base amp, OG amp, etc.\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "WIP pull requests for feature bit unification and TLV bits",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 830
        }
    },
    {
        "title": "[Lightning-dev] BIP proposal for LN wallets to use http get for retrieving invoices",
        "thread_messages": [
            {
                "author": "Ben Hannabuss",
                "date": "2019-02-12T16:56:59",
                "message_text_only": "Hi all,\n\nI was going to write a \u201cgeneral guideline\u201d BIP for bitcoin Lightning\nNetwork wallets to be able to perform a http GET request to retrieve an\ninvoice.\n\nI have experienced some development limitations in LN that could be fixed\nby such a standard, such as, not having static QRs or being limited by the\nlarge size of LN invoices. In the proposal the only data the wallets would\nexpect back is an LN invoice.\n\n* QRs could be printed rather than being dependent on a refreshable\ndisplay, useful in cost minimizing micro transaction scenarios.\n\n* QRs could be very small, as their size would be dependent on the URL\nsize.\n\n* Developers could export some complex functionality to their web server,\nand may discover use cases that inform protocol development.\n\n* There might be possible security benefits to having an airgap between the\nmerchant node and user.\n\nThe measure is somewhat temporary, as many of its enabling features will\nlikely be added natively into LN.\n\nI have received interest from some wallet developers, and https//\ntwitter.com/georgevaccaro created a working example\nhttps://youtu.be/TTpEpk5LJ4E?t=1254 using Eclair for a hack that came out\nof the New York LN hackday.\n\nDoes it make sense penning the guideline as a BIP?\n\nAll the best,\n\nBen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190212/ce24e671/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP proposal for LN wallets to use http get for retrieving invoices",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Ben Hannabuss"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1447
        }
    },
    {
        "title": "[Lightning-dev] CPFP Carve-Out for Fee-Prediction Issues in Contracting Applications (eg Lightning)",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2019-02-13T04:22:39",
                "message_text_only": "Matt Corallo <lf-lists at mattcorallo.com> writes:\n>>> Thus, even if you imagine a steady-state mempool growth, unless the \n>>> \"near the top of the mempool\" criteria is \"near the top of the next \n>>> block\" (which is obviously *not* incentive-compatible)\n>> \n>> I was defining \"top of mempool\" as \"in the first 4 MSipa\", ie. next\n>> block, and assumed you'd only allow RBF if the old package wasn't in the\n>> top and the replacement would be.  That seems incentive compatible; more\n>> than the current scheme?\n>\n> My point was, because of block time variance, even that criteria doesn't hold up. If you assume a steady flow of new transactions and one or two blocks come in \"late\", suddenly \"top 4MWeight\" isn't likely to get confirmed until a few blocks come in \"early\". Given block variance within a 12 block window, this is a relatively likely scenario.\n\n[ Digging through old mail. ]\n\nDoesn't really matter.  Lightning close algorithm would be:\n\n1.  Give bitcoind unileratal close.\n2.  Ask bitcoind what current expidited fee is (or survey your mempool).\n3.  Give bitcoind child \"push\" tx at that total feerate.\n4.  If next block doesn't contain unilateral close tx, goto 2.\n\nIn this case, if you allow a simpified RBF where 'you can replace if\n1. feerate is higher, 2. new tx is in first 4Msipa of mempool, 3. old tx isnt',\nit works.\n\nIt allows someone 100k of free tx spam, sure.  But it's simple.\n\nWe could further restrict it by marking the unilateral close somehow to\nsay \"gonna be pushed\" and further limiting the child tx weight (say,\n5kSipa?) in that case.\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "CPFP Carve-Out for Fee-Prediction Issues in Contracting Applications (eg Lightning)",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1585
        }
    },
    {
        "title": "[Lightning-dev] Proof-of-payments",
        "thread_messages": [
            {
                "author": "Joao Joyce",
                "date": "2019-02-13T11:53:30",
                "message_text_only": "Hi,\n\nRecently I've asked about the possibility of user identification across multiple payments which now I get that it is a bad idea.\n\nIn that previous exchange ZmnSCPxj suggested that for purposes of proving payments (for instance for a user to redownload an already bought document) the service could just ask for the preimage of an invoice that was already paid.\n\nI was wondering if there's interest in standardising a way for payment invoices to contain information to signal wallets that they can skip the payment process if they are able to provide the service with a preimage for a previous payment for that particular item.\n\nUse cases could extend beyond simple download of an item. For instance paying for 30 days of a service and every time you want to access that service you just scan the LN invoice.\n\nI'm aware that intermediate nodes know about this preimage but I'd rather not focus on that for now.\n\nThank you,\nJo\u00e3o Joyce\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190213/71ac80f5/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-02-14T04:07:53",
                "message_text_only": "Good morning Joao,\n\nC-lightning already does this.\nIf it is given an invoice for a payment hash it already knows, it silently succeeds and returns the preimage without sending out any money.\n\nThis should extend to any wallets built on top of C-lightning.\n\nI am uncertain what the other implementations do.\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Wednesday, February 13, 2019 7:53 PM, Joao Joyce <joao.joyce at netcabo.pt> wrote:\n\n> Hi,\n>\n> Recently I've asked about the possibility of user identification across multiple payments\u00a0which now I get that it is a bad idea.\n>\n> In that previous exchange\u00a0ZmnSCPxj suggested that for purposes of proving payments (for instance for a user to redownload an already bought document) the service could just ask for the preimage of an invoice that was already paid.\n>\n> I was wondering if there's interest in standardising a way for payment invoices to contain information to signal wallets that they can skip the payment process if they are able to provide the service with a preimage for a previous payment for that particular item.\n>\n> Use cases could extend beyond simple download of an item. For instance paying for 30 days of a service and every time you want to access that service you just scan the LN invoice.\n>\n> I'm aware that intermediate nodes know about this preimage but I'd rather not focus on that for now.\n>\n> Thank you,\n> Jo\u00e3o Joyce"
            }
        ],
        "thread_summary": {
            "title": "Proof-of-payments",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Joao Joyce",
                "ZmnSCPxj"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 2565
        }
    },
    {
        "title": "[Lightning-dev] Payee pay fee",
        "thread_messages": [
            {
                "author": "Cezary Dziemian",
                "date": "2019-02-14T14:06:12",
                "message_text_only": "Hi,\n\nNot sure if this topic was mentioned, but is there any plan to provide\npayment solution in witch Payee pay fee instead of payer?\n\nThe issue I found is on our exchange, when user can withdraw funds using\nLN. If we don't know fee in advance, he can't just withdraw everything what\nhe has. We can assume, that he can withdraw up to 99,5% of his funds, but\nit would be nice, if he can just withdraw everything and what he receives\nis just his funds minus fee.\n\nDid you discussed this before?\n\nBest Regards,\nCezary Dziemian\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190214/9f774bee/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-02-15T05:40:46",
                "message_text_only": "Good morning Cezary,\n\nI have alluded to this issue before: https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-January/001826.html\nSee \"Withdrawing funds from a service\".\n\n>From my point-of-view, the proper solution would involve the payee providing one or more complete paths from the payer to the payee node.\nThese will be provided as fully encrypted onions to the payer, providing the following benefits:\n\n1.  The payee knows exactly how much it will lose in fees, since it is the one providing the path.\n2.  The payer cannot correlate a particular user with its LN node, improving privacy.\n3.  The payer cannot bias the route towards other nodes it controls that happen, completely for no good reason, to charge high LN fees; the payee generates the route and controls its fees.\n\nThe use-case is where the payer is a publicly-useable service (an exchange as you gave example to).\nIn this case, the payer provides its node address to the user, but the user never provides its node address to the service.\n\nThere is no spec yet, and I am too busy with other considerations to actually work on anything Lightning-related, but perhaps you can pick up this, and continue its development.\n\nWe need:\n\n1.  Some standard of transporting multiple *encrypted* onions from the user (payee) to the service (payer).\n2.  Some implementation must provide some method of generating multiple routes from the user (payee) to the service (payer).\n    Importantly, this must compute \"forwards\", i.e. a constant amount will be released by the payer, and the payee will take whatever value remains after fees.\n    This is more difficult than it seems due to how LN fees are computed, unfortunately (it is based on the outgoing amount; while mathematically it is possible to just manipulate the equations, in practice roundoffs will be different in some edge cases between the \"backwards\" and \"forwards\" methods).\n    In addition, the implementation needs to have some heuristic, i.e. if it finds a route that loses more than 1% of the value being paid (overrideable by the user), then it probably should reject that route and not provide it to the service (payer).\n\nIn essence, this issue shows the \"other side\" of merchants, which is exchanges.\nCurrent LN is biased towards merchants: the merchant exposes its node ID (on the invoice it provides to the user).\nFor exchanges, we need to perform a dual transformation, where the exchange exposes its node ID somehow (via a mechanism that does not yet exist).\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Thursday, February 14, 2019 10:06 PM, Cezary Dziemian <cezary.dziemian at gmail.com> wrote:\n\n> Hi,\n> Not sure if this topic was mentioned, but is there any plan to provide payment solution in witch Payee pay fee instead of payer?\n>\n> The issue I found is on our exchange, when user can withdraw funds using LN. If we don't know fee in advance, he can't just withdraw everything what he has. We can assume, that he can withdraw up to 99,5% of his funds, but it would be nice, if he can just withdraw everything and what he receives is just his funds minus fee.\n> Did you discussed this before?\n> Best Regards,\n> Cezary Dziemian"
            },
            {
                "author": "Cezary Dziemian",
                "date": "2019-02-19T18:46:50",
                "message_text_only": "Thanks for answer ZMNSCPxj,\n\nSad to hear that you have anything non LN-related to do that has higher\npriority.\n\nWhat, can't this this be done in easier way? For example:\n\n1. Payee provides fee limit along with with Invoice. This can be amount\npercentage or absolute value in msats.\n2. Payer in order to pay just finds route, that do not exceed limit from\ninvoice\n3. Payer just pays invoice\n\nSolution above do not solve all issues, but at least it is easy to\nimplement and can be provided quite fast. I think, this is quite important,\nbecause right now I see a lot of services that just cover fee costs, what\nmakes it easy to steal. I'm afraid that sooner or later someone will use\nthis method to steal some funds, what undermines LN confidence.\n\nBest regards,\nCezary Dziemian\n\npt., 15 lut 2019 o 06:40 ZmnSCPxj <ZmnSCPxj at protonmail.com> napisa\u0142(a):\n\n> Good morning Cezary,\n>\n> I have alluded to this issue before:\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-January/001826.html\n> See \"Withdrawing funds from a service\".\n>\n> From my point-of-view, the proper solution would involve the payee\n> providing one or more complete paths from the payer to the payee node.\n> These will be provided as fully encrypted onions to the payer, providing\n> the following benefits:\n>\n> 1.  The payee knows exactly how much it will lose in fees, since it is the\n> one providing the path.\n> 2.  The payer cannot correlate a particular user with its LN node,\n> improving privacy.\n> 3.  The payer cannot bias the route towards other nodes it controls that\n> happen, completely for no good reason, to charge high LN fees; the payee\n> generates the route and controls its fees.\n>\n> The use-case is where the payer is a publicly-useable service (an exchange\n> as you gave example to).\n> In this case, the payer provides its node address to the user, but the\n> user never provides its node address to the service.\n>\n> There is no spec yet, and I am too busy with other considerations to\n> actually work on anything Lightning-related, but perhaps you can pick up\n> this, and continue its development.\n>\n> We need:\n>\n> 1.  Some standard of transporting multiple *encrypted* onions from the\n> user (payee) to the service (payer).\n> 2.  Some implementation must provide some method of generating multiple\n> routes from the user (payee) to the service (payer).\n>     Importantly, this must compute \"forwards\", i.e. a constant amount will\n> be released by the payer, and the payee will take whatever value remains\n> after fees.\n>     This is more difficult than it seems due to how LN fees are computed,\n> unfortunately (it is based on the outgoing amount; while mathematically it\n> is possible to just manipulate the equations, in practice roundoffs will be\n> different in some edge cases between the \"backwards\" and \"forwards\"\n> methods).\n>     In addition, the implementation needs to have some heuristic, i.e. if\n> it finds a route that loses more than 1% of the value being paid\n> (overrideable by the user), then it probably should reject that route and\n> not provide it to the service (payer).\n>\n> In essence, this issue shows the \"other side\" of merchants, which is\n> exchanges.\n> Current LN is biased towards merchants: the merchant exposes its node ID\n> (on the invoice it provides to the user).\n> For exchanges, we need to perform a dual transformation, where the\n> exchange exposes its node ID somehow (via a mechanism that does not yet\n> exist).\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> Sent with ProtonMail Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Thursday, February 14, 2019 10:06 PM, Cezary Dziemian <\n> cezary.dziemian at gmail.com> wrote:\n>\n> > Hi,\n> > Not sure if this topic was mentioned, but is there any plan to provide\n> payment solution in witch Payee pay fee instead of payer?\n> >\n> > The issue I found is on our exchange, when user can withdraw funds using\n> LN. If we don't know fee in advance, he can't just withdraw everything what\n> he has. We can assume, that he can withdraw up to 99,5% of his funds, but\n> it would be nice, if he can just withdraw everything and what he receives\n> is just his funds minus fee.\n> > Did you discussed this before?\n> > Best Regards,\n> > Cezary Dziemian\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190219/e501c3ef/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-02-20T08:52:24",
                "message_text_only": "Good morning Cezary,\n\n> What, can't this this be done in easier way? For example:\n>\n> 1. Payee provides fee limit along with with Invoice. This can be amount percentage or absolute value in msats.\u00a0\n> 2. Payer in order to pay just finds route, that do not exceed limit from invoice\n> 3. Payer just pays invoice\n>\n> Solution above do not solve all issues, but at least it is easy to implement and can be provided quite fast. I think, this is quite important, because right now I see a lot of services that just cover fee costs, what makes it easy to steal. I'm afraid that sooner or later someone will use this method to steal some funds, what undermines LN confidence.\n\nThis is possible.\nYou could propose additional field in BOLT11 spec for this.\n\nI would tweak this slightly.\n\nIt is currently allowed to pay more than an invoice value.\nSo a plausible proposal is:\n\n1.  User of an exchange service decides withdrawn amount.\n2.  User decides largest acceptable loss in LN fees.\n3.  User computes: invoice_value = withdrawn_amount - max_ln_fees.\n4.  In BOLT11, specify a new `withdrawn_amount` tag that signals that the service performing the payment should not spend more than the specified `withdrawn_amount`, and should deduct only the amount released by the service (the amount released, includes fees) from the user account.\n    This is trust-based; but any custodial service is inherently trust-based anyway.\n5.  A \"good\" service would overpay to the user, such that `withdrawn_amount` is exactly what it releases.\n    Again, this computation is more complex than the current computation, as the LN BOLT spec currently specifies that fees are computed \"backwards\" from the value that the destination receives.\n    A \"not bad\" service will just pay the `invoice_value` to the user and deduct `withdrawn_amount` always, and fail the withdrawal if it would release more than `withdrawn_amount`.\n    A \"bad\" service will becomes the next MtGox.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Rusty Russell",
                "date": "2019-02-22T04:24:42",
                "message_text_only": "Cezary Dziemian <cezary.dziemian at gmail.com> writes:\n> Thanks for answer ZMNSCPxj,\n>\n> Sad to hear that you have anything non LN-related to do that has higher\n> priority.\n>\n> What, can't this this be done in easier way? For example:\n\nI've been thinking about this as 'the yalls problem'.  But it is has\nsimilarities to recurring payments and bolt11 \"offers\", where you also\nhave to do an interaction to get the real invoice.\n\nTo recap: yalls currently asks you to produce a valid invoice which it\nwill then pay.  It covers fees (presumably up to some limit).  But it's\na manual and messy process.\n\nAt the summit, Takaya Imai proposed a standard mechanism for such a\n\"pull an invoice\" request.  I now see his wisdom; sorry for the delay!\n\nSo we need a web way of asking a client to send an invoice or offer over\nHTTPS.  Is this a new URI scheme?  How would this work?\n\nLonger term, we need a format for bolt11 offers (lno1...?); kind of a\ntemplate for the real invoice(s) which you would fetch, and a new\nmessage type so you can route these requests through the lightning\nnetwork.  This would give us an \"automated payment\" mechanism, too: you\nwould provide this once and yalls could do automatic payouts by\nrequesting a new invoice though LN itself.\n\nCheers,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-02-22T05:52:58",
                "message_text_only": "Good morning Rusty,\n\n> So we need a web way of asking a client to send an invoice or offer over\n> HTTPS. Is this a new URI scheme? How would this work?\n\nI thought that offers would work over LN alone?\n\nWhen you first proposed the offers, I thought it was this way:\n\n1.  Payee gives BOLT12 offer to Payer.\n2.  Payer generates a completely new random preimage and computes its hash.\n3.  Payer issues a payment along an LN route from Payer to Payee using its random hash.\n4.  At the payee hop, the onion packet contains some identifying information from the BOLT12 offer.\n5.  Payee generates a BOLT11 invoice.\n6.  Payee sends back an error packet, which includes the BOLT11 invoice.\n7.  Payer receives the error packet that includes the BOLT11 invoice.\n8.  Payer pays using the BOLT11 invoice.\n\nIntermediate nodes remain unaware of this new feature and do not require upgrades.\nA node issuing a BOLT12 offer would implicitly signal its support for this feature by the simple fact of being able to issue the BOLT12 offer.\nA node that can understand a BOLT12 offer implicitly means it supports this feature.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Rusty Russell",
                "date": "2019-02-23T03:53:47",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n> Good morning Rusty,\n>\n>> So we need a web way of asking a client to send an invoice or offer over\n>> HTTPS. Is this a new URI scheme? How would this work?\n>\n> I thought that offers would work over LN alone?\n>\n> When you first proposed the offers, I thought it was this way:\n>\n> 1.  Payee gives BOLT12 offer to Payer.\n> 2.  Payer generates a completely new random preimage and computes its hash.\n> 3.  Payer issues a payment along an LN route from Payer to Payee using its random hash.\n> 4.  At the payee hop, the onion packet contains some identifying information from the BOLT12 offer.\n> 5.  Payee generates a BOLT11 invoice.\n> 6.  Payee sends back an error packet, which includes the BOLT11 invoice.\n> 7.  Payer receives the error packet that includes the BOLT11 invoice.\n> 8.  Payer pays using the BOLT11 invoice.\n\nYes.  But how does the payee know to give the bolt12 offer to the payer?\n\nThat's the piece that's missing here, which is actually independent.\n\n> Intermediate nodes remain unaware of this new feature and do not require upgrades.\n\nThat works if we use a fake \"payment\" like this to get the real invoice.\nBe nicer to use a real message format though, as it's less overhead for\neveryone and faster.\n\n> A node issuing a BOLT12 offer would implicitly signal its support for this feature by the simple fact of being able to issue the BOLT12 offer.\n> A node that can understand a BOLT12 offer implicitly means it supports this feature.\n\nYes; I think it's early enough that we don't need to cram offers into\nbolt11 in some backwards compat way, they can be a new thing.\n\nCheers,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-02-26T03:50:33",
                "message_text_only": "Good morning Rusty,\n\n>\n> Yes. But how does the payee know to give the bolt12 offer to the payer?\n>\n> That's the piece that's missing here, which is actually independent.\n\nAh, I understand now.\n\nIn the context of this thread, payer is a service, while payee is user.\nSo I presume an HTTPS PUT or POST request, with the payer providing the HTTPS server?\n\n\n>\n> > Intermediate nodes remain unaware of this new feature and do not require upgrades.\n>\n> That works if we use a fake \"payment\" like this to get the real invoice.\n> Be nicer to use a real message format though, as it's less overhead for\n> everyone and faster.\n\nWhile good for back-compatibility, it indeed has the above drawback of overhead.\nPerhaps it is early enough that rolling out a new feature that must needs be \"sufficiently universal\" is still plausible.\n\nMight it be possible to use SURBs as in the other thread?\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Rusty Russell",
                "date": "2019-02-26T06:22:11",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n> Might it be possible to use SURBs as in the other thread?\n\nIt's possible, but you still don't want it for all the same reasons: you\nhave a nicely anonymized path you know works, so why use something else?\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Payee pay fee",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Cezary Dziemian",
                "ZmnSCPxj"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 15491
        }
    },
    {
        "title": "[Lightning-dev] Quick analysis of channel_update data",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2019-02-18T12:09:43",
                "message_text_only": "BTW, I took a snapshot of our gossip store from two weeks back, which\nsimply stores all gossip in order (compacting every week or so).\n\nchannel_updates which updated existing channels: 17766\n... which changed *only* the timestamps: 12644\n    ... which were a week since the last: 7233\n... which only changed the disable/enable: 4839\n\nSo there are about 5100 timestamp-only updates less than a week apart\n(about 2000 are 1036 seconds apart, who is this?).\n\n1. I'll look at getting even more conservative with flapping (120second\n   delay if we've just sent an update) but that doesn't seem to be the\n   majority of traffic.\n2. I'll also slow down refreshes to every 12 days, rather than 7, but\n   again it's only a marginal change.\n\nBut basically, the majority of updates I saw two weeks ago are actually\nrefreshes, not spam.\n\nHope that adds something?\nRusty.\n\nFabrice Drouin <fabrice.drouin at acinq.fr> writes:\n> Additional info on channel_update traffic:\n>\n> Comparing daily backups of routing tables over the last 2 weeks shows\n> that nearly all channels get at least a new update every day. This\n> means that channel_update traffic is not primarily cause by nodes\n> publishing new updates when channel are about to become stale:\n> otherwise we would see 1/14th of our channels getting a new update on\n> the first day, then another 1/14th on the second day and so on.This is\n> confirmed by comparing routing table backups over a single day: nearly\n> all channels were updated, one average once, with an update that\n> almost always does not include new information.\n>\n> It could be caused by \"flapping\" channels, probably because the hosts\n> that are hosting them are not reliable (as in is often offline).\n>\n> Heuristics can be used to improve traffic but it's orhtogonal to the\n> problem of improving our current sync protocol.\n> Also, these heuristics would probaly be used to close channels to\n> unreliable nodes instead of filtering/delaying publishing updates for\n> them.\n>\n> Finally, this is not just obsessing over bandwidth (though bandwidth\n> is a real issue for most mobile users). I'm also over obsessing over\n> startup time and payment UX :), because they do matter a lot for\n> mobile users, and would like to push the current gossip design as far\n> as it can go. I also think that we'll face the same issue when\n> designing inventory messages for channel_update messages.\n>\n> Cheers,\n>\n> Fabrice\n>\n>\n>\n> On Wed, 9 Jan 2019 at 00:44, Rusty Russell <rusty at rustcorp.com.au> wrote:\n>>\n>> Fabrice Drouin <fabrice.drouin at acinq.fr> writes:\n>> > I think there may even be a simpler case where not replacing updates\n>> > will result in nodes not knowing that a channel has been re-enabled:\n>> > suppose you got 3 updates U1, U2, U3 for the same channel, U2 disables\n>> > it, U3 enables it again and is the same as U1. If you discard it and\n>> > just keep U1, and your peer has U2, how will you tell them that the\n>> > channel has been enabled again ? Unless \"discard\" here means keep the\n>> > update but don't broadcast it ?\n>>\n>> This can only happen if you happen to lose connection to the peer(s)\n>> which sent U2 before it sends U3.\n>>\n>> Again, this corner case penalizes flapping channels.  If we also\n>> ratelimit our own enables to 1 per 120 seconds, you won't hit this case?\n>>\n>> > But then there's a risk that nodes would discard channels as stale\n>> > because they don't get new updates when they reconnect.\n>>\n>> You need to accept redundant updates after 1 week, I think.\n>>\n>> Cheers,\n>> Rusty."
            },
            {
                "author": "Fabrice Drouin",
                "date": "2019-02-18T15:34:47",
                "message_text_only": "I'll start collecting and checking data again, but from what I see now\nusing our checksum extension still significantly reduces gossip\ntraffic.\n\nI'm not saying that heuristics to reduce the number of updates cannot\nhelp, but I just don't think it should be our primary way of handling\nsuch traffic. If you've opened channels to nodes that are unreliable\nthen you should eventually close these channels, but delaying how you\npublish updates that disable/enable them has an impact on everyone,\nespecially if they mostly send payments (as opposed to relaying or\nreceiving them).\n\nCheers,\n\nFabrice\n\nOn Mon, 18 Feb 2019 at 13:10, Rusty Russell <rusty at rustcorp.com.au> wrote:\n>\n> BTW, I took a snapshot of our gossip store from two weeks back, which\n> simply stores all gossip in order (compacting every week or so).\n>\n> channel_updates which updated existing channels: 17766\n> ... which changed *only* the timestamps: 12644\n>     ... which were a week since the last: 7233\n> ... which only changed the disable/enable: 4839\n>\n> So there are about 5100 timestamp-only updates less than a week apart\n> (about 2000 are 1036 seconds apart, who is this?).\n>\n> 1. I'll look at getting even more conservative with flapping (120second\n>    delay if we've just sent an update) but that doesn't seem to be the\n>    majority of traffic.\n> 2. I'll also slow down refreshes to every 12 days, rather than 7, but\n>    again it's only a marginal change.\n>\n> But basically, the majority of updates I saw two weeks ago are actually\n> refreshes, not spam.\n>\n> Hope that adds something?\n> Rusty.\n>\n> Fabrice Drouin <fabrice.drouin at acinq.fr> writes:\n> > Additional info on channel_update traffic:\n> >\n> > Comparing daily backups of routing tables over the last 2 weeks shows\n> > that nearly all channels get at least a new update every day. This\n> > means that channel_update traffic is not primarily cause by nodes\n> > publishing new updates when channel are about to become stale:\n> > otherwise we would see 1/14th of our channels getting a new update on\n> > the first day, then another 1/14th on the second day and so on.This is\n> > confirmed by comparing routing table backups over a single day: nearly\n> > all channels were updated, one average once, with an update that\n> > almost always does not include new information.\n> >\n> > It could be caused by \"flapping\" channels, probably because the hosts\n> > that are hosting them are not reliable (as in is often offline).\n> >\n> > Heuristics can be used to improve traffic but it's orhtogonal to the\n> > problem of improving our current sync protocol.\n> > Also, these heuristics would probaly be used to close channels to\n> > unreliable nodes instead of filtering/delaying publishing updates for\n> > them.\n> >\n> > Finally, this is not just obsessing over bandwidth (though bandwidth\n> > is a real issue for most mobile users). I'm also over obsessing over\n> > startup time and payment UX :), because they do matter a lot for\n> > mobile users, and would like to push the current gossip design as far\n> > as it can go. I also think that we'll face the same issue when\n> > designing inventory messages for channel_update messages.\n> >\n> > Cheers,\n> >\n> > Fabrice\n> >\n> >\n> >\n> > On Wed, 9 Jan 2019 at 00:44, Rusty Russell <rusty at rustcorp.com.au> wrote:\n> >>\n> >> Fabrice Drouin <fabrice.drouin at acinq.fr> writes:\n> >> > I think there may even be a simpler case where not replacing updates\n> >> > will result in nodes not knowing that a channel has been re-enabled:\n> >> > suppose you got 3 updates U1, U2, U3 for the same channel, U2 disables\n> >> > it, U3 enables it again and is the same as U1. If you discard it and\n> >> > just keep U1, and your peer has U2, how will you tell them that the\n> >> > channel has been enabled again ? Unless \"discard\" here means keep the\n> >> > update but don't broadcast it ?\n> >>\n> >> This can only happen if you happen to lose connection to the peer(s)\n> >> which sent U2 before it sends U3.\n> >>\n> >> Again, this corner case penalizes flapping channels.  If we also\n> >> ratelimit our own enables to 1 per 120 seconds, you won't hit this case?\n> >>\n> >> > But then there's a risk that nodes would discard channels as stale\n> >> > because they don't get new updates when they reconnect.\n> >>\n> >> You need to accept redundant updates after 1 week, I think.\n> >>\n> >> Cheers,\n> >> Rusty."
            }
        ],
        "thread_summary": {
            "title": "Quick analysis of channel_update data",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Fabrice Drouin"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 7877
        }
    },
    {
        "title": "[Lightning-dev] Multi-frame sphinx onion format",
        "thread_messages": [
            {
                "author": "Christian Decker",
                "date": "2019-02-18T18:39:25",
                "message_text_only": "Heya everybody,\n\nduring the spec meeting in Adelaide we decided that we'd like to extend\nour current onion-routing capabilities with a couple of new features,\nsuch as rendez-vous routing, spontaneous payments, multi-part payments,\netc. These features rely on two changes to the current onion format:\nbigger per-hop payloads (in the form of multi-frame payloads) and a more\nmodern encoding (given by the TLV encoding).\n\nIn the following I will explain my proposal on how to extend the per-hop\npayload from the current 65 bytes (which include realm and HMAC) to\nmultiples.\n\nUntil now we had a 1-to-1 relationship between a 65 byte segment of\npayload and a hop in the route. Since this is no longer the case, I\npropose we call the 65 byte segment a frame, to differentiate it from a\nhop in the route, hence the name multi-frame onion. The creation and\ndecoding process doesn't really change at all, only some of the\nparameters.\n\nWhen constructing the onion, the sender currently always right-shifts by\na single 65 byte frame, serializes the payload, and encrypts using the\nChaCha20 stream. In parallel it also generates the fillers (basically 0s\nthat get appended and encrypted by the processing nodes, in order to get\nmatching HMACs), these are also shifted by a single 65 byte frame on\neach hop. The change in the generation comes in the form of variable\nshifts for both the payload serialization and filler generation,\ndepending on the payload size. So if the payload fits into 32 bytes\nnothing changes, if the payload is bigger, we just use additional frames\nuntil it fits. The payload is padded with 0s, the HMAC remains as the\nlast 32 bytes of the payload, and the realm stays at the first\nbyte. This gives us\n\n> payload_size = num_frames * 65 byte - 1 byte (realm) - 32 bytes (hmac)\n\nThe realm byte encodes both the payload format as well as how many\nadditional frames were used to encode the payload. The MSB 4 bits encode\nthe number of frames used, while the 4 LSB bits encode the realm/payload\nformat.\n\nThe decoding of an onion packet pretty much stays the same, the\nreceiving node generates the shared secret, then generates the ChaCha20\nstream, and decrypts the packet (and additional padding that matches the\nfiller the sender generated for HMACs). It can then read the realm byte,\nand knows how many frames to read, and how many frames it needs to left-\nshift in order to derive the next onion.\n\nThis is a competing proposal with the proposal by roasbeef on the\nlightning-onion repo [1], but I think it is superior in a number of\nways. The major advantage of this proposal is that the payload is in one\ncontiguous memory region after the decryption, avoiding re-assembly of\nmultiple parts and allowing zero-copy processing of the data. It also\navoids multiple decryption steps, and does not waste space on multiple,\nuseless, HMACs. I also believe that this proposal is simpler than [1],\nsince it doesn't require re-assembly, and creates a clear distinction\nbetween payload units and hops.\n\nTo show that this proposal actually works, and is rather simple, I went\nahead and implemented it for c-lightning [2] and lnd [3] (sorry ACINQ,\nmy scala is not sufficient to implement if for eclair). Most of the code\nchanges are preparation for variable size payloads alongside the legacy\nv0 payloads we used so far, the relevant commits that actually change\nthe generation of the onion are [4] and [5] for c-lightning and lnd\nrespectively.\n\nI'm hoping that this proposal proves to be useful, and that you agree\nabout the advantages I outlined above. I'd also like to mention that,\nwhile this is working, I'm open to suggestions :-)\n\nCheers,\nChristian\n\n[1] https://github.com/lightningnetwork/lightning-onion/pull/31\n[2] https://github.com/ElementsProject/lightning/pull/2363\n[3] https://github.com/lightningnetwork/lightning-onion/pull/33\n[4] https://github.com/ElementsProject/lightning/pull/2363/commits/aac29daeeb5965ae407b9588cd599f38291c0c1f\n[5] https://github.com/lightningnetwork/lightning-onion/pull/33/commits/216c09c257d1a342c27c1e85ef6653559ef39314"
            },
            {
                "author": "Rusty Russell",
                "date": "2019-02-22T03:50:59",
                "message_text_only": "Subnote on this, there's a query on TLV format (1 byte type, 1 byte+\nlen).\n\nThere are two ways to add TLV to the onion:\n1. Leave the existing fields and put TLV in the padding:\n   * [`8`:`short_channel_id`]\n   * [`8`:`amt_to_forward`]\n   * [`4`:`outgoing_cltv_value`]\n   * [`12`:`padding`]\n2. Replace existing fields with TLV (eg. 2=short_channel_id,\n   4=amt_to_forward, 6=outgoing_cltv_value) and use realm > 0\n   to flag the new TLV format.\n\nThe length turns out about the same for intermediary hops, since:\nTLV of short_channel_id => 10 bytes\nTLV of amt_to_forward => probably 5-6 bytes.\nTLV of outgoing_cltv_value => probably 3-4 bytes.\n\nFor final hop, we don't use short_channel_id, so we save significantly\nthere.  That's also where many proposals to add information go (eg. a\nspecial \"app-level\" value), so it sways me in the direction of making\nTLV take the entire room.\n\nCheers,\nRusty.\n\nChristian Decker <decker.christian at gmail.com> writes:\n> Heya everybody,\n>\n> during the spec meeting in Adelaide we decided that we'd like to extend\n> our current onion-routing capabilities with a couple of new features,\n> such as rendez-vous routing, spontaneous payments, multi-part payments,\n> etc. These features rely on two changes to the current onion format:\n> bigger per-hop payloads (in the form of multi-frame payloads) and a more\n> modern encoding (given by the TLV encoding).\n>\n> In the following I will explain my proposal on how to extend the per-hop\n> payload from the current 65 bytes (which include realm and HMAC) to\n> multiples.\n>\n> Until now we had a 1-to-1 relationship between a 65 byte segment of\n> payload and a hop in the route. Since this is no longer the case, I\n> propose we call the 65 byte segment a frame, to differentiate it from a\n> hop in the route, hence the name multi-frame onion. The creation and\n> decoding process doesn't really change at all, only some of the\n> parameters.\n>\n> When constructing the onion, the sender currently always right-shifts by\n> a single 65 byte frame, serializes the payload, and encrypts using the\n> ChaCha20 stream. In parallel it also generates the fillers (basically 0s\n> that get appended and encrypted by the processing nodes, in order to get\n> matching HMACs), these are also shifted by a single 65 byte frame on\n> each hop. The change in the generation comes in the form of variable\n> shifts for both the payload serialization and filler generation,\n> depending on the payload size. So if the payload fits into 32 bytes\n> nothing changes, if the payload is bigger, we just use additional frames\n> until it fits. The payload is padded with 0s, the HMAC remains as the\n> last 32 bytes of the payload, and the realm stays at the first\n> byte. This gives us\n>\n>> payload_size = num_frames * 65 byte - 1 byte (realm) - 32 bytes (hmac)\n>\n> The realm byte encodes both the payload format as well as how many\n> additional frames were used to encode the payload. The MSB 4 bits encode\n> the number of frames used, while the 4 LSB bits encode the realm/payload\n> format.\n>\n> The decoding of an onion packet pretty much stays the same, the\n> receiving node generates the shared secret, then generates the ChaCha20\n> stream, and decrypts the packet (and additional padding that matches the\n> filler the sender generated for HMACs). It can then read the realm byte,\n> and knows how many frames to read, and how many frames it needs to left-\n> shift in order to derive the next onion.\n>\n> This is a competing proposal with the proposal by roasbeef on the\n> lightning-onion repo [1], but I think it is superior in a number of\n> ways. The major advantage of this proposal is that the payload is in one\n> contiguous memory region after the decryption, avoiding re-assembly of\n> multiple parts and allowing zero-copy processing of the data. It also\n> avoids multiple decryption steps, and does not waste space on multiple,\n> useless, HMACs. I also believe that this proposal is simpler than [1],\n> since it doesn't require re-assembly, and creates a clear distinction\n> between payload units and hops.\n>\n> To show that this proposal actually works, and is rather simple, I went\n> ahead and implemented it for c-lightning [2] and lnd [3] (sorry ACINQ,\n> my scala is not sufficient to implement if for eclair). Most of the code\n> changes are preparation for variable size payloads alongside the legacy\n> v0 payloads we used so far, the relevant commits that actually change\n> the generation of the onion are [4] and [5] for c-lightning and lnd\n> respectively.\n>\n> I'm hoping that this proposal proves to be useful, and that you agree\n> about the advantages I outlined above. I'd also like to mention that,\n> while this is working, I'm open to suggestions :-)\n>\n> Cheers,\n> Christian\n>\n> [1] https://github.com/lightningnetwork/lightning-onion/pull/31\n> [2] https://github.com/ElementsProject/lightning/pull/2363\n> [3] https://github.com/lightningnetwork/lightning-onion/pull/33\n> [4] https://github.com/ElementsProject/lightning/pull/2363/commits/aac29daeeb5965ae407b9588cd599f38291c0c1f\n> [5] https://github.com/lightningnetwork/lightning-onion/pull/33/commits/216c09c257d1a342c27c1e85ef6653559ef39314\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Christian Decker",
                "date": "2019-02-22T15:53:50",
                "message_text_only": "Rusty Russell <rusty at rustcorp.com.au> writes:\n> There are two ways to add TLV to the onion:\n> 1. Leave the existing fields and put TLV in the padding:\n>    * [`8`:`short_channel_id`]\n>    * [`8`:`amt_to_forward`]\n>    * [`4`:`outgoing_cltv_value`]\n>    * [`12`:`padding`]\n> 2. Replace existing fields with TLV (eg. 2=short_channel_id,\n>    4=amt_to_forward, 6=outgoing_cltv_value) and use realm > 0\n>    to flag the new TLV format.\n>\n> The length turns out about the same for intermediary hops, since:\n> TLV of short_channel_id => 10 bytes\n> TLV of amt_to_forward => probably 5-6 bytes.\n> TLV of outgoing_cltv_value => probably 3-4 bytes.\n>\n> For final hop, we don't use short_channel_id, so we save significantly\n> there.  That's also where many proposals to add information go (eg. a\n> special \"app-level\" value), so it sways me in the direction of making\n> TLV take the entire room.\n\nI'd definitely vote for making the entire payload a TLV (option 2) since\nthat allows us to completely redefine the payload. I don't think the\noverhead argument really applies since we're currently wasting 12 bytes\nof payload anyway, and with option 2 we still fit the current payload in\na single frame.\n\nThere is however a third option, namely make the entire payload a\nTLV-set and then use the old payload format (`short_channel_id`,\n`amt_to_forward`, `outgoing_ctlv_value`) as a single TLV-value with 20\nbytes of size. That means we have only 2 bytes of overhead compared to\nthe old v0 format (4 byte less than option 2), and can drop it if we\nrequire some other payload that doesn't adhere to this format.\n\nCheers,\nChristian"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-02-24T00:53:03",
                "message_text_only": "Good morning Christian, Rusty, and list,\n\n> There is however a third option, namely make the entire payload a\n> TLV-set and then use the old payload format (`short_channel_id`,\n> `amt_to_forward`, `outgoing_ctlv_value`) as a single TLV-value with 20\n> bytes of size. That means we have only 2 bytes of overhead compared to\n> the old v0 format (4 byte less than option 2), and can drop it if we\n> require some other payload that doesn't adhere to this format.\n\nYou can take this a step further and make the realm 0 byte into a special type \"0\" which has a fixed length of 1299 bytes, with the length never encoded for this special type.\nIt would then define the next 1299 bytes as the \"V\", having the format of 64 bytes of the current hop format (short channel ID, amount, CLTV, 12-byte padding, HMAC), plus 19*65 bytes as the encrypted form of the next hop data.\nThis lets us reclaim even the realm byte, removing its overhead by re-encoding it as the type in a TLV system, and with the special exception of dropping the \"L\" for the type 0 (== current realm 0) case.\n\nIn short, drop the concept of 65-byte \"frames\".\n\nWe could have another special length-not-encoded type 255, which declares the next 32 bytes as HMAC and the rest of the onion packet as the data for the next hop.\n\nThe above is not a particularly serious proposal.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Christian Decker",
                "date": "2019-02-24T17:59:04",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n> Good morning Christian, Rusty, and list,\n> You can take this a step further and make the realm 0 byte into a\n> special type \"0\" which has a fixed length of 1299 bytes, with the\n> length never encoded for this special type.  It would then define the\n> next 1299 bytes as the \"V\", having the format of 64 bytes of the\n> current hop format (short channel ID, amount, CLTV, 12-byte padding,\n> HMAC), plus 19*65 bytes as the encrypted form of the next hop data.\n> This lets us reclaim even the realm byte, removing its overhead by\n> re-encoding it as the type in a TLV system, and with the special\n> exception of dropping the \"L\" for the type 0 (== current realm 0)\n> case.\n\nI disagree that this would be any clearer than the current proposal\nsince we completely lose the separation of payload encoding vs. onion\nencoding. Let's not mix the concepts of payload and transport onion,\nplease.\n\n> In short, drop the concept of 65-byte \"frames\".\n>\n> We could have another special length-not-encoded type 255, which\n> declares the next 32 bytes as HMAC and the rest of the onion packet as\n> the data for the next hop.\n>\n> The above is not a particularly serious proposal.\n\nYou had me worried for a second there :-)"
            }
        ],
        "thread_summary": {
            "title": "Multi-frame sphinx onion format",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "ZmnSCPxj",
                "Christian Decker"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 13623
        }
    },
    {
        "title": "[Lightning-dev] LN on top of plasma chain?",
        "thread_messages": [
            {
                "author": "Cezary Dziemian",
                "date": "2019-02-27T09:47:01",
                "message_text_only": "Hi group,\n\nDo you think it would be possible to run LN on top of plasma chain instead\nof main chain? That would make plasma layer-2 solution and LN layer-3\nsolution.\n\nIn long-term future it would make a lot of sense to have \"full node\"\ncontaining main chain, at least one plasma chain and LN. We can imagine\nthen, that we would install \"full node\" on mobile phone and no need to use\nSPV or neutrino.\n\nBest,\nCD\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190227/c804c455/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-02-27T10:38:03",
                "message_text_only": "Good morning Cezary,\n\nOnce you have had the insight, that a \"blockchain\" is really a subclass of \"cryptocurrency system\", and that a \"Lightning Network payment channel\" is really a subclass of the same \"cryptocurrency system\" (except the constructor for CLightningPaymentChannel itself has a CCryptocurrencySystem as argument, wheres a constructor for CBlockchain has no arguments in its constructor, i.e. is not dependent on the existence of another cryptocurrency system), then you realize that it is immaterial, theoretically, whether an LN payment channel is built on Bitcoin, on another blockchain, or on another LN payment channel.\n\nIn particular, see Fulgurite: https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-December/001721.html\n\nThe key insight here is that with Decker-Wattenhofer and Decker-Russell-Osuntokun, we can have a multiparticipant \"payment channel\", i.e. a CCryptocurrencySystem (whose constructor requires an existing CCryptocurrencySystem).\nAnd that multiparticipant payment channel can itself be used to instantiate other payment channels (which are themselves subclasses of CCryptocurrencySystem).\n\n\nThe hard part is the dreary spec-work of defining what messages are needed, how to make the system extensible, etc.\nI believe Fulgurite is that effort, which also wants to somehow be compatible with the existing LN spec.\n\nIn short, yes, it's theoretically possible to build LN on any cryptocurrency system, whether Bitcoin mainchain, Ethereum, another cryptocurrency system that is not a blockchain, and so on.\n\nThe only minimum requirement is that the cryptocurrency system need to support only a particular small minimum set of functionality.\nFor Poon-Dryja and Decker-Wattenhofer channels it requires only multisignatures, hashlocks, and (absolute and relative) timelocks.\nFor Decker-Russel-Osuntokun it requires multisignatures, hashlocks, timelocks, and `SIGHASH_NOINPUT`.\n(note that Poon-Dryja is restricted to two participants, while the Decker-* variants are multiparticipant but either require longer timelocks on one-sided close (Decker-Wattenhofer) or the new untested `SIGHASH_NOINPUT` (Decker-Russell-Osuntokun))\n\n\nRegards,\nZmnSCPxj\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Wednesday, February 27, 2019 5:47 PM, Cezary Dziemian <cezary.dziemian at gmail.com> wrote:\n\n> Hi group,\n>\n> Do you think it would be possible to run LN on top of plasma chain instead of main chain? That would make plasma layer-2 solution and LN layer-3 solution.\n>\n> In long-term future it would make a lot of sense to have \"full node\" containing main chain, at least one plasma chain and LN. We can imagine then, that we would install \"full node\" on mobile phone and no need to use SPV or neutrino.\u00a0\n>\n> Best,\n> CD"
            }
        ],
        "thread_summary": {
            "title": "LN on top of plasma chain?",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Cezary Dziemian",
                "ZmnSCPxj"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 3370
        }
    }
]