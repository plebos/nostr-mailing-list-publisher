[
    {
        "title": "[Lightning-dev] Splice Pinning Prevention w/o Anchors",
        "thread_messages": [
            {
                "author": "Dustin Dettmer",
                "date": "2022-08-09T20:14:59",
                "message_text_only": "As raised by @crypto-iq and @roasbeef, splices which permit arbitrary\nscript and input inclusion are at risk of being mempool pinned. Here we\npresent a solution to this splice pinning problem.\n\n\n## Background\n\nPinning can be done by building a very large \u201cjunk\u201d transaction that spends\nfrom an important pending one. There are two known pinning vectors:\nancestor bulking thru addition of new inputs and junk pinning via the\nspending of outputs.\n\n\nPinning pushes transactions to the bottom of the priority list without a\npractical way of bumping it up. It is in effect a griefing attack, but in\nthe case of lightning can risk funds loss for HTLCs that have timed out for\na pinned commitment transaction.\n\n\nAnchor outputs were introduced to lightning to mitigate the junk pinning\nvector; they work by adding a minimum of  `1 CSV` lock to all outputs on\nthe commitment transaction except for two \u201canchor\u201d outputs, one for each\nchannel peer. (These take advantage of a 1-tx carve-out exception to enable\npropagation of anchors despite any junk attached to the peer\u2019s anchor).\n\n\n## Mitigation\n\nSplice transactions are susceptible to both junk and bulk pinning attacks.\nHere\u2019s how we propose mitigating these for splice.\n\n\n[https://i.imgur.com/ayiO1Qt.png]\n\n\nFor \u201cancestor bulking\u201d, every `tx_add_input` proposed by a peer must be\nincluded in the UTXO set. A node MUST verify the presence of a proposed\ninput before adding it to the splicing transaction.\n\n\nFor \u201coutput junk\u201d, every output included directly in a splice transaction\nMUST be a v0 P2SH witness script which begins with a minimum of `1 CSV`\nrelative timelock. No output on the splice transaction will be spendable\nuntil it is included in a block. This prevents junk pinning by removing the\nability to propose spends of splice outputs before the transaction is\nincluded in a block.\n\n\nThere are two side effects here.\n\n\n1) You cannot CPFP a splice transaction. All splices must be RBF\u2019d to be\nfee-bumped. The interactive tx protocol already provides a protocol for\ninitiating an RBF, which we re-use for splicing.\n\n2) Arbitrary 3rd party scriptPubKeys are not permissible directly into the\nsplice tx.\n\n\nIn order for this to work we need to validate that every output has a 1\nblock CSV. There are two output types to consider:\n\n   1. New channel outpoints\n   2. Arbitrary splice out funds\n\n\nFor arbitrary splice out, funds can be included in a \u201cfan-out\u201d transaction.\nHere standard pay to address etc outputs can live. The output leading to\nthe fan-out transaction will be a P2WSH that also begins with [OP_1,\nOP_CHECKSEQUENCEVERIFY] (referred to from here on as \u20181 CSV\u2019). Each splice\nparty SHOULD build a fan-out transaction for all arbitrary spliced outputs.\n\n\n[https://i.imgur.com/40Dy3oq.png]\n\n\nSplice-in transactions will not require any fan-out children as long as all\nchange goes into the channel outpoint.\n\n\nFor new channel outpoints, the v0 witness script should be modified to\nstart with [OP_1, OP_CHECKSEQUENCEVERIFY]. It needs to be the first item in\nthe script to allow easy validation that it is used and not hidden in a\nfalse conditional. This would need to be applied to post-splice channel\noutpoints and probably dual funding channels should add it as well so they\ncan be successfully included in splices.\n\n\n### interactive tx protocol changes\n\nFor splices, `tx_add_output` MUST include the `witness_script` in the tlv.\nUpon receiving outputs, nodes must validate the script matches the script\nhash in the output and that it begins with a minimum of 1 CSV.\n\n\n## HTLC Timeouts and Splices\n\nTypically when this technique is used, one or two anchor outputs are added\nto purposely allow for CPFP fee bumping. But, turns out, we already have a\nusable anchor in the original commitment transaction! Very exciting.\n\n\nThe interactive tx protocol mandates that splice txs are RBF-enabled.\nBroadcast splice proposals can be replaced out for the original commitment\ntransaction at any time. Since the original commitment transaction has\nexisting anchors, these may be used to increase fees on a force close. This\ncombined with every other output in the tree being locked behind a 1 CSV\nmeans the force close will always have top mempool priority, mitigating the\n\u201coutput junk\u201d style pin.\n\n\n- Nifty & Dusty\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220809/d79c4ee0/attachment.html>"
            },
            {
                "author": "Eugene Siegel",
                "date": "2022-08-10T15:34:44",
                "message_text_only": "Hi,\n\nI think the ancestor bulking variant of pinning only matters if you are\ntrying to add a new descendant and can't due to the ancestor/descendant\nlimits. In this  example, since all of the outputs are locked with `1\nOP_CSV`, you can't add a descendant to the splice tx. The ancestor bulking\nalso shouldn't matter for RBF since you wouldn't be replacing any of the\nancestors, only the splice tx. I think it might matter if the new funding\noutput isn't encumbered.\n\nThe new funding output can't have `1 OP_CSV` unless we also change the\ncommit tx format, and I'm not sure if it would work. The commit tx has the\ndisable bit set in nSequence so it isn't compatible with the sequence lock.\nEnabling the bit might be tricky since then the commit tx may have a\ntime-based or block-based locktime based on the lower bits of the obscured\ncommitment number, and it must be block-based (and non-zero) for the\nsequence lock to work. That means if it's not encumbered, pinning exists\nsince an attacker can make a junk tree using the anchor output. It is\nreplaceable using RBF since you have your own commit tx (with anchor) to\nbroadcast.\n\nEugene\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220810/667a9a6b/attachment.html>"
            },
            {
                "author": "Greg Sanders",
                "date": "2022-08-10T16:06:05",
                "message_text_only": "> I think the ancestor bulking variant of pinning only matters if you are\ntrying to add a new descendant and can't due to the ancestor/descendant\nlimits.\n\nNot quite. It also matters if you want to RBF that transaction, since low\nfeerate ancestor junk puts the transaction at the bottom of the mempool, so\nto speak, even if it has a high feerate itself. You are forced to pay \"full\nfreight\" to replace it via bip125 rule#3 even though it's not going to be\nmined.\n\n(I don't know if that applies here, just noting the wrinkle)\n\nOn Wed, Aug 10, 2022 at 11:37 AM Eugene Siegel <elzeigel at gmail.com> wrote:\n\n> Hi,\n>\n> I think the ancestor bulking variant of pinning only matters if you are\n> trying to add a new descendant and can't due to the ancestor/descendant\n> limits. In this  example, since all of the outputs are locked with `1\n> OP_CSV`, you can't add a descendant to the splice tx. The ancestor bulking\n> also shouldn't matter for RBF since you wouldn't be replacing any of the\n> ancestors, only the splice tx. I think it might matter if the new funding\n> output isn't encumbered.\n>\n> The new funding output can't have `1 OP_CSV` unless we also change the\n> commit tx format, and I'm not sure if it would work. The commit tx has the\n> disable bit set in nSequence so it isn't compatible with the sequence lock.\n> Enabling the bit might be tricky since then the commit tx may have a\n> time-based or block-based locktime based on the lower bits of the obscured\n> commitment number, and it must be block-based (and non-zero) for the\n> sequence lock to work. That means if it's not encumbered, pinning exists\n> since an attacker can make a junk tree using the anchor output. It is\n> replaceable using RBF since you have your own commit tx (with anchor) to\n> broadcast.\n>\n> Eugene\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220810/cedb54f6/attachment.html>"
            },
            {
                "author": "Eugene Siegel",
                "date": "2022-08-10T16:20:10",
                "message_text_only": "Looking it up, rule 3 is \"The replacement transaction pays an absolute fee\nof at least the sum paid by the original transactions.\" but here the\nancestors aren't getting replaced so I don't think the replacement has to\npay for them? Or maybe your comment was just generally about how it can\nmatter in certain cases\n\nOn Wed, Aug 10, 2022 at 12:06 PM Greg Sanders <gsanders87 at gmail.com> wrote:\n\n> > I think the ancestor bulking variant of pinning only matters if you are\n> trying to add a new descendant and can't due to the ancestor/descendant\n> limits.\n>\n> Not quite. It also matters if you want to RBF that transaction, since low\n> feerate ancestor junk puts the transaction at the bottom of the mempool, so\n> to speak, even if it has a high feerate itself. You are forced to pay \"full\n> freight\" to replace it via bip125 rule#3 even though it's not going to be\n> mined.\n>\n> (I don't know if that applies here, just noting the wrinkle)\n>\n> On Wed, Aug 10, 2022 at 11:37 AM Eugene Siegel <elzeigel at gmail.com> wrote:\n>\n>> Hi,\n>>\n>> I think the ancestor bulking variant of pinning only matters if you are\n>> trying to add a new descendant and can't due to the ancestor/descendant\n>> limits. In this  example, since all of the outputs are locked with `1\n>> OP_CSV`, you can't add a descendant to the splice tx. The ancestor bulking\n>> also shouldn't matter for RBF since you wouldn't be replacing any of the\n>> ancestors, only the splice tx. I think it might matter if the new funding\n>> output isn't encumbered.\n>>\n>> The new funding output can't have `1 OP_CSV` unless we also change the\n>> commit tx format, and I'm not sure if it would work. The commit tx has the\n>> disable bit set in nSequence so it isn't compatible with the sequence lock.\n>> Enabling the bit might be tricky since then the commit tx may have a\n>> time-based or block-based locktime based on the lower bits of the obscured\n>> commitment number, and it must be block-based (and non-zero) for the\n>> sequence lock to work. That means if it's not encumbered, pinning exists\n>> since an attacker can make a junk tree using the anchor output. It is\n>> replaceable using RBF since you have your own commit tx (with anchor) to\n>> broadcast.\n>>\n>> Eugene\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220810/d2cd3edd/attachment.html>"
            },
            {
                "author": "Greg Sanders",
                "date": "2022-08-10T16:31:20",
                "message_text_only": "Your reading is correct.\n\nMy example was that if TxB, size 100vB with feerate 1000 sat/vbyte, has an\n100kvB ancestor paying 1 sat/vbyte. The effective package rate for those\ntwo transactions will be (100*1,000 + 100,000*1)/(100,000 + 100) = ~2\nsat/vybte\n\nThis means TxB will not be picked up if the prevailing rate is > 2\nsat/byte.  Let's say it's 4 sat/vbyte prevailing rate. To replace it with\nTxB', one still has to pay to evict TxB, at roughly 1000/4=250 times the\nnormal feerate.\n\nSorry if I got the math wrong here, but at least trying to get the idea\nacross.\n\nOn Wed, Aug 10, 2022 at 12:20 PM Eugene Siegel <elzeigel at gmail.com> wrote:\n\n> Looking it up, rule 3 is \"The replacement transaction pays an absolute fee\n> of at least the sum paid by the original transactions.\" but here the\n> ancestors aren't getting replaced so I don't think the replacement has to\n> pay for them? Or maybe your comment was just generally about how it can\n> matter in certain cases\n>\n> On Wed, Aug 10, 2022 at 12:06 PM Greg Sanders <gsanders87 at gmail.com>\n> wrote:\n>\n>> > I think the ancestor bulking variant of pinning only matters if you are\n>> trying to add a new descendant and can't due to the ancestor/descendant\n>> limits.\n>>\n>> Not quite. It also matters if you want to RBF that transaction, since low\n>> feerate ancestor junk puts the transaction at the bottom of the mempool, so\n>> to speak, even if it has a high feerate itself. You are forced to pay \"full\n>> freight\" to replace it via bip125 rule#3 even though it's not going to be\n>> mined.\n>>\n>> (I don't know if that applies here, just noting the wrinkle)\n>>\n>> On Wed, Aug 10, 2022 at 11:37 AM Eugene Siegel <elzeigel at gmail.com>\n>> wrote:\n>>\n>>> Hi,\n>>>\n>>> I think the ancestor bulking variant of pinning only matters if you are\n>>> trying to add a new descendant and can't due to the ancestor/descendant\n>>> limits. In this  example, since all of the outputs are locked with `1\n>>> OP_CSV`, you can't add a descendant to the splice tx. The ancestor bulking\n>>> also shouldn't matter for RBF since you wouldn't be replacing any of the\n>>> ancestors, only the splice tx. I think it might matter if the new funding\n>>> output isn't encumbered.\n>>>\n>>> The new funding output can't have `1 OP_CSV` unless we also change the\n>>> commit tx format, and I'm not sure if it would work. The commit tx has the\n>>> disable bit set in nSequence so it isn't compatible with the sequence lock.\n>>> Enabling the bit might be tricky since then the commit tx may have a\n>>> time-based or block-based locktime based on the lower bits of the obscured\n>>> commitment number, and it must be block-based (and non-zero) for the\n>>> sequence lock to work. That means if it's not encumbered, pinning exists\n>>> since an attacker can make a junk tree using the anchor output. It is\n>>> replaceable using RBF since you have your own commit tx (with anchor) to\n>>> broadcast.\n>>>\n>>> Eugene\n>>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220810/7ae290f0/attachment-0001.html>"
            },
            {
                "author": "Eugene Siegel",
                "date": "2022-08-10T18:03:14",
                "message_text_only": "I quickly looked it up and it seems that bitcoind has a function\nPaysMoreThanConflicts which checks that the tx pays a higher feerate than\nthe replaced tx. This isn't a BIP125 rule AFAICT so I think that's what\ntripped me up. That means I'm wrong about the ancestor bulking variant as a\nmalicious counterparty can put a high feerate splice tx at the bottom of\nthe mempool, requiring a higher feerate to replace it.\n\nOn Wed, Aug 10, 2022 at 12:31 PM Greg Sanders <gsanders87 at gmail.com> wrote:\n\n> Your reading is correct.\n>\n> My example was that if TxB, size 100vB with feerate 1000 sat/vbyte, has an\n> 100kvB ancestor paying 1 sat/vbyte. The effective package rate for those\n> two transactions will be (100*1,000 + 100,000*1)/(100,000 + 100) = ~2\n> sat/vybte\n>\n> This means TxB will not be picked up if the prevailing rate is > 2\n> sat/byte.  Let's say it's 4 sat/vbyte prevailing rate. To replace it with\n> TxB', one still has to pay to evict TxB, at roughly 1000/4=250 times the\n> normal feerate.\n>\n> Sorry if I got the math wrong here, but at least trying to get the idea\n> across.\n>\n> On Wed, Aug 10, 2022 at 12:20 PM Eugene Siegel <elzeigel at gmail.com> wrote:\n>\n>> Looking it up, rule 3 is \"The replacement transaction pays an absolute\n>> fee of at least the sum paid by the original transactions.\" but here the\n>> ancestors aren't getting replaced so I don't think the replacement has to\n>> pay for them? Or maybe your comment was just generally about how it can\n>> matter in certain cases\n>>\n>> On Wed, Aug 10, 2022 at 12:06 PM Greg Sanders <gsanders87 at gmail.com>\n>> wrote:\n>>\n>>> > I think the ancestor bulking variant of pinning only matters if you\n>>> are trying to add a new descendant and can't due to the ancestor/descendant\n>>> limits.\n>>>\n>>> Not quite. It also matters if you want to RBF that transaction, since\n>>> low feerate ancestor junk puts the transaction at the bottom of the\n>>> mempool, so to speak, even if it has a high feerate itself. You are forced\n>>> to pay \"full freight\" to replace it via bip125 rule#3 even though it's not\n>>> going to be mined.\n>>>\n>>> (I don't know if that applies here, just noting the wrinkle)\n>>>\n>>> On Wed, Aug 10, 2022 at 11:37 AM Eugene Siegel <elzeigel at gmail.com>\n>>> wrote:\n>>>\n>>>> Hi,\n>>>>\n>>>> I think the ancestor bulking variant of pinning only matters if you are\n>>>> trying to add a new descendant and can't due to the ancestor/descendant\n>>>> limits. In this  example, since all of the outputs are locked with `1\n>>>> OP_CSV`, you can't add a descendant to the splice tx. The ancestor bulking\n>>>> also shouldn't matter for RBF since you wouldn't be replacing any of the\n>>>> ancestors, only the splice tx. I think it might matter if the new funding\n>>>> output isn't encumbered.\n>>>>\n>>>> The new funding output can't have `1 OP_CSV` unless we also change the\n>>>> commit tx format, and I'm not sure if it would work. The commit tx has the\n>>>> disable bit set in nSequence so it isn't compatible with the sequence lock.\n>>>> Enabling the bit might be tricky since then the commit tx may have a\n>>>> time-based or block-based locktime based on the lower bits of the obscured\n>>>> commitment number, and it must be block-based (and non-zero) for the\n>>>> sequence lock to work. That means if it's not encumbered, pinning exists\n>>>> since an attacker can make a junk tree using the anchor output. It is\n>>>> replaceable using RBF since you have your own commit tx (with anchor) to\n>>>> broadcast.\n>>>>\n>>>> Eugene\n>>>> _______________________________________________\n>>>> Lightning-dev mailing list\n>>>> Lightning-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>>\n>>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220810/547ba05f/attachment.html>"
            },
            {
                "author": "Greg Sanders",
                "date": "2022-08-10T18:11:36",
                "message_text_only": "In this vector, I'm pretty sure feerate/total fee pinning is the same\nissue. Even if you don't have to increase feerate, you have to pay for\n100*1000=100,000 sats due to rule#3.\n\nThere's been some work trying to document the exact replacement behavior\nimplemented in core since it has drifted so much, and the feerate one would\nbe \"rule#6\" in the doc:\nhttps://github.com/bitcoin/bitcoin/blob/master/doc/policy/mempool-replacements.md\n\nMaking sure inputs are confirmed completely mitigates this, so I'm guessing\nit's not much of an issue.\n\n\nOn Wed, Aug 10, 2022 at 2:03 PM Eugene Siegel <elzeigel at gmail.com> wrote:\n\n> I quickly looked it up and it seems that bitcoind has a function\n> PaysMoreThanConflicts which checks that the tx pays a higher feerate than\n> the replaced tx. This isn't a BIP125 rule AFAICT so I think that's what\n> tripped me up. That means I'm wrong about the ancestor bulking variant as a\n> malicious counterparty can put a high feerate splice tx at the bottom of\n> the mempool, requiring a higher feerate to replace it.\n>\n> On Wed, Aug 10, 2022 at 12:31 PM Greg Sanders <gsanders87 at gmail.com>\n> wrote:\n>\n>> Your reading is correct.\n>>\n>> My example was that if TxB, size 100vB with feerate 1000 sat/vbyte, has\n>> an 100kvB ancestor paying 1 sat/vbyte. The effective package rate for those\n>> two transactions will be (100*1,000 + 100,000*1)/(100,000 + 100) = ~2\n>> sat/vybte\n>>\n>> This means TxB will not be picked up if the prevailing rate is > 2\n>> sat/byte.  Let's say it's 4 sat/vbyte prevailing rate. To replace it with\n>> TxB', one still has to pay to evict TxB, at roughly 1000/4=250 times the\n>> normal feerate.\n>>\n>> Sorry if I got the math wrong here, but at least trying to get the idea\n>> across.\n>>\n>> On Wed, Aug 10, 2022 at 12:20 PM Eugene Siegel <elzeigel at gmail.com>\n>> wrote:\n>>\n>>> Looking it up, rule 3 is \"The replacement transaction pays an absolute\n>>> fee of at least the sum paid by the original transactions.\" but here the\n>>> ancestors aren't getting replaced so I don't think the replacement has to\n>>> pay for them? Or maybe your comment was just generally about how it can\n>>> matter in certain cases\n>>>\n>>> On Wed, Aug 10, 2022 at 12:06 PM Greg Sanders <gsanders87 at gmail.com>\n>>> wrote:\n>>>\n>>>> > I think the ancestor bulking variant of pinning only matters if you\n>>>> are trying to add a new descendant and can't due to the ancestor/descendant\n>>>> limits.\n>>>>\n>>>> Not quite. It also matters if you want to RBF that transaction, since\n>>>> low feerate ancestor junk puts the transaction at the bottom of the\n>>>> mempool, so to speak, even if it has a high feerate itself. You are forced\n>>>> to pay \"full freight\" to replace it via bip125 rule#3 even though it's not\n>>>> going to be mined.\n>>>>\n>>>> (I don't know if that applies here, just noting the wrinkle)\n>>>>\n>>>> On Wed, Aug 10, 2022 at 11:37 AM Eugene Siegel <elzeigel at gmail.com>\n>>>> wrote:\n>>>>\n>>>>> Hi,\n>>>>>\n>>>>> I think the ancestor bulking variant of pinning only matters if you\n>>>>> are trying to add a new descendant and can't due to the ancestor/descendant\n>>>>> limits. In this  example, since all of the outputs are locked with `1\n>>>>> OP_CSV`, you can't add a descendant to the splice tx. The ancestor bulking\n>>>>> also shouldn't matter for RBF since you wouldn't be replacing any of the\n>>>>> ancestors, only the splice tx. I think it might matter if the new funding\n>>>>> output isn't encumbered.\n>>>>>\n>>>>> The new funding output can't have `1 OP_CSV` unless we also change the\n>>>>> commit tx format, and I'm not sure if it would work. The commit tx has the\n>>>>> disable bit set in nSequence so it isn't compatible with the sequence lock.\n>>>>> Enabling the bit might be tricky since then the commit tx may have a\n>>>>> time-based or block-based locktime based on the lower bits of the obscured\n>>>>> commitment number, and it must be block-based (and non-zero) for the\n>>>>> sequence lock to work. That means if it's not encumbered, pinning exists\n>>>>> since an attacker can make a junk tree using the anchor output. It is\n>>>>> replaceable using RBF since you have your own commit tx (with anchor) to\n>>>>> broadcast.\n>>>>>\n>>>>> Eugene\n>>>>> _______________________________________________\n>>>>> Lightning-dev mailing list\n>>>>> Lightning-dev at lists.linuxfoundation.org\n>>>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>>>\n>>>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220810/ab81a7c1/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Splice Pinning Prevention w/o Anchors",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Greg Sanders",
                "Dustin Dettmer",
                "Eugene Siegel"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 22348
        }
    },
    {
        "title": "[Lightning-dev] Lightning-dev Digest, Vol 83, Issue 11",
        "thread_messages": [
            {
                "author": "airam at gta.ufrj.br",
                "date": "2022-08-09T21:44:35",
                "message_text_only": "26 de Julho de 2022 09:00, lightning-dev-request at lists.linuxfoundation.org escreveu:\n\n> Send Lightning-dev mailing list submissions to\n> lightning-dev at lists.linuxfoundation.org\n> \n> To subscribe or unsubscribe via the World Wide Web, visit\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> or, via email, send a message with subject or body 'help' to\n> lightning-dev-request at lists.linuxfoundation.org\n> \n> You can reach the person managing the list at\n> lightning-dev-owner at lists.linuxfoundation.org\n> \n> When replying, please edit your Subject line so it is more specific\n> than \"Re: Contents of Lightning-dev digest...\"\n> \n> Today's Topics:\n> \n> 1. Re: Onion messages rate-limiting (Bastien TEINTURIER)\n> \n> ----------------------------------------------------------------------\n> \n> Message: 1\n> Date: Tue, 26 Jul 2022 10:16:24 +0200\n> From: Bastien TEINTURIER <bastien at acinq.fr>\n> To: Joost Jager <joost.jager at gmail.com>\n> Cc: lightning-dev <lightning-dev at lists.linuxfoundation.org>\n> Subject: Re: [Lightning-dev] Onion messages rate-limiting\n> Message-ID:\n> <CACdvm3MeeK6RufGQx1OycPX3Jpf58Ko9oZgMUtg2bS5c3JqBrw at mail.gmail.com>\n> Content-Type: text/plain; charset=\"utf-8\"\n> \n> Hey all,\n> \n> Thanks for the comments!\n> Here are a few answers inline to some points that aren't fully addressed\n> yet.\n> \n> @laolu\n> \n>> Another question on my mind is: if this works really well for rate\n> \n> limiting of\n>> onion messages, then why can't we use it for HTLCs as well?\n> \n> Because HTLC DoS is fundamentally different: the culprit isn't always\n> upstream, most of the time it's downstream (holding an HTLC), so back\n> pressure cannot work.\n> \n> Onion messages don't have this issue at all because there's no\n> equivalent to holding an onion message downstream, it doesn't have\n> any impact on previous intermediate nodes.\n> \n> @ariard\n> \n>> as the onion messages routing is source-based, an attacker could\n>> exhaust or reduce targeted onion communication channels to prevent\n>> invoices exchanges between LN peers\n> \n> Can you detail how? That's exactly what this scheme is trying to prevent.\n> This looks similar to Joost's early comment, but I think it's based on a\n> misunderstanding of the proposal (as Joost then acknowledged). Spammers\n> will be statistically penalized, which will allow honest messages to go\n> through. As Joost details below, attackers with perfect information about\n> the state of rate-limits can in theory saturate links, but in practice I\n> believe this cannot work for an extended period of time.\n> \n> @joost\n> \n> Cool work with the simulation, thanks!\n> Let us know if that yields other interesting results.\n> \n> Cheers,\n> Bastien\n> \n> Le lun. 11 juil. 2022 ? 11:09, Joost Jager <joost.jager at gmail.com> a ?crit :\n> \n>> On Sun, Jul 10, 2022 at 9:14 PM Matt Corallo <lf-lists at mattcorallo.com>\n>> wrote:\n>> \n>>>> It can also be considered a bad thing that DoS ability is not based on\n>>> a number of messages. It\n>>>> means that for the one time cost of channel open/close, the attacker\n>>> can generate spam forever if\n>>>> they stay right below the rate limit.\n>>> \n>>> I don't see why this is a problem? This seems to assume some kind of\n>>> per-message cost that nodes\n>>> have to bear, but there is simply no such thing. Indeed, if message spam\n>>> causes denial of service to\n>>> other network participants, this would be an issue, but an attacker\n>>> generating spam from one\n>>> specific location within the network should not cause that, given some\n>>> form of backpressure within\n>>> the network.\n>> \n>> It's more a general observation that an attacker can open a set of\n>> channels in multiple locations once and can use them forever to support\n>> potential attacks. That is assuming attacks aren't entirely thwarted with\n>> backpressure.\n>> \n>>>> Suppose the attacker has enough channels to hit the rate limit on an\n>>> important connection some hops\n>>>> away from themselves. They can then sustain that attack indefinitely,\n>>> assuming that they stay below\n>>>> the rate limit on the routes towards the target connection. What will\n>>> the response be in that case?\n>>>> Will node operators work together to try to trace back to the source\n>>> and take down the attacker?\n>>>> That requires operators to know each other.\n>>> \n>>> No it doesn't, backpressure works totally fine and automatically applies\n>>> pressure backwards until\n>>> nodes, in an automated fashion, are appropriately ratelimiting the source\n>>> of the traffic.\n>> \n>> Turns out I did not actually fully understand the proposal. This version\n>> of backpressure is nice indeed.\n>> \n>> To get a better feel for how it works, I've coded up a simple single node\n>> simulation (\n>> https://gist.github.com/joostjager/bca727bdd4fc806e4c0050e12838ffa3),\n>> which produces output like this:\n>> https://gist.github.com/joostjager/682c4232c69f3c19ec41d7dd4643bb27.\n>> There are a few spammers and one real user. You can see that after some\n>> time, the spammers are all throttled down and the user packets keep being\n>> handled.\n>> \n>> If you add enough spammers, they are obviously still able to hit the next\n>> hop rate limit and affect the user. But because their incoming limits have\n>> been throttled down, you need a lot of them - depending on the minimum rate\n>> that the node goes down to.\n>> \n>> I am wondering about that spiraling-down effect for legitimate users. Once\n>> you hit the limit, it is decreased and it becomes easier to hit it again.\n>> If you don't adapt, you'll end up with a very low rate. You need to take a\n>> break to recover from that. I guess the assumption is that legitimate users\n>> never end up there, because the rate limits are much much higher than what\n>> they need. Even if they'd occasionally hit a limit on a busy connection,\n>> they can go through a lot of halvings before they'll get close to the rate\n>> that they require and it becomes a problem.\n>> \n>> But how would that work if the user only has a single channel and wants to\n>> retry? I suppose they need to be careful to use a long enough delay to not\n>> get into that down-spiral. But how do they determine what is long enough?\n>> Probably not a real problem in practice with network latency etc, even\n>> though a concrete value does need to be picked.\n>> \n>> Spammers are probably also not going to spam at max speed. They'd want to\n>> avoid their rate limit being slashed. In the simulation, I've added a\n>> `perfectSpammers` mode that creates spammers that have complete information\n>> on the state of the rate limiter. Not possible in reality of course. If you\n>> enable this mode, it does get hard for the user. Spammers keep pushing the\n>> limiter to right below the tripping point and an unknowing user trips it\n>> and spirals down. (\n>> https://gist.github.com/joostjager/6eef1de0cf53b5314f5336acf2b2a48a)\n>> \n>> I don't know to what extent spammers without perfect information can still\n>> be smart and optimize their spam rate. They can probably do better than\n>> keep sending at max speed.\n>> \n>> Maybe this is a difference between lightning network and the internet\n>>> that is relevant for this\n>>>> discussion. That routers on the internet know each other and have\n>>> physical links between them, where\n>>>> as in lightning ties can be much looser.\n>>> \n>>> No? The internet does not work by ISPs calling each other up on the phone\n>>> to apply backpressure\n>>> manually whenever someone sends a lot of traffic? If anything lightning\n>>> ties between nodes are much,\n>>> much stronger than ISPs on the internet - you generally are at least\n>>> loosely trusting your peer with\n>>> your money, not just your customer's customer's bits.\n>> \n>> Haha, okay, yes, I actually don't know what ISPs do in case of DoS\n>> attacks. Just trying to find differences between lightning and the internet\n>> that could be relevant for this discussion.\n>> \n>> Seems to me that lightning's onion routing makes it hard to trace back to\n>> the source without node operators calling each other up. Harder than it is\n>> on the internet. Of course if backpressure works, you don't need to trace\n>> nothing so it all doesn't matter.\n>> \n>> Another question on my mind is: if this works really well for rate\n>>> limiting of\n>>>> onion messages, then why can't we use it for HTLCs as well?\n>> \n>> We do? 400-some-odd HTLCs in flight at once is a *really* tight rate\n>>> limit, even! Order of\n>>> magnitudes tighter than onion message rate limits need to be :)\n>> \n>> What we don't yet do is create backpressure on the incoming channels by\n>> lowering the `max_pending_htlc` limit dynamically.\n>> \n>> The idea could also be extended to htlc forwarding rate limiters, to\n>> combat short-lived htlc spam.\n>> \n>> Joost\n> \n> -------------- next part --------------\n> An HTML attachment was scrubbed...\n> URL:\n> <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220726/c52eaf33/attachment-0\n> 01.html>\n> \n> ------------------------------\n> \n> Subject: Digest Footer\n> \n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> \n> ------------------------------\n> \n> End of Lightning-dev Digest, Vol 83, Issue 11\n> *********************************************\n\n-- \n\nLucas Airam C. de Souza\nM.Sc. student at GTA/PEE/COPPE\nUniversidade Federal do Rio de Janeiro\n\nhttp://www.gta.ufrj.br/~airam"
            }
        ],
        "thread_summary": {
            "title": "Lightning-dev Digest, Vol 83, Issue 11",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "airam at gta.ufrj.br"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 9478
        }
    },
    {
        "title": "[Lightning-dev] Advances in Channel Jamming research",
        "thread_messages": [
            {
                "author": "Antoine Riard",
                "date": "2022-08-17T13:29:43",
                "message_text_only": "Gleb Naumenko and I would like to present our latest research on the\nwell-known channel jamming attacks affecting the Lightning Network. For a\nreminder on the basis of channel jamming, we would like to point to Gleb's\nearlier recollection [0].\n\nWe have a serie of research posts available here:\nhttps://jamming-dev.github.io/book/\n\nThe research is based on Lightning Network data as of March 2022.\n\nHere's the summary.\n\nChapter 1 (The impacts of channel jamming) where we discuss:\n\n   - how the attacker may steal routing fees or target victim's routing\n   reputation;\n   - how the attacker may DoS a goods/service provider;\n   - the monetary implications victims may bear;\n   - how jamming could enhance probing;\n   - how jamming may allow an attacker to drag LN users to other payment\n   solutions.\n\nChapter 2 (Channel jamming costs) where we:\n\n   - discuss the on-chain aspect and the opportunity aspect of attack cost;\n   - describe cost optimizations (looping, rebalancing, targeting\n   surroundings);\n   - notice that the targeted attack costs are currently as low as\n   thousands of satoshis;\n   - notice that attacking the entire network requires locking ~million of\n   sats a month;\n   - discuss how an attacker may compensate for these costs.\n\nChapter 3 (Incremental solutions to channel jamming) where we:\n\n   - analyze several low-effort solutions to jamming (slot bucketing, JIT\n   transaction staging, \"active defence\");\n   - realize their fundamental trade-offs, strong and weak points;\n   - discuss slot bucketing in detail (including \"0-bucket strategy\"), a\n   good solution candidate.\n\nChapter 4 (Solution Design Space) where we:\n\n   - make a broad overview of potential solutions (bonding to a payment;\n   reward/punishment incentives);\n   - identify known and novel families of solutions, discuss their\n   trade-offs;\n   - put them in the context of DLC-over-Lightning and other similar \"LiFi\"\n   protocols.\n\nChapter 5 (Hold-time-dependent bidirectional fee schemes) where we:\n\n   - overview the most advanced Upfront Payment fee scheme and identify the\n   trade-offs;\n   - discuss why it's hard to guarantee a game theoretic balance;\n   - suggest improvements.\n\nChapter 6 (The Reputation Scheme: Stake Certificates + Forwarding Pass)\nwhere we:\n\n   - suggest a reputation-based solution based on the combination of two\n   known ideas;\n   - discuss the associated challenges and the importance of designing a\n   strong reputation policy.\n\nAt the end, we suggest our subjective view on moving forward with this. The\nnext steps could be either working on more solutions (for which, we\nhighlight the potential directions) or choosing one of the already\nsuggested. Among the suggestions, the ecosystem should decide which set of\ntrade-offs (including solution complexity) is acceptable.\n\nThis research should be seen as the synthesis of numerous ideas presented\nby other LN developers over the years, and that we can claim original\nauthorship of really few of them. We made a solid effort to find public\nreferences, though sometimes the ideas have been communicated to us\noffline. If you think we missed mentioning the authorship, please let us\nknow. We also invite the best scrutiny and verification of model\nassumptions and research statements. All mistakes or confusions are our own.\n\nFinally, channel jamming has been one of the oldest high-impact issues\nmentioned in the Lightning space [1]. It's likely that any solution will\nhave long-term impacts on the fundamental economic units of the network,\nand therefore we hope that such solution finds the consensus of the LN\ndeveloment community as a whole.\n\nCheers,\nGleb & Antoine\n\nPS: Thanks to the reviewers\n\n[0] https://blog.bitmex.com/preventing-channel-jamming/\n[1]\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2015-August/000135.html\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220817/98c8cdc5/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Advances in Channel Jamming research",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Antoine Riard"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4004
        }
    },
    {
        "title": "[Lightning-dev] Supporting a custodial user who wishes to withdraw all sats from the account...",
        "thread_messages": [
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2022-08-25T15:49:20",
                "message_text_only": "Dear fellow Lightning Developers,\n\nI was recently on an event where the visitors have been gifted 10k sats on\na custodial wallet. They could spend those sats via some web interface and\nan NFC card. During the event I was contacted by several plebs who were\nconfused about one particular thing:\n\nIt was impossible for them to withdraw the full amount from the service.\n\nPasting an invoice for 10k sats would not work as the custodial service\nrequired a fee budget of 1%. However if people submitted an invoice for\n9900 sats the remaining 100 sats were usually not fully required for the\nfees. Thus the users may have had a leftover of for example 67 sats. Now\nthe problem repeated on the residual amount. While some services seem to\nhave a drain feature for such a situation I find this frustrating and was\nwondering if we could help directly on a protocol level.\n\nHere is my proposal for a simple solution to this specific problem:\n`option_recipient_pays_routing_fees`\n\nThis would be a new flag in invoices signaling that the recipient is\nwilling to pay for the routing fees by releasing the preimage even if the\nfull amount has not been arrived in htlcs at the recipient.\n\nSo the workflow would be the following:\n\n1. Alice creates an invoice for 10k sats setting the\n`option_recipient_pays_routing_fees` flag in the invoice and passes it\neither to custodial user Bob or to her own custodial account.\n2. The payer parses the invoice and searches for a payment path or payment\nflow to Alice.\n3. Because `option_recipient_pays_routing_fee` is set, the onion is not\nconstructed in a way that the final HTLC will be for the amount of 10k sats\nbut rather in a way that the first htlc will be for 10k sats and the\nfollowing HTLCs will be of decreasing value so that routing nodes are\ncompensated properly.\n4. When the HTLC(s) arrive at Alice she will release the preimage if and\nonly if not too many sats (e.g. 1% of the amount) are missing. Of course it\nwould be good if the 1% was not hard coded in the protocol / software but\nconfigurable by Alice at the time of invoice creation.\n\nI think the main issue with this proposal is that instead of confusing\nusers who wish to drain an account we may now have to educate users about\ntwo different invoice types. On the other hand I think this can probably\neasily be achieved via the current wide spread user interfaces. Of course\nit may be nice to have folks from the Bitcoin Design community to join this\nspecific part of the discussion.\n\nWith kind regards Rene Pickhardt\n-- \nhttps://www.rene-pickhardt.de\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220825/400b3ecc/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2022-08-27T02:06:27",
                "message_text_only": "Good morning Rene,\n\n> Dear fellow Lightning Developers,\n> \n> I was recently on an event where the visitors have been gifted 10k sats on a custodial wallet. They could spend those sats via some web interface and an NFC card. During the event I was contacted by several plebs who were confused about one particular thing:\n> It was impossible for them to withdraw the full amount from the service.\n> \n> Pasting an invoice for 10k sats would not work as the custodial service required a fee budget of 1%. However if people submitted an invoice for 9900 sats the remaining 100 sats were usually not fully required for the fees. Thus the users may have had a leftover of for example 67 sats. Now the problem repeated on the residual amount. While some services seem to have a drain feature for such a situation I find this frustrating and was wondering if we could help directly on a protocol level.\n> \n> Here is my proposal for a simple solution to this specific problem: `option_recipient_pays_routing_fees`\n> \n> This would be a new flag in invoices signaling that the recipient is willing to pay for the routing fees by releasing the preimage even if the full amount has not been arrived in htlcs at the recipient.\n> \n> So the workflow would be the following:\n> \n> 1. Alice creates an invoice for 10k sats setting the `option_recipient_pays_routing_fees` flag in the invoice and passes it either to custodial user Bob or to her own custodial account.\n> 2. The payer parses the invoice and searches for a payment path or payment flow to Alice.\n> 3. Because `option_recipient_pays_routing_fee` is set, the onion is not constructed in a way that the final HTLC will be for the amount of 10k sats but rather in a way that the first htlc will be for 10k sats and the following HTLCs will be of decreasing value so that routing nodes are compensated properly.\n> 4. When the HTLC(s) arrive at Alice she will release the preimage if and only if not too many sats (e.g. 1% of the amount) are missing. Of course it would be good if the 1% was not hard coded in the protocol / software but configurable by Alice at the time of invoice creation.\n> \n> I think the main issue with this proposal is that instead of confusing users who wish to drain an account we may now have to educate users about two different invoice types. On the other hand I think this can probably easily be achieved via the current wide spread user interfaces. Of course it may be nice to have folks from the Bitcoin Design community to join this specific part of the discussion.\n\nIn theory, trampoline routes / whatever-the-cool-name-is-now should fix this problem as well.\nI am referring to that scheme where the invoice contains an onion and a \"trampoline\" node that is the only node that can decrypt the first layer of the onion.\nThe sender then has to route to the trampoline node, and the trampoline node then receives the rest of the onion.\n\nIn this scheme, the receiver provides an encrypted route from some node to itself.\nAs the receiver provides the route in order to gain privacy from the sender, the onus is on the receiver to deduct the fees from its received funds.\ni.e. the sender is only responsible for paying for fees up to the entry point of the trampoline.\n\nThus, such a drain requirement simply means that the custodial service has to give its node ID.\nThen the receiver finds a route from the custodial service to itself, and encodes that in the trampoline onion, with a direct neighbor of the custodial service node as the trampoline.\nThe custodial service then does not care about any fees as the receiver decided the route; the receiver knows exactly how much to expect (since it calculated the route).\n\n\nOf course, it is also possible as you propose, but any level-1-selfish custodial service will then always keep the remaining fee budget and always ensure that the receiver gets 99% of the value (or 100% - whatever_setting_they_chose), paying fees, and keeping the remaining 1% for itself.\nThe receiver in this case cannot audit the route anyway, and thus cannot determine how much the true fees are; whereas in the trampoline case the route is specifically selected by the receiver.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Martin Habov\u0161tiak",
                "date": "2022-08-31T17:22:52",
                "message_text_only": "Hi folks,\n\nI think I've seen wallets supporting \"send max\" when a zero-amount invoice\nwas used. So isn't it a problem with the custodial service not supporting\nit?\nWhatever idea we figure out they can just refuse to implement it so we\ncan't force them into improving and being custodial they could steal\nalready, so that shouldn't be an issue.\n\nHave a nice day!\nMartin\n\nOn Sat, 27 Aug 2022 at 04:06, ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Rene,\n>\n> > Dear fellow Lightning Developers,\n> >\n> > I was recently on an event where the visitors have been gifted 10k sats\n> on a custodial wallet. They could spend those sats via some web interface\n> and an NFC card. During the event I was contacted by several plebs who were\n> confused about one particular thing:\n> > It was impossible for them to withdraw the full amount from the service.\n> >\n> > Pasting an invoice for 10k sats would not work as the custodial service\n> required a fee budget of 1%. However if people submitted an invoice for\n> 9900 sats the remaining 100 sats were usually not fully required for the\n> fees. Thus the users may have had a leftover of for example 67 sats. Now\n> the problem repeated on the residual amount. While some services seem to\n> have a drain feature for such a situation I find this frustrating and was\n> wondering if we could help directly on a protocol level.\n> >\n> > Here is my proposal for a simple solution to this specific problem:\n> `option_recipient_pays_routing_fees`\n> >\n> > This would be a new flag in invoices signaling that the recipient is\n> willing to pay for the routing fees by releasing the preimage even if the\n> full amount has not been arrived in htlcs at the recipient.\n> >\n> > So the workflow would be the following:\n> >\n> > 1. Alice creates an invoice for 10k sats setting the\n> `option_recipient_pays_routing_fees` flag in the invoice and passes it\n> either to custodial user Bob or to her own custodial account.\n> > 2. The payer parses the invoice and searches for a payment path or\n> payment flow to Alice.\n> > 3. Because `option_recipient_pays_routing_fee` is set, the onion is not\n> constructed in a way that the final HTLC will be for the amount of 10k sats\n> but rather in a way that the first htlc will be for 10k sats and the\n> following HTLCs will be of decreasing value so that routing nodes are\n> compensated properly.\n> > 4. When the HTLC(s) arrive at Alice she will release the preimage if and\n> only if not too many sats (e.g. 1% of the amount) are missing. Of course it\n> would be good if the 1% was not hard coded in the protocol / software but\n> configurable by Alice at the time of invoice creation.\n> >\n> > I think the main issue with this proposal is that instead of confusing\n> users who wish to drain an account we may now have to educate users about\n> two different invoice types. On the other hand I think this can probably\n> easily be achieved via the current wide spread user interfaces. Of course\n> it may be nice to have folks from the Bitcoin Design community to join this\n> specific part of the discussion.\n>\n> In theory, trampoline routes / whatever-the-cool-name-is-now should fix\n> this problem as well.\n> I am referring to that scheme where the invoice contains an onion and a\n> \"trampoline\" node that is the only node that can decrypt the first layer of\n> the onion.\n> The sender then has to route to the trampoline node, and the trampoline\n> node then receives the rest of the onion.\n>\n> In this scheme, the receiver provides an encrypted route from some node to\n> itself.\n> As the receiver provides the route in order to gain privacy from the\n> sender, the onus is on the receiver to deduct the fees from its received\n> funds.\n> i.e. the sender is only responsible for paying for fees up to the entry\n> point of the trampoline.\n>\n> Thus, such a drain requirement simply means that the custodial service has\n> to give its node ID.\n> Then the receiver finds a route from the custodial service to itself, and\n> encodes that in the trampoline onion, with a direct neighbor of the\n> custodial service node as the trampoline.\n> The custodial service then does not care about any fees as the receiver\n> decided the route; the receiver knows exactly how much to expect (since it\n> calculated the route).\n>\n>\n> Of course, it is also possible as you propose, but any level-1-selfish\n> custodial service will then always keep the remaining fee budget and always\n> ensure that the receiver gets 99% of the value (or 100% -\n> whatever_setting_they_chose), paying fees, and keeping the remaining 1% for\n> itself.\n> The receiver in this case cannot audit the route anyway, and thus cannot\n> determine how much the true fees are; whereas in the trampoline case the\n> route is specifically selected by the receiver.\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220831/26c6eb67/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Supporting a custodial user who wishes to withdraw all sats from the account...",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Ren\u00e9 Pickhardt",
                "Martin Habov\u0161tiak",
                "ZmnSCPxj"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 12127
        }
    },
    {
        "title": "[Lightning-dev] Core-Lightning Release v0.12.0 [Web 8-init]",
        "thread_messages": [
            {
                "author": "lisa neigut",
                "date": "2022-08-31T09:13:26",
                "message_text_only": "We're pleased to announce the 0.12.0 release of core-lightning, named by\n@adi2011.\n\n**Developers**: please note the Great Msat Migration in the APIs!\n\n## Highlights for Users\n\n- *NEW* Built-in `bookkeeper` plugin! This plugin tracks all movements of\nmsats for your node, gives you a better idea of your costs and revenues,\nprints out CSVs that are uploadable to Koinly and CoinTracker, lets you\ninspect the on-chain footprint of a channel (useful when it goes to chain).\nCheck out the new `bkpr-` prefixed commands.\n- *NEW* Built-in `commando` plugin! This lets you create runes to allow\naccess to your node from a commando client, which will let you send and\nreceive RPC commands over the lightning network.\n- *NEW* Emergency channel backup (\"static backup\")! Keep track of what\npeers you have channels with, and in case of node failure ask those peers\nto close the channel.\n- *NEW* zeroconf channels are possible for whitelisted peers.\n- `hsmtool` has a new command, `checkhsm`, which will let you check a BIP30\npassphrase against the `hsm_secret`.\n- Multiple `log-file` options will open multiple files for logging.\n- Various crashes and issues fixed in `connectd` including crash on peer\nreconnect and large memory usage when many concurrent peers.\n- PSBT: fixes signature encoding to comply with BIP-0174.\n- We added dynamically detected public IP addresses to `getinfo`.\n- Due to dependency issues on some platforms, a tarball of pre-generated\nmanual pages is included with this release.\n\n\n## Highlights for the Network\n\n- We prefer IPv6 connections when available.\n- We now accept spam gossip and use it for routing, but don't relay it.\n- We no longer create gossip messages with zlib encoding (but still\nunderstand them).\n- We treat LND \"internal error\" as warnings, not force close events\n(reverts to v0.10.0 behavior).\n\n\n## Highlights for Developers\n\n- `_msat` fields are added wherever they were missing in the API: they're\nstill currently an \"msat\"-suffixed string, but will soon bean integer\nvalue. Test with deprecated_apis=false.\n- The `channel_state_changed` notification now fires when a channel moves\ninto state `CHANNELD_AWAITING_LOCKIN`.\n- `htlc_accepted_hook` will now expose the `short_channel_id` and the\nper-channel HTLC `id`.\n- `pyln-testing` now includes utilities to read and parse the gossip\\_store.\n- `startup_regtest.sh` script now includes a `fund_ln` method.\n- Rust binaries such as `cln-grpc` now included in our reproducible builds.\n- Updated the bolts implementation for pyln-spec.\n- Plugins no longer hang indefinitely if `lightningd` closes their\nconnection.\n- M1 architecture support.\n- Upgrade docker base image from Debian buster to bullseye, works with\nglibc 2.29+.\n- Docker images now built with rust plugin `cln-grpc`.\n\n\nSince v0.11.1 we've had 508 commits from 31 different contributors over 80\ndays.\n\nA special thanks goes to 9 first time contributors:\n\n- Aditya Sharma\n- Alex Myers\n- Igor Bubelov\n- Justin Moon\n- Peter Neuroth\n- Swapnil\n- Jose A.P.\n- Brian Barto\n- AutonomoousOrganization\n\n\n~ @niftynei, Christian, and Rusty\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20220831/99bcad9e/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Core-Lightning Release v0.12.0 ",
            "categories": [
                "Lightning-dev",
                "Web 8-init"
            ],
            "authors": [
                "lisa neigut"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3255
        }
    }
]