[
    {
        "title": "[Lightning-dev] LN Summit 2021 Notes & Summary/Commentary",
        "thread_messages": [
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2021-11-03T02:19:04",
                "message_text_only": "Hi y'all,\n\nA few weeks ago over a dozen Lightning developers met up in Zurich for two\ndays to discuss a number of matters related to the current state and\nevolution of the protocol. All major implementations were represented to\nsome degree, and we even had a number of \"independent\"\ndevelopers/researchers join (in person or via a video call) as well.\n\nWhat follows is my best attempt at summarizing (and inserting any relevant\ndetails I forgot to write down, along with a bit of commentary) the set of\nnotes I took during the sessions.  I'm no Kanzure, so I wasn't able to fully\ncapture all the relevant conversations/topics, so what follows is my best\nattempt at cataloguing the most relevant conversations. If you attended and\nfelt I missed out on a key point, or inadvertently misrepresented a\nstatement/idea, please feel free to reply correcting or adding additional\ndetail.\n\nThe meeting notes in full can be found here:\nhttps://docs.google.com/document/d/1fPyjIUNkc9W1DPyMQ81isiv1fKDW9n7b0H6sObQ-QfU/edit?usp=sharing\n\n# Taproot x PTLC x LN\n\nOne of the first larger sessions that kicked off was dedicated to discussing\nvarious paths/proposals to upgrading the entire network to taproot based\nchannels and upgrading the current hash based e2e payment mechanisms (HTLCs)\nto instead be based on EC keys (PTLC utilizing adapter sigs, etc). Taproot\nis desirable as it allows most operations (funding, co-op close, certain\nsweep types, etc) to blend in with normal transactions (once uptake is high\nenough). The addition of schnorr sigs into the protocol alongside taproot\nsignificantly expands the design space of off-chain protocols as it allows\nthe deployment of certain types of scriptless script based adapter\nsignatures. Namely, the PTLC concept that does away with the current\nhash-baed HTLCs, and gives us better privacy + compostability.\n\n## Big Bang vs Iterative Deployment\n\nRecently aj published [4] a proposal for a taproot upgrade that incorporates\nseveral ideas into a single package, with the goal of doing a single large\nupdate to upgrade the network in one swoop. The proposal includes: an\nupgrade to taproot, revising all the scripts we used to be more taprooty and\nscriptless scripty, a base new revocation mechanism for punishment based\nchannels, an instantiation of PTLCs, a new commitment state update machine\n(as it uses symmetric state like eltoo), a new layer commitment structure\nmeant to alleviate a trade-off of symmetric state/eltoo related to CLTV+CSV\ndependencies and ultimately, eltoo itself as well.\n\nA core matter discussed was if we should try to do things in a sort of \"big\nbang\" manner (get everything all at once), or try to roll things out more\niteratively.\n\nPros for the big bang roll out is that we get things all at once, and\nwouldn't need to \"throw away\" any intermediate steps as future ones are\nrolled out. Cons are that it would be, well, a rather big update to the\nentire network, and the core code of all implementations. This would\npotentially be difficult to get right all at once, could take a ton of time\nto properly review the entire protocol, implement, and finally deploy.\n\nAn alternative considered was a more iterative approach. Pros for the\niterative approach would that we'd be able to get some easy wins early on\n(mu-sig based funding outputs as an example) for elements with a smaller\ndesign space. We'd also be able to review the components one at at time,\nwhile making further background progress on the more amorphous aspects of a\ngreater proposal. Cons of the iterative approach is that it would\n_potentially_ take longer than a big bang approach (from start to \"finish\",\nfinish being everything we ever wanted). We'd also potentially need to\n\"abandon\" components as newer ones are proposed to take their place,\npossibly creating technical/code debt. A system for dynamically updating the\nchannel params/format would make this process more streamlined, as with the\nnew channel_type funding feature, we'd be able to incrementally upgrade a\nchannel (to a degree).\n\n### An Potential Iterative Roadmap\n\nThe question of what an iterative roadmap would even look like was brought\nup. A lofty proposal was the following ordering (not binding at all fwiw),\nnote that some of these items can be carried out concurrently:\n\n  1. Mu-Sig\n\n    * The root component everything else relies on. We'd first all implement\n      Mu-Sig 2 (more on that below) and port the current 2-of-2 multi-sig\n      output instead a aggregate key schnorr 2-of-2 output. Along the way\n      we'd do a naive port of the current script set into the tapscript\n      tree. This would mean just porting the scripts as is, with minimal\n      modifications. The main thing we'd need to do is port over all the CMS\n      instances to use CSA (check sig add) instead).\n\n      Note that we'd also likely need to change/modify the current\n      sig/revocation dance to account for proper exchange of nonces, partial\n      signatures, etc. Much of this still needs to be concretely designed.\n\n  2. Native port of scripts into tapscript\n\n    * Next we'd optimize the current set of scripts, rolling them into new\n      tapscript branches as necessary. We'd likely also take a look at\n      miniscript to see how things can be further organized once re-ordered.\n\n  3. PTLCS\n\n    * In this phase we'd start to roll out PTLCs by adding a new node level\n      feature bit, re-working the onion payload, and also the HTLC scripts\n      (and also state machine in the process?). PTLCs only work if the\n      entire path supports it, so it may take some time to get near 100%\n      upgrade of the internal routing network.\n\n  4. New scriptless script revocation mechanisms\n\n    *  Next we'd start to incorporate the new scriptss script based\n       revocation mechanism. At a high level, it does away with the explicit\n       revocation secret reveal and instead bundles it into the normal\n       multi-sig commitment sig transfer using adapter signatures to reveal\n       the revocation secret. See the original proposal, or this paper [1]\n       for further details.\n\n       Note that this step is somewhat optional, as it moves entirely to\n       symmetric state which is nice w.r.t aligning things with the eventual\n       eltoo roll out, but also would require a more significant re-working\n       of the state machine and on-chain handling.\n\n  5. Layer commitments\n\n    * Related to symmetric commitment state and eltoo, this proposes to\nmodify\n      the initial \"update\" transaction to decouple the CLTV+CSV timeouts on\n      HTLCs in a similar manner to our current second-level HTLCs. This is\n      an attempt to mitigate one of the tradeoffs brought about by symmetric\n      state and eltoo.\n\n      Similar to the new revocation mechanism, this is somewhat an optional\n      step as well. The main benefit here is that it would further converge\n      the paths of revocation vs sequence (eltoo) based channels. Assuming\n      revocation channels are still widely in use, they wouldn't necessarily\n      need to adopt this new format at all.\n\n  7. Eltoo\n\n    * Sequence based channels, combines a lot of the above, removes the\n      revocation mechanism from channels, opens things up to multi-party\n      channel design, etc. Last in the sequence as it requires some form of\n      soft-fork update on the base chain.\n\n## Mu-Sig 2\n\nAs a potential first candidate in the iterative taproot roll out process,\nthere was a lot of discussion around where Mu-Sig 2 was: if the libraries\nare ready, if people have already started implementing it, any open design\nquestions, etc. From the discussions, the general conclusion was (note that\nthere was other discussion with developers actively working on the design\nlater in the week) that there still needs to be some standardization work\naround Mu-Sig 2 itself, particularly w.r.t guidance on safe deterministic\nnonce generation.\n\nFor consumers of `secp256k1-zkp`, a PR implementing MuSig2 from an API\nperspective is under active review [2]. From here, it appears the next steps\nwould be attempting to create a BIP around some of the message passing,\nnonce generation, and cicatrization aspects of the protocol when deployed to\na two/multi party setting.\n\nAs the inclusion of MuSig2 would end up modifying the core state machine\n(particularly how new signatures are exchange), some lofty design sketches\nlike piggybacking extra nonces onto the current revoke_and_ack message were\ntossed around, with nothing too concrete being developed during the\nconversations.\n\n### Mu-Sig 2 & Gossip\n\nToday we end up sending 4 signatures whenever we announce a new channel\nannouncement on the network (2 sigs of the multi-sig keys, and 2 sigs of the\nnode keys), using Mu-Sig 2 here in place would allow us to reduce this to a\nsingle signature which makes things slightly more efficient and also saves\nsome space. Given how independent this change was from the core\nchannel/funding changes (can be done today with the existing OG segwit\nchannels), people generally thought this would be a good place to start, as\nit's relatively low risk and help people vet their implementations and\nbecome more comfortable with the new primitives at our disposal.\n\n## PTLCs & The Onion\n\nAside from the core channel level changes, PTLCs are another key development\nbrought about by the activation of taproot. The Surebits team and their\ncollaborators have done a ton of work in this area proving out their concept\nfor their application within the DLC realm. General anointment was that we\nshould be able to build on their work/exploration in designing the\nfinal version for LN itself.\n\nOne thing that needs to be modified is the set of payloads included in the\nonion itself. This doesn't seem to be too big of a lift (nonce and points\nfor the left+right locks, etc), but may end up shrinking the max possible\nroute length a bit, as more space in the onion for a given hop takes away\nfrom the space that can be allocated to later hops. Some ideas were tossed\naround that may help us _save_ some space by re-using the shared secret\nderived for each hop (still needs to be fleshed out some).\n\n# Sync (or slightly more sync?) vs Async Commitment Update State Machines\n\nOne topic that came up a few times was the trade-offs brought about by\nmoving to a _more_ synchronous channel update state machine vs the current\nasync (and potentially fully non-blocking) state machine. When we say sync,\nwe typically mean something that ends up with one or both sides taking turns\nto do updates. This is much simpler than the current fully async update\nstate machine, and appears to be somewhat of a requirement when moving to\nsymmetric channel state (like eltoo does).\n\nAn active proposal to the spec attempts to introduce a 'sftu' message to\nsort of pause things and clear the air for potentially difficult to\nimplement in an async environment enhancements like splicing. Related to\nthat\nis another active proposal that attempts to make the current state machine\nmore sync by adding alternating rounds, which ends up simplifying things\nquite a bit.\n\nRe trade-offs there was discussion w.r.t if one or the other offered\ntheoretical higher transaction rates vs the other. In the end the rough\nconclusion was that both likely end up about the same w.r.t throughput, but\nan async state machine would win over when it comes to latency (as it's more\nnon-blocking, particularly when you allow multiple unrevoked commitments by\nsending more than 1 revocation key at the very start).\n\n# Meta Spec Process Topics\n\nNot _that_ \"Meta\" ;) -- but general discussions around the current process,\nprogress, and priorities of the current spec work.\n\n## IRC vs Video Chats for Spec Meetings\n\nA big topic was the current velocity of active proposals, review\nbandwidth/energy, and just general momentum of the current spec process. A\nfew attendees felt like the move to mostly IRC meetings slowed things down a\nbit, as while it's nice that everything is written down and open access,\ndiscussions tend to drag along, and it's easy to misinterpret a message or\nmiss one during cross chatter. The idea to bring back the video calls was\nbrought up, as many conversations can be hashed out more easily over voice\nvs scattered IRC messages over a 1 hr period. The latest spec meeting had an\noptional video chat that a few people ended up joining. Some ppl have mixed\nfeelings about going back to the calls vs IRC as we lose the transcript, but\nseems the important thing is that the major action items, decisions, and\nfollow up are written down.\n\n# BOLTs, bLIPs, and BOLT Proposals\n\nAs the years have gone on, and the protocol has evolved it's clear that\nthere's just _so much_ stuff to be designed, worked on, and deployed. The\nBOLT system has served us well through the years, but also fallen short at\ntimes when it comes to evolution of the text itself. People seemed to agree\nthat a rough heuristic of what should be in a BOLT is what \"everyone needs\nto agree on\", so core network capabilities like PLTCs. For everything else\nthere're bLIP^TM (which are still in the process of getting off the ground,\nwhich are more descriptive documents that may describe some cool new feature\ndeployed on the edges of the network like custom backup schemes, or async\npayment architectures (like Breez's Lightning Rod).\n\nOn the topic of BOLT evolution, some expressed that the way things have\nevolved it can be hard to reason about what came first, or why certain\nthings are the way they were. A response to this (that has somewhat started\nto catch on), is having a standalone proposals [8] folder that works through\nthe rationale and design space, to be committed alongside a minimal set of\nchanges to the core BOLT document.\n\nRelated to BOLT evolution was the question of: when should a new standalone\ndocument (like BOLT-12/Offers) be created vs extending an existing document?\nThe original idea was to have a logical layering between the numbers to\ncreate clean separation, but over time this principle wasn't fully adhered\nto/communicated, with some documents being more self contained than others.\nIn the past we also attempts to create clear delineations by tagging a\n\"Lighting 1.1\" version, but that never really happened.\n\nSome suggested that we move to a sort of IETF approach, where we have\nmultiple versioned documents that end up copying everything from the prior\nversion, with the new additions (like bgp1, bgp2, etc). This ends up with\nsome copy/past duplication, but allows implementers to just read a single\ndocument from top to bottom and not have to worry about old conditional\nlogic that has been mostly phased out at this point.\n\nRelated to the question of review bandwidth was a topic (tbh not sure I\nfully captured this correctly in the notes) of \"silent dissent\" where by not\nreviewing something it's assumed a contributor doesn't fully support a\nproposal/extension. Some felt this wasn't desirable as it ends up blocking\nproposals, while others were ok with it as they felt if another\nimplementation wasn't ready to pick it up and review it, then maybe it\nwasn't quite yet a BOLT ready extension and needed more review. The\nevolution of onion messages was cited as an example where something sat for\na while, but then was reviewed by another implementation and ended up being\nimproved with lots of good feedback. I don't remember if there was really\nany sort of conclusion here, but some suggested adopting bitcoind's system\nof high priori reviews, which may help, but then again the solution space of\nLN is just so large and multiple things can be worked on independently.\n\nThe session concluded with a call to zoom out a bit, and attempt to tease\nout where we want the spec to be in 5 years or so, then move towards that\nincrementally as a group.\n\n# Onion Messages & Offers\n\nThere was a session on onion messages and the related Offers proposal [5]\nwhere the proposer was able to really dig into a lot of specifics, answer\nquestions on the scope, and tease out a possible staged deployment plan. The\nmain motivation of the design of Offers was to both move us away from the\nawkward bech32 encoding (though it still uses it in certain places?) and\nalso not necessarily require a receiver to be running a web server to be\nable to negotiate the payment. The new invoice format inherits most of the\nfields from BOLT 11, but also adds a pairing key that can be used for\nrefunds (you prove you know the key, it's embedded in the custom invoice\ncreated for your), and also be used to create _unique_ proofs of payment.\n\nIn terms of possible a possible deployment path, there was talk of possible\nleaving out certain features like recurrence, fiat exchange (?), stateless\ninvoices, extra metadata, streaming invoices (allows to not have to fetch a\nnew one each time, but I didn't fully follow the scheme), and just implement\nthe base invoice format w/ the optional interactive invoice creation.\nBridging BOLT 11 and 12 is possible in theory as well, though the custom\nBOLT 12 stuff would need to be left over or like stuffed into some metadata\nfield in BOLT 11.\n\nQuestions of the adoption window were brought up, since some of the\nfunctionality BOLT 12 offers (namely the payment negotiation features) are\nalready implemented and deployed in higher-level protocols like LN-URL (and\nits extensions). So new developers/services need to be won over and\nconvinced to adopt the new system, given they already have alternatives\ndeployed that worked mostly _outside_ the protocol to achieve the\nfunctionality. Some found the lack of tight integration to the web layer as\na plus (for BOLT 12), but others weren't really sure it was a big deal given\nmost services these days are already web based. There was also brief\ndiscussion of BOLT12address [9], which emulates some of the LN Address\nfunctionality, but handles certs in a slightly different manner (?).\n\n# Boomerang, \"Stuckless\" Payments, and Payment Level ACKs\n\nRelated to the PTLC conversation is if we want to (from the start)\nincorporate some of the techniques that allows safe payment retry on the\nnetwork layer by enforcing a sort of 2-phase settlement protocol where the\nsender doesn't allow redundant/repeated payments to be fulfilled. The\noriginal Boomerang [6] scheme was based on a VSS (verifiable secret sharing\nprotocol) to enforce a penalty if the remote party fulls too many shards.\nStuckless [7] in comparison adds another round of iteration and ends up\nbeing slightly simpler.\n\nAt a higher level, there was discussion of if this sort of over/repeated\npayment scenario really happens all that often in practice, but no one\nseemed to have a good answer. One under explored benefit of the scheme\ndiscussed was that it actually allows you to safely send out current HTLCs\nduring path finding, since you're confident that overpayment isn't possible.\nAMP was also discussed as an alternative way to achieve the same thing,\nthough\nvia that atomicity enforced by the secret sharing scheme.\n\nA related topic was the concept of a payment level ACK, which would give the\nsender valuable feedback of when the HTLC _actually_ arrived at the other\nend. Today senders only know about failures, or when things ultimately all\narrive (settle). Being able to know an HTLC arrived is very valuable\ninformation, as it lets one update their path finding or flow analysis in\nreal time based on information from the receiver.\n\nOne way to achieve this (sorta hacky) would be to send a \"tracer\" HTLC\nthat should be cancelled back once the actual HTLC arrives. However this\nruns into issue of the tracer getting stuck, etc (need to ACK the ACK to\nACK the ACK). A better way would be to utilize onion messages (or a sort of\nsoft error, needs to be written) to allow communication between sender and\nreceiver. It also may be the case that stuckless also naturally gives us\nACKs at this level as well.\n\n# Channel Jamming\n\nAnother topic that evolved into its own track/session was the topic of\nchannel jamming and generally DoS mitigation techniques related to channels.\nSeveral categories of mitigations were disused including: prepaying for\neverything, forwarding passes (similar to Bittorrent like reputation),\nstaking certificates, forwarding level up/down stream reputation, per-node\nVDF based global rate limiting, PoW, viewing the existing HTLC costs as a\nbond, and also extending the current fee equation to also factor in the\nworst-case CLTV delay of an HTLC.\n\nPre/post pay techniques have been discussed extensively on the mailing list,\nso I won't go into those and will instead focus on some of the newer\nidea/concepts discussed. Open questions here are mainly surrounding proper\nparametrization (how much should it cost?) and further analysis w.r.t if a\nde minims fee will actually serve to discourage well funded attackers, given\nit's a griefing vector so nothing is gained directly either way.\n\n## Forwarding Passes\n\nThe concept of a \"forwarding\" pass was introduced/discussed, which\neffectively is a per-node sort of rep currency created using symmetric\ncrypto (think of it as a symmetrically encrypted metadata blob). In order\nto route through a node, one needs to first obtain a freebie pass which is\npassed back via the onion, which requires an initial failed payment or some\nsort of LSP bootstrapping mechanism. From there any successfully forwarded\npayments that include that forwarding pass (possibly to be re-randomized?)\nwould accrue additional attributes/weight/reputation. Essentially you buy\nyour way into the routing graces of a node with successful forwards over\ntime and good behavior.\n\nThe general idea is rather than (attempt) to punish individuals, one should\nattempt to ensure that the network is able to gracefully fallback to a sort\nof reduced operating mode is spam is rampant. As this is a per-node system\n(local), if a node is under high load, they can choose to only observe\npasses that are older than 3 weeks, or only those that have generated a\ncertain amount of routings fees, etc. There would exist no global policy,\nbut instead a local policy that nodes would use to restrict the set of\npermissible traffic sources.\n\nThe downsides of this approach is that a forwarding node is able to\ncorrelate senders to a degree (since the pass it tied to the origin, but\ndoesn't give away information like pub keys, it's a new pseudonymous\nidentifier). Others also cited the similarity to the existing Bittorrent\nreputation system and the difficult of ensuring that a party isn't able to\ncontinually obtain \"freebie\" passes/reputation, thereby by passing the\nentire thing.\n\n## Existing HTLC Costs as a Bond\n\nAnother newer concept discussed/generated/re-oriented during the discussion\nwas viewing the existing HTLC cost as a bond. At times sending HTLCs is\nviewed as being \"costless\"on the network, but sending an HTLC has a direct\ncost: the time value of the coins committed in the HTLC. In the worst case,\nthe sender needs to be ready to wait for the absolute CLTV timeout (which is\nhighest at the sender) to expire before they can claim their funds. When\ncombined with generally higher values for the min_htlc routing policy,\nrouting nodes are able to dictate the minimum bond cost to a sender to\ntransit their node.\n\nThis line of thinking asserts that there already _is_ a cost (both the\nHTLC(s) and the cost to fund and maintain a channel), to attempting to spam\nHTLCs, which seems to have played some role in mitigations (but also that\nthere's no true gain, it's griefing). Extending this concept, it's then\npossible for a node to retroactively raise its minimum bond size (either via\nmin_htlc or applied during forwarding) when its set of commitment slots\nbecomes too saturated. This model would then divide up the available\ncommitment space into different QoS buckets with varying amounts for the\nsmallest HTLC allowed in that slot.\n\nQuestions of if dust would be factored in were brought up, and also to start\nto increase the 483 value as it makes attacks easier and can be raised\nhigher to the policy level limit, as the current setting optimizes for an\nuncommon case (breach with a fully loaded commitment transaction) at the\ncost of throughput and making it easier to fully load a commitment\ntransaction.\n\n## Pricing the HTLC Option Cost using Theta\n\nAnother concept discussed was the fact that today, routing fees don't\naccurately reflect the apparent time value: I pay the same fee for\nusing a 1000 block CLTV as I do for a 20 block CLTV. Many viewed this as an\nincentive issue as if corrected, then longer routes (more CLTV deltas) would\nbe more expensive, which would make certain classes of attacks more\nexpensive as well. In addition it would require services that can end up\nholding HTLCs for a long period of time to pay up front (again increase the\n\"bond value\" as mentioned above) for this duration.\n\nIn terms of a potential roll out, something like this could be naively\nphased in by extending the current fee algorithm we a new scaling term,\ndubbed theta:\n\n  * fee = amt*feeRate + baseFee + (amt*cltvAbsolute*theta)\n\nNote that if `theta` is zero, then it's the same as the current algorithm.\nIncreasing it to one causes fees to scale linearly with the product of the\namount and worst case (absolute) time delay. Rather than a simple\nmultiplicative increase, perhaps some polynomial should be used as a scaling\nfactor here to give node operators more flexibility. By setting certain\ncoefficients to zero, they'd be able to opt out of more aggressive scaling\nif they wished.\n\nWith the way gossip and path finding works today, nodes that want to adopt\nthis scheme could begin to do so by adding a new TLV value that includes the\ntheta field possibly with a required (?) feature bit to indicate senders\n_must_ understand theta.\n\nAn alternative way to phase it in brought up was just to repurpose the\nbaseFee (as some advocates think it should be removed/ignored) to instead be\ninterpreted as this `theta` value.\n\nRelated to this topic are also the channel variants that achieve a \"constant\ntime delay\" with their HTLC mechanism, which allows all participants to have\nthe same time delay and avoid having to increment the worst case delay as\nnew routes are added to the hops.\n\n## Packet Switching\n\nOne of the last group sessions was on the topic of introducing new packet\nswitching operating modes into the network. Compared to the current source\nrouting based method (where the sender selects the entire route), with\npacket switching they'd either specify only a destination (possibly using a\nblinded route, more on that below), or select a series of \"waypoints\" with\nthe intermediate nodes having freedom to select the route as they choose (a\nla certain flavors of trampoline).\n\n### Open Questions w.r.t Trampoline Deployment\n\nThe session kicked up by exploring some of the unanswered questions w.r.t a\nwider production deployment of the trampoline scheme (so far there're only\ntwo (?) trampoline nodes on the network: the main ACINQ mainnet node\nHorizon, and the main Electrum node). One question posited was: do\ntrampoline nodes retry _internally_ within the network, or simply fail back\nafter the first failed routing attempt? Internal network retry has the\nbenefit that in theory a trampoline node has a much better grasp on the\nliquidity distribution within their local network than the sender. However,\nassuming a path has several trampoline nodes within a route, the internal\nretry and _each_ of them has the potential to add considerable latency to a\npayment, and also rob the sender of any information they can use to update\ntheir path/attempt (as they aren't able to receive onion errors from the\nfinal destination as normal).\n\n### Trampoline Incentives & Sender Implications\n\nOther open question included: how a sender was to properly set the fee and\ntime lock budget (and how that affected the effort nodes would take on to\noptimize their fees gain), and how nodes were to be discovered in the first\nplace (for clients that only opted to insert the trampoline nodes into their\nlocal graph). As the graph gets larger, some felt that the existence of\ntrampoline nodes actually encourages routing nodes to maintain the graph as\notherwise, it actually isn't needed for routine forwarding.\n\n### Privacy Implications of Trampoline Nodes\n\nAnother big topic of discussion was the ultimate privacy benefits of\ninserting one or many trampoline nodes into the route. An argument was\npresented that that argued that anything but adding trampoline nodes at the\nstart/end would end up degrading privacy, as the intermediate nodes learn\nthat any nodes that accept the HTLC from them to the next trampoline node\ncould be ruled out as the destination, thereby reducing the anonymity set\nand set of possible/available paths (due to loop attack prevention some\nimplementations like lnd use [3]). Assuming the argument holds, then its\nappears desirable to only use the following configurations (more analysis\nneeded ofc):\n\n  * Single trampoline node at the start: essentially offers delegated path\n    finding. Wallets like Phoenix use this operating mode today.\n\n  * Single trampoline node at the end: gives us the long sought after\n    rendezvous payments, which enhance the current protocol by offering\n    _receiver_ anonymity in addition to the current sender anonymity.\n\n  * Two trampoline nodes, one at the start and one at the end: combines the\n    above operating modes, giving best of both worlds (or just route\n    blinding for the final leg to support payments to unadvertised\n    channels?), while minimizing the anonymity set link as each additional\n    trampoline hop can gain more information w.r.t the prior route up to\n    that point.\n\nGenerally more investigation is needed here to understand the privacy\nimplications of moving to a hybrid onion/packet-switched model. In the end\nthough the fundamental trade-off of privacy vs scalability appears to still\nbe a factor.\n\n\n-- Laolu\n\n[1]: https://eprint.iacr.org/2020/476\n[2]: https://github.com/ElementsProject/secp256k1-zkp/pull/131\n[3]: https://github.com/lightningnetwork/lnd/pull/3915\n[4]:\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2021-October/003278.html\n[5]: https://github.com/lightningnetwork/lightning-rfc/pull/798\n[6]: https://arxiv.org/abs/1910.01834\n[7]:\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2019-June/002029.html\n[8]:\nhttps://github.com/lightningnetwork/lightning-rfc/blob/038575ac38ced9eee5ace09dd5ec9ba7515cad55/proposals/trampoline.md\n[9]: https://github.com/rustyrussell/bolt12address\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211102/2f8bcd52/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "LN Summit 2021 Notes & Summary/Commentary",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Olaoluwa Osuntokun"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 30666
        }
    },
    {
        "title": "[Lightning-dev] Removing lnd's source code from the Lightning specs repository",
        "thread_messages": [
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2021-11-03T02:34:39",
                "message_text_only": "Circling back to close the loop here:\n\n  * The new Github org (https://github.com/lightning) now exists, and all\nthe\n    major implementation maintainers have been added to the organization as\n    admins.\n\n  * A new blips repo (https://github.com/lightning/blips) has been created\nto\n    continue the PR that was originally started in the lightning-rfc\nrepo.\n\n  * The old lightning-rfc repo has been moved over, and been renamed to\n\"bolts\"\n    (https://github.com/lightning/bolts -- should it be all caps? )\n\nThanks to all that participated in the discussion (particularly in meatspace\nduring the recent protocol dev meetup!), happy we were able to resolve\nthings\nand begin the next chapter in the evolution of the Lightning protocol!\n\n-- Laolu\n\n\nOn Fri, Oct 15, 2021 at 1:49 AM Fabrice Drouin <fabrice.drouin at acinq.fr>\nwrote:\n\n> On Tue, 12 Oct 2021 at 21:57, Olaoluwa Osuntokun <laolu32 at gmail.com>\n> wrote:\n> > Also note that lnd has _never_ referred to itself as the \"reference\"\n> > implementation.  A few years ago some other implementations adopted that\n> > title themselves, but have since adopted softer language.\n>\n> I don't remember that but if you're referring to c-lightning it was\n> the first lightning implementation, and the only one for a while, so\n> in a way it was a \"reference\" at the time ?\n> Or it could have been a reference to their policy of \"implementing the\n> spec, all the spec and nothing but the spec\"  ?\n>\n> > I think it's worth briefly revisiting a bit of history here w.r.t the\n> github\n> > org in question. In the beginning, the lightningnetwork github org was\n> > created by Joseph, and the lightningnetwork/paper repo was added, the\n> > manuscript that kicked off this entire thing. Later lightningnetwork/lnd\n> was\n> > created where we started to work on an initial implementation (before the\n> > BOLTs in their current form existed), and we were added as owners.\n> > Eventually we (devs of current impls) all met up in Milan and decided to\n> > converge on a single specification, thus we added the BOLTs to the same\n> > repo, despite it being used for lnd and knowingly so.\n>\n> Yes, work on c-lightning then eclair then lnd all began a long time\n> before the BOLTs process was implemented, and we all set up repos,\n> accounts...\n> I agree that we all inherited things  from the \"pre-BOLTS\" era and\n> changing them will create some friction but I still believe it should\n> be done. You also mentioned potential admin rights issues on the\n> current specs repos which would be solved by moving them to a new\n> clean repo.\n>\n> > As it seems the primary grievance here is collocating an implementation\n> of\n> > Lightning along with the _specification_ of the protocol, and given that\n> the\n> > spec was added last, how about we move the spec to an independent repo\n> owned\n> > by the community? I currently have github.com/lightning, and would be\n> happy\n> > to donate it to the community, or we could create a new org like\n> > \"lightning-specs\" or something similar.\n>\n> Sounds great! github.com/lightning is nice (and I like Damian's idea\n> of using github.com/lightning/bolts) and seems to please everyone so\n> it looks that we have a plan!\n>\n> Fabrice\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211102/c53feb8f/attachment.html>"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2021-11-03T02:36:40",
                "message_text_only": "Oh, also there's currently this sort of placeholder logo from waaay back\nthat's used as the org's avatar/image. Perhaps it's time we roll an\n\"official\" logo/avatar? Otherwise we can just switch over the randomly\ngenerated blocks thingy that Github uses when an account/org has no\navatar.\n\n-- Laolu\n\nOn Tue, Nov 2, 2021 at 7:34 PM Olaoluwa Osuntokun <laolu32 at gmail.com> wrote:\n\n> Circling back to close the loop here:\n>\n>   * The new Github org (https://github.com/lightning) now exists, and all\n> the\n>     major implementation maintainers have been added to the organization as\n>     admins.\n>\n>   * A new blips repo (https://github.com/lightning/blips) has been\n> created to\n>     continue the PR that was originally started in the lightning-rfc\n> repo.\n>\n>   * The old lightning-rfc repo has been moved over, and been renamed to\n> \"bolts\"\n>     (https://github.com/lightning/bolts -- should it be all caps? )\n>\n> Thanks to all that participated in the discussion (particularly in\n> meatspace\n> during the recent protocol dev meetup!), happy we were able to resolve\n> things\n> and begin the next chapter in the evolution of the Lightning protocol!\n>\n> -- Laolu\n>\n>\n> On Fri, Oct 15, 2021 at 1:49 AM Fabrice Drouin <fabrice.drouin at acinq.fr>\n> wrote:\n>\n>> On Tue, 12 Oct 2021 at 21:57, Olaoluwa Osuntokun <laolu32 at gmail.com>\n>> wrote:\n>> > Also note that lnd has _never_ referred to itself as the \"reference\"\n>> > implementation.  A few years ago some other implementations adopted that\n>> > title themselves, but have since adopted softer language.\n>>\n>> I don't remember that but if you're referring to c-lightning it was\n>> the first lightning implementation, and the only one for a while, so\n>> in a way it was a \"reference\" at the time ?\n>> Or it could have been a reference to their policy of \"implementing the\n>> spec, all the spec and nothing but the spec\"  ?\n>>\n>> > I think it's worth briefly revisiting a bit of history here w.r.t the\n>> github\n>> > org in question. In the beginning, the lightningnetwork github org was\n>> > created by Joseph, and the lightningnetwork/paper repo was added, the\n>> > manuscript that kicked off this entire thing. Later\n>> lightningnetwork/lnd was\n>> > created where we started to work on an initial implementation (before\n>> the\n>> > BOLTs in their current form existed), and we were added as owners.\n>> > Eventually we (devs of current impls) all met up in Milan and decided to\n>> > converge on a single specification, thus we added the BOLTs to the same\n>> > repo, despite it being used for lnd and knowingly so.\n>>\n>> Yes, work on c-lightning then eclair then lnd all began a long time\n>> before the BOLTs process was implemented, and we all set up repos,\n>> accounts...\n>> I agree that we all inherited things  from the \"pre-BOLTS\" era and\n>> changing them will create some friction but I still believe it should\n>> be done. You also mentioned potential admin rights issues on the\n>> current specs repos which would be solved by moving them to a new\n>> clean repo.\n>>\n>> > As it seems the primary grievance here is collocating an implementation\n>> of\n>> > Lightning along with the _specification_ of the protocol, and given\n>> that the\n>> > spec was added last, how about we move the spec to an independent repo\n>> owned\n>> > by the community? I currently have github.com/lightning, and would be\n>> happy\n>> > to donate it to the community, or we could create a new org like\n>> > \"lightning-specs\" or something similar.\n>>\n>> Sounds great! github.com/lightning is nice (and I like Damian's idea\n>> of using github.com/lightning/bolts) and seems to please everyone so\n>> it looks that we have a plan!\n>>\n>> Fabrice\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211102/4644941c/attachment.html>"
            },
            {
                "author": "Harsha Goli",
                "date": "2021-11-03T02:46:55",
                "message_text_only": "We could use an identicon, we do that with the lightningnetwork repository.\nAn official logo is probably better - give the project a real symbol.\n\nOn Tue, Nov 2, 2021 at 10:37 PM Olaoluwa Osuntokun <laolu32 at gmail.com>\nwrote:\n\n> Oh, also there's currently this sort of placeholder logo from waaay back\n> that's used as the org's avatar/image. Perhaps it's time we roll an\n> \"official\" logo/avatar? Otherwise we can just switch over the randomly\n> generated blocks thingy that Github uses when an account/org has no\n> avatar.\n>\n> -- Laolu\n>\n> On Tue, Nov 2, 2021 at 7:34 PM Olaoluwa Osuntokun <laolu32 at gmail.com>\n> wrote:\n>\n>> Circling back to close the loop here:\n>>\n>>   * The new Github org (https://github.com/lightning) now exists, and\n>> all the\n>>     major implementation maintainers have been added to the organization\n>> as\n>>     admins.\n>>\n>>   * A new blips repo (https://github.com/lightning/blips) has been\n>> created to\n>>     continue the PR that was originally started in the lightning-rfc\n>> repo.\n>>\n>>   * The old lightning-rfc repo has been moved over, and been renamed to\n>> \"bolts\"\n>>     (https://github.com/lightning/bolts -- should it be all caps? )\n>>\n>> Thanks to all that participated in the discussion (particularly in\n>> meatspace\n>> during the recent protocol dev meetup!), happy we were able to resolve\n>> things\n>> and begin the next chapter in the evolution of the Lightning protocol!\n>>\n>> -- Laolu\n>>\n>>\n>> On Fri, Oct 15, 2021 at 1:49 AM Fabrice Drouin <fabrice.drouin at acinq.fr>\n>> wrote:\n>>\n>>> On Tue, 12 Oct 2021 at 21:57, Olaoluwa Osuntokun <laolu32 at gmail.com>\n>>> wrote:\n>>> > Also note that lnd has _never_ referred to itself as the \"reference\"\n>>> > implementation.  A few years ago some other implementations adopted\n>>> that\n>>> > title themselves, but have since adopted softer language.\n>>>\n>>> I don't remember that but if you're referring to c-lightning it was\n>>> the first lightning implementation, and the only one for a while, so\n>>> in a way it was a \"reference\" at the time ?\n>>> Or it could have been a reference to their policy of \"implementing the\n>>> spec, all the spec and nothing but the spec\"  ?\n>>>\n>>> > I think it's worth briefly revisiting a bit of history here w.r.t the\n>>> github\n>>> > org in question. In the beginning, the lightningnetwork github org was\n>>> > created by Joseph, and the lightningnetwork/paper repo was added, the\n>>> > manuscript that kicked off this entire thing. Later\n>>> lightningnetwork/lnd was\n>>> > created where we started to work on an initial implementation (before\n>>> the\n>>> > BOLTs in their current form existed), and we were added as owners.\n>>> > Eventually we (devs of current impls) all met up in Milan and decided\n>>> to\n>>> > converge on a single specification, thus we added the BOLTs to the same\n>>> > repo, despite it being used for lnd and knowingly so.\n>>>\n>>> Yes, work on c-lightning then eclair then lnd all began a long time\n>>> before the BOLTs process was implemented, and we all set up repos,\n>>> accounts...\n>>> I agree that we all inherited things  from the \"pre-BOLTS\" era and\n>>> changing them will create some friction but I still believe it should\n>>> be done. You also mentioned potential admin rights issues on the\n>>> current specs repos which would be solved by moving them to a new\n>>> clean repo.\n>>>\n>>> > As it seems the primary grievance here is collocating an\n>>> implementation of\n>>> > Lightning along with the _specification_ of the protocol, and given\n>>> that the\n>>> > spec was added last, how about we move the spec to an independent repo\n>>> owned\n>>> > by the community? I currently have github.com/lightning, and would be\n>>> happy\n>>> > to donate it to the community, or we could create a new org like\n>>> > \"lightning-specs\" or something similar.\n>>>\n>>> Sounds great! github.com/lightning is nice (and I like Damian's idea\n>>> of using github.com/lightning/bolts) and seems to please everyone so\n>>> it looks that we have a plan!\n>>>\n>>> Fabrice\n>>>\n>> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211102/063833f5/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-11-03T08:45:13",
                "message_text_only": "Good morning list,\n\n> We could use an identicon, we do that with the lightningnetwork repository. An official logo is\u00a0probably better - give the project a real symbol.\n\nI attached an SVG file I have been working on for some time, for the amusement of all.\n\nIt is unfortunately not square, and is very very simple, as well.\n\nRegards,\nZmnSCPxj\n\n>\n> On Tue, Nov 2, 2021 at 10:37 PM Olaoluwa Osuntokun <laolu32 at gmail.com> wrote:\n>\n> > Oh, also there's currently this sort of placeholder logo from waaay back\n> > that's used as the org's avatar/image. Perhaps it's time we roll an\n> > \"official\" logo/avatar? Otherwise we can just switch over the randomly\n> > generated blocks thingy that Github uses when an account/org has no\n> > avatar.\u00a0\u00a0\n> >\n> > -- Laolu\n> >\n> > On Tue, Nov 2, 2021 at 7:34 PM Olaoluwa Osuntokun <laolu32 at gmail.com> wrote:\n> >\n> > > Circling back to close the loop here:\n> > >\n> > > \u00a0 * The new Github org (https://github.com/lightning) now exists, and all the\n> > > \u00a0 \u00a0 major implementation maintainers have\u00a0been added to the organization as\n> > > \u00a0 \u00a0 admins.\u00a0\n> > >\n> > > \u00a0 * A new blips repo (https://github.com/lightning/blips) has been created to\n> > > \u00a0 \u00a0 continue the PR that was originally started in the lightning-rfc repo.\u00a0\u00a0\n> > >\n> > > \u00a0 * The old lightning-rfc repo has been moved over, and been renamed to \"bolts\"\n> > > \u00a0 \u00a0 (https://github.com/lightning/bolts -- should it be all caps? )\n> > >\n> > > Thanks to all that participated in the discussion (particularly in meatspace\n> > > during the recent protocol dev meetup!), happy we were able to resolve things\n> > > and begin the next chapter in the evolution of the Lightning protocol!\u00a0\n> > >\n> > > -- Laolu\n> > >\n> > > On Fri, Oct 15, 2021 at 1:49 AM Fabrice Drouin <fabrice.drouin at acinq.fr> wrote:\n> > >\n> > > > On Tue, 12 Oct 2021 at 21:57, Olaoluwa Osuntokun <laolu32 at gmail.com> wrote:\n> > > > > Also note that lnd has _never_ referred to itself as the \"reference\"\n> > > > > implementation.\u00a0 A few years ago some other implementations adopted that\n> > > > > title themselves, but have since adopted softer language.\n> > > >\n> > > > I don't remember that but if you're referring to c-lightning it was\n> > > > the first lightning implementation, and the only one for a while, so\n> > > > in a way it was a \"reference\" at the time ?\n> > > > Or it could have been a reference to their policy of \"implementing the\n> > > > spec, all the spec and nothing but the spec\"\u00a0 ?\n> > > >\n> > > > > I think it's worth briefly revisiting a bit of history here w.r.t the github\n> > > > > org in question. In the beginning, the lightningnetwork github org was\n> > > > > created by Joseph, and the lightningnetwork/paper repo was added, the\n> > > > > manuscript that kicked off this entire thing. Later lightningnetwork/lnd was\n> > > > > created where we started to work on an initial implementation (before the\n> > > > > BOLTs in their current form existed), and we were added as owners.\n> > > > > Eventually we (devs of current impls) all met up in Milan and decided to\n> > > > > converge on a single specification, thus we added the BOLTs to the same\n> > > > > repo, despite it being used for lnd and knowingly so.\n> > > >\n> > > > Yes, work on c-lightning then eclair then lnd all began a long time\n> > > > before the BOLTs process was implemented, and we all set up repos,\n> > > > accounts...\n> > > > I agree that we all inherited things\u00a0 from the \"pre-BOLTS\" era and\n> > > > changing them will create some friction but I still believe it should\n> > > > be done. You also mentioned potential admin rights issues on the\n> > > > current specs repos which would be solved by moving them to a new\n> > > > clean repo.\n> > > >\n> > > > > As it seems the primary grievance here is collocating an implementation of\n> > > > > Lightning along with the _specification_ of the protocol, and given that the\n> > > > > spec was added last, how about we move the spec to an independent repo owned\n> > > > > by the community? I currently have github.com/lightning, and would be happy\n> > > > > to donate it to the community, or we could create a new org like\n> > > > > \"lightning-specs\" or something similar.\n> > > >\n> > > > Sounds great! github.com/lightning is nice (and I like Damian's idea\n> > > > of using github.com/lightning/bolts) and seems to please everyone so\n> > > > it looks that we have a plan!\n> > > >\n> > > > Fabrice\n> >\n> > _______________________________________________\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: lightning-network.svg\nType: image/svg+xml\nSize: 4309 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211103/68ae8865/attachment.svg>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-11-03T08:58:32",
                "message_text_only": "Good morning again list,\n\n>\n> > We could use an identicon, we do that with the lightningnetwork repository. An official logo is\u00a0probably better - give the project a real symbol.\n>\n> I attached an SVG file I have been working on for some time, for the amusement of all.\n>\n> It is unfortunately not square, and is very very simple, as well.\n\nThe icon attached in the previous email was visually inspired by this: https://game-icons.net/1x1/sbed/electric.html\n\nHowever, the icon attached in the previous email is created solely by me without any code from the above link; I created a right triangle, made two corners round, copied it and rotated 180 degrees, then built the Lightning symbol out of them.\nI hereby release the icon in the previous email under CC0.\n\nAn alternative which looks more \"networky\" is: https://game-icons.net/1x1/willdabeast/chain-lightning.html\nA slight modification of removing the outgoing lightning strike from the leftmost person and adding a lightning strike between the leftmost and rightmost person would certainly imply \"network\" of \"lightning\" users, to me.\n\nOn the other hand, a simple Lightning symbol like in the previous email does have its cachet.\nIn particular, this simple symbol allows for the possibility of third parties to use as basis for their own logo, due to the base logo being very clean and lacking visual busyness.\nFor instance, an implementation may create their own logo based on some modification of this base logo, just as its code might implement the BOLT spec but add its own modifications on top of the BOLT spec.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Removing lnd's source code from the Lightning specs repository",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Olaoluwa Osuntokun",
                "Harsha Goli",
                "ZmnSCPxj"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 18095
        }
    },
    {
        "title": "[Lightning-dev] Route reliability<->fee trade-off control parameter",
        "thread_messages": [
            {
                "author": "Joost Jager",
                "date": "2021-11-15T15:25:26",
                "message_text_only": "In Lightning pathfinding the two main variables to optimize for are routing\nfee and reliability. Routing fee is concrete. It is the sat amount that is\npaid when a payment succeeds. Reliability is a property of a route that can\nbe expressed as a probability. The probability that a route will be\nsuccessful.\n\nDuring pathfinding, route options are compared against each other. So for\nexample:\n\nRoute A: fee 10 sat, success probability 50%\nRoute B: fee 20 sat, success probability 80%\n\nWhich one is the better route? That depends on user preference. A patient\nuser will probably go for route A in the hope of saving on fees whereas for\na time-sensitive payment route B looks better.\n\nIt would be great to offer this trade-off to the user in a simple way.\nPreferably a single [0, 1] value that controls the selection process. At 0,\nthe route is only optimized for fees and probabilities are ignored\ncompletely. At 1, the route is only optimized for reliability and fees are\nignored completely.\n\nBut how to choose between the routes A and B for a value somewhere in\nbetween 0 and 1? For example 0.5 - perfect balance between reliability and\nfee. But what does that mean exactly?\n\nAnyone got an idea on how to approach this best? I am looking for a simple\nformula to decide between routes, preferably with a reasonably sound\nprobability-theoretical basis (whatever that means).\n\nJoost\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211115/fffa5edd/attachment.html>"
            },
            {
                "author": "Clara Shikhelman",
                "date": "2021-11-15T18:36:27",
                "message_text_only": "Hi Joost,\n\nA quick way to resolve this is to normalize the payment fees to a [0,1]\nscale. Two natural ways to do this are the following.\n0 in both of them is some maximum set by the user (maybe with some\nreasonable default), 1 could be either the cheapest path or simply 0 sat.\nOnce we have normalized the fees to a [0,1] scale, we can proceed.\n\nLet [image: \\alpha] be the chosen balance parameter, [image: f] the\nfee and [image:\np] the success probability. Then the score of a channel will be  [image:\n\\alpha\\cdot f + (1-\\alpha)\\cdot p]\n\nClara\n\n\nOn Mon, Nov 15, 2021 at 10:26 AM Joost Jager <joost.jager at gmail.com> wrote:\n\n> In Lightning pathfinding the two main variables to optimize for are\n> routing fee and reliability. Routing fee is concrete. It is the sat amount\n> that is paid when a payment succeeds. Reliability is a property of a route\n> that can be expressed as a probability. The probability that a route will\n> be successful.\n>\n> During pathfinding, route options are compared against each other. So for\n> example:\n>\n> Route A: fee 10 sat, success probability 50%\n> Route B: fee 20 sat, success probability 80%\n>\n> Which one is the better route? That depends on user preference. A patient\n> user will probably go for route A in the hope of saving on fees whereas for\n> a time-sensitive payment route B looks better.\n>\n> It would be great to offer this trade-off to the user in a simple way.\n> Preferably a single [0, 1] value that controls the selection process. At 0,\n> the route is only optimized for fees and probabilities are ignored\n> completely. At 1, the route is only optimized for reliability and fees are\n> ignored completely.\n>\n> But how to choose between the routes A and B for a value somewhere in\n> between 0 and 1? For example 0.5 - perfect balance between reliability and\n> fee. But what does that mean exactly?\n>\n> Anyone got an idea on how to approach this best? I am looking for a simple\n> formula to decide between routes, preferably with a reasonably sound\n> probability-theoretical basis (whatever that means).\n>\n> Joost\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211115/7e7f7ab4/attachment.html>"
            },
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2021-11-15T18:50:52",
                "message_text_only": "Dear Joost,\n\nFirst I am happy that you also agree that reliability can and should be\nexpressed as a probability as discussed in [0].\n\nThe problem that you address is that of feature engineering[1]. Which\nconsists of two (or even more) steps:\n\n1.) Feature selection: That means in payment delivery we will compute a min\ncost flow [2] with a chosen cost function (historically people used\ndijkstra seach for single paths with the cost function representing the\nweights on the edges of the graph -which is what most folks currently still\ndo). While [2] and I personally agree with you that the cost function\nshould be a combination the two features fees and reliability (as in\nsuccessprobability) Matt Corallo righfully pointed out [3] that other\nfeatures might be chosen in the future to deliver more optimal results. For\nexample implementations currently often use CLTV as a feature (which I\nhonestly find horrible) and I am currently investigating if one could add\nlatency of channels or - for known IP addresses - either the geo distance\nor IP distance.\n\n2.) Combining features: This is the question that you are asking. Often\npeople use a linear weighted sum to combine features. This is what often\nhappens implicitly in neural networks. While this is often good enough and\nwhile it is often practical to either learn the weights or give users a\nchoice there are many situation where the weighted linear sum does not work\nwell with the selected features. An example for the weighted sum is the\nrisk-factor in c-lightning that could have been used to decide if one\nwanted the dijkstra seach to either optimize for CLTV delta or for paid\nrouting fees. Also in our paper [2] in which we discuss the same two\nfeatures that you mentioned we explain how a linear sum of two features can\nbe optimal due to the lagrangian bounding principle. However in practice\n(of machine learning) it has been shown that using the harmonic mean [4]\nbetween features often works very well without the necessity to learn a\nweight / parameter. This has for example been done when c-lightnign\nrecently switched to probabilistic path finding [5]. In this thread you\nfind a long discussion and evaluation how the harmonic mean outperformed\nthe linear sum.\n\nI think the main issue that you address here is that there is no universal\ntruth for situations like this. In practice only tests and experience will\nhelp us to make good decisions.\n\nwith kind Regards Rene\n\n[0]:\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2021-March/002984.html\n[1]: https://en.wikipedia.org/wiki/Feature_engineering\n[2]: https://arxiv.org/abs/2107.05322\n[3]:\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2021-September/003219.html\n[4]:  https://en.wikipedia.org/wiki/Harmonic_mean\n[5]: https://github.com/ElementsProject/lightning/pull/4771\n\n\n\n\nOn Mon, Nov 15, 2021 at 4:26 PM Joost Jager <joost.jager at gmail.com> wrote:\n\n> In Lightning pathfinding the two main variables to optimize for are\n> routing fee and reliability. Routing fee is concrete. It is the sat amount\n> that is paid when a payment succeeds. Reliability is a property of a route\n> that can be expressed as a probability. The probability that a route will\n> be successful.\n>\n> During pathfinding, route options are compared against each other. So for\n> example:\n>\n> Route A: fee 10 sat, success probability 50%\n> Route B: fee 20 sat, success probability 80%\n>\n> Which one is the better route? That depends on user preference. A patient\n> user will probably go for route A in the hope of saving on fees whereas for\n> a time-sensitive payment route B looks better.\n>\n> It would be great to offer this trade-off to the user in a simple way.\n> Preferably a single [0, 1] value that controls the selection process. At 0,\n> the route is only optimized for fees and probabilities are ignored\n> completely. At 1, the route is only optimized for reliability and fees are\n> ignored completely.\n>\n> But how to choose between the routes A and B for a value somewhere in\n> between 0 and 1? For example 0.5 - perfect balance between reliability and\n> fee. But what does that mean exactly?\n>\n> Anyone got an idea on how to approach this best? I am looking for a simple\n> formula to decide between routes, preferably with a reasonably sound\n> probability-theoretical basis (whatever that means).\n>\n> Joost\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n\n\n-- \nhttps://www.rene-pickhardt.de\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211115/392fcbf0/attachment-0001.html>"
            },
            {
                "author": "Joost Jager",
                "date": "2021-11-15T19:26:51",
                "message_text_only": "Hi Rene,\n\n\n> First I am happy that you also agree that reliability can and should be\n> expressed as a probability as discussed in [0].\n>\n\nProbability based routing is not new to me. I've implemented a form of that\nin lnd in march 2019: https://github.com/lightningnetwork/lnd/pull/2802,\nfollowed by several rounds of refinement.\n\n\n> The problem that you address is that of feature engineering[1]. Which\n> consists of two (or even more) steps:\n>\n> 1.) Feature selection: That means in payment delivery we will compute a\n> min cost flow [2] with a chosen cost function (historically people used\n> dijkstra seach for single paths with the cost function representing the\n> weights on the edges of the graph -which is what most folks currently still\n> do). While [2] and I personally agree with you that the cost function\n> should be a combination the two features fees and reliability (as in\n> successprobability) Matt Corallo righfully pointed out [3] that other\n> features might be chosen in the future to deliver more optimal results. For\n> example implementations currently often use CLTV as a feature (which I\n> honestly find horrible) and I am currently investigating if one could add\n> latency of channels or - for known IP addresses - either the geo distance\n> or IP distance.\n>\n\nI am aware that there are more candidate features, but my question is\nspecifically about the ones that I mentioned.\n\n2.) Combining features: This is the question that you are asking. Often\n> people use a linear weighted sum to combine features. This is what often\n> happens implicitly in neural networks. While this is often good enough and\n> while it is often practical to either learn the weights or give users a\n> choice there are many situation where the weighted linear sum does not work\n> well with the selected features. An example for the weighted sum is the\n> risk-factor in c-lightning that could have been used to decide if one\n> wanted the dijkstra seach to either optimize for CLTV delta or for paid\n> routing fees. Also in our paper [2] in which we discuss the same two\n> features that you mentioned we explain how a linear sum of two features can\n> be optimal due to the lagrangian bounding principle. However in practice\n> (of machine learning) it has been shown that using the harmonic mean [4]\n> between features often works very well without the necessity to learn a\n> weight / parameter. This has for example been done when c-lightnign\n> recently switched to probabilistic path finding [5]. In this thread you\n> find a long discussion and evaluation how the harmonic mean outperformed\n> the linear sum.\n>\n\nObviously features can be combined in a multitude of ways, but I am looking\nfor something that is anchored to some kind of understandable starting\npoint. What I did in lnd is to work with so called 'payment attempt cost'.\nA virtual satoshi amount that represents the cost of a failed attempt. If\nyou put a high price on failed attempts, pathfinding will tend towards more\nreliable routes even if they require a higher fee. To me, the idea of\nputting a (virtual) cost on a payment attempt is tangible and ideally the\nmath should follow from that. I don't want zero parameters, because I think\nthat ultimately the fee/reliability trade-off is up to the user to decide\non.\n\nJoost\n\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211115/0be67f54/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-11-15T23:37:19",
                "message_text_only": "Good morning Joost,\n\n> What I did in lnd is to work with so called 'payment attempt cost'. A virtual satoshi amount that represents the cost of a failed attempt.\n\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2021-August/003191.html\n\nAnd I quote:\n\n> Introduction\n> ============\n>\n> What is the cost of a failed LN payment?\n\nSee link for more.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Stefan Richter",
                "date": "2021-11-15T19:38:14",
                "message_text_only": "Actually, if you look into our paper, the theory tells us the following:\n\n1) A weighted sum of different cost aspects is attractive because it\nremains convex if all the aspects are convex themselves. This cannot be\nsaid of other methods like the harmonic mean, which kind of forces our hand\nif we aim to really calculate optimal flows.\n\n2) even in the single path case, finding a route that optimizes one goal\n(say, reliability) while ensuring that another cost aspect remains under\nsome boundary, is a (weakly) NP hard problem. My interpretation of this\nfact is that while it is certainly possible to find suitable factors for\nthe linear combination (by, say, gradient descent methods), we cannot\nexpect a method that is simple and works for every conceivable graph every\ntime. In practice, we have observed that the factor needs to be varied over\nmultiple orders of magnitude to make a meaningful impact. Mapping this onto\nan easy user interface (e.g. your suggestion of a linearly feeling value\nbetween 0 and 1) will need some trial and error engineering, IMHO.\n\nCheers,\n    Stefan\n\n\nRen\u00e9 Pickhardt via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\nschrieb am Mo., 15. Nov. 2021, 12:50:\n\n> Dear Joost,\n>\n> First I am happy that you also agree that reliability can and should be\n> expressed as a probability as discussed in [0].\n>\n> The problem that you address is that of feature engineering[1]. Which\n> consists of two (or even more) steps:\n>\n> 1.) Feature selection: That means in payment delivery we will compute a\n> min cost flow [2] with a chosen cost function (historically people used\n> dijkstra seach for single paths with the cost function representing the\n> weights on the edges of the graph -which is what most folks currently still\n> do). While [2] and I personally agree with you that the cost function\n> should be a combination the two features fees and reliability (as in\n> successprobability) Matt Corallo righfully pointed out [3] that other\n> features might be chosen in the future to deliver more optimal results. For\n> example implementations currently often use CLTV as a feature (which I\n> honestly find horrible) and I am currently investigating if one could add\n> latency of channels or - for known IP addresses - either the geo distance\n> or IP distance.\n>\n> 2.) Combining features: This is the question that you are asking. Often\n> people use a linear weighted sum to combine features. This is what often\n> happens implicitly in neural networks. While this is often good enough and\n> while it is often practical to either learn the weights or give users a\n> choice there are many situation where the weighted linear sum does not work\n> well with the selected features. An example for the weighted sum is the\n> risk-factor in c-lightning that could have been used to decide if one\n> wanted the dijkstra seach to either optimize for CLTV delta or for paid\n> routing fees. Also in our paper [2] in which we discuss the same two\n> features that you mentioned we explain how a linear sum of two features can\n> be optimal due to the lagrangian bounding principle. However in practice\n> (of machine learning) it has been shown that using the harmonic mean [4]\n> between features often works very well without the necessity to learn a\n> weight / parameter. This has for example been done when c-lightnign\n> recently switched to probabilistic path finding [5]. In this thread you\n> find a long discussion and evaluation how the harmonic mean outperformed\n> the linear sum.\n>\n> I think the main issue that you address here is that there is no universal\n> truth for situations like this. In practice only tests and experience will\n> help us to make good decisions.\n>\n> with kind Regards Rene\n>\n> [0]:\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-March/002984.html\n> [1]: https://en.wikipedia.org/wiki/Feature_engineering\n> [2]: https://arxiv.org/abs/2107.05322\n> [3]:\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-September/003219.html\n> [4]:  https://en.wikipedia.org/wiki/Harmonic_mean\n> [5]: https://github.com/ElementsProject/lightning/pull/4771\n>\n>\n>\n>\n> On Mon, Nov 15, 2021 at 4:26 PM Joost Jager <joost.jager at gmail.com> wrote:\n>\n>> In Lightning pathfinding the two main variables to optimize for are\n>> routing fee and reliability. Routing fee is concrete. It is the sat amount\n>> that is paid when a payment succeeds. Reliability is a property of a route\n>> that can be expressed as a probability. The probability that a route will\n>> be successful.\n>>\n>> During pathfinding, route options are compared against each other. So for\n>> example:\n>>\n>> Route A: fee 10 sat, success probability 50%\n>> Route B: fee 20 sat, success probability 80%\n>>\n>> Which one is the better route? That depends on user preference. A patient\n>> user will probably go for route A in the hope of saving on fees whereas for\n>> a time-sensitive payment route B looks better.\n>>\n>> It would be great to offer this trade-off to the user in a simple way.\n>> Preferably a single [0, 1] value that controls the selection process. At 0,\n>> the route is only optimized for fees and probabilities are ignored\n>> completely. At 1, the route is only optimized for reliability and fees are\n>> ignored completely.\n>>\n>> But how to choose between the routes A and B for a value somewhere in\n>> between 0 and 1? For example 0.5 - perfect balance between reliability and\n>> fee. But what does that mean exactly?\n>>\n>> Anyone got an idea on how to approach this best? I am looking for a\n>> simple formula to decide between routes, preferably with a reasonably sound\n>> probability-theoretical basis (whatever that means).\n>>\n>> Joost\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n>\n> --\n> https://www.rene-pickhardt.de\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211115/42fe9021/attachment-0001.html>"
            },
            {
                "author": "Joost Jager",
                "date": "2021-11-15T19:44:20",
                "message_text_only": "One direction that I explored is to start with a statement by the user in\nthis form:\n\n\"If there is a route with a success probability of 50%, then I am willing\nto pay up to 1.8x the routing fee for an alternative route that has a 80%\nsuccess probability\"\n\nI like this because it isn't an abstract weight or factor. It is actually\nclear what this means.\n\nWhat I didn't yet succeed in is to find a model where I can plug in 50%,\n80% and 1.8x and generalizes it to arbitrary inputs A% and B%. But it seems\nto me that there must be some probabilistic equation / law / rule / theorem\n/ ... that can support this.\n\nJoost.\n\nOn Mon, Nov 15, 2021 at 4:25 PM Joost Jager <joost.jager at gmail.com> wrote:\n\n> In Lightning pathfinding the two main variables to optimize for are\n> routing fee and reliability. Routing fee is concrete. It is the sat amount\n> that is paid when a payment succeeds. Reliability is a property of a route\n> that can be expressed as a probability. The probability that a route will\n> be successful.\n>\n> During pathfinding, route options are compared against each other. So for\n> example:\n>\n> Route A: fee 10 sat, success probability 50%\n> Route B: fee 20 sat, success probability 80%\n>\n> Which one is the better route? That depends on user preference. A patient\n> user will probably go for route A in the hope of saving on fees whereas for\n> a time-sensitive payment route B looks better.\n>\n> It would be great to offer this trade-off to the user in a simple way.\n> Preferably a single [0, 1] value that controls the selection process. At 0,\n> the route is only optimized for fees and probabilities are ignored\n> completely. At 1, the route is only optimized for reliability and fees are\n> ignored completely.\n>\n> But how to choose between the routes A and B for a value somewhere in\n> between 0 and 1? For example 0.5 - perfect balance between reliability and\n> fee. But what does that mean exactly?\n>\n> Anyone got an idea on how to approach this best? I am looking for a simple\n> formula to decide between routes, preferably with a reasonably sound\n> probability-theoretical basis (whatever that means).\n>\n> Joost\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211115/fb12f072/attachment.html>"
            },
            {
                "author": "Stefan Richter",
                "date": "2021-11-15T21:05:21",
                "message_text_only": "It seems to me there can be no such law unless P=NP. Which would also imply\nBitcoin is worthless.\n\nJoost Jager <joost.jager at gmail.com> schrieb am Mo., 15. Nov. 2021, 13:44:\n\n> One direction that I explored is to start with a statement by the user in\n> this form:\n>\n> \"If there is a route with a success probability of 50%, then I am willing\n> to pay up to 1.8x the routing fee for an alternative route that has a 80%\n> success probability\"\n>\n> I like this because it isn't an abstract weight or factor. It is actually\n> clear what this means.\n>\n> What I didn't yet succeed in is to find a model where I can plug in 50%,\n> 80% and 1.8x and generalizes it to arbitrary inputs A% and B%. But it seems\n> to me that there must be some probabilistic equation / law / rule / theorem\n> / ... that can support this.\n>\n> Joost.\n>\n> On Mon, Nov 15, 2021 at 4:25 PM Joost Jager <joost.jager at gmail.com> wrote:\n>\n>> In Lightning pathfinding the two main variables to optimize for are\n>> routing fee and reliability. Routing fee is concrete. It is the sat amount\n>> that is paid when a payment succeeds. Reliability is a property of a route\n>> that can be expressed as a probability. The probability that a route will\n>> be successful.\n>>\n>> During pathfinding, route options are compared against each other. So for\n>> example:\n>>\n>> Route A: fee 10 sat, success probability 50%\n>> Route B: fee 20 sat, success probability 80%\n>>\n>> Which one is the better route? That depends on user preference. A patient\n>> user will probably go for route A in the hope of saving on fees whereas for\n>> a time-sensitive payment route B looks better.\n>>\n>> It would be great to offer this trade-off to the user in a simple way.\n>> Preferably a single [0, 1] value that controls the selection process. At 0,\n>> the route is only optimized for fees and probabilities are ignored\n>> completely. At 1, the route is only optimized for reliability and fees are\n>> ignored completely.\n>>\n>> But how to choose between the routes A and B for a value somewhere in\n>> between 0 and 1? For example 0.5 - perfect balance between reliability and\n>> fee. But what does that mean exactly?\n>>\n>> Anyone got an idea on how to approach this best? I am looking for a\n>> simple formula to decide between routes, preferably with a reasonably sound\n>> probability-theoretical basis (whatever that means).\n>>\n>> Joost\n>>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211115/3533a287/attachment.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2021-11-17T16:25:56",
                "message_text_only": "Yep, this is roughly the direction we've gone in LDK - an abstract interface that gives you some \ninformation about a channel and you return \"I'm willing to pay up to X msats to avoid routing over \nthat channel as specified\".\n\nIt's obviously not perfect in the sense that it won't generate the absolute optimal route given the \nparameters, but it can do pretty well (after some additional fixes we'd like to land) and at least \noptimizes for something the user controls.\n\nSadly, of course, all of this requires a good model for failure probability, something we don't yet \nhave, so we rely on some naive guesses in our default code, and let the user plug in a more advanced \nmodel if they prefer. Long-term we'll probably add more intelligence, as others (or at least \nc-lightning) have done.\n\nMatt\n\nOn 11/15/21 14:44, Joost Jager wrote:\n> One direction that I explored is to start with a statement by the user in this form:\n> \n> \"If there is a route with a success probability of 50%, then I am willing to pay up to 1.8x the \n> routing fee for an alternative route that has a 80% success probability\"\n> \n> I like this because it isn't an abstract weight or factor. It is actually clear what this means.\n> \n> What I didn't yet succeed in is to find a model where I can plug in 50%, 80% and 1.8x and \n> generalizes it to arbitrary inputs A% and B%. But it seems to me that there must be some \n> probabilistic equation / law / rule / theorem / ... that can support this.\n> \n> Joost.\n> \n> On Mon, Nov 15, 2021 at 4:25 PM Joost Jager <joost.jager at gmail.com <mailto:joost.jager at gmail.com>> \n> wrote:\n> \n>     In Lightning pathfinding the two main variables to optimize for are routing fee and reliability.\n>     Routing fee is concrete. It is the sat amount that is paid when a payment succeeds. Reliability\n>     is a property of a route that can be expressed as a probability. The probability that a route\n>     will be successful.\n> \n>     During pathfinding, route options are compared against each other. So for example:\n> \n>     Route A: fee 10 sat, success probability 50%\n>     Route B: fee 20 sat, success probability 80%\n> \n>     Which one is the better route? That depends on user preference. A patient user will probably go\n>     for route A in the hope of saving on fees whereas for a time-sensitive payment route B looks better.\n> \n>     It would be great to offer this trade-off to the user in a simple way. Preferably a single [0,\n>     1] value that controls the selection process. At 0, the route is only optimized for fees and\n>     probabilities are ignored completely. At 1, the route is only optimized for reliability and fees\n>     are ignored completely.\n> \n>     But how to choose between the routes A and B for a value somewhere in between 0 and 1? For\n>     example 0.5 - perfect balance between reliability and fee. But what does that mean exactly?\n> \n>     Anyone got an idea on how to approach this best? I am looking for a simple formula to decide\n>     between routes, preferably with a reasonably sound probability-theoretical basis (whatever that\n>     means).\n> \n>     Joost\n> \n> \n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>"
            },
            {
                "author": "David A. Harding",
                "date": "2021-11-20T23:02:32",
                "message_text_only": "On Mon, Nov 15, 2021 at 04:25:26PM +0100, Joost Jager wrote:\n> Reliability is a property of a route that can\n> be expressed as a probability. The probability that a route will be\n> successful.\n\nI don't think users care about the abstract concept of reliability\nthat's being returned by the pathfinding code here.  What users care\nabout is \"how long will it take for my payment to make the point-of-sale\nterminal turn green so I can walk away with my warm beverage?\"\n\nThis is basically analogous to the fee optimization question that\nonchain wallets have been asking users for years: how many blocks do you\nwant to wait for [the first] confirmation?  The way that's presented to\nusers in software like Bitcoin Core is,\n\n2 blocks (~20 minutes), x fee\n6 blocks (~60 minutes), y fee\n36 blocks (~6 hours), z fee\netc...\n\nThe onchain estimates in Bitcoin Core are based[1] on a 95% threshold.\n\nIf LN software speculatively chooses a series of attempts with a similar\n95%, accounting for things like the probability of a stuck payment (made\nworse by longer CLTV timeouts on some paths), it could present users\nwith the same sort of options:\n\n~1 second, x fee\n~3 seconds, y fee\n~10 seconds, z fee\n\nThis allows the software to use its reliability scoring efficiently in\nchoosing what series of payment attempts to make and presents to the\nuser the information they need to make a choice appropriate for their\nsituation.  As a bonus, it makes it easier for wallet software to move\ntowards a world where there is no user-visible difference between\nonchain and offchain payments, e.g.:\n\n~1 second, w fee\n~15 seconds, x fee\n~10 minutes, y fee\n~60 minutes, z fee\n\n-Dave\n\n[1] https://gist.github.com/morcos/d3637f015bc4e607e1fd10d8351e9f41\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211120/dbb8d3d7/attachment.sig>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-11-22T06:53:04",
                "message_text_only": "Good morning Dave,\n\n> If LN software speculatively chooses a series of attempts with a similar\n> 95%, accounting for things like the probability of a stuck payment (made\n> worse by longer CLTV timeouts on some paths), it could present users\n> with the same sort of options:\n>\n> ~1 second, x fee\n> ~3 seconds, y fee\n> ~10 seconds, z fee\n>\n> This allows the software to use its reliability scoring efficiently in\n> choosing what series of payment attempts to make and presents to the\n> user the information they need to make a choice appropriate for their\n> situation. As a bonus, it makes it easier for wallet software to move\n> towards a world where there is no user-visible difference between\n> onchain and offchain payments, e.g.:\n>\n> ~1 second, w fee\n> ~15 seconds, x fee\n> ~10 minutes, y fee\n> ~60 minutes, z fee\n\nThis may not match ideally, as in the worst case a forwarding might be struck by literal lightning and dropped off the network while your HTLC is on that node, only for the relevant channel to be dropped onchain days later when the timeout comes due.\nProviding this \"seconds\" estimate does not prepare users for the possibility of such black swan events where a high fee transaction gets stalled due to an accident on the network.\n\nOn the other hand, humans never really handle black swan events in any reasonably way anyway, and 95% of the time it will probably achieve that number of estimated seconds or less.\nEven the best onchain estimators fail when a thundering herd of speculators decides to trade Bitcoin based on random crap from the noosphere.\n\nThe processing to figure out a payment plan also becomes significant at the \"seconds\" level, especially if you switch to mincostflow rather than shortestpath.\nThis means the CPU speed of the local node may become significant, or if you are delegating pathfinding to a trusted server, the load on that trusted server becomes significant.\nSigh.\n\nWhy not just ask for a fee budget for a payment, and avoid committing ourselves to paying within some number of seconds, given that the seconds estimate may very well vary depending on local CPU load?\nWould users really complain overmuch if the number of seconds is not provided, given that we cannot really estimate this well?\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Stefan Richter",
                "date": "2021-11-22T16:11:10",
                "message_text_only": "I also don't believe putting a choice of more or less seconds expectation\nin the UI makes for a great user experience. IMHO the goal should just be:\ngive the user an estimate of fees necessary to succeed within a reasonable\ntime. Maybe give them an option to optimize for fees only if they are\nreally cheap and don't care at all if the payment succeeds.\n\nCheers\n  Stefan\n\nZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\nschrieb am Mo., 22. Nov. 2021, 00:53:\n\n> Good morning Dave,\n>\n> > If LN software speculatively chooses a series of attempts with a similar\n> > 95%, accounting for things like the probability of a stuck payment (made\n> > worse by longer CLTV timeouts on some paths), it could present users\n> > with the same sort of options:\n> >\n> > ~1 second, x fee\n> > ~3 seconds, y fee\n> > ~10 seconds, z fee\n> >\n> > This allows the software to use its reliability scoring efficiently in\n> > choosing what series of payment attempts to make and presents to the\n> > user the information they need to make a choice appropriate for their\n> > situation. As a bonus, it makes it easier for wallet software to move\n> > towards a world where there is no user-visible difference between\n> > onchain and offchain payments, e.g.:\n> >\n> > ~1 second, w fee\n> > ~15 seconds, x fee\n> > ~10 minutes, y fee\n> > ~60 minutes, z fee\n>\n> This may not match ideally, as in the worst case a forwarding might be\n> struck by literal lightning and dropped off the network while your HTLC is\n> on that node, only for the relevant channel to be dropped onchain days\n> later when the timeout comes due.\n> Providing this \"seconds\" estimate does not prepare users for the\n> possibility of such black swan events where a high fee transaction gets\n> stalled due to an accident on the network.\n>\n> On the other hand, humans never really handle black swan events in any\n> reasonably way anyway, and 95% of the time it will probably achieve that\n> number of estimated seconds or less.\n> Even the best onchain estimators fail when a thundering herd of\n> speculators decides to trade Bitcoin based on random crap from the\n> noosphere.\n>\n> The processing to figure out a payment plan also becomes significant at\n> the \"seconds\" level, especially if you switch to mincostflow rather than\n> shortestpath.\n> This means the CPU speed of the local node may become significant, or if\n> you are delegating pathfinding to a trusted server, the load on that\n> trusted server becomes significant.\n> Sigh.\n>\n> Why not just ask for a fee budget for a payment, and avoid committing\n> ourselves to paying within some number of seconds, given that the seconds\n> estimate may very well vary depending on local CPU load?\n> Would users really complain overmuch if the number of seconds is not\n> provided, given that we cannot really estimate this well?\n>\n> Regards,\n> ZmnSCPxj\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211122/60a58188/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Route reliability<->fee trade-off control parameter",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Matt Corallo",
                "Clara Shikhelman",
                "Ren\u00e9 Pickhardt",
                "Joost Jager",
                "David A. Harding",
                "Stefan Richter",
                "ZmnSCPxj"
            ],
            "messages_count": 12,
            "total_messages_chars_count": 34762
        }
    },
    {
        "title": "[Lightning-dev] INTEROPERABILITY",
        "thread_messages": [
            {
                "author": "x raid",
                "date": "2021-11-23T09:15:30",
                "message_text_only": "I propose a dialog of the below joint effort ...\n\nthanks\n/xraid\n\n***\nA decentralised integration lab where CL Eclair LDK LND (++ ?) runs each\nthe latest release on \"one box\" rBOX and master.rc on \"another box\" rcBOX.\n\nThe rBOX of each impl has a channels to the other impl rBOX\u00e9s\nsame setup goes for rcBOX\u00e9s.\n\nThese run on mainnet and can then be tested against from each of the impl\nBOX\u00e9s either in orchestration or as each impl team needs.\n\nEach team would provide their impl of BOX\u00e9s with managed channels between\nall other impl.\n\nThis to ensure the biz critical nature of LN is well tested before any rc\nbecomes a public release and that LN is at a point in time where it is due.\n***\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211123/ac659891/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-11-23T10:27:50",
                "message_text_only": "Good morning x-raid,\n\n> I propose a dialog of the below joint effort ...\n>\n> thanks\n> /xraid\n>\n> ***\n> A decentralised integration lab where CL Eclair LDK LND (++ ?) runs each the latest release on \"one box\" rBOX and master.rc on \"another box\" rcBOX.\n\nI believe Electrum also has its own bespoke implementation.\nThere was also Ptarmigan.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-11-23T10:35:46",
                "message_text_only": "Good morning again x-raid,\n\nAre you proposing as well to provide the hardware and Internet connection for these boxes?\n\nI know of one person at least who runs a node that tracks the C-Lightning master (I think they do a nightly build?), and I run a node that I update every release of C-Lightning (and runs CLBOSS as well).\nI do not know the actual implementations of what they connect to, but LND is very popular on the network and LNBIG is known to be an LND shop, and LNBIG is so pervasive that nearly every long-lived forwarding node has at least one channel with *some* LNBIG node.\nI consider this \"good enough\" in practice to catch interop bugs, but some interop bugs are deeper than just direct node-to-node communications.\nFor example, we had bugs in our interop with LND `keysend` before, by my memory.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "x raid",
                "date": "2021-11-23T11:52:12",
                "message_text_only": "what i can imagine is each team should provide boxes and channel liquidity\nas stake on mainnet for tests before announce a public realise as to feel\nthe pain first hand instead of having several K\u00b4s of plebs confused and at\nworst have funds in channelclosed etc. but mostly for helping in smooth\ntransitioning into future envisioned mass.\n\nIf teams rather outsource the running of boxes with channels on mainnet for\nimpl release and rc versions they would of course be able to, but close to\nhome for managing analysis of the team impl themselves is what I would\nrecommend.\n\nCan also see that each box loglines are collected at one central point\nwhereby requests can be made for comparing interoperability per unix.ts\nidentified by box.\n(thats alot of data You say --not really in Big Data terms, question is\nwhere to set a proper cap in time for collections ? a week ? a month ?)\nI think i might have a solution for the central point collector that could\nbe run by an outside of impl teams perimeter. (sponsored?)\n\n/xraid\n\n\n\nOn Tue, Nov 23, 2021 at 11:35 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning again x-raid,\n>\n> Are you proposing as well to provide the hardware and Internet connection\n> for these boxes?\n>\n> I know of one person at least who runs a node that tracks the C-Lightning\n> master (I think they do a nightly build?), and I run a node that I update\n> every release of C-Lightning (and runs CLBOSS as well).\n> I do not know the actual implementations of what they connect to, but LND\n> is very popular on the network and LNBIG is known to be an LND shop, and\n> LNBIG is so pervasive that nearly every long-lived forwarding node has at\n> least one channel with *some* LNBIG node.\n> I consider this \"good enough\" in practice to catch interop bugs, but some\n> interop bugs are deeper than just direct node-to-node communications.\n> For example, we had bugs in our interop with LND `keysend` before, by my\n> memory.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211123/2a4afb38/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-11-23T12:44:28",
                "message_text_only": "Good morning x-raid,\n\n> what i can imagine is each team should provide boxes and channel liquidity as stake on mainnet for tests before announce a public realise as to feel the pain first hand instead of having several K\u00b4s of plebs confused and at worst have funds in channelclosed etc. but mostly for helping in smooth transitioning into future envisioned mass.\n\nNot all members of all teams are independently wealthy, and cannot afford significant liquidity on mainnet, or can afford good Internet connection and keeping a device operational 24/7.\nFor example, for some time I was a C-Lightning core developer, yet did not run a C-Lightning node myself, relying on sheer code review, because I could not afford to run a node.\nWhat you imagine would raise the barrier towards contribution (i.e. I might not have been able to start contributing to C-Lightning in the first place, for example).\n\nI think you misunderstand the open-source model.\nIf you have the skill, but not the money, you can contribute directly.\nIf you do not have the skill, but do have the money, you can contribute that by hiring developers to work on the project you want.\n\nSo, if you are using a particular open-source implementation and storing your funds with it, either:\n\n* You have the 1337 skillz0rs: you contribute review and actual code.\n* You do not have the 1337 skillz0rs: you contribute hardware and testing reports and possibly money.\n\nIf the several Ks of plebs are confused, they can aggregate their resources and fund one or two developers to review and contribute to the project they are using, and maybe some hardware and coins for boxes they keep running.\n\nAt my point of view, the Real Issue (TM) here is how to aggregate the will of a group of people, without risking that some centralized \"manager\" of resources gets incentives that diverge from the group of people and starts allocating resources in ways that the group of people would, in aggregate, disagree with.\n\n>\n> If teams rather outsource the running of boxes with channels on mainnet for impl release and rc versions they would of course be able to, but close to home for managing analysis of the team impl themselves is what I would recommend.\n>\n> Can also see that each box loglines are collected at one central point whereby requests can be made for comparing interoperability per unix.ts identified by box.\n> (thats alot of data You say --not really in Big Data terms, question is where to set a proper cap in time for collections ? a week ? a month ?)\n> I think i might have a solution for the central point collector that could be run by an outside of impl teams perimeter. (sponsored?)\n\nSee, if the money on the node is my own, and not contributed by the group that is going to receive the logs, I am not going to send the logs verbatim to them, nope not nada.\nI do not want to become a target, because logs leak information like who my channel counterparties are and how often I forward HTLCs and exact dates and times of each event, and thus can be used to locate my node, and location is the first step to targeted attack.\nI mean I use a frikkin set of 8 random letters, come on.\nPossibly if the logs had sensitive information redacted (even dates and times??), but we need to automate that redaction, and in particular, if the implementation changes log messages, we need to ensure that changed log messages do not leak information that gets past the automated redaction.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "x raid",
                "date": "2021-11-23T16:31:43",
                "message_text_only": "so You propose Acinq / Blockstream / Lightning Labs do not have funds to\nrun a box or 2 ?\n\ncontributions can be made towards each impl by ppl while the project still\ndo need put liquidity on mainnet to be a viable test before a public\nsanctioned release.\n\nI find You choose misread what the text is supposed to convey - those with\nthe write credentials to repo, when do a public release could have been\ntested, before, against the network, and that in no way hinders PR toward\nsaid repo.\n\nOn Tue, Nov 23, 2021 at 1:44 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning x-raid,\n>\n> > what i can imagine is each team should provide boxes and channel\n> liquidity as stake on mainnet for tests before announce a public realise as\n> to feel the pain first hand instead of having several K\u00b4s of plebs confused\n> and at worst have funds in channelclosed etc. but mostly for helping in\n> smooth transitioning into future envisioned mass.\n>\n> Not all members of all teams are independently wealthy, and cannot afford\n> significant liquidity on mainnet, or can afford good Internet connection\n> and keeping a device operational 24/7.\n> For example, for some time I was a C-Lightning core developer, yet did not\n> run a C-Lightning node myself, relying on sheer code review, because I\n> could not afford to run a node.\n> What you imagine would raise the barrier towards contribution (i.e. I\n> might not have been able to start contributing to C-Lightning in the first\n> place, for example).\n>\n> I think you misunderstand the open-source model.\n> If you have the skill, but not the money, you can contribute directly.\n> If you do not have the skill, but do have the money, you can contribute\n> that by hiring developers to work on the project you want.\n>\n> So, if you are using a particular open-source implementation and storing\n> your funds with it, either:\n>\n> * You have the 1337 skillz0rs: you contribute review and actual code.\n> * You do not have the 1337 skillz0rs: you contribute hardware and testing\n> reports and possibly money.\n>\n> If the several Ks of plebs are confused, they can aggregate their\n> resources and fund one or two developers to review and contribute to the\n> project they are using, and maybe some hardware and coins for boxes they\n> keep running.\n>\n> At my point of view, the Real Issue (TM) here is how to aggregate the will\n> of a group of people, without risking that some centralized \"manager\" of\n> resources gets incentives that diverge from the group of people and starts\n> allocating resources in ways that the group of people would, in aggregate,\n> disagree with.\n>\n> >\n> > If teams rather outsource the running of boxes with channels on mainnet\n> for impl release and rc versions they would of course be able to, but close\n> to home for managing analysis of the team impl themselves is what I would\n> recommend.\n> >\n> > Can also see that each box loglines are collected at one central point\n> whereby requests can be made for comparing interoperability per unix.ts\n> identified by box.\n> > (thats alot of data You say --not really in Big Data terms, question is\n> where to set a proper cap in time for collections ? a week ? a month ?)\n> > I think i might have a solution for the central point collector that\n> could be run by an outside of impl teams perimeter. (sponsored?)\n>\n> See, if the money on the node is my own, and not contributed by the group\n> that is going to receive the logs, I am not going to send the logs verbatim\n> to them, nope not nada.\n> I do not want to become a target, because logs leak information like who\n> my channel counterparties are and how often I forward HTLCs and exact dates\n> and times of each event, and thus can be used to locate my node, and\n> location is the first step to targeted attack.\n> I mean I use a frikkin set of 8 random letters, come on.\n> Possibly if the logs had sensitive information redacted (even dates and\n> times??), but we need to automate that redaction, and in particular, if the\n> implementation changes log messages, we need to ensure that changed log\n> messages do not leak information that gets past the automated redaction.\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211123/d7d693cb/attachment.html>"
            },
            {
                "author": "x raid",
                "date": "2021-11-23T16:50:36",
                "message_text_only": "Each dev does tests on a local machine before push to repo, repo\nmaintainers do tests and when satisfied do an acceptance test in the\nproposed system to verify against all other implementations partaking\nbefore public release. Has not anything to do with You relly, not Your\nprivate machine but dedicated test machines that do have nano granularity\nin that request against runs can specify unix.ts(start)-range-unix.ts(end)\nof box xyz and independently se if others and own impl behaves as it is\nexpected to.\n\nOn Tue, Nov 23, 2021 at 5:31 PM x raid <xraid at iprobot.com> wrote:\n\n> so You propose Acinq / Blockstream / Lightning Labs do not have funds to\n> run a box or 2 ?\n>\n> contributions can be made towards each impl by ppl while the project still\n> do need put liquidity on mainnet to be a viable test before a public\n> sanctioned release.\n>\n> I find You choose misread what the text is supposed to convey - those with\n> the write credentials to repo, when do a public release could have been\n> tested, before, against the network, and that in no way hinders PR toward\n> said repo.\n>\n> On Tue, Nov 23, 2021 at 1:44 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n>> Good morning x-raid,\n>>\n>> > what i can imagine is each team should provide boxes and channel\n>> liquidity as stake on mainnet for tests before announce a public realise as\n>> to feel the pain first hand instead of having several K\u00b4s of plebs confused\n>> and at worst have funds in channelclosed etc. but mostly for helping in\n>> smooth transitioning into future envisioned mass.\n>>\n>> Not all members of all teams are independently wealthy, and cannot afford\n>> significant liquidity on mainnet, or can afford good Internet connection\n>> and keeping a device operational 24/7.\n>> For example, for some time I was a C-Lightning core developer, yet did\n>> not run a C-Lightning node myself, relying on sheer code review, because I\n>> could not afford to run a node.\n>> What you imagine would raise the barrier towards contribution (i.e. I\n>> might not have been able to start contributing to C-Lightning in the first\n>> place, for example).\n>>\n>> I think you misunderstand the open-source model.\n>> If you have the skill, but not the money, you can contribute directly.\n>> If you do not have the skill, but do have the money, you can contribute\n>> that by hiring developers to work on the project you want.\n>>\n>> So, if you are using a particular open-source implementation and storing\n>> your funds with it, either:\n>>\n>> * You have the 1337 skillz0rs: you contribute review and actual code.\n>> * You do not have the 1337 skillz0rs: you contribute hardware and testing\n>> reports and possibly money.\n>>\n>> If the several Ks of plebs are confused, they can aggregate their\n>> resources and fund one or two developers to review and contribute to the\n>> project they are using, and maybe some hardware and coins for boxes they\n>> keep running.\n>>\n>> At my point of view, the Real Issue (TM) here is how to aggregate the\n>> will of a group of people, without risking that some centralized \"manager\"\n>> of resources gets incentives that diverge from the group of people and\n>> starts allocating resources in ways that the group of people would, in\n>> aggregate, disagree with.\n>>\n>> >\n>> > If teams rather outsource the running of boxes with channels on mainnet\n>> for impl release and rc versions they would of course be able to, but close\n>> to home for managing analysis of the team impl themselves is what I would\n>> recommend.\n>> >\n>> > Can also see that each box loglines are collected at one central point\n>> whereby requests can be made for comparing interoperability per unix.ts\n>> identified by box.\n>> > (thats alot of data You say --not really in Big Data terms, question is\n>> where to set a proper cap in time for collections ? a week ? a month ?)\n>> > I think i might have a solution for the central point collector that\n>> could be run by an outside of impl teams perimeter. (sponsored?)\n>>\n>> See, if the money on the node is my own, and not contributed by the group\n>> that is going to receive the logs, I am not going to send the logs verbatim\n>> to them, nope not nada.\n>> I do not want to become a target, because logs leak information like who\n>> my channel counterparties are and how often I forward HTLCs and exact dates\n>> and times of each event, and thus can be used to locate my node, and\n>> location is the first step to targeted attack.\n>> I mean I use a frikkin set of 8 random letters, come on.\n>> Possibly if the logs had sensitive information redacted (even dates and\n>> times??), but we need to automate that redaction, and in particular, if the\n>> implementation changes log messages, we need to ensure that changed log\n>> messages do not leak information that gets past the automated redaction.\n>>\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211123/63d5b741/attachment-0001.html>"
            },
            {
                "author": "Pierre",
                "date": "2021-11-23T16:56:05",
                "message_text_only": "> so You propose Acinq / Blockstream / Lightning Labs do not have funds to\nrun a box or 2 ?\n\nFwiw we already do that with our main node. It's even better than a demo\none because it has real economic activity, and has a lot of channels to a\nvariety of nodes implementations and versions.\n\nSometimes our node is behind eclair master branch, but it's always\nup-to-date for critical commits and releases. So we eat our own dog food\nand will experience force closes before our users do.\n\nPierre\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211123/fa3738a8/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-11-23T23:14:27",
                "message_text_only": "Good morning x-raid,\n\n> so You propose Acinq / Blockstream / Lightning Labs do not have funds to run a box or 2 ?\n\nNot at all, I am proposing that these people, who have already done the effort to release working Lightning Network Node implementations free of charge to you, are not obligated to *also* devote more hardware and resources.\n\nLet me tell a little story...\n\nSome years ago, during the SegWit wars, there was a sentiment \"when are **they** going to implement Lightning??\"\nBoth anti-SegWit and pro-SegWit asked this:\n\n* anti-SegWit: Yeah, you need bigblocks, Lightning is vaporware, when are **they** going to implement Lightning?\n* pro-SegWit: Lightning is so totes kool, this is why we SegWit, when are **they** going to implement Lightning?\n\nAfter some time participating in the SegWit wars, I realized that I was, in fact, a programmer (LOL).\nSo why should **I** be asking when **they** are going to implement Lightning?\nAs a programmer, **I** could implement Lightning myself!\nI should be asking myself why **I** was not implementing it.\n\nThus I started contributing to the Lightning implementation written in a language I could understand, C-Lightning.\n\n\nMy question to you is: obviously you are a node operator as otherwise the issue you raise would not be relevant to you, but what can *you* do to advance your goal?\n\n(In any case: C-Lightning and Eclair devs have already mentioned they already run mainnet nodes tracking our respective master branches (i.e. we already eat our own dog food, because duh --- for many of us, the reason we are developing this is because for *other* reasons, we *have to* run Lightning nodes), is there any particular implementation you are concerned about?\nMaybe ask them directly?)\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "x raid",
                "date": "2021-11-24T07:48:26",
                "message_text_only": "We are talkin interoperability among impl not individual node operators\nversion management of chosen impl.\n\nwhere Pierre of Acinq says\n\"So we eat our own dog food and will experience force closes before our\nusers do..\"\nhahaha made my day ...\n\na node operator do tests live in its continuous integration efforts would\nbe expected and should be able do so with a by impl assured latest stable\nrelease version.\n\nwhat is suggested for dialog is the different impl maintainers before sign\noff a stable release do a extra test live on mainnet with liquidity in\nchannels towards the other impl versions and by doing so can catch\nunforseen glitches that tests of impl in isolation can not catch.\n\nwhat also suggested was a collection point where one could fetch loglines\nfrom the instances partaking in the interoperability assurance test.\nex. impl (a) try open channel to impl (b) and fails --can then ask central\nlogline point for the loglines of ( a < -- > b ) at unix.ts(start) - range\n- unix.ts(end).\n\nthis then would help assert a new release of a impl is interoperable and\ncan be recommende for install as considered be latest stable release\nversion.\n\nLN a Network System Class \"Finacial\" need in preparation for onboarding 1B\nby 2026 start to grow up *now*.\n\nthanks\n/xraid\n\n\n\nOn Wed, Nov 24, 2021 at 12:14 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning x-raid,\n>\n> > so You propose Acinq / Blockstream / Lightning Labs do not have funds to\n> run a box or 2 ?\n>\n> Not at all, I am proposing that these people, who have already done the\n> effort to release working Lightning Network Node implementations free of\n> charge to you, are not obligated to *also* devote more hardware and\n> resources.\n>\n> Let me tell a little story...\n>\n> Some years ago, during the SegWit wars, there was a sentiment \"when are\n> **they** going to implement Lightning??\"\n> Both anti-SegWit and pro-SegWit asked this:\n>\n> * anti-SegWit: Yeah, you need bigblocks, Lightning is vaporware, when are\n> **they** going to implement Lightning?\n> * pro-SegWit: Lightning is so totes kool, this is why we SegWit, when are\n> **they** going to implement Lightning?\n>\n> After some time participating in the SegWit wars, I realized that I was,\n> in fact, a programmer (LOL).\n> So why should **I** be asking when **they** are going to implement\n> Lightning?\n> As a programmer, **I** could implement Lightning myself!\n> I should be asking myself why **I** was not implementing it.\n>\n> Thus I started contributing to the Lightning implementation written in a\n> language I could understand, C-Lightning.\n>\n>\n> My question to you is: obviously you are a node operator as otherwise the\n> issue you raise would not be relevant to you, but what can *you* do to\n> advance your goal?\n>\n> (In any case: C-Lightning and Eclair devs have already mentioned they\n> already run mainnet nodes tracking our respective master branches (i.e. we\n> already eat our own dog food, because duh --- for many of us, the reason we\n> are developing this is because for *other* reasons, we *have to* run\n> Lightning nodes), is there any particular implementation you are concerned\n> about?\n> Maybe ask them directly?)\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211124/0f74cf48/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-11-24T13:16:57",
                "message_text_only": "Good morning x raid,\n\n> We are talkin interoperability among impl not individual node operators version management of chosen impl.\n>\n> where Pierre of Acinq says\n> \"So we eat our own dog food and will experience force closes before our users do..\"\n> hahaha made my day ...\n>\n> a node operator do tests live in its continuous integration efforts would be expected and should be able do so with a by impl assured latest stable release version.\n>\n> what is suggested for dialog is the different impl maintainers before sign off a stable release do a extra test live on mainnet with liquidity in channels towards the other impl versions and by doing so can catch unforseen glitches that tests of impl in isolation can not catch.\n\n\n***We developers already ARE running nodes that are connected to other implementations, on mainnet, 24/7.***\nIn practice we have large release windows before we actually make a final release, precisely to catch these kinds of bugs that are not easily visible in isolation, but need real data on the network.\nMy own node (C-Lightning) has channels to LNBIG (lnd), and I suspect at least some of the unpublished channels made to me are Electrum, for example, so I already have a node that is already running against other implementations.\n\nWe have been telling you that over several emails already.\n\n\nIs there any specific thing you can offer?\nPut up hardware and coins yourself if you really want this to happen.\nI can give you an SSH key so I can install C-Lightning and CLBOSS on your hardware myself, then give you the addresses of the C-Lightning node so you can provide coins for CLBOSS to manage.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "x raid",
                "date": "2021-11-24T16:15:12",
                "message_text_only": "yes i do have a solution that is easily integrated to the different impl\nfor pumping up live loglines, what's needed there for this very purpose\nwould be a html ws UI with side by side windows representing a impl\ninstance version, also a query for download files of range unix.ts per\ninstance. (need be sponsored !)\n\nohhh i did not know You are the CL maintainer responsible for signing\nstable version releases.\n\nYou are welcome to partake after You talked to the beancounters at\nBlockstream that probably can give You a budget ?\n\n/xraid\n\n\n\nOn Wed, Nov 24, 2021 at 2:17 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning x raid,\n>\n> > We are talkin interoperability among impl not individual node operators\n> version management of chosen impl.\n> >\n> > where Pierre of Acinq says\n> > \"So we eat our own dog food and will experience force closes before our\n> users do..\"\n> > hahaha made my day ...\n> >\n> > a node operator do tests live in its continuous integration efforts\n> would be expected and should be able do so with a by impl assured latest\n> stable release version.\n> >\n> > what is suggested for dialog is the different impl maintainers before\n> sign off a stable release do a extra test live on mainnet with liquidity in\n> channels towards the other impl versions and by doing so can catch\n> unforseen glitches that tests of impl in isolation can not catch.\n>\n>\n> ***We developers already ARE running nodes that are connected to other\n> implementations, on mainnet, 24/7.***\n> In practice we have large release windows before we actually make a final\n> release, precisely to catch these kinds of bugs that are not easily visible\n> in isolation, but need real data on the network.\n> My own node (C-Lightning) has channels to LNBIG (lnd), and I suspect at\n> least some of the unpublished channels made to me are Electrum, for\n> example, so I already have a node that is already running against other\n> implementations.\n>\n> We have been telling you that over several emails already.\n>\n>\n> Is there any specific thing you can offer?\n> Put up hardware and coins yourself if you really want this to happen.\n> I can give you an SSH key so I can install C-Lightning and CLBOSS on your\n> hardware myself, then give you the addresses of the C-Lightning node so you\n> can provide coins for CLBOSS to manage.\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211124/c76dc410/attachment.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2021-11-23T11:55:15",
                "message_text_only": "ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\nwrites:\n> Are you proposing as well to provide the hardware and Internet\n> connection for these boxes?\n\nHaving implemented and operated the lightning integration testing\nframework [1,2] in the past this is something near and dear to my\nheart. However I have since become convinced that this kind of\nartificial setup is unlikely to catch any but the most egregious issues,\ngiven their different usage pattern. Much like the bitcoin testnet is\nnot representative of what happens on the mainnet, I don't think a\nseparate network would be able to reproduce all the issues that occur on\nthe lightning mainnet.\n\nI agree with ZmnSCPxj that testing on the mainnet is much more likely to\ncatch more involved issues, and therefore a solid process with release\ncandidates and nightly builds, in combination with lnprototest [3] to test\nthe nodes for spec adherence in isolation is the way to go.\n\n> I know of one person at least who runs a node that tracks the\n> C-Lightning master (I think they do a nightly build?), and I run a\n> node that I update every release of C-Lightning (and runs CLBOSS as\n> well).  I do not know the actual implementations of what they connect\n> to, but LND is very popular on the network and LNBIG is known to be an\n> LND shop, and LNBIG is so pervasive that nearly every long-lived\n> forwarding node has at least one channel with *some* LNBIG node.  I\n> consider this \"good enough\" in practice to catch interop bugs, but\n> some interop bugs are deeper than just direct node-to-node\n> communications.  For example, we had bugs in our interop with LND\n> `keysend` before, by my memory.\n\nWe should differentiate between spec compliance, and compatibility of\nextensions. `keysend` wasn't and still isn't specd which resulted in us\nhaving to reverse engineer the logic from the first experimental\nimplementation, and I did get some details wrong. For example I expected\nnodes to explicitly opt-into keysend via featurebit 55, but they just\nyolo it...\n\nAs these primitives become more widespread and more users rely on them,\nI think it is paramount that we actually spec them out (something that\nthe new bLIP process should cover), but until we do there is no way of\nsaying what's correct and what isn't.\n\nCheers,\nChristian\n\n[1] https://github.com/cdecker/lightning-integration\n[2] https://cdecker.github.io/lightning-integration/\n[3] https://github.com/rustyrussell/lnprototest"
            }
        ],
        "thread_summary": {
            "title": "INTEROPERABILITY",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "x raid",
                "Christian Decker",
                "Pierre",
                "ZmnSCPxj"
            ],
            "messages_count": 13,
            "total_messages_chars_count": 29490
        }
    },
    {
        "title": "[Lightning-dev] Half-Delegation & Chaperones for Decker Channels",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2021-11-29T23:32:12",
                "message_text_only": "Just a minor curiosity I figured was worth mentioning on the composition of\ndelegations and anyprevout...\n\nDA: Let full delegation be a script S such that I can sign script R and\nthen R may sign for a transaction T.\nDB: Let partial delegation be a script S such that I can sign a tuple\n(script R, transaction T) and R may sign T.\n\nA simple version of this could be done for scriptless multisigs where S\nsigns T and then onion encrypts to the signers of R and distributes the\nshares. However, under such a model, if T is signed by S with AnyPrevOut,\nthen T is now arbitrarily rebindable. Therefore let us define more strictly:\nDC: Let half-delegation be a script S such that I can sign a tuple (script\nR, transaction T) and R may sign T and revealing T/R does grant\nauthorization to any other party.\n\nThe signer of R could choose to sign with APO, in which case they make the\ntxn rebindable. They could also reveal the private keys for R similarly.\nFor \"correct\" use, R should sign with SIGHASH_ALL, binding the transaction\nto a single instance.\n\nObservation: a tuple script R + transaction T can, in many cases, be\nrepresented by script R || <H(transaction T)> CTV.\nCorollary: half-delegation can be derived from full delegation and a\ncovenant.\n\nTherefore delegation + CTV + APO may be sufficient for making chaperone\nsignatures work, if they are desired by a user.\n\nRemarks:\n\nAPO's design discussion should not revisit Chaperone signatures (hopefully\nalready a dead horse?) but instead consider how APO might compose with\nDelegation proposals and CTV.\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211129/a63d9d54/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2021-11-30T00:50:25",
                "message_text_only": "Good morning Jeremy,\n\n> Just a minor curiosity I figured was worth mentioning on the composition of delegations and anyprevout...\n>\n> DA: Let full delegation be a script S such that I can sign script R and then R may sign for a transaction T.\n> DB: Let partial delegation be a script S such that I can sign a tuple (script R, transaction T) and R may sign T.\n>\n> A simple version of this could be done for scriptless multisigs where S signs\u00a0T and then onion encrypts to the signers of R and distributes the shares.\n\nJust to be clear, do you mean, \"for the case where R is a scriptless multisig\"?\nAnd, \"onion encrypts the signature\"?\n\nSince part of the signature `(R, s)` would be a scalar modulo k, `s`, another way would be to SSS that scalar and distribute the shares to the R multisig signers, that may require less computation and would allow R to be k-of-n.\n\n> However, under such a model, if T is signed by S with AnyPrevOut, then T is now arbitrarily rebindable.\n>\n> Therefore let us define more strictly:\n>\n> DC: Let half-delegation be a script S such that I can sign a tuple (script R, transaction T) and R may sign T and revealing T/R does grant authorization\u00a0to any other party.\n\nDo you mean \"does *not* grant\"?\n\nIf S is a delegator that intends to delegate to R, and creates a simple Taproot with keypath S, and signs a spend from that using `SIGHASH_ANYPREVOUT` and distributes shares of the signature to R, then once the signature is revealed onchain, anyone (not just R) may rebind the transaction to any other Taproot with keypath S, which I think is what you wish to prevent with the stricter definition \"does *not* grant authorization to any other party\"?\n\n>\n> The signer of R could choose to sign with APO, in which case they make the txn rebindable. They could also reveal the private keys for R similarly.\n> For \"correct\" use, R should sign with SIGHASH_ALL, binding the transaction to a single instance.\n\nWell, for the limited case where R is a k-of-n multisig (including n-of-n) it seems the \"sign and SSS\" would work similarly, for \"correct\" use R should sign with `SIGHASH_ALL` anyway, so in the \"sign and SSS\" method S should always sign with `SIGHASH_ALL`.\n\nThis does not work if the script S itself is hosted in some construction that requires `SIGHASH_ANYPREVOUT` at the base layer, which I believe is what you are concerned about?\nIn that case all signers should really give fresh pubkeys, i.e. no address reuse.\n\n> Observation: a tuple script R\u00a0+ transaction T can, in many cases, be represented by script R || <H(transaction T)> CTV.\n> Corollary: half-delegation can be derived from full delegation and a covenant.\n>\n> Therefore delegation\u00a0+ CTV\u00a0+ APO may be sufficient for making chaperone signatures work, if they are desired by a user.\n\nHmm what?\nIs there some other use for chaperone signatures other than to artificially encumber `SIGHASH_ANYPREVOUT` or have definitions drifted over time?\n\n> Remarks:\n>\n> APO's design discussion should not revisit Chaperone signatures (hopefully already a dead horse?) but instead consider how APO might compose with Delegation proposals and CTV.\n\nno chaperones == good\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Jeremy",
                "date": "2021-11-30T01:06:32",
                "message_text_only": "Hi zmnscpxj,\n\n>\n>> Just a minor curiosity I figured was worth mentioning on the composition\nof delegations and anyprevout...\n>>\n>> DA: Let full delegation be a script S such that I can sign script R and\nthen R may sign for a transaction T.\n>> DB: Let partial delegation be a script S such that I can sign a tuple\n(script R, transaction T) and R may sign T.\n>>\n>> A simple version of this could be done for scriptless multisigs where S\nsigns T and then onion encrypts to the signers of R and distributes the\nshares.\n>\n>Just to be clear, do you mean, \"for the case where R is a scriptless\nmultisig\"?\n>And, \"onion encrypts the signature\"?\n\n\nNo. Let's suppose that R = 2 of 3 {a,b,c}.\n\nS signs T. S distributes enc(a, enc(b, T)), enc(a, enc(c, T)), and enc(b,\nenc(c, T)) and then R can 'sign' by decrypt and broadcast (of course you\nhave\nan FLP issue here, but let's ignore that for now).\n\nThis is a \"scriptless multisig with onion encryption\" in this context.\n\nNote: you don't have to encrypt T, just the witness to T technically.\n\n>Since part of the signature `(R, s)` would be a scalar modulo k, `s`,\nanother way would be to SSS that scalar and distribute the shares to the R\nmultisig signers, that may require less computation and would allow R to be\nk-of-n.\n\nYep that works too! There are a lot of different things S can do here, was\njust giving the simplest \"it works\" version v.s. focusing on efficiency.\n\n\n>> However, under such a model, if T is signed by S with AnyPrevOut, then T\nis now arbitrarily rebindable.\n>>\n>> Therefore let us define more strictly:\n>>\n>> DC: Let half-delegation be a script S such that I can sign a tuple\n(script R, transaction T) and R may sign T and revealing T/R does grant\nauthorization to any other party.\n>\n>Do you mean \"does *not* grant\"?\n\nYes absolutely, that was a typo.\n\n\n>If S is a delegator that intends to delegate to R, and creates a simple\nTaproot with keypath S, and signs a spend from that using\n`SIGHASH_ANYPREVOUT` and distributes shares of the signature to R, then\nonce the signature is revealed onchain, anyone (not just R) may rebind the\ntransaction to any other Taproot with keypath S, which I think is what you\nwish to prevent with the stricter definition \"does *not* grant\nauthorization to any other party\"?\n\nCorrect.\n\n>>\n>> The signer of R could choose to sign with APO, in which case they make\nthe txn rebindable. They could also reveal the private keys for R similarly.\n>> For \"correct\" use, R should sign with SIGHASH_ALL, binding the\ntransaction to a single instance.\n>\n>Well, for the limited case where R is a k-of-n multisig (including n-of-n)\nit seems the \"sign and SSS\" would work similarly, for \"correct\" use R\nshould sign with `SIGHASH_ALL` anyway, so in the \"sign and SSS\" method S\nshould always sign with `SIGHASH_ALL`.\n\nCorrect.\n\n>This does not work if the script S itself is hosted in some construction\nthat requires `SIGHASH_ANYPREVOUT` at the base layer, which I believe is\nwhat you are concerned about?\n>In that case all signers should really give fresh pubkeys, i.e. no address\nreuse.\n\nI don't think so? Not sure what you mean here.\n\n>> Observation: a tuple script R + transaction T can, in many cases, be\nrepresented by script R || <H(transaction T)> CTV.\n>> Corollary: half-delegation can be derived from full delegation and a\ncovenant.\n>>\n>> Therefore delegation + CTV + APO may be sufficient for making chaperone\nsignatures work, if they are desired by a user.\n>\n>Hmm what?\n>Is there some other use for chaperone signatures other than to\nartificially encumber `SIGHASH_ANYPREVOUT` or have definitions drifted over\ntime?\n\nI don't know; but they are interesting. Of course you can just always write\na script like `<1||pk> checksig <chap_pk> checksig`, but where this is\nunique is that you can accomplish post-hoc chaperoning which lets you\ndynamically pick/rotate keys, for example.\n\n>> Remarks:\n>>\n>> APO's design discussion should not revisit Chaperone signatures\n(hopefully already a dead horse?) but instead consider how APO might\ncompose with Delegation proposals and CTV.\n>\n>no chaperones == good\n\n:)\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20211129/1c3b5f17/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Half-Delegation & Chaperones for Decker Channels",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Jeremy",
                "ZmnSCPxj"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 9249
        }
    }
]