[
    {
        "title": "[Lightning-dev] eltoo implementation in Bitcoin functional test framework",
        "thread_messages": [
            {
                "author": "Richard Myers",
                "date": "2019-09-04T11:19:49",
                "message_text_only": "Hi All,\n\nTo better understand how the eltoo update scheme (\nhttps://blockstream.com/eltoo.pdf ) works in practice I implemented eltoo\nin the Bitcoin functional test framework. These simulations exercise a\nconcrete implementation of the eltoo Bitcoin scripts and explore the data\nflow between nodes that use eltoo to update their channel state.\n\nMy motivation for creating these tests is to have a framework for both\nunderstanding and refining the Bitcoin scripts and message passing protocol\nfor eltoo. I\u2019d love to hear what people think of my initial implementation.\n\nThis simulation uses a fork of Bitcoin with cdecker\u2019s SIGHASH_NOINPUT patch\napplied to the signet2 fork fjahr created with patches applied for signet\n(kallewoof), taproot (sipa) and anyprevout* (ajtowns).\n\nhttps://github.com/remyers/signet2/blob/eltoo/test/functional/simulate_eltoo.py\n\nNext steps:\n\n   -\n\n   add bidirectional channel updates\n   -\n\n   derive public keys for settle transactions from a pre-shared basepoint\n\n\nDoes anyone know of any other eltoo implementations? I\u2019d love to compare\nnotes and get the ball rolling on a detailed specification.\n\nSpecial thanks to the Chaincode Summer Residency and Christian Decker for\ntheir helpful advice and encouragement while I worked on this project.\n\n  -- Richard\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190904/332d1310/attachment.html>"
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2019-09-04T12:52:50",
                "message_text_only": "Good morning Richard,\n\nThis is an interesting initiative, I'm curious to see the results!\nI know we haven't worked on any Eltoo implementation yet at Acinq and I\ndon't know if others have attempted it.\n\nHowever I have a very open question that may impact your project.\nI'm starting to look at miniscript [1] (still a total noob though) and\nlistened to an interview where Pieter Wuille briefly mentioned that using\nminiscript for lightning may be more future-proof and extensible than\ndirectly using bitcoin script.\nHave you considered first re-writing the Eltoo scripts with miniscript? Or\ndid someone else on this list attempt this already?\nDo people on this list have opinions on whether that is the right direction\nfor Eltoo scripts (and maybe even for Bolt 1.x scripts if *any_prevout*\nnever makes it to Bitcoin scripts)?\n\nCheers,\nBastien\n\n[1] http://bitcoin.sipa.be/miniscript/\n\nLe mer. 4 sept. 2019 \u00e0 13:20, Richard Myers <rich at gotenna.com> a \u00e9crit :\n\n> Hi All,\n>\n> To better understand how the eltoo update scheme (\n> https://blockstream.com/eltoo.pdf ) works in practice I implemented eltoo\n> in the Bitcoin functional test framework. These simulations exercise a\n> concrete implementation of the eltoo Bitcoin scripts and explore the data\n> flow between nodes that use eltoo to update their channel state.\n>\n> My motivation for creating these tests is to have a framework for both\n> understanding and refining the Bitcoin scripts and message passing protocol\n> for eltoo. I\u2019d love to hear what people think of my initial implementation.\n>\n> This simulation uses a fork of Bitcoin with cdecker\u2019s SIGHASH_NOINPUT\n> patch applied to the signet2 fork fjahr created with patches applied for\n> signet (kallewoof), taproot (sipa) and anyprevout* (ajtowns).\n>\n>\n> https://github.com/remyers/signet2/blob/eltoo/test/functional/simulate_eltoo.py\n>\n> Next steps:\n>\n>    -\n>\n>    add bidirectional channel updates\n>    -\n>\n>    derive public keys for settle transactions from a pre-shared basepoint\n>\n>\n> Does anyone know of any other eltoo implementations? I\u2019d love to compare\n> notes and get the ball rolling on a detailed specification.\n>\n> Special thanks to the Chaincode Summer Residency and Christian Decker for\n> their helpful advice and encouragement while I worked on this project.\n>\n>   -- Richard\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190904/dc6db5ea/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2019-09-04T16:04:06",
                "message_text_only": "Hello all,\n\nDidn't listen to Pieter Wuille interview, so don't know how he was thinking\nto use miniscript for lightning.\nBut currently in lightning all our scripts are templates, a use of a\nminiscript compiler would be to find optimized bitcoin scripts for a given\npolicy which model the channel and then hardcode them in lightning backend.\nThe other use I can see would be to use miniscript to write customizable\nconditional-payment than our basic HTLCs, real hurdle would be to implement\non-chain monitoring and resolution right.\nNot sure how Eltoo fit into it as it's a sighash extension to get a new\nupdate mechanism, miniscript seems more tailored for the transfer layer.\n\nRegards,\nAntoine\n\nLe mer. 4 sept. 2019 \u00e0 08:53, Bastien TEINTURIER <bastien at acinq.fr> a\n\u00e9crit :\n\n> Good morning Richard,\n>\n> This is an interesting initiative, I'm curious to see the results!\n> I know we haven't worked on any Eltoo implementation yet at Acinq and I\n> don't know if others have attempted it.\n>\n> However I have a very open question that may impact your project.\n> I'm starting to look at miniscript [1] (still a total noob though) and\n> listened to an interview where Pieter Wuille briefly mentioned that using\n> miniscript for lightning may be more future-proof and extensible than\n> directly using bitcoin script.\n> Have you considered first re-writing the Eltoo scripts with miniscript? Or\n> did someone else on this list attempt this already?\n> Do people on this list have opinions on whether that is the right\n> direction for Eltoo scripts (and maybe even for Bolt 1.x scripts if\n> *any_prevout* never makes it to Bitcoin scripts)?\n>\n> Cheers,\n> Bastien\n>\n> [1] http://bitcoin.sipa.be/miniscript/\n>\n> Le mer. 4 sept. 2019 \u00e0 13:20, Richard Myers <rich at gotenna.com> a \u00e9crit :\n>\n>> Hi All,\n>>\n>> To better understand how the eltoo update scheme (\n>> https://blockstream.com/eltoo.pdf ) works in practice I implemented\n>> eltoo in the Bitcoin functional test framework. These simulations exercise\n>> a concrete implementation of the eltoo Bitcoin scripts and explore the data\n>> flow between nodes that use eltoo to update their channel state.\n>>\n>> My motivation for creating these tests is to have a framework for both\n>> understanding and refining the Bitcoin scripts and message passing protocol\n>> for eltoo. I\u2019d love to hear what people think of my initial implementation.\n>>\n>> This simulation uses a fork of Bitcoin with cdecker\u2019s SIGHASH_NOINPUT\n>> patch applied to the signet2 fork fjahr created with patches applied for\n>> signet (kallewoof), taproot (sipa) and anyprevout* (ajtowns).\n>>\n>>\n>> https://github.com/remyers/signet2/blob/eltoo/test/functional/simulate_eltoo.py\n>>\n>> Next steps:\n>>\n>>    -\n>>\n>>    add bidirectional channel updates\n>>    -\n>>\n>>    derive public keys for settle transactions from a pre-shared basepoint\n>>\n>>\n>> Does anyone know of any other eltoo implementations? I\u2019d love to compare\n>> notes and get the ball rolling on a detailed specification.\n>>\n>> Special thanks to the Chaincode Summer Residency and Christian Decker for\n>> their helpful advice and encouragement while I worked on this project.\n>>\n>>   -- Richard\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190904/06f16b99/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "eltoo implementation in Bitcoin functional test framework",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Bastien TEINTURIER",
                "Richard Myers",
                "Antoine Riard"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 7905
        }
    },
    {
        "title": "[Lightning-dev] Avoiding gossip spam: how many updates do you need?",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2019-09-05T06:59:57",
                "message_text_only": "Hi all,\n\n        The next release of c-lightning will start suppressing gossip\nwhich comes too fast.  I have implemented a simple filter which allows\neach message (node_announcement or channel_update) ONCE PER DAY on\naverage, with a burst up to 4 times per day.  We will also discard\nidentical gossip messages (except timestamp and signature of course).\n\nIf people have a reason to want more frequent updates, please tell me\nnow!  If this is tolerable, it will avoid some of the more obvious\nscaling issues in future.\n\nWith 40,000 channels and 10,000 nodes, that caps us at about 90,000\n12 MB per day.  In practice much less.\n\nAs an aside, we're implementing other gossip reductions:\n\n1. We'll start using gossip_queries for backfilling, rather than\n   asking three peers for a complete copy if we think we've missed\n   something.[1]\n\n2. We will no longer ask for the last 24 hours of gossip on startup.[1]\n\n3. We already suppressed our own duplicate gossip, and only generated\n   \"disable\" updates if we had to return an error.\n\n4. My current code has us *never* generating two channel_update or\n   node_announcement less than 300 seconds apart.\n\n5. We have a PR to suppress reply gossip: if you send us a msg, we won't\n   return it to you.\n\n6. My current code has us issuing \"refresh\" updates only once every\n   13 days instead of the current 7.\n\nThe main motivation is one user who has a rPi on a 4G plan.  It's\npainful for him to restart his node at the moment, but I am determined\nto make it reasonable!\n\nCheers,\nRusty.\n[1] Not yet coded, but RSN."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-15T12:27:11",
                "message_text_only": "Good morning Rusty,\n\nAs it happens, I already proposed a possible use-case for relatively-common `channel_update`: https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-July/002055.html\nIn the final section I mention:\n\n> Suppose that in fact, YAijbOJA thinks that the capacity of the ZmnSCPxj<->YAijbOJA channel is too high on the YAijbOJA side.\n> And similarly, suppose Rene thinks the capacity of the Rene<->YAijbOJA channel is too high on the Rene side.\n>\n> Thus, both YAijbOJA and Rene would welcome the ZmnSCPxj proposal to rebalance, as it moves the capacities.\n> It may be that they are so welcoming of this proposal, that they are willing to waive the fee for the rebalance.\n>\n>I observe that many have already proposed \"negative routing fees\" in order to support rebalancing of their channels.\n> I also observe that routing fees are the cost used in pathfinding algorithms, and most pathfinding algorithms do not behave well with negative costs.\n>\n> But it is perfectly fine to use ***zero*** routing fees, I think.\n\nBriefly: if a channel has too much liquidity on your side, passively rebalance by broadcasting a `channel_update` with 0 routing fees.\nThis helps JIT-Routing of nearby nodes as it allows cheaper rebalances to support.\n\nOf course, it is still desirable to rate-limit such updates.\nSo we can do the below policy:\n\n1.  Maintain a \"latest broadcast is zero\" flag.\n2.  If the channel has been >=75% in your favor for more than 10 minutes (or whatever configuration you want), and the \"latest broadcast is zero\" flag is cleared, set it and broadcast a 0-fee `channel_update` and set your feerate to 0.\n3.  If the channel has been <75% in your favor, set your feerate to non-zero, but do not broadcast (meaning \"latest broadcast is zero\" flag does not change).\n4.  If the channel has been <75% in your favor for more than 10 minutes, and the \"latest broadcast is zero\" flag is set, clear it and broacast your normal `channel_update`.\n\nHowever this will probably still lead to more than a burst of 4 `channel_update`s per day.\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Thursday, September 5, 2019 2:59 PM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> Hi all,\n>\n> The next release of c-lightning will start suppressing gossip\n> which comes too fast. I have implemented a simple filter which allows\n> each message (node_announcement or channel_update) ONCE PER DAY on\n> average, with a burst up to 4 times per day. We will also discard\n> identical gossip messages (except timestamp and signature of course).\n>\n> If people have a reason to want more frequent updates, please tell me\n> now! If this is tolerable, it will avoid some of the more obvious\n> scaling issues in future.\n>\n> With 40,000 channels and 10,000 nodes, that caps us at about 90,000\n> 12 MB per day. In practice much less.\n>\n> As an aside, we're implementing other gossip reductions:\n>\n> 1.  We'll start using gossip_queries for backfilling, rather than\n>     asking three peers for a complete copy if we think we've missed\n>     something.[1]\n>\n> 2.  We will no longer ask for the last 24 hours of gossip on startup.[1]\n> 3.  We already suppressed our own duplicate gossip, and only generated\n>     \"disable\" updates if we had to return an error.\n>\n> 4.  My current code has us never generating two channel_update or\n>     node_announcement less than 300 seconds apart.\n>\n> 5.  We have a PR to suppress reply gossip: if you send us a msg, we won't\n>     return it to you.\n>\n> 6.  My current code has us issuing \"refresh\" updates only once every\n>     13 days instead of the current 7.\n>\n>     The main motivation is one user who has a rPi on a 4G plan. It's\n>     painful for him to restart his node at the moment, but I am determined\n>     to make it reasonable!\n>\n>     Cheers,\n>     Rusty.\n>     [1] Not yet coded, but RSN.\n>\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Christian Decker",
                "date": "2019-09-18T13:52:46",
                "message_text_only": "ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\nwrites:\n>> But it is perfectly fine to use ***zero*** routing fees, I think.\n>\n> Briefly: if a channel has too much liquidity on your side, passively\n> rebalance by broadcasting a `channel_update` with 0 routing fees.\n> This helps JIT-Routing of nearby nodes as it allows cheaper rebalances\n> to support.\n\nThis falls a bit outside of the scope of `channel_update`s if you ask\nme. `channel_update`s are meant to communicate coarse grained\ninformation about the channel to the rest of the network. They are not\nmeant to communicate in a local group of nodes. I'd rather have a\n`local_channel_update` that has a small TTL counted down on each hop to\nlimit its spread for this kind of communication. That local update can\nthen also bypass the rate-limiting.\n\n> Of course, it is still desirable to rate-limit such updates.\n> So we can do the below policy:\n>\n> 1.  Maintain a \"latest broadcast is zero\" flag.\n> 2.  If the channel has been >=75% in your favor for more than 10 minutes (or whatever configuration you want), and the \"latest broadcast is zero\" flag is cleared, set it and broadcast a 0-fee `channel_update` and set your feerate to 0.\n> 3.  If the channel has been <75% in your favor, set your feerate to non-zero, but do not broadcast (meaning \"latest broadcast is zero\" flag does not change).\n> 4.  If the channel has been <75% in your favor for more than 10 minutes, and the \"latest broadcast is zero\" flag is set, clear it and broacast your normal `channel_update`.\n>\n> However this will probably still lead to more than a burst of 4 `channel_update`s per day.\n\nThis is way more logic to add to an already complex set of rules. I'd\nprefer having separate negotiation logic for the scenarios you\npropose. `channel_update`s are coarse-grained on purpose and a really\nlarge hammer that is not well-suited for tiny adjustments like\nrebalancing. This is also the reason why I advocated for active\nrebalancing over indirect signalling through negative fees. Notice that\nyou can still allow zero-fee forwarding by using local updates as offers\nand then referencing the offer in the onion, without telling the wider\nworld about the balances in your channel, and without having to deal\nwith someone using that zero-fee much later than you needed it.\n\nCheers,\nChristian"
            }
        ],
        "thread_summary": {
            "title": "Avoiding gossip spam: how many updates do you need?",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Christian Decker",
                "ZmnSCPxj"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 7914
        }
    },
    {
        "title": "[Lightning-dev] Miniscript on LN (was: eltoo implementation in Bitcoin functional test framework)",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-05T11:29:35",
                "message_text_only": "Good morning list,\n\nI do not see much point in using miniscript for Lightning unless we decide to support transporting arbitrary contracts, as here: https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-August/001383.html\n\nOtherwise, it would be far easier implementation-wise, to just have carefully-coded SCRIPT to transport HTLCs.\nIt would even be possible, to write it in miniscript and compile it once, then debate endlessly on how to improve the output of the miniscript compiler, on the principle that all that a human-level or higher intelligence needs, to beat a compiler, is to make a single improvement to the compiled output.\n\nOn the other hand, if we *were* to support arbitrary contracts over payment channels, we should note:\n\n* Very few contracts are \"routable\" (only HTLCs and DLCs come to mind, and various HTLCs-yielding-HTLCs constructions) over the network.\n  * Supporting arbitrary routing would be a massive massive massive headache as forwarding nodes need to have some assurance they can claim the incoming if the outgoing is claimed, or similar.\n    * While miniscript is more amenable to programmatic analysis, I do not know what property needs to be actually proven in order to prove that contracts can be forwarded somehow.\n* Any absolute timelocks on the contract will imply that the hosting payment channel (and channel factory, for that matter) has a lifetime up to the timelock.\n  * This should be easy to extract from the miniscript.\n  * This is needed as the payment channel cannot actually enforce time, only the blockchain layer can, thus enforcement of the timelock can only be done onchain.\n  * For Decker-Russell-Osuntokun, the channel unilateral close needs to be started *before* the absolute timelock, with the channel security parameter of the CSV-delay before the absolute timelock.\n    For Poon-Dryja the channel unilateral close can be done on the block before the absolute timelock (or some more blocks before that as a safety margin).\n* Any contract will automatically get a `|| (A && B)` appended to it, where `A` and `B` are the channel counterparties.\n  * This is simply the right of all participants to agree to ignore the contract and settle it by other means, as in Smart Contracts Unchained: https://zmnscpxj.github.io/bitcoin/unchained.html\n  * Consider how `update_fail_htlc` works: the HTLC does not explicitly contain a clause by which it can simply be \"failed\" other than by the timelock branch.\n    Yet `update_fail_htlc` does not require waiting for the timelock to arrive.\n    * This is simply the fact that the payment channel can be updated such that the contrract is deleted outright, with the contract funds reallocated in any way that both participants agree.\n\n\nOf note is that a miniscript compiler would be quite useful if we were to support arbitrary contracts over Poon-Dryja channels.\nThis is because, as I pointed out in the linked post, there is a need to add the condition `&& (A && B) || (revoke)` to the contract in order to ensure that the transaction first pays out to a revocable output with an `nSequence` restriction.\nThe addition of these extra conditions would be trivial with miniscript, and the miniscript-to-SCRIPT compiler could potentially optimize away the extra conditions, if a Sufficiently Smart Compiler (TM) for miniscript is developed.\n\nOf course, under Decker-Russell-Osuntokun (which is what triggered this thread initially anyway), the additional conditions on the arbitrary contract are unnecessary and all that is needed is to analyze the contract for absolute timelocks.\n\nForwardability of arbitrary contracts is more difficult to prove; I cannot imagine how it can be done.\nBut surely it would be possible, my untrained intuition subroutine reports.\n\nRegards,\nZmnSCPxj\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Thursday, September 5, 2019 12:04 AM, Antoine Riard <antoine.riard at gmail.com> wrote:\n\n> Hello all,\n> Didn't listen to Pieter Wuille interview, so don't know how he was thinking to use miniscript for lightning.\n> But currently in lightning all our scripts are templates, a use of a miniscript compiler would be to find optimized bitcoin scripts for a given policy which model the channel and then hardcode them in lightning backend.\n> The other use I can see would be to use miniscript to write customizable conditional-payment than our basic HTLCs, real hurdle would be to implement on-chain monitoring and resolution right.\n> Not sure how Eltoo fit into it as it's a sighash extension to get a new update mechanism, miniscript seems more tailored for the transfer layer.\n>\n> Regards,\n> Antoine\n>\n> Le\u00a0mer. 4 sept. 2019 \u00e0\u00a008:53, Bastien TEINTURIER <bastien at acinq.fr> a \u00e9crit\u00a0:\n>\n> > Good morning Richard,\n> >\n> > This is an interesting initiative, I'm curious to see the results!\n> > I know we haven't worked on any Eltoo implementation yet at Acinq and I don't know if others have attempted it.\n> >\n> > However I have a very open question that may impact your project.\n> > I'm starting to look at miniscript [1] (still a total noob though) and listened to an interview where Pieter Wuille briefly mentioned that using miniscript for lightning may be more future-proof and extensible than directly using bitcoin script.\n> > Have you considered first re-writing the Eltoo scripts with miniscript? Or did someone else on this list attempt this already?\n> > Do people on this list have opinions on whether that is the right direction for Eltoo scripts (and maybe even for Bolt 1.x scripts if any_prevout never makes it to Bitcoin scripts)?\n> >\n> > Cheers,\n> > Bastien\n> >\n> > [1]\u00a0http://bitcoin.sipa.be/miniscript/\n> >\n> > Le\u00a0mer. 4 sept. 2019 \u00e0\u00a013:20, Richard Myers <rich at gotenna.com> a \u00e9crit\u00a0:\n> >\n> > > Hi All,\n> > >\n> > > To better understand how the eltoo update scheme ( https://blockstream.com/eltoo.pdf ) works in practice I implemented eltoo in the Bitcoin functional test framework. These simulations exercise a concrete implementation of the eltoo Bitcoin scripts and explore the data flow between nodes that use eltoo to update their channel state.\n> > >\n> > > My motivation for creating these tests is to have a framework for both understanding and refining the Bitcoin scripts and message passing protocol for eltoo. I\u2019d love to hear what people think of my initial implementation.\n> > >\n> > > This simulation uses a fork of Bitcoin with cdecker\u2019s SIGHASH_NOINPUT patch applied to the signet2 fork fjahr created with patches applied for signet (kallewoof), taproot (sipa) and anyprevout* (ajtowns).\n> > >\n> > > https://github.com/remyers/signet2/blob/eltoo/test/functional/simulate_eltoo.py\n> > >\n> > > Next steps:\n> > >\n> > > -   add bidirectional channel updates\n> > >\n> > > -   derive public keys for settle transactions from a pre-shared basepoint\n> > >\n> > >\n> > > Does anyone know of any other eltoo implementations? I\u2019d love to compare notes and get the ball rolling on a detailed specification.\n> > >\n> > > Special thanks to the Chaincode Summer Residency and Christian Decker for their helpful advice and encouragement while I worked on this project.\n> > >\n> > > \u00a0\u00a0-- Richard\n> > >\n> > > _______________________________________________\n> > > Lightning-dev mailing list\n> > > Lightning-dev at lists.linuxfoundation.org\n> > > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> >\n> > _______________________________________________\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "David A. Harding",
                "date": "2019-09-06T18:43:05",
                "message_text_only": "On Thu, Sep 05, 2019 at 11:29:35AM +0000, ZmnSCPxj via Lightning-dev wrote:\n> Good morning list,\n> \n> I do not see much point in using miniscript for Lightning unless we\n> decide to support transporting arbitrary contracts, as here:\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-August/001383.html\n> \n> Otherwise, it would be far easier implementation-wise, to just have\n> carefully-coded SCRIPT to transport HTLCs.\n\nSomething that has been impressed upon me is that using miniscript to\ncreate optimized Bitcoin scripts is perhaps not its primary use.\nMiniscript also makes it easy for any miniscript-aware wallet to figure\nout how to create a valid witness for the miniscript (if the wallet has the\nnecessary private keys, hash pre-images, and a function to satisfy any\ntimelocks).\n\nFor example, right now Pieter Wuille is working on incorporating\nminiscript into Bitcoin Core.  If there was then a miniscript for the\ncurrent LN scripts and someone imported their keys and invoice\npre-images[1] into their Bitcoin Core wallet, then Bitcoin Core could\nsign for their LN update and settlement transactions.  E.g., the\nC-Lightning \"HSM\" module could become a thin wrapper around Bitcoin\nCore's wallet (or any other miniscript-aware wallet).\n\nLater, other wallets such as hardware wallets and exchange HSMs may add\nsupport for libminiscript, making it easy for LN nodes to delegate\nsigning to outside devices without anyone having to change the code of\nthose hard-to-change devices.\n\nEven later than that, y'all may change the LN script either slightly or\ndramatically  If both the old script and the new script are miniscript\nbased, then maybe none of the wallets that already supported miniscript\nwill need to update their signing code---libminiscript will tell them\nwhat data they need to provide for the witness and, as long as they have\nfunctions capable of retrieving or generating that data, they'll\nautomatically know how to create a witness for the new miniscript.\n\nFinally, someday consensus changes like taproot and\nSIGHASH_NOINPUT/ANYPREVOUT may be activated.  If libminiscript is\nupdated for that change, getting wallets to support those changes may be\nas easy as updating their bundled libminiscript version.\n\nIn summary, miniscript does help you produce machine-optimized scripts\nand analyze them (and that's a pretty nifty feature by itself), but\nminiscript's true potential may come from allowing any wallet to sign for\nany miniscript-compatible script, freeing developers from having to\nwrite lots of sensitive signing code or heavily coordinating changes\nacross different software (as is common in LN).\n\n-Dave\n\n[1] I don't think this is currently possible, but adding support for it\nusing output script descriptors might not be difficult."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-09T04:06:22",
                "message_text_only": "Good morning David,\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Saturday, September 7, 2019 2:43 AM, David A. Harding <dave at dtrt.org> wrote:\n\n> > Good morning list,\n> > I do not see much point in using miniscript for Lightning unless we\n> > decide to support transporting arbitrary contracts, as here:\n> > https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-August/001383.html\n> > Otherwise, it would be far easier implementation-wise, to just have\n> > carefully-coded SCRIPT to transport HTLCs.\n>\n> Something that has been impressed upon me is that using miniscript to\n> create optimized Bitcoin scripts is perhaps not its primary use.\n> Miniscript also makes it easy for any miniscript-aware wallet to figure\n> out how to create a valid witness for the miniscript (if the wallet has the\n> necessary private keys, hash pre-images, and a function to satisfy any\n> timelocks).\n>\n> For example, right now Pieter Wuille is working on incorporating\n> miniscript into Bitcoin Core. If there was then a miniscript for the\n> current LN scripts and someone imported their keys and invoice\n> pre-images[1] into their Bitcoin Core wallet, then Bitcoin Core could\n> sign for their LN update and settlement transactions. E.g., the\n> C-Lightning \"HSM\" module could become a thin wrapper around Bitcoin\n> Core's wallet (or any other miniscript-aware wallet).\n\nThis seems an important point-of-fact.\nThank you for informing this.\n\nIt seems, there are some complications here, as the signing keys involved in various Lightning scripts are derived from base keys.\nThus, it seems to require also to somehow embed how the derivation is done.\nBOLT #3 has detail: https://github.com/lightningnetwork/lightning-rfc/blob/master/03-transactions.md#key-derivation\nThus the wallet not only needs to know the basepoint secret, but also the per-commitment-point for the specific state being signed for.\n\nStill, it should be doable, and I now see the value of using Miniscript for Lightning scripts.\n\nRegards,\nZmnSCPxj\n\n>\n> Later, other wallets such as hardware wallets and exchange HSMs may add\n> support for libminiscript, making it easy for LN nodes to delegate\n> signing to outside devices without anyone having to change the code of\n> those hard-to-change devices.\n>\n> Even later than that, y'all may change the LN script either slightly or\n> dramatically If both the old script and the new script are miniscript\n> based, then maybe none of the wallets that already supported miniscript\n> will need to update their signing code---libminiscript will tell them\n> what data they need to provide for the witness and, as long as they have\n> functions capable of retrieving or generating that data, they'll\n> automatically know how to create a witness for the new miniscript.\n>\n> Finally, someday consensus changes like taproot and\n> SIGHASH_NOINPUT/ANYPREVOUT may be activated. If libminiscript is\n> updated for that change, getting wallets to support those changes may be\n> as easy as updating their bundled libminiscript version.\n>\n> In summary, miniscript does help you produce machine-optimized scripts\n> and analyze them (and that's a pretty nifty feature by itself), but\n> miniscript's true potential may come from allowing any wallet to sign for\n> any miniscript-compatible script, freeing developers from having to\n> write lots of sensitive signing code or heavily coordinating changes\n> across different software (as is common in LN).\n>\n> -Dave\n>\n> [1] I don't think this is currently possible, but adding support for it\n> using output script descriptors might not be difficult."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-09T07:51:08",
                "message_text_only": "Good morning all,\n\nI saw also this thread: https://www.reddit.com/r/Bitcoin/comments/d19n6l/miniscript_streamlined_bitcoin_scripting/ezjb4ec/\n\nRegards,\nZmnSCPxj\n\n> Good morning David,\n>\n> Sent with ProtonMail Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Saturday, September 7, 2019 2:43 AM, David A. Harding dave at dtrt.org wrote:\n>\n> > > Good morning list,\n> > > I do not see much point in using miniscript for Lightning unless we\n> > > decide to support transporting arbitrary contracts, as here:\n> > > https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-August/001383.html\n> > > Otherwise, it would be far easier implementation-wise, to just have\n> > > carefully-coded SCRIPT to transport HTLCs.\n> >\n> > Something that has been impressed upon me is that using miniscript to\n> > create optimized Bitcoin scripts is perhaps not its primary use.\n> > Miniscript also makes it easy for any miniscript-aware wallet to figure\n> > out how to create a valid witness for the miniscript (if the wallet has the\n> > necessary private keys, hash pre-images, and a function to satisfy any\n> > timelocks).\n> > For example, right now Pieter Wuille is working on incorporating\n> > miniscript into Bitcoin Core. If there was then a miniscript for the\n> > current LN scripts and someone imported their keys and invoice\n> > pre-images[1] into their Bitcoin Core wallet, then Bitcoin Core could\n> > sign for their LN update and settlement transactions. E.g., the\n> > C-Lightning \"HSM\" module could become a thin wrapper around Bitcoin\n> > Core's wallet (or any other miniscript-aware wallet).\n>\n> This seems an important point-of-fact.\n> Thank you for informing this.\n>\n> It seems, there are some complications here, as the signing keys involved in various Lightning scripts are derived from base keys.\n> Thus, it seems to require also to somehow embed how the derivation is done.\n> BOLT #3 has detail: https://github.com/lightningnetwork/lightning-rfc/blob/master/03-transactions.md#key-derivation\n> Thus the wallet not only needs to know the basepoint secret, but also the per-commitment-point for the specific state being signed for.\n>\n> Still, it should be doable, and I now see the value of using Miniscript for Lightning scripts.\n>\n> Regards,\n> ZmnSCPxj\n>\n> > Later, other wallets such as hardware wallets and exchange HSMs may add\n> > support for libminiscript, making it easy for LN nodes to delegate\n> > signing to outside devices without anyone having to change the code of\n> > those hard-to-change devices.\n> > Even later than that, y'all may change the LN script either slightly or\n> > dramatically If both the old script and the new script are miniscript\n> > based, then maybe none of the wallets that already supported miniscript\n> > will need to update their signing code---libminiscript will tell them\n> > what data they need to provide for the witness and, as long as they have\n> > functions capable of retrieving or generating that data, they'll\n> > automatically know how to create a witness for the new miniscript.\n> > Finally, someday consensus changes like taproot and\n> > SIGHASH_NOINPUT/ANYPREVOUT may be activated. If libminiscript is\n> > updated for that change, getting wallets to support those changes may be\n> > as easy as updating their bundled libminiscript version.\n> > In summary, miniscript does help you produce machine-optimized scripts\n> > and analyze them (and that's a pretty nifty feature by itself), but\n> > miniscript's true potential may come from allowing any wallet to sign for\n> > any miniscript-compatible script, freeing developers from having to\n> > write lots of sensitive signing code or heavily coordinating changes\n> > across different software (as is common in LN).\n> > -Dave\n> > [1] I don't think this is currently possible, but adding support for it\n> > using output script descriptors might not be difficult.\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            }
        ],
        "thread_summary": {
            "title": "Miniscript on LN (was: eltoo implementation in Bitcoin functional test framework)",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "David A. Harding",
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 17963
        }
    },
    {
        "title": "[Lightning-dev] Reconciling the off-chain and on-chain models with eltoo",
        "thread_messages": [
            {
                "author": "Christian Decker",
                "date": "2019-09-06T13:18:03",
                "message_text_only": "With the recently published proof-of-concept of eltoo on signet by\nRichard, I thought it might a good time to share some thoughts on ho I\nthink we can build this system. I think there are a few properties of\neltoo that allow us to build a nicely layered protocol stack, which\nimproves flexibility and simplifies the reasoning about their relative\nsecurity.\n\nSince I don't like huge e-mails myself and I'm about to write one,\nhere's a quick TL;DR:\n\n> Using the clean separation of protocol layers provided by eltoo we can\n> reconcile many on-chain and off-chain concepts, and simplify the\n> reasoning to build more complex functionality beyond simple\n> HTLCs. Bitcoin transactions are a natural fit to represent proposed\n> off-chain state-changes while they are being negotiated.\n\n\n### Clean separation of protocol layers\n\nOne of te big advantages of eltoo over other off-chain update mechanisms\nis that it provides strong guarantees regarding the state that will\neventually end up confirmed on-chain. If parties in an eltoo off-chain\ncontract agree on an update, we can be certain (within eltoo's security\nassumptions) that this is the state that will eventually confirm\non-chain, if no newer states are agreed.\n\nIn particular it means that we are guaranteed no earlier state can leak\nonto the chain, keeping anything we build on top of the update layer\nunencumbered since it doesn't have to deal with this case.\n\nThis is in stark contrast to the penalty update mechanism, where\nold/revoked states can leak on-chain, resulting in anything built on top\nof the penalty mechanism having to deal with that eventuality. For\nexample if we look at HTLCs as specified [1] we see that it needs an\nadditional revokation path for the case the commitment transaction that\ncreated this HTLC output is confirmed:\n\n```btcscript\n# To remote node with revocation key\nOP_DUP OP_HASH160 <RIPEMD160(SHA256(revocationpubkey))> OP_EQUAL\nOP_IF\n    OP_CHECKSIG\nOP_ELSE\n    <remote_htlcpubkey> OP_SWAP OP_SIZE 32 OP_EQUAL\n    OP_IF\n        # To local node via HTLC-success transaction.\n        OP_HASH160 <RIPEMD160(payment_hash)> OP_EQUALVERIFY\n        2 OP_SWAP <local_htlcpubkey> 2 OP_CHECKMULTISIG\n    OP_ELSE\n        # To remote node after timeout.\n        OP_DROP <cltv_expiry> OP_CHECKLOCKTIMEVERIFY OP_DROP\n        OP_CHECKSIG\n    OP_ENDIF\nOP_ENDIF\n```\n\nThe update mechanism bleeding into the other layers is rather cumbersome\nif you ask me, and complicates the reasoning about security. Having to\nthread the penalty through outputs created by the off-chain contract may\nalso not work if we deal with more than 2 parties, since penalties\nalways steal all the funds, regardless of whether the output belonged to\nthe cheater or not (see asymmetry vs symmetry argument from the paper\n[2]).\n\nWith the clean separation we get from eltoo we can concentrate on\nbuilding the output scripts we'd like to have without having to thread\npenalties through them. This reduces the complexity and our on-chain\nfootprint.\n\nThe update layer now exposes only two very simple operations:\n`add_output` and `remove_output` (this should sound very familiar :-p).\n\n\n### Ownership and atomic update model\n\nNow that we have a solid update layer, which ensures that agreed upon\nstates will eventually be reflected on-chain, we can turn our attention\nto the next layer up: the negotiation layer. Each output in our\nagreed-upon state needs to be assigned one or more owners. The owners\nare the participants that need to sign off on removal of an output and\nthe creation of new outputs which redistribute the funds contained in\nthe removed outputs to newly created outputs.\n\nIn addition we need to ensure that multiple `remove_output` and\n`add_output` are guaranteed to be applied atomically. By creating a\ndatastructure that lists a number of operations that are to either be\napplied to the current state or discarded, we can have arbitrary complex\nchanges of ownership, and the newly created outputs can have arbitrary\nscripts.\n\nIf all of this sounds familiar that's because this is exactly the UTXO\nmodel and the transaction structure we have in Bitcoin. We\ncollaboratively manage funds bound to some outputs (UTXO) and can change\ntheir ownership and allocation over time (transactions).\n\nThis means that a subset of the participants in an off-chain contract\ncan negotiate among themselves how to redistribute funds, join and split\nthem in an arbitrary fashion, without the rest of the contract being\ninvolved. The end result is a valid Bitcoin transaction that spends some\noutputs of the current state, and is signed by the owners. The\ntransaction can then be presented to the entire group, and applied to\nthe state. Applying the transaction flattens multiple transactions built\non top of the current state into a new state (similar to transaction\ncut-through in mimblewimble).\n\nUsing transactions as a means to represent off-chain negotiations, and\nthen applying them to the off-chain state via cut-through has a number\nof advantages over similar schemes:\n\n- Even if we failed to update the off-chain state, the transactions\n  building on top of it are valid transactions, so once we tear down\n  the channel, our negotiated new state can still be reached by\n  broadcasting the transaction after settlement (this is basically\n  what the channel factory paper [3] was using).\n    \n- We can reuse a lot of tools that we have already built for on-chain\n  transactions, including things like miniscript and hardware wallets,\n  without explicitly requiring them in our own specification. The\n  Bitcoin object model is our interface here.\n\n- It allows for experimentation even inside a running eltoo instance. If\n  you can find another participant that supports a fancy new protocol,\n  you can use that protocol even though some of the other participants\n  may not know anything about it. As long as you can understand the\n  Bitcoin transaction model you can participate in a multi-party\n  channel.\n\nI think this reconciliation between the off-chain model and the on-chain\nmodel, with many concepts cleanly mapping from one context to another\n(state outputs = UTXO, off-chain update = on-chain transactions,\ncut-through = confirmation, operation batching = block creation) is\nrather nice :-)\n\nThat should be enough rambling on my side. I'm interested in what others\nthink about this. Is it completely off, does it make no sense at all, or\nis this something we should be looking into going forward?\n\nCheers,\nChristian\n\n[1] https://github.com/lightningnetwork/lightning-rfc/blob/master/03-transactions.md#received-htlc-outputs\n[2] https://blockstream.com/eltoo.pdf\n[3] https://tik-old.ee.ethz.ch/file/a20a865ce40d40c8f942cf206a7cba96/Scalable%5FFunding%5FOf%5FBlockchain%5FMicropayment%5FNetworks.pdf"
            }
        ],
        "thread_summary": {
            "title": "Reconciling the off-chain and on-chain models with eltoo",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Decker"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 6749
        }
    },
    {
        "title": "[Lightning-dev] [bitcoin-dev] Reconciling the off-chain and on-chain models with eltoo",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-06T14:32:38",
                "message_text_only": "Good morning Christian,\n\nThis is effectively transaction cut-through.\nI mention this in passing here: https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-April/001986.html\n\n> I observe that one may consider any offchain system a specialization of an offchain transaction cut-through system.\n> Thus, one may model changes to the offchain system state as the creation of some transactions, followed by a cut-through of those transactions into the new state.\n\nBasically, we can send a transaction that spends a subset of the current state txos to the participants in the update mechanism.\nThen the participants can agree that it is a valid spend of the specified state txos, and agree to sign a new state with the spent txos deleted and the new txos of the transaction inserted.\nDisagreement at this point is essentially a \"if your tx is so valid why do you not try it on the base blockchain layer huh?\" challenge and is basically an invitation to close it unilaterally and enforce the contract on the blockchain.\n\nThe \"difficulty\" in Poon-Dryja is not very onerous in my opinion; see the sketch here: https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-August/001383.html\n\nOf note is that any contract with a relative locktime requirement would not make sense to maintain offchain.\nIf one wishes to select a relative locktime relative to the current moment, one can quite easily compute an absolute timelock.\n\nAnother note, is that contracts with timelocks need to be enforced onchain on or before the timelock.\nUnder Decker-Russell-Osuntokun the onchain enforcement needs to be triggered early according to the CSV security parameter; this is not an issue under Poon-Dryja (as the CSV is in a later transaction).\nUnder Decker-Russell-Osuntokun due to the use of `SIGHASH_NOINPUT` and the non-stable txids involved, any transaction you wish to transport in the offchain update mechanism needs to also be signed under `SIGHASH_NOINPUT`, but again this is not onerous.\nIn any case it is \"only\" a matter of tradeoffs one is willing to work under anyway, and Decker-Russell-Osuntokun is very cool and uses `nLockTime` and `OP_CHECKLOCKTIMEVERIFY` in a very clever way.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Richard Myers",
                "date": "2019-09-09T16:38:41",
                "message_text_only": "I believe using the eltoo update scheme as a way to consolidate blocks of\noff-chain transactions is an interesting idea worth exploring.\n\nZmnSCPxj brings up some limitations on arbitrary outputs scripts in eltoo.\nAlthough using CSV is more complicated and outputs must also use\nSIGHASH_NOINPUT [1], the ability to have multiple party channels and the\nmost used types of scripts makes eltoo compelling compared to LN-Penalty\nfor this kind of application.\n\nThe multiple party aspect in particular introduces an interesting way to\nunify concepts from different second layer protocols like federated\nsidechains and statechains (ht. aakselrod [2]).\n\nThough the Statechains proposal relies on eltoo [3], I think what Christian\nsuggested does not try to solve the dynamic membership problem. That's why\nI think of this as more an evolution of the channel factory paper towards\nsomething like a federated sidechain.\n\nI think this reconciliation between the off-chain model and the on-chain\n> model, with many concepts cleanly mapping from one context to another\n> (state outputs = UTXO, off-chain update = on-chain transactions,\n> cut-through = confirmation, operation batching = block creation) is\n> rather nice :-)\n\n\nOne additional concept that could be new to this off-chain blockchain model\nwould be something like batched multi-party loop-in/out. In a\nSchnorr/Taproot world you could add signers/inputs and remove\nsigners/outputs with a single multi-signature negotiated off-chain. You'd\nstill like to limit these onchain txs, even if they are small, but updating\nchannels periodically seems like a straight forward way to address the\ndynamic membership problem.\n\nI guess this all gets back to how to design an off-chain protocol for\nmanaging these negotiations. Ultimately I can imagine a sort of multi-party\neltoo based 'signet' with the same RPC interface, but different transaction\nvalidation and block creation logic.  Perhaps there would be a new message\nwhere the channel parties would add their signature before forwarding a\nvalid block, and the block wouldn't be built on until all parties had\nsigned.\n\n[1]\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2018-August/001383.html\n[2] https://twitter.com/stile65/status/1171030423394078720\n[3]\nhttps://medium.com/@RubenSomsen/statechains-non-custodial-off-chain-bitcoin-transfer-1ae4845a4a39\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190909/bb60fee0/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-10T01:28:04",
                "message_text_only": "Good morning Richard,\n\n> I believe using the eltoo update scheme as a way to consolidate blocks of off-chain transactions is an interesting idea worth exploring.\u00a0\u00a0\n>\n> ZmnSCPxj brings up some limitations on arbitrary outputs scripts in eltoo. Although using CSV is more complicated and outputs must also use SIGHASH_NOINPUT [1], the ability to have multiple party channels and the most used types of scripts makes eltoo compelling compared to LN-Penalty for this kind of application.\n\nI broadly agree.\n\nI imagine a future where most people do not typically have single-signer ownership of coins onchain, but are instead share-owners of coins, with single-signer ownership occurring onchain only in the case of dispute or for long-term cold storage.\n\n>\n> The multiple party aspect in particular introduces an interesting way to unify concepts from different second layer protocols like federated sidechains and statechains (ht.\u00a0aakselrod [2]).\n>\n> Though the Statechains proposal relies on eltoo [3], I think what Christian suggested does not try to solve the dynamic membership problem. That's why I think of this as more an evolution of the channel factory paper towards something like a federated sidechain.\n>\n> > I think this reconciliation between the off-chain model and the on-chain\n> > model, with many concepts cleanly mapping from one context to another\n> > (state outputs = UTXO, off-chain update = on-chain transactions,\n> > cut-through = confirmation, operation batching = block creation) is\n> > rather nice :-)\n>\n> One additional concept that could be new to this off-chain blockchain model would be something like batched multi-party loop-in/out. In a Schnorr/Taproot world you could add signers/inputs and remove signers/outputs with a single multi-signature negotiated off-chain. You'd still like to limit these onchain txs, even if they are small, but updating channels periodically seems like a straight forward way to address the dynamic membership problem.\n\nIndeed.\nSuch a change-in-membership transaction would be a 1-input 1-output transaction, and with use of n-of-n MuSig would be as small (and as private, modulo the fact that you are coordinating this with a bunch of other participants) as a single-sig user making a 1-input 1-output transaction (which generally is not very private because such transactions are usually \"send-to-self\" and changing membership generally means ownership does not actually change much).\nThe cost of this transaction would be small (certainly smaller than the update+state transactions needed in Decker-Russell-Osuntokun)\n\nFor setting this up, it might be useful to have the below ritual.\nThis assumes only a change in the membership set is desired, without a simultaneous change in the UTXO set.\n\n1.  Create a new update+state transaction for the current Decker-Russell-Osuntokun mechanism.\n    The state transaction pays out to a single output paying to the new membership set rather than the current UTXO set of the mechanism.\n    Do *not* sign this yet.\n    Call this the \"final\" update+state transaction.\n2.  Create a new Decker-Russell-Osuntokun mechanism initial update+state transaction.\n    This pays out to the current UTXO set of the previous mechanism.\n    This will spend from the new membership set.\n    Completely sign these transactions.\n    * The update transaction can spend the above \"final\" transaction, as it is `SIGHASH_NOINPUT`.\n3.  Sign the final update+state transaction of the previous Decker-Russell-Osuntokun mechanism.\n    Do *not* broadcast the update+state transaction yet.\n4.  Create and sign the membership-change onchain transaction.\n    This spends the current onchain funding transaction output and outputs to the same new membership set.\n    Broadcast this onchain.\n\nThe above ritual ensures that, after step 3 completes, the mechanism can continue operating without waiting for onchain activity to complete.\nIt ensures that, even if the membership-change onchain transaction becomes invalid later (by somebody bribing a miner to publish a previous update transaction from the older membership set), we will still enter an update that will eventually put the new membership set onchain.\nThis reduces the critical path to only steps 1 to 3, and we can continue operating with the new membership set as soon as step 3 completes and we do not need to wait for the membership-change transaction to be deeply-confirmed in order to use the new membership set mechanism.\n\nHowever, it has the drawback that, until the membership-change onchain transaction is deeply-confirmed onchain, the CSV parameter is temporarily doubled (as there is the possibility that the previous mechanism is closed).\nAlso, the mechanism cannot be mutually closed until the membership-change onchain transaction is deeply-confirmed, as there is no stable txid we can spend from (we would strongly prefer to use `SIGHASH_ALL` for cooperative closes to improve our privacy).\n\n>\n> I guess this all gets back to how to design an off-chain protocol for managing these negotiations. Ultimately I can imagine a sort of multi-party eltoo based 'signet' with the same RPC interface, but different transaction validation and block creation logic.\u00a0 Perhaps there would be a new message where the channel parties would add their signature before forwarding a valid block, and the block wouldn't be built on until all parties had signed.\n\nThe \"block\" that would need to be signed by the participants would actually be a Decker-Russell-Osuntokun update+state transaction, and would commit to the UTXO set rather than the transaction set.\nUnless I misunderstand your meaning here.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Richard Myers",
                "date": "2019-09-16T14:08:56",
                "message_text_only": "Thanks for the feedback ZmnSCPxj.\n\nI imagine a future where most people do not typically have single-signer\n> ownership of coins onchain, but are instead share-owners of coins, with\n> single-signer ownership occurring onchain only in the case of dispute or\n> for long-term cold storage.\n>\n\nThe change-in-membership ritual you describe seems like a good start for\nelaborating on this idea.\n\nSome aspects of multi-party Decker-Russell-Osuntokun channels have analogs\nto a signet blockchain that use a n-of-n federation of signers. But other\nplaces, like change-in-membership, do not have direct analogs.\n\nFor example, some signet concepts with multi-party channel analogs:\n\nblock script:\n* the first 'update' and 'settle' transactions, aka 'setup' and 'refund'\ntransactions, define the set of signers that must sign subsequent channel\nupdates\n\ngenesis block:\n* the initial 'funding' transaction, aka outpoint of the commitment\ntransaction, which establishes the funded channel\n\nutxo set:\n* the specific set of on-chain outputs from the 'settlement' transaction\nthat spends the balance of the latest 'update' transaction signed by the\ncomplete set of channel parties.\n\nmempool:\n* the set of proposals for specific changes to the set of outputs from the\nlatest 'settlement' transaction (similar to update_add_htlc,\nupdate_fail_htlc, etc)\n\nConcepts where layer two channels do not have an obvious analog to a layer\none signet blockchain:\n\ncooperative close:\n* when all parties mutually agree to close the channel\n* close the channel with a layer one transaction which finalizes the\noutputs from the most recent channel output state\n* should be optimized for privacy and low on-chain fees\n\nmembership change (ZmnSCPxj ritual):\n* when channel parties want to leave or add new members to the channel\n* close and reopen a new channel via something like a channel splicing\ntransaction to the layer one blockchain\n* should be optimized for privacy and low on-chain fees paid for by parties\nentering and leaving the channel\n\nbalance change (similar to membership change):\n* when channel parties want to add or remove some of the finalized value in\nthe channel\n* close and reopen a new channel via something like a channel splicing\ntransaction to the layer one blockchain\n* should be optimized for privacy and low on-chain fees paid for by parties\nadding and removing value from the channel\n\nuncooperative close:\n* when one or more nodes fails to sign the next channel state update\n* use a layer one transaction to commit both finalized and un-finalized\noutputs from the most recent channel output state\n* script timeouts determine when channel parties should uncooperatively\nclose the channel if not all parties have signed the next 'update' and\n'settlement' transaction\n\nuncooperative membership change:\n* a subset of channel parties might want to cooperatively sign a channel\nsplicing transaction to 'splice out' uncooperative parties\n\nmining, mining reward and difficulty adjustment\n* no equivalent concept for multi-party channels\n\ntransaction fees:\n* updates to layer two channels do not incur transactions fees\n* invalid updates dropped to layer one should be paid by cheating node\n* splice in/out transactions should be paid by requesting signers only\n* do transaction fees prevent 'griefing' attacks?\n\nprivacy:\n* disassociate a particular update from signer(s)\n* disassociate IP address of signers from signature\n* using SIGHASH_ALL for cooperative closes\n\nliveness:\n* if signers know they will be offline, can they pre-sign updates that just\ncommit their own outputs, rather then splice out?\n* contingent tap-leafs to splice out non-responsive signers\n\nThe \"block\" that would need to be signed by the participants would actually\n> be a Decker-Russell-Osuntokun update+state transaction, and would commit to\n> the UTXO set rather than the transaction set.\n> Unless I misunderstand your meaning here.\n>\n\n Oops, ya, I did mean a \"block\" to be a particular Decker-Russell-Osuntokun\nupdate+state transaction.\n\nI think it will be useful to have these ideas in the back of my mind as I\nwork on making eltoo scripts that support multi-party channels.\n\n-- \nRichard Myers\nDecentralized Applications Engineer, goTenna\ngotenna.com\n@gotenna\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190916/afc6b87e/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-18T05:28:38",
                "message_text_only": "Good morning Richards, and list,\n\n> Thanks for the feedback ZmnSCPxj.\n>\n> > I imagine a future where most people do not typically have single-signer ownership of coins onchain, but are instead share-owners of coins, with single-signer ownership occurring onchain only in the case of dispute or for long-term cold storage.\n>\n> The change-in-membership ritual you describe seems like a good start for elaborating on this idea.\u00a0\n>\n> Some aspects of multi-party Decker-Russell-Osuntokun channels have analogs to a signet blockchain that use a n-of-n federation of signers. But other places, like change-in-membership, do not have direct analogs.\n>\n> For example, some signet concepts with multi-party channel analogs:\n>\n> block script:\n> * the first 'update' and 'settle' transactions, aka 'setup' and 'refund' transactions, define the set of signers that must sign subsequent channel updates\n>\n> genesis block:\n> * the initial 'funding' transaction, aka outpoint of the commitment transaction, which establishes the funded channel\n>\n> utxo set:\n> * the specific set of on-chain outputs from the 'settlement' transaction that spends the balance of the latest 'update' transaction signed by the complete set of channel parties.\n>\n> mempool:\n> * the set of proposals for specific changes to the set of outputs from the latest 'settlement' transaction (similar to update_add_htlc, update_fail_htlc, etc)\n>\n> Concepts where layer two channels do not have an obvious analog to a layer one signet blockchain:\n>\n> cooperative close:\n> * when all parties mutually agree to close the channel\n> * close the channel with a layer one transaction which finalizes the outputs from the most recent channel output state\n> * should be optimized for privacy and low on-chain fees\n\nOf note is that a close of an update mechanism does not require the close of any hosted update mechanisms, or more prosaically, \"close of channel factory does not require close of hosted channels\".\nThis is true for both unilateral and cooperative closes.\n\nOf course, the most likely reason you want to unilaterally close an outer mechanism is if you have some contract in some deeply-nested mechanism that will absolute-locktime expire \"soon\", in which case you have to close everything that hosts it.\nBut for example if a channel factory has channels A B C and only A has an HTLC that will expire soon, while the factory and A have to close, B and C can continue operation, even almost as if nothing happened to A.\n\n>\n> membership change (ZmnSCPxj ritual):\n> * when channel parties want to leave or add new members to the channel\n> * close and reopen a new channel via something like a channel splicing transaction to the layer one blockchain\n> * should be optimized for privacy and low on-chain fees paid for by parties entering and leaving the channel\n\nAssuming you mean that any owned funds will eventually have to be claimed onchain, I suppose this is doable as splice-out.\n\nBut note that currently we have some issues with splice-in.\n\nAs far as I can tell (perhaps Lisa Neigut can correct me, I believe she is working on this), splice-in has the below tradeoffs:\n\n1.  Option 1: splice-in is async (other updates can continue after all participants have sent the needed signatures for the splice-in).\n    Drawback is that spliced-in funds need to be placed in a temporary n-of-n, meaning at least one additional tx.\n2.  Option 2: splice-in is efficient (only the splice-in tx appears onchain).\n    Drawback is that subsequent updates can only occur after the splice-in tx is deeply confirmed.\n    * This can be mitigated somewhat by maintaining a pre-splice-in and post-splice-in mechanism, until the splice-in tx is deeply confirmed, after which the pre-splice-in version is discarded.\n      Updates need to be done on *both* mechanisms until then, and any introduced money is \"unuseable\" anyway until the splice-in tx confirms deeply since it would not exist in the pre-splice-in mechanism yet.\n\nBut perhaps a more interesting thing (and more in keeping with my sentiment \"a future where most people do not typically have single-signer ownership of coins onchain\") would be to transfer funds from one multiparticipant offchain mechanism to another multiparticipant offchain, by publishing a single transaction onchain.\nIt may be doable via some extension of my proposed ritual for changing membership set.\n\n>\n> balance change (similar to membership change):\n> * when channel parties want to add or remove some of the finalized value in the channel\n> * close and reopen a new channel via something like a channel splicing transaction to the layer one blockchain\n> * should be optimized for privacy and low on-chain fees paid for by parties adding and removing value from the channel\n>\n> uncooperative close:\n> * when one or more nodes fails to sign the next channel state update\n> * use a layer one transaction to commit both finalized and un-finalized outputs from the most recent channel output state\n> * script timeouts determine when channel parties should uncooperatively close the channel if not all parties have signed the next 'update' and 'settlement' transaction\n>\n> uncooperative membership change:\n> * a subset of channel parties might want to cooperatively sign a channel splicing transaction to 'splice out' uncooperative parties\n\nI believe this is currently considered unsafe.\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2019-April/001975.html\n\nUnless you refer to another mechanism...?\n\nI believe this will end up requiring deep confirmation of the uncooperative close followed by a new mechanism open.\n\n>\n> mining, mining reward and difficulty adjustment\n> * no equivalent concept for multi-party channels\n\nFees for each update.\nConsider how HTLC routing in Lightning implicitly pays forwarding nodes to cooperate with the forwarding.\nI imagine most nodes in a multiparticipant offchain system will want to be paid for cooperation, even if just a nominal sub-satoshi amount.\n\n>\n> transaction fees:\n> * updates to layer two channels do not incur transactions fees\n> * invalid updates dropped to layer one should be paid by cheating node\n> * splice in/out transactions should be paid by requesting signers only\n> * do transaction fees prevent 'griefing' attacks?\n>\n> privacy:\n> * disassociate a particular update from signer(s)\n> * disassociate IP address of signers from signature\n> * using SIGHASH_ALL for cooperative closes\n\nI suppose Tor can be used to disassociate IP address from signers if everyone is from a hidden service.\nHowever, we need to include some kind of mix mechanism to allow individual signers to disassociate their ownership of funds from their identity as signers.\nThough such mechanisms already exist as theoretical constructs, so \"just needs implementing\".\n\nBut then again: if you own funds in the mechanism, you *should* be a signer (else you are trusting a federation).\nSo a basic fact here is that if you are a participant in some offchain mechanism, you are likely (approaching 100% probability) to own money in it.\n\n>\n> liveness:\n> * if signers know they will be offline, can they pre-sign updates that just commit their own outputs, rather then splice out?\n> * contingent tap-leafs to splice out non-responsive signers\n\nIt might be possible to create a new mechanism-within-mechanism layer, if a signer knows they will be offline.\n\nFor example, suppose entities A, B, and C have an offchain update mechanism, which we shall call a \"factory\".\nSuppose this factory contains an A-B channel, a B-C channel, a A-C channel, and some funds owned by B only.\nThen suppose A knows he or she will be offline for some time.\nBefore A goes offline, they can move from this UTXO set:\n\n* A-B channel\n* B-C channel\n* A-C channel\n* B funds\n\nTo this UTXO set:\n\n* A-B channel\n* A-C channel\n* B-C offchain update mechanism (sub-factory), which itself has its own UTXO set:\n  * B-C channel\n  * B funds\n\nThis allows B and C to manage the B-C channels and B funds without cooperation of A.\nThen, later, when A returns online, the B-C offchain update mechanism is collapsed back to the parent A-B-C offchain update mechanism.\n\nThis assumes A knows it will be offline (which it might do for e.g. regular maintenance, or software updates).\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Christian Decker",
                "date": "2019-09-18T13:44:47",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n>> cooperative close:\n>> * when all parties mutually agree to close the channel\n>> * close the channel with a layer one transaction which finalizes the outputs from the most recent channel output state\n>> * should be optimized for privacy and low on-chain fees\n>\n> Of note is that a close of an update mechanism does not require the\n> close of any hosted update mechanisms, or more prosaically, \"close of\n> channel factory does not require close of hosted channels\".  This is\n> true for both unilateral and cooperative closes.\n>\n> Of course, the most likely reason you want to unilaterally close an\n> outer mechanism is if you have some contract in some deeply-nested\n> mechanism that will absolute-locktime expire \"soon\", in which case you\n> have to close everything that hosts it.  But for example if a channel\n> factory has channels A B C and only A has an HTLC that will expire\n> soon, while the factory and A have to close, B and C can continue\n> operation, even almost as if nothing happened to A.\n\nIndeed this is something that I think we already mentioned back in the\nduplex micropayment channel days, though it was a bit hidden and only\nmentioned HTLCs (though the principle carries over for other structures\nbuilt on the raw update mechanism):\n\n> The process simply involves one party creating the teardown\n> transaction, both parties signing it and committing it to the\n> blockchain. HTLC outputs which have not been removed by agreement can\n> be copied over to the summary transaction such that the same timelocks\n> and resolution rules apply.\n\nNotice that in the case of eltoo the settlement transaction is already\nthe same as the teardown transaction in DMC.\n\n>> membership change (ZmnSCPxj ritual):\n>> * when channel parties want to leave or add new members to the channel\n>> * close and reopen a new channel via something like a channel splicing transaction to the layer one blockchain\n>> * should be optimized for privacy and low on-chain fees paid for by parties entering and leaving the channel\n>\n> Assuming you mean that any owned funds will eventually have to be\n> claimed onchain, I suppose this is doable as splice-out.\n>\n> But note that currently we have some issues with splice-in.\n>\n> As far as I can tell (perhaps Lisa Neigut can correct me, I believe\n> she is working on this), splice-in has the below tradeoffs:\n>\n> 1.  Option 1: splice-in is async (other updates can continue after all participants have sent the needed signatures for the splice-in).\n>     Drawback is that spliced-in funds need to be placed in a temporary\n>     n-of-n, meaning at least one additional tx.\n\nIndeed this is the first proposal I had back at the Milan spec meeting,\nand you are right that it requires stashing the funds in a temporary\nco-owned output to make sure the transition once we splice in is\natomic. Batching could help here, if we have 3 participants joining they\ncan coordinate to set the funds aside together and then splice-in at the\nsame time. The downside is the added on-chain transaction, and the fact\nthat the funds are not operational until they reach the required depth\n(I don't think we can avoid this with the current security guarantees\nprovided by Bitcoin). Notice that there is still some uncertainty\nregarding the confirmation of the splice-in even though the funds were\nstashed ahead of time, and we may end up in a state where we assumed\nthat the splice-in will succeed, but the fees we attached turn out to be\ntoo low. In this case we built a sandcastle that collapses due to our\nfoundation being washed away, and we'd have to go back and agree on\nre-splicing with corrected fees (which a malicious participant might\nsabotage) or hope the splice eventually confirms.\n\n> 2.  Option 2: splice-in is efficient (only the splice-in tx appears onchain).\n>     Drawback is that subsequent updates can only occur after the splice-in tx is deeply confirmed.\n>     * This can be mitigated somewhat by maintaining a pre-splice-in\n>     and post-splice-in mechanism, until the splice-in tx is deeply\n>     confirmed, after which the pre-splice-in version is discarded.\n>       Updates need to be done on *both* mechanisms until then, and any\n>     introduced money is \"unuseable\" anyway until the splice-in tx\n>     confirms deeply since it would not exist in the pre-splice-in\n>     mechanism yet.\n\nThis is the more complex variant we discussed during the last\nface-to-face in Australia, and it seemed to me that people were mostly\nin favor of doing it this way. It adds complexity since we maintain\nmultiple variants (making it almost un-implementable in LN-penalty),\nhowever the reduced footprint, and the uncertainty regarding\nconfirmations in the first solution are strong arguments in favor of\nthis option.\n\n> But perhaps a more interesting thing (and more in keeping with my\n> sentiment \"a future where most people do not typically have\n> single-signer ownership of coins onchain\") would be to transfer funds\n> from one multiparticipant offchain mechanism to another\n> multiparticipant offchain, by publishing a single transaction onchain.\n> It may be doable via some extension of my proposed ritual for changing\n> membership set.\n\nAside from a bit more coordination I don't see any roadblocks to do\nthis, and it'd be an awesome improvement. It even allows sub-dust\ntransfers between channels, as long as the total funds in the channel\nremain above dust :-)\n\n>> uncooperative membership change:\n>> * a subset of channel parties might want to cooperatively sign a channel splicing transaction to 'splice out' uncooperative parties\n>\n> I believe this is currently considered unsafe.\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-April/001975.html\n>\n> Unless you refer to another mechanism...?\n>\n> I believe this will end up requiring deep confirmation of the\n> uncooperative close followed by a new mechanism open.\n\nNot necessarily. If we have an escape hatch in the scripts that allows\nto spend any output attached to the settlement transaction by n-1\nparticipants we could reclaim these into a new open right away. The\nfootprint would be 1 unilateral close, n outputs for participants, m\noutputs for contracts built on top, and 1 open transaction that\nrecollects all outputs in which the non-responding participant is not a\nco-signer. The main advantage is that we can avoid downtime.\n\nJust spit-balling here, since it'd leak some of the update logic back\ninto the contracts built on top of the update mechanism, which for me is\nenough to discard this idea again.\n\n>> mining, mining reward and difficulty adjustment\n>> * no equivalent concept for multi-party channels\n>\n> Fees for each update.  Consider how HTLC routing in Lightning\n> implicitly pays forwarding nodes to cooperate with the forwarding.  I\n> imagine most nodes in a multiparticipant offchain system will want to\n> be paid for cooperation, even if just a nominal sub-satoshi amount.\n\nIf we allow generic contracts on top of the base update mechanism it'll\nbe rather difficult to identify the beneficiary of an update, so it's\nhard to know who should pay a fee. I'd rather argue that cooperating is\nin the interest of all participants since they'd eventually want to\ncreate an update of their own, and there is no upside to become\nunresponsive.\n\nNotice that the fees we leverage in LN are because we expose our funds\nto the risk of not being available by allocating them to an HTLC, not\nfor the updates themselves. Since in the forwarding scenario we're only\nexposing the funds of the forwarding nodes to this risk it's only\nnatural that they'd be the ones leveraging a fee, not the other\nparticipants that simply sign off on the change.\n\n>> privacy:\n>> * disassociate a particular update from signer(s)\n>> * disassociate IP address of signers from signature\n>> * using SIGHASH_ALL for cooperative closes\n>\n> I suppose Tor can be used to disassociate IP address from signers if\n> everyone is from a hidden service.  However, we need to include some\n> kind of mix mechanism to allow individual signers to disassociate\n> their ownership of funds from their identity as signers.  Though such\n> mechanisms already exist as theoretical constructs, so \"just needs\n> implementing\".\n>\n> But then again: if you own funds in the mechanism, you *should* be a\n> signer (else you are trusting a federation).  So a basic fact here is\n> that if you are a participant in some offchain mechanism, you are\n> likely (approaching 100% probability) to own money in it.\n\nNotice that we are negotiating whether or not to apply generic\ntransactions to a shared state. This also means that there is no direct\nrelationship between the ownership of an output and the ID signing off\non a change.\n\nThe privacy guarantees are identical to Bitcoin on-chain, with the one\ncaveat that we may identify the proposing participant, but we can defend\nagainst this by mixing as you propose.\n\n>> liveness:\n>> * if signers know they will be offline, can they pre-sign updates that just commit their own outputs, rather then splice out?\n>> * contingent tap-leafs to splice out non-responsive signers\n>\n> It might be possible to create a new mechanism-within-mechanism layer,\n> if a signer knows they will be offline.\n>\n> For example, suppose entities A, B, and C have an offchain update\n> mechanism, which we shall call a \"factory\".  Suppose this factory\n> contains an A-B channel, a B-C channel, a A-C channel, and some funds\n> owned by B only.  Then suppose A knows he or she will be offline for\n> some time.  Before A goes offline, they can move from this UTXO set:\n>\n> * A-B channel\n> * B-C channel\n> * A-C channel\n> * B funds\n>\n> To this UTXO set:\n>\n> * A-B channel\n> * A-C channel\n> * B-C offchain update mechanism (sub-factory), which itself has its own UTXO set:\n>   * B-C channel\n>   * B funds\n>\n> This allows B and C to manage the B-C channels and B funds without\n> cooperation of A.  Then, later, when A returns online, the B-C\n> offchain update mechanism is collapsed back to the parent A-B-C\n> offchain update mechanism.\n>\n> This assumes A knows it will be offline (which it might do for\n> e.g. regular maintenance, or software updates).\n\nWe could theoretically play this game, having each participant create\ntwo updates with the same state-number at each update:\n\n 1) A normal one that just keeps them in the contract\n 2) A fallback splice all outputs they own (direct ones, HTLCs, ...) and\n    putting the rest back into a channel without them.\n\nIn case of one user becoming inactive the others can sign the splice,\ndropping the inactive participant and continue like nothing\nhappened. The worst case scenario is that the normal update gets\nbroadcast and confirmed instead, which means we are back to the\nunilateral close that we'd have to do anyway without this mechanism.\n\nNotice however that this only works if participants drop off one by one,\notherwise we get a combinatorial explosion for the fallback cases where\neach combination of inactive participants needs to splice themselves\nout. It also adds the complexity of having to identify which participant\nis the co-owner of an output, otherwise I can claim ownership of an\nunrelated output and force that to move on-chain by including it in my\nfallback and then becoming unresponsive (added rounds of communication\ncan help here, but are cumbersome).\n\nIt may be a bit much added complexity for a small complexity to be\nhonest, hopefully this won't be needed too often :-)\n\nCheers,\nChristian"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-19T02:01:54",
                "message_text_only": "Good morning Christian, and list,\n\n\n> > > uncooperative membership change:\n> > >\n> > > -   a subset of channel parties might want to cooperatively sign a channel splicing transaction to 'splice out' uncooperative parties\n> >\n> > I believe this is currently considered unsafe.\n> > https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-April/001975.html\n> > Unless you refer to another mechanism...?\n> > I believe this will end up requiring deep confirmation of the\n> > uncooperative close followed by a new mechanism open.\n>\n> Not necessarily. If we have an escape hatch in the scripts that allows\n> to spend any output attached to the settlement transaction by n-1\n> participants we could reclaim these into a new open right away.\n\nThis would have to be very very carefully designed.\nThe entire point of requiring an n-of-n signature is:\n\n* By using an n-of-n signatory where *you* are a signer, you are completely immune to Sybil attacks: even if everybody other than *you* in the signatory set is secretly just one entity, this is no different from doing a 2-of-2 bog-standard boring sleepy Zzzzzz Poon-Dryja Lightning Network channel.\n  * Any m-of-n signatory where strictly m < n allows anybody with the ability to run m nodes to outright steal money from you.\n    * As processing power is cheap nowadays, there is no m that can be considered safe.\n      Your alternative is to fall back on proof-of-work, but that just means going onchain, so you might as well just do things onchain.\n  * This is why 2-of-2 channels work so well, it's the minimum useable construction and any multiparty construction, when Sybilled, devolves to a 2-of-2 channel.\n\nSo the n-1 participants would have to be very very very carefully limited in what they can do.\nAnd if the only \"right\" the n-1 participants can do is to force the nth participant to claim its funds onchain, then that is implementable with a transaction doing just that, which is pre-signed by the nth participant and given to participants 1..n-1.\n\n> > > mining, mining reward and difficulty adjustment\n> > >\n> > > -   no equivalent concept for multi-party channels\n> >\n> > Fees for each update. Consider how HTLC routing in Lightning\n> > implicitly pays forwarding nodes to cooperate with the forwarding. I\n> > imagine most nodes in a multiparticipant offchain system will want to\n> > be paid for cooperation, even if just a nominal sub-satoshi amount.\n>\n> If we allow generic contracts on top of the base update mechanism it'll\n> be rather difficult to identify the beneficiary of an update, so it's\n> hard to know who should pay a fee. I'd rather argue that cooperating is\n> in the interest of all participants since they'd eventually want to\n> create an update of their own, and there is no upside to become\n> unresponsive.\n>\n> Notice that the fees we leverage in LN are because we expose our funds\n> to the risk of not being available by allocating them to an HTLC, not\n> for the updates themselves. Since in the forwarding scenario we're only\n> exposing the funds of the forwarding nodes to this risk it's only\n> natural that they'd be the ones leveraging a fee, not the other\n> participants that simply sign off on the change.\n\nI suppose that could be argued.\n\nHowever, I imagine it is possible for some of the updates to be implementable via HTLCs within sub-mechanisms of the higher mechanism.\nIf so, a participant may refuse to sign for the higher mechanism in order to force others to use HTLCs on the lower mechanisms, and thereby earn fees due to HTLC usage.\nI believe I argue as much here: https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-July/002055.html\n\n> ZmnSCPxj can request a factory channel reorganization to move some funds from the ZmnSCPxj<->Rene channel to the ZmnSCPxj<->YAijbOJA channel.\n> This has the same effect, i.e. it allows a forwarding attempt to push through, that would not be possible without the factory-level channel reorganization.\n>\n> Further, assuming only ZmnSCPxj, YAijbOJA, and Rene are in the channel factory, then it is the same: all three need to be online in order for the JIT-routing to work.\n>\n> But I observed above that, in a channel rebalance using current channels (without factories) Rene cannot be convinced to waive the fee.\n\nThe counterargument above is that if rebalances can be made fee-free, then the above argument disappears.\n\n\n>\n> > > privacy:\n> > >\n> > > -   disassociate a particular update from signer(s)\n> > > -   disassociate IP address of signers from signature\n> > > -   using SIGHASH_ALL for cooperative closes\n> >\n> > I suppose Tor can be used to disassociate IP address from signers if\n> > everyone is from a hidden service. However, we need to include some\n> > kind of mix mechanism to allow individual signers to disassociate\n> > their ownership of funds from their identity as signers. Though such\n> > mechanisms already exist as theoretical constructs, so \"just needs\n> > implementing\".\n> > But then again: if you own funds in the mechanism, you should be a\n> > signer (else you are trusting a federation). So a basic fact here is\n> > that if you are a participant in some offchain mechanism, you are\n> > likely (approaching 100% probability) to own money in it.\n>\n> Notice that we are negotiating whether or not to apply generic\n> transactions to a shared state. This also means that there is no direct\n> relationship between the ownership of an output and the ID signing off\n> on a change.\n>\n> The privacy guarantees are identical to Bitcoin on-chain, with the one\n> caveat that we may identify the proposing participant, but we can defend\n> against this by mixing as you propose.\n\nYes, but if we later combine this with allowing multiilateral kick-out of a member that is unresponsive (i.e. we splice out the outputs it has at least partial ownership of, and keep only those that are owned only by the remaining members), then each member would have to honestly claim which UTXOs it is interested in keeping after it is kicked out of the membership set, defeating this point entirely.\nI believe this is roughly what you propose in the next point, and roughly what you would want with the \"n-1 participants\" earlier.\n\n>\n> > > liveness:\n> > >\n> > > -   if signers know they will be offline, can they pre-sign updates that just commit their own outputs, rather then splice out?\n> > > -   contingent tap-leafs to splice out non-responsive signers\n> >\n> > It might be possible to create a new mechanism-within-mechanism layer,\n> > if a signer knows they will be offline.\n> > For example, suppose entities A, B, and C have an offchain update\n> > mechanism, which we shall call a \"factory\". Suppose this factory\n> > contains an A-B channel, a B-C channel, a A-C channel, and some funds\n> > owned by B only. Then suppose A knows he or she will be offline for\n> > some time. Before A goes offline, they can move from this UTXO set:\n> >\n> > -   A-B channel\n> > -   B-C channel\n> > -   A-C channel\n> > -   B funds\n> >\n> > To this UTXO set:\n> >\n> > -   A-B channel\n> > -   A-C channel\n> > -   B-C offchain update mechanism (sub-factory), which itself has its own UTXO set:\n> >     -   B-C channel\n> >     -   B funds\n> >\n> > This allows B and C to manage the B-C channels and B funds without\n> > cooperation of A. Then, later, when A returns online, the B-C\n> > offchain update mechanism is collapsed back to the parent A-B-C\n> > offchain update mechanism.\n> > This assumes A knows it will be offline (which it might do for\n> > e.g. regular maintenance, or software updates).\n>\n> We could theoretically play this game, having each participant create\n> two updates with the same state-number at each update:\n>\n> 1.  A normal one that just keeps them in the contract\n> 2.  A fallback splice all outputs they own (direct ones, HTLCs, ...) and\n>     putting the rest back into a channel without them.\n>\n>     In case of one user becoming inactive the others can sign the splice,\n>     dropping the inactive participant and continue like nothing\n>     happened. The worst case scenario is that the normal update gets\n>     broadcast and confirmed instead, which means we are back to the\n>     unilateral close that we'd have to do anyway without this mechanism.\n>\n>     Notice however that this only works if participants drop off one by one,\n>     otherwise we get a combinatorial explosion for the fallback cases where\n>     each combination of inactive participants needs to splice themselves\n>     out. It also adds the complexity of having to identify which participant\n>     is the co-owner of an output, otherwise I can claim ownership of an\n>     unrelated output and force that to move on-chain by including it in my\n>     fallback and then becoming unresponsive (added rounds of communication\n>     can help here, but are cumbersome).\n\nThis might be a plausible way of implementing the \"n-1 participants can kick out nth participant\".\n\n>\n>     It may be a bit much added complexity for a small complexity to be\n>     honest, hopefully this won't be needed too often :-)\n\nStatement makes no sense, unless you meant to say \"It may be a bit much complexity for a small benefit\" or similar?\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Christian Decker",
                "date": "2019-09-19T10:26:13",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n>> Not necessarily. If we have an escape hatch in the scripts that allows\n>> to spend any output attached to the settlement transaction by n-1\n>> participants we could reclaim these into a new open right away.\n>\n> This would have to be very very carefully designed.\n> The entire point of requiring an n-of-n signature is:\n>\n> * By using an n-of-n signatory where *you* are a signer, you are completely immune to Sybil attacks: even if everybody other than *you* in the signatory set is secretly just one entity, this is no different from doing a 2-of-2 bog-standard boring sleepy Zzzzzz Poon-Dryja Lightning Network channel.\n>   * Any m-of-n signatory where strictly m < n allows anybody with the ability to run m nodes to outright steal money from you.\n>     * As processing power is cheap nowadays, there is no m that can be considered safe.\n>       Your alternative is to fall back on proof-of-work, but that just means going onchain, so you might as well just do things onchain.\n>   * This is why 2-of-2 channels work so well, it's the minimum useable construction and any multiparty construction, when Sybilled, devolves to a 2-of-2 channel.\n>\n> So the n-1 participants would have to be very very very carefully limited in what they can do.\n> And if the only \"right\" the n-1 participants can do is to force the nth participant to claim its funds onchain, then that is implementable with a transaction doing just that, which is pre-signed by the nth participant and given to participants 1..n-1.\n\nJust to be clear, I do *not* want to support uncooperative splice-outs.\nThis is due to their need to either pre-sign a splice-out of the party\nlike I explained further down, or it requires encumbering whatever we\nbuild on top in order to do a fast-reopen.\n\nBut I do think there is value in exploring what the options are :-)\n\n>> Notice that we are negotiating whether or not to apply generic\n>> transactions to a shared state. This also means that there is no direct\n>> relationship between the ownership of an output and the ID signing off\n>> on a change.\n>>\n>> The privacy guarantees are identical to Bitcoin on-chain, with the one\n>> caveat that we may identify the proposing participant, but we can defend\n>> against this by mixing as you propose.\n>\n> Yes, but if we later combine this with allowing multiilateral kick-out\n> of a member that is unresponsive (i.e. we splice out the outputs it\n> has at least partial ownership of, and keep only those that are owned\n> only by the remaining members), then each member would have to\n> honestly claim which UTXOs it is interested in keeping after it is\n> kicked out of the membership set, defeating this point entirely.  I\n> believe this is roughly what you propose in the next point, and\n> roughly what you would want with the \"n-1 participants\" earlier.\n\nThat is indeed the issue I explained further down:\n\n> It also adds the complexity of having to identify which participant is\n> the co-owner of an output, otherwise I can claim ownership of an\n> unrelated output and force that to move on-chain by including it in my\n> fallback and then becoming unresponsive (added rounds of communication\n> can help here, but are cumbersome).\n\nClaiming ownership would then involve providing a valid input script\n(disregarding any timelocks) that could spend the output under some\ncondition. Others would have to verify this proof-of-ownership before\naccepting the node's self-splice-out before accepting it.\n\n>>     It may be a bit much added complexity for a small complexity to be\n>>     honest, hopefully this won't be needed too often :-)\n>\n> Statement makes no sense, unless you meant to say \"It may be a bit\n> much complexity for a small benefit\" or similar?\n\nIndeed, that was a weird sentence :-) I did mean that it is a lot of\ncomplexity for very little benefit :-)\n\nCheers,\nChristian"
            }
        ],
        "thread_summary": {
            "title": "Reconciling the off-chain and on-chain models with eltoo",
            "categories": [
                "Lightning-dev",
                "bitcoin-dev"
            ],
            "authors": [
                "Richard Myers",
                "Christian Decker",
                "ZmnSCPxj"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 47574
        }
    },
    {
        "title": "[Lightning-dev] (no subject)",
        "thread_messages": [
            {
                "author": "Nongluck Loyha",
                "date": "2019-09-07T12:58:03",
                "message_text_only": "Please find my CV and transfer back to me\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190907/6415099a/attachment.html>"
            },
            {
                "author": "Nongluck Loyha",
                "date": "2019-09-07T12:59:08",
                "message_text_only": "Please let me in the community name sawssdee\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190907/6ee656ac/attachment.html>"
            },
            {
                "author": "Nongluck Loyha",
                "date": "2019-09-07T17:09:40",
                "message_text_only": "-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190908/2a0b1534/attachment.html>"
            },
            {
                "author": "Nongluck Loyha",
                "date": "2019-09-19T18:27:59",
                "message_text_only": "-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190920/a5afec4b/attachment.html>"
            },
            {
                "author": "Nongluck Loyha",
                "date": "2019-09-20T02:39:27",
                "message_text_only": "-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190920/602dfa73/attachment.html>"
            },
            {
                "author": "Nongluck Loyha",
                "date": "2019-09-20T02:40:29",
                "message_text_only": "-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190920/5eef4116/attachment.html>"
            },
            {
                "author": "Nongluck Loyha",
                "date": "2019-09-20T02:40:36",
                "message_text_only": "-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190920/b706bab4/attachment.html>"
            },
            {
                "author": "Chris Malloy",
                "date": "2019-09-20T12:35:03",
                "message_text_only": "Someone please stop these blank emails.\n\nOn Fri., Sep. 20, 2019, 02:19 Nongluck Loyha, <nloyha at gmail.com> wrote:\n\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190920/3ab72678/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "(no subject)",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Chris Malloy",
                "Nongluck Loyha"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 1869
        }
    },
    {
        "title": "[Lightning-dev] Proposal: Automated Inbound Liquidity With Invoices",
        "thread_messages": [
            {
                "author": "Dario Sneidermanis",
                "date": "2019-09-09T20:11:52",
                "message_text_only": "We went ahead with this idea and implemented it in muun wallet as an\nexperiment: you can scan an invoice, and if there isn't a route with enough\ncapacity to the destination node, we'll open a channel directly and, once\nit's locked, fulfill the payment using that channel.\n\nThe initial idea was to improve the UX of not being able to route a\npayment. However, since we have to wait until the channel is locked to make\nthe final hop of the payment, the full process might take about an hour,\ndepending on the block times. That generates a couple of UX challenges:\n* The user is expecting lightning payments to be completed instantly, so it\nmight be preferable to fail the payment rather than locking it for an hour\nuntil the channel is opened.\n* Most invoices in the wild have 10/15 minute expirations, so they don't\neven qualify for doing something like this.\n* Even if the user generates the invoice manually, most interfaces default\nto 1 hour expiration, which might be too little time.\n\nGiven these constrains, we decided that the best application for this flow\nis to top-up your own node. That is, add outbound capacity to your node in\na non-custodial manner. We'd love to hear if you have some idea as to how\nto make this use case better, or apply this concept to other use cases.\n\nOn Fri, Aug 16, 2019 at 12:58 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Dario,\n>\n> > Having said that, if the usability of the scheme \"open channel, wait\n> until it's locked, then send HTLC payment\" were deemed good enough, then\n> routing nodes could implement this idea to route payments \"just in time\",\n> even if there aren't any pre-existing routes to the destination.\n>\n> This is a good idea, but one with some difficulties in implementation.\n>\n> * The current onion route format contains the next short-channel-id (and\n> in particular not the node-id of the next hop in the route).\n>   Indeed, short-channel-ids were invented to reduce the size of the onion\n> route format.\n>   If a channel used to exist between nodes, then the payer might have\n> gotten this short-channel-id in the past via gossip.\n>   Then later, if the channel is closed, most implementations will forget\n> the short-channel-id (and thus would probably also forget *which* node the\n> short-channel-id used to be connected to, so determining the next node for\n> the just-in-time channel opening would be difficult).\n>   * C-Lightning retains this information for some blocks but will forget\n> it at some point.\n>   * Implementations that do this \"just-in-time\" channel-opening will need\n> to remember this short-channel-id for longer.\n> * The final HTLC going to the payee has the tightest time schedule.\n>   If this HTLC has a timeout that is too near, the payee will reject the\n> payment.\n>   Since channel opening requires blocks to pass in order to confirm the\n> funding transaction, by the time the HTLC reaches the payee, the timeout\n> might now be judged too near and the payee will reject the payment anyway.\n>   * The spec itself recommends the use of \"shadow routing\".\n>     Briefly, the payer obscures who the payee is by adding a greater\n> timeout to the payee than the minimum required by the payee.\n>     (since timeouts decrease at each hop, an intermediate node can guess\n> who the payee is by determining how small the remaining timeout looks.)\n>     This can mitigate the above effect.\n>     C-Lightning implements shadow routing.\n>\n> However, this same idea would be greatly helped by trampoline routing:\n>\n> * The planned trampoline routing indicates the node id of the next\n> trampoline hop, thus not requiring implementations to remember who a closed\n> short-channel-id used to be connected to.\n> * Trampoline nodes will generally require a much larger fee and timelock\n> budget, because they also have to build routes.\n>   If the fee and timelock budgets are big enough, then the trampoline node\n> might decide to open a direct channel to the next trampoline node\n> \"just-in-time\" for the next trampoline hop.\n>\n> Regards,\n> ZmnSCPxj\n>\n> >\n> > On Wed, Aug 14, 2019 at 8:42 PM ZmnSCPxj via Lightning-dev <\n> lightning-dev at lists.linuxfoundation.org> wrote:\n> >\n> > > Good morning Ecurrencyhodler,\n> > >\n> > > It seems to me a trusted model then.\n> > > Regardless of who makes the channel (the payee cannot determine who\n> the payer is anyway) the payee cannot trustlessly release the product until\n> the channel is deeply confirmed, else your security is only 0-conf, not\n> off-chain.\n> > >\n> > > Further, `push_msat` has the drawback of not providing\n> proof-of-payment, thus an intermediate hop node may be unable to claim\n> funds.\n> > > (I believe `push_msat` was a mistake: you should simply make a normal\n> HTLC payment (that provides proof-of-payment) after the channel is deeply\n> confirmed, and `push_msat`, if you read lightning-rfc, does have this\n> warning that you cannot trust money you receive that way until the channel\n> is deeply confirmed.)\n> > >\n> > > Regards,\n> > > ZmnSCPxj\n> > >\n> > > Sent with ProtonMail Secure Email.\n> > >\n> > > \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> > > On Thursday, August 15, 2019 2:05 AM, ecurrencyhodler <\n> ecurrencyhodler at gmail.com> wrote:\n> > >\n> > > > >So would `push_msat`; until confirmed deeply the channel opening\n> can still be cancelled by double-spending and it would be foolhardy to\n> deliver the product until the channel is deeply confirmed to be opened.\n> > > >\n> > > > Okay so there's 2 situations here I'd like to explore:\n> > > >\n> > > > 1. Bob -> routing node -> Me\n> > > >\n> > > > 2. Bob -> Me\n> > > >\n> > > > Scenario 1\n> > > > If Bob pays the invoice and the routing node opens a payment channel\n> and pushes sats to me, you could stipulate that the routing node isn't able\n> to fully take ownership of the sats until 6 confirmations potentially via\n> Hodl Invoices (by the time the routing nodes channel with pushed payments\n> confirms with mine).  But I could still make LN payments instantly through\n> the routing node because the routing node just needs to wait until the 6\n> confirmations and settle all accounts after the fact.\n> > > >\n> > > > Scenario 2\n> > > > Bob and I know each other so if channel disappears, it's basically\n> the same situation with Thor's instant channel.  But we could completely\n> remove scenario 2 and only allow routing nodes to open channels to me as\n> long as Bob makes the payment.\n> > > >\n> > > > On Wed, Aug 14, 2019 at 12:03 AM ZmnSCPxj <ZmnSCPxj at protonmail.com>\n> wrote:\n> > > >\n> > > > > Good morning Ecurrencyhodler,\n> > > > >\n> > > > > > Hi ZmnSCPxj!\n> > > > > >\n> > > > > > Submarine swaps are a great current solution, but we still have\n> to wait for confirmations.\n> > > > >\n> > > > > So would `push_msat`; until confirmed deeply the channel opening\n> can still be cancelled by double-spending and it would be foolhardy to\n> deliver the product until the channel is deeply confirmed to be opened.\n> > > > > At least this way, you can perform the preparation in parallel to\n> your other startup operations for starting your business before actual\n> launch of your merchant website.\n> > > > >\n> > > > > >\n> > > > > > >Further, while it involves fees, it does give you control over\n> what nodes you make channels with, and would be a good investment in your\n> future accessibility over the Lightning Network.\n> > > > > >\n> > > > > > What disadvantages do you see over this proposal and say\n> something like autopilot?  Or do you just prefer manual channel management\n> overall?\n> > > > >\n> > > > > This should eventually be implementable by some kind of\n> auto-system.\n> > > > > It is still early days and a lot of infrastructure is yet to be\n> written.\n> > > > >\n> > > > > Regards,\n> > > > > ZmnSCPxj\n> > > > >\n> > > > > >\n> > > > > > On Tue, Aug 13, 2019 at 6:27 PM ZmnSCPxj <\n> ZmnSCPxj at protonmail.com> wrote:\n> > > > > >\n> > > > > > > Good morning Ecurrencyhodler,\n> > > > > > >\n> > > > > > > A current and practical way to set up incoming liquidity would\n> be to take some onchain funds, create a channel to a high-uptime node on\n> the network (just run an autopilot), then use a submarine swap (i.e. pay\n> offchain funds to buy onchain funds).\n> > > > > > > Then you can reuse the same onchain funds over and over to\n> make more liquidity until the submarine swap provider runs out of onchain\n> funds or you have sufficient liquidity or your money has been drained by\n> the fees involved.\n> > > > > > >\n> > > > > > > While this requires onchain funds, presumably as a new\n> business or merchant you will have capital in some form before starting\n> your business.\n> > > > > > > The most sensible way to store and transport financial capital\n> is, of course, Bitcoin, thus you already have what is needed to start this,\n> you simply have to do it before you perform other operations.\n> > > > > > > Further, while it involves fees, it does give you control over\n> what nodes you make channels with, and would be a good investment in your\n> future accessibility over the Lightning Network.\n> > > > > > >\n> > > > > > > Regards,\n> > > > > > > ZmnSCPxj\n> > > > > > >\n> > > > > > > Sent with ProtonMail Secure Email.\n> > > > > > >\n> > > > > > > \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> > > > > > > On Monday, August 12, 2019 11:42 AM, Ecurrencyhodler\n> Blockchains <ecurrencyhodler at gmail.com> wrote:\n> > > > > > >\n> > > > > > > > Hi. I'd like to propose a way for instant inbound liquidity\n> to be automated via invoices and would appreciate your feedback.  It's\n> similar to Thor's instant channel but this proposal would only be valuable\n> if it becomes a standard across all lightning implementations and wallets.\n> It won't work if it's limited to just one Lightning wallet.\n> > > > > > > >\n> > > > > > > > Proposal: Automated Inbound Liquidity With Invoices\n> > > > > > > >\n> > > > > > > > For Who: Full Lightning Network nodes\n> > > > > > > >\n> > > > > > > > Problem: Waiting for inbound liquidity as channel\n> establishes when you first come online and want to receive a LN payment.\n> > > > > > > >\n> > > > > > > > Solution: Embedding the node uri of the invoice creator,\n> along with amount to be routed.\n> > > > > > > >\n> > > > > > > > Scenario:\n> > > > > > > >\n> > > > > > > > 1.  Bob wants to send me 100,000 sats.\n> > > > > > > > 2.  My node just came online and has 0 inbound liquidity.\n> > > > > > > > 3.  I create an invoice for 100,000 sats.  My LN node\n> recognizes I have 0 inbound liquidity so my wallet also embeds my URI in\n> the invoice.\n> > > > > > > > 4.  Bob\u2019s wallet sees an invoice + uri.  Maybe even tries to\n> route.  When it doesn\u2019t see anything, it auto opens a channel + pushes\n> 100,000 sat payment.\n> > > > > > > > 5.  I now own and can spend 100,000 sats instantly.\n> > > > > > > >\n> > > > > > > > Considerations:\n> > > > > > > >\n> > > > > > > > -   This auto establishing of channels and pushing payments\n> isn\u2019t for all LN nodes.  Just routing nodes.\n> > > > > > > > -   Bob doesn\u2019t need to be the one to establish the\n> channel.  He can push the information down the line until a node dedicated\n> to routing is found.  The routing node can then be the one to establish the\n> channel with me.\n> > > > > > > > -   Certain specifics need to be flushed out such as the\n> size of Bob\u2019s channel.  Right now I think Bob can manually set the size of\n> the channels to be established on his end.  Should be smaller channels at\n> first.  If the person gets paid again, just establish another channel\n> towards the same node if there isn't enough capacity.\n> > > > > > > > -   Routing nodes who provide this service can charge a\n> premium.\n> > > > > > > > -   Bob, as a liquidity provider, won't cheat against\n> himself so I can make LN payments instantly.\n> > > > > > > > -   The beauty behind this proposal is that I can receive a\n> payment instantly, I can send payments instantly, and that it hides\n> everything from me as an end user.\n> > > > > > > > -   Can possibly be extended to neutrino LN wallets if they\n> are public.\n> > >\n> > > _______________________________________________\n> > > Lightning-dev mailing list\n> > > Lightning-dev at lists.linuxfoundation.org\n> > > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190909/ef59424f/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-10T01:40:31",
                "message_text_only": "Good morning Dario,\n\n> We went ahead with this idea and implemented it in muun wallet as an experiment: you can scan an invoice, and if there isn't a route with enough capacity to the destination node, we'll open a channel directly and, once it's locked, fulfill the payment using that channel.\n>\n> The initial idea was to improve the UX of not being able to route a payment. However, since we have to wait until the channel is locked to make the final hop of the payment, the full process might take about an hour, depending on the block times. That generates a couple of UX challenges:\n> * The user is expecting lightning payments to be completed instantly, so it might be preferable to fail the payment rather than locking it for an hour until the channel is opened.\n\nIndeed, this is why I did not consider this at all for payments: there is the atrocious slow time for opening a channel.\n\n> * Most invoices in the wild have 10/15 minute expirations, so they don't even qualify\u00a0for doing something like this.\n> * Even if the user generates the invoice manually, most interfaces default to 1 hour expiration, which might be too little time.\n\nC-Lightning now defaults to one week, though wallets on top of it might override it with their own defaults.\n\n>\n> Given these constrains, we decided that the best application for this flow is to top-up your own node. That is, add outbound capacity to your node in a non-custodial manner. We'd love to hear if you have some idea as to how to make this use case better, or apply this concept to other use cases.\n\nYes, this is the same use case that onchain-to-offchain/onchain-to-onchain swaps (submarine swaps, Lightning Loops, whatever the cool kids call it these days) targets.\n\nThough note that, if you have some onchain funds and what to have *outbound* capacity to the network, you can non-custodially do this, probably cheaper, by just making an outgoing channel yourself with your own onchain funds.\n\nRegards,\nZmnSCPxj\n\n>\n> On Fri, Aug 16, 2019 at 12:58 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n> > Good morning Dario,\n> >\n> > > Having\u00a0said that, if the usability of the scheme \"open channel, wait until it's locked, then send HTLC payment\" were deemed good enough, then routing nodes could implement this idea to route payments \"just in time\", even if there aren't any pre-existing routes to the destination.\n> >\n> > This is a good idea, but one with some difficulties in implementation.\n> >\n> > * The current onion route format contains the next short-channel-id (and in particular not the node-id of the next hop in the route).\n> > \u00a0 Indeed, short-channel-ids were invented to reduce the size of the onion route format.\n> > \u00a0 If a channel used to exist between nodes, then the payer might have gotten this short-channel-id in the past via gossip.\n> > \u00a0 Then later, if the channel is closed, most implementations will forget the short-channel-id (and thus would probably also forget *which* node the short-channel-id used to be connected to, so determining the next node for the just-in-time channel opening would be difficult).\n> > \u00a0 * C-Lightning retains this information for some blocks but will forget it at some point.\n> > \u00a0 * Implementations that do this \"just-in-time\" channel-opening will need to remember this short-channel-id for longer.\n> > * The final HTLC going to the payee has the tightest time schedule.\n> > \u00a0 If this HTLC has a timeout that is too near, the payee will reject the payment.\n> > \u00a0 Since channel opening requires blocks to pass in order to confirm the funding transaction, by the time the HTLC reaches the payee, the timeout might now be judged too near and the payee will reject the payment anyway.\n> > \u00a0 * The spec itself recommends the use of \"shadow routing\".\n> > \u00a0 \u00a0 Briefly, the payer obscures who the payee is by adding a greater timeout to the payee than the minimum required by the payee.\n> > \u00a0 \u00a0 (since timeouts decrease at each hop, an intermediate node can guess who the payee is by determining how small the remaining timeout looks.)\n> > \u00a0 \u00a0 This can mitigate the above effect.\n> > \u00a0 \u00a0 C-Lightning implements shadow routing.\n> >\n> > However, this same idea would be greatly helped by trampoline routing:\n> >\n> > * The planned trampoline routing indicates the node id of the next trampoline hop, thus not requiring implementations to remember who a closed short-channel-id used to be connected to.\n> > * Trampoline nodes will generally require a much larger fee and timelock budget, because they also have to build routes.\n> > \u00a0 If the fee and timelock budgets are big enough, then the trampoline node might decide to open a direct channel to the next trampoline node \"just-in-time\" for the next trampoline hop.\n> >\n> > Regards,\n> > ZmnSCPxj\n> >\n> > >\n> > > On Wed, Aug 14, 2019 at 8:42 PM ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n> > >\n> > > > Good morning Ecurrencyhodler,\n> > > >\n> > > > It seems to me a trusted model then.\n> > > > Regardless of who makes the channel (the payee cannot determine who the payer is anyway) the payee cannot trustlessly release the product until the channel is deeply confirmed, else your security is only 0-conf, not off-chain.\n> > > >\n> > > > Further, `push_msat` has the drawback of not providing proof-of-payment, thus an intermediate hop node may be unable to claim funds.\n> > > > (I believe `push_msat` was a mistake: you should simply make a normal HTLC payment (that provides proof-of-payment) after the channel is deeply confirmed, and `push_msat`, if you read lightning-rfc, does have this warning that you cannot trust money you receive that way until the channel is deeply confirmed.)\n> > > >\n> > > > Regards,\n> > > > ZmnSCPxj\n> > > >\n> > > > Sent with ProtonMail Secure Email.\n> > > >\n> > > > \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> > > > On Thursday, August 15, 2019 2:05 AM, ecurrencyhodler <ecurrencyhodler at gmail.com> wrote:\n> > > >\n> > > > > >So would `push_msat`; until confirmed deeply the channel opening can still be cancelled by double-spending and it would be foolhardy to deliver the product until the channel is deeply confirmed to be opened.\n> > > > >\n> > > > > Okay so there's 2 situations here I'd like to explore:\n> > > > >\n> > > > > 1. Bob -> routing node -> Me\n> > > > >\n> > > > > 2. Bob -> Me\n> > > > >\n> > > > > Scenario 1\n> > > > > If Bob pays the invoice and the routing node opens a payment channel and pushes sats to me, you could stipulate that the routing node isn't able to fully take ownership of the sats until 6 confirmations potentially via Hodl Invoices (by the time the routing nodes channel with pushed payments confirms with mine).\u00a0 But I could still make LN payments instantly through the routing node because the routing node just needs to wait until the 6 confirmations and settle all accounts after the fact.\u00a0\u00a0\n> > > > >\n> > > > > Scenario 2\n> > > > > Bob and I know each other so if channel disappears, it's basically the same situation with Thor's instant channel.\u00a0 But we could completely remove scenario 2 and only allow routing nodes to open channels to me as long as Bob makes the payment.\n> > > > >\n> > > > > On Wed, Aug 14, 2019 at 12:03 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n> > > > >\n> > > > > > Good morning Ecurrencyhodler,\n> > > > > >\n> > > > > > > Hi ZmnSCPxj!\u00a0\n> > > > > > >\n> > > > > > > Submarine swaps are a great current solution, but we still have to wait for confirmations.\n> > > > > >\n> > > > > > So would `push_msat`; until confirmed deeply the channel opening can still be cancelled by double-spending and it would be foolhardy to deliver the product until the channel is deeply confirmed to be opened.\n> > > > > > At least this way, you can perform the preparation in parallel to your other startup operations for starting your business before actual launch of your merchant website.\n> > > > > >\n> > > > > > >\n> > > > > > > >Further, while it involves fees, it does give you control over what nodes you make channels with, and would be a good investment in your future accessibility over the Lightning Network.\n> > > > > > >\n> > > > > > > What disadvantages do you see over this proposal and say something like autopilot?\u00a0 Or do you just prefer manual channel management overall?\n> > > > > >\n> > > > > > This should eventually be implementable by some kind of auto-system.\n> > > > > > It is still early days and a lot of infrastructure is yet to be written.\n> > > > > >\n> > > > > > Regards,\n> > > > > > ZmnSCPxj\n> > > > > >\n> > > > > > >\n> > > > > > > On Tue, Aug 13, 2019 at 6:27 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n> > > > > > >\n> > > > > > > > Good morning Ecurrencyhodler,\n> > > > > > > >\n> > > > > > > > A current and practical way to set up incoming liquidity would be to take some onchain funds, create a channel to a high-uptime node on the network (just run an autopilot), then use a submarine swap (i.e. pay offchain funds to buy onchain funds).\n> > > > > > > > Then you can reuse the same onchain funds over and over to make more liquidity until the submarine swap provider runs out of onchain funds or you have sufficient liquidity or your money has been drained by the fees involved.\n> > > > > > > >\n> > > > > > > > While this requires onchain funds, presumably as a new business or merchant you will have capital in some form before starting your business.\n> > > > > > > > The most sensible way to store and transport financial capital is, of course, Bitcoin, thus you already have what is needed to start this, you simply have to do it before you perform other operations.\n> > > > > > > > Further, while it involves fees, it does give you control over what nodes you make channels with, and would be a good investment in your future accessibility over the Lightning Network.\n> > > > > > > >\n> > > > > > > > Regards,\n> > > > > > > > ZmnSCPxj\n> > > > > > > >\n> > > > > > > > Sent with ProtonMail Secure Email.\n> > > > > > > >\n> > > > > > > > \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> > > > > > > > On Monday, August 12, 2019 11:42 AM, Ecurrencyhodler Blockchains <ecurrencyhodler at gmail.com> wrote:\n> > > > > > > >\n> > > > > > > > > Hi.\u00a0I'd like to propose a way for instant inbound liquidity to be automated via invoices and would appreciate your feedback.\u00a0 It's similar to Thor's instant channel but this proposal would only be valuable if it becomes a standard across all lightning implementations and wallets.\u00a0 It won't work if it's limited to just one Lightning wallet.\n> > > > > > > > >\n> > > > > > > > > Proposal: Automated Inbound Liquidity With Invoices\n> > > > > > > > >\n> > > > > > > > > For Who: Full Lightning Network nodes\n> > > > > > > > >\n> > > > > > > > > Problem: Waiting for inbound liquidity as channel establishes when you first come online and want to receive a LN payment.\n> > > > > > > > >\n> > > > > > > > > Solution:\u00a0Embedding the node uri of the invoice creator, along with amount to be routed.\n> > > > > > > > >\n> > > > > > > > > Scenario:\u00a0\n> > > > > > > > >\n> > > > > > > > > 1.\u00a0 Bob wants to send me 100,000 sats.\n> > > > > > > > > 2.\u00a0 My node just came online and has 0 inbound liquidity.\n> > > > > > > > > 3.\u00a0 I create an invoice for 100,000 sats.\u00a0 My LN node recognizes I have 0 inbound liquidity so my wallet also embeds my URI in the invoice.\n> > > > > > > > > 4.\u00a0 Bob\u2019s wallet sees an invoice + uri.\u00a0 Maybe even tries to route.\u00a0 When it doesn\u2019t see anything, it auto opens a channel + pushes 100,000 sat payment.\n> > > > > > > > > 5.\u00a0 I now own and can spend 100,000 sats instantly.\n> > > > > > > > >\n> > > > > > > > > Considerations:\n> > > > > > > > >\n> > > > > > > > > -\u00a0 \u00a0This auto establishing of channels and pushing payments isn\u2019t for all LN nodes.\u00a0 Just routing nodes.\n> > > > > > > > > -\u00a0 \u00a0Bob doesn\u2019t need to be the one to establish the channel.\u00a0 He can push the information down the line until a node dedicated to routing is found.\u00a0 The routing node can then be the one to establish the channel with me.\n> > > > > > > > > -\u00a0 \u00a0Certain specifics need to be flushed out such as the size of Bob\u2019s channel.\u00a0 Right now I think Bob can manually set the size of the channels to be established on his end.\u00a0 Should be smaller channels at first.\u00a0 If the person gets paid again, just establish another channel towards the same node if there isn't enough capacity.\n> > > > > > > > > -\u00a0 \u00a0Routing nodes who provide this service can charge a premium.\n> > > > > > > > > -\u00a0 \u00a0Bob, as a liquidity provider, won't cheat against himself so I can make LN payments instantly.\n> > > > > > > > > -\u00a0 \u00a0The beauty behind this proposal is that I can receive a payment instantly, I can send payments instantly, and that it hides everything from me as an end user.\n> > > > > > > > > -\u00a0 \u00a0Can possibly be extended to neutrino LN wallets if they are public.\n> > > >\n> > > > _______________________________________________\n> > > > Lightning-dev mailing list\n> > > > Lightning-dev at lists.linuxfoundation.org\n> > > > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            }
        ],
        "thread_summary": {
            "title": "Proposal: Automated Inbound Liquidity With Invoices",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Dario Sneidermanis",
                "ZmnSCPxj"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 25351
        }
    },
    {
        "title": "[Lightning-dev] CVEs assigned for lightning projects: please upgrade!",
        "thread_messages": [
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2019-09-10T15:25:31",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nWe've confirmed instances of the CVE being exploited in the wild.  If you\u2019re\nnot on the following versions of either of these implementations (these\nversions are fully patched), then you need to upgrade now to avoid risk of\nfunds loss:\n    * lnd v0.7.1 -- anything 0.7 and below is vulnerable\n    * c-lightning v0.7.1 -- anything 0.7 and below is vulnerable\n    * eclair v0.3.1 -- anything 0.3 and below is vulnerable\n\nWe'd also like to remind the community that we still have limits in place on\nthe network to mitigate widespread funds loss, and please keep that in mind\nwhen putting funds onto the network at this early stage.\n\nIf you have trouble updating for whatever reason, feel free to reach out to\nthe developers of the respective implementations referenced above.\n-----BEGIN PGP SIGNATURE-----\n\niQIzBAEBCgAdFiEE+AN+cMEseiY8AyUIzlj3+OIP2aIFAl13vxQACgkQzlj3+OIP\n2aIUABAAxrXvdyNcrNeerEFgYjqshXXhZVJXUcQwpHrrd4UX7weqS+UakOE4NP/b\nEBDnMlOoqN5X4UhiV8EVR0QMnznXGYJ5ZNws8OCvGg8QCUMbkHRg7rVNEnd4zZJU\noE9c75Vg02E5riNcMT9B+gBkcTppUeZiM/PboDoU6HWvXzdIAhRD3ZXHZaAJj35H\nSRcAD7ehUQ1WRmXH9wfvF6jCX5GZMb731EfVPEvcyA3EiYG/P0GBNXrUKsFzknab\nDE8txA31728iojydnQxesKcMmXZhZqS0IJfeqacBXiyzUNWcgWpTui0QhtPZzV9x\n0yVseqcMWaONagIGRSZ2zrnBbU3aVXSbGQRSy4qvhljQjqrQgvoHCgshROr1JbvU\njqsNI5ZT2v3mRNLQMKQZM6O84ULLAvyIk17/ZiLVoLp018G/5ZI2p8npe/he01Wm\ncClrag2F6a1POWiByd4bQDps/XfBh4yLRxFUCFDZhOPEHf2P7N8ydqmjcGTGh9oZ\niWIX7pHZYqMM9UwdIorgUQlm1K4PQA+0lKjB97pR5Vhj+Nt41bm4+S7UqvCQSalK\nt0B8csNISrqGtA02jjXiNqpOnkRnRoiwiOwsB5wpL3w5cagIgrsE4wNpNsIQC1ZY\nHhVts3uc299TtS8eMwl5WjKiY2zgKHILvIs0WcyEGqpVLV0hjyw=\n=Q5CI\n-----END PGP SIGNATURE-----\n\n\nOn Fri, Aug 30, 2019 at 2:34 AM Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> -----BEGIN PGP SIGNED MESSAGE-----\n> Hash: SHA256\n>\n> Security issues have been found in various lightning projects which\n> could cause loss of funds.\n>\n> Full details will be released in 4 weeks (2019-09-27), please uprade\n> well before then.\n>\n> Effected releases:\n>\n>     CVE-2019-12998 c-lightning < 0.7.1\n>     CVE-2019-12999 lnd < 0.7\n>     CVE-2019-13000 eclair <= 0.3\n>\n> Cheers,\n> Rusty.\n> -----BEGIN PGP SIGNATURE-----\n>\n> iQIzBAEBCAAdFiEEFe6NbKsOfwz5mb/L2SAObNGtuPEFAl1o7UAACgkQ2SAObNGt\n> uPFR7xAAqlcY/gCzfx5Sl49BwLIvr5EZlKYxasIoU4FoiAxLN0sRMksBLY+gUA3L\n> 7XuPi7oJSsnJc0Gvq6DnWo8W/jqAETgK0XeCyESdtX1tLeXMEiCoAXccRBT/hNbr\n> aHRiyeRO6YnrfzJN2CKStzXUvoVEvyB4lpMZ+dTJYdulOUs20ELU/zzSQe/syGnD\n> 7kujvBVyk4LJIYQ9piGl1pc4Y8mORK2ttYCVk4HCy+eu1RGHRVze135ve2MhQVOd\n> Mzs57lqXM8k+ZUumD5eB6pgvENlFzgFVaywYvf7+RSZIx185qosHTbQU84icyunp\n> W68FhCk9DMUYlhU8lBVyX1qS1+YhBYvm79zK4lCSJ9CQBZ2Oox2tz9RuO/3DPSol\n> RCZ3+h8SCKai8ZASXhz4dL4nXSpdKNjJrQdRvp7I1e2netkZpaF2Dyd7FDvFnhad\n> SWP/juo/n9rmkyfbuxQYj5sdixV9G9cpV85BnQDX558r+AMRPVin/xs5NBZMknkN\n> S7Wc9aq8nlVUeoTV5+TnGbz8NPXyYLNSotJdwBnA+RWTD9emCBah3UOxVlJR7N5e\n> nZuumPauLJyZESzxvRDgQ0Hca7hMCMBh+xJ/OFDy+n4oHxFLihCtY3EktSE43v2N\n> +PXbLFXw9w7jSPxn5FgqzB9D/E/eqkLe/+UKsnQ0ji8trEd36DU=\n> =Z6RL\n> -----END PGP SIGNATURE-----\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190910/f1277c15/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: warn.txt.asc\nType: application/octet-stream\nSize: 1659 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190910/f1277c15/attachment.obj>"
            }
        ],
        "thread_summary": {
            "title": "CVEs assigned for lightning projects: please upgrade!",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Olaoluwa Osuntokun"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3652
        }
    },
    {
        "title": "[Lightning-dev] Proposal for Stuckless Payment",
        "thread_messages": [
            {
                "author": "Hiroki Gondo",
                "date": "2019-09-18T10:08:03",
                "message_text_only": "Hi all,\n\nI explained Stuckless Payments on the basis of PTLCs before and some people\nunderstood that this is a proposal that can be accomplished after PTLCs are\nintroduced. But this can also be accomplished using HTLC variants that are\nnot compatible with BOLT 1.x HTLCs. For simplicity, I'd like to describe\nthem in Miniscript policies (http://bitcoin.sipa.be/miniscript/).\n\n# The BOLT #3 offered HTLC policy\nor(pk(key_revocation),and(pk(key_remote),or(pk(key_local),hash160(H))))\n->\nor(pk(key_revocation),and(pk(key_remote),or(pk(key_local),and(hash160(H),hash160(H)))))\n\n# The BOLT #3 received HTLC policy\nor(pk(key_revocation),and(pk(key_remote),or(and(pk(key_local),hash160(H)),older(1008))))\n->\nor(pk(key_revocation),and(pk(key_remote),or(and(pk(key_local),and(hash160(H),hash160(H))),older(1008))))\n\nIn both cases, I just changed `hash160(H)` to `and(hash160(H),\nhash160(H))`. The notation seems to refer to the same `H`, but these are\ndifferent. One is provided by payer and the other is provided by payee. So\nwe don't necessarily have to wait for PTLCs.\n\nRegards,\nHiroki\n\n\n2019\u5e746\u670827\u65e5(\u6728) 18:45 Hiroki Gondo <hiroki.gondo at nayuta.co>:\n\n> Hi ZmnSCPxj and Bastien,\n>\n> When I was putting together this proposal, I thought it would be difficult\n> for me to consider all the security and privacy issues. I am very glad that\n> you raised the possible issues.\n>\n> > So my opinion, it is best to retain this property of \"D does not know\n> payer A\".\n>\n> I agree with your opinion too. I thought there was no problem if the ACK\n> and the PoP were responses of the HTLCs and the key respectively. But,\n>\n> > The added communication round may allow intermediate node to guess the\n> payer.\n>\n> > With addition of new ACK-key turnaround, intermediate node can measure\n> time from send of ACK to receive of key, and guess its distance to payer.\n>\n> Right.\n>\n> > A can select another route (e.g. D -> E -> F -> A) and can create the ACK\n> > onion packet during the setup phase.\n> > A can then embed this ACK packet inside the last hop payload of the\n> > *add_htlc* onion packet.\n> > When D receives it, it simply sends that onion to the indicated recipient\n> > (E) which will unwrap and forward.\n> > This way D doesn't learn anything about A, and intermediate nodes aren't\n> > included in the ACK route so\n> > they don't learn anything either.\n>\n> I think this is likely to be an improvement. This could also be\n> generalized as a case where a packet we send goes back to us via a given\n> node. I need to understand more precisely the limitations of the onion\n> packet including new specs under development. In the process, I will also\n> consider combination of this proposal with AMP and new routing algorithms\n> (Trampoline, Rendezvous).\n>\n> Regards,\n> Hiroki\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190918/5a5bb2be/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-18T10:30:57",
                "message_text_only": "Ohayou Hiroki-san,\n\nI agree this possibility.\n\nOf note is that this also helps support:\n\n1. Cross-currency swaps without premium-free American Call Option.\n   Exchanges will demand for a premium to be paid for revelation of the second preimage.\n2. Non-custodial Escrow.\n   The second preimage is shared between the escrow and the payer.\n\nBoth will also just as well be served by using points.\n\nRegards,\nZmnSCPxj\n\n\n>\n> I explained Stuckless Payments on the basis of PTLCs before and some people understood that this is a proposal that can be accomplished after PTLCs are introduced. But this can also be accomplished using HTLC variants that are not compatible with BOLT 1.x HTLCs. For simplicity, I'd like to describe them in Miniscript policies (http://bitcoin.sipa.be/miniscript/).\n>\n> # The BOLT #3 offered HTLC policy\n> or(pk(key_revocation),and(pk(key_remote),or(pk(key_local),hash160(H))))\n> ->\n> or(pk(key_revocation),and(pk(key_remote),or(pk(key_local),and(hash160(H),hash160(H)))))\n>\n> # The BOLT #3 received HTLC policy\n> or(pk(key_revocation),and(pk(key_remote),or(and(pk(key_local),hash160(H)),older(1008))))\n> ->\n> or(pk(key_revocation),and(pk(key_remote),or(and(pk(key_local),and(hash160(H),hash160(H))),older(1008))))\n>\n> In both cases, I just changed `hash160(H)` to `and(hash160(H), hash160(H))`. The notation seems to refer to the same `H`, but these are different. One is provided by payer and the other is provided by payee. So we don't necessarily have to wait for PTLCs.\n>\n> Regards,\n> Hiroki\n>\n> 2019\u5e746\u670827\u65e5(\u6728) 18:45 Hiroki Gondo <hiroki.gondo at nayuta.co>:\n>\n> > Hi ZmnSCPxj and Bastien,\n> >\n> > When I was putting together this proposal, I thought it would be difficult for me to consider all the security and privacy issues. I am very glad that you raised the possible issues.\n> >\n> > > So my opinion, it is best to retain this property of \"D does not know payer A\".\n> >\n> > I agree with your opinion too. I thought there was no problem if the ACK and the PoP were responses of the HTLCs and the key respectively. But,\n> >\n> > > The added communication round may allow intermediate node to guess the payer.\n> >\n> > > With addition of new ACK-key turnaround, intermediate node can measure time from send of ACK to receive of key, and guess its distance to payer.\n> >\n> > Right.\n> >\n> > > A can select another route (e.g. D -> E -> F -> A) and can create the ACK\n> > > onion packet during the setup phase.\n> > > A can then embed this ACK packet inside the last hop payload of the\n> > > *add_htlc* onion packet.\n> > > When D receives it, it simply sends that onion to the indicated recipient\n> > > (E) which will unwrap and forward.\n> > > This way D doesn't learn anything about A, and intermediate nodes aren't\n> > > included in the ACK route so\n> > > they don't learn anything either.\n> >\n> > I think this is likely to be an improvement. This could also be generalized as a case where a packet we send goes back to us via a given node. I need to understand more precisely the limitations of the onion packet including new specs under development. In the process, I will also consider combination of this proposal with AMP and new routing algorithms (Trampoline, Rendezvous).\n> >\n> > Regards,\n> > Hiroki"
            }
        ],
        "thread_summary": {
            "title": "Proposal for Stuckless Payment",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Hiroki Gondo"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 6171
        }
    },
    {
        "title": "[Lightning-dev] Revocations and Watchtowers",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-19T06:43:22",
                "message_text_only": "Good morning list,\n\nI was reading through the transcript of recent talk: https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/blockchain-design-patterns/\n\nIn section \"Revocations and SIGHASH_NOINPUT\":\n\n> There's another issue in lightning, which is the revocation transactions. There are basically, every time you do a state update, there's an extra transactions that both parties need to hold forever. If you're doing watchtowers, then the watchtowers need to keep all this evergrowing state.\n>\n> ...\n>\n> using SIGHASH_NOINPUT ... You have state to keep around, but it's just one transaction and it scales with O(1) instead of O(n).\n\n\nI thought I would just like to point out a few things:\n\n* Rusty created shachain so that we can store the O(n) transactions in O(1) space (though with large constant) and O(log n) time to extract in case of breach (and breach is expected to be a rare operation).\n  (Rusty can correct me if I am incorrect in the performance of this shachain construct).\n  * For the most part we can ignore (I think) the storage of revocation keys at this point in LN development.\n  * There is a limit to the number of updates possible, but my understanding is that this is so large as to be impractical for users to reach even with long-lifetime channels.\n* Admittedly, watchtowers with Poon-Dryja revocation mechanism need to store O(n) transactions.\n  This is because shachain stores keys, and we do not want watchtowers to possess revocation keys, only pre-built signatures to revocation transactions that pay a partial fee to the watchtower (else the watchtower could sign a revocation transaction paying only to itself without giving the client any money at all).\n  But!\n  * Watchtowers, even with Decker-Russell-Osuntokun, still need to store *all* O(n) transactions it receives for a channel.\n    This is needed to protect against \"poisoned blob\" attacks, where an attacker creates an encrypted blob that is just random data and feeds it into the watchtower.\n    See:\n      * https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-April/001203.html\n      * https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-May/001267.html\n  * Of note is that even Decker-Russell-Osuntokun watchtowers either need to identify their clients so that attackers cannot spoof the clients (meaning clients trust the watchtower with their financial information!) or have to store all encrypted blobs related to a channel (meaning O(n) data is still stored by the watchtower for each channel, despite the other advantages of Decker-Russell-Osuntokun).\n\nI do not know if work has been done on watchtowers to allow them to have O(1) storage of channel state, without leaking channel activity to the watchtower.\n\nThat is, even for Decker-Russell-Osuntokun I think it is better to make an effort to keep channel activity from being correlated by the watchtower, and this will require O(n) storage at the watchtower where n is number of updates in channel.\n\nI think the main advantage of Decker-Russell-Osuntokun (and thus the `SIGHASH_NOINPUT` it requires) is the possibility of having multiparticipant offchain updateable cryptocurrency systems, not the storage advantages.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Christian Decker",
                "date": "2019-09-19T10:14:34",
                "message_text_only": "I don't think this paints an accurate picture, both when it comes to\nwatchtowers for LN-penalty as well as for eltoo:\n\nTechnically the storage requirement for the shachain is also O(log(n))\nand not O(1) due to the fact that we effectively have a cut through the\nheight of the tree, along which we have to keep the inner nodes until we\nget the parent node which then allows us to infer the children. Given\nthat we use a constant size for that tree, it is not really relevant\nbut I thought it might be worth pointing this out. The shachain is\ncurrently limited to 2^48 updates, which is way beyond what we can hope\nto achieve on a single channel, so I agree with you that this limit is\nnot important at all currently.\n\nEven with shachain the storage requirements for the nodes (not the\nwatchtowers) are far from being constant either: since any old state,\nincluding anything that we built on top of it (HTLCs), so we need to\nkeep information around to react to those as well (preimages that cannot\nbe subsumed in a shachain since the HTLC preimage is chosen by many\nremote senders).\n\nWhen it comes to eltoo, just reusing the same watchtower protocol that\nwe designed for LN-penalty, with unidentified blobs, randomly inserted\nby anyone, and encrypted with the commitment transaction is likely too\nsimplistic, and results in the O(n) requirement you mentioned. My\nproposal would be to establish an authenticated session with a\nwatchtower, e.g., by signing all encrypted updates using a session key,\nand the watchtower only replacing updates that match the session. An\nattacker could not replace my updates I stashed with the watchtower\nsince it cannot hijack my session. This means that the watchtower can be\ncertain that it can discard old states, but still have the correct\nreaction stashed when it needs it.\n\nNotice that this is already what the lnd watchtower protocol pretty much\ndoes, and it is likely that we'd like a session anyway in order to pay\nthe watchtower for its service. I think it's unrealistic to expect\naltruistic watchtowers storing encrypted blobs for some random people\nout there in eternity, without getting compensation for it. To hide the\nactivity and timing of our channels we could simply open multiple\nsessions with the watchtower, or spread them across multiple watchtowers.\n\n\nI'd even go further and just add the channel outpoint (or should I call\nit \"contract outpoint\"?) to the update in cleartext so that the\nwatchtower can prune states for closed channels. We can still spread the\nstates across multiple watchtowers to hide update rate and timing. So\nthis effectively gets us to a O(1) storage space for watchtowers in\neltoo.\n\nCheers,\nChristian\n\n\nZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\nwrites:\n\n> Good morning list,\n>\n> I was reading through the transcript of recent talk: https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/blockchain-design-patterns/\n>\n> In section \"Revocations and SIGHASH_NOINPUT\":\n>\n>> There's another issue in lightning, which is the revocation transactions. There are basically, every time you do a state update, there's an extra transactions that both parties need to hold forever. If you're doing watchtowers, then the watchtowers need to keep all this evergrowing state.\n>>\n>> ...\n>>\n>> using SIGHASH_NOINPUT ... You have state to keep around, but it's just one transaction and it scales with O(1) instead of O(n).\n>\n>\n> I thought I would just like to point out a few things:\n>\n> * Rusty created shachain so that we can store the O(n) transactions in O(1) space (though with large constant) and O(log n) time to extract in case of breach (and breach is expected to be a rare operation).\n>   (Rusty can correct me if I am incorrect in the performance of this shachain construct).\n>   * For the most part we can ignore (I think) the storage of revocation keys at this point in LN development.\n>   * There is a limit to the number of updates possible, but my understanding is that this is so large as to be impractical for users to reach even with long-lifetime channels.\n> * Admittedly, watchtowers with Poon-Dryja revocation mechanism need to store O(n) transactions.\n>   This is because shachain stores keys, and we do not want watchtowers to possess revocation keys, only pre-built signatures to revocation transactions that pay a partial fee to the watchtower (else the watchtower could sign a revocation transaction paying only to itself without giving the client any money at all).\n>   But!\n>   * Watchtowers, even with Decker-Russell-Osuntokun, still need to store *all* O(n) transactions it receives for a channel.\n>     This is needed to protect against \"poisoned blob\" attacks, where an attacker creates an encrypted blob that is just random data and feeds it into the watchtower.\n>     See:\n>       * https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-April/001203.html\n>       * https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-May/001267.html\n>   * Of note is that even Decker-Russell-Osuntokun watchtowers either need to identify their clients so that attackers cannot spoof the clients (meaning clients trust the watchtower with their financial information!) or have to store all encrypted blobs related to a channel (meaning O(n) data is still stored by the watchtower for each channel, despite the other advantages of Decker-Russell-Osuntokun).\n>\n> I do not know if work has been done on watchtowers to allow them to have O(1) storage of channel state, without leaking channel activity to the watchtower.\n>\n> That is, even for Decker-Russell-Osuntokun I think it is better to make an effort to keep channel activity from being correlated by the watchtower, and this will require O(n) storage at the watchtower where n is number of updates in channel.\n>\n> I think the main advantage of Decker-Russell-Osuntokun (and thus the `SIGHASH_NOINPUT` it requires) is the possibility of having multiparticipant offchain updateable cryptocurrency systems, not the storage advantages.\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-19T14:54:56",
                "message_text_only": "Good morning Christian,\n\n\n> Even with shachain the storage requirements for the nodes (not the\n> watchtowers) are far from being constant either: since any old state,\n> including anything that we built on top of it (HTLCs), so we need to\n> keep information around to react to those as well (preimages that cannot\n> be subsumed in a shachain since the HTLC preimage is chosen by many\n> remote senders).\n\nAh, right.\nI forgot these.\n\nMore specifically, even though the HTLC outputs are revocable with only knowledge of the revocation key, the SCRIPT itself needs to be provided in full, including the payment hashes.\n\n> When it comes to eltoo, just reusing the same watchtower protocol that\n> we designed for LN-penalty, with unidentified blobs, randomly inserted\n> by anyone, and encrypted with the commitment transaction is likely too\n> simplistic, and results in the O(n) requirement you mentioned. My\n> proposal would be to establish an authenticated session with a\n> watchtower, e.g., by signing all encrypted updates using a session key,\n> and the watchtower only replacing updates that match the session. An\n> attacker could not replace my updates I stashed with the watchtower\n> since it cannot hijack my session. This means that the watchtower can be\n> certain that it can discard old states, but still have the correct\n> reaction stashed when it needs it.\n>\n> Notice that this is already what the lnd watchtower protocol pretty much\n> does, and it is likely that we'd like a session anyway in order to pay\n> the watchtower for its service. I think it's unrealistic to expect\n> altruistic watchtowers storing encrypted blobs for some random people\n> out there in eternity, without getting compensation for it. To hide the\n> activity and timing of our channels we could simply open multiple\n> sessions with the watchtower, or spread them across multiple watchtowers.\n\nIt seems that even with multiple sessions with a single watchtower, if the watchtower assumes you are not under direct attack (a reasonable assumption), it would still get all the information on all activity on a channel.\n\nSpreading across multiple watchtowers assumes other watchtowers are somehow not sybils of an existing Big Brother watchtower.\n\n> I'd even go further and just add the channel outpoint (or should I call\n> it \"contract outpoint\"?) to the update in cleartext so that the\n> watchtower can prune states for closed channels. We can still spread the\n> states across multiple watchtowers to hide update rate and timing. So\n> this effectively gets us to a O(1) storage space for watchtowers in\n> eltoo.\n\nWould this not mean revealing funding outpoints for unpublished channels as well, at least to the watchtower?\n\nIt seems to me there is significantly more privacy loss with these kinds of watchtowers.\n\nBefore, I proposed to continue using encrypted-blob watchtowers, except rather than triggering on txid[:16], instead trigger on sighash[:16] (so it would work with either Poon-Dryja or Decker-Russell-Osuntokun).\nThis would work with `SIGHASH_NOINPUT` on the update transactions (by matching the computed sighash for `SIGHASH_NOINBPUT`), letting watchtowers rebuild the entire sequence of updates (by also looking at further matches of sighash[:16]) in case of a breach, but *only* in case of a breach.\nWith this style, watchtowers cannot know, even within a session, whether a hundred updates you send are for a single channel updating 100 times or for a hundred channels updated once each.\n\nSimilarly to Poon-Dryja watchtowers you would send the (sighash[:16], encrypted_blob) pair for an update tx that has just been replaced with a new version.\nAnd if the old update tx is never put onchain, the watchtower never learns about what channel it was watching (unlike the proposed style where the key is the actual channel outpoint, which reveals to the watchtower the channel it was watching).\n\n\nOf course, I suppose privacy is less important in practice for most users than convenience and low price, sigh.\n\nA privacy-conscious person might run one or more private watchtowers for their nodes, and distribute them physically as much as he or she can.\nBut there is still the risk that one or more of these are hacked (indeed there is increased risk if they are not within easy physical reach of the owner), and it would be best still if the watchtowers so created have as little practical information to reveal as possible, so I believe my point still stands.\n\n\nNonetheless, code talks, so feel free to ignore me here.\n\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Revocations and Watchtowers",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Decker",
                "ZmnSCPxj"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 14019
        }
    },
    {
        "title": "[Lightning-dev] Selling timestamps (via payment points and scalars + Pedersen commitments ) [try2]",
        "thread_messages": [
            {
                "author": "Konstantin Ketterer",
                "date": "2019-09-25T09:01:28",
                "message_text_only": "*Disclaimer*: I have just finished Highschool and I'm only learning a bit\nin my free time.This may be fundamentally broken ;)\n\n*Motivation*: If I had to timestamp multiple messages I could simply\naggregate them in a merkle tree and pay relatively low fees per message.\nHowever, if I only need to timestamp something once in a while I need to\nrely on free services or pay high fees.\n\n*Solution*: buy a place in a merkle tree \"risk-free\"\n\n1. send hash x of my message (or the merkle root of another tree) to the\ntimstamping server\n2. server calculates Pedersen commit: C = x*H + r*G, hashes it, builds\nmerkle tree with other commits in it and publishes a valid transaction\ncontaining the merkle root to the Bitcoin blockchain\n3. after a certain number of block confirmations and with the given proof I\ncan confirm that the commitment C is indeed part of the Bitcoin blockchain\n4. I now have to send a lightning payment with C - x*H = r*G as the payment\npoint  to the timestamping server and as a proof of payment the server must\nreveal r to receive the money.\n\n--> With both r and x I have a valid Pedersen commitment.\n\nThis introduces an additional security assumption to Bitcoin timestamps but\nif the discrete logarithm is broken Bitcoin has bigger problems than broken\ntimestamps.\n\n*Conclusion*\nThis scheme essentially shifts the risk of a timestamping service from the\nbuyer to the seller who now has to pay the onchain transaction fee upfront.\nHence, the seller will most likely charge a small fee upfront just like\nsome submarineswap providers do.\n\nRegards\nKonstantin Ketterer\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190925/8d6502f0/attachment.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2019-09-25T09:43:12",
                "message_text_only": "On Wed, Sep 25, 2019 at 11:01:28AM +0200, Konstantin Ketterer wrote:\n> Motivation: If I had to timestamp multiple messages I could simply aggregate\n> them in a merkle tree and pay relatively low fees per message. However, if I\n> only need to timestamp something once in a while I need to rely on free\n> services or pay high fees.\n\nMaybe model the timestamping service as having fixed and floating users,\nin which case the fixed users pay a subscription fee that covers the costs\nand get placed relatively high in the merkle tree, while the floating\nusers are placed low in the merkle tree and are basically free money?\n\nYour merkle tree might then have 2**N-1 fixed slots, all at height N,\nthen 2**K floating slots, all at height N+K, but you don't need to charge\nthe floating slots anything up front, because your fixed costs are all\npaid for by subscription income from the fixed slots.\n\nYou might still want to charge some up front fee to prevent people\nspamming you with things to timestamp that they're never going to pay\nfor though.\n\n> Solution: buy a place in a merkle tree \"risk-free\"\n> 1. send hash x of my message (or the merkle root of another tree) to the\n> timstamping server\n> 2. server calculates Pedersen commit: C = x*H + r*G, hashes it, builds merkle\n> tree with other commits in it and publishes a valid transaction containing the\n> merkle root to the Bitcoin blockchain\n> 3. after a certain number of block confirmations and with the given proof I can\n> confirm that the commitment C is indeed part of the Bitcoin blockchain\n> 4. I now have to send a lightning payment with C - x*H = r*G as the payment\n> point\u00a0 to the timestamping server and as a proof of payment the server must\n> reveal r to receive the money.\n\nNice.\n\nSince it's off chain, you could also provide R and C and a zero knowledge\nproof that you know an r such that:\n\n   R = SHA256( r )\n   C = SHA256( x || r )\n\nin which case you could do it with lightning as it exists today.\n\nCheers,\naj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-25T13:30:39",
                "message_text_only": "Good morning aj, and list,\n\n> > Solution: buy a place in a merkle tree \"risk-free\"\n> >\n> > 1.  send hash x of my message (or the merkle root of another tree) to the\n> >     timstamping server\n> >\n> > 2.  server calculates Pedersen commit: C = xH + rG, hashes it, builds merkle\n> >     tree with other commits in it and publishes a valid transaction containing the\n> >     merkle root to the Bitcoin blockchain\n> >\n> > 3.  after a certain number of block confirmations and with the given proof I can\n> >     confirm that the commitment C is indeed part of the Bitcoin blockchain\n> >\n> > 4.  I now have to send a lightning payment with C - xH = rG as the payment\n> >     point&nbsp; to the timestamping server and as a proof of payment the server must\n> >     reveal r to receive the money.\n> >\n>\n> Nice.\n\nI agree.\nThis is quite correct for its needs, and kudos to Konstantin for deriving this.\nDo note that Lightning today does not yet support payment points / scalars, only payment hashes / preimages.\n\nIn particular the client might induce the server to \"waste\" a slot on committing some information onchain, but the client will still not be able to get a commitment \"for free\" as it cannot know the blinding key for the commitment.\nThat is, the client can DoS the server and have it make commitments without getting paid, wasting the server capacity, but the client would not be able to prove the commitment does commit to its message without paying.\nThis can be avoided with aj suggestion of \"floating\" and \"subscriber\" clients.\n\nI would have personally used sign-to-contract onchain directly myself for such \"rare\" operations, but aggregation certainly has its efficiency benefits and this is still useful.\n\nSo far it seems, we can use EC magic (payment point / scalar) to:\n\n* Prevent route correlation especially for multipath payments.\n* Allow pay-for-signature.\n* Allow pay-for-pedersen-commitment (this thread).\n* Support multiple parallel payments (\"stuckless\").\n* Support noncustodial Lightning escrow.\n* Probably some other things I have forgotten.\n\n>\n> Since it's off chain, you could also provide R and C and a zero knowledge\n> proof that you know an r such that:\n>\n> R = SHA256( r )\n> C = SHA256( x || r )\n>\n> in which case you could do it with lightning as it exists today.\n\nI can insist on paying only if the server reveals an `r` that matches some known `R` such that `R = SHA256(r)`, as currently in Lightning network.\n\nHowever, how would I prove, knowing only `R` and `x`, and that there exists some `r` such that `R = SHA256(r)`, that `C = SHA256(x || r)`?\nI am curious about this operation, as this is beyond what little I know of cryptography.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Anthony Towns",
                "date": "2019-09-25T19:29:58",
                "message_text_only": "On Wed, Sep 25, 2019 at 01:30:39PM +0000, ZmnSCPxj wrote:\n> > Since it's off chain, you could also provide R and C and a zero knowledge\n> > proof that you know an r such that:\n> > R = SHA256( r )\n> > C = SHA256( x || r )\n\n> > in which case you could do it with lightning as it exists today.\n> I can insist on paying only if the server reveals an `r` that matches some known `R` such that `R = SHA256(r)`, as currently in Lightning network.\n> However, how would I prove, knowing only `R` and `x`, and that there exists some `r` such that `R = SHA256(r)`, that `C = SHA256(x || r)`?\n\nIf you know x and r, you can generate C and R and a zero knowledge proof\nof the relationship between x,C,R that doesn't reveal r (eg, I think\nyou could do that with bulletproofs). Unfortunately that zkp already\nproves that C was generated based on x, so you get your timestamp for\nfree. Ooops. :(\n\nCheers,\naj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-25T23:21:10",
                "message_text_only": "Good morning aj,\n\n> On Wed, Sep 25, 2019 at 01:30:39PM +0000, ZmnSCPxj wrote:\n>\n> > > Since it's off chain, you could also provide R and C and a zero knowledge\n> > > proof that you know an r such that:\n> > > R = SHA256( r )\n> > > C = SHA256( x || r )\n>\n> > > in which case you could do it with lightning as it exists today.\n> > > I can insist on paying only if the server reveals an `r` that matches some known `R` such that `R = SHA256(r)`, as currently in Lightning network.\n> > > However, how would I prove, knowing only `R` and `x`, and that there exists some `r` such that `R = SHA256(r)`, that `C = SHA256(x || r)`?\n>\n> If you know x and r, you can generate C and R and a zero knowledge proof\n> of the relationship between x,C,R that doesn't reveal r (eg, I think\n> you could do that with bulletproofs).\n\nAh, yes, a generic zkp should work indeed.\n\n> Unfortunately that zkp already\n> proves that C was generated based on x, so you get your timestamp for\n> free. Ooops. :(\n\nYes, the \"existence-proof-of-a-proof-of-X is a proof-of-X\".\n\nPerhaps relevant? http://stevengoldfeder.com/papers/ZKCSP.pdf\nLightning payments are essentially zero-knowledge contingent payments already.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Lloyd Fournier",
                "date": "2019-09-25T23:38:57",
                "message_text_only": "This is a nice scheme.\n\nPedersen commitments + pay to point seems to be the most practical way to\ndo it but you can generalise this paying for a decommitment idea to any\ncommitment scheme. For example, you could do this in a payment channel with\nhashes if we had something like OP_CAT. e.g HTLC unlocks based on whether\nyou can provide an r such that H(r || x) == C.\n\n> Unfortunately that zkp already proves that C was generated based on x, so\nyou get your timestamp for free. Ooops. :(\n\nI haven't studied zkp for circuits in general but I guess the\nnon-interactive proofs are fiat-shamir transformations of an interactive\nprotocol. Maybe you could just use the interactive zero knowledge protocol\nwhich doesn't have the side effect of the verifier with a proof they can\ngive to others.\n\nLL\n\nOn Thu, Sep 26, 2019 at 5:30 AM Anthony Towns <aj at erisian.com.au> wrote:\n\n> On Wed, Sep 25, 2019 at 01:30:39PM +0000, ZmnSCPxj wrote:\n> > > Since it's off chain, you could also provide R and C and a zero\n> knowledge\n> > > proof that you know an r such that:\n> > > R = SHA256( r )\n> > > C = SHA256( x || r )\n>\n> > > in which case you could do it with lightning as it exists today.\n> > I can insist on paying only if the server reveals an `r` that matches\n> some known `R` such that `R = SHA256(r)`, as currently in Lightning network.\n> > However, how would I prove, knowing only `R` and `x`, and that there\n> exists some `r` such that `R = SHA256(r)`, that `C = SHA256(x || r)`?\n>\n> If you know x and r, you can generate C and R and a zero knowledge proof\n> of the relationship between x,C,R that doesn't reveal r (eg, I think\n> you could do that with bulletproofs). Unfortunately that zkp already\n> proves that C was generated based on x, so you get your timestamp for\n> free. Ooops. :(\n>\n> Cheers,\n> aj\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190926/16f52927/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2019-09-26T09:08:01",
                "message_text_only": "On Wed, Sep 25, 2019 at 11:01:28AM +0200, Konstantin Ketterer wrote:\n> *Disclaimer*: I have just finished Highschool and I'm only learning a bit\n> in my free time.This may be fundamentally broken ;)\n> \n> *Motivation*: If I had to timestamp multiple messages I could simply\n> aggregate them in a merkle tree and pay relatively low fees per message.\n> However, if I only need to timestamp something once in a while I need to\n> rely on free services or pay high fees.\n> \n> *Solution*: buy a place in a merkle tree \"risk-free\"\n> \n> 1. send hash x of my message (or the merkle root of another tree) to the\n> timstamping server\n> 2. server calculates Pedersen commit: C = x*H + r*G, hashes it, builds\n> merkle tree with other commits in it and publishes a valid transaction\n> containing the merkle root to the Bitcoin blockchain\n> 3. after a certain number of block confirmations and with the given proof I\n> can confirm that the commitment C is indeed part of the Bitcoin blockchain\n> 4. I now have to send a lightning payment with C - x*H = r*G as the payment\n> point  to the timestamping server and as a proof of payment the server must\n> reveal r to receive the money.\n> \n> --> With both r and x I have a valid Pedersen commitment.\n> \n> This introduces an additional security assumption to Bitcoin timestamps but\n> if the discrete logarithm is broken Bitcoin has bigger problems than broken\n> timestamps.\n> \n> *Conclusion*\n> This scheme essentially shifts the risk of a timestamping service from the\n> buyer to the seller who now has to pay the onchain transaction fee upfront.\n> Hence, the seller will most likely charge a small fee upfront just like\n> some submarineswap providers do.\n\nThis sounds like a clever idea. But because timestamping is so scalable I\nalready run a much less clever service called OpenTimestamps that does\ntimestamping for free. Basically, it uses giant merkle trees built every second\nin a scalable way to amortize the cost of the BTC transactions across the\nentire world's timestamps, so there's really no need to charge for them.\n\nEven if, say, every single Android phone in the world timestamped every single\nphoto taken, all I'd have to do is partner with someone like Cloudflare to run\nOpenTimestamps aggregators and it'd still be using just a handful of bitcoin\ntransactions every day.\n\nhttps://opentimestamps.org\n\nAlso, note that Andrew Poelstra has a pull-req to add secp256k1 commitments to\nOpenTimestamps, which may prove useful to you in implementing the above:\n\nhttps://github.com/opentimestamps/python-opentimestamps/pull/14\n\nAfter all, the OpenTimestamps *proof format* doesn't depend on the aggregation\nscheme, so if you actually build the above it'd be awesome if it produced\nOpenTimestamps proofs!\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 488 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190926/c197098f/attachment-0001.sig>"
            },
            {
                "author": "Konstantin Ketterer",
                "date": "2019-09-26T16:51:47",
                "message_text_only": "First of all, thanks for everybodys feedback. I'm happy that it works.\n\nAdopting a standard like OpenTimestamps should be a no brainer because it\nwould save on development work and people are already familiar with it.\n\nI looked into secp256k1 commitments/ sign-to-contract (\nhttps://pdfs.semanticscholar.org/21ac/217d10de3ece8d29dcd1d75305b7385985a5.pdf)\nand love how they basically enable free timestamps at no additional cost by\ntweaking the signature of a normal transaction. I imagine that in the\nfuture nodes such as public lightning routing nodes or submarineswap\nproviders who have to do some transactions like opening new channels or\nperforming swaps anyways will try to subsidise their transaction fees by\nselling timestamps. Because they have no additional risk/cost they only\nneed to charge a fee upfront or require some Hashcash like proof of work\nprotection in case of spam.\n\n*Removing the discrete logarithm security assumption*\nIf we include a hash h( x || r ) of x and r in the hash of the commitment\n--> h( x*H + r*G | | h( x | | r) ) , the timestamp will still remain secure\nand valid incase secp256k1 breaks. We can't enforce it with payment points\nand scalars but if the server doesn't include a valid hash we'll never use\nhis services again and can even prove to other peers that he cheated us. If\nthe system is resistant against sybil attacks with something like\nJoinMarkets time-locked Bitcoins proposal  this should work fine.\n\nRegards\nKonstantin\n\nAm Do., 26. Sept. 2019 um 11:08 Uhr schrieb Peter Todd <pete at petertodd.org>:\n\n> On Wed, Sep 25, 2019 at 11:01:28AM +0200, Konstantin Ketterer wrote:\n> > *Disclaimer*: I have just finished Highschool and I'm only learning a bit\n> > in my free time.This may be fundamentally broken ;)\n> >\n> > *Motivation*: If I had to timestamp multiple messages I could simply\n> > aggregate them in a merkle tree and pay relatively low fees per message.\n> > However, if I only need to timestamp something once in a while I need to\n> > rely on free services or pay high fees.\n> >\n> > *Solution*: buy a place in a merkle tree \"risk-free\"\n> >\n> > 1. send hash x of my message (or the merkle root of another tree) to the\n> > timstamping server\n> > 2. server calculates Pedersen commit: C = x*H + r*G, hashes it, builds\n> > merkle tree with other commits in it and publishes a valid transaction\n> > containing the merkle root to the Bitcoin blockchain\n> > 3. after a certain number of block confirmations and with the given\n> proof I\n> > can confirm that the commitment C is indeed part of the Bitcoin\n> blockchain\n> > 4. I now have to send a lightning payment with C - x*H = r*G as the\n> payment\n> > point  to the timestamping server and as a proof of payment the server\n> must\n> > reveal r to receive the money.\n> >\n> > --> With both r and x I have a valid Pedersen commitment.\n> >\n> > This introduces an additional security assumption to Bitcoin timestamps\n> but\n> > if the discrete logarithm is broken Bitcoin has bigger problems than\n> broken\n> > timestamps.\n> >\n> > *Conclusion*\n> > This scheme essentially shifts the risk of a timestamping service from\n> the\n> > buyer to the seller who now has to pay the onchain transaction fee\n> upfront.\n> > Hence, the seller will most likely charge a small fee upfront just like\n> > some submarineswap providers do.\n>\n> This sounds like a clever idea. But because timestamping is so scalable I\n> already run a much less clever service called OpenTimestamps that does\n> timestamping for free. Basically, it uses giant merkle trees built every\n> second\n> in a scalable way to amortize the cost of the BTC transactions across the\n> entire world's timestamps, so there's really no need to charge for them.\n>\n> Even if, say, every single Android phone in the world timestamped every\n> single\n> photo taken, all I'd have to do is partner with someone like Cloudflare to\n> run\n> OpenTimestamps aggregators and it'd still be using just a handful of\n> bitcoin\n> transactions every day.\n>\n> https://opentimestamps.org\n>\n> Also, note that Andrew Poelstra has a pull-req to add secp256k1\n> commitments to\n> OpenTimestamps, which may prove useful to you in implementing the above:\n>\n> https://github.com/opentimestamps/python-opentimestamps/pull/14\n>\n> After all, the OpenTimestamps *proof format* doesn't depend on the\n> aggregation\n> scheme, so if you actually build the above it'd be awesome if it produced\n> OpenTimestamps proofs!\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20190926/13ce2839/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Selling timestamps (via payment points and scalars + Pedersen commitments ) ",
            "categories": [
                "Lightning-dev",
                "try2"
            ],
            "authors": [
                "Anthony Towns",
                "Peter Todd",
                "Konstantin Ketterer",
                "Lloyd Fournier",
                "ZmnSCPxj"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 18428
        }
    },
    {
        "title": "[Lightning-dev] Full Disclosure: CVE-2019-12998 / CVE-2019-12999 / CVE-2019-13000",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2019-09-27T12:01:46",
                "message_text_only": "Problem\n-------\n\nA lightning node accepting a channel must check that the funding transaction\noutput does indeed open the channel proposed.  Otherwise an attacker can claim\nto open a channel but either not pay to the peer, or not pay the full amount.\nOnce that transaction reaches the minimum depth, it can spend funds from the\nchannel. The victim will only notice when it tries to close the channel and none \nof the commitment or mutual close transactions it has are valid.\n\nImplementations did not always do this check:\n\nc-lightning: v0.7.1 and above do this correctly, prior versions never did.\n     (CVE-2019-12998)\n\n  - This can be exploited by a connecting peer and claiming to open a channel\n    with any transaction id.\n\nlnd: v0.7.1 and above do this correctly, prior versions did not check the\n     amount.  v0.7.0 and above properly check for the scriptpubkey, v0.6.x \n     partially enforces the funding scriptpubkey, but pre-v0.6.0 did not verify\n     at all. (CVE-2019-12999)\n\n  - Exploiting via incorrect amount is possible against all prior versions. In\n    v0.7.0, the attacker must use the correct scriptpubkey, which burns the\n    coins in the funding output.\n  - Exploiting via incorrect scriptpubkey is possible on all versions prior to\n    v0.6.0.  This exploit is also possible in v0.6.x if the node is offline\n    when the funding transaction reached the required number of confirmations\n    and running with -txindex=0 on either full node backend.\n  - Exploiting neutrino users (usually mobile or laptop) with an incorrect\n    outpoint would require the attacker to collide their fake outpoint with\n    the script of the real outpoint in the BIP 158 filter. The siphash key\n    used to create the filters is derived from the blockhash. As a result, the\n    attacker cannot directly grind outpoints without also knowing the block\n    hash ahead of time. In addition, neutrino nodes are typically either\n    non-listening or do not have an advertised address, which means an\n    attacker would have to wait until receiving an inbound connection to\n    perform either exploit.\n\neclair: v0.3.1 and above do this correctly, prior versions did not if using\n     the bitcoin core backend; electrum users only check the script, not the\n     amount.  (CVE-2019-13000)\n\n  - Exploiting Electrum users (on mobile) requires the user to actively\n    connect to a malicious Lightning node, and the attacker to use the correct\n    scriptpubkey, which burns the coins in the funding output. Since Eclair\n    Mobile doesn\u2019t relay payments, the attacker can\u2019t cash out without an\n    offband interaction (e.g. selling something to the user and paying with\n    the funds in the fake channel).\n\n\nSolution\n--------\n\nOnce the funding transaction is seen, peers MUST check that the outpoint as\ndescribed in `funding_created`[1] is a funding transaction output[2] with\nthe amount described in `open_channel`[3].\n\nBackground\n----------\n\nTo open a channel, the funding peer sends `open_channel` with the proposed\n`funding_satoshis`.  The fundee replies with `accept_channel` providing the\nkeys it wants to use for the funding transaction.\n\nThen the funder creates the funding transaction, and sends the transaction id\nand output number in a `funding_created` message.\n\n```\n        +-------+                              +-------+\n        |       |--(1)---  open_channel  ----->|       |\n        |       |<-(2)--  accept_channel  -----|       |\n        |       |                              |       |\n        |   A   |--(3)--  funding_created  --->|   B   |\n        |       |<-(4)--  funding_signed  -----|       |\n        |       |                              |       |\n        |       |--(5)--- funding_locked  ---->|       |\n        |       |<-(6)--- funding_locked  -----|       |\n        +-------+                              +-------+\n\n        - where node A is 'funder' and node B is 'fundee'\n```\n\nWith this information, the fundee can create the signatures on the first\n\"commitment transaction\" and sends it in a `funding_signed` message so the\nfunder can retrieve their funds should something go wrong.  It is then safe\nfor the funder to sign and broadcast the opening transaction.  After some\nnumber of confirmations (set by the fundee), the channel is operational\n(`funding_locked`).\n\nThe specification describes clearly the requirement to check that the various\nsignatures exchanged indeed allow creation of a valid commitment transaction[4],\nand describes the requirement to wait for confirmations[5].\n\nIt did NOT, however, require the receiver to actually check that the\ntransaction is the one promised by the funder: both the amount and the actual\nscriptpubkey.\n\n\nDiscovery\n---------\n\nRusty Russell (Blockstream) discovered this while working on protocol\ntests for the specification itself, as part of an ongoing effort to\ntest multiple new proposed features add new complexities.[6]\n\nThe discovery occurred while writing tests for channel opening\nnegotiation, in particular that invalid variants were rejected; while\nwriting a test where the opener supplied an incorrect\n`funding_output_index` in the `funding_created` message, he realized\nthat it would not be rejected by the c-lightning implementation, which\nonly checked the confirmation count of the `funding_txid`, and not\neven whether the `funding_output_index` even existed!\n\nThis requirement was not mentioned in the specification, so Rusty\nimmediately disclosed the problem the authors of the other most widely\nused implementations (eclair and lnd).  Their own investigations\nrevealed that they were similarly vulnerable in limited circumstances.\n\nTogether the teams made the decision to fix this quietly for pending\nreleases, then reveal the existence of a problem 8 weeks later, once\nmost users had already upgraded.  Four weeks after that, the full\ndisclosure would be made.\n\nWhile this long-standing bug had not been independently discovered, and thus\nwas unlikely to be discovered by a malicious party before being fixed, it did\nprovide an opportunity to test communications and methods of upgrade across\nthe entire lightning ecosystem.\n\n\nTimeline\n--------\n\n2019-06-27: Bug discovered, LND and Eclair notified.\n2019-06-28: CVEs assigned.\n2019-07-02: lnd v0.7.0-beta released.\n2019-07-03: Eclair 0.3.1 released.\n2019-07-04: c-lightning 0.7.1 released.\n2019-07-06: disclosure to other projects begins (rust-lightning, ptarmigan, BLW).\n2019-07-30: lnd v0.7.1-beta released.\n2019-08-17: [Review next dates based on deployment stats/problems]\n2019-08-30: Reveal existence of CVEs, encourage laggards to upgrade.\n2019-09-07: First conclusive evidence of exploit attempt in the wild.\n2019-09-27: Full disclosure of CVEs.\n2019-09-27: Submit PR to spec to require this.\n\n[1] https://github.com/lightningnetwork/lightning-rfc/blob/v1.0/02-peer-protocol.md#the-funding_created-message\n[2] https://github.com/lightningnetwork/lightning-rfc/blob/v1.0/03-transactions.md#funding-transaction-output\n[3] https://github.com/lightningnetwork/lightning-rfc/blob/v1.0/02-peer-protocol.md#the-open_channel-message\n[4] https://github.com/lightningnetwork/lightning-rfc/blob/v1.0/02-peer-protocol.md#requirements-2\n[5] https://github.com/lightningnetwork/lightning-rfc/blob/v1.0/02-peer-protocol.md#the-funding_locked-message\n[6] https://github.com/ElementsProject/lightning-rfc-protocol-test"
            }
        ],
        "thread_summary": {
            "title": "Full Disclosure: CVE-2019-12998 / CVE-2019-12999 / CVE-2019-13000",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 7348
        }
    },
    {
        "title": "[Lightning-dev] Quotes for Article on LN Bug Fix",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2019-09-29T02:34:27",
                "message_text_only": "Hi Ed,\n\n        Sorry for the delay.\n\nThere's always a tension between safety and disclosure.\n\nIn this case, the three implementations agreed that it was best to make\nsure everyone had done a release and ensure there were no problem with\nupgrades and that the majority of people had upgraded before we disclose\nthe issue at all.\n\nGiven we found it ourselves it was considered less urgent, but 90 days\nis fairly standard across the industry.\n\nSome people were still caught unaware by the requirement to ugprade,\nwhich shows we made the right call in being cautious.  Hopefully this\nhas made things smoother for the next time we have an issue which\nrequires upgrading.\n\nCheers,\nRusty.\n\nEd Kelso <edwkelso at gmail.com> writes:\n> Writing an article for CoinSpice on the latest fix.\n>\n> Wondering who would be available for comment.\n>\n> 1. Why the decision to wait basically three months in disclosing?\n>\n> Thanks for any time and trouble answering,\n>\n> Edward"
            }
        ],
        "thread_summary": {
            "title": "Quotes for Article on LN Bug Fix",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 956
        }
    },
    {
        "title": "[Lightning-dev] Continuing the discussion about noinput / anyprevout",
        "thread_messages": [
            {
                "author": "Christian Decker",
                "date": "2019-09-30T13:23:56",
                "message_text_only": "With the recently renewed interest in eltoo, a proof-of-concept implementation\n[1], and the discussions regarding clean abstractions for off-chain protocols\n[2,3], I thought it might be time to revisit the `sighash_noinput` proposal\n(BIP-118 [4]), and AJ's `bip-anyprevout` proposal [5].\n\n(sorry for the long e-mail. I wanted to give enough context and describe the\nvarious tradeoffs so people don't have to stitch them together from memory. If\nyou're impatient there are a couple of open questions at the bottom)\n\nBoth proposals are ways to allow rebinding of transactions to new outputs, by\nadding a sighash flag that excludes the output when signing. This allows the\ntransaction to be bound to any output, without needing a new signature, as\nlong as output script and input script are compatible, e.g., the signature\nmatches the public key specified in the output.\n\nBIP-118 is limited to explaining the details of signature verification, and\nomits anything related to deployment and dependency on other proposals. This\nwas done in order not to depend on bip-taproot which is also in draft-phase\ncurrently, and to allow deployment alongside the next version of segwit\nscript. `bip-anyprevout` builds on top of BIP-118, adding integration with\n`bip-taproot`, chaperone signatures, limits the use of the sighash flag to\nscript path spends, as well as a new pubkey serialization which uses the first\nbyte to signal opt-in.\n\nI'd like to stress that both proposals are complementary and not competing,\nwhich is something that I've heard a couple of times.\n\nThere remain a couple of unclear points which I hope we can address in the\ncoming days, to get this thing moving again, and hopefully get a new tool in\nour toolbox soon(ish).\n\nIn the following I will quote a couple of things that were discussed during\nthe CoreDev meeting earlier this year, but not everybody could join, and it is\nimportant that we engage the wider community, to get a better picture, and I\nthink not everybody is up-to-date about the current state.\n\n\n## Dangers of `sighash_noinput`\n\nAn argument I have heard against noinput is that it is slightly less complex\nor compute intensive than `sighash_all` signatures, which may encourage wallet\ncreators to only implement the noinput variant, and use it indiscrimi-\nnately. This is certainly a good argument, and indeed we have seen at least\none developer proposing to use noinput for all transactions to discourage\naddress reuse.\n\nThis was also mentioned at CoreDev [6]:\n\n> When [...] said he wanted to write a wallet that only used SIGHASH\\_NOINPUT,\n> that was pause for concern. Some people might want to use SIGHASH\\_NOINPUT as a\n> way to cheapen or reduce the complexity of making a wallet\n> implementation. SIGHASH\\_NOINPUT is from a purely procedural point of view\n> easier than doing a SIGHASH\\_ALL, that's all I'm saying. So you're hashing\n> less. It's way faster. That concern has been brought to my attention and it's\n> something I can see. Do we want to avoid people being stupid and shooting\n> themselves and their customers in the foot? Or do we treat this as a special\n> case where you mark we're aware of how it should be used and we just try to\n> get that awareness out?\n\nAnother issue that is sometimes brought up is that an external user may\nattempt to send funds to a script that was really part of a higher-level\nprotocol. This leads to those funds becoming inaccessible unless you gather\nall the participants and sign off on those funds. I don't believe this is\nanything new, and if users really want to shoot themselves in the foot and\nsend funds to random addresses they fish out of a blockexplorer there's little\nwe can do. What we could do is make the scripts used internally in our\nprotocols unaddressable (see output tagging below), removing this issue\naltogether.\n\n\n## Chaperone signatures\n\nChaperone signatures are signatures that ensure that there is no third-party\nmalleability of transactions. The idea is to have an additional signature,\nthat doesn't use noinput, or any of its variants, and therefore needs to be\nauthored by one of the pubkeys in the output script, i.e., one or more of the\nparticipants of the contract the transaction belongs to. Concretely in eltoo\nwe'd be using a shared key known to all participants in the eltoo instance, so\nany participant can sign an update to rebind it to the desired output.\n\nChaperone signatures have a number of downsides however:\n\n-   Additional size: both the public key and the signature actually need to be\n    stored along with the real noinput signature, resulting in transfer,\n    computational and storage overhead. We can't reuse the same pubkey from the\n    noinput signature since that'd require access to the matching privkey which\n    is what we want to get rid of using noinput in the first place.\n-   Protocols can still simply use a globally known privkey, voiding the\n    benefit of chaperone signatures, since third-parties can sign again. I\n    argue that third-party malleability is a subset of first-party\n    malleability, and we should protect against first-party malleability first\n    and foremost. My counterparty has the incentive to trick me, a third-party\n    may not.\n\nOn the plus side chaperone signatures certainly address the lazy-wallet-dev\nscenario, and as AJ points out in [bip-anyprevout] we get back the same\nsecurity guarantees as we had without noinput.\n\n>From what I remember and the transcript (thanks Kanzure for your awesome work\nby the way), there was no strong support for chaperone signatures during the\nmeeting [6], but feedback from people that were not present is needed:\n\n> if everyone who wanted to use NOINPUT was convinced there was a problem, then\n> they would pick the right thing, but clearly people aren't. It's not a\n> foot-gun defense mechanism because it's easily bypassed, and it's easier to\n> bypass it than to use it. Whereas for tagged outputs, it's that if you want\n> any NOINPUT then you must tag.\n\n\n## Output tagging\n\nOne proposal that I found rather fascinating during the discussion in\nAmsterdam was that we could achieve the same disincentive to use on\nnon-smart-contract cases by simply making the output scripts\nunaddressable. This can be done by specifying a version of taproot outputs for\nwhich the bech32 addressing scheme simply doesn't have a representation [6]:\n\n> The tagged outputs idea is that we don't have NOINPUT ANYPREVOUT supported for\n> taproot v1 outputs, instead we have a segwit version 16 v16 that supports\n> taproot. The reason for v16 is that we redefine bech32 to not cover\n> v16. There's no addresses for this type of output. If you're an exchange and\n> receive a bech32 address, you declare it invalid. You make it less user\n> friendly here; and there shouldn't be an address anyway. You might want to see\n> it on a block explorer, but you don't want to pass it around to anyone.\n\nWe don't need addresses in our contract constructions because we deal directly\nwith the scripts. This would also have the desired effect of no allowing\ngeneric wallets to send to these addresses, or users accidentally sending\nfunds to what was supposed to be a one-off script used internally in the\noff-chain contract.\n\nNotice that this idea was already used by Russell O'Connor when performing a\ntransaction on elements using his new scripting language simplicity\n[7]:\n\n> For this experimental development, we created an improper segwit version,\n> \"version 31\" for Simplicity addresses. The payload of this segwit version 31\n> address contains a commitment Merkle root of a Simplicity program to control\n> the UTXO.\n\nThe concern with output tagging is that it hurts fungibility, marking outputs\nused in a contract as such and making them identifiable. But maybe it would be\na good idea to create two domains anyway: one for user-addressable\ndestinations which users can use with their general purpose wallets, and one\ndomain for contracts, which users cannot send to directly.\n\nThis also came up during the CoreDev meeting [ams-coredev]:\n\n> these sort of NOINPUT signatures are only things that are within some\n> application or within some protocol that gets negotiated between participants,\n> but they don't cross-independent domains where you see a wallet or a protocol\n> as a kind of domain. You can't tell the difference, is this an address I can\n> give to someone else or not? It's all scripts, no real addresses. There are\n> types of outputs that are completely insecure unconditionally; there are\n> things that are protected and I can give to anyone, you don't want to reuse\n> it, but there's no security issue from doing so. This is an additional class\n> that is secure perfectly but only when used in the right way.\n\n\n## Open questions\n\nThe questions that remain to be addressed are the following:\n\n1.  General agreement on the usefulness of noinput / anyprevoutanyscript /\n    anyprevout. While at the CoreDev meeting I think everybody agreed that\n    these proposals a useful, also beyond eltoo, not everybody could be\n    there. I'd therefore like to elicit some feedback from the wider community.\n2.  Is there strong support or opposition to the chaperone signatures\n    introduced in anyprevout / anyprevoutanyscript? I think it'd be best to\n    formulate a concrete set of pros and contras, rather than talk about\n    abstract dangers or advantages.\n3.  The same for output tagging / explicit opt-in. What are the advantages and\n    disadvantages?\n4.  Shall we merge BIP-118 and bip-anyprevout. This would likely reduce the\n    confusion and make for simpler discussions in the end.\n5.  Anything I forgot to mention :-)\n\nCheers,\nChristian\n\n[1] <https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-September/002131.html>\n[2] <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-September/017285.html>\n[3] <https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-August/001383.html>\n[4] <https://github.com/bitcoin/bips/blob/master/bip-0118.mediawiki>\n[5] <https://github.com/ajtowns/bips/blob/bip-anyprevout/bip-anyprevout.mediawiki>\n[6] <http://diyhpl.us/wiki/transcripts/bitcoin-core-dev-tech/2019-06-06-noinput-etc/>\n[7] <https://lists.ozlabs.org/pipermail/simplicity/2019/000018.html>"
            }
        ],
        "thread_summary": {
            "title": "Continuing the discussion about noinput / anyprevout",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Decker"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 10205
        }
    },
    {
        "title": "[Lightning-dev] [bitcoin-dev] Continuing the discussion about noinput / anyprevout",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-30T16:00:35",
                "message_text_only": "Good morning Christian,\n\n> The concern with output tagging is that it hurts fungibility, marking outputs\n> used in a contract as such and making them identifiable. But maybe it would be\n> a good idea to create two domains anyway: one for user-addressable\n> destinations which users can use with their general purpose wallets, and one\n> domain for contracts, which users cannot send to directly.\n\nI rather strongly oppose output tagging.\n\nThe entire point of for example Taproot was to reduce the variability of how outputs look like, so that unspent Taproot outputs look exactly like other unspent Taproot outputs regardless of the SCRIPT (or lack of SCRIPT) used to protect the outputs.\nThat is the reason why we would prefer to not support P2SH-wrapped Taproot even though P2SH-wrapping was intended to cover all future uses of SegWit, including SegWit v1 that Taproot will eventually get.\n\nIndeed, if it is output tagging that gets into Bitcoin base layer, I would strongly suggest the below for all Decker-Russell-Osuntokun implementations:\n\n* A standard MuSig 2-of-2 bip-schnorr SegWit v1 Funding Transaction Output, confirmed onchain\n* A \"translator transaction\" spending the above and paying out to a SegWit v16 output-tagged output, kept offchain.\n* Decker-Russell-Osuntokun update transaction, signed with `SIGHASH_NOINPUT` spending the translator transaction output.\n* Decker-Russell-Osuntokun state transaction, signed with `SIGHASH_NOINPUT` spending the update transaction output.\n\nThe point regarding use of a commonly-known privkey to work around chaperone signatures is appropriate to the above, incidentally.\nIn short: this is a workaround, plain and simple, and one wonders the point of adding *either* chaperones *or* output tagging if we will, in practice, just work around them anyway.\n\nAgain, the *more* important point is that special blockchain constructions should only be used in the \"bad\" unilateral close case.\nIn the cooperative case, we want to use simple plain bip-schnorr-signed outputs getting spent to further bip-schnor/Taproot SegWit v1 addresses, to increase the anonymity set of all uses of Decker-Russell-Osuntokun and other applications that might use `SIGHASH_NOINPUT` in some edge case (but which resolve down to simple bip-schnorr-signed n-of-n cases when the protocol is completed successfully by all participants).\n\nWe already have the issue in current Lightning where the blockchain-explorer-revealed address for current, existing Poon-Dryja channels is unsafe to send any amount to.\nGranted, we should work to make things safer; but I suggest that we should be willing to sacrifice some amount of safety against arguably-stupid decisions in order to have better privacy for larger sets of users.\n\n>\n> This also came up during the CoreDev meeting [ams-coredev]:\n>\n> > these sort of NOINPUT signatures are only things that are within some\n> > application or within some protocol that gets negotiated between participants,\n> > but they don't cross-independent domains where you see a wallet or a protocol\n> > as a kind of domain. You can't tell the difference, is this an address I can\n> > give to someone else or not? It's all scripts, no real addresses. There are\n> > types of outputs that are completely insecure unconditionally; there are\n> > things that are protected and I can give to anyone, you don't want to reuse\n> > it, but there's no security issue from doing so. This is an additional class\n> > that is secure perfectly but only when used in the right way.\n\nI submit that a Taproot whose internal Taproot point is a NUMS point (thus nobody knows its scalar) is similarly \"secure perfectly but only when used in the right way\".\nYet the point of Taproot is to hide these outputs until they are spent, improving their privacy while unspent.\n\nI submit also that a Taproot whose internal Taproot point is an n-of-n of all participants, with script branches enforcing particular modes, are similarly \"secure perfectly but only when used in the right way\", and again the point of Taproot is to allow the n-of-n \"everybody agrees\" path to hide among the 1-of-1 whale HODLers.\n\nIn short: I do not see how you can coherently argue for \"we should separate `SIGHASH_NOINPUT` types to a new script type\" while simultaneously arguing \"we should merge all kinds of SCRIPT usage (and non-usage) together into a single script type\".\nIf we will separate `SIGHASH_NOINPUT`-enabled outputs, we should not implement Taproot, as the existing separation of P2WSH and P2WPKH is congruent to the proposed separation of `SIGHASH_NOINPUT`-enablement.\n\n>\n> Open questions\n>\n> ---------------\n>\n> The questions that remain to be addressed are the following:\n>\n> 1.  General agreement on the usefulness of noinput / anyprevoutanyscript /\n>     anyprevout. While at the CoreDev meeting I think everybody agreed that\n>     these proposals a useful, also beyond eltoo, not everybody could be\n>     there. I'd therefore like to elicit some feedback from the wider community.\n\nI strongly agree that `NOINPUT` is useful, and I was not able to attend CoreDev (at least, not with any human fleshbot already known to you --- I checked).\n\n>\n> 2.  Is there strong support or opposition to the chaperone signatures\n>     introduced in anyprevout / anyprevoutanyscript? I think it'd be best to\n>     formulate a concrete set of pros and contras, rather than talk about\n>     abstract dangers or advantages.\n\nNo opposition, we will just work around this by publishing a common known private key to use for all chaperone signatures, since all the important security is in the `NOINPUT` signature anyway.\n\n>\n> 3.  The same for output tagging / explicit opt-in. What are the advantages and\n>     disadvantages?\n\nStrongly oppose, see above about my argument.\n\n>\n> 4.  Shall we merge BIP-118 and bip-anyprevout. This would likely reduce the\n>     confusion and make for simpler discussions in the end.\n\nAmbivalent, mildly support.\n\n>\n> 5.  Anything I forgot to mention :-)\n\nCats are very interesting creatures, and are irrelevant to `SIGHASH_NOINPUT` discussion, but are extremely cute nonetheless.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-30T23:28:43",
                "message_text_only": "Good morning list,\n\nTo elucidate further ---\n\nSuppose rather than `SIGHASH_NOINPUT`, we created a new opcode, `OP_CHECKSIG_WITHOUT_INPUT`.\n\nThis new opcode ignores any `SIGHASH` flags, if present, on a signature, but instead hashes the current transaction without the input references, then checks that hash to the signature.\n\nThis is equivalent to `SIGHASH_NOINPUT`.\n\nYet as an opcode, it would be possible to embed in a Taproot script.\n\nFor example, a Decker-Russell-Osuntokun would have an internal Taproot point be a 2-of-2, then have a script `OP_1 OP_CHECKSIG_WITHOUT_INPUT`.\nUnilateral closes would expose the hidden script, but cooperative closes would use the 2-of-2 directly.\n\nOf note, is that any special SCRIPT would already be supportable by Taproot.\nThis includes SCRIPTs that may potentially lose funds for the user.\nYet such SCRIPTs are already targetable by a Taproot address.\n\nIf we are so concerned about `SIGHASH_NOINPUT` abuse, why are we not so concerned about Taproot abuse?\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Continuing the discussion about noinput / anyprevout",
            "categories": [
                "Lightning-dev",
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 7140
        }
    }
]