[
    {
        "title": "[Lightning-dev] De geschiedenis van Lightning",
        "thread_messages": [
            {
                "author": "Aaron van Wirdum",
                "date": "2018-04-02T22:51:40",
                "message_text_only": "Hi Corn\u00e9,\n\nIk ben op het moment een uitgebreid artikel aan het schrijven over de geschiedenis van the Lightning Network. Dat behelst ook voorlopers van Lightning, en ik zou graag een paragraaf over Amiko Pay toevoegen.\n\nIk had al wat oudere documenten gevonden (zoals http://www.ultimatestunts.nl/bitcoin/ripple_bitcoin_draft_1.pdf <http://www.ultimatestunts.nl/bitcoin/ripple_bitcoin_draft_1.pdf>), maar hoopte dat jij misschien toch nog wat voor me zou kunnen toelichten?\n\nHet gaat vooral om:\n\n- In hoeverre leek Amiko Pay al op het concept dat werd beschreven in de Lightning Network white paper. (Of: in hoeverre leek Amiko Pay al op het concept dat we vandaag the Lightning Network noemen?) Wat waren de overeenkomsten, wat waren de verschillen? Waarom werkte het wel of juist niet?\n\n- In welke zin leek Amiko Pay op Ripple? Ripple is meer een krediet systeem, toch? Wat zijn de overeenkomsten/verschillen? Is dit over de jaren ge\u00ebvolueerd? En gaat het eigenlijk om Ripple oude-stijl, of Ripple nieuwe-stijl, of beiden?\n\nEn dan verder nog een algemeen verzoek. Over het algemeen is de geschiedenis van Lightning volgens mij best wel goed gedocumenteerd (bijvoorbeeld in de Bitcoin wiki, maar ook in nieuwsarchieven enzo). Maar als jij nog suggesties hebt van oude voorstellen, concepten of idee\u00ebn die uiteindelijk een rol hebben gespeeld in de geschiedenis van Lightning en/of Amiko Pay, dan zou ik dat graag van je horen :) (Dit kunnen ook oude chat logs zijn, of bijvoorbeeld forum discussies, of meer.)\n\nDe \u201cdeadline\u201d voor dit artikel is eigenlijk al best wel heel snel: ik wil het morgen af hebben. Voor het grootste deel is het artikel ook al af; er zitten vooral nog wat gaten in, zoals het Amiko Pay deel. (Ik had gehoopt je de afgelopen dagen op IRC te treffen, maar ik heb je niet online gezien.)\n\nIk hoop van je te horen! Je kunt me natuurijk ook pingen op IRC ofzo (AaronvanW).\n\nGroet,\nAaron.\n\nPGP: https://keybase.io/aaronvanw <https://keybase.io/aaronvanw>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180403/ddb764fb/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180403/ddb764fb/attachment.sig>"
            },
            {
                "author": "Aaron van Wirdum",
                "date": "2018-04-03T01:01:13",
                "message_text_only": "In case anyone was left wondering: looping the entire Lightning-dev list into that email to Corn\u00e9 was not part of the original plan.\n\nSorry about that!\n\nPGP: https://keybase.io/aaronvanw <https://keybase.io/aaronvanw>\n> On 03 Apr 2018, at 00:51, Aaron van Wirdum <aaronbitcoining at gmail.com> wrote:\n> \n> Hi Corn\u00e9,\n> \n> Ik ben op het moment een uitgebreid artikel aan het schrijven over de geschiedenis van the Lightning Network. Dat behelst ook voorlopers van Lightning, en ik zou graag een paragraaf over Amiko Pay toevoegen.\n> \n> Ik had al wat oudere documenten gevonden (zoals http://www.ultimatestunts.nl/bitcoin/ripple_bitcoin_draft_1.pdf <http://www.ultimatestunts.nl/bitcoin/ripple_bitcoin_draft_1.pdf>), maar hoopte dat jij misschien toch nog wat voor me zou kunnen toelichten?\n> \n> Het gaat vooral om:\n> \n> - In hoeverre leek Amiko Pay al op het concept dat werd beschreven in de Lightning Network white paper. (Of: in hoeverre leek Amiko Pay al op het concept dat we vandaag the Lightning Network noemen?) Wat waren de overeenkomsten, wat waren de verschillen? Waarom werkte het wel of juist niet?\n> \n> - In welke zin leek Amiko Pay op Ripple? Ripple is meer een krediet systeem, toch? Wat zijn de overeenkomsten/verschillen? Is dit over de jaren ge\u00ebvolueerd? En gaat het eigenlijk om Ripple oude-stijl, of Ripple nieuwe-stijl, of beiden?\n> \n> En dan verder nog een algemeen verzoek. Over het algemeen is de geschiedenis van Lightning volgens mij best wel goed gedocumenteerd (bijvoorbeeld in de Bitcoin wiki, maar ook in nieuwsarchieven enzo). Maar als jij nog suggesties hebt van oude voorstellen, concepten of idee\u00ebn die uiteindelijk een rol hebben gespeeld in de geschiedenis van Lightning en/of Amiko Pay, dan zou ik dat graag van je horen :) (Dit kunnen ook oude chat logs zijn, of bijvoorbeeld forum discussies, of meer.)\n> \n> De \u201cdeadline\u201d voor dit artikel is eigenlijk al best wel heel snel: ik wil het morgen af hebben. Voor het grootste deel is het artikel ook al af; er zitten vooral nog wat gaten in, zoals het Amiko Pay deel. (Ik had gehoopt je de afgelopen dagen op IRC te treffen, maar ik heb je niet online gezien.)\n> \n> Ik hoop van je te horen! Je kunt me natuurijk ook pingen op IRC ofzo (AaronvanW).\n> \n> Groet,\n> Aaron.\n> \n> PGP: https://keybase.io/aaronvanw <https://keybase.io/aaronvanw>\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180403/963cc029/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180403/963cc029/attachment-0001.sig>"
            }
        ],
        "thread_summary": {
            "title": "De geschiedenis van Lightning",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Aaron van Wirdum"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 5283
        }
    },
    {
        "title": "[Lightning-dev] Lightning over NFC",
        "thread_messages": [
            {
                "author": "Igor Cota",
                "date": "2018-04-05T09:46:32",
                "message_text_only": "Hello all,\n\nI feel that one of the biggest promises of lightning lies in it being used\nfor everyday retail payments.\n\nI'd like to see a system that's:\n1) instantaneous like the contactless bank cards of today\n2) encodes a fancy HTML receipt in bolt11 for the payers future reference\n\nQR codes are a bit unwieldy and even more so if you want a nice HTML table\ndescription of your grocery shopping with hundreds of items - this\nrelatively large amount of data makes them impractical to scan.\n\nTo this end I've been running an instance of c-lightning on Android\n[1][2][3] and experimenting with payments via NFC. I set up a machine with\nan NFC USB dongle that acts as an point-of-sale terminal [4]. So far so\ngood!\n\nThere are two basic ways you can use NFC enabled phones today - as passive\ntag readers or in card emulation mode (not sure if the latter is available\non iOS).\n\nPassive tags are really simple and encoding bolt11 to them works as\nexpected. If you set the right MIME type Android will open whatever app is\nregistered to handle lightning and you can either pay instantaneously or\nafter user confirmation. Works great provided both the phone and terminal\nare connected to the network and have a route to each other.\n\nCard emulation mode is more interesting because it enables us to have two\nway communication and therefore an ad hoc connection to the lightning\nnetwork. After some handshaking, phone can tell the terminal that it wants\nto connect to lightning via NFC. All communication between these two\nlightning nodes can be done over NFC or even bluetooth [5]. This might be\nuseful as fallback in situations where mobile data is not available.\n\nI settled on a MIME type (application/lightning) and an NFC application id\n(LIGHTNING). There is also a very simple protocol to forward socket data.\nFor the sake of interoperability it would be great if we agreed on some\nstandards but I'm not sure how to proceed with this. Should these be part\nof a future BOLT or is mailing list banter enough?\n\nI look forward to your views!\n\nCheers,\nIgor\n\n\n[1]\nhttps://github.com/ElementsProject/lightning/commit/bd95aba7a5f9bad8f447bf3de8f7e8cfe83751af\n[2]\nhttps://github.com/ElementsProject/lightning/commit/d4d1c4acb08efb6be4f491cdee5cb6dd4b84ddf7\n[3]\nhttps://github.com/ElementsProject/lightning/commit/bd95aba7a5f9bad8f447bf3de8f7e8cfe83751af\n[4] https://github.com/icota/presto\n[5] https://github.com/ElementsProject/lightning/pull/1323\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180405/14754627/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-05T15:39:58",
                "message_text_only": "Good morning Igor,\n\nThis is quite an interesting use-case for Lightning.\n\nHowever it seems to me that the payer will need a direct channel to the payee, or at least the payment terminal (of the payee...?).\n\nIn addition the payer will need to somehow get blockchain information from the payee if the payer itself has no Internet.  The payee may have an incentive to prevent the payer from knowing that timeouts have been reached, for example, and may withhold new blocks (although all censorship attacks I know of that could be used on LN target the payee and not the payer).\n\nIs my understanding correct?\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn April 5, 2018 5:46 PM, Igor Cota <igor at codexapertus.com> wrote:\n\n> Hello all,\n>\n> I feel that one of the biggest promises of lightning lies in it being used for everyday retail payments.\n>\n> I'd like to see a system that's:\n> 1) instantaneous like the contactless bank cards of today\n> 2) encodes a fancy HTML receipt in bolt11 for the payers future reference\n>\n> QR codes are a bit unwieldy and even more so if you want a nice HTML table description of your grocery shopping with hundreds of items - this relatively large amount of data makes them impractical to scan.\n>\n> To this end I've been running an instance of c-lightning on Android [1][2][3] and experimenting with payments via NFC. I set up a machine with an NFC USB dongle that acts as an point-of-sale terminal [4]. So far so good!\n>\n> There are two basic ways you can use NFC enabled phones today - as passive tag readers or in card emulation mode (not sure if the latter is available on iOS).\n>\n> Passive tags are really simple and encoding bolt11 to them works as expected. If you set the right MIME type Android will open whatever app is registered to handle lightning and you can either pay instantaneously or after user confirmation. Works great provided both the phone and terminal are connected to the network and have a route to each other.\n>\n> Card emulation mode is more interesting because it enables us to have two way communication and therefore an ad hoc connection to the lightning network. After some handshaking, phone can tell the terminal that it wants to connect to lightning via NFC. All communication between these two lightning nodes can be done over NFC or even bluetooth [5]. This might be useful as fallback in situations where mobile data is not available.\n>\n> I settled on a MIME type (application/lightning) and an NFC application id (LIGHTNING). There is also a very simple protocol to forward socket data. For the sake of interoperability it would be great if we agreed on some standards but I'm not sure how to proceed with this. Should these be part of a future BOLT or is mailing list banter enough?\n>\n> I look forward to your views!\n>\n> Cheers,\n> Igor\n>\n> [1] https://github.com/ElementsProject/lightning/commit/bd95aba7a5f9bad8f447bf3de8f7e8cfe83751af\n> [2] https://github.com/ElementsProject/lightning/commit/d4d1c4acb08efb6be4f491cdee5cb6dd4b84ddf7\n> [3] https://github.com/ElementsProject/lightning/commit/bd95aba7a5f9bad8f447bf3de8f7e8cfe83751af\n> [4] https://github.com/icota/presto\n> [5] https://github.com/ElementsProject/lightning/pull/1323\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180405/05da3a10/attachment.html>"
            },
            {
                "author": "Corn\u00e9 Plooy",
                "date": "2018-04-05T15:52:27",
                "message_text_only": "If there are censorship concerns, you could opt for a set-up where payer\nhas an authenticated connection to a trusted server, through the\nInternet connection provided by payee. The trusted server can, for\ninstance, be a full Lightning node running at the payer's home.\n\n\nThe payer then only has to take a very light piece of electronics with\nhim/her. It will still be larger than a credit card (since\nauthentication should be done payer-side, e.g. with a PIN code), but it\ncan be smaller than a smart phone. Personally, I like this kind of\nset-up, because I see cell phones as a huge privacy issue (you're\ncontinuously transmitting your rough location to the network).\n\n\nWhy would there need to be a direct channel between payer and payee? We\nhave the Lightning network to avoid needing direct channels, right?\n\n\nCJP\n\n\n\nOp 05-04-18 om 17:39 schreef ZmnSCPxj via Lightning-dev:\n> Good morning Igor,\n>\n> This is quite an interesting use-case for Lightning.\n>\n> However it seems to me that the payer will need a direct channel to\n> the payee, or at least the payment terminal (of the payee...?).\n>\n> In addition the payer will need to somehow get blockchain information\n> from the payee if the payer itself has no Internet.\u00a0 The payee may\n> have an incentive to prevent the payer from knowing that timeouts have\n> been reached, for example, and may withhold new blocks (although all\n> censorship attacks I know of that could be used on LN target the payee\n> and not the payer).\n>\n> Is my understanding correct?\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> Sent with ProtonMail <https://protonmail.com> Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On April 5, 2018 5:46 PM, Igor Cota <igor at codexapertus.com> wrote:\n>\n>> Hello all,\n>>\n>> I feel that one of the biggest promises of lightning lies in it being\n>> used for everyday retail payments.\n>>\n>> I'd like to see a system that's:\n>> 1) instantaneous like the contactless bank cards of today\n>> 2) encodes a fancy HTML receipt in bolt11 for the payers future reference\n>>\n>> QR codes are a bit unwieldy and even more so if you want a nice HTML\n>> table description of your grocery shopping with hundreds of items -\n>> this relatively large amount of data makes them impractical to scan.\n>>\n>> To this end I've been running an instance of c-lightning on Android\n>> [1][2][3] and experimenting with payments via NFC. I set up a machine\n>> with an NFC USB dongle that acts as an point-of-sale terminal [4]. So\n>> far so good!\n>>\n>> There are two basic ways you can use NFC enabled phones today - as\n>> passive tag readers or in card emulation mode (not sure if the latter\n>> is available on iOS).\n>>\n>> Passive tags are really simple and encoding bolt11 to them works as\n>> expected. If you set the right MIME type Android will open whatever\n>> app is registered to handle lightning and you can either pay\n>> instantaneously or after user confirmation. Works great provided both\n>> the phone and terminal are connected to the network and have a route\n>> to each other.\n>>\n>> Card emulation mode is more interesting because it enables us to have\n>> two way communication and therefore an ad hoc connection to the\n>> lightning network. After some handshaking, phone can tell the\n>> terminal that it wants to connect to lightning via NFC. All\n>> communication between these two lightning nodes can be done over NFC\n>> or even bluetooth [5]. This might be useful as fallback in situations\n>> where mobile data is not available.\n>>\n>> I settled on a MIME type (application/lightning) and an NFC\n>> application id (LIGHTNING). There is also a very simple protocol to\n>> forward socket data. For the sake of interoperability it would be\n>> great if we agreed on some standards but I'm not sure how to proceed\n>> with this. Should these be part of a future BOLT or is mailing list\n>> banter enough?\n>>\n>> I look forward to your views!\n>>\n>> Cheers,\n>> Igor\n>>\n>>\n>> [1]\n>> https://github.com/ElementsProject/lightning/commit/bd95aba7a5f9bad8f447bf3de8f7e8cfe83751af\n>> [2]\n>> https://github.com/ElementsProject/lightning/commit/d4d1c4acb08efb6be4f491cdee5cb6dd4b84ddf7\n>> [3]\n>> https://github.com/ElementsProject/lightning/commit/bd95aba7a5f9bad8f447bf3de8f7e8cfe83751af\n>> [4] https://github.com/icota/presto\n>> [5] https://github.com/ElementsProject/lightning/pull/1323\n>\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-05T16:53:52",
                "message_text_only": "Good morning Corne,\n\nMy understanding, of the setup of Igor, is that, there is a Lightning-protocol connection between the mobile device and the base station/payment terminal device.\n\nInitiating a payment to anyone on the network requires that you have direct communication with whoever you have a direct channel to.\n\nIf the mobile device can communicate only with the payment terminal, then it can only pay using channels with the only node it has a connection to.\n\nThe mobile device could pay anyone else on the network via that channel, but presumably the purpose of the payment terminal is to be the node that receives the payment.\n\nIf the payment terminal itself connects to anyone else, on behalf of the mobile device, then that is beyond the current Lightning protocol.  Perhaps Igor has added more messages that allow such a setup?\n\nCommunicating over a secure channel to a trusted server is how I imagine most practical mobile devices would work.  But what the payment terminal would provide, would not be a connection to the payment terminal node, but a connection to the Internet-in-general.\n\nRegards,\nZmnSCPxj.\n\n\n\u200bSent with ProtonMail Secure Email.\u200b\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n\nOn April 5, 2018 11:52 PM, Corn\u00e9 Plooy via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n\n> If there are censorship concerns, you could opt for a set-up where payer\n> \n> has an authenticated connection to a trusted server, through the\n> \n> Internet connection provided by payee. The trusted server can, for\n> \n> instance, be a full Lightning node running at the payer's home.\n> \n> The payer then only has to take a very light piece of electronics with\n> \n> him/her. It will still be larger than a credit card (since\n> \n> authentication should be done payer-side, e.g. with a PIN code), but it\n> \n> can be smaller than a smart phone. Personally, I like this kind of\n> \n> set-up, because I see cell phones as a huge privacy issue (you're\n> \n> continuously transmitting your rough location to the network).\n> \n> Why would there need to be a direct channel between payer and payee? We\n> \n> have the Lightning network to avoid needing direct channels, right?\n> \n> CJP\n> \n> Op 05-04-18 om 17:39 schreef ZmnSCPxj via Lightning-dev:\n> \n> > Good morning Igor,\n> > \n> > This is quite an interesting use-case for Lightning.\n> > \n> > However it seems to me that the payer will need a direct channel to\n> > \n> > the payee, or at least the payment terminal (of the payee...?).\n> > \n> > In addition the payer will need to somehow get blockchain information\n> > \n> > from the payee if the payer itself has no Internet.\u00a0 The payee may\n> > \n> > have an incentive to prevent the payer from knowing that timeouts have\n> > \n> > been reached, for example, and may withhold new blocks (although all\n> > \n> > censorship attacks I know of that could be used on LN target the payee\n> > \n> > and not the payer).\n> > \n> > Is my understanding correct?\n> > \n> > Regards,\n> > \n> > ZmnSCPxj\n> > \n> > Sent with ProtonMail https://protonmail.com Secure Email.\n> > \n> > \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> > \n> > On April 5, 2018 5:46 PM, Igor Cota igor at codexapertus.com wrote:\n> > \n> > > Hello all,\n> > > \n> > > I feel that one of the biggest promises of lightning lies in it being\n> > > \n> > > used for everyday retail payments.\n> > > \n> > > I'd like to see a system that's:\n> > > \n> > > 1.  instantaneous like the contactless bank cards of today\n> > > 2.  encodes a fancy HTML receipt in bolt11 for the payers future reference\n> > > \n> > > QR codes are a bit unwieldy and even more so if you want a nice HTML\n> > > \n> > > table description of your grocery shopping with hundreds of items -\n> > > \n> > > this relatively large amount of data makes them impractical to scan.\n> > > \n> > > To this end I've been running an instance of c-lightning on Android\n> > > \n> > > [1][2][3] and experimenting with payments via NFC. I set up a machine\n> > > \n> > > with an NFC USB dongle that acts as an point-of-sale terminal [4]. So\n> > > \n> > > far so good!\n> > > \n> > > There are two basic ways you can use NFC enabled phones today - as\n> > > \n> > > passive tag readers or in card emulation mode (not sure if the latter\n> > > \n> > > is available on iOS).\n> > > \n> > > Passive tags are really simple and encoding bolt11 to them works as\n> > > \n> > > expected. If you set the right MIME type Android will open whatever\n> > > \n> > > app is registered to handle lightning and you can either pay\n> > > \n> > > instantaneously or after user confirmation. Works great provided both\n> > > \n> > > the phone and terminal are connected to the network and have a route\n> > > \n> > > to each other.\n> > > \n> > > Card emulation mode is more interesting because it enables us to have\n> > > \n> > > two way communication and therefore an ad hoc connection to the\n> > > \n> > > lightning network. After some handshaking, phone can tell the\n> > > \n> > > terminal that it wants to connect to lightning via NFC. All\n> > > \n> > > communication between these two lightning nodes can be done over NFC\n> > > \n> > > or even bluetooth [5]. This might be useful as fallback in situations\n> > > \n> > > where mobile data is not available.\n> > > \n> > > I settled on a MIME type (application/lightning) and an NFC\n> > > \n> > > application id (LIGHTNING). There is also a very simple protocol to\n> > > \n> > > forward socket data. For the sake of interoperability it would be\n> > > \n> > > great if we agreed on some standards but I'm not sure how to proceed\n> > > \n> > > with this. Should these be part of a future BOLT or is mailing list\n> > > \n> > > banter enough?\n> > > \n> > > I look forward to your views!\n> > > \n> > > Cheers,\n> > > \n> > > Igor\n> > > \n> > > [1]\n> > > \n> > > https://github.com/ElementsProject/lightning/commit/bd95aba7a5f9bad8f447bf3de8f7e8cfe83751af\n> > > \n> > > [2]\n> > > \n> > > https://github.com/ElementsProject/lightning/commit/d4d1c4acb08efb6be4f491cdee5cb6dd4b84ddf7\n> > > \n> > > [3]\n> > > \n> > > https://github.com/ElementsProject/lightning/commit/bd95aba7a5f9bad8f447bf3de8f7e8cfe83751af\n> > > \n> > > [4] https://github.com/icota/presto\n> > > \n> > > [5] https://github.com/ElementsProject/lightning/pull/1323\n> > \n> > Lightning-dev mailing list\n> > \n> > Lightning-dev at lists.linuxfoundation.org\n> > \n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> \n> Lightning-dev mailing list\n> \n> Lightning-dev at lists.linuxfoundation.org\n> \n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Igor Cota",
                "date": "2018-04-06T06:10:09",
                "message_text_only": "Morning all,\n\n\n> However it seems to me that the payer will need a direct channel to the\npayee, or at least the payment terminal (of the payee...?).\n\nYes, for the lightning NFC connection I had the local coffe shop use case\nin mind.\n\n\n> The trusted server can, for instance, be a full Lightning node running at\nthe payer's home.\n\nThis is my current setup and I feel the only feasible one for the privacy\nminded. For the time being at least.\n\n\n> The payer then only has to take a very light piece of electronics with\nhim/her. It will still be larger than a credit card (since authentication\nshould be done payer-side, e.g. with a PIN code), but it can be smaller\nthan a smart phone.\n\nThis is a great idea!\n\n\n> But what the payment terminal would provide, would not be a connection to\nthe payment terminal node, but a connection to the Internet-in-general.\n\n\u00bfPor qu\u00e9 no los dos?\nI'm thinking of a protocol where (after initial BOLT-11 transfer) the\nterminal and device agree on the means of connection depending on what they\nrespectively support or makes sense at that moment. There is a standard way\nfor NFC to handover to bluetooth or wifi, I'll look into that. Basically\nwhatever works as long as it seems seamless to the user and is relatively\nquick.\n\nI'm not so fussed about potential abuse for these types of payments. In my\nexperience people are less likely to scam you if you are physically there.\n:)\n\nThanks for your input! I made a pull request for the BOLT-11 MIME type and\nI'll have a think-over bout the connection-handover business.\n\nCheers,\nIgor\n\n\n\nOn 5 April 2018 at 18:53, ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Corne,\n>\n> My understanding, of the setup of Igor, is that, there is a\n> Lightning-protocol connection between the mobile device and the base\n> station/payment terminal device.\n>\n> Initiating a payment to anyone on the network requires that you have\n> direct communication with whoever you have a direct channel to.\n>\n> If the mobile device can communicate only with the payment terminal, then\n> it can only pay using channels with the only node it has a connection to.\n>\n> The mobile device could pay anyone else on the network via that channel,\n> but presumably the purpose of the payment terminal is to be the node that\n> receives the payment.\n>\n> If the payment terminal itself connects to anyone else, on behalf of the\n> mobile device, then that is beyond the current Lightning protocol.  Perhaps\n> Igor has added more messages that allow such a setup?\n>\n> Communicating over a secure channel to a trusted server is how I imagine\n> most practical mobile devices would work.  But what the payment terminal\n> would provide, would not be a connection to the payment terminal node, but\n> a connection to the Internet-in-general.\n>\n> Regards,\n> ZmnSCPxj.\n>\n>\n> \u200bSent with ProtonMail Secure Email.\u200b\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>\n> On April 5, 2018 11:52 PM, Corn\u00e9 Plooy via Lightning-dev <\n> lightning-dev at lists.linuxfoundation.org> wrote:\n>\n> > If there are censorship concerns, you could opt for a set-up where payer\n> >\n> > has an authenticated connection to a trusted server, through the\n> >\n> > Internet connection provided by payee. The trusted server can, for\n> >\n> > instance, be a full Lightning node running at the payer's home.\n> >\n> > The payer then only has to take a very light piece of electronics with\n> >\n> > him/her. It will still be larger than a credit card (since\n> >\n> > authentication should be done payer-side, e.g. with a PIN code), but it\n> >\n> > can be smaller than a smart phone. Personally, I like this kind of\n> >\n> > set-up, because I see cell phones as a huge privacy issue (you're\n> >\n> > continuously transmitting your rough location to the network).\n> >\n> > Why would there need to be a direct channel between payer and payee? We\n> >\n> > have the Lightning network to avoid needing direct channels, right?\n> >\n> > CJP\n> >\n> > Op 05-04-18 om 17:39 schreef ZmnSCPxj via Lightning-dev:\n> >\n> > > Good morning Igor,\n> > >\n> > > This is quite an interesting use-case for Lightning.\n> > >\n> > > However it seems to me that the payer will need a direct channel to\n> > >\n> > > the payee, or at least the payment terminal (of the payee...?).\n> > >\n> > > In addition the payer will need to somehow get blockchain information\n> > >\n> > > from the payee if the payer itself has no Internet.  The payee may\n> > >\n> > > have an incentive to prevent the payer from knowing that timeouts have\n> > >\n> > > been reached, for example, and may withhold new blocks (although all\n> > >\n> > > censorship attacks I know of that could be used on LN target the payee\n> > >\n> > > and not the payer).\n> > >\n> > > Is my understanding correct?\n> > >\n> > > Regards,\n> > >\n> > > ZmnSCPxj\n> > >\n> > > Sent with ProtonMail https://protonmail.com Secure Email.\n> > >\n> > > \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> > >\n> > > On April 5, 2018 5:46 PM, Igor Cota igor at codexapertus.com wrote:\n> > >\n> > > > Hello all,\n> > > >\n> > > > I feel that one of the biggest promises of lightning lies in it being\n> > > >\n> > > > used for everyday retail payments.\n> > > >\n> > > > I'd like to see a system that's:\n> > > >\n> > > > 1.  instantaneous like the contactless bank cards of today\n> > > > 2.  encodes a fancy HTML receipt in bolt11 for the payers future\n> reference\n> > > >\n> > > > QR codes are a bit unwieldy and even more so if you want a nice HTML\n> > > >\n> > > > table description of your grocery shopping with hundreds of items -\n> > > >\n> > > > this relatively large amount of data makes them impractical to scan.\n> > > >\n> > > > To this end I've been running an instance of c-lightning on Android\n> > > >\n> > > > [1][2][3] and experimenting with payments via NFC. I set up a machine\n> > > >\n> > > > with an NFC USB dongle that acts as an point-of-sale terminal [4]. So\n> > > >\n> > > > far so good!\n> > > >\n> > > > There are two basic ways you can use NFC enabled phones today - as\n> > > >\n> > > > passive tag readers or in card emulation mode (not sure if the latter\n> > > >\n> > > > is available on iOS).\n> > > >\n> > > > Passive tags are really simple and encoding bolt11 to them works as\n> > > >\n> > > > expected. If you set the right MIME type Android will open whatever\n> > > >\n> > > > app is registered to handle lightning and you can either pay\n> > > >\n> > > > instantaneously or after user confirmation. Works great provided both\n> > > >\n> > > > the phone and terminal are connected to the network and have a route\n> > > >\n> > > > to each other.\n> > > >\n> > > > Card emulation mode is more interesting because it enables us to have\n> > > >\n> > > > two way communication and therefore an ad hoc connection to the\n> > > >\n> > > > lightning network. After some handshaking, phone can tell the\n> > > >\n> > > > terminal that it wants to connect to lightning via NFC. All\n> > > >\n> > > > communication between these two lightning nodes can be done over NFC\n> > > >\n> > > > or even bluetooth [5]. This might be useful as fallback in situations\n> > > >\n> > > > where mobile data is not available.\n> > > >\n> > > > I settled on a MIME type (application/lightning) and an NFC\n> > > >\n> > > > application id (LIGHTNING). There is also a very simple protocol to\n> > > >\n> > > > forward socket data. For the sake of interoperability it would be\n> > > >\n> > > > great if we agreed on some standards but I'm not sure how to proceed\n> > > >\n> > > > with this. Should these be part of a future BOLT or is mailing list\n> > > >\n> > > > banter enough?\n> > > >\n> > > > I look forward to your views!\n> > > >\n> > > > Cheers,\n> > > >\n> > > > Igor\n> > > >\n> > > > [1]\n> > > >\n> > > > https://github.com/ElementsProject/lightning/commit/\n> bd95aba7a5f9bad8f447bf3de8f7e8cfe83751af\n> > > >\n> > > > [2]\n> > > >\n> > > > https://github.com/ElementsProject/lightning/commit/\n> d4d1c4acb08efb6be4f491cdee5cb6dd4b84ddf7\n> > > >\n> > > > [3]\n> > > >\n> > > > https://github.com/ElementsProject/lightning/commit/\n> bd95aba7a5f9bad8f447bf3de8f7e8cfe83751af\n> > > >\n> > > > [4] https://github.com/icota/presto\n> > > >\n> > > > [5] https://github.com/ElementsProject/lightning/pull/1323\n> > >\n> > > Lightning-dev mailing list\n> > >\n> > > Lightning-dev at lists.linuxfoundation.org\n> > >\n> > > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> >\n> > Lightning-dev mailing list\n> >\n> > Lightning-dev at lists.linuxfoundation.org\n> >\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n\n\n\n-- \n*Igor Cota*\nCodex Apertus Ltd\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180406/db51bf70/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Lightning over NFC",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Corn\u00e9 Plooy",
                "Igor Cota",
                "ZmnSCPxj"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 25969
        }
    },
    {
        "title": "[Lightning-dev] An Idea to Improve Connectivity of the Graph",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-05T16:13:19",
                "message_text_only": "Good morning Alejandro,\n\nThere is no assumption involved, merely a large number of questions.\n\nIn a retaliation construction, if a party misbehaves, the other party gets the entire amount they are working on together, as disincentive for any party to cheat.\n\nThat works for the two-party case A and B.  If A cheats, B gets money.\n\nHow do you extend that to the three-party case A B C?  If A cheats, what happens?\n\nSuppose the correct current state is A=2, B=99, C=3.  Suppose A cheats and attempts to publish A=102, B=1, C=1.  C detects it because B is asleep at that time.  Does C get to claim the money that A claimed for itself, basically 101+1 and thus 102?  But the correct state has almost all of the money assigned to B instead.  Obviously that is unjust.  Instead C should get to claim only 3 from A (its 3 in the final state) in addition to its 1 in the published state, and should give the 99 to B.  So now B also needs another retaliatory construction for the case \"A cheated first and C found out and and also cheated me\", and a separate construction for \"A cheated but C was honest\".  And that is separate construction for the case \"C cheated first and A found out and also cheated me\" and a separate construction for \"C cheated but A was honest\".\n\nAs should be obvious, it does not scale well with number of participants on a single offchain \"purse\"; it quickly becomes complex fast.\n\nRetaliatory constructions however have the major advantage of not imposing limits on the number of updates that are allowed to the offchain \"purse\".  Prior to Rusty shachains it was thought to require storage linear in the number of updates (which could be pruned once the channel/\"purse\" is brought onchain), but Rusty shachains also require O(1) storage on number of updates.  Thus retaliatory constructions are used for channels.\n\nNote that channel factories, to my understanding, can have the Duplex construction near the root of the initial onchain anchor transaction, but be terminated in Poon-Dryja retaliatory channels, so that a good part of the current LN technology has a good chance of working even after channel factories are implemented.  This strikes me as a good balance: restructuring channels is expected to be much rarer compared to updating them normally for normal usage, so each construction plays its own strengths: the Decker-Wattenhofer construction which imposes a limit on the number of updates, but has no limit on number of participants, is used for the rarer. massive \"channel restructuring\" operations, while the Poon-Dryja construction which imposes a practical limit on number of particiapnts, but has no limit on number of updates, is used for \"day-to-day\" normal operation.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180405/21fe4178/attachment.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-04-06T12:23:45",
                "message_text_only": "ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\nwrites:\n> In a retaliation construction, if a party misbehaves, the other party gets the entire amount they are working on together, as disincentive for any party to cheat.\n>\n> That works for the two-party case A and B.  If A cheats, B gets money.\n>\n> How do you extend that to the three-party case A B C?  If A cheats, what happens?\n>\n> Suppose the correct current state is A=2, B=99, C=3.  Suppose A cheats\n> and attempts to publish A=102, B=1, C=1.  C detects it because B is\n> asleep at that time.  Does C get to claim the money that A claimed for\n> itself, basically 101+1 and thus 102?  But the correct state has\n> almost all of the money assigned to B instead.  Obviously that is\n> unjust.  Instead C should get to claim only 3 from A (its 3 in the\n> final state) in addition to its 1 in the published state, and should\n> give the 99 to B.  So now B also needs another retaliatory\n> construction for the case \"A cheated first and C found out and and\n> also cheated me\", and a separate construction for \"A cheated but C was\n> honest\".  And that is separate construction for the case \"C cheated\n> first and A found out and also cheated me\" and a separate construction\n> for \"C cheated but A was honest\".\n>\n> As should be obvious, it does not scale well with number of\n> participants on a single offchain \"purse\"; it quickly becomes complex\n> fast.\n\nThe need to identify the misbehaving party and punish just that one\nparty could be addressed by having pre-committed retaliation\ntransactions. However this results in a large number of pre-committed\ntransactions that need to be carried around just for the case that\nsomeone really misbehaves. In addition colluding parties may be able to\npunish each other when an cheat attempt seems doomed to fail, which\nreduces the cost of the attack. This could also be partially fixed by\npre-committing retaliation transactions that split the misbehaving\nparty's funds. Overall a very unsatisfactory solution.\n\n> Retaliatory constructions however have the major advantage of not\n> imposing limits on the number of updates that are allowed to the\n> offchain \"purse\".  Prior to Rusty shachains it was thought to require\n> storage linear in the number of updates (which could be pruned once\n> the channel/\"purse\" is brought onchain), but Rusty shachains also\n> require O(1) storage on number of updates.  Thus retaliatory\n> constructions are used for channels.\n>\n> Note that channel factories, to my understanding, can have the Duplex\n> construction near the root of the initial onchain anchor transaction,\n> but be terminated in Poon-Dryja retaliatory channels, so that a good\n> part of the current LN technology has a good chance of working even\n> after channel factories are implemented.  This strikes me as a good\n> balance: restructuring channels is expected to be much rarer compared\n> to updating them normally for normal usage, so each construction plays\n> its own strengths: the Decker-Wattenhofer construction which imposes a\n> limit on the number of updates, but has no limit on number of\n> participants, is used for the rarer. massive \"channel restructuring\"\n> operations, while the Poon-Dryja construction which imposes a\n> practical limit on number of particiapnts, but has no limit on number\n> of updates, is used for \"day-to-day\" normal operation.\n\nThat's not as bad a tradeoff as people usually interpret, the DMC\nconstruction has parameters that allow tweaking the number of\ninvalidations, and with parameters similar to LN we can have 1.4 billion\nupdates. Which is years of operation without need to\nre-anchor. In addition penaltyless invalidation has a number of\nadvantages, for example it doesn't have the state asymmetry inherent in\nLN and there is no toxic state information that, when leaked, results in\nyour funds being claimed through a retaliation. This happened to me btw\nlast month when I accidentally restored a wallet from backup and\nattempted to reconnect.\n\nCheers,\nChristian"
            },
            {
                "author": "Alejandro Ranchal Pedrosa",
                "date": "2018-04-11T08:43:28",
                "message_text_only": "Hi Christian,\n\n> That's not as bad a tradeoff as people usually interpret, the DMC\n> construction has parameters that allow tweaking the number of\n> invalidations, and with parameters similar to LN we can have 1.4 billion\n> updates. Which is years of operation without need to\n> re-anchor. In addition penaltyless invalidation has a number of\n> advantages,\n\nAs far as I understand, long-lasting DMCs require either:\n\n \u00a0\u00a0\u00a0 (a) an initial Refund transaction with a very distant relative \nlocktime\n \u00a0\u00a0\u00a0 (b) periodic updates in the form of a Refund transaction pointing \nto a new Refund transaction resetting initial the locktime, instead of \nactually refunding.\n\n \u00a0\u00a0\u00a0 For an extreme case of (a), if one party goes unresponsive and \ndecides not to sign new commitments then the counterparty in the DMC \nwill have its funds locked for a significant amount of time, without \npenalising the unresponsive party. In the extreme case of (b), either if \nas a result of a malicious, unresponsive, or honest participant, each \nnew refund transaction that resets the refunds may end up hitting the \nblockchain, which means the worst-case utility of the channel itself \ndecreasing due to accumulative blockchain fees. Is this the trade-off \nyou speak of? if so, can you point at any resource where this trade-off \nis tackled to get worst-case utility similar to that of LN channels?\n\nBest,\nAlejandro."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-11T09:40:11",
                "message_text_only": "Good morning Alejandro,\n\nI was about to ask Christian this myself.\n\nThere is another technique:\n\nUse a sequence of `nSequence`d transactions off-chain.  For example, to get an 2-bit counter, you would have:\n\nfunding -> kickoff -> bit1 -> bit0\n\nOnly funding is onchain.  kickoff, bit1, and bit0 transactions are all kept offchain.  We start a unilateral close by broadcasting kickoff, then wait for bit1 to become valid and broadcast then, then wait for bit0 to become valid and broadcast then.\n\nThere are two versions of the bit1 and bit0 transactions.  Each bit position, you have a high `nSequence` to represent the binary 0, and a low `nSequence` value to represent the binary 1.\n\nThen to increment your counter, you replace bit0.  If it has a high `nSequence` you replace it with a new bit0 transaction with the low `nSequence` (equivalent to flipping the bit).  If it is already the low `nSequence` (i.e. logically it is value 1) then we \"carry\" it by replacing the next higher bit, then replacing the current bit with the high `nSequence` (equivalent to propagating the carry and flipping the bit).  Thus it is equivalent to binary incrementation.\n\nIt is safe to re-use the high `nSequence` on a lower bit if some higher bit in the offchain transactions uses the low `nSequence` value, since that higher bit dominates over the rest of the chain.\n\nThis is basically just the \"invalidation tree\" concept brought to its logical conclusion.  We could use trinary or quaternary or more, but that limits the `nSequence` we can use (we do not want to use too large a high `nSequence` value as that increases wait times), so there is some balancing involved in the various parameters (number of digits, radix of counter).\n\nTo get a 32-bit counter for a maximum of 4,294,967,296 updates transactions in sequence, we need 33 transactions in sequence kept off-chain.  When one party disappears, we are forced to feed the 33 transactions one-by-one into the blockchain.  If we use 4 blocks for high `nSequence` (bit 0) and 0 blocks for low `nSequence` (bit 1) then at worst case lockup time for unilateral close is 128 blocks.\n\nNote that all transactions are kept offchain: we never re-point a refund transaction as you describe in your \"(b)\".  Thus we only waste blockchain space if we are forced into a unilateral close.  Normal operation, we simply keep all transactions offchain and only touch the chain on unilateral or bilateral close.\n\nThe big drawback is the large number of transactions in sequence in a unilateral close.  In a bilateral close we collapse all transactions into a single bilateral refund.  I suppose it is hopeful to consider that unilateral closes should be very rare.\n\nSo, Christian, it still seems that techniques that reduce total wait times in a unilateral close have the drawback of increasing the number of transactions in sequence in a unilateral close.  It still seems Poon-Dryja, is superior in that total wait time is easily user-selectable and unilateral closes only have two transactions in sequence.  For low number of updates, we can consider having a tiny \"counter\" (possibly a quaternary counter) that itself terminates in multiple Poon-Dryja channels, which I believe is what the Burchert-Decker-Wattenhofer channel factories do.\n\nRegards,\nZmnSCPxj\n\n\n\u200bSent with ProtonMail Secure Email.\u200b\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n\nOn April 11, 2018 4:43 PM, Alejandro Ranchal Pedrosa <alejandro.ranchal_pedrosa at etu.upmc.fr> wrote:\n\n> Hi Christian,\n> \n> > That's not as bad a tradeoff as people usually interpret, the DMC\n> > \n> > construction has parameters that allow tweaking the number of\n> > \n> > invalidations, and with parameters similar to LN we can have 1.4 billion\n> > \n> > updates. Which is years of operation without need to\n> > \n> > re-anchor. In addition penaltyless invalidation has a number of\n> > \n> > advantages,\n> \n> As far as I understand, long-lasting DMCs require either:\n> \n> \u00a0\u00a0\u00a0 (a) an initial Refund transaction with a very distant relative\n> \n> locktime\n> \n> \u00a0\u00a0\u00a0 (b) periodic updates in the form of a Refund transaction pointing\n> \n> to a new Refund transaction resetting initial the locktime, instead of\n> \n> actually refunding.\n> \n> \u00a0\u00a0\u00a0 For an extreme case of (a), if one party goes unresponsive and\n> \n> decides not to sign new commitments then the counterparty in the DMC\n> \n> will have its funds locked for a significant amount of time, without\n> \n> penalising the unresponsive party. In the extreme case of (b), either if\n> \n> as a result of a malicious, unresponsive, or honest participant, each\n> \n> new refund transaction that resets the refunds may end up hitting the\n> \n> blockchain, which means the worst-case utility of the channel itself\n> \n> decreasing due to accumulative blockchain fees. Is this the trade-off\n> \n> you speak of? if so, can you point at any resource where this trade-off\n> \n> is tackled to get worst-case utility similar to that of LN channels?\n> \n> Best,\n> \n> Alejandro.\n> \n> Lightning-dev mailing list\n> \n> Lightning-dev at lists.linuxfoundation.org\n> \n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Christian Decker",
                "date": "2018-04-11T20:15:41",
                "message_text_only": "ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org>\nwrites:\n\n> Good morning Alejandro,\n>\n> I was about to ask Christian this myself.\n>\n> There is another technique:\n>\n> Use a sequence of `nSequence`d transactions off-chain.  For example,\n> to get an 2-bit counter, you would have:\n>\n> funding -> kickoff -> bit1 -> bit0\n>\n> Only funding is onchain.  kickoff, bit1, and bit0 transactions are all\n> kept offchain.  We start a unilateral close by broadcasting kickoff,\n> then wait for bit1 to become valid and broadcast then, then wait for\n> bit0 to become valid and broadcast then.\n\nYes, this is exactly the way we would create a shared output that has an\nindefinite lifetime, but would still be protected against the\ncounterparty becoming unresponsive. I usually call the `kickoff`\ntransaction the `trigger` transaction because it triggers the countdown\non the CSV encumbered scripts.\n\n> There are two versions of the bit1 and bit0 transactions.  Each bit\n> position, you have a high `nSequence` to represent the binary 0, and a\n> low `nSequence` value to represent the binary 1.\n>\n> Then to increment your counter, you replace bit0.  If it has a high\n> `nSequence` you replace it with a new bit0 transaction with the low\n> `nSequence` (equivalent to flipping the bit).  If it is already the\n> low `nSequence` (i.e. logically it is value 1) then we \"carry\" it by\n> replacing the next higher bit, then replacing the current bit with the\n> high `nSequence` (equivalent to propagating the carry and flipping the\n> bit).  Thus it is equivalent to binary incrementation.\n>\n> It is safe to re-use the high `nSequence` on a lower bit if some\n> higher bit in the offchain transactions uses the low `nSequence`\n> value, since that higher bit dominates over the rest of the chain.\n>\n> This is basically just the \"invalidation tree\" concept brought to its\n> logical conclusion.  We could use trinary or quaternary or more, but\n> that limits the `nSequence` we can use (we do not want to use too\n> large a high `nSequence` value as that increases wait times), so there\n> is some balancing involved in the various parameters (number of\n> digits, radix of counter).\n\nWell, what you just described is a branching factor of 2, while in the\npaper we usually used a branching factor of 48 (1 hour deltas, for 2\ndays total wait time). Unlike the Locktime based timeouts the deltas\nalong a branch in the tree are now cumulative so you'd probably want to\nmake sure that they sum up to a reasonable max timeout, i.e., all sum of\ntimeouts along a branch <= 2 days total.\n\n> To get a 32-bit counter for a maximum of 4,294,967,296 updates\n> transactions in sequence, we need 33 transactions in sequence kept\n> off-chain.  When one party disappears, we are forced to feed the 33\n> transactions one-by-one into the blockchain.  If we use 4 blocks for\n> high `nSequence` (bit 0) and 0 blocks for low `nSequence` (bit 1) then\n> at worst case lockup time for unilateral close is 128 blocks.\n\nThat is mostly due to the selection of 1 bit sequence diffs, the\nbranching gives us a huge increase in the number of invalidations. The\npaper has the example of branching factor of 46, and a tree depth of 11,\nwhich results in 1.48e11 updates.\n\n> Note that all transactions are kept offchain: we never re-point a\n> refund transaction as you describe in your \"(b)\".  Thus we only waste\n> blockchain space if we are forced into a unilateral close.  Normal\n> operation, we simply keep all transactions offchain and only touch the\n> chain on unilateral or bilateral close.\n>\n> The big drawback is the large number of transactions in sequence in a\n> unilateral close.  In a bilateral close we collapse all transactions\n> into a single bilateral refund.  I suppose it is hopeful to consider\n> that unilateral closes should be very rare.\n>\n> So, Christian, it still seems that techniques that reduce total wait\n> times in a unilateral close have the drawback of increasing the number\n> of transactions in sequence in a unilateral close.  It still seems\n> Poon-Dryja, is superior in that total wait time is easily\n> user-selectable and unilateral closes only have two transactions in\n> sequence.  For low number of updates, we can consider having a tiny\n> \"counter\" (possibly a quaternary counter) that itself terminates in\n> multiple Poon-Dryja channels, which I believe is what the\n> Burchert-Decker-Wattenhofer channel factories do.\n\nYes, I agree that DMCs have a much wider on-chain footprint for the\nnon-cooperative close scenario. I do prefer DMC style updates for some\nuse-cases though, since they do not have the issue with more than 2\nparties, they have no toxic material that can result in your funds being\ngrabbed, just because you were out of date, and because it means that we\ncan totally forget old HTLCs since there is no way for them to ever\nbecome relevant again (in LN, if an old commitment gets confirmed we\nneed to scramble to recover the preimage so the rightful owner can claim\nit).\n\nI guess it's another tool in our toolbox :-)\n\nCheers,\nChristian"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-12T00:46:16",
                "message_text_only": "Good morning,\n\n> \n> That is mostly due to the selection of 1 bit sequence diffs, the\n> \n> branching gives us a huge increase in the number of invalidations. The\n> \n> paper has the example of branching factor of 46, and a tree depth of 11,\n> \n> which results in 1.48e11 updates.\n\n>From your description, it seems, you are somehow imposing a total of 288 blocks wait time.  Does this mean you first start with:\n\nkickoff -> (288) tree0\n\nThen further updates:\n\nkickoff -> (282) tree1 -> (6) tree0\n\nkickoff -> (282) tree1 -> (0) tree0\n\nkickoff -> (276) tree2 -> (12) tree1\n\nkickoff -> (276) tree2 -> (6) tree1 -> (6) tree0\n\nkickoff -> (276) tree2 -> (6) tree1 -> (0) tree0\n\nkickoff -> (276) tree2 -> (0) tree1 -> (12) tree0\n\nHow exactly do you maintain the 288 blocks total wait time?\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "An Idea to Improve Connectivity of the Graph",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Decker",
                "Alejandro Ranchal Pedrosa",
                "ZmnSCPxj"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 19264
        }
    },
    {
        "title": "[Lightning-dev] QR of node information",
        "thread_messages": [
            {
                "author": "Robert Olsson",
                "date": "2018-04-07T15:17:22",
                "message_text_only": "Hello all,\n\nI seem to not find a bolt regarding the QR code of node at ip:port\n\nIt seems eclair only supports the format hex at ip:port format, and i haven't\ntried any other mobile wallets.\n\nI thought there would be support for bech32 nodeid:s to keep the QR small,\nbut it doesn't seem that way.\n\nIf it isn't standardized yet, i think we should do it soon so all wallets\nwill support it from start and we can avoid bulky QR codes.\n\nTo fully utilize QR it should work with charset in text-mode, so i would\nsuggest a format like\n\nlightning:ln1bech32nodeid/ipnumber/port\n\nwhere /port is optional if port is 9735\n\nthis is to avoid @ and confusion of : in ipv6 and :portnumber\n(skip '[' and ']' in ipv6)\n\nanother approach would be to encode ip and portnumber in bech32 as well. my\nopinion is that everything coded entirely in bech32 shouldn't need a\nprotocol so the 'lightning:' part could possibly be omitted as well.\n\nor did i just miss a bolt somewhere?\n\nbest regards\nRobert Olsson\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180407/4dc3c679/attachment.html>"
            },
            {
                "author": "Corn\u00e9 Plooy",
                "date": "2018-04-09T09:47:51",
                "message_text_only": "Why put everything in bech32? It hurts readability. The only possible\nadvantage is that data inside the bech32 blob can be digitally signed in\na convenient way. If you don't need that, I'd keep your data ourside the\nbech32 blob, in a (expert-)human-readable format.\n\n\nWhy not follow a regular URL format when host and port are involved? I\ndon't see the advantage of lightning:ln1bech32nodeid/ipnumber/port over\nnode at ip:port. In practice, I see both C-Lightning and LND also using\nnode at ip:port, BTW.\n\n\nIs this really only about reducing the size of QR codes? How many\npercent reduction do you think you can accomplish with your approach? I\nthink, when it comes to reducing QR code size, it makes more sense to\nthink of a better way to encode the node ID. Hexadecimal isn't exactly\nthe most space-efficient encoding.\n\n\nCJP\n\n\n\nOp 07-04-18 om 17:17 schreef Robert Olsson:\n> Hello all,\n>\n> I seem to not find a bolt regarding the QR code of node at ip:port\n>\n> It seems eclair only supports the format hex at ip:port format, and i\n> haven't tried any other mobile wallets.\n>\n> I thought there would be support for bech32 nodeid:s to keep the QR\n> small, but it doesn't seem that way.\n>\n> If it isn't standardized yet, i think we should do it soon so all\n> wallets will support it from start and we can avoid bulky QR codes.\n>\n> To fully utilize QR it should work with charset in text-mode, so i\n> would suggest a format like\n>\n> lightning:ln1bech32nodeid/ipnumber/port\n>\n> where /port is optional if port is 9735\n>\n> this is to avoid @ and confusion of : in ipv6 and :portnumber\n> (skip '[' and ']' in ipv6)\n>\n> another approach would be to encode ip and portnumber in bech32 as\n> well. my opinion is that everything coded entirely in bech32 shouldn't\n> need a protocol so the 'lightning:' part could possibly be omitted as\n> well.\n>\n> or did i just miss a bolt somewhere?\n>\n> best regards\n> Robert Olsson\n>\n>\n>\n>\n>\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Igor Cota",
                "date": "2018-04-09T11:06:54",
                "message_text_only": "Hi all,\n\nOn 9 April 2018 at 11:47, Corn\u00e9 Plooy via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n>\n> Is this really only about reducing the size of QR codes? How many\n> percent reduction do you think you can accomplish with your approach? I\n> think, when it comes to reducing QR code size, it makes more sense to\n> think of a better way to encode the node ID. Hexadecimal isn't exactly\n> the most space-efficient encoding.\n>\n\nWe'd save 33 bytes by not using hex. Makes the QR code a bit rarer\n(whatever is opposite of dense).\nI intend to support both approaches, if there are 33 bytes before the '@'\nit's raw, 66 it's hex.\n\nIgor\n\n\n\n> Op 07-04-18 om 17:17 schreef Robert Olsson:\n> > Hello all,\n> >\n> > I seem to not find a bolt regarding the QR code of node at ip:port\n> >\n> > It seems eclair only supports the format hex at ip:port format, and i\n> > haven't tried any other mobile wallets.\n> >\n> > I thought there would be support for bech32 nodeid:s to keep the QR\n> > small, but it doesn't seem that way.\n> >\n> > If it isn't standardized yet, i think we should do it soon so all\n> > wallets will support it from start and we can avoid bulky QR codes.\n> >\n> > To fully utilize QR it should work with charset in text-mode, so i\n> > would suggest a format like\n> >\n> > lightning:ln1bech32nodeid/ipnumber/port\n> >\n> > where /port is optional if port is 9735\n> >\n> > this is to avoid @ and confusion of : in ipv6 and :portnumber\n> > (skip '[' and ']' in ipv6)\n> >\n> > another approach would be to encode ip and portnumber in bech32 as\n> > well. my opinion is that everything coded entirely in bech32 shouldn't\n> > need a protocol so the 'lightning:' part could possibly be omitted as\n> > well.\n> >\n> > or did i just miss a bolt somewhere?\n> >\n> > best regards\n> > Robert Olsson\n> >\n> >\n> >\n> >\n> >\n> >\n> >\n> > _______________________________________________\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n\n\n\n-- \n*Igor Cota*\nCodex Apertus Ltd\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180409/eb71167a/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-04-10T23:47:49",
                "message_text_only": "Robert Olsson <robban at robtex.com> writes:\n> Hello all,\n>\n> I seem to not find a bolt regarding the QR code of node at ip:port\n>\n> It seems eclair only supports the format hex at ip:port format, and i haven't\n> tried any other mobile wallets.\n\nI anticipate a move away from \"manually connect to node\" and this wart\nwill be less visible.  We could come up with a bech32 'ln1' encoding, I\nguess.  It would be 62 chars vs 66 though, if my math is correct...\n\nCheers,\nRusty."
            },
            {
                "author": "Robert Olsson",
                "date": "2018-04-12T09:56:11",
                "message_text_only": "hello all,\n\nyes the biggest advantage of bech32 would be for making small QR codes,\nwhere it does much more savings than in ascii.\n(you could still print the hex underneath the QR code of course if you want\nto enter it manually. personally i would prefer bech32 there as well\nbecause of its advantages for manual typing, with checksums and\nerror-corrections)\n\nbech32 is designed also to make small QR codes because of the ability to\ncreate text-mode QR-codes which are much smaller.\nthat is *if* the bech32 string first is made uppercase, and you avoid\ninserting certain characters such as '@' and ':'\n\nthe invoices are pure bech32 and satisfies those requirements for small QR\ncodes. however the only live case i've seen that actually realizes that and\nmakes the QR code for invoices uppercase is blockstream, but i might be\nwrong.\n\nanyhows, if you upon payment for lets say a burger can't find a route that\nwill handle the amount, i think you probably would like to connect to the\nreceiving party directly.\n(rather than randomly select a node and open a channel to that one and hope\nthat one has a path, and repeat that until it succeeds or you run out of\nonchain funds while your burger is getting cold. maybe the payee for the\nmoment doesn't have any available inbound capacity at all, you'd be stuck\nforever trying out new channels)\n\ni think connecting to the recipients node directly is far better. it could\nof course be optional, and the UX could ask the user \"your current channels\ndoesn't have a route to mcdonalds with sufficient capacity, do you want to\nopen a new channel directly to mcdonalds, or to a randomly selected goat\nfarmer on the other side of the world that might have a well funded path?\"\n\nif you DO want to open a direct channel to the stores you use the most, the\ninvoice does already contain the node-id, and sure you could look that up\nin the graph to find out and your wallet will establish a properly sized\nconnection, perhaps depending on your payment history, perhaps automatic\neven after successful payments via other routes.\n\nimho it would be awesome if the invoice contained the addr-part (from node)\nas well to provide for automatic opening of channel without having to scan\nthe graph, or better yet the proposed bolt12, even if it means you would\nhave to rely on DNSSEC to make sure mcdonalds.com isn't hijacked by someone\nthat wants to prevent you from using LN, just as you would have to while\nbootstrapping.\n\ni imagine mcdonalds could print the QR-code on the papers on your trays and\nsay \"scan this and next time use our node! we have lower LN fees than\nburger king\" and preferably use a protocol of some sorts to provide\nmultiple alternative nodes (like bolt12), rather than just a single node-id\nthat might be changed.\n\nthe lightning network is impressive, and it grows in connectivity and\ncapacity. but i think direct channels to the nodes you pay frequently and\nfrom they guys that pay you will make the network grow faster and more\nnatural rather than if you *only* make random channels to nodes that\nperhaps have made random channels to random nodes that in turn randomly\nconnects to mcdonalds. and even when the lightning network is well funded,\ni still might want to avoid routing fees. shouldn't i be allowed to do that\nin an easy way?\n\nsure it would make mcdonalds nodes turn into big hubs. at least slightly\nbigger and cheaper than burger king ones. free competition is a bitch.\nand also your employer would have a direct channel to you, rather than via\nsome random dude that for some reason decided that opening a channel to you\nenough for your monthly salary was a good idea.\n\nregarding sizes of QR codes, i've made a reckless PoC-implementation of\ncurrent hex, bech32 and bolt12(RIP?) QR-codes so you can compare the sizes.\n\nhttps://www.robtex.com/lightning/node/02ad6fb8d693dc1e4569bcedefadf5f72a931ae027dc0f0c544b34c1c6f3b9a02b\n\n\n\n\n\nOn Wed, Apr 11, 2018 at 2:47 AM, Rusty Russell <rusty at rustcorp.com.au>\nwrote:\n\n> Robert Olsson <robban at robtex.com> writes:\n> > Hello all,\n> >\n> > I seem to not find a bolt regarding the QR code of node at ip:port\n> >\n> > It seems eclair only supports the format hex at ip:port format, and i\n> haven't\n> > tried any other mobile wallets.\n>\n> I anticipate a move away from \"manually connect to node\" and this wart\n> will be less visible.  We could come up with a bech32 'ln1' encoding, I\n> guess.  It would be 62 chars vs 66 though, if my math is correct...\n>\n> Cheers,\n> Rusty.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180412/2cea71ca/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "QR of node information",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Robert Olsson",
                "Corn\u00e9 Plooy",
                "Igor Cota"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 10847
        }
    },
    {
        "title": "[Lightning-dev] Proposal for Advertising Lightning nodes via DNS records.",
        "thread_messages": [
            {
                "author": "Tyler H",
                "date": "2018-04-07T22:48:49",
                "message_text_only": "Greetings,\n\nA challenge end-users face is connecting to nodes with enough liquidity to\npay every merchant, and failing that, finding the merchant node in a\nreasonably sane way to open a channel to them for payments.\n\nAs it is now, people find nodes in other people's visualizers, and pass\nnode aliases around via word of mouth which is very prone to inaccuracy and\nMITM attacks. A current alternative is attempting to make a payment,\ndecoding the payment request, finding the node on your graph and attempting\nto open a channel to the merchant.  This is only possible if the\ndestination is advertising addresses.\n\nWe (Robert Olsson and I) propose an additional BOLT, tentatively scheduled\nto be BOLT 12, to allow for operators of domain names to create SRV records\nfor their nodes.  This is separate from BOLT 10's seed functionality as the\ndesired outcome is to get only the nodes associated with a particular\ndomain.  This would allow, as an example, users to say to each other\n\"connect to a Blockstream.com node\" and the user can independently look up\nthat domain, find advertised nodes and connect/open channels.\n\nThis also improves security from the perspective of nodes masquerading as\nother nodes, as anyone with a domain can authoritatively list their nodes.\n\nIn addition, domain operators could provide subdomains for their node\naddresses to distinguish between nodes intended for a specific purpose,\nfrom a human perspective.\n\nRobert Olsson (rompert) and I have created\nhttps://github.com/lightningnetwork/lightning-rfc/pull/406 as a draft of\nwhat the RFC could look like.\n\nFeedback is much appreciated.\n\nBest regards,\nTyler (tyzbit)\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180407/49c5ed2f/attachment.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-04-08T20:45:29",
                "message_text_only": "Hi Tyler,\nHi Robert,\n\nfirst of all, welcome to the mailing list, always good to have more\npeople looking and improving the spec. I quickly read through the spec\nand it is very well written, and it looks good.\n\nOn a conceptual level, I do however have some issues with the\nproposal. I don't think that the kind of selective attachment to the\nnode of a merchant is beneficial to neither the node that is opening the\nchannel, nor for the network as a whole:\n\n - For the node opening a channel at the time of a payment is too late,\n   it basically means that for the first payment you'd have to wait for\n   an on-chain confirmation, even if we use `push_msat` to perform the\n   initial payment. This is bad for the user experience. Channels should\n   be opened ahead of time so that, when the customer enters a shop,\n   everything is already set up. Special cases are always hard to\n   communicate (\"you have to wait, but only this time, then in future\n   all will be nice and quick\")\n - It also causes all future payments to go through that merchant, which\n   can now collate your shopping activity with all of your other\n   payments, and create a profile. It's basically the hub-and-spoke\n   threat with the added problem of the hub also knowing your identity.\n - The merchant can cripple future payments that he might suspect are\n   going to a competitor (Starbucks may attempt to block payments for\n   amounts that look like coffee payments and go to their\n   competitor). Think net neutrality for Lightning.\n - For the network as a whole this creates a network of large hubs that\n   are only weakly interconnected, or not connected at all, unless the\n   merchants are \"generous\" enough to maintain connections among each\n   other.\n\nBut it's not all bad, I really like the possibility to look up a\nmerchant's node ID through DNS, so that my wallet can check (indirect)\nconnectivity to that node and try to optimize their connectivity.\n\nI think we should encourage people, and implement the clients, to open\nrandom connections, biased towards strenghtening the overall\nconnectivity. With the gossip protocol we already disseminate enough\ninformation to allow nodes to identify bottlenecks and provide\nadditional capacity to bridge them.\n\nSorry for being so pessimistic, but I think it's important we move away\nfrom people attempting to open targeted channels directly to the\nmerchants. I still regret publishing the IP address of SLEEPYARK.\n\nRegards,\nChristian\n\nTyler H <tyzbit at gmail.com> writes:\n> Greetings,\n>\n> A challenge end-users face is connecting to nodes with enough liquidity to\n> pay every merchant, and failing that, finding the merchant node in a\n> reasonably sane way to open a channel to them for payments.\n>\n> As it is now, people find nodes in other people's visualizers, and pass\n> node aliases around via word of mouth which is very prone to inaccuracy and\n> MITM attacks. A current alternative is attempting to make a payment,\n> decoding the payment request, finding the node on your graph and attempting\n> to open a channel to the merchant.  This is only possible if the\n> destination is advertising addresses.\n>\n> We (Robert Olsson and I) propose an additional BOLT, tentatively scheduled\n> to be BOLT 12, to allow for operators of domain names to create SRV records\n> for their nodes.  This is separate from BOLT 10's seed functionality as the\n> desired outcome is to get only the nodes associated with a particular\n> domain.  This would allow, as an example, users to say to each other\n> \"connect to a Blockstream.com node\" and the user can independently look up\n> that domain, find advertised nodes and connect/open channels.\n>\n> This also improves security from the perspective of nodes masquerading as\n> other nodes, as anyone with a domain can authoritatively list their nodes.\n>\n> In addition, domain operators could provide subdomains for their node\n> addresses to distinguish between nodes intended for a specific purpose,\n> from a human perspective.\n>\n> Robert Olsson (rompert) and I have created\n> https://github.com/lightningnetwork/lightning-rfc/pull/406 as a draft of\n> what the RFC could look like.\n>\n> Feedback is much appreciated.\n>\n> Best regards,\n> Tyler (tyzbit)\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Tyler H",
                "date": "2018-04-08T21:48:51",
                "message_text_only": "Christian,\n\nI think your points are all valid.  I believe the challenge with something\nlike this will be in it's general use and implementation, which is why the\nRFC doesn't make mention of intended usage past mentioning different nodes\nfor \"clothing\" or \"ebooks\" a domain could advertise.\n\n--Regarding looking up nodes at the time of payments:\n\nIn the future, nodes could negotiate a channel open with a push amount and\nprovide the TXID or payment hash as proof of their payment of the invoice.\nThis wouldn't even require the channel to be usable, and merchants could\ndecide to accept 1 (or even 0) confirmations of this transaction based on\ntheir acceptable level of risk, considering the properties of the channel\n(capacity, local balance etc).  So in that use case, this would be a rough\nprocess of the interaction:\n\nUser tries to pay lightning invoice, and it fails.  The user's wallet\noffers to pay via channel opening.  The user accepts.  The wallet reads the\ninvoice for a \"domain\" field, or perhaps if the wallet happens to be a\nbrowser, it does a SRV lookup against the current domain serving the\ninvoice.  The wallet looks up the domain records, and verifies the\ndestination node is present.  If so, the wallet picks the correct node\nbased on the records present, and opens a channel with a push amount to\nit.  The destination node sees this and via as some yet undetermined\nmethod, associates it to that payment invoice and chooses to mark it as\n\"paid\" or \"pending X confirmations\" according to whatever criteria the node\noperator wishes to use.\n\nIn a simple example, you could list all of your nodes but prefer clients\nopen channels to a single one, similar to ACINQ's setup with \"endurance\"\nand \"starblocks\" on testnet.  This example would simply require setting\n\"endurance\" to have the highest priority. This also allows domain operators\nto have one or more public nodes, but many private ones with channels open\nto their public nodes to better manage their risk. For example, the private\nnodes could be behind a firewall.\n\nThe result of this is that the user experience is improved, and a side\nbenefit is being able to safely associate a given payment request, and by\nextension node, with a domain.  Another nontrivial benefit is there will be\nmore channels opened with value on the other side, allowing for receiving\nfunds back from Lightning.\n\nThere are some possible open questions regarding ensuring a payment request\nhasn't been spoofed, but if you present the domain to the user, he/she can\nverify that the wallet is about to open a channel to the domain they\nexpect.  Other issues with this are with DNS hijacking, which to be frank\nis not an unlikely scenario.  Caution would be necessary, and perhaps\ncryptographic means of associating nodes and their associated domains would\nbe a requirement for something like this to exist, but the proposed BOLT\nlays the groundwork for that to happen.\n\n--Future payments going through the merchant:\n\nThis is probably the biggest wrinkle.  The merchant _does_ have the ability\nto know when a payment transits the channel, thus reducing privacy.  I\nthink the proposed BOLT should only be used to improve user experience, not\nas a replacement for the decentralized nature of Lightning.  For example,\nnode operators will use autopilot-like functionality for opening channels,\nBUT they will be able to augment that with looking up common stores and\nmerchant's domain records and open their own channels to them to provide\nalternate routes to popular anticipated destinations for payments, thus\nmaking their own node more valuable and increasing the decentralization of\nthe network.  For example, if you know people are going to be paying\nStarbucks, you can issue a DNS request of your own, get their current\npreferred node and connect, and then any node you have channels with will\nbe able to pay Starbucks through you, without having to open a channel of\ntheir own.\n\n--Merchant crippling payments:\n\nWith the convention I described above, using channel opens as proof of\npayment, if Starbucks wants to deny a customer the ability to pay McDonalds\n(or simply doesn't have the appropriate channels to do so), the user's\nwallet will simply fall back, look up mcdonalds.com, find the appropriate\nnode and pay the invoice via channel opening.  This also partly addresses\npoint 2, as if a merchant wants to spy on its customers, it must provide\nroutes to its competitors.  It can either spy or deny routes, but not\nboth.  In addition, the onion-like nature of payments means the merchant\ncan't be sure a user paid a competitor, or a node behind them, though some\nconfigurations of channels and nodes can definitely reduce privacy quite a\nbit (example: a tiny etsy shop only has a couple of connections, Evil\nStarbucks being one of them with the largest channel.  A user paying an\namount above the second largest channel to this shop would have to use the\nmerchant's channel, and the merchant would be sure that the payment didn't\ntravel any further from there.)\n\n--Network of large hubs:\nI disagree.  Again, leaning on the ability to open channels with push\namounts that have some minor assurances (authority of DNS records) that\nyou're getting the node you intend, I expect routing node operators to\npreemptively open channels to merchants they expect to receive payments,\nand they could advertise their own node to do so, along with allowing\ncustomers to connect directly to merchants.  The minimum requirement to use\nthis BOLT are the same as running a Lightning node full time, plus\nownership of a domain.\n\nWith that said, I agree regarding the value of random connections in\nstrengthening the network.  Nodes are well-equipped to find inefficiencies\nand correct them.  The intention of the BOLT is really to improve the\non-boarding experience, along with providing an additional means to\nadvertise \"official\" nodes to ease clients, especially mobile ones, onto\nthe network.\n\nYour pessimism is warranted and invited.\n\nApologies for the lengthy reply,\nTyler\n\nOn Sun, Apr 8, 2018 at 4:47 PM Christian Decker <decker.christian at gmail.com>\nwrote:\n\n> Hi Tyler,\n> Hi Robert,\n>\n> first of all, welcome to the mailing list, always good to have more\n> people looking and improving the spec. I quickly read through the spec\n> and it is very well written, and it looks good.\n>\n> On a conceptual level, I do however have some issues with the\n> proposal. I don't think that the kind of selective attachment to the\n> node of a merchant is beneficial to neither the node that is opening the\n> channel, nor for the network as a whole:\n>\n>  - For the node opening a channel at the time of a payment is too late,\n>    it basically means that for the first payment you'd have to wait for\n>    an on-chain confirmation, even if we use `push_msat` to perform the\n>    initial payment. This is bad for the user experience. Channels should\n>    be opened ahead of time so that, when the customer enters a shop,\n>    everything is already set up. Special cases are always hard to\n>    communicate (\"you have to wait, but only this time, then in future\n>    all will be nice and quick\")\n>  - It also causes all future payments to go through that merchant, which\n>    can now collate your shopping activity with all of your other\n>    payments, and create a profile. It's basically the hub-and-spoke\n>    threat with the added problem of the hub also knowing your identity.\n>  - The merchant can cripple future payments that he might suspect are\n>    going to a competitor (Starbucks may attempt to block payments for\n>    amounts that look like coffee payments and go to their\n>    competitor). Think net neutrality for Lightning.\n>  - For the network as a whole this creates a network of large hubs that\n>    are only weakly interconnected, or not connected at all, unless the\n>    merchants are \"generous\" enough to maintain connections among each\n>    other.\n>\n> But it's not all bad, I really like the possibility to look up a\n> merchant's node ID through DNS, so that my wallet can check (indirect)\n> connectivity to that node and try to optimize their connectivity.\n>\n> I think we should encourage people, and implement the clients, to open\n> random connections, biased towards strenghtening the overall\n> connectivity. With the gossip protocol we already disseminate enough\n> information to allow nodes to identify bottlenecks and provide\n> additional capacity to bridge them.\n>\n> Sorry for being so pessimistic, but I think it's important we move away\n> from people attempting to open targeted channels directly to the\n> merchants. I still regret publishing the IP address of SLEEPYARK.\n>\n> Regards,\n> Christian\n>\n> Tyler H <tyzbit at gmail.com> writes:\n> > Greetings,\n> >\n> > A challenge end-users face is connecting to nodes with enough liquidity\n> to\n> > pay every merchant, and failing that, finding the merchant node in a\n> > reasonably sane way to open a channel to them for payments.\n> >\n> > As it is now, people find nodes in other people's visualizers, and pass\n> > node aliases around via word of mouth which is very prone to inaccuracy\n> and\n> > MITM attacks. A current alternative is attempting to make a payment,\n> > decoding the payment request, finding the node on your graph and\n> attempting\n> > to open a channel to the merchant.  This is only possible if the\n> > destination is advertising addresses.\n> >\n> > We (Robert Olsson and I) propose an additional BOLT, tentatively\n> scheduled\n> > to be BOLT 12, to allow for operators of domain names to create SRV\n> records\n> > for their nodes.  This is separate from BOLT 10's seed functionality as\n> the\n> > desired outcome is to get only the nodes associated with a particular\n> > domain.  This would allow, as an example, users to say to each other\n> > \"connect to a Blockstream.com node\" and the user can independently look\n> up\n> > that domain, find advertised nodes and connect/open channels.\n> >\n> > This also improves security from the perspective of nodes masquerading as\n> > other nodes, as anyone with a domain can authoritatively list their\n> nodes.\n> >\n> > In addition, domain operators could provide subdomains for their node\n> > addresses to distinguish between nodes intended for a specific purpose,\n> > from a human perspective.\n> >\n> > Robert Olsson (rompert) and I have created\n> > https://github.com/lightningnetwork/lightning-rfc/pull/406 as a draft of\n> > what the RFC could look like.\n> >\n> > Feedback is much appreciated.\n> >\n> > Best regards,\n> > Tyler (tyzbit)\n> > _______________________________________________\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180408/7ec182b6/attachment-0001.html>"
            },
            {
                "author": "Tyler H",
                "date": "2018-04-09T15:18:01",
                "message_text_only": "Christian et al,\n\nI've added additional wording to the PR to explicitly state BOLT 12 MUST\nNOT be used for node bootstrapping.  I will squash the commits should this\nproposal become a standard.\n\nA side effect of this BOLT would be, as an example, the mobile Eclair\nwallet could be updated to accept a domain parameter to specify an initial\nnode to open a user's first channel to rather than only the option to\n\"autoconnect\" to their hard-coded node, and the wallet could handle\nresolving and picking a node transparently, thus increasing\ndecentralization of \"fringe\" users such as mobile users and SPV nodes.\n\nCriticism and feedback is enthusiastically invited.\n\nThanks,\nTyler\n\nOn Sun, Apr 8, 2018 at 5:48 PM Tyler H <tyzbit at gmail.com> wrote:\n\n> Christian,\n>\n> I think your points are all valid.  I believe the challenge with something\n> like this will be in it's general use and implementation, which is why the\n> RFC doesn't make mention of intended usage past mentioning different nodes\n> for \"clothing\" or \"ebooks\" a domain could advertise.\n>\n> --Regarding looking up nodes at the time of payments:\n>\n> In the future, nodes could negotiate a channel open with a push amount and\n> provide the TXID or payment hash as proof of their payment of the invoice.\n> This wouldn't even require the channel to be usable, and merchants could\n> decide to accept 1 (or even 0) confirmations of this transaction based on\n> their acceptable level of risk, considering the properties of the channel\n> (capacity, local balance etc).  So in that use case, this would be a rough\n> process of the interaction:\n>\n> User tries to pay lightning invoice, and it fails.  The user's wallet\n> offers to pay via channel opening.  The user accepts.  The wallet reads the\n> invoice for a \"domain\" field, or perhaps if the wallet happens to be a\n> browser, it does a SRV lookup against the current domain serving the\n> invoice.  The wallet looks up the domain records, and verifies the\n> destination node is present.  If so, the wallet picks the correct node\n> based on the records present, and opens a channel with a push amount to\n> it.  The destination node sees this and via as some yet undetermined\n> method, associates it to that payment invoice and chooses to mark it as\n> \"paid\" or \"pending X confirmations\" according to whatever criteria the node\n> operator wishes to use.\n>\n> In a simple example, you could list all of your nodes but prefer clients\n> open channels to a single one, similar to ACINQ's setup with \"endurance\"\n> and \"starblocks\" on testnet.  This example would simply require setting\n> \"endurance\" to have the highest priority. This also allows domain operators\n> to have one or more public nodes, but many private ones with channels open\n> to their public nodes to better manage their risk. For example, the private\n> nodes could be behind a firewall.\n>\n> The result of this is that the user experience is improved, and a side\n> benefit is being able to safely associate a given payment request, and by\n> extension node, with a domain.  Another nontrivial benefit is there will be\n> more channels opened with value on the other side, allowing for receiving\n> funds back from Lightning.\n>\n> There are some possible open questions regarding ensuring a payment\n> request hasn't been spoofed, but if you present the domain to the user,\n> he/she can verify that the wallet is about to open a channel to the domain\n> they expect.  Other issues with this are with DNS hijacking, which to be\n> frank is not an unlikely scenario.  Caution would be necessary, and perhaps\n> cryptographic means of associating nodes and their associated domains would\n> be a requirement for something like this to exist, but the proposed BOLT\n> lays the groundwork for that to happen.\n>\n> --Future payments going through the merchant:\n>\n> This is probably the biggest wrinkle.  The merchant _does_ have the\n> ability to know when a payment transits the channel, thus reducing\n> privacy.  I think the proposed BOLT should only be used to improve user\n> experience, not as a replacement for the decentralized nature of\n> Lightning.  For example, node operators will use autopilot-like\n> functionality for opening channels, BUT they will be able to augment that\n> with looking up common stores and merchant's domain records and open their\n> own channels to them to provide alternate routes to popular anticipated\n> destinations for payments, thus making their own node more valuable and\n> increasing the decentralization of the network.  For example, if you know\n> people are going to be paying Starbucks, you can issue a DNS request of\n> your own, get their current preferred node and connect, and then any node\n> you have channels with will be able to pay Starbucks through you, without\n> having to open a channel of their own.\n>\n> --Merchant crippling payments:\n>\n> With the convention I described above, using channel opens as proof of\n> payment, if Starbucks wants to deny a customer the ability to pay McDonalds\n> (or simply doesn't have the appropriate channels to do so), the user's\n> wallet will simply fall back, look up mcdonalds.com, find the appropriate\n> node and pay the invoice via channel opening.  This also partly addresses\n> point 2, as if a merchant wants to spy on its customers, it must provide\n> routes to its competitors.  It can either spy or deny routes, but not\n> both.  In addition, the onion-like nature of payments means the merchant\n> can't be sure a user paid a competitor, or a node behind them, though some\n> configurations of channels and nodes can definitely reduce privacy quite a\n> bit (example: a tiny etsy shop only has a couple of connections, Evil\n> Starbucks being one of them with the largest channel.  A user paying an\n> amount above the second largest channel to this shop would have to use the\n> merchant's channel, and the merchant would be sure that the payment didn't\n> travel any further from there.)\n>\n> --Network of large hubs:\n> I disagree.  Again, leaning on the ability to open channels with push\n> amounts that have some minor assurances (authority of DNS records) that\n> you're getting the node you intend, I expect routing node operators to\n> preemptively open channels to merchants they expect to receive payments,\n> and they could advertise their own node to do so, along with allowing\n> customers to connect directly to merchants.  The minimum requirement to use\n> this BOLT are the same as running a Lightning node full time, plus\n> ownership of a domain.\n>\n> With that said, I agree regarding the value of random connections in\n> strengthening the network.  Nodes are well-equipped to find inefficiencies\n> and correct them.  The intention of the BOLT is really to improve the\n> on-boarding experience, along with providing an additional means to\n> advertise \"official\" nodes to ease clients, especially mobile ones, onto\n> the network.\n>\n> Your pessimism is warranted and invited.\n>\n> Apologies for the lengthy reply,\n> Tyler\n>\n> On Sun, Apr 8, 2018 at 4:47 PM Christian Decker <\n> decker.christian at gmail.com> wrote:\n>\n>> Hi Tyler,\n>> Hi Robert,\n>>\n>> first of all, welcome to the mailing list, always good to have more\n>> people looking and improving the spec. I quickly read through the spec\n>> and it is very well written, and it looks good.\n>>\n>> On a conceptual level, I do however have some issues with the\n>> proposal. I don't think that the kind of selective attachment to the\n>> node of a merchant is beneficial to neither the node that is opening the\n>> channel, nor for the network as a whole:\n>>\n>>  - For the node opening a channel at the time of a payment is too late,\n>>    it basically means that for the first payment you'd have to wait for\n>>    an on-chain confirmation, even if we use `push_msat` to perform the\n>>    initial payment. This is bad for the user experience. Channels should\n>>    be opened ahead of time so that, when the customer enters a shop,\n>>    everything is already set up. Special cases are always hard to\n>>    communicate (\"you have to wait, but only this time, then in future\n>>    all will be nice and quick\")\n>>  - It also causes all future payments to go through that merchant, which\n>>    can now collate your shopping activity with all of your other\n>>    payments, and create a profile. It's basically the hub-and-spoke\n>>    threat with the added problem of the hub also knowing your identity.\n>>  - The merchant can cripple future payments that he might suspect are\n>>    going to a competitor (Starbucks may attempt to block payments for\n>>    amounts that look like coffee payments and go to their\n>>    competitor). Think net neutrality for Lightning.\n>>  - For the network as a whole this creates a network of large hubs that\n>>    are only weakly interconnected, or not connected at all, unless the\n>>    merchants are \"generous\" enough to maintain connections among each\n>>    other.\n>>\n>> But it's not all bad, I really like the possibility to look up a\n>> merchant's node ID through DNS, so that my wallet can check (indirect)\n>> connectivity to that node and try to optimize their connectivity.\n>>\n>> I think we should encourage people, and implement the clients, to open\n>> random connections, biased towards strenghtening the overall\n>> connectivity. With the gossip protocol we already disseminate enough\n>> information to allow nodes to identify bottlenecks and provide\n>> additional capacity to bridge them.\n>>\n>> Sorry for being so pessimistic, but I think it's important we move away\n>> from people attempting to open targeted channels directly to the\n>> merchants. I still regret publishing the IP address of SLEEPYARK.\n>>\n>> Regards,\n>> Christian\n>>\n>> Tyler H <tyzbit at gmail.com> writes:\n>> > Greetings,\n>> >\n>> > A challenge end-users face is connecting to nodes with enough liquidity\n>> to\n>> > pay every merchant, and failing that, finding the merchant node in a\n>> > reasonably sane way to open a channel to them for payments.\n>> >\n>> > As it is now, people find nodes in other people's visualizers, and pass\n>> > node aliases around via word of mouth which is very prone to inaccuracy\n>> and\n>> > MITM attacks. A current alternative is attempting to make a payment,\n>> > decoding the payment request, finding the node on your graph and\n>> attempting\n>> > to open a channel to the merchant.  This is only possible if the\n>> > destination is advertising addresses.\n>> >\n>> > We (Robert Olsson and I) propose an additional BOLT, tentatively\n>> scheduled\n>> > to be BOLT 12, to allow for operators of domain names to create SRV\n>> records\n>> > for their nodes.  This is separate from BOLT 10's seed functionality as\n>> the\n>> > desired outcome is to get only the nodes associated with a particular\n>> > domain.  This would allow, as an example, users to say to each other\n>> > \"connect to a Blockstream.com node\" and the user can independently look\n>> up\n>> > that domain, find advertised nodes and connect/open channels.\n>> >\n>> > This also improves security from the perspective of nodes masquerading\n>> as\n>> > other nodes, as anyone with a domain can authoritatively list their\n>> nodes.\n>> >\n>> > In addition, domain operators could provide subdomains for their node\n>> > addresses to distinguish between nodes intended for a specific purpose,\n>> > from a human perspective.\n>> >\n>> > Robert Olsson (rompert) and I have created\n>> > https://github.com/lightningnetwork/lightning-rfc/pull/406 as a draft\n>> of\n>> > what the RFC could look like.\n>> >\n>> > Feedback is much appreciated.\n>> >\n>> > Best regards,\n>> > Tyler (tyzbit)\n>> > _______________________________________________\n>> > Lightning-dev mailing list\n>> > Lightning-dev at lists.linuxfoundation.org\n>> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180409/128cc9b9/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-09T23:31:41",
                "message_text_only": "Good morning Tyler,\n\n> A side effect of this BOLT would be, as an example, the mobile Eclair wallet could be updated to accept a domain parameter to specify an initial node to open a user's first channel to rather than only the option to \"autoconnect\" to their hard-coded node, and the wallet could handle resolving and picking a node transparently, thus increasing decentralization of \"fringe\" users such as mobile users and SPV nodes.\n\nConnect is not the same as make a channel with.  Connect simply lets you access gossip information.  So the hard-coded node is not privileged: it simply relays gossip information to the wallet, equivalent to getting an entire map of the network as visible from that node.  The plan is that you connect (but NOT make a channel with) a known fixed node with known high uptime, then the autopilot downloads the entire network map, then connects and creates channels to nodes from the map.\n\nWhile certainly getting a node other than the hardcoded one might let you avoid censorship of nodes by free software developers of the wallet, I am uncertain if getting gossip from a known merchant node is *better* than that.  Certainly you can be sure that the free software developers have at least some nominal checks and balances (and publicly-visible codebase) to prevent censorship, which might not be the case for purely commercial enterprises.\n\n> This also allows domain operators to have one or more public nodes, but many private ones with channels open to their public nodes to better manage their risk. For example, the private nodes could be behind a firewall.\n\nI am not sure how the risk gets managed if the public and private nodes are owned by the same economic entity.\n\nSuppose I am a single economic entity, and I have a public node B and a private node C.  You are the customer A who pays me.\n\nA -> B -> C\n\nNow the channel B->C contains money I own.  Any transfers between B and C are simply money juggling around between two accounts I own.  Thus my earnings are never in the B->C channel, but in the (public!) A->B channel.  So attacking B will still allow hackers to take my earnings, because B->C only contains savings.  Indeed I probably take *more* risk here, since I need to fund B->C rather than, say, keep that money in a cold storage paper in a locked vault buried beneath concrete somewhere in the jungles of Africa (I would like to take the time to note that this is not where I actually keep my cold storage).\n\nWhich is not to say this is completely worthless.  Perhaps B and C are owned by different entities: B takes on risk, and in exchange charges a larger-than-usual feerate for the B->C channel transfers.\n\nAlternatively, perhaps I am a large conglomerate and I have multiple subsidiaries.  I might create a single public access node and several private nodes for each of my subsidiaries, giving one larger-than-normal (>16777215 satoshi) channel for each subsidiary.  I take actual earnings from my single public node, and then each of my subsidiaries implicitly gives a report of how much they earned (I simply look up how much of each private channel belongs belongs to the subsidiary private node; this is equivalent to what the subsidiary earned).\n\nBut I do not think it is possible for a single entity to use this to manage its own risk.  Perhaps indeed \"hubs\" will arise who take on the risk of being a public node with possibly large amounts of money in their channels, and create private channels to their clients, which at least are trustless since the client can drop the channel onchain if they lose trust in the hub (i.e. it is still a better situation than current \"merchant accounts\" offered by exchanges, where you cannot get your money out if the exchange decides you are unworthy).\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180409/28e90e01/attachment.html>"
            },
            {
                "author": "Tyler H",
                "date": "2018-04-10T00:04:37",
                "message_text_only": "> Connect is not the same as make a channel with.  Connect simply lets you\naccess gossip information.  So the hard-coded node is not privileged: it\nsimply relays gossip information to the wallet, equivalent to getting an\nentire map of the network as visible from that node.  The plan is that you\nconnect (but NOT make a channel with) a known fixed node with known high\nuptime, then the autopilot downloads the entire network map, then connects\nand creates channels to nodes from the map.\n\nThis is outside of the spec, isn't it? All implementations should use a\nseed service to bootstrap themselves to the network.\n\n> The plan is that you connect (but NOT make a channel with) a known fixed\nnode with known high uptime, then the autopilot downloads the entire\nnetwork map, then connects and creates channels to nodes from the map.\n\nThis is not the intention.  This BOLT _does not_ replace bootstrapping seed\nfunctionality, now or ever.  A client can supplement her view of the\nnetwork by getting the graph from well-known nodes if she wishes, but no\nmore.  To do otherwise _would_ centralize the network to an uncomfortable\ndegree.  I used \"autoconnect\" because that's the terminology in the mobile\nwallet, but it is misleading.\n\nI hope the additional text I've added in the RFC makes this clear, and I\nregret any confusion.  Most of the functionality enabled by this proposed\nBOLT would be in giving users the ability to more easily open channels to\nthe node they intend to, by giving node operators a way to advertise their\nnodes. I do think perhaps the proposed RFC could be further improved by\nadding a stipulation that autopilot functionality MUST NOT rely on domains\nadvertising nodes, and a user MUST choose to open a channel to a node based\non the domain.\n\n> I am not sure how the risk gets managed if the public and private nodes\nare owned by the same economic entity.\n\nIf the public facing node gets hacked, it cannot draw funds from the\nprivate node, only send them out to the attacker on the network, or close\nthe channels and send the funds + wallet balance to an on-chain address.\nThe \"warm\" funds in your example sit on the C side of the B -> C channel.\n\nRegarding \"hubs\", I think that while the barrier to entry into running\nmultiple nodes isn't zero, it's low enough that even singular moderately\ntechnical node operators might operate with their channels in such a\nconfiguration as this to better reduce their external risk.  A user with a\nlaptop and Docker could run multiple nodes with channels between them, for\ninstance, and the containers could be insulated from each other except for\nLightning protocol traffic.\n\nBest,\nTyler\n\nOn Mon, Apr 9, 2018 at 7:31 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Tyler,\n>\n> > A side effect of this BOLT would be, as an example, the mobile Eclair\n> wallet could be updated to accept a domain parameter to specify an initial\n> node to open a user's first channel to rather than only the option to\n> \"autoconnect\" to their hard-coded node, and the wallet could handle\n> resolving and picking a node transparently, thus increasing\n> decentralization of \"fringe\" users such as mobile users and SPV nodes.\n>\n> Connect is not the same as make a channel with.  Connect simply lets you\n> access gossip information.  So the hard-coded node is not privileged: it\n> simply relays gossip information to the wallet, equivalent to getting an\n> entire map of the network as visible from that node.  The plan is that you\n> connect (but NOT make a channel with) a known fixed node with known high\n> uptime, then the autopilot downloads the entire network map, then connects\n> and creates channels to nodes from the map.\n>\n> While certainly getting a node other than the hardcoded one might let you\n> avoid censorship of nodes by free software developers of the wallet, I am\n> uncertain if getting gossip from a known merchant node is *better* than\n> that.  Certainly you can be sure that the free software developers have at\n> least some nominal checks and balances (and publicly-visible codebase) to\n> prevent censorship, which might not be the case for purely commercial\n> enterprises.\n>\n> > This also allows domain operators to have one or more public nodes, but\n> many private ones with channels open to their public nodes to better manage\n> their risk. For example, the private nodes could be behind a firewall.\n>\n> I am not sure how the risk gets managed if the public and private nodes\n> are owned by the same economic entity.\n>\n> Suppose I am a single economic entity, and I have a public node B and a\n> private node C.  You are the customer A who pays me.\n>\n> A -> B -> C\n>\n> Now the channel B->C contains money I own.  Any transfers between B and C\n> are simply money juggling around between two accounts I own.  Thus my\n> earnings are never in the B->C channel, but in the (public!) A->B channel.\n> So attacking B will still allow hackers to take my earnings, because B->C\n> only contains savings.  Indeed I probably take *more* risk here, since I\n> need to fund B->C rather than, say, keep that money in a cold storage paper\n> in a locked vault buried beneath concrete somewhere in the jungles of\n> Africa (I would like to take the time to note that this is not where I\n> actually keep my cold storage).\n>\n> Which is not to say this is completely worthless.  Perhaps B and C are\n> owned by different entities: B takes on risk, and in exchange charges a\n> larger-than-usual feerate for the B->C channel transfers.\n>\n> Alternatively, perhaps I am a large conglomerate and I have multiple\n> subsidiaries.  I might create a single public access node and several\n> private nodes for each of my subsidiaries, giving one larger-than-normal\n> (>16777215 satoshi) channel for each subsidiary.  I take actual earnings\n> from my single public node, and then each of my subsidiaries implicitly\n> gives a report of how much they earned (I simply look up how much of each\n> private channel belongs belongs to the subsidiary private node; this is\n> equivalent to what the subsidiary earned).\n>\n> But I do not think it is possible for a single entity to use this to\n> manage its own risk.  Perhaps indeed \"hubs\" will arise who take on the risk\n> of being a public node with possibly large amounts of money in their\n> channels, and create private channels to their clients, which at least are\n> trustless since the client can drop the channel onchain if they lose trust\n> in the hub (i.e. it is still a better situation than current \"merchant\n> accounts\" offered by exchanges, where you cannot get your money out if the\n> exchange decides you are unworthy).\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180410/8bda40cb/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-10T00:58:10",
                "message_text_only": "Good morning Tyler,\n\n> This is not the intention.  This BOLT _does not_ replace bootstrapping seed functionality, now or ever.  A client can supplement her view of the network by getting the graph from well-known nodes if she wishes, but no more.  To do otherwise _would_ centralize the network to an uncomfortable degree.  I used \"autoconnect\" because that's the terminology in the mobile wallet, but it is misleading.\n\nAh, I see.  Should have been \"autochannel\" I suppose.\n\n>> I am not sure how the risk gets managed if the public and private nodes are owned by the same economic entity.\n>\n> If the public facing node gets hacked, it cannot draw funds from the private node, only send them out to the attacker on the network, or close the channels and send the funds + wallet balance to an on-chain address.  The \"warm\" funds in your example sit on the C side of the B -> C channel.\n\nLet us break this down.\n\nSuppose we start with this state:\n\nA 2 <-> 0 B 2 <-> 0 C\n\nNow, again, suppose the situation is that B and C are owned by the same economic entity, Tyler & Rompert Enterprises.\n\nSuppose A pays 1 BTC to C:\n\nA 1 <-> 1 B 1 <-> 1 C\n\nNow suppose public node B is hacked.  This means B can close the channels and move the funds onchain to the hacker onchain address.  In that case, a total of 2 BTC can be stolen from node B.\n\nNow suppose Tyler & Rompert Enterprises decides not to actually have a private node C.  We start with this state:\n\nA 2 <-> 0 B\n\nSuppose A pays 1 BTC to B:\n\nA 1 <-> 1 B\n\nNow suppose public node B is hacked. This means B can close the channels and move the funds onchain to the hacker onchain address. In that case, a total of 1 BTC can be stolen from node B.  Compare this to the previous situation, where 2 BTC can be stolen from node B, *precisely because of the existence of B<->C*.\n\nSo it is strictly better it seems, from a risk perspective, to just use a public node directly, than running a public node and one or more private nodes.  You lose less this way than also funding a channel from your public to your private node.\n\nEither that, or you contract to an external party who takes on the risk of running a public node, most likely in exchange for much higher feerates to your private node.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180409/c471c6ac/attachment.html>"
            },
            {
                "author": "Tyler H",
                "date": "2018-04-10T01:32:17",
                "message_text_only": "I understand now, I hadn't fully considered the necessary channels for such\na configuration, though there is still the value of domain owners being\nable to advertise preferred nodes to connect to in order to pay them\nefficiently.  The external party idea is interesting, but I'm fearful that\nit can't be done in a way that retains a bare minimum of privacy.\n\nThanks,\nTyler\nOn Mon, Apr 9, 2018 at 8:58 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Tyler,\n>\n> This is not the intention.  This BOLT _does not_ replace bootstrapping\n> seed functionality, now or ever.  A client can supplement her view of the\n> network by getting the graph from well-known nodes if she wishes, but no\n> more.  To do otherwise _would_ centralize the network to an uncomfortable\n> degree.  I used \"autoconnect\" because that's the terminology in the mobile\n> wallet, but it is misleading.\n>\n>\n> Ah, I see.  Should have been \"autochannel\" I suppose.\n>\n> > I am not sure how the risk gets managed if the public and private nodes\n> are owned by the same economic entity.\n>\n> If the public facing node gets hacked, it cannot draw funds from the\n> private node, only send them out to the attacker on the network, or close\n> the channels and send the funds + wallet balance to an on-chain address.\n> The \"warm\" funds in your example sit on the C side of the B -> C channel.\n>\n>\n> Let us break this down.\n>\n> Suppose we start with this state:\n>\n> A 2 <-> 0 B 2 <-> 0 C\n>\n> Now, again, suppose the situation is that B and C are owned by the same\n> economic entity, Tyler & Rompert Enterprises.\n>\n> Suppose A pays 1 BTC to C:\n>\n> A 1 <-> 1 B 1 <-> 1 C\n>\n> Now suppose public node B is hacked.  This means B can close the channels\n> and move the funds onchain to the hacker onchain address.  In that case, a\n> total of 2 BTC can be stolen from node B.\n>\n> Now suppose Tyler & Rompert Enterprises decides not to actually have a\n> private node C.  We start with this state:\n>\n> A 2 <-> 0 B\n>\n> Suppose A pays 1 BTC to B:\n>\n> A 1 <-> 1 B\n>\n> Now suppose public node B is hacked. This means B can close the channels\n> and move the funds onchain to the hacker onchain address. In that case, a\n> total of 1 BTC can be stolen from node B.  Compare this to the previous\n> situation, where 2 BTC can be stolen from node B, *precisely because of the\n> existence of B<->C*.\n>\n> So it is strictly better it seems, from a risk perspective, to just use a\n> public node directly, than running a public node and one or more private\n> nodes.  You lose less this way than also funding a channel from your public\n> to your private node.\n>\n> Either that, or you contract to an external party who takes on the risk of\n> running a public node, most likely in exchange for much higher feerates to\n> your private node.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180410/9d723a63/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-10T09:23:43",
                "message_text_only": "Good morning Tyler,\n\n> The external party idea is interesting, but I'm fearful that it can't be done in a way that retains a bare minimum of privacy.\n\nNo, of course not.  \"Private\" channels are privacy sieves and should not be used by privacy-conscious entities.  Since the channel is never published the \"public\" side knows that any economic activity going through the \"private\" channel must terminate on the other side.\n\nPerhaps better terms would be \"published\" and \"unpublished\" channels.  We should really warn people that use of unpublished channels leaks your economic information, whereas use of published channels give the plausible deniability that it could be somebody else using that channel, not you.\n\nYou could try contracting out to multiple external parties, so that at least no single entity knows *all* your economic activity.  You still leak all your economic activity, you are simply hoping that those external parties do not pool their information together to get a complete profile of you.  Seems like a quixotic endeavor.  You may be better off using your own public node.\n\nMultiple public nodes may be useful for load distribution.  You could also try implementation diversity, using different secure operating system, hardware, and LN node software for each node, in the hope that 0days have lower probability of affecting them all simultaneously.\n\nYou could have multiple public nodes A <-> B with a published channel between them that is larger than normally allowed; many of the issues with large channels disappear when you know that you can trust each other. and if you really own both A and B, then you know A can trust B and vice versa.  The purpose is load distribution: you could source half your invoices with one and half your invoices with the other, and the channel between them allows customers to use e.g. a channel to A to pay an invoice made by B when all other published channels to B are depleted.  But in terms of hackability, you should really not make A trust B and vice versa, though.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180410/5ed0d7c2/attachment-0001.html>"
            },
            {
                "author": "Tyler H",
                "date": "2018-04-10T18:34:18",
                "message_text_only": "Christian, ZmnSCPxj et al,\n\nYour concerns have been taken seriously, and while this might provide some\nuseful features with regard to opening appropriate channels (and I guess\ncan be implemented outside of spec, if an implementation so wishes), after\nconsideration and some very useful feedback from Olaoluwa Osuntokun on the\nLND slack, I've decided to pull my support for implementing this specific\nproposal as part of this spec.\n\nTo summarize the primary issue with this proposed BOLT:\nDNS in its current form cannot be trusted as part of the Lightning spec,\nplain and simple.\n\nWhile I've rescinded my support, I don't discourage thoughtful\nimplementation of functionality like this, but I do caution any\nimplementation to properly inform the user as to the inherent risk in\ntrusting DNS, and only use DNS records as a way to increase confidence, not\nmake guarantees, that a node is associated to the domain it says it is.\n\nI will continue to approach the problem of securely advertising\nhuman-understandable node names, and I hope someday soon I will have a\nsolution Lightning can use that retains the open, decentralized properties\nof the technology and the underlying blockchains.\n\nI leave this proposal in Robert's hands to further defend if he wishes, and\nI would discourage future proposals largely similar to this but on other\nauthenticated technologies (for example, advertising node information via\nforum posts).  Any information that doesn't come from the network itself\ncannot be backed by cryptographic guarantees.\n\nOther discussions regarding public vs private nodes and channel structures\nare encouraged.\n\nBest regards,\nTyler\n\nOn Tue, Apr 10, 2018 at 5:23 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Tyler,\n>\n> The external party idea is interesting, but I'm fearful that it can't be\n> done in a way that retains a bare minimum of privacy.\n>\n>\n> No, of course not.  \"Private\" channels are privacy sieves and should not\n> be used by privacy-conscious entities.  Since the channel is never\n> published the \"public\" side knows that any economic activity going through\n> the \"private\" channel must terminate on the other side.\n>\n> Perhaps better terms would be \"published\" and \"unpublished\" channels.  We\n> should really warn people that use of unpublished channels leaks your\n> economic information, whereas use of published channels give the plausible\n> deniability that it could be somebody else using that channel, not you.\n>\n> You could try contracting out to multiple external parties, so that at\n> least no single entity knows *all* your economic activity.  You still leak\n> all your economic activity, you are simply hoping that those external\n> parties do not pool their information together to get a complete profile of\n> you.  Seems like a quixotic endeavor.  You may be better off using your own\n> public node.\n>\n> Multiple public nodes may be useful for load distribution.  You could also\n> try implementation diversity, using different secure operating system,\n> hardware, and LN node software for each node, in the hope that 0days have\n> lower probability of affecting them all simultaneously.\n>\n> You could have multiple public nodes A <-> B with a published channel\n> between them that is larger than normally allowed; many of the issues with\n> large channels disappear when you know that you can trust each other. and\n> if you really own both A and B, then you know A can trust B and vice\n> versa.  The purpose is load distribution: you could source half your\n> invoices with one and half your invoices with the other, and the channel\n> between them allows customers to use e.g. a channel to A to pay an invoice\n> made by B when all other published channels to B are depleted.  But in\n> terms of hackability, you should really not make A trust B and vice versa,\n> though.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180410/2817880e/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-11T07:28:19",
                "message_text_only": "Good morning Tyler,\n\n> I will continue to approach the problem of securely advertising human-understandable node names, and I hope someday soon I will have a solution Lightning can use that retains the open, decentralized properties of the technology and the underlying blockchains.\n\nI believe this faces the issue of Zooko's Triangle?  Decentralized, Secure, Human-meaningful: pick any two.\n\nNode pubkeys are Decentralized and Secure (good luck memorizing store.blockstream.com node pubkey if you are merely human).\n\nNode aliases are Decentralized and Human-meaningful (nothing prevents me from naming my node SLEEPYARK, though).\n\nDNS is Secure and Human-meaningful (DNS registration is centralized around ICANN).\n\nMaybe a DNS la\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180411/4dacef24/attachment.html>"
            },
            {
                "author": "Tyler H",
                "date": "2018-04-11T15:28:28",
                "message_text_only": "ZmnSCPxj,\n\nYes, I understand I essentially I'd have to solve that trilemma in order to\nimplement something suitable for Lightning.\n\nThat is why I have pulled my support for my proposal, and I do insist that\nthe proposal AT MOST be a convention, but not a standard, and nodes SHOULD\nNOT trust DNS.\n\nThanks,\nTyler\n\nOn Wed, Apr 11, 2018 at 3:28 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Tyler,\n>\n>\n> I will continue to approach the problem of securely advertising\n> human-understandable node names, and I hope someday soon I will have a\n> solution Lightning can use that retains the open, decentralized properties\n> of the technology and the underlying blockchains.\n>\n>\n> I believe this faces the issue of Zooko's Triangle?  Decentralized,\n> Secure, Human-meaningful: pick any two.\n>\n> Node pubkeys are Decentralized and Secure (good luck memorizing\n> store.blockstream.com node pubkey if you are merely human).\n>\n> Node aliases are Decentralized and Human-meaningful (nothing prevents me\n> from naming my node SLEEPYARK, though).\n>\n> DNS is Secure and Human-meaningful (DNS registration is centralized around\n> ICANN).\n>\n> Maybe a DNS la\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180411/ca4ea811/attachment.html>"
            },
            {
                "author": "Corn\u00e9 Plooy",
                "date": "2018-04-16T10:19:38",
                "message_text_only": "Op 10-04-18 om 20:34 schreef Tyler H:\n>\n> I will continue to approach the problem of securely advertising\n> human-understandable node names, and I hope someday soon I will have a\n> solution Lightning can use that retains the open, decentralized\n> properties of the technology and the underlying blockchains.\n>\nTwo of my favorite approaches:\n* Namecoin-style: Register your name first-come-first-serve on a block\nchain.\n\u00a0 -> Provides no protection against name squatting and attackers\nregistering similarly-looking names.\n* Web of Trust: I tell you I believe this pubkey really corresponds to\nthis name; someone else might tell you something else. DNS is\nessentially a special case of this, where the WoT has a centralized star\nshape. TLS is another case, where there is dozens of signing parties\n(CAs), and everyone typically gets their keys signed by only one of\nthem, so anyone verifying keys has to trust all these CAs. More\ngenerally, a WoT can have any shape though.\n\u00a0 -> Provides little to no protection against trusted parties lying to you.\n\nCJP"
            },
            {
                "author": "Tyler H",
                "date": "2018-04-19T20:15:11",
                "message_text_only": "I'm working on a proposal called Numerifides.  Full working document here:\nhttps://github.com/tyzbit/numerifides\n\nHighlights:\n- Committed directly to Bitcoin blockchain\n- Seems to solve Zooko's triangle (Decentralized, secure and human\nmeaningful)\n- Can use already existing SPV infrastructure for lookups (like DNS\nrequests).\n- Doesn't have the squatting problems of Namecoin (squatting a name costs\nyou locked up Bitcoin funds)\n- Consensus revocation of names (Someone squatting google.com but the\ncommunity knows that's a lie? It's possible to \"unseat\" that registration)\n- If you registered a name no one cares about (oeJFwlkS) no one will care\nto try to unseat your name, except to steal your funds you locked up (which\nneed to just be high enough so as to not be dust)\n- Usable for any name->data association such as Lightning nodes, DNS,\nCertificate Authorities, decentralized identities etc\n\nAlready I know some concerns are in the details of implementation like the\nhash function used for the transaction puzzle, censorship resistance\n(though the market effect does play itself well here) and privacy concerns\n(though the committed data can be encrypted or hashed before being stored\nas I do envision a \"catchall\" unadvertised datatype where anyone can commit\nanything for any purpose such as for document existence or even committing\nan encrypted key to some piece of data).  I also don't like the idea of\npeople committing IP addresses of their websites to the blockchain for all\ntime, but perhaps a 2nd-layer \"nameserver\"-like configuration can be found\nfor less permanent, more ephemeral data like DNS.\n\nI'd love any feedback the list has to offer.\n\nOn Mon, Apr 16, 2018 at 6:19 AM Corn\u00e9 Plooy via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n>\n> Op 10-04-18 om 20:34 schreef Tyler H:\n> >\n> > I will continue to approach the problem of securely advertising\n> > human-understandable node names, and I hope someday soon I will have a\n> > solution Lightning can use that retains the open, decentralized\n> > properties of the technology and the underlying blockchains.\n> >\n> Two of my favorite approaches:\n> * Namecoin-style: Register your name first-come-first-serve on a block\n> chain.\n>   -> Provides no protection against name squatting and attackers\n> registering similarly-looking names.\n> * Web of Trust: I tell you I believe this pubkey really corresponds to\n> this name; someone else might tell you something else. DNS is\n> essentially a special case of this, where the WoT has a centralized star\n> shape. TLS is another case, where there is dozens of signing parties\n> (CAs), and everyone typically gets their keys signed by only one of\n> them, so anyone verifying keys has to trust all these CAs. More\n> generally, a WoT can have any shape though.\n>   -> Provides little to no protection against trusted parties lying to you.\n>\n> CJP\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180419/48d4b74b/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-20T03:43:30",
                "message_text_only": "Good morning Tyler,\n\nOffhand, I am uncertain the first script given in \"Technical Proposal\" works as a \"check proof-of-work\" script.\n\nAre the \"[]\" comments? Or are they pushes of actual data embedded in the SCRIPT?  It seems to be comments...?\n\nOP_CheckLockTimeVerify is absolute time, not relative time.  Why blockheight 52560 in particular?  I believe this was in 2010?  Or are you thinking OP_CHECKSEQUENCEVERIFY which imposes a relative timelock?\n\nLocking funds for a time may be enough without pulling in proof-of-work, especially since the Bitcoin blockchain itself is already proof-of-work.  See my half-baked ideas for proof-of-mainstake, where locking funds in the mainchain is used as voting rights for correctness of the sidechain, avoiding normal proof-of-stake problems since the stake that backs the chain is on a separate proof-of-work chain.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180419/d006b840/attachment.html>"
            },
            {
                "author": "Tyler H",
                "date": "2018-04-20T04:03:55",
                "message_text_only": "\"[]\" are placeholders for the appropriate data. I believed that CLTV less\nthan the Unix epoch would be for a relative time lock but admittedly I've\nnever written Bitcoin script so CSV definitely could be the appropriate\nopcode to be use here for a relative time lock.\n\n52560 was meant to be a year in block time, coinciding with the duration of\nthe name registration.\n\nI'll look into your proof of mainstake as that does sound similar to what\nI'm working on here.\n\nThanks,\nTyler\nOn Thu, Apr 19, 2018, 23:43 ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Tyler,\n>\n> Offhand, I am uncertain the first script given in \"Technical Proposal\"\n> works as a \"check proof-of-work\" script.\n>\n> Are the \"[]\" comments? Or are they pushes of actual data embedded in the\n> SCRIPT?  It seems to be comments...?\n>\n> OP_CheckLockTimeVerify is absolute time, not relative time.  Why\n> blockheight 52560 in particular?  I believe this was in 2010?  Or are you\n> thinking OP_CHECKSEQUENCEVERIFY which imposes a relative timelock?\n>\n> Locking funds for a time may be enough without pulling in proof-of-work,\n> especially since the Bitcoin blockchain itself is already proof-of-work.\n> See my half-baked ideas for proof-of-mainstake, where locking funds in the\n> mainchain is used as voting rights for correctness of the sidechain,\n> avoiding normal proof-of-stake problems since the stake that backs the\n> chain is on a separate proof-of-work chain.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180420/3b929dfe/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-20T04:30:08",
                "message_text_only": "Good morning,\n\nCLTV < unix epoch is for absolute lock time measured sanely in blocks, while > unix epoch is for absolute lock time measured in that arbitrary human-preferred unit called \"seconds\".  I believe you mean CSV, as that is for relative lock time measured in blocks (but note that it has a special encoding, so you might be able to get 52560 precisely).\n\nThe scheme as-is puts a lot of non-financial data onchain, which will make our bitcoin-dev colleagues cry.  We can consider something similar to pay-to-contract instead, which is similar to Taproot (indeed pay-to-contract is the basis of Taproot)\n\nTo create a Numerifides command, a user does the below:\n\n1.  Generates a secret private key p = random() and the public key P = p * G.\n2.  Encodes the Numerifides command (it could simply be a mapping \"google.com = 127.0.0.1\") as \"command\".\n3.  Computes the pay-to-contract public key: C = P + h(P || command) * G.  This has corresponding private key c = p + h(P || command) that only the user knows.\n4.  Generates a P2WSH to the script: <52560 blocks> OP_CHECKSEQUENCEVERIFY OP_DROP <C> OP_CHECKSIG\n5.  Pays to that P2WSH on the Bitcoin network.\n6.  Broadcasts command, P, and the txid+outnum of the UTXO that pays to the P2WSH above, to the Numerifides network (not the Bitcoin network, Bitcoin cannot understand it).\n\nNumerifides network nodes, on receiving a command+P+outpoint, then verifies it by confirming that it can get C = P + h(P || command) * G, and that the outpoint is unspent, and pays to a P2WSH matching the above script template with the <C> replaced with the computed C.\n\nWhen the command expires (i.e. the lock time is completed) then the user can reclaim its locked coins from c = p + h(P || command), meaning it only has to memorize p and command.\n\nUTXOs that pay to the above construction that have expired the CSV will have the corresponding command deleted from your Numerifides database.\n\nIf two commands conflict, then we simply prefer the one with higher locked amount (if equal, I do not know, your choice, maybe prefer the earlier one).  And so on.  What those commands are can be specified as you wish in your Numerifides proposal.\n\nIf you insist on bringing in proof-of-work, the proof-of-work can be embedded in the \"command\" rather than on the Bitcoin blockchain.  All that is published on the Bitcoin blockchain will be the point <C> (33 bytes) and a signature using c (64 bytes) plus a relatively small script, keeping bitcoin-dev happy.\n\nThe same scheme can be used for practically any kind of asset I believe, not just names.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180420/35ebca45/attachment.html>"
            },
            {
                "author": "Tyler H",
                "date": "2018-04-20T05:10:10",
                "message_text_only": "I like the efficiency your method brings and I'm also not that enthused\nabout bloating the blockchain with \"non-financial data\", however I do think\nthere's value in having the data live in the base chain, both from\naccessibility and censorship resistance of the data to less additional\n\"networks\". Already today any user that includes a commensurate miner's fee\ncan use the pushdata opcodes and add whatever data they want to the\nblockchain.\n\nOne thing that the design requires is a separate method of communicating\nbindings and not being censored - if it were onchain, a DNS lookup could\nsimply be no more than a light client requesting the relevant block.\n\nI think anything that gets seriously far along will need to have some data\ncrunched and if only 100 users per day would fill up blocks then of course\nconstraints would necessitate other avenues.\n\nThanks,\nTyler\n\nOn Fri, Apr 20, 2018, 00:30 ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning,\n>\n> CLTV < unix epoch is for absolute lock time measured sanely in blocks,\n> while > unix epoch is for absolute lock time measured in that arbitrary\n> human-preferred unit called \"seconds\".  I believe you mean CSV, as that is\n> for relative lock time measured in blocks (but note that it has a special\n> encoding, so you might be able to get 52560 precisely).\n>\n> The scheme as-is puts a lot of non-financial data onchain, which will make\n> our bitcoin-dev colleagues cry.  We can consider something similar to\n> pay-to-contract instead, which is similar to Taproot (indeed\n> pay-to-contract is the basis of Taproot)\n>\n> To create a Numerifides command, a user does the below:\n>\n> 1.  Generates a secret private key p = random() and the public key P = p *\n> G.\n> 2.  Encodes the Numerifides command (it could simply be a mapping \"\n> google.com = 127.0.0.1\") as \"command\".\n> 3.  Computes the pay-to-contract public key: C = P + h(P || command) * G.\n> This has corresponding private key c = p + h(P || command) that only the\n> user knows.\n> 4.  Generates a P2WSH to the script: <52560 blocks> OP_CHECKSEQUENCEVERIFY\n> OP_DROP <C> OP_CHECKSIG\n> 5.  Pays to that P2WSH on the Bitcoin network.\n> 6.  Broadcasts command, P, and the txid+outnum of the UTXO that pays to\n> the P2WSH above, to the Numerifides network (not the Bitcoin network,\n> Bitcoin cannot understand it).\n>\n> Numerifides network nodes, on receiving a command+P+outpoint, then\n> verifies it by confirming that it can get C = P + h(P || command) * G, and\n> that the outpoint is unspent, and pays to a P2WSH matching the above script\n> template with the <C> replaced with the computed C.\n>\n> When the command expires (i.e. the lock time is completed) then the user\n> can reclaim its locked coins from c = p + h(P || command), meaning it only\n> has to memorize p and command.\n>\n> UTXOs that pay to the above construction that have expired the CSV will\n> have the corresponding command deleted from your Numerifides database.\n>\n> If two commands conflict, then we simply prefer the one with higher locked\n> amount (if equal, I do not know, your choice, maybe prefer the earlier\n> one).  And so on.  What those commands are can be specified as you wish in\n> your Numerifides proposal.\n>\n> If you insist on bringing in proof-of-work, the proof-of-work can be\n> embedded in the \"command\" rather than on the Bitcoin blockchain.  All that\n> is published on the Bitcoin blockchain will be the point <C> (33 bytes) and\n> a signature using c (64 bytes) plus a relatively small script, keeping\n> bitcoin-dev happy.\n>\n> The same scheme can be used for practically any kind of asset I believe,\n> not just names.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180420/f6e0172b/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-20T05:46:12",
                "message_text_only": "Good morning Tyler,\n\n> I like the efficiency your method brings and I'm also not that enthused about bloating the blockchain with \"non-financial data\", however I do think there's value in having the data live in the base chain, both from accessibility and censorship resistance of the data to less additional \"networks\".\n\nGossiped data is almost impossible to censor (ask Streisand how well that works to censor her Malibu home).  However, mere gossip is often unverifiable.\n\nWhat we do here is twofold:\n\n1.  We use the blockchain layer for verification.  Commands \"google.com=127.0.0.1\" are backed by actual Bitcoin satoshi being locked, sacrificing opportunity costs, making them costly and verifiably costly, unlike gossip which is unverifiable.\n2.  We use the gossip overlay for censorship resistance.  Once a command has been confirmed on the Bitcoin blockchain, we can share that command to our peers on the gossip overlay, and unless all our peers are colluding, it is likely that a command gets out somehow.\n\nThis design also uses P2WSH, so 51% miners, at least, cannot censor Numerifides commands: all they see is a hash of something which could be a LN fundchannel or a M-of-N SegWit or etc etc. We wait for the transaction to confirm (which starts the CSV relative-locktime countdown anyway), after which the miner cannot \"take back\" its confirmation of your Numerifide command without losing costly work, and only THEN reveal the P2WSH preimage on the Numerifides gossip overlay network.\n\nThe gossip overlay then provides censorship resistance on top of that, revealing the preimage of the P2WSH (AFTER it has been confirmed onchain) and revealing your Numerifide command.  It is unlikely that anyone can stop the gossip overlay unless they control your entire Internet connection, in which case you have more serious problems and might not even be able to have a current view of the Bitcoin blockchain anyway.\n\n> Already today any user that includes a commensurate miner's fee can use the pushdata opcodes and add whatever data they want to the blockchain.\n\nGranted.  It still makes bitcoin-dev cry when this is done.  And in any case, reducing the blockchain footprint has real benefits of reducing the amount that gets given to miners and increasing what can be put into command bids anyway.\n\n> One thing that the design requires is a separate method of communicating bindings and not being censored - if it were onchain, a DNS lookup could simply be no more than a light client requesting the relevant block.\n\nPossibly.  Note however that the \"publish everything onchain\" design requires cooperation of a Bitcoin miner, since it seems you are using scriptpubkey rather than P2WSH.  In particular the IsStandard() check will mean your transaction will not get transmitted on the normal Bitcoin peer network and you will need direct connection and cooperation of a Bitcoin miner, to get your non-standard script in a scriptpubkey.\n\nIf you intend to use P2SH or P2WSH, then you will need a gossip layer to reveal the script preimage anyway, so you might as well use the more efficient P2WSH-based construction I showed.\n\n> I think anything that gets seriously far along will need to have some data crunched and if only 100 users per day would fill up blocks then of course constraints would necessitate other avenues.\n\nYes.  Knowing that, we might as well start efficient.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180420/4a7db250/attachment.html>"
            },
            {
                "author": "Tyler H",
                "date": "2018-04-20T09:58:35",
                "message_text_only": "Great points.  IsStandard() is something I hadn't considered yet, but I\nthink miners are incentivized to want Numerifides transactions as a\nregistration will need a solid miners fee, and \"revoked\" names will cause\nescalating fee wars that the miners can just soak up.  I think a standard\nthat uses mappings in a sane way (and maybe pushdata2/4 won't be allowed if\n255 bytes are enough) would be allowable given the benefit it brings of\ntruly decentralized, human-readable trust.\n\nI also wonder what the economic incentive might be for every node to store\nand gossip the Numerifides mappings - sure they want everyone to find them,\nbut who cares about other people? It could be a situation like the current\nBitcoin mempool where it's saved on a best-effort basis and is\nsemi-transient, but that makes troubleshooting lookups problematic.\n\nAlso, I know this is only tangentially related to Lightning so if this is a\ndiscussion best left off the mailing list, just let me know.\n\nThanks,\nTyler\n\nOn Fri, Apr 20, 2018 at 1:46 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Tyler,\n>\n> I like the efficiency your method brings and I'm also not that enthused\n> about bloating the blockchain with \"non-financial data\", however I do think\n> there's value in having the data live in the base chain, both from\n> accessibility and censorship resistance of the data to less additional\n> \"networks\".\n>\n>\n> Gossiped data is almost impossible to censor (ask Streisand how well that\n> works to censor her Malibu home).  However, mere gossip is often\n> unverifiable.\n>\n> What we do here is twofold:\n>\n> 1.  We use the blockchain layer for verification.  Commands \"google.com=127.0.0.1\"\n> are backed by actual Bitcoin satoshi being locked, sacrificing opportunity\n> costs, making them costly and verifiably costly, unlike gossip which is\n> unverifiable.\n> 2.  We use the gossip overlay for censorship resistance.  Once a command\n> has been confirmed on the Bitcoin blockchain, we can share that command to\n> our peers on the gossip overlay, and unless all our peers are colluding, it\n> is likely that a command gets out somehow.\n>\n> This design also uses P2WSH, so 51% miners, at least, cannot censor\n> Numerifides commands: all they see is a hash of something which could be a\n> LN fundchannel or a M-of-N SegWit or etc etc. We wait for the transaction\n> to confirm (which starts the CSV relative-locktime countdown anyway), after\n> which the miner cannot \"take back\" its confirmation of your Numerifide\n> command without losing costly work, and only THEN reveal the P2WSH preimage\n> on the Numerifides gossip overlay network.\n>\n> The gossip overlay then provides censorship resistance on top of that,\n> revealing the preimage of the P2WSH (AFTER it has been confirmed onchain)\n> and revealing your Numerifide command.  It is unlikely that anyone can stop\n> the gossip overlay unless they control your entire Internet connection, in\n> which case you have more serious problems and might not even be able to\n> have a current view of the Bitcoin blockchain anyway.\n>\n> Already today any user that includes a commensurate miner's fee can use\n> the pushdata opcodes and add whatever data they want to the blockchain.\n>\n>\n> Granted.  It still makes bitcoin-dev cry when this is done.  And in any\n> case, reducing the blockchain footprint has real benefits of reducing the\n> amount that gets given to miners and increasing what can be put into\n> command bids anyway.\n>\n>\n> One thing that the design requires is a separate method of communicating\n> bindings and not being censored - if it were onchain, a DNS lookup could\n> simply be no more than a light client requesting the relevant block.\n>\n>\n> Possibly.  Note however that the \"publish everything onchain\" design\n> requires cooperation of a Bitcoin miner, since it seems you are using\n> scriptpubkey rather than P2WSH.  In particular the IsStandard() check will\n> mean your transaction will not get transmitted on the normal Bitcoin peer\n> network and you will need direct connection and cooperation of a Bitcoin\n> miner, to get your non-standard script in a scriptpubkey.\n>\n> If you intend to use P2SH or P2WSH, then you will need a gossip layer to\n> reveal the script preimage anyway, so you might as well use the more\n> efficient P2WSH-based construction I showed.\n>\n> I think anything that gets seriously far along will need to have some data\n> crunched and if only 100 users per day would fill up blocks then of course\n> constraints would necessitate other avenues.\n>\n>\n> Yes.  Knowing that, we might as well start efficient.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180420/579e6c65/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-20T13:42:51",
                "message_text_only": "Good morning Tyler,\n\n> Great points.  IsStandard() is something I hadn't considered yet, but I think miners are incentivized to want Numerifides transactions as a registration will need a solid miners fee, and \"revoked\" names will cause escalating fee wars that the miners can just soak up.  I think a standard that uses mappings in a sane way (and maybe pushdata2/4 won't be allowed if 255 bytes are enough) would be allowable given the benefit it brings of truly decentralized, human-readable trust.\n\nGranted, but using scriptpubkey will require changes to miner software, and would require large number of mining pools to support it.  And large numbers of mining pools will not support it significantly unless you have already demonstrated its usefulness, so you may find bootstrapping less easy.\n\nOne thing that can be done would be to publish the command in the witness vector and use an intermediate transaction.  This at least lets you use the cheaper witness space.\n\n1.  First pay to a P2WSH OP_HASH160 <h(blocks || nextpubkey || command)> OP_EQUALVERIFY <pubkey> OP_CHECKSIG\n2.  Spend the above P2WSH, which requires you to provide the witness data <signature> <blocks || nextpubkey || command>\n3.  The spend should pay out a value to the P2WSH <blocks> OP_CHECKSEQUENCEVERIFY OP_DROP <nextpubkey> OP_CHECKSIG\n\nThis puts the extra data into the witness area, which is cheaper, and also utilizes P2WSH so that you do not have to convince miners to use Numerifides.  bitcoin-dev will still cry because it puts non-financial data onchain, but at least fewer tears will be shed since it is the witness area.\n\n> I also wonder what the economic incentive might be for every node to store and gossip the Numerifides mappings - sure they want everyone to find them, but who cares about other people? It could be a situation like the current Bitcoin mempool where it's saved on a best-effort basis and is semi-transient, but that makes troubleshooting lookups problematic.\n\nYou have an economic incentive to *store* all the Numerifides mappings -- if you do not, somebody could fool you with a revoked mapping, or you might not be able to locate a mapping you need to use.\n\nIncentive to then *share* mappings could be that peers would try a \"tit for tat\" strategy: they will give you one (or a few) mappings \"for free\", but if you do not give any back, they will stop sharing with you.  So you are incentivized to contact multiple peers and try to trade information from one with information from another.  But that requires a durable identity from you, which may be undesirable.\n\nOne could also wonder what economic incentive might be to *seed* torrents as opposed to leech them only, other than a \"high-level\" consideration that if nobody seeds, nobody can leech.\n\n> Also, I know this is only tangentially related to Lightning so if this is a discussion best left off the mailing list, just let me know.\n\nbitcoin-dev will probably have more ideas and might be able to point you at some prior art for similar systems.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180420/c079d13f/attachment.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-04-10T13:27:19",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n>> This also allows domain operators to have one or more public nodes,\n>> but many private ones with channels open to their public nodes to\n>> better manage their risk. For example, the private nodes could be\n>> behind a firewall.\n>\n> I am not sure how the risk gets managed if the public and private\n> nodes are owned by the same economic entity.\n>\n> Suppose I am a single economic entity, and I have a public node B and\n> a private node C.  You are the customer A who pays me.\n>\n> A -> B -> C\n>\n> Now the channel B->C contains money I own.  Any transfers between B\n> and C are simply money juggling around between two accounts I own.\n> Thus my earnings are never in the B->C channel, but in the (public!)\n> A->B channel.  So attacking B will still allow hackers to take my\n> earnings, because B->C only contains savings.  Indeed I probably take\n> *more* risk here, since I need to fund B->C rather than, say, keep\n> that money in a cold storage paper in a locked vault buried beneath\n> concrete somewhere in the jungles of Africa (I would like to take the\n> time to note that this is not where I actually keep my cold storage).\n>\n> Which is not to say this is completely worthless.  Perhaps B and C are\n> owned by different entities: B takes on risk, and in exchange charges\n> a larger-than-usual feerate for the B->C channel transfers.\n\nExcellent point, but I think there are more advantages to having a node\nseparate from the gateway as source of truth. Let's assume the gateway\nnode, exposed directly to the open network is compromised, that still\nmeans that an eventual store independently verifies incoming payments,\ni.e., it is not possible for the compromised node to escalate to the\nstore, without also compromising the hidden nodes. If however the\ngateway node provides the ground truth for the store, then the attacker\ncould just mark all of the attacker's invoices as complete and thus\nsteal goods from the shop. The attacker is limited to drain the B -> C\nchannel, to steal goods from the store, until it gets rebalanced.\n\nCheers,\nChristian"
            },
            {
                "author": "Christian Decker",
                "date": "2018-04-09T16:26:19",
                "message_text_only": "Tyler,\n\nthanks for the detailed feedback, I'll try to address some of the issues\ninline:\n\nTyler H <tyzbit at gmail.com> writes:\n> --Regarding looking up nodes at the time of payments:\n>\n> In the future, nodes could negotiate a channel open with a push amount and\n> provide the TXID or payment hash as proof of their payment of the invoice.\n> This wouldn't even require the channel to be usable, and merchants could\n> decide to accept 1 (or even 0) confirmations of this transaction based on\n> their acceptable level of risk, considering the properties of the channel\n> (capacity, local balance etc).  So in that use case, this would be a rough\n> process of the interaction:\n\nThere is very little difference between pushing with the channel\ncreation and just doing an immediate update even though the channel\nisn't confirmed yet. To be honest I think the `push_msat` feature is the\nclassical case of optimizing too early.\n\nBut the end result is still that the merchant either takes a hit in the\ntrustworthiness of the incoming payment, or the buyer is going to have a\nbad time waiting at the checkout until the channel confirms. \n\n> User tries to pay lightning invoice, and it fails.  The user's wallet\n> offers to pay via channel opening.  The user accepts.  The wallet reads the\n> invoice for a \"domain\" field, or perhaps if the wallet happens to be a\n> browser, it does a SRV lookup against the current domain serving the\n> invoice.  The wallet looks up the domain records, and verifies the\n> destination node is present.  If so, the wallet picks the correct node\n> based on the records present, and opens a channel with a push amount to\n> it.  The destination node sees this and via as some yet undetermined\n> method, associates it to that payment invoice and chooses to mark it as\n> \"paid\" or \"pending X confirmations\" according to whatever criteria the node\n> operator wishes to use.\n\nI was going to comment that, since we already have an invoice detailing\nthe destination, the indirection through the DNS system to find the\ndesired connection point was useless, but your example with Starblocks\nwhere connections are accepted by one node, and payments by another\nconvinced me that this is indeed a useful feature. A feature however\nthat could be solved just as well by including an `r` tag in the invoice\nitself. In this case you can either use the gossip protocol or the BOLT\n10 DNS lookup system to locate the entry point into the merchant's\nnetwork. I don't think that a direct connection to the merchant in case\nof it being unreachable is a good idea, because it creates latent\nhubs. But I see the slight advantage of reducing the failure probability\nw.r.t. to opening a channel with a random node.\n\n> In a simple example, you could list all of your nodes but prefer clients\n> open channels to a single one, similar to ACINQ's setup with \"endurance\"\n> and \"starblocks\" on testnet.  This example would simply require setting\n> \"endurance\" to have the highest priority. This also allows domain operators\n> to have one or more public nodes, but many private ones with channels open\n> to their public nodes to better manage their risk. For example, the private\n> nodes could be behind a firewall.\n\nThis is definitely true, if I'm not mistaken, starblocks doesn't even\nallow incoming connections, so you have to use endurance as an entry\npoint.\n\n> The result of this is that the user experience is improved, and a side\n> benefit is being able to safely associate a given payment request, and by\n> extension node, with a domain.  Another nontrivial benefit is there will be\n> more channels opened with value on the other side, allowing for receiving\n> funds back from Lightning.\n>\n> There are some possible open questions regarding ensuring a payment request\n> hasn't been spoofed, but if you present the domain to the user, he/she can\n> verify that the wallet is about to open a channel to the domain they\n> expect.  Other issues with this are with DNS hijacking, which to be frank\n> is not an unlikely scenario.  Caution would be necessary, and perhaps\n> cryptographic means of associating nodes and their associated domains would\n> be a requirement for something like this to exist, but the proposed BOLT\n> lays the groundwork for that to happen.\n\nThere's some value in this, that's definitely true, however these kinds\nof added security through DNS haven't quite worked out in the past. Then\nagain we can just do the domain -> nodeid binding without encouraging\nusers to actually open a direct connection :-)\n\n> --Future payments going through the merchant:\n>\n> This is probably the biggest wrinkle.  The merchant _does_ have the ability\n> to know when a payment transits the channel, thus reducing privacy.  I\n> think the proposed BOLT should only be used to improve user experience, not\n> as a replacement for the decentralized nature of Lightning.  For example,\n> node operators will use autopilot-like functionality for opening channels,\n> BUT they will be able to augment that with looking up common stores and\n> merchant's domain records and open their own channels to them to provide\n> alternate routes to popular anticipated destinations for payments, thus\n> making their own node more valuable and increasing the decentralization of\n> the network.  For example, if you know people are going to be paying\n> Starbucks, you can issue a DNS request of your own, get their current\n> preferred node and connect, and then any node you have channels with will\n> be able to pay Starbucks through you, without having to open a channel of\n> their own.\n\nOk, I definitely agree that, if implemented, this would be only a\nfallback solution. The problem is how to communicate this until we have\nthe autopilots that take care of the normal operation? The risk is that\nif we spec and implement this right now, it'll become the normal mode of\noperation and we'll end up with a very poor network.\n\n> --Merchant crippling payments:\n>\n> With the convention I described above, using channel opens as proof of\n> payment, if Starbucks wants to deny a customer the ability to pay McDonalds\n> (or simply doesn't have the appropriate channels to do so), the user's\n> wallet will simply fall back, look up mcdonalds.com, find the appropriate\n> node and pay the invoice via channel opening.  This also partly addresses\n> point 2, as if a merchant wants to spy on its customers, it must provide\n> routes to its competitors.  It can either spy or deny routes, but not\n> both.  In addition, the onion-like nature of payments means the merchant\n> can't be sure a user paid a competitor, or a node behind them, though some\n> configurations of channels and nodes can definitely reduce privacy quite a\n> bit (example: a tiny etsy shop only has a couple of connections, Evil\n> Starbucks being one of them with the largest channel.  A user paying an\n> amount above the second largest channel to this shop would have to use the\n> merchant's channel, and the merchant would be sure that the payment didn't\n> travel any further from there.)\n\nWell, the fallback solution is not exactly free either, it takes time to\nconfirm the channel, so the merchant can indeed force a degraded user\nexperience. Unlike fully random connection the merchant can also be\nreasonably sure that the origin of the payment he is tampering with is\nactually its customer and that degrading their experience might result\nin the customer preferring them over the competition.\n\n> --Network of large hubs:\n> I disagree.  Again, leaning on the ability to open channels with push\n> amounts that have some minor assurances (authority of DNS records) that\n> you're getting the node you intend, I expect routing node operators to\n> preemptively open channels to merchants they expect to receive payments,\n> and they could advertise their own node to do so, along with allowing\n> customers to connect directly to merchants.  The minimum requirement to use\n> this BOLT are the same as running a Lightning node full time, plus\n> ownership of a domain.\n>\n> With that said, I agree regarding the value of random connections in\n> strengthening the network.  Nodes are well-equipped to find inefficiencies\n> and correct them.  The intention of the BOLT is really to improve the\n> on-boarding experience, along with providing an additional means to\n> advertise \"official\" nodes to ease clients, especially mobile ones, onto\n> the network.\n\nI'm ok with this being a fallback solution, I just don't want it to\nbecome the de-facto standard of operating, which'd result in the extreme\nscenarios I listed above. But maybe we're both looking at this from\nextreme ends and the truth (most likely) lies somewhere in-between :-)\n\n> Your pessimism is warranted and invited.\n\nYeah, sorry about that, I tend to be overly pessimistic in these cases\n;-)\n\nCheers,\nChristian"
            },
            {
                "author": "Tyler H",
                "date": "2018-04-09T21:01:10",
                "message_text_only": "Christian,\n\nI hope the additional clarification in the RFC makes clear that BOLT 10\ntakes precedence for bootstrapping and autopilot functionality.  To\nsummarize the intention of this BOLT: Lightning is authoritative, but DNS\ncan be used to assist in on-boarding (with all of its usefulness AND\ninherent flaws.)\n\n>we can just do the domain -> nodeid binding without encouraging\n> users to actually open a direct connection :-)\n\nRight - the intention is to provide fallback mechanisms and user-friendly\nways of finding the right nodes.  If a user wants to open a channel to\nStarbucks before they leave their house, then can and then let the\nconfirmation process start on the way there.\n\n> The risk is that\n> if we spec and implement this right now, it'll become the normal mode of\n> operation and we'll end up with a very poor network.\n\nI agree, and I am in no rush to get this BOLT part of the spec before every\nimplementation has an autopilot function in a state they're comfortable\nwith.  If we want to kick it out for some months or even longer to allow\ntime for the network to bootstrap itself in a decentralized way, I'm fine\nwith that. I do think the pros of being able to associate a given\nmerchant/user with their incoming node in a way familiar to users will help\nto ease the pain of opening channels that are useful to the user.\n\n> Well, the fallback solution is not exactly free either, it takes time to\nconfirm the channel, so the merchant can indeed force a degraded user\nexperience\n\nAh, good point. I would exercise caution against implementing my exact\nproposal regarding channel opens as payments as it was an example of\nfunctionality that would be enabled by the BOLT that needs careful thought\nand design to address concerns.  I think the ability to find nodes operated\nby the owners of domains and subdomains could open up other useful\npossibilities as well, including giving mobile users the option of where to\nopen their first channel to.\n\nWith your feedback, perhaps a good idea would be to decide on and\nexplicitly defined allowable uses for information gleaned from DNS records\nsuch as the line already added about disallowing bootstrapping from a\nnon-seed domain.\n\nPerhaps the first approved use-case could be invoices that include a domain\nin the extra fields, clients can do a lookup on the domain and ensure the\nnode they're paying is listed, and if not provide a warning notification to\nthe user, or simply display the domain and the result of the lookup.\n\nThis would provide some protection against invoice tampering, as a\nmalicious actor with the ability to modify the invoice displayed to the\nuser would have to also display a domain other than the one the one\nassociated with the website the user intended to pay.\n\nThanks,\nTyler\n\nOn Mon, Apr 9, 2018 at 12:26 PM Christian Decker <decker.christian at gmail.com>\nwrote:\n\n> Tyler,\n>\n> thanks for the detailed feedback, I'll try to address some of the issues\n> inline:\n>\n> Tyler H <tyzbit at gmail.com> writes:\n> > --Regarding looking up nodes at the time of payments:\n> >\n> > In the future, nodes could negotiate a channel open with a push amount\n> and\n> > provide the TXID or payment hash as proof of their payment of the\n> invoice.\n> > This wouldn't even require the channel to be usable, and merchants could\n> > decide to accept 1 (or even 0) confirmations of this transaction based on\n> > their acceptable level of risk, considering the properties of the channel\n> > (capacity, local balance etc).  So in that use case, this would be a\n> rough\n> > process of the interaction:\n>\n> There is very little difference between pushing with the channel\n> creation and just doing an immediate update even though the channel\n> isn't confirmed yet. To be honest I think the `push_msat` feature is the\n> classical case of optimizing too early.\n>\n> But the end result is still that the merchant either takes a hit in the\n> trustworthiness of the incoming payment, or the buyer is going to have a\n> bad time waiting at the checkout until the channel confirms.\n>\n> > User tries to pay lightning invoice, and it fails.  The user's wallet\n> > offers to pay via channel opening.  The user accepts.  The wallet reads\n> the\n> > invoice for a \"domain\" field, or perhaps if the wallet happens to be a\n> > browser, it does a SRV lookup against the current domain serving the\n> > invoice.  The wallet looks up the domain records, and verifies the\n> > destination node is present.  If so, the wallet picks the correct node\n> > based on the records present, and opens a channel with a push amount to\n> > it.  The destination node sees this and via as some yet undetermined\n> > method, associates it to that payment invoice and chooses to mark it as\n> > \"paid\" or \"pending X confirmations\" according to whatever criteria the\n> node\n> > operator wishes to use.\n>\n> I was going to comment that, since we already have an invoice detailing\n> the destination, the indirection through the DNS system to find the\n> desired connection point was useless, but your example with Starblocks\n> where connections are accepted by one node, and payments by another\n> convinced me that this is indeed a useful feature. A feature however\n> that could be solved just as well by including an `r` tag in the invoice\n> itself. In this case you can either use the gossip protocol or the BOLT\n> 10 DNS lookup system to locate the entry point into the merchant's\n> network. I don't think that a direct connection to the merchant in case\n> of it being unreachable is a good idea, because it creates latent\n> hubs. But I see the slight advantage of reducing the failure probability\n> w.r.t. to opening a channel with a random node.\n>\n> > In a simple example, you could list all of your nodes but prefer clients\n> > open channels to a single one, similar to ACINQ's setup with \"endurance\"\n> > and \"starblocks\" on testnet.  This example would simply require setting\n> > \"endurance\" to have the highest priority. This also allows domain\n> operators\n> > to have one or more public nodes, but many private ones with channels\n> open\n> > to their public nodes to better manage their risk. For example, the\n> private\n> > nodes could be behind a firewall.\n>\n> This is definitely true, if I'm not mistaken, starblocks doesn't even\n> allow incoming connections, so you have to use endurance as an entry\n> point.\n>\n> > The result of this is that the user experience is improved, and a side\n> > benefit is being able to safely associate a given payment request, and by\n> > extension node, with a domain.  Another nontrivial benefit is there will\n> be\n> > more channels opened with value on the other side, allowing for receiving\n> > funds back from Lightning.\n> >\n> > There are some possible open questions regarding ensuring a payment\n> request\n> > hasn't been spoofed, but if you present the domain to the user, he/she\n> can\n> > verify that the wallet is about to open a channel to the domain they\n> > expect.  Other issues with this are with DNS hijacking, which to be frank\n> > is not an unlikely scenario.  Caution would be necessary, and perhaps\n> > cryptographic means of associating nodes and their associated domains\n> would\n> > be a requirement for something like this to exist, but the proposed BOLT\n> > lays the groundwork for that to happen.\n>\n> There's some value in this, that's definitely true, however these kinds\n> of added security through DNS haven't quite worked out in the past. Then\n> again we can just do the domain -> nodeid binding without encouraging\n> users to actually open a direct connection :-)\n>\n> > --Future payments going through the merchant:\n> >\n> > This is probably the biggest wrinkle.  The merchant _does_ have the\n> ability\n> > to know when a payment transits the channel, thus reducing privacy.  I\n> > think the proposed BOLT should only be used to improve user experience,\n> not\n> > as a replacement for the decentralized nature of Lightning.  For example,\n> > node operators will use autopilot-like functionality for opening\n> channels,\n> > BUT they will be able to augment that with looking up common stores and\n> > merchant's domain records and open their own channels to them to provide\n> > alternate routes to popular anticipated destinations for payments, thus\n> > making their own node more valuable and increasing the decentralization\n> of\n> > the network.  For example, if you know people are going to be paying\n> > Starbucks, you can issue a DNS request of your own, get their current\n> > preferred node and connect, and then any node you have channels with will\n> > be able to pay Starbucks through you, without having to open a channel of\n> > their own.\n>\n> Ok, I definitely agree that, if implemented, this would be only a\n> fallback solution. The problem is how to communicate this until we have\n> the autopilots that take care of the normal operation? The risk is that\n> if we spec and implement this right now, it'll become the normal mode of\n> operation and we'll end up with a very poor network.\n>\n> > --Merchant crippling payments:\n> >\n> > With the convention I described above, using channel opens as proof of\n> > payment, if Starbucks wants to deny a customer the ability to pay\n> McDonalds\n> > (or simply doesn't have the appropriate channels to do so), the user's\n> > wallet will simply fall back, look up mcdonalds.com, find the\n> appropriate\n> > node and pay the invoice via channel opening.  This also partly addresses\n> > point 2, as if a merchant wants to spy on its customers, it must provide\n> > routes to its competitors.  It can either spy or deny routes, but not\n> > both.  In addition, the onion-like nature of payments means the merchant\n> > can't be sure a user paid a competitor, or a node behind them, though\n> some\n> > configurations of channels and nodes can definitely reduce privacy quite\n> a\n> > bit (example: a tiny etsy shop only has a couple of connections, Evil\n> > Starbucks being one of them with the largest channel.  A user paying an\n> > amount above the second largest channel to this shop would have to use\n> the\n> > merchant's channel, and the merchant would be sure that the payment\n> didn't\n> > travel any further from there.)\n>\n> Well, the fallback solution is not exactly free either, it takes time to\n> confirm the channel, so the merchant can indeed force a degraded user\n> experience. Unlike fully random connection the merchant can also be\n> reasonably sure that the origin of the payment he is tampering with is\n> actually its customer and that degrading their experience might result\n> in the customer preferring them over the competition.\n>\n> > --Network of large hubs:\n> > I disagree.  Again, leaning on the ability to open channels with push\n> > amounts that have some minor assurances (authority of DNS records) that\n> > you're getting the node you intend, I expect routing node operators to\n> > preemptively open channels to merchants they expect to receive payments,\n> > and they could advertise their own node to do so, along with allowing\n> > customers to connect directly to merchants.  The minimum requirement to\n> use\n> > this BOLT are the same as running a Lightning node full time, plus\n> > ownership of a domain.\n> >\n> > With that said, I agree regarding the value of random connections in\n> > strengthening the network.  Nodes are well-equipped to find\n> inefficiencies\n> > and correct them.  The intention of the BOLT is really to improve the\n> > on-boarding experience, along with providing an additional means to\n> > advertise \"official\" nodes to ease clients, especially mobile ones, onto\n> > the network.\n>\n> I'm ok with this being a fallback solution, I just don't want it to\n> become the de-facto standard of operating, which'd result in the extreme\n> scenarios I listed above. But maybe we're both looking at this from\n> extreme ends and the truth (most likely) lies somewhere in-between :-)\n>\n> > Your pessimism is warranted and invited.\n>\n> Yeah, sorry about that, I tend to be overly pessimistic in these cases\n> ;-)\n>\n> Cheers,\n> Christian\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180409/db07c7bb/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Proposal for Advertising Lightning nodes via DNS records.",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Corn\u00e9 Plooy",
                "ZmnSCPxj",
                "Tyler H",
                "Christian Decker"
            ],
            "messages_count": 24,
            "total_messages_chars_count": 102156
        }
    },
    {
        "title": "[Lightning-dev] Closing Transaction Cut-through as a Generalization of Splice-in/Splice-out",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-10T09:44:15",
                "message_text_only": "Good morning list,\n\nI have the below speculation idea.\n\nSuppose, rather than implement a splice-in/splice-out (\"channel top-up\", etc.) we instead implement a more general \"cut-through\" for a channel close transaction.\n\nNormally a channel close spends a single input and makes 1 or 2 outputs.  Instead of such a simple transaction, both sides could additionally provide signed normal transactions that spend the outputs, then they could cooperatively create a new close transaction that cuts through the original close transaction and the additional normal transactions.\n\nA splice-in and splice-out would then be a closing transaction that gets cut-through with a funding transaction to the same peer.\n\nThe generalization is useful if we want to \"reseat\" a channel to one peer to another peer.  For example, if the node keeps payment statistics and notices that the channel with one peer always has a high probability of failing to forward to a destination, then it could decide to close that channel and open a channel to some other peer.  This reseat operation could use the closing transaction cut-through to close the channel and open to another peer in a single onchain transaction.\n\nSuch a reseat operation also seems like a reasonable primitive for Burchert-Decker-Wattenhofer channel factories to offer; reseats can be done offchain if both the reseat-form peer and the reseat-to peer and the node belong to the same channel factory.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180410/da93ba65/attachment.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2018-04-11T17:38:47",
                "message_text_only": "ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> writes:\n> Suppose, rather than implement a splice-in/splice-out (\"channel\n> top-up\", etc.) we instead implement a more general \"cut-through\" for a\n> channel close transaction.\n>\n> Normally a channel close spends a single input and makes 1 or 2\n> outputs.  Instead of such a simple transaction, both sides could\n> additionally provide signed normal transactions that spend the\n> outputs, then they could cooperatively create a new close transaction\n> that cuts through the original close transaction and the additional\n> normal transactions.\n\nWe could go a bit further and have both sides provide incomplete and\nunsigned stubs, that would then be applied to the closing transaction:\ninputs in the stubs are added as inputs to the closing transaction\nadding to the balance of the providing party, and outputs are also added\nto the closing transaction, drawing from the balance of the party adding\nthe new output. This way we can perform any number of splice-in / -out\noperations in a single reseat operation. Not sure if we need to have any\nadditional negotiation besides this. Admittedly using tx formatted\nmessages to transport the intent is not really necessary, but it\nreconnects to the idea of cut-through, combining multiple transactions\ninto one.\n\n> A splice-in and splice-out would then be a closing transaction that\n> gets cut-through with a funding transaction to the same peer.\n\nThat may complicate the state tracking a bit, but we'll eventually have\ntransactions that assume multiple roles anyway, so that sounds ok.\n\n> The generalization is useful if we want to \"reseat\" a channel to one\n> peer to another peer.  For example, if the node keeps payment\n> statistics and notices that the channel with one peer always has a\n> high probability of failing to forward to a destination, then it could\n> decide to close that channel and open a channel to some other peer.\n> This reseat operation could use the closing transaction cut-through to\n> close the channel and open to another peer in a single onchain\n> transaction.\n>\n> Such a reseat operation also seems like a reasonable primitive for\n> Burchert-Decker-Wattenhofer channel factories to offer; reseats can be\n> done offchain if both the reseat-form peer and the reseat-to peer and\n> the node belong to the same channel factory.\n\nThe connection the channel factories is not really necessary, as long as\nwe have an invalidation scheme that allows us to invalidate a prior\nfunding transaction we can reseat without needing a cut-through, just\ninvalidate the funding tx of the old channel and add the funding tx for\nthe new one in the new state."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-13T13:10:56",
                "message_text_only": "Good morning Christian,\n\n\n> \n> The connection the channel factories is not really necessary, as long as\n> \n> we have an invalidation scheme that allows us to invalidate a prior\n> \n> funding transaction we can reseat without needing a cut-through, just\n> \n> invalidate the funding tx of the old channel and add the funding tx for\n> \n> the new one in the new state.\n\nIndeed, it is unnecessary at all.\n\nMy consideration, was that we could present it as an operation to wallet implementers (or advanced users).\n\nIn much the same way that it would be sensible to present a `multifundchannel` command at c-lightning RPC level, it would be sensible to present a `reseatchannel` command at c-lightning RPC level to transfer the remaining funds of a channel from one peer to a new channel to another (or possibly to splice-out from one and immediately splice-in to another).\n\nPrior to Burchert-Decker-Wattenhofer channel factories being deployed, `multifundchannel` and `reseatchannel` would use current operations (multiple  channel funding txouts from one funding tx for the former, separate close-then-open operations for the latter (possibly implemented with cut-through if it can be specced)).  Then when the Burchert-Decker-Wattenhofer channel factories are deployed we can optimize (`multifundchannel` actually creates a new channel factory with this node and all nodes listed in the multi-fund operation as members of the factory, with the starting fund only happening to come from this node only; `reseatchannel` is an offchain channel reorganization request to the factory).\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Closing Transaction Cut-through as a Generalization of Splice-in/Splice-out",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Decker",
                "ZmnSCPxj"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 5914
        }
    },
    {
        "title": "[Lightning-dev] High level fee mechanics",
        "thread_messages": [
            {
                "author": "Thomas Steenholdt",
                "date": "2018-04-10T15:02:39",
                "message_text_only": "Hi ZmnSCPxj,\n\n\nI came up with a followup question...\n\n\nDoes node GOSSIP also reveal the funding/balance of channels, same way it does the fees?\n\n\nI'm trying to understand how to make an informed payment routing decision as a sender, based on the fees (that you have already explained), but also the funding/balance of each channel, to select the cheapest route with the highest chance of success.\n\n\nI have looked through the RFC and can't seem to find an explanation on whether or not the channel funding/balance information is available from GOSSIP or how else you'd handle this kind of thing?\n\n\nI was hoping you might have a short explanation for this stuff as well? :-)\n\n\n/Thomas\n\n\n________________________________\nFrom: ZmnSCPxj <ZmnSCPxj at protonmail.com>\nSent: Sunday, March 18, 2018 8:48:57 PM\nTo: Thomas Steenholdt\nCc: lightning-dev at lists.linuxfoundation.org\nSubject: Re: [Lightning-dev] High level fee mechanics\n\nGood morning Thomas,\n\n\nSent with ProtonMail<https://protonmail.com> Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn March 19, 2018 6:24 AM, Thomas Steenholdt <TSteenholdt at cascadetechnologypartners.com> wrote:\n\n\nHi,\n\n\nI've been trying to figure out the mechanics of Lightning fees, especially in the case of routed payments. Unfortunately, I haven't had any success in finding a high level description on the topic.\n\n\n\nI'm hoping somebody is able to point me in the right direction?\n\nBOLT spec https://github.com/lightningnetwork/lightning-rfc contains everything, but is very detailed and contains the topic in multiple places.\n\n\n\nExample:\n\nA multi-hop routed payment where A needs to pay D through B and C. Established channels are A -> B -> C -> D.\n\n\n\nWhat I'm looking for is a high level explanation of how fees are established, announced and ultimately claimed in a payment like this. Some of the questions that come to mind are:\n\n\n- Does A know ahead of time the fees on B and C, or only when trying to set up the payment? And how?\n\nYes.  Node gossip, the `channel_update` message in BOLT#7.  This message, contains `fee_base_msat` and `fee_proportional_millionths`.  For each channel, there are two `channel_update` messages, one from each direction.  For example B<->C channel, B announces its fee for B->C transfers while C announnces its fee for C->B transfers.\n\nThe A may have obsolete information about fees (e.g. B or C change their fee but their `channel_update` has not propagated to A yet).  In this case, payment routing will fail, but the `channel_update` will also be sent as part of the error message returned by payment routing failure.\n\n\n- How does A know the amount of fees that need to be added to the payment to cover all fees?\n\nIt computes it.  If D is to be given a payment with value `msatoshi` then it computes first the C->D fee, which is the C->D `fee_base_msat` +  (C->D `fee_proportion_millionts` * `msatoshi` / 1,000,000).  Add that to `msatoshi` and that is the payment that needs to reach C, so A computes the payment from B->C similarly, except the `msatoshi` is replaced with the payment that should reach C.  Then A knows how much it has to give to B.\n\n\n- Is D aware of the full amount including fees or is that somehow hidden?\n\nNo.  D is only aware of how much C offers it.\n\n\n- How are the fees actually claimed (who ends up paying whom)?\n\nA offer B a value that is higher than what A instruct B to forward to C.  The difference is the fee.  Since the highest value is at the source A, A is the one, who ends up paying the entire fee.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180410/9bead1af/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-11T03:04:09",
                "message_text_only": "Good morning Thomas,\n\n> Does node GOSSIP also reveal the funding/balance of channels, same way it does the fees?\n>\n> I'm trying to understand how to make an informed payment routing decision as a sender, based on the fees (that you have already explained), but also the funding/balance of each channel, to select the cheapest route with the highest chance of success.\n>\n> I have looked through the RFC and can't seem to find an explanation on whether or not the channel funding/balance information is available from GOSSIP or how else you'd handle this kind of thing?\n\nNo, channel balance of each peer on the channel is not revealed on node gossip.\n\nLogically, invert the question: do you want to report how much you spend/receive on each of your channels to the network?  Do you want to report how much you own on Lightning to be reported to everyone on Lightning?\n\nSince the balance on each peer is effectively the amount of money each peer owns on that channel, and each change to that balance represents a send/receive on that channel, you will not want to report your balance, and any changes in that balance, to the entire network.\n\nLogically you can then expect not to receive such updates from anybody else, either.\n\nHow do real-life implementations like c-lightning get your payment routes then?  By brute-force trial-and-error.  If one channel on a route fails, we just mark it as temporarily unuseable and plot a new route that does not include that channel.  If a channel on THAT route fails, we mark it and plot another route.  And so on until we run out of possible routes because all possible channels to the destination are blocked.\n\n--\n\nNote though that you can easily get the channel total capacity for each channel (just not how the channel is divided between the two parties).\n\nEach published channel has a short channel id composed of blockheight, transaction index within block, and output index within transaction.  This identifies a specific txout on the blockchain you are using.  If that txout is spent, then the channel has been closed and you cannot use it for routing.  If that txout is unspent, then the value of that UTXO is the total channel capacity.  C-lightning records this but does not (yet) use the total channel capacity (logically if your payment would exceed the total channel capacity then the channel is unuseable for that payment, and if it is a large fraction of that total channel capacity then it is very unlikely to be useable); but the existing brute-force trial-and-error algorithm works well enough already.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180410/612e3351/attachment.html>"
            },
            {
                "author": "Alejandro Ranchal Pedrosa",
                "date": "2018-04-11T08:01:02",
                "message_text_only": "Hi ZmnSCPxj,\n\n\n> No, channel balance of each peer on the channel is not revealed on \n> node gossip.\n>\n> Logically, invert the question: do you want to report how much you \n> spend/receive on each of your channels to the network? Do you want to \n> report how much you own on Lightning to be reported to everyone on \n> Lightning?\n>\n> Since the balance on each peer is effectively the amount of money each \n> peer owns on that channel, and each change to that balance represents \n> a send/receive on that channel, you will not want to report your \n> balance, and any changes in that balance, to the entire network.\n>\n> Logically you can then expect not to receive such updates from anybody \n> else, either.\n>\n> How do real-life implementations like c-lightning get your payment \n> routes then?\u00a0 By brute-force trial-and-error\n\nIf payment routes are discovered by brute-force trial-and-error, and \nactually the sender can interrupt any payment by simply not revealing \nthe secret, isn't it possible for any sender to simply start probing to \ndiscover the capacities in each path?\n\nBest,\nAlejandro.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180411/3c086b31/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-11T09:17:15",
                "message_text_only": "Good morning Alejandro,\n\n>> No, channel balance of each peer on the channel is not revealed on node gossip.\n>>\n>> Logically, invert the question: do you want to report how much you spend/receive on each of your channels to the network? Do you want to report how much you own on Lightning to be reported to everyone on Lightning?\n>>\n>> Since the balance on each peer is effectively the amount of money each peer owns on that channel, and each change to that balance represents a send/receive on that channel, you will not want to report your balance, and any changes in that balance, to the entire network.\n>>\n>> Logically you can then expect not to receive such updates from anybody else, either.\n>>\n>> How do real-life implementations like c-lightning get your payment routes then?  By brute-force trial-and-error\n>\n> If payment routes are discovered by brute-force trial-and-error, and actually the sender can interrupt any payment by simply not revealing the secret, isn't it possible for any sender to simply start probing\n> to discover the capacities in each path?\n\nYes.  Although now the sender risks its funds: if a node along the route it selects stalls, then the sender risks having its money locked for some blocks.\n\nAlso, the sender only gets one bit of information to the question: Is the channel balance in this direction greater than X?\n\nFinally, the exact failure TEMPORARY_CHANNEL_FAILURE can mean that the other node is currently down rather than the channel not having enough capacity in that direction, or if there are too many HTLCs in-flight on that channel, or so on (the most likely currently seems to be the node is currently down rather than the channel balance being insufficient, since it seems many people do not leave their nodes running 24/7).\n\nSo it is always less desirable than getting the exact channel balances at each balance update.  You get degraded privacy, but not a full loss of privacy compared to broadcasting all balance updates.\n\n(in particular, if the channel balance changes, you would have to re-query the channel again to learn this)\n\n(your technique is flawed in the detail that the sender simply selects a destination randomly and a random payment hash, which has negligible probability of the randomly-selected destination knowing its preimage, but is otherwise sound in its broad strokes)\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180411/a0d0a1ae/attachment-0001.html>"
            },
            {
                "author": "Benjamin Mord",
                "date": "2018-04-11T16:00:47",
                "message_text_only": "Do (should) channels have the option of publicizing their balances, so as\nto improve routing performance / scalability in a large network, and for\ncompetitive differentiation among competing routes? This would allow\nchannel owners to balance privacy with efficiency, and where the incentive\nto publish would go up in proportion to network scalability requirements.\nBrute force trial & error seems expensive at scale, and also reduces\nprivacy of the sender - so it seems a useful hedge to leave this decision\nto the market (if technically practical).\n\n\nOn Wed, Apr 11, 2018 at 5:17 AM, ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Alejandro,\n>\n>\n> No, channel balance of each peer on the channel is not revealed on node\n> gossip.\n>\n> Logically, invert the question: do you want to report how much you\n> spend/receive on each of your channels to the network? Do you want to\n> report how much you own on Lightning to be reported to everyone on\n> Lightning?\n>\n> Since the balance on each peer is effectively the amount of money each\n> peer owns on that channel, and each change to that balance represents a\n> send/receive on that channel, you will not want to report your balance, and\n> any changes in that balance, to the entire network.\n>\n> Logically you can then expect not to receive such updates from anybody\n> else, either.\n>\n> How do real-life implementations like c-lightning get your payment routes\n> then?  By brute-force trial-and-error\n>\n>\n> If payment routes are discovered by brute-force trial-and-error, and\n> actually the sender can interrupt any payment by simply not revealing the\n> secret, isn't it possible for any sender to simply start probing\n> to discover the capacities in each path?\n>\n>\n> Yes.  Although now the sender risks its funds: if a node along the route\n> it selects stalls, then the sender risks having its money locked for some\n> blocks.\n>\n> Also, the sender only gets one bit of information to the question: Is the\n> channel balance in this direction greater than X?\n>\n> Finally, the exact failure TEMPORARY_CHANNEL_FAILURE can mean that the\n> other node is currently down rather than the channel not having enough\n> capacity in that direction, or if there are too many HTLCs in-flight on\n> that channel, or so on (the most likely currently seems to be the node is\n> currently down rather than the channel balance being insufficient, since it\n> seems many people do not leave their nodes running 24/7).\n>\n> So it is always less desirable than getting the exact channel balances at\n> each balance update.  You get degraded privacy, but not a full loss of\n> privacy compared to broadcasting all balance updates.\n>\n> (in particular, if the channel balance changes, you would have to re-query\n> the channel again to learn this)\n>\n> (your technique is flawed in the detail that the sender simply selects a\n> destination randomly and a random payment hash, which has negligible\n> probability of the randomly-selected destination knowing its preimage, but\n> is otherwise sound in its broad strokes)\n>\n> Regards,\n> ZmnSCPxj\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180411/5d786b71/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-12T04:49:23",
                "message_text_only": "Good morning Benjamin,\n\n> Do (should) channels have the option of publicizing their balances, so as to improve routing performance / scalability in a large network, and for competitive differentiation among competing routes? This would allow channel owners to balance privacy with efficiency, and where the incentive to publish would go up in proportion to network scalability requirements. Brute force trial & error seems expensive at scale, and also reduces privacy of the sender - so it seems a useful hedge to leave this decision to the market (if technically practical).\n\nI think brute-force scales well enough, but perhaps we should see the network in action more.\n\nTo an extent, it is possible to hint the suitability of a channel for routing in a particular direction, without completely leaking your balance in detail, by adjusting the on-Lightning `fee_base_msat` and `fee_proportional_millionths` of channels.  If you have a high balance on a channel, you reduce your side of the fee for that channel (i.e. the direction where you are the source for payments on that channel) to encourage others to use it and hopefully pay you on a depleted channel.  If you have a low balance, you increase your fee.  These fees are already propagated using `channel_update`.  No current node software implements this yet, however.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180412/f07760fc/attachment-0001.html>"
            },
            {
                "author": "Benjamin Mord",
                "date": "2018-04-12T20:37:17",
                "message_text_only": "Thank you, ZmnSCPxj.\n\n\"... by adjusting the on-Lightning `fee_base_msat` and\n`fee_proportional_millionths` of channels.\"\n\nYes, I agree these prices are a critical signaling mechanism that can have\nsubstantial impact on expected channel lifetime and thus economic\nefficiency of lightning operation overall. (As you may recall, I believe we\nshould allow negative prices - even if present day routing algorithms\nchoose to treat negative fees as zero for temporary simplicity.) You make a\ngood point it can also improve routing efficiency by hinting at capacity,\nbut for now they are unfortunately linear.\n\nThe following paper did not account for the improved efficiency that price\nadjustment in response to channel state will likely enable, but one thing\nwhich may be relevant here is the underlying power law assumption of\ntransaction size distribution (which is apparently drawn from actual data),\nand the more general approach to estimating channel lifespan. In lieu of\nadvertising max capacity, perhaps we should instead permit a price exponent\nwhich may optionally be set to something larger than 1. The cost to channel\noperator of processing a transaction is largely the impact to expected\nchannel lifespan, which in turn is nonlinear with respect to transaction\nsize - and dramatically so as transaction size approaches (or exceeds)\nremaining capacity.\nhttps://arxiv.org/pdf/1712.10222.pdf\n\nIf we combine nonlinear pricing with your March 19 AMP proposal, I expect\neconomic efficiency could be greatly improved.\n\nThanks again,\nBenjamin Mord\n\n\nOn Thu, Apr 12, 2018 at 12:49 AM, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Benjamin,\n>\n> Do (should) channels have the option of publicizing their balances, so as\n> to improve routing performance / scalability in a large network, and for\n> competitive differentiation among competing routes? This would allow\n> channel owners to balance privacy with efficiency, and where the incentive\n> to publish would go up in proportion to network scalability requirements.\n> Brute force trial & error seems expensive at scale, and also reduces\n> privacy of the sender - so it seems a useful hedge to leave this decision\n> to the market (if technically practical).\n>\n>\n> I think brute-force scales well enough, but perhaps we should see the\n> network in action more.\n>\n> To an extent, it is possible to hint the suitability of a channel for\n> routing in a particular direction, without completely leaking your balance\n> in detail, by adjusting the on-Lightning `fee_base_msat` and\n> `fee_proportional_millionths` of channels.  If you have a high balance on a\n> channel, you reduce your side of the fee for that channel (i.e. the\n> direction where you are the source for payments on that channel) to\n> encourage others to use it and hopefully pay you on a depleted channel.  If\n> you have a low balance, you increase your fee.  These fees are already\n> propagated using `channel_update`.  No current node software implements\n> this yet, however.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180412/d4d4baee/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-13T13:26:15",
                "message_text_only": "Good morning Benjamin,\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn April 13, 2018 4:37 AM, Benjamin Mord <ben at mord.io> wrote:\n\n> Thank you, ZmnSCPxj.\n>\n> \"... by adjusting the on-Lightning `fee_base_msat` and `fee_proportional_millionths` of channels.\"\n>\n> Yes, I agree these prices are a critical signaling mechanism that can have substantial impact on expected channel lifetime and thus economic efficiency of lightning operation overall. (As you may recall, I believe we should allow negative prices - even if present day routing algorithms choose to treat negative fees as zero for temporary simplicity.) You make a good point it can also improve routing efficiency by hinting at capacity, but for now they are unfortunately linear.\n>\n> The following paper did not account for the improved efficiency that price adjustment in response to channel state will likely enable, but one thing which may be relevant here is the underlying power law assumption of transaction size distribution (which is apparently drawn from actual data), and the more general approach to estimating channel lifespan. In lieu of advertising max capacity, perhaps we should instead permit a price exponent which may optionally be set to something larger than 1. The cost to channel operator of processing a transaction is largely the impact to expected channel lifespan, which in turn is nonlinear with respect to transaction size - and dramatically so as transaction size approaches (or exceeds) remaining capacity.\n> https://arxiv.org/pdf/1712.10222.pdf\n\nLarger payments also have a much lower chance of successfully propagating through the network, as every channel in its route needs to have the requisite capacity, so I think it somewhat balances out (maybe).\n\nAdding a nonlinear component would be difficult to add on to the protocol currently, as I think there is no provision for it in the protocol.  But maybe I am incorrect..?\n\n> If we combine nonlinear pricing with your March 19 AMP proposal, I expect economic efficiency could be greatly improved.\n\nMy AMP proposal cannot work soon.  It requires at minimum for Bellare-Neven/MuSig/Schnorr (I get confused, which is the proper name for this) signatures to be added to Bitcoin to get HD+SS.  Then we need to switch over all implementations to using scriptless script contingent payments rather than hashlocked contingent payments (and convince all network node operators to upgrade); we will be unable to use an intermediate node that does not understand SS contingent payments for my style of AMP.\n\nThe earlier AMP proposal by roasbeef is back-compatible (uses the same hashlocked contingent payments we already use now), but does not support a proof-of-payment compatible with ZKCP protocols (although possibly I am wrong, I think roasbeef has mentioned before that it is ZKCP compatible).\n\nRegards,\nZmnSCPxj\n\n> Thanks again,\n> Benjamin Mord\n>\n> On Thu, Apr 12, 2018 at 12:49 AM, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n>> Good morning Benjamin,\n>>\n>>> Do (should) channels have the option of publicizing their balances, so as to improve routing performance / scalability in a large network, and for competitive differentiation among competing routes? This would allow channel owners to balance privacy with efficiency, and where the incentive to publish would go up in proportion to network scalability requirements. Brute force trial & error seems expensive at scale, and also reduces privacy of the sender - so it seems a useful hedge to leave this decision to the market (if technically practical).\n>>\n>> I think brute-force scales well enough, but perhaps we should see the network in action more.\n>>\n>> To an extent, it is possible to hint the suitability of a channel for routing in a particular direction, without completely leaking your balance in detail, by adjusting the on-Lightning `fee_base_msat` and `fee_proportional_millionths` of channels.  If you have a high balance on a channel, you reduce your side of the fee for that channel (i.e. the direction where you are the source for payments on that channel) to encourage others to use it and hopefully pay you on a depleted channel.  If you have a low balance, you increase your fee.  These fees are already propagated using `channel_update`.  No current node software implements this yet, however.\n>>\n>> Regards,\n>> ZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180413/ac3dc39c/attachment.html>"
            },
            {
                "author": "Benjamin Mord",
                "date": "2018-04-13T16:13:18",
                "message_text_only": "Good morning ZmnSCPxj,\n\nAs a skeptic of discrete logarithm's long-term security, I view scriptless\nscripts as dangerously seductive. (But wow, are they cool! Almost cool\nenough to wish we could uninvent quantum computing. I wonder if R-LWE can\nbe used instead as foundation? Not that I expect R-LWE to hold long-term\neither...) But I digress.\n\nAs I listen to all the work starting up in the legacy financial markets to\nmitigate the likely future failure of LIBOR, given how little thought went\ninto that possibility in the writing of currently-traded derivative\ncontracts, I'm reminded of how important and also how possible it is to\nthink about short and long-term goals simultaneously as we build systems.\nIt is far easier now than it will soon be to add expressiveness into the\ncore protocol, such as negative fees and optional exponential component.\nJust because we pragmatically ignore negative fees and exponents in routing\ndecisions today, does not mean we will not feel enormous need for them in\nthe future - and having the ability to express such fee structures now will\nenable efficiency improvements in the future, as simple implementation\n(rather than protocol) upgrades.\n\nI recognize AMP (at least as you proposed) is a long way out, but it seems\nlike something we'll inevitably want and will surely add. It is therefore\nworth assuming now, as we think strategically about how fee dynamics will\nimprove efficiency over time. Who knows, my skepticism of discrete\nlogarithm hardness may prove misplaced, or else we'll find other ways to\nachieve AMP. (I have not read roasbeef's proposal, but I shall.) The\nprotocol does not presently allow an exponential component, but it would be\ntrivial to add (even if, at first, defaulted to 1).\n\nThanks,\nBen\n\nOn Fri, Apr 13, 2018 at 9:26 AM, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Benjamin,\n>\n>\n>\n>\n> Sent with ProtonMail <https://protonmail.com> Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On April 13, 2018 4:37 AM, Benjamin Mord <ben at mord.io> wrote:\n>\n> Thank you, ZmnSCPxj.\n>\n> \"... by adjusting the on-Lightning `fee_base_msat` and\n> `fee_proportional_millionths` of channels.\"\n>\n> Yes, I agree these prices are a critical signaling mechanism that can have\n> substantial impact on expected channel lifetime and thus economic\n> efficiency of lightning operation overall. (As you may recall, I believe we\n> should allow negative prices - even if present day routing algorithms\n> choose to treat negative fees as zero for temporary simplicity.) You make\n> a good point it can also improve routing efficiency by hinting at capacity,\n> but for now they are unfortunately linear.\n>\n> The following paper did not account for the improved efficiency that price\n> adjustment in response to channel state will likely enable, but one thing\n> which may be relevant here is the underlying power law assumption of\n> transaction size distribution (which is apparently drawn from actual data),\n> and the more general approach to estimating channel lifespan. In lieu of\n> advertising max capacity, perhaps we should instead permit a price exponent\n> which may optionally be set to something larger than 1. The cost to channel\n> operator of processing a transaction is largely the impact to expected\n> channel lifespan, which in turn is nonlinear with respect to transaction\n> size - and dramatically so as transaction size approaches (or exceeds)\n> remaining capacity.\n> https://arxiv.org/pdf/1712.10222.pdf\n>\n>\n> Larger payments also have a much lower chance of successfully propagating\n> through the network, as every channel in its route needs to have the\n> requisite capacity, so I think it somewhat balances out (maybe).\n>\n> Adding a nonlinear component would be difficult to add on to the protocol\n> currently, as I think there is no provision for it in the protocol.  But\n> maybe I am incorrect..?\n>\n> If we combine nonlinear pricing with your March 19 AMP proposal, I expect\n> economic efficiency could be greatly improved.\n>\n>\n> My AMP proposal cannot work soon.  It requires at minimum for\n> Bellare-Neven/MuSig/Schnorr (I get confused, which is the proper name for\n> this) signatures to be added to Bitcoin to get HD+SS.  Then we need to\n> switch over all implementations to using scriptless script contingent\n> payments rather than hashlocked contingent payments (and convince all\n> network node operators to upgrade); we will be unable to use an\n> intermediate node that does not understand SS contingent payments for my\n> style of AMP.\n>\n> The earlier AMP proposal by roasbeef is back-compatible (uses the same\n> hashlocked contingent payments we already use now), but does not support a\n> proof-of-payment compatible with ZKCP protocols (although possibly I am\n> wrong, I think roasbeef has mentioned before that it is ZKCP compatible).\n>\n> Regards,\n> ZmnSCPxj\n>\n> Thanks again,\n> Benjamin Mord\n>\n>\n> On Thu, Apr 12, 2018 at 12:49 AM, ZmnSCPxj <ZmnSCPxj at protonmail.com>\n> wrote:\n>\n>> Good morning Benjamin,\n>>\n>> Do (should) channels have the option of publicizing their balances, so as\n>> to improve routing performance / scalability in a large network, and for\n>> competitive differentiation among competing routes? This would allow\n>> channel owners to balance privacy with efficiency, and where the incentive\n>> to publish would go up in proportion to network scalability requirements.\n>> Brute force trial & error seems expensive at scale, and also reduces\n>> privacy of the sender - so it seems a useful hedge to leave this decision\n>> to the market (if technically practical).\n>>\n>>\n>> I think brute-force scales well enough, but perhaps we should see the\n>> network in action more.\n>>\n>> To an extent, it is possible to hint the suitability of a channel for\n>> routing in a particular direction, without completely leaking your balance\n>> in detail, by adjusting the on-Lightning `fee_base_msat` and\n>> `fee_proportional_millionths` of channels.  If you have a high balance on a\n>> channel, you reduce your side of the fee for that channel (i.e. the\n>> direction where you are the source for payments on that channel) to\n>> encourage others to use it and hopefully pay you on a depleted channel.  If\n>> you have a low balance, you increase your fee.  These fees are already\n>> propagated using `channel_update`.  No current node software implements\n>> this yet, however.\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180413/c35af87b/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "High level fee mechanics",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Alejandro Ranchal Pedrosa",
                "Benjamin Mord",
                "ZmnSCPxj",
                "Thomas Steenholdt"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 29705
        }
    },
    {
        "title": "[Lightning-dev] Lightning Developer Summit #2: Adelaide, Australia 2018-10-08 and 2018-10-09",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-04-12T02:10:51",
                "message_text_only": "Hi all,\n\n        Note the date change; it's now November.  Same location, same\ndiscussions, and we'll be finalizing the agenda closer to the date.\n\n        I'm scouting exact locations for 15-30 people at the moment;\nI'll post here once it's finalized, and ask for RSVPs.\n\nThanks,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Lightning Developer Summit #2: Adelaide, Australia 2018-10-08 and 2018-10-09",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 287
        }
    },
    {
        "title": "[Lightning-dev] Lightning Developer Summit #2: Adelaide, Australia 2018-11-08 and 2018-11-09",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2018-04-12T03:12:28",
                "message_text_only": "Subject correction: 2018-11-08 and 2018-11-09.  November, not October.\n\nThanks AJ...\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Lightning Developer Summit #2: Adelaide, Australia 2018-11-08 and 2018-11-09",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 91
        }
    },
    {
        "title": "[Lightning-dev] Lightning JavaScript implementation that conforms BOLT",
        "thread_messages": [
            {
                "author": "\u0411\u044b\u0445\u0443\u043d, \u0410\u043b\u0435\u043a\u0441\u0435\u0439 \u0412\u0438\u043a\u0442\u043e\u0440\u043e\u0432\u0438\u0447",
                "date": "2018-04-12T14:39:00",
                "message_text_only": "Hi everyone!\n\nI am looking for a way to run a LN node inside the browser. One way would\nbe to implement BOLT protocol from scratch in JS, but I am thinking of a\nmore easy way.\n\nHas anyone succeed in compiling, for example, c-lightning project (\nhttps://github.com/ElementsProject/lightning) under WebAssembly (\nhttp://webassembly.org/getting-started/developers-guide/).\n\nWebAssembly is a C/C++ compiler into browser-compatible byte-code. It can\nuse JS-API, but can also work with low-level C functions.\n\nThere are some things c-lighting does (e.g. sockets), that should stop it\nfrom compiling easily. However, there are wrappers for many C-functions by\nEmscripten lib: https://github.com/kripken/emscripten.\n\nMy question is what should I look for when trying to run that? And also, I\nwant to hear your general feedback on the idea.\n\nAleksey Bykhun.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180412/ba27cdac/attachment.html>"
            },
            {
                "author": "Igor Cota",
                "date": "2018-04-23T06:27:11",
                "message_text_only": "Hi Aleksey,\n\nYour biggest obstacle is probably the fact that c-lightning spawns several\nprocesses (subdaemons) and depends on the bitcoin-cli binary for bitcoind\nRPC. If WebAssembly supports multiple processes (not just threads) that's a\ngood start I guess.\n\nThere is a c-lightning specific mailing list on\nhttps://lists.ozlabs.org/listinfo/c-lightning\n\nCheers,\nIgor\n\nOn 12 April 2018 at 16:39, \u0411\u044b\u0445\u0443\u043d, \u0410\u043b\u0435\u043a\u0441\u0435\u0439 \u0412\u0438\u043a\u0442\u043e\u0440\u043e\u0432\u0438\u0447 <\naleksey.bykhun at phystech.edu> wrote:\n\n> Hi everyone!\n>\n> I am looking for a way to run a LN node inside the browser. One way would\n> be to implement BOLT protocol from scratch in JS, but I am thinking of a\n> more easy way.\n>\n> Has anyone succeed in compiling, for example, c-lightning project (\n> https://github.com/ElementsProject/lightning) under WebAssembly (\n> http://webassembly.org/getting-started/developers-guide/).\n>\n> WebAssembly is a C/C++ compiler into browser-compatible byte-code. It can\n> use JS-API, but can also work with low-level C functions.\n>\n> There are some things c-lighting does (e.g. sockets), that should stop it\n> from compiling easily. However, there are wrappers for many C-functions by\n> Emscripten lib: https://github.com/kripken/emscripten.\n>\n> My question is what should I look for when trying to run that? And also, I\n> want to hear your general feedback on the idea.\n>\n> Aleksey Bykhun.\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n\n\n-- \n*Igor Cota*\nCodex Apertus Ltd\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180423/03f76e6a/attachment.html>"
            },
            {
                "author": "Tyler H",
                "date": "2018-04-23T13:23:34",
                "message_text_only": "Aleksey,\n\nConsidering the security situation with browsers, I think a better approach\nwould be to write an extension that interfaces with a daemon already\nrunning on the system thrlugh REST or similar.\n\nLightning Charge would help here for c-lightning, or lnd has REST and gRPC\nbuilt in.\n\nThe key difference here is key msterial isn't accessed by the browser and\nsecured by the browser's pitiful security, but instead live in the usual\ndirectory and the daemon handles it normally.\n\nYou could even do something like the Tor Browser Bundle and bundle the\ndaemon with the browser in a neat package.\n\nThanks,\nTyler\n\nOn Mon, Apr 23, 2018, 02:27 Igor Cota <igor at codexapertus.com> wrote:\n\n> Hi Aleksey,\n>\n> Your biggest obstacle is probably the fact that c-lightning spawns several\n> processes (subdaemons) and depends on the bitcoin-cli binary for bitcoind\n> RPC. If WebAssembly supports multiple processes (not just threads) that's a\n> good start I guess.\n>\n> There is a c-lightning specific mailing list on\n> https://lists.ozlabs.org/listinfo/c-lightning\n>\n> Cheers,\n> Igor\n>\n> On 12 April 2018 at 16:39, \u0411\u044b\u0445\u0443\u043d, \u0410\u043b\u0435\u043a\u0441\u0435\u0439 \u0412\u0438\u043a\u0442\u043e\u0440\u043e\u0432\u0438\u0447 <\n> aleksey.bykhun at phystech.edu> wrote:\n>\n>> Hi everyone!\n>>\n>> I am looking for a way to run a LN node inside the browser. One way would\n>> be to implement BOLT protocol from scratch in JS, but I am thinking of a\n>> more easy way.\n>>\n>> Has anyone succeed in compiling, for example, c-lightning project (\n>> https://github.com/ElementsProject/lightning) under WebAssembly (\n>> http://webassembly.org/getting-started/developers-guide/).\n>>\n>> WebAssembly is a C/C++ compiler into browser-compatible byte-code. It can\n>> use JS-API, but can also work with low-level C functions.\n>>\n>> There are some things c-lighting does (e.g. sockets), that should stop it\n>> from compiling easily. However, there are wrappers for many C-functions by\n>> Emscripten lib: https://github.com/kripken/emscripten.\n>>\n>> My question is what should I look for when trying to run that? And also,\n>> I want to hear your general feedback on the idea.\n>>\n>> Aleksey Bykhun.\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>>\n>\n>\n> --\n> *Igor Cota*\n> Codex Apertus Ltd\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180423/80b156dd/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Lightning JavaScript implementation that conforms BOLT",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "\u0411\u044b\u0445\u0443\u043d, \u0410\u043b\u0435\u043a\u0441\u0435\u0439 \u0412\u0438\u043a\u0442\u043e\u0440\u043e\u0432\u0438\u0447",
                "Igor Cota",
                "Tyler H"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 5504
        }
    },
    {
        "title": "[Lightning-dev] Commitment delay asymmetry",
        "thread_messages": [
            {
                "author": "Jim Posen",
                "date": "2018-04-12T17:04:59",
                "message_text_only": "As specified in BOLT 3, in the commitment transactions the to_local output\nis time-locked with OP_CSV while the to_remote is a simple P2WPKH. The\nto_local output must be time-locked in order to allow the other party to\ncome online and sweep funds from a published revoked commitment. In the\ncase of an honest unilateral close, however, this wastes the time-value of\ncapital locked in the channel for the publisher but not the other party.\n\nThis seems to create perverse incentives where a party that goes offline\nand forces a unilateral close is not penalized and only the party that\nbroadcasts is. I see this as a problem in both normal operation and attack\nscenarios. Consider cases where the peer is misbehaving and the node needs\nto broadcast to chain. Concretely, consider a case where the other party\ndoes not send an update_fail_htlc after it expires. A rational node might\ndecide to just become unresponsive instead of broadcasting the commitment\nin the hopes that the other party publishes instead. Or if the value of the\nHTLC is sufficient, it would want to claim the time-locked output ASAP in\nwhich case the misbehaving peer is not punished and gets access to its\nfunds immediately.\n\nI find it easier to analyze the game theory of these situations if the\nto_remote output is also time-locked by the to_remote_delay. Making the\nconsequence of an on-chain settlement symmetric changes the game from\nchicken [1] to a tragedy of the commons [2]. I'm curious how other people\nthink about this.\n\n-jimpo\n\n[1] https://en.wikipedia.org/wiki/Chicken_(game)\n[2] https://en.wikipedia.org/wiki/Tragedy_of_the_commons\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180412/18ef498c/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2018-04-13T00:02:40",
                "message_text_only": "Jim Posen <jim.posen at gmail.com> writes:\n> I find it easier to analyze the game theory of these situations if the\n> to_remote output is also time-locked by the to_remote_delay. Making the\n> consequence of an on-chain settlement symmetric changes the game from\n> chicken [1] to a tragedy of the commons [2]. I'm curious how other people\n> think about this.\n\nIt does increase incentive to mutual close, and it makes some kinds of\nsense: A tells B what the delay is, so having A subject to it too is\nfair.\n\nBy extension, perhaps both sides should use the maximum delay either one\nasks for?\n\nI don't think it's urgent, but please put it into the brainstorming part\nof the wiki so we don't lose track?[1]\n\nCheers,\nRusty.\n[1] Which someone should organize into a new \"proposals\" page.."
            },
            {
                "author": "Jim Posen",
                "date": "2018-04-13T22:10:16",
                "message_text_only": "> By extension, perhaps both sides should use the maximum delay either one\n> asks for?\n>\n\nI'm not sure that is necessary. As long as both parties have to wait the\nsame amount of time regardless of whether they publish the commitment or\nthe other side does, that would resolve the issue.\n\n\n> I don't think it's urgent, but please put it into the brainstorming part\n> of the wiki so we don't lose track?[1]\n>\n\nI don't have access to add to the wiki. I'd write a section like:\n\n# Symmetric CSV Delay\n\nChange the script of the remote output of all commitment transactions to\nrequire the full CSV delay. This acts as further incentive for both parties\nto mutually close instead of waiting for the other side to unilaterally\nclose, and serves as punishment to misbehaving or unresponsive nodes that\nforce the other endpoint to go to chain.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180413/d373d903/attachment.html>"
            },
            {
                "author": "Daniel McNally",
                "date": "2018-04-14T04:17:18",
                "message_text_only": "This makes a lot of sense to me as a way to correct the incentives for\nclosing channels. I figure that honest nodes that have truly gone offline\nwill not require (or be able to take advantage of) immediate access to\ntheir balance, such that this change shouldn't cause too much inconvenience.\n\nI was trying to think if this could open up a DOS vector - dishonest nodes\nperforming unilateral closes even when mutual closes are possible just to\nlock up the other side's coins - but it seems like not much of a concern. I\nfigure it's hard to pull off on a large scale.\n\nDaniel\n\nOn Fri, Apr 13, 2018, 6:10 PM Jim Posen <jim.posen at gmail.com> wrote:\n\n>\n> By extension, perhaps both sides should use the maximum delay either one\n>> asks for?\n>>\n>\n> I'm not sure that is necessary. As long as both parties have to wait the\n> same amount of time regardless of whether they publish the commitment or\n> the other side does, that would resolve the issue.\n>\n>\n>> I don't think it's urgent, but please put it into the brainstorming part\n>> of the wiki so we don't lose track?[1]\n>>\n>\n> I don't have access to add to the wiki. I'd write a section like:\n>\n> # Symmetric CSV Delay\n>\n> Change the script of the remote output of all commitment transactions to\n> require the full CSV delay. This acts as further incentive for both parties\n> to mutually close instead of waiting for the other side to unilaterally\n> close, and serves as punishment to misbehaving or unresponsive nodes that\n> force the other endpoint to go to chain.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180414/96622c6e/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-15T13:35:55",
                "message_text_only": "Good morning Daniel,\n\n> This makes a lot of sense to me as a way to correct the incentives for closing channels. I figure that honest nodes that have truly gone offline will not require (or be able to take advantage of) immediate access to their balance, such that this change shouldn't cause too much inconvenience.\n>\n> I was trying to think if this could open up a DOS vector - dishonest nodes performing unilateral closes even when mutual closes are possible just to lock up the other side's coins - but it seems like not much of a concern. I figure it's hard to pull off on a large scale.\n\nNow that you bring this up, I think, it is indeed a concern, and one we should not take lightly.\n\nAs a purely selfish rational being, it matters not to me whether my commitment transaction will delay your output or not; all that matters is that it delays mine, and that is enough for me to prefer a bilateral close if possible.  I think we do not need to change commitment transactions to be symmetrical then --- it is enough that the one holding the commitment transaction has its own outputs delayed.\n\nIf I had a goal to disrupt rather than cooperate with the Lightning Network, and commitment transactions would also delay the side not holding the commitment transaction (i.e. \"symmetrical delay\" commitments), I would find it easier to disrupt cheaply if I could wait for a channel to be unbalanced in your favor (i.e. you own more money on it than I do), then lock up both our funds by doing a unilateral transaction.  Since it is unbalanced in your favor, you end up losing more utility than I do.  Indeed, in the situation where you are funding a new channel to me, I have 0 satoshi on the channel and can perform this attack costlessly.\n\nNow perhaps one may argue, in the case of asymmetric delays, that if I were evil, I could still disrupt the network by misbehaving and forcing the other side to push its commitment transaction.  Indeed I could even just accept a channel and then always fail to forward any payment you try to make over it, performing a disruption costlessly too (as I have no money in this).  But this attack is somewhat more passive than the above attack under a symmetrical delay commitment transaction scheme.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180415/bc7a2473/attachment.html>"
            },
            {
                "author": "Jim Posen",
                "date": "2018-04-15T18:37:05",
                "message_text_only": "I believe that anyone attempting a DOS by forcing on-chain settlement can\ndo it just as easily with asymmetric delays than with symmetric delays.\n\nIf my goal is to waste the time-value of your money in a channel, in a\nworld with symmetric delays, I could just publish the commitment\ntransaction and you would have to wait the full delay for access to your\nfunds. True. But with delays asymmetric as they are now, I can just as\neasily refuse to participate in a mutual close, forcing you to close\non-chain. This is just as bad. In fact, I'd argue that it is worse, because\nI lose less by doing this (in the sense that I as the attacker get\nimmediate access to my funds). So in my assessment, it is a very active\nattack and symmetric delays are something of a mitigation. You are right\nthat the balance of funds in the channel becomes a factor too, but note\nthat there is the reserve balance, so I'm always losing access to some\nfunds for some time.\n\n-jimpo\n\nOn Sun, Apr 15, 2018 at 6:35 AM, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Daniel,\n>\n>\n> This makes a lot of sense to me as a way to correct the incentives for\n> closing channels. I figure that honest nodes that have truly gone offline\n> will not require (or be able to take advantage of) immediate access to\n> their balance, such that this change shouldn't cause too much inconvenience.\n>\n> I was trying to think if this could open up a DOS vector - dishonest nodes\n> performing unilateral closes even when mutual closes are possible just to\n> lock up the other side's coins - but it seems like not much of a concern. I\n> figure it's hard to pull off on a large scale.\n>\n>\n>\n> Now that you bring this up, I think, it is indeed a concern, and one we\n> should not take lightly.\n>\n> As a purely selfish rational being, it matters not to me whether my\n> commitment transaction will delay your output or not; all that matters is\n> that it delays mine, and that is enough for me to prefer a bilateral close\n> if possible.  I think we do not need to change commitment transactions to\n> be symmetrical then --- it is enough that the one holding the commitment\n> transaction has its own outputs delayed.\n>\n> If I had a goal to disrupt rather than cooperate with the Lightning\n> Network, and commitment transactions would also delay the side not holding\n> the commitment transaction (i.e. \"symmetrical delay\" commitments), I would\n> find it easier to disrupt cheaply if I could wait for a channel to be\n> unbalanced in your favor (i.e. you own more money on it than I do), then\n> lock up both our funds by doing a unilateral transaction.  Since it is\n> unbalanced in your favor, you end up losing more utility than I do.\n> Indeed, in the situation where you are funding a new channel to me, I have\n> 0 satoshi on the channel and can perform this attack costlessly.\n>\n> Now perhaps one may argue, in the case of asymmetric delays, that if I\n> were evil, I could still disrupt the network by misbehaving and forcing the\n> other side to push its commitment transaction.  Indeed I could even just\n> accept a channel and then always fail to forward any payment you try to\n> make over it, performing a disruption costlessly too (as I have no money in\n> this).  But this attack is somewhat more passive than the above attack\n> under a symmetrical delay commitment transaction scheme.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180415/f52b7c35/attachment.html>"
            },
            {
                "author": "Daniel McNally",
                "date": "2018-04-15T19:52:13",
                "message_text_only": "Thanks ZmnSCPxj and Jim,\n\n> Indeed, in the situation where you are funding a new channel to me, I have 0 satoshi on the channel and can perform this attack costlessly.\n\nMy thinking here is that an attacker would have a hard time getting\nothers to open new channels with them, and that even when others do\nthere are other ways to misbehave as you mentioned.\n\nOtherwise I agree with Jim and the asymmetry seems more of a concern.\nI haven't fully thought this through yet, but one thought might be to\nscale the other side's delay according to the balance of the channel.\nFor example, in the case where the side unilaterally closing the\nchannel has zero balance, the other side gets no delay and symmetry as\nmeasured by (coins locked) * (duration of lock) equals zero on both\nsides. When the side closing the channel has at least 50% of the\nbalance, both sides must wait the full delay. Thoughts?\n\nDaniel"
            },
            {
                "author": "Ariel Lorenzo-Luaces",
                "date": "2018-04-15T20:00:38",
                "message_text_only": "Letting the attacker have immediate access to their funds is a null point because the attacker always has the preparation time to unbalance the channel to the honest node's favor. The attacker's 'funds' in this case is trivially reduced to 'reserve balance'. It's hard to argue that forcing the malicious node to wait for the delay before having access to their reserve balance is disincentive enough to not perform the attack.\n\nCheers\nAriel Lorenzo-Luaces\n\n\nOn Apr 15, 2018, 11:37 AM, at 11:37 AM, Jim Posen <jim.posen at gmail.com> wrote:\n>I believe that anyone attempting a DOS by forcing on-chain settlement\n>can\n>do it just as easily with asymmetric delays than with symmetric delays.\n>\n>If my goal is to waste the time-value of your money in a channel, in a\n>world with symmetric delays, I could just publish the commitment\n>transaction and you would have to wait the full delay for access to\n>your\n>funds. True. But with delays asymmetric as they are now, I can just as\n>easily refuse to participate in a mutual close, forcing you to close\n>on-chain. This is just as bad. In fact, I'd argue that it is worse,\n>because\n>I lose less by doing this (in the sense that I as the attacker get\n>immediate access to my funds). So in my assessment, it is a very active\n>attack and symmetric delays are something of a mitigation. You are\n>right\n>that the balance of funds in the channel becomes a factor too, but note\n>that there is the reserve balance, so I'm always losing access to some\n>funds for some time.\n>\n>-jimpo\n>\n>On Sun, Apr 15, 2018 at 6:35 AM, ZmnSCPxj <ZmnSCPxj at protonmail.com>\n>wrote:\n>\n>> Good morning Daniel,\n>>\n>>\n>> This makes a lot of sense to me as a way to correct the incentives\n>for\n>> closing channels. I figure that honest nodes that have truly gone\n>offline\n>> will not require (or be able to take advantage of) immediate access\n>to\n>> their balance, such that this change shouldn't cause too much\n>inconvenience.\n>>\n>> I was trying to think if this could open up a DOS vector - dishonest\n>nodes\n>> performing unilateral closes even when mutual closes are possible\n>just to\n>> lock up the other side's coins - but it seems like not much of a\n>concern. I\n>> figure it's hard to pull off on a large scale.\n>>\n>>\n>>\n>> Now that you bring this up, I think, it is indeed a concern, and one\n>we\n>> should not take lightly.\n>>\n>> As a purely selfish rational being, it matters not to me whether my\n>> commitment transaction will delay your output or not; all that\n>matters is\n>> that it delays mine, and that is enough for me to prefer a bilateral\n>close\n>> if possible.  I think we do not need to change commitment\n>transactions to\n>> be symmetrical then --- it is enough that the one holding the\n>commitment\n>> transaction has its own outputs delayed.\n>>\n>> If I had a goal to disrupt rather than cooperate with the Lightning\n>> Network, and commitment transactions would also delay the side not\n>holding\n>> the commitment transaction (i.e. \"symmetrical delay\" commitments), I\n>would\n>> find it easier to disrupt cheaply if I could wait for a channel to be\n>> unbalanced in your favor (i.e. you own more money on it than I do),\n>then\n>> lock up both our funds by doing a unilateral transaction.  Since it\n>is\n>> unbalanced in your favor, you end up losing more utility than I do.\n>> Indeed, in the situation where you are funding a new channel to me, I\n>have\n>> 0 satoshi on the channel and can perform this attack costlessly.\n>>\n>> Now perhaps one may argue, in the case of asymmetric delays, that if\n>I\n>> were evil, I could still disrupt the network by misbehaving and\n>forcing the\n>> other side to push its commitment transaction.  Indeed I could even\n>just\n>> accept a channel and then always fail to forward any payment you try\n>to\n>> make over it, performing a disruption costlessly too (as I have no\n>money in\n>> this).  But this attack is somewhat more passive than the above\n>attack\n>> under a symmetrical delay commitment transaction scheme.\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>\n>\n>------------------------------------------------------------------------\n>\n>_______________________________________________\n>Lightning-dev mailing list\n>Lightning-dev at lists.linuxfoundation.org\n>https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180415/2b1c8937/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-16T03:52:48",
                "message_text_only": "Good morning all,\n\nIt seems to me the below two worlds are possible:\n\n1.  Symmetric delays.\n1.1.  I can attack passively: I force a condition where most funds are in the other side (e.g. forwarding to another node I control, or exchanging BTC for material goods), then stop forwarding payments and generally being a pest.  The other side closes unilaterally in frustration (locking its funds) and I get penalized by having my (smaller, in my case) amount locked for some blocks.\n1.2.  I can attack actively: I force a condition where most funds are in the other side, then unilaterally close the channel (locking my counterparty funds).  I get penalized by having my smaller amount locked for some blocks.\n\n2.  Asymmetric delays.\n2.1.  I can attack passively: I force a condition where most funds are in the other side (e.g. forwarding to another node I control, or exchanging BTC for material goods), then stop forwarding payments and generally being a pest.  The other side closes unilaterally in frustration (locking its funds) and I do not get penalized.\n\nIt seems to me that adding an entire new attack vector in order to only *mitigate* (not eliminate!) another attack vector is not a good enough trade-off.  In particular the new attack seems *easier* to perform.  The current attack where I annoy the other side until it closes has the risk that the other side may have a high tolerance for annoyance, and decide not to close the channel unilaterally anyway.  But in a symmetric-delay world, I do not have to wait for the other side to get annoyed: I just trigger the lockup period immediately in the active attack.\n\n--\n\n> For example, in the case where the side unilaterally closing the channel has zero balance, the other side gets no delay and symmetry as measured by (coins locked) * (duration of lock) equals zero on both sides. When the side closing the channel has at least 50% of the balance, both sides must wait the full delay. Thoughts?\n\nSo on channel setup where I am the funder to a 1BTC  channel I make to Daniel:\n\n* Daniel holds a commitment transaction with: ZmnSCPxj=1BTC+no delay, Daniel=0BTC+no delay\n* I hold a commitment transaction with: ZmnSCPxj=1BTC+no delay, Daniel=0BTC+no delay\n\nIn order to make the symmetry \"(coins locked) * (duration of lock)\" equal on both sides of the commitment transaction (after all, Daniel has 0 BTC, so the product 0BTC * anything is 0, so I should not be penalized with a delay on my output of the commitment transaction).\n\nThen I send 0.99BTC to Daniel for 0.99BTC of Daniel products.\n\nThen I publish my original, revoked, commitment transaction with ZmnSCPxj=1BTC+no delay, Danel=0BTC+no delay\n\nSince there is no delay involved in my branch, I can get the money immediately without Daniel being able to revoke it.  So I get 1.0BTC and 0.99BTC worth of Daniel products.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180415/a224bd0f/attachment.html>"
            },
            {
                "author": "Daniel McNally",
                "date": "2018-04-16T04:39:20",
                "message_text_only": "> Since there is no delay involved in my branch, I can get the money\n> immediately without Daniel being able to revoke it.  So I get 1.0BTC and\n> 0.99BTC worth of Daniel products.\n\nPerhaps I should have clarified, the side unilaterally closing the\nchannel would always have to wait for the full delay to allow time for\nrevoke transactions to be broadcast, preventing the scenario you bring\nup. It's a matter of what delay is imposed on the other side.\n\nMy understanding is that, currently, each channel has an agreed upon\nCSV delay and each side's commitment transaction(s) has this delay for\ntheir own output only. Jim's suggesting to apply this same delay to\nthe remote output as well. I'm wondering if it would make more sense\nto scale the delay on the remote output according to the balance\ndistribution (while leaving the local outputs with the full delay) to\navoid the situation where a misbehaving node can unilaterally close\nchannels where it has little or no balance, thereby locking up the\nfunds of the remote node at virtually no cost to itself. The delay on\nthe remote output would scale from zero delay (what it always is\ncurrently) up to the same delay as the side unilaterally closing the\nchannel. That wouldn't always make it completely symmetric (at least\nin terms of coins locked * duration of lock), but it seems like an\nimprovement.\n\nDaniel"
            },
            {
                "author": "Jim Posen",
                "date": "2018-04-16T04:42:49",
                "message_text_only": ">\n> It seems to me that adding an entire new attack vector in order to only\n> *mitigate* (not eliminate!) another attack vector is not a good enough\n> trade-off.  In particular the new attack seems *easier* to perform.  The\n> current attack where I annoy the other side until it closes has the risk\n> that the other side may have a high tolerance for annoyance, and decide not\n> to close the channel unilaterally anyway.  But in a symmetric-delay world,\n> I do not have to wait for the other side to get annoyed: I just trigger the\n> lockup period immediately in the active attack.\n>\n\nI don't see the two attacks in the symmetric case as any different from one\nanother. In 1.1, you force a unilateral close by becoming unresponsive and\nforcing the other side to eventually broadcast the commitment. In this case\nyou waste the other party's channel balance for the full time of the delay\nPLUS the additional time they wait around to determine if you are ever\ngoing to come online. In 1.2, you force a unilateral close by broadcasting\nyourself. This is actually a weaker attack because the other party only has\nto wait for the delay period and there is no uncertainty about when they\nwill get access to funds. So basically, I see no reason for an attacker to\never choose 1.2 over 1.1.\n\nSo the question is whether 1.1 or 2.1 is a worse DOS. To me it's pretty\nclear that it is 2.1 because the attacker does not get penalized and can\nfor more quickly use any remaining channel balance to open a new channel\nwith someone else and start over.\n\nI also would not classify 1.1 nor 2.1 as a passive attack -- the attacker\nis proactively rebalancing the victim's channel balances in order to waste\nthe maximal amount of time-money. Passive attacks [1] are where an attacker\ndoes not directly interact with the victim and just eavesdrops or tries to\nobserve and extract information.\n\n\n> > For example, in the case where the side unilaterally closing the channel\n> has zero balance, the other side gets no delay and symmetry as measured by\n> (coins locked) * (duration of lock) equals zero on both sides. When the\n> side closing the channel has at least 50% of the balance, both sides must\n> wait the full delay. Thoughts?\n>\n> So on channel setup where I am the funder to a 1BTC  channel I make to\n> Daniel:\n>\n> * Daniel holds a commitment transaction with: ZmnSCPxj=1BTC+no delay,\n> Daniel=0BTC+no delay\n> * I hold a commitment transaction with: ZmnSCPxj=1BTC+no delay,\n> Daniel=0BTC+no delay\n>\n\nI rather like Daniel's suggestion to scale the delay in proportion to the\ntime-money lost by the broadcasting party. Essentially, the delay just\nserves as punishment, so we should ensure that the punishment delivered is\nno greater than the time-value lost by the initiator of the unilateral\nclose.\n\nThis example is not quite right: the commitment delays do not need to be\nthe same in both commitment transaction with this scaling strategy. So the\ndelay for the local output is ALWAYS the to_local_delay, as it is in the\nBOLT 3 spec today. When assigning the delay on the remote output, however,\ninstead of using 0 as BOLT specifies now or to_remote_delay as I originally\nproposed, a better rule might be min(to_remote_delay, to_local_delay *\nto_local_value / to_remote_value). So the delay is never worse than what\nthe opposite side would get by broadcasting themself, but is the punishment\nduration is reduced if the attacker broadcasts a commitment transaction in\nwhich the balance of funds is skewed towards the victim's end of the\nchannel. However, I'm not sure how much this matters because as I argued\nabove, an attacker should always prefer to become unresponsive rather than\nbroadcast the commitment themself.\n\n[1] https://en.wikipedia.org/wiki/Passive_attack\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180415/b2c9ac05/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-16T11:56:16",
                "message_text_only": "Good morning Jim,\n\n>> It seems to me that adding an entire new attack vector in order to only *mitigate* (not eliminate!) another attack vector is not a good enough trade-off.  In particular the new attack seems *easier* to perform.  The current attack where I annoy the other side until it closes has the risk that the other side may have a high tolerance for annoyance, and decide not to close the channel unilaterally anyway.  But in a symmetric-delay world, I do not have to wait for the other side to get annoyed: I just trigger the lockup period immediately in the active attack.\n>\n> I don't see the two attacks in the symmetric case as any different from one another. In 1.1, you force a unilateral close by becoming unresponsive and forcing the other side to eventually broadcast the commitment. In this case you waste the other party's channel balance for the full time of the delay PLUS the additional time they wait around to determine if you are ever going to come online. In 1.2, you force a unilateral close by broadcasting yourself. This is actually a weaker attack because the other party only has to wait for the delay period and there is no uncertainty about when they will get access to funds. So basically, I see no reason for an attacker to ever choose 1.2 over 1.1.\n\nYou make a good point there, I understand.\n\n>>> For example, in the case where the side unilaterally closing the channel has zero balance, the other side gets no delay and symmetry as measured by (coins locked) * (duration of lock) equals zero on both sides. When the side closing the channel has at least 50% of the balance, both sides must wait the full delay. Thoughts?\n>>\n>> So on channel setup where I am the funder to a 1BTC  channel I make to Daniel:\n>>\n>> * Daniel holds a commitment transaction with: ZmnSCPxj=1BTC+no delay, Daniel=0BTC+no delay\n>> * I hold a commitment transaction with: ZmnSCPxj=1BTC+no delay, Daniel=0BTC+no delay\n>\n> I rather like Daniel's suggestion to scale the delay in proportion to the time-money lost by the broadcasting party. Essentially, the delay just serves as punishment, so we should ensure that the punishment delivered is no greater than the time-value lost by the initiator of the unilateral close.\n>\n> This example is not quite right: the commitment delays do not need to be the same in both commitment transaction with this scaling strategy. So the delay for the local output is ALWAYS the to_local_delay, as it is in the BOLT 3 spec today. When assigning the delay on the remote output, however, instead of using 0 as BOLT specifies now or to_remote_delay as I originally proposed, a better rule might be min(to_remote_delay, to_local_delay * to_local_value / to_remote_value). So the delay is never worse than what the opposite side would get by broadcasting themself, but is the punishment duration is reduced if the attacker broadcasts a commitment transaction in which the balance of funds is skewed towards the victim's end of the channel. However, I'm not sure how much this matters because as I argued above, an attacker should always prefer to become unresponsive rather than broadcast the commitment themself.\n\nThis seems complicated, so perhaps just make delays equal as in the original proposal.  Of course, each side has its own `to_self_delay` that currently is applied to the other side.  It seems best the rule:\n\nIf I impose a specific `to_self_delay`, that applies to your commitment transaction, but for both branches of that.\n\nMy commitment transaction will have delays from your `to_self_delay` setting.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180416/c7cd50b7/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Commitment delay asymmetry",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Daniel McNally",
                "Ariel Lorenzo-Luaces",
                "Rusty Russell",
                "Jim Posen",
                "ZmnSCPxj"
            ],
            "messages_count": 12,
            "total_messages_chars_count": 28946
        }
    },
    {
        "title": "[Lightning-dev] Decker-Wattenhofer channels (was: An Idea to Improve Connectivity of the Graph)",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-13T13:41:32",
                "message_text_only": "Good morning Christian,\n\nI wonder suddenly, about how HTLCs are offered under Decker-Wattenhofer Duplex Micropayment Channels.\n\nUnder the Decker-Wattenhofer construction, I believe the transaction sequence is the below:\n\nfunding -> trigger -> (relative-timelock) invalidation tree -> ... (relative-timelock) invalidation tree\n\nThe outputs of the final invalidation tree transaction splits up the contents of the funds between the payer and payee in the individual simplex channels that compose the duplex channels.\n\nHowever, HTLCs have an absolute timelock, so I am uncertain how those are forced into compatibility with the relative timelock the invalidation tree uses.\n\nUnder Poon-Dryja channels, the relative-timelock exists only on the claim transaction after a unilateral commitment transaction.  HTLCs are offered as outputs of the unilateral commitment transaction, so that the relative-timelock on the main output does not interfere with their normal operation (apparently the HTLCs offered can also be revoked, incidentally, though I have not studied them in detail: apparently unrevoked HTLC paths that go to ourself have an extra CSV in the HTLC-timeout and HTLC-success paths: but in any case the HTLC-timeout case, the relative timelock is relative to the absolute one that comes first).\n\nThis is of concern as this seems likely to affect Burchert-Decker-Wattenhofer channel factories, which use invalidation trees internally also, which come before the HTLCs they eventually pay out to.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Christian Decker",
                "date": "2018-04-13T20:51:54",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n\n> Good morning Christian,\n>\n> I wonder suddenly, about how HTLCs are offered under\n> Decker-Wattenhofer Duplex Micropayment Channels.\n>\n> Under the Decker-Wattenhofer construction, I believe the transaction\n> sequence is the below:\n>\n> funding -> trigger -> (relative-timelock) invalidation tree -> ... (relative-timelock) invalidation tree\n>\n> The outputs of the final invalidation tree transaction splits up the\n> contents of the funds between the payer and payee in the individual\n> simplex channels that compose the duplex channels.\n\nLet's drop the simple micropayment channel from the end and just\nconsider the update mechanism. They are just an optimisation, and we can\ndo without, just updating from one state to the next state.\n\n> However, HTLCs have an absolute timelock, so I am uncertain how those\n> are forced into compatibility with the relative timelock the\n> invalidation tree uses.\n\nThat is a very good observation. Indeed the absolute timelocks need to\nbe far enough in the future so that we can commit the latest branch of\nthe invalidation tree on-chain and then commit the HTLC resolution\nbefore the HTLC timeout expires. That means that if we have a CLTV of\n1000, a timelock range of 144 blocks (sum of the CSVs along the branch)\nand a delta (security parameters of 6 blocks), then we would need to\nstart settling on-chain at depth 850 (144 timelock range + 6 blocks to\nresolve the HTLC). So if we didn't resolve and remove the HTLC by block\nheight 850 we would initiate the settlement. This is similar to the\nrequirement to go on chain when an HTLC fails to resolve in time in LN,\ncompounded by the need to drop earlier since we need to commit the tree\nbranch as well.\n\n> Under Poon-Dryja channels, the relative-timelock exists only on the\n> claim transaction after a unilateral commitment transaction.  HTLCs\n> are offered as outputs of the unilateral commitment transaction, so\n> that the relative-timelock on the main output does not interfere with\n> their normal operation (apparently the HTLCs offered can also be\n> revoked, incidentally, though I have not studied them in detail:\n> apparently unrevoked HTLC paths that go to ourself have an extra CSV\n> in the HTLC-timeout and HTLC-success paths: but in any case the\n> HTLC-timeout case, the relative timelock is relative to the absolute\n> one that comes first).\n\nNot really, the HTLC timeouts are also absolute, and require you to drop\non-chain in order to guarantee that all following hops resolve prior to\nyou resolving the incoming one.\n\n> This is of concern as this seems likely to affect\n> Burchert-Decker-Wattenhofer channel factories, which use invalidation\n> trees internally also, which come before the HTLCs they eventually pay\n> out to.\n\nYep, it is one of the reasons why I opted to join the Lightning camp :-)"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-15T14:04:38",
                "message_text_only": "Good morning Christian,\n> That is a very good observation. Indeed the absolute timelocks need to\n> \n> be far enough in the future so that we can commit the latest branch of\n> \n> the invalidation tree on-chain and then commit the HTLC resolution\n> \n> before the HTLC timeout expires. That means that if we have a CLTV of\n> \n> 1000, a timelock range of 144 blocks (sum of the CSVs along the branch)\n> \n> and a delta (security parameters of 6 blocks), then we would need to\n> \n> start settling on-chain at depth 850 (144 timelock range + 6 blocks to\n> \n> resolve the HTLC). So if we didn't resolve and remove the HTLC by block\n> \n> height 850 we would initiate the settlement. This is similar to the\n> \n> requirement to go on chain when an HTLC fails to resolve in time in LN,\n> \n> compounded by the need to drop earlier since we need to commit the tree\n> \n> branch as well.\n\nOuch.  The numbers look much much larger than the numbers we have as default in c-lightning.\n\n> \n> > Under Poon-Dryja channels, the relative-timelock exists only on the\n> > \n> > claim transaction after a unilateral commitment transaction. HTLCs\n> > \n> > are offered as outputs of the unilateral commitment transaction, so\n> > \n> > that the relative-timelock on the main output does not interfere with\n> > \n> > their normal operation (apparently the HTLCs offered can also be\n> > \n> > revoked, incidentally, though I have not studied them in detail:\n> > \n> > apparently unrevoked HTLC paths that go to ourself have an extra CSV\n> > \n> > in the HTLC-timeout and HTLC-success paths: but in any case the\n> > \n> > HTLC-timeout case, the relative timelock is relative to the absolute\n> > \n> > one that comes first).\n> \n> Not really, the HTLC timeouts are also absolute, and require you to drop\n> \n> on-chain in order to guarantee that all following hops resolve prior to\n> \n> you resolving the incoming one.\n\n\nI was referring to the below comparisons of Decker-Wattenhofer with an HTLC offered but timed out:\n\nfunding -> kickoff -> (relative-locktime) invalidation tree HTLC-offer -> (absolute-timelock) HTLC-timeout -> claim\n\nvs. Poon-Dryja:\n\nfunding -> commitment HTLC-offer -> (absolute-locktime) HTLC-timeout -> (relative-locktime) claim\n\nIndeed I was pleasantly surprised to find out that HTLC-timeout exists in the BOLT 3 spec, and is itself also revokable (and thus has a relative-locktime to claim it).  The relative-locktime on claiming the HTLC-timeout output is effectively appended to the absolute locktime and does not overlap with it, as in the Decker-Wattenhofer case, and allows it to be considered separately from the HTLC timeout.\n\n \n> > This is of concern as this seems likely to affect\n> > \n> > Burchert-Decker-Wattenhofer channel factories, which use invalidation\n> > \n> > trees internally also, which come before the HTLCs they eventually pay\n> > \n> > out to.\n> \n> Yep, it is one of the reasons why I opted to join the Lightning camp :-)\n\nWell, the Burchert-Decker-Wattenhofer channel factories have very nice theoretical numbers of how much blockspace they could save over just Lightning, and they use the invalidation tree structure.  I guess this simply leads back again to my original argument: we should have Burchert-Decker-Wattenhofer channel factories terminate into Poon-Dryja channels; we have the channel factories have a small number of updates so that the relative locktimes involved are kept small and this reflects the reality that we want to rearrange channels less often than we actually update them, and we use Poon-Dryja channels for the actual channels so that we keep the locktimes involved relatively small for the number of updates we can support.  We also have the precision, that the `cltv_delta` we report for a channel should be larger for channels created inside a channel factory, by the relative locktime consumed by the invalidation tree structure, precisely because of the relative locktimes along the way to the HTLC in the transaction.\n\nPerhaps we can simply not have channel factories allow channel reorganization?  Then we would not have an invalidation tree at all ( consuming no relative-locktime): we have a funding transaction that funds the entire factory that is confirmed onchain, then an offchain split transaction (non timelocked) that funds multiple channels, and finally commitment transactions that spend from the split transaction.  In the case of a unilateral close we save no blockspace, but in case of a multilateral close where all channel factory owners are available for closing we can collapse the split and commitment transactions into a single close transaction.  Indeed, perhaps for this we can impose (1) 3 or more members (2) each member puts an equal amount (3) channels are fixed in my favorite structure, a cyclic superhub.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Decker-Wattenhofer channels (was: An Idea to Improve Connectivity of the Graph)",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Decker",
                "ZmnSCPxj"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 9160
        }
    },
    {
        "title": "[Lightning-dev] Trustless WatchTowers?",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-16T03:32:43",
                "message_text_only": "Hi all,\n\nNicolas Dorier was requesting additional hooks in c-lightning for a simple WatchTower system: https://github.com/ElementsProject/lightning/issues/1353\n\nUnfortunately I was only able to provide an interface which requires a *trusted* WatchTower.  Trust is of course a five-letter word and should not be used in polite company.\n\nMy key problem is that I provide enough information to the WatchTower for the WatchTower to be able to create the justice transaction by itself.  If so, the WatchTower could just make the justice transaction output to itself and the counterparty, so that the WatchTower and the counterparty can cooperate to steal the channel funds: the counterparty publishes a revoked transaction, the WatchTower writes a justice transaction on it that splits the earnings between itself and the counterparty.\n\nIt seems to me, that the only safe way to implement a trustless WatchTower, is for the node to generate a fully-signed justice transaction, IMMEDIATELY after every commitment transaction is revoked, and transmit it to the WatchTower.  The WatchTower would have to store each and every justice transaction it received, and would not be able to compress it or use various techniques to store data efficiently.  The WatchTower would not have enough information to regenerate justice transactions (and in particular would not be able to create a travesty-of-justice transaction that pays out to itself rather than the protected party).  In practice this would require that node software also keep around those transactions until some process has ensured that the WatchTower has received the justice transactions.\n\nIs there a good way to make trustless WatchTowers currently or did this simply not reach BOLT v1.0?\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180415/51a0da32/attachment.html>"
            },
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2018-04-16T19:52:04",
                "message_text_only": "Hi ZmnSCPxj,\n\n> It seems to me, that the only safe way to implement a trustless\nWatchTower,\n> is for the node to generate a fully-signed justice transaction,\nIMMEDIATELY\n> after every commitment transaction is revoked, and transmit it to the\n> WatchTower.\n\nNo, one doesn't need to transmit the entire justice transaction. Instead,\nthe client simply sends out the latest items in the script template, and a\nseries of _signatures_ for the various breach outputs. The pre-generated\nsignature means that the server is *forced* to reproduce the justice\ntransaction that satisfies the latest template and signature. Upfront, free\nparameters such as breach bonus (or w/e else) can be negotiated.\n\n> The WatchTower would have to store each and every justice transaction it\n> received, and would not be able to compress it or use various techniques\nto\n> store data efficiently.\n\nIn our current implementation, we've abandoned the \"savings\" from\ncompressing the shachain/elkrem tree. When one factors in the space\ncomplexity due the *just* the commitment signatures, the savings from\ncompression become less attractive. Going a step father, once you factor in\nthe space complexity of the 2-stage HTLC claims, then the savings from\ncompressing the revocation tree become insignificant.\n\nIt's also worth pointing out that if the server is able to compress the\nrevocation tree, then their necessarily linking new breach payloads with a\nparticular channel. Another downside, is that if you go to revocation tree\ncompression, then all updates *must* be sent in order, and updates cannot be\n*skipped*.\n\nAs a result of these downside, our current implementation goes back to the\nol' \"encrypted blob\" approach. One immediate benefit with this approach is\nthat the outsourcing protocol isn't so coupled with the current _commitment\nprotocol_. Instead, the internal payload can be typed, allowing the server\nto dispatch the proper breach protocol based on the commitment type. The\nblob approach can also support a \"swap\" protocol which is required for\ncommitment designs that allow for O(1) outsourcer state per-client, like the\nscheme I presented at the last Scaling Bitcoin.\n\n-- Laolu\n\n\nOn Sun, Apr 15, 2018 at 8:32 PM ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Hi all,\n>\n> Nicolas Dorier was requesting additional hooks in c-lightning for a simple\n> WatchTower system:\n> https://github.com/ElementsProject/lightning/issues/1353\n>\n> Unfortunately I was only able to provide an interface which requires a\n> *trusted* WatchTower.  Trust is of course a five-letter word and should not\n> be used in polite company.\n>\n> My key problem is that I provide enough information to the WatchTower for\n> the WatchTower to be able to create the justice transaction by itself.  If\n> so, the WatchTower could just make the justice transaction output to itself\n> and the counterparty, so that the WatchTower and the counterparty can\n> cooperate to steal the channel funds: the counterparty publishes a revoked\n> transaction, the WatchTower writes a justice transaction on it that splits\n> the earnings between itself and the counterparty.\n>\n> It seems to me, that the only safe way to implement a trustless\n> WatchTower, is for the node to generate a fully-signed justice transaction,\n> IMMEDIATELY after every commitment transaction is revoked, and transmit it\n> to the WatchTower.  The WatchTower would have to store each and every\n> justice transaction it received, and would not be able to compress it or\n> use various techniques to store data efficiently.  The WatchTower would not\n> have enough information to regenerate justice transactions (and in\n> particular would not be able to create a travesty-of-justice transaction\n> that pays out to itself rather than the protected party).  In practice this\n> would require that node software also keep around those transactions until\n> some process has ensured that the WatchTower has received the justice\n> transactions.\n>\n> Is there a good way to make trustless WatchTowers currently or did this\n> simply not reach BOLT v1.0?\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180416/ed660fae/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-16T23:30:27",
                "message_text_only": "Good morning Laolu,\n\n> Hi ZmnSCPxj,\n>\n>> It seems to me, that the only safe way to implement a trustless WatchTower,\n>> is for the node to generate a fully-signed justice transaction, IMMEDIATELY\n>> after every commitment transaction is revoked, and transmit it to the\n>> WatchTower.\n>\n> No, one doesn't need to transmit the entire justice transaction. Instead,\n> the client simply sends out the latest items in the script template, and a\n> series of _signatures_ for the various breach outputs. The pre-generated\n> signature means that the server is *forced* to reproduce the justice\n> transaction that satisfies the latest template and signature. Upfront, free\n> parameters such as breach bonus (or w/e else) can be negotiated.\n\nThank you, I understand.\n\n> As a result of these downside, our current implementation goes back to the\n> ol' \"encrypted blob\" approach. One immediate benefit with this approach is\n> that the outsourcing protocol isn't so coupled with the current _commitment\n> protocol_. Instead, the internal payload can be typed, allowing the server\n> to dispatch the proper breach protocol based on the commitment type. The\n> blob approach can also support a \"swap\" protocol which is required for\n> commitment designs that allow for O(1) outsourcer state per-client, like the\n> scheme I presented at the last Scaling Bitcoin.\n\nCan you describe the \"encrypted blob\" approach to me? Or point me to materials?\n\nI imagine that in this case, the protected node hands a (txid, blob) pair to the WatchTower.  If the WatchTower sees a transaction that matches the given txid, it gets some information from the actual transaction to decrypt the blob (e.g. use the encrypted commitment index in `nLockTime` and `nSequence` as a decryption key); the blob is the justice transaction (or just a template type and its signatures as you describe above).\n\nDo you have a description of the WatchTower protocol used in lnd? It may be useful to be intercompatible.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180416/d6bc4c75/attachment.html>"
            },
            {
                "author": "Conner Fromknecht",
                "date": "2018-04-17T04:28:35",
                "message_text_only": "Hi ZmnSCPxj,\n\n> Can you describe the \"encrypted blob\" approach to me? Or point me to\n> materials?\n\nThere's an awesome watchtower thread on the mailing list from 2016 that\nstarts\nhere [1]. It covers a broader range of possibilities than just the encrypted\nblob approach, and also considers other revocation schemes, e.g. elkrem.\n\nSimilar to what you described, one encrypted blob approached discussed in\nthat thread is:\n1. hint = tixd[:16]\n2. blob = Enc(data, txid[16:])\n3. Send (hint, blob) to watchtower.\n\nWhenever a new block is mined, the watchtower checks if it has an entry for\neach\ntxid[:16]. If so, it decrypts using txid[16:], assembles the justice txn,\nand\nbroadcasts (assuming the reward output matches what was negotiated).\n\n> Do you have a description of the WatchTower protocol used in lnd? It may\nbe\n> useful to be intercompatible.\n\nWe don't have anything written up formally, though what we have currently\noperates on the design above.\n\nThere are more complex proposals discussed allowing an encrypted blob to\nreference data stored in a prior encrypted blob. Primary advantage would be\nreducing the storage costs of HTLCs present on multiple successive\ncommitment transactions; primary disadvantage is that it's significantly\nmore\ncomplex, in addition to the other points brought up by Laolu.\n\nI'm not positive as to the extent this approach was implemented/fleshed\nout, or\nif any other pros/cons may have been realized in the process. I haven't done\nnearly as much research as Tadge on that front, he's probably got some\nextensive thoughts on the tradeoffs.\n\n=======\n\nI'll also take this time to brain dump some recent investigations I've been\ndoing on\nwatchtowers. TL;DR @ fin.\n\nFWIW, I've been thinking about this in the context of the simple encrypted\nblob approach, though the observations can generalize to other schemes.\n\nAs Laolu mentioned, the storage requirement for the watchtower is dominated\nby\nthe number of HTLC signatures included in the encrypted blob. Due to\nindependence of the second stage transactions, there is a combinatoric\nblowup in\nthe number of signatures that would need to be pre-signed under the\nrevocation\nprivate key _if sweeping of HTLC outputs is batched_.\n\nIf we want to batch sweep without more liberal sighash flags, I think we'd\nneed to\npre-sign n*2^n signatures. There are 2^n possible ways that n HTLCs can\nstraddle\nthe first and second stages, and each permutation would require n distinct\nsignatures\nsince the set of inputs is unique to each permutation. Needless to say,\nthis isn't feasible\nwith the maximum number of HTLCs allowed in the protocol.\n\nHowever, I have some observations that might inform an efficient set of\nsignatures we can choose to include in the encrypted blobs.\n\nThe first is that the HTLC timeout or HTLC success transaction _must_ be\nbroadcast before the attacker can move funds back into their wallet. If\nthese transactions are never mined, it is actually fine to do nothing and\nleave\nthose outputs in the breached state.\n\nIf/when the victim comes back online, they themselves can sign and broadcast\na justice transaction that executes the revocation clause of either the\noffered or\nreceived HTLC scripts, based on the observed spentness of the various\ncommitment\nHLTC outputs at that time. So, we can save on signature data by only\nrequiring the\nwatchtower to act if second stage transactions are confirmed.\n\nOne reallyyy nice thing about not having the watchtower sweep the HTLC\n outputs\non the commitment txn directly is that it doesn't need to know how to\nreconstruct the more complex HTLC redeem scripts. It only needs to\nreconstruct\ncommitment to-local and second-stage to-local scripts and witnesses. This\nmeans\nthe blob primarily contains:\n - 1 revocation pubkey\n - 1 local delay pubkey\n - 1 CSV delay\n - 2 commitment signatures\n - n HTLC signatures\nand we don't have to bother sending CLTVs, local/remote htlc pubkeys, or\npayment hashes at all.\n\nThe storage for this ends up being something like ~100 + 64*(2+nhtlcs) when\nyou\ninclude other things like the sweep address.\n\nThe second observation is that the second stage transactions could be\nbroadcast\nsequentially such that the CSV delays don't overlap at all. In this event,\nthe\nwatchtower needs to sweep the HTLCs iteratively to prevent the attacker from\nsweeping any of the outputs as the relative timelocks expire.\n\nOne minimal solution could be to send signatures for independent sweep\ntransactions, allowing the watchtower to sweep each HTLC output\nindividually.\nThis is nice because it permits the watchtower to sweep exactly the subset\nof\nHTLCs that ever transition into the second stage, and under any permutation\nwrt. ordering of confirmed second stage transactions.\n\nWith the single transaction per HTLC approach, the total number of\nsignatures that\nare sent to the watchtower remains linear in the number HTLCs on the\ncommitment\ntransaction. This approach does have the downside of consuming slightly more\nfees, since each output is swept with a distinct transaction.\n\nHowever, this approach is fairly efficient in preventing the attacker\nentirely from\nmoving funds from the channel into their wallet wrt. to the amount of data\nstored.\nConsidering that the majority of the channel balance is expected to be in\nthe commitment outputs and that hypothetically on-chains fees are offset by\nthe\nremote balance, this could be an acceptable tradeoff.\n\nI suspect that in practice, most second stage transactions will be valid by\nthe\ntime an attacker would drop to chain. Because of this, it's possible that\nthey\ncould be mined in the same block as the breach transaction.\n\nIf everything is mined in the same block or in quick succession, it might be\nworthwhile to also pre-sign a justice txn that batch sweeps all HTLCs\ndirectly\nfrom the second layer, requiring one additional signature/HTLC.\n\nThis could be a plausible scenario if the offender breached\nunintentionally, and\ntheir implementation tries to proceed normally. However it does require all\nof the\nCSV delays to conincide. If that doesn't happen, the watchtower can always\nresort to sweeping the outputs individually.\n\nAll in all, I think the ability to sweep each HTLC independently is\nmore-or-less\na requirement just given the complexity of how the on-chain state-space can\nmanifest, especially if CLTVs have already expired. Other scenarios may\nbe worth including on a case by case basis or if we feel they are\njustified. This\ncould be handled dynamically by including some bitvector or some compact\nrepresentation of how to reconstruct the transactions for any additional,\nincluded\nsignatures.\n\nTL;DR: We can get away with just sweeping the second stage outputs. Sweeping\neach in a distinct txn avoids combinatoric blowup of trying to batch the\nsweeps. The\nstorage is linear in the number of HTLC outputs, and also reduces the data\nrequired\nto reconstruct the individual redeem scripts.\n\nAny feedback or additional insights would be greatly appreciated! Let me\nknow if\nI've overlooked anything critical :)\n\nCheers,\nConner\n\n[1] https://lists.linuxfoundation.org/pipermail/lightning-dev\n/2016-August/000565.html\n\n\nOn Mon, Apr 16, 2018 at 11:30 PM ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning Laolu,\n>\n>\n> Hi ZmnSCPxj,\n>\n> > It seems to me, that the only safe way to implement a trustless\n> WatchTower,\n> > is for the node to generate a fully-signed justice transaction,\n> IMMEDIATELY\n> > after every commitment transaction is revoked, and transmit it to the\n> > WatchTower.\n>\n> No, one doesn't need to transmit the entire justice transaction. Instead,\n> the client simply sends out the latest items in the script template, and a\n> series of _signatures_ for the various breach outputs. The pre-generated\n> signature means that the server is *forced* to reproduce the justice\n> transaction that satisfies the latest template and signature. Upfront, free\n> parameters such as breach bonus (or w/e else) can be negotiated.\n>\n>\n> Thank you, I understand.\n>\n> As a result of these downside, our current implementation goes back to the\n> ol' \"encrypted blob\" approach. One immediate benefit with this approach is\n> that the outsourcing protocol isn't so coupled with the current _commitment\n> protocol_. Instead, the internal payload can be typed, allowing the server\n> to dispatch the proper breach protocol based on the commitment type. The\n> blob approach can also support a \"swap\" protocol which is required for\n> commitment designs that allow for O(1) outsourcer state per-client, like\n> the\n> scheme I presented at the last Scaling Bitcoin.\n>\n>\n> Can you describe the \"encrypted blob\" approach to me? Or point me to\n> materials?\n>\n> I imagine that in this case, the protected node hands a (txid, blob) pair\n> to the WatchTower.  If the WatchTower sees a transaction that matches the\n> given txid, it gets some information from the actual transaction to decrypt\n> the blob (e.g. use the encrypted commitment index in `nLockTime` and\n> `nSequence` as a decryption key); the blob is the justice transaction (or\n> just a template type and its signatures as you describe above).\n>\n> Do you have a description of the WatchTower protocol used in lnd? It may\n> be useful to be intercompatible.\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180417/0da51a71/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-17T06:14:37",
                "message_text_only": "Good morning Conner,\n\n> Hi ZmnSCPxj,\n>\n>> Can you describe the \"encrypted blob\" approach to me? Or point me to\n>> materials?\n>\n> There's an awesome watchtower thread on the mailing list from 2016 that starts\n> here [1]. It covers a broader range of possibilities than just the encrypted\n> blob approach, and also considers other revocation schemes, e.g. elkrem.\n>\n> Similar to what you described, one encrypted blob approached discussed in\n> that thread is:1. hint = tixd[:16]2. blob = Enc(data, txid[16:])3. Send (hint, blob) to watchtower.\n>\n> Whenever a new block is mined, the watchtower checks if it has an entry for each\n> txid[:16]. If so, it decrypts using txid[16:], assembles the justice txn, andbroadcasts (assuming the reward output matches what was negotiated).\n\nThank you, that is indeed similar to what I was thinking given the name \"encrypted blob\".\n\nAlso, thank you for the link. I have not had much time to back-read anything older than 2017 in the archives. I observe that neither Poon nor Dryja seem to strongly participate in this list from 2017 onwards.\n\n>> Do you have a description of the WatchTower protocol used in lnd? It may be> useful to be intercompatible.\n> We don't have anything written up formally, though what we have currently\n> operates on the design above.\n\nI understand. It would be good to know what you have, and perhaps consider planning a new BOLT document for such.\n\nNicolas Dorier mentioned plans for BTCPay to somehow host \"merchant support networks\" where merchants may expose WatchTower endpoints, which other merchants may post revocation information for their channels to.\n\n> I'll also take this time to brain dump some recent investigations I've been doing on\n>\n> watchtowers. TL;DR @ fin.\n>\n> FWIW, I've been thinking about this in the context of the simple encrypted\n> blob approach, though the observations can generalize to other schemes.\n>\n> As Laolu mentioned, the storage requirement for the watchtower is dominated bythe number of HTLC signatures included in the encrypted blob. Due toindependence of the second stage transactions, there is a combinatoric blowup inthe number of signatures that would need to be pre-signed under the revocationprivate key _if sweeping of HTLC outputs is batched_.\n>\n> If we want to batch sweep without more liberal sighash flags, I think we'd need to\n> pre-sign n*2^n signatures. There are 2^n possible ways that n HTLCs can straddle\n> the first and second stages, and each permutation would require n distinct signatures\n> since the set of inputs is unique to each permutation. Needless to say, this isn't feasible\n> with the maximum number of HTLCs allowed in the protocol.\n\nYes, I thought this too.\n\n> However, I have some observations that might inform an efficient set of\n> signatures we can choose to include in the encrypted blobs.\n>\n> The first is that the HTLC timeout or HTLC success transaction _must_ bebroadcast before the attacker can move funds back into their wallet. If\n> these transactions are never mined, it is actually fine to do nothing and leave\n> those outputs in the breached state.\n>\n> If/when the victim comes back online, they themselves can sign and broadcast\n> a justice transaction that executes the revocation clause of either the offered or\n> received HTLC scripts, based on the observed spentness of the various commitmentHLTC outputs at that time. So, we can save on signature data by only requiring thewatchtower to act if second stage transactions are confirmed.\n\nThis is a good observation!  I initially thought that we would have to provide both the first-stage and second-stage revocation signatures.\n\n> One reallyyy nice thing about not having the watchtower sweep the HTLC outputson the commitment txn directly is that it doesn't need to know how toreconstruct the more complex HTLC redeem scripts. It only needs to reconstructcommitment to-local and second-stage to-local scripts and witnesses. This means\n> the blob primarily contains:\n>  - 1 revocation pubkey\n>  - 1 local delay pubkey\n>  - 1 CSV delay\n>  - 2 commitment signatures - n HTLC signatures\n> and we don't have to bother sending CLTVs, local/remote htlc pubkeys, or payment hashes at all.\n>\n> The storage for this ends up being something like ~100 + 64*(2+nhtlcs) when you\n> include other things like the sweep address.\n\nThank you, that seems like a start at something that can be implemented.\n\n> The second observation is that the second stage transactions could be broadcast\n> sequentially such that the CSV delays don't overlap at all. In this event, thewatchtower needs to sweep the HTLCs iteratively to prevent the attacker from\n> sweeping any of the outputs as the relative timelocks expire.\n\nSorry, I seem confused this idea.  Can you give example for commitment with 2x HTLC?\n\n> One minimal solution could be to send signatures for independent sweep\n> transactions, allowing the watchtower to sweep each HTLC output individually.\n> This is nice because it permits the watchtower to sweep exactly the subset ofHTLCs that ever transition into the second stage, and under any permutationwrt. ordering of confirmed second stage transactions.\n\nYes, this seems like a good general idea.\n\n> With the single transaction per HTLC approach, the total number of signatures thatare sent to the watchtower remains linear in the number HTLCs on the commitmenttransaction. This approach does have the downside of consuming slightly more\n> fees, since each output is swept with a distinct transaction.\n>\n> However, this approach is fairly efficient in preventing the attacker entirely from\n> moving funds from the channel into their wallet wrt. to the amount of data stored.\n> Considering that the majority of the channel balance is expected to be in\n> the commitment outputs and that hypothetically on-chains fees are offset by the\n> remote balance, this could be an acceptable tradeoff.\n>\n> I suspect that in practice, most second stage transactions will be valid by the time an attacker would drop to chain. Because of this, it's possible that they\n> could be mined in the same block as the breach transaction.\n>\n> If everything is mined in the same block or in quick succession, it might be\n> worthwhile to also pre-sign a justice txn that batch sweeps all HTLCs directlyfrom the second layer, requiring one additional signature/HTLC.\n> This could be a plausible scenario if the offender breached unintentionally, and their implementation tries to proceed normally. However it does require all of the\n> CSV delays to conincide. If that doesn't happen, the watchtower can alwaysresort to sweeping the outputs individually.\n>\n> All in all, I think the ability to sweep each HTLC independently is more-or-lessa requirement just given the complexity of how the on-chain state-space can manifest, especially if CLTVs have already expired. Other scenarios may\n> be worth including on a case by case basis or if we feel they are justified. This\n> could be handled dynamically by including some bitvector or some compact\n> representation of how to reconstruct the transactions for any additional, included\n> signatures.\n\nOkay.  So it seems, the blob contains:\n\n1.  Revocation pubkey (from our revocation basepoint and per-commitment basepoint)\n2.  Their delayed payment pubkey (needed in scripts)\n3.  Our imposed to_self_delay (the setting we indicate, that we impose on the remote side)\n4.  Our payment pubkey\n5.  0 or 1 or 2 signatures for the main outputs. These sign a single transaction that claims only the main outputs.\n6.  0 or more second-stage HTLC revocation signatures.  These sign individual transactions (one per HTLC) that claims only the second-stage HTLC output.\n7.  scriptpubkey to put all the funds in.\n\nWhen the commitment txid is found onchain, the WatchTower creates a single main output claim transaction using the 1 or 2 signatures for the main outputs.  And for each HTLC outpoint on the commitment transaction, if it gets spent, the WatchTower creates one HTLC justice transaction from the second-stage HTLC transaction.\n\nIs that approximately what is needed?  Have I missed anything?\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180417/441f5a17/attachment-0001.html>"
            },
            {
                "author": "Conner Fromknecht",
                "date": "2018-04-17T07:18:49",
                "message_text_only": "Good evening ZmnSCPxj,\n\n> Also, thank you for the link.\n\nDefinitely! I had to do some digging myself to recover these hidden gems.\n\n> I understand. It would be good to know what you have, and perhaps consider\n> planning a new BOLT document for such.\n\nYes, that is the ultimate goal. I think it might be a little to soon to\nhave a\nfull-on BOLT spec. There are still some implementation details that we would\nlike to address before formalizing everything. I am working to have\nsomething\nwritten up in the short-term documenting the approach[es] that ends up being\nsolidified. Hopefully that can get some eyes during development, and perhaps\nserve as working document/rough draft.\n\n> Sorry, I seem confused this idea.  Can you give example for commitment\nwith 2x\n> HTLC?\n\nSure thing! The confirmation of second level HTLC txns can be separated by\narbitrary delays. This is particularly true if the CLTVs have already\nexpired,\noffering an attacker total control over when the txns appear on the\nnetwork. One\nway this can happen is if the attacker iteratively broadcasts a single\nsecond-level txn, waits for confirmation and CSV to expire, then repeat with\nanother second-level txn.\n\nSince the CSVs begin ticking as soon as they are included in the chain, the\nattacker could try to sweep each one immediately after its CSV expires. If\nthe\nwatchtower doesn't have the ability to sweep outputs independently, it would\nhave no way to intercept this behavior, and prevent the breacher from\nsweeping\nindividual HTLCs sequentially.\n\n> When the commitment txid is found onchain, the WatchTower creates a single\n> main output claim transaction using the 1 or 2 signatures for the main\n> outputs.  And for each HTLC outpoint on the commitment transaction, if it\ngets\n> spent, the WatchTower creates one HTLC justice transaction from the\n> second-stage HTLC transaction.\n\nYes, this is how it would work in context of what I was suggesting.\nCertainly,\nthere are other ways to accomplish the same thing. I don't wish to claim\nthat\nthis is the best solution available, there are a lot of tradeoffs that need\nto be evaluated. I'm hoping that you and others can bring any shortcomings\nto\nlight and help us sift through them.\n\n> 5.  0 or 1 or 2 signatures for the main outputs. These sign a single\n> transaction that claims only the main outputs.\n\nYes, it seems necessary to separate the commitment outpoints from the HTLC\noutpoints in case the commitment txn is broadcasted before the CLTVs expire.\nYou could try to batch these with the HTLCs, but then we get back into\nexponential territory.\n\n> Is that approximately what is needed?  Have I missed anything?\n\nNope, I think your understanding is on point. IMO this seems to be a\nreasonable\ncompromise of the tradeoffs at hand, and definitely something that could\nserve\nas an initial iteration due to its simplicity. In the future, there\nare definitely\nways\nto improve on this on make it even more efficient! Though having a\nsolid/workable v0 is important if it is to be deployed. I enjoy hearing your\nthoughts on this, thank you for your responses!\n\nBest,\nConner\n\nOn Tue, Apr 17, 2018 at 6:14 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Conner,\n>\n>\n>\n>\n> Hi ZmnSCPxj,\n> > Can you describe the \"encrypted blob\" approach to me? Or point me to\n> > materials?\n>\n> There's an awesome watchtower thread on the mailing list from 2016 that\n> starts\n> here [1]. It covers a broader range of possibilities than just the\n> encrypted\n> blob approach, and also considers other revocation schemes, e.g. elkrem.\n>\n> Similar to what you described, one encrypted blob approached discussed in\n> that thread is:\n> 1. hint = tixd[:16]\n> 2. blob = Enc(data, txid[16:])\n> 3. Send (hint, blob) to watchtower.\n>\n> Whenever a new block is mined, the watchtower checks if it has an entry\n> for each\n> txid[:16]. If so, it decrypts using txid[16:], assembles the justice txn,\n> and\n> broadcasts (assuming the reward output matches what was negotiated).\n>\n>\n> Thank you, that is indeed similar to what I was thinking given the name\n> \"encrypted blob\".\n>\n> Also, thank you for the link. I have not had much time to back-read\n> anything older than 2017 in the archives. I observe that neither Poon nor\n> Dryja seem to strongly participate in this list from 2017 onwards.\n>\n>\n>\n> > Do you have a description of the WatchTower protocol used in lnd? It\n> may be\n> > useful to be intercompatible.\n> We don't have anything written up formally, though what we have currently\n> operates on the design above.\n>\n>\n> I understand. It would be good to know what you have, and perhaps consider\n> planning a new BOLT document for such.\n>\n> Nicolas Dorier mentioned plans for BTCPay to somehow host \"merchant\n> support networks\" where merchants may expose WatchTower endpoints, which\n> other merchants may post revocation information for their channels to.\n>\n>\n>\n> I'll also take this time to brain dump some recent investigations I've\n> been doing on\n>\n>\n>\n> watchtowers. TL;DR @ fin.\n>\n>\n>\n> FWIW, I've been thinking about this in the context of the simple encrypted\n> blob approach, though the observations can generalize to other schemes.\n>\n>\n>\n> As Laolu mentioned, the storage requirement for the watchtower is\n> dominated by\n> the number of HTLC signatures included in the encrypted blob. Due to\n> independence of the second stage transactions, there is a combinatoric\n> blowup in\n> the number of signatures that would need to be pre-signed under the\n> revocation\n> private key _if sweeping of HTLC outputs is batched_.\n>\n> If we want to batch sweep without more liberal sighash flags, I think we'd\n> need to\n> pre-sign n*2^n signatures. There are 2^n possible ways that n HTLCs can\n> straddle\n> the first and second stages, and each permutation would require n distinct\n> signatures\n> since the set of inputs is unique to each permutation. Needless to say,\n> this isn't feasible\n> with the maximum number of HTLCs allowed in the protocol.\n>\n>\n> Yes, I thought this too.\n>\n>\n>\n> However, I have some observations that might inform an efficient set of\n> signatures we can choose to include in the encrypted blobs.\n>\n>\n>\n> The first is that the HTLC timeout or HTLC success transaction _must_ be\n> broadcast before the attacker can move funds back into their wallet. If\n> these transactions are never mined, it is actually fine to do nothing and\n> leave\n> those outputs in the breached state.\n>\n> If/when the victim comes back online, they themselves can sign and\n> broadcast\n> a justice transaction that executes the revocation clause of either the\n> offered or\n> received HTLC scripts, based on the observed spentness of the various\n> commitment\n> HLTC outputs at that time. So, we can save on signature data by only\n> requiring the\n> watchtower to act if second stage transactions are confirmed.\n>\n>\n> This is a good observation!  I initially thought that we would have to\n> provide both the first-stage and second-stage revocation signatures.\n>\n>\n> One reallyyy nice thing about not having the watchtower sweep the HTLC\n>  outputs\n> on the commitment txn directly is that it doesn't need to know how to\n> reconstruct the more complex HTLC redeem scripts. It only needs to\n> reconstruct\n> commitment to-local and second-stage to-local scripts and witnesses. This\n> means\n> the blob primarily contains:\n>  - 1 revocation pubkey\n>  - 1 local delay pubkey\n>  - 1 CSV delay\n>  - 2 commitment signatures\n>  - n HTLC signatures\n> and we don't have to bother sending CLTVs, local/remote htlc pubkeys, or\n> payment hashes at all.\n>\n> The storage for this ends up being something like ~100 + 64*(2+nhtlcs)\n> when you\n> include other things like the sweep address.\n>\n>\n> Thank you, that seems like a start at something that can be implemented.\n>\n>\n> The second observation is that the second stage transactions could be\n> broadcast\n> sequentially such that the CSV delays don't overlap at all. In this\n> event, the\n> watchtower needs to sweep the HTLCs iteratively to prevent the attacker\n> from\n> sweeping any of the outputs as the relative timelocks expire.\n>\n>\n> Sorry, I seem confused this idea.  Can you give example for commitment\n> with 2x HTLC?\n>\n>\n> One minimal solution could be to send signatures for independent sweep\n> transactions, allowing the watchtower to sweep each HTLC output\n> individually.\n> This is nice because it permits the watchtower to sweep exactly the\n> subset of\n> HTLCs that ever transition into the second stage, and under any\n> permutation\n> wrt. ordering of confirmed second stage transactions.\n>\n>\n> Yes, this seems like a good general idea.\n>\n>\n> With the single transaction per HTLC approach, the total number of\n> signatures that\n> are sent to the watchtower remains linear in the number HTLCs on the\n> commitment\n> transaction. This approach does have the downside of consuming slightly\n> more\n> fees, since each output is swept with a distinct transaction.\n>\n>\n>\n> However, this approach is fairly efficient in preventing the attacker\n> entirely from\n> moving funds from the channel into their wallet wrt. to the amount of data\n> stored.\n> Considering that the majority of the channel balance is expected to be in\n> the commitment outputs and that hypothetically on-chains fees are offset\n> by the\n> remote balance, this could be an acceptable tradeoff.\n>\n>\n>\n> I suspect that in practice, most second stage transactions will be valid\n> by the\n> time an attacker would drop to chain. Because of this, it's possible that\n> they\n> could be mined in the same block as the breach transaction.\n>\n> If everything is mined in the same block or in quick succession, it might\n> be\n> worthwhile to also pre-sign a justice txn that batch sweeps all HTLCs\n> directly\n> from the second layer, requiring one additional signature/HTLC.\n> This could be a plausible scenario if the offender breached\n> unintentionally, and\n> their implementation tries to proceed normally. However it does require\n> all of the\n> CSV delays to conincide. If that doesn't happen, the watchtower can always\n> resort to sweeping the outputs individually.\n>\n> All in all, I think the ability to sweep each HTLC independently is\n> more-or-less\n> a requirement just given the complexity of how the on-chain state-space can\n>\n> manifest, especially if CLTVs have already expired. Other scenarios may\n> be worth including on a case by case basis or if we feel they are\n> justified. This\n> could be handled dynamically by including some bitvector or some compact\n> representation of how to reconstruct the transactions for any additional,\n> included\n> signatures.\n>\n>\n> Okay.  So it seems, the blob contains:\n>\n> 1.  Revocation pubkey (from our revocation basepoint and per-commitment\n> basepoint)\n> 2.  Their delayed payment pubkey (needed in scripts)\n> 3.  Our imposed to_self_delay (the setting we indicate, that we impose on\n> the remote side)\n> 4.  Our payment pubkey\n> 5.  0 or 1 or 2 signatures for the main outputs. These sign a single\n> transaction that claims only the main outputs.\n> 6.  0 or more second-stage HTLC revocation signatures.  These sign\n> individual transactions (one per HTLC) that claims only the second-stage\n> HTLC output.\n> 7.  scriptpubkey to put all the funds in.\n>\n> When the commitment txid is found onchain, the WatchTower creates a single\n> main output claim transaction using the 1 or 2 signatures for the main\n> outputs.  And for each HTLC outpoint on the commitment transaction, if it\n> gets spent, the WatchTower creates one HTLC justice transaction from the\n> second-stage HTLC transaction.\n>\n> Is that approximately what is needed?  Have I missed anything?\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180417/873b48e1/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-17T08:02:43",
                "message_text_only": "Good morning Conner,\n\n>> I understand. It would be good to know what you have, and perhaps consider\n>> planning a new BOLT document for such.\n> Yes, that is the ultimate goal. I think it might be a little to soon to have a\n> full-on BOLT spec. There are still some implementation details that we would\n> like to address before formalizing everything. I am working to have something\n> written up in the short-term documenting the approach[es] that ends up being\n> solidified. Hopefully that can get some eyes during development, and perhaps\n> serve as working document/rough draft.\n\nI understand.  For myself, I will also wait for comment from other c-lightning developers: this seems to require a bit of surgery on our code I think (currently construction of justice transactions is done in a separate process, and we always generate a justice transaction that claims all claimable outputs of the revoked commitment transaction), and we might decide to defer this feature for later (leaking revocation basepoint secret is easy and requires maybe a few dozen sloc, but that requires a trusted WatchTower).\n\n>> Sorry, I seem confused this idea.  Can you give example for commitment with 2x\n>> HTLC?\n> Sure thing! The confirmation of second level HTLCtxns can be separated byarbitrary delays. This is particularly true if the CLTVs have already expired,offering an attacker total control over when the txns appear on the network. One way this can happen is if the attacker iteratively broadcasts a singlesecond-level txn, waits for confirmation and CSV to expire, then repeat withanother second-level txn.\n> Since the CSVs begin ticking as soon as they are included in the chain, the attacker could try to sweep each one immediately after its CSV expires. If the watchtower doesn't have the ability to sweep outputs independently, it would\n> have no way to intercept this behavior, and prevent the breacher from sweepingindividual HTLCs sequentially.\n\nAh, I thought you wanted to impose some kind of contract on HTLC-timeout/HTLC-success to enforce this behavior, you are referring to a technique that the attacker might attempt to use if we use only a single justice transaction that claims all HTLC outputs.\n\n>> 5.  0 or 1 or 2 signatures for the main outputs. These sign a single\n>> transaction that claims only the main outputs.\n>\n> Yes, it seems necessary to separate the commitment outpoints from the HTLCoutpoints in case the commitment txn is broadcasted before the CLTVs expire.You could try to batch these with the HTLCs, but then we get back intoexponential territory.\n\nAgreed.\n\n>> Is that approximately what is needed?  Have I missed anything?\n>\n> Nope, I think your understanding is on point. IMO this seems to be a reasonable\n> compromise of the tradeoffs at hand, and definitely something that could serveas an initial iteration due to its simplicity. In the future, there are definitely ways\n> to improve on this on make it even more efficient! Though having a solid/workable v0 is important if it is to be deployed. I enjoy hearing yourthoughts on this, thank you for your responses!\n\nThank you for this confirmation.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180417/d82214af/attachment.html>"
            },
            {
                "author": "Conner Fromknecht",
                "date": "2018-04-17T08:30:42",
                "message_text_only": "Hi ZmnSCPxj,\n\n> I understand.  For myself, I will also wait for comment from other\nc-lightning\n> developers: this seems to require a bit of surgery on our code I think\n> (currently construction of justice transactions is done in a separate\nprocess,\n> and we always generate a justice transaction that claims all claimable\noutputs\n> of the revoked commitment transaction), and we might decide to defer this\n> feature for later (leaking revocation basepoint secret is easy and\nrequires\n> maybe a few dozen sloc, but that requires a trusted WatchTower).\n\nCertainly, it will require changes to ours as well. Would also love to hear\nwhat the\nother implementations think of such a proposal. As of now, we detect if the\ncommitment outputs have been spent, and if so, attempt to spend an\naggregate of\nthe commitment outputs and second-level outputs conditioned on which are\nreported as spent. To realize this fully, we would need to also detect the\ncase\nin which the second-level txns have already been spent, and then forgo\nsweeping\nthem entirely (on the assumption that it has already been done by a\nwatchtower).\n\n> Ah, I thought you wanted to impose some kind of contract on\n> HTLC-timeout/HTLC-success to enforce this behavior, you are referring to a\n> technique that the attacker might attempt to use if we use only a single\n> justice transaction that claims all HTLC outputs.\n\nPrecisely, if the attacker knows that we can only sweep a particular sets of\noutputs when batched, they can choose other sets that the watchtower can't\nact\non. Spending them independently seems to resolve this.\n\n-Conner\n\n\nOn Tue, Apr 17, 2018 at 8:02 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Conner,\n>\n> > I understand. It would be good to know what you have, and perhaps\n> consider\n> > planning a new BOLT document for such.\n> Yes, that is the ultimate goal. I think it might be a little to soon to\n> have a\n> full-on BOLT spec. There are still some implementation details that we\n> would\n> like to address before formalizing everything. I am working to have\n> something\n> written up in the short-term documenting the approach[es] that ends up\n> being\n> solidified. Hopefully that can get some eyes during development, and\n> perhaps\n> serve as working document/rough draft.\n>\n>\n> I understand.  For myself, I will also wait for comment from other\n> c-lightning developers: this seems to require a bit of surgery on our code\n> I think (currently construction of justice transactions is done in a\n> separate process, and we always generate a justice transaction that claims\n> all claimable outputs of the revoked commitment transaction), and we might\n> decide to defer this feature for later (leaking revocation basepoint secret\n> is easy and requires maybe a few dozen sloc, but that requires a trusted\n> WatchTower).\n>\n> > Sorry, I seem confused this idea.  Can you give example for commitment\n> with 2x\n> > HTLC?\n>\n> Sure thing! The confirmation of second level HTLC txns can be separated by\n> arbitrary delays. This is particularly true if the CLTVs have already\n> expired,\n> offering an attacker total control over when the txns appear on the\n> network. One\n> way this can happen is if the attacker iteratively broadcasts a single\n> second-level txn, waits for confirmation and CSV to expire, then repeat\n> with\n> another second-level txn.\n>\n> Since the CSVs begin ticking as soon as they are included in the chain,\n> the\n> attacker could try to sweep each one immediately after its CSV expires.\n> If the\n> watchtower doesn't have the ability to sweep outputs independently, it\n> would\n> have no way to intercept this behavior, and prevent the breacher from\n> sweeping\n> individual HTLCs sequentially.\n>\n> Ah, I thought you wanted to impose some kind of contract on\n> HTLC-timeout/HTLC-success to enforce this behavior, you are referring to a\n> technique that the attacker might attempt to use if we use only a single\n> justice transaction that claims all HTLC outputs.\n>\n>\n> > 5.  0 or 1 or 2 signatures for the main outputs. These sign a single\n> > transaction that claims only the main outputs.\n>\n> Yes, it seems necessary to separate the commitment outpoints from the HTLC\n> outpoints in case the commitment txn is broadcasted before the CLTVs\n> expire.\n> You could try to batch these with the HTLCs, but then we get back into\n> exponential territory.\n>\n> Agreed.\n>\n> > Is that approximately what is needed?  Have I missed anything?\n>\n> Nope, I think your understanding is on point. IMO this seems to be a\n> reasonable\n> compromise of the tradeoffs at hand, and definitely something that could\n> serve\n> as an initial iteration due to its simplicity. In the future, there are definitely\n> ways\n> to improve on this on make it even more efficient! Though having a\n> solid/workable v0 is important if it is to be deployed. I enjoy hearing\n> your\n> thoughts on this, thank you for your responses!\n>\n> Thank you for this confirmation.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180417/466f490f/attachment-0001.html>"
            },
            {
                "author": "Conner Fromknecht",
                "date": "2018-04-17T09:07:22",
                "message_text_only": "The ability for a watchtower to spend them independently seems to resolve\nthis*\nOn Tue, Apr 17, 2018 at 01:30 Conner Fromknecht\n<conner at lightning.engineering> wrote:\n\n> Hi ZmnSCPxj,\n>\n>\n> > I understand.  For myself, I will also wait for comment from other\n> c-lightning\n> > developers: this seems to require a bit of surgery on our code I think\n> > (currently construction of justice transactions is done in a separate\n> process,\n> > and we always generate a justice transaction that claims all claimable\n> outputs\n> > of the revoked commitment transaction), and we might decide to defer this\n> > feature for later (leaking revocation basepoint secret is easy and\n> requires\n> > maybe a few dozen sloc, but that requires a trusted WatchTower).\n>\n> Certainly, it will require changes to ours as well. Would also love to\n> hear what the\n> other implementations think of such a proposal. As of now, we detect if the\n>\n> commitment outputs have been spent, and if so, attempt to spend an\n> aggregate of\n> the commitment outputs and second-level outputs conditioned on which are\n> reported as spent. To realize this fully, we would need to also detect the\n> case\n> in which the second-level txns have already been spent, and then forgo\n> sweeping\n> them entirely (on the assumption that it has already been done by a\n> watchtower).\n>\n>\n>\n> > Ah, I thought you wanted to impose some kind of contract on\n> > HTLC-timeout/HTLC-success to enforce this behavior, you are referring\n> to a\n> > technique that the attacker might attempt to use if we use only a single\n> > justice transaction that claims all HTLC outputs.\n>\n> Precisely, if the attacker knows that we can only sweep a particular sets\n> of\n> outputs when batched, they can choose other sets that the watchtower can't\n> act\n> on. Spending them independently seems to resolve this.\n>\n>\n>\n> -Conner\n>\n> On Tue, Apr 17, 2018 at 8:02 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n>> Good morning Conner,\n>>\n>> > I understand. It would be good to know what you have, and perhaps\n>> consider\n>> > planning a new BOLT document for such.\n>> Yes, that is the ultimate goal. I think it might be a little to soon to\n>> have a\n>> full-on BOLT spec. There are still some implementation details that we\n>> would\n>> like to address before formalizing everything. I am working to have\n>> something\n>> written up in the short-term documenting the approach[es] that ends up\n>> being\n>> solidified. Hopefully that can get some eyes during development, and\n>> perhaps\n>> serve as working document/rough draft.\n>>\n>>\n>> I understand.  For myself, I will also wait for comment from other\n>> c-lightning developers: this seems to require a bit of surgery on our code\n>> I think (currently construction of justice transactions is done in a\n>> separate process, and we always generate a justice transaction that claims\n>> all claimable outputs of the revoked commitment transaction), and we might\n>> decide to defer this feature for later (leaking revocation basepoint secret\n>> is easy and requires maybe a few dozen sloc, but that requires a trusted\n>> WatchTower).\n>>\n>> > Sorry, I seem confused this idea.  Can you give example for commitment\n>> with 2x\n>> > HTLC?\n>>\n>> Sure thing! The confirmation of second level HTLC txns can be separated\n>> by\n>> arbitrary delays. This is particularly true if the CLTVs have already\n>> expired,\n>> offering an attacker total control over when the txns appear on the\n>> network. One\n>> way this can happen is if the attacker iteratively broadcasts a single\n>> second-level txn, waits for confirmation and CSV to expire, then repeat\n>> with\n>> another second-level txn.\n>>\n>> Since the CSVs begin ticking as soon as they are included in the chain,\n>> the\n>> attacker could try to sweep each one immediately after its CSV expires.\n>> If the\n>> watchtower doesn't have the ability to sweep outputs independently, it\n>> would\n>> have no way to intercept this behavior, and prevent the breacher from\n>> sweeping\n>> individual HTLCs sequentially.\n>>\n>> Ah, I thought you wanted to impose some kind of contract on\n>> HTLC-timeout/HTLC-success to enforce this behavior, you are referring to a\n>> technique that the attacker might attempt to use if we use only a single\n>> justice transaction that claims all HTLC outputs.\n>>\n>>\n>> > 5.  0 or 1 or 2 signatures for the main outputs. These sign a single\n>> > transaction that claims only the main outputs.\n>>\n>> Yes, it seems necessary to separate the commitment outpoints from the\n>> HTLC\n>> outpoints in case the commitment txn is broadcasted before the CLTVs\n>> expire.\n>> You could try to batch these with the HTLCs, but then we get back into\n>> exponential territory.\n>>\n>> Agreed.\n>>\n>> > Is that approximately what is needed?  Have I missed anything?\n>>\n>> Nope, I think your understanding is on point. IMO this seems to be a\n>> reasonable\n>> compromise of the tradeoffs at hand, and definitely something that could\n>> serve\n>> as an initial iteration due to its simplicity. In the future, there are definitely\n>> ways\n>> to improve on this on make it even more efficient! Though having a\n>> solid/workable v0 is important if it is to be deployed. I enjoy hearing\n>> your\n>> thoughts on this, thank you for your responses!\n>>\n>> Thank you for this confirmation.\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180417/ba5d4ec3/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-17T09:44:50",
                "message_text_only": "Good morning Conner,\n\nI have an insane idea.\n\n> One minimal solution could be to send signatures for independent sweep\n> transactions, allowing the watchtower to sweep each HTLC output individually.\n> This is nice because it permits the watchtower to sweep exactly the subset ofHTLCs that ever transition into the second stage, and under any permutationwrt. ordering of confirmed second stage transactions.\n>\n> With the single transaction per HTLC approach, the total number of signatures that\n> are sent to the watchtower remains linear in the number HTLCs on the commitmenttransaction. This approach does have the downside of consuming slightly more\n> fees, since each output is swept with a distinct transaction.\n\nI consider the idea, to take this even further.  Why have one blob contain data for multiple justice transactions?  Since the WatchTower will make multiple justice transactions for each outpoint of the revoked commitment transaction, why not make it one-blob-one-justice?\n\nCurrently our basic idea is that a single blob is keyed to the revoked commitment txid, and contains how to claim the main outputs, and all the second-stage HTLCs from that commitment txid.\n\nBut I observe, that on the revoked commitment txid, there is exactly one output that needs to be claimed in a timely manner, and that is the output that goes to the stealing node.  The output that goes to the protected node is safe, and if the second stage of the HTLC outputs are not yet claimed, those outputs are also safe.\n\nAnd on the second-stage HTLC (HTLC-success or HTLC-timeout), there is also exactly one output that needs to be claimed in a timely manner.\n\nSo I consider the idea, that we create (txid[:16], blob) pairs for the commitment transaction, and separate (txid[:16], blob) pairs for each second-stage HTLC transaction, and upload all this to the WatchTower.\n\nEach blob then only contains, encrypted:\n\n1.  The outnum on the tx being watched for.\n2.  The witness stack (signature plus witness script).\n3.  The scriptpubkey to pay out to.\n\nWe could pad this so that the witness stack size does not leak whether the tx being watched is a revoked commitment transaction or a revoked HTLC-success or HTLC-timeout transaction, and also some extra padding so that if we add more possible transactions to watch (or Bitcoin makes some excessively long standard scriptpubkey), we have some space to expand into.\n\nThis greatly simplifies WatchTower construction, as justice transactions it has to synthesize are simple one-input, one-output transactions (or possibly two-output, with the other output being the WatchTower bounty; perhaps the revoking signature on the witness stack could be SIGHASH_SINGLE (is that safe???) and the first output goes to the protected node, with the rest of the value split between the WatchTower and the mining fee, and the justice transaction opt-in RBF, so that the WatchTower can balance between remaining CSV timelock available and mining fees; this would also allow the same blob to be given to different WatchTowers, for even more insurance).\n\nWe could possibly move the outnum outside the blob, and have (txid[:16], outnum, blob), with the key for lookup being (txid[:16], outnum), so that a single monitored transaction can trigger multiple justice transactions for each outnum given.  This has the advantage that even if we completely change channel commitment structure, and the contracts we transport over channels (e.g. to support discreet log contracts), there will be no need to change existing WatchTowers: we always specify the entire witness stack of the justice transaction and the output of the justice transaction, and can freely change it.  Whether this is a big enough advantage, I do not know.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180417/35e0c44f/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-18T10:16:26",
                "message_text_only": "Good morning list,\n\nA possible problem with the encrypted blob approach came to my mind.\n\nA potential thief, knows the commitment transaction it will attempt to use to steal (obviously).\n\nThat potential thief, also knows the commitment transaction ID (obviously).\n\nIn the encrypted blob approach, the key is part of the commitment transaction ID.\n\nNow it seems, that if I am a thief, and I wish to steal from (for example) Rusty while he is on vacation, I could identify the WatchTower(s) he is using, and send many (txid[16:], blob) with random blob to that WatchTower(s).\n\nNow if the WatchTower is given a (txid[16:], blob) for a txid[16:] that it already has, but for a different blob, what should it do?\n\n* If it ignores the new txid[16:], then I could send the invalid (txid[16:], blob) to the WatchTower before I send the revocation of the commitment to Rusty; Rusty can only send a valid (txid[16:], blob) after I send the revocation to him, after all.  Then I implcitly prevent the WatchTower from accepting the correct blob from Rusty,\n* If it replaces the old txid[16:] and keeps the new pair, I could send txid[16:] to the WatchTower some time after I send the revocation to Rusty, hoping that Rusty behaves \"politely\" and does not spam the WatchTower repeatedly with its blob after I send my replacement.\n* If it stores all the (txid[16:], blob) pairs it receives, then an obvious DoS is to flood the WatchTower with such pairs, preferably distributedly, in the hope of bringing down the WatchTower.\n\nNow the WatchTower cannot know if it is Rusty who has the \"right\" to provide a given txid[16:], or me, or some other hardware I have \"hired\" to do my bidding.  This is in fact the whole point of an encrypted blob: the WatchTower only learns about the channels (and indirectly the identity of the counterparties in the channel) if a theft attempt is actually made.  Indeed, Rusty could have used Tor to contact the WatchTower (to obscure further who the WatchTower is protecting, in case the channel does not get stolen) and the WatchTower cannot know if it was actually Rusty or I (and it would leak privacy for the WatchTower to learn for certain who it is protecting, potentially allowing the WatchTower to profile Rusty spending habits).\n\nThe (txid[16:], blob) pairs I make in this attack need not have valid blob: either way the WatchTower cannot know, before I publish the entire commitment transaction, which blob came from Rusty correctly and which ones were invalid ones created by me and my army of fellow machines taking over the world.\n\n---\n\nAn obvious solution is for the WatchTower to charge a tiny amount (micropayment, how apt) for each (txid[16:] blob) pairs it keeps.  Then I cannot flood the WatchTower with poisoned blobs without at some point spending more than what I would earn by stealing.\n\nNow Lightning itself is positioned as a micropayment platform, so the obvious logic is that the WatchTower will get paid on-Lightning.  But every successful (and unsuccessful!) payment requires two channel updates, invalidating two commitment transactions and requiring two (txid[16:], blob) pairs that Rusty needs to get to a WatchTower.  Obviously Rusty has to have two WatchTowers, so that he uses one WatchTower to watch the channel of the other WatchTower.  But once Rusty pays to one WatchTower, he now has two (txid[16:], blob) pairs to send to the other WatchTower, which would charge for this service and require a payment.  This emits two new (txid[16:], blob) pairs to send to the first WatchTower, ad infinitum, at least until Rusty runs out of money.\n\nOne way to break this loop would be for WatchTowers to provide a \"prepaid watching\" service,\n\n1.  Rusty contacts two WatchTowers and gets invoices for prepaid watching.\n2.  On paying an invoice for prepaid watching, Rusty gets a preimage that serves as a \"ticket\" (encryption key). The WatchTower who provided that preimage promises to watch up to N txids (with N much greater than 2) when presented using this ticket.  For example let us assume that an invoice for prepaid watching pays for 100 (txid[16:], blob) pairs.\n3.  On paying both invoices, Rusty now has two tickets and four (txid[16:], blob) pairs.  Rusty can now put the blobs from one WatchTower to the other WatchTower, using the two tickets, and having 98 more blobs he can use on each ticket for his other Lightning activity.\n4.  An obvious rule for the WatchTower to apply would be to require that, at least within a ticket, a txid[16:] cannot be duplicated.  Across tickets, txid[16:] can be duplicated.\n\nThe ticket partially obscures the privacy of Rusty: the WatchTower knows that all the blobs within a ticket are from the same node, but cannot correlate across tickets (well if Rusty always uses non-published channels to them, they can identify him easily; obviously he should publish those channels and let others route through them).  Having multiple WatchTowers reduces how much each WatchTower learns about Rusty, and lets Rusty have one WatchTower watch the channel with a different WatchTower.\n\nIf I were to try stealing from Rusty, I would need to poison txid[16:] across multiple tickets.  Since within a ticket, txid[16:] cannot be duplicated, I need to buy 1000 tickets to flood the WatchTowers with 1000 invalid (txid[16:],blob).  Of course if I were to try stealing from all 1000 nodes on the mainnet network, I would be able to amortize that, but that would require greater preparation on my part.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180418/bf23b29e/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Trustless WatchTowers?",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Olaoluwa Osuntokun",
                "Conner Fromknecht",
                "ZmnSCPxj"
            ],
            "messages_count": 11,
            "total_messages_chars_count": 61987
        }
    },
    {
        "title": "[Lightning-dev] Towards a gridlike Lightning Network",
        "thread_messages": [
            {
                "author": "Benjamin Mord",
                "date": "2018-04-18T23:56:17",
                "message_text_only": "Elegant idea.\n\nIs there a simulation platform yet for experimenting with ideas such as\nthis? I imagine it may sometimes be useful to empirically test aggregate\neffects of different routing heuristics, however naive or artificial the\nunderlying assumptions may need to be.\n\nIs there an API, perhaps implementation agnostic, to separate such\nstrategies from the protocol itself?\n\nIs there a place yet to specify such heuristics where tight coordination on\ndetails are of mutual benefit, such as a bolt?\n\nOn Sat, Mar 24, 2018, 8:08 AM ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning list,\n>\n> I have decided on a better termination condition for searching for a\n> cyclic superhub.  I re-describe below the algorithm:\n>\n> Start with `i` = 0 and a set of known nodes, including our own node.\n>\n> Iterate over `i`:\n>\n> - Compute hash = H(i || pubkey) for each node. H = RIPEMD160 . SHA256,\n> serialize `i` as a big-endian 32-bit number.  Also compute our_hash = H(i\n> || our_pubkey) for our self.  Put this in a working set.\n>\n> - Iterate over bits (start with the 7th bit (128) of the first byte):\n>\n> - - Split the working set into two sets, the matching set and the\n> non-matching set, where the bit in the hash matches the bit in our_hash.\n>\n> - - If the non-matching set is empty, skip to the next bit.\n>\n> - - If the matching set is 1 or 2 members, or the non-matching set is 1 or\n> 2 members, merge the two sets together into the working set and exit this\n> loop: we have found a cyclic superhub.\n>\n> - - else set the working set to the matching set.\n>\n> - Sort the set according to the hash (treat the hash as a 160-bit\n> big-endian number).\n>\n> - We should open a channel to the node after us in the sorted list; if we\n> are the last, wrap around to the first node in the list.\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> Sent with ProtonMail <https://protonmail.com> Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On March 23, 2018 11:29 PM, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n> Good morning list,\n>\n> Igor Cota has started implementing my idea:\n> https://github.com/icota/presto/commit/3311785e660d840f0ac8f2e333d0f0097aec980e\n>\n> This forced me to actually start thinking more deeply about the algorithm\n> I gave.\n>\n> 1.  We should use a well-used hash algorithm, such as RIPEMD160(SHA256(x))\n> 2.  We should specify the size of `i` - 32-bits, 4 bytes - and indicate\n> its endianness.  Let us use big-endian, as is typical for the rest of\n> Lightning and for network order.\n> 3.  My original algorithm had a significant probability of diverging.  So\n> I respecify the termination condition later.\n> 4.  Our own node should be part of the original working set.\n> 5.  In the decimation loop, start with the highest bit.  This is the\n> 7-index bit (1 << 7) of the first byte in the 20-byte hash (we treat the\n> hash as a big-endian 160-bit number).\n>\n> The modified termination condition for the decimation loop is below:\n>\n> * If the working set is 7 nodes or more, decimate (i.e. match the next bit\n> in the hashes and remove those that do not match our own hash in that bit.).\n> * If the working set is 3 to 6 nodes, stop, that is now the members of the\n> superhub and we then sort them by hash and decide our position in the\n> superhub (who will channel to us and who we will channel to).\n> * If the working set is 1 or 2 nodes, fail to form a superhub.  Increment\n> `i` and restart.\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> Sent with ProtonMail <https://protonmail.com> Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On March 20, 2018 11:19 AM, ZmnSCPxj via Lightning-dev <\n> lightning-dev at lists.linuxfoundation.org> wrote:\n>\n> Good morning list,\n>\n> As my award-winning and supremely notable and\n> talked-about-by-the-man-on-the-street article \"Cyclic Superhubs as Solution\n> Towards Reasonable Lightning Network Topography\" points out, cycles are a\n> good way to organize the LN in order to allow easier accessibility to the\n> network for all participants of all kinds.\n>\n> An issue here is the need for coordination in order to set up cyclic\n> superhubs.  A node acting by itself cannot form cyclic superhubs.\n>\n> However, one can consider that coordination is needed only to identify\n> peers with which one forms superhubs.  But we already have a system that\n> identifies peers: the node gossip.\n>\n> So let us assume: All nodes have similar-enough views of the\n> publicly-visible peers on the node graph, as built by node gossip.\n>\n> I now present an algorithm, which given a set of nodes extracted from node\n> gossip, returns a peer to try connecting and funding a channel to.\n>\n> --\n>\n> First, start with a 32-bit number i = 0.\n>\n> For each node, get hash = H(i || pubkey), where H is some standard hash\n> algorithm, and pubkey is the public key of the node.  Also get our_hash =\n> H(i || our_pubkey)\n>\n> Perform successive filtering.  While the set is larger than 2 nodes,\n> successively compare high bits.  If the highest bit of hash does not match\n> the highest bit of our_hash, remove it from the set.  If the resulting set\n> is still larger than 2, match the next bit.  When the set is now 2 or 1\n> node, back off by one bit and add back the most recently removed nodes.\n> This yields a set that is at least 3 or more nodes.\n>\n> Sort the nodes according to hash.\n>\n> Identify where our node is in the sorted list.  Then our candidate is the\n> next node in the list, or if we are the last node, then the first node in\n> the list.\n>\n> If the candidate already has a channel with us, or has no address info and\n> cannot be found by DNS seed or so on, or cannot be contacted, or refuses\n> incoming channels or some other error, then increment i and try finding\n> again.\n>\n> ---\n>\n> Even if nodes have some divergence in their own local maps of the network,\n> there is the chance that the difference will be filtered away and the nodes\n> that are \"destined\" to form a superhub can still find each other in the\n> same superhub.\n>\n> Assuming all nodes have the same routemap, then all nodes will form their\n> own, non-overlapping superhubs for each i.  However if some nodes get to\n> increment i, hopefully because it already has a channel with its destined\n> candidate peer at one value of i, it can then potentially form superhubs\n> with other nodes that have also reached higher i.\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180418/067b809c/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-19T02:04:52",
                "message_text_only": "Good morning Benjamin,\n\nRusty simulated an older version of my idea here; C code near the end of the message: https://lists.ozlabs.org/pipermail/c-lightning/2018-April/000029.html\n\nHowever this has a bug: I specify that:\n\n>If the candidate already has a channel with us, or has no address info and\n>cannot be found by DNS seed or so on, or cannot be contacted, or refuses\n>incoming channels or some other error, then increment i and try finding again.\n\nThe code there does not implement the check \"if the candidate has a channel with us\", leading to smaller reachability since nodes who could afford to create multiple channels will create multiple channels to the same peer in the simulation.\n\nA naive analysis suggests that if only one node in the entire network uses the algorithm I described, it should be indistinguishable from a random connection policy, so a naive analysis suggests that something has gone wrong if the reachability of this algorithm is significantly less than the reachability of a random connection algorithm.  The simulation also does not consider that existing nodes may break old channels or make new channels themselves; it is not certain how often that happens on the real network.\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn April 19, 2018 7:56 AM, Benjamin Mord <ben at mord.family> wrote:\n\n> Elegant idea.\n>\n> Is there a simulation platform yet for experimenting with ideas such as this? I imagine it may sometimes be useful to empirically test aggregate effects of different routing heuristics, however naive or artificial the underlying assumptions may need to be.\n>\n> Is there an API, perhaps implementation agnostic, to separate such strategies from the protocol itself?\n>\n> Is there a place yet to specify such heuristics where tight coordination on details are of mutual benefit, such as a bolt?\n>\n> On Sat, Mar 24, 2018, 8:08 AM ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n>\n>> Good morning list,\n>>\n>> I have decided on a better termination condition for searching for a cyclic superhub.  I re-describe below the algorithm:\n>>\n>> Start with `i` = 0 and a set of known nodes, including our own node.\n>>\n>> Iterate over `i`:\n>>\n>> - Compute hash = H(i || pubkey) for each node. H = RIPEMD160 . SHA256, serialize `i` as a big-endian 32-bit number.  Also compute our_hash = H(i || our_pubkey) for our self.  Put this in a working set.\n>>\n>> - Iterate over bits (start with the 7th bit (128) of the first byte):\n>>\n>> - - Split the working set into two sets, the matching set and the non-matching set, where the bit in the hash matches the bit in our_hash.\n>>\n>> - - If the non-matching set is empty, skip to the next bit.\n>>\n>> - - If the matching set is 1 or 2 members, or the non-matching set is 1 or 2 members, merge the two sets together into the working set and exit this loop: we have found a cyclic superhub.\n>>\n>> - - else set the working set to the matching set.\n>>\n>> - Sort the set according to the hash (treat the hash as a 160-bit big-endian number).\n>>\n>> - We should open a channel to the node after us in the sorted list; if we are the last, wrap around to the first node in the list.\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>> Sent with [ProtonMail](https://protonmail.com) Secure Email.\n>>\n>> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>> On March 23, 2018 11:29 PM, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>>\n>>> Good morning list,\n>>>\n>>> Igor Cota has started implementing my idea: https://github.com/icota/presto/commit/3311785e660d840f0ac8f2e333d0f0097aec980e\n>>>\n>>> This forced me to actually start thinking more deeply about the algorithm I gave.\n>>>\n>>> 1.  We should use a well-used hash algorithm, such as RIPEMD160(SHA256(x))\n>>> 2.  We should specify the size of `i` - 32-bits, 4 bytes - and indicate its endianness.  Let us use big-endian, as is typical for the rest of Lightning and for network order.\n>>> 3.  My original algorithm had a significant probability of diverging.  So I respecify the termination condition later.\n>>> 4.  Our own node should be part of the original working set.\n>>> 5.  In the decimation loop, start with the highest bit.  This is the 7-index bit (1 << 7) of the first byte in the 20-byte hash (we treat the hash as a big-endian 160-bit number).\n>>>\n>>> The modified termination condition for the decimation loop is below:\n>>>\n>>> * If the working set is 7 nodes or more, decimate (i.e. match the next bit in the hashes and remove those that do not match our own hash in that bit.).\n>>> * If the working set is 3 to 6 nodes, stop, that is now the members of the superhub and we then sort them by hash and decide our position in the superhub (who will channel to us and who we will channel to).\n>>> * If the working set is 1 or 2 nodes, fail to form a superhub.  Increment `i` and restart.\n>>>\n>>> Regards,\n>>> ZmnSCPxj\n>>>\n>>> Sent with [ProtonMail](https://protonmail.com) Secure Email.\n>>>\n>>> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>>> On March 20, 2018 11:19 AM, ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> Good morning list,\n>>>>\n>>>> As my award-winning and supremely notable and talked-about-by-the-man-on-the-street article \"Cyclic Superhubs as Solution Towards Reasonable Lightning Network Topography\" points out, cycles are a good way to organize the LN in order to allow easier accessibility to the network for all participants of all kinds.\n>>>>\n>>>> An issue here is the need for coordination in order to set up cyclic superhubs.  A node acting by itself cannot form cyclic superhubs.\n>>>>\n>>>> However, one can consider that coordination is needed only to identify peers with which one forms superhubs.  But we already have a system that identifies peers: the node gossip.\n>>>>\n>>>> So let us assume: All nodes have similar-enough views of the publicly-visible peers on the node graph, as built by node gossip.\n>>>>\n>>>> I now present an algorithm, which given a set of nodes extracted from node gossip, returns a peer to try connecting and funding a channel to.\n>>>>\n>>>> --\n>>>>\n>>>> First, start with a 32-bit number i = 0.\n>>>>\n>>>> For each node, get hash = H(i || pubkey), where H is some standard hash algorithm, and pubkey is the public key of the node.  Also get our_hash = H(i || our_pubkey)\n>>>>\n>>>> Perform successive filtering.  While the set is larger than 2 nodes, successively compare high bits.  If the highest bit of hash does not match the highest bit of our_hash, remove it from the set.  If the resulting set is still larger than 2, match the next bit.  When the set is now 2 or 1 node, back off by one bit and add back the most recently removed nodes.  This yields a set that is at least 3 or more nodes.\n>>>>\n>>>> Sort the nodes according to hash.\n>>>>\n>>>> Identify where our node is in the sorted list.  Then our candidate is the next node in the list, or if we are the last node, then the first node in the list.\n>>>>\n>>>> If the candidate already has a channel with us, or has no address info and cannot be found by DNS seed or so on, or cannot be contacted, or refuses incoming channels or some other error, then increment i and try finding again.\n>>>>\n>>>> ---\n>>>>\n>>>> Even if nodes have some divergence in their own local maps of the network, there is the chance that the difference will be filtered away and the nodes that are \"destined\" to form a superhub can still find each other in the same superhub.\n>>>>\n>>>> Assuming all nodes have the same routemap, then all nodes will form their own, non-overlapping superhubs for each i.  However if some nodes get to increment i, hopefully because it already has a channel with its destined candidate peer at one value of i, it can then potentially form superhubs with other nodes that have also reached higher i.\n>>>>\n>>>> Regards,\n>>>> ZmnSCPxj\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180418/f849474c/attachment.html>"
            },
            {
                "author": "Benjamin Mord",
                "date": "2018-04-19T18:21:01",
                "message_text_only": "Hello ZmnSCPxj,\n\nI think there are two distinct concepts here. The first is the\nidentification of a 'neighborhood', and the second is the establishment of\nan order within that neighborhood for purpose of cycle formation.\n\nYour use of bloom filters to define a neighborhood, is I think the most\nvaluable contribution. Formation of neighborhoods with high connectivity,\nwith sparse but redundant connections among these neighborhoods, does seem\nlike an economically efficient approach to maintaining useful competition\nand redundancy. If there are any graph theorists or category theorists on\nthe list, perhaps they could offer some formal validation or optimization.\nFor this, I prefer your March 23 proposal over March 24, I'm curious what\nimprovement is intended in March 24 vs 23?\n\nThe emergent definition and maintenance of a unique ordering for cycle\nestablishment within a neighborhood is, I think, a much more ambitious\nundertaking. I'm not sure how we efficiently make that robust in a dynamic\ncontext, except perhaps with interactive coordination among the members\noperating off something other than just static global data. Otherwise\ndifferent members would have different ideas about cycle order, depending\non when they first joined. I also don't see how cycles recover when someone\nleaves.\n\nAs people come and go, cycles will break. As the lightning network grows\noverall, neighborhoods identified by one setting of the bloom filter will\nbecome undesirably large. Perhaps a less ambitious but more robust\nheuristic would be one where probability of establishing a channel is\nproportional to the number of bits in common in the pubkey hash, normalized\nby the number of nodes currently observed? This heuristic would\nautomatically adjust granularity over time as lightning membership grows\nand shrinks. Nodes could periodically reevaluate their channel allocations\nas the overall network grows or shrinks.\n\nWere it not for the privacy goals, dynamic optimization based on actual\nusage would be possible. Nodes could track the routes of payments that flow\nthrough their channels and could spot fees that seem both large and\npopular, and could use this information to identify under-served nodes to\nwhich a direct channel might be in order. If we allowed nodes to see two\nhops of the route instead of just the one, then such optimization would\nbecome possible, although this compromise would require longer minimum\nroutes for a given level of privacy.\n\nThanks,\nBen\n\n\nOn Wed, Apr 18, 2018 at 10:04 PM, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Benjamin,\n>\n> Rusty simulated an older version of my idea here; C code near the end of\n> the message: https://lists.ozlabs.org/pipermail/c-lightning/2018-\n> April/000029.html\n>\n> However this has a bug: I specify that:\n>\n> >If the candidate already has a channel with us, or has no address info and\n> >cannot be found by DNS seed or so on, or cannot be contacted, or refuses\n> >incoming channels or some other error, then increment i and try finding again.\n>\n> The code there does not implement the check \"if the candidate has a\n> channel with us\", leading to smaller reachability since nodes who could\n> afford to create multiple channels will create multiple channels to the\n> same peer in the simulation.\n>\n> A naive analysis suggests that if only one node in the entire network uses\n> the algorithm I described, it should be indistinguishable from a random\n> connection policy, so a naive analysis suggests that something has gone\n> wrong if the reachability of this algorithm is significantly less than the\n> reachability of a random connection algorithm.  The simulation also does\n> not consider that existing nodes may break old channels or make new\n> channels themselves; it is not certain how often that happens on the real\n> network.\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n> Sent with ProtonMail <https://protonmail.com> Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On April 19, 2018 7:56 AM, Benjamin Mord <ben at mord.family> wrote:\n>\n>\n> Elegant idea.\n>\n> Is there a simulation platform yet for experimenting with ideas such as\n> this? I imagine it may sometimes be useful to empirically test aggregate\n> effects of different routing heuristics, however naive or artificial the\n> underlying assumptions may need to be.\n>\n> Is there an API, perhaps implementation agnostic, to separate such\n> strategies from the protocol itself?\n>\n> Is there a place yet to specify such heuristics where tight coordination\n> on details are of mutual benefit, such as a bolt?\n>\n> On Sat, Mar 24, 2018, 8:08 AM ZmnSCPxj via Lightning-dev <\n> lightning-dev at lists.linuxfoundation.org> wrote:\n>\n>> Good morning list,\n>>\n>> I have decided on a better termination condition for searching for a\n>> cyclic superhub.  I re-describe below the algorithm:\n>>\n>> Start with `i` = 0 and a set of known nodes, including our own node.\n>>\n>> Iterate over `i`:\n>>\n>> - Compute hash = H(i || pubkey) for each node. H = RIPEMD160 . SHA256,\n>> serialize `i` as a big-endian 32-bit number.  Also compute our_hash = H(i\n>> || our_pubkey) for our self.  Put this in a working set.\n>>\n>> - Iterate over bits (start with the 7th bit (128) of the first byte):\n>>\n>> - - Split the working set into two sets, the matching set and the\n>> non-matching set, where the bit in the hash matches the bit in our_hash.\n>>\n>> - - If the non-matching set is empty, skip to the next bit.\n>>\n>> - - If the matching set is 1 or 2 members, or the non-matching set is 1\n>> or 2 members, merge the two sets together into the working set and exit\n>> this loop: we have found a cyclic superhub.\n>>\n>> - - else set the working set to the matching set.\n>>\n>> - Sort the set according to the hash (treat the hash as a 160-bit\n>> big-endian number).\n>>\n>> - We should open a channel to the node after us in the sorted list; if we\n>> are the last, wrap around to the first node in the list.\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>>\n>> Sent with ProtonMail <https://protonmail.com> Secure Email.\n>>\n>> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>> On March 23, 2018 11:29 PM, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>>\n>> Good morning list,\n>>\n>> Igor Cota has started implementing my idea: https://github.com/icota/\n>> presto/commit/3311785e660d840f0ac8f2e333d0f0097aec980e\n>>\n>> This forced me to actually start thinking more deeply about the algorithm\n>> I gave.\n>>\n>> 1.  We should use a well-used hash algorithm, such as RIPEMD160(SHA256(x))\n>> 2.  We should specify the size of `i` - 32-bits, 4 bytes - and indicate\n>> its endianness.  Let us use big-endian, as is typical for the rest of\n>> Lightning and for network order.\n>> 3.  My original algorithm had a significant probability of diverging.  So\n>> I respecify the termination condition later.\n>> 4.  Our own node should be part of the original working set.\n>> 5.  In the decimation loop, start with the highest bit.  This is the\n>> 7-index bit (1 << 7) of the first byte in the 20-byte hash (we treat the\n>> hash as a big-endian 160-bit number).\n>>\n>> The modified termination condition for the decimation loop is below:\n>>\n>> * If the working set is 7 nodes or more, decimate (i.e. match the next\n>> bit in the hashes and remove those that do not match our own hash in that\n>> bit.).\n>> * If the working set is 3 to 6 nodes, stop, that is now the members of\n>> the superhub and we then sort them by hash and decide our position in the\n>> superhub (who will channel to us and who we will channel to).\n>> * If the working set is 1 or 2 nodes, fail to form a superhub.  Increment\n>> `i` and restart.\n>>\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>>\n>> Sent with ProtonMail <https://protonmail.com> Secure Email.\n>>\n>> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>> On March 20, 2018 11:19 AM, ZmnSCPxj via Lightning-dev <\n>> lightning-dev at lists.linuxfoundation.org> wrote:\n>>\n>> Good morning list,\n>>\n>> As my award-winning and supremely notable and talked-about-by-the-man-on-the-street\n>> article \"Cyclic Superhubs as Solution Towards Reasonable Lightning Network\n>> Topography\" points out, cycles are a good way to organize the LN in order\n>> to allow easier accessibility to the network for all participants of all\n>> kinds.\n>>\n>> An issue here is the need for coordination in order to set up cyclic\n>> superhubs.  A node acting by itself cannot form cyclic superhubs.\n>>\n>> However, one can consider that coordination is needed only to identify\n>> peers with which one forms superhubs.  But we already have a system that\n>> identifies peers: the node gossip.\n>>\n>> So let us assume: All nodes have similar-enough views of the\n>> publicly-visible peers on the node graph, as built by node gossip.\n>>\n>> I now present an algorithm, which given a set of nodes extracted from\n>> node gossip, returns a peer to try connecting and funding a channel to.\n>>\n>> --\n>>\n>> First, start with a 32-bit number i = 0.\n>>\n>> For each node, get hash = H(i || pubkey), where H is some standard hash\n>> algorithm, and pubkey is the public key of the node.  Also get our_hash =\n>> H(i || our_pubkey)\n>>\n>> Perform successive filtering.  While the set is larger than 2 nodes,\n>> successively compare high bits.  If the highest bit of hash does not match\n>> the highest bit of our_hash, remove it from the set.  If the resulting set\n>> is still larger than 2, match the next bit.  When the set is now 2 or 1\n>> node, back off by one bit and add back the most recently removed nodes.\n>> This yields a set that is at least 3 or more nodes.\n>>\n>> Sort the nodes according to hash.\n>>\n>> Identify where our node is in the sorted list.  Then our candidate is the\n>> next node in the list, or if we are the last node, then the first node in\n>> the list.\n>>\n>> If the candidate already has a channel with us, or has no address info\n>> and cannot be found by DNS seed or so on, or cannot be contacted, or\n>> refuses incoming channels or some other error, then increment i and try\n>> finding again.\n>>\n>> ---\n>>\n>> Even if nodes have some divergence in their own local maps of the\n>> network, there is the chance that the difference will be filtered away and\n>> the nodes that are \"destined\" to form a superhub can still find each other\n>> in the same superhub.\n>>\n>> Assuming all nodes have the same routemap, then all nodes will form their\n>> own, non-overlapping superhubs for each i.  However if some nodes get to\n>> increment i, hopefully because it already has a channel with its destined\n>> candidate peer at one value of i, it can then potentially form superhubs\n>> with other nodes that have also reached higher i.\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>>\n>>\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180419/a12578c3/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-20T03:24:40",
                "message_text_only": "Good morning Benjamin,\n\n> I think there are two distinct concepts here. The first is the identification of a 'neighborhood', and the second is the establishment of an order within that neighborhood for purpose of cycle formation.\n>\n> Your use of bloom filters to define a neighborhood, is I think the most valuable contribution. Formation of neighborhoods with high connectivity, with sparse but redundant connections among these neighborhoods, does seem like an economically efficient approach to maintaining useful competition and redundancy. If there are any graph theorists or category theorists on the list, perhaps they could offer some formal validation or optimization. For this, I prefer your March 23 proposal over March 24, I'm curious what improvement is intended in March 24 vs 23?\n\nI do not see a bloom filter? But then I am not a mathematician so it is possible I fail to see how the Bloom filter arises from the algorithm I described.\n\nRegarding 24 vs 23, the condition for 23 allows a 3 members of a 5-member neighborhood to think they form a single 3-member neighborhood, while the remaining 2 members think they are in a 5-member neighborhood that includes the other 3 members who have formed a 3-member neighborhood.\n\n> The emergent definition and maintenance of a unique ordering for cycle establishment within a neighborhood is, I think, a much more ambitious undertaking. I'm not sure how we efficiently make that robust in a dynamic context, except perhaps with interactive coordination among the members operating off something other than just static global data. Otherwise different members would have different ideas about cycle order, depending on when they first joined. I also don't see how cycles recover when someone leaves.\n>\n> As people come and go, cycles will break. As the lightning network grows overall, neighborhoods identified by one setting of the bloom filter will become undesirably large. Perhaps a less ambitious but more robust heuristic would be one where probability of establishing a channel is proportional to the number of bits in common in the pubkey hash, normalized by the number of nodes currently observed?\n\nI believe that is what the algorithm already does? It dynamically sizes neighborhoods to be small, with high probability of neighborhoods to be 3->5 members.\n\n> This heuristic would automatically adjust granularity over time as lightning membership grows and shrinks. Nodes could periodically reevaluate their channel allocations as the overall network grows or shrinks.\n\nThe algorithm does not consider what happens when we have a cycle already existing, and a new member joins or an existing one wishes to leave.  There is no way to inform this.  My expectation is that people will just close channels that they no longer  find useful; this makes funds available onchain.  Then a process notices there are onchain funds, and calls this algorithm to get a proposed channel; this adapts to whatever the topology is right now.\n\nIt is not clear when we should close channels.  For one, gossip requires that a node first open a channel to somebody, before its existence is acknowledged and gossiped across the network: this is intended to prevent spammers from spinning up nodes without actually intending to join the network.  Similarly, to leave the network, we assume that nodes will at least get all their channels closed: channel closure is an onchain event visible to everyone monitoring the the blockchain (which is what all LN nodes SHOULD do), and once all channels of a node have closed, we MAY drop them from the network view (c-lightning implements this, but I do not know if other implementations do).\n\nSo at least for *leaving* LN permanently, the leaving node SHOULD close all its channels (or at least their peers SHOULD close it for them in unilateral closes if the peer just does not respond at all anymore).  This updates the network view of everybody (assuming they follow the recommendation that they MAY drop nodes from the network view, if that node has all its channels closed).  The closing will also put the channel funds onchain, and presumably the autopilots of its neighbors will notice the onchain funds, calls the algorithm to get a peer to channel to, which computes (hopefully) using the updated network view that has the leaving node removed already (this may not be true: the leaving node might not be able to close all channels simultaneously, and may misbehave and expect its neighbors to close the channels for it), and adapts correctly to the node leaving the network.\n\nHowever for a new node entering the network, there is problem.  This requires existing nodes to close existing channels and open new ones to the new node: as this costs onchain fees, there is no real incentive for them to do so.  I can only fall back on the informal argument: that people will at first experiment with the Lightning Network and commit a tiny amount of funds, then later they will put in more funds and thus open new channels, hopefully using this algorithm so that other people who come in later will also get new channels to them: the first channels people make will (eventually) not be in the neighborhood later on, but since they will open new channels later those will adapt to new neighborhoods of the larger network graph.\n\nI believe the main benefit of the algorithm I describe is that it flattens the number of channels a node will have and reduces centralization (although I believe roasbeef argues that centralization at the LN layer is relatively unimportant?).  If each node opens two channels to two different nodes, pure random selection will by chance award a few lucky nodes with 3 or 4 or 5 or more incoming channels while about 1/4 of nodes will have no channels incoming, but this algorithm will force all nodes to have exactly two incoming and two outgoing channels, while having similar reachability as random selection.  Of course, that assumes everyone already knows the entire network beforehand, and the issue of new nodes coming in is absent.\n\n> Were it not for the privacy goals, dynamic optimization based on actual usage would be possible. Nodes could track the routes of payments that flow through their channels and could spot fees that seem both large and popular, and could use this information to identify under-served nodes to which a direct channel might be in order. If we allowed nodes to see two hops of the route instead of just the one, then such optimization would become possible, although this compromise would require longer minimum routes for a given level of privacy.\n\nIntermediate nodes already know two hops?  The incoming and outgoing hop?  Or do you need more information?\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180419/b54d151b/attachment-0001.html>"
            },
            {
                "author": "Benjamin Mord",
                "date": "2018-04-20T20:43:20",
                "message_text_only": "Good afternoon ZmnSCPxj,\n\n\"I do not see a bloom filter?\"\n\nWell, if you look at it kinda sideways, you are using a bloom filter in\nyour March 23rd proposal. As originally defined, I think the \"false\npositives\" in bloom filtering were the unfortunate cost of performance. In\nBIP 37, the false positives become desirable, although still are 'false' in\nthat their only function is to serve as red herrings. But (omitting i for\nclarity), your proposal takes BIP 37's spin on bloom filters one step\nfurther to actually take the 'false positives' as the very definition of\nour desired set, since what you are \"searching for\" is just your own public\nkey, which ends up being the least interesting result within that set.\n\n\" Regarding 24 vs 23, the condition for 23 allows a 3 members of a 5-member\nneighborhood to think they form a single 3-member neighborhood, while the\nremaining 2 members think they are in a 5-member neighborhood that includes\nthe other 3 members who have formed a 3-member neighborhood.\"\n\nOh, I see. But the reason that occurs is because different nodes are\nconsidering different numbers of high-order bits. If everyone used the same\nnumber of high-order bits, then it would become an equivalence\nrelationship, with which we can partition the network. This is because\nthen, a=b, would imply b=a, and also a=b and b=c, would imply a=c.\nhttps://en.wikipedia.org/wiki/Equivalence_relation#Partition\n\nI think algorithm from March 24 is broken actually, on second look, but I\nunderstand now what you are trying to achieve. You want to allow local\njudgement over best local cell size, and yet somehow end up with precise\nuniform agreement on who is in which cells, because cycles require such\nprecision. But if you throw in that the network is dynamic, knowledge is\nimperfect, and malicious behavior may occur, then I think strict\nequivalence relationships and cycles become brittle. Perhaps we should\ngeneralize the equivalence relationship into a distance function, so that\nwe can start thinking of this as a metric space which we want to fill with\nsome sort of structure. Perhaps then we can design efficient yet robustly\n\"fuzzy\" structures. Perhaps we want a fuzzy fractal of some sort. Hmm...\n\n\"Intermediate nodes already know two hops?  The incoming and outgoing hop?\nOr do you need more information?\"\n\nYes, nodes would need to know one hope more, since the idea would be to\nattract competition to the high-usage yet high-fee links.\n\nThanks,\nBen\n\n\nOn Thu, Apr 19, 2018 at 11:24 PM, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Benjamin,\n>\n>\n> I think there are two distinct concepts here. The first is the\n> identification of a 'neighborhood', and the second is the establishment of\n> an order within that neighborhood for purpose of cycle formation.\n>\n> Your use of bloom filters to define a neighborhood, is I think the most\n> valuable contribution. Formation of neighborhoods with high connectivity,\n> with sparse but redundant connections among these neighborhoods, does seem\n> like an economically efficient approach to maintaining useful competition\n> and redundancy. If there are any graph theorists or category theorists on\n> the list, perhaps they could offer some formal validation or optimization.\n> For this, I prefer your March 23 proposal over March 24, I'm curious what\n> improvement is intended in March 24 vs 23?\n>\n>\n> I do not see a bloom filter? But then I am not a mathematician so it is\n> possible I fail to see how the Bloom filter arises from the algorithm I\n> described.\n>\n> Regarding 24 vs 23, the condition for 23 allows a 3 members of a 5-member\n> neighborhood to think they form a single 3-member neighborhood, while the\n> remaining 2 members think they are in a 5-member neighborhood that includes\n> the other 3 members who have formed a 3-member neighborhood.\n>\n>\n> The emergent definition and maintenance of a unique ordering for cycle\n> establishment within a neighborhood is, I think, a much more ambitious\n> undertaking. I'm not sure how we efficiently make that robust in a dynamic\n> context, except perhaps with interactive coordination among the members\n> operating off something other than just static global data. Otherwise\n> different members would have different ideas about cycle order, depending\n> on when they first joined. I also don't see how cycles recover when someone\n> leaves.\n>\n> As people come and go, cycles will break. As the lightning network grows\n> overall, neighborhoods identified by one setting of the bloom filter will\n> become undesirably large. Perhaps a less ambitious but more robust\n> heuristic would be one where probability of establishing a channel is\n> proportional to the number of bits in common in the pubkey hash, normalized\n> by the number of nodes currently observed?\n>\n>\n> I believe that is what the algorithm already does? It dynamically sizes\n> neighborhoods to be small, with high probability of neighborhoods to be\n> 3->5 members.\n>\n> This heuristic would automatically adjust granularity over time as\n> lightning membership grows and shrinks. Nodes could periodically reevaluate\n> their channel allocations as the overall network grows or shrinks.\n>\n>\n> The algorithm does not consider what happens when we have a cycle already\n> existing, and a new member joins or an existing one wishes to leave.  There\n> is no way to inform this.  My expectation is that people will just close\n> channels that they no longer  find useful; this makes funds available\n> onchain.  Then a process notices there are onchain funds, and calls this\n> algorithm to get a proposed channel; this adapts to whatever the topology\n> is right now.\n>\n> It is not clear when we should close channels.  For one, gossip requires\n> that a node first open a channel to somebody, before its existence is\n> acknowledged and gossiped across the network: this is intended to prevent\n> spammers from spinning up nodes without actually intending to join the\n> network.  Similarly, to leave the network, we assume that nodes will at\n> least get all their channels closed: channel closure is an onchain event\n> visible to everyone monitoring the the blockchain (which is what all LN\n> nodes SHOULD do), and once all channels of a node have closed, we MAY drop\n> them from the network view (c-lightning implements this, but I do not know\n> if other implementations do).\n>\n> So at least for *leaving* LN permanently, the leaving node SHOULD close\n> all its channels (or at least their peers SHOULD close it for them in\n> unilateral closes if the peer just does not respond at all anymore).  This\n> updates the network view of everybody (assuming they follow the\n> recommendation that they MAY drop nodes from the network view, if that node\n> has all its channels closed).  The closing will also put the channel funds\n> onchain, and presumably the autopilots of its neighbors will notice the\n> onchain funds, calls the algorithm to get a peer to channel to, which\n> computes (hopefully) using the updated network view that has the leaving\n> node removed already (this may not be true: the leaving node might not be\n> able to close all channels simultaneously, and may misbehave and expect its\n> neighbors to close the channels for it), and adapts correctly to the node\n> leaving the network.\n>\n> However for a new node entering the network, there is problem.  This\n> requires existing nodes to close existing channels and open new ones to the\n> new node: as this costs onchain fees, there is no real incentive for them\n> to do so.  I can only fall back on the informal argument: that people will\n> at first experiment with the Lightning Network and commit a tiny amount of\n> funds, then later they will put in more funds and thus open new channels,\n> hopefully using this algorithm so that other people who come in later will\n> also get new channels to them: the first channels people make will\n> (eventually) not be in the neighborhood later on, but since they will open\n> new channels later those will adapt to new neighborhoods of the larger\n> network graph.\n>\n> I believe the main benefit of the algorithm I describe is that it flattens\n> the number of channels a node will have and reduces centralization\n> (although I believe roasbeef argues that centralization at the LN layer is\n> relatively unimportant?).  If each node opens two channels to two different\n> nodes, pure random selection will by chance award a few lucky nodes with 3\n> or 4 or 5 or more incoming channels while about 1/4 of nodes will have no\n> channels incoming, but this algorithm will force all nodes to have exactly\n> two incoming and two outgoing channels, while having similar reachability\n> as random selection.  Of course, that assumes everyone already knows the\n> entire network beforehand, and the issue of new nodes coming in is absent.\n>\n>\n> Were it not for the privacy goals, dynamic optimization based on actual\n> usage would be possible. Nodes could track the routes of payments that flow\n> through their channels and could spot fees that seem both large and\n> popular, and could use this information to identify under-served nodes to\n> which a direct channel might be in order. If we allowed nodes to see two\n> hops of the route instead of just the one, then such optimization would\n> become possible, although this compromise would require longer minimum\n> routes for a given level of privacy.\n>\n>\n> Intermediate nodes already know two hops?  The incoming and outgoing hop?\n> Or do you need more information?\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180420/ab47485a/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Towards a gridlike Lightning Network",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Benjamin Mord"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 42587
        }
    },
    {
        "title": "[Lightning-dev] Scriptless Scripts with ECDSA",
        "thread_messages": [
            {
                "author": "Pedro Moreno Sanchez",
                "date": "2018-04-26T17:13:34",
                "message_text_only": "Hello guys,\n\nas some of you already know, I am working on some cryptographic\nconstructions that might be of interest and useful for the Lightning\nNetwork.\n\nRecently, I have come up with a scriptless version of the adaptor\nsignatures and the contract required in the Lighting Network using only\n2-party ECDSA signatures. The main advantage is that, instead of waiting\nfor Schnorr signatures to be deployed in Bitcoin so that Poelstra's\nscriptless scripts can be used, I believe that this ECDSA-version of the\nscriptless scripts can be directly applied today.\n\nDetails are in the attached PDF. I am looking forward to hearing your\ncomments and suggestions.\n\nCheers,\nPedro.\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: scriptless-ecdsa.pdf\nType: application/pdf\nSize: 161444 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180426/fe978423/attachment-0001.pdf>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 819 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180426/fe978423/attachment-0001.sig>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-30T04:23:11",
                "message_text_only": "Good morning Pedro,\n\nThis is certainly of great interest to me; unfortunately I am not a mathematician and probably cannot review if the math is correct or not.  In particular it seems to me, naively, to be able to implement my AMP idea which supports both path decorrelation and proof-of-payment, which is based on SS and HD.\n\nThe Lightning BOLT 1.0 spec is mostly frozen and we have good inter-implementation working of HTLCs.  Supporting SS, whether on top of ECDSA or Bellare-Neven, will be a large effort, and it is not clear to me if it is easy to switch between ECDSA and Bellare-Neven dynamically (i.e. if one hop supports ECDSA SS and the next hop supports Bellare-Neven SS).\n\nIt is also not clear to me how well B-N signature aggregation can work for Lightning use-cases; certainly onchain claims of unilateral closes can be made smaller with signature aggregation, but for mutual closes, there is only one input, unless we support close aggregation somehow (involving more than two parties, so much more effort).  A 2-of-2 with a single signature (which I believe is the basis of your SS work?) would let the mutual close and commitment transactions be smaller by one signature and one pubkey, though.\n\nAt the Lightning BOLT spec level:\n\n1.  We need a new global feature bit, `option_support_scriptless`, which would support routing of scriptless-script conditional payments.  Paying via SS can only be done if the entire route supports this option, which may hamper adoption and complicate routing implementations (cannot route an SS payment through nodes that do not  support SS).\n\n2.  Depending on how easy it would be to translate between ECDSA and Bellare-Neven SS, maybe only a local-level feature bit for `option_support_scriptless_ecdsa` and `option_support_scriptless_bn`?\n\n3.  Also affects BOLT11 as we would have to support both `SHA256(secret)` and `secret * G` in invoices, with the latter being used for SS payments.\n\n4.  We may want intra-path decorrelation (indeed, aside from AMP, this is the other use of SS on Lightning).  This requires passing a blinding secret to each layer of the onion in the onion routes, I think (?).\n\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Scriptless Scripts with ECDSA",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Pedro Moreno Sanchez",
                "ZmnSCPxj"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 3416
        }
    },
    {
        "title": "[Lightning-dev] Receiving via unpublished channels",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2018-04-26T23:35:16",
                "message_text_only": "Good morning list,\n\nWhile implementing support for `r` field in invoices, I stumbled upon some issues regarding *creating* invoices with `r` fields.\n\nIn order to receive via an unpublished channel, we need to know what onLightning fees the other side of that channel wants to charge.  We cannot use our own onLightning fees because our fees apply if we were forwarding to the other side.\n\nHowever, in case of an unpublished channel, we do not send channel_announcement, and in that case we do not send channel_update.  So the other side of the channel never informs us of the onLightning fees they want to charge if we would receive funds by this channel.\n\nAn idea we want to consider is to simply send `channel_update` as soon as we lock in the channel: https://github.com/ElementsProject/lightning/pull/1330#issuecomment-383931817\n\nI want to ask the other LN implementations (lnd, eclair, ucoin, lit) if we should consider standardizing this behavior (i.e. send `channel_update` after lockin  regardless of published/unpublished state).  It seems back-compatible: software which does not expect this behavior will simply drop the `channel_update` (as they do not follow a `channel_announcement`).\n\nIn any case, what was the intended way to get the onLightning fee rates to put into invoice `r` fields for private routes?\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180426/d1f069e7/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Receiving via unpublished channels",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "ZmnSCPxj"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1526
        }
    },
    {
        "title": "[Lightning-dev] eltoo: A Simplified update Mechanism for Lightning and Off-Chain Contracts",
        "thread_messages": [
            {
                "author": "Christian Decker",
                "date": "2018-04-30T15:41:38",
                "message_text_only": "(cross-posting to bitcoin-dev since this serves as motivation behind the\nsighash_noinput proposal)\n\n> TL;DR: we announce a new, simple, update mechanism for off-chain protocols,\n> see the announcement [1] and the paper [2] :-)\n\nA little over a year ago, the three Lightning Network implementation\nteams joined forces to work on a common specification for the protocol\nstack. Now that both that specification and our three implementations\nare becoming stable and usable, it is time to look forward: to further\nimprove the protocol, to add new features, to simplify, and to fix\ndownsides.\n\nOne of the core innovations that enabled Lightning in the first place was an\noff-chain update mechanism to renegotiate a new state and ensure that the old\nstate can not be settled on-chain. Today, we're excited to release our latest\nresearch paper on a new, simplified, update mechanism for layer 2 protocols,\ncalled eltoo.\n\neltoo is a drop-in replacement for the penalty based invalidation\nmechanism that is used today in the Lightning specification. It is\nsimilar in many ways to the sequence number mechanism that was already\npresent in the original Bitcoin implementation. But, while sequence\nnumbers were unenforceable on the blockchain, eltoo is enforceable by\noverriding subsequent states on-chain.\n\nUnlike the current mechanism used in Lightning so far, it is not penalty\nbased, i.e., publishing an old state does not result in the faulty node\nto automatically lose funds, and is most similar to the duplex\nmicropayment channels construction. It is a symmetric scheme, i.e., all\nparticipants share an identical set of transactions, and it ensures that the\nlast agreed upon state is settled on-chain, with similar tradeoffs as\ntoday's Lightning (timelock vs. online requirement).\n\neltoo addresses some of the issues we encountered while speficying and\nimplementing the Lightning Network. For example outsourcing becomes very\nsimple since old states becoming public can't hurt us anymore. We\ncompletely remove the need to estimate fees ahead of time. The\nconstruction allows us to attach fees when settling, and even allows for\nfees to be bumped using CPFP or RBF.\n\nBeyond Lightning, eltoo can be used as a generic update mechanism for an\noff-chain contract, for a larger number of participants. This was not\npossible in the current update mechanism since reactions to a\nmisbehaving participant needed to be tailore to that participant. This\nenables other protocols such as the channel factories, and in\ncombination with Schnorr signatures allows for very large off-chain\ncontracts with minimal on-chain footprint.\n\nBefore we can implement eltoo, we need a minor change to Bitcoin: the\nintroduction of the SIGHASH_NOINPUT flag for signatures. This was first\ndiscussed a few months ago in the context of watchtowers to help secure\nLightning channels, but was not formally proposed. A formal proposal may\nnow be found in the eltoo paper.\n\nWe invite the community to consider our proposal and to participate in\nits discussion. We hope to arrive at a consensus for the usage of\nSIGHASH_NOINPUT, so that it can be accepted and included in a future\nsoft fork of Bitcoin Script. Doing so will put us on the road to a more\nreliable and simpler Lightning Network, incorporating a new update\nmechanism that can also be used for many other applications.\n\nThe full official announcement can be found at [1] and the paper with the full\ndetails can be found at [2].\n\nLooking forward to the communities feedback,\nChristian\n\n[1] https://blockstream.com/2018/04/30/eltoo-next-lightning.html\n[2] https://blockstream.com/eltoo.pdf"
            }
        ],
        "thread_summary": {
            "title": "eltoo: A Simplified update Mechanism for Lightning and Off-Chain Contracts",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Decker"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3605
        }
    },
    {
        "title": "[Lightning-dev] BIP sighash_noinput",
        "thread_messages": [
            {
                "author": "Christian Decker",
                "date": "2018-04-30T16:29:53",
                "message_text_only": "Hi all,\n\nI'd like to pick up the discussion from a few months ago, and propose a new\nsighash flag, `SIGHASH_NOINPUT`, that removes the commitment to the previous\noutput. This was previously mentioned on the list by Joseph Poon [1], but was\nnever formally proposed, so I wrote a proposal [2].\n\nWe have long known that `SIGHASH_NOINPUT` would be a great fit for Lightning.\nThey enable simple watch-towers, i.e., outsource the need to watch the\nblockchain for channel closures, and react appropriately if our counterparty\nmisbehaves. In addition to this we just released the eltoo [3,4] paper which\ndescribes a simplified update mechanism that can be used in Lightning, and other\noff-chain contracts, with any number of participants.\n\nBy not committing to the previous output being spent by the transaction, we can\nrebind an input to point to any outpoint with a matching output script and\nvalue. The binding therefore is no longer explicit through a reference, but\nthrough script compatibility, and the transaction ID reference in the input is a\nhint to validators. The sighash flag is meant to enable some off-chain use-cases\nand should not be used unless the tradeoffs are well-known. In particular we\nsuggest using contract specific key-pairs, in order to avoid having any unwanted\nrebinding opportunities.\n\nThe proposal is very minimalistic, and simple. However, there are a few things\nwhere we'd like to hear the input of the wider community with regards to the\nimplementation details though. We had some discussions internally on whether to\nuse a separate opcode or a sighash flag, some feeling that the sighash flag\ncould lead to some confusion with existing wallets, but given that we have\n`SIGHASH_NONE`, and that existing wallets will not sign things with unknown\nflags, we decided to go the sighash way. Another thing is that we still commit\nto the amount of the outpoint being spent. The rationale behind this is that,\nwhile rebinding to outpoints with the same value maintains the value\nrelationship between input and output, we will probably not want to bind to\nsomething with a different value and suddenly pay a gigantic fee.\n\nThe deployment part of the proposal is left vague on purpose in order not to\ncollide with any other proposals. It should be possible to introduce it by\nbumping the segwit script version and adding the new behavior.\n\nI hope the proposal is well received, and I'm looking forward to discussing\nvariants and tradeoffs here. I think the applications we proposed so far are\nquite interesting, and I'm sure there are many more we can enable with this\nchange.\n\nCheers,\nChristian\n\n[1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-February/012460.html\n[2] https://github.com/cdecker/bips/blob/noinput/bip-xyz.mediawiki\n[3] https://blockstream.com/2018/04/30/eltoo-next-lightning.html\n[4] https://blockstream.com/eltoo.pdf"
            }
        ],
        "thread_summary": {
            "title": "BIP sighash_noinput",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Decker"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2869
        }
    },
    {
        "title": "[Lightning-dev] [bitcoin-dev] BIP sighash_noinput",
        "thread_messages": [
            {
                "author": "Dario Sneidermanis",
                "date": "2018-04-30T18:25:42",
                "message_text_only": "Something like this might also be useful for several use cases related to\nRBF. For example:\n\nAlice sends Bob an RBF-activated transaction T1 with the intention of\nbumping its fee if necessary. Bob wants to send these funds to Carol, but\ncannot wait until T1 confirms, so he crafts a transaction T2 that spends T1\nusing SIGHASH_NOINPUT, and pays Carol. Carol can now make sure she receives\nthe money even if Alice fee-bumps T1, as long as the outputs of the\nreplaced transactions are compatible.\n\nExtra care should be taken to avoid rebinding, maybe by including an extra\ninput in T2 that doesn't use SIGHASH_NOINPUT.\n\nOn Mon, Apr 30, 2018 at 1:29 PM, Christian Decker via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi all,\n>\n> I'd like to pick up the discussion from a few months ago, and propose a new\n> sighash flag, `SIGHASH_NOINPUT`, that removes the commitment to the\n> previous\n> output. This was previously mentioned on the list by Joseph Poon [1], but\n> was\n> never formally proposed, so I wrote a proposal [2].\n>\n> We have long known that `SIGHASH_NOINPUT` would be a great fit for\n> Lightning.\n> They enable simple watch-towers, i.e., outsource the need to watch the\n> blockchain for channel closures, and react appropriately if our\n> counterparty\n> misbehaves. In addition to this we just released the eltoo [3,4] paper\n> which\n> describes a simplified update mechanism that can be used in Lightning, and\n> other\n> off-chain contracts, with any number of participants.\n>\n> By not committing to the previous output being spent by the transaction,\n> we can\n> rebind an input to point to any outpoint with a matching output script and\n> value. The binding therefore is no longer explicit through a reference, but\n> through script compatibility, and the transaction ID reference in the\n> input is a\n> hint to validators. The sighash flag is meant to enable some off-chain\n> use-cases\n> and should not be used unless the tradeoffs are well-known. In particular\n> we\n> suggest using contract specific key-pairs, in order to avoid having any\n> unwanted\n> rebinding opportunities.\n>\n> The proposal is very minimalistic, and simple. However, there are a few\n> things\n> where we'd like to hear the input of the wider community with regards to\n> the\n> implementation details though. We had some discussions internally on\n> whether to\n> use a separate opcode or a sighash flag, some feeling that the sighash flag\n> could lead to some confusion with existing wallets, but given that we have\n> `SIGHASH_NONE`, and that existing wallets will not sign things with unknown\n> flags, we decided to go the sighash way. Another thing is that we still\n> commit\n> to the amount of the outpoint being spent. The rationale behind this is\n> that,\n> while rebinding to outpoints with the same value maintains the value\n> relationship between input and output, we will probably not want to bind to\n> something with a different value and suddenly pay a gigantic fee.\n>\n> The deployment part of the proposal is left vague on purpose in order not\n> to\n> collide with any other proposals. It should be possible to introduce it by\n> bumping the segwit script version and adding the new behavior.\n>\n> I hope the proposal is well received, and I'm looking forward to discussing\n> variants and tradeoffs here. I think the applications we proposed so far\n> are\n> quite interesting, and I'm sure there are many more we can enable with this\n> change.\n>\n> Cheers,\n> Christian\n>\n> [1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/\n> 2016-February/012460.html\n> [2] https://github.com/cdecker/bips/blob/noinput/bip-xyz.mediawiki\n> [3] https://blockstream.com/2018/04/30/eltoo-next-lightning.html\n> [4] https://blockstream.com/eltoo.pdf\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180430/4b977159/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP sighash_noinput",
            "categories": [
                "Lightning-dev",
                "bitcoin-dev"
            ],
            "authors": [
                "Dario Sneidermanis"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4110
        }
    }
]