[
    {
        "title": "[Lightning-dev] Payment Re-routing",
        "thread_messages": [
            {
                "author": "Kevin Greene",
                "date": "2015-07-01T16:31:47",
                "message_text_only": "Blargh. The dumb solution here is to just shrug and say that you have to\ntrust these processors to be highly available, and never try to do\nre-routing. That's pretty much equivalent to what would happen if one of\nthe banks in the visa network had networking issues for example.\n\nThe big difference here though is that visa will kick you out of the\nnetwork if you're a bank that's consistently not meeting their\nstrict SLA's, and that keeps the network honest. There is no such central\nprocessor though in this case to enforce the reputation of lightening nodes.\n\n\nOn Monday, June 29, 2015, Stephen Morse <stephencalebmorse at gmail.com> wrote:\n\n> Hi Rusty,\n>\n> On Sat, Jun 27, 2015 at 2:41 AM, Rusty Russell <rusty at rustcorp.com.au\n> <javascript:_e(%7B%7D,'cvml','rusty at rustcorp.com.au');>> wrote:\n>\n>>\n>> Yes, C can just get the preimage from E and collude to steal the funds,\n>> which is a nasty failure mode.\n>>\n>>\n> This scenario may even happen non-maliciously, if C has an honest outage\n> and attempts to pick up where it left off on each of its channels. To fix\n> the non-malicious case, C could get a refund from E (a new signed\n> transaction with a lower lock time), if C knows he has been offline for\n> longer than B's willingness to wait before re-routing. But this isn't\n> perfect, or even good, because E cannot know that C isn't just trying to\n> get a refund even though they have taken the payment from B. In fact, C is\n> guaranteed the payment from B, since they have the pre-image.\n>\n>\n>> Delaying the entire payment is a poor option; can anyone see a better\n>> one?\n>>\n>\n> Like you say, delaying the payment seems like a bad way to go, as then the\n> payments wouldn't be quite \"Lightning\" fast anymore. 99% of the payment\n> could be re-routed though. Perhaps the 99% could be re-routed, while A\n> waits for C to rejoin. Or if multiple paths are being used to process the\n> payment, just redistribute the remaining payments allotted for the broken\n> path among the other functioning paths.\n>\n> The bigger problem here seems to be that the incentives are slightly\n> skewed in favor of dishonestly. One can minimize the impact of that\n> dishonesty by breaking the payment into smaller chunks and across diverse\n> paths, but this comes at the cost of bandwidth and speed. Some sort of a\n> rating system could come into play possibly, if nothing can be\n> cryptographically worked out.\n>\n> Best,\n> Stephen\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150701/9c344b96/attachment.html>"
            },
            {
                "author": "Nick ODell",
                "date": "2015-07-01T16:55:46",
                "message_text_only": ">There is no such central processor though in this case to enforce the\nreputation of lightening nodes.\n\nThere's no reason why there couldn't be.\n\nTor, for example, has nine \"directory authorities.\" They attempt to reach\nnodes in the Tor network, and record whether they're available. Then, they\nvote among themselves to produce a directory consensus, and they all sign\nit. Lightning could use a similar system. Unlike Tor, we don't need to\nrequire everyone to use the same directory authorities, either.\n\nOn Wed, Jul 1, 2015 at 10:53 AM, Nick ODell <nickodell at gmail.com> wrote:\n\n> >There is no such central processor though in this case to enforce the\n> reputation of lightening nodes.\n>\n> There's no reason why there couldn't be.\n>\n> Tor, for example, has nine \"directory authorities.\" They attempt to reach\n> nodes in the Tor network, and record whether they're available. Then, they\n> vote among themselves to produce a directory consensus, and they all sign\n> it. Lightning could use a similar system. Unlike Tor, we don't need to\n> require everyone to use the same directory authority, either.\n>\n> On Wed, Jul 1, 2015 at 10:31 AM, Kevin Greene <kgreenek at gmail.com> wrote:\n>\n>> Blargh. The dumb solution here is to just shrug and say that you have to\n>> trust these processors to be highly available, and never try to do\n>> re-routing. That's pretty much equivalent to what would happen if one of\n>> the banks in the visa network had networking issues for example.\n>>\n>> The big difference here though is that visa will kick you out of the\n>> network if you're a bank that's consistently not meeting their\n>> strict SLA's, and that keeps the network honest. There is no such central\n>> processor though in this case to enforce the reputation of lightening\n>> nodes.\n>>\n>>\n>>\n>> On Monday, June 29, 2015, Stephen Morse <stephencalebmorse at gmail.com>\n>> wrote:\n>>\n>>> Hi Rusty,\n>>>\n>>> On Sat, Jun 27, 2015 at 2:41 AM, Rusty Russell <rusty at rustcorp.com.au>\n>>> wrote:\n>>>\n>>>>\n>>>> Yes, C can just get the preimage from E and collude to steal the funds,\n>>>> which is a nasty failure mode.\n>>>>\n>>>>\n>>> This scenario may even happen non-maliciously, if C has an honest outage\n>>> and attempts to pick up where it left off on each of its channels. To fix\n>>> the non-malicious case, C could get a refund from E (a new signed\n>>> transaction with a lower lock time), if C knows he has been offline for\n>>> longer than B's willingness to wait before re-routing. But this isn't\n>>> perfect, or even good, because E cannot know that C isn't just trying to\n>>> get a refund even though they have taken the payment from B. In fact, C is\n>>> guaranteed the payment from B, since they have the pre-image.\n>>>\n>>>\n>>>> Delaying the entire payment is a poor option; can anyone see a better\n>>>> one?\n>>>>\n>>>\n>>> Like you say, delaying the payment seems like a bad way to go, as then\n>>> the payments wouldn't be quite \"Lightning\" fast anymore. 99% of the payment\n>>> could be re-routed though. Perhaps the 99% could be re-routed, while A\n>>> waits for C to rejoin. Or if multiple paths are being used to process the\n>>> payment, just redistribute the remaining payments allotted for the broken\n>>> path among the other functioning paths.\n>>>\n>>> The bigger problem here seems to be that the incentives are slightly\n>>> skewed in favor of dishonestly. One can minimize the impact of that\n>>> dishonesty by breaking the payment into smaller chunks and across diverse\n>>> paths, but this comes at the cost of bandwidth and speed. Some sort of a\n>>> rating system could come into play possibly, if nothing can be\n>>> cryptographically worked out.\n>>>\n>>> Best,\n>>> Stephen\n>>>\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150701/83839504/attachment.html>"
            },
            {
                "author": "Kevin Greene",
                "date": "2015-07-01T18:19:09",
                "message_text_only": "Interesting. It sounds like Joseph may have a solution already, but as a\nthought experiment I'm curious how directory nodes could work with the\nlightening network. I guess you would have a set of such authorities that\nopen payment channels with all known lightening processors (how would they\nbe discovered?), and have a protocol for periodically moving money back and\nforth to verify connectivity. One difference here between Tor and\nLightening is that \"verifying connectivity\" on the Lightening network is\nnot as simple as connecting to a Tor node. For example, in the ABCD\nexample, what if C decides to attack only payments that come from B? It\ncould be non-malicious if C just had a datacenter fire or something that\ntook out the keys and tx data associated with their channel with B.\nAnyways, if the directory nodes didn't test every possible route through\nthe network (which has exponential complexity), then I don't think they\ncould reliably tell you if C is trustworthy or not.\n\nOn Wed, Jul 1, 2015 at 9:55 AM, Nick ODell <nickodell at gmail.com> wrote:\n\n> >There is no such central processor though in this case to enforce the\n> reputation of lightening nodes.\n>\n> There's no reason why there couldn't be.\n>\n> Tor, for example, has nine \"directory authorities.\" They attempt to reach\n> nodes in the Tor network, and record whether they're available. Then, they\n> vote among themselves to produce a directory consensus, and they all sign\n> it. Lightning could use a similar system. Unlike Tor, we don't need to\n> require everyone to use the same directory authorities, either.\n>\n> On Wed, Jul 1, 2015 at 10:53 AM, Nick ODell <nickodell at gmail.com> wrote:\n>\n>> >There is no such central processor though in this case to enforce the\n>> reputation of lightening nodes.\n>>\n>> There's no reason why there couldn't be.\n>>\n>> Tor, for example, has nine \"directory authorities.\" They attempt to reach\n>> nodes in the Tor network, and record whether they're available. Then, they\n>> vote among themselves to produce a directory consensus, and they all sign\n>> it. Lightning could use a similar system. Unlike Tor, we don't need to\n>> require everyone to use the same directory authority, either.\n>>\n>> On Wed, Jul 1, 2015 at 10:31 AM, Kevin Greene <kgreenek at gmail.com> wrote:\n>>\n>>> Blargh. The dumb solution here is to just shrug and say that you have to\n>>> trust these processors to be highly available, and never try to do\n>>> re-routing. That's pretty much equivalent to what would happen if one of\n>>> the banks in the visa network had networking issues for example.\n>>>\n>>> The big difference here though is that visa will kick you out of the\n>>> network if you're a bank that's consistently not meeting their\n>>> strict SLA's, and that keeps the network honest. There is no such central\n>>> processor though in this case to enforce the reputation of lightening\n>>> nodes.\n>>>\n>>>\n>>>\n>>> On Monday, June 29, 2015, Stephen Morse <stephencalebmorse at gmail.com>\n>>> wrote:\n>>>\n>>>> Hi Rusty,\n>>>>\n>>>> On Sat, Jun 27, 2015 at 2:41 AM, Rusty Russell <rusty at rustcorp.com.au>\n>>>> wrote:\n>>>>\n>>>>>\n>>>>> Yes, C can just get the preimage from E and collude to steal the funds,\n>>>>> which is a nasty failure mode.\n>>>>>\n>>>>>\n>>>> This scenario may even happen non-maliciously, if C has an honest\n>>>> outage and attempts to pick up where it left off on each of its channels.\n>>>> To fix the non-malicious case, C could get a refund from E (a new signed\n>>>> transaction with a lower lock time), if C knows he has been offline for\n>>>> longer than B's willingness to wait before re-routing. But this isn't\n>>>> perfect, or even good, because E cannot know that C isn't just trying to\n>>>> get a refund even though they have taken the payment from B. In fact, C is\n>>>> guaranteed the payment from B, since they have the pre-image.\n>>>>\n>>>>\n>>>>> Delaying the entire payment is a poor option; can anyone see a better\n>>>>> one?\n>>>>>\n>>>>\n>>>> Like you say, delaying the payment seems like a bad way to go, as then\n>>>> the payments wouldn't be quite \"Lightning\" fast anymore. 99% of the payment\n>>>> could be re-routed though. Perhaps the 99% could be re-routed, while A\n>>>> waits for C to rejoin. Or if multiple paths are being used to process the\n>>>> payment, just redistribute the remaining payments allotted for the broken\n>>>> path among the other functioning paths.\n>>>>\n>>>> The bigger problem here seems to be that the incentives are slightly\n>>>> skewed in favor of dishonestly. One can minimize the impact of that\n>>>> dishonesty by breaking the payment into smaller chunks and across diverse\n>>>> paths, but this comes at the cost of bandwidth and speed. Some sort of a\n>>>> rating system could come into play possibly, if nothing can be\n>>>> cryptographically worked out.\n>>>>\n>>>> Best,\n>>>> Stephen\n>>>>\n>>>\n>>> _______________________________________________\n>>> Lightning-dev mailing list\n>>> Lightning-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>\n>>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150701/33ad4caa/attachment-0001.html>"
            },
            {
                "author": "Nick ODell",
                "date": "2015-07-01T22:35:36",
                "message_text_only": ">(how would they be discovered?)\nTwo major ways I can see:\n * Each Lightning node keeps track of peers it has seen, and provides part\nof this list to anyone who asks. Directory authorities run spiders, like\nthe one at getaddr.bitnodes.io. This could be overlaid onto the Bitcoin\nprotocol by setting one of the service bits when the node is an active\nlightning processor.  (getaddr approach)\n * Your node tells all of the directory authorities it knows about itself.\n(Tor approach)\n\n\n>One difference here between Tor and Lightening is that \"verifying\nconnectivity\" on the Lightening network is not as simple as connecting to a\nTor node.\nI think the two of those are similar. Tor can detect various sorts of\naccidental connectivity issues. For example, if you tell Tor in its config\nfile that it has a gigabit connection, and it doesn't, it will figure that\nout by itself. However, the most important kind of intentional misbehavior,\nlogging connections, cannot be detected remotely.\n\nLightning is similar. We can detect when someone's internet connection goes\ndown. We can detect (with some plumbing) when their Bitcoin node is not\nsynchronized yet. But we can't detect the most important kind of\nintentional misbehavior, stealing money, without actually sending money\nthrough the network.\n\n(Or someone else trying to send money, and complaining when it doesn't go\nthrough. That would work better if the sender of the payment had some kind\nof log of signed statements made by the nodes involved, though.)\n\n>From a privacy perspective, active scanning (sending money through the\nnetwork yourself) is much easier to secure than passive scanning (acting on\nan audit log of someone whose payments got stolen.)\n\n>For example, in the ABCD example, what if C decides to attack only\npayments that come from B? It could be non-malicious if C just had a\ndatacenter fire or something that took out the keys and tx data associated\nwith their channel with B.\nIt doesn't seem like you can catch everybody who's selectively scamming\nthrough active scanning. For example, if someone stole one out of every\nmillion payments, the directories would never notice. Personally, I'd more\nworried about someone trying to defeat active scanning by fingerprinting\nwallet software. (e.g. this wallet software always puts zero in this field,\nor this directory authority always connects from Tor addresses.)\n\nWRT the non-malicious example: It seems like a non-malicious node would ask\nfor the channel to be closed ASAP, if it no longer remembered the data that\nwould show who owned what. This would still leave the payments that it was\nprocessing just before the data loss in limbo, though, so that's not a\ncure-all.\n\n>Anyways, if the directory nodes didn't test every possible route through\nthe network (which has exponential complexity), then I don't think they\ncould reliably tell you if C is trustworthy or not.\nI don't think they need to test every route. In the ABCD example, the only\nnodes that C should know about are B and D. Therefore, the routes EBCD and\nABCD are equivalent from C's point of view.\n\nThat's still superlinear, though.\n\nOn Wed, Jul 1, 2015 at 12:19 PM, Kevin Greene <kgreenek at gmail.com> wrote:\n\n> Interesting. It sounds like Joseph may have a solution already, but as a\n> thought experiment I'm curious how directory nodes could work with the\n> lightening network. I guess you would have a set of such authorities that\n> open payment channels with all known lightening processors (how would they\n> be discovered?), and have a protocol for periodically moving money back and\n> forth to verify connectivity. One difference here between Tor and\n> Lightening is that \"verifying connectivity\" on the Lightening network is\n> not as simple as connecting to a Tor node. For example, in the ABCD\n> example, what if C decides to attack only payments that come from B? It\n> could be non-malicious if C just had a datacenter fire or something that\n> took out the keys and tx data associated with their channel with B.\n> Anyways, if the directory nodes didn't test every possible route through\n> the network (which has exponential complexity), then I don't think they\n> could reliably tell you if C is trustworthy or not.\n>\n> On Wed, Jul 1, 2015 at 9:55 AM, Nick ODell <nickodell at gmail.com> wrote:\n>\n>> >There is no such central processor though in this case to enforce the\n>> reputation of lightening nodes.\n>>\n>> There's no reason why there couldn't be.\n>>\n>> Tor, for example, has nine \"directory authorities.\" They attempt to reach\n>> nodes in the Tor network, and record whether they're available. Then, they\n>> vote among themselves to produce a directory consensus, and they all sign\n>> it. Lightning could use a similar system. Unlike Tor, we don't need to\n>> require everyone to use the same directory authorities, either.\n>>\n>> On Wed, Jul 1, 2015 at 10:53 AM, Nick ODell <nickodell at gmail.com> wrote:\n>>\n>>> >There is no such central processor though in this case to enforce the\n>>> reputation of lightening nodes.\n>>>\n>>> There's no reason why there couldn't be.\n>>>\n>>> Tor, for example, has nine \"directory authorities.\" They attempt to\n>>> reach nodes in the Tor network, and record whether they're available. Then,\n>>> they vote among themselves to produce a directory consensus, and they all\n>>> sign it. Lightning could use a similar system. Unlike Tor, we don't need to\n>>> require everyone to use the same directory authority, either.\n>>>\n>>> On Wed, Jul 1, 2015 at 10:31 AM, Kevin Greene <kgreenek at gmail.com>\n>>> wrote:\n>>>\n>>>> Blargh. The dumb solution here is to just shrug and say that you have\n>>>> to trust these processors to be highly available, and never try to do\n>>>> re-routing. That's pretty much equivalent to what would happen if one of\n>>>> the banks in the visa network had networking issues for example.\n>>>>\n>>>> The big difference here though is that visa will kick you out of the\n>>>> network if you're a bank that's consistently not meeting their\n>>>> strict SLA's, and that keeps the network honest. There is no such central\n>>>> processor though in this case to enforce the reputation of lightening\n>>>> nodes.\n>>>>\n>>>>\n>>>>\n>>>> On Monday, June 29, 2015, Stephen Morse <stephencalebmorse at gmail.com>\n>>>> wrote:\n>>>>\n>>>>> Hi Rusty,\n>>>>>\n>>>>> On Sat, Jun 27, 2015 at 2:41 AM, Rusty Russell <rusty at rustcorp.com.au>\n>>>>> wrote:\n>>>>>\n>>>>>>\n>>>>>> Yes, C can just get the preimage from E and collude to steal the\n>>>>>> funds,\n>>>>>> which is a nasty failure mode.\n>>>>>>\n>>>>>>\n>>>>> This scenario may even happen non-maliciously, if C has an honest\n>>>>> outage and attempts to pick up where it left off on each of its channels.\n>>>>> To fix the non-malicious case, C could get a refund from E (a new signed\n>>>>> transaction with a lower lock time), if C knows he has been offline for\n>>>>> longer than B's willingness to wait before re-routing. But this isn't\n>>>>> perfect, or even good, because E cannot know that C isn't just trying to\n>>>>> get a refund even though they have taken the payment from B. In fact, C is\n>>>>> guaranteed the payment from B, since they have the pre-image.\n>>>>>\n>>>>>\n>>>>>> Delaying the entire payment is a poor option; can anyone see a better\n>>>>>> one?\n>>>>>>\n>>>>>\n>>>>> Like you say, delaying the payment seems like a bad way to go, as then\n>>>>> the payments wouldn't be quite \"Lightning\" fast anymore. 99% of the payment\n>>>>> could be re-routed though. Perhaps the 99% could be re-routed, while A\n>>>>> waits for C to rejoin. Or if multiple paths are being used to process the\n>>>>> payment, just redistribute the remaining payments allotted for the broken\n>>>>> path among the other functioning paths.\n>>>>>\n>>>>> The bigger problem here seems to be that the incentives are slightly\n>>>>> skewed in favor of dishonestly. One can minimize the impact of that\n>>>>> dishonesty by breaking the payment into smaller chunks and across diverse\n>>>>> paths, but this comes at the cost of bandwidth and speed. Some sort of a\n>>>>> rating system could come into play possibly, if nothing can be\n>>>>> cryptographically worked out.\n>>>>>\n>>>>> Best,\n>>>>> Stephen\n>>>>>\n>>>>\n>>>> _______________________________________________\n>>>> Lightning-dev mailing list\n>>>> Lightning-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>>\n>>>>\n>>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150701/04e5f863/attachment.html>"
            },
            {
                "author": "Kevin Greene",
                "date": "2015-07-01T23:01:31",
                "message_text_only": "On Wed, Jul 1, 2015 at 3:35 PM, Nick ODell <nickodell at gmail.com> wrote:\n\n> >(how would they be discovered?)\n> Two major ways I can see:\n>  * Each Lightning node keeps track of peers it has seen, and provides part\n> of this list to anyone who asks. Directory authorities run spiders, like\n> the one at getaddr.bitnodes.io. This could be overlaid onto the Bitcoin\n> protocol by setting one of the service bits when the node is an active\n> lightning processor.  (getaddr approach)\n>  * Your node tells all of the directory authorities it knows about itself.\n> (Tor approach)\n>\n>\n> >One difference here between Tor and Lightening is that \"verifying\n> connectivity\" on the Lightening network is not as simple as connecting to a\n> Tor node.\n> I think the two of those are similar. Tor can detect various sorts of\n> accidental connectivity issues. For example, if you tell Tor in its config\n> file that it has a gigabit connection, and it doesn't, it will figure that\n> out by itself. However, the most important kind of intentional misbehavior,\n> logging connections, cannot be detected remotely.\n>\n> Lightning is similar. We can detect when someone's internet connection\n> goes down. We can detect (with some plumbing) when their Bitcoin node is\n> not synchronized yet. But we can't detect the most important kind of\n> intentional misbehavior, stealing money, without actually sending money\n> through the network.\n>\n> (Or someone else trying to send money, and complaining when it doesn't go\n> through. That would work better if the sender of the payment had some kind\n> of log of signed statements made by the nodes involved, though.)\n>\n> From a privacy perspective, active scanning (sending money through the\n> network yourself) is much easier to secure than passive scanning (acting on\n> an audit log of someone whose payments got stolen.)\n>\n> >For example, in the ABCD example, what if C decides to attack only\n> payments that come from B? It could be non-malicious if C just had a\n> datacenter fire or something that took out the keys and tx data associated\n> with their channel with B.\n> It doesn't seem like you can catch everybody who's selectively scamming\n> through active scanning. For example, if someone stole one out of every\n> million payments, the directories would never notice. Personally, I'd more\n> worried about someone trying to defeat active scanning by fingerprinting\n> wallet software. (e.g. this wallet software always puts zero in this field,\n> or this directory authority always connects from Tor addresses.)\n>\n> WRT the non-malicious example: It seems like a non-malicious node would\n> ask for the channel to be closed ASAP, if it no longer remembered the data\n> that would show who owned what. This would still leave the payments that it\n> was processing just before the data loss in limbo, though, so that's not a\n> cure-all.\n>\n> >Anyways, if the directory nodes didn't test every possible route through\n> the network (which has exponential complexity), then I don't think they\n> could reliably tell you if C is trustworthy or not.\n> I don't think they need to test every route. In the ABCD example, the only\n> nodes that C should know about are B and D. Therefore, the routes EBCD and\n> ABCD are equivalent from C's point of view.\n>\n> That's still superlinear, though.\n>\n\n\u200bYeah. Also, how will A know what nodes B\u200b is connected to? B could\nadvertise its connected peers ala BGP AS-Paths.\n\nSpeaking of which, how does routing work in the lightening network? Forgive\nme if that's already documented somewhere. Is that designed already?\n\n\n>\n> On Wed, Jul 1, 2015 at 12:19 PM, Kevin Greene <kgreenek at gmail.com> wrote:\n>\n>> Interesting. It sounds like Joseph may have a solution already, but as a\n>> thought experiment I'm curious how directory nodes could work with the\n>> lightening network. I guess you would have a set of such authorities that\n>> open payment channels with all known lightening processors (how would they\n>> be discovered?), and have a protocol for periodically moving money back and\n>> forth to verify connectivity. One difference here between Tor and\n>> Lightening is that \"verifying connectivity\" on the Lightening network is\n>> not as simple as connecting to a Tor node. For example, in the ABCD\n>> example, what if C decides to attack only payments that come from B? It\n>> could be non-malicious if C just had a datacenter fire or something that\n>> took out the keys and tx data associated with their channel with B.\n>> Anyways, if the directory nodes didn't test every possible route through\n>> the network (which has exponential complexity), then I don't think they\n>> could reliably tell you if C is trustworthy or not.\n>>\n>> On Wed, Jul 1, 2015 at 9:55 AM, Nick ODell <nickodell at gmail.com> wrote:\n>>\n>>> >There is no such central processor though in this case to enforce the\n>>> reputation of lightening nodes.\n>>>\n>>> There's no reason why there couldn't be.\n>>>\n>>> Tor, for example, has nine \"directory authorities.\" They attempt to\n>>> reach nodes in the Tor network, and record whether they're available. Then,\n>>> they vote among themselves to produce a directory consensus, and they all\n>>> sign it. Lightning could use a similar system. Unlike Tor, we don't need to\n>>> require everyone to use the same directory authorities, either.\n>>>\n>>> On Wed, Jul 1, 2015 at 10:53 AM, Nick ODell <nickodell at gmail.com> wrote:\n>>>\n>>>> >There is no such central processor though in this case to enforce the\n>>>> reputation of lightening nodes.\n>>>>\n>>>> There's no reason why there couldn't be.\n>>>>\n>>>> Tor, for example, has nine \"directory authorities.\" They attempt to\n>>>> reach nodes in the Tor network, and record whether they're available. Then,\n>>>> they vote among themselves to produce a directory consensus, and they all\n>>>> sign it. Lightning could use a similar system. Unlike Tor, we don't need to\n>>>> require everyone to use the same directory authority, either.\n>>>>\n>>>> On Wed, Jul 1, 2015 at 10:31 AM, Kevin Greene <kgreenek at gmail.com>\n>>>> wrote:\n>>>>\n>>>>> Blargh. The dumb solution here is to just shrug and say that you have\n>>>>> to trust these processors to be highly available, and never try to do\n>>>>> re-routing. That's pretty much equivalent to what would happen if one of\n>>>>> the banks in the visa network had networking issues for example.\n>>>>>\n>>>>> The big difference here though is that visa will kick you out of the\n>>>>> network if you're a bank that's consistently not meeting their\n>>>>> strict SLA's, and that keeps the network honest. There is no such central\n>>>>> processor though in this case to enforce the reputation of lightening\n>>>>> nodes.\n>>>>>\n>>>>>\n>>>>>\n>>>>> On Monday, June 29, 2015, Stephen Morse <stephencalebmorse at gmail.com>\n>>>>> wrote:\n>>>>>\n>>>>>> Hi Rusty,\n>>>>>>\n>>>>>> On Sat, Jun 27, 2015 at 2:41 AM, Rusty Russell <rusty at rustcorp.com.au\n>>>>>> > wrote:\n>>>>>>\n>>>>>>>\n>>>>>>> Yes, C can just get the preimage from E and collude to steal the\n>>>>>>> funds,\n>>>>>>> which is a nasty failure mode.\n>>>>>>>\n>>>>>>>\n>>>>>> This scenario may even happen non-maliciously, if C has an honest\n>>>>>> outage and attempts to pick up where it left off on each of its channels.\n>>>>>> To fix the non-malicious case, C could get a refund from E (a new signed\n>>>>>> transaction with a lower lock time), if C knows he has been offline for\n>>>>>> longer than B's willingness to wait before re-routing. But this isn't\n>>>>>> perfect, or even good, because E cannot know that C isn't just trying to\n>>>>>> get a refund even though they have taken the payment from B. In fact, C is\n>>>>>> guaranteed the payment from B, since they have the pre-image.\n>>>>>>\n>>>>>>\n>>>>>>> Delaying the entire payment is a poor option; can anyone see a better\n>>>>>>> one?\n>>>>>>>\n>>>>>>\n>>>>>> Like you say, delaying the payment seems like a bad way to go, as\n>>>>>> then the payments wouldn't be quite \"Lightning\" fast anymore. 99% of the\n>>>>>> payment could be re-routed though. Perhaps the 99% could be re-routed,\n>>>>>> while A waits for C to rejoin. Or if multiple paths are being used to\n>>>>>> process the payment, just redistribute the remaining payments allotted for\n>>>>>> the broken path among the other functioning paths.\n>>>>>>\n>>>>>> The bigger problem here seems to be that the incentives are slightly\n>>>>>> skewed in favor of dishonestly. One can minimize the impact of that\n>>>>>> dishonesty by breaking the payment into smaller chunks and across diverse\n>>>>>> paths, but this comes at the cost of bandwidth and speed. Some sort of a\n>>>>>> rating system could come into play possibly, if nothing can be\n>>>>>> cryptographically worked out.\n>>>>>>\n>>>>>> Best,\n>>>>>> Stephen\n>>>>>>\n>>>>>\n>>>>> _______________________________________________\n>>>>> Lightning-dev mailing list\n>>>>> Lightning-dev at lists.linuxfoundation.org\n>>>>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>>>>\n>>>>>\n>>>>\n>>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150701/e7a8f1ab/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-02T05:11:18",
                "message_text_only": "Kevin Greene <kgreenek at gmail.com> writes:\n> On Wed, Jul 1, 2015 at 3:35 PM, Nick ODell <nickodell at gmail.com> wrote:\n> \u200bYeah. Also, how will A know what nodes B\u200b is connected to? B could\n> advertise its connected peers ala BGP AS-Paths.\n>\n> Speaking of which, how does routing work in the lightening network? Forgive\n> me if that's already documented somewhere. Is that designed already?\n\nNope, but it's worth its own thread.  Let me start that now :)\n\nThanks,\nRusty."
            },
            {
                "author": "Joseph Poon",
                "date": "2015-07-02T11:40:19",
                "message_text_only": "Hi Rusty and Stephen,\n\nOn Tue, Jun 30, 2015 at 05:33:00PM +0930, Rusty Russell wrote:\n> Joseph's solution is that E can route a conditional refund back to A\n> with a larger timeout (say 3 days) via some other route: this pays\n> back the amount to A if they present the preimage for the initial\n> stalled payment and another preimage A only has.  This serves as a\n> guarantee that E will not reveal the preimage required to take the\n> stalled payment.\n\nTo clarify, this is only necessary if there is a routing failure when a\nsigned transaction has been sent but not acknowledged or cancellation is\nrefused.\n\nFor example, presume the prior route A->B->C->E. If C acknowledges B's\nattempt to route but does not actually route after the signature has\nbeen sent by B to C, then A and B are unsure whether C's computer has\ngone offline or is acting maliciously. In that case, it's necessary for\nE to send a \"conditional refund\" back to A. The reason A requires an\nadditional preimage/hash when doing the \"conditional refund\" is in case\nthe conditional refund itself fails.\n\nHowever, the most likely case is the routing fails cleanly. If B is\nunable to send to C because C has been offline or B otherwise refuses to\nroute to C, B can undo the HTLC by cancelling the HTLC entirely\n(replacement with a new Commitment transaction state with A). This\ncancellation can cascade back to the sender to free up the money. In the\nevent that the cancellation doesn't end up cascading back to the sender\n(should be fairly rare), then A can get E to do the same E->D->A with\nthe same hash described in the previous example. Most routing failures\nshould end up being rollbacks.\n\n> This raises other questions, such as who would pay E (and any other\n> intermediate nodes) for locking up their money for such a time.  Could\n> A provide evidence that the route really had timed out?  How many\n> times can A claim \"payment failed\"?  etc.\n\nI'm assuming that the payment from A to E is split into many small\npayments. If the payment is too small to be split up, then it's probably\ncheap enough to not matter anyway (in most cases, waiting for expiration\nis no big deal). Resolving incomplete payments should be deferred until\nafter the payment is sufficiently complete; E can have as a policy to\nonly send \"conditional refunds\" when she has received sufficient funds\nfrom A (and A has paid for the time-value/fee of the refund). Since the\npayment is likely source-routed, it is the responsibility for the sender\nto pay for payment failure. The incentives are largely in favor of\nreceiver being online and accepting -- the recipient, is after all,\nincreasing the amount of bitcoin they own. \n\n-- \nJoseph Poon"
            }
        ],
        "thread_summary": {
            "title": "Payment Re-routing",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Nick ODell",
                "Kevin Greene",
                "Joseph Poon"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 32766
        }
    },
    {
        "title": "[Lightning-dev] Routing on the lightning network?",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2015-07-03T02:10:15",
                "message_text_only": "Hi all,\n\n        One of the fun open questions for LN is how routing will work.\nI'd like to kick off that discussion now, to see if we can create a\nstrawman which doesn't immediately collapse.\n\nAssumptions:\n1. I'm assuming each node is known by its pubkey.\n\n2. Source routing seems the easiest route; best for privacy, best for\n   any tradeoffs between reliability/price etc.\n\n3. We should do onion routing: each node knows the source and next step.\n   This is not perfect: R values trivially identifies connections (if\n   you own two nodes on the path, you can connect them), and the timeout\n   implies a minimum TTL.\n\n4. A recipient gives the payer 100 routes from some nodes to them.  The\n   payer hopefully can route to one of the mentioned nodes (probably the\n   cheapest).  This also means that if the payer has to do some route\n   query it doesn't trivially reveal who the recipient is.\n\nRoute broadcast is more fun.  It's not like BGP where you have useful\nsubnets; even if you did, you need the pubkey of every node.\n\nMy original idea was a subset of hubs (a few thousand?) to which you\nwould connect: that makes full discovery routing fairly easy within that\nnetwork, and you report your address as \"client XXXXX via hub <pubkey>\".\nYour hub(s) keep the routing tables, you just query them mostly.\n\nA more ambitious idea would be to select N \"beacons\" based on the block\nhash which every node figures out their best routes to/from.  That's\nactually really efficient for broadcasting: you can guess whether a node\nis a likely beacon based on previous results, and only broadcast likely\nwinners.  It also means each node only has to remember N * 144 routes\neach way if we want beacons to expire after a day.\n\nBut could also result in the beacons (and their neighbors) getting\nslammed.  Maybe beacons only become usable after 10 blocks, so they have\na chance to boost their connections in preparation?  I'd have to\nsimulate it...\n\nJoseph also pointed out that the anchor transactions in the blockchain\nimply the network topology.  That's kind of cool, but I'll let him\nexplore that.\n\nCheers,\nRusty"
            },
            {
                "author": "CJP",
                "date": "2015-07-07T19:06:08",
                "message_text_only": "The routing design has important implications for privacy, but also for\nthe enforcement of regulations on the Lightning network.\n\nImagine, for instance, that a couple of large nodes start requiring\ntheir neighbors to provide identity information (KYC-style regulation),\nand then require them to recursively provide identity information for\nall their neighbors' neighbors, and so on. If it is visible to\nintermediate nodes which other nodes participate in a transaction, this\nwould cause the Lightning network to split into a regulated and a\nnon-regulated part: nobody would dare to interface between the two,\nsince that would prove to the regulated side that they illegally provide\nconnectivity on the non-regulated side.\n\nSo, I don't want nodes to explicitly know the shape of the entire\nnetwork. Based on how Wikipedia explains source routing to me, I think\nit is incompatible with what I want. Please also note that IP almost\nnever uses source routing.\n\nAlso, as a counter-measure against censorship (or persecution) based on\ndestination address, I think the function of \"destination address of a\nroute\" should be de-coupled from the function of \"payer endpoint\" or\n\"payee endpoint\" of a route. In many cases, the \"payer endpoint\" or\nespecially the \"payee endpoint\" will also fulfill the role of\n\"destination address\", but they may also choose a neutral \"meeting\npoint\" node in the middle, and both route towards its address. This will\nallow nodes to secretly interface between regulated and non-regulated\nparts of the network, for transactions going in both directions.\n\nThe time-out value is a bit of a problem in this concept, since it is an\nindication of the number of hops from the payee endpoint. However, if\nnodes are free to choose the time-out increment for themselves, they\ncould choose to make that increment smaller, to be able to route through\na node that provides an interface to the regulated part.\n\nAn additional advantage of separating destination addresses from the\npayment endpoints is that routing tables can be much smaller. Most\nconsumers, and a lot of small shops can choose not to have their own\ndestination address, but instead route through the destination address\nof their Lightning provider (a bit like a NAT router's IP address).\n\nIn my view, routing tables are a sort of a heuristic, that tells you how\nlikely a payment (of a certain amount!) to/from a certain destination\naddress is to succeed on one of your interfaces. It is an optimization\nover the dumb algorithm of simply trying out all your interfaces one by\none(*). It is TBD how to determine these heuristics, and how to exchange\nthem between nodes.\n\nThis is probably quite different from how routing on the Internet works,\nand I'm not sure how it will scale and how it can be defended against\nDoS attacks, but it sort of follows automatically from the desire to\nkeep the network free.\n\nCJP\n\n(*) Which is currently the only routing method implemented in Amiko Pay.\n\n\nRusty Russell schreef op vr 03-07-2015 om 11:40 [+0930]:\n> Hi all,\n> \n>         One of the fun open questions for LN is how routing will work.\n> I'd like to kick off that discussion now, to see if we can create a\n> strawman which doesn't immediately collapse.\n> \n> Assumptions:\n> 1. I'm assuming each node is known by its pubkey.\n> \n> 2. Source routing seems the easiest route; best for privacy, best for\n>    any tradeoffs between reliability/price etc.\n> \n> 3. We should do onion routing: each node knows the source and next step.\n>    This is not perfect: R values trivially identifies connections (if\n>    you own two nodes on the path, you can connect them), and the timeout\n>    implies a minimum TTL.\n> \n> 4. A recipient gives the payer 100 routes from some nodes to them.  The\n>    payer hopefully can route to one of the mentioned nodes (probably the\n>    cheapest).  This also means that if the payer has to do some route\n>    query it doesn't trivially reveal who the recipient is.\n> \n> Route broadcast is more fun.  It's not like BGP where you have useful\n> subnets; even if you did, you need the pubkey of every node.\n> \n> My original idea was a subset of hubs (a few thousand?) to which you\n> would connect: that makes full discovery routing fairly easy within that\n> network, and you report your address as \"client XXXXX via hub <pubkey>\".\n> Your hub(s) keep the routing tables, you just query them mostly.\n> \n> A more ambitious idea would be to select N \"beacons\" based on the block\n> hash which every node figures out their best routes to/from.  That's\n> actually really efficient for broadcasting: you can guess whether a node\n> is a likely beacon based on previous results, and only broadcast likely\n> winners.  It also means each node only has to remember N * 144 routes\n> each way if we want beacons to expire after a day.\n> \n> But could also result in the beacons (and their neighbors) getting\n> slammed.  Maybe beacons only become usable after 10 blocks, so they have\n> a chance to boost their connections in preparation?  I'd have to\n> simulate it...\n> \n> Joseph also pointed out that the anchor transactions in the blockchain\n> imply the network topology.  That's kind of cool, but I'll let him\n> explore that.\n> \n> Cheers,\n> Rusty"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-08T00:21:14",
                "message_text_only": "CJP <cjp at ultimatestunts.nl> writes:\n> The routing design has important implications for privacy, but also for\n> the enforcement of regulations on the Lightning network.\n\nHi CJP!  I was hoping you'd weigh in here, thanks!\n\n> Imagine, for instance, that a couple of large nodes start requiring\n> their neighbors to provide identity information (KYC-style regulation),\n> and then require them to recursively provide identity information for\n> all their neighbors' neighbors, and so on. If it is visible to\n> intermediate nodes which other nodes participate in a transaction, this\n> would cause the Lightning network to split into a regulated and a\n> non-regulated part: nobody would dare to interface between the two,\n> since that would prove to the regulated side that they illegally provide\n> connectivity on the non-regulated side.\n>\n> So, I don't want nodes to explicitly know the shape of the entire\n> network. Based on how Wikipedia explains source routing to me, I think\n> it is incompatible with what I want. Please also note that IP almost\n> never uses source routing.\n\n        Total agreement.  The network must be robust against\ncensorship/partition for good technical reasons as well as malice.\nPeople will also rightfully expect a caching layer for bitcoin to have\nthe same open-membership properties that bitcoin has.\n\n> Also, as a counter-measure against censorship (or persecution) based on\n> destination address, I think the function of \"destination address of a\n> route\" should be de-coupled from the function of \"payer endpoint\" or\n> \"payee endpoint\" of a route. In many cases, the \"payer endpoint\" or\n> especially the \"payee endpoint\" will also fulfill the role of\n> \"destination address\", but they may also choose a neutral \"meeting\n> point\" node in the middle, and both route towards its address. This will\n> allow nodes to secretly interface between regulated and non-regulated\n> parts of the network, for transactions going in both directions.\n\nOK, so this is why I proposed an onion routing system.\n\nBasically: each node sees the next hop, the R hash, the amount, the\ntimeout, the fee being offered.  It doesn't see the source, nor the\nfinal destination.\n\nThis, however, requires source routing.\n\n> The time-out value is a bit of a problem in this concept, since it is an\n> indication of the number of hops from the payee endpoint. However, if\n> nodes are free to choose the time-out increment for themselves, they\n> could choose to make that increment smaller, to be able to route through\n> a node that provides an interface to the regulated part.\n>\n> An additional advantage of separating destination addresses from the\n> payment endpoints is that routing tables can be much smaller. Most\n> consumers, and a lot of small shops can choose not to have their own\n> destination address, but instead route through the destination address\n> of their Lightning provider (a bit like a NAT router's IP address).\n\nThis was close to my original mental model: several thousand hubs, most\npeople as clients.  But this risks becoming centralized, which directly\nleads to the problem of censorship.  You would simply blacklist certain\nproviders, or whitelist the ones you approve of.\n\nSo Joseph pushed my thinkoing in a radically more decentralized\ndirection, but routing becomes a *much* harder problem.\n\nAnyway, I think it makes sense to support this in the protocol by adding\nan opaque destination token.  This could distinguish separate payments\nor separate clients.  Some nodes may well support transparent forwarding\nof these to other nodes.\n\n> In my view, routing tables are a sort of a heuristic, that tells you how\n> likely a payment (of a certain amount!) to/from a certain destination\n> address is to succeed on one of your interfaces. It is an optimization\n> over the dumb algorithm of simply trying out all your interfaces one by\n> one(*). It is TBD how to determine these heuristics, and how to exchange\n> them between nodes.\n>\n> This is probably quite different from how routing on the Internet works,\n> and I'm not sure how it will scale and how it can be defended against\n> DoS attacks, but it sort of follows automatically from the desire to\n> keep the network free.\n\nYep, spray-and-pray is always a good starting point!  But it definitely\nwon't scale, so I'd like to make sure we don't paint ourselves into a\ncorner (even if that's our first cut).\n\nFees are a real issue.  Without source routing the client is guessing\nhow much fees will be, and there'll be a lot of gaming to decide how\nmuch of the pie to take (take too much, you get none as payment fails to\nroute).  I think you'll end up asking your provider how you should to\npay, and that's a pretty horrible model for privacy.\n\nWith source routing and onion it's a little better; you can explicitly\nstate what each hop gets.  Of course, if your route/payment information\nis out of date you lose, too.\n\nIn summary:\n\n1) Each-hop routing:\n        - Final destination hub is revealed to all nodes.\n                - May be forwarded, though.\n        - Source may be revealed to all nodes?\n        - Fees are tricky.\n                - Too low will fail\n                - How to estimate?\n        - Adaptable to changing network conditions\n                - Intermediary nodes can reroute.\n        - End clients need not know anything.\n\n2) Source routing:\n        - Neither final source nor dest revealed to intermediary nodes.\n        - Fees are known in advance.\n        - Requires retransmission from source if routes change.\n        - End clients need routing/fee information.\n        - Allows selection of nodes from source\n                - May let you avoid bad/tracking/unreliable nodes?\n\nIs there anything I missed?\n\nCheers,\nRusty."
            },
            {
                "author": "CJP",
                "date": "2015-07-14T18:03:56",
                "message_text_only": "> OK, so this is why I proposed an onion routing system.\n> \n> Basically: each node sees the next hop, the R hash, the amount, the\n> timeout, the fee being offered.  It doesn't see the source, nor the\n> final destination.\n> \n> This, however, requires source routing.\n\nAh, now I understand a bit better what you mean with onion routing. Yes,\nthat requires source routing, and it is another way of anonymizing the\nroute. A disadvantage of this approach is that it requires the source of\na route (so basically everyone) to know the shape of the network (who is\nconnected to who), which is a privacy disadvantage. This is not\nnecessary in TOR, since in TOR, every node can (usually) connect to\nevery other node, so finding a route is trivial.\n\nAt the risk of making things too complicated: it is possible to combine\nboth concepts in a single design. Source routing just requires the\nprotocol to be able to carry arbitrary payload data to the next\nwaypoint, so that the waypoint (which is supposed to understand the\narbitrary payload data) can determine how the route should be continued.\nIt's perfectly fine if the final waypoint of the route is a \"neutral\nmeeting point\" somewhere in the middle, as in my concept. In-between\nwaypoints, routers are free to use non-source routing, as long as the\nwaypoints can report with reasonable accuracy which other waypoints are\nreachable, so that other nodes know the high-level shape of the network\nfor use in their source routing.\n\nI don't see the \"several thousand hubs\" model as more sensitive to\ncentralization/censorship than other routing models, as long as there is\nno barrier to creating your own hub and to start using new hubs. Any\nrouting model has routable addresses and risks addresses being censored\nby a part of the network.\n\nThere is one other attack mode I see, which is independent of the\nrouting method: a powerful attacker (read: government) could be\nmonitoring transactions on several \"regulated\" nodes. It could also gain\nthe ability, every once in a while, to initiate transactions from an\n\"illegal\" node that should have been censored (e.g. by physical access\nto its hardware). If such transactions are routed over \"regulated\"\nnodes, it would immediately recognize this, because the transaction hash\nwould be the same. The attacker can then identify the node that allows\n\"illegal\" transactions to enter the regulated network, and punish it.\nEven if we find a way to somehow use a different hash on every hop of a\ntransaction, it can still do this based on the exact payment amount, or\nbased on timing. I don't see right now how this attack mode can be\neliminated; maybe it should be accepted as a risk inherent in the design\nof the network. Let's hope that the freedom-loving part of the network\nwill always be so large that censorship-loving parts will just hurt\nthemselves by isolating themselves.\n\n\n> In summary:\n> \n> 1) Each-hop routing:\n>         - Final destination hub is revealed to all nodes.\n>                 - May be forwarded, though.\nYes, may be forwarded, as in the \"hybrid design\" I described here. Also,\nbi-directional routing towards a meeting point in the middle doesn't\nreveal the final destination of the route as a whole.\n>         - Source may be revealed to all nodes?\nNot necessary. You just need to keep the route open for a while, so that\nmessages towards the source can follow it back.\n>         - Fees are tricky.\n>                 - Too low will fail\n>                 - How to estimate?\nI'll make another reply about fees; that's a whole subject on its own.\n>         - Adaptable to changing network conditions\n>                 - Intermediary nodes can reroute.\n>         - End clients need not know anything.\n> \n> 2) Source routing:\n>         - Neither final source nor dest revealed to intermediary nodes.\n>         - Fees are known in advance.\n>         - Requires retransmission from source if routes change.\n>         - End clients need routing/fee information.\n>         - Allows selection of nodes from source\n>                 - May let you avoid bad/tracking/unreliable nodes?\n\nCJP"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-15T01:19:25",
                "message_text_only": "CJP <cjp at ultimatestunts.nl> writes:\n> Rusty Russell <rusty at rustcorp.com.au> wrote:\n>> OK, so this is why I proposed an onion routing system.\n>> \n>> Basically: each node sees the next hop, the R hash, the amount, the\n>> timeout, the fee being offered.  It doesn't see the source, nor the\n>> final destination.\n>> \n>> This, however, requires source routing.\n>\n> Ah, now I understand a bit better what you mean with onion routing. Yes,\n> that requires source routing, and it is another way of anonymizing the\n> route. A disadvantage of this approach is that it requires the source of\n> a route (so basically everyone) to know the shape of the network (who is\n> connected to who), which is a privacy disadvantage. This is not\n> necessary in TOR, since in TOR, every node can (usually) connect to\n> every other node, so finding a route is trivial.\n>\n> At the risk of making things too complicated: it is possible to combine\n> both concepts in a single design. Source routing just requires the\n> protocol to be able to carry arbitrary payload data to the next\n> waypoint, so that the waypoint (which is supposed to understand the\n> arbitrary payload data) can determine how the route should be continued.\n> It's perfectly fine if the final waypoint of the route is a \"neutral\n> meeting point\" somewhere in the middle, as in my concept. In-between\n> waypoints, routers are free to use non-source routing, as long as the\n> waypoints can report with reasonable accuracy which other waypoints are\n> reachable, so that other nodes know the high-level shape of the network\n> for use in their source routing.\n\nIt does follow logically: the node is given the next hop, the fee the\ntransaction is prepared to pay there, and the time delta (eg. there must\nbe 3 days left on the HTLC at that point).\n\nIf it's expressed that way, there's no reason that \"next hop\" need be\nadjacent, right?\n\n> I don't see the \"several thousand hubs\" model as more sensitive to\n> centralization/censorship than other routing models, as long as there is\n> no barrier to creating your own hub and to start using new hubs. Any\n> routing model has routable addresses and risks addresses being censored\n> by a part of the network.\n\nMy concern is mainly that if we design something which doesn't scale,\nnodes will be forced to insert barriers to newcomers for their own\npreservation.  Thus my preference to design in terms of millions, not\nthousands, if that makes sense.\n\n> There is one other attack mode I see, which is independent of the\n> routing method: a powerful attacker (read: government) could be\n> monitoring transactions on several \"regulated\" nodes. It could also gain\n> the ability, every once in a while, to initiate transactions from an\n> \"illegal\" node that should have been censored (e.g. by physical access\n> to its hardware). If such transactions are routed over \"regulated\"\n> nodes, it would immediately recognize this, because the transaction hash\n> would be the same. The attacker can then identify the node that allows\n> \"illegal\" transactions to enter the regulated network, and punish it.\n> Even if we find a way to somehow use a different hash on every hop of a\n> transaction, it can still do this based on the exact payment amount, or\n> based on timing. I don't see right now how this attack mode can be\n> eliminated; maybe it should be accepted as a risk inherent in the design\n> of the network. Let's hope that the freedom-loving part of the network\n> will always be so large that censorship-loving parts will just hurt\n> themselves by isolating themselves.\n\nYes, indeed.\n\nCheers,\nRusty."
            },
            {
                "author": "CJP",
                "date": "2015-07-14T18:54:44",
                "message_text_only": "> Fees are a real issue.  Without source routing the client is guessing\n> how much fees will be, and there'll be a lot of gaming to decide how\n> much of the pie to take (take too much, you get none as payment fails to\n> route).  I think you'll end up asking your provider how you should to\n> pay, and that's a pretty horrible model for privacy.\n> \n> With source routing and onion it's a little better; you can explicitly\n> state what each hop gets.  Of course, if your route/payment information\n> is out of date you lose, too.\n\nI like to think of fees in the same way as we pay for Internet access.\nEvery physical hop in the Internet has related costs, e.g. in placing\nthe cables and upgrading the cables when new technology becomes\navailable and when demand grows. Yet it doesn't matter for your Internet\nbill how many hops your packets make, or which route they follow. Your\nISP will just average out all the costs it has to make on its\ninterfaces, and present a fraction of that to each customer. At some\npoints in the middle between providers, there are places where both\nsides have an equal interest in maintaining their link, and no fees are\ncharged.\n\nOne major difference with the Internet is that we already have a\nmicro-transaction infrastructure in place, which is something the\nInternet has never had (until now). This means it is possible to do\ninstant per-transaction payment of transaction fees. The fact that we\nCAN do it doesn't mean we SHOULD, but I think there are advantages:\nnon-immediate payment models always require some form of trust from at\nleast one of the sides. Immediate payment of a transaction fee is as\nsimple as updating the micro-transaction channel with a slightly larger\namount than the to-be-forwarded transaction amount.\n\nAn interesting question is whether nodes will be prepared to forward\npayments at a net loss (the to-be-paid fee is higher than the\nto-be-received fee); maybe they will, if they can compensate the losses\nwith higher profits on other transactions. Fee differences could play a\nrole in routing decisions.\n\nThat brings me to another point: fees could be used as a way to\nincentivize people to bring channels back to equilibrium. When a\nchannel's funds are almost fully assigned to one of its sides, further\npayments towards that side become nearly impossible. Increasing fees in\nthat direction and decreasing fees in the opposite direction should\nincentivize people to perform more transactions that bring the channel\nback to equilibrium, and to perform less transactions that bring it\nfurther out of equilibrium, or find alternative routes for those\ntransactions.\n\nYou could even offer negative fees for transactions that bring a channel\nback to equilibrium. There could be a market for people making money\nfrom bringing other peoples' channels back to equilibrium. This would\nrequire either to step away from \"net neutrality\" (so, not the same fee\nfor every route / destination), or it would require some form of source\nrouting and explicitly setting the fees of intermediate nodes.\n\nMy \"neutral meeting point\" routing design, which is effectively a\ntwo-hop source routing, is already good enough: a node in the middle of\nthe network is advertising that it can benefit from a negative fee, and\nit invites people to perform transactions and to share the profit. It\ncreates two routable addresses (one for the negative-fee interface (A)\nand one for all other interfaces (B)). Other people can then perform a\npayment-to-self, with payee side routing to A and payer-side routing to\nB. Payee-side can then have a larger payment amount than payer-side, as\nagreed with the meeting point, to transfer a part of the profit to the\nperson performing the transaction.\n\nCJP"
            },
            {
                "author": "Nick ODell",
                "date": "2015-07-15T00:29:10",
                "message_text_only": ">I like to think of fees in the same way as we pay for Internet access.\n>Every physical hop in the Internet has related costs, e.g. in placing\n>the cables and upgrading the cables when new technology becomes\n>available and when demand grows.\n\nWhat sort of fee would this be? A percentage fee? A per-transaction fee? Both?\n\nI can see a compelling case for any of the three.\n\nOn Tue, Jul 14, 2015 at 12:54 PM, CJP <cjp at ultimatestunts.nl> wrote:\n>\n>> Fees are a real issue.  Without source routing the client is guessing\n>> how much fees will be, and there'll be a lot of gaming to decide how\n>> much of the pie to take (take too much, you get none as payment fails to\n>> route).  I think you'll end up asking your provider how you should to\n>> pay, and that's a pretty horrible model for privacy.\n>>\n>> With source routing and onion it's a little better; you can explicitly\n>> state what each hop gets.  Of course, if your route/payment information\n>> is out of date you lose, too.\n>\n> I like to think of fees in the same way as we pay for Internet access.\n> Every physical hop in the Internet has related costs, e.g. in placing\n> the cables and upgrading the cables when new technology becomes\n> available and when demand grows. Yet it doesn't matter for your Internet\n> bill how many hops your packets make, or which route they follow. Your\n> ISP will just average out all the costs it has to make on its\n> interfaces, and present a fraction of that to each customer. At some\n> points in the middle between providers, there are places where both\n> sides have an equal interest in maintaining their link, and no fees are\n> charged.\n>\n> One major difference with the Internet is that we already have a\n> micro-transaction infrastructure in place, which is something the\n> Internet has never had (until now). This means it is possible to do\n> instant per-transaction payment of transaction fees. The fact that we\n> CAN do it doesn't mean we SHOULD, but I think there are advantages:\n> non-immediate payment models always require some form of trust from at\n> least one of the sides. Immediate payment of a transaction fee is as\n> simple as updating the micro-transaction channel with a slightly larger\n> amount than the to-be-forwarded transaction amount.\n>\n> An interesting question is whether nodes will be prepared to forward\n> payments at a net loss (the to-be-paid fee is higher than the\n> to-be-received fee); maybe they will, if they can compensate the losses\n> with higher profits on other transactions. Fee differences could play a\n> role in routing decisions.\n>\n> That brings me to another point: fees could be used as a way to\n> incentivize people to bring channels back to equilibrium. When a\n> channel's funds are almost fully assigned to one of its sides, further\n> payments towards that side become nearly impossible. Increasing fees in\n> that direction and decreasing fees in the opposite direction should\n> incentivize people to perform more transactions that bring the channel\n> back to equilibrium, and to perform less transactions that bring it\n> further out of equilibrium, or find alternative routes for those\n> transactions.\n>\n> You could even offer negative fees for transactions that bring a channel\n> back to equilibrium. There could be a market for people making money\n> from bringing other peoples' channels back to equilibrium. This would\n> require either to step away from \"net neutrality\" (so, not the same fee\n> for every route / destination), or it would require some form of source\n> routing and explicitly setting the fees of intermediate nodes.\n>\n> My \"neutral meeting point\" routing design, which is effectively a\n> two-hop source routing, is already good enough: a node in the middle of\n> the network is advertising that it can benefit from a negative fee, and\n> it invites people to perform transactions and to share the profit. It\n> creates two routable addresses (one for the negative-fee interface (A)\n> and one for all other interfaces (B)). Other people can then perform a\n> payment-to-self, with payee side routing to A and payer-side routing to\n> B. Payee-side can then have a larger payment amount than payer-side, as\n> agreed with the meeting point, to transfer a part of the profit to the\n> person performing the transaction.\n>\n> CJP\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "CJP",
                "date": "2015-07-15T20:19:56",
                "message_text_only": "Nick ODell schreef op di 14-07-2015 om 18:29 [-0600]:\n> >I like to think of fees in the same way as we pay for Internet access.\n> >Every physical hop in the Internet has related costs, e.g. in placing\n> >the cables and upgrading the cables when new technology becomes\n> >available and when demand grows.\n> \n> What sort of fee would this be? A percentage fee? A per-transaction fee? Both?\n> \n> I can see a compelling case for any of the three.\n\nRusty has argued for a fee that scales with Satoshi-seconds, so the\nto-be-transferred amount times the amount of time it takes to finish the\ntransaction. The reason for that would be because then the fee scales\nwith the actual scarce good you're consuming (the ability to lock a\ncertain amount of funds for a certain amount of time on a channel is the\nthing that's scarce).\n\nPersonally, I'd like to keep participants as free as possible in\nchoosing the right fee structure; the technology platform shouldn't\nstand in the way. Virtually any fee structure is possible anyway, as\nlong as some trust exists between two sides of a link, but in order to\nmake fees trust-free, some fee structures require special features from\nthe underlying technology. Per-transaction fees that can be determined\nin advance are easy to do, but e.g. the Satoshi-seconds structure is\nsomething that requires an extension of the micro-transaction channel\ndesign.\n\nCJP"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-15T02:21:06",
                "message_text_only": "CJP <cjp at ultimatestunts.nl> writes:\n>> Fees are a real issue.  Without source routing the client is guessing\n>> how much fees will be, and there'll be a lot of gaming to decide how\n>> much of the pie to take (take too much, you get none as payment fails to\n>> route).  I think you'll end up asking your provider how you should to\n>> pay, and that's a pretty horrible model for privacy.\n>> \n>> With source routing and onion it's a little better; you can explicitly\n>> state what each hop gets.  Of course, if your route/payment information\n>> is out of date you lose, too.\n>\n> I like to think of fees in the same way as we pay for Internet access.\n> Every physical hop in the Internet has related costs, e.g. in placing\n> the cables and upgrading the cables when new technology becomes\n> available and when demand grows. Yet it doesn't matter for your Internet\n> bill how many hops your packets make, or which route they follow. Your\n> ISP will just average out all the costs it has to make on its\n> interfaces, and present a fraction of that to each customer. At some\n> points in the middle between providers, there are places where both\n> sides have an equal interest in maintaining their link, and no fees are\n> charged.\n>\n> One major difference with the Internet is that we already have a\n> micro-transaction infrastructure in place, which is something the\n> Internet has never had (until now). This means it is possible to do\n> instant per-transaction payment of transaction fees. The fact that we\n> CAN do it doesn't mean we SHOULD, but I think there are advantages:\n> non-immediate payment models always require some form of trust from at\n> least one of the sides. Immediate payment of a transaction fee is as\n> simple as updating the micro-transaction channel with a slightly larger\n> amount than the to-be-forwarded transaction amount.\n\nYes, it's a great question!  The resource which is used up is not so\nmuch CPU and bandwidth, it's the channel capacity and the security risk\ninvolved with having bitcoin in a hot wallet.  Both these costs scale\nwith the size of payment, making a \"pay per satoshi\" model seem\nreasonable.\n\nI'm concerned that if we don't take a reasonable stab at monetization,\nit's another centralization pressure: the only nodes become those who\nhave a second income source, such as selling your data or providing\nservice only to (paying) registered businesses.\n\n> An interesting question is whether nodes will be prepared to forward\n> payments at a net loss (the to-be-paid fee is higher than the\n> to-be-received fee); maybe they will, if they can compensate the losses\n> with higher profits on other transactions. Fee differences could play a\n> role in routing decisions.\n>\n> That brings me to another point: fees could be used as a way to\n> incentivize people to bring channels back to equilibrium. When a\n> channel's funds are almost fully assigned to one of its sides, further\n> payments towards that side become nearly impossible. Increasing fees in\n> that direction and decreasing fees in the opposite direction should\n> incentivize people to perform more transactions that bring the channel\n> back to equilibrium, and to perform less transactions that bring it\n> further out of equilibrium, or find alternative routes for those\n> transactions.\n>\n> You could even offer negative fees for transactions that bring a channel\n> back to equilibrium. There could be a market for people making money\n> from bringing other peoples' channels back to equilibrium. This would\n> require either to step away from \"net neutrality\" (so, not the same fee\n> for every route / destination), or it would require some form of source\n> routing and explicitly setting the fees of intermediate nodes.\n\nYes, this was suggested to me by Joseph Poon in a face-to-face\nconversation we had in San Francisco.  It kind of blew my mind,\nactually.  The fact that you discovered it too provides fairly\nconvincing proof that you're smarter than me :)\n\neg. He suggested your client would initially connect to 5 random hubs.\nIt would then occasionally route payments back to itself, where doing so\nwas profitable or even neutral.  If every client did this, it could\nprovide significant liquidity.\n\n> My \"neutral meeting point\" routing design, which is effectively a\n> two-hop source routing, is already good enough: a node in the middle of\n> the network is advertising that it can benefit from a negative fee, and\n> it invites people to perform transactions and to share the profit. It\n> creates two routable addresses (one for the negative-fee interface (A)\n> and one for all other interfaces (B)). Other people can then perform a\n> payment-to-self, with payee side routing to A and payer-side routing to\n> B. Payee-side can then have a larger payment amount than payer-side, as\n> agreed with the meeting point, to transfer a part of the profit to the\n> person performing the transaction.\n\n(Sorry, a bit of a brain dump follows!)\n\nI think negative fees fall out naturally from a route description which\nincludes fees (eg. A->B costs Xa + Ya-per-satoshi, B->A costs Xb +\nYb-per-satoshi).  Naturally they need constraints (ie. don't bother\nsending me 1BTC, my channel isn't that big).\n\nThere's going to be a real problem here with minimizing route flap.\nSpamming the network every time pricing changes due to another HTLC is\nnot going to work, and could even undermine privacy by revealing\namounts.\n\nA time-based model may work, but we'd need some serious modelling.\neg. \"My fee will decrease by 0.1 satoshi per byte per second until you\nhear otherwise\".\n\nWRT fee payment: The simplest fee method involves skimming an amount\nfrom the HTLC.  That only works if the HTLC succeeds!  On the other\nhand, if you pay each node up-front, it has no incentive to deliver.\nAnd stalled payments are the greatest cost to a node (tying up capital\nfor days, potentially).\n\nIt seems the ideal payment calculation would be in satoshi-seconds (how\nmuch capital you used, for how long).\n\nPerhaps we can rig something that requires the recipient to pay more\naccording to time?\n\nJoseph?\n\nCheers,\nRusty."
            },
            {
                "author": "Joseph Poon",
                "date": "2015-07-15T18:54:47",
                "message_text_only": "On Wed, Jul 15, 2015 at 11:51:06AM +0930, Rusty Russell wrote:\n> Perhaps we can rig something that requires the recipient to pay more\n> according to time?\n> \n> Joseph?\n\nIt's definitely possible, depends on what kind of complexity you're\ncomfortable with. I think Tadge brought up the idea a long time ago\nabout using the timelock for decay of payments with one's counterparty\nfor on-chain enforceability. E.g. A current Commitment has 50\nsub-commitments which pay out different lightning fee values with later\nlocktimes.\n\nPresume an HTLC has a 0.09 value with 0.01 allocated to fees (refunds\nback to Alice any extra fees). If we are currently at Commitment #123,\nwe have Commitment123_1, Commitment123_2, and Commitment123_3. Each have\nvery similar payouts, with very minor differences in HTLC fees paid and\nthe locktime.\n\nAssuming some kind of full on-chain Replace-By-Fee, you\ncan prioritize Commitment123_3 over Commitment123_2 on-chain, but\nCommitment123_3 will also have a higher fee on lightning as well.\nHowever, Commitment123_3 can only be broadcast at a later date, so\n\"earlier\" Commitment123 values can be valid. Things can get a little\nwonky at the edges, so you have to arrange the fees such that if there's\nsome time asynchronousness along the chain, that intermediary nodes\ndon't lose out (functionally I think this means the time-decay will be\nsomewhat marginal and be a small percentage of the total lightning fees\npaid).\n\n-- \nJoseph Poon"
            },
            {
                "author": "CJP",
                "date": "2015-07-15T20:05:44",
                "message_text_only": "> > You could even offer negative fees for transactions that bring a channel\n> > back to equilibrium. There could be a market for people making money\n> > from bringing other peoples' channels back to equilibrium. This would\n> > require either to step away from \"net neutrality\" (so, not the same fee\n> > for every route / destination), or it would require some form of source\n> > routing and explicitly setting the fees of intermediate nodes.\n> \n> Yes, this was suggested to me by Joseph Poon in a face-to-face\n> conversation we had in San Francisco.  It kind of blew my mind,\n> actually.  The fact that you discovered it too provides fairly\n> convincing proof that you're smarter than me :)\n\nMaybe :), but I'm not sure I invented it myself. I had a talk about\nAmiko Pay at the Bitcoinference in Amsterdam, and someone in the\naudience actually came up with this idea. I vaguely remember I was\nalready playing with the idea at that time, but I'm not really sure.\n\nCJP"
            },
            {
                "author": "Anthony Towns",
                "date": "2015-07-18T09:46:35",
                "message_text_only": "On 8 July 2015 at 10:21, Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> 1) Each-hop routing:\n> 2) Source routing:\n> Is there anything I missed?\n>\n\n\u200b\"Por que no los dos?\"\n\nIf you have source routing from alice to bob to carol to dave, with\nspecified fees for each hop, why should that preclude bob deciding to route\nto carol via eliza and frank (and sharing the hop's fee correspondingly)?\nThen \"each-hop\" routing falls out as the special case where you specify\nsource routing directly from your hub to the final destination.\n\n3) Extensible source-routing\n    - client chooses how many layers are required (fees, reliability vs\nanonymity)\n    - at any point, holder of transaction may extend the route by adding\nintermediary hops (optimise fees, channels, hub/hub balances, etc)\n   Pros:\n    - only hop endpoints are visible at any step\n    - adaptable to changing network conditions\n    - source can be anonymous to destination, source and destination\nanonymous to intermediaries\n    - clients need minimal info (ability to estimate fees, info on hub\nreputation for anonymising)\n   Cons:\n    - does not let you avoid nodes\n      + (NSA sets up a hub with negative fees in every direction, hubs\nreroute everything though it to bump their fees)\n    - how to work out fees?\n    - how to figure out how to route to other hubs you don't want to have a\ndirect channel with?\n\nI think the latter two points have to be solved with some sort of global\n(but not necessarily complete) routing announcement service, so you can\nquery who has channels and do cheapest path finding amongst them;\nclients/leaf-nodes so they can estimate fees, hubs so they can do routing,\noptimise fees, and work out profitable new channels to connect. Maybe that\ncan be derived from transactions on the blockchain though? But that's\nalready in the lightning paper.\n\nI think a routed \"transaction\" looks something like:\n\n To: Bob\n  - Here's 200 satoshi from Alice locked with R\n  - You need to send 195 satoshi to Carol with message X, who will unlock R.\n\nSo extending the route would just be Bob making a new transaction:\n\n To: Dave:\n  - Here's 198 satoshi from Bob locked with R\n  - You need to send 195 satoshi to Carol with message X, who will unlock R.\n\nwhich seems plausible -- though I haven't checked it against the actual\nprotocol so maybe it fails in the details... If it's okay, then maliciously\nrouting to /dev/null just means R never gets revealed, no one gets paid,\nand the transaction eventually is considered refunded/cancelled; and if it\ndoes get where it's going the only consequence versus going directly is it\ntakes a little longer and Bob loses some fees.\n\nSpeaking of fees, I wonder if the \"fee proportional to satoshi-hours\" is\nbackwards -- rather than saying \"the intermediary wants to charge for how\nlong finalisation takes\", couldn't you just say \"the sender is willing to\npay inversely to how long finalisation takes\" in every case?\n\nIf I'm an intermediary, that works out as me being offered (F - k * t)\nsatoshi to deliver X satoshi within t seconds, for some F and k, then if I\nwant to take a cut of X*t*r to cover my costs, that just looks like me\nonsending X satoshi plus a fee of up to (F - k * t - X*t*r) = (F - (k+X*r)\n* t). If you can arrange that fee structure technically, a successful\ntransaction means everyone has an incentive to close the txn ASAP\n(including the final recipient who receives the leftover fee as a\ntime-sensitive bonus). In that case you just want to choose r based on your\navailable funds in both directions, making it expensive when you're\nover-committed, and potentially offering refunds (r<0) when you're\nunbalanced.\n\nI think it's possible to cancel an unroutable transaction so that the funds\ncan be reused (by effectively routing back to the sender?); if it is,\nnominating a smaller but still time-sensitive fee to have that happen\nsooner rather than later might be good too. That could also be used to\nimplement a fee-enforced TTL; if the success fee is characterised by (F_1,\nk_1) and the failure fee is (F_2, k_2), with F_1 > F_2 and k_1 > k_2 then\nfailing becomes more profitable than succeeding at t > (F_1-F_2) /\n(k_1-k_2). (F_2 > F_1, failing is immediately better than succeeding; k_2 >\nk_1, failing never become a better option; when passing on fees, probably\nwould be clever to keep that time roughly constant, which is admittedly\nstraight-forward). That might be useful if you want the protocol to have\nlong timeouts for safety, but you want short timeouts in practice for\nresponsiveness.\n\nOffering an insufficient fee seems like it would easily render a\ntransaction unroutable; if one of the hubs is on a satellite or floating\nplatform for anonymity purposes, it might want massively high fees; if\nonion routing is in place, this may only be discoverable mid-way through\nthe routing.\n\nIf you structure the transaction as \"<Bob> here's <N-K*t> satoshi, locked\nwith <R> to be revealed by <Carol> once you deliver <M> and as many of\nthose satoshi as possible to her\" with the actual payment Carol's expecting\nnot encoded anywhere other than (encrypted) in M, then if Bob tries taking\nmore fees than needed, he increases the risk Carol won't unlock R and he'll\nget nothing.\n\nI don't quite see how channels can be safely used for independent\nconcurrent transactions though. If I (Bob) have an idle channel to Carol\nfor 100k satoshi, and I want to route 100 satoshi on behalf of Alice to\nDave (locked to R_1), and 200 satoshi from Anna to Doug (locked to R_2) and\n150 satoshi from Amelia to Drew through that channel simultaneously, how do\nI sign things given that any combination of those transactions could fail,\nbreaking the potential \"chain\"? There's 7 scenarios that could happen then,\ndo I need to send potential transactions for all of them to Carol?\n\n    CHANNEL -> [a] Bob 999,900 | Carol + R_1 100\n\n    CHANNEL -> [b] Bob 999,800 | Carol + R_2 200\n    [a]     -> [c] Bob 999,700 | Carol + R_2 200\n\n    CHANNEL -> [_] Bob 999,850 | Carol + R_3 150\n    [a]     -> [_] Bob 999,750 | Carol + R_3 150\n    [b]     -> [_] Bob 999,650 | Carol + R_3 150\n    [c]     -> [_] Bob 999,550 | Carol + R_3 150\n\nIf you can't have concurrent independent txns on a channel, then it seems\nlike you want /really/ short timeouts (seconds not days) to keep things\nflowing -- your txn doesn't block just the satoshis its spending, it blocks\n/all/ the unspent satoshis in the channel...\n\nCheers,\naj (hoping the above is adding to the discussion)\n\n-- \nAnthony Towns <aj at erisian.com.au>\n\u200b\u200b\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150718/2b1d2c60/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-18T11:10:01",
                "message_text_only": "Anthony Towns <aj at erisian.com.au> writes:\n> On 8 July 2015 at 10:21, Rusty Russell <rusty at rustcorp.com.au> wrote:\n>\n>> 1) Each-hop routing:\n>> 2) Source routing:\n>> Is there anything I missed?\n>>\n>\n> \u200b\"Por que no los dos?\"\n>\n> If you have source routing from alice to bob to carol to dave, with\n> specified fees for each hop, why should that preclude bob deciding to route\n> to carol via eliza and frank (and sharing the hop's fee correspondingly)?\n> Then \"each-hop\" routing falls out as the special case where you specify\n> source routing directly from your hub to the final destination.\n\nSi!  As I said in a followup to CJP:\n\n    It does follow logically: the node is given the next hop, the fee the\n    transaction is prepared to pay there, and the time delta (eg. there must\n    be 3 days left on the HTLC at that point).\n\n    If it's expressed that way, there's no reason that \"next hop\" need be\n    adjacent, right?\n\nIn fact, you can't really avoid them using intermediaries.\n\n>    Cons:\n>     - does not let you avoid nodes\n>       + (NSA sets up a hub with negative fees in every direction, hubs\n> reroute everything though it to bump their fees)\n\nGood point.  Especially if they're prepared to use very tight timing\n(since the money is not important), so a node won't lose too much expiry\ntime on the HTLC.\n\n>     - how to work out fees?\n>     - how to figure out how to route to other hubs you don't want to have a\n> direct channel with?\n> \n> I think the latter two points have to be solved with some sort of global\n> (but not necessarily complete) routing announcement service, so you can\n> query who has channels and do cheapest path finding amongst them;\n> clients/leaf-nodes so they can estimate fees, hubs so they can do routing,\n> optimise fees, and work out profitable new channels to connect.\n\nAgreed.  I think some dynamic routing protocol has to give you fees and\nother info.  That's a fun, hard problem.\n\n> Maybe that\n> can be derived from transactions on the blockchain though? But that's\n> already in the lightning paper.\n\nJoseph half-seriously suggested that the anchor txs be open-kimono,\nmeaning that the routing info is on the blockchain already.  It's cute,\nbut since you need the dynamic info I'm not sure it saves anyyhing.\n\n> Speaking of fees, I wonder if the \"fee proportional to satoshi-hours\" is\n> backwards -- rather than saying \"the intermediary wants to charge for how\n> long finalisation takes\", couldn't you just say \"the sender is willing to\n> pay inversely to how long finalisation takes\" in every case?\n>\n> If I'm an intermediary, that works out as me being offered (F - k * t)\n> satoshi to deliver X satoshi within t seconds, for some F and k, then if I\n> want to take a cut of X*t*r to cover my costs, that just looks like me\n> onsending X satoshi plus a fee of up to (F - k * t - X*t*r) = (F - (k+X*r)\n> * t). If you can arrange that fee structure technically, a successful\n> transaction means everyone has an incentive to close the txn ASAP\n> (including the final recipient who receives the leftover fee as a\n> time-sensitive bonus). In that case you just want to choose r based on your\n> available funds in both directions, making it expensive when you're\n> over-committed, and potentially offering refunds (r<0) when you're\n> unbalanced.\n\nI think there's a natural bias to collect ASAP in every case, so I'm not\nsure if further incentive there is required.\n\nThe problematic case is payment fail after timeout.  In a naive model,\nif the payment succeeds (eventually), at least you get some money.  If\nit fails, there's no transaction to skim the fees from.\n\n> I think it's possible to cancel an unroutable transaction so that the funds\n> can be reused (by effectively routing back to the sender?); if it is,\n> nominating a smaller but still time-sensitive fee to have that happen\n> sooner rather than later might be good too. That could also be used to\n> implement a fee-enforced TTL; if the success fee is characterised by (F_1,\n> k_1) and the failure fee is (F_2, k_2), with F_1 > F_2 and k_1 > k_2 then\n> failing becomes more profitable than succeeding at t > (F_1-F_2) /\n> (k_1-k_2). (F_2 > F_1, failing is immediately better than succeeding; k_2 >\n> k_1, failing never become a better option; when passing on fees, probably\n> would be clever to keep that time roughly constant, which is admittedly\n> straight-forward). That might be useful if you want the protocol to have\n> long timeouts for safety, but you want short timeouts in practice for\n> responsiveness.\n\nThe TTL in practice is the time difference each node wants for timeouts.\nOP_CSV is cleverly implemented in terms of median blocktime, which makes\nit less manipulable, but I wouldn't want to use a difference of less 1\nhour per hop simply because there's a non-trivial chance of getting no\nblocks for an hour.\n\n> Offering an insufficient fee seems like it would easily render a\n> transaction unroutable; if one of the hubs is on a satellite or floating\n> platform for anonymity purposes, it might want massively high fees; if\n> onion routing is in place, this may only be discoverable mid-way through\n> the routing.\n>\n> If you structure the transaction as \"<Bob> here's <N-K*t> satoshi, locked\n> with <R> to be revealed by <Carol> once you deliver <M> and as many of\n> those satoshi as possible to her\" with the actual payment Carol's expecting\n> not encoded anywhere other than (encrypted) in M, then if Bob tries taking\n> more fees than needed, he increases the risk Carol won't unlock R and he'll\n> get nothing.\n\nNo, I think fees need to be explicit.  \"I will pay you N satoshi to get\nM satoshi to Carol\".\n\n> I don't quite see how channels can be safely used for independent\n> concurrent transactions though. If I (Bob) have an idle channel to Carol\n> for 100k satoshi, and I want to route 100 satoshi on behalf of Alice to\n> Dave (locked to R_1), and 200 satoshi from Anna to Doug (locked to R_2) and\n> 150 satoshi from Amelia to Drew through that channel simultaneously, how do\n> I sign things given that any combination of those transactions could fail,\n> breaking the potential \"chain\"? There's 7 scenarios that could happen then,\n> do I need to send potential transactions for all of them to Carol?\n\nThey become separate HTLCs.  That all works fine.\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Routing on the lightning network?",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Anthony Towns",
                "Joseph Poon",
                "CJP",
                "Rusty Russell",
                "Nick ODell"
            ],
            "messages_count": 13,
            "total_messages_chars_count": 51777
        }
    },
    {
        "title": "[Lightning-dev] Updates, move to Elements Alpha",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2015-07-06T03:49:03",
                "message_text_only": "Hi all!\n\n        Those watching the repository late last week will note that the\ncode has gained ifdefs to support Blockstream's Elements Alpha\nsidechain.  Along the way, there were some bugfixes as you'd expect.\n\n        This is a stepping stone; done because it already has the\nfeatures LN wants which aren't soft-forked into bitcoin yet.  OTOH,\nalpha contains many \"cool features\" we don't care about (like\nConfidential Transactions), but made the port a bit trickier than I'd\nhoped.\n\n        I'm working on HTLCs now.  Because I'm using hashes for\nrevocation rather than exposing private keys (and because I'm using\nOP_CHECKSEQUENCEVERIFY), they look different from the ones in the paper.\nOnce I've got something that's not obviously wrong, I'll post here.\n\nThanks,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Updates, move to Elements Alpha",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 776
        }
    },
    {
        "title": "[Lightning-dev] HTLCs using OP_CHECKSEQUENCEVERIFY/OP_LOCKTIMEVERIFY and revocation hashes.",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2015-07-06T06:41:34",
                "message_text_only": "Hi all,\n\n        To recap: each side maintains a commitment transaction with two\noutputs: one paying to self (with some delay), and the second paying to\nthe other side.\n\n        To generate hash time-locked contracts (required for lightning\nto be a network), both commitment transactions get an additional output.\nThis output is spendable under four conditions:\n\n1) Recipient knows the R value (funds go to recipient), OR\n2) The HTLC has timed out (funds return to initiator), OR\n3) The HTLC has been revoked (funds to go \"non-cheating\" side), OR\n4) The Commit transaction has been revoked (funds to go \"non-cheating\" side)\n\nThe last two failure modes are separate from each other, because HTLCs\nhave different lifetimes from commit transactions.\n\nSince we use \"revocation preimages\" to revoke transactions (rather than\nsending pubkeys as the original draft paper), the result of this for A's\ncommitment transaction look like this:\n\nHTLC from A to B:\n1) R value and B's signature, OR\n2) HTLC timeout and A's signature[*], OR\n3) HTLC revocation preimage and B's signature, OR\n4) Commitment transaction revocation preimage and B's signature.\n\nHTLC from B to A:\n1) R value and A's signature[*], OR\n2) HTLC timeout and B's signature, OR\n3) HTLC revocation preimate and B's signature, OR\n4) Commitment transaction revocation preimage and B's signature.\n\nWe need to ensure delays in the cases where payment can go to A (marked\nwith [*]) so that B has a chance to steal the funds if the HTLC or\ncommitment tx has been revoked.\n\nThe result is one of the following scriptPubKey from the commitment tx\nfor the HTLC like so (note: unchecked and unoptimized!):\n\nHTLC from US to THEM:\n---------------------\n\n# They present HTLC's R value, or either revocation hash:\nOP_DUP OP_HASH160 <HTLC-R-HASH> OP_EQUAL\nOP_SWAP <HTLC-REVOCATION-HASH> OP_EQUAL\nOP_ADD OP_SWAP <COMMIT-REVOCATION-HASH> OP_EQUAL\nOP_ADD\nOP_IF\n        # One hash matched, pay to them.\n        OP_DUP OP_HASH160 <THEM-pubKeyHash> OP_EQUALVERIFY OP_CHECKSIG\nOP_ELSE\n        # Must be us, with HTLC timed out.\n        <HTLC-ABSOLUTE-TIMEOUT> OP_CHECKLOCKTIMEVERIFY OP_DROP\n        <VERIFICATION-RELATIVE-TIMEOUT> OP_CHECKSEQUENCEVERIFY OP_DROP\n        OP_DUP OP_HASH160 <US-pubKeyHash> OP_EQUALVERIFY OP_CHECKSIG\nOP_ENDIF\n\nHTLC from THEM to US:\n---------------------\n# Revocation cases:\nOP_DUP OP_HASH160 <HTLC-REVOCATION-HASH> OP_EQUAL\nOP_SWAP <COMMIT-REVOCATION-HASH> OP_EQUAL\nOP_ADD\nOP_IF\n        # One hash matched, pay to them.\n        OP_DUP OP_HASH160 <THEM-pubKeyHash> OP_EQUALVERIFY OP_CHECKSIG\nOP_ELSE\n        # Us with R value?\n        3 OP_DEPTH OP_EQUAL OP_IF\n                OP_DUP OP_HASH160 <HTLC-R-HASH> OP_EQUALVERIFY\n                <VERIFICATION-RELATIVE-TIMEOUT> OP_CHECKSEQUENCEVERIFY OP_DROP\n                OP_DUP OP_HASH160 <US-pubKeyHash> OP_EQUALVERIFY OP_CHECKSIG\n        OP_ELSE\n                # Them with timeout.\n                <HTLC-ABSOLUTE-TIMEOUT> OP_CHECKLOCKTIMEVERIFY OP_DROP\n                OP_DUP OP_HASH160 <THEM-pubKeyHash> OP_EQUALVERIFY OP_CHECKSIG\n        OP_ENDIF\nOP_ENDIF\n\nIf you've read this far, congratulations!\n\nAFAICT we don't need new SIGOPS here; the logic has all been moved to\nthe commitment transaction output (thanks to OP_CLV and OP_CSV), so each\nside can generate the HTLC spending transaction with needing a signature\nfrom the other.\n\nFeedback, fixed and optimizations welcome...\nRusty."
            },
            {
                "author": "CJP",
                "date": "2015-07-07T19:51:54",
                "message_text_only": "> Since we use \"revocation preimages\" to revoke transactions (rather than\n> sending pubkeys as the original draft paper)\n\nI remember the original paper mentioned sending private keys. I suppose\nyou mean that the preimages replace the *private* keys, not the pubkeys?\n\nI was not aware of that design change, but it sounds like an\nimprovement.\n\nCJP"
            },
            {
                "author": "Adam Back",
                "date": "2015-07-07T19:59:28",
                "message_text_only": "The use of the private key sending function, is just intended to be a\nmore compact and efficient way of sending the other end of the channel\na signed message, it says \"well here, have the private key, you can\nsign it yourself\".\n\nNow that being the case, and as the transaction has another signature\nanyway it occurred to me that you should be able to use a chain of\nhash preimages to do it more efficiently again.\n\nRusty generalised that to have a lower setup by using a short of\nhypercube multi-dimensional array of preimages.  (If you want 1million\nhash preimages, then you have to actually compute 1 million of them at\nsetup.)  I had the idea that Rusty might've written a blog post on\nthis preimage generalisation however I dont seem to be able to find it\nnow.\n\nAdam\n\nOn 7 July 2015 at 21:51, CJP <cjp at ultimatestunts.nl> wrote:\n>> Since we use \"revocation preimages\" to revoke transactions (rather than\n>> sending pubkeys as the original draft paper)\n>\n> I remember the original paper mentioned sending private keys. I suppose\n> you mean that the preimages replace the *private* keys, not the pubkeys?\n>\n> I was not aware of that design change, but it sounds like an\n> improvement.\n>\n> CJP\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-08T00:32:34",
                "message_text_only": "Adam Back <adam at cypherspace.org> writes:\n> The use of the private key sending function, is just intended to be a\n> more compact and efficient way of sending the other end of the channel\n> a signed message, it says \"well here, have the private key, you can\n> sign it yourself\".\n\nYep, the creation of revocable transactions was one of the reasons I'm\nstill in awe of the LN paper.\n\nThe general construct of a \"revocable transaction\" is any output like:\n\n        I can take the money after some delay, OR\n        You can take the money immediately if you know some secret.\n\nIn the paper the secret was a temp private key; Adam points out it could\nhave been a pre-signed 2 of 2 transaction, but privkeys can be generated\nalgorithmically so you can store millions of these trivially.  But it's\neven easier to use hashes instead of privkeys, so that's what I did.\n\n> Now that being the case, and as the transaction has another signature\n> anyway it occurred to me that you should be able to use a chain of\n> hash preimages to do it more efficiently again.\n>\n> Rusty generalised that to have a lower setup by using a short of\n> hypercube multi-dimensional array of preimages.  (If you want 1million\n> hash preimages, then you have to actually compute 1 million of them at\n> setup.)  I had the idea that Rusty might've written a blog post on\n> this preimage generalisation however I dont seem to be able to find it\n> now.\n\nIt's on github, in the ccan/crypto/shachain module:\n\nhttps://github.com/rustyrussell/ccan/blob/master/ccan/crypto/shachain/design.txt\n\nSorry if it's a bit opaque :(\n\nCheers,\nRusty."
            },
            {
                "author": "Anthony Towns",
                "date": "2015-07-23T05:07:33",
                "message_text_only": "On 6 July 2015 at 16:41, Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n>         To recap: each side maintains a commitment transaction with two\n> outputs: one paying to self (with some delay), and the second paying to\n> the other side.\n>         To generate hash time-locked contracts (required for lightning\n> to be a network), both commitment transactions get an additional output.\n>\n\n\u200bThat is, an additional output per HTLC, no?\u200b\n\nThis output is spendable under four conditions:\n\n1) Recipient knows the R value (funds go to recipient), OR\n> 2) The HTLC has timed out (funds return to initiator), OR\n> 3) The HTLC has been revoked (funds to go \"non-cheating\" side), OR\n> 4) The Commit transaction has been revoked (funds to go \"non-cheating\"\n> side)\n>\n\n\n> The last two failure modes are separate from each other, because HTLCs\n> have different lifetimes from commit transactions.\n>\n\n\u200bI'm not sure that makes sense? It seems to me there's two options:\n\n a) HTLC resolved off-chain\n b) HTLC resolved on-chain\n\u200b\nIf (a) then both parties (nominally) agree which way the funds should go,\nand both the commitment and HTLC are expired simultaneously.\n\nIf (b) then either party decides to go to the blockchain, publishing tSheir\nside of the commitment, so both the commitment and HTLC are executed\nsimultaneously.\n\nSo afaics the commit transaction might as well always revoked before or\nsimultaneously with the HTLC.\n\nIn that case the conditions are just:\n\n - Recipient knows R value\n - Sender sees HTLC has timed out\n - Commit transaction has been revoked\n\nScripts for whatever it's worth:\n\nHTLC from US to THEM:\n>\n---------------------\n>\n\n(R | Us_Commit_Revoke) Them | TIMEOUT Us DELAY\n\u200b===>\u200b\n\n\u200bOP_HASH160 OP_DUP\n   rhash OP_EQUAL OP_SWAP\u200b\n   revhash OP_EQUAL\nOP_ADD\nOP_IF\n   OP_DUP OP_HASH160   thempubkeyhash   OP_EQUALVERIFY OP_CHECKSIG\nOP_ELSE\n   timeout  OP_CHECKTIMELOCKVERIFY OP_DROP\n   OP_DUP OP_HASH160   mypubkeyhash     OP_EQUALVERIFY OP_CHECKSIG\n\u200bOP_ENDIF\u200b\n\n\u200bSpend:\n R TheirHash TheirSig\n Revoke TheirHash TheirSig\u200b\n 0 OurHash OurSig\n\nHTLC from THEM to US:\n> ---------------------\n>\n\n\u200bR Us\u200b DELAY | (Us_Commit_Revoke | TIMEOUT) Them\n\nOP_HASH160 OP_DUP\nrhash OP_EQUAL\nOP_IF\n    OP_DROP\n    delay OP_CHECKSEQUENCEVERIFY\n    OP_DUP OP_HASH160  mypubkeyhash  OP_EQUALVERIFY OP_CHECKSIG\nOP_ELSE\n    revhash OP_EQUAL\n    OP_IF OP_ELSE\n      timeout OP_CHECKTIMELOCKVERIFY OP_DROP\n    OP_ENDIF\n    OP_DUP OP_HASH160  theirpubkeyhash OP_EQUALVERIFY OP_CHECKSIG\nOP_ENDIF\n\nCheers,\naj\n\n-- \nAnthony Towns <aj at erisian.com.au>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150723/867dcc96/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-24T00:54:05",
                "message_text_only": "Anthony Towns <aj at erisian.com.au> writes:\n> On 6 July 2015 at 16:41, Rusty Russell <rusty at rustcorp.com.au> wrote:\n>\n>>         To recap: each side maintains a commitment transaction with two\n>> outputs: one paying to self (with some delay), and the second paying to\n>> the other side.\n>>         To generate hash time-locked contracts (required for lightning\n>> to be a network), both commitment transactions get an additional output.\n>>\n>\n> \u200bThat is, an additional output per HTLC, no?\u200b\n\nYep.\n\n> This output is spendable under four conditions:\n>\n> 1) Recipient knows the R value (funds go to recipient), OR\n>> 2) The HTLC has timed out (funds return to initiator), OR\n>> 3) The HTLC has been revoked (funds to go \"non-cheating\" side), OR\n>> 4) The Commit transaction has been revoked (funds to go \"non-cheating\"\n>> side)\n>>\n>\n>\n>> The last two failure modes are separate from each other, because HTLCs\n>> have different lifetimes from commit transactions.\n>>\n>\n> \u200bI'm not sure that makes sense? It seems to me there's two options:\n\nYes, the paper removed the unneceesary HTLC revocation.  It was a\nleftover from before HTLCs were reduced to a single output.\n\nSee:\n\n        https://github.com/ElementsProject/lightning/blob/master/doc/deployable-lightning.pdf\n\n(Still haven't written the code, so these scripts are untested.  I'm\n hoping to finish the dual-anchor code soon though, then HTLCs are next).\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "HTLCs using OP_CHECKSEQUENCEVERIFY/OP_LOCKTIMEVERIFY and revocation hashes.",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Anthony Towns",
                "Adam Back",
                "CJP"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 10875
        }
    },
    {
        "title": "[Lightning-dev] [RFC] Anchor (funding) transactions without segregated witness",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2015-07-07T06:09:39",
                "message_text_only": "Hi all,\n\n        http://ozlabs.org/~rusty/diagrams/dual-anchor.svg\n\n        Since I posted my first design of HTLC yesterday, and noted that\nit doesn't seem to require new sighash modes, I went back and revisited\nmy discarded ideas for establishing an anchor without new sighash modes.\nIf we can do that (and my HTLC design stands up), then lightning network\nonly needs OP_CHECKSEQUENCEVERIFY and OP_CHECKLOCKTIMEVERIFY, which are\nfairly low-albedo soft forks.\n\n        To recap: the draft paper and current code trade signatures on\nthe first commitment transaction before signing the anchor transaction.\nThat way you are sure to have a way to get your funds back before you\nput them into the anchor.  (The paper uses the term funding transaction;\nI prefer anchor).\n\n        This can't be done in normal bitcoin, as you don't know the TXID\nof the anchor until after its inputs are signed, so you can't sign the\ncommitment transaction without knowing the txid of the anchor.  It works\nin Elements Alpha because they have segregated witness; the txid of the\nanchor doesn't hash the input scripts.  It could work in bitcoin with a\nsoftfork of a new CHECKSIG2 which has new signature modes, but there's\nnot even a BIP for that, and there are so many things that could be done\nthere that it's likely to be long delayed.\n\n        So, how can we solve this?  Well, we can have two anchors\ninstead of one.  I put my inputs into my anchor, you put your inputs\ninto yours: each one requires both our signatures to spend.  The\ncommitment tx has two inputs, one for each.\n\n        We can trade anchor txids, so we can both sign the commitment\ntx.  But now one of could withhold our anchor, leaving us with an\nunusable commitment tx and stuck output from an anchor.  We need a way\nto get the funds back in that \"abort\" case.\n\n        Thus we add an intermediary transaction (called \"Escape\"\ntransactions) which spends the 2 of 2 anchor output, but can be spent\neither by 2 of 2 (ie. the commitment tx), OR back to the anchor owner\nafter a delay (using OP_CHECKSEQUENCEVERIFY).\n\n        The order is as follows:\n\n1) We both trade anchor txids and amounts.\n2) We both trade signatures for the escape transactions, so either one\n   can broadcast them.\n3) Now we are sure to be able to recover our funds, we each broadcast\n   our anchor txs.\n4) If the other side broadcasts their escape transaction, abort and\n   broadcast our escape transaction.  After the timeout, we can spend\n   it.\n5) If the other side doesn't broadcast their anchor tx, abort and\n   broadcast our escape transaction.\n6) Otherwise, when the anchor txs reach the required depth, we exchange\n   signatures for the commitment transaction.\n7) If the other side broadcasts either escape transaction, broadcast\n   the other escape transaction and the commitment tx as normal (this is\n   a unilateral close) before they can reclaim their anchor funds.\n\nI think this works, and doesn't add any new requirements; you now need\nto watch out for escape txs being broadcast instead of commitment txs.\n\nThe downside is that there are 3 extra transactions involved; 1 extra\nfor the channel open, and 2 for the channel close.\n\nFeedback, optimizations, horrible holes?\nRusty."
            },
            {
                "author": "Joseph Poon",
                "date": "2015-07-13T22:26:59",
                "message_text_only": "On Tue, Jul 07, 2015 at 03:39:39PM +0930, Rusty Russell wrote:\n> Feedback, optimizations, horrible holes?\n\nI think this model works! As soon as OP_CHECKLOCKTIMEVERIFY soft-forks\ninto bitcoin, a basic lightning implementation may be theoretically\npossible in real bitcoin (with some significant caveats)!\n\nI think Thaddeus Dryja came up with a similar implementation to resolve\nmalleability in multisig (involving a clock and 2-input/2-output).\nHowever, I think a true malleability fix is still ideal.\n\nTo complete the thought, I think it's possible to make the Commitment\nTransactions malleability-safe under this construction.\n\n>         The order is as follows:\n> \n> 1) We both trade anchor txids and amounts.\n> 2) We both trade signatures for the escape transactions, so either one\n>    can broadcast them.\n> 3) Now we are sure to be able to recover our funds, we each broadcast\n>    our anchor txs.\n> 4) If the other side broadcasts their escape transaction, abort and\n>    broadcast our escape transaction.  After the timeout, we can spend\n>    it.\n> 5) If the other side doesn't broadcast their anchor tx, abort and\n>    broadcast our escape transaction.\n> 6) Otherwise, when the anchor txs reach the required depth, we exchange\n>    signatures for the commitment transaction.\n> 7) If the other side broadcasts either escape transaction, broadcast\n>    the other escape transaction and the commitment tx as normal (this is\n>    a unilateral close) before they can reclaim their anchor funds.\n\nTo create the Commitment Transaction (in step 6 and all future\nCommitment Transactions), it requires spending from the two inputs\nseparately and the output would require having OP_CLTV or OP_CSV in the\nscript output to determine whether a Commitment has been revoked. This\nis necessary since one cannot be fully confident about the Transaction\nID beforehand.\n\nIf the inputs are 0.5 Alice and 0.5 Bob, the first Commitment\nTransaction would refund 0.5 to Alice and 0.5 to Bob. As always, there\nare a pair of Commitment Transactions per commitment state. Presume the\ncurrent block height is 350,000 and the channel closes at 355,760.\n\nThe Commitment Transaction which only Alice can broadcast, Commitment\n1a, would have the following outputs:\n\n0. 0.5 BTC\n\tBobKey\n1. 0.5 BTC\nOP_IF \n\t<AlicePubKey> OP_CHECKSIGVERIFY \n\t<355,760> OP_CLTV OP_DROP\nOP_ELSE\n\tOP_HASH160 <RevocationHash> OP_EQUALVERIFY\n\t<BobPubKey> OP_CHECKSIGVERIFY\nOP_END\n\nThis is the general idea at least (haven't checked the script). Bob gets\nall his money if Alice broadcasts it immediately because Alice is\nattesting Bob should get *at least* 0.5 BTC. For the second output\n(output 1), the first path gives Alice the funds at channel expiration.\nThe second path is so if the current Commitment transaction is not\nCommitment 1 and Alice should lose all her money for incorrectly\nbroadcasting Commitment 1. Alice does this by attesting to Bob she\nwouldn't broadcast Commitment 1 by giving the RevocationPreimage which\nis hashed into RevocationHash.\n\nBob also has a Commitment Transaction which is the opposite (Alice's\nfunds get paid immediately, Bob's funds is encumbered by time).\n\nThe purpose of doing this type of construction instead of using\nnLockTime on the transactions spending from the Commitment Transaction\nis so that each output only requires one signature. By having only one\nsignature, malleability concerns can be mitigated, since that single\nparty can simply resign and is not dependent upon the cooperation of the\ncounterparty if the Commitment Transaction itself gets mutated. Since\nthe Commitment Transaction is only build after the Anchor and Escape\ntransactions exist, then this construction will allow for Lightning\nNetwork channels to exist with OP_CLTV, with the caveat that with\nuncooperative counterparties, you will have to wait until channel\nexpiration to get your money back. However, it does mean that playing\nwith LN is a possibility on the real bitcoin chain in the near future.\n\nVery cool, Rusty!\n\n-- \nJoseph Poon"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-14T05:56:57",
                "message_text_only": "Joseph Poon <joseph at lightning.network> writes:\n> On Tue, Jul 07, 2015 at 03:39:39PM +0930, Rusty Russell wrote:\n>> Feedback, optimizations, horrible holes?\n>\n> I think this model works! As soon as OP_CHECKLOCKTIMEVERIFY soft-forks\n> into bitcoin, a basic lightning implementation may be theoretically\n> possible in real bitcoin (with some significant caveats)!\n\nWe could.  I think OP_CHECKSEQUENCEVERIFY (ie. relative CTLV) would\nreduce those caveats enough that we should assume that, too (if that\nproves too optimistic, we can return to global timeous and OP_CLTV).\n\n[ BTW, Joseph and I had a deep and complex discussion over the last week\n  via private email.  I'm summarizing here. ]\n\nIt *almost* works, but once you drew my attention to the malleability\nissue, it's clear that the escape transaction(s) can be malleated[1],\ncausing the commitment transaction to be useless.\n\nThen I came up with another variant, which Joseph approved of.  And\nthen, of course, improved upon!  I'm writing up final result now.\n\nThanks!\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Anchor (funding) transactions without segregated witness",
            "categories": [
                "Lightning-dev",
                "RFC"
            ],
            "authors": [
                "Rusty Russell",
                "Joseph Poon"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 8252
        }
    },
    {
        "title": "[Lightning-dev] Timechain - Time-Lock Encryption",
        "thread_messages": [
            {
                "author": "Mashuri Clark",
                "date": "2015-07-16T19:52:37",
                "message_text_only": "http://roberts.pm/timechain\n\n \n\nI post this here because it's a unique way to implement a time lock.\nPerhaps we can find this method useful for different implementations of\nHTLC's or time-sensitive rewards / penalties.  To make things even more\ninteresting, the authors are working on integrating adjustable difficulty\nand distribution for rewards:\nhttps://bitcointalk.org/index.php?topic=1095369.msg11741451#msg11741451.\nIt's tantamount to creating micro POW mining environments.  Pretty cool\nstuff and possibly a uniquely useful tool for payment channels.\n\n \n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150716/0283029f/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-16T21:50:01",
                "message_text_only": "Mashuri Clark <mashuribc at gmail.com> writes:\n> http://roberts.pm/timechain\n>\n>  \n>\n> I post this here because it's a unique way to implement a time lock.\n\nThere are many interesting things in the world.  Most of them are not\nobviously relevant to the development of the lightning network.\n\nThanks,\nRusty."
            },
            {
                "author": "Mashuri Clark",
                "date": "2015-07-17T01:26:08",
                "message_text_only": "You're running a tight ship Rusty.  I'll try to stay within your parameters.\n:)\n\n--\nMC\n\n-----Original Message-----\nFrom: Rusty Russell [mailto:rusty at rustcorp.com.au] \nSent: Thursday, July 16, 2015 2:50 PM\nTo: Mashuri Clark; lightning-dev at lists.linuxfoundation.org\nSubject: Re: [Lightning-dev] Timechain - Time-Lock Encryption\n\nMashuri Clark <mashuribc at gmail.com> writes:\n> http://roberts.pm/timechain\n>\n>  \n>\n> I post this here because it's a unique way to implement a time lock.\n\nThere are many interesting things in the world.  Most of them are not\nobviously relevant to the development of the lightning network.\n\nThanks,\nRusty."
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-17T03:36:10",
                "message_text_only": "Mashuri Clark <mashuribc at gmail.com> writes:\n> You're running a tight ship Rusty.  I'll try to stay within your parameters.\n> :)\n\nMainly because people like to spam mailing lists with their latest\naltcoin pump :(\n\nPlease tell me if I get too fascist!\n\nThanks,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Timechain - Time-Lock Encryption",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Mashuri Clark"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 1959
        }
    },
    {
        "title": "[Lightning-dev] Lightning modifications draft paper",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2015-07-17T08:19:15",
                "message_text_only": "Hi all,\n\n        http://ozlabs.org/~rusty/ln-deploy-draft-01.pdf\n\n        I haven't had time to proofread this properly, nor check the\nscript examples.  But wanted to post it before the weekend so you all\nhave something to chew on :)\n\nCheers,\nRusty."
            },
            {
                "author": "Joseph Poon",
                "date": "2015-07-17T09:21:17",
                "message_text_only": "On Fri, Jul 17, 2015 at 05:49:15PM +0930, Rusty Russell wrote:\n>         http://ozlabs.org/~rusty/ln-deploy-draft-01.pdf\n\nVery cool!! The proposed construction with OP_CHECKLOCKTIMEVERIFY and\nOP_CHECKSEQUENCEVERIFY may make lightning be deployed *much* sooner.\nRusty's idea is fantastic and goes very far in creating a usable way to\nreally try out lightning on Bitcoin.\n\nI'll have an update of my paper incorporating these changes, they're\nreally significant. \n\n(Current version, will incorporate the above changes very soon:\nhttp://lightning.network/lightning-network-paper-0.5.9.pdf )\n\n-- \nJoseph Poon"
            },
            {
                "author": "Nick ODell",
                "date": "2015-07-18T15:15:27",
                "message_text_only": "I'm pretty sure that BIP62 is abandonded. At least, the PR based on it\nwas never merged. BIP66 implements some of it, and rules 2-7 have been\nnonstandard for a while, but I don't think that rules 2-7 are enforced\nagainst new blocks.\n\nOn Fri, Jul 17, 2015 at 2:19 AM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n> Hi all,\n>\n>         http://ozlabs.org/~rusty/ln-deploy-draft-01.pdf\n>\n>         I haven't had time to proofread this properly, nor check the\n> script examples.  But wanted to post it before the weekend so you all\n> have something to chew on :)\n>\n> Cheers,\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2015-07-18T15:46:15",
                "message_text_only": "BIP62 is not in any way abandoned. It just takes time to implement such\nbroad changes and to be assured of their safety. BIP66 rushed a subset of\nfeatures that were necessary to close we pretty serious vulnerabilities\n(details of that are forthcoming soon now that it has been deployed).\nOn Jul 18, 2015 08:15, \"Nick ODell\" <nickodell at gmail.com> wrote:\n\n> I'm pretty sure that BIP62 is abandonded. At least, the PR based on it\n> was never merged. BIP66 implements some of it, and rules 2-7 have been\n> nonstandard for a while, but I don't think that rules 2-7 are enforced\n> against new blocks.\n>\n> On Fri, Jul 17, 2015 at 2:19 AM, Rusty Russell <rusty at rustcorp.com.au>\n> wrote:\n> > Hi all,\n> >\n> >         http://ozlabs.org/~rusty/ln-deploy-draft-01.pdf\n> >\n> >         I haven't had time to proofread this properly, nor check the\n> > script examples.  But wanted to post it before the weekend so you all\n> > have something to chew on :)\n> >\n> > Cheers,\n> > Rusty.\n> > _______________________________________________\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150718/d047d7b3/attachment.html>"
            },
            {
                "author": "Nick ODell",
                "date": "2015-07-18T16:19:19",
                "message_text_only": "There doesn't seem to be any deployment timeline, and the BIP is\nincredibly out of date.\n\nI agree that rules 2-7 are nonstandard, but I don't think they're\napplied to blocks.\n\n>(details of that are forthcoming soon now that it has been deployed).\nI was under the impression that the changes in BIP66 were only\nprioritized because asking OpenSSL to verify DER encoding required\nbuilding with a specific version of OpenSSL, not because of any\nsecurity vulns.\n\nOn Sat, Jul 18, 2015 at 9:46 AM, Mark Friedenbach <mark at friedenbach.org> wrote:\n> BIP62 is not in any way abandoned. It just takes time to implement such\n> broad changes and to be assured of their safety. BIP66 rushed a subset of\n> features that were necessary to close we pretty serious vulnerabilities\n> (details of that are forthcoming soon now that it has been deployed).\n>\n> On Jul 18, 2015 08:15, \"Nick ODell\" <nickodell at gmail.com> wrote:\n>>\n>> I'm pretty sure that BIP62 is abandonded. At least, the PR based on it\n>> was never merged. BIP66 implements some of it, and rules 2-7 have been\n>> nonstandard for a while, but I don't think that rules 2-7 are enforced\n>> against new blocks.\n>>\n>> On Fri, Jul 17, 2015 at 2:19 AM, Rusty Russell <rusty at rustcorp.com.au>\n>> wrote:\n>> > Hi all,\n>> >\n>> >         http://ozlabs.org/~rusty/ln-deploy-draft-01.pdf\n>> >\n>> >         I haven't had time to proofread this properly, nor check the\n>> > script examples.  But wanted to post it before the weekend so you all\n>> > have something to chew on :)\n>> >\n>> > Cheers,\n>> > Rusty.\n>> > _______________________________________________\n>> > Lightning-dev mailing list\n>> > Lightning-dev at lists.linuxfoundation.org\n>> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2015-07-18T16:25:54",
                "message_text_only": "On Sat, Jul 18, 2015 at 9:19 AM, Nick ODell <nickodell at gmail.com> wrote:\n\n> There doesn't seem to be any deployment timeline.\n>\n\nWelcome to bitcoin development.\n\nAt the moment we have only the capability to push out one soft fork vote at\na time. The uncontroversial aspects of BIP62 were rushed out as BIP66 in\nresponse to an undisclosed vulnerability, as mentioned. I believe there is\nconsensus now that BIP65: CHECKLOCKTIMEVERIFY has higher deployment\npriority, so it will be next. There is no deployment timeline for BIP62\nbecause it is a low priority in this soft-fork logjam.\n\nAs to BIP62 being out of date, can you point to specific things? They'll\nget fixed.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150718/2d3ce21e/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2015-07-18T16:50:24",
                "message_text_only": "On Sat, Jul 18, 2015 at 09:25:54AM -0700, Mark Friedenbach wrote:\n> On Sat, Jul 18, 2015 at 9:19 AM, Nick ODell <nickodell at gmail.com> wrote:\n> \n> > There doesn't seem to be any deployment timeline.\n> >\n> \n> Welcome to bitcoin development.\n> \n> At the moment we have only the capability to push out one soft fork vote at\n> a time. The uncontroversial aspects of BIP62 were rushed out as BIP66 in\n> response to an undisclosed vulnerability, as mentioned. I believe there is\n> consensus now that BIP65: CHECKLOCKTIMEVERIFY has higher deployment\n> priority, so it will be next. There is no deployment timeline for BIP62\n> because it is a low priority in this soft-fork logjam.\n\nA slight clarification: we do have the capability to push out more than\none soft-fork *upgrade signaling* at a time, but this is very far from a\nvote because if miners decide not to upgrade there is no easy way to\nrecover. The nVersion bits mechanism I co-authored with Pieter Wuille\nand Gregory Maxwell is closer to a vote because a soft-fork failing to\ngo through has a clear and non-coercive outcome.\n\nFor instance, if my own BIP65 had been accepted into v0.11.0 miners who\nhad upgraded to v0.10.x/0.9.5 would have been signaling that they\nsupported BIP66, while sumultaneously miners running v0.11.0 would be\nsignalling that they supported both BIP66 and BIP65. As adoption\nincreased BIP66 would trigger first, followed by BIP65. (theoretically\nboth could trigger on the same block too)\n\nThe problem is if miners had decided they didn't like BIP66 but wanted\nto implement BIP65 there would be no mechanism to do that - it depends\non the details, but from the point of view of at least some nodes you\nlikely would have hard-forked Bitcoin in the process of stopping the\nfailed soft-fork.\n\n-- \n'peter'[:-1]@petertodd.org\n00000000000000000b675c4d825a10c278b8d63ee4df90a19393f3b6498fd073\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150719/4c48df02/attachment.sig>"
            },
            {
                "author": "Nick ODell",
                "date": "2015-07-18T19:48:32",
                "message_text_only": ">As to BIP62 being out of date, can you point to specific things? They'll get fixed.\nJust one thing, actually. The \"Block validity\" section references\nversion 3 blocks, but those are already used by the BIP66 softfork.\n\nOn Sat, Jul 18, 2015 at 10:50 AM, Peter Todd <pete at petertodd.org> wrote:\n> On Sat, Jul 18, 2015 at 09:25:54AM -0700, Mark Friedenbach wrote:\n>> On Sat, Jul 18, 2015 at 9:19 AM, Nick ODell <nickodell at gmail.com> wrote:\n>>\n>> > There doesn't seem to be any deployment timeline.\n>> >\n>>\n>> Welcome to bitcoin development.\n>>\n>> At the moment we have only the capability to push out one soft fork vote at\n>> a time. The uncontroversial aspects of BIP62 were rushed out as BIP66 in\n>> response to an undisclosed vulnerability, as mentioned. I believe there is\n>> consensus now that BIP65: CHECKLOCKTIMEVERIFY has higher deployment\n>> priority, so it will be next. There is no deployment timeline for BIP62\n>> because it is a low priority in this soft-fork logjam.\n>\n> A slight clarification: we do have the capability to push out more than\n> one soft-fork *upgrade signaling* at a time, but this is very far from a\n> vote because if miners decide not to upgrade there is no easy way to\n> recover. The nVersion bits mechanism I co-authored with Pieter Wuille\n> and Gregory Maxwell is closer to a vote because a soft-fork failing to\n> go through has a clear and non-coercive outcome.\n>\n> For instance, if my own BIP65 had been accepted into v0.11.0 miners who\n> had upgraded to v0.10.x/0.9.5 would have been signaling that they\n> supported BIP66, while sumultaneously miners running v0.11.0 would be\n> signalling that they supported both BIP66 and BIP65. As adoption\n> increased BIP66 would trigger first, followed by BIP65. (theoretically\n> both could trigger on the same block too)\n>\n> The problem is if miners had decided they didn't like BIP66 but wanted\n> to implement BIP65 there would be no mechanism to do that - it depends\n> on the details, but from the point of view of at least some nodes you\n> likely would have hard-forked Bitcoin in the process of stopping the\n> failed soft-fork.\n>\n> --\n> 'peter'[:-1]@petertodd.org\n> 00000000000000000b675c4d825a10c278b8d63ee4df90a19393f3b6498fd073"
            }
        ],
        "thread_summary": {
            "title": "Lightning modifications draft paper",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Peter Todd",
                "Joseph Poon",
                "Rusty Russell",
                "Nick ODell",
                "Mark Friedenbach"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 10324
        }
    },
    {
        "title": "[Lightning-dev] #lightning-dev IRC channel on freenode",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2015-07-18T11:14:58",
                "message_text_only": "Hi all,\n\n        Just wanted to point out there's now an IRC channel.  It will be\nlogged, and is a great resource for hashing out unfinished ideas.\n\nBut please make sure you send any worthwhile results to the list!\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "#lightning-dev IRC channel on freenode",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 230
        }
    },
    {
        "title": "[Lightning-dev] Thoughts on HTLC Scripts",
        "thread_messages": [
            {
                "author": "Mats Jerratsch",
                "date": "2015-07-20T18:42:11",
                "message_text_only": "Hey everybody,\n\nI'm currently working on a Lightning Implementation Client/Server in\nJava, building on bitcoinj (just as a basic framework, I wrote my own\nclasses to realize LN). Will push it into GitHub within a few weeks I\nguess.\n\nI had an implementation ready, that would not need any further changes\nfor bitcoin (works today already), but I just threw it all off the\nship, reading through your paper. It was based on some trust\ndependencies and channel transactions were highly asynchronous,\nmeaning that a LN-Network would not be possible (since one party will\nalways be assumed lower trust and therefore has a disadvantage in\nenforcing the ruleset). I can share further details if there is any\ninterest (it further needed to exchange 3 transactions for each\npayment in the channel, building up huge amount of data within a few\nhundred payments....)\n\nFirst I wanted to write up my solution for the anchor problem, but\nthen I realized, your solution makes it possible to have channels open\nindefinitely, while mine doesn't. And while it really looks fishy,\nindefinite channels are really worth it. However, it is important to\nwait for the anchor tx of the other party. Otherwise the server has to\npay transaction fees for releasing his funds again and again (which\ncan really add up..).\n\nWhile implementing the new redeemscripts, I noticed there is no delay\nfor the 'HTLC Receiver Redeemscript', when redeeming the contract\nusing R. Doesn't this mean that revoked or not, if the receiver has R,\nhe can instantly claim these outputs. Let's assume a channel with 4\nstates:\n\nt=t0 - client has no funds in the channel (or very little, he wants to\nreceive money)\nt=t1 - client has received funds and has lots of unsettled payments in\nhis channel\nt=t2 - client settled with the server (revealed R)\nt=t3 - client has spent all funds again\n\nAt t=t3, the client has no incentive anymore to play with the rules,\nsince there's nothing he can lose (his balance is zero after all..).\nSo he can broadcast the channel transaction from t1 and instantly\nclaim all outputs using R. While the server can technically claim the\nfunds aswell, using the COMMIT-REVOCATION-HASH, it boils down to a\nrace. I'm not really sure if this will solve the issue completely, but\nI think OP_CSV after OP_DROP will mitigate this by ensuring some\ndelay. This is especially important other way round, as clients won't\nbe online all the time and the delay here really determines how often\nthe client has to check back.\n\nReally good work though, although I just had to delete and rewrite a\ngood share of my work. ;)"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-25T05:04:46",
                "message_text_only": "Mats Jerratsch <matsjj at gmail.com> writes:\n> Hey everybody,\n>\n> I'm currently working on a Lightning Implementation Client/Server in\n> Java, building on bitcoinj (just as a basic framework, I wrote my own\n> classes to realize LN). Will push it into GitHub within a few weeks I\n> guess.\n\nHi Mats!\n\n        Awesome, I look forward to brushing up my Java skills :)\n\n> I had an implementation ready, that would not need any further changes\n> for bitcoin (works today already), but I just threw it all off the\n> ship, reading through your paper. It was based on some trust\n> dependencies and channel transactions were highly asynchronous,\n> meaning that a LN-Network would not be possible (since one party will\n> always be assumed lower trust and therefore has a disadvantage in\n> enforcing the ruleset). I can share further details if there is any\n> interest (it further needed to exchange 3 transactions for each\n> payment in the channel, building up huge amount of data within a few\n> hundred payments....)\n>\n> First I wanted to write up my solution for the anchor problem, but\n> then I realized, your solution makes it possible to have channels open\n> indefinitely, while mine doesn't. And while it really looks fishy,\n> indefinite channels are really worth it. However, it is important to\n> wait for the anchor tx of the other party. Otherwise the server has to\n> pay transaction fees for releasing his funds again and again (which\n> can really add up..).\n\nYes, there's a delay waiting for the anchor(s) to be buried deep enough\nto be considered irrevocable.  Also, if the anchors change, there's a\nwhile where commitment txs need to be maintained for both the old and\nnew anchors.\n\n> While implementing the new redeemscripts, I noticed there is no delay\n> for the 'HTLC Receiver Redeemscript', when redeeming the contract\n> using R. Doesn't this mean that revoked or not, if the receiver has R,\n> he can instantly claim these outputs. Let's assume a channel with 4\n> states:\n\nWhich paper are you reading?  The LN draft at lightning.network, or the\nimplementation paper at https://github.com/ElementsProject/lightning/tree/master/doc?\n\nThe rule is simple: any output condition which pays to \"self\" must be\ndelayed (so A's HTLC output to A must be delayed, similarly B's HTLC\noutput to B).\n\nI didn't spell out all the cases in Figure 9, nor even in the Appendix.\nI probably should, to make it clear...\n\n> Really good work though, although I just had to delete and rewrite a\n> good share of my work. ;)\n\nI know that feeling!  I just rewrote my test-cli utils to support dual\nanchors...\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Thoughts on HTLC Scripts",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Mats Jerratsch"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 5180
        }
    },
    {
        "title": "[Lightning-dev] commitment update steps",
        "thread_messages": [
            {
                "author": "Anthony Towns",
                "date": "2015-07-23T04:40:45",
                "message_text_only": "Hi *,\n\nFor my own understanding I've been trying to work out what the lightning\nprotocol looks like at a network-protocol level. I think the following\nworks, maybe it's interesting for others:\n\nFor notational convenience I'm going to just list the secrets that need to\nbe known to use to spend an output. \"Alice\" and \"Bob\" are Alice and Bob's\nrespective keys, Alice_N and Bob_N are the Nth numbers in shachain\nsequences [0]. I'm using TIMEOUT for the checktimelockverify construction;\nDELAY for the checksequenceverify construction.\n\n\u200bAssume Alice and Bob already have a channel setup. Then their current\ncommitments might be:\n\nAlice's commitment txn: (fully signed)\n  500 Alice + DELAY | #Alice_101 + Bob\n  500 Bob\n\nBob's commitment txn: (fully signed)\n  500 Alice\n  500 Bob + DELAY | #Bob_101 + Alice\n\nAlice knows the hash of #Bob_101 and Bob knows the hash of #Alice_101\n(because they've respectively seen the full txns to sign them).\n\nIf Alice wants to update the channel to reflect a conditional payment from\nBob once R is revealed, they can follow the following steps:\n\n1) Alice proposes: (unsigned)\n     500 Alice + DELAY | #Alice_102 + Bob\n     400 Bob\n     100 R + Alice + DELAY | Bob + TIMEOUT | #Alice_102 + Bob\n\n     [1]\n\n   Bob checks: txn structure, amounts, R, Bob key is correct\n   Bob stores the hash of #Alice_102\n\n2a) Bob declines; proposal never happened\n2b) Bob approves, replies:\n     signing Alice's proposal\n     requesting sig of:\n       500 Alice\n       400 Bob + DELAY | #Bob_102 + Alice\n       100 R + Alice | Bob + TIMEOUT + DELAY | #Bob_102 + Alice\n\n    Alice checks: signature, txn structure, amounts, R, Alice key is correct\n    Alice signs and stores new txn.\n    Alice stores the hash of #Bob_102\n\n3) Alice discards old commitment txn.\n   Alice replies:\n     signing Bob's transaction\n     revealing Alice_101\n\n    Bob checks: signature,\n     Alice_101 hashes correctly (ie matches the hash of #Alice_101, stored\npreviously),\n     Alice_101 forms hash chain with prior secrets (Alice_100, Alice_99..)\nas expected\n\n    Bob signs and stores his new commitment txn\n    Bob discards the hash of #Alice_101.\n\n4) Bob discards old commitment txn\n   Bob replies:\n     revealing Bob_101\n\n    Alice checks:\n     Bob_101 hashes correctly (ie #Bob_101 does clear the old txn),\n     Bob_101 forms hash chain with prior secrets (Bob_100, Alice_99..) as\nexpected\n    Alice discards the hash of #Bob_101\n\nIf the protocol follows through to completion, then they each have\nmatching, updated, signed commitment transactions; along with the secrets\nnecessary to void attempts to use older commitments. If the protocol goes\noff track (checks fail, or no response from partner within a protocol\ntimeout), then either party can safely close the channel after any step:\n\n Alice can close at (500/500) up until step (3)\n Alice can close at (500/400/100) after step (2b)\n\n Bob can close at (500/500) up until step (4)\n Bob can close at (500/400/100) after step (3)\n\nIf Alice ever tries cheating, and publishes and old commitment:\n\n  800 Alice + DELAY | #Alice_42 + Bob\n  200 Bob\n\nThen Bob needs to work out which of the 100 Alice_N hashes he knows or can\nwork out is being abused; prior to the DELAY expiring. With millions of\ntransactions that could be a bunch of hash calculations or a 100MB lookup\ntable. Might make more sense to have a dummy output of \"0: OP_RETURN 42\" to\nmake that calculation trivial though? That could trivially be verified as\npart of the \"forms hash chain as expect\" and \"txn structure\" checks.\n\nHTLCs are harder if you assume pay2scripthash is used though. If Alice\npublished:\n\n  100 Alice + Delay | #Alice_55 + Bob\n  100 Bob\n  200 R1 + Alice + DELAY | Bob + TIMEOUT1 | #Alice_55 + Bob\n  200 R2 + Alice + DELAY | Bob + TIMEOUT2 | #Alice_55 + Bob\n  200 R3 + Alice + DELAY | Bob + TIMEOUT3 | #Alice_55 + Bob\n  200 R4 + Alice + DELAY | Bob + TIMEOUT4 | #Alice_55 + Bob\n\nwell after R1..R4 were known and Alice_55 was revealed in order to try\nstealing most of the channel's funds, I think Bob could only claim the\nfinal outputs if he could unhash the scripts, which would require having\nremembered R1..R4 even after those contracts had long been resolved. I\nguess it could be feasible in that case to have the extra output be \"0:\nOP_RETURN 42 #R1 #R2 #R3 #R4\"?\n\nCheers,\naj\n\n\u200b[0] It's easy to calculate Alice_N given Alice_M for some M > N, but\nunfeasible for any M < N.\n\n\u200b[1] I don't understand the construction for HTLCs in 0.5.9 of the\nlightning paper; what I'm doing instead is taking an underlying output of\n\"Alice + R | Bob + TIMEOUT\" and mapping it through \"my key becomes my key +\nDELAY\" + \"they get everything with my secret sequence and their key\". I'll\npost about that separately so it can get shot down :)\n\n[2] (Unattached footnote) This project's motto is \"The lightning network:\nit's off the chain!\" right?\nhttp://www.urbandictionary.com/define.php?term=off+the+chain\n\n-- \nAnthony Towns <aj at erisian.com.au>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150723/b330b01a/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-24T00:49:49",
                "message_text_only": "Anthony Towns <aj at erisian.com.au> writes:\n> If Alice ever tries cheating, and publishes and old commitment:\n>\n>   800 Alice + DELAY | #Alice_42 + Bob\n>   200 Bob\n>\n> Then Bob needs to work out which of the 100 Alice_N hashes he knows or can\n> work out is being abused; prior to the DELAY expiring. With millions of\n> transactions that could be a bunch of hash calculations or a 100MB lookup\n> table. Might make more sense to have a dummy output of \"0: OP_RETURN 42\" to\n> make that calculation trivial though? That could trivially be verified as\n> part of the \"forms hash chain as expect\" and \"txn structure\" checks.\n\nIt might be millions.  What happens is Bob sees the anchor being spent,\nchecks if it's the latest commitment transaction.  It's not, so does a\nbackwards search to find the revocation key.\n\nThe time taken for that search is O(N), where N is the current\ncommitment transaction number.  But measurements on my laptop show that\n1M transactions takes 5.4 seconds (see benchmark below), so I don't\nthink it's worth optimizing this \"never happens\" case.\n\n> HTLCs are harder if you assume pay2scripthash is used though. If Alice\n> published:\n>\n>   100 Alice + Delay | #Alice_55 + Bob\n>   100 Bob\n>   200 R1 + Alice + DELAY | Bob + TIMEOUT1 | #Alice_55 + Bob\n>   200 R2 + Alice + DELAY | Bob + TIMEOUT2 | #Alice_55 + Bob\n>   200 R3 + Alice + DELAY | Bob + TIMEOUT3 | #Alice_55 + Bob\n>   200 R4 + Alice + DELAY | Bob + TIMEOUT4 | #Alice_55 + Bob\n>\n> well after R1..R4 were known and Alice_55 was revealed in order to try\n> stealing most of the channel's funds, I think Bob could only claim the\n> final outputs if he could unhash the scripts, which would require having\n> remembered R1..R4 even after those contracts had long been resolved. I\n> guess it could be feasible in that case to have the extra output be \"0:\n> OP_RETURN 42 #R1 #R2 #R3 #R4\"?\n\nGood point!  With p2sh you need to know the R hash values and timeouts\nto spend the output (40 bytes).  Since OP_RETURN is length-limited to 80\nbytes, you can't fit more than 2.\n\nAnd if the HTLC outputs are not P2SH, they're non-standard and won't be\nrelayed.\n\nWhat else can we come up with?\n\nThanks,\nRusty.\n\n> [2] (Unattached footnote) This project's motto is \"The lightning network:\n> it's off the chain!\" right?\n> http://www.urbandictionary.com/define.php?term=off+the+chain\n\nErr.... Yeah.  It's spelled \"caching layer for bitcoin\" but it's\npronounced just like that."
            },
            {
                "author": "Anthony Towns",
                "date": "2015-07-24T03:30:05",
                "message_text_only": "On 24 July 2015 at 10:49, Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> Anthony Towns <aj at erisian.com.au> writes:\n> > If Alice ever tries cheating, and publishes and old commitment:\n> >   800 Alice + DELAY | #Alice_42 + Bob\n> >   200 Bob\n> > Then Bob needs to work out which of the 100 Alice_N hashes he knows or\n> can\n> > work out is being abused; prior to the DELAY expiring. With millions of\n> > transactions that could be a bunch of hash calculations or a 100MB lookup\n> > table. Might make more sense to have a dummy output of \"0: OP_RETURN 42\"\n> to\n> > make that calculation trivial though? That could trivially be verified as\n> > part of the \"forms hash chain as expect\" and \"txn structure\" checks.\n> It might be millions.\n\n\nIf a channel is updated ~100 of times a second, and lasts for a month, that\nwould be 259M updates\u200b, which on your laptop would be 22 minutes of search\ntime. If we're talking 3 days worth of OP_CSV delay, even that would be\npretty fine. So yeah, okay, seems plausible.\n\n> HTLCs are harder if you assume pay2scripthash is used though. If Alice\n> > published:\n> >\n> >   100 Alice + Delay | #Alice_55 + Bob\n> >   100 Bob\n> >   200 R1 + Alice + DELAY | Bob + TIMEOUT1 | #Alice_55 + Bob\n> >   200 R2 + Alice + DELAY | Bob + TIMEOUT2 | #Alice_55 + Bob\n> >   200 R3 + Alice + DELAY | Bob + TIMEOUT3 | #Alice_55 + Bob\n> >   200 R4 + Alice + DELAY | Bob + TIMEOUT4 | #Alice_55 + Bob\n> >\n> > well after R1..R4 were known and Alice_55 was revealed in order to try\n> > stealing most of the channel's funds, I think Bob could only claim the\n> > final outputs if he could unhash the scripts, which would require having\n> > remembered R1..R4 even after those contracts had long been resolved. I\n> > guess it could be feasible in that case to have the extra output be \"0:\n> > OP_RETURN 42 #R1 #R2 #R3 #R4\"?\n>\n> Good point!  With p2sh you need to know the R hash values and timeouts\n> to spend the output (40 bytes).  Since OP_RETURN is length-limited to 80\n> bytes, you can't fit more than 2.\n>\n\n\u200bYou could have multiple OP_RETURN outputs though? Your txn would look like:\n\n version\n n inputs: 2\n input 1: [txn] [idx] [len] [SIGA SIGB] [seq]\n input 2: [txn] [idx] [len] [SIGB SIGA] [seq]\n n outputs: 2 + x\n\u200b output 1: [value] [len] [p2sh] # Alice\n output 2: [value] [len] [p2sh] # Bob\n output 3: [value] [len] [p2sh] # R1\n output 4: [value] [len] [p2sh] # R2\n output 5: [value] [len] [OP_RETURN R1R2]\n ...\n\np2sh outputs are 32 bytes total I think; OP_RETURN is 51 bytes, so you're\nincreasing the txn size by about 80%.\n\nOtherwise I think you have to remember all the R's you see. But if that's\nokay -- 100/second for a month is just 5GB if you just store them in the\norder you see them; you can probably do something like:\n\n - at the time of this transaction, I've seen 0 < N < 2^32 R's on this\nchannel\n - here's a 288 bit bloom filter telling you which of the first N R's that\nI've seen are worth checking\n - add a single 0btc \"OP_RETURN [N | bloomfilter]\" output\n - (or if there are 10 or less R outputs, just concatenate their indexes as\nthe OP_RETURN data)\n\nActually, I forgot about the TIMEOUT values which you'd presumably also\nneed; so I guess that's an extra 4 bytes to include in the database of\nevery R (+25%), and if you're not storing, I guess an extra OP_RETURN\noutput that covers 10 R's for an additional overhead of 16%, so ~96%\noverhead all up.\n\nIf you consider your counterparty very reliable, then having 100% overhead\nin the commitment txns might not be a big deal -- you'll almost always\nclose the channel cooperatively anyway, so the commitments don't get used\nand the fees for the overhead won't get paid; OTOH, if your counterparty\nisn't known to you, and you think it's likely they might randomly disappear\noff the net and you'll have to use the commitment, then trading off disk\nfor fees might be sensible. You could change the choice while the channel's\noperating -- if a new R value is verbatim in the output, no need to store\nit locally, whether or not you've stored previous R values locally.\n\nCheers,\naj\n\n-- \nAnthony Towns <aj at erisian.com.au>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150724/268e220f/attachment.html>"
            },
            {
                "author": "Joseph Poon",
                "date": "2015-07-24T22:38:28",
                "message_text_only": "Hi Anthony,\n\nIf we're presuming everyone uses OP_CSV in the long-term, you can\noverload nLockTime with values below current unixtime as a\nfilter/counter. It should be enough bits of entropy no matter the size\n(even in the billions of transactions in a single channel) Since both\nparties are signing the nLockTime value, it's safe to use that as an\nidentifier in the Commitment Transaction.\n\n-- \nJoseph Poon"
            },
            {
                "author": "Joseph Poon",
                "date": "2015-07-24T23:24:49",
                "message_text_only": "Ah sorry, that only solves the Commitment Transactions, not the HTLC\noutputs. It's also not possible to use the pubkeys as identifiers, as\nRusty said, P2SH would be used.\n\nWhile it's possible to only check only recent blocks before the\nCommitment Transaction for the search space (e.g. 3 days worth), since\nyou know when the Commitment Transaction was broadcast, the search space\nlimitation sort of breaks down if you permit long-dated HTLCs.\n\nWorst-case it may be possible to have long-dated HTLCs on a seperate\nhash-tree, but it's not an ideal solution.\n\nIn retrospect, this P2SH problem is somewhat exacerbated by the fact\nthat the timeout being different numbers as well, so ideally that should\nbe stored as part of the output. The tradeoff between having the entire\nscript in the output (which results in larger transactions), and using\nP2SH (which reduces bits of entropy/identifiability) is a bit of a\nproblem. For some reason, I've always assumed the output would be\nincluded (ignoring isStandard issues), but that may not be optimal.\n\nFor now, I think a reasonable stop-gap solution would be to have some\nsmall storage of prior commitment transactions. For every commitment,\nand each HTLC output, store the timeout and the original Commitment\nTransaction height when the HTLC was first made. That should be enough\ninformation to work with (you can work backwards if you know which\nCommitment Transaction the HTLC was first created) and amounts to 48\nbits (6 bytes) of storage per HTLC output per fully expired Commitment\nTransaction. I generally dislike OP_RETURN as a solution, but it's\npossible.\n\nThanks for bringing this up, I haven't really properly considered this!\n\n-- \nJoseph Poon"
            },
            {
                "author": "Joseph Poon",
                "date": "2015-07-25T00:38:25",
                "message_text_only": "Oh, I forgot it's necessary to store the hash of the R value. That'll\nmake it much bigger. 26-bytes or so.\n\nAlso, if OP_RETURN is viewed as acceptable, then you should be able to\nfit 3 outputs per OP_RETURN metadata output.\n\nThinking through further, using OP_RETURN metadata is objectively better\nthan just having the nonstandard non-P2SH output when considering\ntransaction size.\n\nSo for OP_RETURN, you could have a blob up to 80 bytes (or 40 if you\nwant to maximize relay), which results in ~3 transactions if you assume\n26-bytes per transaction. If you have a lot, you should probably just\nfill it all up and compact it, I guess.\n\n16-bits is fine for timeouts since that's 65535 block heights, which is\na little over a year's worth. Nothing's stopping you from supporting\nmore than a year's worth if you can find the route, but that's a fine\nupper-bound for now.\n\n32-bits is used for the Commitment Transaction. For even the most\nhigh-volume node, 10 commitments per second results in 300 million\nCommitment Transactions. This identifies in which Commitment Transaction\nthe HTLC was created. By knowing the Commitment Transaction, you'll know\nthe revocation preimage, so after the revocation information has been\nexchanged, you only need to know which Commitment Transaction the HTLC\nwas originally formed, since the revocation information was originally\n*generated* using a merkle tree derived from the Commitment Transaction\nas an index.\n\nIn total that's 48-bits (6bytes) per HTLC output per Commitment. Plus\n20-bytes for the hash(R), 26bytes.\n\nIf someone broadcasts an old Commitment and you don't have the HTLC data\nbecause it's expired and too old, check the OP_RETURN data for the\n6-bytes, then compute the revocation data and compute a couple hundred\nrevocations and see which one fits.\n\nI think the tradeoff might be worth it. If you stored this data locally,\nthe cost shouldn't be too high for end-users. However, for those that\nwish to do a lot of routing, this can add up. A node that does 10\ncommits/s with 100 HTLCs on average that results in a little over 800GB\nof local storage per channel if OP_RETURN wasn't used, which may very\nwell be feasible for large hubs. Of course, whether OP_RETURN or local\nstorage were used, it's better than having the entire script as part of\nthe output.\n\n-- \nJoseph Poon"
            },
            {
                "author": "Anthony Towns",
                "date": "2015-07-25T08:44:26",
                "message_text_only": "On Fri, Jul 24, 2015 at 03:38:28PM -0700, Joseph Poon wrote:\n> If we're presuming everyone uses OP_CSV in the long-term, you can\n> overload nLockTime with values below current unixtime as a\n> filter/counter. It should be enough bits of entropy no matter the size\n> (even in the billions of transactions in a single channel) Since both\n> parties are signing the nLockTime value, it's safe to use that as an\n> identifier in the Commitment Transaction.\n\nOh, that's clever! You can use the range between 500M and $NOW, which\ngives you 937,798,763 values at the time of writing, so about a billion\nupdates per channel. If that wasn't enough, you could divide your actual\nn by 10, 100, 1000 etc, and just have to search through an additional 10,\n100, 1000 hashes to work out which value to use when claiming cheating.\n\nOn Fri, Jul 24, 2015 at 04:24:49PM -0700, Joseph Poon wrote:\n> Ah sorry, that only solves the Commitment Transactions, not the HTLC\n> outputs. It's also not possible to use the pubkeys as identifiers, as\n> Rusty said, P2SH would be used.\n> \n> While it's possible to only check only recent blocks before the\n> Commitment Transaction for the search space (e.g. 3 days worth), since\n> you know when the Commitment Transaction was broadcast, the search space\n> limitation sort of breaks down if you permit long-dated HTLCs.\n\nI don't think it matters how long the HTLC was; maybe they're way old\nand all expired, but were payments to you. Say the current channel is:\n\n 12 -> Cheater\n 88 -> You\n\nand the old transaction that Cheater just pushed to the blockchain was:\n\n 55 -> Cheater\n  3 -> You\n 10 -> You & R1 | Cheater & Timeout1\n 20 -> You & R2 | Cheater & Timeout2\n 12 -> You & R3 | Cheater & Timeout3\n\nTo get at least your 88 owed, you need all but the last transaction, so\nyou need to be able to workout #R1 and #R2 and Timeout1 and Timeout2, no\nmatter how long ago they were.\n\n> For now, I think a reasonable stop-gap solution would be to have some\n> small storage of prior commitment transactions. For every commitment,\n> and each HTLC output, store the timeout and the original Commitment\n> Transaction height when the HTLC was first made.\n\nI don't think you want to multiply each HTLC output by every commitment\nit's stored in -- if the TIMEOUT is on the order of a day, and the\nchannel is updated just once a second that's a x86,400 blowout in\nstorage, so almost 5 orders of magnitude.\n\nBut if everytime you see a new HTLC output (ie, R4, Timeout4), you could\nstore those values and use the nLockTime trick to store the height of\nyour HTLC storage. Then you just have to search back down from R4 to\nfind the other HTLCs in the txn, ie R3, R2 and R1, which is just a\nmatter of pulling out the values R, Timeout, dropping them into payment\nscript templates, and checking if they match.\n\nYou could also store your commitment count to still limit the searching\nyou have to do there. If you make the rule:\n\n - nLockTime will increment everytime we introduce a new HTLC\n - nLockTime will increment everytime there's been N commitment updates\n   since the last time nLockTime incremented\n\nand you store:\n\n - 47b commitment index\n -  1b am I being paid?\n - 80b R\n - 16b timeout\n\neach time. If it's a new HTLC you store the info for that, if it's just\na commitment bump, you store the active HTLC that's furthest from the\ntop of the stack, or all 0s. That's 18 bytes per HTLC or n commitments.\nIf you spend a year doing 100 new HTLC/s that's 57GB for HTLCs and\nif you set n to be 100k hashes to search through (so half a minute's\nwork on Rusty's laptop), and assume 1000 commitments/s in a worst case\ndistribution, that's just an extra 5MB.\n\nYou might have to increment by ~0.25 each time instead to last a year\nwithout nLockTime surpassing current Unix time; I don't think that causes\nmuch problem though -- you have maybe 4x as many commitment hashes to\ncheck, and up to an extra 3 HTLCs to check and skip. Reduce n by 4 to\ncompensate, and that's an extra 20MB instead of 5MB.\n\n~60GB after a year is about 30*12 = 360 GB-months of data, which is\nabout $12 on Amazon S3. That seems reasonably plausible, even at scale,\ndoesn't it?\n\n(If you need an extra 4B per HTLC to avoid relying on OP_CTV/OP_CSV;\nthat's ~23% more space; so say $15 over the course of a year)\n\n> That should be enough\n> information to work with (you can work backwards if you know which\n> Commitment Transaction the HTLC was first created) and amounts to 48\n> bits (6 bytes) of storage per HTLC output per fully expired Commitment\n> Transaction. I generally dislike OP_RETURN as a solution, but it's\n> possible.\n\nHmm, I'm not sure OP_RETURN actually works well enough for avoiding\nlocal storage of HTLC specs -- more than one OP_RETURN is non-standard :(\n\n(Of course the scripts behind the P2SH hashes are non-standard too)\n\n> Thanks for bringing this up, I haven't really properly considered this!\n\nGlad it's novel :)\n\nOn Fri, Jul 24, 2015 at 05:38:25PM -0700, Joseph Poon wrote:\n> Oh, I forgot it's necessary to store the hash of the R value. That'll\n> make it much bigger. 26-bytes or so.\n> Also, if OP_RETURN is viewed as acceptable, then you should be able to\n> fit 3 outputs per OP_RETURN metadata output.\n\nYeah; 80 bytes works much better than 40 bytes.\n\n> 32-bits is used for the Commitment Transaction. For even the most\n> high-volume node, 10 commitments per second results in 300 million\n> Commitment Transactions. This identifies in which Commitment Transaction\n> the HTLC was created. By knowing the Commitment Transaction, you'll know\n> the revocation preimage, so after the revocation information has been\n> exchanged, you only need to know which Commitment Transaction the HTLC\n> was originally formed, since the revocation information was originally\n> *generated* using a merkle tree derived from the Commitment Transaction\n> as an index.\n\nI don't think this is useful if you've got OP_CTV and OP_CSV? If your\nscript is:\n\n  Pay: (Alice & R & DELAY) | (Bob & TIMEOUT) | (Bob & REVOCATION)\n\nthen the REVOCATION has to be updated with each commitment update, or\nelse Bob would be able to claim it immediately after the next commitment\nupdate. So you only need to know the txn's commitment id, which you\nwork out from nLockTime anyway.\n\nOtherwise, Alice, Bob, and DELAY are channel parameters; leaving just\nR and TIMEOUT which fit in 22 bytes. So you can fit ~3.6 R&TIMEOUTs in\na single OP_RETURN (so 3.6 in 1, 7.2 in 2, exactly 40 in 11).\n\nI'm not sure how the key management works for when you don't have OP_CTV\nor OP_CSV. I guess if the the key set used for HTLC #N is calculable given\nany secret M>N (but not M<=N), and you always reveal secret MIN(current\nactive HTLC ids), then you just need to record the HTLC's index. You\ncould again allow for a small search though; you only have to calculate\nthe public key and hash the transaction against the calculated keys so\nsearching should still be somewhat cheap. So yeah, I think that makes\nsense?\n\nBTW, 10 commitments per second (per channel) doesn't sound /that/ high\nvolume :) Pay per megabyte for an end user at 100Mb/s is already\naround that at least at peak times, eg.\n\nCheers,\naj"
            },
            {
                "author": "Joseph Poon",
                "date": "2015-07-27T21:29:56",
                "message_text_only": "Hi Anthony,\n\nOn Sat, Jul 25, 2015 at 06:44:26PM +1000, Anthony Towns wrote:\n> On Fri, Jul 24, 2015 at 04:24:49PM -0700, Joseph Poon wrote:\n> > Ah sorry, that only solves the Commitment Transactions, not the HTLC\n> > outputs. It's also not possible to use the pubkeys as identifiers,\n> > as Rusty said, P2SH would be used.\n> > \n> > While it's possible to only check only recent blocks before the\n> > Commitment Transaction for the search space (e.g. 3 days worth),\n> > since you know when the Commitment Transaction was broadcast, the\n> > search space limitation sort of breaks down if you permit long-dated\n> > HTLCs.\n> \n> I don't think it matters how long the HTLC was; maybe they're way old\n> and all expired, but were payments to you. Say the current channel is:\n> \n>  12 -> Cheater 88 -> You\n> \n> and the old transaction that Cheater just pushed to the blockchain\n> was:\n> \n>  55 -> Cheater 3 -> You 10 -> You & R1 | Cheater & Timeout1 20 -> You\n>  & R2 | Cheater & Timeout2 12 -> You & R3 | Cheater & Timeout3\n> \n> To get at least your 88 owed, you need all but the last transaction,\n> so you need to be able to workout #R1 and #R2 and Timeout1 and\n> Timeout2, no matter how long ago they were.\n\nYes, I agree, that is absolutely true. I was alluding to something\ndifferent (but didn't properly explain myself), which is that if you did\ngrinding of only recent Commitments, it's possible that there will be\nHTLCs with very high timeouts in the future and this may be a necessary\nrequirement for some possible future use cases (e.g.\nrecurring/pre-allocated billing).\n\n> > For now, I think a reasonable stop-gap solution would be to have\n> > some small storage of prior commitment transactions. For every\n> > commitment, and each HTLC output, store the timeout and the original\n> > Commitment Transaction height when the HTLC was first made.\n> \n> I don't think you want to multiply each HTLC output by every\n> commitment it's stored in -- if the TIMEOUT is on the order of a day,\n> and the channel is updated just once a second that's a x86,400 blowout\n> in storage, so almost 5 orders of magnitude.\n> \n> But if everytime you see a new HTLC output (ie, R4, Timeout4), you\n> could store those values and use the nLockTime trick to store the\n> height of your HTLC storage. Then you just have to search back down\n> from R4 to find the other HTLCs in the txn, ie R3, R2 and R1, which is\n> just a matter of pulling out the values R, Timeout, dropping them into\n> payment script templates, and checking if they match.\n\nYes, that's a good point(!), especially when you're doing local storage.\nIf you're relying on OP_RETURN, though, you must put in some more\ncontextual data. If you're willing to regenerate the revocation hash\nevery time, I guess the OP_RETURN can just be timeout and H. For local\nstorage, you don't need to do it for every HTLC if you're willing to\nsearch back on near-dated HTLCs, but long-dated HTLCs (say, greater than\na couple days) could be included (class memory vs. computation\ntradeoff). Agreed, the necessary data storage isn't *that bad* for core\nnodes, and trivial for edge nodes not doing liquidity providing\n(ignoring backup concerns, of course).\n\n> BTW, 10 commitments per second (per channel) doesn't sound /that/ high\n> volume :) Pay per megabyte for an end user at 100Mb/s is already\n> around that at least at peak times, eg.\n\nPerhaps with a relatively distributed graph and core nodes having many\nconnections, it's possible that's the range. Either way, it should be\nfine. If you have enough entropy to filter by hundreds of millions using\nnLockTime, even if you have 10 billion (or 100 billion) to search\nthrough it should be nearly instant. If you have 1000 possible\nrevocation hashes, just look at the first txout (the non-HTLC payouts to\nAlice and Bob) and see which revocation fits. Once you know the exact\nCommitment number, the rest of the outputs are easy.\n\n-- \nJoseph Poon"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-27T01:43:19",
                "message_text_only": "Joseph Poon <joseph at lightning.network> writes:\n> Oh, I forgot it's necessary to store the hash of the R value. That'll\n> make it much bigger. 26-bytes or so.\n>\n> Also, if OP_RETURN is viewed as acceptable, then you should be able to\n> fit 3 outputs per OP_RETURN metadata output.\n\nSo that's the summary of where we stand.  Beyond 3 HTLCs, you need to\nremember HTLC values forever.\n\nI think this has an effect on how we do anchor upgrades (to increase or\ndecrease channel capitalization).\n\nNaively, we just open another channel.\n\nAlternately, we create a new anchor which spends the existing anchor(s).\n\nWhile we're waiting for it to be sufficiently buried we create\ncommitment txs (and HTLCs) against both the new and old anchor.  Once\nthe new anchor is buried enough, we drop the old one.\n\nAt that point, those ancient HTLCs all become unspendable, so we can\nforget those old values.  I think that's a win...\n\n(I've ignored issues with how we avoid mutation etc. with the new\nanchor, since I'm about to re-open that can in another thread).\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "commitment update steps",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Anthony Towns",
                "Rusty Russell",
                "Joseph Poon"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 28376
        }
    },
    {
        "title": "[Lightning-dev] Breach of contract?",
        "thread_messages": [
            {
                "author": "Christopher Jamthagen",
                "date": "2015-07-25T20:59:16",
                "message_text_only": "An HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150725/ebfeffe0/attachment.html>"
            },
            {
                "author": "Joseph Poon",
                "date": "2015-07-26T14:57:53",
                "message_text_only": "On Sat, Jul 25, 2015 at 10:59:16PM +0200, Christopher Jamthagen wrote:\n> <div>According to the whitepaper: &quot; If three days have elapsed,\n> then the above clause is null and void and the clearing process is\n> invalidated, both parties must not attempt to settle and claim payment\n> after three days.&quot; But clearly there is nothing stopping Bob from\n> taking the HTLC output when Alice is forced to broadcast the\n> commitment transaction, even if it is supposed to be null and\n> void.</div>\n\nHi Christopher,\n\nThe design of the HTLCs have a contestation period built-in where the\nparty which broadcasts the Commitment Transaction must wait a period of\ntime before the payment goes back to themselves.\n\nI think your concern may have some implications for Rusty's dual\nanchor/funding version. I had incorrectly stated that it might be\npossible to do it only with OP_CLTV, but it clearly requires both\nOP_CLTV and OP_CSV.\n\nThere's more information being attested when relying on OP_CSV for the\nHTLC without a transaction chained 2 levels deep. It will require\ngreater time delay between each hop in the payment to account for the\nrelative time to prove whether the Commitment has been revoked. This\ngreater time creates a tradeoff which requires each channel participant\n(for every hop) to watch the blockchain at a more frequent interval,\nsince that OP_CSV value is intrinsically linked to the payment.\n\nWith a SIGHASH_NOINPUT (or similar) model having transactions two-deep,\nthis contestation period can be independent of the actual HTLC payments.\nIn effect, the first transaction spending from the HTLC validates\nwhether the preimages are known, the second is whether the Commitment\nitself is invalidated. With separated anchor/funding, those two steps\nare combined inside the Commitment Transaction -- AFAIK, (minus the\nabove tradeoffs) it still works though, but I'll double-check.\n\n-- \nJoseph Poon"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-27T01:50:54",
                "message_text_only": "Christopher Jamthagen <cjamthagen at gmx.com> writes:\n> When a HTLC's CLTV has expired, the receiver of the HTLC should not be\n> able to use the pre-image to spend the output from a commitment\n> transaction that has not been invalidated.\n> Assume a circuit is established: Alice -> Bob -> Dave\n\nYes, I assume that the HTLC gets eliminated by a commitment transaction\nupdate at (or before) that time.\n\nWe could add an additional delay for this case, but it seems like\noverengineering?\n\nCheers,\nRusty."
            },
            {
                "author": "Joseph Poon",
                "date": "2015-07-27T19:37:57",
                "message_text_only": "On Mon, Jul 27, 2015 at 11:20:54AM +0930, Rusty Russell wrote:\n> Yes, I assume that the HTLC gets eliminated by a commitment transaction\n> update at (or before) that time.\n> \n> We could add an additional delay for this case, but it seems like\n> overengineering?\n\nTo ensure that the older version of the transaction does not get\nbroadcast through a credible threat, there needs to be some contestation\nperiod for one's own HTLC when one is redeeming funds.\n\nHowever, there are less elegant solutions that are possible as a\nstop-gap before a full malleability fix which permits you to generate\nchild transactions before signing the parent.\n\nCurrent/unexpired HTLCs will have the same payout and enforcement, but\nthere is a risk of broadcasting older Commitments and stealing the HTLC\npayout, e.g. transactions that are believed to be timed out but whose\npreimages are known after-the-fact. Theft of the HTLC via broadcast of\nexpired Commitments can be mitigated by having some funds in reserve\navailable on one's own channel balance to ensure honesty. In effect, the\ntotal value of the HTLCs must be below one's own reserve balance (for\nboth parties). The reserve balance must not be used ever.\n\nNote that this presumes dual-funder. I'll go into single-funder model\nlater.\n\nFor example, if Alice and Bob have a channel with the latest Commitment:\n0.49 to Alice (0.02 in permanent reserve)\n0.50 to Bob (0.02 in permanent reserve)\n0.01 HTLC Alice to Bob\n\nThis is a valid HTLC, since Alice's current channel balance not\nallocated to HTLCs is 0.49. This balance must be at or above 0.02 at\nall times throughout the life of the channel, until Alice closes it out\nor does a final payment to zero it out and close. Similarly, Bob also\nmust maintain a balance of 0.02 throughout the life of the channel.\n\nThe sum of all HTLCs going from Alice to Bob must be at or (preferably)\nbelow this 0.02 limit at all times before closing out the channel.\n\nThe result is if Alice broadcasts an old Commitment, Bob is assured that\nthe balance of the HTLC will be at or below 0.02. The maximum Alice can\nsend will be 0.98 in the channel, so even if she attempts to steal the\nHTLC, Bob can be made whole by taking back all his funds, as well as all\nof Alice's funds as penalty. Even if he is unable to take back the HTLC,\nhe will take all of Alice's funds in reserve, which is less than the\nbalance of all HTLCs in transit from Alice to Bob at all times\nthroughout the historical life of the channel.\n\nDepending on how willing you are to enforce the HTLC past this point,\nyou can make the script substantially simpler, as well.\n\nTo fund this using single-funder, one should be very cognizant of risks\nrelated to systemic risks related to trust asymmetry of the channel\ncounterparties. If we construct a model using single-funder, it requires\nvery shallow rebalancing of funding for symmetric trust, i.e. Alice\nopens a channel to Bob first, then Bob opens a channel to Alice. This\ninitial channel funding would probably have a very high OP_CSV value.\nFor the OP_CSV value to be this high and functional without DoS risks,\nit requires the number of LN hops to be fairly low during this channel\nsetup phase (but won't matter after), as they may be potentially locking\nup money for a longer period of time if the HTLC payment is not\nfulfilled). For OP_CLTV only (without OP_CSV) I think it'll be to the\npoint where it *requires* setting up two channels with the same person.\n\nPersonally, I have some reservations for models which have funds in\npermanent reserve, but this model is a fairly good stop-gap before a\nreal malleability fix (SIGHASH_NOINPUT or segregated witness). This\nmodel should be able to work with just OP_CLTV (and with OP_CSV too),\nbut may not be quite as fun. Also, to maximize fun under this model to\nmitigate when a counteparty is a jerk, you should always make sure the\namount in permanent reserve is *always above* (not equal to) the value\nencumbered in HTLCs.\n\n-- \nJoseph Poon"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-28T01:38:05",
                "message_text_only": "Joseph Poon <joseph at lightning.network> writes:\n> On Mon, Jul 27, 2015 at 11:20:54AM +0930, Rusty Russell wrote:\n>> Yes, I assume that the HTLC gets eliminated by a commitment transaction\n>> update at (or before) that time.\n>> \n>> We could add an additional delay for this case, but it seems like\n>> overengineering?\n>\n> To ensure that the older version of the transaction does not get\n> broadcast through a credible threat, there needs to be some contestation\n> period for one's own HTLC when one is redeeming funds.\n\nThe rule, AFAICT, is: if it's A's commitment transaction, all outputs\nwhich are redeemable by A must be delayed.\n\nFor HTLCs, this means:\n1) Timeout returns for HTLCs A initiates must be OP_CSV delayed.\n2) Payments for HTLCs A receives must be delayed.\n\nI just noticed the scripts in the 0.1 draft are a bit messed up; in\nparticular they're missing a delay.  Here's the (fixed!) A offers HTLC\nto B case:\n\n(See https://github.com/ElementsProject/lightning/blob/master/doc/ )\n\nHTLC Sender Redeemscript (A):\n\nOP_HASH160 OP_DUP        Replace top element with two copies of its hash\n<R-HASH> OP_EQUAL        Test if they supplied the HTLC R value\nOP_SWAP <COMMIT-REVOCATION-HASH> OP_EQUAL OP_ADD\n                         Or the commitment revocation hash\n\nOP_IF                    If any hash matched.\n        <KEY-B>          Pay to B.\nOP_ELSE                  Must be A, after HTLC has timed out.\n\n        <HTLC-TIMEOUT> OP_CHECKLOCKTIMEVERIFY OP_DROP\n                         Ensure (absolute) time has passed.\n        <DELAY> OP_CHECKSEQUENCEVERIFY OP_DROP\n                         Delay gives B enough time to use revocation if it has it.\n        <KEY-A>          Pay to A.\nOP_ENDIF\nOP_CHECKSIG              Verify A or B's signature is correct.\n\nHTLC Receiver Redeemscript (B):\n\nOP_HASH160 OP_DUP        Replace top element with two copies of its hash\n<R-HASH> OP_EQUAL        B redeeming the contract, using R preimage?\nOP_IF\n        OP_DROP          Remove extra hash\n        <DELAY> OP_CHECKSEQUENCEVERIFY OP_DROP\n                         Delay gives A enough time to use revocation if it has it.\n\n        <KEY-B>          Pay to B\nOP_ELSE\n        <COMMIT-REVOCATION-HASH> OP_EQUAL\n                         If the commit has been revoked.\n        OP_NOTIF\n                         If not, you need to wait for timeout.\n                <HTLC-TIMEOUT> OP_CHECKLOCKTIMEVERIFY OP_DROP\n                         Ensure (absolute) time has passed.\n        OP_ENDIF\n\n        <KEY-A>          Pay to A\nOP_ENDIF\nOP_CHECKSIG              Verify A or B's signature is correct.\n\n> Current/unexpired HTLCs will have the same payout and enforcement, but\n> there is a risk of broadcasting older Commitments and stealing the HTLC\n> payout, e.g. transactions that are believed to be timed out but whose\n> preimages are known after-the-fact.\n\nI see that?\n\nIf A broadcast an older commitment, B can steal the HTLC payout, but\nthat's as designed.\n\nCheers,\nRusty."
            },
            {
                "author": "Joseph Poon",
                "date": "2015-07-29T19:50:06",
                "message_text_only": "On Tue, Jul 28, 2015 at 11:08:05AM +0930, Rusty Russell wrote:\n> For HTLCs, this means:\n> 1) Timeout returns for HTLCs A initiates must be OP_CSV delayed.\n> 2) Payments for HTLCs A receives must be delayed.\n> \n> I just noticed the scripts in the 0.1 draft are a bit messed up; in\n> particular they're missing a delay.  Here's the (fixed!) A offers HTLC\n> to B case:\n\nAh ok, cool!\n\n> [scripts]\n\nAfter thinking about this for a bit, there's two implications for this\nscript:\n\n1. De-facto requires constantly watching the blockchain for a very low\ninterval. If Alice and Bob establish a channel, make a couple payments,\nand now the balance of the channel is now 0 to Alice and 1 BTC to Bob,\nif Bob doesn't constantly watch the chain, he can lose money. If the\nHTLC-TIMEOUT is defined as 1 day, Alice can broadcast an old Commitment\nand then hope Bob isn't paying attention and steal some money. In\neffect, the maximum time between watching the chain will be the minimum\nHTLC-TIMEOUT throughout the life of the channel when the channel balance\nis currently tiled heavily in one direction.\n\n2. Probably at the minimum doubles the HTLC timelock on LN payments. If\nthere is a minimum amount of time to wait to redeem funds (or receive a\nrefund), then the HTLC timeout must give you sufficient amount of time\nto redeem as well. I suspect the amount of time necessary is about the\nsame since they're both dependent upon the estimated amount of time to\nenter into the blockchain. If that's the case, doubling the HTLC\ntimeouts has some implications since it'll result in higher fees as a\ndownside, but might bias towards less graph centralization as well.\n\nFundamentally, the cause is derived from the fact that the HTLC timeout\nand the OP_CSV revocation are inextricably linked.\n\nNumber 1 is more relevant to me (IMO), which is why I brought up the\nreserve thing. I'm not so into the reserve balance concept, simply\nbecause it severely limits the amount of transactional flow available at\nonce (it also limits the number of retries/multiplexing sends), which\nmatters more for liquidity providers (that model can reduce available\nliquidity by 4x in best-case scenarios).\n\n-- \nJoseph Poon"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-30T02:33:21",
                "message_text_only": "Joseph Poon <joseph at lightning.network> writes:\n> On Tue, Jul 28, 2015 at 11:08:05AM +0930, Rusty Russell wrote:\n>> For HTLCs, this means:\n>> 1) Timeout returns for HTLCs A initiates must be OP_CSV delayed.\n>> 2) Payments for HTLCs A receives must be delayed.\n>> \n>> I just noticed the scripts in the 0.1 draft are a bit messed up; in\n>> particular they're missing a delay.  Here's the (fixed!) A offers HTLC\n>> to B case:\n>\n> Ah ok, cool!\n>\n>> [scripts]\n>\n> After thinking about this for a bit, there's two implications for this\n> script:\n>\n> 1. De-facto requires constantly watching the blockchain for a very low\n> interval. If Alice and Bob establish a channel, make a couple payments,\n> and now the balance of the channel is now 0 to Alice and 1 BTC to Bob,\n> if Bob doesn't constantly watch the chain, he can lose money. If the\n> HTLC-TIMEOUT is defined as 1 day, Alice can broadcast an old Commitment\n> and then hope Bob isn't paying attention and steal some money. In\n> effect, the maximum time between watching the chain will be the minimum\n> HTLC-TIMEOUT throughout the life of the channel when the channel balance\n> is currently tiled heavily in one direction.\n\nHTLC-TIMEOUT is an absolute time/block, not relative.  Thus\nOP_CHECKLOCKTIMEVERIFY is a noop for old HTLCs.\n\nSo, if A broadcasts, they need to wait <DELAY> to spend.  I don't think\nI added anything new here?\n\n> 2. Probably at the minimum doubles the HTLC timelock on LN payments. If\n> there is a minimum amount of time to wait to redeem funds (or receive a\n> refund), then the HTLC timeout must give you sufficient amount of time\n> to redeem as well. I suspect the amount of time necessary is about the\n> same since they're both dependent upon the estimated amount of time to\n> enter into the blockchain. If that's the case, doubling the HTLC\n> timeouts has some implications since it'll result in higher fees as a\n> downside, but might bias towards less graph centralization as well.\n\nYes, the effective minimum HTLC-TIMEOUT is \"current-time + <DELAY>\",\nbecause if A broadcasts its commitment tx, the HTLC stays redeemable\nuntil A spends it (which it can't do until after <DELAY>).\n\nBut it's not clear that this \"htlc timeout doubling\" applies to every\nstep on the route, it seems to just add one?\n\nOr am I missing something else?\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Breach of contract?",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Christopher Jamthagen",
                "Joseph Poon"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 13985
        }
    },
    {
        "title": "[Lightning-dev] Single-funder anchor model?",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2015-07-27T02:28:12",
                "message_text_only": "Hi all,\n\n        This mentioned on the weekend via #lightning-dev (sorry, still\nnot archived) from go1111111:\n\n        https://bitcointalk.org/index.php?topic=1134319.new#new\n\nBasically it points out that a single-funder anchor can be done without\nrequiring new sighash ops nor losing outsourcability.\n\nThe other end can transfer funds (if it wants to balance the channel) in\ntwo obvious ways.  The first is to use the lightning network as normal\n(via some other channel it already has).  The second (from AJ) is to use\nthe atomic cross-blockchain idea[1] to atomically transfer funds in from\nnative bitcoin.\n\nPros:\n        1. Fairly simple.\n        2. Outsourcability.\n\nCons:\n        1. Asymmetric creation risk\n        2. Wants cross-chain atomic txs sooner\n        3. Takes twice the time to get a full two-way channel\n\nThe asymmetric risk is as much a feature as a problem: with the\ndual-anchor proposal, either side could abort with no penalty and make\nthe other side wait for the escape timeout anyway.\n\nWe've handwaved over the incentives for channel creation so far; they're\ntied with routing, and not immediately clear to me.  But it doesn't seem\nunreasonable that if you connect to a hub, you front the funds.\n\nThoughts?\nRusty.\n\n[1] https://bitcointalk.org/index.php?topic=1036208.0 and discussed earlier\n    on the list[2]\n[2] Still agitating to have those early archives merged into the lf ones..."
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-27T03:16:59",
                "message_text_only": "Rusty Russell <rusty at rustcorp.com.au> writes:\n>         3. Takes twice the time to get a full two-way channel\n\nThis is wrong[1]; go1111111 points out that the atomic swap tx can\nhit the bitcoin blockchain about the same time as the anchor tx.\n\nCheers,\nRusty.\n[1] https://bitcointalk.org/index.php?topic=1134319.msg11969780#msg11969780"
            },
            {
                "author": "Joseph Poon",
                "date": "2015-07-28T01:42:24",
                "message_text_only": "On Mon, Jul 27, 2015 at 11:58:12AM +0930, Rusty Russell wrote:\n> The asymmetric risk is as much a feature as a problem: with the\n> dual-anchor proposal, either side could abort with no penalty and make\n> the other side wait for the escape timeout anyway.\n\nCool, I think this works.\n\nYeah non-cooperation risks in this model aren't that big of a deal,\nbecause the channel is going to be closed out anyway if they're not\ncooperative -- they could always refuse to route payments, and then\neveryone's going to get their money back.\n\n> We've handwaved over the incentives for channel creation so far; they're\n> tied with routing, and not immediately clear to me.  But it doesn't seem\n> unreasonable that if you connect to a hub, you front the funds.\n\nYeah, there's likely some weird asymmetric economic incentive things\ngoing on. If both channels are established with the same person, it\nshould be fairly clean, though. I think there will probably be some\nmeasure of trust/reputation involved with pre-payment of the time-value\nfor the channel (shorter with OP_CSV, but still non-zero).\n\nOP_CSV still requires BIP 62, though. It's possible to construct a model\nwith OP_CLTV without BIP 62 (described in a post earlier today) using\nsingle-funder with some OP_CLTV'd output which returns the full balance\nto the original funder at a date very far in the future after the\nexpiration of all Commitments and its dependent outputs.\n\n-- \nJoseph Poon"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-28T02:00:11",
                "message_text_only": "Joseph Poon <joseph at lightning.network> writes:\n> OP_CSV still requires BIP 62, though. It's possible to construct a model\n> with OP_CLTV without BIP 62 (described in a post earlier today) using\n> single-funder with some OP_CLTV'd output which returns the full balance\n> to the original funder at a date very far in the future after the\n> expiration of all Commitments and its dependent outputs.\n\nYeah, I'm happy at this stage assuming BIP62.  There don't seem any\nobjections to it, just not huge motivation.\n\nNice to know we have a backup if that proves overly optimistic :)\n\nCheers,\nRusty."
            },
            {
                "author": "Eric Lombrozo",
                "date": "2015-07-28T04:22:21",
                "message_text_only": "I don\u2019t really think there\u2019s a lack of motivation.\n\nThe unfortunate situation is that soft forks are backlogged\u2026and the entire soft fork process is undergoing some pretty significant changes. There were already some pretty major concerns about it. The version bits BIP (https://gist.github.com/sipa/bf69659f43e763540550 <https://gist.github.com/sipa/bf69659f43e763540550>) which would allow multiple concurrent soft forks is still under works. Then the BIP66 fork brought to light some more problems with the process. And then on top of all that we have this block size hard fork circus\u2026\n\n> On Jul 27, 2015, at 7:00 PM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n> \n> Joseph Poon <joseph at lightning.network> writes:\n>> OP_CSV still requires BIP 62, though. It's possible to construct a model\n>> with OP_CLTV without BIP 62 (described in a post earlier today) using\n>> single-funder with some OP_CLTV'd output which returns the full balance\n>> to the original funder at a date very far in the future after the\n>> expiration of all Commitments and its dependent outputs.\n> \n> Yeah, I'm happy at this stage assuming BIP62.  There don't seem any\n> objections to it, just not huge motivation.\n> \n> Nice to know we have a backup if that proves overly optimistic :)\n> \n> Cheers,\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150727/53284608/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 842 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150727/53284608/attachment-0001.sig>"
            }
        ],
        "thread_summary": {
            "title": "Single-funder anchor model?",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Eric Lombrozo",
                "Joseph Poon"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 5754
        }
    },
    {
        "title": "[Lightning-dev] OP_CHECKSPVPROOFVERIFY",
        "thread_messages": [
            {
                "author": "Eric Lombrozo",
                "date": "2015-07-29T09:08:39",
                "message_text_only": "I don\u2019t know if anyone has done any research or published anything in this regard, but one of the major issues with bitcoin I\u2019ve been trying to solve is how to properly incentivize nodes to construct SPV proofs.\n\nIt occurs to me that with the LN, it might be practical to outsource SPV proofs from other nodes.\n\nIt is obviously ridiculously prohibitive and self-defeating to include SPV proofs in the blockchain\u2026however, in practice this would only be necessary when the SPV client fails to pay the prover.\n\nThoughts?\n\n\n- Eric\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 842 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150729/657cc36e/attachment.sig>"
            },
            {
                "author": "Joseph Poon",
                "date": "2015-07-29T19:54:17",
                "message_text_only": "Hi Eric,\n\nOn Wed, Jul 29, 2015 at 02:08:39AM -0700, Eric Lombrozo wrote:\n> It occurs to me that with the LN, it might be practical to outsource\n> SPV proofs from other nodes.\n\nI couldn't find anything on an SPV proof opcode, what kind of opcode are\nyou thinking of or do you have any links? I tried looking it up but\ncouldn't find anything about it. I'm curious on whether/how it could it\noffer significantly better security than current SPV proofs.\n\n-- \nJoseph Poon"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-30T01:19:15",
                "message_text_only": "Eric Lombrozo <elombrozo at gmail.com> writes:\n> I don\u2019t know if anyone has done any research or published anything in\n> this regard, but one of the major issues with bitcoin I\u2019ve been trying\n> to solve is how to properly incentivize nodes to construct SPV proofs.\n\nThis can almost be done via P2SH, but not quite:\n\n1) OP_CAT is disabled :(\n2) The txlen limit might bite, I'd have to do the maths.\n\nCheers,\nRusty."
            },
            {
                "author": "Eric Lombrozo",
                "date": "2015-07-30T06:38:50",
                "message_text_only": "I\u2019m not entirely clear on how you intended to use OP_CAT.\n\nI was thinking something along the lines of\n\n<block hash> <partial merkle tree for transaction> <transaction> OP_CHECKSPVPROOFVERIFY OP_DROP\n\n\n\n- Eric\n\n\n> On Jul 29, 2015, at 6:19 PM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n> \n> Eric Lombrozo <elombrozo at gmail.com> writes:\n>> I don\u2019t know if anyone has done any research or published anything in\n>> this regard, but one of the major issues with bitcoin I\u2019ve been trying\n>> to solve is how to properly incentivize nodes to construct SPV proofs.\n> \n> This can almost be done via P2SH, but not quite:\n> \n> 1) OP_CAT is disabled :(\n> 2) The txlen limit might bite, I'd have to do the maths.\n> \n> Cheers,\n> Rusty.\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 842 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150729/04d17efb/attachment.sig>"
            },
            {
                "author": "Eric Lombrozo",
                "date": "2015-07-30T12:18:42",
                "message_text_only": "Let me elaborate more on the way I see this working in practice. I\u2019ll ignore fees for now. Given that sending the proof on the blockchain is expensive, the parties need to negotiate how they split the risk. Moreover, once revoked, we want to encourage the second outputs to be claimed using the revocation secret, not the SPV proof\u2026but we\u2019ll ignore this detail for now.\n\nWe have two parties, Prover and Verifier. Verifier wants to pay Prover one currency unit for an SPV proof. Assume they have an open channel with each party having 10 currency units.\n\n\nHere are the commitment transactions:\n\nVerifier Commitment Transaction\n=========================\n10\tProverSig\n1\tProverSig + VerifierRevocation || ProverSig + SPV proof || VerifierSig + timeout\n9\tProverSig + VerifierRevocation || VerifierSig + timeout\n\nProver Commitment Transaction\n=========================\n9\tVerifierSig\n1\tVerifierSig + ProverRevocation || ProverSig + SPV proof || VerifierSig + timeout\n10\tVerifierSig + ProverRevocation || ProverSig + timeout\n\n\nA script for [ProverSig + VerifierRevocation || ProverSig + SPV proof || VerifierSig + timeout] could look like:\n\nOP_IF\n\tOP_IF\n\t\tOP_HASH160 <VerifierRevocation> OP_EQUALVERIFY\n\tOP_ELSE\n\t\t<transaction hash> OP_CHECKSPVPROOFVERIFY OP_DROP\n\tOP_ENDIF\n\t<ProverPubKey> OP_CHECKSIG\nOP_ELSE\n\t<timeout> OP_CHECKLOCKTIMEVERIFY OP_DROP\n\t<VerifierPubKey> OP_CHECKSIG\nOP_ENDIF\n\n\nTo redeem this output using the SPV proof, the Prover uses:\n\n<ProverSig> <block hash> <partial merkle tree for transaction> <0> <1>\n\n\nOnce the commitment transactions are created, the Prover gives the Verifier the SPV proof, then they negotiate settlement transactions and exchange revocations.\n\nWould something like this work?\n\n> On Jul 29, 2015, at 11:38 PM, Eric Lombrozo <elombrozo at gmail.com> wrote:\n> \n> I\u2019m not entirely clear on how you intended to use OP_CAT.\n> \n> I was thinking something along the lines of\n> \n> <block hash> <partial merkle tree for transaction> <transaction> OP_CHECKSPVPROOFVERIFY OP_DROP\n> \n> \n> \n> - Eric\n> \n> \n>> On Jul 29, 2015, at 6:19 PM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n>> \n>> Eric Lombrozo <elombrozo at gmail.com> writes:\n>>> I don\u2019t know if anyone has done any research or published anything in\n>>> this regard, but one of the major issues with bitcoin I\u2019ve been trying\n>>> to solve is how to properly incentivize nodes to construct SPV proofs.\n>> \n>> This can almost be done via P2SH, but not quite:\n>> \n>> 1) OP_CAT is disabled :(\n>> 2) The txlen limit might bite, I'd have to do the maths.\n>> \n>> Cheers,\n>> Rusty.\n> \n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 842 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150730/e29f03b1/attachment.sig>"
            },
            {
                "author": "Eric Lombrozo",
                "date": "2015-07-29T22:46:22",
                "message_text_only": "The reason such outsourceability is desirable is because it leads to\nconcrete, quantifiable incentives for running nodes to serve SPV clients\nmaking it possible to reason about the economic security model of the\nnetwork.\nOn Jul 29, 2015 3:28 PM, \"Eric Lombrozo\" <elombrozo at gmail.com> wrote:\n\n> I should have posted this to the whole group. Sorry, hit the wrong button.\n> :p\n> ---------- Forwarded message ----------\n> From: \"Eric Lombrozo\" <elombrozo at gmail.com>\n> Date: Jul 29, 2015 3:27 PM\n> Subject: Re: [Lightning-dev] OP_CHECKSPVPROOFVERIFY\n> To: \"Joseph Poon\" <joseph at lightning.network>\n> Cc:\n>\n> Joseph,\n>\n> The point isn't better security than current SPV proofs. That would\n> require improvements to the commitment structures.\n>\n> The point is to allow outsourceability of SPV proofs over LN. We would\n> want to avoid actually using OP_CHECKSPVPROOFVERIFY in the blockchain...but\n> it would allow crafting a contract requesting payment from the SPV client\n> along with an enforcement mechanism in the event the client fails to pay.\n>\n> - Eric\n> On Jul 29, 2015 12:54 PM, \"Joseph Poon\" <joseph at lightning.network> wrote:\n>\n>> Hi Eric,\n>>\n>> On Wed, Jul 29, 2015 at 02:08:39AM -0700, Eric Lombrozo wrote:\n>> > It occurs to me that with the LN, it might be practical to outsource\n>> > SPV proofs from other nodes.\n>>\n>> I couldn't find anything on an SPV proof opcode, what kind of opcode are\n>> you thinking of or do you have any links? I tried looking it up but\n>> couldn't find anything about it. I'm curious on whether/how it could it\n>> offer significantly better security than current SPV proofs.\n>>\n>> --\n>> Joseph Poon\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150729/3c49ba2a/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "OP_CHECKSPVPROOFVERIFY",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Joseph Poon",
                "Eric Lombrozo"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 7438
        }
    },
    {
        "title": "[Lightning-dev] Stealing money from a hub?",
        "thread_messages": [
            {
                "author": "Christopher Jamthagen",
                "date": "2015-07-29T19:57:32",
                "message_text_only": "An HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150729/b0b4c34c/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-30T02:41:32",
                "message_text_only": "Christopher Jamthagen <cjamthagen at gmx.com> writes:\n> Still trying to get the details right of this protocol. Please correct\n> me if I am wrong in any of my assumptions below.\n\n> Assume a payment route: Alice<>Bob<>Carol\n\n> Alice want to pay Carol some amount. Carol gives Alice H(R) and Alice\n> updates her commitment tx with Bob including the HTLC output and Bob\n> does the same with Carol.\n\nOK.\n\n> Carol witholds R, forcing Bob to broadcast the commitment tx between\n> Bob and Carol.\n\nYep, Carol goes non-responsive.  Got it.\n\n> Carol can now spend the HTLC output because she knows R and thus\n> revealing it to the world. Alice now also refuses to update the\n> commitment tx with Bob, forcing Bob to broadcast that commitment tx.\n\nPoor Bob.  Yep.\n\n> This commitment tx is putting a delay on\n> Bobs ability to spend the HTLC output (as well as all other outputs to\n> him), but Alice can spend the HTLC output if the CLTV has expired.\n\nIndeed, don't ever offer an HTLC less than your delay!\n\n> In most examples I have seen, the CLTV is 2 days between Alice and Bob\n> and 1 day between Bob and Carol, and all CSV delays are 3 days.\n\nI haven't seen an example which included a CSV delay amount.\n\nAs the discussion with Joseph is establishing, the minimum CSV you allow\ncontrols the worst-case HTLC you can accept.  CSV of a few hours should\nbe OK if you're online all the time.  I think...\n\nAnyone want to do some stats on that?  CSV uses the median time of last\n11 blocks, so to some extent you can tell the worst case...\n\nCheers,\nRusty."
            },
            {
                "author": "Benjamin",
                "date": "2015-07-30T08:17:55",
                "message_text_only": ">> Still trying to get the details right of this protocol.\n\nMe too, but I have some more basic problems.\n\n>> Assume a payment route: Alice<>Bob<>Carol\n\n* how does Alice know Bob and Carol? In Bitcoin there needs to be\nout-of-band key exchange, but there is no ID attached to the keys. The\nconcept of a hub seems to imply either use of standard PKI or Web-of-trust.\nBoth have big problems when it comes to large, frequent financial\ntransactions.\n\n* why should Bob even participate in this transaction? Currently I don't\nsee that incentives are described. That is a fundamental part of Bitcoin\nand makes network based intermediation possible (Alice <> computer network\nwith N nodes <> Carol). From the point of view of a node, Bitcoin does not\nhave a scalability issue. The only concern of the node is to maximize\nknowable profit.\n\nOn Thu, Jul 30, 2015 at 4:41 AM, Rusty Russell <rusty at rustcorp.com.au>\nwrote:\n\n> Christopher Jamthagen <cjamthagen at gmx.com> writes:\n> > Still trying to get the details right of this protocol. Please correct\n> > me if I am wrong in any of my assumptions below.\n>\n> > Assume a payment route: Alice<>Bob<>Carol\n>\n> > Alice want to pay Carol some amount. Carol gives Alice H(R) and Alice\n> > updates her commitment tx with Bob including the HTLC output and Bob\n> > does the same with Carol.\n>\n> OK.\n>\n> > Carol witholds R, forcing Bob to broadcast the commitment tx between\n> > Bob and Carol.\n>\n> Yep, Carol goes non-responsive.  Got it.\n>\n> > Carol can now spend the HTLC output because she knows R and thus\n> > revealing it to the world. Alice now also refuses to update the\n> > commitment tx with Bob, forcing Bob to broadcast that commitment tx.\n>\n> Poor Bob.  Yep.\n>\n> > This commitment tx is putting a delay on\n> > Bobs ability to spend the HTLC output (as well as all other outputs to\n> > him), but Alice can spend the HTLC output if the CLTV has expired.\n>\n> Indeed, don't ever offer an HTLC less than your delay!\n>\n> > In most examples I have seen, the CLTV is 2 days between Alice and Bob\n> > and 1 day between Bob and Carol, and all CSV delays are 3 days.\n>\n> I haven't seen an example which included a CSV delay amount.\n>\n> As the discussion with Joseph is establishing, the minimum CSV you allow\n> controls the worst-case HTLC you can accept.  CSV of a few hours should\n> be OK if you're online all the time.  I think...\n>\n> Anyone want to do some stats on that?  CSV uses the median time of last\n> 11 blocks, so to some extent you can tell the worst case...\n>\n> Cheers,\n> Rusty.\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150730/4b836826/attachment.html>"
            },
            {
                "author": "Christopher Jamthagen",
                "date": "2015-07-30T10:01:17",
                "message_text_only": "Sent:\u00a0Thursday, July 30, 2015 at 4:41 AM\nFrom:\u00a0\"Rusty Russell\" <rusty at rustcorp.com.au>\nTo:\u00a0\"Christopher Jamthagen\" <cjamthagen at gmx.com>, \"lightning-dev at lists.linuxfoundation.org\" <lightning-dev at lists.linuxfoundation.org>\nSubject:\u00a0Re: [Lightning-dev] Stealing money from a hub?\nChristopher Jamthagen <cjamthagen at gmx.com> writes:\n>> Still trying to get the details right of this protocol. Please correct\n>> me if I am wrong in any of my assumptions below.\n\n>> Assume a payment route: Alice<>Bob<>Carol\n\n>> Alice want to pay Carol some amount. Carol gives Alice H(R) and Alice\n>> updates her commitment tx with Bob including the HTLC output and Bob\n>> does the same with Carol.\n\n> OK.\n\n>> Carol witholds R, forcing Bob to broadcast the commitment tx between\n>> Bob and Carol.\n\n> Yep, Carol goes non-responsive. Got it.\n\n>> Carol can now spend the HTLC output because she knows R and thus\n>> revealing it to the world. Alice now also refuses to update the\n>> commitment tx with Bob, forcing Bob to broadcast that commitment tx.\n\n> Poor Bob. Yep.\n\n>> This commitment tx is putting a delay on\n>> Bobs ability to spend the HTLC output (as well as all other outputs to\n>> him), but Alice can spend the HTLC output if the CLTV has expired.\n\n> Indeed, don't ever offer an HTLC less than your delay!\n\nYes, now that you mention it :)\n\nIf we assume that Gregory Maxwell's timestop feature is in use to further delay the expiration of a CSV in the case of full (or near-full) blocks. If this is used, the counterparty can just fill the blocks for a limited amount of time until his CLTV has expired and then take the HTLC output. I guess the time between CSV expiration and CLTV expiration can be adjusted depending on the value being transferred. \n\nWould it be desirable/possible to implement the timestop feature for CLTV as well? That would make the difference between the number of blocks until either expiration the same in case of a block-filling attack. If I'm not mistaken Peter Todds BIP is already merged, but this feature could be implemented with another soft fork.\n\n>> In most examples I have seen, the CLTV is 2 days between Alice and Bob\n>> and 1 day between Bob and Carol, and all CSV delays are 3 days.\n\n> I haven't seen an example which included a CSV delay amount.\n\u00a0\n\u00a0\n> As the discussion with Joseph is establishing, the minimum CSV you allow\n> controls the worst-case HTLC you can accept. CSV of a few hours should\n> be OK if you're online all the time. I think...\n\nSpeaking of being online all the time, checking the blockchain is outsourceable, right? So it seems that miners would be the perfect third party to check for cheaters in LN. By offering them a nice chunk of our counterparty's funds as fees, they should be incentiviced enough to keep an extra eye for us on the blockchain.\n\n> Anyone want to do some stats on that? CSV uses the median time of last\n> 11 blocks, so to some extent you can tell the worst case...\n\n> Cheers,\n> Rusty."
            },
            {
                "author": "Rusty Russell",
                "date": "2015-07-30T23:48:24",
                "message_text_only": "Christopher Jamthagen <cjamthagen at gmx.com> writes:\n> Would it be desirable/possible to implement the timestop feature for\n> CLTV as well? That would make the difference between the number of\n> blocks until either expiration the same in case of a block-filling\n> attack. If I'm not mistaken Peter Todds BIP is already merged, but\n> this feature could be implemented with another soft fork.\n\nYes, timestop would logically be a softfork add, and it should apply to\nboth (same logic applies).\n\n> Speaking of being online all the time, checking the blockchain is\n> outsourceable, right? So it seems that miners would be the perfect\n> third party to check for cheaters in LN. By offering them a nice chunk\n> of our counterparty's funds as fees, they should be incentiviced\n> enough to keep an extra eye for us on the blockchain.\n\nOutsourcability scales really well; once you're full-time monitoring the\nblockchain, might as well get as many clients as possible.  You can also\nautomate the outsourcee's fee, by including it in the \"steal\" tx.\n\nBut I realized yesterday, outsourcing needs a new sighash op mode (or\nnormalized txids), so it's not really something to design a deployable\nsystem around today.\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Stealing money from a hub?",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Christopher Jamthagen",
                "Benjamin"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 8769
        }
    },
    {
        "title": "[Lightning-dev]  OP_CHECKSPVPROOFVERIFY",
        "thread_messages": [
            {
                "author": "Eric Lombrozo",
                "date": "2015-07-29T22:28:53",
                "message_text_only": "I should have posted this to the whole group. Sorry, hit the wrong button.\n:p\n---------- Forwarded message ----------\nFrom: \"Eric Lombrozo\" <elombrozo at gmail.com>\nDate: Jul 29, 2015 3:27 PM\nSubject: Re: [Lightning-dev] OP_CHECKSPVPROOFVERIFY\nTo: \"Joseph Poon\" <joseph at lightning.network>\nCc:\n\nJoseph,\n\nThe point isn't better security than current SPV proofs. That would require\nimprovements to the commitment structures.\n\nThe point is to allow outsourceability of SPV proofs over LN. We would want\nto avoid actually using OP_CHECKSPVPROOFVERIFY in the blockchain...but it\nwould allow crafting a contract requesting payment from the SPV client\nalong with an enforcement mechanism in the event the client fails to pay.\n\n- Eric\nOn Jul 29, 2015 12:54 PM, \"Joseph Poon\" <joseph at lightning.network> wrote:\n\n> Hi Eric,\n>\n> On Wed, Jul 29, 2015 at 02:08:39AM -0700, Eric Lombrozo wrote:\n> > It occurs to me that with the LN, it might be practical to outsource\n> > SPV proofs from other nodes.\n>\n> I couldn't find anything on an SPV proof opcode, what kind of opcode are\n> you thinking of or do you have any links? I tried looking it up but\n> couldn't find anything about it. I'm curious on whether/how it could it\n> offer significantly better security than current SPV proofs.\n>\n> --\n> Joseph Poon\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20150729/4f04040a/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "OP_CHECKSPVPROOFVERIFY",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Eric Lombrozo"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1482
        }
    }
]