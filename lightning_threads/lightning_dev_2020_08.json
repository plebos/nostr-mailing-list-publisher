[
    {
        "title": "[Lightning-dev] Thoughts on Improving MPP",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2020-08-02T02:02:25",
                "message_text_only": "Good morning Lightning world,\n\nThis was originally written for C-Lightning, hence the C-Lightning-isms, but I realized the general principles were valid for all LN implementations.\n\n---\n\nFirst, let us consider some C-Lightning node who, for some reason, only has unpublished channels to the network (note: in my opinion, ***unpublished channels delenda est!***).  Let us suppose this node wishes to receive some amount of funds, from multiple different payers.\n\nNow, the payee node knows MPP exists, and thus, it is not very concerned that it has insufficient incoming capacity in a ***single*** channel to accept one of the payments.  Reasoning that MPP exists, it considers instead the *sum total* of all incoming capacities.  It sees that it has sufficient *sum total* incoming capacity that it can accept all payments from all payers, with some to spare.\n\nHowever, at the channel-level detail, *none* of the channels has sufficient capacity to accept a single one of the payments the C-Lightning node now expects to receive, in full.  So, what should the C-Lightning node put as routehints in a generated invoice?\n\nAnother, is that we should note that I described \"payers\" with an \"s\" at the end.  In the English language as commonly used by puny humans, adding an \"s\" at the end of a noun is a common (but not universal) convention implying that the subject under discussion is actually composed of more than one item.  So not only must the C-Lightning node (all of whose channels are unpublished, thus cannot be paid unless it reveals at least some of the channels as routehints in the invoice) make an invoice with sufficient routehints to get an MPP delivered, it must make *multiple* invoices, such that the invoices it issues have as little overlap in their routehints as possible\n\nOtherwise, if we provide the **same** set of routehints in invoices to two **different** payers, both of them will interfere with each other, possibly to the point that neither can pay to the payee (since e.g. some of the available capacity is taken up by parts of one payment while the rest is taken up by parts of the other payment, and neither payment can then complete in full due to this deadlock).\n\nThis is important in case the C-Lightning node receiver is completely unannounced (i.e. has only unpublished channels).  The payers cannot fall back to just trying directly routing on a different incoming channel of the receiver, as they may not have any knowledge of such channels.\n\nI suggest, then, that the C-Lightning node that wants to get paid, and uses only unpublished channels, should use a Round-Robin strategy for selecting routehints.\n\nTo implement this, the `invoice` command maintains a persistent list of all channels the node has.  When a newly funded channel is locked-in by both sides (transitions to `CHANNELD_NORMAL`) it is simply appended to this list.  When a channel leaves `CHANNELD_NORMAL`it is simply removed from this list.  Let us call this the round-robin list.\n\nThen, when the `invoice` command is invoked, it generates routehints by executing a loop:\n\n* Maintain variables: a removed list (initially empty), a running sum amount (initially `AMOUNT_MSAT(0)`), and a set of proposed routehints (initially empty)\n* Round-robin: Remove a channel from the front of the round-robin list and put it in the end of the removed list.\n* If the channel has no incoming capacity, skip to the top of the loop again (`continue;`).\n* If the channel is a dead end (i.e. connects to a node which has no published channels elsewhere), skip as well (`continue;`).\n* Copy the scid and any other details to the set of proposed routehints.\n* Add the incoming capacity of the taken channel to the running sum.  If the running sum now exceeds the amount to be paid, append the removed list to the current round-robin list and leave the loop.\n* If the round-robin list is now empty, exit the loop (append the removed list to the current empty round-robin list) and report a `warning_capacity` that it looks like there is insufficient incoming capacity for this invoice.\n\nOn exit of the above loop, we sort the set of proposed routehints, from highest incoming capacity to lowest, and use that set as the routehints for the invoice.\n\n(It would probably be a good idea as well to persist the round-robin list)\n\nThe above ensures that as much as possible, different invoices will have different sets of channels routehinted (due to the round-robin behavior), but gracefully degrades (some overlap in routehints) if the number of channels available is low.\n\nAn issue is privacy.  A probing fake payer could spam the receiver with multiple requests for invoices it never intends to pay.  This can let the fake payer discover, at minimum, the entry points used by the payee to connect to the public network (which cannot be removed, even if you somehow obscure the actual short-channel-IDs of the payee, since the payer has to know *what* node to reach to get to the payee), which the payer can then probe or otherwise hack or buy out in order to extract information about the economic activity of the payee (due to the Axiom of Terminus, any forward that goes *to* an unpublished channel, *is* the final hop to the actual final destination, so the entry points have accurate data on incoming payments of the unpublished payee via the channel with them).  If the payer simulates multiple payers (i.e. Sybils) the payee cannot attempt to reuse channels in routehints to the different simulated payers, as that would degrade the ability to pay since the capacity of the channels has to be shared by the different payers if those payers were not sockpuppets.  Thus the lie of improved privacy by unpublished channels is revealed, and therefore, in my opinion, unpublished channels delenda est.\n\n----\n\nNow, let us turn our attention to the payer of such an invoice.\n\nCurrently, our `paymod` system uses a single sequence of routehints for all sub-payments of an MPP.\n\nThus, if a payment is split in two, both sub-payments will start executing on the same routehint.\n\nYet as considered above, the point of multiple routehints is that not a single one has sufficient capacity to receive, and the multiple routehints are provided which in total are needed to receive all the incoming funds.\n\nThus, I suggest as well, that sub-payments should have different sequences of routehints to try.\n\nFor example, currently, for sub-payments 0 and 1, they will try routehints A, B, C, D in this order:\n\n    0  1\n    A  A\n    B  B\n    C  C\n    D  D\n\nInstead of using the same shared sequence of routehints, on splitting, the split payments should use:\n\n     0  1\n     A  B\n     C  D\n     B  A\n     D  C\n\nThat is, sub-payment 0 should try routehints in the order A, C, B, D, while the sub-payment 1 should try routehints in the order B, D, A, C.\n\nThe reasoning is the same as with the argument for round-robin routehint selection: by having different sub-payments initially try different routehints, we improve our success by reducing their overlap in the use of shared resources, and therefore reduce the risk of deadlock (especially if the sub-payments are adaptively split into even more sub-payments).\n\nWe can do this by a sort of round-robin, as well.  For each sub-payment we initially create an empty list of routehints.  Then we \"spread\" the routehints to each sub-payment.\n\n* If there are more sub-payments than routehints, then we repeat the routehints until we have given one routehint to each sub-payment.\n* If there are more routehints than sub-payments, then we repeat the sub-payments until we have completed the routehints.\n\nAfter the above initial distribution, we then go through all sub-payments, and for each sub-payment, append routehints in the original order, but skipping those that were already given to that sub-payment in the above initial distribution.\n\nFor example, suppose we are distributing 3 routehints A B C to two sub-payments 0 1.  We do the initial distribution:\n\n    0  1\n    A  B\n    C\n\nAnd then we give each sub-payment the rest of the routehints:\n\n    0  1\n    A  B\n    C  A\n    B  C\n\nAnother example, where we are distributing 2 routehints A B to four sub-payments 0 1 2 3.  Our initial distribution is:\n\n    0  1  2  3\n    A  B  A  B\n\nThen we give each sub-payment the rest of the routehints:\n\n    0  1  2  3\n    A  B  A  B\n    B  A  B  A\n\nThus, each sub-payment gets the entire list of routehints, but in a different order.\n\n----\n\nFinally: the same argument --- that sub-payments should avoid using the same set of resources as much as possible -- applies to the *first* hop just as much as the *last* hop.\n\nThus, one possibility is to also maintain a list of outgoing channels for each sub-payment, which sub-payments try in round-robin order.  And again, each sub-payment should get a different order from each other in a coordinated fashion which reduces their interference.\n\nWe do this by, at the *start* of the payment before we split it up, taking all local channels and shuffling them.  Then we distribute the outgoing channels with the same algorithm as the above.\n\nThen, when a sub-payment executes, we use a similar algorithm as the `invoice` case where it selects routehints.\n\n* Maintain a removed list (initially empty).\n* Round-robin: Remove the channel at the front of the round-robin list, append to removed list.\n  * If the round-robin list is empty, then we should append the removed list to the round-robin list and consider splitting the payment.\n* If it has insufficient outgoing capacity, skip.\n* If it is a dead end, skip.\n* Otherwise it has sufficient capacity, break out of the loop (append the removed list to the round-robin list) and try routing via that channel.\n\n--\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-08-12T18:20:13",
                "message_text_only": "Good morning Lightning world,\n\nA minor report from the MPP trenches.\n\nOne of the resources that the C-Lightning MPP implementation is hitting is the limit on the number of HTLCs a channel can have.\n\nFor the 0.9.0 release, the initial consideration was that we can count the number of channels with outgoing capacity, and from there derive a number of HTLCs that the payer can afford to put on the network.\nVery roughly speaking, for every channel with outgoing capacity, we allocate 10 HTLCs.\nThis is the \"limit\" on our connectivity to the network: adding more HTLCs beyond this risks overloading our local connectivity and we would be unable to get good capacity.\n\nHowever, we neglected to consider the *incoming number-of-HTLCs limit* of the the payee.\nI believe this is the cause of this reported issue: https://github.com/ElementsProject/lightning/issues/3926\nIn the report, the payer node has 16 channels, and thus it allows up to 160 HTLCs.\nInitial splitting of the payment led to 51 starting splits, and since we do not implement re-merging of sub-payments, that number of splits can only grow.\nYet it seems that the payee had far fewer channels than the payer, and the much higher number of splits then could not fit in the incoming channels of the payee.\n\nThis is exacerbated by the use of the same failure code `temporary_channel_failure` for hitting both *msat capacity* and *number of HTLCs* limits.\nOur assumption was that any such `temporary_channel_failure` was due only to *msat capacity* being hit.\nWe then annotated that channel with the smallest HTLC that failed to route through it, and do not route through that channel for sub-payments equal or larger than that size.\nThis lead our code into splitting the 51 payments even further into more smaller payments, when it would have been objectively better to instead *merge* those payments (or not split up into such tiny pieces in the first place!).\nUnfortunately, the local annotations would then be poisoned --- it would think that very small payments were failing because of the *msat capacity* of the channel being ridiculously low.\nThis ended up convincing the payment subsystem that it would be better to keep on splitting payments **even more**, leading to >100 payments outgoing, further preventing the receiver from being able to receive (because the problem was not *msat capacity* but rather *number of HTLCs*) and further crashing ourselves into the problem.\n\nSo, I think it would be reasonable:\n\n* To count the number of channels the payee has (if the receiver is not published, count the number of routehints in the invoice), and use it as well as the basis of the number of HTLCs the receiver can get, and to get the lower of this and the outgoing channels of the payer.\n\n\nOverall, the issue is probably fixable if we consider the number of channels of the payer (as C-Lightning 0.9.0 does) ***and*** also the number of channels of the payee.\nWe can consider that, if we assume the rest of the public LN is well-connected, the only bottlenecks are at the payer and at the payee, and that for intermediate nodes there are a large number of alternate routes available.\nSo it may be sufficient to just limit based on the smaller of the number of payer-side channels and the number of payee-side channels.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-08-14T02:59:30",
                "message_text_only": "Good morning Lightning world,\n\nA minor report from the MPP trenches.\n\nOne of the resources that the C-Lightning MPP implementation is hitting is the limit on the number of HTLCs a channel can have.\n\nFor the 0.9.0 release, the initial consideration was that we can count the number of channels with outgoing capacity, and from there derive a number of HTLCs that the payer can afford to put on the network.\nVery roughly speaking, for every channel with outgoing capacity, we allocate 10 HTLCs.\nThis is the \"limit\" on our connectivity to the network: adding more HTLCs beyond this risks overloading our local connectivity and we would be unable to get good capacity.\n\nHowever, we neglected to consider the *incoming number-of-HTLCs limit* of the the payee.\nI believe this is the cause of this reported issue: https://github.com/ElementsProject/lightning/issues/3926\nIn the report, the payer node has 16 channels, and thus it allows up to 160 HTLCs.\nInitial splitting of the payment led to 51 starting splits, and since we do not implement re-merging of sub-payments, that number of splits can only grow.\nYet it seems that the payee had far fewer channels than the payer, and the much higher number of splits then could not fit in the incoming channels of the payee.\n\nThis is exacerbated by the use of the same failure code `temporary_channel_failure` for hitting both *msat capacity* and *number of HTLCs* limits.\nOur assumption was that any such `temporary_channel_failure` was due only to *msat capacity* being hit.\nWe then annotated that channel with the smallest HTLC that failed to route through it, and do not route through that channel for sub-payments equal or larger than that size.\nThis lead our code into splitting the 51 payments even further into more smaller payments, when it would have been objectively better to instead *merge* those payments (or not split up into such tiny pieces in the first place!).\nUnfortunately, the local annotations would then be poisoned --- it would think that very small payments were failing because of the *msat capacity* of the channel being ridiculously low.\nThis ended up convincing the payment subsystem that it would be better to keep on splitting payments **even more**, leading to >100 payments outgoing, further preventing the receiver from being able to receive (because the problem was not *msat capacity* but rather *number of HTLCs*) and further crashing ourselves into the problem.\n\nSo, I think it would be reasonable:\n\n* To count the number of channels the payee has (if the receiver is not published, count the number of routehints in the invoice), and use it as well as the basis of the number of HTLCs the receiver can get, and to get the lower of this and the outgoing channels of the payer.\n\n\nOverall, the issue is probably fixable if we consider the number of channels of the payer (as C-Lightning 0.9.0 does) ***and*** also the number of channels of the payee.\nWe can consider that, if we assume the rest of the public LN is well-connected, the only bottlenecks are at the payer and at the payee, and that for intermediate nodes there are a large number of alternate routes available.\nSo it may be sufficient to just limit based on the smaller of the number of payer-side channels and the number of payee-side channels.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-08-16T19:10:13",
                "message_text_only": "Good morning once again Lightningfolk,\n\nAn idea I have been entertaining is that rather than splitting payments by half in case of an adaptive split, we should split in terms of a Fibonacci sequence.\n\nIntuitively, if we split payments in half all the time, then it implies that we have a set of \"standard\" bins that are some constant times the powers of two.\nFor example, if we start with 1,000,000 msat, splitting by half results in splits of 500,000; 250,000; 125,000; 62,500; 31,250; 15,625; and it is as if we are using bins of 15,625 times powers of two.\n\nNow, let us consider the *worst case* number of splits when we have some channel capacity.\n\nFor example, if we have a channel capacity of 4,294,967,295 msat.\nIn that case, we would require 32 splits, from values ranging from 2^0 to 2^31, if we were to use the \"split by half\" rule.\n\nHowever, what if we instead used amount bins that are derived from the Fibonacci sequence?\nFor the same 4,294,967,295 capacity, we would split up into bins of:\n\n29,712,150,73; 1,134,903,170; 165,580,141; 14,930,352; 5,702,887; 2,178,309; 317,811; 121,393; 17,711; 377; 55; 13; 3\n\nThat is 13 splits.\n\nBut that is unfair!\n4,294,967,295 is specifically chosen as a worst-case behavior of the power-of-two splitting.\nSo how do we choose a similar worst-case for the Fibonacci sequence?\n\nAn intuition we must have is that we derived the worst-case example for power-of-two splitting by adding the powers of two in sequence: 1 + 2 + 4 + 8 ... etc.\n\nNow, what about if we add the Fibonacci sequence in sequence?\nWill that similarly provide a worst-case example similar to the 4,294,967,295 example?\n1 + 1 + 2 + 3 + 5 ...\n\nA thing to note is that if we add two adjacent Fibonacci sequence items, such as 2 + 3, we get the *next* Fibonacci sequence item.\nThus, if our \"worst-case\" generation sums up two adjacent Fibonacci sequence items, that will actually cause the splits to move up, meaning fewer splits needed.\nThus, to generate the worst-case example for the Fibonacci sequence, we should actually *skip* an entry each time.\nThus for the Fibonacci sequence: 1; 1; 2; 3; 5; 8; 13; 21; 34; 55; .... we should sum up 1 + 2 + 5 + 13 + 34 + ....\n\nAnd a thing we should notice is to compare that to the worst-case generation for the power-of-two sequence: 1 + 2 + 4 + 8 + 16 + ....\n\n   1 + 2 + 5 + 13 + 34 + ...\n   1 + 2 + 4 + 8  + 16 + ...\n\nWhat you should notice is that the numbers being added to the worst-case Fibonacci case quickly becomes larger, faster, than the worst-case power-of-two.\n\nWhat this means is that, given an arbitrary random channel capacity, in order to fully utilize that capacity for transport, we expect that it would require fewer splits, on average, if we use Fibonacci sequence than power-of-two sequence.\n\nSo I think Fibonacci sequence for our payment splitting schedule is better than the power-of-two sequence we currently use (I believe `lnd` as well also started with such a simple \"split by half\" solution).\nWe expect this to lead to fewer splits in general (given that each HTLC is a risk of paying fees later, we want fewer splits) and better utilization of available channel capacity.\n\nNow, of course, we are doing payment *splitting*, i.e. if a big payment does not go through we try again with multiple smaller payments.\nGetting into a power-of-two schedule is easy: just divide by 2.\n\nIn order to get into an approximately Fibonacci sequence, we can divide by the Golden Ratio, i.e. `phi`, i.e. 1.6180339887... i.e. (1 + sqrt(5))/2\nThis is because two consecutive entries in the Fibonacci sequence have a ratio that approximately converges towards this number.\nSo for example, if we start with a 1,000,000 msat payment that fails, we should split it into 618,034 and 381,966 splits.\nAnd so on.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Thoughts on Improving MPP",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 20130
        }
    },
    {
        "title": "[Lightning-dev] Dynamic Commitments: Upgrading Channels Without On-Chain Transactions",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2020-08-23T04:26:16",
                "message_text_only": "Olaoluwa Osuntokun <laolu32 at gmail.com> writes:\n> After getting some feedback from the Lightning Labs squad, we're thinking\n> that it may be better to make the initial switch over double-opt-in, similar\n> to the current `shutdown` message flow. So with this variant, we'd add two\n> new messages: `commit_switch` and `commit_switch_reply` (placeholder\n> names). We may want to retain the \"initiator\" only etiquette for simplicity,\n> but if we want to allow both sides to initiate then we'll need to handle\n> collisions (with a randomized back off possibly).\n\n(Sorry for long delay catching up with backlog).\n\nYeah, modelling on the shutdown flow makes more sense to me, due to\nsimplicity.\n\nI think we will end up with a linear progression of channel types (type\nn+1 is always preferred over type n).  This has the benefit of\n*reducing* the test matrix at some point by dropping older formats.\n\n(You can't drop older format completely without an onchain event, of\ncourse, since you need to be able to penalize ancient commit txs.\nThough perhaps you just pregen penalty txs for those cases and behave like\na watchtower, maybe even not bothering about HTLCs?)\n\nI think inventing a new commitment type numbering scheme is unnecessary:\njust use existing feature bits and define what upgrades are permissable.\n\nI send `commit_switch` with features, you send `commit_switch` with\nfeatures, we do feature matching to determine new features for channel.\nYou can easily figure out the intersection: if one requires a feature\nthe other doesn't offer, it's a noop (upgrade failure).  Similarly, if\nthe combination offers no new features, it's a noop.\n\nYou can't add HTLCs after you've sent `commit_switch`.  You can add\nagain (under the new rules) once:\n1. You've both sent and received `commit_switch`.\n2. You have no outstanding HTLCs (in either direction).\n\nThis means we don't have to worry about the case where we both propose\nupgrades at once, it Just Works.  It's also Just Works to always send on\nreconnect, and simply echo your current features if you receive an\nunexpected `commit_switch`.\n\n---\nI'd like to Upgrade The World to anchor_outputs, so maybe cleanest would\nbe:\n\n1. Release supports anchor_outputs (odd).\n2. Release supports upgrading to anchor_outputs.\n3. Release requires anchor_outputs (even), unilaterally closes channels\n   w/o (ideally very few!).\n\nWe need a feature bit for upgrades, since we don't want to stop the flow\nif they don't respond to commit_switch (i.e. it should be even).\n\nAnyone working on this right now?\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Dynamic Commitments: Upgrading Channels Without On-Chain Transactions",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2552
        }
    },
    {
        "title": "[Lightning-dev] Proposal for skip channel confirmation.",
        "thread_messages": [
            {
                "author": "Roei Erez",
                "date": "2020-08-24T08:16:44",
                "message_text_only": "Hello everyone,\n\nI would like to discuss the ability to skip a channel funding\ntransaction confirmation, making the channel fully operational before\nits on-chain confirmation (aka a zero-conf channel).\nTill confirmation, this channel requires trust between its two parties\nand in the case of a remote initiator, it puts the received funds of\nthe local party at risk.\nNevertheless, there are cases where it makes sense to support this\nbehavior. For example, in cases both parties decide to trust each\nother. Or, in cases where trust between the parties already exists\n(buying a pre-loaded channel from a service like Bitrefill).\n\nThe motivation is gained from the \"Immediate on-boarding\" use case:\n* Bob is connected to a routing node and issues an invoice with a\n   routing hint that points to a fake channel between Bob and that node.\n* When Alice pays Bob's invoice, the routing node intercepts the HTLC\n   and holds it.\n* Then, the routing node does the following:\n  * Opens a channel to Bob where Bob has a choice of skipping funding\n     confirmation (channel is open and active).\n  * Pays Bob the original Alices' invoice (potentially, minus a service fee)\n\n>From Bob perspective it is his choice on whether to agree for the\npayment via this channel (and by that increase the trust) or disagree\nand wait for confirmation.\nAnother practical way for Bob is to skip confirmation and \"hold\" the\npayment by not providing the pre-image.\n\nRight now different implementations support zero-conf channels in\ndifferent ways. These implementations have defined their own way on\nhow to agree on a short_channel_id (fake one) before the transaction\nis confirmed.\n\nThe following suggests some changes to the funding flow to support that:\n  1. accept_channel message - in case the fundee wants to skip\n      confirmation he sends minimum_depth=0\n  2. funding_signed message - no change.\n  3. funding_locked message - if fundee has sent minimum_depth=0, then\n      both parties send funding_locked while the channel_id is derived using a\n      convention agreed on both. One proposal for such convention is to take it\n      from the temporary_channel_id provided in previous open_channel\n      message as follows:\n        * Use the first 8 bytes to initialize an unsigned integer,\n           call it shortID\n        * Apply this transformation:  shortID / 2^6 + 100,000\n        * The above transformation ensures the block height falls in the\n           range of 100,000 - 2^18+100,000. The rationale is that the id will\n           never point to a valid mined transaction and the first 100,000 blocks\n           are left for testing in other chains.\n        * Assuming the temporary_channel_id is some random number, it is\n          not likely that the derived short_channel_id will conflict with other\n          channels in both peers but both peers should validate that before\n          sending funding_locked.\n  4. When the channel is confirmed gossip messages such as\n      channel_update are re-broadcasted and refers to the confirmed\n      channel_id (such as the case with re-org).\n\nI created a PR in LND that implements these changes\nhttps://github.com/lightningnetwork/lnd/pull/4424\n\nCheers,\nRoei"
            },
            {
                "author": "Matt Corallo",
                "date": "2020-08-24T19:22:33",
                "message_text_only": "A few notes.\n\nGiven gossip messages will be rejected by many nodes if no such on-chain transaction exists, I don't think you can \n\"re-broadcast\" gossip messages at that time, instead I believe you simply need to not gossip until the funding \ntransaction has some confirmations. Still, this shouldn't prevent receiving payments, as invoices carrying a last-hop \nhint should be able to indicate any short_channel_id value and have it be accepted.\n\nIt may make sense to reuse some \"private short channel ID negotiation\" feature for the temporary 0-conf short channel id \nvalue.\n\nOne thing this protocol doesn't capture is unidirectional 0-conf - maybe the channel initiator is happy to receive \npayments (since its their funds which opened the channel, this is reasonable), but the channel initie-ee (?) isn't \n(which, again, is reasonable). This leaves only the push_msat value pay-able, and only once, but is a perfectly \nreasonable trust model and I believe some wallets use this today.\n\nMatt\n\nOn 8/24/20 4:16 AM, Roei Erez wrote:\n> Hello everyone,\n> \n> I would like to discuss the ability to skip a channel funding\n> transaction confirmation, making the channel fully operational before\n> its on-chain confirmation (aka a zero-conf channel).\n> Till confirmation, this channel requires trust between its two parties\n> and in the case of a remote initiator, it puts the received funds of\n> the local party at risk.\n> Nevertheless, there are cases where it makes sense to support this\n> behavior. For example, in cases both parties decide to trust each\n> other. Or, in cases where trust between the parties already exists\n> (buying a pre-loaded channel from a service like Bitrefill).\n> \n> The motivation is gained from the \"Immediate on-boarding\" use case:\n> * Bob is connected to a routing node and issues an invoice with a\n>     routing hint that points to a fake channel between Bob and that node.\n> * When Alice pays Bob's invoice, the routing node intercepts the HTLC\n>     and holds it.\n> * Then, the routing node does the following:\n>    * Opens a channel to Bob where Bob has a choice of skipping funding\n>       confirmation (channel is open and active).\n>    * Pays Bob the original Alices' invoice (potentially, minus a service fee)\n> \n>  From Bob perspective it is his choice on whether to agree for the\n> payment via this channel (and by that increase the trust) or disagree\n> and wait for confirmation.\n> Another practical way for Bob is to skip confirmation and \"hold\" the\n> payment by not providing the pre-image.\n> \n> Right now different implementations support zero-conf channels in\n> different ways. These implementations have defined their own way on\n> how to agree on a short_channel_id (fake one) before the transaction\n> is confirmed.\n> \n> The following suggests some changes to the funding flow to support that:\n>    1. accept_channel message - in case the fundee wants to skip\n>        confirmation he sends minimum_depth=0\n>    2. funding_signed message - no change.\n>    3. funding_locked message - if fundee has sent minimum_depth=0, then\n>        both parties send funding_locked while the channel_id is derived using a\n>        convention agreed on both. One proposal for such convention is to take it\n>        from the temporary_channel_id provided in previous open_channel\n>        message as follows:\n>          * Use the first 8 bytes to initialize an unsigned integer,\n>             call it shortID\n>          * Apply this transformation:  shortID / 2^6 + 100,000\n>          * The above transformation ensures the block height falls in the\n>             range of 100,000 - 2^18+100,000. The rationale is that the id will\n>             never point to a valid mined transaction and the first 100,000 blocks\n>             are left for testing in other chains.\n>          * Assuming the temporary_channel_id is some random number, it is\n>            not likely that the derived short_channel_id will conflict with other\n>            channels in both peers but both peers should validate that before\n>            sending funding_locked.\n>    4. When the channel is confirmed gossip messages such as\n>        channel_update are re-broadcasted and refers to the confirmed\n>        channel_id (such as the case with re-org).\n> \n> I created a PR in LND that implements these changes\n> https://github.com/lightningnetwork/lnd/pull/4424\n> \n> Cheers,\n> Roei\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-08-24T19:56:50",
                "message_text_only": "Hi Roei,\n\nYou might have a mechanism to lower trust in zero-conf channel opener.\nActually the local party can be in charge of broadcasting the funding\ntransaction, thus ensuring it's well-propagated across network mempools and\nthen start to accept incoming payment on the zero-conf channel. Per BIP 125\nrules, a malicious funder/opener would have to pay a higher fee to replace\nthe channel funding tx and thus double-spend the HTLC. A local party may\nrequire a higher fee funding transaction than it is necessary wrt ongoing\ncongestion to increase level of protection. And I think it's okay on the\neconomic-side, you will amortize this fee premium on the channel lifecycle.\nUntil the transaction gets confirmed you might only accept HTLC under this\nfee. So you have game-theory security for your zero-conf channels as it\nwould cost more in fees than a HTLC double-spend win for the malicious\nopener, under the assumption of non-miner-collusion with the attacker.\n\nActually this higher fee could be attached by a zero-conf channel insurance\nservice through a CPFP on a special output, and spread across a batch of\nfunding transaction, thus replacement cost would be far higher for attacker\nbut give the same value protection to any user involved in the batch. That\nsaid, it might be a bit slower and more expensive than a UX-fast zero-conf\nchannel, as it's likely offered by wallet today, so maybe not a user demand\nfor zero-conf channel improved safety.\n\nWith regards to the current proposal in itself, skimming quickly on BOLT 2\nwe don't explicitly require minimum_depth > 0 ? So only the new requirement\nzero-conf chan is about the channel identifier in the lack of an anchoring\nblock ? If the channel is private, it doesn't matter id to be random,\nthat's just a convention between channel peers. A local alias\nshort_channel_id can be sent to any potential payer.\n\nOverall, I lean to think this kind of proposal might belong to a higher\nlayer spec, as it's more a matter of policy between nodes than a global\nnetwork mechanism. Such higher spec could gather specifications on other\npoint-to-point Lightning programmable interfaces, like onion content,\nassuming we keep track of collision types. It would fasten ecosystem\nfeatures while letting BOLT specifications focus on the core layer\nrequirements. Though it might be too early for such a thing.\n\nCheers,\nAntoine\n\nLe lun. 24 ao\u00fbt 2020 \u00e0 20:22, Matt Corallo <lf-lists at mattcorallo.com> a\n\u00e9crit :\n\n> A few notes.\n>\n> Given gossip messages will be rejected by many nodes if no such on-chain\n> transaction exists, I don't think you can\n> \"re-broadcast\" gossip messages at that time, instead I believe you simply\n> need to not gossip until the funding\n> transaction has some confirmations. Still, this shouldn't prevent\n> receiving payments, as invoices carrying a last-hop\n> hint should be able to indicate any short_channel_id value and have it be\n> accepted.\n>\n> It may make sense to reuse some \"private short channel ID negotiation\"\n> feature for the temporary 0-conf short channel id\n> value.\n>\n> One thing this protocol doesn't capture is unidirectional 0-conf - maybe\n> the channel initiator is happy to receive\n> payments (since its their funds which opened the channel, this is\n> reasonable), but the channel initie-ee (?) isn't\n> (which, again, is reasonable). This leaves only the push_msat value\n> pay-able, and only once, but is a perfectly\n> reasonable trust model and I believe some wallets use this today.\n>\n> Matt\n>\n> On 8/24/20 4:16 AM, Roei Erez wrote:\n> > Hello everyone,\n> >\n> > I would like to discuss the ability to skip a channel funding\n> > transaction confirmation, making the channel fully operational before\n> > its on-chain confirmation (aka a zero-conf channel).\n> > Till confirmation, this channel requires trust between its two parties\n> > and in the case of a remote initiator, it puts the received funds of\n> > the local party at risk.\n> > Nevertheless, there are cases where it makes sense to support this\n> > behavior. For example, in cases both parties decide to trust each\n> > other. Or, in cases where trust between the parties already exists\n> > (buying a pre-loaded channel from a service like Bitrefill).\n> >\n> > The motivation is gained from the \"Immediate on-boarding\" use case:\n> > * Bob is connected to a routing node and issues an invoice with a\n> >     routing hint that points to a fake channel between Bob and that node.\n> > * When Alice pays Bob's invoice, the routing node intercepts the HTLC\n> >     and holds it.\n> > * Then, the routing node does the following:\n> >    * Opens a channel to Bob where Bob has a choice of skipping funding\n> >       confirmation (channel is open and active).\n> >    * Pays Bob the original Alices' invoice (potentially, minus a service\n> fee)\n> >\n> >  From Bob perspective it is his choice on whether to agree for the\n> > payment via this channel (and by that increase the trust) or disagree\n> > and wait for confirmation.\n> > Another practical way for Bob is to skip confirmation and \"hold\" the\n> > payment by not providing the pre-image.\n> >\n> > Right now different implementations support zero-conf channels in\n> > different ways. These implementations have defined their own way on\n> > how to agree on a short_channel_id (fake one) before the transaction\n> > is confirmed.\n> >\n> > The following suggests some changes to the funding flow to support that:\n> >    1. accept_channel message - in case the fundee wants to skip\n> >        confirmation he sends minimum_depth=0\n> >    2. funding_signed message - no change.\n> >    3. funding_locked message - if fundee has sent minimum_depth=0, then\n> >        both parties send funding_locked while the channel_id is derived\n> using a\n> >        convention agreed on both. One proposal for such convention is to\n> take it\n> >        from the temporary_channel_id provided in previous open_channel\n> >        message as follows:\n> >          * Use the first 8 bytes to initialize an unsigned integer,\n> >             call it shortID\n> >          * Apply this transformation:  shortID / 2^6 + 100,000\n> >          * The above transformation ensures the block height falls in the\n> >             range of 100,000 - 2^18+100,000. The rationale is that the\n> id will\n> >             never point to a valid mined transaction and the first\n> 100,000 blocks\n> >             are left for testing in other chains.\n> >          * Assuming the temporary_channel_id is some random number, it is\n> >            not likely that the derived short_channel_id will conflict\n> with other\n> >            channels in both peers but both peers should validate that\n> before\n> >            sending funding_locked.\n> >    4. When the channel is confirmed gossip messages such as\n> >        channel_update are re-broadcasted and refers to the confirmed\n> >        channel_id (such as the case with re-org).\n> >\n> > I created a PR in LND that implements these changes\n> > https://github.com/lightningnetwork/lnd/pull/4424\n> >\n> > Cheers,\n> > Roei\n> > _______________________________________________\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> >\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200824/250f03bf/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-08-25T02:38:15",
                "message_text_only": "Good morning Antoine,\n\n> Hi Roei,\n> You might have a mechanism to lower trust in zero-conf channel opener. Actually the local party can be in charge of broadcasting the funding transaction, thus ensuring it's well-propagated across network mempools and then start to accept incoming payment on the zero-conf channel. Per BIP 125 rules, a malicious funder/opener would have to pay a higher fee to replace the channel funding tx and thus double-spend the HTLC. A local party may require a higher fee funding transaction than it is necessary wrt ongoing congestion to increase level of protection. And I think it's okay on the economic-side, you will amortize this fee premium on the channel lifecycle. Until the transaction gets confirmed you might only accept HTLC under this fee. So you have game-theory security for your zero-conf channels as it would cost more in fees than a HTLC double-spend win for the malicious opener, under the assumption of non-miner-collusion with the attacker.\n\nSince RBF is opt-in for Bitcoin Core nodes, and I believe most miners are running Bitcoin Core, it is trivial to double-broadcast.\ni.e. I send my high-fee RBF-enabled channel funding to you, at the same time I send a conflicting low-fee RBF-disabled transaction (that pays the entire channel amount to myself) to all the miners I can find.\n\nSince the miners received an RBF-disabled tx, they will not evict it even if they see a higher-fee RBF-enabled tx.\nAnd your fullnode will not see the conflicting low-fee RBF-disabled tx either because it is lower fee than what you have in your mempool and you will reject it.\n\nYou really have to trust that I do not do this when I offer a channel to you.\n\nThere Ain't No Such Thing As A Global Mempool!\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Antoine Riard",
                "date": "2020-08-25T18:16:56",
                "message_text_only": "Hi Zeeman,\n\n> i.e. I send my high-fee RBF-enabled channel funding to you, at the same\ntime I send a conflicting low-fee RBF-disabled transaction (that pays the\nentire channel amount to myself) to all the miners I can find.\n\nMapping miners mempools will be a cost in spying infrastructure and thus\nmake the malicious routing node job harder, providing a security\nimprovement for zero-conf channels. I used \"lower trust\" intentionally,\nit's not binary (what about opening a channel with a reorg-powerful\ncounterparty ?).\n\n> And your fullnode will not see the conflicting low-fee RBF-disabled tx\neither because it is lower fee than what you have in your mempool and you\nwill reject it.\n\nI was assuming a no-mempool mobile LN client, thus not going to be blind by\nyour high-fee RBF. But still able to speak with the p2p network thus you\ncan actively seek that your transaction has been accepted by ~100 peers.\n\nOverall, I don't think this scheme is worthy to work on unless double-spend\nof zero-conf chans become a real issue, just to mention we have potential\nsolutions in this case.\n\n> There Ain't No Such Thing As A Global Mempool!\n\nI know :)\n\nLe mar. 25 ao\u00fbt 2020 \u00e0 03:38, ZmnSCPxj <ZmnSCPxj at protonmail.com> a \u00e9crit :\n\n> Good morning Antoine,\n>\n> > Hi Roei,\n> > You might have a mechanism to lower trust in zero-conf channel opener.\n> Actually the local party can be in charge of broadcasting the funding\n> transaction, thus ensuring it's well-propagated across network mempools and\n> then start to accept incoming payment on the zero-conf channel. Per BIP 125\n> rules, a malicious funder/opener would have to pay a higher fee to replace\n> the channel funding tx and thus double-spend the HTLC. A local party may\n> require a higher fee funding transaction than it is necessary wrt ongoing\n> congestion to increase level of protection. And I think it's okay on the\n> economic-side, you will amortize this fee premium on the channel lifecycle.\n> Until the transaction gets confirmed you might only accept HTLC under this\n> fee. So you have game-theory security for your zero-conf channels as it\n> would cost more in fees than a HTLC double-spend win for the malicious\n> opener, under the assumption of non-miner-collusion with the attacker.\n>\n> Since RBF is opt-in for Bitcoin Core nodes, and I believe most miners are\n> running Bitcoin Core, it is trivial to double-broadcast.\n> i.e. I send my high-fee RBF-enabled channel funding to you, at the same\n> time I send a conflicting low-fee RBF-disabled transaction (that pays the\n> entire channel amount to myself) to all the miners I can find.\n>\n> Since the miners received an RBF-disabled tx, they will not evict it even\n> if they see a higher-fee RBF-enabled tx.\n> And your fullnode will not see the conflicting low-fee RBF-disabled tx\n> either because it is lower fee than what you have in your mempool and you\n> will reject it.\n>\n> You really have to trust that I do not do this when I offer a channel to\n> you.\n>\n> There Ain't No Such Thing As A Global Mempool!\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200825/b8b3c7ea/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-08-27T01:29:55",
                "message_text_only": "Good morning Antoine,\n\n> Hi Zeeman,\n>\n> > i.e. I send my high-fee RBF-enabled channel funding to you, at the same time I send a conflicting low-fee RBF-disabled transaction (that pays the entire channel amount to myself) to all the miners I can find.\n> Mapping miners mempools will be a cost in spying infrastructure and thus make the malicious routing node job harder, providing a security improvement for zero-conf channels. I used \"lower trust\" intentionally, it's not binary (what about opening a channel with a reorg-powerful counterparty ?).\n\nA reorg-powerful entity would destroy all assumptions depended upon by higher layers, I think, and would be an extinction event on all higher layers.\nIn particular, any timelock-based higher layer is at risk for anyone powerful enough to reorg, as they could potentially delay non-timelocked transactions to after the timelock expires.\n\nMapping miner nodes is indeed a cost, but not a high one IMO --- presumably miners are the ones who get blocks earlier than everyone else, and would be incentivized to e.g. unsolicited `block` push, though I am uncertain if that has ever been implemented.\n\n> > And your fullnode will not see the conflicting low-fee RBF-disabled tx either because it is lower fee than what you have in your mempool and you will reject it.\n>\n> I was assuming a no-mempool mobile LN client, thus not going to be blind by your high-fee RBF. But still able to speak with the p2p network thus you can actively seek that your transaction has been accepted by ~100 peers.\n\nThat seems to be a fairly high amount of bandwidth in `inv` messages?\nYou also need to select the peers in a way that attackers find hard to predict, else sybil is possible.\nHmmm.\n\n> Overall, I don't think this scheme is worthy to work on unless double-spend of zero-conf chans become a real issue, just to mention we have potential solutions in this case.\n\n0-conf is simply not safe, and I do not think this increases the costs on breaking the mechanism enough.\n\n\nWith all that said, once deeply confirmed, the channel becomes perfectly safe.\nAnd in general, most 0-conf channel mechanisms are usually set up such that the one offering the 0-conf channel is a fiat-to-Bitcoin exchange, with a `push_msat` non-gift that is actually the equivalent amount of a number of fiat units.\nAs it involves fiat, tr\\*st is necessary anyway, so it is a negligible degradation of security in practice.\nAnd once the channel *does* get confirmed deeply, it is upgraded automatically to trust-reduced.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Roei Erez",
                "date": "2020-08-25T10:01:53",
                "message_text_only": "Hi Matt and thanks for your notes.\n\nOn Mon, 24 Aug 2020 at 22:22, Matt Corallo <lf-lists at mattcorallo.com> wrote:\n>\n> A few notes.\n>\n> Given gossip messages will be rejected by many nodes if no such on-chain transaction exists, I don't think you can\n> \"re-broadcast\" gossip messages at that time, instead I believe you simply need to not gossip until the funding\n> transaction has some confirmations. Still, this shouldn't prevent receiving payments, as invoices carrying a last-hop\n> hint should be able to indicate any short_channel_id value and have it be accepted.\n\nYou are right.  They really should be broadcasted once after the\nfunding transaction is sufficiently deep. I confused\nthat with the exchange of channel_update privately between them before\nthe channel is confirmed so they both\nwill be able to relay payments using this channel.\n\n>\n> It may make sense to reuse some \"private short channel ID negotiation\" feature for the temporary 0-conf short channel id\n> value.\n>\n> One thing this protocol doesn't capture is unidirectional 0-conf - maybe the channel initiator is happy to receive\n> payments (since its their funds which opened the channel, this is reasonable), but the channel initie-ee (?) isn't\n> (which, again, is reasonable). This leaves only the push_msat value pay-able, and only once, but is a perfectly\n> reasonable trust model and I believe some wallets use this today.\n\nAlthough this proposal addresses the bi-directional zero-conf channel\nboth parties are able to \"hold\" any payment.\nWhen the payee decides not to release the preimage based on  some\npolicy (total funds at risk, wait for confirmation)\nthe channel becomes unidirectional.\nImplementing a unidirectional channel this way also has some advantages such as:\n1. It gives you the ability to increase trust on an existing zero-conf\nchannel. Sometimes this is preferable because\n    it saves the need to open additional channels and it shortens the\ntrust period (waiting for confirmation for a\n    previously opened channel).\n2. The funds sent to the channel acceptor can be a result of a\nlightning payment, including proof of payment for the\n    payer.\n\nRoei\n\n>\n> Matt\n>\n> On 8/24/20 4:16 AM, Roei Erez wrote:\n> > Hello everyone,\n> >\n> > I would like to discuss the ability to skip a channel funding\n> > transaction confirmation, making the channel fully operational before\n> > its on-chain confirmation (aka a zero-conf channel).\n> > Till confirmation, this channel requires trust between its two parties\n> > and in the case of a remote initiator, it puts the received funds of\n> > the local party at risk.\n> > Nevertheless, there are cases where it makes sense to support this\n> > behavior. For example, in cases both parties decide to trust each\n> > other. Or, in cases where trust between the parties already exists\n> > (buying a pre-loaded channel from a service like Bitrefill).\n> >\n> > The motivation is gained from the \"Immediate on-boarding\" use case:\n> > * Bob is connected to a routing node and issues an invoice with a\n> >     routing hint that points to a fake channel between Bob and that node.\n> > * When Alice pays Bob's invoice, the routing node intercepts the HTLC\n> >     and holds it.\n> > * Then, the routing node does the following:\n> >    * Opens a channel to Bob where Bob has a choice of skipping funding\n> >       confirmation (channel is open and active).\n> >    * Pays Bob the original Alices' invoice (potentially, minus a service fee)\n> >\n> >  From Bob perspective it is his choice on whether to agree for the\n> > payment via this channel (and by that increase the trust) or disagree\n> > and wait for confirmation.\n> > Another practical way for Bob is to skip confirmation and \"hold\" the\n> > payment by not providing the pre-image.\n> >\n> > Right now different implementations support zero-conf channels in\n> > different ways. These implementations have defined their own way on\n> > how to agree on a short_channel_id (fake one) before the transaction\n> > is confirmed.\n> >\n> > The following suggests some changes to the funding flow to support that:\n> >    1. accept_channel message - in case the fundee wants to skip\n> >        confirmation he sends minimum_depth=0\n> >    2. funding_signed message - no change.\n> >    3. funding_locked message - if fundee has sent minimum_depth=0, then\n> >        both parties send funding_locked while the channel_id is derived using a\n> >        convention agreed on both. One proposal for such convention is to take it\n> >        from the temporary_channel_id provided in previous open_channel\n> >        message as follows:\n> >          * Use the first 8 bytes to initialize an unsigned integer,\n> >             call it shortID\n> >          * Apply this transformation:  shortID / 2^6 + 100,000\n> >          * The above transformation ensures the block height falls in the\n> >             range of 100,000 - 2^18+100,000. The rationale is that the id will\n> >             never point to a valid mined transaction and the first 100,000 blocks\n> >             are left for testing in other chains.\n> >          * Assuming the temporary_channel_id is some random number, it is\n> >            not likely that the derived short_channel_id will conflict with other\n> >            channels in both peers but both peers should validate that before\n> >            sending funding_locked.\n> >    4. When the channel is confirmed gossip messages such as\n> >        channel_update are re-broadcasted and refers to the confirmed\n> >        channel_id (such as the case with re-org).\n> >\n> > I created a PR in LND that implements these changes\n> > https://github.com/lightningnetwork/lnd/pull/4424\n> >\n> > Cheers,\n> > Roei\n> > _______________________________________________\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n> >"
            }
        ],
        "thread_summary": {
            "title": "Proposal for skip channel confirmation.",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Matt Corallo",
                "Antoine Riard",
                "Roei Erez"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 28744
        }
    },
    {
        "title": "[Lightning-dev] Witness asymmetric payment channels",
        "thread_messages": [
            {
                "author": "Lloyd Fournier",
                "date": "2020-08-25T11:39:11",
                "message_text_only": "# Abstract\n\nThis is a proposal for a new channel symmetric channel construction\nthat uses the\nkey idea from a recent paper called \"Generalized Bitcoin-Compatible Channels\"[1]\nand tries to practically apply it to lightning. If you prefer, you can\nread the rendered\nmarkdown version here: https://github.com/LLFourn/witness-asymmetric-channel\n\nThe purpose of this post is to get feedback to see if it's worth doing\na PoC implementation.\n\n# Background\n\nAs presently specified the two parties in a lightning channel are assigned\ndifferent commitment transactions. This _transaction asymmetry_ is logically\nnecessary for the protocol to identify which party broadcasted a commitment\ntransaction and potentially punish them if the other party provides\nproof it has been revoked (i.e. knows the revocation key).\n\nWouldn't it be nice if we could identify the broadcasting party without\nassigning them different transactions? Riard first considered this problem in\n[8] while trying to add a punishment mechanism to eltoo[9] style channel\nupdates. They proposed that you could identify the broadcasting party using\n_witness asymmetry_ i.e. both parties broadcast the same transaction but have\ndifferent witnesses. Unfortunately, the solution proposed is rather convoluted.\n\nMore recently in [1], Aumayr et al. introduced a much more elegant witness\nasymmetric solution using adaptor signatures. Instead of being assigned\ndifferent transactions, the parties are assigned different adaptor signatures as\nwitnesses for the _same_ transaction. The adaptor signatures force the party\nbroadcasting a commitment transaction to reveal a \"publishing secret\" to the\nother party. The honest party can then use this publishing secret along with\nknowledge of the usual revocation secret to punish the malicious party for\nbroadcasting an old commitment transaction.\n\nAumayr et al. combine this idea with a \"punish-then-split\" mechanism similar to\nthe original eltoo proposal. Unfortunately, it therefore inherits the same issue\nwith staggering time-locks. BOLT 3 [4] describes why it avoids this problem as a\ndesign choice:\n\n> The reason for the separate transaction stage for HTLC outputs is so that\n> HTLCs can timeout or be fulfilled even though they are within the\n> to_self_delay delay. Otherwise, the required minimum timeout on HTLCs is\n> lengthened by this delay, causing longer timeouts for HTLCs traversing the\n> network.\n\nThere is further background discussion to this choice in [2] and Towns proposes\na solution for eltoo in [3].\n\nIn short, the problem is that it creates a risk for the party that needs to\nfulfill an HTLC with the secret in time. The only known way of accounting for\nthis risk is to increase the difference between the time-locks on each hop.\nThere could be situations where this trade off makes sense but it seems\nundesirable for a general purpose payment channel network.\n\n# Proposal\n\nI propose a channel protocol which steals the main idea from Aumayr et al. while\nretaining the time-lock precedence of BOLT 3 transactions. That is, absolute\ntime-locks are settled before relative time-locks to avoid having to account for\nrelative time-locks when calculating absolute time-locks.\n\nThe guiding principle is to keep commitment transactions symmetric but to use\nthe asymmetric knowledge of the parties to simulate the way lightning works\nright now. The main benefits of this seem to be:\n\n- It is more elegant as there are half the number of possible transactions. I\n  expect this will follow through to reduced implementation complexity and maybe\n  make it easier to explain as well.\n- Every output can just be a 2-of-2 multi-sig (which could be a single key with\n  MuSig or OP_CHECKMULTISIG with ECDSA etc). This makes the transactions a\n  little smaller even when using 2-of-2 with ECDSA on balance, The space saving\n  comes from avoiding explicit revocation keys in the commitment transaction\n  outputs and using PTLCs rather than HTLCs.\n- The design works today and easily transitions into a post-taproot world\n  although there is still a bit to explore there [5].\n\n## Notation\n\nI describe the protocol with respect to two parties Alice and Bob. 2-of-2(Xa,Xb)\nrefers to a multi-signature output that supports adaptor signatures and requires\nthe owners of Xa (Alice) and Xb (Bob) to authorize it (e.g. `OP_CHECKMULTISIG`\nwith ECDSA [6], or MuSig with Schnorr etc [7]).\n\n## The Fund transaction\n\nThe structure of channel funding does not change from the current BOLT spec. The\nFund transaction spends from the funding party's (or funding _parties_) outputs\nto an output of 2-of-2(Fa,Fb) where Fa and Fb are public keys owned by Alice and\nBob respectively. These keys are generated and exchanged once per channel.\n\n## Commitment transactions\n\nAll commitment transactions spend from the 2-of-2 on the Fund transaction and\neach represents a \"state\" of the channel. A commitment transaction has two\nbalance outputs and zero or more PTLC outputs.\n\nBefore creating a commitment transaction the parties must exchange two curve\npoints each:\n\n- A _publication_ point (denoted P) whose secret is revealed if that party\n  broadcasts the commitment transaction.\n- A _revocation_ point (denoted R) whose secret is explicitly revealed to the\n  other party when revoking this commitment transaction.\n\nLet (Pa, Ra) and (Pb, Rb) be the publication and revocation points of Alice and\nBob respectively. The scriptPubkey of all outputs on a commitment transaction is\n2-of-2(Pa + Ra, Pb + Rb). To make it slightly harder to distinguish these\noutputs from other uses of 2-of-2 you can imagine that we pseudorandomly\nrandomize each output so that they are not identical.\n\nWhen signing a commitment transaction, the parties instead exchange adaptor\nsignatures such that the party who publishes the commitment transaction must\nreveal their publication secret. This means that if a malicious party broadcasts\na commitment transaction for which they have already revealed their revocation\nsecret the other party will know both secrets and therefore both secret keys in\n2-of-2(Pa + Ra, Pb + Rb). They can use this to unilaterally spend from all the\noutputs on the commitment transaction to punish the malicious party.\n\nAs a point of interest there is no problem with both parties broadcasting the\nsame commitment transaction at the same time with their different signatures. In\ntheory, both parties seeing the other's commitment transaction over the Bitcoin\nnetwork could act as a kind of out of band optimization because it means they\nboth learn each other's publication secrets and can therefore settle all the\noutputs without having to wait for relative time-locks (regardless of which\nsignature makes it into the blockchain).\n\n## Balance outputs\n\nA balance output going to Alice has a scriptPubkey of 2-of-2(Pb, Ra) and the\nconverse for Bob's balance output i.e. 2-of-2(Pa,Rb). Each balance output has a\npre-signed relative time-locked claim transaction spending it to an address\nowned by the deserving party.\n\n## PTLCs\n\nPTLC outputs are added directly to commitment transactions in the form described\nabove. Each PTLC has two pre-signed transactions spending from it: PTLC-success\nand PTLC-timeout. Broadcasting the PTLC-success transaction reveals the PTLC\nsecret in the usual way using an adaptor signatures. The PTLC-timeout\ntransaction has an absolute time-lock on it through the nlocktime transaction\nvalue.\n\nFor a PTLC output being offered by Alice to Bob both transactions have a single\noutput with the following scriptPubkeys:\n\n- PTLC-success: 2-of-2(Pa, Rb)\n- PTLC-timeout: 2-of-2(Pb, Ra)\n\nBoth transactions have a pre-signed \"claim\" transaction that spends the funds to\nan address owned by the desired party after a relative time-lock (i.e. it has a\nsequence number set). Alternatively, the PTLC-success/timeout can be constructed\nlike HTLC-success/timeout transactions in lightning today where the destination\nparty can spend unilaterally after the relative time-lock enforced with OP_CSV.\nI find this slightly unappealing because it means using an output that is not\njust a 2-of-2.\n\nOnly the destination party needs to have the signature (or adaptor signature) on\nthe PTLC-success or PTLC-timeout transactions. So if it's a PTLC offered by\nAlice to Bob then Bob will have an adaptor signature on PTLC-success and Alice\nwill have an ordinary signature on the PTLC-timeout transaction. There is no\ntheoretical security issue with both parties having the signatures it just makes\nwriting state machines easier if Alice can rule out a PTLC-success\ntransaction being broadcast unless she broadcasted it herself.\n\n# Scenarios\n\nTo demonstrate the logical implications of the key combinations used in the\nabove 2-of-2s I'll somewhat tediously go through how each output is resolved.\nI'll use the label \"BOB OWNS\" to indicate that Bob knows both keys for the\n2-of-2 and Alice has no pending time-locked transactions that spend from the\noutput. Likewise I'll use \"BOB MUST SPEND\" to indicate that Bob knows both keys\nbut there *is* a pending time-locked transaction that Alice may use in the\nfuture.\n\nIn these examples Alice is the one broadcasting the commitment transaction but\nit could just as easily be Bob (remember it is the same transaction), in which\ncase the converse of each situation applies.\n\n## Balance output\n\nHere is what happens for balance outputs.\n\nAlice broadcasts a non-revoked commitment transaction (reveals Pa):\n1. Balance output for Alice: Alice waits for the relative time-lock and then\n   broadcasts her claim transaction.\n2. Balance output for Bob: BOB OWNS. The output is 2-of-2(Pa,Rb) and Alice has\n   revealed Pa.\n\nAlice broadcasts a revoked commitment transaction (reveals Pa and has already\nrevealed Ra):\n1. Balance output for Alice: BOB MUST SPEND. The output is 2-of-2(Ra,Pb) so Bob\n   knows both keys but he needs to spend it before Alice's relative time-locked\n   claim transaction.\n2. Balance output for Bob: BOB OWNS. The output is 2-of-2(Pa,Rb) and Alice has\n   revealed Pa.\n\n## PTLC output\n\nIn each of the following scenarios Alice broadcasts the commitment transaction\nand therefore reveals Pa. I describe what happens when the PTLC-success\ntransaction makes it in instead of the PTLC-timeout and vise versa.\n\nAlice broadcasts a non-revoked commitment transaction which has a PTLC offered\nto Bob (reveals Pa):\n1. PTLC-success confirmed: BOB OWNS. The output is 2-of-2(Pa,Rb) and Alice\n   revealed Pa when she broadcasted the commitment transaction.\n2. PTLC-timeout confirmed: Alice waits until the relative time lock expires and\n   then broadcasts the claim transaction.\n\nAlice broadcasts a non-revoked commitment transaction which has a PTLC offered\nto herself (reveals Pa):\n1. PTLC-success confirmed: Alice waits for the relative time-lock to expire and\n   then broadcasts the claim transaction.\n2. PTLC-timeout confirmed: BOB OWNS. The output is 2-of-2(Pa,Rb) and Alice\n   revealed Pa when she broadcasted the commitment transaction.\n\nWhen Alice broadcasts a revoked commitment with a PTLC either Alice manages to\nalso confirm the PTLC-success or PTLC-timeout transactions (depending on the\ndirection of the PTLC) or Bob revokes the PTLC output in a transaction of his\nchoosing. Bob can unilaterally spend the PTLC output because he knows all keys\nin 2-of-2(Pa + Ra, Pb + Rb). If he misses out, he gets another shot after the\nPTLC-success and PTLC-timeout transactions are confirmed. This is very similar\nto lightning today but here is what happens in the two scenarios for\ncompleteness:\n\nAlice broadcasts a revoked commitment transaction which has a PTLC towards Bob\n(reveals Pa and has already revealed Ra):\n1. PTLC-timeout confirmed: BOB MUST SPEND. The output is 2-of-2(Pb,Ra) and Alice\n   revealed Ra when she revoked the commitment transaction but Alice has a\n   pending claim transaction to spend the funds.\n2. Revocation tx confirmed: Bob takes all the funds.\n\nAlice broadcasts a revoked commitment transaction which has a PTLC towards\nherself (reveals Pa and has already revealed Ra):\n1. PTLC-success confirmed: BOB MUST SPEND. The output is 2-of-2(Pb,Ra) and Alice\n   revealed Ra when she revoked the commitment transaction but Alice has a\n   pending claim transaction to spend the funds.\n2. Revocation tx confirmed: Bob takes all the funds.\n\n# Misc Remarks\n\n- It looks straightforward to apply anchor outputs to this scheme\n- Each \"claim\" transaction can be `SIGHASH_SINGLE | SIGHASH_ANYONECANPAY` to\n  allow combining it into a larger transaction.\n\n[1]: https://eprint.iacr.org/2020/476.pdf\n[2]: https://lists.linuxfoundation.org/pipermail/lightning-dev/2015-November/000339.html\n[3]: https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-January/002448.html\n[4]: https://github.com/lightningnetwork/lightning-rfc/blob/master/03-transactions.md\n[5]: https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-December/002375.html\n[6]: https://joinmarket.me/blog/blog/schnorrless-scriptless-scripts/\n[7]: https://joinmarket.me/blog/blog/flipping-the-scriptless-script-on-schnorr/_\n[8]: https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-July/002064.html\n[9]: https://blockstream.com/eltoo.pdf\n\nPlease let me know if something is not clear or underdeveloped or you think I\nhave missed something. Thanks to those who have offered their comments so far\nand thanks in advance for any ideas you have that could improve this scheme.\n\nLL"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-08-25T12:45:50",
                "message_text_only": "Good morning Lloyd,\n\nI think this is excellent work overall.\n\nWith that said...\n\n\n> -   It is more elegant as there are half the number of possible transactions. I\n>     expect this will follow through to reduced implementation complexity and maybe\n>     make it easier to explain as well.\n\nI am not sure the complexity will be reduced all that much.\n\nCurrently:\n\n* We provide a partial signature for the other side for their commitment transaction.\n* We keep our own commitment transaction and the partial signature we receive from the other side.\n\nThe node never has to retain the commitment transaction of the other side.\n\nWith this setup:\n\n* We provide a partial signature for the other side for their asymmetric signature.\n* We keep a copy of the shared commitment transaction and the partial signature we received for our own asymmetric signature from the other side.\n\nSo storage complexity is still the same.\n\nAn issue is that with asymmetric transactions, it is fairly easy to use TCP to communicate changes to the commitment txes.\nWe send a bunch of HTLC changes we want to apply to the other side commitment tx, then send a signature for those changes.\nSince what we send applies to *their* transaction only, we do not have to consider what they sent to us, we just have to consider what we sent to them.\nConversely, when keeping track of what our commitment transaction is, we only have to consider what they sent to us, in order, and then when we receive a signature we know it is for the commitment transaction with all the updates the other side sent.\n\n(This arguably just moves the complexity higher, however: we cannot forward an HTLC until both us and the other side have revoked the transactions that do not contain it i.e. the \"irrevocably committed\" state.)\n\nWhen we have \"the same\" transaction on both sides, however, we need to synchronize between the two sides.\nSuppose both participants want to forward HTLCs to one another.\nWithout any kind of locking, both participants could send network packets containing the HTLCs they want to add to each other, and it becomes ambiguous whether the signature they *should* send contains one, or both.\n\nBasically, TCP only assures a global order for *one* direction of the communications, once we have two network nodes talking simultaneously, the order in which one writes and then reads is a lot more ambiguous.\n\nThis issue also exists for Decker-Russell-Osuntokun, incidentally.\n\nOne way to solve this would be to have a \"token\" that is passed alternately between the participants.\nAt initial connection, they run a secure multiparty coinflip that indicates which one gets the token.\nThen, the one that holds the token can add more HTLCs, then tell the other \"okay, now we sign\" and they exchange signatures for a new version that involves only the HTLCs from the token-holder.\nThen the token-holder passes the token to the other side.\n\nIf the current token-holder does not have any HTLCs it wants to send, it can wait for some time (in case it receives a request to forward), then if there are still no HTLCs, it can pass the token to the other side by sending a token-passing message.\n\nThis solution requires a good amount of bandwidth in such token-passing messages, which can multiply with the number of channels a single node has.\nIf token-passing is not done in short time frames (sub-second) then it potentially increases the latency of forwarding, thus this represents a latency vs bandwidth tradeoff.\n\nThere may be better solutions for this race-condition problem.\nFor example, it seems to me that we can still have different histories for both sides of the channel, i.e. different transactions on both sides, the same as in current Poon-Dryja BOLT.\nAfter all, the witnesses are asymmetric anyway.\nBut that completely negates the stated goal of removing the different transactions on both sides and the hoped-for reduction in complexity, so an exercise in futility.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-08-27T01:48:13",
                "message_text_only": "Good morning LL, and other LNers...\n\nSince we want to upgrade to Decker-Russell-Osuntokun in the future anyway, we still need to solve this \"simultaneous HTLC\" problem.\n\nSo here is another cut at this, without the token-passing:\n\n* Perform a coin toss whenever simultaneous HTLC offers occur.\n* Typically, a multiparty coin-toss involves two rounds: first commitments to random numbers are sent, then the actual random numbers are sent, and then after validating that they match commitments, their lowest bits are XORed and the resulting bit is heads/tails.\n  * However, we should recognize that HTLCs hashes are not under full control of anyone other than the payee, and if somebody is *offering* an HTLC, it is either the payer, or a forwarding node.\n  * Even *if* it is under control of the offerer of the HTLC, once an HTLC is instantiated, it consumes capacity on the channel (`max_accepted_htlcs`).\n    Thus, even if one counterparty keeps winning the coin toss, it will eventually run out of capacity to add a new HTLC.\n  * So we could just use the HTLC hashes to seed the random numbers of the coin toss.\n    For example, it could be salted with the node IDs of the channel parties, then the resulting hash of the hash is used in the deterministic coin toss.\n\nSo let us consider two messages:\n\n* `add_htlc` containing 1 or more HTLCs the sender wants to add.\n* `ack_htlc` containing nothing.\n\nWhenever a node wants to add one or more HTLCs, it sends `add_htlc`, then waits for *either* `add_htlc` *or* `ack_htlc`.\nIf it receives an `ack_htlc`, then it is the only one with HTLCs to add, so they add the HTLCs and send partial signatures of the new state to each other.\n\nIf we receive an `add_htlc` without having sent an `add_htlc` of our own, we just send out an `ack_htlc` and proceed to partial signature sharing.\n\nHowever, if both peers sent `add_htlc` to each other, they perform a coin toss ritual.\nThey concatenate their node IDs (lexicographic order), then concatenate those with the set of HTLCs being added by each side.\nThey hash the concatenation, and then take the lowest bit of that hash.\nIf it is 0, then the node that owns the `/0` direction won and the HTLCs it added are what goes in the next update (and the loser has to buffer up its changes until after the update ritual completes).\nIf it is 1, then the node that owns the `/1` direction won.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Witness asymmetric payment channels",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Lloyd Fournier",
                "ZmnSCPxj"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 19748
        }
    },
    {
        "title": "[Lightning-dev] Simulating Eltoo Factories using SCU Escrows (aka SCUE'd Eltoo)",
        "thread_messages": [
            {
                "author": "Nadav Kohen",
                "date": "2020-08-31T23:06:34",
                "message_text_only": "Hi all,\n\n# Simulating Eltoo / ANYPREVOUT Factories Using SCU Escrows\n\nIn this write-up I hope to convince you that it is possible to create some\nweak version of Eltoo channels and channel factories today without\nSIGHASH_ANYPREVOUT (although the version using this sighash is clearly\nsuperior) using ZmnSCPxj's proposal Smart Contracts Unchained (SCU) which\nBen Carman has cleverly given the name SCUE'd Eltoo.\n\n## Introduction\n\n### Eltoo / ANYPREVOUT\n\nEltoo is a proposal for a new (and generally improved) way of doing\nLightning channels which also allows for multi-party channels (and channel\nfactories). I am by no means fluent in the going's on of eltoo and\nanyprevout so I will link https://blockstream.com/eltoo.pdf and\nhttps://bitcoinops.org/en/topics/sighash_noinput/. My understanding is that\nat a high level, rather than using a penalty mechanism to update channel\nstates, sighash_anyprevout is used to make any old commitment transaction\nspendable by any newer commitment transaction so that old revoked states\ncan be updated on-chain instead of relying on a punishment mechanism.\nBenefits of this scheme include but are not limited to easier watchtower\nimplementations, static partial backups, and multi-party channels.\n\n### Smart Contracts Unchained (SCU)\n\nI strongly recommend the reader read this write up by ZmnSCPxj before\ncontinuing https://zmnscpxj.github.io/bitcoin/unchained.html\n\nAt a high level the idea is to use a participant-chosen \"federation\" of\n\"escrows\" which can be thought of as virtual machines which understand\ncontracts written in some language and which enforce said contracts by\ngiving users signatures of transactions that are produced by these\ncontracts. A general goal of SCU is to be trust-minimizing and as private\nas possible. For example, escrows should not be able to see that they are\nbeing used if there are no disputes, among other considerations that can be\nmade to make SCU Escrows as oblivious as possible (discussed further below).\n\n## Proposal (Un-Optimized)\n\nAt a high level, this proposal is to replace the use of ANYPREVOUT with a\nfederation of SCU Escrows which will enforce state updates by only\ngenerating signatures to spend older states with newer ones.\n\nI will work in the general context of multi-party channels but all of this\nworks just as well in two-party (Lightning) channels.\n\nSay that we have N parties who wish to enter into a multi-party channel\n(aka channel factory). Each participant has a public key P_i and together\nthey do a distributed key generation (DKG) of some kind to reach some\nshared secret x (for example, each party contributes a commitment to a\nrandom number and then that random number, MuSig style, and the sum of\nthese random numbers constitutes the shared secret). This x will be used to\nderive a sequence of (shared) key pairs (x_k, X_k) (for example this can be\ndone by having x_k = PRNG(x, k)).\n\nLet State(k) be some agreed upon commitment of the channel state at update\nk (for example, HMAC(k, kth State Tx outputs)). State(0) is a commitment to\n0 and the initial channel balances.\n\nLet Delta be some CSV timelock.\n\nFor the sake of simplicity, let us consider the case where only a single\nSCU escrow is used which has public key E, but note that all of the\nfollowing can be extended to a threshold scheme of escrows. E_k will be\nused to denote some tweak of E by State(k) similar to the tweak described\nin SCU.\n\n### Transactions\n\n#### Funding Transaction\n\nLike all such schemes, the funding transaction is some transaction\ncontaining an N-of-N multi-signature output with keys P_1, ..., P_N called\nthe funding output.\n\n#### Commitment Transaction\n\nThe commitment transaction spends the funding output and has a single\noutput which has two spending conditions: Either E_k and X_k sign OR all N\nparties sign cooperatively after Delta.\n\n#### State Transaction\n\nThe state transaction spends the commitment transaction via the cooperative\nbranch and has (potentially many) outputs representing the current channel\nstate. For example there will be an output for each solvent participant in\nthis channel, as well as an output for ever contract living on this channel\n(for instance, other smaller channels).\n\n#### Commitment Update Transaction\n\nLet k2 be some state where k2 > k.\n\nThe commitment update transaction spends either a commitment transaction's\nnon-cooperative branch (E_k and X_k) or another commitment update\ntransaction's non-time-locked branch, and has a single output which has two\nspending conditions: Either E_k2 and X_k2 sign OR E_k2' and X_k2' sign\nafter Delta where those are tweaked keys in some way (to avoid signatures\ngenerated for one case being used in the other).\n\n#### State Update Transaction\n\nThe state update transaction spends the commitment update transaction via\nthe time-locked branch and has outputs equal to those on the (k2)th state\ntransaction.\n\n### Update Mechanism\n\nThe update mechanism here is the same as would be expected for a\nmulti-party payment channel but with the added step that all parties must\nsign the commitment State(k) before they sign State Transaction k.\n\n### Settlement\n\n#### Cooperative (Normal Close)\n\nAs you might expect, cooperative closure is where a transaction is\ncooperatively constructed which directly spends the on-chain funding UTXO\nand outputs the current State Transaction's outputs.\n\n#### Non-Cooperative (Force Close)\n\nIn any case where not all parties are able or willing to sign a cooperative\nclosing transaction, any party can broadcast the most recent commitment\ntransaction, which can then be spent by anyone broadcasting the most recent\nstate transaction after Delta.\n\nIf, at any time, any party broadcasts an old commitment transaction k < c,\nany other party has until Delta to correct this mistake/attack. They do so\nby going to the SCU Escrow and presenting all signatures of State(k) and of\nState(c) which the Escrow verifies as well as verifying that k < c. Should\nall of these things check out, the Escrow can construct a Commitment Update\nTransaction (for (k, k2) = (k, c)) and the corresponding State Update\nTransaction and sign both of these transactions using E. These signatures\n(along with signatures from the shared keys X_k and X_c) can be used to\nbroadcast the commitment update transaction, and after Delta, the state\nupdate transaction.\n\nIf a commitment update transaction is broadcast for an old state c < c',\nthen any party has until Delta to correct this mistake/attack. They do so\nby following the same exact steps as in the previous paragraph but with k\n<- c and c <- c' and where the Commitment Update Transaction spends the\nprevious Commitment Update Transaction instead of a Commitment Transaction.\n\nIn this way any channel participant can unilaterally update the on-chain\ncommitment transaction until the most recent state is reached after which\nDelta will pass and a State Update Transaction with the current state will\nbe valid to broadcast.\n\n## Optimizations and Open Details\n\n### Multiple Escrows\n\nThe above can be done with some user-chosen federation with some threshold\nby replacing E above with a threshold condition using many escrow public\nkeys. Doing so with as large and diverse a federation as possible is\nstrongly encouraged as it reduces the likelihood that the federation will\nbe bribed to spend the non-time-locked branch of the commitment transaction\nalong with some channel participant directly. I believe it should\n(hopefully) be possible to make such an attack traceable (i.e. provide\nproof that this happened in an illegal way) so that attacked parties can\nprove that Escrows have been malicious.\n\n### Taproot\n\nAs is mentioned in SCU, the escrow scheme is made much better (especially\nin the multi-escrow case) by Taproot and the above scheme using SCU is\nimproved even further as all outputs are bi-conditional and these two\nconditions can be separated into different merkle branches to increase\nprivacy and fungibility.\n\n### What is given to the Escrow? (aka Blinding / ZKP)\n\nIn the above proposal, virtually all information about the channel, as well\nas how to find it on chain, is given to the escrow(s). This is really bad,\nand luckily it is avoidable! In principal we want Escrows to do nothing but\n(potentially many) random looking simple computations on random looking\ninputs to generate random looking outputs. The algorithm given the the\nEscrow is currently:\n\nInputs =\n\n* output to spend (either a commitment output or a commitment update output)\n* State(k) corresponding to that output\n* signatures of State(k)\n* State(c) with c > k\n* signatures of State(c)\n* N public keys\n* Relevant shared public keys\n* Delta\n\nOutput = If any signature is invalid or c <= k, FAIL. Otherwise, generate a\ndigital signature using E with some tweak (as a function of inputs) and of\nsome hash (as a function of inputs).\n\nAs such, I will first note that the verification part of this algorithm's\nexecution is linear time and so there must be a way to do it in Zero\nKnowledge. Specifically I believe this should be \"as simple as\" blinding\nall state inputs with random tweaks and blinding signatures of these states\nin the corresponding way (this may require that the signatures given by all\nparties during updates actually be altered in some way to make this work).\nFurthermore I think it should be possible (at least in theory it seems\nplausible to me) that all inputs can be hidden/blinded/tweaked and the\nEscrow performs some computations on these random looking inputs resulting\nin either a FAIL, or in further random looking computation using E (likely\nrequiring some ZKP inputs proving that the calling party has followed some\nset of rules) to generate a blinded signature which can then be unblinded\nby the caller to receive a valid digital signature usable to enforce the\nabove proposal.\n\nPlease note that I do not have these details worked out in any meaningful\nway (and probably won't be able to do so, would love if someone more apt in\nthis area would give this some thought!), but also that while this vastly\nimproves the privacy and security of this scheme, it isn't strictly\nspeaking a necessary optimization if you are willing to place more trust\nand be less private with Escrows.\n\n### Fees\n\nI have given no thought to transaction fees in the above and I'm sure there\nare a bunch of ways to do them wrong but I'm hoping that it is possible to\nadd anchor outputs or whatever other alterations need to occur to allow fee\nconsiderations to work out.\n\nI hope people find this proposal interesting! In theory it could be\nimplemented on today's Bitcoin (though I will not have time to work on this\nin the foreseeable future, but would be happy to help anyone who would want\nto try to do this)!\n\nBest,\nNadav\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200831/44227008/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Simulating Eltoo Factories using SCU Escrows (aka SCUE'd Eltoo)",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Nadav Kohen"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 10908
        }
    }
]