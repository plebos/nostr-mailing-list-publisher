[
    {
        "title": "[Lightning-dev] Sphinx and Push Notifications",
        "thread_messages": [
            {
                "author": "Pavol Rusnak",
                "date": "2020-02-02T12:39:05",
                "message_text_only": "Hi all!\n\nI have a couple of unrelated questions, hope you can give me some pointers.\n\n1) Is c-lightning going to support Sphinx or other form of spontaneous\npayments?\n\n2) Can a lightning node (such as lnd or c-lightning) send a push\nnotification (e.g. to a webhook) when it receives or routes a payment? If\nyes, is this notification cryptographically signed (for example with the\nnode's private key)? Is this documented somewhere?\n\nThanks!\n\n--\nBest Regards / S pozdravom,\n\nPavol \"stick\" Rusnak\nCTO, SatoshiLabs\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200202/1528e829/attachment.html>"
            },
            {
                "author": "darosior",
                "date": "2020-02-02T13:59:16",
                "message_text_only": "Hi Pavol,\n\n> 1) Is c-lightning going to support Sphinx or other form of spontaneous payments?\n\nI think cdecker is working on integrating keysend to his noise plugin (https://github.com/lightningd/plugins/pull/68).\n\n> 2) Can a lightning node (such as lnd or c-lightning) send a push notification (e.g. to a webhook) when it receives or routes a payment? If yes, is this notification cryptographically signed (for example with the node's private key)? Is this documented somewhere?\n\nC-lightning sends notifications (and hooks, but it doesn't seem to be your usecase here) for typical events such as \"I received an HTLC !\". You can make a plugin which registers to these lightningd notifications sends encrypted push notifs. Doc here https://lightning.readthedocs.io/PLUGINS.html#event-notifications :-).\n\nDarosior\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nLe dimanche, f\u00e9vrier 2, 2020 1:39 PM, Pavol Rusnak via Lightning-dev <lightning-dev at lists.linuxfoundation.org> a \u00e9crit\u00a0:\n\n> Hi all!\n> \n\n> I have a couple of unrelated questions, hope you can give me some pointers.\n> \n\n> 1) Is c-lightning going to support Sphinx or other form of spontaneous payments?\n> \n\n> 2) Can a lightning node (such as lnd or c-lightning) send a push notification (e.g. to a webhook) when it receives or routes a payment? If yes, is this notification cryptographically signed (for example with the node's private key)? Is this documented somewhere?\n> \n\n> Thanks!\n> \n\n> --\n> Best Regards / S pozdravom,\n> \n\n> Pavol \"stick\" Rusnak\n> CTO, SatoshiLabs\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200202/49a4ac78/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 477 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200202/49a4ac78/attachment.sig>"
            },
            {
                "author": "Christian Decker",
                "date": "2020-02-04T14:25:10",
                "message_text_only": "darosior via Lightning-dev <lightning-dev at lists.linuxfoundation.org> writes:\n> Hi Pavol,\n>\n>> 1) Is c-lightning going to support Sphinx or other form of\n>> spontaneous payments?\n>\n> I think cdecker is working on integrating keysend to his noise plugin\n> (https://github.com/lightningd/plugins/pull/68).\n\nThe keysend functionality is implemented in the noise plugin and I am\nplanning to pull the keysend part out of the plugin, since that part is\nreally trivial to implement (`htlc_accepted` hook that checkes the\npayment_hash against the preimage in the onion, then tell `lightningd`\nto resolve directly).\n\nAs a side note: Sphinx-send is a terrible misnomer, since sphinx is the\nname of our onion construction, keysend is the proper name to use in\nthis case.\n\n>> 2) Can a lightning node (such as lnd or c-lightning) send a push\n>> notification (e.g. to a webhook) when it receives or routes a\n>> payment? If yes, is this notification cryptographically signed (for\n>> example with the node's private key)? Is this documented somewhere?\n>\n> C-lightning sends notifications (and hooks, but it doesn't seem to be\n> your usecase here) for typical events such as \"I received an HTLC\n> !\". You can make a plugin which registers to these lightningd\n> notifications sends encrypted push notifs. Doc here\n> https://lightning.readthedocs.io/PLUGINS.html#event-notifications :-).\n\nYou can have a plugin subscribe to HTLC related events (such as\n`forward_event` [1], or `invoice_payment` [2], to get notified about\nforwardings or invoices being paid. What you do with that notification\nthen is up to you. It could queue the event in kafka, call out to a\nwebhook, or log a message with a log management system. You can\narbitrarily transform the event in the plugin, including issuing calls\nto `signmessage` which will create a signature for the event message,\nthus allowing you to prove authenticity of the message. You'd most\nlikely need to canonicalize the message before signing, since JSON is\nnot the best format for canonical serialization, i.e., decoding and\nre-encoding can result in subtle changes, which could then fail\nsignature verification, but that should not be a major issue.\n\nCheers,\nChristian"
            },
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2020-02-04T10:10:03",
                "message_text_only": "2) lnd is getting the API you need in the next release (v0.10), that\nlet you subscribe to HTLC events. See PR\nhttps://github.com/lightningnetwork/lnd/pull/3848. The notification\nwon't be signed (but the stream uses TLS), but that can easily be\nadded using the `signmessage` API:\nhttps://api.lightning.community/#signmessage\n\nCheers,\nJohan\n\nOn Sun, Feb 2, 2020 at 1:46 PM Pavol Rusnak via Lightning-dev\n<lightning-dev at lists.linuxfoundation.org> wrote:\n>\n> Hi all!\n>\n> I have a couple of unrelated questions, hope you can give me some pointers.\n>\n> 1) Is c-lightning going to support Sphinx or other form of spontaneous payments?\n>\n> 2) Can a lightning node (such as lnd or c-lightning) send a push notification (e.g. to a webhook) when it receives or routes a payment? If yes, is this notification cryptographically signed (for example with the node's private key)? Is this documented somewhere?\n>\n> Thanks!\n>\n> --\n> Best Regards / S pozdravom,\n>\n> Pavol \"stick\" Rusnak\n> CTO, SatoshiLabs\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            }
        ],
        "thread_summary": {
            "title": "Sphinx and Push Notifications",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Johan Tor\u00e5s Halseth",
                "Pavol Rusnak",
                "darosior",
                "Christian Decker"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 6063
        }
    },
    {
        "title": "[Lightning-dev] Decoy node_ids and short_channel_ids",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2020-02-03T04:37:56",
                "message_text_only": "Bastien TEINTURIER <bastien at acinq.fr> writes:\n> We can easily get rid of (1.) by leveraging the `payment_secret`. The\n> improved scheme is:\n>\n> * Alice draws a random `decoy_key`\n> * Alice computes the corresponding `decoy_node_id = decoy_key * G`\n> * Alice draws a random `payment_secret`\n> * Alice computes `decoy_short_channel_id = H(payment_secret * decoy_key *\n> bob_node_id) xor short_channel_id`\n> * Alice uses the `decoy_key` to sign the invoice\n> * Carol recovers `decoy_node_id` from the invoice signature\n> * Carol includes `P_I = payment_secret * decoy_node_id` in the onion\n> payload for Bob\n> * Bob can compute `short_channel_id = H(bob_private_key * P_I) xor\n> decoy_short_channel_id`\n>\n> But I don't see how to get rid of (2.). If anyone has a clever idea on how\n> to do that, I'd love to hear it!\n\nI really don't want a special marker on Carol; she needs to just pay\nlike normal.  Not just because it's simple, but because it means that\nCarol can use a custodial wallet without having to flag the payment as\nsomehow special.\n\nAFAICT, having Bob assign scids is the only viable way to do this.  The\ncurrent proposal limits to one scid at a time, but it could be extended\nto allow multiple scids.\n\n(I'm seeking a clever way that Bob can assign them and trivially tell\nwhich ID is assigned to which peer, but I can't figure it out, so I\nguess Bob keeps a mapping and restricts each peer to 256 live scids?).\n\nI've updated and somewhat simplified the PR now.\n\nCheers,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-03T05:31:04",
                "message_text_only": "Good morning Rusty,\n\n> Bastien TEINTURIER bastien at acinq.fr writes:\n>\n> > We can easily get rid of (1.) by leveraging the `payment_secret`. The\n> > improved scheme is:\n> >\n> > -   Alice draws a random `decoy_key`\n> > -   Alice computes the corresponding `decoy_node_id = decoy_key * G`\n> > -   Alice draws a random `payment_secret`\n> > -   Alice computes `decoy_short_channel_id = H(payment_secret * decoy_key * bob_node_id) xor short_channel_id`\n> > -   Alice uses the `decoy_key` to sign the invoice\n> > -   Carol recovers `decoy_node_id` from the invoice signature\n> > -   Carol includes `P_I = payment_secret * decoy_node_id` in the onion\n> >     payload for Bob\n> >\n> > -   Bob can compute `short_channel_id = H(bob_private_key * P_I) xor decoy_short_channel_id`\n> >\n> > But I don't see how to get rid of (2.). If anyone has a clever idea on how\n> > to do that, I'd love to hear it!\n>\n> I really don't want a special marker on Carol; she needs to just pay\n> like normal. Not just because it's simple, but because it means that\n> Carol can use a custodial wallet without having to flag the payment as\n> somehow special.\n>\n> AFAICT, having Bob assign scids is the only viable way to do this. The\n> current proposal limits to one scid at a time, but it could be extended\n> to allow multiple scids.\n>\n> (I'm seeking a clever way that Bob can assign them and trivially tell\n> which ID is assigned to which peer, but I can't figure it out, so I\n> guess Bob keeps a mapping and restricts each peer to 256 live scids?).\n\nWe can observe that short-channel-ids have a 24-bit blocknum, but it is exceedingly unlikely that for most blockchains, the genesis block will have a Lightning network channel.\n\nSo we could reserve blocknum=0 to identify special SCIDs.\n\nThe rest of the SCID could refer to the lowest 40 bits of the X-coord of the node ID that is the destination.\nWe should remember that short channel IDs are used as a convenient way to refer to the next *node* and not the next channel in the onion routing (which is why in Adelaide 2018 we decided to make short channel IDs \"advisory\", implementation that support multiple channels per peer can use any channel with that peer to forward, not just the specific SCID indicated in the onion).\nNow, 40 bits is not a lot, but we can observe that for almost all git repositories, 7 or 8 hex digits is usually enough to unambiguously identify a commit within the repository, even for git repositories with thousands of commits, and 8 hex digits is just 32 bits of identification.\nSo it seems to me that Bob could just look up the 40 bit identifier to each of the nodes with unpublished channels with it, and this will work well up to Bob having a few thousand peers with unpublished channels.\n\nIf we focus on Bitcoin specifically, we can observe as well that `when_lightning_became_cool` is well above 262144 (2^18 ) so we can steal 18 more bits from the blocknum, i.e. if none of the top 6 bits of blocknum are set (blocknum < 262144), then the lower 58 bits of the blockid are the lowest 58 bits of the node ID of the next hop.\nThough obviously that is not as good for regtest and testnet, do note that, assuming a non-premined blockchain with a similar 100-block maturity for coinbases, we could still steal 6 bits (blocknum < 64), since no Lightning channel can occur on the first 100 blocks anyway due to the maturity requirement (there *are* no coins that can be spent before then, so no Lightning channels can be created then).\n\n\nAdmittedly, if somebody knows your node id, they need only 40 bits of work to grind a node id of their own whose last 40 bits matches yours, then connect to the same public node you are on.\nIn that case, it becomes ambiguous for Bob which of the nodes it should send the last hop to, so it could just try them one by one (trying them in parallel risks Bob getting ripped off by an attacker who specifically generates multiple nodes with the same lower bits in the node ID).\nOr Bob could just reject future channels from nodes whose lower bits match that with something already channeled with it.\n\n\nFinally, in this context, this is intended to be used for nodes with unpublished channels.\nOf note is that the second-to-the-last node already knows the exact identity, timing, and amount of every payment to the last node anyway, because unpublished channels are not private.\nSo in this particular case, the second-to-the-last node can actually just drop the payer onion, and replace it with its own onion to the final node.\nThis is relevant if we ever want to hide the node id of the last node: Bob could provide a symmetric encryption key to all its peers with unpublished channels, which the peer can XOR with its own true node id and use the lowest 40 bits (or 46 bits or 58 bits) in the SCID.\nThen when Bob receives an onion whose next SCID has the top 24 or 18 or 6 bits set to 0, it can XOR the symmetric key to the lower bits and then determine the lowest bits of the node id of the last node, and it can then replace the outgoing onion with the corrected onion to that node.\nThe last node cannot use the payment secret (invoice secret), but that is not going to protect against probe attacks from a public node to a completely unpublished node anyway.\nAlso the last node cannot receive any data via this method (because the onion is replaced by Bob) but for simple pay-for-preimage applications this will work perfectly fine.\n\n\nIt strikes me as well that a C-Lightning plugin can actually implement this due to `htlc_accepted` hook.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "m.a.holden",
                "date": "2020-02-03T06:50:20",
                "message_text_only": "> (I'm seeking a clever way that Bob can assign them and trivially tell\n> which ID is assigned to which peer, but I can't figure it out, so I\n> guess Bob keeps a mapping and restricts each peer to 256 live scids?).\n\nHi Rusty.\n\nHere's a potential way for Alice and Bob to agree a set of 256 scids without any additional messages or changes to existing messages beyond a feature flag and a flag in open_channel, but comes with a computational cost.\n\nAlice and Bob agree on a random integer `r`. This could be negotiated on `open_channel`, but we shouldn't need to send additional information because we already have a random integer we can use: the `temporary_channel_id`. This is not known to anybody besides Alice and Bob.\n\nWhen a channel is locked, Bob computes n=256 scids, using something approximating `concat(n, trunc_bytes(sha256(ec_mult(2^n*r, Q)), 7))`, where `Q` is Alice's public key for the channel funding transaction.\n\nThe chance of scid collisions between channels is 2^56, which is probably no cause for concern.\n\nInstead of keeping a map of 256 scids for each channel, Bob can use a cuckoo filter for efficiency. The filter can be used for a quick membership test and also as an associative map from scids to channels. It can also support scid deletion in the event of channel closure (at the cost of recomputing 256 ec_mults again).\n\nSo when Bob receives a new HTLC to forward, he tests it against his cuckoo filter and retreives a candidate set of possible channels to which it may refer. For each channel, he takes the most significant byte of the scid as `m` and performs `trunc_bytes(sha256(ec_mult(2^m*r, Q)), 7)` and tests the least-significant 7 bytes of the result against the scid.\n\nAlice does not need to keep all of the scids she may use for invoices because they can be computed on the fly, but she will need to keep a copy of the `temporary_channel_id`.\n\nIn the reverse direction of Alice forwarding HTLCs to Bob, Bob's public key for the funding transaction is used instead.\n\nRegards,\nMark Holden"
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2020-02-03T14:06:50",
                "message_text_only": "Thanks for the feedback and discussion. Here are some more comments.\n\nThis is relevant if we ever want to hide the node id of the last node: Bob\n> could provide a symmetric\n> encryption key to all its peers with unpublished channels, which the peer\n> can XOR with its own true\n> node id and use the lowest 40 bits (or 46 bits or 58 bits) in the SCID.\n\n\nI don't understand your point here. Alice cannot hide her node_id from Bob\nsince the `node_id` is\ntied to the (unannounced) channel creation.\n\nBut this is not an issue. What Alice wants to break is the ability to link\nmultiple HTLCs together\nbecause they use the same `node_id`. Since Alice can use a different\n`node_id` in every invoice,\nit's easy for her to make sure Carol cannot tie those HTLCs together.\n\nIn order to hide from Bob, the best Alice can do is use a different\n`node_id` for each channel she\nopens to Bob and use Tor. This way Bob cannot know that node_id_1 and\nnode_id_2 both belong to Alice.\nI don't think we can do better than that.\n\nI really don't want a special marker on Carol; she needs to just pay like\n> normal.\n\n\nI agree that this would be the ideal outcome (and my current proposal\ndoesn't achieve that, but I'm\nhoping I can improve it to achieve that). Do note that even though my\ncurrent proposal requires\na code update from Carol, the code-change would be very small. Adding\nsupport for `payment_secret`\ndid require a change on Carol to improve security; I'm hoping that a small\nenough code-change with\na big enough privacy improvement would eventually be supported by all three\nimplementations (and\nthen find its way inside wallets).\n\nI must admit I'm a bit turned off by the state management required by your\nproposal. I'm afraid it\nmay be complex to get right, or be subject to fingerprinting and wouldn't\nresult in the privacy\ngain we're hoping.\n\nI think this really needs to be cheap for Bob; if Bob can be DoS-ed by\noffering this feature, I\ndon't think the Bobs out there will activate it.\n\nI really feel some cryptography trick can allow us to find a solution that\nrequires no more than a\nshared secret to be kept between Alice and Bob, and no\nsynchronization/state management.\nI'd like to explore this option further.\n\nCheers,\nBastien\n\nLe lun. 3 f\u00e9vr. 2020 \u00e0 07:51, m.a.holden via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n> > (I'm seeking a clever way that Bob can assign them and trivially tell\n> > which ID is assigned to which peer, but I can't figure it out, so I\n> > guess Bob keeps a mapping and restricts each peer to 256 live scids?).\n>\n> Hi Rusty.\n>\n> Here's a potential way for Alice and Bob to agree a set of 256 scids\n> without any additional messages or changes to existing messages beyond a\n> feature flag and a flag in open_channel, but comes with a computational\n> cost.\n>\n> Alice and Bob agree on a random integer `r`. This could be negotiated on\n> `open_channel`, but we shouldn't need to send additional information\n> because we already have a random integer we can use: the\n> `temporary_channel_id`. This is not known to anybody besides Alice and Bob.\n>\n> When a channel is locked, Bob computes n=256 scids, using something\n> approximating `concat(n, trunc_bytes(sha256(ec_mult(2^n*r, Q)), 7))`, where\n> `Q` is Alice's public key for the channel funding transaction.\n>\n> The chance of scid collisions between channels is 2^56, which is probably\n> no cause for concern.\n>\n> Instead of keeping a map of 256 scids for each channel, Bob can use a\n> cuckoo filter for efficiency. The filter can be used for a quick membership\n> test and also as an associative map from scids to channels. It can also\n> support scid deletion in the event of channel closure (at the cost of\n> recomputing 256 ec_mults again).\n>\n> So when Bob receives a new HTLC to forward, he tests it against his cuckoo\n> filter and retreives a candidate set of possible channels to which it may\n> refer. For each channel, he takes the most significant byte of the scid as\n> `m` and performs `trunc_bytes(sha256(ec_mult(2^m*r, Q)), 7)` and tests the\n> least-significant 7 bytes of the result against the scid.\n>\n> Alice does not need to keep all of the scids she may use for invoices\n> because they can be computed on the fly, but she will need to keep a copy\n> of the `temporary_channel_id`.\n>\n> In the reverse direction of Alice forwarding HTLCs to Bob, Bob's public\n> key for the funding transaction is used instead.\n>\n> Regards,\n> Mark Holden\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200203/46cc458b/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-03T14:51:33",
                "message_text_only": "Good morning t-bast,\n\n\n> > This is relevant if we ever want to hide the node id of the last node: Bob could provide a symmetric\n> > encryption key to all its peers with unpublished channels, which the peer can XOR with its own true\n> > node id and use the lowest 40 bits (or 46 bits or 58 bits) in the SCID.\n>\n> I don't understand your point here. Alice cannot hide her node_id from Bob since the `node_id` is\n> tied to the (unannounced) channel creation.\n>\n> But this is not an issue. What Alice wants to break is the ability to link multiple HTLCs together\n> because they use the same `node_id`. Since Alice can use a different `node_id` in every invoice,\n> it's easy for her to make sure Carol cannot tie those HTLCs together.\n\nThat is precisely what I am referring to, the lowest bits of the node ID are embedded in the SCID, which we do not want to openly reveal to Carol.\nThough if the point is to prevent Carol from correlating different invoices as arising from the same payee, then my scheme fails against that.\n\n>\n> In order to hide from Bob, the best Alice can do is use a different `node_id` for each channel she\n> opens to Bob and use Tor. This way Bob cannot know that node_id_1 and node_id_2 both belong to Alice.\n> I don't think we can do better than that.\n\nAlice would do better to use multiple Bobs in that case.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2020-02-03T15:05:25",
                "message_text_only": "Hi ZmnSCPxj,\n\nThat is precisely what I am referring to, the lowest bits of the node ID\n> are embedded in the SCID, which we do not want to openly reveal to Carol.\n>\n\nGot it, I wasn't understanding your point correctly. We totally agree on\nthat.\n\nThough if the point is to prevent Carol from correlating different invoices\n> as arising from the same payee, then my scheme fails against that.\n>\n\nIMO we should prevent Carol from correlating different invoices by using a\ndifferent node_id for each invoice.\nThis requires minimal changes and happens entirely payee-side (see my\ninitial mail).\n\nAlice would do better to use multiple Bobs in that case.\n>\n\nThat's of course a solution as well. Even with that though, if Alice opens\nmultiple channels to each of her Bobs,\nshe should use Tor and a different node_id each time for better privacy.\n\nCheers,\nBastien\n\nLe lun. 3 f\u00e9vr. 2020 \u00e0 15:51, ZmnSCPxj <ZmnSCPxj at protonmail.com> a \u00e9crit :\n\n> Good morning t-bast,\n>\n>\n> > > This is relevant if we ever want to hide the node id of the last node:\n> Bob could provide a symmetric\n> > > encryption key to all its peers with unpublished channels, which the\n> peer can XOR with its own true\n> > > node id and use the lowest 40 bits (or 46 bits or 58 bits) in the SCID.\n> >\n> > I don't understand your point here. Alice cannot hide her node_id from\n> Bob since the `node_id` is\n> > tied to the (unannounced) channel creation.\n> >\n> > But this is not an issue. What Alice wants to break is the ability to\n> link multiple HTLCs together\n> > because they use the same `node_id`. Since Alice can use a different\n> `node_id` in every invoice,\n> > it's easy for her to make sure Carol cannot tie those HTLCs together.\n>\n> That is precisely what I am referring to, the lowest bits of the node ID\n> are embedded in the SCID, which we do not want to openly reveal to Carol.\n> Though if the point is to prevent Carol from correlating different\n> invoices as arising from the same payee, then my scheme fails against that.\n>\n> >\n> > In order to hide from Bob, the best Alice can do is use a different\n> `node_id` for each channel she\n> > opens to Bob and use Tor. This way Bob cannot know that node_id_1 and\n> node_id_2 both belong to Alice.\n> > I don't think we can do better than that.\n>\n> Alice would do better to use multiple Bobs in that case.\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200203/acea682e/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2020-02-04T04:04:31",
                "message_text_only": "Bastien TEINTURIER <bastien at acinq.fr> writes:\n> That's of course a solution as well. Even with that though, if Alice opens\n> multiple channels to each of her Bobs,\n> she should use Tor and a different node_id each time for better privacy.\n\nThere are two uses for this feature (both of which I started implementing):\n\n1. Simply always use a temporary id when you have a private channel, to\n   obscure your onchain footprint.  This is a nobrainer.\n\n2. For an extra layer of transience, apply a new temporary id and new\n   nodeid on every invoice *which applies only for that invoice*.\n\nBut implementing the latter securely is fraught!\n\nFirstly, need to brute-force the onion against your N keys.  Secondly,\nif you use a temporary key, then you *don't* end up using the HTLC to\npay an invoice matching that key, you *MUST* pretend you couldn't\ndecrypt the onion!  This applies to all code paths between the two,\nincluding parsing the TLV, etc: they must ALL return\nWIRE_INVALID_ONION_HMAC.\n\nOtherwise, Mallory can get an invoice, then send malformed payments to\nAlice using the transient key in the invoice and see if she decrypts it.\n\nAnd then I realized that Alice can't do this properly without Bob\ntelling her what the scid he used to route was.\n\nOtherwise Mallory gets two invoices, and wants to know if they're\nactually the same node.  Inv1 has nodeid N1, routehint Bob->C1, Inv2 has\nnodeid N2, routehint Bob->C2.\n\nNow Mallory uses Bob->C2 to pay to N1 for Inv1.  If it works, he knows\nit's the same node issuing both invoices.\n\nSo, update_add_htlc needs a new scid field.\n\nAt this point, I think we should just add a new channel_flag, which if\nyou set it (and feature flag is offered) you get assigned random SCID\nfrom the peer in funding_locked.  This overrides your\nfunding-transaction-based SCID.\n\nThat gets the first case for new channels, without adding much\ncomplexity at all.[1]\n\nThoughts?\nRusty.\n\n[1] If we want to cover existing channels, we need a new \"give me a\n    replacement scid\" msg and reply.  But it can be idempotent (you\n    only ever get one replacement)."
            },
            {
                "author": "Rusty Russell",
                "date": "2020-02-04T04:29:09",
                "message_text_only": "Rusty Russell <rusty at rustcorp.com.au> writes:\n> Bastien TEINTURIER <bastien at acinq.fr> writes:\n>> That's of course a solution as well. Even with that though, if Alice opens\n>> multiple channels to each of her Bobs,\n>> she should use Tor and a different node_id each time for better privacy.\n>\n> There are two uses for this feature (both of which I started implementing):\n>\n> 1. Simply always use a temporary id when you have a private channel, to\n>    obscure your onchain footprint.  This is a nobrainer.\n>\n> 2. For an extra layer of transience, apply a new temporary id and new\n>    nodeid on every invoice *which applies only for that invoice*.\n>\n> But implementing the latter securely is fraught!\n>\n> Firstly, need to brute-force the onion against your N keys.  Secondly,\n> if you use a temporary key, then you *don't* end up using the HTLC to\n> pay an invoice matching that key, you *MUST* pretend you couldn't\n> decrypt the onion!  This applies to all code paths between the two,\n> including parsing the TLV, etc: they must ALL return\n> WIRE_INVALID_ONION_HMAC.\n>\n> Otherwise, Mallory can get an invoice, then send malformed payments to\n> Alice using the transient key in the invoice and see if she decrypts it.\n\nActually, that was too hasty.  You can use the payment_hash as a\nfastpath:\n\n1. Look up invoice using payment_hash.\n\n2. If there is an invoice, and it has a temporary id associated with it,\n   try using that to decrypt the onion.  If that works, and the onion is\n   on the final hop, and the TLV decodes, and the payment_secret is\n   correct, you can go back and use this temporary key to decrypt the onion.\n   Otherwise, go back and use the normal node key.\n\nThat's still quite a bit of tricky code though...\n\nCheers,\nRusty."
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2020-02-04T14:09:16",
                "message_text_only": "I'm a bit confused, I don't know if the implementation work you're\nmentioning refers to my proposal\nor yours :).\n\nWhen you say `temporary id`, could you clarify whether you mean a temporary\n`node_id` or `scid`?\n\nFirstly, need to brute-force the onion against your N keys.\n\n\nThis is probably the part that confuses me. Are you talking about Bob or\nAlice there?\nAlice can easily have her `decoy_node_id` be derived from her real\n`node_id`'s privacy key and the\n`payment_hash` or `payment_preimage`. When she receives a payment, she\nknows which `decoy_node_id`\nshould have been used so she doesn't need to brute-force.\n\nThat means Alice doesn't even have to change how she stores invoices. When\nAlice retrieves the\ninvoice from her DB, if it has the `decoy_node_id` feature bit set, she\nknows she needs to derive\nthe correct `node_id`. If it doesn't have that feature bit set, it's a\n\"legacy\" invoice and she has\nto use her real `node_id`.\n\nNow Mallory uses Bob->C2 to pay to N1 for Inv1. If it works, he knows it's\n> the same node issuing both invoices.\n\n\nSame, that wouldn't work because Alice can easily detect the mismatch and\npretend she can't decrypt\nthe onion (the code doesn't even have to pretend: it will use the expected\n`node_id` and use the\nexisting error paths).\n\nActually, that was too hasty.\n\n\nOk I think your second email came to the same conclusions and clarifies it\na bit :).\n\nIt's true that this is code where the developer may easily get confused\nbetween keys (but it's a\nlot simpler than the Sphinx or Noise implementation).\n\nHowever in my opinion it's still simpler than the `scid` state management\nthat needs to happen at\nAlice and Bob in https://github.com/lightningnetwork/lightning-rfc/pull/681\n(but I would need to\nimplement both E2E to be able to fairly judge that).\n\nThanks for the feedback, I'll keep working on improving the proposal.\nBastien\n\nLe mar. 4 f\u00e9vr. 2020 \u00e0 05:29, Rusty Russell <rusty at rustcorp.com.au> a \u00e9crit\n:\n>\n> Rusty Russell <rusty at rustcorp.com.au> writes:\n> > Bastien TEINTURIER <bastien at acinq.fr> writes:\n> >> That's of course a solution as well. Even with that though, if Alice\nopens\n> >> multiple channels to each of her Bobs,\n> >> she should use Tor and a different node_id each time for better\nprivacy.\n> >\n> > There are two uses for this feature (both of which I started\nimplementing):\n> >\n> > 1. Simply always use a temporary id when you have a private channel, to\n> >    obscure your onchain footprint.  This is a nobrainer.\n> >\n> > 2. For an extra layer of transience, apply a new temporary id and new\n> >    nodeid on every invoice *which applies only for that invoice*.\n> >\n> > But implementing the latter securely is fraught!\n> >\n> > Firstly, need to brute-force the onion against your N keys.  Secondly,\n> > if you use a temporary key, then you *don't* end up using the HTLC to\n> > pay an invoice matching that key, you *MUST* pretend you couldn't\n> > decrypt the onion!  This applies to all code paths between the two,\n> > including parsing the TLV, etc: they must ALL return\n> > WIRE_INVALID_ONION_HMAC.\n> >\n> > Otherwise, Mallory can get an invoice, then send malformed payments to\n> > Alice using the transient key in the invoice and see if she decrypts it.\n>\n> Actually, that was too hasty.  You can use the payment_hash as a\n> fastpath:\n>\n> 1. Look up invoice using payment_hash.\n>\n> 2. If there is an invoice, and it has a temporary id associated with it,\n>    try using that to decrypt the onion.  If that works, and the onion is\n>    on the final hop, and the TLV decodes, and the payment_secret is\n>    correct, you can go back and use this temporary key to decrypt the\nonion.\n>    Otherwise, go back and use the normal node key.\n>\n> That's still quite a bit of tricky code though...\n>\n> Cheers,\n> Rusty.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200204/f31934c0/attachment.html>"
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2020-02-04T14:50:26",
                "message_text_only": "Hey again,\n\nOtherwise Mallory gets two invoices, and wants to know if they're\n> actually the same node.  Inv1 has nodeid N1, routehint Bob->C1, Inv2 has\n> nodeid N2, routehint Bob->C2.\n>\n\nI think this attack is interesting. AFAICT my proposal defends against this\nbecause of the way\n`payment_secret` and `decoy_key` are both used to derive the `decoy_scid`\n(but don't trust me, do\nverify that I'm not missing something).\n\nIf Mallory doesn't use both the right `decoy_node_id` and `payment_secret`\nto compute `P_I`, Bob\nwill not decode that to a valid real `scid` and will return an\n`unknown_next_peer` which is good\nfor privacy.\n\nIt seems to me that\nhttps://github.com/lightningnetwork/lightning-rfc/pull/681 cannot defend\nagainst this attack. If both invoices are currently valid, Bob will forward\nan HTLC that uses N1\nwith C2 (because Bob has no way of knowing N1 from the onion, for privacy\nreasons).\nThe only way I'd see to avoid is would be that Alice needs to share her\n`decoy_node_id`s with\nBob (and the mapping to a `decoy_scid`) which means more state to\nmanage...but maybe I'm just\nmissing a better mitigation?\n\nCheers,\nBastien\n\nLe mar. 4 f\u00e9vr. 2020 \u00e0 15:09, Bastien TEINTURIER <bastien at acinq.fr> a\n\u00e9crit :\n\n> I'm a bit confused, I don't know if the implementation work you're\n> mentioning refers to my proposal\n> or yours :).\n>\n> When you say `temporary id`, could you clarify whether you mean a\n> temporary `node_id` or `scid`?\n>\n> Firstly, need to brute-force the onion against your N keys.\n>\n>\n> This is probably the part that confuses me. Are you talking about Bob or\n> Alice there?\n> Alice can easily have her `decoy_node_id` be derived from her real\n> `node_id`'s privacy key and the\n> `payment_hash` or `payment_preimage`. When she receives a payment, she\n> knows which `decoy_node_id`\n> should have been used so she doesn't need to brute-force.\n>\n> That means Alice doesn't even have to change how she stores invoices. When\n> Alice retrieves the\n> invoice from her DB, if it has the `decoy_node_id` feature bit set, she\n> knows she needs to derive\n> the correct `node_id`. If it doesn't have that feature bit set, it's a\n> \"legacy\" invoice and she has\n> to use her real `node_id`.\n>\n> Now Mallory uses Bob->C2 to pay to N1 for Inv1. If it works, he knows it's\n>> the same node issuing both invoices.\n>\n>\n> Same, that wouldn't work because Alice can easily detect the mismatch and\n> pretend she can't decrypt\n> the onion (the code doesn't even have to pretend: it will use the expected\n> `node_id` and use the\n> existing error paths).\n>\n> Actually, that was too hasty.\n>\n>\n> Ok I think your second email came to the same conclusions and clarifies it\n> a bit :).\n>\n> It's true that this is code where the developer may easily get confused\n> between keys (but it's a\n> lot simpler than the Sphinx or Noise implementation).\n>\n> However in my opinion it's still simpler than the `scid` state management\n> that needs to happen at\n> Alice and Bob in\n> https://github.com/lightningnetwork/lightning-rfc/pull/681 (but I would\n> need to\n> implement both E2E to be able to fairly judge that).\n>\n> Thanks for the feedback, I'll keep working on improving the proposal.\n> Bastien\n>\n> Le mar. 4 f\u00e9vr. 2020 \u00e0 05:29, Rusty Russell <rusty at rustcorp.com.au> a\n> \u00e9crit :\n> >\n> > Rusty Russell <rusty at rustcorp.com.au> writes:\n> > > Bastien TEINTURIER <bastien at acinq.fr> writes:\n> > >> That's of course a solution as well. Even with that though, if Alice\n> opens\n> > >> multiple channels to each of her Bobs,\n> > >> she should use Tor and a different node_id each time for better\n> privacy.\n> > >\n> > > There are two uses for this feature (both of which I started\n> implementing):\n> > >\n> > > 1. Simply always use a temporary id when you have a private channel, to\n> > >    obscure your onchain footprint.  This is a nobrainer.\n> > >\n> > > 2. For an extra layer of transience, apply a new temporary id and new\n> > >    nodeid on every invoice *which applies only for that invoice*.\n> > >\n> > > But implementing the latter securely is fraught!\n> > >\n> > > Firstly, need to brute-force the onion against your N keys.  Secondly,\n> > > if you use a temporary key, then you *don't* end up using the HTLC to\n> > > pay an invoice matching that key, you *MUST* pretend you couldn't\n> > > decrypt the onion!  This applies to all code paths between the two,\n> > > including parsing the TLV, etc: they must ALL return\n> > > WIRE_INVALID_ONION_HMAC.\n> > >\n> > > Otherwise, Mallory can get an invoice, then send malformed payments to\n> > > Alice using the transient key in the invoice and see if she decrypts\n> it.\n> >\n> > Actually, that was too hasty.  You can use the payment_hash as a\n> > fastpath:\n> >\n> > 1. Look up invoice using payment_hash.\n> >\n> > 2. If there is an invoice, and it has a temporary id associated with it,\n> >    try using that to decrypt the onion.  If that works, and the onion is\n> >    on the final hop, and the TLV decodes, and the payment_secret is\n> >    correct, you can go back and use this temporary key to decrypt the\n> onion.\n> >    Otherwise, go back and use the normal node key.\n> >\n> > That's still quite a bit of tricky code though...\n> >\n> > Cheers,\n> > Rusty.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200204/41cc31da/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2020-02-05T01:28:43",
                "message_text_only": "Bastien TEINTURIER <bastien at acinq.fr> writes:\n> Hey again,\n>\n> Otherwise Mallory gets two invoices, and wants to know if they're\n>> actually the same node.  Inv1 has nodeid N1, routehint Bob->C1, Inv2 has\n>> nodeid N2, routehint Bob->C2.\n>\n> I think this attack is interesting. AFAICT my proposal defends against this\n> because of the way\n> `payment_secret` and `decoy_key` are both used to derive the `decoy_scid`\n> (but don't trust me, do\n> verify that I'm not missing something).\n>\n> If Mallory doesn't use both the right `decoy_node_id` and `payment_secret`\n> to compute `P_I`, Bob\n> will not decode that to a valid real `scid` and will return an\n> `unknown_next_peer` which is good\n> for privacy.\n\nBut Mallory can do the same attack, I think.  Just include the P_I from\nthe wrong invoice for Bob.\n\n> It seems to me that\n> https://github.com/lightningnetwork/lightning-rfc/pull/681 cannot defend\n> against this attack. If both invoices are currently valid, Bob will forward\n> an HTLC that uses N1\n> with C2 (because Bob has no way of knowing N1 from the onion, for privacy\n> reasons).\n> The only way I'd see to avoid is would be that Alice needs to share her\n> `decoy_node_id`s with\n> Bob (and the mapping to a `decoy_scid`) which means more state to\n> manage...but maybe I'm just\n> missing a better mitigation?\n\nNo, Bob can include the scid he used in the update_add_htlc message, so\nAlice can check.\n\nI'm extremely nervous about custodial lightning services restricting\nwhat they will pay to.  This is not theoretical: they will come under\nimmense KYC pressure in the near future, which means they cannot pay\narbitrary invoices.\n\nThus my preference for a system which doesn't add any requirements on\nthe payer.\n\nCheers,\nRusty."
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2020-02-05T09:00:32",
                "message_text_only": ">\n> But Mallory can do the same attack, I think.  Just include the P_I from\n> the wrong invoice for Bob.\n>\n\nGood catch, that's true, thanks for keeping me honest there! In that case\nmy proposal\nwould need the same mitigation as yours, Bob will need to include the\n`scid` he received\nin `update_add_htlc` (this is in fact not that hard once we allow TLV\nextensions on every\nmessage).\n\nI'm extremely nervous about custodial lightning services restricting\n> what they will pay to.  This is not theoretical: they will come under\n> immense KYC pressure in the near future, which means they cannot pay\n> arbitrary invoices.\n>\n\nThat's a very good point, thanks for raising this. However I believe that\nthere are (and will be) enough\nnon-custodial wallets to let motivated users pay whatever they want. Users\ncan even run their own\nnode to pay such invoices if needed.\n\nIf you are using a custodial wallet and KYC pressure kicks in, then\nregardless of that feature law may\nrequire users to completely reveal who they are paying, so even normal\npayments wouldn't protect\nthem, don't you think? Regulation could for example disallow paying via\nunannounced channels entirely\n(or require you to show the funding tx associated to your unannounced\nchannel).\n\nIf we're taking into account such KYC pressure, then I believe none of the\nsolutions we can provide will\nbe useful. It will be up to the recipient to decide whether he thus wants\nto use a normal invoice and\nreveal his identity or pass on that payment.\n\nWhat do you think? Do you believe `option_scid_assign` can do a better job\nin such situations?\n\nCheers,\nBastien\n\nLe mer. 5 f\u00e9vr. 2020 \u00e0 02:44, Rusty Russell <rusty at rustcorp.com.au> a\n\u00e9crit :\n\n> Bastien TEINTURIER <bastien at acinq.fr> writes:\n> > Hey again,\n> >\n> > Otherwise Mallory gets two invoices, and wants to know if they're\n> >> actually the same node.  Inv1 has nodeid N1, routehint Bob->C1, Inv2 has\n> >> nodeid N2, routehint Bob->C2.\n> >\n> > I think this attack is interesting. AFAICT my proposal defends against\n> this\n> > because of the way\n> > `payment_secret` and `decoy_key` are both used to derive the `decoy_scid`\n> > (but don't trust me, do\n> > verify that I'm not missing something).\n> >\n> > If Mallory doesn't use both the right `decoy_node_id` and\n> `payment_secret`\n> > to compute `P_I`, Bob\n> > will not decode that to a valid real `scid` and will return an\n> > `unknown_next_peer` which is good\n> > for privacy.\n>\n> But Mallory can do the same attack, I think.  Just include the P_I from\n> the wrong invoice for Bob.\n>\n> > It seems to me that\n> > https://github.com/lightningnetwork/lightning-rfc/pull/681 cannot defend\n> > against this attack. If both invoices are currently valid, Bob will\n> forward\n> > an HTLC that uses N1\n> > with C2 (because Bob has no way of knowing N1 from the onion, for privacy\n> > reasons).\n> > The only way I'd see to avoid is would be that Alice needs to share her\n> > `decoy_node_id`s with\n> > Bob (and the mapping to a `decoy_scid`) which means more state to\n> > manage...but maybe I'm just\n> > missing a better mitigation?\n>\n> No, Bob can include the scid he used in the update_add_htlc message, so\n> Alice can check.\n>\n> I'm extremely nervous about custodial lightning services restricting\n> what they will pay to.  This is not theoretical: they will come under\n> immense KYC pressure in the near future, which means they cannot pay\n> arbitrary invoices.\n>\n> Thus my preference for a system which doesn't add any requirements on\n> the payer.\n>\n> Cheers,\n> Rusty.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200205/08571a4f/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2020-02-10T03:40:10",
                "message_text_only": "Bastien TEINTURIER <bastien at acinq.fr> writes:\n>> But Mallory can do the same attack, I think.  Just include the P_I from\n>> the wrong invoice for Bob.\n>\n> Good catch, that's true, thanks for keeping me honest there! In that case\n> my proposal\n> would need the same mitigation as yours, Bob will need to include the\n> `scid` he received\n> in `update_add_htlc` (this is in fact not that hard once we allow TLV\n> extensions on every\n> message).\n\nYes, I've added this to the PR.  Which gives a new validation path, I\nthink:\n\n## Figuring out what nodeid to use to decode onion\n\n1. Look up scid from HTLC; if it didn't include one, use default.\n2. Look up payment_hash; if no invoice is found, use default.\n3. If invoice specified this scid, get nodeid and use that.\n4. ... and refuse to forward the HTLC (it must terminate here).\n\nMy plan is to add an argument to `invoice` which is an array of one or\nmore scids: we get a temporary scids for each peer and use them in the\nroutehints.  We also assign a random temporary nodeid to that invoice.\n\nThe above algo is designed to ensure we behave like any other node which\nhas no idea about this nodeid if Mallory:\n\n1. tries to use a temporary node id on a normal channel to us.\n2. tries to pay another invoice using this temporary node id.\n3. tries to probe our outgoing channels using this routing hint\n   (I think we should probably ban forwarding to private channels,\n   too, for similar reasons).\n\n---\n\nNote that with any self-assigned SCID schemes, Alice has to respond to\nunknown scids in update_add_htlc with some BADONION code (which makes\n*Bob* give Carol an error response, since Alice can't without revealing\nher identity).\n\nWith Bob-assigned SCIDs, Alice simply needs to make him unallocate\nit before forgetting the invoice, so she will simply never see old\ninvoices.\n\n(All these schemes give limited privacy, of course: Bob knows who Alice\nis, and fingerprinting and liveness attacks are always possible).\n\n> I'm extremely nervous about custodial lightning services restricting\n>> what they will pay to.  This is not theoretical: they will come under\n>> immense KYC pressure in the near future, which means they cannot pay\n>> arbitrary invoices.\n1>>\n>\n> That's a very good point, thanks for raising this. However I believe that\n> there are (and will be) enough\n> non-custodial wallets to let motivated users pay whatever they want. Users\n> can even run their own\n> node to pay such invoices if needed.\n\nNot if ln_strike (no, the other one!) is the future.\n\n> If you are using a custodial wallet and KYC pressure kicks in, then\n> regardless of that feature law may\n> require users to completely reveal who they are paying, so even normal\n> payments wouldn't protect\n> them, don't you think? Regulation could for example disallow paying via\n> unannounced channels entirely\n> (or require you to show the funding tx associated to your unannounced\n> channel).\n\nActually, as long as the same method is required for both normal private\nchannels (which will all use non-tx-based short_channel_ids in the near\nfuture I hope!), I don't really mind.  I expect such payments to become\nsignificant, and as long as paying to a temporary id and paying to a\nprivate channel looks identical, it's too draconian to ban.  A business\nwould probably meet any KYC requirements by simply asking the user\n(perhaps over a certain amount, etc).\n\n(I've put my implementation on hold for a moment while I'm supposed to\nbe releasing 0.8.1-rc1 RSN!)\n\nCheers,\nRusty."
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2020-02-11T10:58:14",
                "message_text_only": "Hi Rusty,\n\nThanks for the answer, and good luck with c-lightning 0.8.1-rc1 ;)\n\n(I think we should probably ban forwarding to private channels,\n> too, for similar reasons).\n\n\nCan you detail why? I believe that forwarding through private channels can\nactually be pretty useful in the future for payee privacy (more on that\nlater).\n\nNote that with any self-assigned SCID schemes, Alice has to respond to\n> unknown scids in update_add_htlc with some BADONION code (which makes\n> *Bob* give Carol an error response, since Alice can't without revealing\n> her identity).\n\n\nI believe the difference is that in your scheme, Bob would answer with\n`unknown_next_peer`. When instead Alice responds with a `BADONION`, the only\nthing it reveals is that Alice does use the decoy feature (which Mallory\nalready knows because she has seen an invoice from Alice). As long as this\nbehavior is consistent throughout the network, I think both options offer\nthe\nsame privacy (unless I'm missing something).\n\nI expect such payments to become\n> significant, and as long as paying to a temporary id and paying to a\n> private channel looks identical, it's too draconian to ban.\n\n\nTrue, that must become the default flow for receiving payments on mobile\nwallets.\nGranted, my solution would take longer to deploy because it needs to be\nadded to\nsender wallets before receivers can require it.\n\nI've been thinking more about improving my scheme to not require any sender\nchange, but I don't think that's possible at the moment. As with all\nLightning\ntricks though, once we have Schnorr then it's really easy to do.\nAlice simply needs to use `s * d_a` as her \"preimage\" (and the payment point\nbecomes the P_I Bob needs). That may depend on the exact multi-hop locks\nconstruction we end up using though, so I'm not 100% sure about that yet.\n\nBut I did come up with what could be an interesting development.\nNothing prevents the decoy scheme to be used for public channels too, and\nfor\nmultiple hops: that enables a cheap form of rendezvous that only costs a few\nhundred bytes in the invoice.\n\nAlice would select multiple hops to a rendezvous node, and would apply some\nblinding to those hops' `node_id` and `scid`. Alice would include these\ndecoy\nhops in the invoice `routing_hints` (only costs 51 bytes per hop instead of\na\nfull onion). Mallory would only learn an upper bound on the distance between\nAlice and the rendezvous.\n\nI have a detailed version of the scheme in a gist [1] if people want to\ntake a\ndeeper look and break it (beer on me to the first one who breaks the\nscheme).\n\n[1] https://gist.github.com/t-bast/9972bfe9523bb18395bdedb8dc691faf\n\nCheers,\nBastien\n\nLe lun. 10 f\u00e9vr. 2020 \u00e0 04:40, Rusty Russell <rusty at rustcorp.com.au> a\n\u00e9crit :\n>\n> Bastien TEINTURIER <bastien at acinq.fr> writes:\n> >> But Mallory can do the same attack, I think.  Just include the P_I from\n> >> the wrong invoice for Bob.\n> >\n> > Good catch, that's true, thanks for keeping me honest there! In that\ncase\n> > my proposal\n> > would need the same mitigation as yours, Bob will need to include the\n> > `scid` he received\n> > in `update_add_htlc` (this is in fact not that hard once we allow TLV\n> > extensions on every\n> > message).\n>\n> Yes, I've added this to the PR.  Which gives a new validation path, I\n> think:\n>\n> ## Figuring out what nodeid to use to decode onion\n>\n> 1. Look up scid from HTLC; if it didn't include one, use default.\n> 2. Look up payment_hash; if no invoice is found, use default.\n> 3. If invoice specified this scid, get nodeid and use that.\n> 4. ... and refuse to forward the HTLC (it must terminate here).\n>\n> My plan is to add an argument to `invoice` which is an array of one or\n> more scids: we get a temporary scids for each peer and use them in the\n> routehints.  We also assign a random temporary nodeid to that invoice.\n>\n> The above algo is designed to ensure we behave like any other node which\n> has no idea about this nodeid if Mallory:\n>\n> 1. tries to use a temporary node id on a normal channel to us.\n> 2. tries to pay another invoice using this temporary node id.\n> 3. tries to probe our outgoing channels using this routing hint\n>    (I think we should probably ban forwarding to private channels,\n>    too, for similar reasons).\n>\n> ---\n>\n> Note that with any self-assigned SCID schemes, Alice has to respond to\n> unknown scids in update_add_htlc with some BADONION code (which makes\n> *Bob* give Carol an error response, since Alice can't without revealing\n> her identity).\n>\n> With Bob-assigned SCIDs, Alice simply needs to make him unallocate\n> it before forgetting the invoice, so she will simply never see old\n> invoices.\n>\n> (All these schemes give limited privacy, of course: Bob knows who Alice\n> is, and fingerprinting and liveness attacks are always possible).\n>\n> > I'm extremely nervous about custodial lightning services restricting\n> >> what they will pay to.  This is not theoretical: they will come under\n> >> immense KYC pressure in the near future, which means they cannot pay\n> >> arbitrary invoices.\n> 1>>\n> >\n> > That's a very good point, thanks for raising this. However I believe\nthat\n> > there are (and will be) enough\n> > non-custodial wallets to let motivated users pay whatever they want.\nUsers\n> > can even run their own\n> > node to pay such invoices if needed.\n>\n> Not if ln_strike (no, the other one!) is the future.\n>\n> > If you are using a custodial wallet and KYC pressure kicks in, then\n> > regardless of that feature law may\n> > require users to completely reveal who they are paying, so even normal\n> > payments wouldn't protect\n> > them, don't you think? Regulation could for example disallow paying via\n> > unannounced channels entirely\n> > (or require you to show the funding tx associated to your unannounced\n> > channel).\n>\n> Actually, as long as the same method is required for both normal private\n> channels (which will all use non-tx-based short_channel_ids in the near\n> future I hope!), I don't really mind.  I expect such payments to become\n> significant, and as long as paying to a temporary id and paying to a\n> private channel looks identical, it's too draconian to ban.  A business\n> would probably meet any KYC requirements by simply asking the user\n> (perhaps over a certain amount, etc).\n>\n> (I've put my implementation on hold for a moment while I'm supposed to\n> be releasing 0.8.1-rc1 RSN!)\n>\n> Cheers,\n> Rusty.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200211/41e5aa47/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2020-02-13T04:49:47",
                "message_text_only": "Bastien TEINTURIER <bastien at acinq.fr> writes:\n> Hi Rusty,\n>\n> Thanks for the answer, and good luck with c-lightning 0.8.1-rc1 ;)\n\n... Now -rc2.  I actually had a RL use for lightning (OMG!), and sure\nenough found a bug.\n\n> I've been thinking more about improving my scheme to not require any sender\n> change, but I don't think that's possible at the moment. As with all\n> Lightning\n> tricks though, once we have Schnorr then it's really easy to do.\n> Alice simply needs to use `s * d_a` as her \"preimage\" (and the payment point\n> becomes the P_I Bob needs). That may depend on the exact multi-hop locks\n> construction we end up using though, so I'm not 100% sure about that yet.\n\nI was starting to think this whole thing was of marginal benefit: note\nthat solving \"private channels need a temp scid\" is far simpler[1].\n\nBut since your scheme extends to rendevous, it's much more tempting!\n\nWe would use this for normal private channels as well as private routes\naka new rendezvous.  Even better, this would be a replacement for\ncurrent route hints (which lack ability to specify feature bits, which\nwe would add here, and is also grossly inefficient if you just want to\nuse it for Routeboost[2]).\n\nPropose we take the `z` to use as bolt11 letter, because even the French\ndon't pronounce it in \"rendez-vous\"!)\n\nThen use TLV inside:[3]\n\n* `z` (2): `data_length` variable. One or more entries containing extra\n  routing information; there may be more than one `z` field.  Each entry\n  looks like:\n   * `tlv_len` (8 bits)\n   * `rendezvous_tlv` (tlv_len bytes)\n\n1. tlvs: `rendezvous_tlv`\n2. types:\n   1. type: 1 (`pubkey`)\n   2. data:\n      * [`point`:`nodeid`]\n   1. type: 2 (`short_channel_id`)\n   2. data:\n      * [`short_channel_id`:`short_channel_id`]\n   1. type: 3 (`fee_base_msat`)\n   2. data:\n      * [`tu32`:`fee_base_msat`]\n   1. type: 4 (`fee_proportional_millionths`)\n   2. data:\n      * [`tu32`:`fee_proportional_millionths`]\n   1. type: 5 (`cltv_expiry_delta`)\n   2. data:\n      * [`tu16`:`cltv_expiry_delta`]\n   1. type: 6 (`features`)\n   2. data:\n      * [`...*byte`:`features`]\n\nThat probably adds 6 bytes entry, but worth it I think.\n\nCheers,\nRusty.\n\n[1] Add a new field to 'funding_locked': \"private_scid\".  If both sides\n    support 'option_private_scid' (?) then the \"real\" scid is no longer\n    valid for routing, and we use the private scid.\n\n[2] It's enough to give the scid(s) in this case indicating where you\n    have incoming capacity.\n\n[3] I'm really starting to dislike my bolt11 format.  We should probably\n    start afresh with a TLV-based one, where signature covers the hash\n    of each entry (so they can be easily externalized!), but that's a\n    big, unrelated task."
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2020-02-13T09:44:23",
                "message_text_only": "Hey Rusty and list,\n\nI was starting to think this whole thing was of marginal benefit: note\n> that solving \"private channels need a temp scid\" is far simpler[1].\n\n\nThat's true, the simpler solution does break the on-chain / off-chain link\nbut\nI think we can take this opportunity to also improve payee privacy to make\nsure\ntwo invoices can't leak that they are from the same payee.\n\nEven better, this would be a replacement for current route hints\n\n\nDefinitely, this is clearly a good opportunity to re-work route hints to\nsomething that can fix all the short-comings of current route hints, thanks\nfor\nyour suggestions on that. And if anyone on this list has other fields that\nmay\nbe useful in these new route hints, please do say it.\n\nPropose we take the `z` to use as bolt11 letter, because even the French\n> don't pronounce it in \"rendez-vous\"!)\n\n\nAs long as Z-man didn't want to claim this bolt11 letter for himself or his\npuppet army, that sounds good :).\n\nI'll get started on an implementation, and will start working on a spec PR\nas\nwell. I'm hoping to get more reviews from anyone experienced with both\nlightning and cryptography to verify that the scheme isn't broken. I'm still\noffering beers and cocktails to anyone who cracks it [1]!\n\nThanks!\nBastien\n\n[1] https://twitter.com/realtbast/status/1227233654503505925\n\nLe jeu. 13 f\u00e9vr. 2020 \u00e0 05:49, Rusty Russell <rusty at rustcorp.com.au> a\n\u00e9crit :\n>\n> Bastien TEINTURIER <bastien at acinq.fr> writes:\n> > Hi Rusty,\n> >\n> > Thanks for the answer, and good luck with c-lightning 0.8.1-rc1 ;)\n>\n> ... Now -rc2.  I actually had a RL use for lightning (OMG!), and sure\n> enough found a bug.\n>\n> > I've been thinking more about improving my scheme to not require any\nsender\n> > change, but I don't think that's possible at the moment. As with all\n> > Lightning\n> > tricks though, once we have Schnorr then it's really easy to do.\n> > Alice simply needs to use `s * d_a` as her \"preimage\" (and the payment\npoint\n> > becomes the P_I Bob needs). That may depend on the exact multi-hop locks\n> > construction we end up using though, so I'm not 100% sure about that\nyet.\n>\n> I was starting to think this whole thing was of marginal benefit: note\n> that solving \"private channels need a temp scid\" is far simpler[1].\n>\n> But since your scheme extends to rendevous, it's much more tempting!\n>\n> We would use this for normal private channels as well as private routes\n> aka new rendezvous.  Even better, this would be a replacement for\n> current route hints (which lack ability to specify feature bits, which\n> we would add here, and is also grossly inefficient if you just want to\n> use it for Routeboost[2]).\n>\n> Propose we take the `z` to use as bolt11 letter, because even the French\n> don't pronounce it in \"rendez-vous\"!)\n>\n> Then use TLV inside:[3]\n>\n> * `z` (2): `data_length` variable. One or more entries containing extra\n>   routing information; there may be more than one `z` field.  Each entry\n>   looks like:\n>    * `tlv_len` (8 bits)\n>    * `rendezvous_tlv` (tlv_len bytes)\n>\n> 1. tlvs: `rendezvous_tlv`\n> 2. types:\n>    1. type: 1 (`pubkey`)\n>    2. data:\n>       * [`point`:`nodeid`]\n>    1. type: 2 (`short_channel_id`)\n>    2. data:\n>       * [`short_channel_id`:`short_channel_id`]\n>    1. type: 3 (`fee_base_msat`)\n>    2. data:\n>       * [`tu32`:`fee_base_msat`]\n>    1. type: 4 (`fee_proportional_millionths`)\n>    2. data:\n>       * [`tu32`:`fee_proportional_millionths`]\n>    1. type: 5 (`cltv_expiry_delta`)\n>    2. data:\n>       * [`tu16`:`cltv_expiry_delta`]\n>    1. type: 6 (`features`)\n>    2. data:\n>       * [`...*byte`:`features`]\n>\n> That probably adds 6 bytes entry, but worth it I think.\n>\n> Cheers,\n> Rusty.\n>\n> [1] Add a new field to 'funding_locked': \"private_scid\".  If both sides\n>     support 'option_private_scid' (?) then the \"real\" scid is no longer\n>     valid for routing, and we use the private scid.\n>\n> [2] It's enough to give the scid(s) in this case indicating where you\n>     have incoming capacity.\n>\n> [3] I'm really starting to dislike my bolt11 format.  We should probably\n>     start afresh with a TLV-based one, where signature covers the hash\n>     of each entry (so they can be easily externalized!), but that's a\n>     big, unrelated task.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200213/5939bbb3/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-13T10:43:58",
                "message_text_only": "Good morning t-bast,\n\n> > Propose we take the `z` to use as bolt11 letter, because even the French\n> > don't pronounce it in \"rendez-vous\"!)\n>\n> As long as Z-man didn't want to claim this bolt11 letter for himself or his\n> puppet army, that sounds good :).\n\nThat would be too obvious.\nWhat I *am* claiming is `8` for my own use and for my non-existent army of city-marching robots, because it does not appear in my public alias at all, thus actively misleading surveillors.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2020-02-13T10:45:46",
                "message_text_only": "Damn you're good.\n\nLe jeu. 13 f\u00e9vr. 2020 \u00e0 11:44, ZmnSCPxj <ZmnSCPxj at protonmail.com> a \u00e9crit :\n\n> Good morning t-bast,\n>\n> > > Propose we take the `z` to use as bolt11 letter, because even the\n> French\n> > > don't pronounce it in \"rendez-vous\"!)\n> >\n> > As long as Z-man didn't want to claim this bolt11 letter for himself or\n> his\n> > puppet army, that sounds good :).\n>\n> That would be too obvious.\n> What I *am* claiming is `8` for my own use and for my non-existent army of\n> city-marching robots, because it does not appear in my public alias at all,\n> thus actively misleading surveillors.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200213/dfaa1dea/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-06T02:38:30",
                "message_text_only": "Good morning Rusty,\n\n\n> No, Bob can include the scid he used in the update_add_htlc message, so\n> Alice can check.\n>\n> I'm extremely nervous about custodial lightning services restricting\n> what they will pay to. This is not theoretical: they will come under\n> immense KYC pressure in the near future, which means they cannot pay\n> arbitrary invoices.\n>\n> Thus my preference for a system which doesn't add any requirements on\n> the payer.\n\nThis adds requirements on Bob, so the KYC pressure could transfer to them instead.\nThis might be acceptable though, if the payer and Bob are on separate jurisdictions (i.e. Risk-Sharing), but then if the payer is on a custodial service as well, the custodial service can be pressured to inspect the routing hints of any invoice it is told to pay.\n\nWhich I suppose is the entire point of t-bast email.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Decoy node_ids and short_channel_ids",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "m.a.holden",
                "Bastien TEINTURIER",
                "ZmnSCPxj"
            ],
            "messages_count": 19,
            "total_messages_chars_count": 55758
        }
    },
    {
        "title": "[Lightning-dev] DRAFT: interactive tx construction protocol",
        "thread_messages": [
            {
                "author": "lisa neigut",
                "date": "2020-02-04T23:22:28",
                "message_text_only": "Rusty had some suggestions about how to improve the protocol messages for\nthis, namely adding a serial_id to the inputs and outputs, which can then\nbe reused for deletions.\n\nThe serial id can then also be used as the ordering heuristic for\ntransaction inputs during construction (replacing current usage of BIP69).\nInputs can be shared amongst peers by flipping the bottom bit of the\nserial_id before relaying them to another peer (as your own).\n\nSee below for details.\n\n\n1. type:   440 `tx_add_input`\n>\n> 2. data:\n>\n>     * [`32*byte`:`channel_identifier`]\n>\n        * [`32*byte`:``serial_id`]\n\nAdd a serial id.\n\nEach input addition must have a unique serial id.\n\nNo addition may have a repeated id number.\n\nThe initiator's serial id's must be odd. The non-initiator's serial id's\nmust be even.\nSerial ids are used as sorting heuristic for input ordering in final\ntransaction, replaces BIP69\n\n\n    * [`u64`:`sats`]\n>\n>     * [`sha256`:`prevtx_txid`]\n>\n>     * [`u32`:`prevtx_vout`]\n>\n>     * [`u16`:`prevtx_scriptpubkey_len`]\n>\n>     * [`prevtx_scriptpubkey_len*byte`:`prevtx_scriptpubkey`]\n>\n>     * [`u16`:`max_witness_len`]\n>\n>     * [`u16`:`scriptlen`]\n>\n>     * [`scriptlen*byte`:`script`]\n>\n> Removes the signal_rbf; everything will be flagged as RBF eligible. (This\nmakes verifying RBF eligibility during a RBF round simpler.)\n\n\n> 1. type: 442 `tx_add_output`\n>\n> 2. data:\n>\n>     * [`32*byte`:`channel_identifier`]\n>\n    * [`16*byte`:`serial_id`]\n\nAdd a serial id. Same rules as for inputs, but a distinct counter set is\nused.\nUsed for ordering the transactions\u2019 outputs, replacing BIP69\n\n\n\n>     * [`u64`:`sats`]\n>\n>     * [`u16`:`scriptlen`]\n>\n>     * [`scriptlen*byte`:`script`]\n>\n> 1. type: 444 `tx_remove_input`\n>\n> 2. data:\n>\n>     * [`32*byte`:`channel_identifier`]\n>\n    * [`16*byte`:`serial_id`]\n\n\nInput to remove identified by the serial id, not txid and index.\n\n\n\n>\n> 1. type: 446 `tx_remove_output`\n>\n> 2. data:\n>\n>     * [`32*byte`:`channel_identifier`]\n>\n    * [`16*byte`:`serial_id]\n\nOutput to remove identified by the serial id, not output script and amount.\n\n\n\n> 1. type: 448 `tx_complete`\n>\n> 2. data:\n>\n>     * [`32*byte`:`channel_identifier`]\n>\n\nTotal counts removed from tx_complete. The txid exchanged in the `tx_sigs`\nwill serves as a checksum for the transaction.\n\n\n> 1. type:  448 `tx_sigs`\n>\n> 2. data:\n>\n>     * [`channel_id`:`channel_identifier`]\n>\n>     * [`u16`:`num_witnesses`]\n>\n>     * [`num_witnesses*witness_stack`:`witness_stack`]\n>\n> 1. subtype: `witness_stack`\n>\n> 2. data:\n>\n    * [`u16`:`num_input_witness`]\n>\n>     * [`num_input_witness*witness_element`:`witness_element`]\n>\n\nprev_out and prev_txid are removed; witnesses ordered implicitly by\nserial_id.\n\n\n> 1. subtype: `witness_element`\n>\n> 2. data:\n>\n>     * [`u16`:`len`]\n>\n>     * [`len*byte`:`witness`]\n>\n>\n>\n> ## General Notes\n>\n> - All output scripts must be standard\n>\n> - nLocktime is always set to 0x00000000\n>\n- If a blockheight to be used as nLocktime is communicated in the\ninitiation step, is set to blockheight-6; otherwise set to zero-\n- Serial ids should be chosen at random\n- For multiparty constructions, the initiator MUST flip the bottom bit of\nany received inputs before relaying them to a peer.\n- Collisions of serial ids between peers is a protocol error\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200204/d6136e56/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-06T02:25:32",
                "message_text_only": "Good morning niftynei,\n\n\n> Rusty had some suggestions about how to improve the protocol messages for this, namely adding a serial_id to the inputs and outputs, which can then be reused for deletions.\u00a0\n>\n> The serial id can then also be used as the ordering heuristic for transaction inputs during construction (replacing current usage of BIP69). Inputs can be shared amongst\u00a0peers by flipping the bottom bit of the serial_id before relaying them to another peer (as your own).\n\nWhat happens if the initiator deliberately provides serial IDs 0x1, 0x3, .... while the acceptor naively provides serial IDs from `/dev/urandom`?\n\nThen the balance of probability is that the initiator inputs and outputs are sorted before the acceptor.\nNow, this is probably not an issue, since the initiator and acceptor both know which inputs and outputs are theirs and not theirs, so they could just reveal this information to anyone, so an actor providing such lousy serial IDs is just hurting its own privacy relative to blockchain analysts, so probably will not happen in practice.\n\nMy initial reaction was to propose adding a secret-sharing round where the resulting key is XORed to each serial ID before sorting by the XORed serial ID, but this might be too overweight, and again the initiator is only hurting its own privacy, and the two participants already know whose money is whose anyway....\n\n>\n> See below for details.\n>\n> > 1. type: \u00a0 440 `tx_add_input`\n> >\n> > 2. data:\n> >\n> > \u00a0\u00a0\u00a0\u00a0* [`32*byte`:`channel_identifier`]\n>\n> \u00a0 \u00a0 \u00a0 \u00a0 * [`32*byte`:``serial_id`]\u00a0\n>\n> Add a serial id.\n>\n> Each input addition must have a unique serial id.\n>\n> No addition may have a repeated id number.\n>\n> The initiator's serial id's must be odd. The non-initiator's serial id's must be even.\n>\n> Serial ids are used as sorting heuristic for input ordering in final transaction, replaces BIP69\n> \u00a0\n>\n> > \u00a0\u00a0\u00a0\u00a0* [`u64`:`sats`]\n> >\n> > \u00a0\u00a0\u00a0\u00a0* [`sha256`:`prevtx_txid`]\n> >\n> > \u00a0\u00a0\u00a0\u00a0* [`u32`:`prevtx_vout`]\n> >\n> > \u00a0\u00a0\u00a0\u00a0* [`u16`:`prevtx_scriptpubkey_len`]\n> >\n> > \u00a0\u00a0\u00a0\u00a0* [`prevtx_scriptpubkey_len*byte`:`prevtx_scriptpubkey`]\n> >\n> > \u00a0\u00a0\u00a0\u00a0* [`u16`:`max_witness_len`]\n> >\n> > \u00a0\u00a0\u00a0\u00a0* [`u16`:`scriptlen`]\n> >\n> > \u00a0\u00a0\u00a0\u00a0* [`scriptlen*byte`:`script`]\n>\n> Removes the signal_rbf; everything will be flagged as RBF eligible. (This makes verifying RBF eligibility during a RBF round simpler.)\n\nYes. Ish.\nRBF and privacy do not work well together unfortunately.\nThis is still initiator-pays, right?\n\n\n> > 1. subtype: `witness_element`\n> >\n> > 2. data:\n> >\n> > \u00a0\u00a0\u00a0\u00a0* [`u16`:`len`]\n> >\n> > \u00a0\u00a0\u00a0\u00a0* [`len*byte`:`witness`]\n> >\n> > ## General Notes\n> >\n> > - All output scripts must be standard\n> >\n> > - nLocktime is always set to 0x00000000\n>\n> - If a blockheight to be used as nLocktime is communicated in the initiation step, is set to blockheight-6; otherwise set to zero-\n\nI am unsure what is the purpose of this minus 6.\n\nIf you fear blockheight disagreements, this is probably a good time to introduce block headers.\nSo for example if the acceptor thinks the initiator blockheight is too high, it could challenge the initiator to give block headers from its known blockheight to the initiator blockheight.\nIf the acceptor thinks the initiator blockheight is too low, it could provide block headers itself as proof.\nThis could be limited so that gross differences in blockheight are outright rejected by the acceptor (it could `error` the temporary channel ID rather than accept it).\n\nThis is SPV, but neither side is actually making or accepting a payment *yet*, just synchronizing clocks, so maybe not as bad as normal SPV.\n\nMassive chain reorgs cannot reduce blockheight, only increase it (else the reorg attempt fails in the first place) so there must still exist at least one chain(split) with the highest known blockheight already given a proof-of-header-chain, and all you really need is some mining activity on top of *one* split that confirms your funding transaction.\n\nIf it is not because of blockheight disagreements or massive chain reorgs, what is the purpose of `blockheight - 6`?\n\n\n\n> - Serial ids should be chosen at random\n> - For multiparty constructions, the initiator MUST flip the bottom bit of any received inputs before relaying them to a peer.\n>\n> - Collisions of serial ids between peers is a protocol error\n\nI suppose we should define collision to mean \"equal in all bits except the lowest bit\".\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "lisa neigut",
                "date": "2020-02-06T22:51:24",
                "message_text_only": "> I am unsure what is the purpose of this minus 6.\n\nThe original motivation was to keep the funding transaction from being\nrejected from the mempool in the case of a re-org, but as you pointed out,\nthe 'next block' is always at -par or ahead of the current chain tip, so\nI'm not sure this accomplishes this goal.  I'm not sure how bitcoind\nhandles the mempool in the case of the 'best block' moving to another tip,\nthe goal of setting it to -6 is to avoid the funding transaction being\nevicted.\n\nIn practice, setting the locktime back a few blocks makes the funding\ntransaction eligible for inclusion in any of the previous six blocks, so in\ncase of a reorg there's a higher probability it will have been included in\nthe reorganization. In other words, it enables fee-sniping for up to 6\nblocks in the hopes that any 'eligible' re-org includes the funding\ntransaction (the short channel id will change, but otherwise the channel\nopen will be the same).\n\nOn second thought, this doesn't seem like something that we should include\nat the protocol level; if a peer wanted to 'allow fee-sniping for up to X\nblocks', then they'd simply relay the \"blocktip\" that they're using for the\nnLocktime to be at the depth they'd desire. Though it might be worth\nimposing a limit as to how far back in the past a peer can allow\nfee-sniping for... no more than 6 blocks from our current tip seems\nreasonable. (This would then limit the 'acceptable range' for an offset of\nan initiator to 5, as your peer may be off from your tip by one.)\n\nOn that note, I believe bitcoind fuzzes the nLocktime value to obfuscate\nexactly what blockheight the outgoing transaction was composed / broadcast\nat, which is probably something we should encourage in lightning\nimplementations as well.\n\n\n\nOn Wed, Feb 5, 2020 at 8:25 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning niftynei,\n>\n>\n> > Rusty had some suggestions about how to improve the protocol messages\n> for this, namely adding a serial_id to the inputs and outputs, which can\n> then be reused for deletions.\n> >\n> > The serial id can then also be used as the ordering heuristic for\n> transaction inputs during construction (replacing current usage of BIP69).\n> Inputs can be shared amongst peers by flipping the bottom bit of the\n> serial_id before relaying them to another peer (as your own).\n>\n> What happens if the initiator deliberately provides serial IDs 0x1, 0x3,\n> .... while the acceptor naively provides serial IDs from `/dev/urandom`?\n>\n> Then the balance of probability is that the initiator inputs and outputs\n> are sorted before the acceptor.\n> Now, this is probably not an issue, since the initiator and acceptor both\n> know which inputs and outputs are theirs and not theirs, so they could just\n> reveal this information to anyone, so an actor providing such lousy serial\n> IDs is just hurting its own privacy relative to blockchain analysts, so\n> probably will not happen in practice.\n>\n> My initial reaction was to propose adding a secret-sharing round where the\n> resulting key is XORed to each serial ID before sorting by the XORed serial\n> ID, but this might be too overweight, and again the initiator is only\n> hurting its own privacy, and the two participants already know whose money\n> is whose anyway....\n>\n> >\n> > See below for details.\n> >\n> > > 1. type:   440 `tx_add_input`\n> > >\n> > > 2. data:\n> > >\n> > >     * [`32*byte`:`channel_identifier`]\n> >\n> >         * [`32*byte`:``serial_id`]\n> >\n> > Add a serial id.\n> >\n> > Each input addition must have a unique serial id.\n> >\n> > No addition may have a repeated id number.\n> >\n> > The initiator's serial id's must be odd. The non-initiator's serial id's\n> must be even.\n> >\n> > Serial ids are used as sorting heuristic for input ordering in final\n> transaction, replaces BIP69\n> >\n> >\n> > >     * [`u64`:`sats`]\n> > >\n> > >     * [`sha256`:`prevtx_txid`]\n> > >\n> > >     * [`u32`:`prevtx_vout`]\n> > >\n> > >     * [`u16`:`prevtx_scriptpubkey_len`]\n> > >\n> > >     * [`prevtx_scriptpubkey_len*byte`:`prevtx_scriptpubkey`]\n> > >\n> > >     * [`u16`:`max_witness_len`]\n> > >\n> > >     * [`u16`:`scriptlen`]\n> > >\n> > >     * [`scriptlen*byte`:`script`]\n> >\n> > Removes the signal_rbf; everything will be flagged as RBF eligible.\n> (This makes verifying RBF eligibility during a RBF round simpler.)\n>\n> Yes. Ish.\n> RBF and privacy do not work well together unfortunately.\n> This is still initiator-pays, right?\n>\n>\n> > > 1. subtype: `witness_element`\n> > >\n> > > 2. data:\n> > >\n> > >     * [`u16`:`len`]\n> > >\n> > >     * [`len*byte`:`witness`]\n> > >\n> > > ## General Notes\n> > >\n> > > - All output scripts must be standard\n> > >\n> > > - nLocktime is always set to 0x00000000\n> >\n> > - If a blockheight to be used as nLocktime is communicated in the\n> initiation step, is set to blockheight-6; otherwise set to zero-\n>\n> I am unsure what is the purpose of this minus 6.\n>\n> If you fear blockheight disagreements, this is probably a good time to\n> introduce block headers.\n> So for example if the acceptor thinks the initiator blockheight is too\n> high, it could challenge the initiator to give block headers from its known\n> blockheight to the initiator blockheight.\n> If the acceptor thinks the initiator blockheight is too low, it could\n> provide block headers itself as proof.\n> This could be limited so that gross differences in blockheight are\n> outright rejected by the acceptor (it could `error` the temporary channel\n> ID rather than accept it).\n>\n> This is SPV, but neither side is actually making or accepting a payment\n> *yet*, just synchronizing clocks, so maybe not as bad as normal SPV.\n>\n> Massive chain reorgs cannot reduce blockheight, only increase it (else the\n> reorg attempt fails in the first place) so there must still exist at least\n> one chain(split) with the highest known blockheight already given a\n> proof-of-header-chain, and all you really need is some mining activity on\n> top of *one* split that confirms your funding transaction.\n>\n> If it is not because of blockheight disagreements or massive chain reorgs,\n> what is the purpose of `blockheight - 6`?\n>\n>\n>\n> > - Serial ids should be chosen at random\n> > - For multiparty constructions, the initiator MUST flip the bottom bit\n> of any received inputs before relaying them to a peer.\n> >\n> > - Collisions of serial ids between peers is a protocol error\n>\n> I suppose we should define collision to mean \"equal in all bits except the\n> lowest bit\".\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200206/f7cc9d4e/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-07T00:23:15",
                "message_text_only": "Good morning lisa,\n\n> > I am unsure what is the purpose of this minus 6.\n>\n> The original motivation was to keep the funding transaction from being rejected from the mempool in the case of a re-org, but as you pointed out, the 'next block' is always at -par or ahead of the current chain tip, so I'm not sure this accomplishes this goal.\u00a0 I'm not sure how bitcoind handles the mempool in the case of the 'best block' moving to another tip, the goal of setting it to -6 is to avoid the funding transaction being evicted.\u00a0\n\nMy understanding is that it rewinds the abandoned tip, putting the transactions in those blocks back into its local mempool (which may lead to evictions if the mempool gets full), all the way to the branch-off point, then it re-adds blocks back to the new tip (which can lead to removals from the mempool, if transactions in the block spend the same UTXOs (or *are* the same transactions) as transactions in the mempool).\nThe main effect is that there could be suddenly higher fee pressure for the transactions in the reorged-away blocks (because of possible mempool congestion if the longer chainsplit has fewer transactions per block), but that is why the dual-funding protocol has RBF built-in right?\n\nSetting blockheight - 6 also increases the incentive of potential deliberate reorgers to actually perform a reorg attack, because the transaction you just added is valid for earlier blocks that the reorger wants to rewrite.\nThis is a bad thing, because you want your funding txout to be confirmed, not have parts of global hashpower contemplating reorgs and delaying your confirmations even more.\n\n\n>\n> In practice, setting the locktime back a few blocks makes the funding transaction eligible for inclusion in any of the previous six blocks, so in case of a reorg there's a higher probability it will have been included in the reorganization. In other words, it enables fee-sniping for up to 6 blocks in the hopes that any 'eligible' re-org includes the funding transaction (the short channel id will change, but otherwise the channel open will be the same).\u00a0\n>\n> On second thought, this doesn't seem like something that we should include at the protocol level; if a peer wanted to 'allow fee-sniping for up to X blocks', then they'd simply relay the \"blocktip\" that they're using for the nLocktime to be at the depth they'd desire. Though it might be worth imposing a limit as to how far back in the past a peer can allow fee-sniping for... no more than 6 blocks from our current tip seems reasonable. (This would then limit the 'acceptable range' for an offset of an initiator to 5, as your peer may be off from your tip by one.)\n>\n> On that note, I believe bitcoind fuzzes the nLocktime value to obfuscate exactly what blockheight the outgoing transaction was composed / broadcast at, which is probably something we should encourage in lightning implementations as well.\n\nBut if you impose the blockheight - 6 in the Lightning protocol level, and Lightning succeeds (meaning a substantial fraction of blockchain transactions are Lightning opens) --- then transactions with `nLockTime` equal to the block they are included in minus 5 will be more common than others, and would be a reliable indicator that the transaction is a Lightning channel funding attempt.\nThe fuzzing may not be big enough to cover that, as there is a 10% chance to fuzz and about 1% subsequent chance (total 0.1% chance) that Bitcoin ore will put a transaction at blockheight - 6 (as opposed to the 99 other possibilities: blockheight - 0 to blockheight - 99 inclusive).\nSo once more than 0.1% of onchain transactions are Lightning dual-fundings, an analyst has > 50% chance of correctly betting that a blockheight - 5 transaction (yes, - 5, because a transaction can typically be added only on the next block) is a Lightning funding.\n\n\nYou are better off with blockheight, possibly with SPV-header-chain-proofs if one side or the other thinks the blockheight has changed since one side or the other proposed it.\n\n\nRegards,\nZmnSCPxj\n\n>\n> On Wed, Feb 5, 2020 at 8:25 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n> > Good morning niftynei,\n> >\n> > > Rusty had some suggestions about how to improve the protocol messages for this, namely adding a serial_id to the inputs and outputs, which can then be reused for deletions.\u00a0\n> > >\n> > > The serial id can then also be used as the ordering heuristic for transaction inputs during construction (replacing current usage of BIP69). Inputs can be shared amongst\u00a0peers by flipping the bottom bit of the serial_id before relaying them to another peer (as your own).\n> >\n> > What happens if the initiator deliberately provides serial IDs 0x1, 0x3, .... while the acceptor naively provides serial IDs from `/dev/urandom`?\n> >\n> > Then the balance of probability is that the initiator inputs and outputs are sorted before the acceptor.\n> > Now, this is probably not an issue, since the initiator and acceptor both know which inputs and outputs are theirs and not theirs, so they could just reveal this information to anyone, so an actor providing such lousy serial IDs is just hurting its own privacy relative to blockchain analysts, so probably will not happen in practice.\n> >\n> > My initial reaction was to propose adding a secret-sharing round where the resulting key is XORed to each serial ID before sorting by the XORed serial ID, but this might be too overweight, and again the initiator is only hurting its own privacy, and the two participants already know whose money is whose anyway....\n> >\n> > >\n> > > See below for details.\n> > >\n> > > > 1. type: \u00a0 440 `tx_add_input`\n> > > >\n> > > > 2. data:\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0* [`32*byte`:`channel_identifier`]\n> > >\n> > > \u00a0 \u00a0 \u00a0 \u00a0 * [`32*byte`:``serial_id`]\u00a0\n> > >\n> > > Add a serial id.\n> > >\n> > > Each input addition must have a unique serial id.\n> > >\n> > > No addition may have a repeated id number.\n> > >\n> > > The initiator's serial id's must be odd. The non-initiator's serial id's must be even.\n> > >\n> > > Serial ids are used as sorting heuristic for input ordering in final transaction, replaces BIP69\n> > > \u00a0\n> > >\n> > > > \u00a0\u00a0\u00a0\u00a0* [`u64`:`sats`]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0* [`sha256`:`prevtx_txid`]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0* [`u32`:`prevtx_vout`]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0* [`u16`:`prevtx_scriptpubkey_len`]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0* [`prevtx_scriptpubkey_len*byte`:`prevtx_scriptpubkey`]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0* [`u16`:`max_witness_len`]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0* [`u16`:`scriptlen`]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0* [`scriptlen*byte`:`script`]\n> > >\n> > > Removes the signal_rbf; everything will be flagged as RBF eligible. (This makes verifying RBF eligibility during a RBF round simpler.)\n> >\n> > Yes. Ish.\n> > RBF and privacy do not work well together unfortunately.\n> > This is still initiator-pays, right?\n> >\n> > > > 1. subtype: `witness_element`\n> > > >\n> > > > 2. data:\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0* [`u16`:`len`]\n> > > >\n> > > > \u00a0\u00a0\u00a0\u00a0* [`len*byte`:`witness`]\n> > > >\n> > > > ## General Notes\n> > > >\n> > > > - All output scripts must be standard\n> > > >\n> > > > - nLocktime is always set to 0x00000000\n> > >\n> > > - If a blockheight to be used as nLocktime is communicated in the initiation step, is set to blockheight-6; otherwise set to zero-\n> >\n> > I am unsure what is the purpose of this minus 6.\n> >\n> > If you fear blockheight disagreements, this is probably a good time to introduce block headers.\n> > So for example if the acceptor thinks the initiator blockheight is too high, it could challenge the initiator to give block headers from its known blockheight to the initiator blockheight.\n> > If the acceptor thinks the initiator blockheight is too low, it could provide block headers itself as proof.\n> > This could be limited so that gross differences in blockheight are outright rejected by the acceptor (it could `error` the temporary channel ID rather than accept it).\n> >\n> > This is SPV, but neither side is actually making or accepting a payment *yet*, just synchronizing clocks, so maybe not as bad as normal SPV.\n> >\n> > Massive chain reorgs cannot reduce blockheight, only increase it (else the reorg attempt fails in the first place) so there must still exist at least one chain(split) with the highest known blockheight already given a proof-of-header-chain, and all you really need is some mining activity on top of *one* split that confirms your funding transaction.\n> >\n> > If it is not because of blockheight disagreements or massive chain reorgs, what is the purpose of `blockheight - 6`?\n> >\n> > > - Serial ids should be chosen at random\n> > > - For multiparty constructions, the initiator MUST flip the bottom bit of any received inputs before relaying them to a peer.\n> > >\n> > > - Collisions of serial ids between peers is a protocol error\n> >\n> > I suppose we should define collision to mean \"equal in all bits except the lowest bit\".\n> >\n> > Regards,\n> > ZmnSCPxj"
            },
            {
                "author": "lisa neigut",
                "date": "2020-02-10T21:53:28",
                "message_text_only": "> But if you impose the blockheight - 6 in the Lightning protocol level,\nand Lightning succeeds (meaning a substantial fraction of blockchain\ntransactions are Lightning opens)...\n>  --- then transactions with `nLockTime` equal to the block they are\nincluded in minus 5 will be more common than others, and would be a\nreliable indicator that the transaction is a Lightning channel funding\nattempt.\n\nAh good point. This can be mitigated by setting the acceptable range up to\n100 then, matching the behavior of bitcoind.\n<https://github.com/bitcoin/bitcoin/blob/master/src/wallet/wallet.cpp#L2507-L2544>\n\n\n\n\n\nOn Thu, Feb 6, 2020 at 6:23 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning lisa,\n>\n> > > I am unsure what is the purpose of this minus 6.\n> >\n> > The original motivation was to keep the funding transaction from being\n> rejected from the mempool in the case of a re-org, but as you pointed out,\n> the 'next block' is always at -par or ahead of the current chain tip, so\n> I'm not sure this accomplishes this goal.  I'm not sure how bitcoind\n> handles the mempool in the case of the 'best block' moving to another tip,\n> the goal of setting it to -6 is to avoid the funding transaction being\n> evicted.\n>\n> My understanding is that it rewinds the abandoned tip, putting the\n> transactions in those blocks back into its local mempool (which may lead to\n> evictions if the mempool gets full), all the way to the branch-off point,\n> then it re-adds blocks back to the new tip (which can lead to removals from\n> the mempool, if transactions in the block spend the same UTXOs (or *are*\n> the same transactions) as transactions in the mempool).\n> The main effect is that there could be suddenly higher fee pressure for\n> the transactions in the reorged-away blocks (because of possible mempool\n> congestion if the longer chainsplit has fewer transactions per block), but\n> that is why the dual-funding protocol has RBF built-in right?\n>\n> Setting blockheight - 6 also increases the incentive of potential\n> deliberate reorgers to actually perform a reorg attack, because the\n> transaction you just added is valid for earlier blocks that the reorger\n> wants to rewrite.\n> This is a bad thing, because you want your funding txout to be confirmed,\n> not have parts of global hashpower contemplating reorgs and delaying your\n> confirmations even more.\n>\n>\n> >\n> > In practice, setting the locktime back a few blocks makes the funding\n> transaction eligible for inclusion in any of the previous six blocks, so in\n> case of a reorg there's a higher probability it will have been included in\n> the reorganization. In other words, it enables fee-sniping for up to 6\n> blocks in the hopes that any 'eligible' re-org includes the funding\n> transaction (the short channel id will change, but otherwise the channel\n> open will be the same).\n> >\n> > On second thought, this doesn't seem like something that we should\n> include at the protocol level; if a peer wanted to 'allow fee-sniping for\n> up to X blocks', then they'd simply relay the \"blocktip\" that they're using\n> for the nLocktime to be at the depth they'd desire. Though it might be\n> worth imposing a limit as to how far back in the past a peer can allow\n> fee-sniping for... no more than 6 blocks from our current tip seems\n> reasonable. (This would then limit the 'acceptable range' for an offset of\n> an initiator to 5, as your peer may be off from your tip by one.)\n> >\n> > On that note, I believe bitcoind fuzzes the nLocktime value to obfuscate\n> exactly what blockheight the outgoing transaction was composed / broadcast\n> at, which is probably something we should encourage in lightning\n> implementations as well.\n>\n> But if you impose the blockheight - 6 in the Lightning protocol level, and\n> Lightning succeeds (meaning a substantial fraction of blockchain\n> transactions are Lightning opens) --- then transactions with `nLockTime`\n> equal to the block they are included in minus 5 will be more common than\n> others, and would be a reliable indicator that the transaction is a\n> Lightning channel funding attempt.\n> The fuzzing may not be big enough to cover that, as there is a 10% chance\n> to fuzz and about 1% subsequent chance (total 0.1% chance) that Bitcoin ore\n> will put a transaction at blockheight - 6 (as opposed to the 99 other\n> possibilities: blockheight - 0 to blockheight - 99 inclusive).\n> So once more than 0.1% of onchain transactions are Lightning\n> dual-fundings, an analyst has > 50% chance of correctly betting that a\n> blockheight - 5 transaction (yes, - 5, because a transaction can typically\n> be added only on the next block) is a Lightning funding.\n>\n>\n> You are better off with blockheight, possibly with SPV-header-chain-proofs\n> if one side or the other thinks the blockheight has changed since one side\n> or the other proposed it.\n>\n>\n> Regards,\n> ZmnSCPxj\n>\n> >\n> > On Wed, Feb 5, 2020 at 8:25 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n> >\n> > > Good morning niftynei,\n> > >\n> > > > Rusty had some suggestions about how to improve the protocol\n> messages for this, namely adding a serial_id to the inputs and outputs,\n> which can then be reused for deletions.\n> > > >\n> > > > The serial id can then also be used as the ordering heuristic for\n> transaction inputs during construction (replacing current usage of BIP69).\n> Inputs can be shared amongst peers by flipping the bottom bit of the\n> serial_id before relaying them to another peer (as your own).\n> > >\n> > > What happens if the initiator deliberately provides serial IDs 0x1,\n> 0x3, .... while the acceptor naively provides serial IDs from\n> `/dev/urandom`?\n> > >\n> > > Then the balance of probability is that the initiator inputs and\n> outputs are sorted before the acceptor.\n> > > Now, this is probably not an issue, since the initiator and acceptor\n> both know which inputs and outputs are theirs and not theirs, so they could\n> just reveal this information to anyone, so an actor providing such lousy\n> serial IDs is just hurting its own privacy relative to blockchain analysts,\n> so probably will not happen in practice.\n> > >\n> > > My initial reaction was to propose adding a secret-sharing round where\n> the resulting key is XORed to each serial ID before sorting by the XORed\n> serial ID, but this might be too overweight, and again the initiator is\n> only hurting its own privacy, and the two participants already know whose\n> money is whose anyway....\n> > >\n> > > >\n> > > > See below for details.\n> > > >\n> > > > > 1. type:   440 `tx_add_input`\n> > > > >\n> > > > > 2. data:\n> > > > >\n> > > > >     * [`32*byte`:`channel_identifier`]\n> > > >\n> > > >         * [`32*byte`:``serial_id`]\n> > > >\n> > > > Add a serial id.\n> > > >\n> > > > Each input addition must have a unique serial id.\n> > > >\n> > > > No addition may have a repeated id number.\n> > > >\n> > > > The initiator's serial id's must be odd. The non-initiator's serial\n> id's must be even.\n> > > >\n> > > > Serial ids are used as sorting heuristic for input ordering in final\n> transaction, replaces BIP69\n> > > >\n> > > >\n> > > > >     * [`u64`:`sats`]\n> > > > >\n> > > > >     * [`sha256`:`prevtx_txid`]\n> > > > >\n> > > > >     * [`u32`:`prevtx_vout`]\n> > > > >\n> > > > >     * [`u16`:`prevtx_scriptpubkey_len`]\n> > > > >\n> > > > >     * [`prevtx_scriptpubkey_len*byte`:`prevtx_scriptpubkey`]\n> > > > >\n> > > > >     * [`u16`:`max_witness_len`]\n> > > > >\n> > > > >     * [`u16`:`scriptlen`]\n> > > > >\n> > > > >     * [`scriptlen*byte`:`script`]\n> > > >\n> > > > Removes the signal_rbf; everything will be flagged as RBF eligible.\n> (This makes verifying RBF eligibility during a RBF round simpler.)\n> > >\n> > > Yes. Ish.\n> > > RBF and privacy do not work well together unfortunately.\n> > > This is still initiator-pays, right?\n> > >\n> > > > > 1. subtype: `witness_element`\n> > > > >\n> > > > > 2. data:\n> > > > >\n> > > > >     * [`u16`:`len`]\n> > > > >\n> > > > >     * [`len*byte`:`witness`]\n> > > > >\n> > > > > ## General Notes\n> > > > >\n> > > > > - All output scripts must be standard\n> > > > >\n> > > > > - nLocktime is always set to 0x00000000\n> > > >\n> > > > - If a blockheight to be used as nLocktime is communicated in the\n> initiation step, is set to blockheight-6; otherwise set to zero-\n> > >\n> > > I am unsure what is the purpose of this minus 6.\n> > >\n> > > If you fear blockheight disagreements, this is probably a good time to\n> introduce block headers.\n> > > So for example if the acceptor thinks the initiator blockheight is too\n> high, it could challenge the initiator to give block headers from its known\n> blockheight to the initiator blockheight.\n> > > If the acceptor thinks the initiator blockheight is too low, it could\n> provide block headers itself as proof.\n> > > This could be limited so that gross differences in blockheight are\n> outright rejected by the acceptor (it could `error` the temporary channel\n> ID rather than accept it).\n> > >\n> > > This is SPV, but neither side is actually making or accepting a\n> payment *yet*, just synchronizing clocks, so maybe not as bad as normal SPV.\n> > >\n> > > Massive chain reorgs cannot reduce blockheight, only increase it (else\n> the reorg attempt fails in the first place) so there must still exist at\n> least one chain(split) with the highest known blockheight already given a\n> proof-of-header-chain, and all you really need is some mining activity on\n> top of *one* split that confirms your funding transaction.\n> > >\n> > > If it is not because of blockheight disagreements or massive chain\n> reorgs, what is the purpose of `blockheight - 6`?\n> > >\n> > > > - Serial ids should be chosen at random\n> > > > - For multiparty constructions, the initiator MUST flip the bottom\n> bit of any received inputs before relaying them to a peer.\n> > > >\n> > > > - Collisions of serial ids between peers is a protocol error\n> > >\n> > > I suppose we should define collision to mean \"equal in all bits except\n> the lowest bit\".\n> > >\n> > > Regards,\n> > > ZmnSCPxj\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200210/26f95449/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2020-02-13T05:10:27",
                "message_text_only": "ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> writes:\n> Good morning niftynei,\n>\n>\n>> Rusty had some suggestions about how to improve the protocol messages for this, namely adding a serial_id to the inputs and outputs, which can then be reused for deletions.\u00a0\n>>\n>> The serial id can then also be used as the ordering heuristic for transaction inputs during construction (replacing current usage of BIP69). Inputs can be shared amongst\u00a0peers by flipping the bottom bit of the serial_id before relaying them to another peer (as your own).\n>\n> What happens if the initiator deliberately provides serial IDs 0x1, 0x3, .... while the acceptor naively provides serial IDs from `/dev/urandom`?\n\nThis is a feature, and one you might need to use if you have some\nSIGHASH_SINGLE or other weirdness for one input.\n\n> Then the balance of probability is that the initiator inputs and outputs are sorted before the acceptor.\n> Now, this is probably not an issue, since the initiator and acceptor both know which inputs and outputs are theirs and not theirs, so they could just reveal this information to anyone, so an actor providing such lousy serial IDs is just hurting its own privacy relative to blockchain analysts, so probably will not happen in practice.\n>\n> My initial reaction was to propose adding a secret-sharing round where the resulting key is XORed to each serial ID before sorting by the XORed serial ID, but this might be too overweight, and again the initiator is only hurting its own privacy, and the two participants already know whose money is whose anyway....\n\n>> > - nLocktime is always set to 0x00000000\n>>\n>> - If a blockheight to be used as nLocktime is communicated in the initiation step, is set to blockheight-6; otherwise set to zero-\n>\n> I am unsure what is the purpose of this minus 6.\n>\n> If you fear blockheight disagreements, this is probably a good time to introduce block headers.\n> So for example if the acceptor thinks the initiator blockheight is too high, it could challenge the initiator to give block headers from its known blockheight to the initiator blockheight.\n> If the acceptor thinks the initiator blockheight is too low, it could provide block headers itself as proof.\n> This could be limited so that gross differences in blockheight are outright rejected by the acceptor (it could `error` the temporary channel ID rather than accept it).\n\nYes, I would just have the initiator specify nLocktime directly, just\nlike feerate.  If you don't like it, don't contribute to the tx\nconstruction.\n\n> This is SPV, but neither side is actually making or accepting a payment *yet*, just synchronizing clocks, so maybe not as bad as normal SPV.\n>\n> Massive chain reorgs cannot reduce blockheight, only increase it (else\n> the reorg attempt fails in the first place)\n\nThis is not quite true, due to difficulty adjustments.  It's true in\npractice, however, and not relevant since you'd just have to wait one\nmore block.\n\n>> - Serial ids should be chosen at random\n>> - For multiparty constructions, the initiator MUST flip the bottom bit of any received inputs before relaying them to a peer.\n>>\n>> - Collisions of serial ids between peers is a protocol error\n>\n> I suppose we should define collision to mean \"equal in all bits except the lowest bit\".\n\nNo, literally equal.  i.e. you can only make this error by clashing with\nyourself.\n\nCheers,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-13T06:17:53",
                "message_text_only": "Good morning Rusty, niftynei, and list,\n\n> > > -   Serial ids should be chosen at random\n> > >\n> > > -   For multiparty constructions, the initiator MUST flip the bottom bit of any received inputs before relaying them to a peer.\n> > >\n> > > -   Collisions of serial ids between peers is a protocol error\n> > >\n> >\n> > I suppose we should define collision to mean \"equal in all bits except the lowest bit\".\n>\n> No, literally equal. i.e. you can only make this error by clashing with\n> yourself.\n\nhmm, I thought the entire point of having the low bit was that you could multifund in such a way that the initiator creates multiple channels simultaneously with multiple nodes?\nSo you would have to take the UTXOs of one peer and give it to the other peer claiming it as your own.\nOr something.\n\nWith PoDLE this would not be possible I think, as you would not be able to open the PoDLE commitment with the other node as the target (if we go with the modified PoDLE which also commits to which node an opening is for, to prevent the pouncing venus flytrap attack).\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "lisa neigut",
                "date": "2020-02-13T16:52:55",
                "message_text_only": "> With PoDLE this would not be possible I think, as you would not be able\nto open the PoDLE commitment with the other node as the target (if we go\nwith the modified PoDLE which also commits to which node an opening is for,\nto prevent the pouncing venus flytrap attack).\n\nGood question. It should be possible to do multi-channel open even with the\nPoDLE signature committing to a node_id.\n\n- An initiator can use the same utxo (h2) as their proof for multiple\npeers; the signatures passed to each peer will have to commit to that\nspecific peer's node_id, however.\n- The revised PoDLE signature commitment requires every initiator to\ninclude at least one of their own inputs in the tx. Attempting to initiate\nan additional open etc using someone else's utxo's won't work (this is the\npouncing venus flytrap attack which we're preventing). The initiator\nincluding at least one input is expected behavior, at least in the open\ncase, since the opener has to cover the fees for the funding output.\n- Ideally, a node would remove the PoDLE TLV data from any 'forwarded'\n`tx_add_inputs` that isn't the input they're proving for, to prevent\nleaking information about which inputs belong to other parties. I say\nideally here because even if you fail to do this, the peer can iterate\nthrough all the provided commitment proofs until one of them\nmatches/verifies with the upfront provided PoDLE.\n\n\n\nOn Thu, Feb 13, 2020 at 12:18 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Rusty, niftynei, and list,\n>\n> > > > -   Serial ids should be chosen at random\n> > > >\n> > > > -   For multiparty constructions, the initiator MUST flip the bottom\n> bit of any received inputs before relaying them to a peer.\n> > > >\n> > > > -   Collisions of serial ids between peers is a protocol error\n> > > >\n> > >\n> > > I suppose we should define collision to mean \"equal in all bits except\n> the lowest bit\".\n> >\n> > No, literally equal. i.e. you can only make this error by clashing with\n> > yourself.\n>\n> hmm, I thought the entire point of having the low bit was that you could\n> multifund in such a way that the initiator creates multiple channels\n> simultaneously with multiple nodes?\n> So you would have to take the UTXOs of one peer and give it to the other\n> peer claiming it as your own.\n> Or something.\n>\n> With PoDLE this would not be possible I think, as you would not be able to\n> open the PoDLE commitment with the other node as the target (if we go with\n> the modified PoDLE which also commits to which node an opening is for, to\n> prevent the pouncing venus flytrap attack).\n>\n> Regards,\n> ZmnSCPxj\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200213/b925f71c/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2020-02-20T09:50:32",
                "message_text_only": "lisa neigut <niftynei at gmail.com> writes:\n>> With PoDLE this would not be possible I think, as you would not be able\n> to open the PoDLE commitment with the other node as the target (if we go\n> with the modified PoDLE which also commits to which node an opening is for,\n> to prevent the pouncing venus flytrap attack).\n>\n> Good question. It should be possible to do multi-channel open even with the\n> PoDLE signature committing to a node_id.\n>\n> - An initiator can use the same utxo (h2) as their proof for multiple\n> peers; the signatures passed to each peer will have to commit to that\n> specific peer's node_id, however.\n> - The revised PoDLE signature commitment requires every initiator to\n> include at least one of their own inputs in the tx. Attempting to initiate\n> an additional open etc using someone else's utxo's won't work (this is the\n> pouncing venus flytrap attack which we're preventing). The initiator\n> including at least one input is expected behavior, at least in the open\n> case, since the opener has to cover the fees for the funding output.\n> - Ideally, a node would remove the PoDLE TLV data from any 'forwarded'\n> `tx_add_inputs` that isn't the input they're proving for, to prevent\n> leaking information about which inputs belong to other parties. I say\n> ideally here because even if you fail to do this, the peer can iterate\n> through all the provided commitment proofs until one of them\n> matches/verifies with the upfront provided PoDLE.\n\nYes, you need to PoDLE your own contribution I think, which means you\nneed one UTXO per contributor in the N-way-open who you want to\ncontribute a UTXO.\n\nConsider Alice trying to create a single-tx to open a channel with both\nBob and Carol, and wants *both* of them to also contribute.\n\nAlice sends her own UTXO1 with proof to Bob, he shares his UTXO back.\nAlice sends her own UTXO2 with proof to Carol, she shares a UTXO back.\nAlice sets the lower bit on the serial_id from Bob and sends to Carol,\nand sets the lower on the serial_id from Carol and sends to Bob.  She\nsimilarly reflects everything from Carol to Bob and vice-versa, and\nsends both of them the two \"channel opening\" outputs.\n\nNow all parties have the same tx; unless Bob and Carol chose the same\nserial_ids (spec says random, but Bob and Carol don't get along).  But\nthis is trivially identifiable, and you give up on mutual opening.\n\nCheers,\nRusty."
            },
            {
                "author": "lisa neigut",
                "date": "2020-02-10T23:11:54",
                "message_text_only": "Here's some thoughts I had on PoDLE's and lightning. An enormous\ntip-of-the-hat is due to ZmnSCPxj for surfacing the work that JoinMarket\nhas done here already.\n\n- The initiating message (in the case of open channel, this would be\n`open_channel2`) is extended to include an 'H2' field in its TLV, a 32-byte\nhash commitment to the P2 key.\n- Only one H2 commitment is required.\n- The `tx_add_input` message, as specified previously, is extended to an\ninclude a TLV type. This must be present on the input addition that\ncorresponds with the UTXO used for the originally transmitted commitment\n- The non-initiator SHOULD wait to send any `tx_add_input` messages of\ntheir own until after receiving a `tx_add_input` message with a valid PoDLE\nTLV extension.\n\n1. tlvs: `add_input_tlvs`\n2. types:\n    1. type: 1 (`proof_of_dle`)\n    2. data:\n        *[`64*byte`:`s||e`]\n        *[`33*byte`:pubkey`]\n        *[`33*byte`:pubkey2`]\n\n- If the proof is incorrect, the non-initiator MAY fail the transaction\ncollaboration or respond with `tx_complete`. There is no need for them to\npublish the PoDLE.\n- If the proof is correct, the non-initiator verifies that the commitment\n(hash of pubkey2) has not been communicated to them via gossip.\n- If the proof is not in their gossip store, the transaction collaboration\ncontinues. It is considered 'safe' for the non-initiator to send\n`tx_add_input` to their peer.\n- If the proof IS in their gossip store, the transaction collaboration\nSHOULD reply with `tx_complete`. It is considered 'unsafe' for the\nnon-initiator to send `tx_add_input`. (This allows errored/erroring\ninitiators to use blacklisted utxos, however it prevents them from privy to\nany other nodes' UTXO set.)\n- The initiator MUST NOT remove the committed to UTXO from the\ncollaboration set.\n\n- If the transaction collaboration fails/is errored by the initiator,\n    - the non-initiator SHOULD broadcast the original PoDLE commitment to\nthe gossip network.\n    - the non-initiator MAY delay broadcast to allow the initiating node to\nre-attempt the open.\n\nThe gossip message for a PoDLE blacklist entry is as follows:\n\n1. type: 259 (`podle_blacklist`)\n2. data:\n    *[`signature`:`signature`]\n    *[`32*byte`:`H2`]\n    *[`point`:`node_id`]\n    *[`u32`:`timestamp`]\n\nNote that the `node_id` is the id of the node that signs (and broadcasts)\nthe blacklisted PoDLE. h/t to ZmnSCPxj for the gossip construction.\nThe timestamp is added as a convenience for peers to trim/discard blacklist\nparticipants as they wish depending on time/staleness.\n\n## Some Notes:\n- The JoinMarket protocol allows nodes to use any of a range of secondary\npoints for J. Since the lightning version of this allows blacklisted UTXOs\nto still open channels, albeit without participation from the peer, it\nseems unnecessary to allow for more than one valid J point. I'd propose\nfixing the J the same zero-index point used by JoinMarket. This reduces the\nnumber of valid H2's that are available for any given utxo set, while also\nkeeping blacklisted H2's compatible with the blacklist set generated by\nJoinMarket implementations.\n- The blacklist originates from the 'non-initiating' peer, and does not\nreveal the offending node's id.\n- Assuming that every node honestly participates in the blacklist, only\nverified H2's will be submitted to the blacklist\n- A malicious non-initiator can only prevent an honest initiator from using\nthe committed UTXO for collaborative transactions; they won't prevent them\nfrom successfully initiating a one-sided transaction with honest peers.\n- Only nodes that have at least one public channel will be able to\ncontribute to the public PoDLE blacklist. This means it's possible for a\nmalicious initiator to grief non-public nodes without much consequence,\nhowever this requires the ability to send inbound messages to private\nnodes, i.e. more likely for a close or splice interaction.\n- As ZmnSCPxj has pointed out elsewhere, a malicious peer could broadcast\njunk H2's; it is acceptable to rate-limit the number of PoDLE blacklists\ngenerated by a peer.peer\n- It is possible for a malicious peer to fail to relay their `H2` entries\nin the blacklisted gossip set.\n- Duplicate H2 gossip should replace older timestamped versions.\n- Elsewhere we've had a discussion/concern over floods of PoDLE blacklist\nmessages. It's possible for gossip message floods to originate from a\nmalicious peer; they also might signal an ongoing probe attempt. Given a\ntimestamp and a rough measure of the number of utxos' currently outstanding\nin the mempool, however, it should be possible to distinguish the two.\n\n## Open Questions:\n- Should PoDLE be required for every collaborative transaction (opens,\nsplices + closes), or only for opens? It seems reasonable to limit them\njust to opens, as for all others you'll already have a shared UTXO with the\npeer.\n- Is fixing the generator point too restrictive? JoinMarket allows for a\nrange of acceptable NUMS (J) points (up to 256). The smaller the pool of\neligible J's, the smaller the pool of potential blacklisted PoDLE's (up to\nno. NUMs * current utxo count). One upside to allowing a larger pool of J's\nmeans that the same UTXO can be retried on failure. One downside to\nallowing a pool of J's means that a single UTXO can be validly retried in a\nprobe attack against a variety of peers.\n\nOn Thu, Jan 30, 2020 at 5:32 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning darosior, ariard, niftynei, and list,\n>\n> > We could also consider PoDLE as used in JoinMarket, which solves a\n> similar problem.\n> >\n> https://gist.github.com/AdamISZ/9cbba5e9408d23813ca8#defence-2-committing-to-a-utxo-in-publicplaintext-at-the-start-of-the-handshake\n> > Basically, a PoDLE commits to a UTXO, without being trivially grindable\n> from the UTXO set and also including a proof that the creator of the PoDLE\n> knows the secret key behind it.\n> > It can later be opened to reveal which UTXO the opener allocated.\n> > If the opener aborts (i.e. does not provide its signatures to the\n> funding transaction) then the acceptor can gossip the UTXO and the revealed\n> PoDLE as well to the rest of Lightning, so that the opener at least cannot\n> reuse the same UTXO to probe other potential acceptors.\n> > (though, my understanding, there is no clear way to determine when we\n> can safely delete old PoDLEs: maybe each node can keep it around for a\n> month, which might be good enough to limit the practical ability of a snoop\n> to probe other nodes)\n> > I believe JoinMarket also has solved the issue of allowing a UTXO to be\n> used at most N times (for example due to \"honest\" failures, such as\n> connectivity interruptions which might cause an abort of the protocol); I\n> think it involves appending a single byte to something that is hashed, and\n> ensuring its value is less than N, so that it can only be used from 0 to N\n> - 1 (and thus allow a UTXO to be used at most N times).\n> >\n> > Getting into contact with waxwing / Adam Gibson for this might be useful\n> to fill out how PoDLE works and so on; basically, I believe this issue is a\n> practically solved problem already for JoinMarket, though waxwing may be\n> able to provide a more nuanced opinion.\n>\n> I communicated with waxwing, and he said:\n>\n> * See also: https://joinmarket.me/blog/blog/poodle \\[sic\\].\n> * The counter I mentioned is implemented using the second generator point.\n>   * The PoDLE construction requires the standard base point `G`, and\n> another generator point `J`.\n>   * To create the generator point `J`, JoinMarket appends the counter byte\n> (the one used to limit N number of uses of the same UTXO) to `G`, hashes\n> it, then uses a coerce-to-point.\n> * PoDLE is sometimes called DLEQ elsewhere.\n> * There is no concrete answer on \"when to delete old PoDLE\"; JoinMarket\n> never deletes (though they might if throughput increases).\n> * Watermarks like `nLockTime`, `nSequence`, `nVersion` are currently fixed\n> values; JoinMarket sees no reason to change this since equal-valued\n> CoinJoins are otherwise obvious to chain analysis anyway.\n>   * But note: JoinMarket implements PayJoin, which is not otherwise\n> obvious onchain, and does indeed do anti-fee-sniping emulation for PayJoin.\n>   * JoinMarket also strives to make similar feerates across users.\n>\n> In any case, for myself, my thoughts are:\n>\n> * I observe that our use-case is quite similar to a PayJoin:\n>   * The opener proposes to make a payment (to a channel between the opener\n> and the acceptor, rather than outright giving control to the acceptor as in\n> PayJoin).\n>   * The acceptor adds some UTXOs which will contribute to the payment\n> output (i.e. the channel).\n>   * This probably does mean we want to later consider `nLockTime`\n> anti-fee-sniping as well in multi-funded channel opens.\n> * Speaking of multi-funded channel opens, it seems to me this interactive\n> tx construction mechanism as well can be later used for channel factories.\n>   * Similarly, PoDLE techniques would be useful as well to multi-funded\n> channel factories.\n> * It would probably be a good idea to share PoDLE format with JoinMarket\n> so we can share PoDLE with them (there could be bridges that share PoDLE\n> between a JoinMarket maker and a Lightning node, and each network already\n> has its own gossip protocols, so LN just needs a gossip protocol for\n> sharing PoDLEs as well).\n> * Probably we can mandate in some BOLT spec to retain PoDLE for at least a\n> year or a month or two weeks or so, which should be enough to slow down\n> probe attempts.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200210/047f7af7/attachment.html>"
            },
            {
                "author": "lisa neigut",
                "date": "2020-02-10T23:43:41",
                "message_text_only": "I'd like to propose that we add a second commitment requirement to the\nPoDLE that JoinMarket uses, to limit the use of a commitment's validity to\nbe only between an initiator and a single peer. Otherwise you can enable\nsomething I'll call the \"pouncing venus-flytrap attack\"[1].  Venus-flytrap\nbecause they sit in wait for victims; pouncing because the venus-flytrap\nthen attacks other nodes using the provided fly/utxo bait.\n\n## The Attack\nA malicious node sits and waits until another, honest, node initiates an\nopen with them. They wait until the honest initiator has sent them the\ncommitment and utxo proof. They then use the provided, non-blacklisted utxo\nand commitment proof to attempt to open a channel with as many other nodes\nas possible, simultaneously. They may either fail to respond or not fail\nthe original channel open. They fail every other open attempt,\nsimultaneously. Each of the nodes they've griefed will blacklist the\nprovided UTXO; the honest initiator has now had their utxo blacklisted.\n\n## Mitigation\nHave each initiator provide two commitments: one to the shared/global J\npoint and one to a point that is found from the hash of the non-initiating\nnode's node_id.[2]\n\nThe global-point commitment is the one that is blacklisted; the node_id's\ncommitment prevents the other party from being able to re-use a commitment\nin another channel, as they'll be unable to produce a valid commitment to\nthe point derived from the node_id of their victim (so the victim will know\nthe commitment has been re-used).\n\nThis has implications for 'multi-channel opens', in that any node\ninitiating an open MUST provide at least one utxo of their own. This seems\nlike an acceptable limitation, imo.\n\nThe protocol adjustments required for this are :\n\n- Add a second commitment to the TLV of `open_channel2`; two H2's, one for\nthe 'global J' and one for the 'nodes J', with the global point commitment\nalways appearing first.\n- The TLV type for the `tx_add_input` for the 'committed utxo' will now\ninclude an array of two `proof of dle's`, in commitment hash order.\n\n1. tlvs: `add_input_tlvs`\n2. types:\n    1. type: 1 (`proof_of_dle_array`)\n    2. data:\n        *[`2*proof_of_dle`]\n\n1. subtype (`proof_of_dle`)\n        *[`64*byte`:`s||e`]\n        *[`33*byte`:pubkey`]\n        *[`33*byte`:pubkey2`]\n\nA node that provides a valid global point but an invalid 'local point'\ncommitment should be immediately errored on and potentially blacklisted.\nA failure of this type should *not* result in a blacklist of the global\ncommitment.\n\n[1] There's probably a better analogy here, but it's escaping me at the\nmoment.\n[2] We reuse JoinMarket's NUMs point generation idea of appending a counter\nto a hash until a valid positive-public key point is found, but without the\nindex.\n\nOn Mon, Feb 10, 2020 at 5:11 PM lisa neigut <niftynei at gmail.com> wrote:\n\n> Here's some thoughts I had on PoDLE's and lightning. An enormous\n> tip-of-the-hat is due to ZmnSCPxj for surfacing the work that JoinMarket\n> has done here already.\n>\n> - The initiating message (in the case of open channel, this would be\n> `open_channel2`) is extended to include an 'H2' field in its TLV, a 32-byte\n> hash commitment to the P2 key.\n> - Only one H2 commitment is required.\n> - The `tx_add_input` message, as specified previously, is extended to an\n> include a TLV type. This must be present on the input addition that\n> corresponds with the UTXO used for the originally transmitted commitment\n> - The non-initiator SHOULD wait to send any `tx_add_input` messages of\n> their own until after receiving a `tx_add_input` message with a valid PoDLE\n> TLV extension.\n>\n> 1. tlvs: `add_input_tlvs`\n> 2. types:\n>     1. type: 1 (`proof_of_dle`)\n>     2. data:\n>         *[`64*byte`:`s||e`]\n>         *[`33*byte`:pubkey`]\n>         *[`33*byte`:pubkey2`]\n>\n> - If the proof is incorrect, the non-initiator MAY fail the transaction\n> collaboration or respond with `tx_complete`. There is no need for them to\n> publish the PoDLE.\n> - If the proof is correct, the non-initiator verifies that the commitment\n> (hash of pubkey2) has not been communicated to them via gossip.\n> - If the proof is not in their gossip store, the transaction collaboration\n> continues. It is considered 'safe' for the non-initiator to send\n> `tx_add_input` to their peer.\n> - If the proof IS in their gossip store, the transaction collaboration\n> SHOULD reply with `tx_complete`. It is considered 'unsafe' for the\n> non-initiator to send `tx_add_input`. (This allows errored/erroring\n> initiators to use blacklisted utxos, however it prevents them from privy to\n> any other nodes' UTXO set.)\n> - The initiator MUST NOT remove the committed to UTXO from the\n> collaboration set.\n>\n> - If the transaction collaboration fails/is errored by the initiator,\n>     - the non-initiator SHOULD broadcast the original PoDLE commitment to\n> the gossip network.\n>     - the non-initiator MAY delay broadcast to allow the initiating node\n> to re-attempt the open.\n>\n> The gossip message for a PoDLE blacklist entry is as follows:\n>\n> 1. type: 259 (`podle_blacklist`)\n> 2. data:\n>     *[`signature`:`signature`]\n>     *[`32*byte`:`H2`]\n>     *[`point`:`node_id`]\n>     *[`u32`:`timestamp`]\n>\n> Note that the `node_id` is the id of the node that signs (and broadcasts)\n> the blacklisted PoDLE. h/t to ZmnSCPxj for the gossip construction.\n> The timestamp is added as a convenience for peers to trim/discard\n> blacklist participants as they wish depending on time/staleness.\n>\n> ## Some Notes:\n> - The JoinMarket protocol allows nodes to use any of a range of secondary\n> points for J. Since the lightning version of this allows blacklisted UTXOs\n> to still open channels, albeit without participation from the peer, it\n> seems unnecessary to allow for more than one valid J point. I'd propose\n> fixing the J the same zero-index point used by JoinMarket. This reduces the\n> number of valid H2's that are available for any given utxo set, while also\n> keeping blacklisted H2's compatible with the blacklist set generated by\n> JoinMarket implementations.\n> - The blacklist originates from the 'non-initiating' peer, and does not\n> reveal the offending node's id.\n> - Assuming that every node honestly participates in the blacklist, only\n> verified H2's will be submitted to the blacklist\n> - A malicious non-initiator can only prevent an honest initiator from\n> using the committed UTXO for collaborative transactions; they won't prevent\n> them from successfully initiating a one-sided transaction with honest peers.\n> - Only nodes that have at least one public channel will be able to\n> contribute to the public PoDLE blacklist. This means it's possible for a\n> malicious initiator to grief non-public nodes without much consequence,\n> however this requires the ability to send inbound messages to private\n> nodes, i.e. more likely for a close or splice interaction.\n> - As ZmnSCPxj has pointed out elsewhere, a malicious peer could broadcast\n> junk H2's; it is acceptable to rate-limit the number of PoDLE blacklists\n> generated by a peer.peer\n> - It is possible for a malicious peer to fail to relay their `H2` entries\n> in the blacklisted gossip set.\n> - Duplicate H2 gossip should replace older timestamped versions.\n> - Elsewhere we've had a discussion/concern over floods of PoDLE blacklist\n> messages. It's possible for gossip message floods to originate from a\n> malicious peer; they also might signal an ongoing probe attempt. Given a\n> timestamp and a rough measure of the number of utxos' currently outstanding\n> in the mempool, however, it should be possible to distinguish the two.\n>\n> ## Open Questions:\n> - Should PoDLE be required for every collaborative transaction (opens,\n> splices + closes), or only for opens? It seems reasonable to limit them\n> just to opens, as for all others you'll already have a shared UTXO with the\n> peer.\n> - Is fixing the generator point too restrictive? JoinMarket allows for a\n> range of acceptable NUMS (J) points (up to 256). The smaller the pool of\n> eligible J's, the smaller the pool of potential blacklisted PoDLE's (up to\n> no. NUMs * current utxo count). One upside to allowing a larger pool of J's\n> means that the same UTXO can be retried on failure. One downside to\n> allowing a pool of J's means that a single UTXO can be validly retried in a\n> probe attack against a variety of peers.\n>\n> On Thu, Jan 30, 2020 at 5:32 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n>> Good morning darosior, ariard, niftynei, and list,\n>>\n>> > We could also consider PoDLE as used in JoinMarket, which solves a\n>> similar problem.\n>> >\n>> https://gist.github.com/AdamISZ/9cbba5e9408d23813ca8#defence-2-committing-to-a-utxo-in-publicplaintext-at-the-start-of-the-handshake\n>> > Basically, a PoDLE commits to a UTXO, without being trivially grindable\n>> from the UTXO set and also including a proof that the creator of the PoDLE\n>> knows the secret key behind it.\n>> > It can later be opened to reveal which UTXO the opener allocated.\n>> > If the opener aborts (i.e. does not provide its signatures to the\n>> funding transaction) then the acceptor can gossip the UTXO and the revealed\n>> PoDLE as well to the rest of Lightning, so that the opener at least cannot\n>> reuse the same UTXO to probe other potential acceptors.\n>> > (though, my understanding, there is no clear way to determine when we\n>> can safely delete old PoDLEs: maybe each node can keep it around for a\n>> month, which might be good enough to limit the practical ability of a snoop\n>> to probe other nodes)\n>> > I believe JoinMarket also has solved the issue of allowing a UTXO to be\n>> used at most N times (for example due to \"honest\" failures, such as\n>> connectivity interruptions which might cause an abort of the protocol); I\n>> think it involves appending a single byte to something that is hashed, and\n>> ensuring its value is less than N, so that it can only be used from 0 to N\n>> - 1 (and thus allow a UTXO to be used at most N times).\n>> >\n>> > Getting into contact with waxwing / Adam Gibson for this might be\n>> useful to fill out how PoDLE works and so on; basically, I believe this\n>> issue is a practically solved problem already for JoinMarket, though\n>> waxwing may be able to provide a more nuanced opinion.\n>>\n>> I communicated with waxwing, and he said:\n>>\n>> * See also: https://joinmarket.me/blog/blog/poodle \\[sic\\].\n>> * The counter I mentioned is implemented using the second generator point.\n>>   * The PoDLE construction requires the standard base point `G`, and\n>> another generator point `J`.\n>>   * To create the generator point `J`, JoinMarket appends the counter\n>> byte (the one used to limit N number of uses of the same UTXO) to `G`,\n>> hashes it, then uses a coerce-to-point.\n>> * PoDLE is sometimes called DLEQ elsewhere.\n>> * There is no concrete answer on \"when to delete old PoDLE\"; JoinMarket\n>> never deletes (though they might if throughput increases).\n>> * Watermarks like `nLockTime`, `nSequence`, `nVersion` are currently\n>> fixed values; JoinMarket sees no reason to change this since equal-valued\n>> CoinJoins are otherwise obvious to chain analysis anyway.\n>>   * But note: JoinMarket implements PayJoin, which is not otherwise\n>> obvious onchain, and does indeed do anti-fee-sniping emulation for PayJoin.\n>>   * JoinMarket also strives to make similar feerates across users.\n>>\n>> In any case, for myself, my thoughts are:\n>>\n>> * I observe that our use-case is quite similar to a PayJoin:\n>>   * The opener proposes to make a payment (to a channel between the\n>> opener and the acceptor, rather than outright giving control to the\n>> acceptor as in PayJoin).\n>>   * The acceptor adds some UTXOs which will contribute to the payment\n>> output (i.e. the channel).\n>>   * This probably does mean we want to later consider `nLockTime`\n>> anti-fee-sniping as well in multi-funded channel opens.\n>> * Speaking of multi-funded channel opens, it seems to me this interactive\n>> tx construction mechanism as well can be later used for channel factories.\n>>   * Similarly, PoDLE techniques would be useful as well to multi-funded\n>> channel factories.\n>> * It would probably be a good idea to share PoDLE format with JoinMarket\n>> so we can share PoDLE with them (there could be bridges that share PoDLE\n>> between a JoinMarket maker and a Lightning node, and each network already\n>> has its own gossip protocols, so LN just needs a gossip protocol for\n>> sharing PoDLEs as well).\n>> * Probably we can mandate in some BOLT spec to retain PoDLE for at least\n>> a year or a month or two weeks or so, which should be enough to slow down\n>> probe attempts.\n>>\n>> Regards,\n>> ZmnSCPxj\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200210/f584936f/attachment-0001.html>"
            },
            {
                "author": "darosior",
                "date": "2020-02-11T10:48:34",
                "message_text_only": "Hi niftynei and list,\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nLe mardi, f\u00e9vrier 11, 2020 12:11 AM, lisa neigut <niftynei at gmail.com> a \u00e9crit\u00a0:\n\n> Here's some thoughts I had on PoDLE's and lightning. An enormous tip-of-the-hat is due to ZmnSCPxj for surfacing the work that JoinMarket has done here already.\n> \n\n> - The initiating\u00a0message (in the case of open channel, this would be `open_channel2`) is extended to include an 'H2' field in its TLV, a 32-byte hash commitment to the P2 key.\n> - Only one H2 commitment is required.\n> - The `tx_add_input` message, as specified previously, is extended to an include a TLV type. This must be present on the input addition that corresponds with the UTXO used for the originally transmitted commitment\n> - The non-initiator SHOULD wait to send any `tx_add_input` messages of their own until after receiving a `tx_add_input` message with a valid PoDLE TLV extension.\n> \n\n> 1. tlvs: `add_input_tlvs`\n> 2. types:\n> \u00a0 \u00a0 1. type: 1 (`proof_of_dle`)\n> \u00a0 \u00a0 2. data:\n> \u00a0 \u00a0 \u00a0 \u00a0 *[`64*byte`:`s||e`]\n> \u00a0 \u00a0 \u00a0 \u00a0 *[`33*byte`:pubkey`]\n> \u00a0 \u00a0 \u00a0 \u00a0 *[`33*byte`:pubkey2`]\n> \n\n> - If the proof is incorrect, the non-initiator MAY fail the transaction collaboration or respond with `tx_complete`. There is no need for them to publish the PoDLE.\n> - If the proof is correct, the non-initiator verifies that the commitment (hash of pubkey2) has not been communicated to them via gossip.\n> - If the proof is not in their gossip store, the transaction collaboration continues. It is considered 'safe' for the non-initiator to send `tx_add_input` to their peer.\n> - If the proof IS in their gossip store, the transaction collaboration SHOULD reply with `tx_complete`. It is considered 'unsafe' for the non-initiator to send `tx_add_input`. (This allows errored/erroring initiators to use blacklisted utxos, however it prevents them from privy to any other nodes' UTXO set.)\n\nWe could agree on an acceptable number of reuse in case on a non-malicious failure from the initiator after a valid PoDLE exchange ? (credits ZmnSCPxj)\n\n> - The initiator MUST NOT remove the committed to UTXO from the collaboration set.\n> \n\n> - If the transaction collaboration fails/is errored by the initiator,\n> \u00a0 \u00a0 - the non-initiator SHOULD broadcast the original PoDLE commitment to the gossip network.\n> \u00a0 \u00a0 - the non-initiator MAY delay broadcast to allow the initiating node to re-attempt the open.\n> \n\n> The gossip message for a PoDLE blacklist entry is as follows:\n> \n\n> 1. type: 259 (`podle_blacklist`)\n> 2. data:\u00a0\n> \u00a0 \u00a0 *[`signature`:`signature`]\n> \u00a0 \u00a0 *[`32*byte`:`H2`]\n> \u00a0 \u00a0 *[`point`:`node_id`]\n> \u00a0 \u00a0 *[`u32`:`timestamp`]\n> \n\n> Note that the `node_id` is the id of the node that signs (and broadcasts) the blacklisted PoDLE. h/t to ZmnSCPxj for the gossip construction.\n> The timestamp is added as a convenience for peers to trim/discard blacklist participants as they wish depending on time/staleness.\n> \n\n> ## Some Notes:\n> - The JoinMarket protocol allows nodes to use any of a range of secondary points for J. Since the lightning version of this allows blacklisted UTXOs to still open channels, albeit without participation from the peer, it seems unnecessary to allow for more than one valid J point. I'd propose fixing the J the same zero-index point used by JoinMarket. This reduces the number of valid H2's that are available for any given utxo set, while also keeping blacklisted H2's compatible with the blacklist set generated by JoinMarket implementations.\n> - The blacklist originates from the 'non-initiating' peer, and does not reveal the offending node's id.\u00a0\n> - Assuming that every node honestly participates in the blacklist, only verified H2's will be submitted to the blacklist\n> - A malicious non-initiator can only prevent an honest initiator from using the committed UTXO for collaborative transactions; they won't prevent them from successfully initiating a one-sided transaction with honest peers.\n> - Only nodes that have at least one public channel will be able to contribute to the public PoDLE blacklist. This means it's possible for a malicious initiator to grief non-public nodes without much consequence, however this requires the ability to send inbound messages to private nodes, i.e. more likely for a close or splice interaction.\n> - As ZmnSCPxj has pointed out elsewhere, a malicious peer could broadcast junk H2's; it is acceptable to rate-limit the number of PoDLE blacklists generated by a peer.peer\n> - It is possible for a malicious peer to fail to relay their `H2` entries in the blacklisted gossip set.\n> - Duplicate H2 gossip should replace older timestamped versions.\n> - Elsewhere we've had a discussion/concern over floods of PoDLE blacklist messages. It's possible for gossip message floods to originate from a malicious peer; they also might signal an ongoing probe attempt. Given a timestamp and a rough measure of the number of utxos' currently outstanding in the mempool, however, it should be possible to distinguish the two.\n\nOk, so knowing where PoDLE originate from mitigates the flood we talked about with ZmnSCPxj.\nHowever I don't see how the number of utxos in the mempool is useful here, as you cannot distinguish which PoDLE is the real one out of the load you are receiving in case of a flood ?\n\n> ## Open Questions:\n> - Should PoDLE be required for every collaborative transaction (opens, splices\u00a0+ closes), or only for opens? It seems reasonable to limit them just to opens, as for all others you'll already have a shared UTXO with the peer.\n> - Is fixing the generator point too restrictive? JoinMarket allows for a range of acceptable NUMS (J) points (up to 256). The smaller the pool of eligible J's, the smaller the pool of potential blacklisted PoDLE's (up to no. NUMs * current utxo count). One upside to allowing a larger pool of J's means that the same UTXO can be retried on failure. One downside to allowing a pool of J's means that a single UTXO can be validly retried in a probe attack against a variety of peers.\n> \n\n> On Thu, Jan 30, 2020 at 5:32 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n> \n\n> > Good morning darosior, ariard, niftynei, and list,\n> > \n\n> > > We could also consider PoDLE as used in JoinMarket, which solves a similar problem.\n> > > https://gist.github.com/AdamISZ/9cbba5e9408d23813ca8#defence-2-committing-to-a-utxo-in-publicplaintext-at-the-start-of-the-handshake\n> > > Basically, a PoDLE commits to a UTXO, without being trivially grindable from the UTXO set and also including a proof that the creator of the PoDLE knows the secret key behind it.\n> > > It can later be opened to reveal which UTXO the opener allocated.\n> > > If the opener aborts (i.e. does not provide its signatures to the funding transaction) then the acceptor can gossip the UTXO and the revealed PoDLE as well to the rest of Lightning, so that the opener at least cannot reuse the same UTXO to probe other potential acceptors.\n> > > (though, my understanding, there is no clear way to determine when we can safely delete old PoDLEs: maybe each node can keep it around for a month, which might be good enough to limit the practical ability of a snoop to probe other nodes)\n> > > I believe JoinMarket also has solved the issue of allowing a UTXO to be used at most N times (for example due to \"honest\" failures, such as connectivity interruptions which might cause an abort of the protocol); I think it involves appending a single byte to something that is hashed, and ensuring its value is less than N, so that it can only be used from 0 to N - 1 (and thus allow a UTXO to be used at most N times).\n> > >\n> > > Getting into contact with waxwing / Adam Gibson for this might be useful to fill out how PoDLE works and so on; basically, I believe this issue is a practically solved problem already for JoinMarket, though waxwing may be able to provide a more nuanced opinion.\n> > \n\n> > I communicated with waxwing, and he said:\n> > \n\n> > * See also: https://joinmarket.me/blog/blog/poodle \\[sic\\].\n> > * The counter I mentioned is implemented using the second generator point.\n> > \u00a0 * The PoDLE construction requires the standard base point `G`, and another generator point `J`.\n> > \u00a0 * To create the generator point `J`, JoinMarket appends the counter byte (the one used to limit N number of uses of the same UTXO) to `G`, hashes it, then uses a coerce-to-point.\n> > * PoDLE is sometimes called DLEQ elsewhere.\n> > * There is no concrete answer on \"when to delete old PoDLE\"; JoinMarket never deletes (though they might if throughput increases).\n> > * Watermarks like `nLockTime`, `nSequence`, `nVersion` are currently fixed values; JoinMarket sees no reason to change this since equal-valued CoinJoins are otherwise obvious to chain analysis anyway.\n> > \u00a0 * But note: JoinMarket implements PayJoin, which is not otherwise obvious onchain, and does indeed do anti-fee-sniping emulation for PayJoin.\n> > \u00a0 * JoinMarket also strives to make similar feerates across users.\n> > \n\n> > In any case, for myself, my thoughts are:\n> > \n\n> > * I observe that our use-case is quite similar to a PayJoin:\n> > \u00a0 * The opener proposes to make a payment (to a channel between the opener and the acceptor, rather than outright giving control to the acceptor as in PayJoin).\n> > \u00a0 * The acceptor adds some UTXOs which will contribute to the payment output (i.e. the channel).\n> > \u00a0 * This probably does mean we want to later consider `nLockTime` anti-fee-sniping as well in multi-funded channel opens.\n> > * Speaking of multi-funded channel opens, it seems to me this interactive tx construction mechanism as well can be later used for channel factories.\n> > \u00a0 * Similarly, PoDLE techniques would be useful as well to multi-funded channel factories.\n> > * It would probably be a good idea to share PoDLE format with JoinMarket so we can share PoDLE with them (there could be bridges that share PoDLE between a JoinMarket maker and a Lightning node, and each network already has its own gossip protocols, so LN just needs a gossip protocol for sharing PoDLEs as well).\n> > * Probably we can mandate in some BOLT spec to retain PoDLE for at least a year or a month or two weeks or so, which should be enough to slow down probe attempts.\n> > \n\n> > Regards,\n> > ZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200211/32163fb0/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 477 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200211/32163fb0/attachment-0001.sig>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-11T13:05:08",
                "message_text_only": "Good morning darosior, niftynei, and list,\n\n\n>\n> We could agree on an acceptable number of reuse in case on a non-malicious failure from the initiator after a valid PoDLE exchange ? (credits ZmnSCPxj)\n\nThe default of 3 for JoinMarket seems reasonable.\n\n\n>\n> Ok, so knowing where PoDLE originate from mitigates the flood we talked about with ZmnSCPxj.\n> However I don't see how the number of utxos in the mempool is useful here, as you cannot distinguish which PoDLE is the real one out of the load you are receiving in case of a flood ?\n\nNo idea either, but if we limit accepted `node_id`s to those that we have seen in a `node_announcement` before, then we ride on the fact that `node_announcement` is costly in the sense that somebody has to allocate at least some small amount of funds to a channel that is visible onchain, because `node_announcement` requires a `channel_announcement` with an anchored channel.\n\nThen if nodes on the network can just send PoDLE gossip that they did not sign themselves, but are signed by *some* node that was `node_announcement`ed before, we can identify those nodes that are spamming a lot of their own signed PoDLE gossip, and rate-limit those.\n\nIt is likely that announced nodes are the ones who will have such attack attempts performed on them, so they are in the best position to inform others of such attempts and are the most likely to have such data.\n\nAt some point we probably also need to have set reconciliation for these as well.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-11T14:15:59",
                "message_text_only": "Hi darosior, niftynei, and list,\n\nwaxwing replied the below text, and asked to propagate as well to lightning-dev.\nHe has just recently re-subscribed to lightning-dev, but may be waiting for the necessary subscription notices or whatnot.\n\nRegards,\nZmnSCPxj\n\n-----------\n\nRe: Venus Flytrap attack and JoinMarket\n\nThis issue didn't crop up in our use case because takers always send out to 5-12 (typically) makers at once, and the HP2 only needs to get broadcast by one to stop any reuse.\nBut whichever way you look at it, it's a very good point! And in LN case, seems like a very substantial attack (at least from what little I've read so far).\n\nIn case a brief summary of JM mechanism is helpful, here's the taker-maker conversation:\n\n!fill amount, oid, commitment (HP2)\n-- this is where a taker sends to each maker an hp2 value. This is the step intended to enforce scarcity, and the assumption in JM was always that this would basically inevitably get shared. Because there are typically 5-12 makers involved, this seemed a reasonably safe assumption.\nIf the commitment value is already used and thus not valid, it gets broadcast immediately. If it's not, it only gets shared as part of the !ioauth step below.\n\n!pubkey key\n\n-- this is just the maker giving an ephemeral key for the encryption\n\n!auth (s, e, u, P, P2)\n-- (encrypted) this is the taker opening the above commitment. It's rather weird at first sight, because he is opening immediately after committing, with apparently no step inbetween; but in fact the implicit intermediate step is the broadcast (exactly what is being questioned with 'venus flytrap').\n\n!ioauth maker-utxo-data\n-- notice the maker is only sending this utxo data (encrypted of course) after proof of ownership of the utxo above.\nIt's only at this step that the hp2 commitment value is (a) added to the maker's local \"used up\" list, and (b)privmsged to 1  randomly chosen other bots in the trading pit, who then pubmsgs it to everyone (and that happens multiple times because multiple makers in tx), and they in turn record it as \"used\".\n\nThe mechanism is both not very strong - we use 3 allowed attempts per utxo - and imperfect in its \"justice\"; such commitments can be \"used up\" by failures of one's counterparties. But it does serve to stop trivial global snooping, and doesn't cost anything in terms of identity or locked funds, so it has served a purpose (we did actually see such attacks before it, and not after it).\n\nI'd also note that in terms of the venus flytrap attack mentioned, there could be a small time window between one maker receiving !auth and at least one other honest maker getting to broadcast step at !ioauth; while I don't think that's very practical in our use case, it is for sure a theoretical concern and removing it could be either slightly, or extremely, important in another use case.\n\nI'll have a look at this new idea related to node-id and get back to you on that. Thanks for this analysis and investigation, it's a very interesting area."
            },
            {
                "author": "AdamISZ",
                "date": "2020-02-11T16:04:50",
                "message_text_only": "niftynei, ZmnSCPxj and list:\n\n\nZmn** pinged me about this discussion and I thought I could add something directly:\n\n\nFirst, re:\n> I'd like to propose that we add a second commitment requirement to the PoDLE that JoinMarket uses, to limit the use of a commitment's validity to be only between an initiator and a single peer. Otherwise you can enable something I'll call the \"pouncing venus-flytrap attack\"[1].\n\nHere's some thoughts that may give context to this (excellent) observation:\n\nThis issue didn't crop up (well, kinda! I do remember discussion about it) in our use case because takers always send out to 5-12 (typically) makers at once, and the HP2 only needs to get broadcast by one to stop any reuse.\nBut whichever way you look at it, it's a very good point! And in LN case, seems like a very substantial attack (certainly no question it could be allowed for 2 party protocol).\n\nIn case a brief summary of JM mechanism is helpful, I added some info on the the taker-maker conversation at the end of this mail [1].\n\nSecond, re:\n> ## Mitigation\n> Have each initiator provide two commitments: one to the shared/global J\n> point and one to a point that is found from the hash of the non-initiating\n> node's node_id.[2]\n\nI get the thinking here, and it makes a lot of sense, but I do think it can be done more compactly.\nIf the commitment is H(P2), the opening of the commitment could be altered to include the receiving node:\n\ns = k + H(kG || kJ || P || P2 || utxo || receiving-node) x\n\nand as before transfer opening: (P, P2, u, s, e) with receiving-node implicitly reconstructed to do the verification of the Schnorr sig. It's basically a message in a signature.\n\nAs you note, we wouldn't want to ban usage of a H(P2) value based on an incorrect opening; we just use that failure to decide to not hand over our utxo information (as receiver of the commitment). But unless I missed something, doing it the above way is the more logical/compact choice.\n\nSeems like there's a lot of fine nuance here. A malicious counterparty can always choose to blacklist. In Joinmarket we accept (because of our stringent no-identity policy) some roughness and assume some meaningful level of honest participation. A Taker issuing a request to 10 cps hopes that at least some number (min 4 by default) will actually respond to an honest request; if say 8 of 10 do so, he will do the coinjoin with those. That it is brittle or flaky is why we allow 3 tries for each qualifying utxo (qualified on age, size), and also allow custom insertion of additional utxos (although it's rarely if ever needed). It works fine in practice, for now, but it is not watertight; if you have overwhelmingly malicious counterparties you are kinda screwed from other angles, as well as this one. Meanwhile on the Maker side we're trying to create a kind of 'herd immunity'; as long as some few of them are honest, word will get out about used commitments which will stop free spam queries, at least (but it's not a super strong defence!).\n\n\n[1] Taker-Maker convo (excerpt); some notes re: commitments/PoDLE.\n===\n!fill amount, oid, commitment (HP2)\n-- this is where a taker sends to each maker an hp2 value. This is the step intended to enforce scarcity, and the assumption in JM was always that this would basically inevitably get shared. Because there are typically 5-12 makers involved, this seemed a reasonably safe assumption.\nIf the commitment value is already used and thus not valid, it gets broadcast immediately. If it's not, it only gets shared as part of the !ioauth step below.\n\n!pubkey key\n\n-- this is just the maker giving an ephemeral key for the encryption\n\n!auth (s, e, u, P, P2)\n-- (encrypted) this is the taker opening the above commitment. It's rather weird at first sight, because he is opening immediately after committing, with apparently no step inbetween; but in fact the implicit intermediate step is the broadcast (exactly what is being questioned with 'venus flytrap').\n\n!ioauth maker-utxo-data\n-- notice the maker is only sending this utxo data (encrypted of course) after proof of ownership of the utxo above.\nIt's only at this step that the hp2 commitment value is (a) added to the maker's local \"used up\" list, and (b)privmsged to 1  randomly chosen other bots in the trading pit, who then pubmsgs it to everyone (and that happens multiple times because multiple makers in tx), and they in turn record it as \"used\".\n\nThe mechanism is both not very strong - we use 3 allowed attempts per utxo - and imperfect in its \"justice\"; such commitments can be \"used up\" by failures of one's counterparties. But it does serve to stop trivial global snooping, and doesn't cost anything in terms of identity or locked funds, so it has served a purpose (we did actually see such attacks before it, and not after it).\n\nI'd also note that in terms of the venus flytrap attack mentioned, there could be a small time window between one maker receiving !auth and at least one other honest maker getting to broadcast step at !ioauth; while I don't think that's very practical in our use case, it is for sure a theoretical concern and removing it could be either slightly, or extremely, important in another use case.\n\nThanks,\nAdam Gibson/waxwing/AdamISZ\n\nSent with ProtonMail Secure Email."
            },
            {
                "author": "lisa neigut",
                "date": "2020-02-11T18:12:48",
                "message_text_only": "> s = k + H(kG || kJ || P || P2 || utxo || receiving-node) x\n\n> and as before transfer opening: (P, P2, u, s, e) with receiving-node\nimplicitly reconstructed to do the verification of the Schnorr sig. It's\nbasically a message in a signature.\n\nOh that's *much* nicer than calculating a second commitment. Verification\nby any node that's not the intended recipient will fail, as they'll use the\nwrong node_id (their own).\n\nIt seems unnecessary to me to commit to the utxo, since the pubkey pair\neffectively does that. What's the motivation for including it? Though, now\nthat I think about it, it does seem imperative to verify that the pubkey\nprovided is in fact locked to by the utxo script, which we can do since the\nscript will have been provided in the `tx_add_input` message.\n\nSeems worth nothing that, given such a proof, you can grind to find out who\nthe intended node was. However, if the failure is indeed because of the\n\"venus flytrap\" attack I mentioned above, it'd pretty obviously be the node\nsending you the invalid signature (or a node that they spoofed/MITM'd),\nwhich isn't much of a leak.  Actually, this 'grindability' might be quite\nuseful for finding the originator of the attack, if needed. There's no\nreason for you to leak a PoDLE signature, but if you do you're\npotentially tying an H2 commitment offer to your node id. Seems very nice\nindeed!\n\nOne of the stated goals of implementing PoDLEs was to be \"compatible with\nJoinMarket\", but I believe this compatibility goal only extends as far as\nthe H2 construction (and not the proof), so we're ok there with this tweak.\n\nCheers!\nniftynei\n\nOn Tue, Feb 11, 2020 at 10:05 AM AdamISZ via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> niftynei, ZmnSCPxj and list:\n>\n>\n> Zmn** pinged me about this discussion and I thought I could add something\n> directly:\n>\n>\n> First, re:\n> > I'd like to propose that we add a second commitment requirement to the\n> PoDLE that JoinMarket uses, to limit the use of a commitment's validity to\n> be only between an initiator and a single peer. Otherwise you can enable\n> something I'll call the \"pouncing venus-flytrap attack\"[1].\n>\n> Here's some thoughts that may give context to this (excellent) observation:\n>\n> This issue didn't crop up (well, kinda! I do remember discussion about it)\n> in our use case because takers always send out to 5-12 (typically) makers\n> at once, and the HP2 only needs to get broadcast by one to stop any reuse.\n> But whichever way you look at it, it's a very good point! And in LN case,\n> seems like a very substantial attack (certainly no question it could be\n> allowed for 2 party protocol).\n>\n> In case a brief summary of JM mechanism is helpful, I added some info on\n> the the taker-maker conversation at the end of this mail [1].\n>\n> Second, re:\n> > ## Mitigation\n> > Have each initiator provide two commitments: one to the shared/global J\n> > point and one to a point that is found from the hash of the\n> non-initiating\n> > node's node_id.[2]\n>\n> I get the thinking here, and it makes a lot of sense, but I do think it\n> can be done more compactly.\n> If the commitment is H(P2), the opening of the commitment could be altered\n> to include the receiving node:\n>\n> s = k + H(kG || kJ || P || P2 || utxo || receiving-node) x\n>\n> and as before transfer opening: (P, P2, u, s, e) with receiving-node\n> implicitly reconstructed to do the verification of the Schnorr sig. It's\n> basically a message in a signature.\n>\n> As you note, we wouldn't want to ban usage of a H(P2) value based on an\n> incorrect opening; we just use that failure to decide to not hand over our\n> utxo information (as receiver of the commitment). But unless I missed\n> something, doing it the above way is the more logical/compact choice.\n>\n> Seems like there's a lot of fine nuance here. A malicious counterparty can\n> always choose to blacklist. In Joinmarket we accept (because of our\n> stringent no-identity policy) some roughness and assume some meaningful\n> level of honest participation. A Taker issuing a request to 10 cps hopes\n> that at least some number (min 4 by default) will actually respond to an\n> honest request; if say 8 of 10 do so, he will do the coinjoin with those.\n> That it is brittle or flaky is why we allow 3 tries for each qualifying\n> utxo (qualified on age, size), and also allow custom insertion of\n> additional utxos (although it's rarely if ever needed). It works fine in\n> practice, for now, but it is not watertight; if you have overwhelmingly\n> malicious counterparties you are kinda screwed from other angles, as well\n> as this one. Meanwhile on the Maker side we're trying to create a kind of\n> 'herd immunity'; as long as some few of them are honest, word will get out\n> about used commitments which will stop free spam queries,\n>   at least (but it's not a super strong defence!).\n>\n>\n> [1] Taker-Maker convo (excerpt); some notes re: commitments/PoDLE.\n> ===\n> !fill amount, oid, commitment (HP2)\n> -- this is where a taker sends to each maker an hp2 value. This is the\n> step intended to enforce scarcity, and the assumption in JM was always that\n> this would basically inevitably get shared. Because there are typically\n> 5-12 makers involved, this seemed a reasonably safe assumption.\n> If the commitment value is already used and thus not valid, it gets\n> broadcast immediately. If it's not, it only gets shared as part of the\n> !ioauth step below.\n>\n> !pubkey key\n>\n> -- this is just the maker giving an ephemeral key for the encryption\n>\n> !auth (s, e, u, P, P2)\n> -- (encrypted) this is the taker opening the above commitment. It's rather\n> weird at first sight, because he is opening immediately after committing,\n> with apparently no step inbetween; but in fact the implicit intermediate\n> step is the broadcast (exactly what is being questioned with 'venus\n> flytrap').\n>\n> !ioauth maker-utxo-data\n> -- notice the maker is only sending this utxo data (encrypted of course)\n> after proof of ownership of the utxo above.\n> It's only at this step that the hp2 commitment value is (a) added to the\n> maker's local \"used up\" list, and (b)privmsged to 1  randomly chosen other\n> bots in the trading pit, who then pubmsgs it to everyone (and that happens\n> multiple times because multiple makers in tx), and they in turn record it\n> as \"used\".\n>\n> The mechanism is both not very strong - we use 3 allowed attempts per utxo\n> - and imperfect in its \"justice\"; such commitments can be \"used up\" by\n> failures of one's counterparties. But it does serve to stop trivial global\n> snooping, and doesn't cost anything in terms of identity or locked funds,\n> so it has served a purpose (we did actually see such attacks before it, and\n> not after it).\n>\n> I'd also note that in terms of the venus flytrap attack mentioned, there\n> could be a small time window between one maker receiving !auth and at least\n> one other honest maker getting to broadcast step at !ioauth; while I don't\n> think that's very practical in our use case, it is for sure a theoretical\n> concern and removing it could be either slightly, or extremely, important\n> in another use case.\n>\n> Thanks,\n> Adam Gibson/waxwing/AdamISZ\n>\n> Sent with ProtonMail Secure Email.\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200211/d140fadd/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-12T04:04:42",
                "message_text_only": "Good morning niftynei, and waxwing, and list,\n\n> > s = k + H(kG || kJ || P || P2 || utxo || receiving-node) x\n>\n> > and as before transfer opening: (P, P2, u, s, e) with receiving-node implicitly reconstructed to do the verification of the Schnorr sig. It's basically a message in a signature.\n>\n> Oh that's *much* nicer than calculating a second commitment. Verification by any node that's not the intended recipient will fail, as they'll use the wrong node_id (their own).\u00a0\n>\n> It seems unnecessary\u00a0to me to commit to the utxo, since the pubkey pair effectively does that. What's the motivation for including it?\n\nProbably so that address reuse is not dinged, i.e. I have two UTXOs with the same address and want to make two different channels with different peers.\n\nWhile address reuse Is Bad, you might not have much control over some wog who is supposed to pay you and decides to give you your money in two separate UTXOs to the same address.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "lisa neigut",
                "date": "2020-02-12T23:09:17",
                "message_text_only": "> Probably so that address reuse is not dinged, i.e. I have two UTXOs with\nthe same address and want to make two different channels with different\npeers.\n\nHaving 2 utxos locked to the same pubkey will map to a single H2 value\nthough, which is what is used to flag utxo reuse. With a PoDLE you're\nproving that you have a *key* for a utxo; the verifier checks that the key\nyou say you know does in fact map to controlling the utxo that you say it's\nattached to. Whether or not you added the utxo to the signature commitment\ndoesn't add anything to the security of the verification.\n\nAt worse, it might leak what other utxo that the initiator controls, if\nthey accidentally commit to the wrong utxo and the peer decided to try\ngrinding utxo outpoints on the offchance that one matched.\n\n\n\nOn Tue, Feb 11, 2020 at 10:04 PM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning niftynei, and waxwing, and list,\n>\n> > > s = k + H(kG || kJ || P || P2 || utxo || receiving-node) x\n> >\n> > > and as before transfer opening: (P, P2, u, s, e) with receiving-node\n> implicitly reconstructed to do the verification of the Schnorr sig. It's\n> basically a message in a signature.\n> >\n> > Oh that's *much* nicer than calculating a second commitment.\n> Verification by any node that's not the intended recipient will fail, as\n> they'll use the wrong node_id (their own).\n> >\n> > It seems unnecessary to me to commit to the utxo, since the pubkey pair\n> effectively does that. What's the motivation for including it?\n>\n> Probably so that address reuse is not dinged, i.e. I have two UTXOs with\n> the same address and want to make two different channels with different\n> peers.\n>\n> While address reuse Is Bad, you might not have much control over some wog\n> who is supposed to pay you and decides to give you your money in two\n> separate UTXOs to the same address.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200212/1c55131e/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-12T23:23:01",
                "message_text_only": "Good morning niftynei, waxwing, and list,\n\n> > Probably so that address reuse is not dinged, i.e. I have two UTXOs with the same address and want to make two different channels with different peers.\n>\n> Having 2 utxos locked to the same pubkey\u00a0will map to a single H2 value though, which is what is used to flag utxo reuse. With a PoDLE you're proving that you have a key for a utxo; the verifier checks that the key you say you know does in fact map to controlling the utxo that you say it's attached to. Whether or not you added the utxo to the signature commitment doesn't add anything to the security of the verification.\n>\n> At worse, it might leak what other utxo that the initiator controls, if they accidentally commit to the wrong utxo and the peer decided to try grinding utxo outpoints on the offchance that one matched.\n\nRight, right, H2 commits to knowledge of the privkey, not a specific UTXO.\n\nI suppose the Right Thing to do if somebody foists address reuse on you would be to spend all UTXOs with the same address together.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "AdamISZ",
                "date": "2020-02-12T14:57:28",
                "message_text_only": "> One of the stated goals of implementing PoDLEs was to be \"compatible with JoinMarket\", but I believe this compatibility goal only extends as far as the H2 construction (and not the proof), so we're ok there with this tweak.\n\nGood point about H2 being cross-compatible, but I would not tie yourselves down in any way with attempting to keep compatibility with Joinmarket as-is, unless it's trivial to do so ... we will need to pretty much wholesale upgrade our protocol at some relatively soon point, ideally straight to schnorr/taproot, or if not, at least to native segwit, since coinjoin is a fee-heavy protocol. And there's a bunch of legacy stuff (especially in terms of encodings, but other stuff too) that will need to change. If you guys end up finding a stronger and clearer version of this podle/dleq thing and it ends up being useful, we will just tag along (at least, that's likely). And this is why I should not be lazy and try to keep up with this conversation!\n\nI wanted to mention something else. Way back, maybe 2 years ago, I remember being interested that there *was* actually at least one use-case of DLEQ to create blinded tokens in the wild apart from our own. I dug up the link; it's really a beautiful idea but it's more based around a client-server model and using 'blind signing' (oblivious PRF based, so not old-style RSA or Chaum), but it's an easy idea to read and grok I think:\n\nhttps://github.com/privacypass/challenge-bypass-extension/blob/master/docs/PROTOCOL.md\n\nWhile it's very different from our use-case (harder because not client-server), it's still interesting that they use a DLEQ to prove correctly formed token construction, and then prevent 'double spend'. I wouldn't be surprised if there is something to learn from this line of thinking.\nCheers,\nwaxwing"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-12T23:09:55",
                "message_text_only": "Good morning waxwing,\n\n>\n> https://github.com/privacypass/challenge-bypass-extension/blob/master/docs/PROTOCOL.md\n>\n> While it's very different from our use-case (harder because not client-server),\n\nAm still going through the document, but wanted to react to \"not client-server\" thing.\n\nGenerally over the Internet the presumption is that the server just passively lies there in wait, and then a client actively contacts the server to get some service.\nIn terms of Lightning opening protocols, the channel opener is the client, and the acceptor is the server.\nSimilarly, in terms of JoinMarket, the taker is the client, and the maker is the server.\n\nOf course the link seems to be very different, am still reading through it.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "DRAFT: interactive tx construction protocol",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "darosior",
                "AdamISZ",
                "lisa neigut",
                "Rusty Russell",
                "ZmnSCPxj"
            ],
            "messages_count": 21,
            "total_messages_chars_count": 100459
        }
    },
    {
        "title": "[Lightning-dev] New paper on ant routing",
        "thread_messages": [
            {
                "author": "LEH\u00c9RICY Gabriel",
                "date": "2020-02-06T10:32:50",
                "message_text_only": "Dear All,\n\n  I would like to announce our new paper on the ant routing algorithm for the lightning network. The paper is available online here:\nhttps://arxiv.org/abs/2002.01374. It gives an estimate for the scalability of the ant routing algorithm.\n\n  If you have any question regarding our work, I will be happy to answer them via email.\n\n  Sincerely,\n\n  Gabriel Leh\u00e9ricy\n\n[https://storage.letsignit.com/5bbf3d27229c7c0001b516ac/logo_5bbf3d27229c7c0001b516ac_a703125b9809706c7ecf086c8d1f365b.png]     Gabriel LEH\u00c9RICY\nEnseignant Chercheur\nD\u00e9partement Ing\u00e9nierie Financi\u00e8re\nRetrouvez-nous sur esilv.fr<https://cloud.letsignit.com/collect/bc/5dac9f76636d120008f181c3?p=nP2-ScO6-vNP5RaGcPvyEKdWgVGNlodC4kLGsvUnUpY76wPghhUgLqkR8eOwaTCP67PPz_3zqTo7rxg5DU3tSFukuWdcRCJoEzlCaBQIIve2als5BOhNJ2TklT7dIKwtHsZY96NFkrahdOTKI_x75xQTTmPUjJGaiVnQ6FKPiPw=>\n[https://storage.letsignit.com/5bbf3d27229c7c0001b516ac/logo_5bbf3d27229c7c0001b516ac_fa26d4badf2c6377bc99410d39ab3e86.png] <https://cloud.letsignit.com/collect/bc/5dac9f76636d120008f181c3?p=nP2-ScO6-vNP5RaGcPvyEKdWgVGNlodC4kLGsvUnUpY76wPghhUgLqkR8eOwaTCP67PPz_3zqTo7rxg5DU3tSFukuWdcRCJoEzlCaBQIIvdZzBjyGPD8cVxcR2t5wgIOQpLS3RsA8v4NX8-CZowUHAkMhx3EtQbkAXbkkYWPsGB8lCk0kDvPoYXNkuSwZQLS> [https://storage.letsignit.com/5bbf3d27229c7c0001b516ac/logo_5bbf3d27229c7c0001b516ac_30a7735a477788d7833988f38fa47b90.png]  <https://cloud.letsignit.com/collect/bc/5dac9f76636d120008f181c3?p=nP2-ScO6-vNP5RaGcPvyEKdWgVGNlodC4kLGsvUnUpY76wPghhUgLqkR8eOwaTCP67PPz_3zqTo7rxg5DU3tSFukuWdcRCJoEzlCaBQIIvchDW18CE_jy1bfCHuOQFxyvUTvBNtHcBo2VGDJi8HUaRvE_W-kFCQ9GcXmCH9AMaakLdegAkG4oPqtWl6UnMNV9vyY8WvrZMicp6VYUVFsNJus64r9oK6YTkaorqQL9yUUE05j1IyRmolZ0OhSj4j8> [https://storage.letsignit.com/5bbf3d27229c7c0001b516ac/logo_5bbf3d27229c7c0001b516ac_959dfa6c5ceef1acde39b485b1e8493e.png]  <https://cloud.letsignit.com/collect/bc/5dac9f76636d120008f181c3?p=nP2-ScO6-vNP5RaGcPvyEKdWgVGNlodC4kLGsvUnUpY76wPghhUgLqkR8eOwaTCP67PPz_3zqTo7rxg5DU3tSFukuWdcRCJoEzlCaBQIIvefostVjuFSu99UhWRh79FoNd3JUF1Iy2P0EF5y1qxKTMqDvml9sSB_0LGt_kxNEXe4EiVJoxr6ybYWHttLJEFn> [https://storage.letsignit.com/5bbf3d27229c7c0001b516ac/logo_5bbf3d27229c7c0001b516ac_c4b2fc296b83f99e6fc2b58a412ed46c.png]  <https://cloud.letsignit.com/collect/bc/5dac9f76636d120008f181c3?p=nP2-ScO6-vNP5RaGcPvyEKdWgVGNlodC4kLGsvUnUpY76wPghhUgLqkR8eOwaTCP67PPz_3zqTo7rxg5DU3tSFukuWdcRCJoEzlCaBQIIvcnEaajpT_6_EXXzUWabTxtEfOszAa6GLdsZOTwjGXDstxZy1hrCTfu70GRyxxFQGmtHVCkiV4C75Vh1zv10Hc23daUh4fsGMRK2wuiqc_T2g312vKSAjGczNE62uELtEUEWnO3og1CgH40InAApdJmuBIlSaMa-sm2Fh7bSyRBZw==> [https://storage.letsignit.com/5bbf3d27229c7c0001b516ac/logo_5bbf3d27229c7c0001b516ac_f357ead540d478d5ef45625e199c4e1d.png]  <https://cloud.letsignit.com/collect/bc/5dac9f76636d120008f181c3?p=nP2-ScO6-vNP5RaGcPvyEKdWgVGNlodC4kLGsvUnUpY76wPghhUgLqkR8eOwaTCP67PPz_3zqTo7rxg5DU3tSFukuWdcRCJoEzlCaBQIIvcAV-34A7dx40R84vUbjK1cGBQRprfCQNEqlaSDqp31wwkMhx3EtQbkAXbkkYWPsGB8lCk0kDvPoYXNkuSwZQLS>\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200206/d07dd169/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-07T04:11:03",
                "message_text_only": "Good morning Gabriel,\n\n\nInteresting idea and it helps to reduce routemap size by completely eliminating the routemap, and also removes distinctions between published and unpublished channels by making every channel unpublished.\nHowever there seem to be some considerations as well.\n\n--\n\nA node which is able to match the payee seed pheromone and the payer seed pheromone knows the total distance traversed between the payer and payee, and also knows exactly the distance between itself and the payee/payer.\nAdmittedly this only gives an upper bound on the distance, but the pheromone system with its ability to find shorter and shorter paths will, over time, give such a matcher better and better information about distance to payer and payee.\nA surveillance node would deliberately defer broadcasting each pheromone it receives, in the hope that the matching pheromone reaches it as well and it can determine upper bounds on distance to both a payer and the corresponding payee.\n\nThis can be fixed by having just the payee broadcast the pheromone, and have the payer wait for incoming pheromones from the payee.\nFurther, it preserves the current privacy of the payer, which is much harder to find in the current Lightning Network source-pathfinding onion-routing scheme, and adds privacy to the payee (the payer only knows its distance to the payee, not the exact node ID of the payee).\n\n--\n\nHaving a single pheromone seed (or a pair of matched seeds) that is recognizable for the entire path prevents us from implementing any kind of path decorrelation.\nThis is fine when considering just the current HTLCs (which have the same property that a single path is recognizable as being a single path solely from the hash used), but PTLCs can buy us some privacy (the entire path has no single \"smoking gun\" that identifies it, just coincidences like being near in sidereal time, having similar value, having decrementing locktime...), which is then lost with the pheromone system.\n\nIt is unclear to me whether this is fixable: you would need something that intermediate nodes can malleate, but which the matcher (which, if we go with the above \"only the payee sends out pheromones\", the payer is the only possible matcher) must somehow still recognize and match to the payment.\n\nThis is a big weakness of Ant Routing.\n\n--\n\nThere have been some discussions as well of performing particularly complicated payment schemes by taking advantage of homomorphism of points and scalars, enabled by PTLCs.\nIt is not clear to me as well if the pheromone system can help or hinder such schemes.\n\n--\n\nConfirming the path length is an additional step.\nIt can be elided by recognizing that the timelock component of the PTLC/HTLC routing must decrement at each hop.\n\nSuppose some node under-reports the distance that a pheromone travelled, in the hopes that the payment will go through them and they can earn fees thereby.\nThe payer can allocate only enough timelock to cover the reported length.\nSince the true length of that path is actually longer, some other node will refuse to forward the payment due to insufficient timelock, and the payment fails and the under-reporting node will not earn fees anyway.\n\nAgainst this, however, we must caution that an under-reporting node might *NOT* be interested in earning fees, but instead to get payment statistics.\nThus it would be able to \"pheromone-hijack\" and acquire information about the amount of the payment and its payment hash/point, even though it knows the payment cannot push through.\n\nSo this is not a perfect solution in terms of privacy.\n\n--\n\nRouting failures seem somewhat harder to handle.\nBecause the payer itself does not know the whole path to the payee, it would be pointless to reveal which node actually failed to forward; the payer can do nothing about this information anyway.\nThe payer can only just try with a different peer that has also reported the target pheromone.\n\nAgainst this, however, we can point out that we can reduce payment failures.\nThe fact that a pheromone reached the payer recently indicates that the forwarding nodes along that path have also recently been online and working, so the chances of it going offline soon are expected to be low.\nFurther, if a channel is imbalanced with most of the value owned by a forwarding node, the forwarding node can simply avoid sending a pheromone down that channel, since it would not be likely to be routable via that channel anyway.\n\nPerhaps in terms of failure, a forwarding node could also remember the second-lowest distance pheromone, and report a failure back as an increase in the effective pheromone distance along that path (or a \"true failure\" where it knows of no second-lower distance pheromone).\nFurther a forwarding node which has received more than one equal-distance pheromone can just retry the HTLC along those pheromone distances.\nThis is similar to how JIT Routing works, with payments effectively getting rerouted via alternate paths without telling the original payer the exact details of the payment rerouting.\n\n--\n\nDistance measurements need not be in units of hops.\n\n--\n\nFinally: a MAJOR objection against Ant Routing.\n\nThe main reason why Lightning is a scaling solution is that it drastically reduces how many nodes you tell about a payment.\nCompare this to the blockchain layer, where every node has, at minimum, to be told about every confirmed transaction, and this is the reason why we have a block size limit in the first place.\n\nWith Ant Routing, every payment needs to have a pheromone broadcasted.\nThis pheromone will reach out to *every* part of the network.\n(Even with pheromones emitted at both the payer and payee end, it is likely that one or the other pheromone will reach the entire network.)\nThus, we are still sending out data that has to reach each and every node on the network at *each* payment.\n\nThis negates the big-O scaling achieved by Lightning.\n\nAdmittedly, constant factors are much lower with Ant Routing and it may remain practical.\nIf you use a pheromone emitted only by the payee, we can probably use just 160 bits or even 128 bits of entropy for the pheromone identifier; it only has to be a universally-unique identifier without any special mathematical properties, and the invoice could contain the pheromone identifier as well, thus reducing the communications rounds between payer and payee to a single communication, the invoice (same as current Lightning).\nThe distance count could be a single byte (if we use units in terms of hops).\nThis means 17 bytes broadcasted to the entire network per payment (compared to the hundred bytes or so needed per payment on the blockchain layer).\n\n--\n\nIn summary, two main objections:\n\n* Ant Routing sends data proportional to p payments to n nodes or O(pn).\n  Current source routing just sends data proportional to p payments to a constant limit of nodes or O(p).\n* Surveillors can easily determine payments and the maximum distance to the destination and likely source.\n  This is same as current Lightning but we already have proposal (path decorrelation by using payment points) to remove it, it seems not to be useable with Ant Routing.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-09T00:57:24",
                "message_text_only": "Good morning Gabriel,\n\nSome further thinking:\n\n--\n\nI notice as well that you propose to add a random number to the initial hop distance counter.\nThis does not quite obscure as much as you might think.\n\nSuppose I have two nodes I control in the Lightning Network, which we will pretend is this blank sheet of paper.\n\n    +------------------------------------------+\n    |                                          |\n    |                                          |\n    |                                          |\n    |                                          |\n    |                                          |\n    |                                          |\n    |       X                          X       |\n    |                                          |\n    |                                          |\n    |                                          |\n    |                                          |\n    |                                          |\n    |                                          |\n    |                                          |\n    +------------------------------------------+\n\nNow suppose my two nodes happen to receive the same pheromone, and the distance counters are equal.\nI can then conclude that the originating node has the same distance to my two nodes, or:\n\n    +------------------------------------------+\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    |       X            :             X       |\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    +------------------------------------------+\n\nThe originating node is now known to be somewhere along the above dotted line.\n(the same analysis can be done even if the distance counters received by both nodes are not equal: I can just take the difference between them, which automatically cancels out the random number you are trying to use to obscure the distance, and get an indicator of whether the dotted line should be nearer to one node or the other.)\n\nWorse, if I have a *third* node, then I can get two more such lines, and then triangulate where the originator of the pheromone is.\n\nYou can bet that any surveillor is going to run multiple nodes.\nSo the added random number is just going to protect against single-node operators, but even medium-corporate-level surveillors will be able to run as few as 3 nodes on the network.\nAnd since pheromones are broadcast to the *entire* network, 3 nodes is enough to make a mapping of pheromone-to-node.\n\nOf course, the real Lightning Network is not a sheet of paper, so maybe 3 nodes will still not be enough, but a small number of nodes will be able to make such a mapping.\nAnd of course since every node and channel in Ant Routing is unpublished, such a surveillor will still need to do some extra work to map out the network by other means.\n\n--\n\nAn advantage of the current published network is that it automatically gives a way to discover other nodes you can connect to and make channels with.\n\nThis even gets spam-capping for free, since we only gossip about nodes which have a proof that they have at least one channel somewhere.\n\n--\n\nChannel rebalancing seems difficult with Ant Routing.\nRebalancing is basically making a payment to oneself, and the shortest path to yourself is to do nothing.\n\n--\n\nNothing prevents someone spamming the network with pheromones for payments they are not going to receive anyway.\nCreating pheromones for broadcast would have to be costly, but that now allows certain initiator-does-not-pay attacks where the sender keeps requesting invoices from the receiver, which creates a pheromone for each apparent invoice, but the sender does not actually make any payments.\n\n--\n\nOne can observe that Dijkstra algorithm is a simulation of pheromones in Ant Routing, and is why Dijkstra can actually discover shortest paths.\n\nThus, one might consider Ant Routing to be a sort of \"distributed Dijkstra\".\nWe observe as well that, without an \"early-out\" case, Dijkstra really forms a shortest-path tree of the entire routemap.\n\nRegards,\nZmnSCPxj\n\n\n> Good morning Gabriel,\n>\n> Interesting idea and it helps to reduce routemap size by completely eliminating the routemap, and also removes distinctions between published and unpublished channels by making every channel unpublished.\n> However there seem to be some considerations as well.\n>\n> -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> A node which is able to match the payee seed pheromone and the payer seed pheromone knows the total distance traversed between the payer and payee, and also knows exactly the distance between itself and the payee/payer.\n> Admittedly this only gives an upper bound on the distance, but the pheromone system with its ability to find shorter and shorter paths will, over time, give such a matcher better and better information about distance to payer and payee.\n> A surveillance node would deliberately defer broadcasting each pheromone it receives, in the hope that the matching pheromone reaches it as well and it can determine upper bounds on distance to both a payer and the corresponding payee.\n>\n> This can be fixed by having just the payee broadcast the pheromone, and have the payer wait for incoming pheromones from the payee.\n> Further, it preserves the current privacy of the payer, which is much harder to find in the current Lightning Network source-pathfinding onion-routing scheme, and adds privacy to the payee (the payer only knows its distance to the payee, not the exact node ID of the payee).\n>\n> -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> Having a single pheromone seed (or a pair of matched seeds) that is recognizable for the entire path prevents us from implementing any kind of path decorrelation.\n> This is fine when considering just the current HTLCs (which have the same property that a single path is recognizable as being a single path solely from the hash used), but PTLCs can buy us some privacy (the entire path has no single \"smoking gun\" that identifies it, just coincidences like being near in sidereal time, having similar value, having decrementing locktime...), which is then lost with the pheromone system.\n>\n> It is unclear to me whether this is fixable: you would need something that intermediate nodes can malleate, but which the matcher (which, if we go with the above \"only the payee sends out pheromones\", the payer is the only possible matcher) must somehow still recognize and match to the payment.\n>\n> This is a big weakness of Ant Routing.\n>\n> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> There have been some discussions as well of performing particularly complicated payment schemes by taking advantage of homomorphism of points and scalars, enabled by PTLCs.\n> It is not clear to me as well if the pheromone system can help or hinder such schemes.\n>\n> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> Confirming the path length is an additional step.\n> It can be elided by recognizing that the timelock component of the PTLC/HTLC routing must decrement at each hop.\n>\n> Suppose some node under-reports the distance that a pheromone travelled, in the hopes that the payment will go through them and they can earn fees thereby.\n> The payer can allocate only enough timelock to cover the reported length.\n> Since the true length of that path is actually longer, some other node will refuse to forward the payment due to insufficient timelock, and the payment fails and the under-reporting node will not earn fees anyway.\n>\n> Against this, however, we must caution that an under-reporting node might NOT be interested in earning fees, but instead to get payment statistics.\n> Thus it would be able to \"pheromone-hijack\" and acquire information about the amount of the payment and its payment hash/point, even though it knows the payment cannot push through.\n>\n> So this is not a perfect solution in terms of privacy.\n>\n> -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> Routing failures seem somewhat harder to handle.\n> Because the payer itself does not know the whole path to the payee, it would be pointless to reveal which node actually failed to forward; the payer can do nothing about this information anyway.\n> The payer can only just try with a different peer that has also reported the target pheromone.\n>\n> Against this, however, we can point out that we can reduce payment failures.\n> The fact that a pheromone reached the payer recently indicates that the forwarding nodes along that path have also recently been online and working, so the chances of it going offline soon are expected to be low.\n> Further, if a channel is imbalanced with most of the value owned by a forwarding node, the forwarding node can simply avoid sending a pheromone down that channel, since it would not be likely to be routable via that channel anyway.\n>\n> Perhaps in terms of failure, a forwarding node could also remember the second-lowest distance pheromone, and report a failure back as an increase in the effective pheromone distance along that path (or a \"true failure\" where it knows of no second-lower distance pheromone).\n> Further a forwarding node which has received more than one equal-distance pheromone can just retry the HTLC along those pheromone distances.\n> This is similar to how JIT Routing works, with payments effectively getting rerouted via alternate paths without telling the original payer the exact details of the payment rerouting.\n>\n> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> Distance measurements need not be in units of hops.\n>\n> ------------------------------------------------------\n>\n> Finally: a MAJOR objection against Ant Routing.\n>\n> The main reason why Lightning is a scaling solution is that it drastically reduces how many nodes you tell about a payment.\n> Compare this to the blockchain layer, where every node has, at minimum, to be told about every confirmed transaction, and this is the reason why we have a block size limit in the first place.\n>\n> With Ant Routing, every payment needs to have a pheromone broadcasted.\n> This pheromone will reach out to every part of the network.\n> (Even with pheromones emitted at both the payer and payee end, it is likely that one or the other pheromone will reach the entire network.)\n> Thus, we are still sending out data that has to reach each and every node on the network at each payment.\n>\n> This negates the big-O scaling achieved by Lightning.\n>\n> Admittedly, constant factors are much lower with Ant Routing and it may remain practical.\n> If you use a pheromone emitted only by the payee, we can probably use just 160 bits or even 128 bits of entropy for the pheromone identifier; it only has to be a universally-unique identifier without any special mathematical properties, and the invoice could contain the pheromone identifier as well, thus reducing the communications rounds between payer and payee to a single communication, the invoice (same as current Lightning).\n> The distance count could be a single byte (if we use units in terms of hops).\n> This means 17 bytes broadcasted to the entire network per payment (compared to the hundred bytes or so needed per payment on the blockchain layer).\n>\n> --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> In summary, two main objections:\n>\n> -   Ant Routing sends data proportional to p payments to n nodes or O(pn).\n>     Current source routing just sends data proportional to p payments to a constant limit of nodes or O(p).\n>\n> -   Surveillors can easily determine payments and the maximum distance to the destination and likely source.\n>     This is same as current Lightning but we already have proposal (path decorrelation by using payment points) to remove it, it seems not to be useable with Ant Routing.\n>\n>     Regards,\n>     ZmnSCPxj\n>\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "LEH\u00c9RICY Gabriel",
                "date": "2020-02-12T10:11:38",
                "message_text_only": "Hello ZmnSCPxj,\n\n   Thank you for your comments, we are glad for your interest in our work. Below some answers to your comments.\n\n  Concerning the information that intermediary nodes can gather from counters: We are working under the assumption of a large highly connected network (with thousands of nodes and node connection larger than 10, or nodes connected to highly connected nodes if they are newcomers).  Such a network has a very different geometry from the plane. In particular, triangulation is not feasible in general. Typically the distance between the majority of any pair of nodes is between 3 and 7 for a worldwide network. We want to obfuscate the counter to avoid giving information to immediate neighbours (that in principle are more trustable than others) about the origin or end of the transaction. Also, finding the shortest path in a highly connected graph is not our primary concern since most paths are quite short, which is why we are not considering optimization with a Dijkstra type algorithm.\n\nConcerning spamming, this is unavoidable (as for the Bitcoin network) and scrutinity from nodes is required. Nodes are free to relay the seeds that they want. In particular, if a node N notices that one of its neighbours, say node M, starts spamming the network with pheromones (with a traffic much larger than its historical average share), then N can choose to ignore the seeds coming from M. It is even in N's best interest to be careful not to relay what he perceives as spams, because N itself could otherwise be branded as \"spammer\" by its neighbours. For this reason it is advisable for nodes to keep historic data on behaviour of neighbours and close the channels if they suspect them of acting maliciously (which can be revealed with the historical data).\n\nConcerning payment failures: it was our understanding that the reason for the high failure rate of the current routing algorithm is because\nAlice doesn't know the channel balances of other nodes, and thus cannot be sure that her choice of path has enough funds to forward her payment. Ant routing\nsolves this problem during the pheromone phase: a node  forwards the pheromone to a neighbour only if the channel balance allows the amount of the transaction to go through. This way, when Alice receives a matched seed, she is certain that the channel balances on the path have enough funds to forward her whole payment. It is also our understanding that the gossip network (that can also be a source of spamming) is used to update the channel balance in the routing tables. Note that the update of these channel balances, which seems necessary with the current routing, reveals and deanonimizes who has made transactions in the last period (and we can even reconstruct very easily a lot of transactions if updates are made often).\n\nWhen you say \"Distance measurements need not be in units of hops\", I am not sure what you mean here, and why this is a problem; could you elaborate?\n\nConcerning your \"main objection\": as you noticed, the size of pheromones is significantly less than bitcoin transactions (16 Bytes, as we indicate in the paper) and they are deleted after 3 seconds (this keeps the seed mempool small). Pheromone Ids can be so small because they only need to distinguish between the about 30k tx present in the seed mempool (for a regime of about 10k tx/sec). The purpose of our paper is to prove scalability up to 10.000 tx/sec, we don't claim anything else, and certainly not infinite scalability. In that regard,theoretical O-estimates seem irrelevant to us (any O-estimate is dependent of the implicit constants and the hardware used, and is only relevant when we aim for \"infinite scalability\"). In the paper, we have a more practical and direct approach and we use the Bitcoin network that scales to 5-7 tx/sec as a proxy for the flooding algorithm . The argument is given in Section 6 of the paper. If you have any objection to that section we will be glad to discuss it and we would like to understand why your objection does not apply to the Bitcoin network or the other networks that are given as examples.\n\nBest,\n\nThe authors\n\n\n\n________________________________\nDe : ZmnSCPxj <ZmnSCPxj at protonmail.com>\nEnvoy\u00e9 : dimanche 9 f\u00e9vrier 2020 01:57\n\u00c0 : ZmnSCPxj <ZmnSCPxj at protonmail.com>\nCc : LEH\u00c9RICY Gabriel <gabriel.lehericy at devinci.fr>; GRUNSPAN Cyril <cyril.grunspan at devinci.fr>; Ricardo P\u00e9rez Marco <ricardo.perez.marco at gmail.com>; lightning-dev at lists.linuxfoundation.org <lightning-dev at lists.linuxfoundation.org>\nObjet : Re: [Lightning-dev] New paper on ant routing\n\nGood morning Gabriel,\n\nSome further thinking:\n\n--\n\nI notice as well that you propose to add a random number to the initial hop distance counter.\nThis does not quite obscure as much as you might think.\n\nSuppose I have two nodes I control in the Lightning Network, which we will pretend is this blank sheet of paper.\n\n    +------------------------------------------+\n    |                                          |\n    |                                          |\n    |                                          |\n    |                                          |\n    |                                          |\n    |                                          |\n    |       X                          X       |\n    |                                          |\n    |                                          |\n    |                                          |\n    |                                          |\n    |                                          |\n    |                                          |\n    |                                          |\n    +------------------------------------------+\n\nNow suppose my two nodes happen to receive the same pheromone, and the distance counters are equal.\nI can then conclude that the originating node has the same distance to my two nodes, or:\n\n    +------------------------------------------+\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    |       X            :             X       |\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    |                    :                     |\n    +------------------------------------------+\n\nThe originating node is now known to be somewhere along the above dotted line.\n(the same analysis can be done even if the distance counters received by both nodes are not equal: I can just take the difference between them, which automatically cancels out the random number you are trying to use to obscure the distance, and get an indicator of whether the dotted line should be nearer to one node or the other.)\n\nWorse, if I have a *third* node, then I can get two more such lines, and then triangulate where the originator of the pheromone is.\n\nYou can bet that any surveillor is going to run multiple nodes.\nSo the added random number is just going to protect against single-node operators, but even medium-corporate-level surveillors will be able to run as few as 3 nodes on the network.\nAnd since pheromones are broadcast to the *entire* network, 3 nodes is enough to make a mapping of pheromone-to-node.\n\nOf course, the real Lightning Network is not a sheet of paper, so maybe 3 nodes will still not be enough, but a small number of nodes will be able to make such a mapping.\nAnd of course since every node and channel in Ant Routing is unpublished, such a surveillor will still need to do some extra work to map out the network by other means.\n\n--\n\nAn advantage of the current published network is that it automatically gives a way to discover other nodes you can connect to and make channels with.\n\nThis even gets spam-capping for free, since we only gossip about nodes which have a proof that they have at least one channel somewhere.\n\n--\n\nChannel rebalancing seems difficult with Ant Routing.\nRebalancing is basically making a payment to oneself, and the shortest path to yourself is to do nothing.\n\n--\n\nNothing prevents someone spamming the network with pheromones for payments they are not going to receive anyway.\nCreating pheromones for broadcast would have to be costly, but that now allows certain initiator-does-not-pay attacks where the sender keeps requesting invoices from the receiver, which creates a pheromone for each apparent invoice, but the sender does not actually make any payments.\n\n--\n\nOne can observe that Dijkstra algorithm is a simulation of pheromones in Ant Routing, and is why Dijkstra can actually discover shortest paths.\n\nThus, one might consider Ant Routing to be a sort of \"distributed Dijkstra\".\nWe observe as well that, without an \"early-out\" case, Dijkstra really forms a shortest-path tree of the entire routemap.\n\nRegards,\nZmnSCPxj\n\n\n> Good morning Gabriel,\n>\n> Interesting idea and it helps to reduce routemap size by completely eliminating the routemap, and also removes distinctions between published and unpublished channels by making every channel unpublished.\n> However there seem to be some considerations as well.\n>\n> -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> A node which is able to match the payee seed pheromone and the payer seed pheromone knows the total distance traversed between the payer and payee, and also knows exactly the distance between itself and the payee/payer.\n> Admittedly this only gives an upper bound on the distance, but the pheromone system with its ability to find shorter and shorter paths will, over time, give such a matcher better and better information about distance to payer and payee.\n> A surveillance node would deliberately defer broadcasting each pheromone it receives, in the hope that the matching pheromone reaches it as well and it can determine upper bounds on distance to both a payer and the corresponding payee.\n>\n> This can be fixed by having just the payee broadcast the pheromone, and have the payer wait for incoming pheromones from the payee.\n> Further, it preserves the current privacy of the payer, which is much harder to find in the current Lightning Network source-pathfinding onion-routing scheme, and adds privacy to the payee (the payer only knows its distance to the payee, not the exact node ID of the payee).\n>\n> -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> Having a single pheromone seed (or a pair of matched seeds) that is recognizable for the entire path prevents us from implementing any kind of path decorrelation.\n> This is fine when considering just the current HTLCs (which have the same property that a single path is recognizable as being a single path solely from the hash used), but PTLCs can buy us some privacy (the entire path has no single \"smoking gun\" that identifies it, just coincidences like being near in sidereal time, having similar value, having decrementing locktime...), which is then lost with the pheromone system.\n>\n> It is unclear to me whether this is fixable: you would need something that intermediate nodes can malleate, but which the matcher (which, if we go with the above \"only the payee sends out pheromones\", the payer is the only possible matcher) must somehow still recognize and match to the payment.\n>\n> This is a big weakness of Ant Routing.\n>\n> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> There have been some discussions as well of performing particularly complicated payment schemes by taking advantage of homomorphism of points and scalars, enabled by PTLCs.\n> It is not clear to me as well if the pheromone system can help or hinder such schemes.\n>\n> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> Confirming the path length is an additional step.\n> It can be elided by recognizing that the timelock component of the PTLC/HTLC routing must decrement at each hop.\n>\n> Suppose some node under-reports the distance that a pheromone travelled, in the hopes that the payment will go through them and they can earn fees thereby.\n> The payer can allocate only enough timelock to cover the reported length.\n> Since the true length of that path is actually longer, some other node will refuse to forward the payment due to insufficient timelock, and the payment fails and the under-reporting node will not earn fees anyway.\n>\n> Against this, however, we must caution that an under-reporting node might NOT be interested in earning fees, but instead to get payment statistics.\n> Thus it would be able to \"pheromone-hijack\" and acquire information about the amount of the payment and its payment hash/point, even though it knows the payment cannot push through.\n>\n> So this is not a perfect solution in terms of privacy.\n>\n> -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> Routing failures seem somewhat harder to handle.\n> Because the payer itself does not know the whole path to the payee, it would be pointless to reveal which node actually failed to forward; the payer can do nothing about this information anyway.\n> The payer can only just try with a different peer that has also reported the target pheromone.\n>\n> Against this, however, we can point out that we can reduce payment failures.\n> The fact that a pheromone reached the payer recently indicates that the forwarding nodes along that path have also recently been online and working, so the chances of it going offline soon are expected to be low.\n> Further, if a channel is imbalanced with most of the value owned by a forwarding node, the forwarding node can simply avoid sending a pheromone down that channel, since it would not be likely to be routable via that channel anyway.\n>\n> Perhaps in terms of failure, a forwarding node could also remember the second-lowest distance pheromone, and report a failure back as an increase in the effective pheromone distance along that path (or a \"true failure\" where it knows of no second-lower distance pheromone).\n> Further a forwarding node which has received more than one equal-distance pheromone can just retry the HTLC along those pheromone distances.\n> This is similar to how JIT Routing works, with payments effectively getting rerouted via alternate paths without telling the original payer the exact details of the payment rerouting.\n>\n> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> Distance measurements need not be in units of hops.\n>\n> ------------------------------------------------------\n>\n> Finally: a MAJOR objection against Ant Routing.\n>\n> The main reason why Lightning is a scaling solution is that it drastically reduces how many nodes you tell about a payment.\n> Compare this to the blockchain layer, where every node has, at minimum, to be told about every confirmed transaction, and this is the reason why we have a block size limit in the first place.\n>\n> With Ant Routing, every payment needs to have a pheromone broadcasted.\n> This pheromone will reach out to every part of the network.\n> (Even with pheromones emitted at both the payer and payee end, it is likely that one or the other pheromone will reach the entire network.)\n> Thus, we are still sending out data that has to reach each and every node on the network at each payment.\n>\n> This negates the big-O scaling achieved by Lightning.\n>\n> Admittedly, constant factors are much lower with Ant Routing and it may remain practical.\n> If you use a pheromone emitted only by the payee, we can probably use just 160 bits or even 128 bits of entropy for the pheromone identifier; it only has to be a universally-unique identifier without any special mathematical properties, and the invoice could contain the pheromone identifier as well, thus reducing the communications rounds between payer and payee to a single communication, the invoice (same as current Lightning).\n> The distance count could be a single byte (if we use units in terms of hops).\n> This means 17 bytes broadcasted to the entire network per payment (compared to the hundred bytes or so needed per payment on the blockchain layer).\n>\n> --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n>\n> In summary, two main objections:\n>\n> -   Ant Routing sends data proportional to p payments to n nodes or O(pn).\n>     Current source routing just sends data proportional to p payments to a constant limit of nodes or O(p).\n>\n> -   Surveillors can easily determine payments and the maximum distance to the destination and likely source.\n>     This is same as current Lightning but we already have proposal (path decorrelation by using payment points) to remove it, it seems not to be useable with Ant Routing.\n>\n>     Regards,\n>     ZmnSCPxj\n>\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200212/c17dd0e2/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-12T10:47:55",
                "message_text_only": "Good morning The Authors,\n\n> Hello ZmnSCPxj,\n> \u00a0\u00a0 Thank you for your comments, we are glad for your interest in our work. Below some answers to your comments.\n> \u00a0 Concerning the information that intermediary nodes can gather from counters:\u00a0We are working under the assumption of a large highly connected network (with thousands of nodes and node connection larger than 10, or nodes connected to highly connected nodes if they are newcomers).\u00a0 Such a network has a very different geometry from the plane. In particular, triangulation is not feasible in general. Typically the distance between the majority of any pair of nodes is between 3 and 7 for a worldwide network. We want to obfuscate the counter to avoid giving information to immediate neighbours (that in principle are more trustable than others) about the origin or end of the transaction. Also, finding the shortest path in a highly connected graph is not our primary concern since most paths are quite short, which is why we are not considering optimization with a Dijkstra type algorithm.\n\nAssuming a space whose dimensionality approaches infinity, yes, you are correct.\nBut not all nodes will have significant numbers of channels, and there may be sections of the network that are more \"plane\"-like than the assumed inifinite number of dimensions, meaning a limited number of nodes can be used to usefully triangulate.\nIt seems unreasonable to assume an infinite number of dimensions given that each node will only have a finite number of channels, thus I suspect there is *some* number of nodes that can usefully triangulate each and every pheromone.\nThat number could be impractically high for most, but seems to be less than infinity.\n(In particular, the blocksize limit also limits the number of channels, thus limits how many possible dimensions the graph will have on average.)\n\n> Concerning spamming, this is unavoidable (as for the Bitcoin network) and scrutinity from nodes is required. Nodes are free to relay the seeds that they want. In particular, if a node N notices that one of its neighbours, say node M, starts spamming the network with pheromones (with a traffic much larger than its historical average share), then N can choose to ignore the seeds coming from M. It is even in N's best interest to be careful not to relay what he perceives as spams, because N itself could otherwise be branded as \"spammer\" by its neighbours. For this reason it is advisable for nodes to keep historic data on behaviour of neighbours and close the channels if they suspect them of acting maliciously (which can be revealed with the historical data).\n\nThat is doable I suppose, but the details contain the devil.\n\n> Concerning payment failures: it was our understanding that the reason for the high failure rate of the current routing algorithm is because\n> Alice doesn't know the channel balances of other nodes, and thus cannot be sure that her choice of path has enough funds to forward her payment. Ant routing\n> solves this problem during the pheromone phase: a node\u00a0 forwards the pheromone to a neighbour only if the channel balance allows the amount of the transaction to go through. This way, when Alice receives a matched seed, she is certain that the channel balances on the path have enough funds to forward her whole payment. It is also our understanding that the gossip network (that can also be a source of spamming) is used to update the channel balance in the routing tables. Note that the update of these channel balances, which seems necessary with the current routing, reveals and deanonimizes who has made transactions in the last period (and we can even reconstruct very easily a lot of transactions if updates are made often).\n\nThis is incorrect --- channel balances, or even hints of channel balances, are currently not broadcasted, and there are now moves to make channel updates very rare to limit the ability to spam gossip.\nThus gossip in the current Lightning network is bounded by the transactions-per-second of the blockchain layer.\n\n> When you say \"Distance measurements need not be in units of hops\", I am not sure what you mean here, and why this is a problem; could you elaborate?\n\nThis is a random comment and not a problem.\nDistance measurements might be measured in some other unit than raw hops --- for example, it could be in terms of a flat millisatoshi fee that each node charges for forwarding.\n\nIt is not clear to me if there is any point to this, but it may be useful to consider other units than just hops, not saying there is, just a random thought that has no true followup (at least for now).\n\n> Concerning your \"main objection\": as you noticed, the size of pheromones is significantly less than bitcoin transactions (16 Bytes, as we indicate in the paper) and they are deleted after 3 seconds (this keeps the seed mempool small). Pheromone Ids can be so small because they only need to distinguish between the about 30k tx present in the seed mempool (for a regime of about 10k tx/sec). The purpose of our paper is to prove scalability up to 10.000 tx/sec, we don't claim anything else, and certainly not infinite scalability. In that regard,theoretical O-estimates seem irrelevant to us (any O-estimate is dependent of the implicit constants and the hardware used, and is only relevant when we aim for \"infinite scalability\"). In the paper, we have a more practical and direct approach and we use the Bitcoin network that scales to 5-7 tx/sec as a proxy for the flooding algorithm . The argument is given in Section 6 of the paper. If you have any objection to that section we will be glad to discuss it and we would like to understand why your objection does not apply to the Bitcoin network or the other networks that are given as examples.\n\nThe Bitcoin network only propagates a transaction if it:\n\n* Does not spend any UTXOs that are currently spent by any transaction in the mempool.\n* OR, if it does, has a higher fee than the transactions it would remove from the mempool.\n\nThe number of UTXOs is finitely bounded by the existing history of the blockchain, and transactions can kick out transactions they double-spend only if they pay a higher fee, and nobody owns infinite bitcoins, so at *some* point you will be unable to propagate a transaction that spends the finite number of UTXOs you control: the total amount in those UTXOs bounds your ability to spam the network with more transactions.\nOr: fees bound your ability to spam.\n(Others may be better able to correct or more accurately present the spam-mitigations done by Bitcoin, but I think the above is a rough \"broad strokes\" correct.)\n\nThe current Lightning Network gossip reuses the above \"fee limits your ability to spam\" by requiring that a deeply confirmed transaction output commit to your channel, and you are allowed to output only so much data about this channel.\nIf you want to push more data into the gossip network, you need to have more confirmed transactions, and it is the fees involved in confirming at the blockchain layer which limits your ability to spam the Lightning gossip network.\n\nNo such fee-based limit exists for Ant routing, though I admit your proposals for otherwise limiting rates of pheromones appear sound (but I am no expert on spam-mitigation; what we normally do is require that people prove they have some funds in a Lightning channel, so anything not based on that is not something I have much experience using).\n\n\nRegards,\nZmnSCPxj\n\n> Best,\n> The authors\n>\n> \u00a0\n>\n> De : ZmnSCPxj <ZmnSCPxj at protonmail.com>\n>\n> Envoy\u00e9 : dimanche 9 f\u00e9vrier 2020 01:57\n>\n> \u00c0 : ZmnSCPxj <ZmnSCPxj at protonmail.com>\n>\n> Cc\u00a0: LEH\u00c9RICY Gabriel <gabriel.lehericy at devinci.fr>; GRUNSPAN Cyril <cyril.grunspan at devinci.fr>; Ricardo P\u00e9rez Marco <ricardo.perez.marco at gmail.com>; lightning-dev at lists.linuxfoundation.org <lightning-dev at lists.linuxfoundation.org>\n>\n> Objet : Re: [Lightning-dev] New paper on ant routing\u00a0\n> Good morning Gabriel,\n>\n> Some further thinking:\n>\n> --\n>\n> I notice as well that you propose to add a random number to the initial hop distance counter.\n> This does not quite obscure as much as you might think.\n>\n> Suppose I have two nodes I control in the Lightning Network, which we will pretend is this blank sheet of paper.\n>\n> \u00a0\u00a0\u00a0 +------------------------------------------+\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 X\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 X\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 +------------------------------------------+\n>\n> Now suppose my two nodes happen to receive the same pheromone, and the distance counters are equal.\n> I can then conclude that the originating node has the same distance to my two nodes, or:\n>\n> \u00a0\u00a0\u00a0 +------------------------------------------+\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 :\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 :\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 :\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 :\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 :\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 :\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 X\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 :\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 X\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 :\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 :\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 :\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 :\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 :\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 :\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 |\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 :\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n> \u00a0\u00a0\u00a0 +------------------------------------------+\n>\n> The originating node is now known to be somewhere along the above dotted line.\n> (the same analysis can be done even if the distance counters received by both nodes are not equal: I can just take the difference between them, which automatically cancels out the random number you are trying to use to obscure the distance, and get an indicator of whether the dotted line should be nearer to one node or the other.)\n>\n> Worse, if I have a *third* node, then I can get two more such lines, and then triangulate where the originator of the pheromone is.\n>\n> You can bet that any surveillor is going to run multiple nodes.\n> So the added random number is just going to protect against single-node operators, but even medium-corporate-level surveillors will be able to run as few as 3 nodes on the network.\n> And since pheromones are broadcast to the *entire* network, 3 nodes is enough to make a mapping of pheromone-to-node.\n>\n> Of course, the real Lightning Network is not a sheet of paper, so maybe 3 nodes will still not be enough, but a small number of nodes will be able to make such a mapping.\n> And of course since every node and channel in Ant Routing is unpublished, such a surveillor will still need to do some extra work to map out the network by other means.\n>\n> --\n>\n> An advantage of the current published network is that it automatically gives a way to discover other nodes you can connect to and make channels with.\n>\n> This even gets spam-capping for free, since we only gossip about nodes which have a proof that they have at least one channel somewhere.\n>\n> --\n>\n> Channel rebalancing seems difficult with Ant Routing.\n> Rebalancing is basically making a payment to oneself, and the shortest path to yourself is to do nothing.\n>\n> --\n>\n> Nothing prevents someone spamming the network with pheromones for payments they are not going to receive anyway.\n> Creating pheromones for broadcast would have to be costly, but that now allows certain initiator-does-not-pay attacks where the sender keeps requesting invoices from the receiver, which creates a pheromone for each apparent invoice, but the sender does not actually make any payments.\n>\n> --\n>\n> One can observe that Dijkstra algorithm is a simulation of pheromones in Ant Routing, and is why Dijkstra can actually discover shortest paths.\n>\n> Thus, one might consider Ant Routing to be a sort of \"distributed Dijkstra\".\n> We observe as well that, without an \"early-out\" case, Dijkstra really forms a shortest-path tree of the entire routemap.\n>\n> Regards,\n> ZmnSCPxj\n>\n> > Good morning Gabriel,\n> >\n> > Interesting idea and it helps to reduce routemap size by completely eliminating the routemap, and also removes distinctions between published and unpublished channels by making every channel unpublished.\n> > However there seem to be some considerations as well.\n> >\n> > -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n> >\n> > A node which is able to match the payee seed pheromone and the payer seed pheromone knows the total distance traversed between the payer and payee, and also knows exactly the distance between itself and the payee/payer.\n> > Admittedly this only gives an upper bound on the distance, but the pheromone system with its ability to find shorter and shorter paths will, over time, give such a matcher better and better information about distance to payer and payee.\n> > A surveillance node would deliberately defer broadcasting each pheromone it receives, in the hope that the matching pheromone reaches it as well and it can determine upper bounds on distance to both a payer and the corresponding payee.\n> >\n> > This can be fixed by having just the payee broadcast the pheromone, and have the payer wait for incoming pheromones from the payee.\n> > Further, it preserves the current privacy of the payer, which is much harder to find in the current Lightning Network source-pathfinding onion-routing scheme, and adds privacy to the payee (the payer only knows its distance to the payee, not the exact node ID of the payee).\n> >\n> > -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n> >\n> > Having a single pheromone seed (or a pair of matched seeds) that is recognizable for the entire path prevents us from implementing any kind of path decorrelation.\n> > This is fine when considering just the current HTLCs (which have the same property that a single path is recognizable as being a single path solely from the hash used), but PTLCs can buy us some privacy (the entire path has no single \"smoking gun\" that identifies it, just coincidences like being near in sidereal time, having similar value, having decrementing locktime...), which is then lost with the pheromone system.\n> >\n> > It is unclear to me whether this is fixable: you would need something that intermediate nodes can malleate, but which the matcher (which, if we go with the above \"only the payee sends out pheromones\", the payer is the only possible matcher) must somehow still recognize and match to the payment.\n> >\n> > This is a big weakness of Ant Routing.\n> >\n> > ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n> >\n> > There have been some discussions as well of performing particularly complicated payment schemes by taking advantage of homomorphism of points and scalars, enabled by PTLCs.\n> > It is not clear to me as well if the pheromone system can help or hinder such schemes.\n> >\n> > ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n> >\n> > Confirming the path length is an additional step.\n> > It can be elided by recognizing that the timelock component of the PTLC/HTLC routing must decrement at each hop.\n> >\n> > Suppose some node under-reports the distance that a pheromone travelled, in the hopes that the payment will go through them and they can earn fees thereby.\n> > The payer can allocate only enough timelock to cover the reported length.\n> > Since the true length of that path is actually longer, some other node will refuse to forward the payment due to insufficient timelock, and the payment fails and the under-reporting node will not earn fees anyway.\n> >\n> > Against this, however, we must caution that an under-reporting node might NOT be interested in earning fees, but instead to get payment statistics.\n> > Thus it would be able to \"pheromone-hijack\" and acquire information about the amount of the payment and its payment hash/point, even though it knows the payment cannot push through.\n> >\n> > So this is not a perfect solution in terms of privacy.\n> >\n> > -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n> >\n> > Routing failures seem somewhat harder to handle.\n> > Because the payer itself does not know the whole path to the payee, it would be pointless to reveal which node actually failed to forward; the payer can do nothing about this information anyway.\n> > The payer can only just try with a different peer that has also reported the target pheromone.\n> >\n> > Against this, however, we can point out that we can reduce payment failures.\n> > The fact that a pheromone reached the payer recently indicates that the forwarding nodes along that path have also recently been online and working, so the chances of it going offline soon are expected to be low.\n> > Further, if a channel is imbalanced with most of the value owned by a forwarding node, the forwarding node can simply avoid sending a pheromone down that channel, since it would not be likely to be routable via that channel anyway.\n> >\n> > Perhaps in terms of failure, a forwarding node could also remember the second-lowest distance pheromone, and report a failure back as an increase in the effective pheromone distance along that path (or a \"true failure\" where it knows of no second-lower distance pheromone).\n> > Further a forwarding node which has received more than one equal-distance pheromone can just retry the HTLC along those pheromone distances.\n> > This is similar to how JIT Routing works, with payments effectively getting rerouted via alternate paths without telling the original payer the exact details of the payment rerouting.\n> >\n> > ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n> >\n> > Distance measurements need not be in units of hops.\n> >\n> > ------------------------------------------------------\n> >\n> > Finally: a MAJOR objection against Ant Routing.\n> >\n> > The main reason why Lightning is a scaling solution is that it drastically reduces how many nodes you tell about a payment.\n> > Compare this to the blockchain layer, where every node has, at minimum, to be told about every confirmed transaction, and this is the reason why we have a block size limit in the first place.\n> >\n> > With Ant Routing, every payment needs to have a pheromone broadcasted.\n> > This pheromone will reach out to every part of the network.\n> > (Even with pheromones emitted at both the payer and payee end, it is likely that one or the other pheromone will reach the entire network.)\n> > Thus, we are still sending out data that has to reach each and every node on the network at each payment.\n> >\n> > This negates the big-O scaling achieved by Lightning.\n> >\n> > Admittedly, constant factors are much lower with Ant Routing and it may remain practical.\n> > If you use a pheromone emitted only by the payee, we can probably use just 160 bits or even 128 bits of entropy for the pheromone identifier; it only has to be a universally-unique identifier without any special mathematical properties, and the invoice could contain the pheromone identifier as well, thus reducing the communications rounds between payer and payee to a single communication, the invoice (same as current Lightning).\n> > The distance count could be a single byte (if we use units in terms of hops).\n> > This means 17 bytes broadcasted to the entire network per payment (compared to the hundred bytes or so needed per payment on the blockchain layer).\n> >\n> > --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n> >\n> > In summary, two main objections:\n> >\n> > -\u00a0\u00a0 Ant Routing sends data proportional to p payments to n nodes or O(pn).\n> >\u00a0\u00a0\u00a0\u00a0 Current source routing just sends data proportional to p payments to a constant limit of nodes or O(p).\n> >\n> > -\u00a0\u00a0 Surveillors can easily determine payments and the maximum distance to the destination and likely source.\n> >\u00a0\u00a0\u00a0\u00a0 This is same as current Lightning but we already have proposal (path decorrelation by using payment points) to remove it, it seems not to be useable with Ant Routing.\n> >\n> >\u00a0\u00a0\u00a0\u00a0 Regards,\n> >\u00a0\u00a0\u00a0\u00a0 ZmnSCPxj\n> >\n> >\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-12T22:50:58",
                "message_text_only": "Good morning again The Authors,\n\n> > \u00a0 Concerning the information that intermediary nodes can gather from counters:\u00a0We are working under the assumption of a large highly connected network (with thousands of nodes and node connection larger than 10, or nodes connected to highly connected nodes if they are newcomers).\u00a0 Such a network has a very different geometry from the plane. In particular, triangulation is not feasible in general. Typically the distance between the majority of any pair of nodes is between 3 and 7 for a worldwide network. We want to obfuscate the counter to avoid giving information to immediate neighbours (that in principle are more trustable than others) about the origin or end of the transaction. Also, finding the shortest path in a highly connected graph is not our primary concern since most paths are quite short, which is why we are not considering optimization with a Dijkstra type algorithm.\n>\n> Assuming a space whose dimensionality approaches infinity, yes, you are correct.\n> But not all nodes will have significant numbers of channels, and there may be sections of the network that are more \"plane\"-like than the assumed inifinite number of dimensions, meaning a limited number of nodes can be used to usefully triangulate.\n> It seems unreasonable to assume an infinite number of dimensions given that each node will only have a finite number of channels, thus I suspect there is some number of nodes that can usefully triangulate each and every pheromone.\n> That number could be impractically high for most, but seems to be less than infinity.\n> (In particular, the blocksize limit also limits the number of channels, thus limits how many possible dimensions the graph will have on average.)\n\nA reason why I think it is unreasonable to assume that this kind of triangulation is possible is the existence of the Dandelion proposal for the Bitcoin network.\n\nConsider that when a Bitcoin node broadcasts a transaction, what it really does is that it selects an arbitrary large number, in units of Planck intervals since the Epoch (i.e. the Big Bang), more commonly known by mere humans as \"the current time\".\nThen, surveillance nodes on the Bitoin network receive the transaction with this counter updated by some delta number-of-Planck-intervals-since-the-Epoch.\nCooperating surveillance nodes can then compare the number at which they got the transaction with each other, in order to guess which node on the Bitcoin network originally broadcasted the transaction.\n\nMy understanding is that this triangulation is successful often enough to be a problem for privacy, which is why Dandelion even *exists*.\nAdmittedly, this is just SPV-level verification (I am looking at the fact that people have poured work into Dandelion and from there assume that \"people can traingulate the broadcaster of the transaction in the Bitcoin network\" is in fact true, without actually validating that myself).\n\nSince the same analysis is basically possible with Ant Routing using units of hops rather than Planck-intervals-since-the-Epoch, I think you still have the same basic problem that Dandelion is solving, assuming of course that the fact that Dandelion exists and is being worked on implies the problem actually exists.\n\n(I guess this is where the \"Distance counters need not be in units of hops\" trap card triggers.)\n\nMore importantly: on the Bitcoin network, a node can drop a connection with a peer and then select a new node to connect with, at very little cost or risk.\nOn the Lightning network, a node closing a channel and then re-opening elsewhere is significantly more costly and time-consuming and risky.\nThis means that any probes on the network topology of Lightning are likely to remain valid for longer than probes on the topology of Bitcoin network, meaning we expect this kind of triangulation to be *easier* on Lightning than on Bitcoin, simply because of the greater permanence of channels vs connections.\n\nFortunately, the fact that Dandelion exists means you can probably just reuse it here.\nWhen a payee wants to broadcast a pheromone, it instead sends it to one peer with the \"stem\" flag set.\nWhen a node receives a pheromone with the \"stem\" flag set, it randomly promotes it to \"fluff\" stage and broadcasts it itself, or sends it out again to one other peer with the \"stem\" flag still set.\nAdditional tooling will be needed to ensure a stem does not get stuck, and so on, I am sure the people working on Dandelion can give you additional details.\nThis misleads triangulation and strengthens the obfuscation you add to the distance counters.\n\n\n> > Concerning payment failures: it was our understanding that the reason for the high failure rate of the current routing algorithm is because\n> > Alice doesn't know the channel balances of other nodes, and thus cannot be sure that her choice of path has enough funds to forward her payment. Ant routing\n> > solves this problem during the pheromone phase: a node\u00a0 forwards the pheromone to a neighbour only if the channel balance allows the amount of the transaction to go through.\n\nThis neglects the possibility that an intermediate node might propagate a pheromone outward, then suddenly the neighbors, who happen to be Alvin & the Chipmunks, blow up the street post that happens to be supporting  the power supply going into the node before the payment could be routed through.\n\nGranted, the probability of an intermediate node happening to have Alvin & the Chipmunks as neighbors is exceedingly low, possibly below 1 in 2^128 , but I think the more general case of a node failing *after* it propagates a pheromone but *before* it could be routed through must be considered.\nAnt Routing makes this probability smaller, but does not eliminate it completely, and robust payment systems still need to handle this.\n\nIf the payer only has a single channel, how can intermediate nodes help it find alternate routes?\nIt seems to me that intermediate nodes need to store other pheromones with higher distance counters as well, not just the payer, in the extreme case where the payer has only one channel, intermediate nodes will have to assist the payer by saying \"actually you have to adjust your distance estimate by +N now because something bad happened\".\nAnd since you need to support retrying, you may need to extend your pheromone timeout from 3s.\nThe additional memory and timeout probably means you have to shave off a 0 from your scaling estimates as well.\n\n--\n\nAnother thing: it is unreasonable as well to promote the assumption \"the payee must be online to receive\" to the assumption \"the payee is *contactable by the payer* to receive\".\n\nConsider this (hopefully very very common) case:\n\n* A fan decides to donate to me over Lightning and asks me (over IRC or email) for an invoice to donate to.\n* Since I am ZmnSCPxj, my node is only contactable over an .onion service and is not contactable over IPv4 or IPv6.\n* My fan, unfortunately, did not install Tor.\n\nThus, while my node is *online*, it is *not contactable by the payer*.\n\nWith the current Lightning Network, this is perfectly fine, because I only need to transmit a single invoice, and I can access email / IRC over Tor myself.\nWith the Ant Routing proposal, the payer is now stymied as it needs some way to directly contact my node, and that means more engineering and implementation work to let a Tor-less payer contact a Tor-only payee.\n\nAny routing proposal that requires continuous communication between payer and payee, instead of a one-time send of an invoice from payee to payer, makes this unreasonable assumption.\n\n--\n\nIt seems to me you can use just a one-byte distance counter, if we assume that the network graph cannot have a diameter greater than 127 hops.\nThis seems a reasonable assumption, given you are already assuming a well-connected network as well, which tends to reduce graph diameters.\n\nWith wraparound, I can implement a less than operation based on subtraction modulo 256, then cast it to a signed byte and then use the sign bit to determine which of two distance counters is lesser or greater.\nDistances are expected to be small anyway, so any extra range in the original subtraction modulo whatever is wasted anyway.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "New paper on ant routing",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "LEH\u00c9RICY Gabriel",
                "ZmnSCPxj"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 87531
        }
    },
    {
        "title": "[Lightning-dev] Few questions",
        "thread_messages": [
            {
                "author": "Cezary Dziemian",
                "date": "2020-02-09T09:25:21",
                "message_text_only": "Good morning, there are few things I'm not completely sure about, so would\nlike to ask in order to prevent misunderstanding in Polish LN community.\n\n1. Is this possible that by sending funds without invoice, the last hub\nprepares the last HTLC with small amount to the payee? In other words - Can\npayee detect, that the last HTLC amount is smaller that it should be?\n\n2. Are there additional data added to the end of onion encrypted list of\nHTLCs in order to prevent last hub to guess, that it is the last hub in the\nroute?\n\n3. When payment is during confirmation, are channels locked entirely, or\nonly for the in flight payment amount? In other words - can single channel\nprocess more that single transaction at once?\n\nI would like to kindly pleas to reply in simple words, as my English is\nstill far from being perfect.\n\nBest Regards,\nCezary Dziemian\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200209/db6a7726/attachment.html>"
            },
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2020-02-09T09:51:02",
                "message_text_only": "Good Morning Cezary,\n\nyou might want to direct questions about understanding the lightning\nnetwork protocol like yours to https://bitcoin.stackexchanage.com as this\nmailinglist is more devoted towards driving the development of the\nprotocol. Anyway here are the answers to your questions 2 and 3 and\nprobably also to the first one though I am not entirely sure if I\nunderstand exactly what you are asking for. In case I misunderstood you\nsuggest to put follow up questions on stackexchange.\n\n1. Is this possible that by sending funds without invoice, the last hub\n> prepares the last HTLC with small amount to the payee? In other words - Can\n> payee detect, that the last HTLC amount is smaller that it should be?\n>\n\nBut in general the payee will only release the preimage for an invoice if\nthe payee is satisfied with the amount - which is usually specified in the\ninvoice. If you talk about keysend then the payee does not expect an amount\nand will most likely release the preimage as the payee would consider this\nto be free money\n\n\n> 2. Are there additional data added to the end of onion encrypted list of\n> HTLCs in order to prevent last hub to guess, that it is the last hub in the\n> route?\n>\n\nyes the onions are always of constant size (20 * 65 Byte = 1300 Byte) This\nprocess of padding is well described in the Sphinx paper\nhttps://cypherpunks.ca/~iang/pubs/Sphinx_Oakland09.pdf and in BOLT 04\nhttps://github.com/lightningnetwork/lightning-rfc/blob/master/04-onion-routing.md\n\n3. When payment is during confirmation, are channels locked entirely, or\n> only for the in flight payment amount? In other words - can single channel\n> process more that single transaction at once?\n>\n\nHTLCs are additional outputs in the commitment transaction. The protocol\nallows for up to 483 htlcs concurrently in flight as specified in BOLT 04 (\"\nmax_accepted_htlcs is limited to 483 to ensure that, even if both sides\nsend the maximum number of HTLCs, the commitment_signed message will still\nbe under the maximum message size. It also ensures that a single penalty\ntransaction can spend the entire commitment transaction, as calculated in BOLT\n#5\n<https://github.com/lightningnetwork/lightning-rfc/blob/master/05-onchain.md#penalty-transaction-weight-calculation>\n.\")\n\nHowever the the standard of implementations and recommendation is 30. This\nmeans that a single payment is not freezing the channel. It however \"locks\"\nthe amount of that payment which for the time until settlement cannot be\nused by either party of the channel for other payments / activities.\n\nwith kind regards Rene\n\n\n> I would like to kindly pleas to reply in simple words, as my English is\n> still far from being perfect.\n>\n> Best Regards,\n> Cezary Dziemian\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n\n\n-- \nhttps://www.rene-pickhardt.de\n\nSkype: rene.pickhardt\n\nmobile: +49 (0)176 5762 3618\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200209/d8727a02/attachment-0001.html>"
            },
            {
                "author": "Cezary Dziemian",
                "date": "2020-02-10T17:53:16",
                "message_text_only": "Thanks a lot for clarification Ren\u00e9.\n\nSorry for that, next time I will not use dev list to ask such questions,\nbut in \"keysend\" there are some details would like to discuss.\n\nDo we agree, that because payee doesn't know amount that payer wants to\nsend him, the last hub can just prepare own HTLC for one satoshi? If this\nis true, I think this is not correct behavior. If payer wants to pay X,\npayee shouldn't receive less.\n\nCan't payer just send \"preimage + amount\" encrypted by payee pub key? That\nway payee can check what amount payer wanted to send him, and should reject\nif HTLC contains other value.\n\nBest Regards,\nCD\n\nniedz., 9 lut 2020 o 10:51 Ren\u00e9 Pickhardt <r.pickhardt at googlemail.com>\nnapisa\u0142(a):\n\n> Good Morning Cezary,\n>\n> you might want to direct questions about understanding the lightning\n> network protocol like yours to https://bitcoin.stackexchanage.com as this\n> mailinglist is more devoted towards driving the development of the\n> protocol. Anyway here are the answers to your questions 2 and 3 and\n> probably also to the first one though I am not entirely sure if I\n> understand exactly what you are asking for. In case I misunderstood you\n> suggest to put follow up questions on stackexchange.\n>\n> 1. Is this possible that by sending funds without invoice, the last hub\n>> prepares the last HTLC with small amount to the payee? In other words - Can\n>> payee detect, that the last HTLC amount is smaller that it should be?\n>>\n>\n> But in general the payee will only release the preimage for an invoice if\n> the payee is satisfied with the amount - which is usually specified in the\n> invoice. If you talk about keysend then the payee does not expect an amount\n> and will most likely release the preimage as the payee would consider this\n> to be free money\n>\n>\n>> 2. Are there additional data added to the end of onion encrypted list of\n>> HTLCs in order to prevent last hub to guess, that it is the last hub in the\n>> route?\n>>\n>\n> yes the onions are always of constant size (20 * 65 Byte = 1300 Byte) This\n> process of padding is well described in the Sphinx paper\n> https://cypherpunks.ca/~iang/pubs/Sphinx_Oakland09.pdf and in BOLT 04\n> https://github.com/lightningnetwork/lightning-rfc/blob/master/04-onion-routing.md\n>\n> 3. When payment is during confirmation, are channels locked entirely, or\n>> only for the in flight payment amount? In other words - can single channel\n>> process more that single transaction at once?\n>>\n>\n> HTLCs are additional outputs in the commitment transaction. The protocol\n> allows for up to 483 htlcs concurrently in flight as specified in BOLT 04 (\"\n> max_accepted_htlcs is limited to 483 to ensure that, even if both sides\n> send the maximum number of HTLCs, the commitment_signed message will\n> still be under the maximum message size. It also ensures that a single\n> penalty transaction can spend the entire commitment transaction, as\n> calculated in BOLT #5\n> <https://github.com/lightningnetwork/lightning-rfc/blob/master/05-onchain.md#penalty-transaction-weight-calculation>\n> .\")\n>\n> However the the standard of implementations and recommendation is 30. This\n> means that a single payment is not freezing the channel. It however \"locks\"\n> the amount of that payment which for the time until settlement cannot be\n> used by either party of the channel for other payments / activities.\n>\n> with kind regards Rene\n>\n>\n>> I would like to kindly pleas to reply in simple words, as my English is\n>> still far from being perfect.\n>>\n>> Best Regards,\n>> Cezary Dziemian\n>>\n>>\n>> _______________________________________________\n>> Lightning-dev mailing list\n>> Lightning-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>>\n>\n>\n> --\n> https://www.rene-pickhardt.de\n>\n> Skype: rene.pickhardt\n>\n> mobile: +49 (0)176 5762 3618\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200210/24934f4c/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Few questions",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Ren\u00e9 Pickhardt",
                "Cezary Dziemian"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 8250
        }
    },
    {
        "title": "[Lightning-dev] A New Routing Paradigm:Ant Routing +`getroutequick` + Trampoline",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-10T10:35:26",
                "message_text_only": "Overview of Components\n======================\n\nAnt Routing\n-----------\n\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2020-February/002505.html\n\nAnt Routing is a distributed pathfinding algorithm where nodes emit \"pheromones\", which are broadcasted over the entire network.\nWhen a node receives a pheromone (a UUID plus a distance counter) from a peer it has a channel with, it records that pheromone locally, then broadcasts it to other peers it has channels with, but with the distance counter increased by one.\n\nSubsequently, a payee can then provide the pheromone identifier to a payer, which can check if it has received that pheromone, and from which channel it received it from.\nIt can the forward the payment via the channel.\nThe next node can itself perform this operation, looking up the pheromone identifier and determining which channel it came from, and so on, until the payment reaches the destination.\n\n`getroutequick`\n---------------\n\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2019-August/002095.html\nhttps://zmnscpxj.github.io/activity/2019-10-18/presentation.odp\n\nThe overall `getroutequick` algorithm simply uses a Greedy Best First Search, which requires a heuristic that returns a distance to the target.\nThe heuristic is generated from cached data: the cache itself is generated by first performing a Dijkstra on the entire routemap, recording the distance from our own node at each mapped node.\nThe `getroutequick` algorithm then starts at one end of the route, and the other end must be our own node; this typically makes sense since both ends of the route are the payer and the payee, and have an interest in the payment succeeding by having a route available.\n\nThe power of `getroutequick` lies in pre-caching the Dijkstra run; Dijkstra is heavy as it requires traversing the entire routemap, but its result can be cached and then used in Greedy Best First Search, which is likely to traverse only the shortest route.\nThis moves the heavy lifting from the point in time in which a payment is initiated, improving payment experience by reducing the amount of time needed to find a route to a particular payee.\n\nTrampoline\n----------\n\nhttps://github.com/lightningnetwork/lightning-rfc/pull/654\n\nTrampoline simply means doing onion routing at a level distinct from the individual channel level.\nAn onion route of \"trampoline\" nodes is formed, without specifying the exact channels in the route between them.\nCurrently, the idea is that there is an \"outer\" onion that describes a path to the next trampoline node, and an \"inner\" onion that describes the next-next trampoline node.\n\nDigression: On the Current Gossip System\n========================================\n\nCurrently, we use a gossip system where nodes and channels publicly show that particular outputs on the blockchain layer are actually funding transaction outputs that back channels.\n\nWhenever a new node joins the Lightning network, it anchors its existence to the blockchain by having a channel opened with it (either it funds, or is funded to).\nThen, on the basis of this anchored channel, it announces its existence.\nThis implies that bandwidth usage for this gossip system is bounded by the bandwidth limits we have imposed in the blockchain layer.\nThus, even though this gossip system requires the data to be broadcast globally to all nodes, the utilized resource is still bounded by the space limits of the Bitcoin blockchain layer.\n\nFurther, the gossip system allows announcements to be refreshed periodically.\nHowever, ultimately the amount of bandwidth used for routing information broadcast via gossip is bounded by the amount of bandwidth we have allowed the blockchain layer to use (i.e. the block size and block rate parameters of the blockchain).\n\nCombined Proposal\n=================\n\nCombining Ant Routing and `getroutequick`\n-----------------------------------------\n\nAnt routing, we can observe, is equivalent to a distributed form of Dijkstra algorithm.\nIts major drawback is that every payment causes the emission of a pheromone, which must be broadcasted to the entire network.\nThis implies using resources proportional to the total number of payments globally, unlike the current Lightning network where each node only gets data regarding payments it is involved in routing.\nThis reverses the advantage of Lightning network, making it as inefficient (in terms of big-O, not necessarily in the lower-level details) as a blockchain.\n\n`getroutequick` works by pre-caching the result of a Dijkstra run, with the result then used as the heuristic in a subsequent, faster Greedy Best First Search.\n\nThis leads to the realization that we could have a possible payee release a pheromone *once* (equivalent to the pre-cached Dijkstra run, now made distributed) and then subsequent payments to that payee just use the pre-cached Dijkstra by referring to that pheromone.\n(This reduces privacy as the pheromone persistently identifies the node, but I fix this later; please bear with me.)\n\n### Pheromone Handling\n\nSo what we do is, every node that wants to be a forwarding node keeps a mapping, from a non-self node ID to a distance counter.\nA pheromone is then composed of:\n\n* Node ID (33 bytes).\n* A reference to a channel that the node is a participant of (8 bytes, a short channel ID).\n* A proof that the Node ID is indeed a participant in the indicated channel (65 bytes for the node signature, 33 bytes for the node ID of the counterparty of the node, maybe some more bytes for whatever details on how the channel script is derived or whatever).\n* A distance counter (1 byte can probably fit; do we expect Lightning diameter to exceed 255? maybe in some really insane conditions? how attackable is this?).\n\nWhen a node receives a pheromone from a peer it has a channel with, it checks if the node already exists in its mapping.\nIf it exists, and the distance counter in the pheromone is larger than or equal to the distance counter in the mapping, it ignores the pheromone and does not propagate it.\nHowever, if the distance counter in the pheromone is less than that in the mapping, or the mapping does not contain that pheromone, it updates its mapping, then sends the pheromone to its peers it has channels with, but with the distance counter one greater than what it has now.\n\n### Distance Queries and Payment Routing\n\nA node can ask its direct peers about the distance of that peer to a specific node ID.\n(the peer could lie, but I cover this case later; please bear with me.)\n\nWhen a payer wants to route, the payer knows its (supposed) distance to the payee.\nIt then creates an HTLC whose timelock limit is limited only to the given distance to the payee.\nThe payer then queries each online peer for its mapping of the payee node ID and distance counter.\nIt selects any online peer with sufficient payer-side capacity in the channel, whose distance counter is lower than its own and sends the HTLC out via a channel with that peer.\nIf there are no such, it could select any peer with the lowest distance counter (and update its own distance counter to be one higher than that peer as well).\n\nThe same operation is done by each forwarding node.\nIt queries each peer, where it has sufficient capacity to forward to, to get the distance counters for that node.\nThen it forwards to any peer that has lower distance counter than itself, to which it has sufficient capacity.\n\n### Forwarding Failures\n\nThere are only two failures:\n\n* The destination has absolutely no idea of what the fayment you are talking about.\n  * This case should include a proof that it comes from the destination, e.g. a signature.\n* A peer is unable to forward because the HTLC it receives has insufficient timelock remaining for it to forward to the destination, and it reports back how many more hops needs to be added (this has to be 1 or higher).\n\nFailures are not encrypted, i.e. they are in plaintext.\n\nSuppose a forwarding node currently thinks it is 2 hops away from the payee.\nHowever, the channel to the node that is 1 hop away is closed, or that node goes offline, etc.\n\nSince the forwarding node also propagated the pheromone outwards such that it is 2 hops away from the payee, the payer has allocated it just enough timelock in the HTLC that reaches it to be worth 2 hops of timelock.\nThe forwarding node then checks its *other* peers, in the hope that one of them is 1 hop away from the payee.\nIf it finds a peer that is one hop away, all is well with the world and it just forwards to that peer.\n\nOn the other hand, suppose it finds that the peer it has that is nearest to the payee is 4 hops away from the payee.\nIt updates its own distance counter to 5 (one higher than the peer that is nearest), then (because the HTLC has too little timelock left for that number of hops) it propagates a failure back to the incoming HTLC, with the indication +3 (i.e. it had to add +3 to its previous distance counter of 2 to get its current distance counter of 5).\nWhen the previous forwarding node (which presumably had a distance counter of 3) receives this failure, it can instead try to search other peers that have a distance counter of 2 or less and silently retry with those, or if there are none it could look for those that are still nearer than the adjusted counter of the failing peer (it was 2, but with the +3 is now at 5, so any peer it has that is 4 or less could be nearer and it can lower the adjustment of +3 to something lower), or if there are still none, propagate the +3 hops failure back to the previous node, and so on.\n\nSimilarly, when the ultimate payer receives this +N hops failure, it can readjust its own sense of how distant it is from that payee, then retry with the same peer, or a different peer that is now nearer than the updated distance of the peer that propagated the failure.\n\nThis case partially handles liars who underreport their distance to the payee.\nThey cannot forward the payment and expect the payment to push through, since some node beyond it will see that it has too little time left in the HTLC to propagate and report this as a +N hops failure.\nThe lying node can then only admit its lie and report back a +N hops failure, or keep mum and keep the HTLC until it is about to time out (the latter behavior is something current forwarding nodes can already do).\n(But note: a lying node could effectively censor a particular node, by misreporting its distance to that node as 1 and then keeping the HTLC around until near the locktime limit, then admit just a +1 hops failure (if it did not, its peer will drop the channel with the lying node onchain in order to enforce the locktime limit and will then search among *its* peers for how distant it truly is), slowly reducing its censorship but still able to do so among a number of nodes on the network; this will settle over time, but would still be a nasty attack.)\n(this could be mitigated if we had a clever mathematical construct such that if I have proof that somebody committed to N, I can forge a proof that the same somebody committed to N+1 but cannot forge a proof that somebody committed to N-1; maybe sinking signatures, with \"height\" in sinking signatures being some constant minus the distance? but then if you get N you could propagate N: and you could as well also be running multiple nodes that you propagate N to but not actually have channels with.)\n\n### Periodic Updates\n\nPeriodically, a node may want to update the Dijkstra run for itself, by re-emitting a new pheromone.\nThis refreshes the sense of the rest of the network of what their distance is to each node on the network.\n\nWe already allow the current gossip protocol to publish similar periodic updates to the channel and node announcements, thus we expect the big-O bandwidth use to be similar with periodic pheromone re-emission.\n\nPlugging Privacy With Trampoline Routing\n----------------------------------------\n\nThe core idea of trampoline routing is simply to add an onion routing to a level above individual channel hops.\n\nIn current Lightning, we use onion routing to encode individual channel hops.\nIndividual channel hops, with our new Ant Routing + `getroutequick` scheme, are handled by the distributed `getroutequick`.\nThis has the major drawback that the `getroutequick` needs to know the exact destination.\n\nFor this new routing paradigm, we simply add an onion routing on a layer above the channel-level routing, in much the same way that Tor adds onion routing on top of the TCP router-leving routing.\nThat is, we move the onion packet from the hop level to the trampoline node level.\n\nAn onion packet is sent to the destination that we admit to the `getroutequick` channel-level routing layer.\nThis onion packet indicates openly how much of the HTLC timelock is allocated to reach that destination, and how much is allocated to the destination itself.\nOn reaching the destination, it unwraps the onion by one layer, and it might find that it is the final destination, or that it has to use the allocated timelock as well to forward to the next destination.\n\n### Payer Allocation\n\nEach node already has a mapping of nodes to distance counters.\nThus, to make a payment to a node, it need only find some number of nodes in this mapping.\n\nIdeally, it finds two other nodes that are nearer to it than the payee node (i.e. has distance counters lower than the distance to the actual payee) in the hope that they will be in \"the same\" direction or area as the final destination.\n\nSuppose that it currently has a destination, and selects an intermediate node in the trampoline onion.\nIt got both nodes from its local map of node ID to distance, thus it knows the distance from itself to both nodes (assuming this data is not too stale).\nBy considering itself, and the two nodes, as a triangle, we can conclude that the maximum distance between those two nodes is equal to the sum of the distances between itself and each of the nodes.\nSo for example if the trampoline node is 5 hops away and the payee is 3 hops away, then the maximum distance between both is 8 hops.\nSo, the payer will allocate 8 hops for the route from the intermediate node to the current destination.\n\nThe payer can repeat that however many times it wants, in order to add more layers to the trampoline onion.\nFor example, it could add second trampoline, with a distance of 6 hops away, and it gets the 5 hops distance of the previous trampoline node and adds those together, allocating 11 hops for the route from second to first trampoline, and allocating the above 8 hops for the first trampoline to the payee.\nThen, it sends out an HTLC of a total of 6 (distance to second trampoline) + 11 (route from second to first trampoline) + 8 (route from first trampoline to destination) hops of timelock and fees.\n\n### Trampoline-level Failures\n\nA trampoline node might, for some reason, not be able to find the next trampoline.\nIt might also find that the payer information is so stale that the budgeted number of hops for that trampoline hop is insufficient.\nIn those cases, the trampoline node can report back a failure.\n\nThese would have a distinct failure code compared to the +N hops needed failure at the channel hop level.\nHowever, it may be possible to add the destination \"I have no idea what the fayment you are talking about\" to these failures.\nLike the onion-wrapped failures in the current Lightning onion routing, it may be possible to also onion-wrap the failures at the trampoline node level.\nThen failures seen at the channel hop level are either \"some onion-wrapped failure\" or \"add +N hops plz\".\nOf note is that a trampoline node that finds it has been given insufficient budget should not use the \"add +N hops plz\" message, but an onion-wrapped failure (which itself might be just \"add +N hops plz, but to my budget\").\n\n### Payment Point Rotation\n\nWith payment point+scalar, we can have \"path decorrelation\", where each hop in the onion route changes the outgoing PTLC by a constant scalar that is secretly shared between itself and the original payer.\n\nThis will still work by moving the onion routing one level higher, from the level of channel hops to the level of trampoline nodes.\n\n### Hidden Destinations\n\nAnother advantage of trampoline onions is that the payee can provide a pre-encrypted trampoline onion which the payer can prepend its own trampoline nodes to, i.e. hidden destinations.\nThis feature remains unchanged when done on top of the hop-level Ant Routing + `getroutequick` scheme.\n\n\nAdvantages and Disadvantages\n----------------------------\n\nAdvantages:\n\n* Far fewer channels have to be published offchain; a node that wants to receive in the future needs only publish *one* of its channels in order to act as proof that it is on Lightning.\n  A node that expects many incoming payments can have multiple channels opened towards it, but only admit ownership of one channel.\n  Two cooperating nodes that have a channel between them can use that channel to prove their existence in their individual pheromones, thereby revealing to the rest of the network only a small number of channels.\n  This makes it much harder to map out the full network, but with this hiding much more consistently distributed among nodes, for better risk-sharing.\n  * Nodes that do not expect to receive in the future, except from direct peers, do not need to publish *any* channels.\n    Even if they do not publish *any* channels, however, they can still participate in forwarding, since forwarding nodes perform local queries to determine the next hop, and participation in forwarding is an important privacy technique; a node that regularly forwards can always claim that its payment is actually forwarded from somebody else, a property lost with the current \"private\"^H^H^H^H^H^H^H^H^Hunpublished channels.\n\nDisadvantages:\n\n* Censorship attacks are trivial: just lie about your distance to the node you want to censor and say you know them, then just HODL on to the HTLC that should go to them.\n  This is a major disadvantage, thus possibly a good reason to avoid this paradigm.\n  My hope is someone else can come up with some way to mitigate or remove this weakness.\n* We would need to impose a consistent feerate and CLTV-delta at each node.\n  * On the other hand, one can argue that it is precisely the ability of forwarding nodes to give arbitrary feerates that allows surveillors to effectively \"pay to surveill\" by giving below-market-rate feerates, so ***maybe*** central planning of this parameter (yuck!) would be useful... nah non-free-market, boo.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Cezary Dziemian",
                "date": "2020-02-11T18:58:51",
                "message_text_only": "That was really interesting to read this.\n\nWhy you want to send Node ID inside pheromone? Why not to send random\nnumber, that would be then passed though invoice?\n\nTo increase privacy, node could generate new random number every week and\ndistribute pheromone gain.\n\nBest regards,\nCezary Dziemian\n\n\npon., 10 lut 2020 o 11:35 ZmnSCPxj via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> napisa\u0142(a):\n\n> Overview of Components\n> ======================\n>\n> Ant Routing\n> -----------\n>\n>\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-February/002505.html\n>\n> Ant Routing is a distributed pathfinding algorithm where nodes emit\n> \"pheromones\", which are broadcasted over the entire network.\n> When a node receives a pheromone (a UUID plus a distance counter) from a\n> peer it has a channel with, it records that pheromone locally, then\n> broadcasts it to other peers it has channels with, but with the distance\n> counter increased by one.\n>\n> Subsequently, a payee can then provide the pheromone identifier to a\n> payer, which can check if it has received that pheromone, and from which\n> channel it received it from.\n> It can the forward the payment via the channel.\n> The next node can itself perform this operation, looking up the pheromone\n> identifier and determining which channel it came from, and so on, until the\n> payment reaches the destination.\n>\n> `getroutequick`\n> ---------------\n>\n>\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-August/002095.html\n> https://zmnscpxj.github.io/activity/2019-10-18/presentation.odp\n>\n> The overall `getroutequick` algorithm simply uses a Greedy Best First\n> Search, which requires a heuristic that returns a distance to the target.\n> The heuristic is generated from cached data: the cache itself is generated\n> by first performing a Dijkstra on the entire routemap, recording the\n> distance from our own node at each mapped node.\n> The `getroutequick` algorithm then starts at one end of the route, and the\n> other end must be our own node; this typically makes sense since both ends\n> of the route are the payer and the payee, and have an interest in the\n> payment succeeding by having a route available.\n>\n> The power of `getroutequick` lies in pre-caching the Dijkstra run;\n> Dijkstra is heavy as it requires traversing the entire routemap, but its\n> result can be cached and then used in Greedy Best First Search, which is\n> likely to traverse only the shortest route.\n> This moves the heavy lifting from the point in time in which a payment is\n> initiated, improving payment experience by reducing the amount of time\n> needed to find a route to a particular payee.\n>\n> Trampoline\n> ----------\n>\n> https://github.com/lightningnetwork/lightning-rfc/pull/654\n>\n> Trampoline simply means doing onion routing at a level distinct from the\n> individual channel level.\n> An onion route of \"trampoline\" nodes is formed, without specifying the\n> exact channels in the route between them.\n> Currently, the idea is that there is an \"outer\" onion that describes a\n> path to the next trampoline node, and an \"inner\" onion that describes the\n> next-next trampoline node.\n>\n> Digression: On the Current Gossip System\n> ========================================\n>\n> Currently, we use a gossip system where nodes and channels publicly show\n> that particular outputs on the blockchain layer are actually funding\n> transaction outputs that back channels.\n>\n> Whenever a new node joins the Lightning network, it anchors its existence\n> to the blockchain by having a channel opened with it (either it funds, or\n> is funded to).\n> Then, on the basis of this anchored channel, it announces its existence.\n> This implies that bandwidth usage for this gossip system is bounded by the\n> bandwidth limits we have imposed in the blockchain layer.\n> Thus, even though this gossip system requires the data to be broadcast\n> globally to all nodes, the utilized resource is still bounded by the space\n> limits of the Bitcoin blockchain layer.\n>\n> Further, the gossip system allows announcements to be refreshed\n> periodically.\n> However, ultimately the amount of bandwidth used for routing information\n> broadcast via gossip is bounded by the amount of bandwidth we have allowed\n> the blockchain layer to use (i.e. the block size and block rate parameters\n> of the blockchain).\n>\n> Combined Proposal\n> =================\n>\n> Combining Ant Routing and `getroutequick`\n> -----------------------------------------\n>\n> Ant routing, we can observe, is equivalent to a distributed form of\n> Dijkstra algorithm.\n> Its major drawback is that every payment causes the emission of a\n> pheromone, which must be broadcasted to the entire network.\n> This implies using resources proportional to the total number of payments\n> globally, unlike the current Lightning network where each node only gets\n> data regarding payments it is involved in routing.\n> This reverses the advantage of Lightning network, making it as inefficient\n> (in terms of big-O, not necessarily in the lower-level details) as a\n> blockchain.\n>\n> `getroutequick` works by pre-caching the result of a Dijkstra run, with\n> the result then used as the heuristic in a subsequent, faster Greedy Best\n> First Search.\n>\n> This leads to the realization that we could have a possible payee release\n> a pheromone *once* (equivalent to the pre-cached Dijkstra run, now made\n> distributed) and then subsequent payments to that payee just use the\n> pre-cached Dijkstra by referring to that pheromone.\n> (This reduces privacy as the pheromone persistently identifies the node,\n> but I fix this later; please bear with me.)\n>\n> ### Pheromone Handling\n>\n> So what we do is, every node that wants to be a forwarding node keeps a\n> mapping, from a non-self node ID to a distance counter.\n> A pheromone is then composed of:\n>\n> * Node ID (33 bytes).\n> * A reference to a channel that the node is a participant of (8 bytes, a\n> short channel ID).\n> * A proof that the Node ID is indeed a participant in the indicated\n> channel (65 bytes for the node signature, 33 bytes for the node ID of the\n> counterparty of the node, maybe some more bytes for whatever details on how\n> the channel script is derived or whatever).\n> * A distance counter (1 byte can probably fit; do we expect Lightning\n> diameter to exceed 255? maybe in some really insane conditions? how\n> attackable is this?).\n>\n> When a node receives a pheromone from a peer it has a channel with, it\n> checks if the node already exists in its mapping.\n> If it exists, and the distance counter in the pheromone is larger than or\n> equal to the distance counter in the mapping, it ignores the pheromone and\n> does not propagate it.\n> However, if the distance counter in the pheromone is less than that in the\n> mapping, or the mapping does not contain that pheromone, it updates its\n> mapping, then sends the pheromone to its peers it has channels with, but\n> with the distance counter one greater than what it has now.\n>\n> ### Distance Queries and Payment Routing\n>\n> A node can ask its direct peers about the distance of that peer to a\n> specific node ID.\n> (the peer could lie, but I cover this case later; please bear with me.)\n>\n> When a payer wants to route, the payer knows its (supposed) distance to\n> the payee.\n> It then creates an HTLC whose timelock limit is limited only to the given\n> distance to the payee.\n> The payer then queries each online peer for its mapping of the payee node\n> ID and distance counter.\n> It selects any online peer with sufficient payer-side capacity in the\n> channel, whose distance counter is lower than its own and sends the HTLC\n> out via a channel with that peer.\n> If there are no such, it could select any peer with the lowest distance\n> counter (and update its own distance counter to be one higher than that\n> peer as well).\n>\n> The same operation is done by each forwarding node.\n> It queries each peer, where it has sufficient capacity to forward to, to\n> get the distance counters for that node.\n> Then it forwards to any peer that has lower distance counter than itself,\n> to which it has sufficient capacity.\n>\n> ### Forwarding Failures\n>\n> There are only two failures:\n>\n> * The destination has absolutely no idea of what the fayment you are\n> talking about.\n>   * This case should include a proof that it comes from the destination,\n> e.g. a signature.\n> * A peer is unable to forward because the HTLC it receives has\n> insufficient timelock remaining for it to forward to the destination, and\n> it reports back how many more hops needs to be added (this has to be 1 or\n> higher).\n>\n> Failures are not encrypted, i.e. they are in plaintext.\n>\n> Suppose a forwarding node currently thinks it is 2 hops away from the\n> payee.\n> However, the channel to the node that is 1 hop away is closed, or that\n> node goes offline, etc.\n>\n> Since the forwarding node also propagated the pheromone outwards such that\n> it is 2 hops away from the payee, the payer has allocated it just enough\n> timelock in the HTLC that reaches it to be worth 2 hops of timelock.\n> The forwarding node then checks its *other* peers, in the hope that one of\n> them is 1 hop away from the payee.\n> If it finds a peer that is one hop away, all is well with the world and it\n> just forwards to that peer.\n>\n> On the other hand, suppose it finds that the peer it has that is nearest\n> to the payee is 4 hops away from the payee.\n> It updates its own distance counter to 5 (one higher than the peer that is\n> nearest), then (because the HTLC has too little timelock left for that\n> number of hops) it propagates a failure back to the incoming HTLC, with the\n> indication +3 (i.e. it had to add +3 to its previous distance counter of 2\n> to get its current distance counter of 5).\n> When the previous forwarding node (which presumably had a distance counter\n> of 3) receives this failure, it can instead try to search other peers that\n> have a distance counter of 2 or less and silently retry with those, or if\n> there are none it could look for those that are still nearer than the\n> adjusted counter of the failing peer (it was 2, but with the +3 is now at\n> 5, so any peer it has that is 4 or less could be nearer and it can lower\n> the adjustment of +3 to something lower), or if there are still none,\n> propagate the +3 hops failure back to the previous node, and so on.\n>\n> Similarly, when the ultimate payer receives this +N hops failure, it can\n> readjust its own sense of how distant it is from that payee, then retry\n> with the same peer, or a different peer that is now nearer than the updated\n> distance of the peer that propagated the failure.\n>\n> This case partially handles liars who underreport their distance to the\n> payee.\n> They cannot forward the payment and expect the payment to push through,\n> since some node beyond it will see that it has too little time left in the\n> HTLC to propagate and report this as a +N hops failure.\n> The lying node can then only admit its lie and report back a +N hops\n> failure, or keep mum and keep the HTLC until it is about to time out (the\n> latter behavior is something current forwarding nodes can already do).\n> (But note: a lying node could effectively censor a particular node, by\n> misreporting its distance to that node as 1 and then keeping the HTLC\n> around until near the locktime limit, then admit just a +1 hops failure (if\n> it did not, its peer will drop the channel with the lying node onchain in\n> order to enforce the locktime limit and will then search among *its* peers\n> for how distant it truly is), slowly reducing its censorship but still able\n> to do so among a number of nodes on the network; this will settle over\n> time, but would still be a nasty attack.)\n> (this could be mitigated if we had a clever mathematical construct such\n> that if I have proof that somebody committed to N, I can forge a proof that\n> the same somebody committed to N+1 but cannot forge a proof that somebody\n> committed to N-1; maybe sinking signatures, with \"height\" in sinking\n> signatures being some constant minus the distance? but then if you get N\n> you could propagate N: and you could as well also be running multiple nodes\n> that you propagate N to but not actually have channels with.)\n>\n> ### Periodic Updates\n>\n> Periodically, a node may want to update the Dijkstra run for itself, by\n> re-emitting a new pheromone.\n> This refreshes the sense of the rest of the network of what their distance\n> is to each node on the network.\n>\n> We already allow the current gossip protocol to publish similar periodic\n> updates to the channel and node announcements, thus we expect the big-O\n> bandwidth use to be similar with periodic pheromone re-emission.\n>\n> Plugging Privacy With Trampoline Routing\n> ----------------------------------------\n>\n> The core idea of trampoline routing is simply to add an onion routing to a\n> level above individual channel hops.\n>\n> In current Lightning, we use onion routing to encode individual channel\n> hops.\n> Individual channel hops, with our new Ant Routing + `getroutequick`\n> scheme, are handled by the distributed `getroutequick`.\n> This has the major drawback that the `getroutequick` needs to know the\n> exact destination.\n>\n> For this new routing paradigm, we simply add an onion routing on a layer\n> above the channel-level routing, in much the same way that Tor adds onion\n> routing on top of the TCP router-leving routing.\n> That is, we move the onion packet from the hop level to the trampoline\n> node level.\n>\n> An onion packet is sent to the destination that we admit to the\n> `getroutequick` channel-level routing layer.\n> This onion packet indicates openly how much of the HTLC timelock is\n> allocated to reach that destination, and how much is allocated to the\n> destination itself.\n> On reaching the destination, it unwraps the onion by one layer, and it\n> might find that it is the final destination, or that it has to use the\n> allocated timelock as well to forward to the next destination.\n>\n> ### Payer Allocation\n>\n> Each node already has a mapping of nodes to distance counters.\n> Thus, to make a payment to a node, it need only find some number of nodes\n> in this mapping.\n>\n> Ideally, it finds two other nodes that are nearer to it than the payee\n> node (i.e. has distance counters lower than the distance to the actual\n> payee) in the hope that they will be in \"the same\" direction or area as the\n> final destination.\n>\n> Suppose that it currently has a destination, and selects an intermediate\n> node in the trampoline onion.\n> It got both nodes from its local map of node ID to distance, thus it knows\n> the distance from itself to both nodes (assuming this data is not too\n> stale).\n> By considering itself, and the two nodes, as a triangle, we can conclude\n> that the maximum distance between those two nodes is equal to the sum of\n> the distances between itself and each of the nodes.\n> So for example if the trampoline node is 5 hops away and the payee is 3\n> hops away, then the maximum distance between both is 8 hops.\n> So, the payer will allocate 8 hops for the route from the intermediate\n> node to the current destination.\n>\n> The payer can repeat that however many times it wants, in order to add\n> more layers to the trampoline onion.\n> For example, it could add second trampoline, with a distance of 6 hops\n> away, and it gets the 5 hops distance of the previous trampoline node and\n> adds those together, allocating 11 hops for the route from second to first\n> trampoline, and allocating the above 8 hops for the first trampoline to the\n> payee.\n> Then, it sends out an HTLC of a total of 6 (distance to second trampoline)\n> + 11 (route from second to first trampoline) + 8 (route from first\n> trampoline to destination) hops of timelock and fees.\n>\n> ### Trampoline-level Failures\n>\n> A trampoline node might, for some reason, not be able to find the next\n> trampoline.\n> It might also find that the payer information is so stale that the\n> budgeted number of hops for that trampoline hop is insufficient.\n> In those cases, the trampoline node can report back a failure.\n>\n> These would have a distinct failure code compared to the +N hops needed\n> failure at the channel hop level.\n> However, it may be possible to add the destination \"I have no idea what\n> the fayment you are talking about\" to these failures.\n> Like the onion-wrapped failures in the current Lightning onion routing, it\n> may be possible to also onion-wrap the failures at the trampoline node\n> level.\n> Then failures seen at the channel hop level are either \"some onion-wrapped\n> failure\" or \"add +N hops plz\".\n> Of note is that a trampoline node that finds it has been given\n> insufficient budget should not use the \"add +N hops plz\" message, but an\n> onion-wrapped failure (which itself might be just \"add +N hops plz, but to\n> my budget\").\n>\n> ### Payment Point Rotation\n>\n> With payment point+scalar, we can have \"path decorrelation\", where each\n> hop in the onion route changes the outgoing PTLC by a constant scalar that\n> is secretly shared between itself and the original payer.\n>\n> This will still work by moving the onion routing one level higher, from\n> the level of channel hops to the level of trampoline nodes.\n>\n> ### Hidden Destinations\n>\n> Another advantage of trampoline onions is that the payee can provide a\n> pre-encrypted trampoline onion which the payer can prepend its own\n> trampoline nodes to, i.e. hidden destinations.\n> This feature remains unchanged when done on top of the hop-level Ant\n> Routing + `getroutequick` scheme.\n>\n>\n> Advantages and Disadvantages\n> ----------------------------\n>\n> Advantages:\n>\n> * Far fewer channels have to be published offchain; a node that wants to\n> receive in the future needs only publish *one* of its channels in order to\n> act as proof that it is on Lightning.\n>   A node that expects many incoming payments can have multiple channels\n> opened towards it, but only admit ownership of one channel.\n>   Two cooperating nodes that have a channel between them can use that\n> channel to prove their existence in their individual pheromones, thereby\n> revealing to the rest of the network only a small number of channels.\n>   This makes it much harder to map out the full network, but with this\n> hiding much more consistently distributed among nodes, for better\n> risk-sharing.\n>   * Nodes that do not expect to receive in the future, except from direct\n> peers, do not need to publish *any* channels.\n>     Even if they do not publish *any* channels, however, they can still\n> participate in forwarding, since forwarding nodes perform local queries to\n> determine the next hop, and participation in forwarding is an important\n> privacy technique; a node that regularly forwards can always claim that its\n> payment is actually forwarded from somebody else, a property lost with the\n> current \"private\"^H^H^H^H^H^H^H^H^Hunpublished channels.\n>\n> Disadvantages:\n>\n> * Censorship attacks are trivial: just lie about your distance to the node\n> you want to censor and say you know them, then just HODL on to the HTLC\n> that should go to them.\n>   This is a major disadvantage, thus possibly a good reason to avoid this\n> paradigm.\n>   My hope is someone else can come up with some way to mitigate or remove\n> this weakness.\n> * We would need to impose a consistent feerate and CLTV-delta at each node.\n>   * On the other hand, one can argue that it is precisely the ability of\n> forwarding nodes to give arbitrary feerates that allows surveillors to\n> effectively \"pay to surveill\" by giving below-market-rate feerates, so\n> ***maybe*** central planning of this parameter (yuck!) would be useful...\n> nah non-free-market, boo.\n>\n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200211/6b15b7d6/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-12T04:08:32",
                "message_text_only": "Good morning Cezary,\n\n> That was really interesting to read this.\n> Why you want to send Node ID inside pheromone? Why not to send random number, that would be then passed though invoice?\n> To increase privacy, node could generate new random number every week and distribute pheromone gain.\n\nOur spam-limiting mechanism in current Lightning is tied to node IDs, and node IDs are effectively anchored onchain by the channels they have (and onchain is public anyway...).\nI was hoping to reuse the same mechanism to give an upper bound on how much spam you can ride on the Lightning pheromone network (the same bound applies to the current Lightning gossip, you can only spam Lightning by spamming Bitcoin, and spamming Bitcoin is costly).\n\nHowever, if you have other ideas about how to limit pheromone spam, I would gladly like to hear it.\n\nRegards,\nZmnSCPxj\n\n\n> Best regards,\n> Cezary Dziemian\n>\n> pon., 10 lut 2020 o 11:35\u00a0ZmnSCPxj via Lightning-dev <lightning-dev at lists.linuxfoundation.org> napisa\u0142(a):\n>\n> > Overview of Components\n> > ======================\n> >\n> > Ant Routing\n> > -----------\n> >\n> > https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-February/002505.html\n> >\n> > Ant Routing is a distributed pathfinding algorithm where nodes emit \"pheromones\", which are broadcasted over the entire network.\n> > When a node receives a pheromone (a UUID plus a distance counter) from a peer it has a channel with, it records that pheromone locally, then broadcasts it to other peers it has channels with, but with the distance counter increased by one.\n> >\n> > Subsequently, a payee can then provide the pheromone identifier to a payer, which can check if it has received that pheromone, and from which channel it received it from.\n> > It can the forward the payment via the channel.\n> > The next node can itself perform this operation, looking up the pheromone identifier and determining which channel it came from, and so on, until the payment reaches the destination.\n> >\n> > `getroutequick`\n> > ---------------\n> >\n> > https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-August/002095.html\n> > https://zmnscpxj.github.io/activity/2019-10-18/presentation.odp\n> >\n> > The overall `getroutequick` algorithm simply uses a Greedy Best First Search, which requires a heuristic that returns a distance to the target.\n> > The heuristic is generated from cached data: the cache itself is generated by first performing a Dijkstra on the entire routemap, recording the distance from our own node at each mapped node.\n> > The `getroutequick` algorithm then starts at one end of the route, and the other end must be our own node; this typically makes sense since both ends of the route are the payer and the payee, and have an interest in the payment succeeding by having a route available.\n> >\n> > The power of `getroutequick` lies in pre-caching the Dijkstra run; Dijkstra is heavy as it requires traversing the entire routemap, but its result can be cached and then used in Greedy Best First Search, which is likely to traverse only the shortest route.\n> > This moves the heavy lifting from the point in time in which a payment is initiated, improving payment experience by reducing the amount of time needed to find a route to a particular payee.\n> >\n> > Trampoline\n> > ----------\n> >\n> > https://github.com/lightningnetwork/lightning-rfc/pull/654\n> >\n> > Trampoline simply means doing onion routing at a level distinct from the individual channel level.\n> > An onion route of \"trampoline\" nodes is formed, without specifying the exact channels in the route between them.\n> > Currently, the idea is that there is an \"outer\" onion that describes a path to the next trampoline node, and an \"inner\" onion that describes the next-next trampoline node.\n> >\n> > Digression: On the Current Gossip System\n> > ========================================\n> >\n> > Currently, we use a gossip system where nodes and channels publicly show that particular outputs on the blockchain layer are actually funding transaction outputs that back channels.\n> >\n> > Whenever a new node joins the Lightning network, it anchors its existence to the blockchain by having a channel opened with it (either it funds, or is funded to).\n> > Then, on the basis of this anchored channel, it announces its existence.\n> > This implies that bandwidth usage for this gossip system is bounded by the bandwidth limits we have imposed in the blockchain layer.\n> > Thus, even though this gossip system requires the data to be broadcast globally to all nodes, the utilized resource is still bounded by the space limits of the Bitcoin blockchain layer.\n> >\n> > Further, the gossip system allows announcements to be refreshed periodically.\n> > However, ultimately the amount of bandwidth used for routing information broadcast via gossip is bounded by the amount of bandwidth we have allowed the blockchain layer to use (i.e. the block size and block rate parameters of the blockchain).\n> >\n> > Combined Proposal\n> > =================\n> >\n> > Combining Ant Routing and `getroutequick`\n> > -----------------------------------------\n> >\n> > Ant routing, we can observe, is equivalent to a distributed form of Dijkstra algorithm.\n> > Its major drawback is that every payment causes the emission of a pheromone, which must be broadcasted to the entire network.\n> > This implies using resources proportional to the total number of payments globally, unlike the current Lightning network where each node only gets data regarding payments it is involved in routing.\n> > This reverses the advantage of Lightning network, making it as inefficient (in terms of big-O, not necessarily in the lower-level details) as a blockchain.\n> >\n> > `getroutequick` works by pre-caching the result of a Dijkstra run, with the result then used as the heuristic in a subsequent, faster Greedy Best First Search.\n> >\n> > This leads to the realization that we could have a possible payee release a pheromone *once* (equivalent to the pre-cached Dijkstra run, now made distributed) and then subsequent payments to that payee just use the pre-cached Dijkstra by referring to that pheromone.\n> > (This reduces privacy as the pheromone persistently identifies the node, but I fix this later; please bear with me.)\n> >\n> > ### Pheromone Handling\n> >\n> > So what we do is, every node that wants to be a forwarding node keeps a mapping, from a non-self node ID to a distance counter.\n> > A pheromone is then composed of:\n> >\n> > * Node ID (33 bytes).\n> > * A reference to a channel that the node is a participant of (8 bytes, a short channel ID).\n> > * A proof that the Node ID is indeed a participant in the indicated channel (65 bytes for the node signature, 33 bytes for the node ID of the counterparty of the node, maybe some more bytes for whatever details on how the channel script is derived or whatever).\n> > * A distance counter (1 byte can probably fit; do we expect Lightning diameter to exceed 255? maybe in some really insane conditions? how attackable is this?).\n> >\n> > When a node receives a pheromone from a peer it has a channel with, it checks if the node already exists in its mapping.\n> > If it exists, and the distance counter in the pheromone is larger than or equal to the distance counter in the mapping, it ignores the pheromone and does not propagate it.\n> > However, if the distance counter in the pheromone is less than that in the mapping, or the mapping does not contain that pheromone, it updates its mapping, then sends the pheromone to its peers it has channels with, but with the distance counter one greater than what it has now.\n> >\n> > ### Distance Queries and Payment Routing\n> >\n> > A node can ask its direct peers about the distance of that peer to a specific node ID.\n> > (the peer could lie, but I cover this case later; please bear with me.)\n> >\n> > When a payer wants to route, the payer knows its (supposed) distance to the payee.\n> > It then creates an HTLC whose timelock limit is limited only to the given distance to the payee.\n> > The payer then queries each online peer for its mapping of the payee node ID and distance counter.\n> > It selects any online peer with sufficient payer-side capacity in the channel, whose distance counter is lower than its own and sends the HTLC out via a channel with that peer.\n> > If there are no such, it could select any peer with the lowest distance counter (and update its own distance counter to be one higher than that peer as well).\n> >\n> > The same operation is done by each forwarding node.\n> > It queries each peer, where it has sufficient capacity to forward to, to get the distance counters for that node.\n> > Then it forwards to any peer that has lower distance counter than itself, to which it has sufficient capacity.\n> >\n> > ### Forwarding Failures\n> >\n> > There are only two failures:\n> >\n> > * The destination has absolutely no idea of what the fayment you are talking about.\n> > \u00a0 * This case should include a proof that it comes from the destination, e.g. a signature.\n> > * A peer is unable to forward because the HTLC it receives has insufficient timelock remaining for it to forward to the destination, and it reports back how many more hops needs to be added (this has to be 1 or higher).\n> >\n> > Failures are not encrypted, i.e. they are in plaintext.\n> >\n> > Suppose a forwarding node currently thinks it is 2 hops away from the payee.\n> > However, the channel to the node that is 1 hop away is closed, or that node goes offline, etc.\n> >\n> > Since the forwarding node also propagated the pheromone outwards such that it is 2 hops away from the payee, the payer has allocated it just enough timelock in the HTLC that reaches it to be worth 2 hops of timelock.\n> > The forwarding node then checks its *other* peers, in the hope that one of them is 1 hop away from the payee.\n> > If it finds a peer that is one hop away, all is well with the world and it just forwards to that peer.\n> >\n> > On the other hand, suppose it finds that the peer it has that is nearest to the payee is 4 hops away from the payee.\n> > It updates its own distance counter to 5 (one higher than the peer that is nearest), then (because the HTLC has too little timelock left for that number of hops) it propagates a failure back to the incoming HTLC, with the indication +3 (i.e. it had to add +3 to its previous distance counter of 2 to get its current distance counter of 5).\n> > When the previous forwarding node (which presumably had a distance counter of 3) receives this failure, it can instead try to search other peers that have a distance counter of 2 or less and silently retry with those, or if there are none it could look for those that are still nearer than the adjusted counter of the failing peer (it was 2, but with the +3 is now at 5, so any peer it has that is 4 or less could be nearer and it can lower the adjustment of +3 to something lower), or if there are still none, propagate the +3 hops failure back to the previous node, and so on.\n> >\n> > Similarly, when the ultimate payer receives this +N hops failure, it can readjust its own sense of how distant it is from that payee, then retry with the same peer, or a different peer that is now nearer than the updated distance of the peer that propagated the failure.\n> >\n> > This case partially handles liars who underreport their distance to the payee.\n> > They cannot forward the payment and expect the payment to push through, since some node beyond it will see that it has too little time left in the HTLC to propagate and report this as a +N hops failure.\n> > The lying node can then only admit its lie and report back a +N hops failure, or keep mum and keep the HTLC until it is about to time out (the latter behavior is something current forwarding nodes can already do).\n> > (But note: a lying node could effectively censor a particular node, by misreporting its distance to that node as 1 and then keeping the HTLC around until near the locktime limit, then admit just a +1 hops failure (if it did not, its peer will drop the channel with the lying node onchain in order to enforce the locktime limit and will then search among *its* peers for how distant it truly is), slowly reducing its censorship but still able to do so among a number of nodes on the network; this will settle over time, but would still be a nasty attack.)\n> > (this could be mitigated if we had a clever mathematical construct such that if I have proof that somebody committed to N, I can forge a proof that the same somebody committed to N+1 but cannot forge a proof that somebody committed to N-1; maybe sinking signatures, with \"height\" in sinking signatures being some constant minus the distance? but then if you get N you could propagate N: and you could as well also be running multiple nodes that you propagate N to but not actually have channels with.)\n> >\n> > ### Periodic Updates\n> >\n> > Periodically, a node may want to update the Dijkstra run for itself, by re-emitting a new pheromone.\n> > This refreshes the sense of the rest of the network of what their distance is to each node on the network.\n> >\n> > We already allow the current gossip protocol to publish similar periodic updates to the channel and node announcements, thus we expect the big-O bandwidth use to be similar with periodic pheromone re-emission.\n> >\n> > Plugging Privacy With Trampoline Routing\n> > ----------------------------------------\n> >\n> > The core idea of trampoline routing is simply to add an onion routing to a level above individual channel hops.\n> >\n> > In current Lightning, we use onion routing to encode individual channel hops.\n> > Individual channel hops, with our new Ant Routing + `getroutequick` scheme, are handled by the distributed `getroutequick`.\n> > This has the major drawback that the `getroutequick` needs to know the exact destination.\n> >\n> > For this new routing paradigm, we simply add an onion routing on a layer above the channel-level routing, in much the same way that Tor adds onion routing on top of the TCP router-leving routing.\n> > That is, we move the onion packet from the hop level to the trampoline node level.\n> >\n> > An onion packet is sent to the destination that we admit to the `getroutequick` channel-level routing layer.\n> > This onion packet indicates openly how much of the HTLC timelock is allocated to reach that destination, and how much is allocated to the destination itself.\n> > On reaching the destination, it unwraps the onion by one layer, and it might find that it is the final destination, or that it has to use the allocated timelock as well to forward to the next destination.\n> >\n> > ### Payer Allocation\n> >\n> > Each node already has a mapping of nodes to distance counters.\n> > Thus, to make a payment to a node, it need only find some number of nodes in this mapping.\n> >\n> > Ideally, it finds two other nodes that are nearer to it than the payee node (i.e. has distance counters lower than the distance to the actual payee) in the hope that they will be in \"the same\" direction or area as the final destination.\n> >\n> > Suppose that it currently has a destination, and selects an intermediate node in the trampoline onion.\n> > It got both nodes from its local map of node ID to distance, thus it knows the distance from itself to both nodes (assuming this data is not too stale).\n> > By considering itself, and the two nodes, as a triangle, we can conclude that the maximum distance between those two nodes is equal to the sum of the distances between itself and each of the nodes.\n> > So for example if the trampoline node is 5 hops away and the payee is 3 hops away, then the maximum distance between both is 8 hops.\n> > So, the payer will allocate 8 hops for the route from the intermediate node to the current destination.\n> >\n> > The payer can repeat that however many times it wants, in order to add more layers to the trampoline onion.\n> > For example, it could add second trampoline, with a distance of 6 hops away, and it gets the 5 hops distance of the previous trampoline node and adds those together, allocating 11 hops for the route from second to first trampoline, and allocating the above 8 hops for the first trampoline to the payee.\n> > Then, it sends out an HTLC of a total of 6 (distance to second trampoline) + 11 (route from second to first trampoline) + 8 (route from first trampoline to destination) hops of timelock and fees.\n> >\n> > ### Trampoline-level Failures\n> >\n> > A trampoline node might, for some reason, not be able to find the next trampoline.\n> > It might also find that the payer information is so stale that the budgeted number of hops for that trampoline hop is insufficient.\n> > In those cases, the trampoline node can report back a failure.\n> >\n> > These would have a distinct failure code compared to the +N hops needed failure at the channel hop level.\n> > However, it may be possible to add the destination \"I have no idea what the fayment you are talking about\" to these failures.\n> > Like the onion-wrapped failures in the current Lightning onion routing, it may be possible to also onion-wrap the failures at the trampoline node level.\n> > Then failures seen at the channel hop level are either \"some onion-wrapped failure\" or \"add +N hops plz\".\n> > Of note is that a trampoline node that finds it has been given insufficient budget should not use the \"add +N hops plz\" message, but an onion-wrapped failure (which itself might be just \"add +N hops plz, but to my budget\").\n> >\n> > ### Payment Point Rotation\n> >\n> > With payment point+scalar, we can have \"path decorrelation\", where each hop in the onion route changes the outgoing PTLC by a constant scalar that is secretly shared between itself and the original payer.\n> >\n> > This will still work by moving the onion routing one level higher, from the level of channel hops to the level of trampoline nodes.\n> >\n> > ### Hidden Destinations\n> >\n> > Another advantage of trampoline onions is that the payee can provide a pre-encrypted trampoline onion which the payer can prepend its own trampoline nodes to, i.e. hidden destinations.\n> > This feature remains unchanged when done on top of the hop-level Ant Routing + `getroutequick` scheme.\n> >\n> > Advantages and Disadvantages\n> > ----------------------------\n> >\n> > Advantages:\n> >\n> > * Far fewer channels have to be published offchain; a node that wants to receive in the future needs only publish *one* of its channels in order to act as proof that it is on Lightning.\n> > \u00a0 A node that expects many incoming payments can have multiple channels opened towards it, but only admit ownership of one channel.\n> > \u00a0 Two cooperating nodes that have a channel between them can use that channel to prove their existence in their individual pheromones, thereby revealing to the rest of the network only a small number of channels.\n> > \u00a0 This makes it much harder to map out the full network, but with this hiding much more consistently distributed among nodes, for better risk-sharing.\n> > \u00a0 * Nodes that do not expect to receive in the future, except from direct peers, do not need to publish *any* channels.\n> > \u00a0 \u00a0 Even if they do not publish *any* channels, however, they can still participate in forwarding, since forwarding nodes perform local queries to determine the next hop, and participation in forwarding is an important privacy technique; a node that regularly forwards can always claim that its payment is actually forwarded from somebody else, a property lost with the current \"private\"^H^H^H^H^H^H^H^H^Hunpublished channels.\n> >\n> > Disadvantages:\n> >\n> > * Censorship attacks are trivial: just lie about your distance to the node you want to censor and say you know them, then just HODL on to the HTLC that should go to them.\n> > \u00a0 This is a major disadvantage, thus possibly a good reason to avoid this paradigm.\n> > \u00a0 My hope is someone else can come up with some way to mitigate or remove this weakness.\n> > * We would need to impose a consistent feerate and CLTV-delta at each node.\n> > \u00a0 * On the other hand, one can argue that it is precisely the ability of forwarding nodes to give arbitrary feerates that allows surveillors to effectively \"pay to surveill\" by giving below-market-rate feerates, so ***maybe*** central planning of this parameter (yuck!) would be useful... nah non-free-market, boo.\n> >\n> > Regards,\n> > ZmnSCPxj\n> > _______________________________________________\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-12T05:02:38",
                "message_text_only": "Good morning again Cezary,\n\n\n> > That was really interesting to read this.\n> > Why you want to send Node ID inside pheromone? Why not to send random number, that would be then passed though invoice?\n> > To increase privacy, node could generate new random number every week and distribute pheromone gain.\n>\n> Our spam-limiting mechanism in current Lightning is tied to node IDs, and node IDs are effectively anchored onchain by the channels they have (and onchain is public anyway...).\n> I was hoping to reuse the same mechanism to give an upper bound on how much spam you can ride on the Lightning pheromone network (the same bound applies to the current Lightning gossip, you can only spam Lightning by spamming Bitcoin, and spamming Bitcoin is costly).\n>\n> However, if you have other ideas about how to limit pheromone spam, I would gladly like to hear it.\n\nFor example, instead of considering distance-from-node, we could realize that it is the *channel* itself that is what limits the pheromone spam.\nSo maybe the pheromone should count distance-from-*channel*.\n\nIf I want to be a receiver, I just need to ensure that at least one of my open channels has been published as a pheromone (and I do not need to publish *all* my channels, just enough of them to have a good chance of being reachable).\nThe pheromone would contain signatures of me and my counterparty.\n(In a post-Taproot world, it would contain a single signature, plus a proof that the UTXO involved is reserved *only* for Lightning network (for example, channel UTXOs could have a taprooted `OP_RETURN \"Lightning Is Awesome!!\"` branch which can never be used, but which can be revealed to show that it is for Lightning), and is not a locked UTXO that is *also* being used for another purpose, as that obviates the spam-limiting since multiple applications could now be spammed with a single onchain UTXO.)\nCrucially, the pubkeys used need not be our node IDs, and every channel will have different pubkeys, even if two channels are to the same two nodes.\n\nNow suppose I want to issue an invoice.\nI just check what channels I have that have been pheromone-broadcast.\nThe invoice then contains the selected short-channel-id(s) rather than the actual node (though since invoices are signed, what pubkey do we use to sign it?).\n\nThen suppose I receive an incoming HTLC that is supposed to reach a short-channel-id of a channel I have.\nEither it is to me, or to my peer on that channel.\nIf it is to me, then I should be able to recognize the payment hash / payment point on the HTLC/PTLC, and can claim it now.\nIf I do not recognize it, it is probably to my counterparty, who can then check if it recognizes the payment hash / point and send back a definite `incorrect_or_unknown_payment_details`, signed by itself (which the payer can recognize as one of the signatories of the pheromone).\nCrucially, this lets me receive money via other, unpublished channels as well; the payment might be going in the direction of my channel, but I could also be on the shortest path between the payer and that specific channel.\n\nNow let us turn our attention to onion-routing a trampoline route when our pheromones are channel-based instead of node-based.\nRemember, onion-routing requires that we know a static public key of a node, with which we can make an asymmetric encryption.\nHowever, pheromones also show the two public keys involved in the channel, and our trampoline routing can use one or the other key arbitrarily (though budgets may need to add +1 hop in case it lands in the \"wrong\" direction).\nThen if I receive a trampoline-routed onion to a channel that I have, I can try to decrypt with my key, and if that succeeds, then I have unwrapped the onion and know the next trampoline (or I know that I am the final destination).\nIf decryption fails (there is an HMAC again of the \"rest\" of the onion after all) then the onion is for my peer on that channel and I hand over the HTLC to it.\nSimilarly, since payment point decorrelation will now be handled at the trampoline level, presumably the onion can now contain the tweak to be applied to the payment point.\n\n\nThis gives a mild improvement in privacy: everyone else who is not involved in the channel has a 50/50 chance of guessing who is the real destination of the payment.\nFurther, every channel I have has its own pubkey I own, which is not the same as the pubkey I own on another channel.\nI could use one channel as the destination when I am selling Ahura Mazda Holy Writings and Sanctified Commentary, and another channel as the destination when I am selling The Horned Man Depraved Sex Paraphernalia, even from the same Lightning node.\nWith proper handling of UTXOs after closing (i.e. doing onchain mixing before spending onchain, or creating a new channel) then the single node I operate can sell both without anyone realizing I sell both kinds of products; I could claim that I was just an innocent third-party node that happened to have channels to both the Ahura Maza Holy Writings and Sanctified Commentary node, and The Horned Man Depravedd Sex Paraphernalia node.\n\nRegards,\nZmnSCPXj"
            }
        ],
        "thread_summary": {
            "title": "A New Routing Paradigm:Ant Routing +`getroutequick` + Trampoline",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Cezary Dziemian",
                "ZmnSCPxj"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 64287
        }
    },
    {
        "title": "[Lightning-dev] Lightning Spec Meeting 2020/02/17",
        "thread_messages": [
            {
                "author": "Christian Decker",
                "date": "2020-02-14T12:07:21",
                "message_text_only": "Dear Fellow Protocol Devs,\n\nthe next meeting is this Monday (2020/02/17), and to facilitate review\nand meeting preparations we have prepared a short agenda [1].\n\nThe open topic discussions during the last two iterations have been very\ninteresting, albeit a bit long, so this time we decided to limit\nourselves to just two topics, and track other topics of interest in a\nbacklog section. If there is time we can start discussing entries from\nthe backlog section, however it is likely better to concentrate well on\na few topics rather than touching many briefly. Let me know if you\nagree, and of course any other feedback is more than welcome.\n\nThe agenda is not yet final, so if there are topics people are eager to\ndiscuss please let me know either on GH or reply to this mail :-)\n\nSo far the agenda looks as follows:\n\n```markdown\nThe meeting will take place on Monday 2020/02/17 on IRC [#lightning-dev](irc://chat.freenode.net/lightning-dev). It is open to the public.\n\n## Pull Request Review\n- [ ] A home for BOLT #738\n- [ ] Reply channel range simplification #737\n- [ ] BOLT11 additional and negative tests #736\n- [ ] Avoid stuck channels after fee increase #740\n\n## Long Term Updates\n- [ ] Protocol testing framework (@rustyrussell). See the `tools/` and `tests/events` directories in [lightning-rfc-protocol-test](https://github.com/ElementsProject/lightning-rfc-protocol-test) for details.\n- [ ] Poor man's rendez-vous routing (@t-bast). See [mail by t-bast](https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-February/002519.html) and [gist](https://gist.github.com/t-bast/9972bfe9523bb18395bdedb8dc691faf) for details. (Since this is a fresh proposal still in everybody's mind this moved up the list to minimize loss of context).\n\n## Backlog\nThe following are topics that we should discuss at some point, so if we have time to discuss them great, otherwise they slip to the next meeting.\n\n- [ ] Current status of the trampoline routing proposal (@t-bast)\n- [ ] How can we improve the gossip (gossip_queries_ex)? (@sstone )\n```\n\nLooking forward to Monday's meeting :-)\n\nCheers,\nChristian\n\n[1] https://github.com/lightningnetwork/lightning-rfc/issues/735"
            }
        ],
        "thread_summary": {
            "title": "Lightning Spec Meeting 2020/02/17",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Decker"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2172
        }
    },
    {
        "title": "[Lightning-dev] Using libp2p as a communication protocol for Lightning",
        "thread_messages": [
            {
                "author": "Alexandr Burdiyan",
                "date": "2020-02-17T14:12:31",
                "message_text_only": "Hi everyone!\n\nSince I recently started digging into all-things-peer-to-peer, I found that there\u2019s a lot of fragmentation between many different projects that seemingly have a lot of things in common, like networking, encoding standards, and etc. I suppose there\u2019re lots of historical reasons for that.\n\nMore concretely for Lightning, I wonder why it couldn\u2019t use some existing open source technologies and standards, like libp2p [1] for communication, or various multiformats [2] standards for addresses, hashes and encodings?\n\nI do think that building and evolving common toolkits and standards for decentralized system like libp2p, or multiformats, or IPLD [3] could be something very useful for the whole community. Currently, it feels like everyone wants to go so fast, so there\u2019s no time for coordination and consensus to build these kinds of specs. That is understandable. But I wonder if Lightning community ever looked at projects like libp2p and multiformats, or maybe is considering to implement them in lightning. Or maybe there was a decision of not using them for some reason that I might be missing.\n\n[1]:\u00a0https://libp2p.io\n[2]:\u00a0https://multiformats.io\n[3]:\u00a0https://ipld.io\n\nThanks!\n\nAlexandr Burdiyan\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200217/0da539a9/attachment.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2020-02-17T17:00:24",
                "message_text_only": "Because writing connection logic and peer management is really not that complicated compared to HTLC state machines and the rest of lightning. For crypto, lighting does use the noise framework, though the resulting code is so simple (in a good way) that its super easy to just write it yourself instead of fighting with a dependency.\n\nLastly, for self-respecting cryptocurrency developers, not-carefully-audited dependencies are security vulnerabilities that will expose your users\u2019 funds. By pulling simple connection logic into a lighting implementation, it\u2019s easier to  test/fuzz/etc with the rest of a project.\n\nMatt\n\n> On Feb 17, 2020, at 06:12, Alexandr Burdiyan <burdiyan at gmail.com> wrote:\n> \n> \ufeff\n> Hi everyone!\n> \n> Since I recently started digging into all-things-peer-to-peer, I found that there\u2019s a lot of fragmentation between many different projects that seemingly have a lot of things in common, like networking, encoding standards, and etc. I suppose there\u2019re lots of historical reasons for that. \n> \n> More concretely for Lightning, I wonder why it couldn\u2019t use some existing open source technologies and standards, like libp2p [1] for communication, or various multiformats [2] standards for addresses, hashes and encodings?\n> \n> I do think that building and evolving common toolkits and standards for decentralized system like libp2p, or multiformats, or IPLD [3] could be something very useful for the whole community. Currently, it feels like everyone wants to go so fast, so there\u2019s no time for coordination and consensus to build these kinds of specs. That is understandable. But I wonder if Lightning community ever looked at projects like libp2p and multiformats, or maybe is considering to implement them in lightning. Or maybe there was a decision of not using them for some reason that I might be missing.\n> \n> [1]: https://libp2p.io\n> [2]: https://multiformats.io\n> [3]: https://ipld.io\n> \n> Thanks!\n> \n> Alexandr Burdiyan\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200217/57e0d0a0/attachment.html>"
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2020-02-17T17:10:21",
                "message_text_only": "Exactly what Matt said.\n\nI would also add that libp2p aims to be a kind of swiss-army knife for p2p\nnetworking: that's nice for many use-cases, but when security is your main\nfocus, it's not.\nLook at TLS: most attacks are downgrade attacks because the protocol offers\nway too many options.\nProtocols like Wireguard have perfectly understood this. No options, not\nmany configuration hooks -> small, auditable codebase.\n\nFor lightning it's the same: we prefer a very simple transport that has no\noptions whatsoever.\nSimple to implement, simple to test, and works great in practice.\n\nBastien\n\nLe lun. 17 f\u00e9vr. 2020 \u00e0 18:00, Matt Corallo <lf-lists at mattcorallo.com> a\n\u00e9crit :\n\n> Because writing connection logic and peer management is really not that\n> complicated compared to HTLC state machines and the rest of lightning. For\n> crypto, lighting does use the noise framework, though the resulting code is\n> so simple (in a good way) that its super easy to just write it yourself\n> instead of fighting with a dependency.\n>\n> Lastly, for self-respecting cryptocurrency developers,\n> not-carefully-audited dependencies are security vulnerabilities that will\n> expose your users\u2019 funds. By pulling simple connection logic into a\n> lighting implementation, it\u2019s easier to  test/fuzz/etc with the rest of a\n> project.\n>\n> Matt\n>\n> On Feb 17, 2020, at 06:12, Alexandr Burdiyan <burdiyan at gmail.com> wrote:\n>\n> \ufeff\n> Hi everyone!\n>\n> Since I recently started digging into all-things-peer-to-peer, I found\n> that there\u2019s a lot of fragmentation between many different projects that\n> seemingly have a lot of things in common, like networking, encoding\n> standards, and etc. I suppose there\u2019re lots of historical reasons for that.\n>\n> More concretely for Lightning, I wonder why it couldn\u2019t use some existing\n> open source technologies and standards, like libp2p [1] for communication,\n> or various multiformats [2] standards for addresses, hashes and encodings?\n>\n> I do think that building and evolving common toolkits and standards for\n> decentralized system like libp2p, or multiformats, or IPLD [3] could be\n> something very useful for the whole community. Currently, it feels like\n> everyone wants to go so fast, so there\u2019s no time for coordination and\n> consensus to build these kinds of specs. That is understandable. But I\n> wonder if Lightning community ever looked at projects like libp2p and\n> multiformats, or maybe is considering to implement them in lightning. Or\n> maybe there was a decision of not using them for some reason that I might\n> be missing.\n>\n> [1]: https://libp2p.io\n> [2]: https://multiformats.io\n> [3]: https://ipld.io\n>\n> Thanks!\n>\n> Alexandr Burdiyan\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200217/3f44b0fb/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2020-02-20T09:29:33",
                "message_text_only": "Bastien TEINTURIER <bastien at acinq.fr> writes:\n> Exactly what Matt said.\n>\n> I would also add that libp2p aims to be a kind of swiss-army knife for p2p\n> networking: that's nice for many use-cases, but when security is your main\n> focus, it's not.\n> Look at TLS: most attacks are downgrade attacks because the protocol offers\n> way too many options.\n> Protocols like Wireguard have perfectly understood this. No options, not\n> many configuration hooks -> small, auditable codebase.\n>\n> For lightning it's the same: we prefer a very simple transport that has no\n> options whatsoever.\n> Simple to implement, simple to test, and works great in practice.\n\nTo add to this: at Milan we chose a raw protocol instead of using\nprotobufs.  At the time I was unsure, but being able to specify each\nmessage down to the bit level has meant we've never really had problems\nat that level.\n\nBut it did mean we wasted time arguing over endianness, etc!\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Using libp2p as a communication protocol for Lightning",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Bastien TEINTURIER",
                "Rusty Russell",
                "Alexandr Burdiyan",
                "Matt Corallo"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 7924
        }
    },
    {
        "title": "[Lightning-dev] [RELEASE] c-lightning 0.8.1: \"Channel to the Moon\"",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2020-02-17T23:30:58",
                "message_text_only": "We're pleased to announce 0.8.1, named by @vasild (who last release was\na new committer!)\n\n        https://github.com/ElementsProject/lightning/releases/tag/v0.8.1\n\n*Highlights for Users*\n\n- We now support gifting msat to the peer when opening a channel, via\n  push_msat, providing a brand new way to lose money!\n\n- Invoice routehints can be overridden using exposeprivatechannels: try\n  setting to [] to eliminate all of them to fit your invoice in twitter\n  messages!\n\n- Preliminary support for plugins hooks which can replace the default\n  bitcoin-cli with other blockchain querying methods (API may change in\n  future releases though!).\n\nHighlights for the Network\n\n- Plugins can set additional feature bits, for more experimentation.\n\n- Wallet withdraw transactions now set nLocktime, making them blend in\n  more with other wallets.\n\n- Prevent a case where grossly unbalanced channels could become unusable.\n\nMore details can be found in\n\n        https://github.com/ElementsProject/lightning/blob/v0.8.1/CHANGELOG.md\n\nThanks to everyone for their contributions and bug reports; please keep\nthem coming!\n\nSince 0.8.0 we've had 257 commits from 17 different authors, with 5\nfirst-time contributors:\n\n    Niklas Claesson @NickeZ\n    @minidisk1147\n    Ken Sedgwick @ksedgwic\n    Zoe Faltib\u00e0 @jwilkins\n    Glen Cooper @jwilkins\n\nCheers,\nRusty, Lisa, Christian, and ZmnSCPxj."
            }
        ],
        "thread_summary": {
            "title": "c-lightning 0.8.1: \"Channel to the Moon\"",
            "categories": [
                "Lightning-dev",
                "RELEASE"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1374
        }
    },
    {
        "title": "[Lightning-dev] A proposal for up-front payments.",
        "thread_messages": [
            {
                "author": "Joost Jager",
                "date": "2020-02-18T09:23:29",
                "message_text_only": "Hi all,\n\nWithin our team, we've been discussing the subject of preventing\nliquidity-consuming spam (aka channel jamming) further. One idea came up\nthat I think is worth sharing.\n\nPrevious prepay ideas were based on the sender paying something up-front in\ncase the htlc causes grief on the network. This however leaves the sender\nvulnerable to nodes stealing that up-front payment.\n\nConsider what is probably the worst known channel jamming attack: an\nattacker sends minimum sized htlcs to fill up the limited number of\ncommitment slots of channels along the route. Those htlcs will be held as\nlong as possible by the receiving node (that is also controlled by the\nattacker). The hold time per htlc doesn't even need to be very long,\nbecause a fresh htlc can be launched to immediately re-occupy a slot after\nit opens up again.\n\nThe cost to the network of this attack is mostly dependent on the capacity\nof the channels used. The bigger the capacity, the more funds are locked up\nif a sufficient number of minimum sized htlcs are pending. The size of the\nup-front payment likely needs to be proportional to this cost.\n\nThis means that for small htlcs, the up-front payment requirements may very\nwell be exceeding the htlc amount and routing fees paid by far. At that\npoint, a routing node may decide to steal the up-front payment rather than\nearn the routing fee in an honest way.\n\nA different way of mitigating this is to reverse the direction in which the\nbond is paid. So instead of paying to offer an htlc, nodes need to pay to\nreceive an htlc. This sounds counterintuitive, but for the described\njamming attack there is also an attacker node at the end of the route. The\nattacker still pays. The advantage is that for legitimate senders, there is\nno up-front payment that can be stolen.\n\nHow this would work is that channel peers charge each other for the time\nthat the other party holds an htlc. So if node A extends an htlc to node B,\nnode B will pay node A amount x per minute of hold time. If node B doesn't\npay (doesn't hold up the contract), A will close the channel. It can be a\nrunning balance between A and B that materializes as a single htlc per\nchannel on the commitment transaction.\n\nAs long as node B forwards the htlc swiftly to node C, the dfiference (the\nactual cost) between what B needs to pay A and what B receives from C will\nbe tiny. Only when the htlc reaches the attacker node, or any other node on\nthe network that is (unintentionally) mishaving for some reason, the delta\nstarts to increase quickly for that node. The cost is borne by the node\nthat should bear it.\n\nThis would also fix concerns that have been voiced around hodl invoices.\nWith the reverse bond payment as described above, hodling nodes will pay\nfor the cost of their actions.\n\nMany details skipped over, but interested to hear opinions on the viability\nof this variation of up-front payments.\n\nJoost\n\nOn Tue, Nov 5, 2019 at 3:25 AM Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> Hi all,\n>\n>         It's been widely known that we're going to have to have up-front\n> payments for msgs eventually, to avoid Type 2 spam (I think of Type 1\n> link-local, Type 2 though multiple nodes, and Type 3 liquidity-using\n> spam).\n>\n>         Since both Offers and Joost's WhatSat are looking at sending\n> messages, it's time to float actual proposals.  I've been trying to come\n> up with something for several years now, so thought I'd present the best\n> I've got in the hope that others can improve on it.\n>\n> 1. New feature bit, extended messages, etc.\n> 2. Adding an HTLC causes a *push* of a number of msat on\n>    commitment_signed (new field), and a hash.\n> 3. Failing/succeeding an HTLC returns some of those msat, and a count\n>    and preimage (new fields).\n>\n> How many msat can you take for forwarding?  That depends on you\n> presenting a series of preimages (which chain into a final hash given in\n> the HTLC add), which you get by decoding the onion.  You get to keep 50\n> msat[1] per preimage you present[2].\n>\n> So, how many preimages does the user have to give to have you forward\n> the payment?  That depends.  The base rate is 16 preimages, but subtract\n> one for each leading 4 zero bits of the SHA256(blockhash | hmac) of the\n> onion.  The blockhash is the hash of the block specified in the onion:\n> reject if it's not in the last 3 blocks[3].\n>\n> This simply adds some payment noise, while allowing a hashcash style\n> tradeoff of sats for work.\n>\n> The final node gets some variable number of preimages, which adds noise.\n> It should take all and subtract from the minimum required invoice amount\n> on success, or take some random number on failure.\n>\n> This leaks some forward information, and makes an explicit tradeoff for\n> the sender between amount spent and privacy, but it's the best I've been\n> able to come up with.\n>\n> Thoughts?\n> Rusty.\n>\n> [1] If we assume $1 per GB, $10k per BTC and 64k messages, we get about\n>     655msat per message.  Flat pricing for simplicity; we're trying to\n>     prevent spam, not create a spam market.\n> [2] Actually, a number and a single preimage; you can check this is\n>     indeed the n'th preimage.\n> [3] This reduces incentive to grind the damn things in advance, though\n>     maybe that's dumb?  We can also use a shorter hash (siphash?), or\n>     even truncated SHA256 (128 bits).\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200218/59b4ba73/attachment.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2020-02-20T03:22:30",
                "message_text_only": "On Tue, Feb 18, 2020 at 10:23:29AM +0100, Joost Jager wrote:\n> A different way of mitigating this is to reverse the direction in which the\n> bond is paid. So instead of paying to offer an htlc, nodes need to pay to\n> receive an htlc. This sounds counterintuitive, but for the described jamming\n> attack there is also an attacker node at the end of the route. The attacker\n> still pays.\n\nI think this makes a lot of sense. I think the way it would end up working\nis that the further the route extends, the greater the payments are, so:\n\n  A -> B   : B sends A 1msat per minute\n  A -> B -> C : C sends B 2msat per minute, B forwards 1msat/min to A\n  A -> B -> C -> D : D sends C 3 msat, etc\n  A -> B -> C -> D -> E : E sends D 4 msat, etc\n\nso each node is receiving +1 msat/minute, except for the last one, who's\npaying n msat/minute, where n is the number of hops to have gotten up to\nthe last one. There's the obvious privacy issue there, with fairly\nobvious ways to fudge around it, I think.\n\nBut that's rational, because that last node can either (a) collect the\npayment, covering their cost; or (b) forward the payment, at which point\nthey'll start collecting funds rather than paying them; or (c) cancel\nthe payment releasing all the locked up funds all the way back.\n\nI think it might make sense for the payments to have a grace period --\nie, \"if you keep this payment open longer than 20 seconds, you have to\nstart paying me x msat/minute, but if it fulfills or cancels before\nthen, it's all good\".\n\nI'm not sure if there needs to be any enforcement for this beyond \"this\npeer isn't obeying the protocol, so I'm going to close the channel\"; not\neven sure it's something that needs to be negotiated as part of payment\nrouting -- it could just be something each peer does for HTLCs on their\nchannels? If that can be made to work, it doesn't need much crypto or\nbitcoin consensus changes, or even much deployment coordination, all of\nwhich would be awesome.\n\nI think at $10k/BTC then 1msat is about the fair price for locking up $5\nworth of BTC (so 50k sat) for 1 minute at a 1% pa interest rate, fwiw.\n\nMaybe this opens up some sort of an attack where a peer lies about the\ntime to make the \"per minute\" go faster, but if msats-per-minute is the\nunits, not sure that really matters.\n\nMaybe this also implies a different protocol for HTLC forwarding,\nsomething like:\n\n  1. A sends the HTLC onion packet to B\n  2. B decrypts it, makes sure it makes sense\n  3. B sends a half-signed updated channel state back to A\n  4. A accepts it, and forwards the other half-signed channel update to B\n\nso that at any point before (4) Alice can say \"this is taking too long,\nI'll start losing money\" and safely abort the HTLC she was forwarding to\nBob to avoid paying fees; while only after (4) can she start the time on\nexpecting Bob to start paying fees that she'll forward back. That means\n1.5 round-trips before Bob can really forward the HTLC on to Carol;\nbut maybe it's parallelisable, so Bob/Carol could start at (1) as soon\nas Alice/Bob has finished (2).\n\nCheers\naj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-20T03:42:39",
                "message_text_only": "Good morning Joost and aj,\n\nA thought that arises here is, what happens if I have forwarded a payment, then the outgoing channel is dropped onchain and that peer disconnects from me?\n\nSince the onchain HTLC might have a timelock of, say, a few hundred blocks from now, the outgoing peer can claim it up until the timelock.\nIf the peer does not claim it, I cannot claim it in my incoming as well.\nI also cannot safely fail my incoming, as the outgoing peer can still claim it until the timelock expires.\n\nAm I liable for paying the encumbrance fee in this situation?\nHow do I charge the next node the encumbrance fee myself if it has dropped the channel onchain and disconnected from me?\n\nRegards,\nZmnSCPxj\n\n> On Tue, Feb 18, 2020 at 10:23:29AM +0100, Joost Jager wrote:\n>\n> > A different way of mitigating this is to reverse the direction in which the\n> > bond is paid. So instead of paying to offer an htlc, nodes need to pay to\n> > receive an htlc. This sounds counterintuitive, but for the described jamming\n> > attack there is also an attacker node at the end of the route. The attacker\n> > still pays.\n>\n> I think this makes a lot of sense. I think the way it would end up working\n> is that the further the route extends, the greater the payments are, so:\n>\n> A -> B : B sends A 1msat per minute\n> A -> B -> C : C sends B 2msat per minute, B forwards 1msat/min to A\n> A -> B -> C -> D : D sends C 3 msat, etc\n> A -> B -> C -> D -> E : E sends D 4 msat, etc\n>\n> so each node is receiving +1 msat/minute, except for the last one, who's\n> paying n msat/minute, where n is the number of hops to have gotten up to\n> the last one. There's the obvious privacy issue there, with fairly\n> obvious ways to fudge around it, I think.\n>\n> But that's rational, because that last node can either (a) collect the\n> payment, covering their cost; or (b) forward the payment, at which point\n> they'll start collecting funds rather than paying them; or (c) cancel\n> the payment releasing all the locked up funds all the way back.\n>\n> I think it might make sense for the payments to have a grace period --\n> ie, \"if you keep this payment open longer than 20 seconds, you have to\n> start paying me x msat/minute, but if it fulfills or cancels before\n> then, it's all good\".\n>\n> I'm not sure if there needs to be any enforcement for this beyond \"this\n> peer isn't obeying the protocol, so I'm going to close the channel\"; not\n> even sure it's something that needs to be negotiated as part of payment\n> routing -- it could just be something each peer does for HTLCs on their\n> channels? If that can be made to work, it doesn't need much crypto or\n> bitcoin consensus changes, or even much deployment coordination, all of\n> which would be awesome.\n>\n> I think at $10k/BTC then 1msat is about the fair price for locking up $5\n> worth of BTC (so 50k sat) for 1 minute at a 1% pa interest rate, fwiw.\n>\n> Maybe this opens up some sort of an attack where a peer lies about the\n> time to make the \"per minute\" go faster, but if msats-per-minute is the\n> units, not sure that really matters.\n>\n> Maybe this also implies a different protocol for HTLC forwarding,\n> something like:\n>\n> 1.  A sends the HTLC onion packet to B\n> 2.  B decrypts it, makes sure it makes sense\n> 3.  B sends a half-signed updated channel state back to A\n> 4.  A accepts it, and forwards the other half-signed channel update to B\n>\n>     so that at any point before (4) Alice can say \"this is taking too long,\n>     I'll start losing money\" and safely abort the HTLC she was forwarding to\n>     Bob to avoid paying fees; while only after (4) can she start the time on\n>     expecting Bob to start paying fees that she'll forward back. That means\n>     1.5 round-trips before Bob can really forward the HTLC on to Carol;\n>     but maybe it's parallelisable, so Bob/Carol could start at (1) as soon\n>     as Alice/Bob has finished (2).\n>\n>     Cheers\n>     aj\n>\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Anthony Towns",
                "date": "2020-02-20T06:02:25",
                "message_text_only": "On Thu, Feb 20, 2020 at 03:42:39AM +0000, ZmnSCPxj wrote:\n> A thought that arises here is, what happens if I have forwarded a payment, then the outgoing channel is dropped onchain and that peer disconnects from me?\n> \n> Since the onchain HTLC might have a timelock of, say, a few hundred blocks from now, the outgoing peer can claim it up until the timelock.\n> If the peer does not claim it, I cannot claim it in my incoming as well.\n> I also cannot safely fail my incoming, as the outgoing peer can still claim it until the timelock expires.\n\nSuppose the channel state looks like:\n\n  Bob's balance:   $150\n  Carol's balance: $500\n  Bob to Carol:     $50, hash X, timelock +2016 blocks\n\nThe pre-signed close transaction will have already deducted maybe $1 in\nfees, say 50c from each balance.\n\nAt 5% pa, that's $50*0.05*2/52, so about 10 cents worth of \"holding\"\nfees, so that seems like it's worth just committing to up-front, ie:\n\n  Bob's balance:   $149.60 (-.50+.10)\n  Carol's balance: $499.40 (-.50-.10)\n  Bob to Carol:     $50, hash X, timelock +2016 blocks\n  Fees:              $1\n\nAnd that seems necessary anyway: if the channel does drop to the chain,\nthen the HTLC can't be cancelled, so if it never confirms, Bob will have\nhad to pay, say, 9.5c to Alice waiting for the timeout, and can then\nimmediately cancel the HTLC with Alice allowing it to finish unwinding.\n\nSo I think the idea would be not to accept a (rate, amount, timelock)\ntuple for an incoming HTLC unless the rate*amount*timelock product\nis substantially less than what you're putting towards the blockchain\nfees anyway, as otherwise you've got bad incentives for the other guy to\ndrop to the chain.\n\nNote the rate increases with number of hops, so if it's 1% pa per hop,\nthe 11th peer will be emitting 10% pa. I think that's probably okay,\nbecause BTC's deflationary nature probably means you don't need to earn\nmuch interest on it, and you can naturally choose the rate dynamically\nbased on how many HTLCs you currently have open and how much of your\nchannel funds are being used up by the HTLC?\n\nAlso, you'd presumably update your channel state every hundred blocks,\nreducing the 10c by half a cent or so each time, so you could have your\nrisk reduce. Maybe there could be some way of bumping the timelock across\na HTLC path so that the risk is capped, but if the HTLC is still being\npaid for it doesn't have to be cancelled?\n\nCheers,\naj"
            },
            {
                "author": "Rusty Russell",
                "date": "2020-02-21T02:05:20",
                "message_text_only": "Anthony Towns <aj at erisian.com.au> writes:\n> On Tue, Feb 18, 2020 at 10:23:29AM +0100, Joost Jager wrote:\n>> A different way of mitigating this is to reverse the direction in which the\n>> bond is paid. So instead of paying to offer an htlc, nodes need to pay to\n>> receive an htlc. This sounds counterintuitive, but for the described jamming\n>> attack there is also an attacker node at the end of the route. The attacker\n>> still pays.\n>\n> I think this makes a lot of sense. I think the way it would end up working\n> is that the further the route extends, the greater the payments are, so:\n>\n>   A -> B   : B sends A 1msat per minute\n>   A -> B -> C : C sends B 2msat per minute, B forwards 1msat/min to A\n>   A -> B -> C -> D : D sends C 3 msat, etc\n>   A -> B -> C -> D -> E : E sends D 4 msat, etc\n>\n> so each node is receiving +1 msat/minute, except for the last one, who's\n> paying n msat/minute, where n is the number of hops to have gotten up to\n> the last one. There's the obvious privacy issue there, with fairly\n> obvious ways to fudge around it, I think.\n\nYes, it needs to scale with distance to work at all.  However, it has\nthe same problems with other upfront schemes: how does E know to send\n4msat per minute?\n\n> I think it might make sense for the payments to have a grace period --\n> ie, \"if you keep this payment open longer than 20 seconds, you have to\n> start paying me x msat/minute, but if it fulfills or cancels before\n> then, it's all good\".\n\nBut whatever the grace period, I can just rely on knowing that B is in\nAustralia (with a 1 second HTLC commit time) to make that node bleed\nsatoshis.  I can send A->B->C, and have C fail the htlc after 19\nseconds for free.  But B has to send 1msat to A.  B can't blame A or C,\nsince this attack could come from further away, too.\n\nThis attack always seems possible.  Are you supposed to pay immediately\nto fail an HTLC?  That makes for a trivial attack, so I guess not.\n\nAnd if there is a grace period, I can just gum up the network with lots\nof slow-but-not-slow-enough HTLCs.\n\n> Maybe this also implies a different protocol for HTLC forwarding,\n> something like:\n>\n>   1. A sends the HTLC onion packet to B\n>   2. B decrypts it, makes sure it makes sense\n>   3. B sends a half-signed updated channel state back to A\n>   4. A accepts it, and forwards the other half-signed channel update to B\n>\n> so that at any point before (4) Alice can say \"this is taking too long,\n> I'll start losing money\" and safely abort the HTLC she was forwarding to\n> Bob to avoid paying fees; while only after (4) can she start the time on\n> expecting Bob to start paying fees that she'll forward back. That means\n> 1.5 round-trips before Bob can really forward the HTLC on to Carol;\n> but maybe it's parallelisable, so Bob/Carol could start at (1) as soon\n> as Alice/Bob has finished (2).\n\nWe added a ping-before-commit[1] to avoid the case where B has disconnected\nand we don't know yet; we have to assume an HTLC is stuck once we send\ncommitment_signed.  This would be a formalization of that, but I don't\nthink it's any better?\n\nThere's an old proposal to fast-fail HTLCs: Bob sends an new message \"I\nwould fail this HTLC once it's committed, here's the error\" and if Alice\ngets it before she sends the commitment_signed, she sends a new\n\"unadd_htlc\" message first.  This theoretically allows Bob to do the\nsame: optimistically forward it, and unadd it if Alice doesn't commit\nwith it in time.[2]\n\nCheers,\nRusty.\n\n[1] Technically, if we haven't seen any traffic from the peer in the\n    last 30 seconds, we send a ping and wait.\n\n[2] This seems like a speedup, but it only is if someone fails the HTLC.\n    We still need to send the commitment_signed back and forth (w/\n    revoke and ack) before committing to it in the next hop."
            },
            {
                "author": "Anthony Towns",
                "date": "2020-02-23T09:08:01",
                "message_text_only": "On Fri, Feb 21, 2020 at 12:35:20PM +1030, Rusty Russell wrote:\n> > I think the way it would end up working\n> > is that the further the route extends, the greater the payments are, so:\n> >   A -> B   : B sends A 1msat per minute\n> >   A -> B -> C : C sends B 2msat per minute, B forwards 1msat/min to A\n> >   A -> B -> C -> D : D sends C 3 msat, etc\n> >   A -> B -> C -> D -> E : E sends D 4 msat, etc\n> > so each node is receiving +1 msat/minute, except for the last one, who's\n> > paying n msat/minute, where n is the number of hops to have gotten up to\n> > the last one. There's the obvious privacy issue there, with fairly\n> > obvious ways to fudge around it, I think.\n> Yes, it needs to scale with distance to work at all.  However, it has\n> the same problems with other upfront schemes: how does E know to send\n> 4msat per minute?\n\nD tells it \"if you want this HTLC, you'll need to pay 4msat/minute after\nthe grace period of 65 seconds\". Which also means A as the originator can\nalso choose whatever fees they like. The only consequence of choosing too\nhigh a fee is that it's more likely one of the intermediate nodes will\nsay \"screw that!\" and abort the HTLC before it gets to the destination.\n\n> > I think it might make sense for the payments to have a grace period --\n> > ie, \"if you keep this payment open longer than 20 seconds, you have to\n> > start paying me x msat/minute, but if it fulfills or cancels before\n> > then, it's all good\".\n> But whatever the grace period, I can just rely on knowing that B is in\n> Australia (with a 1 second HTLC commit time) to make that node bleed\n> satoshis.  I can send A->B->C, and have C fail the htlc after 19\n> seconds for free.  But B has to send 1msat to A.  B can't blame A or C,\n> since this attack could come from further away, too.\n\nSo A gives B a grace period of 35 seconds, B deducts 5 seconds\nprocessing time and 10 seconds for latency, so gives C a grace period of\n20 seconds; C rejects after 19 seconds, and B still has 15 seconds to\nnotify A before he has to start paying fees. Same setup as decreasing\ntimelocks when forwarding HTLCs.\n\n> And if there is a grace period, I can just gum up the network with lots\n> of slow-but-not-slow-enough HTLCs.\n\nWell, it reduces the \"gum up the network for <timeout> blocks\" to \"gum\nup the network for <grace period> seconds\", which seems like a pretty\nbig win. I think if you had 20 hops each with a 1 minute grace period,\nand each channel had a max_accepted_htlcs of 30, you'd need 25 HTLCs per\nsecond to block 1000 channels (so 2.7% of the 36k channels 1ml reports),\nso at the very least, successfully performing this attack would be\ndemonstrating lightning's solved bitcoin's transactions-per-second\nlimitation?\n\nI think you could do better by having the acceptable grace period be\ndynamic: both (a) requiring a shorter grace period the more funds a HTLC\nlocks up, which stops a single HTLC from gumming up the channel, and (b) \nrequiring a shorter grace period the more active HTLCs you have (or, the\nmore active HTLCs you have that are in the grace period, perhaps). That\nway if the network is loaded, you're prioritising more efficient routes\n(or at least ones that are willing to pay their way), and if it's under\nattack, you're dynamically increasing the resources needed to maintain\nthe attack.\n\nAnyway, that's my hot take; not claiming it's a perfect solution or\nfinal answer, rather that this still seems worth brainstorming out.\n\nMy feeling is that this might interact nicely with the sender-initiated\nupfront fee. Like, you could replace a grace period of 30 seconds at\n2msat/minute by always charging 2msat/minute but doing a forward payment\nof 1msat. But at this point I can't keep it all in my head at once to\nfigure out something that really makes sense.\n\n> > Maybe this also implies a different protocol for HTLC forwarding,\n> > something like:\n> >   1. A sends the HTLC onion packet to B\n> >   2. B decrypts it, makes sure it makes sense\n> >   3. B sends a half-signed updated channel state back to A\n> >   4. A accepts it, and forwards the other half-signed channel update to B\n> > so that at any point before (4) Alice can say \"this is taking too long,\n> > I'll start losing money\" and safely abort the HTLC she was forwarding to\n> > Bob to avoid paying fees; while only after (4) can she start the time on\n> > expecting Bob to start paying fees that she'll forward back. That means\n> > 1.5 round-trips before Bob can really forward the HTLC on to Carol;\n> > but maybe it's parallelisable, so Bob/Carol could start at (1) as soon\n> > as Alice/Bob has finished (2).\n> We added a ping-before-commit[1] to avoid the case where B has disconnected\n> and we don't know yet; we have to assume an HTLC is stuck once we send\n> commitment_signed.  This would be a formalization of that, but I don't\n> think it's any better?\n\nI don't think it's any better as things stand, but with the \"B pays A\nholding fees\" I think it becomes necessary. If you've got a route\nA->B->C then from B's perspective I think it currently looks like:\n\n  A->B: here's a HTLC, locked in\n\n  B->C: ping\n  C->B: pong!\n  B->C: updated commitment with HTLC locked in\n\n  C->B: *silence*\n\nat which point the best B can do is unilaterally close the B/C channel\nwith their pre-HTLC commitment, but they still have to wait for that to\nconfirm before they can safely cancel the HTLC with A, and that will\nlikely take more than whatever the grace period is, so B will be losing\nmoney on holding fees.\n\nWhereas:\n\n  A->B: here's a HTLC, locked in\n\n  B->C: HTLC proposal\n  C->B: sure: updated commitment with HTLC locked in\n  B->C: great, corresponding updated commitment, plus revocation\n  C->B: revocation\n\nmeans that if C goes silent before B receives a new commitment, B can\ncancel the HTLC with A with no risk (B can publish the old commitment\nstill even if the new arrives later, and C can only publish the pre-HTLC\ncommitment), and if C goes silent after B receives the new commitment, B\ncan drop the new commitment to the blockchain and pay A's fees out of it.\n\n> There's an old proposal to fast-fail HTLCs: Bob sends an new message \"I\n> would fail this HTLC once it's committed, here's the error\" \n\nYeah, you could do \"B->C: proposal, C->B: no way!\" instead of \"sure\" to\nfast fail the above too. \n\nAnd I think something like that's necessary (at least with my view of how\nthis \"keep the HTLC open\" payment would work), otherwise B could send C a\n\"1 microsecond grace period, rate of 3e11 msat/minute, HTLC for 100 sat,\ntimeout of 2016 blocks\" and if C couldn't reject it immediately would\nowe B 50c per millisecond it took to cancel.\n\nCheers,\naj"
            },
            {
                "author": "Rusty Russell",
                "date": "2020-02-24T02:59:36",
                "message_text_only": "Anthony Towns <aj at erisian.com.au> writes:\n> On Fri, Feb 21, 2020 at 12:35:20PM +1030, Rusty Russell wrote:\n>> And if there is a grace period, I can just gum up the network with lots\n>> of slow-but-not-slow-enough HTLCs.\n>\n> Well, it reduces the \"gum up the network for <timeout> blocks\" to \"gum\n> up the network for <grace period> seconds\", which seems like a pretty\n> big win. I think if you had 20 hops each with a 1 minute grace period,\n> and each channel had a max_accepted_htlcs of 30, you'd need 25 HTLCs per\n> second to block 1000 channels (so 2.7% of the 36k channels 1ml reports),\n> so at the very least, successfully performing this attack would be\n> demonstrating lightning's solved bitcoin's transactions-per-second\n> limitation?\n\nBut the comparison here is not with the current state, but with the\n\"best previous proposal we have\", which is:\n\n1. Charge an up-front fee for accepting any HTLC.\n2. Will hang-up after grace period unless you either prove a channel\n   close, or gain another grace period by decrypting onion.\n\n(There was is an obvious extension to this, where you pay another HTLC\nfirst which covers the (larger) up-front fee for the \"I know the next\nHTLC is going to take a long time\").\n\nThat proposal is simpler, and covers this case quite nicely.\n\n> at which point the best B can do is unilaterally close the B/C channel\n> with their pre-HTLC commitment, but they still have to wait for that to\n> confirm before they can safely cancel the HTLC with A, and that will\n> likely take more than whatever the grace period is, so B will be losing\n> money on holding fees.\n>\n> Whereas:\n>\n>   A->B: here's a HTLC, locked in\n>\n>   B->C: HTLC proposal\n>   C->B: sure: updated commitment with HTLC locked in\n>   B->C: great, corresponding updated commitment, plus revocation\n>   C->B: revocation\n>\n> means that if C goes silent before B receives a new commitment, B can\n> cancel the HTLC with A with no risk (B can publish the old commitment\n> still even if the new arrives later, and C can only publish the pre-HTLC\n> commitment), and if C goes silent after B receives the new commitment, B\n> can drop the new commitment to the blockchain and pay A's fees out of it.\n\nInteresting; this adds a trip, but not in latency (since C can still\ncount on the HTLC being locked in at step 3).\n\nI don't see how it helps B though?  It still ends up paying A, and C\ndoesn't pay anything?\n\nIt forces a liveness check of C, but TBH I dread rewriting the state\nmachine for this when we can just ping like we do now.\n\n>> There's an old proposal to fast-fail HTLCs: Bob sends an new message \"I\n>> would fail this HTLC once it's committed, here's the error\" \n>\n> Yeah, you could do \"B->C: proposal, C->B: no way!\" instead of \"sure\" to\n> fast fail the above too. \n>\n> And I think something like that's necessary (at least with my view of how\n> this \"keep the HTLC open\" payment would work), otherwise B could send C a\n> \"1 microsecond grace period, rate of 3e11 msat/minute, HTLC for 100 sat,\n> timeout of 2016 blocks\" and if C couldn't reject it immediately would\n> owe B 50c per millisecond it took to cancel.\n\nWell, surely grace period (and penalty rate) are either fixed in the\nprotocol or negotiated up-front, not per-HTLC.\n\nCheers,\nRusty."
            },
            {
                "author": "Anthony Towns",
                "date": "2020-02-27T12:06:56",
                "message_text_only": "On Mon, Feb 24, 2020 at 01:29:36PM +1030, Rusty Russell wrote:\n> Anthony Towns <aj at erisian.com.au> writes:\n> > On Fri, Feb 21, 2020 at 12:35:20PM +1030, Rusty Russell wrote:\n> >> And if there is a grace period, I can just gum up the network with lots\n> >> of slow-but-not-slow-enough HTLCs.\n> > Well, it reduces the \"gum up the network for <timeout> blocks\" to \"gum\n> > up the network for <grace period> seconds\", which seems like a pretty\n> > big win. I think if you had 20 hops each with a 1 minute grace period,\n> > and each channel had a max_accepted_htlcs of 30, you'd need 25 HTLCs per\n> > second to block 1000 channels (so 2.7% of the 36k channels 1ml reports),\n> > so at the very least, successfully performing this attack would be\n> > demonstrating lightning's solved bitcoin's transactions-per-second\n> > limitation?\n> But the comparison here is not with the current state, but with the\n> \"best previous proposal we have\", which is:\n> \n> 1. Charge an up-front fee for accepting any HTLC.\n> 2. Will hang-up after grace period unless you either prove a channel\n>    close, or gain another grace period by decrypting onion.\n\nIn general I don't really like comparing ideas that are still in\nbrainstorming mode; it's never clear whether there are unavoidable\npitfalls in one or the other that won't become clear until they're\nactually implemented...\n\nSpecifically, I'm not a fan of either channel closes or peeling the onion\n-- the former causes problems if you're trying to route across sidechains\nor have lightning as a third layer above channel factories or similar,\nand I'm not convinced even within Bitcoin \"proving a channel close\"\nis that meaningful, and passing around decrypted onions seems like it\nopens up privacy attacks.\n\nAside from those philosophical complaints, seems to me the simplest\nattack would be:\n\n  * route 1000s of HTLCs from your node A1 to your node A2 via different,\n    long paths, using up the total channel capacity of your A1/A2 nodes,\n    with long timeouts\n  * have A2 offer up a transaction claiming that was the channel\n    close to A3; make it a real thing if necessary, but it's probably\n    fake-able\n  * then leave the HTLCs open until they time out, using up capacity\n    from all the nodes in your 1000s of routes. For every satoshi of\n    yours that's tied up, you should be able to tie up 10-20sat of other\n    people's funds\n\nThat increases the cost of the attack by one on-chain transaction per\ntimeout period, and limits the attack surface by how many transactions\nyou can get started/completed within whatever the grace period is, but\nit doesn't seem a lot better than what we have today, unless onchain\nfees go up a lot.\n\n(If the up-front fee is constant, then A1 paid a fee, and A2 collected a\nfee so it's a net wash; if it's not constant then you've got a lot of\nhassle making it work with any privacy I think)\n\n> >   A->B: here's a HTLC, locked in\n> >   B->C: HTLC proposal\n> >   C->B: sure: updated commitment with HTLC locked in\n> >   B->C: great, corresponding updated commitment, plus revocation\n> >   C->B: revocation\n> Interesting; this adds a trip, but not in latency (since C can still\n> count on the HTLC being locked in at step 3).\n> I don't see how it helps B though?  It still ends up paying A, and C\n> doesn't pay anything?\n\nThe updated commitment has C paying B onchain; if B doesn't receive that\nby the time the grace period's about over, B can cancel the HTLC with A,\nand then there's statemachine complexity for B to cancel it with C if\nC comes alive again a little later.\n\n> It forces a liveness check of C, but TBH I dread rewriting the state\n> machine for this when we can just ping like we do now.\n\nI'd be surprised if making musig work doesn't require a dread rewrite\nof the state machine as well, and then there's PTLCs and eltoo...\n\n> >> There's an old proposal to fast-fail HTLCs: Bob sends an new message \"I\n> >> would fail this HTLC once it's committed, here's the error\" \n> > Yeah, you could do \"B->C: proposal, C->B: no way!\" instead of \"sure\" to\n> > fast fail the above too. \n> > And I think something like that's necessary (at least with my view of how\n> > this \"keep the HTLC open\" payment would work), otherwise B could send C a\n> > \"1 microsecond grace period, rate of 3e11 msat/minute, HTLC for 100 sat,\n> > timeout of 2016 blocks\" and if C couldn't reject it immediately would\n> > owe B 50c per millisecond it took to cancel.\n> Well, surely grace period (and penalty rate) are either fixed in the\n> protocol or negotiated up-front, not per-HTLC.\n\nI think the \"keep open rate\" should depend on how many nodes have\nalready been in the route (the more hops it's gone through, the more\nfunds/channels you're tying up by holding onto the HTLC, so the more\nyou should pay), while the grace period should depend on how many nodes\nthere are still to go in the route (it needs to be higher to let each of\nthose nodes deduct their delta from it). So I think you *should* expect\nthose to change per HTLC than you're forwarding, as those factors will\nbe different for different HTLCs.\n\nCheers,\naj"
            },
            {
                "author": "Rusty Russell",
                "date": "2020-02-28T03:41:32",
                "message_text_only": "Anthony Towns <aj at erisian.com.au> writes:\n> Aside from those philosophical complaints, seems to me the simplest\n> attack would be:\n>\n>   * route 1000s of HTLCs from your node A1 to your node A2 via different,\n>     long paths, using up the total channel capacity of your A1/A2 nodes,\n>     with long timeouts\n>   * have A2 offer up a transaction claiming that was the channel\n>     close to A3; make it a real thing if necessary, but it's probably\n>     fake-able\n>   * then leave the HTLCs open until they time out, using up capacity\n>     from all the nodes in your 1000s of routes. For every satoshi of\n>     yours that's tied up, you should be able to tie up 10-20sat of other\n>     people's funds\n>\n> That increases the cost of the attack by one on-chain transaction per\n> timeout period, and limits the attack surface by how many transactions\n> you can get started/completed within whatever the grace period is, but\n> it doesn't seem a lot better than what we have today, unless onchain\n> fees go up a lot.\n\nInterestingly, I think your \"reverse commitment signing\" proposal would\nmean the close tx will have the HTLC within it, so this attack is not\npossible?  (Modulo handling dust HTLCs, which won't show up in the\ncommitment tx).\n\nPreviously I suggested the node simply send a (signed) list of up to N\nadditional HTLCs (this reduces batching to N, so make it at least 16).\nThis is gossiped, and if you get conflicting versions, the channel break\nis considered invalid, so (as always) the previous channel has to break.\n\n>> >   A->B: here's a HTLC, locked in\n>> >   B->C: HTLC proposal\n>> >   C->B: sure: updated commitment with HTLC locked in\n>> >   B->C: great, corresponding updated commitment, plus revocation\n>> >   C->B: revocation\n>> Interesting; this adds a trip, but not in latency (since C can still\n>> count on the HTLC being locked in at step 3).\n>> I don't see how it helps B though?  It still ends up paying A, and C\n>> doesn't pay anything?\n>\n> The updated commitment has C paying B onchain; if B doesn't receive that\n> by the time the grace period's about over, B can cancel the HTLC with A,\n> and then there's statemachine complexity for B to cancel it with C if\n> C comes alive again a little later.\n\nI thought C paid per unit time, so it wouldn't pay up-front?  You're\nsuggesting it pays the max in the commitment, and then it gets some back\nin the normal case of things going right?\n\n>> It forces a liveness check of C, but TBH I dread rewriting the state\n>> machine for this when we can just ping like we do now.\n>\n> I'd be surprised if making musig work doesn't require a dread rewrite\n> of the state machine as well, and then there's PTLCs and eltoo...\n\nHmm, PTLCs and eltoo don't.  Musig requires some mods to the protocol,\nbut the state machine changes are trivial.\n\n>> >> There's an old proposal to fast-fail HTLCs: Bob sends an new message \"I\n>> >> would fail this HTLC once it's committed, here's the error\" \n>> > Yeah, you could do \"B->C: proposal, C->B: no way!\" instead of \"sure\" to\n>> > fast fail the above too. \n>> > And I think something like that's necessary (at least with my view of how\n>> > this \"keep the HTLC open\" payment would work), otherwise B could send C a\n>> > \"1 microsecond grace period, rate of 3e11 msat/minute, HTLC for 100 sat,\n>> > timeout of 2016 blocks\" and if C couldn't reject it immediately would\n>> > owe B 50c per millisecond it took to cancel.\n>> Well, surely grace period (and penalty rate) are either fixed in the\n>> protocol or negotiated up-front, not per-HTLC.\n>\n> I think the \"keep open rate\" should depend on how many nodes have\n> already been in the route (the more hops it's gone through, the more\n> funds/channels you're tying up by holding onto the HTLC, so the more\n> you should pay), while the grace period should depend on how many nodes\n> there are still to go in the route (it needs to be higher to let each of\n> those nodes deduct their delta from it). So I think you *should* expect\n> those to change per HTLC than you're forwarding, as those factors will\n> be different for different HTLCs.\n\nIn theory, but I could lie about both, and it's very undesirable to\ncommunicate these things anyway.  I think it might make it worse, not\nbetter, than having a fixed (per-msat?) rate.\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "A proposal for up-front payments.",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Anthony Towns",
                "Rusty Russell",
                "Joost Jager",
                "ZmnSCPxj"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 38259
        }
    },
    {
        "title": "[Lightning-dev] Direct Message draft",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2020-02-20T09:36:55",
                "message_text_only": "Hi all!\n\n        It seems that messaging over lightning is A Thing, and I want to\nuse it for the offers protocol anyway.  So I've come up with the\nsimplest proposal I can, and even implemented it.\n\n        Importantly, it's unreliable.  Our implementation doesn't\nremember across restarts, limits us to 1000 total remembered forwards\nwith random drop, and the protocol doesn't (yet?) include a method for\nerrors.\n\n        This is much friendlier on nodes than using an HTLC (which\nrequires 2 round trips, signature calculations and db commits), so is an\nobvious candidate for much more than just invoice requests.\n\n        The WIP patch is small enough I've pasted it below, but it's\nalso at https://github.com/lightningnetwork/lightning-rfc/pull/748\n\ndiff --git a/01-messaging.md b/01-messaging.md\nindex 40d1909..faa5b18 100644\n--- a/01-messaging.md\n+++ b/01-messaging.md\n@@ -56,7 +56,7 @@ The messages are grouped logically into five groups, ordered by the most signifi\n   - Setup & Control (types `0`-`31`): messages related to connection setup, control, supported features, and error reporting (described below)\n   - Channel (types `32`-`127`): messages used to setup and tear down micropayment channels (described in [BOLT #2](02-peer-protocol.md))\n   - Commitment (types `128`-`255`): messages related to updating the current commitment transaction, which includes adding, revoking, and settling HTLCs as well as updating fees and exchanging signatures (described in [BOLT #2](02-peer-protocol.md))\n-  - Routing (types `256`-`511`): messages containing node and channel announcements, as well as any active route exploration (described in [BOLT #7](07-routing-gossip.md))\n+  - Routing (types `256`-`511`): messages containing node and channel announcements, as well as any active route exploration or forwarding (described in [BOLT #7](07-routing-gossip.md))\n   - Custom (types `32768`-`65535`): experimental and application-specific messages\n \n The size of the message is required by the transport layer to fit into a 2-byte unsigned int; therefore, the maximum possible size is 65535 bytes.\ndiff --git a/04-onion-routing.md b/04-onion-routing.md\nindex 8d0f343..84eff9a 100644\n--- a/04-onion-routing.md\n+++ b/04-onion-routing.md\n@@ -51,6 +51,7 @@ A node:\n     * [Legacy HopData Payload Format](#legacy-hop_data-payload-format)\n     * [TLV Payload Format](#tlv_payload-format)\n     * [Basic Multi-Part Payments](#basic-multi-part-payments)\n+    * [Directed Messages](#directed-messages)\n   * [Accepting and Forwarding a Payment](#accepting-and-forwarding-a-payment)\n     * [Payload for the Last Node](#payload-for-the-last-node)\n     * [Non-strict Forwarding](#non-strict-forwarding)\n@@ -62,6 +63,7 @@ A node:\n   * [Returning Errors](#returning-errors)\n     * [Failure Messages](#failure-messages)\n     * [Receiving Failure Codes](#receiving-failure-codes)\n+  * [Directed Message Replies](#directed-message-replies)\n   * [Test Vector](#test-vector)\n     * [Returning Errors](#returning-errors)\n   * [References](#references)\n@@ -366,6 +368,13 @@ otherwise meets the amount criterion (eg. some other failure, or\n invoice timeout), however if it were to fulfill only some of them,\n intermediary nodes could simply claim the remaining ones.\n \n+### Directed Messages\n+\n+Directed messages have an onion with an alternate `hop_payload`\n+format.  If this node is not the intended recipient, the payload is\n+simply a 33-byte pubkey indicating the next recipient.  Otherwise, the\n+payload is the message for this node.\n+\n # Accepting and Forwarding a Payment\n \n Once a node has decoded the payload it either accepts the payment locally, or forwards it to the peer indicated as the next hop in the payload.\n@@ -1142,6 +1151,11 @@ The _origin node_:\n   - MAY use the data specified in the various failure types for debugging\n   purposes.\n \n+## Directed Message Replies\n+\n+Directed message replies are encoded the same way as failure messages,\n+except the contents is a directed message for the originator.\n+\n # Test Vector\n \n ## Returning Errors\ndiff --git a/07-routing-gossip.md b/07-routing-gossip.md\nindex ec1a8f0..4c2b836 100644\n--- a/07-routing-gossip.md\n+++ b/07-routing-gossip.md\n@@ -1,4 +1,4 @@\n-# BOLT #7: P2P Node and Channel Discovery\n+# BOLT #7: P2P Node and Channel Discovery and Directed Messages\n \n This specification describes simple node discovery, channel discovery, and channel update mechanisms that do not rely on a third-party to disseminate the information.\n \n@@ -31,6 +31,7 @@ multiple `node_announcement` messages, in order to update the node information.\n   * [HTLC Fees](#htlc-fees)\n   * [Pruning the Network View](#pruning-the-network-view)\n   * [Recommendations for Routing](#recommendations-for-routing)\n+  * [Directed Messages](#directed-messages)\n   * [References](#references)\n \n ## Definition of `short_channel_id`\n@@ -1103,6 +1104,37 @@ A->D's `update_add_htlc` message would be:\n And D->C's `update_add_htlc` would again be the same as B->C's direct payment\n above.\n \n+# Directed Messages\n+\n+Directed messages allow peers to use existing connections to query for\n+invoices (see [BOLT 12](12-offer-encoding.md)).  Like gossip messages,\n+they are not associated with a particular local channel.  Like HTLCs,\n+they use [BOLT 4](04-onion-routing.md#directed-messages) protocol for\n+end-to-end encryption.\n+\n+Directed messages are unreliable: in particular, they are designed to\n+be cheap and not to need to be committed to a database (though an\n+implementation may choose to).  Each one has an optional reply, which\n+is [onion encoded](04-onion-routing.md#directed-message-replies) 0just\n+like HTLC errors.\n+\n+## The `directed` and `directed_reply` Messages\n+\n+1. type: 385 (`directed`) (`option_directed_messages`)\n+2. data:\n+    * [`1366*byte`:`onion_routing_packet`]\n+\n+1. type: 386 (`directed_reply`) (`option_directed_messages`)\n+2. data:\n+    * [`sha256`:`onion_routing_packet_hash`]\n+    * [`u16`:`len`]\n+    * [`len*byte`:`reply`]\n+\n+## Requirements\n+\n+FIXME: similar to update_add_htlc and update_fail_htlc.\n+FIXME: define reasonable timeout after which you can forget if not replied?\n+\n ## References\n \n 1. <a id=\"reference-1\">[RFC 1950 \"ZLIB Compressed Data Format Specification version 3.3](https://www.ietf.org/rfc/rfc1950.txt)</a>"
            },
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2020-02-20T10:01:01",
                "message_text_only": "Hey Rusty,\n\nI was very delighted to read your proposal. But I don't see how you prevent\nmessage spam. If I understand you correctly you suggest that I can\ncommunicate to any node along a path of peer connections (not necessarily\nbacked by payment channels but kind of only known through channel\nannouncements of gossip) via onions and these onions which are send within\na new gossip message are not bound to any fees or payments.\n\nLet's assume I just missed some spam prevention mechanism or that we can\nfix them. Do I understand the impact of your suggestion correctly that I\ncould use this protocol to\n\n1.) create a fee free rebalancing protocol? Because I could also attach a\nnew lightning message inside the onions that would allow nodes without\ndirect peer connection to set up a circular rebalancing path.\n2.) have the ability to communicate with nodes further away than just my\npeers - for example to exchange information for pathfinding and / or\nautopilots?\n\n\nWith kind regards Rene\n\nRusty Russell <rusty at rustcorp.com.au> schrieb am Do., 20. Feb. 2020, 10:37:\n\n> Hi all!\n>\n>         It seems that messaging over lightning is A Thing, and I want to\n> use it for the offers protocol anyway.  So I've come up with the\n> simplest proposal I can, and even implemented it.\n>\n>         Importantly, it's unreliable.  Our implementation doesn't\n> remember across restarts, limits us to 1000 total remembered forwards\n> with random drop, and the protocol doesn't (yet?) include a method for\n> errors.\n>\n>         This is much friendlier on nodes than using an HTLC (which\n> requires 2 round trips, signature calculations and db commits), so is an\n> obvious candidate for much more than just invoice requests.\n>\n>         The WIP patch is small enough I've pasted it below, but it's\n> also at https://github.com/lightningnetwork/lightning-rfc/pull/748\n>\n> diff --git a/01-messaging.md b/01-messaging.md\n> index 40d1909..faa5b18 100644\n> --- a/01-messaging.md\n> +++ b/01-messaging.md\n> @@ -56,7 +56,7 @@ The messages are grouped logically into five groups,\n> ordered by the most signifi\n>    - Setup & Control (types `0`-`31`): messages related to connection\n> setup, control, supported features, and error reporting (described below)\n>    - Channel (types `32`-`127`): messages used to setup and tear down\n> micropayment channels (described in [BOLT #2](02-peer-protocol.md))\n>    - Commitment (types `128`-`255`): messages related to updating the\n> current commitment transaction, which includes adding, revoking, and\n> settling HTLCs as well as updating fees and exchanging signatures\n> (described in [BOLT #2](02-peer-protocol.md))\n> -  - Routing (types `256`-`511`): messages containing node and channel\n> announcements, as well as any active route exploration (described in [BOLT\n> #7](07-routing-gossip.md))\n> +  - Routing (types `256`-`511`): messages containing node and channel\n> announcements, as well as any active route exploration or forwarding\n> (described in [BOLT #7](07-routing-gossip.md))\n>    - Custom (types `32768`-`65535`): experimental and application-specific\n> messages\n>\n>  The size of the message is required by the transport layer to fit into a\n> 2-byte unsigned int; therefore, the maximum possible size is 65535 bytes.\n> diff --git a/04-onion-routing.md b/04-onion-routing.md\n> index 8d0f343..84eff9a 100644\n> --- a/04-onion-routing.md\n> +++ b/04-onion-routing.md\n> @@ -51,6 +51,7 @@ A node:\n>      * [Legacy HopData Payload Format](#legacy-hop_data-payload-format)\n>      * [TLV Payload Format](#tlv_payload-format)\n>      * [Basic Multi-Part Payments](#basic-multi-part-payments)\n> +    * [Directed Messages](#directed-messages)\n>    * [Accepting and Forwarding a\n> Payment](#accepting-and-forwarding-a-payment)\n>      * [Payload for the Last Node](#payload-for-the-last-node)\n>      * [Non-strict Forwarding](#non-strict-forwarding)\n> @@ -62,6 +63,7 @@ A node:\n>    * [Returning Errors](#returning-errors)\n>      * [Failure Messages](#failure-messages)\n>      * [Receiving Failure Codes](#receiving-failure-codes)\n> +  * [Directed Message Replies](#directed-message-replies)\n>    * [Test Vector](#test-vector)\n>      * [Returning Errors](#returning-errors)\n>    * [References](#references)\n> @@ -366,6 +368,13 @@ otherwise meets the amount criterion (eg. some other\n> failure, or\n>  invoice timeout), however if it were to fulfill only some of them,\n>  intermediary nodes could simply claim the remaining ones.\n>\n> +### Directed Messages\n> +\n> +Directed messages have an onion with an alternate `hop_payload`\n> +format.  If this node is not the intended recipient, the payload is\n> +simply a 33-byte pubkey indicating the next recipient.  Otherwise, the\n> +payload is the message for this node.\n> +\n>  # Accepting and Forwarding a Payment\n>\n>  Once a node has decoded the payload it either accepts the payment\n> locally, or forwards it to the peer indicated as the next hop in the\n> payload.\n> @@ -1142,6 +1151,11 @@ The _origin node_:\n>    - MAY use the data specified in the various failure types for debugging\n>    purposes.\n>\n> +## Directed Message Replies\n> +\n> +Directed message replies are encoded the same way as failure messages,\n> +except the contents is a directed message for the originator.\n> +\n>  # Test Vector\n>\n>  ## Returning Errors\n> diff --git a/07-routing-gossip.md b/07-routing-gossip.md\n> index ec1a8f0..4c2b836 100644\n> --- a/07-routing-gossip.md\n> +++ b/07-routing-gossip.md\n> @@ -1,4 +1,4 @@\n> -# BOLT #7: P2P Node and Channel Discovery\n> +# BOLT #7: P2P Node and Channel Discovery and Directed Messages\n>\n>  This specification describes simple node discovery, channel discovery,\n> and channel update mechanisms that do not rely on a third-party to\n> disseminate the information.\n>\n> @@ -31,6 +31,7 @@ multiple `node_announcement` messages, in order to\n> update the node information.\n>    * [HTLC Fees](#htlc-fees)\n>    * [Pruning the Network View](#pruning-the-network-view)\n>    * [Recommendations for Routing](#recommendations-for-routing)\n> +  * [Directed Messages](#directed-messages)\n>    * [References](#references)\n>\n>  ## Definition of `short_channel_id`\n> @@ -1103,6 +1104,37 @@ A->D's `update_add_htlc` message would be:\n>  And D->C's `update_add_htlc` would again be the same as B->C's direct\n> payment\n>  above.\n>\n> +# Directed Messages\n> +\n> +Directed messages allow peers to use existing connections to query for\n> +invoices (see [BOLT 12](12-offer-encoding.md)).  Like gossip messages,\n> +they are not associated with a particular local channel.  Like HTLCs,\n> +they use [BOLT 4](04-onion-routing.md#directed-messages) protocol for\n> +end-to-end encryption.\n> +\n> +Directed messages are unreliable: in particular, they are designed to\n> +be cheap and not to need to be committed to a database (though an\n> +implementation may choose to).  Each one has an optional reply, which\n> +is [onion encoded](04-onion-routing.md#directed-message-replies) 0just\n> +like HTLC errors.\n> +\n> +## The `directed` and `directed_reply` Messages\n> +\n> +1. type: 385 (`directed`) (`option_directed_messages`)\n> +2. data:\n> +    * [`1366*byte`:`onion_routing_packet`]\n> +\n> +1. type: 386 (`directed_reply`) (`option_directed_messages`)\n> +2. data:\n> +    * [`sha256`:`onion_routing_packet_hash`]\n> +    * [`u16`:`len`]\n> +    * [`len*byte`:`reply`]\n> +\n> +## Requirements\n> +\n> +FIXME: similar to update_add_htlc and update_fail_htlc.\n> +FIXME: define reasonable timeout after which you can forget if not\n> replied?\n> +\n>  ## References\n>\n>  1. <a id=\"reference-1\">[RFC 1950 \"ZLIB Compressed Data Format\n> Specification version 3.3](https://www.ietf.org/rfc/rfc1950.txt)</a>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200220/8274f3ba/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2020-02-20T23:33:22",
                "message_text_only": "Ren\u00e9 Pickhardt <r.pickhardt at googlemail.com> writes:\n> Hey Rusty,\n>\n> I was very delighted to read your proposal. But I don't see how you prevent\n> message spam. If I understand you correctly you suggest that I can\n> communicate to any node along a path of peer connections (not necessarily\n> backed by payment channels but kind of only known through channel\n> announcements of gossip) via onions and these onions which are send within\n> a new gossip message are not bound to any fees or payments.\n\nIt doesn't handle spam, but OTOH it's far cheaper than the HTLC system\n(which also doesn't handle spam).  I'd be delighted to add an up-front\n1msat payment, as soon as we can figure out how to do that.\n\nThe non-persistent storage costs for remembering how to forward the\nreply are the 200 bytes in my implementation (one pointer to the source\npeer, two SHA256s, and the shared secret).\n\n> Let's assume I just missed some spam prevention mechanism or that we can\n> fix them. Do I understand the impact of your suggestion correctly that I\n> could use this protocol to\n>\n> 1.) create a fee free rebalancing protocol? Because I could also attach a\n> new lightning message inside the onions that would allow nodes without\n> direct peer connection to set up a circular rebalancing path.\n> 2.) have the ability to communicate with nodes further away than just my\n> peers - for example to exchange information for pathfinding and / or\n> autopilots?\n\nIndeed.  I haven't prevented it, precisely because we *can't*.  This\nproposal merely gives a more efficient method than encoding via HTLCs.\n\nCheers,\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-20T10:17:30",
                "message_text_only": "Good morning Rusty,\n\nA concern I have brought up in the past is that if this is more than just a single request-response, i.e. if this is a conversation where Alice sends to Bob, Bob sends back to Alice, Alice sends back to Bob, and so on, then if the same path is used each time Alice sends to Bob, the timing from Bob response to Alice to the next Alice sends to Bob can help an intermediate node guess how far away Alice is from itself.\nObviously the timing from Alice sending to Bob and Bob replying gives a hint as well as to the distance the intermediate node is to Bob already.\n\nIt may be good to at least recommend that direct messages use different paths if they are part of a larger conversation between the two parties.\n\nWould it not be better to create a circular path?\nBy this I mean, Alice constructs an onion that overall creates a path from herself to Bob and back, ensuring different nodes on the forward and return directions.\nThe onion hop at Bob reveals that Bob is the chosen conversation partner, and Bob forwards its reply via the onion return path (that Alice prepared herself to get back to her via another path).\nAfter Alice receives the first message from Bob the circular \"circuit\" is established and they can continue to communicate using the same circuit: timing attacks are now \"impossible\" since Alice and Bob can be anywhere along the circle, even if two of the nodes in the circuit are surveillors cooperating with each other, the timing information they get is the distance between the surveillor nodes.\n\nOf course, if a node in the circular path drops the circuit is disrupted, so any higher-level protocols on top of that should probably be willing to resume the conversation on another circular circuit.\n\nI believe I even tied this to an HTLC in an attempt to provide a spam-limit as well: https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-November/002294.html\n\nFinally: what does this improve over, say, requiring that all Lightning nodes have a Tor .onion address and just doing direct messaging over Tor?\n\nRegards,\nZmnSCPxj\n\n> Hi all!\n>\n> It seems that messaging over lightning is A Thing, and I want to\n> use it for the offers protocol anyway. So I've come up with the\n> simplest proposal I can, and even implemented it.\n>\n> Importantly, it's unreliable. Our implementation doesn't\n> remember across restarts, limits us to 1000 total remembered forwards\n> with random drop, and the protocol doesn't (yet?) include a method for\n> errors.\n>\n> This is much friendlier on nodes than using an HTLC (which\n> requires 2 round trips, signature calculations and db commits), so is an\n> obvious candidate for much more than just invoice requests.\n>\n> The WIP patch is small enough I've pasted it below, but it's\n> also at https://github.com/lightningnetwork/lightning-rfc/pull/748\n>\n> diff --git a/01-messaging.md b/01-messaging.md\n> index 40d1909..faa5b18 100644\n> --- a/01-messaging.md\n> +++ b/01-messaging.md\n> @@ -56,7 +56,7 @@ The messages are grouped logically into five groups, ordered by the most signifi\n>\n> -   Setup & Control (types `0`-`31`): messages related to connection setup, control, supported features, and error reporting (described below)\n> -   Channel (types `32`-`127`): messages used to setup and tear down micropayment channels (described in BOLT #2)\n> -   Commitment (types `128`-`255`): messages related to updating the current commitment transaction, which includes adding, revoking, and settling HTLCs as well as updating fees and exchanging signatures (described in BOLT #2)\n> -   -   Routing (types `256`-`511`): messages containing node and channel announcements, as well as any active route exploration (described in BOLT #7)\n>\n> -   -   Routing (types `256`-`511`): messages containing node and channel announcements, as well as any active route exploration or forwarding (described in BOLT #7)\n>     -   Custom (types `32768`-`65535`): experimental and application-specific messages\n>\n>         The size of the message is required by the transport layer to fit into a 2-byte unsigned int; therefore, the maximum possible size is 65535 bytes.\n>         diff --git a/04-onion-routing.md b/04-onion-routing.md\n>         index 8d0f343..84eff9a 100644\n>         --- a/04-onion-routing.md\n>         +++ b/04-onion-routing.md\n>         @@ -51,6 +51,7 @@ A node:\n>         -   Legacy HopData Payload Format\n>         -   TLV Payload Format\n>         -   Basic Multi-Part Payments\n> -   -   Directed Messages\n>\n> -   Accepting and Forwarding a Payment\n>     -   Payload for the Last Node\n>     -   Non-strict Forwarding\n>         @@ -62,6 +63,7 @@ A node:\n>\n> -   Returning Errors\n>     -   Failure Messages\n>     -   Receiving Failure Codes\n>\n> -   -   Directed Message Replies\n>     -   Test Vector\n>         -   Returning Errors\n>     -   References\n>         @@ -366,6 +368,13 @@ otherwise meets the amount criterion (eg. some other failure, or\n>         invoice timeout), however if it were to fulfill only some of them,\n>         intermediary nodes could simply claim the remaining ones.\n>\n>         +### Directed Messages\n>\n> -\n>\n> +Directed messages have an onion with an alternate `hop_payload`\n> +format. If this node is not the intended recipient, the payload is\n> +simply a 33-byte pubkey indicating the next recipient. Otherwise, the\n> +payload is the message for this node.\n> +\n>\n> Accepting and Forwarding a Payment\n>\n> ===================================\n>\n> Once a node has decoded the payload it either accepts the payment locally, or forwards it to the peer indicated as the next hop in the payload.\n> @@ -1142,6 +1151,11 @@ The origin node:\n>\n> -   MAY use the data specified in the various failure types for debugging\n>     purposes.\n>\n>     +## Directed Message Replies\n>\n>\n> -\n>\n> +Directed message replies are encoded the same way as failure messages,\n> +except the contents is a directed message for the originator.\n> +\n>\n> Test Vector\n>\n> ============\n>\n> Returning Errors\n>\n> -----------------\n>\n> diff --git a/07-routing-gossip.md b/07-routing-gossip.md\n> index ec1a8f0..4c2b836 100644\n> --- a/07-routing-gossip.md\n> +++ b/07-routing-gossip.md\n> @@ -1,4 +1,4 @@\n> -# BOLT #7: P2P Node and Channel Discovery\n> +# BOLT #7: P2P Node and Channel Discovery and Directed Messages\n>\n> This specification describes simple node discovery, channel discovery, and channel update mechanisms that do not rely on a third-party to disseminate the information.\n>\n> @@ -31,6 +31,7 @@ multiple `node_announcement` messages, in order to update the node information.\n>\n> -   HTLC Fees\n> -   Pruning the Network View\n> -   Recommendations for Routing\n>\n> -   -   Directed Messages\n>     -   References\n>\n> Definition of `short_channel_id`\n>\n> ---------------------------------\n>\n> @@ -1103,6 +1104,37 @@ A->D's `update_add_htlc` message would be:\n> And D->C's `update_add_htlc` would again be the same as B->C's direct payment\n> above.\n>\n> +# Directed Messages\n> +\n> +Directed messages allow peers to use existing connections to query for\n> +invoices (see BOLT 12). Like gossip messages,\n> +they are not associated with a particular local channel. Like HTLCs,\n> +they use BOLT 4 protocol for\n> +end-to-end encryption.\n> +\n> +Directed messages are unreliable: in particular, they are designed to\n> +be cheap and not to need to be committed to a database (though an\n> +implementation may choose to). Each one has an optional reply, which\n> +is onion encoded 0just\n> +like HTLC errors.\n> +\n> +## The `directed` and `directed_reply` Messages\n> +\n> +1. type: 385 (`directed`) (`option_directed_messages`)\n> +2. data:\n>\n> -   -   [`1366*byte`:`onion_routing_packet`]\n> -\n>\n> +1. type: 386 (`directed_reply`) (`option_directed_messages`)\n> +2. data:\n>\n> -   -   [`sha256`:`onion_routing_packet_hash`]\n> -   -   [`u16`:`len`]\n> -   -   [`len*byte`:`reply`]\n> -\n>\n> +## Requirements\n> +\n> +FIXME: similar to update_add_htlc and update_fail_htlc.\n> +FIXME: define reasonable timeout after which you can forget if not replied?\n> +\n>\n> References\n>\n> -----------\n>\n> 1.  <a id=\"reference-1\">RFC 1950 \"ZLIB Compressed Data Format Specification version 3.3</a>\n>\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Rusty Russell",
                "date": "2020-02-21T00:03:33",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n> Good morning Rusty,\n>\n> A concern I have brought up in the past is that if this is more than just a single request-response, i.e. if this is a conversation where Alice sends to Bob, Bob sends back to Alice, Alice sends back to Bob, and so on, then if the same path is used each time Alice sends to Bob, the timing from Bob response to Alice to the next Alice sends to Bob can help an intermediate node guess how far away Alice is from itself.\n> Obviously the timing from Alice sending to Bob and Bob replying gives a hint as well as to the distance the intermediate node is to Bob already.\n>\n> It may be good to at least recommend that direct messages use different paths if they are part of a larger conversation between the two parties.\n\nThis already applies to HTLCs, no?\n\n> Would it not be better to create a circular path?\n> By this I mean, Alice constructs an onion that overall creates a path from herself to Bob and back, ensuring different nodes on the forward and return directions.\n> The onion hop at Bob reveals that Bob is the chosen conversation partner, and Bob forwards its reply via the onion return path (that Alice prepared herself to get back to her via another path).\n\nI like it!  The lack of \"reply\" function eliminates all storage\nrequirements for the intermediaries.  Unfortunately it's not currently\npossible to fit the reply onion inside the existing onion, but I know\nChristian has a rabbit in his hat for this?\n\n> After Alice receives the first message from Bob the circular \"circuit\" is established and they can continue to communicate using the same circuit: timing attacks are now \"impossible\" since Alice and Bob can be anywhere along the circle, even if two of the nodes in the circuit are surveillors cooperating with each other, the timing information they get is the distance between the surveillor nodes.\n>\n> Of course, if a node in the circular path drops the circuit is disrupted, so any higher-level protocols on top of that should probably be willing to resume the conversation on another circular circuit.\n\nMy immediate purpose for this is for \"offers\" which cause a invoice\nrequest, followed by an invoice reply.  This will probably be reused\nonce for the payment itself.  2 uses is not sufficient to justify\nsetting up a circuit, AFAICT.\n\n> I believe I even tied this to an HTLC in an attempt to provide a\n> spam-limit as well:\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-November/002294.html\n\nThis part was deeply unclear.  Eventually we will have to charge\nup-front for forwarding HTLCs (say 5% of existing fee, plus 1msat), and\nthen we could use the same scheme with lesser amounts (say, 1msat) for\nforwarding messages.\n\nBut I have been unable to come up with an upfront scheme which doesn't\nleak information badly.\n\nThe best I can do is some hashcash scheme, combined with the ability to\nbuy a single-use token to weaken it.  Under load, a node would raise\ntheir hashcash difficulty, and you could either find another route,\ngrind your onion more to meet it, or send a payment for a token from\nthat node which would let your HTLC through: the preimage could even be\nthe XOR of some secret you send with the HTLC, and a shachain key which\ngives you 1000 tokens, and you can use them in order, etc.\n\n(Really want to use some kind of Chaumian token here, but it's probably\noverkill).\n\n> Finally: what does this improve over, say, requiring that all\n> Lightning nodes have a Tor .onion address and just doing direct\n> messaging over Tor?\n\nThat would be far better!  But that's not happening: lnurl over https is\nhappening.  Using lightning to tunnel messages is a strict improvement\nover that, at least.\n\nCheers!\nRusty."
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-21T08:45:34",
                "message_text_only": "Good morning Rusty,\n\n> > Would it not be better to create a circular path?\n> > By this I mean, Alice constructs an onion that overall creates a path from herself to Bob and back, ensuring different nodes on the forward and return directions.\n> > The onion hop at Bob reveals that Bob is the chosen conversation partner, and Bob forwards its reply via the onion return path (that Alice prepared herself to get back to her via another path).\n>\n> I like it! The lack of \"reply\" function eliminates all storage\n> requirements for the intermediaries. Unfortunately it's not currently\n> possible to fit the reply onion inside the existing onion, but I know\n> Christian has a rabbit in his hat for this?\n\nWhy not the same onion-in-an-onion we use in trampoline?\nWe could probably optimize this a little since we do not need to send data like outgoing amounts and timelocks and stuff but basically the same construction seems to work?\n\nWithout the ability to send messages in the reverse direction, a failure would be silent.\nIn particular, if I send out a direct message and then not get a response after a while, I might be tempted to send out another direct message over a different path.\nThen whatever was stuck gets unstuck and the recipient gets two messages (and I might get two responses back after a while).\nThis implies that any higher-level protocol built on this must treat this like a UDP request-response: unreliable delivery, possible multiple copies of the same message getting received, probably have to send multiple copies for reliable delivery, etc.\nIn particular, requests that change the world must be idempotent.\n\nBut I suppose that also applies for your original formulation as well.\n\n>\n> > After Alice receives the first message from Bob the circular \"circuit\" is established and they can continue to communicate using the same circuit: timing attacks are now \"impossible\" since Alice and Bob can be anywhere along the circle, even if two of the nodes in the circuit are surveillors cooperating with each other, the timing information they get is the distance between the surveillor nodes.\n> > Of course, if a node in the circular path drops the circuit is disrupted, so any higher-level protocols on top of that should probably be willing to resume the conversation on another circular circuit.\n>\n> My immediate purpose for this is for \"offers\" which cause a invoice\n> request, followed by an invoice reply. This will probably be reused\n> once for the payment itself. 2 uses is not sufficient to justify\n> setting up a circuit, AFAICT.\n>\n> > I believe I even tied this to an HTLC in an attempt to provide a\n> > spam-limit as well:\n> > https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-November/002294.html\n>\n> This part was deeply unclear. Eventually we will have to charge\n> up-front for forwarding HTLCs (say 5% of existing fee, plus 1msat), and\n> then we could use the same scheme with lesser amounts (say, 1msat) for\n> forwarding messages.\n\nApparently, since nobody replied to it.\n\n>\n> But I have been unable to come up with an upfront scheme which doesn't\n> leak information badly.\n>\n> The best I can do is some hashcash scheme, combined with the ability to\n> buy a single-use token to weaken it. Under load, a node would raise\n> their hashcash difficulty, and you could either find another route,\n> grind your onion more to meet it, or send a payment for a token from\n> that node which would let your HTLC through: the preimage could even be\n> the XOR of some secret you send with the HTLC, and a shachain key which\n> gives you 1000 tokens, and you can use them in order, etc.\n\nIn principle any use of hashcash can be replaced with a spend of Bitcoin, hmmm.\n\n>\n> (Really want to use some kind of Chaumian token here, but it's probably\n> overkill).\n\nNo, Chaumian tokens are cool, we should totally add it for nerd points.\n\nBut I mean: if it works better that way, why not?\nImplementation complexity I suppose?\nwaxwing showed a PoDLE-based Chaumian token protocol which, at least to my naive eyes, is not susceptible to Wagnerian attack the way blind Schnorr signatures are, so it seems to be something we can use as a way to issue tokens in a manner very much like Chaumian banks do.\nThough it does require getting the reciprocal of a scalar, an operation which is not exposed in secp256k1.h for some reason.\nhttps://privacypass.github.io/protocol\n\n>\n> > Finally: what does this improve over, say, requiring that all\n> > Lightning nodes have a Tor .onion address and just doing direct\n> > messaging over Tor?\n>\n> That would be far better! But that's not happening: lnurl over https is\n> happening. Using lightning to tunnel messages is a strict improvement\n> over that, at least.\n\n....\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Christian Decker",
                "date": "2020-02-21T21:22:41",
                "message_text_only": "Rusty Russell <rusty at rustcorp.com.au> writes:\n\n>> Would it not be better to create a circular path?  By this I mean,\n>> Alice constructs an onion that overall creates a path from herself to\n>> Bob and back, ensuring different nodes on the forward and return\n>> directions.  The onion hop at Bob reveals that Bob is the chosen\n>> conversation partner, and Bob forwards its reply via the onion return\n>> path (that Alice prepared herself to get back to her via another\n>> path).\n>\n> I like it!  The lack of \"reply\" function eliminates all storage\n> requirements for the intermediaries.  Unfortunately it's not currently\n> possible to fit the reply onion inside the existing onion, but I know\n> Christian has a rabbit in his hat for this?\n\nI think circular payment really means an onion that is\n\n> A -> ... -> B -> ... -> A\n\nand not a reply onion inside of a forward onion.\n\nThe problem with the circular path is that the \"recipient\" cannot add\nany reply without invalidating the HMACs on the return leg of the\nonion. The onion is fully predetermined by the sender, any malleability\nintroduced in order to allow the recipient to reply poses a threat to\nthe integrity of the onion routing, e.g., it opens us up to probing by\nfiddling with parts of the onion until the attacker identifies the\nlocation the recipient is supposed to put his reply into.\n\nAs Rusty mentioned I have a construction of the onion routing packet\nthat allows us to compress it in such a way that it fits inside of the\npayload itself. I'll write up a complete proposal over the coming days,\nbut the basic idea is to initialize the unused part of the onion in such\na way that it cancels out the layers of encryption and the fully wrapped\nonion consists of all `0x00` bytes. These can then be removed resulting\nin a compressed onion, and the sender can simply add the padding 0x00\nbytes back to get the original, fully HMACd onion, and then send it like\nnormal (there is an obfuscation step to hide the `0x00` bytes from the\nnext hop, but more on this in the full rendez-vous proposal later).\n\nThis rendez-vous construction is a bit more involved since we want to\nfit an onion into another onion of the same size. If we design a\ncompletely new messaging system, requiring end-to-end communication, it\nmight be worth re-introducing the end-to-end payload which we removed in\nthe routing onion. It's a simply, variable or fixed length, payload,\nthat is onion-decrypted at each hop and its contents are revealed to the\ndestination (this is how onion routing usually works). Since that\npayload doesn't have to adhere to the constraints of the routing onions\n(multiple payloads, one for each hop, and no special larger payload\ndestined for the final recipient) this is both simpler, and would allow\nus to store a full, unmodified, return-onion in the end-to-end payload.\n\nAnother advantage is that the end-to-end payload is not covered by the\nHMACs in the header, meaning that the recipient can construct a reply\nwithout having to modify (and invalidate) the routing onion. I guess\nthis is going back to the roots of the Sphinx paper :-)\n\n\nMight be worth a consideration, as it seems to me like it'd be simpler\n:-) The downside of course is that we'd end up with two different onion\nconstructions for different use-cases.\n\n\n>> After Alice receives the first message from Bob the circular\n>> \"circuit\" is established and they can continue to communicate using\n>> the same circuit: timing attacks are now \"impossible\" since Alice and\n>> Bob can be anywhere along the circle, even if two of the nodes in the\n>> circuit are surveillors cooperating with each other, the timing\n>> information they get is the distance between the surveillor nodes.\n>>\n>> Of course, if a node in the circular path drops the circuit is\n>> disrupted, so any higher-level protocols on top of that should\n>> probably be willing to resume the conversation on another circular\n>> circuit.\n>\n> My immediate purpose for this is for \"offers\" which cause a invoice\n> request, followed by an invoice reply.  This will probably be reused\n> once for the payment itself.  2 uses is not sufficient to justify\n> setting up a circuit, AFAICT.\n\nI know someone who is itching to implement hornet for these use-cases\n;-)\n\nCheers,\nChristian"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-23T23:21:23",
                "message_text_only": "Good morning Christian, and Rusty,\n\n> > > Would it not be better to create a circular path? By this I mean,\n> > > Alice constructs an onion that overall creates a path from herself to\n> > > Bob and back, ensuring different nodes on the forward and return\n> > > directions. The onion hop at Bob reveals that Bob is the chosen\n> > > conversation partner, and Bob forwards its reply via the onion return\n> > > path (that Alice prepared herself to get back to her via another\n> > > path).\n> >\n> > I like it! The lack of \"reply\" function eliminates all storage\n> > requirements for the intermediaries. Unfortunately it's not currently\n> > possible to fit the reply onion inside the existing onion, but I know\n> > Christian has a rabbit in his hat for this?\n>\n> I think circular payment really means an onion that is\n>\n> > A -> ... -> B -> ... -> A\n>\n> and not a reply onion inside of a forward onion.\n>\n> The problem with the circular path is that the \"recipient\" cannot add\n> any reply without invalidating the HMACs on the return leg of the\n> onion. The onion is fully predetermined by the sender, any malleability\n> introduced in order to allow the recipient to reply poses a threat to\n> the integrity of the onion routing, e.g., it opens us up to probing by\n> fiddling with parts of the onion until the attacker identifies the\n> location the recipient is supposed to put his reply into.\n\nAt the risk of constructing a novel cryptosystem, I think we can separate the request/response from the onion.\nWe effectively treat the onion as establishing a *non*-encrypted temporary tunnel, and add an asymmetric encryption between Alice and Bob for the request and response.\n\nThe onion is kept as-is (except without information about HTLC amounts and timelocks).\nWe add a field *uotside* the onion which contains the request/response.\nAt each hop, we derive a key from the shared secret between the ephemeral keypair and the hop keypair, and use the derived key to generate a symmetric stream cipher to encrypt the separated request/response.\n\nAlice first creates a *separate* ephemeral key just for communication with Bob.\nIt encrypts the request using this level 2 ephemeral key and adds a MAC tag as well, and treat the encrypted request plus the MAC tag as a binary blob.\nThen, for each hop, it derives the symmetric stream cipher using the onion (level 1) ephemeral key with that hop and applies the stream cipher on it.\nThen it sends out the completed onion plus this encrypted request/response blob.\n\nEach hop effectively peels a layer of encryption, because it is a symmetric stream cipher.\nOn reaching Bob, the encrypted request/response message plus MAC tag is revealed to Bob.\nBob learns it is the true destination by some TLV in the onion part, including the (level 2) ephemeral key, then validates the MAC using the Alice and Bob shared secret and if it is valid, decrypts the request part and processes the request.\n\nBob then generates its reply, and encrypts the reply with the shared secret between its static key and the level 2 ephemeral key, then creates a MAC using the level 2 ephemeral key and its static key.\nThen it sends it together with the rest of the onion onward.\n\nEach hop after Bob effectively adds a layer of encryption, because it is a symmetric stream cipher.\nOn reaching Alice, Alice (who knows the entire route, since it was the one who established the route) can peel every layer between Bob and Alice on the return route.\nThen it should get the binary blob that is the (level 2) encryption of the reply plus a MAC, validates the MAC, then decrypts the reply.\n\nWe treat the tunnel as unencrypted (i.e. we have a level 2 asymmetric encryption between Alice and Bob) because the request/response is outside the onion.\nWe still bother to do a multilayer encryption so that, in case of a route like A->I->J->K->L->B, where I and L are controlled by the same surveillor, the request/response is different at each hop and I and L cannot be certain they are on the same route (though of course timing and message size can improve their accuracy --- we can have a fixed size for the request/response to hide message size, but we can do nothing about timing).\n\nMy *vague* understanding is that HORNET is effectively a better version of this --- it uses a \"full\" onion to establish a circuit, then uses simpler symmetric ciphers during circuit operation.\nThis effectively tears down the circuit as soon as the message passes through.\n\n\n>\n> As Rusty mentioned I have a construction of the onion routing packet\n> that allows us to compress it in such a way that it fits inside of the\n> payload itself. I'll write up a complete proposal over the coming days,\n> but the basic idea is to initialize the unused part of the onion in such\n> a way that it cancels out the layers of encryption and the fully wrapped\n> onion consists of all `0x00` bytes. These can then be removed resulting\n> in a compressed onion, and the sender can simply add the padding 0x00\n> bytes back to get the original, fully HMACd onion, and then send it like\n> normal (there is an obfuscation step to hide the `0x00` bytes from the\n> next hop, but more on this in the full rendez-vous proposal later).\n>\n> This rendez-vous construction is a bit more involved since we want to\n> fit an onion into another onion of the same size. If we design a\n> completely new messaging system, requiring end-to-end communication, it\n> might be worth re-introducing the end-to-end payload which we removed in\n> the routing onion. It's a simply, variable or fixed length, payload,\n> that is onion-decrypted at each hop and its contents are revealed to the\n> destination (this is how onion routing usually works). Since that\n> payload doesn't have to adhere to the constraints of the routing onions\n> (multiple payloads, one for each hop, and no special larger payload\n> destined for the final recipient) this is both simpler, and would allow\n> us to store a full, unmodified, return-onion in the end-to-end payload.\n>\n> Another advantage is that the end-to-end payload is not covered by the\n> HMACs in the header, meaning that the recipient can construct a reply\n> without having to modify (and invalidate) the routing onion. I guess\n> this is going back to the roots of the Sphinx paper :-)\n\nHmmm okay..... is this basically what I just described above?\n\n\n\n>\n> Might be worth a consideration, as it seems to me like it'd be simpler\n> :-) The downside of course is that we'd end up with two different onion\n> constructions for different use-cases.\n\n\"Use the best tool for the job\"?\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Rusty Russell",
                "date": "2020-02-24T03:15:58",
                "message_text_only": "Christian Decker <decker.christian at gmail.com> writes:\n> Rusty Russell <rusty at rustcorp.com.au> writes:\n>\n>> I like it!  The lack of \"reply\" function eliminates all storage\n>> requirements for the intermediaries.  Unfortunately it's not currently\n>> possible to fit the reply onion inside the existing onion, but I know\n>> Christian has a rabbit in his hat for this?\n>\n> I think circular payment really means an onion that is\n>\n>> A -> ... -> B -> ... -> A\n>\n> and not a reply onion inside of a forward onion.\n>\n> The problem with the circular path is that the \"recipient\" cannot add\n> any reply without invalidating the HMACs on the return leg of the\n> onion. The onion is fully predetermined by the sender, any malleability\n> introduced in order to allow the recipient to reply poses a threat to\n> the integrity of the onion routing, e.g., it opens us up to probing by\n> fiddling with parts of the onion until the attacker identifies the\n> location the recipient is supposed to put his reply into.\n>\n> As Rusty mentioned I have a construction of the onion routing packet\n> that allows us to compress it in such a way that it fits inside of the\n> payload itself.\n\nI think this has the same problem though, that there's no way Alice can\nsend Bob an onion to use with an arbitrary message?\n\n> Another advantage is that the end-to-end payload is not covered by the\n> HMACs in the header, meaning that the recipient can construct a reply\n> without having to modify (and invalidate) the routing onion. I guess\n> this is going back to the roots of the Sphinx paper :-)\n\nGood point, and it's trivial.  The paper suggests the payload be \"final\nkey\" followed by the desired data, providing a simple validation scheme.\n\nWe could potentially generalize the HTLC messages like this, but it's\nunnecessary at this point.\n\nThanks,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Direct Message draft",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Christian Decker",
                "Ren\u00e9 Pickhardt",
                "ZmnSCPxj"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 45268
        }
    },
    {
        "title": "[Lightning-dev] Sphinx Rendezvous Update",
        "thread_messages": [
            {
                "author": "Bastien TEINTURIER",
                "date": "2020-02-24T09:33:33",
                "message_text_only": "Good morning list,\n\nAfter exploring decoys [1], which is a cheap way of doing route blinding,\nI'm turning back to exploring rendezvous.\nThe previous mails on the mailing list mentioned that there was a\ntechnicality\nto make the HMACs check out, but didn't provide a lot of details.\nThe issue is that the filler generation needs to take into account some hops\nthat will be added *later*, by the payer.\n\nHowever it is quite easy to work-around, with a few space trade-offs.\nLet's consider a typical rendezvous setup, where Alice wants to be paid via\nrendezvous Bob, and Carol wants to pay that invoice:\n\nCarol -> ... -> Bob -> ... -> Alice\n\nIf Alice knows how many bytes Carol is going to use for her part of the\nonion\npayloads, Alice can easily take them into account when generating her\nfiller by\npre-pending the same amount of `0` bytes. It seems reasonable to impose a\nfixed\nnumber of onion bytes for each side of the rendezvous (650 each?) so Alice\nwould\nknow that amount.\n\nWhen Carol completes the onion with her part of the route, she simply needs\nto\ngenerate filler data for her part of the route following the normal Sphinx\nprotocol\nand apply it to the onion she found in the invoice.\n\nBut the tricky part is that she needs to give Bob a way of generating the\nsame\nfiller data to unapply it. Then all HMACs correctly check out.\n\nI see two ways of doing that:\n\n* Carol simply sends that filler (650 bytes), probably via a TLV in\n`update_add_htlc`.\nThis means every intermediate hop needs to forward that, which is painful\nand\npotentially leaking too much data.\n* Carol provides Bob with the rho keys used to generate her filler, and the\nlength\nused by each hop. This leaks to Bob an upper bound on the number of hops\nand the\nnumber of bytes sent to each hop.\n\nSince shift-and-xor kind of crypto is hard to read as equations, but very\neasy to\nread as diagrams, I spent a bit of time doing beautiful ASCII art [2].\nDon't hesitate\nto have a look at it to find more details about how that works. You can\nalso print\nthat on t-shirts to look fancy at conferences. I also have some sample code\nworking\nin eclair [3] for those who can read Scala without getting headaches.\n\nAre there other tricks we can use to reconcile both sides of the onion at\nBob's?\nMaybe cdecker (or someone else) has an ace up his sleeve for me there? :)\n\nOne important thing to note is that rendezvous on normal onions will be\ncostly to\nintegrate into invoices: it takes 1366 bytes to include one onion, and if\nwe want\nto handle route failures or let the sender use multi-part, we will need to\nhave a\nhandful of pre-encrypted onions in the invoice (hence a few kB, which may\nnot be\npractical for QR codes).\n\nBut I did mention before that doing rendezvous on the trampoline onion\ncould have\nbetter properties [4]. When doing that, having Carol transmit her filler\ndata only\nto Bob, via the outer onion payload becomes practical and doesn't leak\ninformation.\nMulti-part would work with a single trampoline onion in the invoice (~500\nbytes),\nbecause nodes can do MPP between trampoline nodes thanks to the\nonion-in-onion\nconstruction. We simply need to decide the size of the trampoline onion to\nallow\neach side of the rendezvous to be able to insert a number of hops we're\ncomfortable\nwith. You can find more details in the \"Rendezvous on a trampoline\" section\nof [2].\n\nI'm really interested in other approaches to making rendezvous work with\nthe HMACs\ncorrectly checking out. If people on this list have drafts, intuitions or\nrandom\nthoughts about possible constructions, please share them, I'd be happy to\ndive into\nthem to explore alternatives to the one I found, hoping we can make this\nwork and\nprovide this feature to our users in the near future.\n\nA small side-note on Hornet. Hornet does offer many features that I believe\nwe will\nwant in Lightning in the future. It may seem that doing a custom rendezvous\nscheme\nis a waste of time since we'll ditch it once/if we implement Hornet. While\nthat is\ntrue in the long run, I believe that if we're able to find a rendezvous\nscheme that\nisn't too much work to implement, it makes sense to have something\navailable soon-ish.\nHornet will likely be a longer-term effort that we won't get as soon as\nwe'd like\n(especially since it will probably require a network-wide update). But who\nknows, maybe\nwe may see that we are trying to create many features that are already\nbuilt into Hornet\n(rendezvous, directed message support, etc) and will decide to implement\nHornet sooner\nthan expected?\n\nCheers,\nBastien\n\n[1]\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2020-January/002435.html\n[2] https://gist.github.com/t-bast/ab42a7f52eb2e73105557957c8359601\n[3] https://github.com/ACINQ/eclair/tree/sphinx-rendezvous\n[4]\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2019-October/002237.html\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200224/02d2cd82/attachment-0001.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2020-02-24T18:22:08",
                "message_text_only": "Hi Bastien,\n\nseems you were a bit quicker than I was with my writeup of my\nproposal. I came up with a scheme that allows us to drop a large part of\nthe partial onion, so that it can indeed fit into an outer onion, and\nthe rendez-vous node RV can re-construct the original packet from the\nincluded data [1].\n\nThe construction comes down to initializing the part of the routing info\nstring that is not going to be used, in such a way that the incremental\nunwrappings at the nodes in the partial onion cancels out. Like you\nmentioned in your mail it comes down extending the filler generation to\nalso cover the unused part and then applying all the encryption streams\nxored to the unused space. By doing this we get the middle part of the\nonion consisting of only 0x00 bytes.\n\nI then decided to apply an additional ChaCha20 stream to this prefill,\nsuch that the onion will not consist of mostly 0x00 bytes which would be\na dead giveaway to `RV+1` that `RV` was a rendez-vous node.\n\nThe process for the partial onion creator boils down to:\n\n - Compute a path from `RV` of its choice to recipient `R`.\n - Compute a shared secret using a random ephemeral private key and\n  `RV`s public key, and then generate a prefill-key\n - Compute the prefill by combining the correct substrings of the\n   encryption streams for the nodes along the path, then add the\n   ChaCha20 stream keyed with the prefill-key.\n - Wrap the onion, including payloads for each of the nodes along path\n   `RV` to `R`\n - Trim out the unused space, which now will match the obfuscation\n   stream generated with the prefill-key\n\nAs an example such an onion, with 5 legacy hops (65 byte each) results\nin a 325 + 66 bytes onion, and we save 975 bytes. See [2] for an example\nof how this looks like.\n\nThe sender `S` then just does the following:\n\n - Compute a route from `S` to `RV`\n - Build an onion with the route, specifying the trimmed partial onion\n   as payload, along with the usual parameters, for `RV`\n - Initiate payment with the constructed onion\n\nUpon receiving an incoming HTLC with a partial onion the rendez-vous\nnode `RV` then just does the following:\n\n - Verify all parameters as usual\n - Extract the partial onion\n - Use the ephemeral key from the partial onion to generate the shared\n   secret and the prefill key\n - Generate the prefill stream and insert it in the correct place,\n   before the HMAC. This reconstitutes the original routing packet\n - Swap out the original onion with the reconstituted onion and forward.\n\nMy writeup [1] is an early draft, but I wanted to get it out early to\ngive the discussion a basis to work off. I'll revisit it a couple of\ntimes before opening a PR, but feel free to shout at me if I have\nforgotten to consider something :-)\n\nCheers,\nChristian\n\n[1] https://github.com/lightningnetwork/lightning-rfc/blob/rendez-vous/proposals/0001-rendez-vous.md\n[2] https://gist.github.com/cdecker/ec06452bc470749d9f6d2de73651c5fd\n\nBastien TEINTURIER via Lightning-dev\n<lightning-dev at lists.linuxfoundation.org> writes:\n> Good morning list,\n>\n> After exploring decoys [1], which is a cheap way of doing route blinding,\n> I'm turning back to exploring rendezvous.\n> The previous mails on the mailing list mentioned that there was a\n> technicality\n> to make the HMACs check out, but didn't provide a lot of details.\n> The issue is that the filler generation needs to take into account some hops\n> that will be added *later*, by the payer.\n>\n> However it is quite easy to work-around, with a few space trade-offs.\n> Let's consider a typical rendezvous setup, where Alice wants to be paid via\n> rendezvous Bob, and Carol wants to pay that invoice:\n>\n> Carol -> ... -> Bob -> ... -> Alice\n>\n> If Alice knows how many bytes Carol is going to use for her part of the\n> onion\n> payloads, Alice can easily take them into account when generating her\n> filler by\n> pre-pending the same amount of `0` bytes. It seems reasonable to impose a\n> fixed\n> number of onion bytes for each side of the rendezvous (650 each?) so Alice\n> would\n> know that amount.\n>\n> When Carol completes the onion with her part of the route, she simply needs\n> to\n> generate filler data for her part of the route following the normal Sphinx\n> protocol\n> and apply it to the onion she found in the invoice.\n>\n> But the tricky part is that she needs to give Bob a way of generating the\n> same\n> filler data to unapply it. Then all HMACs correctly check out.\n>\n> I see two ways of doing that:\n>\n> * Carol simply sends that filler (650 bytes), probably via a TLV in\n> `update_add_htlc`.\n> This means every intermediate hop needs to forward that, which is painful\n> and\n> potentially leaking too much data.\n> * Carol provides Bob with the rho keys used to generate her filler, and the\n> length\n> used by each hop. This leaks to Bob an upper bound on the number of hops\n> and the\n> number of bytes sent to each hop.\n>\n> Since shift-and-xor kind of crypto is hard to read as equations, but very\n> easy to\n> read as diagrams, I spent a bit of time doing beautiful ASCII art [2].\n> Don't hesitate\n> to have a look at it to find more details about how that works. You can\n> also print\n> that on t-shirts to look fancy at conferences. I also have some sample code\n> working\n> in eclair [3] for those who can read Scala without getting headaches.\n>\n> Are there other tricks we can use to reconcile both sides of the onion at\n> Bob's?\n> Maybe cdecker (or someone else) has an ace up his sleeve for me there? :)\n>\n> One important thing to note is that rendezvous on normal onions will be\n> costly to\n> integrate into invoices: it takes 1366 bytes to include one onion, and if\n> we want\n> to handle route failures or let the sender use multi-part, we will need to\n> have a\n> handful of pre-encrypted onions in the invoice (hence a few kB, which may\n> not be\n> practical for QR codes).\n>\n> But I did mention before that doing rendezvous on the trampoline onion\n> could have\n> better properties [4]. When doing that, having Carol transmit her filler\n> data only\n> to Bob, via the outer onion payload becomes practical and doesn't leak\n> information.\n> Multi-part would work with a single trampoline onion in the invoice (~500\n> bytes),\n> because nodes can do MPP between trampoline nodes thanks to the\n> onion-in-onion\n> construction. We simply need to decide the size of the trampoline onion to\n> allow\n> each side of the rendezvous to be able to insert a number of hops we're\n> comfortable\n> with. You can find more details in the \"Rendezvous on a trampoline\" section\n> of [2].\n>\n> I'm really interested in other approaches to making rendezvous work with\n> the HMACs\n> correctly checking out. If people on this list have drafts, intuitions or\n> random\n> thoughts about possible constructions, please share them, I'd be happy to\n> dive into\n> them to explore alternatives to the one I found, hoping we can make this\n> work and\n> provide this feature to our users in the near future.\n>\n> A small side-note on Hornet. Hornet does offer many features that I believe\n> we will\n> want in Lightning in the future. It may seem that doing a custom rendezvous\n> scheme\n> is a waste of time since we'll ditch it once/if we implement Hornet. While\n> that is\n> true in the long run, I believe that if we're able to find a rendezvous\n> scheme that\n> isn't too much work to implement, it makes sense to have something\n> available soon-ish.\n> Hornet will likely be a longer-term effort that we won't get as soon as\n> we'd like\n> (especially since it will probably require a network-wide update). But who\n> knows, maybe\n> we may see that we are trying to create many features that are already\n> built into Hornet\n> (rendezvous, directed message support, etc) and will decide to implement\n> Hornet sooner\n> than expected?\n>\n> Cheers,\n> Bastien\n>\n> [1]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-January/002435.html\n> [2] https://gist.github.com/t-bast/ab42a7f52eb2e73105557957c8359601\n> [3] https://github.com/ACINQ/eclair/tree/sphinx-rendezvous\n> [4]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-October/002237.html\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev"
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2020-02-25T16:24:29",
                "message_text_only": "Hi Christian,\n\nThis is great, thanks for sharing!\nWhat's really nice with your proposal is that there is effectively no onion\npayload for `RV` in the partial onion, which frees up more space than mine.\n\nI believe this makes it quite usable in Bolt 11 invoices, without blowing up\nthe size of the QR code (but more experimentation is needed on that).\n\nAs an example such an onion, with 5 legacy hops (65 byte each) results\n> in a 325 + 66 bytes onion, and we save 975 bytes.\n\n\nWhile having flexibility when choosing the length of the prefill stream\nfeels nice,\nwouldn't it be safer to impose a fixed size to avoid any kind of heuristic\nat `RV`\nto try to guess how many hops there are between him and the recipient?\n\nCompute a shared secret using a random ephemeral private key and\n> `RV`s public key, and then generate a prefill-key\n\n\nWhile implementing, I felt that the part about the shared secret used to\ngenerate\nthe prefill stream is a bit blurry (your proposal on Github doesn't phrase\nit the\nsame way). I think it's important to stress that this secret is derived\nfrom both\n`ephkey` and `RV`'s private key, so that `RV+1` can't compute the same\nstream.\n\nAnother thing that may be worth mentioning is error forwarding. Since the\nrecipient generated the onion, `RV` won't have the shared secrets (that's by\ndesign). So it's expected that payment errors won't be readable by `RV`, but\nit's probably a good idea if `RV` returns an indication to the sender that\nthe\npayment failed *after* the rendezvous point.\n\nAn important side-note is that your proposal is really quick and simple to\nimplement\nfrom the existing Sphinx code. I have made ASCII diagrams of the scheme\n(see [1]).\nThis may help readers visualize it more easily.\n\nIt still has the issue that each hop's amount/cltv is fixed at invoice\ngeneration\ntime by the recipient. That means MPP cannot be used, and if any channel\nalong the\npath updates their fee the partial onion becomes invalid (unless you\noverpay the fees).\n\nTrampoline should be able to address that since it provides more freedom to\neach\ntrampoline node to find an efficient way to forward to the next trampoline.\nIt's not yet obvious to me how I can mix these two proposals to make it\nwork though.\nI'll spend more time experimenting with that.\n\nThanks,\nBastien\n\n[1]\nhttps://gist.github.com/t-bast/ab42a7f52eb2e73105557957c8359601#Christian\n\nLe lun. 24 f\u00e9vr. 2020 \u00e0 19:22, Christian Decker <decker.christian at gmail.com>\na \u00e9crit :\n\n> Hi Bastien,\n>\n> seems you were a bit quicker than I was with my writeup of my\n> proposal. I came up with a scheme that allows us to drop a large part of\n> the partial onion, so that it can indeed fit into an outer onion, and\n> the rendez-vous node RV can re-construct the original packet from the\n> included data [1].\n>\n> The construction comes down to initializing the part of the routing info\n> string that is not going to be used, in such a way that the incremental\n> unwrappings at the nodes in the partial onion cancels out. Like you\n> mentioned in your mail it comes down extending the filler generation to\n> also cover the unused part and then applying all the encryption streams\n> xored to the unused space. By doing this we get the middle part of the\n> onion consisting of only 0x00 bytes.\n>\n> I then decided to apply an additional ChaCha20 stream to this prefill,\n> such that the onion will not consist of mostly 0x00 bytes which would be\n> a dead giveaway to `RV+1` that `RV` was a rendez-vous node.\n>\n> The process for the partial onion creator boils down to:\n>\n>  - Compute a path from `RV` of its choice to recipient `R`.\n>  - Compute a shared secret using a random ephemeral private key and\n>   `RV`s public key, and then generate a prefill-key\n>  - Compute the prefill by combining the correct substrings of the\n>    encryption streams for the nodes along the path, then add the\n>    ChaCha20 stream keyed with the prefill-key.\n>  - Wrap the onion, including payloads for each of the nodes along path\n>    `RV` to `R`\n>  - Trim out the unused space, which now will match the obfuscation\n>    stream generated with the prefill-key\n>\n> As an example such an onion, with 5 legacy hops (65 byte each) results\n> in a 325 + 66 bytes onion, and we save 975 bytes. See [2] for an example\n> of how this looks like.\n>\n> The sender `S` then just does the following:\n>\n>  - Compute a route from `S` to `RV`\n>  - Build an onion with the route, specifying the trimmed partial onion\n>    as payload, along with the usual parameters, for `RV`\n>  - Initiate payment with the constructed onion\n>\n> Upon receiving an incoming HTLC with a partial onion the rendez-vous\n> node `RV` then just does the following:\n>\n>  - Verify all parameters as usual\n>  - Extract the partial onion\n>  - Use the ephemeral key from the partial onion to generate the shared\n>    secret and the prefill key\n>  - Generate the prefill stream and insert it in the correct place,\n>    before the HMAC. This reconstitutes the original routing packet\n>  - Swap out the original onion with the reconstituted onion and forward.\n>\n> My writeup [1] is an early draft, but I wanted to get it out early to\n> give the discussion a basis to work off. I'll revisit it a couple of\n> times before opening a PR, but feel free to shout at me if I have\n> forgotten to consider something :-)\n>\n> Cheers,\n> Christian\n>\n> [1]\n> https://github.com/lightningnetwork/lightning-rfc/blob/rendez-vous/proposals/0001-rendez-vous.md\n> [2] https://gist.github.com/cdecker/ec06452bc470749d9f6d2de73651c5fd\n>\n> Bastien TEINTURIER via Lightning-dev\n> <lightning-dev at lists.linuxfoundation.org> writes:\n> > Good morning list,\n> >\n> > After exploring decoys [1], which is a cheap way of doing route blinding,\n> > I'm turning back to exploring rendezvous.\n> > The previous mails on the mailing list mentioned that there was a\n> > technicality\n> > to make the HMACs check out, but didn't provide a lot of details.\n> > The issue is that the filler generation needs to take into account some\n> hops\n> > that will be added *later*, by the payer.\n> >\n> > However it is quite easy to work-around, with a few space trade-offs.\n> > Let's consider a typical rendezvous setup, where Alice wants to be paid\n> via\n> > rendezvous Bob, and Carol wants to pay that invoice:\n> >\n> > Carol -> ... -> Bob -> ... -> Alice\n> >\n> > If Alice knows how many bytes Carol is going to use for her part of the\n> > onion\n> > payloads, Alice can easily take them into account when generating her\n> > filler by\n> > pre-pending the same amount of `0` bytes. It seems reasonable to impose a\n> > fixed\n> > number of onion bytes for each side of the rendezvous (650 each?) so\n> Alice\n> > would\n> > know that amount.\n> >\n> > When Carol completes the onion with her part of the route, she simply\n> needs\n> > to\n> > generate filler data for her part of the route following the normal\n> Sphinx\n> > protocol\n> > and apply it to the onion she found in the invoice.\n> >\n> > But the tricky part is that she needs to give Bob a way of generating the\n> > same\n> > filler data to unapply it. Then all HMACs correctly check out.\n> >\n> > I see two ways of doing that:\n> >\n> > * Carol simply sends that filler (650 bytes), probably via a TLV in\n> > `update_add_htlc`.\n> > This means every intermediate hop needs to forward that, which is painful\n> > and\n> > potentially leaking too much data.\n> > * Carol provides Bob with the rho keys used to generate her filler, and\n> the\n> > length\n> > used by each hop. This leaks to Bob an upper bound on the number of hops\n> > and the\n> > number of bytes sent to each hop.\n> >\n> > Since shift-and-xor kind of crypto is hard to read as equations, but very\n> > easy to\n> > read as diagrams, I spent a bit of time doing beautiful ASCII art [2].\n> > Don't hesitate\n> > to have a look at it to find more details about how that works. You can\n> > also print\n> > that on t-shirts to look fancy at conferences. I also have some sample\n> code\n> > working\n> > in eclair [3] for those who can read Scala without getting headaches.\n> >\n> > Are there other tricks we can use to reconcile both sides of the onion at\n> > Bob's?\n> > Maybe cdecker (or someone else) has an ace up his sleeve for me there? :)\n> >\n> > One important thing to note is that rendezvous on normal onions will be\n> > costly to\n> > integrate into invoices: it takes 1366 bytes to include one onion, and if\n> > we want\n> > to handle route failures or let the sender use multi-part, we will need\n> to\n> > have a\n> > handful of pre-encrypted onions in the invoice (hence a few kB, which may\n> > not be\n> > practical for QR codes).\n> >\n> > But I did mention before that doing rendezvous on the trampoline onion\n> > could have\n> > better properties [4]. When doing that, having Carol transmit her filler\n> > data only\n> > to Bob, via the outer onion payload becomes practical and doesn't leak\n> > information.\n> > Multi-part would work with a single trampoline onion in the invoice (~500\n> > bytes),\n> > because nodes can do MPP between trampoline nodes thanks to the\n> > onion-in-onion\n> > construction. We simply need to decide the size of the trampoline onion\n> to\n> > allow\n> > each side of the rendezvous to be able to insert a number of hops we're\n> > comfortable\n> > with. You can find more details in the \"Rendezvous on a trampoline\"\n> section\n> > of [2].\n> >\n> > I'm really interested in other approaches to making rendezvous work with\n> > the HMACs\n> > correctly checking out. If people on this list have drafts, intuitions or\n> > random\n> > thoughts about possible constructions, please share them, I'd be happy to\n> > dive into\n> > them to explore alternatives to the one I found, hoping we can make this\n> > work and\n> > provide this feature to our users in the near future.\n> >\n> > A small side-note on Hornet. Hornet does offer many features that I\n> believe\n> > we will\n> > want in Lightning in the future. It may seem that doing a custom\n> rendezvous\n> > scheme\n> > is a waste of time since we'll ditch it once/if we implement Hornet.\n> While\n> > that is\n> > true in the long run, I believe that if we're able to find a rendezvous\n> > scheme that\n> > isn't too much work to implement, it makes sense to have something\n> > available soon-ish.\n> > Hornet will likely be a longer-term effort that we won't get as soon as\n> > we'd like\n> > (especially since it will probably require a network-wide update). But\n> who\n> > knows, maybe\n> > we may see that we are trying to create many features that are already\n> > built into Hornet\n> > (rendezvous, directed message support, etc) and will decide to implement\n> > Hornet sooner\n> > than expected?\n> >\n> > Cheers,\n> > Bastien\n> >\n> > [1]\n> >\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-January/002435.html\n> > [2] https://gist.github.com/t-bast/ab42a7f52eb2e73105557957c8359601\n> > [3] https://github.com/ACINQ/eclair/tree/sphinx-rendezvous\n> > [4]\n> >\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-October/002237.html\n> > _______________________________________________\n> > Lightning-dev mailing list\n> > Lightning-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200225/8301e226/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Sphinx Rendezvous Update",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Bastien TEINTURIER",
                "Christian Decker"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 24642
        }
    },
    {
        "title": "[Lightning-dev] On massive channel closing and fee bumping",
        "thread_messages": [
            {
                "author": "Gleb Naumenko",
                "date": "2020-02-26T15:32:46",
                "message_text_only": "In this email, myself (gleb) and ariard want to discuss some aspects of the LN implementations when it comes to massive channel closing.\n\nLN security model relies on the unilateral capability to timely confirm on-chain commitment transaction. Currently, fee rates of both commitment transaction and HTLC-timeout/HTLC-Success are pre-committed at signatures and can be interactively updated with a `update_fee` message. In case of mempool fee rates surge and a counterparty being adversarial or irresponsive (by being offline by occasion or under attack), this mechanism isn\u2019t reliable because a low-fee rate commitment transaction may never make it into network mempools. Switching to automatic single-party dynamic fee-bumping of *their* commitment transaction via CPFP/package relay would solve this issue, while potentially opening new attack vectors.\n\nIf dynamic fee-bumping is used by a significant fraction of LN nodes, this security measure may be exploited by a miner, a massive LN channels closing would choke the mempool, dynamic fee-bumpers would react in consequence and fee rates raise to the roof. Miners would harvest abnormal high-fees for multiple blocks.\n\nA massive channel closing may be provoked by feeding an invalid block to light clients (in the BIP157 paradigm), as they don\u2019t have utxo access, they can\u2019t verify input signatures (note: the only utxo spend they can check is the funding_output and they should do so) and lead to think than their channel is closed. This may provoke a spurious broadcast of their local commitment transaction, this one being valid and propagating on the base layer. Even if an invalid block isn\u2019t fetched, the secure strategy on what to do when your chain view is messed up by an attacker is still an open question. Note that one invalid block may be used to force-close multiple channels, making this attack more economically feasible.\n\nAnother attack building block could be to exploit any LN protocol/implementation vulnerability like a malicious HTLC-of-death which would provoke honest parties to close their mutual channel when routed through [0]\n\nLN light clients should disable HTLC routing and avoid any aggressive fee-bumping for a broadcast of local commitment transactions as time-sensitivity doesn\u2019t matter in this case beyond UX and funds stuck in-flight.\n\nBounding dynamic-fees engine may be viewed as a game-theoretic aspect between LN parties (burn the maximum in fee rate to avoid an attacker to make any profit) and macro-considerations (prevent miner to exploit the whole LN network, conservative mempool/resources usage).\n\nConsidering that most of the block reward is currently subsidized, the incentives for miners to launch this attack are questionable. However, this might change when the fraction of fees in the reward becomes higher.\nAs LN becomes an important part of the Bitcoin ecosystem, it\u2019s important to acknowledge the mining-related incentives and risks, as these may at the end be used to influence protocol development.\n\nSince the LN infrastructure seems to be moving towards the heavy use of light clients, and the attacks we mentioned are expected to appear again (at least in some of the implementations), we believe it\u2019s important to understand the mechanics of these attacks and countermeasures.\n\nIt would be interesting to have an empirical study (based on the historical data) and a simulation of the fee spikes, with parameterized:\n- how many channels are vulnerable to force-closing (based on the particular LN implementations)\n- what are the properties of those channels (amount, timelocks)\n- what is the distribution of those channels across nodes\n- how many nodes implement dynamic bumping\n- mining reward allocation\n\nWhat are your opinions on these issues?\n\n\u2013 gleb\n\n\n[0] One example with this RL issue:\n(https://github.com/rust-bitcoin/rust-lightning/pull/513)\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20200226/d529ce9f/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2020-02-28T13:00:58",
                "message_text_only": "Good morning Gleb,\n\n> In this email, myself (gleb) and ariard want to discuss some aspects of the LN implementations when it comes to massive channel closing.\n>\n> LN security model relies on the unilateral capability to timely confirm on-chain commitment transaction. Currently, fee rates of both commitment transaction and HTLC-timeout/HTLC-Success are pre-committed at signatures and can be interactively updated with a `update_fee` message. In case of mempool fee rates surge and a counterparty being adversarial or irresponsive (by being offline by occasion or under attack), this mechanism isn\u2019t reliable because a low-fee rate commitment transaction may never make it into network mempools. Switching to automatic single-party dynamic fee-bumping of *their* commitment transaction via CPFP/package relay would solve this issue, while potentially opening new attack vectors.\u00a0\n\nA concern I have been ruminating upon for a good while already is that dynamic fee-bumping violates Initiator Pays.\n\nSuppose I have a permanent LN node somewhere on the network.\nThen I trivially make up a completely-new identity and fund a channel to your node, over Tor.\nThen I transfer out as much of those funds as possible to my permanent LN node.\nAfterwards, after creating a signature from your commitment transaction, spending the `to_remote` (i.e. mine, as the commitment transaction is yours), I burn the private keys for the temporary alias and disconnect from you.\n\nThis leaves you with a channel containing a chunk of your funds in an illiquid dead-end channel and you are forced to eventually close the channel unilaterally.\n\nIt seems to me that the reserve system, plus the fact that channel-funder-pays-closing-fee, helps deter against the above attack, since I have to (1) leave a little of my money in the channel (reserve) and this is as well reduced by (2) since I am the original channel funder I am forced to pay for the closing fee on the unilateral close as well.\n\nRemoving the channel-funder-pays-closing-fee (i.e. adding dynamic pay-for-your-own-close) worries me as it seems to reduce the cost of this attack.\nThough the attack remains costly, as I still have to pay for onchain fees to establish the channel in the first place, and is the reason why I cannot find myself bringing this up otherwise.\n\n\n\nIf onchain feerates rise quickly, then you should really consider dropping the channel onchain if I am offline, so as to not have the feerate *too* obsolete.\nUnfortunately due to feerate disagreements this behavior has a lot of leeway in current implementations, as otherwise feerate changes tend to make the LN drop channels across the network, especially between different implementations (which tend to use slightly different feerate estimations / heuristics).\n\n\n>\n> If dynamic fee-bumping is used by a significant fraction of LN nodes, this security measure may be exploited by a miner, a massive LN channels closing would choke the mempool, dynamic fee-bumpers would react in consequence and fee rates raise to the roof. Miners would harvest abnormal high-fees for multiple blocks.\n\nI suggest that a node that has been online for a good amount of time, that is still connected to you and has been willing to sign fee updates, and has other published channels as well, would probably be better given some leeway and should not be dropped as easily as some unknown node with bad uptime and low liquidity.\n\n>\n> A massive channel closing may be provoked by feeding an invalid block to light clients (in the BIP157 paradigm), as they don\u2019t have utxo access, they can\u2019t verify input signatures (note: the only utxo spend they can check is the funding_output and they should do so) and lead to think than their channel is closed. This may provoke a spurious broadcast of their local commitment transaction, this one being valid and propagating on the base layer. Even if an invalid block isn\u2019t fetched, the secure strategy on what to do when your chain view is messed up by an attacker is still an open question. Note that one invalid block may be used to force-close multiple channels, making this attack more economically feasible.\n\nIf the spend of the channel funding output is valid, then the miner has to somehow have access to one or more closing transactions of that channel in order to put them in an otherwise-invalid block.\nEven if a BIP157 server lies and claims that a block at blockheight N spends your channel, you can download that block and check that it contains a transaction that does spend your channel.\nEven if the place where you downloaded that block lies, it somehow had to have access to *some* transaction that spends your channel funding output, and is a *valid* spend of that output, and if you did not broadcast that transaction yourself, it must have come from your counterparty (only the two of you working together can make a valid spend of the funding output), in which case dropping the channel onchain would be the correct behavior, whether the block itself is valid or not: if somebody released a valid spend of the channel funding output you should presume that you did not do this yourself (else you would know about it) and therefore either your counterparty wants to close, is malicious, or is compromised (or you are amnesiac....).\n\nUnless I misunderstand something?\n\n>\n> Another attack building block could be to exploit any LN protocol/implementation vulnerability like a malicious HTLC-of-death which would provoke honest parties to close their mutual channel when routed through [0]\n>\n> LN light clients should disable HTLC routing and avoid any aggressive fee-bumping for a broadcast of local commitment transactions as time-sensitivity doesn\u2019t matter in this case beyond UX and funds stuck in-flight.\n\n\"beyond UX\" yet if the UX is bad, nobody will use the software.\n\n\n> Bounding dynamic-fees engine may be viewed as a game-theoretic aspect between LN parties (burn the maximum in fee rate to avoid an attacker to make any profit) and macro-considerations (prevent miner to exploit the whole LN network, conservative mempool/resources usage).\u00a0\n>\n> Considering that most of the block reward is currently subsidized, the incentives for miners to launch this attack are questionable. However, this might change when the fraction of fees in the reward becomes higher.\n>\n> As LN becomes an important part of the Bitcoin ecosystem, it\u2019s important to acknowledge the mining-related incentives and risks, as these may at the end be used to influence protocol development.\n>\n> Since the LN infrastructure seems to be moving towards the heavy use of light clients, and the attacks we mentioned are expected to appear again (at least in some of the implementations), we believe it\u2019s important to understand the mechanics of these attacks and countermeasures.\n>\n> It would be interesting to have an empirical study (based on the historical data) and a simulation of the fee spikes, with parameterized:\n>\n> - how many channels are vulnerable to force-closing (based on the particular LN implementations)\n>\n> - what are the properties of those channels (amount, timelocks)\n>\n> - what is the distribution of those channels across nodes\n>\n> - how many nodes implement dynamic bumping\n\nMy understanding is that the pay-your-own-commitment spec is still in-flux, unless you mean some other mechanism?\n\n\n\nRegards,\nZmnSCPXj"
            },
            {
                "author": "Devrandom",
                "date": "2020-02-28T20:04:42",
                "message_text_only": "On Thu, Feb 27, 2020 at 8:42 PM Gleb Naumenko <naumenko.gs at gmail.com> wrote:\n>\n> In this email, myself (gleb) and ariard want to discuss some aspects of the LN implementations when it comes to massive channel closing.\n>\n> [...]\n> - how many nodes implement dynamic bumping\n\nI think it's important to distinguish time-sensitive and\nnon-time-sensitive tx broadcasts\n\n>From a game theoretic point of view, for non-time-sensitive txs (e.g.\nnormal closing) you just want to bump fees in a non-aggressive way, to\noptimize tx inclusion vs time-value of money.  So you mostly want to\ntrack the global fee situation.  The expected fee is less than 1% in\nmost situations.\n\nFor time-sensitive txs (mostly penalty broadcast), you stand to lose\nyour balance after the deadline, so you want to bump in an aggressive\nway to keep the chance of losing your balance relatively low.  Another\ncomplication is that your estimate of the global state of fees might\nbe wrong because of fast changes in the global situation.  So I would\nexpect that the game theoretic response would be to smoothly escalate\nthe fee to a significant % of the balance (maybe 50%+) as you get\nclose to the deadline.\n\nHopefully an attacker cannot trigger the time-sensitive case globally.\n\n> Bounding dynamic-fees engine may be viewed as a game-theoretic aspect between LN parties (burn the maximum in fee rate to avoid an attacker to make any profit) and macro-considerations (prevent miner to exploit the whole LN network, conservative mempool/resources usage).\n\nI'm not sure it makes sense to manage macro considerations with local\npolicies, if those policies end up contrary to self-interest of the\nnode operators.  The rational response of the operator would be to\nmodify the software to conform to their local self-interest.  The\nmagic of Bitcoin is that there are no selfish local modifications that\nresult in fatal global dynamics.  If it ends up that LN has such\npotential local modifications, we should be looking at protocol\nchanges to fix the local incentives."
            }
        ],
        "thread_summary": {
            "title": "On massive channel closing and fee bumping",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Devrandom",
                "Gleb Naumenko",
                "ZmnSCPxj"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 13442
        }
    },
    {
        "title": "[Lightning-dev] Lightning Spec Meeting 2020/03/02",
        "thread_messages": [
            {
                "author": "Christian Decker",
                "date": "2020-02-28T20:55:32",
                "message_text_only": "Dear Protocol Devs,\n\nstart you text-editors, the next meeting is this Monday (2020/03/02),\nand to facilitate review and meeting preparations we have prepared a\nshort agenda [1], this time brought to you by @t-bast, because I almost\nforgot :-)\n\nBelow is a snapshot of the current agenda. Should there be any pull\nrequest, issue or topic missing, please reply either here, or on the\nissue on Github and we will add it if necessary.\n\n```markdown\nThe meeting will take place on Monday 2020/03/02 on IRC [#lightning-dev](irc://chat.freenode.net/lightning-dev). It is open to the public.\n\n## Pull Request Review\n- [ ] Reply channel range simplification #737\n   - Adds details to the spec which were interpreted differently by the implementations.\n- [ ] BOLT11 additional and negative tests #736\n- [ ] Stuck channels: #740 and #750\n- [ ] Wumbo advisory for scaling confirmations: #746 \n- [ ] Quick follow-up on Gitbook #738 \n\n## Long Term Updates\n- [ ] Current status of the trampoline routing proposal (@t-bast)\n- [ ] Protocol testing framework (@rustyrussell). See the `tools/` and `tests/events` directories in [lightning-rfc-protocol-test](https://github.com/ElementsProject/lightning-rfc-protocol-test) for details.\n- [ ] Rendez-vous (@cdecker and @t-bast)\n- [ ] How can we improve the gossip (`gossip_queries_ex`)? (@sstone )\n```\n\nIn particular the rendez-vous routing and the trampoline routing\nproposals are slowly taking shape, so make sure to catch up on the\ndiscussions [2,3].\n\nCheers,\nChristian\n\n[1] https://github.com/lightningnetwork/lightning-rfc/issues/744\n[2] https://gist.github.com/t-bast/ab42a7f52eb2e73105557957c8359601\n[3] https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-February/002565.html"
            }
        ],
        "thread_summary": {
            "title": "Lightning Spec Meeting 2020/03/02",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Christian Decker"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1721
        }
    }
]