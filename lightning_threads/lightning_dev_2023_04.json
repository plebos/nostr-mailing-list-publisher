[
    {
        "title": "[Lightning-dev] Resizing Lightning Channels Off-Chain With Hierarchical Channels",
        "thread_messages": [
            {
                "author": "Anthony Towns",
                "date": "2023-04-03T14:00:19",
                "message_text_only": "On Sat, Mar 18, 2023 at 12:41:00AM +0000, jlspc via Lightning-dev wrote:\n> TL;DR\n\nEven with Harding's optech write ups, and the optech space, I barely\nfollow all this, so I'm going to try explaining it too as a way of\nunderstanding it myself; hopefully maybe that helps someone. Corrections\nwelcome, obviously!\n\nI think understanding all this requires going through each of the four\nsteps.\n\nStep 1: Tunable penalties;\n  https://github.com/JohnLaw2/ln-tunable-penalties\n  https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-October/003732.html\n\nThis is a clever constructions that lets you do a 2-party lightning\nchannel with existing opcodes where cheating doesn't result in you\nlosing all your funds (or, in fact, any of your in-channel funds). It\nalso retains the ability to do layered commit transactions, that is you can\nimmediately commit to claiming an HTLC or that it's already timed out,\neven while you're waiting for the to_self_delay to expire to ensure\nyou're not cheating.\n\nThe way that it works is by separating the flow of channels funds, from\nthe control flow. So instead of managing the channel via a single utxo,\nwe instead manage it via 3 utxos: F (the channel funds), InA (control\nflow for a unilateral close by A), InB (control flow for a unilateral\nclose by B).\n\nFor each update to a new state \"i\", which has \"k\" HTLCs, we create 4 primary txs, and 8k HTLC claims.\n\n  StAi which spends InA, and has k+1 outputs. The first output is used\n  for controlling broadcast of the commitment tx, the remaining k are for\n  controlling the resolution of each HTLC.\n\n  ComAi is the commitment for the state. It spends the funding output\n  F, and the first output of StAi. In order to spend StAi, it requires\n  a to_self_delay (and signature by A), giving B time to object that i\n  is a revoked state. If B does object, he is able to immediately spend\n  the first output of StAi directly using the revocation information,\n  and these funds form the penalty. It has k+2 outputs, one for the\n  balance of each participant, and one for each HTLC.\n\n  For each of the k HTLCs, we construct two success and two timeout\n  transactions: (HAi-j-s, HAi-j-p); (HAi-j-t, HAi-j-r). HAi-j-s and\n  HAi-j-t both spend the jth output of StAi, conditional either on a\n  preimage reveal or a timeout respectively; HAi-j-p and HAi-j-r spend\n  the output of HAi-j-s and HAi-j-t respectively, as well as the output\n  of ComAi. (s=success commitment, t=timeout commitment, p=payment on\n  success, r=refund)\n\n  And Bob has similar versions of all of these.\n\nSo if Alice is honest, the process is:\n\n  * Alice publishes StAi\n  * Alice publishes HAi-j-{s,t} for any HTLCs she is able to resolve\n    immediately; as does Bob.\n  * Alice waits for to_self_delay to complete\n  * Alice publishes ComAi, and any HAi-j-{r,p} transactions she is able\n    to, and if desired consolidates her funds.\n  * As any remaining HTLCs resolve, those are also claimed.\n  * Bob's InB output is available to do whatever he wants with.\n\nIf Alice is dishonest, the process is:\n\n  * Alice publishes StAi, and perhaps publishes some HAi-j-{s,t}\n    transactions.\n  * Bob spends the first output of StAi unilaterally claiming the\n  * penalty, meaning ComAi can now never be confirmed.\n  * Bob publishes StBi', and continues with the honest protocol.\n\nBob only needs the usual O(log(n)) state in order to be able to\nreconstruct the key to spend the first output of revoked StAi txs.\nBecause that prevents the corresponding ComAi from ever being published,\nno revoked HTLC-related state can make it on chain in any way that Bob\nneeds to care about.\n\nIf both Alice and Bob are dishonest (Alice tries to cheat, but Bob\nrestored from an old backup and also publishes a revoked state) then\nboth the StAi and StBi' may have their first output claimed by the other\nparty, in which case the channels funds are lost (unless Alice and Bob\nmanage to agree to a cooperative close somehow, even after all the\nattempts to cheat each other).\n\nWhile 4+8k transactions per state is a lot, I think you only actually\nneed 2+4k signatures in advance (StAi and HAi-j-{s,t} only need to be\nsigned when they're broadcast). Perhaps using ANYPREVOUT would let you\nreduce the number of HTLC states?\n\nStep 2: Efficient Factories for Lightning Channels\n https://lists.linuxfoundation.org/pipermail/lightning-dev/2023-January/003827.html\n https://github.com/JohnLaw2/ln-efficient-factories\n\nThis generalizes the tunable penalties setup for more than two\nparticipants.\n\nThe first part of this is a straightforward generalisation, and\ndoesn't cover HTLCs. Where we had 2(2+4k) transactions previously, we\npresumably would now have P(2+4k) transactions, where P is the number\nof participants.\n\nThe second part of this aims to avoid that factor P. It does this by\nintroducing Trigger and Mold transactions.\n\nTo do this, we first establish the number of states that the factory\nwill support; perhaps 2**40. In that case, the trigger transaction will\nspend the funding tx, and have 40+1 outputs. All of them will require a\nP-of-P signature to be spend, with the first also requiring a relative\ntimelock of 3*to_self_delay and containing the channel funds, while the\nrest contain dust-ish amounts.\n\nFor any given state i, we represent i as a binary number, and the\ncommitment tx Com_i will spend the outputs corresponding to \"0\" in\nthe binary number, as well as the first output containing the channel\nfunds.\n\nWe will also have St{A..Z}_i transactions, spending In{A..Z} as\npreviously. The sole output of StAi (etc) will be spent either by any\nother participant via a revoked pubkey, or else by the Mold{A..Z}_i\ntransaction. The Mold{A..Z}_i transaction will also spend the remaining\noutputs of the Trigger transaction that were not spent by Com_i.\n\nIn the honest scenario, this looks like:\n\n * Alice publishes Trigger\n * Alice publishes StA_i\n * Alice waits to_self_delay\n * Alice publishes MoldA_i\n * Alice waits an additional 2*to_self_delay\n * Alice publishes Com_i\n * Alice and everyone else claims their funds\n\nThere are various dishonest scenarios available:\n\n * If Alice publishes StA_i before publishing the Trigger, someone else\n   publishes the Trigger.\n\n * If Alice doesn't publish StA_i quickly, Bob publishes StB_i\n   and continues. If multiple St{A..Z}_i's are published, whoever does\n   not publish the Mold transaction simply reclaims their funds by the\n   \"revocation\" path.\n\n * If Alice publishes an old StA_i, Bob claims the funds using the\n   revoked key, penalising A, and then publishes the correct StB_i,\n   and continues.\n\n * If Alice does not publish MoldA_i, Bob can publish StB_i and MoldB_i.\n\n * Once MoldB_i is confirmed, someone could attempt to broadcast an\n   outdated Com_i' where i' < i. In that case, the outputs corresponding\n   to all the 1's in the binary representation of i are already spent\n   (by MoldB_i), but for any i' < i, the i' necessarily has a 0 somewhere\n   where i had a 1 (otherwise i' >= i), so Com_i' would be double spending\n   an input already spent by MoldB_i.\n\nIn this case, you need to track P+1 outputs (F+InA..Z), you need\nO(P*log(N)) state, and the onchain impact of a unilateral close is ideally\n4 transactions (Trigger, StAi, MoldAi, Comi) with size O(log(MaxN)),\nbut maybe be up to 2*P+2 transactions (Trigger, St{A..Z}i, MoldAi,\nrefund{B..Z}i, Comi).\n\nNote that this doesn't consider HTLCs at all.\n\nStep 3: Factory Optimized protocols for Lighting\n https://github.com/JohnLaw2/ln-factory-optimized\n https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-December/003782.html\n https://bitcoinops.org/en/newsletters/2022/12/14/#factory-optimized-ln-protocol-proposal\n\nPerhaps this should have been step 2, whoopsie. Anyway, this optimises\nthe construction in step 1 for channels included in factories; mostly\nto deal with the fact that closing a factory is tedious and can take a\nwhile. I'm ignoring the Partial-Factory-Optimized step -- it's barely\ndifferent to the Tunable Penalty mechanism. The Fully Factory Optimized\nprotocol is more interesting.\n\nThe main idea here is this: if a channel in a factory goes defunct while\nan HTLC is pending, we'd like to be able to guarantee we've resolved\nthe HTLC to our satisfaction while deferring the decision of whether\nto shutdown the entire factory in order to close the channel, just\nin case our channel partner eventually comes back, and we can resolve\neverything properly.\n\nThe way we do that is twofold: first, we set things up so that the default\nresolution of an HTLC is a refund. That immediately does away with half\nof our HTLC transactions, because now we only need the success/payment\npaths, not the timeout/refund ones. Second, we require whoever's\ngoing to receive the payment to publish their StXi transaction -- that\navoids us having to do P*k success/payment paths, now we only need 1*k\nsuccess/payment paths.  Unfortunately, we do introduce a new \"kickoff\"\ntransaction to make it a three transaction kickoff/success/payment path,\nrather than just two transactions.\n\nIn this case your transactions are:\n\n  F - the funding output, only available once the factory is closed\n  InB - as before\n  StBi - your state commitment, one output that will be spent by ComBi,\n         k outputs for each pending HTLC paying to B in state i.\n  HBi-j-k - the kickoff transaction for HTLC \"j\" paying to B, spends\n         the appropriate output of StBi, conditional on revealing the\n\t HTLC preimage and B's signature. Spendable either by B after\n\t to-self-delay, or by A after the HTLC's expiry plus\n\t to-self-delay\n  HBi-j-s - the success transaction, spendable by B\n  HBi-j-p - the payment transaction, spends HBi-j-s and the HTLC output\n         from ComB_i\n  HAi-j-p - the payment transaction, spends HBi-j-s and the HTLC output\n         from ComA_i\n\nI think there's an error in the paper here; it says as well as being\nspendable by H{A,B}i-j-p as above, the HTLC output in ComA_i should be\nspendable by A after to-self-delay. I believe it should require both\nto-self-delay (relative timelock) and the HTLC expiry (absolute timelock)\nbefore it can be spendable by A.\n\nAnyway, how's that work? If you want to shut the factory down\nimmediately, it looks like:\n\n * Shut the factory down\n * Broadcast StBi, HBi-j-k\n * Wait to-self-delay\n * Broadcast ComBi, HBi-j-s, HBi-j-p\n * Done!\n\nIf you were cheating, then:\n\n * Alice steals StBi's first output if i was on old state, and ComBi\n   cannot be broadcast. Alice publishes the current StAi', ComAi', etc.\n \n * If the HTLC had timed out, Alice claims the output of HBi-j-k before\n   to-self-delay is finished, so that HBi-j-p cannot be broadcast, then\n   claims the output of ComBi once both timeouts are complete.\n\nHowever, what if you don't want to shut the factory down? In that\ncase:\n\n * Broadcast StBi, HBi-j-k.\n * Wait for to_self_delay.\n * Spend HBi-j-k to HBi-j-s.\n * Wait some more.\n * The other guy comes online! Let's recover the channel!\n * Propose spending the first output of StBi and the output of HBi-j-s\n   to a new InB2, but don't sign it.\n * Update all the off-chain channel data to a new state i+1 that uses\n   InB2 instead of InB, and that acknowledges your claim to the HTLC\n   funds.\n * Sign and broadcast InB2\n * Continue \n\nIf the other guy doesn't come online, you close the factory, immediately\nspend F and the first output of StBi via ComBi, and immediately spend\nHBi-j-s and the HTLC output of ComBi to claim your funds.\n\nWhile this is described as an optimisation focussed on improving channels\nwithin factories; it seems to me that the reduction in state compared to\nthe \"tunable penalties\" approach in step 1 makes this a strict improvement\nin general.\n\nAnyway, combining this step and the previous gives us an idea how to do\nboth factories and HTLCs. I believe that would look like:\n\n Factory funding output -- multisig of A..Z\n Factory In{A..Z}\n\n Factory Trigger, spends the funding output\n Factory St{A..Z}i spends In{A..Z}\n Factory Mold{A..Z}i spends St{A..Z}i and various Trigger outputs\n Factory Com_i spends the other Trigger outputs; its outputs are the\n   channels in the factory.\n\n Channel F_x - an output of the Factory Com_i\n Channel InA, InB\n Channel StAi, StBi -- spends InA/InB\n Channel ComAi, ComBi -- spends F_x and the first output of StA/StB\n Channel H{A,B}i_j_{k,s,p} -- success path funds for active HTLCs\n\nSo to update the channel state, the channel participants need:\n\n 3*k HTLC transactions (only 1 pre-signed)\n 2 commitment transactions (both pre-signed)\n 2 St transactions (neither pre-signed)\n\nEvery time the factory updates, every channel state must also update (as\nthe channel funding outputs will change txid).\n\nEvery participant needs 1+c \"In\" confirmed utxos available -- one for\nthe factory itself, and one for each channel they're involved in.\n\nEvery participant needs to monitor P+c+1 outputs on chain -- the factory\nFunding output (which may be spent by the Trigger tx), the P\nSt{A..Z}i outputs, and their counterparty's InX output for each channel\nthey're participating in.\n\nThat's getting pretttty complicated, so I'm not confident I've got it\nall in my head correctly, but I think it still works.\n\nI'm skipping over the watchtower-freedom/casual user section here. cf\nhttps://bitcoinops.org/en/newsletters/2022/10/12/#ln-with-long-timeouts-proposal\n\nStep 4: Resizing Lightning Channels Off-Chain / Hierarchial Channels\n  https://lists.linuxfoundation.org/pipermail/lightning-dev/2023-March/003886.html\n  https://github.com/JohnLaw2/ln-hierarchical-channels\n  https://bitcoinops.org/en/newsletters/2023/03/29/#preventing-stranded-capital-with-multiparty-channels-and-channel-factories\n\nHey, we made it to this thread!\n\nI'm not entirely sure of the novelty in this proposal; once you have\nchannels in factories, lots of magic is possible, but it's all very\ncomplex. I believe the particular proposal here is something like:\n\n - Instead of just having Alice/Bob/Carol/etc as identities in\n   lightning, let them \"pair\" up, so that AliceBob is considered a node,\n   and CarolDave is also a node.\n\n - So we have a utxo where AliceBob has a channel with CarolDave, and\n   another where CarolDave has a channel with Elizabeth, eg.\n\n - But actually the AliceBob/CarolDave utxo is a factory; and there's\n   an internal channel between Alice and Bob, and another between Carol\n   and Dave\n\n - Now, because we describe AliceBob and CarolDave as a channel, that\n   means funds can move between AliceBob and CarolDave; but that is\n   equivalent to saying the overall capacity of the internal Alice/Bob\n   channel is actually decreasing without any on-chain activity! Neat!\n\nBut... that was always the point of channel factories? And the specific\nstructure of four participants split into a single pair of channels\ndoesn't seem particularly compelling? I don't know, I feel like I'm\nmissing something here. Or maybe it's just the first three steps were\namazing, so merely interesting seems pedestrian by comparison?\n\nHmm, looking at Harding's email, I see:\n\n> **Liquidity multiplexing:** Alice, Bob, Carol, and Dan each rightfully\n> own some portion of a UTXO.  Alice and Bob expect to always be\n> available; Carol and Dan may sometimes be unavailable.  The proposal\n> allows Carol and Dan to spend/receive in combination with Alice and\n> Bob, but also ensures Alice and Bob can spend back and forth the\n> entirety their portions of the UTXO even if Carol, Dan, or both of\n> them are unavailable.\n\nI guess I'm not entirely enthusiastic about that because in that case\nAlice can only send funds to Carol when Dan (and whoever else is involved\nin the factory) eventually come online to signoff on the factory state\nupdate. That's still useful for (slow) offchain channel reallocations,\nbut it doesn't seem reliable/fast enough for a payment.\n\nFor the case where all factory participants are reliably online (perhaps\nwith some exceptions) I guess I could see that making sense?  Then you're\ngenerally just treating it as a 4-party channel of A/B/C/D with everyone\nable to easily forward to anyone; but when Alice is offline for system\nmaintenance for an hour every week, it automatically degrades to just\nhaving the Carol/Dave channel operational, with no other problems.\n\nfin\n\nCheers,\naj"
            },
            {
                "author": "jlspc",
                "date": "2023-04-03T23:39:54",
                "message_text_only": "Hi Dave,\n\nThank you for your clear and insightful response.\n\nComments inline below:\n\n>Hi John,\n\n>Thank you for another innovative application of your tunable penalties.\n>I see two key benefits being described by your paper[1]:\n\n>- **Offchain channel resizes:** in state 0, Alice and Bob share control\n>   over an offchain UTXO valued at x satoshis; in state 1, the value of\n>   the offchain UTXO is y satoshis.\n\n>- **Liquidity multiplexing:** Alice, Bob, Carol, and Dan each rightfully\n>   own some portion of a UTXO.  Alice and Bob expect to always be\n>   available; Carol and Dan may sometimes be unavailable.  The proposal\n>   allows Carol and Dan to spend/receive in combination with Alice and\n>   Bob, but also ensures Alice and Bob can spend back and forth the\n>   entirety their portions of the UTXO even if Carol, Dan, or both of\n>   them are unavailable.\n\n>For the Offchain Channel Resizes, I don't see how your proposal\n>functionally differs from a classic channel factory.  In section 3, you\n>show the set {A, B, C, D} with the subset {A,B} where A reduces its\n>balance in {A,B} by transfering it to {C,D} via an HTLC to another of its\n>nodes (A').\n\n>Your description uses hierarchical channels (which may have >2\n>participants per channel).  In a classic pair-producing channel factory,\n>each channel only has two participants, e.g. the factory {A, B, C, D}\n>produces the channels,\n\n>   {A,B}\n>   {A,C}\n>   {A,D}\n>   {B,C}\n>   {B,D}\n>   {C,D}\n\n>However, the same thing is possible, A as part of {A,B} can pay through\n>{B,C} out of the factory to A'.  After the HTLCs are settled, the\n>offchain channel setup transactions inside the factory can be\n>regenerated with the cooperation of all {A, B, C, D}.\n\n>Am I missing something, or is this first key benefit something that was\n>already possible (in theory) with pair-producing channel factories?\n\nWhen the first key benefit is defined as:\n\n\tBenefit 1: Ability to resize a channel owned by Alice and Bob\n\toffchain from x satoshis to y satoshis\n\nyou are correct that this can be achieved with existing techniques\nusing channel factories.\n\nHowever, when the key benefit is defined differently, it becomes clear\nthat it can be achieved only with hierarchical channels. I'll give two\nother definitions of the benefit that demonstrate what is new. In these\ndefinitions, note that the quantity \"delta\" could be positive or\nnegative. Also, assume that all capacity owned by the users considered\nmust be in a Lightning channel at all times (in order to avoid\nstranding liquidity). Finally, for simplicity, ignore routing fees\nin the following.\n\n\tBenefit 2: Ability to resize a channel owned by Alice and Bob\n\toffchain from x satoshis to y = x - delta satoshis, while\n\tresizing a channel owned by Harriet and Isaac from u satoshis\n\tto v = u + delta satoshis, where:\n\t\ta) Harriet and Isaac do not know Alice and Bob and\n\t\tnever co-sign transactions with Alice and Bob, and\n\t\tb) all other 2-user channels' capacities are\n\t\tunchanged.\n\nNote that Benefit 2 can't be achieved with channel factories, as they\nwould violate requirement a) above. In contrast, Benefit 2 can be\nachieved with hierarchical channels, as long as all channels are\nviewed as logical (rather than physical) channels. An example of\nhow this can be achieved is with the payment given in Figure 4 of\nthe paper (p. 8), but stopping the payment one hop earlier as it\nis received by H and I (Harriet and Isaac). Benefit 2 matters, as\nit's a lot easier to find a channel that wants to make a capacity\nchange that offsets the capacity change that Alice and Bob want\nto make if the offsetting channel can be anywhere in the world\n(but connected via the Lightning Network) as opposed to in a\nchannel factory containing Alice and Bob (as there will only\nbe, say, 10 or 100 users in each such factory). Having to offset\na channel capacity change by finding a channel making the opposite\nchange within a channel factory is like having to make LN payments\nwithout using HTLCs. It would be possible to make payments within\na factory, but in most cases that wouldn't help, as the payer and\npayee would not happen to be in the same factory.\n\n\tBenefit 3: Ability to resize a channel owned by Alice and Bob\n\toffchain from x satoshis to y = x - delta satoshis, where all\n\tother 2-user channels' capacities are unchanged.\n\nNote that Benefit 3 cannot be achieved with channel factories, as any\nchange in the capacity of a channel in a factory must be offset by\nthe opposite change in one or more other channels within the factory\n(given our requirement that all capacity is always kept within channels\nin order to avoid stranding liquidity).\n\nIn contrast, Benefit 3 is possible with hierarchical channels, as\nlong as they are viewed as logical channels. Examples include the\npayment shown in Figure 1 of the paper (p. 4). This somewhat\nsurprising result is due to the existence of a 3-user hierarchical\nchannel (namely the one owned by C, D and E in Figure 1) that\ntransitions from HTLCs that swap capacity between pairs of 2-user\nchannels to HTLCs that swap balances between users within a 2-user\nchannel. This benefit is even stronger than the previous one, as\nno channel that wants to make an offsetting capacity change has\nto be found at all.\n\nI hope these two explicitly-stated benefits demonstrate that\nhierarchical channels *do* provide new capabilities that did not\nexist previously, and that these new capabilities are very\nimportant in practice.\n\nPlease let me know if any of this doesn't make sense.\n\nThanks again,\nJohn"
            },
            {
                "author": "Anthony Towns",
                "date": "2023-04-04T00:46:21",
                "message_text_only": "On Tue, Apr 04, 2023 at 12:00:32AM +1000, Anthony Towns wrote:\n> On Sat, Mar 18, 2023 at 12:41:00AM +0000, jlspc via Lightning-dev wrote:\n> > TL;DR\n> \n> Step 1: Tunable penalties;\n>   https://github.com/JohnLaw2/ln-tunable-penalties\n>   https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-October/003732.html\n> \n> This is a clever constructions that lets you do a 2-party lightning\n> channel with existing opcodes where cheating doesn't result in you\n> losing all your funds (or, in fact, any of your in-channel funds).\n\nAh, a significant difference between this and eltoo is in the game\ntheory of what happens if you lose access to the latest state.\n\nIn eltoo, how things would work in that case, is that you would attempt\nto close the channel to an old state that you do still remember (from a\nbackup), at which point either (a) your counterparty publishes a later\nstate, and you settle with that (possibly with you paying some modest\npenalty if you're using a Daric-like protocol), or (b) your counterparty\ndoes nothing, and you settle at the old state.\n\nWith tunable penalties, you are in more of a quandry. If you broadcast\nan old \"St\" transaction to attempt to close to an old state, then your\ncounterparty will simply claim those funds and penalise you; however\nthere is nothing forcing them to publish any newer state as well. At\nthat point your counterparty can hold your share of the channel funds\nhostage indefinitely.\n\nHolding your funds hostage is probably an improvement on simply losing\nthem altogether, of course, so I think this is still a strict improvement\non ln-penalty (modulo additional complexity etc).\n\nCheers,\naj"
            },
            {
                "author": "jlspc",
                "date": "2023-04-08T22:30:54",
                "message_text_only": "Comments below:\n\n>> Step 1: Tunable penalties;\n>> <a href=\"https://github.com/JohnLaw2/ln-tunable-penalties\">https://github.com/JohnLaw2/ln-tunable-penalties</a>\n>> <a href=\"https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-October/003732.html\">https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-October/003732.html</a>\n\n>> This is a clever constructions that lets you do a 2-party lightning\n>> channel with existing opcodes where cheating doesn't result in you\n>> losing all your funds (or, in fact, any of your in-channel funds).\n\n> Ah, a significant difference between this and eltoo is in the game\n> theory of what happens if you lose access to the latest state.\n\n> In eltoo, how things would work in that case, is that you would attempt\n> to close the channel to an old state that you do still remember (from a\n> backup), at which point either (a) your counterparty publishes a later\n> state, and you settle with that (possibly with you paying some modest\n> penalty if you're using a Daric-like protocol), or (b) your counterparty\n> does nothing, and you settle at the old state.\n\n> With tunable penalties, you are in more of a quandry. If you broadcast\n> an old \"St\" transaction to attempt to close to an old state, then your\n> counterparty will simply claim those funds and penalise you; however\n> there is nothing forcing them to publish any newer state as well. At\n> that point your counterparty can hold your share of the channel funds\n> hostage indefinitely.\n\n> Holding your funds hostage is probably an improvement on simply losing\n> them altogether, of course, so I think this is still a strict improvement\n> on ln-penalty (modulo additional complexity etc).\n\nYes, that's a good point.\n\nI did describe an extension, called \"Unilateral Close after an Old Transaction is Put On-Chain\", in the Tunable Penalties paper and in the Factory Optimized Channels paper.\nThe idea is to add a Trigger transaction that spends the output of the Funding transaction.\nIn response to seeing the Trigger transaction, the other party can put their final State transaction and (after a to-self-delay) Commitment transaction on-chain.\nHowever, if the other party doesn't do so, then after a 3*to-self-delay, the party that forgot the state can initiate the Decker-Wattenhofer protocol to settle the channel.\nOf course, the eltoo protocol could be used instead of the Decker-Wattenhofer protocol at this point if APO is available.\n\nRegards,\nJohn"
            },
            {
                "author": "jlspc",
                "date": "2023-04-08T22:26:45",
                "message_text_only": "Hi aj,\n\nThanks for your great write-up!\n\nComments below:\n\n> Even with Harding's optech write ups, and the optech space, I barely\n> follow all this, so I'm going to try explaining it too as a way of\n> understanding it myself; hopefully maybe that helps someone. Corrections\n> welcome, obviously!\n\n> I think understanding all this requires going through each of the four\n> steps.\n\n[...]\n\n> Step 3: Factory Optimized protocols for Lighting\n>  <a href=\"https://github.com/JohnLaw2/ln-factory-optimized\">https://github.com/JohnLaw2/ln-factory-optimized</a>\n>  <a href=\"https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-December/003782.html\">https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-December/003782.html</a>\n>  <a href=\"https://bitcoinops.org/en/newsletters/2022/12/14/#factory-optimized-ln-protocol-proposal\">https://bitcoinops.org/en/newsletters/2022/12/14/#factory-optimized-ln-protocol-proposal</a>\n\n> In this case your transactions are:\n\n>   F - the funding output, only available once the factory is closed\n>   InB - as before\n>   StBi - your state commitment, one output that will be spent by ComBi,\n>          k outputs for each pending HTLC paying to B in state i.\n>   HBi-j-k - the kickoff transaction for HTLC \"j\" paying to B, spends\n>          the appropriate output of StBi, conditional on revealing the\n> \t HTLC preimage and B's signature. Spendable either by B after\n> \t to-self-delay, or by A after the HTLC's expiry plus\n> \t to-self-delay\n>   HBi-j-s - the success transaction, spendable by B\n>   HBi-j-p - the payment transaction, spends HBi-j-s and the HTLC output\n>          from ComB_i\n>   HAi-j-p - the payment transaction, spends HBi-j-s and the HTLC output\n>          from ComA_i\n\n> I think there's an error in the paper here; it says as well as being\n> spendable by H{A,B}i-j-p as above, the HTLC output in ComA_i should be\n> spendable by A after to-self-delay. I believe it should require both\n> to-self-delay (relative timelock) and the HTLC expiry (absolute timelock)\n> before it can be spendable by A.\n\nIt's not actually an error in the paper, because the paper includes a \"max_cltv_expiry\" parameter that prevents the race you're concerned about.\nHowever, it's easy to miss that parameter (it's only introduced in an appendix) and I like your idea of using an absolute delay in the HTLC output in ComA_i when it is spent by A.\nI plan to change the paper to add such an absolute delay (which I believe should be Alice's to-self-delay after the HTLC's expiry) and remove the \"max_cltv_expiry\" parameter.\nThanks for the good idea!\n\n> While this is described as an optimisation focussed on improving channels\n> within factories; it seems to me that the reduction in state compared to\n> the \"tunable penalties\" approach in step 1 makes this a strict improvement\n> in general.\n\nI agree.\n\n> Every participant needs 1+c \"In\" confirmed utxos available -- one for\n> the factory itself, and one for each channel they're involved in.\n\nWhile 1+c \"In\" confirmed utxos will work, it's also possible to just have a single confirmed utxo and to create the 1+c desired \"In\" utxos from it by putting a transaction, or a tree of transactions, on-chain if and when needed.\nThis optimization is described as the \"Off-Chain Control Outputs\" extension in the original Tunable Penalties paper and in the Factory Optimized Channels paper.\n\n> Step 4: Resizing Lightning Channels Off-Chain / Hierarchial Channels\n>   <a href=\"https://lists.linuxfoundation.org/pipermail/lightning-dev/2023-March/003886.html\">https://lists.linuxfoundation.org/pipermail/lightning-dev/2023-March/003886.html</a>\n>   <a href=\"https://github.com/JohnLaw2/ln-hierarchical-channels\">https://github.com/JohnLaw2/ln-hierarchical-channels</a>\n>   <a href=\"https://bitcoinops.org/en/newsletters/2023/03/29/#preventing-stranded-capital-with-multiparty-channels-and-channel-factories\">https://bitcoinops.org/en/newsletters/2023/03/29/#preventing-stranded-capital-with-multiparty-channels-and-channel-factories</a>\n\n> Hey, we made it to this thread!\n\n> I'm not entirely sure of the novelty in this proposal; once you have\n> channels in factories, lots of magic is possible, but it's all very\n> complex. I believe the particular proposal here is something like:\n\n>  - Instead of just having Alice/Bob/Carol/etc as identities in\n>    lightning, let them \"pair\" up, so that AliceBob is considered a node,\n>    and CarolDave is also a node.\n\n>  - So we have a utxo where AliceBob has a channel with CarolDave, and\n>    another where CarolDave has a channel with Elizabeth, eg.\n\n>  - But actually the AliceBob/CarolDave utxo is a factory; and there's\n>    an internal channel between Alice and Bob, and another between Carol\n>    and Dave\n\n>  - Now, because we describe AliceBob and CarolDave as a channel, that\n>    means funds can move between AliceBob and CarolDave; but that is\n>    equivalent to saying the overall capacity of the internal Alice/Bob\n>    channel is actually decreasing without any on-chain activity! Neat!\n\n> But... that was always the point of channel factories? And the specific\n> structure of four participants split into a single pair of channels\n> doesn't seem particularly compelling? I don't know, I feel like I'm\n> missing something here. Or maybe it's just the first three steps were\n> amazing, so merely interesting seems pedestrian by comparison?\n\nThanks!\n\n>From my perspective, this paper makes two contributions (which, to be fair, may only be \"interesting\" :)\n1) it allows dedicated users to resize Lightning channels off-chain by sending channel capacity over the Lightning network, and\n2) it allows each casual user to work with a pair of dedicated users in order to let the casual user send and receive payments without forcing the dedicated users to leave any of the channel capacity idle when the casual user is unavailable.\n\nI'll discuss 2) more below.\n\nRegarding 1), I wouldn't say that \"that was always the point of channel factories\".\nWhile it's true that channel factories allow users to resize two-user channels off-chain, they can only do this subject to the following limitations:\n* whatever channel capacity change is being made is exactly offset by one or more other channel capacity changes in the other direction (assuming all factory capacity is in channels),\n* the desired change and the offsetting change(s) have to be within a single channel factory, and\n* every user in the factory has to be available to sign for the factory update.\n\nThe first two limitations make one want to create factories with lots of users (in order to have flexibility in finding offsetting channels), while the third limitation makes one want factories with few users (in order to enable obtaining all of the required signatures).\n\n1) eliminates all of these limitations by allowing channel capacity to be routed over the Lightning Network.\nPreviously, I hadn't realized this was possible.\n\nAs a result, hierarchical channels with just 3 or 4 users seem to be enough for resizing channels off-chain.\n\n> Hmm, looking at Harding's email, I see:\n\n>> **Liquidity multiplexing:** Alice, Bob, Carol, and Dan each rightfully\n>> own some portion of a UTXO.  Alice and Bob expect to always be\n>> available; Carol and Dan may sometimes be unavailable.  The proposal\n>> allows Carol and Dan to spend/receive in combination with Alice and\n>> Bob, but also ensures Alice and Bob can spend back and forth the\n>> entirety their portions of the UTXO even if Carol, Dan, or both of\n>> them are unavailable.\n\n> I guess I'm not entirely enthusiastic about that because in that case\n> Alice can only send funds to Carol when Dan (and whoever else is involved\n> in the factory) eventually come online to signoff on the factory state\n> update. That's still useful for (slow) offchain channel reallocations,\n> but it doesn't seem reliable/fast enough for a payment.\n\nI too would not be enthusiastic if a casual user could only send and receive funds when some other casual user is available.\nHowever, by using three-user channels (two of whom are dedicated), a casual user can send and receive without requiring availability from any other casual user (and without stranding funds).\n\nRegards,\nJohn"
            },
            {
                "author": "Anthony Towns",
                "date": "2023-04-12T06:03:03",
                "message_text_only": "On Sat, Apr 08, 2023 at 10:26:45PM +0000, jlspc via Lightning-dev wrote:\n> From my perspective, this paper makes two contributions (which, to be fair, may only be \"interesting\" :)\n\nOne thing that confuses me about the paper is how to think about routing\nto a \"channel\" rather than a node -- ie the payment from \"E->FG->A\" where\n\"FG\" isn't \"F\" or \"G\", but \"both of them\". It feels like there's a whole\nmass of complications hidden in there from a routing perspective; like how\ndo you link \"FG\" back with \"F\" and \"G\", how do you decide fees, how do\nyou communicate fees/max_htlc/etc. I think it also implies that channel\ncapacity is no longer really something you can gossip very sensibly --\nif you have a factory ((A,B),C,D,E) then every payment through AB to C\nor D or E will decrease AB's channel capacity. You could still gossip the\ncapacity of the overall factory, and sum that to get an overall lightning\nnetwork capacity, of course. But a lot of the ways of simplifying it\nalso make it harder to do all the nice rebalancing.\n\nAnyway, I've tried a few times now to put some thoughts together on that\nand come up with nothing that I'm happy with, so figured it might be at\nleast worth posing explicitly as a problem...\n\nCheers,\naj"
            },
            {
                "author": "jlspc",
                "date": "2023-04-18T19:17:34",
                "message_text_only": "> One thing that confuses me about the paper is how to think about routing\n> to a \"channel\" rather than a node -- ie the payment from \"E->FG->A\" where\n> \"FG\" isn't \"F\" or \"G\", but \"both of them\".\n\nYes, I found it very difficult to think about, and I kept getting confused between concepts like \"user\", \"node\", \"channel\", and \"factory\".\nThe thing that works best for me is to create a clear definition of each of these terms, along with the term \"party\".\n\nI also think it's best to imagine a world in which there are hierarchical channels, but there are no \"factories\" per se.\nThe distinction is meaningful in the sense that a hierarchical channel requires that there are exactly *two* *fixed* \"parties\" to which the hierarchical channel pays out, and all changes to the balances paid to those parties are made via HTLCs.\nIn contrast, a \"factory\" can pay out to an arbitrary number of users or groups of users, and changes to the balances paid to those users or groups of users are made via updating the state of the factory (typically without an HTLC being required).\n\nSo, in a world with hierarchical channels, but without factories, we have the following terms:\n* User: a person\n* Party: a fixed group consisting of one or more users\n* Node: a party\n  - so \"party\" and \"node\" are synonyms, with \"party\" emphasizing the human side of things and \"node\" emphasizing the graph side of things, such as when discussing the Lightning routing graph\n* Physical channel: a layer 2 construct that is funded by an on-chain or an off-chain UTXO, is owned by 2 parties, pays a balance to each of the parties, and updates the parties' balances through HTLCs and a channel protocol\n  - a physical channel can be non-hierarchical (where each of the 2 parties is a single user) or hierarchical (where at least one party consists of more than 1 user)\n  - (Footnote: The concept of an \"off-chain UTXO\" is itself a bit tricky, as it often refers to one of multiple possible transaction outputs, where the transactions or their ancestors conflict, so only one of them can actually be instantiated. For example, a Lightning channel (using the current penalty protocol) can be said to create an off-chain UTXO that pays to one of the users, even though it's not clear which of the users' Commitment transactions will actually be instantiated. In general, an off-chain UTXO is a guaranteed way of getting a certain portion of a specific on-chain UTXO's funds. Let's skip going down this rabbit hole any further and just assume we understand these issues.)\n* Logical Channel: a layer 2 construct that consists of all of the physical channels owned by a specific pair of parties\n  - the size (capacity) of a logical channel is the sum of the sizes of their physical channels\n  - (Footnote: It's possible, with a significant amount of software development work that I in no way discount, to route a payment through a logical channel where the payment traverses multiple physical channels at the same time. This is done by using separate HTLCs, all sharing the same secret, in each of the physical channels that the payment traverses. I can write more about this if that would be helpful.)\n* Lightning Network (LN): a layer 2 network consisting of parties and logical channels between parties\n  - the LN can be represented as a directed graph, where each party is a node and each logical channel is pair of arcs (one in each direction) between two nodes\n  - the LN can be used to make payments from one node to another node via a path through the graph\n    - the purpose of the payment could be to send bitcoin from one user to another (in this case, the payment's source and destination nodes are both 1-user parties)\n    - the purpose of the payment could be to increase or decrease the size of a logical channel (in this case, the payment's source and/or destination node is a multi-user party)\n      - (Footnote: Here's another great opportunity for confusion, as the source and/or destination of the payment is a multi-user party, which is defined as more than two users, and yet the purpose of the payment is to resize a logical channel. Obviously, a group of users is different from a logical channel (as shown in the definitions above), so how does making a payment to or from a group of users change the size of a logical channel? The answer is that the logical channel being resized is the one owned by the group of users.)\n* Factory: a term that doesn't exist in this world view\n\nSorry if all of this seems overly pedantic.\nIt's the only way I've been able to keep these concepts straight in my mind.\nI've also found that drawings help clarify these issues, which is why the paper has 20 drawings, many of which are examples of payments and channel graphs.\n\n> It feels like there's a whole\n> mass of complications hidden in there from a routing perspective; like how\n> do you link \"FG\" back with \"F\" and \"G\", how do you decide fees, how do\n> you communicate fees/max_htlc/etc.\n\nIn addition to the assumptions and definitions above, we need to use Rusty Russell's idea for channel_update_v2 messages [1].\n\nRegarding the specific issues you raised:\n\nQ: How do you link \"FG\" back with \"F\" and \"G\"?\nA: In terms of gossiping and the channel graph, you don't explicitly link \"FG\" with \"F\" and \"G\". \"FG\", \"F\" and \"G\" each have their own identity in the LN's Onion network and each one appears as a separate node in the routing graph, with no explicit linkage between them. Every logical channel in the channel graph is announced with channel_update_v2 messages that provide the channel's current capacity and refer back to an on-chain UTXO. It's possible, but not necessary, that some of the logical channels between \"FG\" and other nodes, between \"F\" and other nodes, and between \"G\" and other nodes, use the same on-chain UTXO for their channel_update_v2 messages.\n\nQ: How do you decide fees?\nA: All of the users that own a given logical channel negotiate the routing fees that they want to charge. These routing fees are of two types: 1) a fee for devoting capital (by being the \"payer\" or \"payee\" as defined in the paper), and 2) a fee for providing signatures without devoting capital. For example, in order to traverse the logical channel ((A,B),(C,D)) (where A, B, C and D are dedicated users, A is the \"payer\", and C is the \"payee\"), C will get a payment for devoting capital and D will get a payment for providing signatures. It's reasonable to assume that the sum of these fees will be larger than the fees charged by most non-hierarchical channels, so it's reasonable to assume that the logical channel ((A,B),(C,D)) will be used more often as the first or last hop in a payment (in order to resize (A,B) or (C,D), but not both of them), rather than as an intermediate hop in a payment.\n\nQ: How do you communicate fees/max_htlc/etc.?\nA: Just like you do today, with the only difference being that a specific user within each node should handle the Onion traffic for that node and (and should forward it to the other users within that node, if it's a multi-user node). This user could be called the \"leader\" for the node. I didn't describe this detail in the paper, but I could add it if you think it would be helpful.\n\n> I think it also implies that channel\n> capacity is no longer really something you can gossip very sensibly --\n\nGiven the above definitions and assumptions, including the use of channel_update_v2 messages, I think you can gossip channel capacity quite reasonably.\n\nAs is shown in the paper, just routing through a logical channel does *not* change its capacity (except for a slight increase due to fees). The only time a channel capacity changes significantly is when it is being resized by being the source or destination of a LN payment. The new capacity will be broadcast in the next weekly channel_update_v2 message. Obviously, there's some potential for an unexpected inability for a channel to route requested payments before the channel_update_v2 message showing a reduced capacity has been received, but nothing actually breaks. Of course, it may be worth sending out a channel_update_v2 message as soon as a channel is resized.\n\n> if you have a factory ((A,B),C,D,E) then every payment through AB to C\n> or D or E will decrease AB's channel capacity.\n\nFirst, let's translate this example into one without factories (as that's the world I'm envisioning). Let's assume we have logical channals ((A,B),C), ((A,B),D) and ((A,B),D).\n\nLet's assume that C sends a payment to some other random user/node G that is routed through AB. In this case, the logical channel between A and B does *not* change capacity (except for growing slightly due to fees)! This is shown in Figures 8 and 9 of the paper (with \"BC\" in those figures playing the role of \"AB\" described here). That's the beauty of using logical, rather than physical, channels in the channel graph.\n\nIt took me a long time to see this and I obviously have not succeeded in explaining it very well. Please let me know if this example isn't clear, in which case I'll try to find a better way of explaining it.\n\n> You could still gossip the\n> capacity of the overall factory, and sum that to get an overall lightning\n> network capacity, of course. But a lot of the ways of simplifying it\n> also make it harder to do all the nice rebalancing.\n\nI think the above approach solves these problems. Please let me know if I've missed something.\n\nFinally, I realize that creating a world without factories doesn't sound like a good solution for scaling Bitcoin. However, I believe hierarchical channels largely solve the problem of resizing channels off-chain. This still leaves the problem of creating channels off-chain, but I don't think we need factories to solve that problem. The key observation is that we don't need to create a factory with *updatable* state in order to create a huge number of channels off-chain. Instead, we just need something that instantiates all of those off-chain channels in a way that guarantees the off-chain UTXOs creating those factories. I think the solution to this simpler problem is Timeout-Trees, but I still need to write that up. In any case, please consider hierarchical channels as being a partial solution to scaling Bitcoin and wait until I can make the case for Timeout-Trees before evaluating whether or not we need factories.\n\n> Anyway, I've tried a few times now to put some thoughts together on that\n> and come up with nothing that I'm happy with, so figured it might be at\n> least worth posing explicitly as a problem...\n\nThanks!\n\nI really appreciate your working through all of these issues.\n\nRegards,\nJohn\n\n[1] https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-February/003470.html"
            },
            {
                "author": "Anthony Towns",
                "date": "2023-04-19T11:42:20",
                "message_text_only": "On Tue, Apr 18, 2023 at 07:17:34PM +0000, jlspc wrote:\n> > One thing that confuses me about the paper is how to think about routing\n> > to a \"channel\" rather than a node -- ie the payment from \"E->FG->A\" where\n> > \"FG\" isn't \"F\" or \"G\", but \"both of them\".\n> Yes, I found it very difficult to think about, and I kept getting confused between concepts like \"user\", \"node\", \"channel\", and \"factory\".\n> The thing that works best for me is to create a clear definition of each of these terms, along with the term \"party\".\n\nOkay, that makes sense. I think it might work better to treat \"node\" as\nsynonymous with \"user\" rather than \"party\" though -- that way you can say\n\"you create a lightning node by running lightning node software such as\nlnd/cln/eclair/etc\". That means not all vertices in the payment routing\nnetwork are nodes; but all vertices in the *gossip* network are nodes,\nso that seems okay.\n\nJust saying \"channel\" (instead of \"logical channel\") and \"utxo/off-chain\nutxo\" (instead of \"physical channel\") might also work okay.\n\n> I also think it's best to imagine a world in which there are hierarchical channels, but there are no \"factories\" per se.\n\nPersonally, I use \"channel factory\" to mean \"anything that lets a\nsingle utxo contain multiple channels between different users, that\ncan be reorganised without going on-chain\", so I think once you've got\nhierarchial channels, you've implicitly got (a variation of) channel\nfactories.\n\n(I'm not sure \"channel factories\" is really the most evocative way of\ndescribing them -- at least when I think of a factory, I think the product\nshould be accessible to everyone; but for channel factories you have to\nbe involved in the factory's original mutlisig to be able to use one of\nits channels. Maybe better to call them \"channel coops\", where you're\ncreating a little commune of friends/allies to work together with each\nother. Could be pronounced like \"workers' co-op\" or like \"chicken coop\",\neither way :)\n\n> * Logical Channel: a layer 2 construct that consists of all of the physical channels owned by a specific pair of parties\n>   - the size (capacity) of a logical channel is the sum of the sizes of their physical channels\n>   - (Footnote: It's possible, with a significant amount of software development work that I in no way discount, to route a payment through a logical channel where the payment traverses multiple physical channels at the same time. This is done by using separate HTLCs, all sharing the same secret, in each of the physical channels that the payment traverses. I can write more about this if that would be helpful.)\n\nI think it might already be interesting to write a BOLT/BLIP for that?\nHaving a single channel backed by multiple on-chain utxos is probably\ninteresting for splicing (adding or spending a utxo while keeping the\nchannel open on the other utxos might be able to be done more simply than\nsplicing in general), and having multiple utxos might let you increase\nsome of your channel limits, eg `max_accepted_htlcs` might be able to\nbe increased to 483*U where U is the number of UTXOs backing the channel.\n\n> > It feels like there's a whole\n> > mass of complications hidden in there from a routing perspective; like how\n> > do you link \"FG\" back with \"F\" and \"G\", how do you decide fees, how do\n> > you communicate fees/max_htlc/etc.\n> Regarding the specific issues you raised:\n> Q: How do you link \"FG\" back with \"F\" and \"G\"?\n> A: In terms of gossiping and the channel graph, you don't\n\nYeah, I think that simplifies things substantially.\n\nI think the main thing that misled me here was the \"CD->E->FG\" payment\nchain -- it doesn't make sense to me why E would want to devote funds\nthat can only be used for rebalancing channels, but not normal payments.\nHaving that be CD->DE->FG seems like it would make much more sense in that\nmodel. (Though, obviously, no one except D and E could necessarily tell\nthe difference between those two scenarios in practice, and just because\nsomething doesn't make sense, doesn't mean nobody will actually do it)\n\nThe other thing was that going from N nodes to C*N channels, then\nre-considering each of the C*N channels (A->B, etc) as also potentially\nbeing nodes and adding an additional K*C*N channels (AB->CD, etc) seemed\nlike it might be quadratic to me. But it's probably not -- C (channels per\nnode) and K (utxos per channel) are probably constant or logarithmic in\nN, so it's probably okay? \n\nOn the other hand, I could see the rebalancing channels not actually\nbeing very useful for routing payments (they require 3+ signatures,\nand may not even be publicly connected to any of the level-1 nodes),\nso it could make sense to just treat them as two different networks,\nwhere regular people doing payments only see the base channels, but\nhigh-availability nodes also find out about the rebalancing channels.\nIf so, then the extra nodes/channels in the rebalancing graph only affect\npeople who can afford to dedicate the resources to storing it anyway,\nso it's probably fine.\n\n> Q: How do you decide fees?\n> Q: How do you communicate fees/max_htlc/etc.?\n\nYep, both these bcome trivial.\n\n> > if you have a factory ((A,B),C,D,E) then every payment through AB to C\n> > or D or E will decrease AB's channel capacity.\n\nI was assuming a payment path using the channels (X->A) and (AB->C)\nhere. But that's not something anyone can pick in this model, unless A\nannounces an (A->AB) path that others can use to link them, and in that\ncase either {A,AB} is a real channel and everything works fine, or it's\na fake one that A and B have negotiated because they're both happy if\nthe AB channel changes capacity randomly.\n\n> Finally, I realize that creating a world without factories doesn't sound like a good solution for scaling Bitcoin. However, I believe hierarchical channels largely solve the problem of resizing channels off-chain.\n\nI think this is probably a lot harder in practice than in theory? If\nyou have an {A,B} channel holding 3 BTC across two hierarchial channels,\n{X:1 BTC, AB:1 BTC} and {Y:1 BTC, AB:2 BTC}, and someone wants to route\n0.5 BTC through X->AB->Y, then that will look something like:\n\n   {X:1, AB:1}    {AB:2, Y:1}\n\n   {X:0.5, XAB:0.5, AB:1}  {AB:2, Y:1}\n\n   {X:0.5, XAB:0.5, AB:1}  {AB:1.5, ABY:0.5 Y:1}\n\nand either:\n\n   {X:1, AB:1}    {AB:2, Y:1}   (on failure)\nor\n   {X:0.5, AB:1.5}    {AB:1.5, Y:1.5}   (on success)\n\nBut what if you're in the middle of routing 2 BTC over the A,B channel\nin the meantime? In that case you need some of the AB payments to be\nconditional on the success path of XAB and the failure path of ABY.\n\nI *think* that's fine, and doesn't involve a combinatorical blowup in\nthe event that you're routing rebalances across multiple off-chain utxos\n-- you just end up splitting your channel across {X+2*Y} utxos where X\nis the number of \"physical\" channels and \"Y\" is the number of pending\nrebalances. But it seems like there's a fair chunk of complexity and\nmaybe some extra round trips (eg, moving a pending HTLC from being\npurely in the AB:2 output to being split across the {XAB:0.5/success and\nABY:0.5/timeout} atomically seems tricky?).\n\n(I figure implementing something eltoo-like via 2-user tunable penalty\nchannels and/or ln-symmetry (let alone splicing, taproot funding\naddresses, and ptlcs) is a sufficient sink for all the available\nengineering effort any time soon, but talking about hierarchial/factory\nthings well in advance of when they could reasonably be implemented is\nfun too)\n\nCheers,\naj"
            },
            {
                "author": "jlspc",
                "date": "2023-04-28T15:57:57",
                "message_text_only": "Replies inline:\n\n> > > One thing that confuses me about the paper is how to think about routing\n> > > to a \"channel\" rather than a node -- ie the payment from \"E->FG->A\" where\n> > > \"FG\" isn't \"F\" or \"G\", but \"both of them\".\n> > Yes, I found it very difficult to think about, and I kept getting confused between concepts like \"user\", \"node\", \"channel\", and \"factory\".\n> > The thing that works best for me is to create a clear definition of each of these terms, along with the term \"party\".\n\n> Okay, that makes sense. I think it might work better to treat \"node\" as\n> synonymous with \"user\" rather than \"party\" though -- that way you can say\n> \"you create a lightning node by running lightning node software such as\n> lnd/cln/eclair/etc\". That means not all vertices in the payment routing\n> network are nodes; but all vertices in the *gossip* network are nodes,\n> so that seems okay.\n\nYes, it's probably best to refer to a user who runs lightning node software as being a \"node\".\n\nOn the other hand, it sounds really awkward to talk about routing in a directed graph without using the word \"node\" in some form. Maybe \"routing node\" for entities in the routing network?\n\n> (I'm not sure \"channel factories\" is really the most evocative way of\n> describing them -- at least when I think of a factory, I think the product\n> should be accessible to everyone; but for channel factories you have to\n> be involved in the factory's original mutlisig to be able to use one of\n> its channels. Maybe better to call them \"channel coops\", where you're\n> creating a little commune of friends/allies to work together with each\n> other. Could be pronounced like \"workers' co-op\" or like \"chicken coop\",\n> either way :)\n\nGood point regarding \"factories\". I like \"channel co-op\" as an alternative.\n\n> > * Logical Channel: a layer 2 construct that consists of all of the physical channels owned by a specific pair of parties\n> >   - the size (capacity) of a logical channel is the sum of the sizes of their physical channels\n> >   - (Footnote: It's possible, with a significant amount of software development work that I in no way discount, to route a payment through a logical channel where the payment traverses multiple physical channels at the same time. This is done by using separate HTLCs, all sharing the same secret, in each of the physical channels that the payment traverses. I can write more about this if that would be helpful.)\n\n> I think it might already be interesting to write a BOLT/BLIP for that?\n> Having a single channel backed by multiple on-chain utxos is probably\n> interesting for splicing (adding or spending a utxo while keeping the\n> channel open on the other utxos might be able to be done more simply than\n> splicing in general), and having multiple utxos might let you increase\n> some of your channel limits, eg `max_accepted_htlcs` might be able to\n> be increased to 483*U where U is the number of UTXOs backing the channel.\n\nSounds good. I'm glad to write something up, but I'm afraid it may take me a few months.\n\n> > > It feels like there's a whole\n> > > mass of complications hidden in there from a routing perspective; like how\n> > > do you link \"FG\" back with \"F\" and \"G\", how do you decide fees, how do\n> > > you communicate fees/max_htlc/etc.\n> > Regarding the specific issues you raised:\n> > Q: How do you link \"FG\" back with \"F\" and \"G\"?\n> > A: In terms of gossiping and the channel graph, you don't\n\n> Yeah, I think that simplifies things substantially.\n\n> I think the main thing that misled me here was the \"CD->E->FG\" payment\n> chain -- it doesn't make sense to me why E would want to devote funds\n> that can only be used for rebalancing channels, but not normal payments.\n\nActually, E's funds in the channels ((C,D),E) and (E,(F,G)) can be used for normal payments. It might not seem attractive to do so, but there may be reasons for doing just that (see below).\n\n> Having that be CD->DE->FG seems like it would make much more sense in that\n> model. (Though, obviously, no one except D and E could necessarily tell\n> the difference between those two scenarios in practice, and just because\n> something doesn't make sense, doesn't mean nobody will actually do it)\n\nI included going from a single-user party to a multi-user party and back to a single-user party, as in E->FG->HI->A in Figure 4 in the paper, just to show the poassibility. I didn't think it would be common, given the extra signatures and fees required. However, I'm now thinking that routing through multi-user parties could be important in practice, even when making normal LN payments between single users. There's a lot more on that idea below.\n\n> The other thing was that going from N nodes to C*N channels, then\n> re-considering each of the C*N channels (A->B, etc) as also potentially\n> being nodes and adding an additional K*C*N channels (AB->CD, etc) seemed\n> like it might be quadratic to me. But it's probably not -- C (channels per\n> node) and K (utxos per channel) are probably constant or logarithmic in\n> N, so it's probably okay?\n\nYep, I'd assume C and K are largely independent of N (and constant or nearly so as the network grows), so that shouldn't be a problem.\n\n> On the other hand, I could see the rebalancing channels not actually\n> being very useful for routing payments (they require 3+ signatures,\n> and may not even be publicly connected to any of the level-1 nodes),\n> so it could make sense to just treat them as two different networks,\n> where regular people doing payments only see the base channels, but\n> high-availability nodes also find out about the rebalancing channels.\n> If so, then the extra nodes/channels in the rebalancing graph only affect\n> people who can afford to dedicate the resources to storing it anyway,\n> so it's probably fine.\n\nIt would be possible to have a separate rebalancing network consisting of multi-user parties only and a base network consisting of single-user parties only. However, that both complicates and limits the rebalancing functionality.\n\nLet's say A and B want to decrease the size of their channel (A,B) using the separate rebalancing network.\n\nThey make a payment on the rebalancing network:\n\nAB->CD->EF->GH->IJ\n\nHowever, there are two problems with this approach:\n\n1) A and B have to find another channel (I,J) that wants to increase its capacity by exactly the same amount (minus fees) to offset the decrease in (A,B). In general, the rebalancing network can move capacity from one base channel (a.k.a., two-user channel or channel with single-user parties) to another one, but it can't increase or decrease the overall capacity of the channels in the base network.\n\n2) The payment AB->CD->EF->IJ not only rebalances channels, it also sends bitcoin from the payer in (A,B) to the payee in (I,J). This would have to be offset by making a corresponding payment (using the base network) from the payee in (I,J) (e.g., I) to the payer in (A,B) (e.g., A) and that offsetting payment would have to be atomic with the rebalancing payment. It's possible to make this work by using the same secret for the payments in the base network and the rebalancing network, but it certainly adds complexity.\n\nIn addition, there are reasons for wanting to include multi-user parties when making regular LN payments (again, see below).\n\nConnecting the level-2 routing nodes with the level-1 routing nodes requires at least some channels that consist of a multi-user party and a single-user party, such as the channel ((C,D),E). Once that's done, the above problems go away and it's possible to increase or decrease the overall capacity of the two-user channels without going on-chain.\n\n> > Finally, I realize that creating a world without factories doesn't sound like a good solution for scaling Bitcoin. However, I believe hierarchical channels largely solve the problem of resizing channels off-chain.\n\n> I think this is probably a lot harder in practice than in theory? If\n> you have an {A,B} channel holding 3 BTC across two hierarchial channels,\n> {X:1 BTC, AB:1 BTC} and {Y:1 BTC, AB:2 BTC}, and someone wants to route\n> 0.5 BTC through X->AB->Y, then that will look something like:\n\n>    {X:1, AB:1}    {AB:2, Y:1}\n\n>    {X:0.5, XAB:0.5, AB:1}  {AB:2, Y:1}\n\n>    {X:0.5, XAB:0.5, AB:1}  {AB:1.5, ABY:0.5 Y:1}\n\n> and either:\n\n>    {X:1, AB:1}    {AB:2, Y:1}   (on failure)\n> or\n>    {X:0.5, AB:1.5}    {AB:1.5, Y:1.5}   (on success)\n\n> But what if you're in the middle of routing 2 BTC over the A,B channel\n> in the meantime? In that case you need some of the AB payments to be\n> conditional on the success path of XAB and the failure path of ABY.\n\n> I *think* that's fine, and doesn't involve a combinatorical blowup in\n> the event that you're routing rebalances across multiple off-chain utxos\n> -- you just end up splitting your channel across {X+2*Y} utxos where X\n> is the number of \"physical\" channels and \"Y\" is the number of pending\n> rebalances. But it seems like there's a fair chunk of complexity and\n> maybe some extra round trips (eg, moving a pending HTLC from being\n> purely in the AB:2 output to being split across the {XAB:0.5/success and\n> ABY:0.5/timeout} atomically seems tricky?).\n\nWow, that's a cool idea!\n\nI hadn't considered having an active HTLC (sending 2 BTC from A to B) that's (partially) funded by a pair of active HTLCs (sending 0.5 BTC from X to Y via the path X->AB->Y). I figured that would be too complex, but I hadn't thought through the details.\n\nIn contrast, I had considered having an active HTLC that's funded by a resolved (either successful or failed) HTLC. This seems important, as the resolved HTLC requires 3+ signatures in order to merge it into a new Commitment transaction, so it might not be possible to get all the signatures right away. For example, dedicated users A and B want to be able to use their newly-gained capacity in the channel (C,(A,B)) after making a payment from casual user C without having to wait for C to update the state of (C,(A,B)).\n\nThe hierarchical channels paper requires that all the funds in an HTLC be provided by a single user, denoted as the \"payer\". As a result, the capital in a hierarchical channel can only be used for a single active HTLC at a single level at a time. This requires multiplexing the capital between level-1 channel HTLCs and level-2 channel HTLCs, but I figured that was OK as the level-2 channels would mainly be used for rebalancing, which should be far less frequent than level-1 payments (and the rebalancing could wait until a path was available). Thus, one doesn't have to allow an active HTLC to be funded by a pair of active HTLCs in order to have flexible off-chain rebalancing of channels.\n\nHowever, as you point out, it should be possible to have an active HTLC be funded by a pair of active HTLCs. The thing that's amazing about this is that the *same capital* is used for routing at two different levels in the hierarchy simultaneously! In other words, in addition to routing normal LN payments through single-user parties, it's possible to simultaneously route independent normal LN payments through multi-user parties by re-using the *same capital*.\n\nSure, the payments through multi-user parties require more signatures, so that could slow them down or complicate them, but the potential to maybe double the routing fees that can be generated from a given unit of capital (in addition to enabling off-chain rebalancing) sounds pretty compelling if the cost of capital is high.\n\nAs you noted, making this work atomically is tricky. Let's consider your example again, using slightly modified notation.\n\nInitially, there's an {A,B} channel holding 3 BTC across two hierarchical channels:\n\nState 0:\n\t{X:1 BTC, {A:0.5 BTC, B:0.5 BTC}}\n\tand\n\t{{A:2 BTC, B:0 BTC}, Y:1 BTC}\n\nFirst, A initiates a payment of 2 BTC with secret s1 via B in the hierarchical channel with Y:\n\nState 1:\n\t{X:1 BTC, {A:0.5 BTC, B:0.5 BTC}}\n\tand\n\t{{A_or_s1_B:2 BTC}, Y:1 BTC}\n\nThen, while this payment is pending, X sends 0.5 BTC with secret s2 to Y via the following states:\n\nState 2:\n\t{X:0.5 BTC, X_or_s2_{A_or_s1_B:0.5 BTC}, {A:0.5 BTC, B:0.5 BTC}}\n\tand\n\t{{A_or_s1_B:2 BTC}, Y:1 BTC}\n\nState 3:\n\t{X:0.5 BTC, X_or_s2_{A_or_s1_B:0.5 BTC}, {A:0.5 BTC, B:0.5 BTC}}\n\tand\n\t{{A_or_s1_B:1.5 BTC}, {A_or_s1_B:0.5 BTC}_or_s2_Y:0.5 BTC, Y:1 BTC}\n\n>From this point, there are 8 possibilities in terms of whether the HTLCs succeed or fail, and in which order they do so.\n\nFor example, if s1 is revealed and then the payment with secret s2 times out, we get:\n\nState 4:\n\t{X:0.5 BTC, X_or_s2_{B:0.5 BTC}, {A:0.5 BTC, B:0.5 BTC}}\n\tand\n\t{{B:1.5 BTC}, {B:0.5 BTC}_or_s2_Y:0.5 BTC, Y:1 BTC}\n\nState 5:\n\t{X:0.5 BTC, X:0.5 BTC, {A:0.5 BTC, B:0.5 BTC}}\n\tand\n\t{{B:1.5 BTC}, {B:0.5 BTC}, Y:1 BTC}\n\nState 6:\n\t{X:1.0 BTC, {A:0.5 BTC, B:0.5 BTC}}\n\tand\n\t{{A:0 BTC, B:2.0 BTC}, Y:1 BTC}\n\nAlternatively, if s2 is revealed and then s1 is revealed, we get:\n\nState 4':\n\t{X:0.5 BTC, {A_or_s1_B:0.5 BTC}, {A:0.5 BTC, B:0.5 BTC}}\n\tand\n\t{{A_or_s1_B:1.5 BTC}, Y:0.5 BTC, Y:1 BTC}\n\nState 5':\n\t{X:0.5 BTC, {B:0.5 BTC}, {A:0.5 BTC, B:0.5 BTC}}\n\tand\n\t{{B:1.5 BTC}, Y:0.5 BTC, Y:1 BTC}\n\nState 6':\n\t{X:0.5 BTC, {A:0.5 BTC, B:1 BTC}}\n\tand\n\t{{A:0 BTC, B:1.5 BTC}, Y:1.5 BTC}\n\nThe trickiest step is defining State 2. When A and B get the HTCL offered by X with secret s2, A and B figure out what they're going to give up in the hierarchical channel with Y in case the payment from X succeeds. Given that all of A's and B's capital in {{A_or_s1_B:2 BTC}, Y:1 BTC} is in the HTLC with secret s1, they take 0.5 BTC of that HTLC and add it as the payout from secret s2 in the channel with X to obtain State 2. Then, they update the channel with Y to obtain State 3.\n\nThis seems to address the atomicity issue. However, there are a couple other details to address in the hierarchical channel protocol.\n\nFirst, in the adaptation of the FFO protocol to hierarchical channels, the \"payee\" for an HTLC is the user that must provide the HTLC's secret with an HTLC-kickoff transaction (see Figure 14 in the paper). However, when the HTLC pays to a lower-level HTLC, there is no single \"payee\" that can be determined. This could be addressed by enabling both users that could be payees to reveal the HTLC's secret with an HTLC-kickoff transaction followed by an HTLC-success transaction (note that this doubles the number of HTLC-payment transactions that are required).\n\nSecond, in going from HTLCs to PTLCs, the payee has to create a secret that's subtracted from the secret that's revealed at the payment's next hop. The challenge is how to define a secret that depends on multiple potential payees' secrets. I think it may be possible to solve this by having all potential payees at hop i create their own secret, define the overall secret at hop i as being the sum of the potential payees' secrets (after protecting against key/secret cancellation), and sharing partial signatures between potential payees at hop i such that each potential payee just needs to get hop (i+1)'s secret in order to produce hop (i)'s overall secret, but I haven't worked through the details.\n\nTo be clear, the idea of having an active HTLC that's funded by a pair of active HTLCs is your idea, and it's very interesting. We don't need to support this in order to resize channels off-chain, but it does allow a given unit of capital to facilitate two independent payments simultaneously, which is amazing!\n\n> (I figure implementing something eltoo-like via 2-user tunable penalty\n> channels and/or ln-symmetry (let alone splicing, taproot funding\n> addresses, and ptlcs) is a sufficient sink for all the available\n> engineering effort any time soon, but talking about hierarchial/factory\n> things well in advance of when they could reasonably be implemented is\n> fun too)\n\nThat makes sense.\n\nI'm also hoping that a good understanding of what's possible without changing Bitcoin, plus what's enabled with changes like CTV and/or APO, will help inform any future changes to Bitcoin's consensus rules.\n\nRegards,\nJohn"
            }
        ],
        "thread_summary": {
            "title": "Resizing Lightning Channels Off-Chain With Hierarchical Channels",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "jlspc",
                "Anthony Towns"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 69473
        }
    },
    {
        "title": "[Lightning-dev] Proposed changes to the splicing specification",
        "thread_messages": [
            {
                "author": "Antoine Riard",
                "date": "2023-04-03T17:01:39",
                "message_text_only": "Hi Bastien,\n\nThanks for the update on the state of splicing.\n\n> We've also discovered that implementing 0-conf splicing is tricky: you\n> need to be very careful about scenarios where your peer force-closes\n> using an *inactive* commitment that ends up double-spending what you\n> think is the only *active* commitment but is unconfirmed. We'd be happy\n> to discuss that in more details with other implementers to reduce the\n> risk of introducing new vulnerabilities when shipping that feature.\n\nI think halting 0-conf splicing is pretty easy for a counterparty by\nabusing Bitcoin Core mempool replacement rule #5 on the maximum number of\noriginal transactions replaced.\n\nLet's say you have Alice with 10% of the channel capacity as a balance in\nthe \"inactive\" commitment and the 90% remaining in favor of Bob. Bob has\ninitiated a splice out of 70% of the channel capacity. On the interactive\ntransaction, Alice adds 4 unrelated confirmed inputs and then broadcasts 4\nchains of 25 unconfirmed transactions from those inputs.\n\nWhen Bob broadcasts the splice-out, it should be rejected by the network\nmempools on the grounds of RBF rule #5, whatever the absolute fee and\nfeerate. So the \"0-conf\" splicing might be maintained under risk of\ndouble-spend by your counterparty for a while.\n\nIt sounds like Bob's splice out funds should be segregated until the\ncorresponding \"active commitment\" is confirmed, i.e no use to fund another\nchannel,\nwith inbound/outbound HTLC flows.\n\nBest,\nAntoine\n\nLe lun. 3 avr. 2023 \u00e0 00:25, Bastien TEINTURIER <bastien at acinq.fr> a \u00e9crit :\n\n> Good morning list,\n>\n> As some of you may know, we've been hard at work experimenting with\n> splicing [1]. Splicing is a complex feature with a large design space.\n> It was interesting to iterate on two separate implementations (eclair\n> and cln) and discover the pain points, edge cases and things that could\n> be improved in the protocol specification.\n>\n> After a few months trying out different approaches, we'd like to share\n> changes that we believe make the splicing protocol simpler and more\n> robust.\n>\n> We call \"active commitments\" the set of valid commitment transactions to\n> which updates must be applied. While one (or more) splices are ongoing,\n> there is more than one active commitment. When signing updates, we send\n> one `commitment_signed` message per active commitment. We send those\n> messages in the order in which the corresponding funding transactions\n> have been created, which lets the receiver implicitly match every\n> `commitment_signed` to their respective funding transaction.\n>\n> Once we've negotiated a new splice and reached the signing steps of the\n> interactive-tx protocol, we send a single `commitment_signed` for that\n> new commitment. We don't revoke the previous commitment(s), as this adds\n> an unnecessary step. Conceptually, we're simply adding a new commitment\n> to our active commitments set.\n>\n> A sample flow will look like this:\n>\n>    Alice                           Bob\n>      |             stfu             |\n>      |----------------------------->|\n>      |             stfu             |\n>      |<-----------------------------|\n>      |          splice_init         |\n>      |----------------------------->|\n>      |          splice_ack          |\n>      |<-----------------------------|\n>      |                              |\n>      |       <interactive-tx>       |\n>      |<---------------------------->|\n>      |                              |\n>      |         tx_complete          |\n>      |----------------------------->|\n>      |         tx_complete          |\n>      |<-----------------------------|\n>      |         commit_sig           | Sign the new commitment.\n>      |----------------------------->|\n>      |         commit_sig           | Sign the new commitment.\n>      |<-----------------------------|\n>      |        tx_signatures         |\n>      |----------------------------->|\n>      |        tx_signatures         |\n>      |<-----------------------------|\n>      |                              |\n>      |       update_add_htlc        | Alice and Bob use the channel while\n> the splice transaction is unconfirmed.\n>      |----------------------------->|\n>      |       update_add_htlc        |\n>      |----------------------------->|\n>      |         commit_sig           | Sign the old commitment.\n>      |----------------------------->|\n>      |         commit_sig           | Sign the new commitment.\n>      |----------------------------->|\n>      |       revoke_and_ack         |\n>      |<-----------------------------|\n>      |         commit_sig           | Sign the old commitment.\n>      |<-----------------------------|\n>      |         commit_sig           | Sign the new commitment.\n>      |<-----------------------------|\n>      |       revoke_and_ack         |\n>      |----------------------------->|\n>      |                              |\n>      |        splice_locked         | The splice transaction confirms.\n>      |----------------------------->|\n>      |        splice_locked         |\n>      |<-----------------------------|\n>      |                              |\n>      |       update_add_htlc        | Alice and Bob can use the channel\n> and forget the old commitment.\n>      |----------------------------->|\n>      |         commit_sig           | Sign the new commitment.\n>      |----------------------------->|\n>      |       revoke_and_ack         |\n>      |<-----------------------------|\n>      |         commit_sig           | Sign the new commitment.\n>      |<-----------------------------|\n>      |       revoke_and_ack         |\n>      |----------------------------->|\n>      |                              |\n>\n> You can find many more details and sample flows in [2].\n>\n> We require nodes to store data about the funding transaction as soon as\n> they send their `commitment_signed` message. This lets us handle every\n> disconnection scenario safely, allowing us to either resume the signing\n> steps on reconnection or forget the funding attempt. This is important\n> because if peers disagree on the set of active commitments, this will\n> lead to a force-close. In order to achieve that, we only need to add\n> the `next_funding_txid` to the `channel_reestablish` message, and fill\n> it when we're missing signatures from our peer. Again, you can find more\n> details and sample flows in [2].\n>\n> Finally, after trying various approaches, we believe that the funding\n> amounts that peer exchange in `splice_init` and `splice_ack` should be\n> relative amounts based on each peer's current channel balance.\n>\n> If Alice sends `funding_amount = 200_000 sats`, it means she will be\n> adding 200 000 sats to the channel's capacity (splice-in).\n>\n> If she sends `funding_amount = -50_000 sats`, it means she will be\n> removing 50 000 sats from the channel's capacity (splice-out).\n>\n> This makes it easier to compute the new channel balances (otherwise we\n> have to deal with millisatoshi to satoshi truncation) and better matches\n> the UX that node operators are expecting, which means there is less need\n> to glue code between the RPC exposed to the node operator and the actual\n> underlying protocol.\n>\n> We've also discovered that implementing 0-conf splicing is tricky: you\n> need to be very careful about scenarios where your peer force-closes\n> using an *inactive* commitment that ends up double-spending what you\n> think is the only *active* commitment but is unconfirmed. We'd be happy\n> to discuss that in more details with other implementers to reduce the\n> risk of introducing new vulnerabilities when shipping that feature.\n>\n> Cheers,\n> Bastien\n>\n> [1] https://github.com/lightning/bolts/pull/863\n> [2] https://gist.github.com/t-bast/1ac31f4e27734a10c5b9847d06db8d86\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20230403/ef027b9b/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2023-04-04T11:15:09",
                "message_text_only": "Hi ariard and t-bast,\n\nI would like to point out that spends from swap-in-potentiam addresses are safely 0-conf if Bob is the other signatory in the swap-in-potentiam address.\n\nOn the other hand swap-in-potentiam is arguably cheating, since sending to a swap-in-potentiam address is actually a channel open of a Spilman-like channel with `OP_CSV` instead of `OP_CLTV`.\n\nThis implicit protection against 0-conf double-spend risk that swap-in-potentiam provides, exists for all operations that move from onchain to Lightning, including: channel opens, onchain-to-offchain swap, splice-in.\n\nI should also note that the UTXOs with swap-in-potentiam addressed do need to be confirmed.\n\n--\n\nFor cases where the one doing splice-in is an LSP and the other side is a client of that LSP, also consider this proposal: https://github.com/BitcoinAndLightningLayerSpecs/lsp/pull/24\n\nWhile it is designed for 0-conf channel funding, the actual protocol is generic enough that it can be used where there is double-spend risk from an LSP, that the client wants to protect against.\nThis can applied to splice-in and channel factory construction, as the protocol is simply a promise \"I the LSP will do my best to get the transaction with this TXID confirmed before some future blockheight, so you the client can rest assured that even if it is unconfirmed now (0-conf) you can always rely on it being confirmed later.\"\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2023-04-04T12:27:50",
                "message_text_only": "Good morning again ariard and t-bast,\n\n> \n> For cases where the one doing splice-in is an LSP and the other side is a client of that LSP, also consider this proposal: https://github.com/BitcoinAndLightningLayerSpecs/lsp/pull/24\n> \n> While it is designed for 0-conf channel funding, the actual protocol is generic enough that it can be used where there is double-spend risk from an LSP, that the client wants to protect against.\n> This can applied to splice-in and channel factory construction, as the protocol is simply a promise \"I the LSP will do my best to get the transaction with this TXID confirmed before some future blockheight, so you the client can rest assured that even if it is unconfirmed now (0-conf) you can always rely on it being confirmed later.\"\n\nActually, given that the LSP is held liable if the TXID never confirms, and the splice TXID has as input the previous funding txo, this is actually risky for the LSP.\n\nEven if the client has given revocation keys for all states dependent on the previous funding txo, the client can still post, and have confirmed, a revoked state.\nThis prevents the LSP from ever getting the splice TXID confirmed.\nThe client loses all its funds in the channel, but in exchange the LSP is held liable for not getting the splice TXID confirmed and the LSP reputation is destroyed.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Dustin Dettmer",
                "date": "2023-04-04T19:14:46",
                "message_text_only": "This all works for me, I will update my implementation to be compatible\nwith this approach.\n\nPerhaps we should pick another name than `funding_amount` though?\n\nThe current spec (for `splice` & `splice_ack`) proposal uses\n* [`u64`:`funding_satoshis`]\n\nHow about we go with something like:\n* [`s64`:`relative_satoshis`]\n\nIn this new mid-splice single commit_sig approach, `tx_signature` will be a\nlittle\noverloaded as the commit ACK as well as the ending of STFU mode.\n\nWhich should work fine but we will need to modify the spec to no longer\n\"MUST\" reply\n`revoke_and_ack` to `commitment_signed` with a carve out for this special\ncase.\n\n\n\nOn Sun, Apr 2, 2023 at 7:25\u202fPM Bastien TEINTURIER <bastien at acinq.fr> wrote:\n\n> Good morning list,\n>\n> As some of you may know, we've been hard at work experimenting with\n> splicing [1]. Splicing is a complex feature with a large design space.\n> It was interesting to iterate on two separate implementations (eclair\n> and cln) and discover the pain points, edge cases and things that could\n> be improved in the protocol specification.\n>\n> After a few months trying out different approaches, we'd like to share\n> changes that we believe make the splicing protocol simpler and more\n> robust.\n>\n> We call \"active commitments\" the set of valid commitment transactions to\n> which updates must be applied. While one (or more) splices are ongoing,\n> there is more than one active commitment. When signing updates, we send\n> one `commitment_signed` message per active commitment. We send those\n> messages in the order in which the corresponding funding transactions\n> have been created, which lets the receiver implicitly match every\n> `commitment_signed` to their respective funding transaction.\n>\n> Once we've negotiated a new splice and reached the signing steps of the\n> interactive-tx protocol, we send a single `commitment_signed` for that\n> new commitment. We don't revoke the previous commitment(s), as this adds\n> an unnecessary step. Conceptually, we're simply adding a new commitment\n> to our active commitments set.\n>\n> A sample flow will look like this:\n>\n>    Alice                           Bob\n>      |             stfu             |\n>      |----------------------------->|\n>      |             stfu             |\n>      |<-----------------------------|\n>      |          splice_init         |\n>      |----------------------------->|\n>      |          splice_ack          |\n>      |<-----------------------------|\n>      |                              |\n>      |       <interactive-tx>       |\n>      |<---------------------------->|\n>      |                              |\n>      |         tx_complete          |\n>      |----------------------------->|\n>      |         tx_complete          |\n>      |<-----------------------------|\n>      |         commit_sig           | Sign the new commitment.\n>      |----------------------------->|\n>      |         commit_sig           | Sign the new commitment.\n>      |<-----------------------------|\n>      |        tx_signatures         |\n>      |----------------------------->|\n>      |        tx_signatures         |\n>      |<-----------------------------|\n>      |                              |\n>      |       update_add_htlc        | Alice and Bob use the channel while\n> the splice transaction is unconfirmed.\n>      |----------------------------->|\n>      |       update_add_htlc        |\n>      |----------------------------->|\n>      |         commit_sig           | Sign the old commitment.\n>      |----------------------------->|\n>      |         commit_sig           | Sign the new commitment.\n>      |----------------------------->|\n>      |       revoke_and_ack         |\n>      |<-----------------------------|\n>      |         commit_sig           | Sign the old commitment.\n>      |<-----------------------------|\n>      |         commit_sig           | Sign the new commitment.\n>      |<-----------------------------|\n>      |       revoke_and_ack         |\n>      |----------------------------->|\n>      |                              |\n>      |        splice_locked         | The splice transaction confirms.\n>      |----------------------------->|\n>      |        splice_locked         |\n>      |<-----------------------------|\n>      |                              |\n>      |       update_add_htlc        | Alice and Bob can use the channel\n> and forget the old commitment.\n>      |----------------------------->|\n>      |         commit_sig           | Sign the new commitment.\n>      |----------------------------->|\n>      |       revoke_and_ack         |\n>      |<-----------------------------|\n>      |         commit_sig           | Sign the new commitment.\n>      |<-----------------------------|\n>      |       revoke_and_ack         |\n>      |----------------------------->|\n>      |                              |\n>\n> You can find many more details and sample flows in [2].\n>\n> We require nodes to store data about the funding transaction as soon as\n> they send their `commitment_signed` message. This lets us handle every\n> disconnection scenario safely, allowing us to either resume the signing\n> steps on reconnection or forget the funding attempt. This is important\n> because if peers disagree on the set of active commitments, this will\n> lead to a force-close. In order to achieve that, we only need to add\n> the `next_funding_txid` to the `channel_reestablish` message, and fill\n> it when we're missing signatures from our peer. Again, you can find more\n> details and sample flows in [2].\n>\n> Finally, after trying various approaches, we believe that the funding\n> amounts that peer exchange in `splice_init` and `splice_ack` should be\n> relative amounts based on each peer's current channel balance.\n>\n> If Alice sends `funding_amount = 200_000 sats`, it means she will be\n> adding 200 000 sats to the channel's capacity (splice-in).\n>\n> If she sends `funding_amount = -50_000 sats`, it means she will be\n> removing 50 000 sats from the channel's capacity (splice-out).\n>\n> This makes it easier to compute the new channel balances (otherwise we\n> have to deal with millisatoshi to satoshi truncation) and better matches\n> the UX that node operators are expecting, which means there is less need\n> to glue code between the RPC exposed to the node operator and the actual\n> underlying protocol.\n>\n> We've also discovered that implementing 0-conf splicing is tricky: you\n> need to be very careful about scenarios where your peer force-closes\n> using an *inactive* commitment that ends up double-spending what you\n> think is the only *active* commitment but is unconfirmed. We'd be happy\n> to discuss that in more details with other implementers to reduce the\n> risk of introducing new vulnerabilities when shipping that feature.\n>\n> Cheers,\n> Bastien\n>\n> [1] https://github.com/lightning/bolts/pull/863\n> [2] https://gist.github.com/t-bast/1ac31f4e27734a10c5b9847d06db8d86\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20230404/925b7825/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Proposed changes to the splicing specification",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Dustin Dettmer",
                "Antoine Riard"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 18184
        }
    },
    {
        "title": "[Lightning-dev] Splice Lock Race Condition Solution",
        "thread_messages": [
            {
                "author": "Dustin Dettmer",
                "date": "2023-04-04T19:45:03",
                "message_text_only": "Hey,\n\nIn testing the `splice_locked` workflow I discovered a race condition which\nis critical we solve correctly. The core problem happens if any channel\nactivity occurs in the time after `splice_locked` is sent and before\n`splice_locked` is received.\n\n`splice_locked` is defined as being locked once it is both sent and\nreceived. It is fairly trivial to build a test case for this -- have a node\ncontinually spamming payments while `splice_lock`ing is occurring and the\nrace condition will trigger relatively often.\n\nThe race condition effects two messages in particular: `commitment_signed`\nand `announcement_signatures`. Below is an example of how it occurs with\ncommitment but the flow is essentially the same for announcement:\n\nLegend:\nItem -> means sent\nItem <- means received\nChan X (implies a channel at block height X)\n(Since these happen at different times)\nSplice locked race condition example\nNode A. Node B.\n* Channel starts at block height 100\nsplice_locked ->\n<- splice_locked\n<- commitments_signed (Chan 100)\n-> splice_locked\nNode B now considers splice locked (Chan 106)\n<- commitments_signed (Chan 106)\nsplice_locked <-\nNode A now considers splice locked (Chan 106)\ncommitments_signed <- (Chan 100)\ncommitments_signed <- (Chan 106)\nNode A considers the commitments_signed for Chan 100 invalid.\nThe commitments_signed for Chan 106 is, however, valid.\nThis example uses commitments_signed but remains a problem for any message\nthat depends on channel state.\n\nThe solution requires the temporary storing of two items:\n* [scid] last_short_channel_id (the pre-splice short channel id)\n* [bool] splice_await_commitment_succcess\n\nAfter sending & receiving `splice_locked` (so called 'mutual splice lock),\nthe last_short_channel_id should be set to the pre-splice short channel id\nand splice_await_commitment_succcess should be flagged to true.\n\nIf an `announcement_signatures` is received with an scid matching\n`last_short_channel_id` the message should be ignored and the channel\nconnection should not be aborted (as it normally would).\n\nIf a `commitment_signed` message is received with the\ntlv splice_info->splice_channel_id set to something other than the\nsuccessfully confirmed splice channel_id, the message should be ignored.\n\nOnce a revoke_and_ack is successfully sent OR received,\n`last_short_channel_id` and `splice_await_commitment_succcess` should be\nreset and normal validation of `announcement_signatures` and\n`commitment_signed` should be resumed.\n\nThis solves the race condition while preserving as strict a validation of\nmessages as possible and removes the need to add new fields to these\nmessages.\n\nCheers,\nDusty\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20230404/15da6a65/attachment-0001.html>"
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2023-04-06T15:49:46",
                "message_text_only": "Hi Dustin,\n\nI believe this is the scenario I described in [1]?\n\nI haven't looked at the `announcement_signatures` case yet, but at least\nfor the `commit_sig` case this should never be an issue. It only means\nthat sometimes, after sending `splice_locked`, you will receive some\n`commit_sig` messages that are for commitments that you don't care about\nanymore. You should be able to safely ignore those `commit_sig`. I have\nprovided more details in the gist linked.\n\nLet me know if I'm missing something, but I believe this is simply an\nedge case that implementations need to correctly handle, not a protocol\nissue? Or maybe I'm not understanding the scenario correctly?\n\nBy the way, I find your notation a bit hard to follow...I think that we\nreally need to detail the exact message flow (like I did in the linked\ngist) to be able to explain protocol issues, otherwise there's always\na risk that people think about a slightly different message flow, which\nmeans we'll just talk past each other...\n\nCheers,\nBastien\n\n[1]\nhttps://gist.github.com/t-bast/1ac31f4e27734a10c5b9847d06db8d86#multiple-splices-with-racy-splice_locked\n\n\nLe jeu. 6 avr. 2023 \u00e0 02:40, Dustin Dettmer <dustin at koinkeep.com> a \u00e9crit :\n\n> Hey,\n>\n> In testing the `splice_locked` workflow I discovered a race condition\n> which is critical we solve correctly. The core problem happens if any\n> channel activity occurs in the time after `splice_locked` is sent and\n> before `splice_locked` is received.\n>\n> `splice_locked` is defined as being locked once it is both sent and\n> received. It is fairly trivial to build a test case for this -- have a node\n> continually spamming payments while `splice_lock`ing is occurring and the\n> race condition will trigger relatively often.\n>\n> The race condition effects two messages in particular: `commitment_signed`\n> and `announcement_signatures`. Below is an example of how it occurs with\n> commitment but the flow is essentially the same for announcement:\n>\n> Legend:\n> Item -> means sent\n> Item <- means received\n> Chan X (implies a channel at block height X)\n> (Since these happen at different times)\n> Splice locked race condition example\n> Node A. Node B.\n> * Channel starts at block height 100\n> splice_locked ->\n> <- splice_locked\n> <- commitments_signed (Chan 100)\n> -> splice_locked\n> Node B now considers splice locked (Chan 106)\n> <- commitments_signed (Chan 106)\n> splice_locked <-\n> Node A now considers splice locked (Chan 106)\n> commitments_signed <- (Chan 100)\n> commitments_signed <- (Chan 106)\n> Node A considers the commitments_signed for Chan 100 invalid.\n> The commitments_signed for Chan 106 is, however, valid.\n> This example uses commitments_signed but remains a problem for any message\n> that depends on channel state.\n>\n> The solution requires the temporary storing of two items:\n> * [scid] last_short_channel_id (the pre-splice short channel id)\n> * [bool] splice_await_commitment_succcess\n>\n> After sending & receiving `splice_locked` (so called 'mutual splice lock),\n> the last_short_channel_id should be set to the pre-splice short channel id\n> and splice_await_commitment_succcess should be flagged to true.\n>\n> If an `announcement_signatures` is received with an scid matching\n> `last_short_channel_id` the message should be ignored and the channel\n> connection should not be aborted (as it normally would).\n>\n> If a `commitment_signed` message is received with the\n> tlv splice_info->splice_channel_id set to something other than the\n> successfully confirmed splice channel_id, the message should be ignored.\n>\n> Once a revoke_and_ack is successfully sent OR received,\n> `last_short_channel_id` and `splice_await_commitment_succcess` should be\n> reset and normal validation of `announcement_signatures` and\n> `commitment_signed` should be resumed.\n>\n> This solves the race condition while preserving as strict a validation of\n> messages as possible and removes the need to add new fields to these\n> messages.\n>\n> Cheers,\n> Dusty\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20230406/058383a0/attachment-0001.html>"
            },
            {
                "author": "Dusty Daemon",
                "date": "2023-04-06T16:14:41",
                "message_text_only": ">\n> I haven't looked at the `announcement_signatures` case yet, but at least\n> for the `commit_sig` case this should never be an issue.\n>\nYup the issue is the same for `announcement_signatures`. Storing the\nlast_short_channel_id is key here so you know which announcement\nmessage you can safely ignore and which are considered errors. This\nbehavior should be enacted until sending OR receiving `revoke_and_ack`.\n\n\n> It only means\n> that sometimes, after sending `splice_locked`, you will receive some\n> `commit_sig` messages that are for commitments that you don't care about\n> anymore. You should be able to safely ignore those `commit_sig`. I have\n> provided more details in the gist linked.\n>\nYup you should ignore invalid commit_sigs for this brief period of time but\nthen\ngo back to rejecting invalid commit_sigs after sending OR receiving\n`revoke_and_ack`.\n\n\n> Let me know if I'm missing something, but I believe this is simply an\n> edge case that implementations need to correctly handle, not a protocol\n> issue? Or maybe I'm not understanding the scenario correctly?\n>\nIt is a critical detail to implement correctly. Implementations without\ngood test coverage can easily ship releases that will break / force close\nrandomly during the splice lock process. What's worse is this effects\nthe larger more valuable/busy routing nodes more often and is easy to\nmiss on a simple regtest node \ud83d\ude33.\n\nBy the way, I find your notation a bit hard to follow...I think that we\n> really need to detail the exact message flow (like I did in the linked\n> gist) to be able to explain protocol issues, otherwise there's always\n> a risk that people think about a slightly different message flow, which\n> means we'll just talk past each other...\n>\nThe original gist from back in January is here:\nhttps://gist.github.com/ddustin/7ee222eb31c3eac5b141c991c0937fae\n\nHappy to add more details but the example is accurate to exactly the\nmessages sent during this time. Confirmed it with actual tests as well.\n\nIs there some message that it looks like I missed here? If it helps I can\ngive you an actual log message flow from the real tests, but honestly,\nthey just make it more confusing to understand \ud83e\udd37.\n\nIt might be simpler to follow by working backwards from this solution:\nhttps://gist.github.com/ddustin/017aeadfbf34d2fcd950f1238614afe2\n\nMy original proposal from late January ^ 100% solves the issue but\nadds a lock on the connection via an extra STFU step.\n\nMy current proposal is essentially \"let's allow the race condition and\nobserve which things become invalid during it.\" I settled on two things\ninvalid events that occur:\n* A stale `commitments_signed` message (bundle) with extra signatures\n* A stale `announcement_sigs` message for the pre-splice channel\n\nAn \"easy\" solution an implementation could do is allow any invalid\n`commitments_signed` or `announcement_sigs` to come through\nand ignore them without warning or error. This \"works\" but leaves the\nnode in a messy state where actual errors are being squelched\nand opens up a potential DoS issue.\n\nSo the ideal solution is to allow a certain class of 'stale' messages\nfor a period of time, that time being from:\nA) mutual_splice_locked (the moment we have both sent & received\n`splice_locked`)\nB) A successful `commitment_signed` <-> `revoke_and_ack` round trip (in\neither direction)\n\nThe definition of A is pretty straightforward and we need to detect\nmutual_splice_lock anyway so that's easy.\n\nThe definition of B can be a couple of things but the simplest is I believe\nthe sending OR receiving of `revoke_and_ack`.\n\nIs it a little more work to implement it this way? Yeah. But I think the\neffort\nis worth it to make the protocol & our nodes more robust.\n\nCheers,\nDusty\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20230406/cee4770b/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Splice Lock Race Condition Solution",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Dustin Dettmer",
                "Bastien TEINTURIER",
                "Dusty Daemon"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 11092
        }
    },
    {
        "title": "[Lightning-dev] A new Bitcoin implementation integrated with Core Lightning",
        "thread_messages": [
            {
                "author": "Michael Folkson",
                "date": "2023-04-18T17:06:14",
                "message_text_only": "Any thoughts on this from the Core Lightning contributors? The way I see it with upcoming proposed changes to default policy (primarily though not exclusively for Lightning) and a soft fork activation attempt of APO/APOAS (primarily though not exclusively for Lightning) that a tighter coupling between the full node and the Lightning node could eventually make sense. In a world where transaction fees were much higher you'd think almost every full node would also want to be a Lightning node and so the separation of concerns would make less sense. Having two separate P2P networks and two separate P2P protocols also wouldn't make much sense in this scenario. You could obviously still opt out of Lightning P2P messages if you weren't interested in Lightning.\n\nThe alternative would be just to focus on Knots style consensus compatible forks of Core with limited additional functionality. But I think we've reached the point of no return on Core dominance and not having widely used \"distros\". As the ecosystem scales systems and processes should be constantly evolving and improving and to me if anything Core's seem to be going backwards.\n\nThanks\nMichael\n\n--\nMichael Folkson\nEmail: michaelfolkson at [protonmail.com](http://protonmail.com/)\nKeybase: michaelfolkson\nPGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n\n------- Original Message -------\nOn Saturday, January 14th, 2023 at 20:26, Michael Folkson <michaelfolkson at protonmail.com> wrote:\n\n> I tweeted this [0] back in November 2022.\n>\n> \"With the btcd bugs and the analysis paralysis on a RBF policy option in Core increasingly thinking @BitcoinKnots and consensus compatible forks of Core are the future. Gonna chalk that one up to another thing @LukeDashjr was right about all along.\"\n>\n> A new bare bones Knots style Bitcoin implementation (in C++/C) integrated with Core Lightning was a long term idea I had (and presumably many others have had) but the dysfunction on the Bitcoin Core project this week (if anything it has been getting worse over time, not better) has made me start to take the idea more seriously. It is clear to me that the current way the Bitcoin Core project is being managed is not how I would like an open source project to be managed. Very little discussion is public anymore and decisions seem to be increasingly made behind closed doors or in private IRC channels (to the extent that decisions are made at all). Core Lightning seems to have the opposite problem. It is managed effectively in the open (admittedly with fewer contributors) but doesn't have the eyeballs or the usage that Bitcoin Core does. Regardless, selfishly I at some point would like a bare bones Bitcoin and Lightning implementation integrated in one codebase. The Bitcoin Core codebase has collected a lot of cruft over time and the ultra conservatism that is needed when treating (potential) consensus code seems to permeate into parts of the codebase that no one is using, definitely isn't consensus code and should probably just be removed.\n>\n> The libbitcoinkernel project was (is?) an attempt to extract the consensus engine out of Core but it seems like it won't achieve that as consensus is just too slippery a concept and Knots style consensus compatible codebase forks of Bitcoin Core seem to still the model. To what extent you can safely chop off this cruft and effectively maintain this less crufty fork of Bitcoin Core also isn't clear to me yet.\n>\n> Then there is the question of whether it makes sense to mix C and C++ code that people have different views on. C++ is obviously a superset of C but assuming this merging of Bitcoin Core and Core Lightning is/was the optimal final destination it surely would have been better if Core Lightning was written in the same language (i.e. with classes) as Bitcoin Core.\n>\n> I'm just floating the idea to (hopefully) hear from people who are much more familiar with the entirety of the Bitcoin Core and Core Lightning codebases. It would be an ambitious long term project but it would be nice to focus on some ambitious project(s) (even if just conceptually) for a while given (thankfully) there seems to be a lull in soft fork activation chaos.\n>\n> Thanks\n> Michael\n>\n> [0]: https://twitter.com/michaelfolkson/status/1589220155006910464?s=20&t=GbPm7w5BqS7rS3kiVFTNcw\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at [protonmail.com](http://protonmail.com/)\n> Keybase: michaelfolkson\n> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20230418/a61cc0c7/attachment-0001.html>"
            },
            {
                "author": "niftynei",
                "date": "2023-04-24T16:06:59",
                "message_text_only": "Hi Michael,\n\nCLN as implemented is currently nicely decoupled from the block source; as\na project we assume that the node runner will choose a block backend that\nfits their self-sovereignty goals.\n\nThis provides us with a nice separation of concerns. The block source is\nresponsible for ensuring that only consensus valid data is delivered to the\nnode, which in turn allows us to focus on processing and reacting to that\ndata, as necessary.\n\nBitcoin core as a project implements a broad swath of functionality\n(wallet, consensus, peering, rpc server, coin selection, key management,\netc); breaking out the validation and peering functions into more\ncomposable parts would def open up more opportunities for building block\nsources for a wide variety of projects, not just CLN.\n\nThere\u2019s probably a real opportunity to \u201ccomingle\u201d the peering of LN gossip\n+ block data networks, this has been suggested a few times but never\nseriously pursued from the LN side. Having the peering functions of\nbitcoin-core broken out into a more composable/reusable piece may be a good\nfirst step here, and as a project would largely be on the bitcoin core\nside. Maybe this work is already in progress? I havent been keeping up with\ndevelopments there.\n\nThanks for the email, it\u2019s definitely a good question.\n\nLisa\n\n\nOn Mon, Apr 24, 2023 at 02:09 Michael Folkson via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Any thoughts on this from the Core Lightning contributors? The way I see\n> it with upcoming proposed changes to default policy (primarily though not\n> exclusively for Lightning) and a soft fork activation attempt of APO/APOAS\n> (primarily though not exclusively for Lightning) that a tighter coupling\n> between the full node and the Lightning node could eventually make sense.\n> In a world where transaction fees were much higher you'd think almost every\n> full node would also want to be a Lightning node and so the separation of\n> concerns would make less sense. Having two separate P2P networks and two\n> separate P2P protocols also wouldn't make much sense in this scenario. You\n> could obviously still opt out of Lightning P2P messages if you weren't\n> interested in Lightning.\n>\n> The alternative would be just to focus on Knots style consensus compatible\n> forks of Core with limited additional functionality. But I think we've\n> reached the point of no return on Core dominance and not having widely used\n> \"distros\". As the ecosystem scales systems and processes should be\n> constantly evolving and improving and to me if anything Core's seem to be\n> going backwards.\n>\n> Thanks\n> Michael\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> Keybase: michaelfolkson\n> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>\n> ------- Original Message -------\n>\n> On Saturday, January 14th, 2023 at 20:26, Michael Folkson <\n> michaelfolkson at protonmail.com> wrote:\n>\n> I tweeted this [0] back in November 2022.\n>\n> \"With the btcd bugs and the analysis paralysis on a RBF policy option in\n> Core increasingly thinking @BitcoinKnots and consensus compatible forks of\n> Core are the future. Gonna chalk that one up to another thing @LukeDashjr\n> was right about all along.\"\n>\n> A new bare bones Knots style Bitcoin implementation (in C++/C) integrated\n> with Core Lightning was a long term idea I had (and presumably many others\n> have had) but the dysfunction on the Bitcoin Core project this week (if\n> anything it has been getting worse over time, not better) has made me start\n> to take the idea more seriously. It is clear to me that the current way the\n> Bitcoin Core project is being managed is not how I would like an open\n> source project to be managed. Very little discussion is public anymore and\n> decisions seem to be increasingly made behind closed doors or in private\n> IRC channels (to the extent that decisions are made at all). Core Lightning\n> seems to have the opposite problem. It is managed effectively in the open\n> (admittedly with fewer contributors) but doesn't have the eyeballs or the\n> usage that Bitcoin Core does. Regardless, selfishly I at some point would\n> like a bare bones Bitcoin and Lightning implementation integrated in one\n> codebase. The Bitcoin Core codebase has collected a lot of cruft over time\n> and the ultra conservatism that is needed when treating (potential)\n> consensus code seems to permeate into parts of the codebase that no one is\n> using, definitely isn't consensus code and should probably just be removed.\n>\n> The libbitcoinkernel project was (is?) an attempt to extract the consensus\n> engine out of Core but it seems like it won't achieve that as consensus is\n> just too slippery a concept and Knots style consensus compatible codebase\n> forks of Bitcoin Core seem to still the model. To what extent you can\n> safely chop off this cruft and effectively maintain this less crufty fork\n> of Bitcoin Core also isn't clear to me yet.\n>\n> Then there is the question of whether it makes sense to mix C and C++ code\n> that people have different views on. C++ is obviously a superset of C but\n> assuming this merging of Bitcoin Core and Core Lightning is/was the optimal\n> final destination it surely would have been better if Core Lightning was\n> written in the same language (i.e. with classes) as Bitcoin Core.\n>\n> I'm just floating the idea to (hopefully) hear from people who are much\n> more familiar with the entirety of the Bitcoin Core and Core Lightning\n> codebases. It would be an ambitious long term project but it would be nice\n> to focus on some ambitious project(s) (even if just conceptually) for a\n> while given (thankfully) there seems to be a lull in soft fork activation\n> chaos.\n>\n> Thanks\n> Michael\n>\n> [0]:\n> https://twitter.com/michaelfolkson/status/1589220155006910464?s=20&t=GbPm7w5BqS7rS3kiVFTNcw\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> Keybase: michaelfolkson\n> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>\n>\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20230424/911bc9d0/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "A new Bitcoin implementation integrated with Core Lightning",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Michael Folkson",
                "niftynei"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 11017
        }
    },
    {
        "title": "[Lightning-dev] [bitcoin-dev] A new Bitcoin implementation integrated with Core Lightning",
        "thread_messages": [
            {
                "author": "Kostas Karasavvas",
                "date": "2023-04-19T09:05:10",
                "message_text_only": "Hi Michael,\n\nOn Wed, Apr 19, 2023 at 2:40\u202fAM Michael Folkson via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Any thoughts on this from the Core Lightning contributors? The way I see\n> it with upcoming proposed changes to default policy (primarily though not\n> exclusively for Lightning) and a soft fork activation attempt of APO/APOAS\n> (primarily though not\n>\n\nCould you please point me to a resource that describes the default policy\nchanges (that are happening for lightning)? I have seen discussions here\nand there but it would help if they are aggregated somewhere for reviewing.\n\n\n> exclusively for Lightning) that a tighter coupling between the full node\n> and the Lightning node could eventually make sense. In a world where\n> transaction fees were much higher you'd think almost every full node would\n> also want to be a Lightning node and so the separation of concerns would\n> make less sense.\n>\n\nSeparation of concerns always makes sense to manage complexity. One would\nneed to have really strong incentives to counter the complexity argument.\n\nI might be missing some context here but what would the actual benefit of\nintegrating them be? Not having to install lightning node separately and\nmaybe a more intuitive UX?\n\n\nHaving two separate P2P networks and two separate P2P protocols also\n> wouldn't make much sense in this scenario. You could obviously still opt\n> out of Lightning P2P messages if you weren't interested in Lightning.\n>\n> The alternative would be just to focus on Knots style consensus compatible\n> forks of Core with limited additional functionality. But I think we've\n> reached the point of no return on Core dominance and not having widely used\n> \"distros\". As the ecosystem scales systems and processes should be\n> constantly evolving and improving and to me if anything Core's seem to be\n> going backwards.\n>\n>\nPersonally, I have great difficulty seeing lightning as something other\nthan an L2 build on top of Bitcoin. There will be other L2s.\n\nRegards,\nKostas\n\nPS. Besides, the amount of effort would be significant. Wouldn't that\neffort be better spent on, say, separating the consensus logic (i.e. a\nsecond libbitcoinkernel attempt)?\n\n\n\n> Thanks\n> Michael\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> Keybase: michaelfolkson\n> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>\n> ------- Original Message -------\n> On Saturday, January 14th, 2023 at 20:26, Michael Folkson <\n> michaelfolkson at protonmail.com> wrote:\n>\n> I tweeted this [0] back in November 2022.\n>\n> \"With the btcd bugs and the analysis paralysis on a RBF policy option in\n> Core increasingly thinking @BitcoinKnots and consensus compatible forks of\n> Core are the future. Gonna chalk that one up to another thing @LukeDashjr\n> was right about all along.\"\n>\n> A new bare bones Knots style Bitcoin implementation (in C++/C) integrated\n> with Core Lightning was a long term idea I had (and presumably many others\n> have had) but the dysfunction on the Bitcoin Core project this week (if\n> anything it has been getting worse over time, not better) has made me start\n> to take the idea more seriously. It is clear to me that the current way the\n> Bitcoin Core project is being managed is not how I would like an open\n> source project to be managed. Very little discussion is public anymore and\n> decisions seem to be increasingly made behind closed doors or in private\n> IRC channels (to the extent that decisions are made at all). Core Lightning\n> seems to have the opposite problem. It is managed effectively in the open\n> (admittedly with fewer contributors) but doesn't have the eyeballs or the\n> usage that Bitcoin Core does. Regardless, selfishly I at some point would\n> like a bare bones Bitcoin and Lightning implementation integrated in one\n> codebase. The Bitcoin Core codebase has collected a lot of cruft over time\n> and the ultra conservatism that is needed when treating (potential)\n> consensus code seems to permeate into parts of the codebase that no one is\n> using, definitely isn't consensus code and should probably just be removed.\n>\n> The libbitcoinkernel project was (is?) an attempt to extract the consensus\n> engine out of Core but it seems like it won't achieve that as consensus is\n> just too slippery a concept and Knots style consensus compatible codebase\n> forks of Bitcoin Core seem to still the model. To what extent you can\n> safely chop off this cruft and effectively maintain this less crufty fork\n> of Bitcoin Core also isn't clear to me yet.\n>\n> Then there is the question of whether it makes sense to mix C and C++ code\n> that people have different views on. C++ is obviously a superset of C but\n> assuming this merging of Bitcoin Core and Core Lightning is/was the optimal\n> final destination it surely would have been better if Core Lightning was\n> written in the same language (i.e. with classes) as Bitcoin Core.\n>\n> I'm just floating the idea to (hopefully) hear from people who are much\n> more familiar with the entirety of the Bitcoin Core and Core Lightning\n> codebases. It would be an ambitious long term project but it would be nice\n> to focus on some ambitious project(s) (even if just conceptually) for a\n> while given (thankfully) there seems to be a lull in soft fork activation\n> chaos.\n>\n> Thanks\n> Michael\n>\n> [0]:\n> https://twitter.com/michaelfolkson/status/1589220155006910464?s=20&t=GbPm7w5BqS7rS3kiVFTNcw\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> Keybase: michaelfolkson\n> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n-- \nhttps://twitter.com/kkarasavvas\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20230419/feeac28d/attachment-0001.html>"
            },
            {
                "author": "Michael Folkson",
                "date": "2023-04-19T10:54:10",
                "message_text_only": "Hi Kostas\n\n> Could you please point me to a resource that describes the default policy changes (that are happening for lightning)? I have seen discussions here and there but it would help if they are aggregated somewhere for reviewing.\n\nIt is hard to follow because most of the discussions aren't on public channels, a number of the devs working on these proposed default policy changes aren't taking the BIP process seriously and no one is willing to discuss the criteria for merging default policy changes (and consensus changes for that matter) into bitcoin-inquisition (default signet). In addition the work (to the extent that it is public) is scattered all over the place. So yeah it seems like a mess to me from the perspective of someone is seeking to follow, review and monitor it.\n\nThis Bitcoin StackExchange post [0] is my first attempt to do what you're looking for and these Bitcoin Core PR review clubs [1], [2] were really good from Gloria. But yeah the BIP process (as I've said a thousand times and been ignored) is the place to hammer out specifications for complex things like default policy proposals and when people don't care about formalizing specifications it becomes very hard for people like you and me to follow.\n\n> Separation of concerns always makes sense to manage complexity. One would need to have really strong incentives to counter the complexity argument.\n>> I might be missing some context here but what would the actual benefit of integrating them be? Not having to install lightning node separately and maybe a more intuitive UX?\n\nAs I say in the original email having two separate P2P networks and two separate P2P protocols (perhaps) doesn't make much sense if all (or most of the nodes) are both full nodes and Lightning nodes. A testing framework that integrates both base layer and Lightning tests could potentially be easier to track edge cases which fall in the grey area between base layer and Lightning but are critically important for Lightning. A Core wallet that doesn't support Lightning doesn't make much sense in a world where transaction fees are really high and you have to use Lightning unless you are transferring huge amounts. I agree with you that these arguments have to be strong to counter the separation of concerns angle and maybe it is too early to consider it. But if moving in the direction of more widely used consensus compatible forks of Core then having Lightning integrated could make it an attractive option.\n\n> PS. Besides, the amount of effort would be significant. Wouldn't that effort be better spent on, say, separating the consensus logic (i.e. a second libbitcoinkernel attempt)?\n\nlibbitcoinkernel can achieve smaller (and still important) goals but I'm skeptical that the more ambitious goal of having lots of different implementations in different languages with libbitcoinkernel at its core and not having to worry about consensus bugs will be reached in the medium term. As we saw with the recent btcd/lnd bugs [3] consensus bugs can crop up in places you might not expect. In that case it was a wire parsing library that you wouldn't expect to be part of a libbitcoinkernel. So if you're still going to encounter consensus bugs outside of libbitcoinkernel there isn't much point (in my view) in using it for alternative implementations.\n\nThanks\nMichael\n\n[0]: https://bitcoin.stackexchange.com/questions/117315/what-and-where-are-the-current-status-of-the-bip-125-replacement-the-v3-policy\n[1]: https://bitcoincore.reviews/25038\n[2]: https://bitcoincore.reviews/25038-2\n[3]: https://bitcoin.stackexchange.com/questions/115527/what-is-the-october-2022-bug-in-lnd-what-caused-it-and-what-would-prevent-a-sim\n\n--\nMichael Folkson\nEmail: michaelfolkson at [protonmail.com](http://protonmail.com/)\nKeybase: michaelfolkson\nPGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n\n------- Original Message -------\nOn Wednesday, April 19th, 2023 at 10:05, Kostas Karasavvas <kkarasavvas at gmail.com> wrote:\n\n> Hi Michael,\n>\n> On Wed, Apr 19, 2023 at 2:40\u202fAM Michael Folkson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Any thoughts on this from the Core Lightning contributors? The way I see it with upcoming proposed changes to default policy (primarily though not exclusively for Lightning) and a soft fork activation attempt of APO/APOAS (primarily though not\n>\n> Could you please point me to a resource that describes the default policy changes (that are happening for lightning)? I have seen discussions here and there but it would help if they are aggregated somewhere for reviewing.\n>\n>> exclusively for Lightning) that a tighter coupling between the full node and the Lightning node could eventually make sense. In a world where transaction fees were much higher you'd think almost every full node would also want to be a Lightning node and so the separation of concerns would make less sense.\n>\n> Separation of concerns always makes sense to manage complexity. One would need to have really strong incentives to counter the complexity argument.\n>\n> I might be missing some context here but what would the actual benefit of integrating them be? Not having to install lightning node separately and maybe a more intuitive UX?\n>\n>> Having two separate P2P networks and two separate P2P protocols also wouldn't make much sense in this scenario. You could obviously still opt out of Lightning P2P messages if you weren't interested in Lightning.\n>\n>> The alternative would be just to focus on Knots style consensus compatible forks of Core with limited additional functionality. But I think we've reached the point of no return on Core dominance and not having widely used \"distros\". As the ecosystem scales systems and processes should be constantly evolving and improving and to me if anything Core's seem to be going backwards.\n>\n> Personally, I have great difficulty seeing lightning as something other than an L2 build on top of Bitcoin. There will be other L2s.\n>\n> Regards,\n> Kostas\n>\n> PS. Besides, the amount of effort would be significant. Wouldn't that effort be better spent on, say, separating the consensus logic (i.e. a second libbitcoinkernel attempt)?\n>\n>> Thanks\n>> Michael\n>>\n>> --\n>> Michael Folkson\n>> Email: michaelfolkson at [protonmail.com](http://protonmail.com/)\n>> Keybase: michaelfolkson\n>> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>>\n>> ------- Original Message -------\n>> On Saturday, January 14th, 2023 at 20:26, Michael Folkson <michaelfolkson at protonmail.com> wrote:\n>>\n>>> I tweeted this [0] back in November 2022.\n>>>\n>>> \"With the btcd bugs and the analysis paralysis on a RBF policy option in Core increasingly thinking @BitcoinKnots and consensus compatible forks of Core are the future. Gonna chalk that one up to another thing @LukeDashjr was right about all along.\"\n>>>\n>>> A new bare bones Knots style Bitcoin implementation (in C++/C) integrated with Core Lightning was a long term idea I had (and presumably many others have had) but the dysfunction on the Bitcoin Core project this week (if anything it has been getting worse over time, not better) has made me start to take the idea more seriously. It is clear to me that the current way the Bitcoin Core project is being managed is not how I would like an open source project to be managed. Very little discussion is public anymore and decisions seem to be increasingly made behind closed doors or in private IRC channels (to the extent that decisions are made at all). Core Lightning seems to have the opposite problem. It is managed effectively in the open (admittedly with fewer contributors) but doesn't have the eyeballs or the usage that Bitcoin Core does. Regardless, selfishly I at some point would like a bare bones Bitcoin and Lightning implementation integrated in one codebase. The Bitcoin Core codebase has collected a lot of cruft over time and the ultra conservatism that is needed when treating (potential) consensus code seems to permeate into parts of the codebase that no one is using, definitely isn't consensus code and should probably just be removed.\n>>>\n>>> The libbitcoinkernel project was (is?) an attempt to extract the consensus engine out of Core but it seems like it won't achieve that as consensus is just too slippery a concept and Knots style consensus compatible codebase forks of Bitcoin Core seem to still the model. To what extent you can safely chop off this cruft and effectively maintain this less crufty fork of Bitcoin Core also isn't clear to me yet.\n>>>\n>>> Then there is the question of whether it makes sense to mix C and C++ code that people have different views on. C++ is obviously a superset of C but assuming this merging of Bitcoin Core and Core Lightning is/was the optimal final destination it surely would have been better if Core Lightning was written in the same language (i.e. with classes) as Bitcoin Core.\n>>>\n>>> I'm just floating the idea to (hopefully) hear from people who are much more familiar with the entirety of the Bitcoin Core and Core Lightning codebases. It would be an ambitious long term project but it would be nice to focus on some ambitious project(s) (even if just conceptually) for a while given (thankfully) there seems to be a lull in soft fork activation chaos.\n>>>\n>>> Thanks\n>>> Michael\n>>>\n>>> [0]: https://twitter.com/michaelfolkson/status/1589220155006910464?s=20&t=GbPm7w5BqS7rS3kiVFTNcw\n>>>\n>>> --\n>>> Michael Folkson\n>>> Email: michaelfolkson at [protonmail.com](http://protonmail.com/)\n>>> Keybase: michaelfolkson\n>>> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n> --\n>\n> https://twitter.com/kkarasavvas\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20230419/43c5b5f7/attachment-0001.html>"
            },
            {
                "author": "Vincenzo Palazzo",
                "date": "2023-04-30T15:22:01",
                "message_text_only": "Hi Michael and Lisa,\n\n> Hi Michael,\n>\n> CLN as implemented is currently nicely decoupled from the block source; as\n> a project we assume that the node runner will choose a block backend that\n> fits their self-sovereignty goals.\n>\n> This provides us with a nice separation of concerns. The block source is\n> responsible for ensuring that only consensus valid data is delivered to the\n> node, which in turn allows us to focus on processing and reacting to that\n> data, as necessary.\n\nLet me just mention that [1] I have been working on a plugin \nthat allows experimentation with different types of Bitcoin Core \nnode alternatives (including core too), and it also supports BIP 157 \nwith nakamoto [2].\n\nIn the upcoming months, I plan to allocate some time to work \ndirectly on Nakamoto.\n\n> There\u2019s probably a real opportunity to \u201ccomingle\u201d the peering of LN gossip\n> + block data networks, this has been suggested a few times but never\n> seriously pursued from the LN side. Having the peering functions of\n> bitcoin-core broken out into a more composable/reusable piece may be a good\n> first step here, and as a project would largely be on the bitcoin core\n> side. Maybe this work is already in progress? I havent been keeping up with\n> developments there.\n\nA missing piece at the moment is a unified approach to fee calculation. \nThis logic is critical for Lightning nodes, so if we don't have a uniform \nway of estimating fees, it could lead to several issues.\n\nP.S: The fee estimation problem may have already been solved by Neutrino, \nbut I'm not aware of it.\n\n[1] https://github.com/coffee-tools/folgore\n[2] https://github.com/cloudhead/nakamoto\n\nCheers!\n\nVincent."
            }
        ],
        "thread_summary": {
            "title": "A new Bitcoin implementation integrated with Core Lightning",
            "categories": [
                "Lightning-dev",
                "bitcoin-dev"
            ],
            "authors": [
                "Michael Folkson",
                "Kostas Karasavvas",
                "Vincenzo Palazzo"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 17657
        }
    },
    {
        "title": "[Lightning-dev] A Note on Public Communication",
        "thread_messages": [
            {
                "author": "niftynei",
                "date": "2023-04-24T16:16:42",
                "message_text_only": "Hi all,\n\nWhen I joined the lightning community a few years ago, I was relatively new\nto open source software and specification work. Rusty really impressed on\nme on the importance of holding conversations, as much as possible in\npublic.\n\nPractically speaking, this encompasses IRC, this mailing list, and github\nissues/PRs.\n\nThe reason for this is twofold.  It helps document the range of options\nconsidered for technical decisions and it provides an interface point for\nnew participants to contribute to the discussion.\n\nGiven some recent mails that were posted to this list, now seems like a\ngood time to reiterate the importance and preference of public\ncommunication whenever possible, especially for specification or technical\ndiscussions.\n\n\n~ nifty\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20230424/d37aa552/attachment-0001.html>"
            },
            {
                "author": "Vincenzo Palazzo",
                "date": "2023-04-30T15:26:54",
                "message_text_only": "Hi niftynei,\n\n> When I joined the lightning community a few years ago, I was relatively new\n> to open source software and specification work. Rusty really impressed on\n> me on the importance of holding conversations, as much as possible in\n> public.\n>\n> Practically speaking, this encompasses IRC, this mailing list, and github\n> issues/PRs.\n>\n> The reason for this is twofold.  It helps document the range of options\n> considered for technical decisions and it provides an interface point for\n> new participants to contribute to the discussion.\n>\n> Given some recent mails that were posted to this list, now seems like a\n> good time to reiterate the importance and preference of public\n> communication whenever possible, especially for specification or technical\n> discussions.\n>\n\nI have to admit that I feel the same way. Although I wasn't present during \nthe early days, when I scanned the list, I found some very good discussions \nabout possible problems and solutions. It seems like the communication is \nmore fragmented now.\n\nCheers!\n\nVincent."
            }
        ],
        "thread_summary": {
            "title": "A Note on Public Communication",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "niftynei",
                "Vincenzo Palazzo"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 1993
        }
    },
    {
        "title": "[Lightning-dev] Spending `to_local` output of commitment",
        "thread_messages": [
            {
                "author": "Benjamin Weintraub",
                "date": "2023-04-27T12:41:47",
                "message_text_only": "Hi all,\n\nI have a question about commitments. If a peer force closes a channel by sending a commitment to the blockchain, what kind of witness script is needed to redeem the `to_local` funds? (assuming the `to_self_delay` has elapsed.) It seems that the transaction described here is for cooperative closures: https://github.com/lightning/bolts/blob/c74a3bbcf890799d343c62cb05fcbcdc952a1cf3/03-transactions.md#closing-transaction. But for force closures, I would think that the txin would need to be the `to_local` txout of the commitment.\n\nConcretely, I have commited the following transaction on a local simnet bitcoin blockchain and mined 500 blocks on top of it. I want to spend vout[2], how can I generate such a transaction?\n\n\n{\n  \"hash\": \"47d15337bb3c29c7c2881dd7cd912604b401ed221c66ea6f781b456d4983d451\",\n  \"size\": 444,\n  \"vsize\": 279,\n  \"weight\": 1113,\n  \"version\": 2,\n  \"locktime\": 551351761,\n  \"vin\": [\n    {\n      \"txid\": \"0248025b9447df8267d02d14c34ab9b269f52cd827132c70159a55cbf27ab3c1\",\n      \"vout\": 0,\n      \"scriptSig\": {\n        \"asm\": \"\",\n        \"hex\": \"\"\n      },\n      \"txinwitness\": [\n        \"\",\n        \"3045022100d3f52ca04d6a71587c29592931e542b16a47f3e9e577f1869b416547d00c62dd0220485da35ad31ff71b4263b1a25f0ba9f35990e1c8d5ac848365bbd588c3ce83d701\",\n        \"3044022057fc3878e17a865c12d57b7885ed48f0d6122bd9e00511c8eac150180d1508d502205fd1d0674a41b3c0118d0b6c19b1c77d35fc95bb89f929da6478f22e94dbf5ce01\",\n        \"5221038acdafe305edd06e91706ee687a091be306f0f29bcbda52dadde084bbaa36c902103d8fd53b9b43638c2255e1abd6f134a0232d2fba65527252c4eb81f926ddf50ad52ae\"\n      ],\n      \"sequence\": 2161061453\n    }\n  ],\n  \"vout\": [\n    {\n      \"value\": 0.0000033,\n      \"n\": 0,\n      \"scriptPubKey\": {\n        \"asm\": \"0 45ec86244376d47000ca6592783ba26f6b2ae619a24c8f5fad249b8c716955d6\",\n        \"hex\": \"002045ec86244376d47000ca6592783ba26f6b2ae619a24c8f5fad249b8c716955d6\",\n        \"reqSigs\": 1,\n        \"type\": \"witness_v0_scripthash\",\n        \"addresses\": [\n          \"sb1qghkgvfzrwm28qqx2vkf8swazda4j4ese5fxg7hadyjdccutf2htqysq3qz\"\n        ]\n      }\n    },\n    {\n      \"value\": 0.0000033,\n      \"n\": 1,\n      \"scriptPubKey\": {\n        \"asm\": \"0 502a17644b334482d0a3f589d9861af6e2105a9b7afd3f5c258efc98bb6aeeed\",\n        \"hex\": \"0020502a17644b334482d0a3f589d9861af6e2105a9b7afd3f5c258efc98bb6aeeed\",\n        \"reqSigs\": 1,\n        \"type\": \"witness_v0_scripthash\",\n        \"addresses\": [\n          \"sb1q2q4pweztxdzg959r7kyanps67m3pqk5m0t7n7hp93m7f3wm2amksa0fysc\"\n        ]\n      }\n    },\n    {\n      \"value\": 0.0002,\n      \"n\": 2,\n      \"scriptPubKey\": {\n        \"asm\": \"0 045553fc789494f16eff4cfa221d0294e140fb79772efeb7d8397d0ac1c4cf85\",\n        \"hex\": \"0020045553fc789494f16eff4cfa221d0294e140fb79772efeb7d8397d0ac1c4cf85\",\n        \"reqSigs\": 1,\n        \"type\": \"witness_v0_scripthash\",\n        \"addresses\": [\n          \"sb1qq3248lrcjj20zmhlfnazy8gzjns5p7mewuh0ad7c897s4swye7zsyrm5pc\"\n        ]\n      }\n    },\n    {\n      \"value\": 0.009761,\n      \"n\": 3,\n      \"scriptPubKey\": {\n        \"asm\": \"0 2d51ca420d0b6ab56c97ca2631d7304c9ad9025252ea71f3af8f97361679042e\",\n        \"hex\": \"00202d51ca420d0b6ab56c97ca2631d7304c9ad9025252ea71f3af8f97361679042e\",\n        \"reqSigs\": 1,\n        \"type\": \"witness_v0_scripthash\",\n        \"addresses\": [\n          \"sb1q94gu5ssdpd4t2myhegnrr4esfjddjqjj2t48rua037tnv9neqshqm4z7yr\"\n        ]\n      }\n    }\n  ],\n  \"blockhash\": \"0fa78bc7e9f6e0a60be71bb5fb2eaaf42a97895bb057f09d7cbb2c49120fa61d\",\n  \"confirmations\": 500,\n  \"time\": 1682451410,\n  \"blocktime\": 1682451410\n}\n\n\n\nThanks in advance,\n\nBen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20230427/d0c110bb/attachment-0001.html>"
            },
            {
                "author": "Ken Sedgwick",
                "date": "2023-04-30T18:30:10",
                "message_text_only": "Ben,\n\nThe necessary witness is described here:\nhttps://github.com/lightning/bolts/blob/master/03-transactions.md#to_local-output\n\nRegards,\n\nKen\n\nOn Sat, Apr 29, 2023 at 7:57\u202fPM Benjamin Weintraub via Lightning-dev <\nlightning-dev at lists.linuxfoundation.org> wrote:\n\n> Hi all,\n>\n> I have a question about commitments. If a peer force closes a channel by\n> sending a commitment to the blockchain, what kind of witness script is\n> needed to redeem the `to_local` funds? (assuming the `to_self_delay` has\n> elapsed.) It seems that the transaction described here is for cooperative\n> closures:\n> https://github.com/lightning/bolts/blob/c74a3bbcf890799d343c62cb05fcbcdc952a1cf3/03-transactions.md#closing-transaction\n> . But for force closures, I would think that the txin would need to be\n> the `to_local` txout of the commitment.\n>\n> Concretely, I have commited the following transaction on a local simnet\n> bitcoin blockchain and mined 500 blocks on top of it. I want to spend\n> vout[2], how can I generate such a transaction?\n>\n>\n> {\n>   \"hash\":\n> \"47d15337bb3c29c7c2881dd7cd912604b401ed221c66ea6f781b456d4983d451\",\n>   \"size\": 444,\n>   \"vsize\": 279,\n>   \"weight\": 1113,\n>   \"version\": 2,\n>   \"locktime\": 551351761,\n>   \"vin\": [\n>     {\n>       \"txid\":\n> \"0248025b9447df8267d02d14c34ab9b269f52cd827132c70159a55cbf27ab3c1\",\n>       \"vout\": 0,\n>       \"scriptSig\": {\n>         \"asm\": \"\",\n>         \"hex\": \"\"\n>       },\n>       \"txinwitness\": [\n>         \"\",\n>\n> \"3045022100d3f52ca04d6a71587c29592931e542b16a47f3e9e577f1869b416547d00c62dd0220485da35ad31ff71b4263b1a25f0ba9f35990e1c8d5ac848365bbd588c3ce83d701\",\n>\n> \"3044022057fc3878e17a865c12d57b7885ed48f0d6122bd9e00511c8eac150180d1508d502205fd1d0674a41b3c0118d0b6c19b1c77d35fc95bb89f929da6478f22e94dbf5ce01\",\n>\n> \"5221038acdafe305edd06e91706ee687a091be306f0f29bcbda52dadde084bbaa36c902103d8fd53b9b43638c2255e1abd6f134a0232d2fba65527252c4eb81f926ddf50ad52ae\"\n>       ],\n>       \"sequence\": 2161061453\n>     }\n>   ],\n>   \"vout\": [\n>     {\n>       \"value\": 0.0000033,\n>       \"n\": 0,\n>       \"scriptPubKey\": {\n>         \"asm\": \"0\n> 45ec86244376d47000ca6592783ba26f6b2ae619a24c8f5fad249b8c716955d6\",\n>         \"hex\":\n> \"002045ec86244376d47000ca6592783ba26f6b2ae619a24c8f5fad249b8c716955d6\",\n>         \"reqSigs\": 1,\n>         \"type\": \"witness_v0_scripthash\",\n>         \"addresses\": [\n>           \"sb1qghkgvfzrwm28qqx2vkf8swazda4j4ese5fxg7hadyjdccutf2htqysq3qz\"\n>         ]\n>       }\n>     },\n>     {\n>       \"value\": 0.0000033,\n>       \"n\": 1,\n>       \"scriptPubKey\": {\n>         \"asm\": \"0\n> 502a17644b334482d0a3f589d9861af6e2105a9b7afd3f5c258efc98bb6aeeed\",\n>         \"hex\":\n> \"0020502a17644b334482d0a3f589d9861af6e2105a9b7afd3f5c258efc98bb6aeeed\",\n>         \"reqSigs\": 1,\n>         \"type\": \"witness_v0_scripthash\",\n>         \"addresses\": [\n>           \"sb1q2q4pweztxdzg959r7kyanps67m3pqk5m0t7n7hp93m7f3wm2amksa0fysc\"\n>         ]\n>       }\n>     },\n>     {\n>       \"value\": 0.0002,\n>       \"n\": 2,\n>       \"scriptPubKey\": {\n>         \"asm\": \"0\n> 045553fc789494f16eff4cfa221d0294e140fb79772efeb7d8397d0ac1c4cf85\",\n>         \"hex\":\n> \"0020045553fc789494f16eff4cfa221d0294e140fb79772efeb7d8397d0ac1c4cf85\",\n>         \"reqSigs\": 1,\n>         \"type\": \"witness_v0_scripthash\",\n>         \"addresses\": [\n>           \"sb1qq3248lrcjj20zmhlfnazy8gzjns5p7mewuh0ad7c897s4swye7zsyrm5pc\"\n>         ]\n>       }\n>     },\n>     {\n>       \"value\": 0.009761,\n>       \"n\": 3,\n>       \"scriptPubKey\": {\n>         \"asm\": \"0\n> 2d51ca420d0b6ab56c97ca2631d7304c9ad9025252ea71f3af8f97361679042e\",\n>         \"hex\":\n> \"00202d51ca420d0b6ab56c97ca2631d7304c9ad9025252ea71f3af8f97361679042e\",\n>         \"reqSigs\": 1,\n>         \"type\": \"witness_v0_scripthash\",\n>         \"addresses\": [\n>           \"sb1q94gu5ssdpd4t2myhegnrr4esfjddjqjj2t48rua037tnv9neqshqm4z7yr\"\n>         ]\n>       }\n>     }\n>   ],\n>   \"blockhash\":\n> \"0fa78bc7e9f6e0a60be71bb5fb2eaaf42a97895bb057f09d7cbb2c49120fa61d\",\n>   \"confirmations\": 500,\n>   \"time\": 1682451410,\n>   \"blocktime\": 1682451410\n> }\n>\n>\n>\n> Thanks in advance,\n>\n> Ben\n> _______________________________________________\n> Lightning-dev mailing list\n> Lightning-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n>\n\n\n-- \nKen Sedgwick\nBonsai Software, Inc.\nhttp://www.bonsai.com/ken/\n(510) 269-7334\nken at bonsai.com\nPublic Key: http://www.bonsai.com/ken/ken.asc\nGPG Fingerprint: 4695 E5B8 F781 BF85 4326  9639 BBFC E515 8602 5550\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20230430/57eb19dd/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Spending `to_local` output of commitment",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Benjamin Weintraub",
                "Ken Sedgwick"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 8343
        }
    },
    {
        "title": "[Lightning-dev] HTLC Endorsement for Jamming Mitigation",
        "thread_messages": [
            {
                "author": "Carla Kirk-Cohen",
                "date": "2023-04-28T18:48:40",
                "message_text_only": "Hi list,\n\nSome updates on channel jamming!\n\n# Next Call\n- Monday 01 May @ 15:00 UTC\n- https://meet.jit.si/UnjammingLN\n- Agenda: https://github.com/ClaraShk/LNJamming/issues/12\n\n# Data Gathering\nDuring these weekly calls, we've come to agreement that we would like\nto gather data about the use of HTLC endorsement and local reputation\ntracking for jamming mitigation. A reminder of the full scheme is\nincluded at the end of this email, and covered more verbosely in [1].\n\nWe have a few goals in mind:\n- Observe the effect of endorsement in the steady state with\n  logging-only implementation.\n- Gather real-world data for use in future simulation work.\n- Experiment with different algorithms for tracking local reputation.\n\nThe minimal changes required to add HTLC endorsement are outlined in [2].\nOur suggestion is to start simple with a binary endorsement field. As\nwe learn more, we will be better equipped to understand whether a\nmore expressive value is required.\n\nWith this infrastructure in place, we can start to experiment with\nvarious local reputation schemes and data gathering, possibly even\nexternally to LN implementations in projects like circuitbreaker [3].\nWe'd be interested to hear whether there's any appetite to deploy using\nan experimental TLV value?\n\n# Reputation Scheme\n- Each node locally tracks the reputation of its direct neighbors.\n- Each node allocates, per its risk tolerance:\n  - A number of slots reserved for endorsed HTLCs from high reputation\n    peers.\n  - A portion of liquidity reserved for endorsed HTLCs from high\n    reputation peers.\n- Forwarding of HTLCs:\n  - If a HTLC is endorsed by a high reputation peer, it is forwarded\n    as usual with endorsed = 1.\n  - Otherwise, it is forwarded with endorsed = 0 if there are slots and\n    liquidity available for unknown HTLCs.\n\nEndorsement and reputation are proposed as the first step in a two part\nscheme for mitigating channel jamming:\n- Reputation for slow jams which are easily detected as misbehavior.\n- Unconditional fees for quick jams that are difficult to detect, as\n  they can always fall under a target threshold.\n\nLooking forward to discussing further in the upcoming call!\n\nBest,\nCarla and Clara\n\n[1] https://gist.github.com/carlaKC/be820bb638624253f3ae7b39dbd0e343\n[2] https://github.com/lightning/bolts/pull/1071\n[3] https://github.com/lightningequipment/circuitbreaker\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20230428/686b99f7/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "HTLC Endorsement for Jamming Mitigation",
            "categories": [
                "Lightning-dev"
            ],
            "authors": [
                "Carla Kirk-Cohen"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2558
        }
    }
]