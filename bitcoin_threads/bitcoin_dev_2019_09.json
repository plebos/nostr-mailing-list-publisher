[
    {
        "title": "[bitcoin-dev] Draft BIP for SNICKER",
        "thread_messages": [
            {
                "author": "AdamISZ",
                "date": "2019-09-01T13:46:57",
                "message_text_only": "Hello list,\nHere is a link for a draft of a BIP for a different type of CoinJoin I've named 'SNICKER' = Simple Non-Interactive Coinjoin with Keys for Encryption Reused.\n\nhttps://gist.github.com/AdamISZ/2c13fb5819bd469ca318156e2cf25d79\n\nSummary in document abstract and motivation, but also there is a more discursive blog post I wrote a while back, linked in the abstract, if you find that helpful.\n\nPurpose of writing this as a BIP:\nThere was some discussion on the Wasabi repo about this recently (https://github.com/zkSNACKs/Meta/issues/67) and it prompted me to do something I should have done way back when I came up with the idea in late '17: write a technical specification, because one of the main attractive points about this is that it isn't a hugely difficult task for a wallet developer to implement (especially: Receiver side), and it would only really have value if wallet developers did indeed implement it. To be specific, it requires ECDH (which is already available in libsecp256k1 anyway) and ECIES which is pretty easy to do (just ecdh and hmac, kinda).\n\nPlenty of uncertainty on the specs, in particular the specification for transactions, e.g. see 'Partially signed transactions' subsection, point 3). Also perhaps the encryption specs. I went with the exact algo already used by Electrum here, but it could be considered dubious (CBC).\n\nThanks for any feedback.\n\nAdam Gibson / waxwing\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20190901/de941638/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Draft BIP for SNICKER",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "AdamISZ"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1652
        }
    },
    {
        "title": "[bitcoin-dev] Browser version - Discover and move your coins by yourself",
        "thread_messages": [
            {
                "author": "Aymeric Vitte",
                "date": "2019-09-02T07:38:50",
                "message_text_only": "The browser version is now released, please see https://peersm.com/wallet\n\nComments/suggestions still welcome\n\nLe 07/08/2019 \u00e0 12:54, Aymeric Vitte a \u00e9crit\u00a0:\n>\n> FYI Phase 3 is released https://github.com/Ayms/bitcoin-transactions,\n> features:\n>\n> - create transactions\n>\n> - decode transactions\n>\n> - verify transactions\n>\n> - convert/map addresses (including bech32)\n>\n> - create/map wallets (bip32,39,44, etc), wallets recovery\n> (missing/wrong words) and check\n>\n> - decode/create multisig redeem scripts\n>\n> - pubkey/privkey mapping , conversion and formats\n>\n> - sign/verify messages\n>\n> Browserifying everything now for the end of the month\n>\n>\n>\n> -------- Message transf\u00e9r\u00e9 --------\n> Sujet\u00a0: \tDiscover and move your coins by yourself\n> Date\u00a0: \tFri, 12 Jul 2019 20:35:00 +0200\n> De\u00a0: \tAymeric Vitte <vitteaymeric at gmail.com>\n> Pour\u00a0: \tBitcoin Dev <bitcoin-dev at lists.linuxfoundation.org>\n>\n>\n>\n>\n> Please see https://github.com/Ayms/bitcoin-transactions this is a merge\n> of former bitcoin-transactions and bitcoin-wallets nodejs modules with\n> additional features to be implemented as described in the README\n>\n> It is financed by NLnet via EU Horizon 2020 Next Generation Internet\n> Search and Discovery call\n>\n> So the initial dev fees have been removed and the code is now open\n> source and provided in clear under a MIT license\n>\n> The intent is to provide all the necessary tools for anybody to discover\n> and manage their coins, as well as making transactions by themselves,\n> without having to sync a full node or as an alternative to wallets when\n> people don't understand where their coins are (we saw quite a lot of\n> confusion for people not understanding at all how to find their coins\n> and to what keys their addresses did relate in case of multisig, segwit\n> and now bech32)\n>\n> It's somewhere bitcoin-cli outside of bitcoin core more easy to use and\n> not restricted to its own wallet, available for any bitcoin based coins\n>\n> At the end it will be a secure standalone offline js webapp inside\n> browsers (like https://peersm.com/wallet but the app does not reflect\n> the current state of the nodejs repo)\n>\n> It's not a remake of iancoleman's tool but of course some features\n> overlap, as well as for other existing tools, we will also extend all of\n> this inside one tool with no limitations (for example some tools do not\n> accept \"invalid\" bip39 seeds, or bip32 seeds, etc)\n>\n> Comments/suggestions welcome\n>\n> PS: initially sent to bitcoin-discuss but the list seems to be dead\n>\n> -- \n> Move your coins by yourself (browser version): https://peersm.com/wallet\n> Bitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions\n> Zcash wallets made simple: https://github.com/Ayms/zcash-wallets\n> Bitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets\n> Get the torrent dynamic blocklist: http://peersm.com/getblocklist\n> Check the 10 M passwords list: http://peersm.com/findmyass\n> Anti-spies and private torrents, dynamic blocklist: http://torrent-live.org\n> Peersm : http://www.peersm.com\n> torrent-live: https://github.com/Ayms/torrent-live\n> node-Tor : https://www.github.com/Ayms/node-Tor\n> GitHub : https://www.github.com/Ayms\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20190902/3e4e3354/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Browser version - Discover and move your coins by yourself",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Aymeric Vitte"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3383
        }
    },
    {
        "title": "[bitcoin-dev] Reconciling the off-chain and on-chain models with eltoo",
        "thread_messages": [
            {
                "author": "Christian Decker",
                "date": "2019-09-06T13:18:03",
                "message_text_only": "With the recently published proof-of-concept of eltoo on signet by\nRichard, I thought it might a good time to share some thoughts on ho I\nthink we can build this system. I think there are a few properties of\neltoo that allow us to build a nicely layered protocol stack, which\nimproves flexibility and simplifies the reasoning about their relative\nsecurity.\n\nSince I don't like huge e-mails myself and I'm about to write one,\nhere's a quick TL;DR:\n\n> Using the clean separation of protocol layers provided by eltoo we can\n> reconcile many on-chain and off-chain concepts, and simplify the\n> reasoning to build more complex functionality beyond simple\n> HTLCs. Bitcoin transactions are a natural fit to represent proposed\n> off-chain state-changes while they are being negotiated.\n\n\n### Clean separation of protocol layers\n\nOne of te big advantages of eltoo over other off-chain update mechanisms\nis that it provides strong guarantees regarding the state that will\neventually end up confirmed on-chain. If parties in an eltoo off-chain\ncontract agree on an update, we can be certain (within eltoo's security\nassumptions) that this is the state that will eventually confirm\non-chain, if no newer states are agreed.\n\nIn particular it means that we are guaranteed no earlier state can leak\nonto the chain, keeping anything we build on top of the update layer\nunencumbered since it doesn't have to deal with this case.\n\nThis is in stark contrast to the penalty update mechanism, where\nold/revoked states can leak on-chain, resulting in anything built on top\nof the penalty mechanism having to deal with that eventuality. For\nexample if we look at HTLCs as specified [1] we see that it needs an\nadditional revokation path for the case the commitment transaction that\ncreated this HTLC output is confirmed:\n\n```btcscript\n# To remote node with revocation key\nOP_DUP OP_HASH160 <RIPEMD160(SHA256(revocationpubkey))> OP_EQUAL\nOP_IF\n    OP_CHECKSIG\nOP_ELSE\n    <remote_htlcpubkey> OP_SWAP OP_SIZE 32 OP_EQUAL\n    OP_IF\n        # To local node via HTLC-success transaction.\n        OP_HASH160 <RIPEMD160(payment_hash)> OP_EQUALVERIFY\n        2 OP_SWAP <local_htlcpubkey> 2 OP_CHECKMULTISIG\n    OP_ELSE\n        # To remote node after timeout.\n        OP_DROP <cltv_expiry> OP_CHECKLOCKTIMEVERIFY OP_DROP\n        OP_CHECKSIG\n    OP_ENDIF\nOP_ENDIF\n```\n\nThe update mechanism bleeding into the other layers is rather cumbersome\nif you ask me, and complicates the reasoning about security. Having to\nthread the penalty through outputs created by the off-chain contract may\nalso not work if we deal with more than 2 parties, since penalties\nalways steal all the funds, regardless of whether the output belonged to\nthe cheater or not (see asymmetry vs symmetry argument from the paper\n[2]).\n\nWith the clean separation we get from eltoo we can concentrate on\nbuilding the output scripts we'd like to have without having to thread\npenalties through them. This reduces the complexity and our on-chain\nfootprint.\n\nThe update layer now exposes only two very simple operations:\n`add_output` and `remove_output` (this should sound very familiar :-p).\n\n\n### Ownership and atomic update model\n\nNow that we have a solid update layer, which ensures that agreed upon\nstates will eventually be reflected on-chain, we can turn our attention\nto the next layer up: the negotiation layer. Each output in our\nagreed-upon state needs to be assigned one or more owners. The owners\nare the participants that need to sign off on removal of an output and\nthe creation of new outputs which redistribute the funds contained in\nthe removed outputs to newly created outputs.\n\nIn addition we need to ensure that multiple `remove_output` and\n`add_output` are guaranteed to be applied atomically. By creating a\ndatastructure that lists a number of operations that are to either be\napplied to the current state or discarded, we can have arbitrary complex\nchanges of ownership, and the newly created outputs can have arbitrary\nscripts.\n\nIf all of this sounds familiar that's because this is exactly the UTXO\nmodel and the transaction structure we have in Bitcoin. We\ncollaboratively manage funds bound to some outputs (UTXO) and can change\ntheir ownership and allocation over time (transactions).\n\nThis means that a subset of the participants in an off-chain contract\ncan negotiate among themselves how to redistribute funds, join and split\nthem in an arbitrary fashion, without the rest of the contract being\ninvolved. The end result is a valid Bitcoin transaction that spends some\noutputs of the current state, and is signed by the owners. The\ntransaction can then be presented to the entire group, and applied to\nthe state. Applying the transaction flattens multiple transactions built\non top of the current state into a new state (similar to transaction\ncut-through in mimblewimble).\n\nUsing transactions as a means to represent off-chain negotiations, and\nthen applying them to the off-chain state via cut-through has a number\nof advantages over similar schemes:\n\n- Even if we failed to update the off-chain state, the transactions\n  building on top of it are valid transactions, so once we tear down\n  the channel, our negotiated new state can still be reached by\n  broadcasting the transaction after settlement (this is basically\n  what the channel factory paper [3] was using).\n    \n- We can reuse a lot of tools that we have already built for on-chain\n  transactions, including things like miniscript and hardware wallets,\n  without explicitly requiring them in our own specification. The\n  Bitcoin object model is our interface here.\n\n- It allows for experimentation even inside a running eltoo instance. If\n  you can find another participant that supports a fancy new protocol,\n  you can use that protocol even though some of the other participants\n  may not know anything about it. As long as you can understand the\n  Bitcoin transaction model you can participate in a multi-party\n  channel.\n\nI think this reconciliation between the off-chain model and the on-chain\nmodel, with many concepts cleanly mapping from one context to another\n(state outputs = UTXO, off-chain update = on-chain transactions,\ncut-through = confirmation, operation batching = block creation) is\nrather nice :-)\n\nThat should be enough rambling on my side. I'm interested in what others\nthink about this. Is it completely off, does it make no sense at all, or\nis this something we should be looking into going forward?\n\nCheers,\nChristian\n\n[1] https://github.com/lightningnetwork/lightning-rfc/blob/master/03-transactions.md#received-htlc-outputs\n[2] https://blockstream.com/eltoo.pdf\n[3] https://tik-old.ee.ethz.ch/file/a20a865ce40d40c8f942cf206a7cba96/Scalable%5FFunding%5FOf%5FBlockchain%5FMicropayment%5FNetworks.pdf"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-06T14:32:38",
                "message_text_only": "Good morning Christian,\n\nThis is effectively transaction cut-through.\nI mention this in passing here: https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-April/001986.html\n\n> I observe that one may consider any offchain system a specialization of an offchain transaction cut-through system.\n> Thus, one may model changes to the offchain system state as the creation of some transactions, followed by a cut-through of those transactions into the new state.\n\nBasically, we can send a transaction that spends a subset of the current state txos to the participants in the update mechanism.\nThen the participants can agree that it is a valid spend of the specified state txos, and agree to sign a new state with the spent txos deleted and the new txos of the transaction inserted.\nDisagreement at this point is essentially a \"if your tx is so valid why do you not try it on the base blockchain layer huh?\" challenge and is basically an invitation to close it unilaterally and enforce the contract on the blockchain.\n\nThe \"difficulty\" in Poon-Dryja is not very onerous in my opinion; see the sketch here: https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-August/001383.html\n\nOf note is that any contract with a relative locktime requirement would not make sense to maintain offchain.\nIf one wishes to select a relative locktime relative to the current moment, one can quite easily compute an absolute timelock.\n\nAnother note, is that contracts with timelocks need to be enforced onchain on or before the timelock.\nUnder Decker-Russell-Osuntokun the onchain enforcement needs to be triggered early according to the CSV security parameter; this is not an issue under Poon-Dryja (as the CSV is in a later transaction).\nUnder Decker-Russell-Osuntokun due to the use of `SIGHASH_NOINPUT` and the non-stable txids involved, any transaction you wish to transport in the offchain update mechanism needs to also be signed under `SIGHASH_NOINPUT`, but again this is not onerous.\nIn any case it is \"only\" a matter of tradeoffs one is willing to work under anyway, and Decker-Russell-Osuntokun is very cool and uses `nLockTime` and `OP_CHECKLOCKTIMEVERIFY` in a very clever way.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Reconciling the off-chain and on-chain models with eltoo",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Christian Decker"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 8952
        }
    },
    {
        "title": "[bitcoin-dev] PoW fraud proofs without a soft fork",
        "thread_messages": [
            {
                "author": "Ruben Somsen",
                "date": "2019-09-08T03:39:28",
                "message_text_only": "After looking more deeply into Tadge Dryja\u2019s utreexo work [0], it has\nbecome clear to me that this opens up a way to implement PoW fraud\nproofs [1] without a soft fork. With utreexo, we can efficiently\nverify state transitions between blocks. Verifying a block from a\nvalid utreexo hash requires only about a megabyte worth of merkle\nproofs.\n\nPoW fraud proofs assume that block N is valid if no miner has tried to\nfork it (read my original post for details [1]). We can extend that\nassumption to the utreexo hash of block N, and use that to verify fork\nblock N+1, and reject it if the block is invalid, with just 2-3MB of\ndata.\n\nFor simplicity, I\u2019ll first start by explaining a version with\ncommitments (which would require a soft fork).\n\nWhen a fork (i.e. a PoW fraud proof) occurs at height N+1, indicating\nthat the block might be invalid, you\u2019d need to download:\n\n1. block N+1 from the most PoW chain (~1-2MB)\n2. the utreexo hash commitment inside of block N (e.g. a merkle path\nto the coinbase)\n3. the utreexo merkle proofs which prove that all inputs of N+1 are\npart of the UTXO set (~1MB)\n\nOf course step 2 requires a soft fork, but we can also do a\nnon-committed version by relying on the assumption that at least one\nof your peers is honest and then evaluate disagreements.\n\nWe simply replace step 2 above with the following:\n2. [Download] the utreexo hash of block N from all your peers\n\nIf it turns out that one of your peers disagrees on what the correct\nhash is, you find the last utreexo hash where that peer still agreed,\nlet\u2019s say block M, and you simply execute the same three steps to find\nout which peer is wrong: download block M+1, then get the merkle\nproofs to verify whether the peer correctly transitioned their utreexo\nhash from M to M+1.\n\nOne might intuitively feel that the lack of a commitment is unsafe,\nbut there seems to be no impact on security (only bandwidth). The only\nway you can be fooled is if all peers lie to you (Sybil), causing you\nto follow a malicious minority chain. But even full nodes (or the\ncommitted version of PoW fraud proofs) can be fooled in this way if\nthey are denied access to the valid most PoW chain. If there are\nadditional security concerns I overlooked, I\u2019d love to hear them.\n\nIn short, utreexo can enable PoW fraud proofs without a soft fork. At\nthe cost of downloading a couple of MB per stale block (and per\nmalicious peer), an SPV client gains the ability to (eventually)\nreject the most PoW chain as long as one honest block gets mined,\nthereby increasing its security beyond 51% honest miners.\n\nFinally, while I think this goes without saying, I\u2019d like to reiterate\nthat this is by no means a replacement for running a full node. You\u2019re\ndepending on other full nodes to do full verification and assuming at\nleast some of the miners are honest. If everyone did this, Bitcoin\nwould not be secure.\n\n-- Ruben Somsen\n\n\n[0] Utreexo paper: https://eprint.iacr.org/2019/611.pdf\n\n[1] Improving SPV security with PoW fraud proofs:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-April/016873.html"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-09T04:14:07",
                "message_text_only": "Good morning Ruben,\n\n\n>     One might intuitively feel that the lack of a commitment is unsafe,\n>     but there seems to be no impact on security (only bandwidth). The only\n>     way you can be fooled is if all peers lie to you (Sybil), causing you\n>     to follow a malicious minority chain. But even full nodes (or the\n>     committed version of PoW fraud proofs) can be fooled in this way if\n>     they are denied access to the valid most PoW chain. If there are\n>     additional security concerns I overlooked, I\u2019d love to hear them.\n\n\nI think it would be better to more precisely say that:\n\n1.  In event of a sybil attack, a fullnode will stall and think the blockchain has no more miners.\n2.  In event of a sybil attack, an SPV, even using this style, will follow the false blockchain.\n\nThis has some differences when considering automated systems.\n\nOnchain automated payment processing systems, which use a fullnode, will refuse to acknowledge any incoming payments.\nThis will lead to noisy complaints from clients of the automated payment processor, but this is a good thing since it warns the automated payment processor of the possibility of this attack occurring on them.\nThe use of a timeout wherein if the fullnode is unable to see a new block for, say, 6 hours, could be done, to warn higher-layer management systems to pay attention.\nWhile it is sometimes the case that the real network will be unable to find a new block for hours at a time, this warning can be used to confirm if such an event is occurring, rather than a sybil attack targeting that fullnode.\n\nOn the other hand, such a payment processing system, which uses an SPV with PoW fraud proofs, will be able to at least see incoming payments, and continue to release product in exchange for payment.\nYet this is precisely a point of attack, where the automated payment processing system is sybilled and then false payments are given to the payment processor on the attack chain, which are double-spent on the global consensus chain.\nAnd the automated system may very well not be able to notice this.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Dragi Bucukovski",
                "date": "2019-09-09T04:47:17",
                "message_text_only": "How much do I have in my account can you please tell me \n\nSent from my iPhone\n\n> On 9 Sep 2019, at 2:14 pm, ZmnSCPxj via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Good morning Ruben,\n> \n> \n>>    One might intuitively feel that the lack of a commitment is unsafe,\n>>    but there seems to be no impact on security (only bandwidth). The only\n>>    way you can be fooled is if all peers lie to you (Sybil), causing you\n>>    to follow a malicious minority chain. But even full nodes (or the\n>>    committed version of PoW fraud proofs) can be fooled in this way if\n>>    they are denied access to the valid most PoW chain. If there are\n>>    additional security concerns I overlooked, I\u2019d love to hear them.\n> \n> \n> I think it would be better to more precisely say that:\n> \n> 1.  In event of a sybil attack, a fullnode will stall and think the blockchain has no more miners.\n> 2.  In event of a sybil attack, an SPV, even using this style, will follow the false blockchain.\n> \n> This has some differences when considering automated systems.\n> \n> Onchain automated payment processing systems, which use a fullnode, will refuse to acknowledge any incoming payments.\n> This will lead to noisy complaints from clients of the automated payment processor, but this is a good thing since it warns the automated payment processor of the possibility of this attack occurring on them.\n> The use of a timeout wherein if the fullnode is unable to see a new block for, say, 6 hours, could be done, to warn higher-layer management systems to pay attention.\n> While it is sometimes the case that the real network will be unable to find a new block for hours at a time, this warning can be used to confirm if such an event is occurring, rather than a sybil attack targeting that fullnode.\n> \n> On the other hand, such a payment processing system, which uses an SPV with PoW fraud proofs, will be able to at least see incoming payments, and continue to release product in exchange for payment.\n> Yet this is precisely a point of attack, where the automated payment processing system is sybilled and then false payments are given to the payment processor on the attack chain, which are double-spent on the global consensus chain.\n> And the automated system may very well not be able to notice this.\n> \n> Regards,\n> ZmnSCPxj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Ruben Somsen",
                "date": "2019-09-09T06:53:28",
                "message_text_only": "Hi ZmnSCPxj,\n\nThank you for your comments. You raise an important point that I should clarify.\n\n>1.  In event of a sybil attack, a fullnode will stall and think the blockchain has no more miners.\n\nYou can still attack the full node by feeding it a minority PoW chain,\nthen it won't stall.\n\n>2.  In event of a sybil attack, an SPV, even using this style, will follow the false blockchain.\n\nCorrect, but this false blockchain does need to have valid PoW.\n\nSo in both cases valid PoW is required to fool nodes. The one\ndifference is that for a full node, the blocks themselves also need to\nbe valid (except for the fact that they are in a minority chain), but\nthe end result is still that a victim can be successfully double spent\nand lose money.\n\nI hope this clarifies why I consider the security for these two\nsituations to be roughly equivalent. In either situation, victims can\nbe fooled into accepting invalid payments.\n\nCheers,\nRuben\n\nOn Mon, Sep 9, 2019 at 6:14 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n> Good morning Ruben,\n>\n>\n> >     One might intuitively feel that the lack of a commitment is unsafe,\n> >     but there seems to be no impact on security (only bandwidth). The only\n> >     way you can be fooled is if all peers lie to you (Sybil), causing you\n> >     to follow a malicious minority chain. But even full nodes (or the\n> >     committed version of PoW fraud proofs) can be fooled in this way if\n> >     they are denied access to the valid most PoW chain. If there are\n> >     additional security concerns I overlooked, I\u2019d love to hear them.\n>\n>\n> I think it would be better to more precisely say that:\n>\n> 1.  In event of a sybil attack, a fullnode will stall and think the blockchain has no more miners.\n> 2.  In event of a sybil attack, an SPV, even using this style, will follow the false blockchain.\n>\n> This has some differences when considering automated systems.\n>\n> Onchain automated payment processing systems, which use a fullnode, will refuse to acknowledge any incoming payments.\n> This will lead to noisy complaints from clients of the automated payment processor, but this is a good thing since it warns the automated payment processor of the possibility of this attack occurring on them.\n> The use of a timeout wherein if the fullnode is unable to see a new block for, say, 6 hours, could be done, to warn higher-layer management systems to pay attention.\n> While it is sometimes the case that the real network will be unable to find a new block for hours at a time, this warning can be used to confirm if such an event is occurring, rather than a sybil attack targeting that fullnode.\n>\n> On the other hand, such a payment processing system, which uses an SPV with PoW fraud proofs, will be able to at least see incoming payments, and continue to release product in exchange for payment.\n> Yet this is precisely a point of attack, where the automated payment processing system is sybilled and then false payments are given to the payment processor on the attack chain, which are double-spent on the global consensus chain.\n> And the automated system may very well not be able to notice this.\n>\n> Regards,\n> ZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-09T06:58:12",
                "message_text_only": "Good morning Ruben,\n\nYes, I suppose that is correct.\n\nI suppose the critical difference is that invalid inflation can fool the SPV node, the fullnode will not be so fooled.\n\nA somewhat larger-scale attack is to force a miner-supported miner-subsidy-increase / blocksize-increase hard fork.\nIf enough such SPV nodes can be sybilled, they can be forced to use the hard fork, which might incentivize them to support the hard fork rather than back-compatible consensus chain.\n\nRegards,\nZmnSCPxj\n\n> Hi ZmnSCPxj,\n>\n> Thank you for your comments. You raise an important point that I should clarify.\n>\n> > 1.  In event of a sybil attack, a fullnode will stall and think the blockchain has no more miners.\n>\n> You can still attack the full node by feeding it a minority PoW chain,\n> then it won't stall.\n>\n> > 2.  In event of a sybil attack, an SPV, even using this style, will follow the false blockchain.\n>\n> Correct, but this false blockchain does need to have valid PoW.\n>\n> So in both cases valid PoW is required to fool nodes. The one\n> difference is that for a full node, the blocks themselves also need to\n> be valid (except for the fact that they are in a minority chain), but\n> the end result is still that a victim can be successfully double spent\n> and lose money.\n>\n> I hope this clarifies why I consider the security for these two\n> situations to be roughly equivalent. In either situation, victims can\n> be fooled into accepting invalid payments.\n>\n> Cheers,\n> Ruben\n>\n> On Mon, Sep 9, 2019 at 6:14 AM ZmnSCPxj ZmnSCPxj at protonmail.com wrote:\n>\n> > Good morning Ruben,\n> >\n> > >     One might intuitively feel that the lack of a commitment is unsafe,\n> > >     but there seems to be no impact on security (only bandwidth). The only\n> > >     way you can be fooled is if all peers lie to you (Sybil), causing you\n> > >     to follow a malicious minority chain. But even full nodes (or the\n> > >     committed version of PoW fraud proofs) can be fooled in this way if\n> > >     they are denied access to the valid most PoW chain. If there are\n> > >     additional security concerns I overlooked, I\u2019d love to hear them.\n> > >\n> >\n> > I think it would be better to more precisely say that:\n> >\n> > 1.  In event of a sybil attack, a fullnode will stall and think the blockchain has no more miners.\n> > 2.  In event of a sybil attack, an SPV, even using this style, will follow the false blockchain.\n> >\n> > This has some differences when considering automated systems.\n> > Onchain automated payment processing systems, which use a fullnode, will refuse to acknowledge any incoming payments.\n> > This will lead to noisy complaints from clients of the automated payment processor, but this is a good thing since it warns the automated payment processor of the possibility of this attack occurring on them.\n> > The use of a timeout wherein if the fullnode is unable to see a new block for, say, 6 hours, could be done, to warn higher-layer management systems to pay attention.\n> > While it is sometimes the case that the real network will be unable to find a new block for hours at a time, this warning can be used to confirm if such an event is occurring, rather than a sybil attack targeting that fullnode.\n> > On the other hand, such a payment processing system, which uses an SPV with PoW fraud proofs, will be able to at least see incoming payments, and continue to release product in exchange for payment.\n> > Yet this is precisely a point of attack, where the automated payment processing system is sybilled and then false payments are given to the payment processor on the attack chain, which are double-spent on the global consensus chain.\n> > And the automated system may very well not be able to notice this.\n> > Regards,\n> > ZmnSCPxj"
            },
            {
                "author": "Ruben Somsen",
                "date": "2019-09-11T04:58:57",
                "message_text_only": "Hi ZmnSCPxj,\n\n>I suppose the critical difference is that invalid inflation can fool the SPV node, the fullnode will not be so fooled.\n\nThat is correct. If you sybil the SPV node, you can break any\nconsensus rule you like. I believe this is inherent to fraud proofs in\ngeneral, because you skip consensus checks unless you're able to\nreceive a fraud proof.\n\nBut note that my goal in the comparison was to assert that there is no\nsecurity difference between committing or not committing the utreexo\nhash into a block. The attack your describe works in either situation,\nso my conclusion remains that committing the hash adds no security.\n\nOther weaknesses compared to full nodes are:\n- the SPV nodes rely on the existence of a healthy network of utreexo\nsupporting full nodes\n- at least one honest block needs to be mined\n- consensus slows down, because you need to allow time for an honest\nminority to produce a block\n\nCheers,\nRuben\n\nOn Mon, Sep 9, 2019 at 8:58 AM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n>\n> Good morning Ruben,\n>\n> Yes, I suppose that is correct.\n>\n> I suppose the critical difference is that invalid inflation can fool the SPV node, the fullnode will not be so fooled.\n>\n> A somewhat larger-scale attack is to force a miner-supported miner-subsidy-increase / blocksize-increase hard fork.\n> If enough such SPV nodes can be sybilled, they can be forced to use the hard fork, which might incentivize them to support the hard fork rather than back-compatible consensus chain.\n>\n> Regards,\n> ZmnSCPxj\n>\n> > Hi ZmnSCPxj,\n> >\n> > Thank you for your comments. You raise an important point that I should clarify.\n> >\n> > > 1.  In event of a sybil attack, a fullnode will stall and think the blockchain has no more miners.\n> >\n> > You can still attack the full node by feeding it a minority PoW chain,\n> > then it won't stall.\n> >\n> > > 2.  In event of a sybil attack, an SPV, even using this style, will follow the false blockchain.\n> >\n> > Correct, but this false blockchain does need to have valid PoW.\n> >\n> > So in both cases valid PoW is required to fool nodes. The one\n> > difference is that for a full node, the blocks themselves also need to\n> > be valid (except for the fact that they are in a minority chain), but\n> > the end result is still that a victim can be successfully double spent\n> > and lose money.\n> >\n> > I hope this clarifies why I consider the security for these two\n> > situations to be roughly equivalent. In either situation, victims can\n> > be fooled into accepting invalid payments.\n> >\n> > Cheers,\n> > Ruben\n> >\n> > On Mon, Sep 9, 2019 at 6:14 AM ZmnSCPxj ZmnSCPxj at protonmail.com wrote:\n> >\n> > > Good morning Ruben,\n> > >\n> > > >     One might intuitively feel that the lack of a commitment is unsafe,\n> > > >     but there seems to be no impact on security (only bandwidth). The only\n> > > >     way you can be fooled is if all peers lie to you (Sybil), causing you\n> > > >     to follow a malicious minority chain. But even full nodes (or the\n> > > >     committed version of PoW fraud proofs) can be fooled in this way if\n> > > >     they are denied access to the valid most PoW chain. If there are\n> > > >     additional security concerns I overlooked, I\u2019d love to hear them.\n> > > >\n> > >\n> > > I think it would be better to more precisely say that:\n> > >\n> > > 1.  In event of a sybil attack, a fullnode will stall and think the blockchain has no more miners.\n> > > 2.  In event of a sybil attack, an SPV, even using this style, will follow the false blockchain.\n> > >\n> > > This has some differences when considering automated systems.\n> > > Onchain automated payment processing systems, which use a fullnode, will refuse to acknowledge any incoming payments.\n> > > This will lead to noisy complaints from clients of the automated payment processor, but this is a good thing since it warns the automated payment processor of the possibility of this attack occurring on them.\n> > > The use of a timeout wherein if the fullnode is unable to see a new block for, say, 6 hours, could be done, to warn higher-layer management systems to pay attention.\n> > > While it is sometimes the case that the real network will be unable to find a new block for hours at a time, this warning can be used to confirm if such an event is occurring, rather than a sybil attack targeting that fullnode.\n> > > On the other hand, such a payment processing system, which uses an SPV with PoW fraud proofs, will be able to at least see incoming payments, and continue to release product in exchange for payment.\n> > > Yet this is precisely a point of attack, where the automated payment processing system is sybilled and then false payments are given to the payment processor on the attack chain, which are double-spent on the global consensus chain.\n> > > And the automated system may very well not be able to notice this.\n> > > Regards,\n> > > ZmnSCPxj\n>\n>"
            },
            {
                "author": "David A. Harding",
                "date": "2019-09-16T16:48:21",
                "message_text_only": "On Sun, Sep 08, 2019 at 05:39:28AM +0200, Ruben Somsen via bitcoin-dev wrote:\n> After looking more deeply into Tadge Dryja\u2019s utreexo work [0], it has\n> become clear to me that this opens up a way to implement PoW fraud\n> proofs [1] without a soft fork. \n\nThis is a nifty idea.\n\n> [...] you\u2019d need to download:\n>\n> [...]\n>\n> 3. the utreexo merkle proofs which prove that all inputs of N+1 are\n> part of the UTXO set (~1MB)\n\nI think \"~1 MB\" is probably a reasonable estimate for the average case\nbut not for the worst case.  To allow verification of the spends in\nblock N+1, each UTXO entry must contain its entire scriptPubKey.  I\nbelieve the current consensus rules allow scriptPubKeys to be up to\n10,000 bytes in size.  A specially-constructed block can contain a bit\nmore than 20,000 inputs, making the worst case size of just the UTXO\nentries that needs to be communicated over 200 MB.\n\n> If it turns out that one of your peers disagrees on what the correct\n> hash is, you find the last utreexo hash where that peer still agreed,\n> let\u2019s say block M, and you simply execute the same three steps to find\n> out which peer is wrong\n\nI think this also expands to a worst-case of over 200 MB.  A lying peer\nwill only be able to get you on one of these checks, so it's 200 MB per\nlying peer.  For an honest peer communicating valid blocks, the worst\ncase is that they'll need to communicate both of these state\ntransactions, so over 400 MB.  That could be a bandwidth-wasting DoS\nattack on honest listening nodes if there were a large number of SPV\nclients using this type of fraud proofs.\n\nAdditionally, each node capable of providing fraud proofs will need to\npersistently store the state transition proof for each new block.  I\nassume this is equal to the block undo data currently stored by archival\nfull nodes plus the utreexo partial merkle branches.\n\nThis data would probably not be stored by pruned nodes, at least not\nbeyond their prune depth, even for pruned nodes that use utreexo.  That\nwould mean this system will only work with archival full nodes with an\nextra \"index\" containing the utreexo partial merkle branches, or it will\nrequire querying utreexo bridge nodes.\n\nGiven that both of those would require significant additional system\nresources beyond the minimum required to operate a full node, such nodes\nmight be rare and so make it relatively easy to eclipse attack an SPV\nclient depending on these proofs.\n\nFinally, this system depends on SPV clients implementing all the same\nconsensus checks that full nodes can currently perform.  Given that most\nSPV clients I'm aware of today don't even perform the full range of\nchecks it's possible to run on block headers, I have serious doubts that\nmany (or any) SPV clients will actually implement full verification.  On\ntop of that, each client must implement those checks perfectly or they\ncould be tricked into a chainsplit the same as a full node that follows\ndifferent rules than the economic consensus.\n\n> [1] Improving SPV security with PoW fraud proofs:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-April/016873.html\n\nOne thing I didn't like in your original proposal---which I appologize\nfor keeping to myself---is that the SPV client will accept confirmations\non the bad chain until a fork is produced.  Even a miner with a minority\nof the hash rate will sometimes be able to produce a 6-block chain before\nthe remaining miners produce a single block.  In that case, SPV clients\nwith a single dishonest peer in collusion with the miner will accept any\ntransctions in the first block of that chain as having six\nconfirmations.  That's the same as it is today, but today SPV users\ndon't think fraud proofs help keep them secure.\n\nI think that, if we wanted to widely deploy fraud proofs depending on\nforks as a signal, we'd have to also retrain SPV users to wait for much\nhigher confirmation counts before accepting transactions as reasonably\nsecure.\n\n-Dave"
            }
        ],
        "thread_summary": {
            "title": "PoW fraud proofs without a soft fork",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "David A. Harding",
                "Dragi Bucukovski",
                "Ruben Somsen"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 23414
        }
    },
    {
        "title": "[bitcoin-dev] [Lightning-dev] Reconciling the off-chain and on-chain models with eltoo",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-10T01:28:04",
                "message_text_only": "Good morning Richard,\n\n> I believe using the eltoo update scheme as a way to consolidate blocks of off-chain transactions is an interesting idea worth exploring.\u00a0\u00a0\n>\n> ZmnSCPxj brings up some limitations on arbitrary outputs scripts in eltoo. Although using CSV is more complicated and outputs must also use SIGHASH_NOINPUT [1], the ability to have multiple party channels and the most used types of scripts makes eltoo compelling compared to LN-Penalty for this kind of application.\n\nI broadly agree.\n\nI imagine a future where most people do not typically have single-signer ownership of coins onchain, but are instead share-owners of coins, with single-signer ownership occurring onchain only in the case of dispute or for long-term cold storage.\n\n>\n> The multiple party aspect in particular introduces an interesting way to unify concepts from different second layer protocols like federated sidechains and statechains (ht.\u00a0aakselrod [2]).\n>\n> Though the Statechains proposal relies on eltoo [3], I think what Christian suggested does not try to solve the dynamic membership problem. That's why I think of this as more an evolution of the channel factory paper towards something like a federated sidechain.\n>\n> > I think this reconciliation between the off-chain model and the on-chain\n> > model, with many concepts cleanly mapping from one context to another\n> > (state outputs = UTXO, off-chain update = on-chain transactions,\n> > cut-through = confirmation, operation batching = block creation) is\n> > rather nice :-)\n>\n> One additional concept that could be new to this off-chain blockchain model would be something like batched multi-party loop-in/out. In a Schnorr/Taproot world you could add signers/inputs and remove signers/outputs with a single multi-signature negotiated off-chain. You'd still like to limit these onchain txs, even if they are small, but updating channels periodically seems like a straight forward way to address the dynamic membership problem.\n\nIndeed.\nSuch a change-in-membership transaction would be a 1-input 1-output transaction, and with use of n-of-n MuSig would be as small (and as private, modulo the fact that you are coordinating this with a bunch of other participants) as a single-sig user making a 1-input 1-output transaction (which generally is not very private because such transactions are usually \"send-to-self\" and changing membership generally means ownership does not actually change much).\nThe cost of this transaction would be small (certainly smaller than the update+state transactions needed in Decker-Russell-Osuntokun)\n\nFor setting this up, it might be useful to have the below ritual.\nThis assumes only a change in the membership set is desired, without a simultaneous change in the UTXO set.\n\n1.  Create a new update+state transaction for the current Decker-Russell-Osuntokun mechanism.\n    The state transaction pays out to a single output paying to the new membership set rather than the current UTXO set of the mechanism.\n    Do *not* sign this yet.\n    Call this the \"final\" update+state transaction.\n2.  Create a new Decker-Russell-Osuntokun mechanism initial update+state transaction.\n    This pays out to the current UTXO set of the previous mechanism.\n    This will spend from the new membership set.\n    Completely sign these transactions.\n    * The update transaction can spend the above \"final\" transaction, as it is `SIGHASH_NOINPUT`.\n3.  Sign the final update+state transaction of the previous Decker-Russell-Osuntokun mechanism.\n    Do *not* broadcast the update+state transaction yet.\n4.  Create and sign the membership-change onchain transaction.\n    This spends the current onchain funding transaction output and outputs to the same new membership set.\n    Broadcast this onchain.\n\nThe above ritual ensures that, after step 3 completes, the mechanism can continue operating without waiting for onchain activity to complete.\nIt ensures that, even if the membership-change onchain transaction becomes invalid later (by somebody bribing a miner to publish a previous update transaction from the older membership set), we will still enter an update that will eventually put the new membership set onchain.\nThis reduces the critical path to only steps 1 to 3, and we can continue operating with the new membership set as soon as step 3 completes and we do not need to wait for the membership-change transaction to be deeply-confirmed in order to use the new membership set mechanism.\n\nHowever, it has the drawback that, until the membership-change onchain transaction is deeply-confirmed onchain, the CSV parameter is temporarily doubled (as there is the possibility that the previous mechanism is closed).\nAlso, the mechanism cannot be mutually closed until the membership-change onchain transaction is deeply-confirmed, as there is no stable txid we can spend from (we would strongly prefer to use `SIGHASH_ALL` for cooperative closes to improve our privacy).\n\n>\n> I guess this all gets back to how to design an off-chain protocol for managing these negotiations. Ultimately I can imagine a sort of multi-party eltoo based 'signet' with the same RPC interface, but different transaction validation and block creation logic.\u00a0 Perhaps there would be a new message where the channel parties would add their signature before forwarding a valid block, and the block wouldn't be built on until all parties had signed.\n\nThe \"block\" that would need to be signed by the participants would actually be a Decker-Russell-Osuntokun update+state transaction, and would commit to the UTXO set rather than the transaction set.\nUnless I misunderstand your meaning here.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-18T05:28:38",
                "message_text_only": "Good morning Richards, and list,\n\n> Thanks for the feedback ZmnSCPxj.\n>\n> > I imagine a future where most people do not typically have single-signer ownership of coins onchain, but are instead share-owners of coins, with single-signer ownership occurring onchain only in the case of dispute or for long-term cold storage.\n>\n> The change-in-membership ritual you describe seems like a good start for elaborating on this idea.\u00a0\n>\n> Some aspects of multi-party Decker-Russell-Osuntokun channels have analogs to a signet blockchain that use a n-of-n federation of signers. But other places, like change-in-membership, do not have direct analogs.\n>\n> For example, some signet concepts with multi-party channel analogs:\n>\n> block script:\n> * the first 'update' and 'settle' transactions, aka 'setup' and 'refund' transactions, define the set of signers that must sign subsequent channel updates\n>\n> genesis block:\n> * the initial 'funding' transaction, aka outpoint of the commitment transaction, which establishes the funded channel\n>\n> utxo set:\n> * the specific set of on-chain outputs from the 'settlement' transaction that spends the balance of the latest 'update' transaction signed by the complete set of channel parties.\n>\n> mempool:\n> * the set of proposals for specific changes to the set of outputs from the latest 'settlement' transaction (similar to update_add_htlc, update_fail_htlc, etc)\n>\n> Concepts where layer two channels do not have an obvious analog to a layer one signet blockchain:\n>\n> cooperative close:\n> * when all parties mutually agree to close the channel\n> * close the channel with a layer one transaction which finalizes the outputs from the most recent channel output state\n> * should be optimized for privacy and low on-chain fees\n\nOf note is that a close of an update mechanism does not require the close of any hosted update mechanisms, or more prosaically, \"close of channel factory does not require close of hosted channels\".\nThis is true for both unilateral and cooperative closes.\n\nOf course, the most likely reason you want to unilaterally close an outer mechanism is if you have some contract in some deeply-nested mechanism that will absolute-locktime expire \"soon\", in which case you have to close everything that hosts it.\nBut for example if a channel factory has channels A B C and only A has an HTLC that will expire soon, while the factory and A have to close, B and C can continue operation, even almost as if nothing happened to A.\n\n>\n> membership change (ZmnSCPxj ritual):\n> * when channel parties want to leave or add new members to the channel\n> * close and reopen a new channel via something like a channel splicing transaction to the layer one blockchain\n> * should be optimized for privacy and low on-chain fees paid for by parties entering and leaving the channel\n\nAssuming you mean that any owned funds will eventually have to be claimed onchain, I suppose this is doable as splice-out.\n\nBut note that currently we have some issues with splice-in.\n\nAs far as I can tell (perhaps Lisa Neigut can correct me, I believe she is working on this), splice-in has the below tradeoffs:\n\n1.  Option 1: splice-in is async (other updates can continue after all participants have sent the needed signatures for the splice-in).\n    Drawback is that spliced-in funds need to be placed in a temporary n-of-n, meaning at least one additional tx.\n2.  Option 2: splice-in is efficient (only the splice-in tx appears onchain).\n    Drawback is that subsequent updates can only occur after the splice-in tx is deeply confirmed.\n    * This can be mitigated somewhat by maintaining a pre-splice-in and post-splice-in mechanism, until the splice-in tx is deeply confirmed, after which the pre-splice-in version is discarded.\n      Updates need to be done on *both* mechanisms until then, and any introduced money is \"unuseable\" anyway until the splice-in tx confirms deeply since it would not exist in the pre-splice-in mechanism yet.\n\nBut perhaps a more interesting thing (and more in keeping with my sentiment \"a future where most people do not typically have single-signer ownership of coins onchain\") would be to transfer funds from one multiparticipant offchain mechanism to another multiparticipant offchain, by publishing a single transaction onchain.\nIt may be doable via some extension of my proposed ritual for changing membership set.\n\n>\n> balance change (similar to membership change):\n> * when channel parties want to add or remove some of the finalized value in the channel\n> * close and reopen a new channel via something like a channel splicing transaction to the layer one blockchain\n> * should be optimized for privacy and low on-chain fees paid for by parties adding and removing value from the channel\n>\n> uncooperative close:\n> * when one or more nodes fails to sign the next channel state update\n> * use a layer one transaction to commit both finalized and un-finalized outputs from the most recent channel output state\n> * script timeouts determine when channel parties should uncooperatively close the channel if not all parties have signed the next 'update' and 'settlement' transaction\n>\n> uncooperative membership change:\n> * a subset of channel parties might want to cooperatively sign a channel splicing transaction to 'splice out' uncooperative parties\n\nI believe this is currently considered unsafe.\nhttps://lists.linuxfoundation.org/pipermail/lightning-dev/2019-April/001975.html\n\nUnless you refer to another mechanism...?\n\nI believe this will end up requiring deep confirmation of the uncooperative close followed by a new mechanism open.\n\n>\n> mining, mining reward and difficulty adjustment\n> * no equivalent concept for multi-party channels\n\nFees for each update.\nConsider how HTLC routing in Lightning implicitly pays forwarding nodes to cooperate with the forwarding.\nI imagine most nodes in a multiparticipant offchain system will want to be paid for cooperation, even if just a nominal sub-satoshi amount.\n\n>\n> transaction fees:\n> * updates to layer two channels do not incur transactions fees\n> * invalid updates dropped to layer one should be paid by cheating node\n> * splice in/out transactions should be paid by requesting signers only\n> * do transaction fees prevent 'griefing' attacks?\n>\n> privacy:\n> * disassociate a particular update from signer(s)\n> * disassociate IP address of signers from signature\n> * using SIGHASH_ALL for cooperative closes\n\nI suppose Tor can be used to disassociate IP address from signers if everyone is from a hidden service.\nHowever, we need to include some kind of mix mechanism to allow individual signers to disassociate their ownership of funds from their identity as signers.\nThough such mechanisms already exist as theoretical constructs, so \"just needs implementing\".\n\nBut then again: if you own funds in the mechanism, you *should* be a signer (else you are trusting a federation).\nSo a basic fact here is that if you are a participant in some offchain mechanism, you are likely (approaching 100% probability) to own money in it.\n\n>\n> liveness:\n> * if signers know they will be offline, can they pre-sign updates that just commit their own outputs, rather then splice out?\n> * contingent tap-leafs to splice out non-responsive signers\n\nIt might be possible to create a new mechanism-within-mechanism layer, if a signer knows they will be offline.\n\nFor example, suppose entities A, B, and C have an offchain update mechanism, which we shall call a \"factory\".\nSuppose this factory contains an A-B channel, a B-C channel, a A-C channel, and some funds owned by B only.\nThen suppose A knows he or she will be offline for some time.\nBefore A goes offline, they can move from this UTXO set:\n\n* A-B channel\n* B-C channel\n* A-C channel\n* B funds\n\nTo this UTXO set:\n\n* A-B channel\n* A-C channel\n* B-C offchain update mechanism (sub-factory), which itself has its own UTXO set:\n  * B-C channel\n  * B funds\n\nThis allows B and C to manage the B-C channels and B funds without cooperation of A.\nThen, later, when A returns online, the B-C offchain update mechanism is collapsed back to the parent A-B-C offchain update mechanism.\n\nThis assumes A knows it will be offline (which it might do for e.g. regular maintenance, or software updates).\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Christian Decker",
                "date": "2019-09-18T13:44:47",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n>> cooperative close:\n>> * when all parties mutually agree to close the channel\n>> * close the channel with a layer one transaction which finalizes the outputs from the most recent channel output state\n>> * should be optimized for privacy and low on-chain fees\n>\n> Of note is that a close of an update mechanism does not require the\n> close of any hosted update mechanisms, or more prosaically, \"close of\n> channel factory does not require close of hosted channels\".  This is\n> true for both unilateral and cooperative closes.\n>\n> Of course, the most likely reason you want to unilaterally close an\n> outer mechanism is if you have some contract in some deeply-nested\n> mechanism that will absolute-locktime expire \"soon\", in which case you\n> have to close everything that hosts it.  But for example if a channel\n> factory has channels A B C and only A has an HTLC that will expire\n> soon, while the factory and A have to close, B and C can continue\n> operation, even almost as if nothing happened to A.\n\nIndeed this is something that I think we already mentioned back in the\nduplex micropayment channel days, though it was a bit hidden and only\nmentioned HTLCs (though the principle carries over for other structures\nbuilt on the raw update mechanism):\n\n> The process simply involves one party creating the teardown\n> transaction, both parties signing it and committing it to the\n> blockchain. HTLC outputs which have not been removed by agreement can\n> be copied over to the summary transaction such that the same timelocks\n> and resolution rules apply.\n\nNotice that in the case of eltoo the settlement transaction is already\nthe same as the teardown transaction in DMC.\n\n>> membership change (ZmnSCPxj ritual):\n>> * when channel parties want to leave or add new members to the channel\n>> * close and reopen a new channel via something like a channel splicing transaction to the layer one blockchain\n>> * should be optimized for privacy and low on-chain fees paid for by parties entering and leaving the channel\n>\n> Assuming you mean that any owned funds will eventually have to be\n> claimed onchain, I suppose this is doable as splice-out.\n>\n> But note that currently we have some issues with splice-in.\n>\n> As far as I can tell (perhaps Lisa Neigut can correct me, I believe\n> she is working on this), splice-in has the below tradeoffs:\n>\n> 1.  Option 1: splice-in is async (other updates can continue after all participants have sent the needed signatures for the splice-in).\n>     Drawback is that spliced-in funds need to be placed in a temporary\n>     n-of-n, meaning at least one additional tx.\n\nIndeed this is the first proposal I had back at the Milan spec meeting,\nand you are right that it requires stashing the funds in a temporary\nco-owned output to make sure the transition once we splice in is\natomic. Batching could help here, if we have 3 participants joining they\ncan coordinate to set the funds aside together and then splice-in at the\nsame time. The downside is the added on-chain transaction, and the fact\nthat the funds are not operational until they reach the required depth\n(I don't think we can avoid this with the current security guarantees\nprovided by Bitcoin). Notice that there is still some uncertainty\nregarding the confirmation of the splice-in even though the funds were\nstashed ahead of time, and we may end up in a state where we assumed\nthat the splice-in will succeed, but the fees we attached turn out to be\ntoo low. In this case we built a sandcastle that collapses due to our\nfoundation being washed away, and we'd have to go back and agree on\nre-splicing with corrected fees (which a malicious participant might\nsabotage) or hope the splice eventually confirms.\n\n> 2.  Option 2: splice-in is efficient (only the splice-in tx appears onchain).\n>     Drawback is that subsequent updates can only occur after the splice-in tx is deeply confirmed.\n>     * This can be mitigated somewhat by maintaining a pre-splice-in\n>     and post-splice-in mechanism, until the splice-in tx is deeply\n>     confirmed, after which the pre-splice-in version is discarded.\n>       Updates need to be done on *both* mechanisms until then, and any\n>     introduced money is \"unuseable\" anyway until the splice-in tx\n>     confirms deeply since it would not exist in the pre-splice-in\n>     mechanism yet.\n\nThis is the more complex variant we discussed during the last\nface-to-face in Australia, and it seemed to me that people were mostly\nin favor of doing it this way. It adds complexity since we maintain\nmultiple variants (making it almost un-implementable in LN-penalty),\nhowever the reduced footprint, and the uncertainty regarding\nconfirmations in the first solution are strong arguments in favor of\nthis option.\n\n> But perhaps a more interesting thing (and more in keeping with my\n> sentiment \"a future where most people do not typically have\n> single-signer ownership of coins onchain\") would be to transfer funds\n> from one multiparticipant offchain mechanism to another\n> multiparticipant offchain, by publishing a single transaction onchain.\n> It may be doable via some extension of my proposed ritual for changing\n> membership set.\n\nAside from a bit more coordination I don't see any roadblocks to do\nthis, and it'd be an awesome improvement. It even allows sub-dust\ntransfers between channels, as long as the total funds in the channel\nremain above dust :-)\n\n>> uncooperative membership change:\n>> * a subset of channel parties might want to cooperatively sign a channel splicing transaction to 'splice out' uncooperative parties\n>\n> I believe this is currently considered unsafe.\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-April/001975.html\n>\n> Unless you refer to another mechanism...?\n>\n> I believe this will end up requiring deep confirmation of the\n> uncooperative close followed by a new mechanism open.\n\nNot necessarily. If we have an escape hatch in the scripts that allows\nto spend any output attached to the settlement transaction by n-1\nparticipants we could reclaim these into a new open right away. The\nfootprint would be 1 unilateral close, n outputs for participants, m\noutputs for contracts built on top, and 1 open transaction that\nrecollects all outputs in which the non-responding participant is not a\nco-signer. The main advantage is that we can avoid downtime.\n\nJust spit-balling here, since it'd leak some of the update logic back\ninto the contracts built on top of the update mechanism, which for me is\nenough to discard this idea again.\n\n>> mining, mining reward and difficulty adjustment\n>> * no equivalent concept for multi-party channels\n>\n> Fees for each update.  Consider how HTLC routing in Lightning\n> implicitly pays forwarding nodes to cooperate with the forwarding.  I\n> imagine most nodes in a multiparticipant offchain system will want to\n> be paid for cooperation, even if just a nominal sub-satoshi amount.\n\nIf we allow generic contracts on top of the base update mechanism it'll\nbe rather difficult to identify the beneficiary of an update, so it's\nhard to know who should pay a fee. I'd rather argue that cooperating is\nin the interest of all participants since they'd eventually want to\ncreate an update of their own, and there is no upside to become\nunresponsive.\n\nNotice that the fees we leverage in LN are because we expose our funds\nto the risk of not being available by allocating them to an HTLC, not\nfor the updates themselves. Since in the forwarding scenario we're only\nexposing the funds of the forwarding nodes to this risk it's only\nnatural that they'd be the ones leveraging a fee, not the other\nparticipants that simply sign off on the change.\n\n>> privacy:\n>> * disassociate a particular update from signer(s)\n>> * disassociate IP address of signers from signature\n>> * using SIGHASH_ALL for cooperative closes\n>\n> I suppose Tor can be used to disassociate IP address from signers if\n> everyone is from a hidden service.  However, we need to include some\n> kind of mix mechanism to allow individual signers to disassociate\n> their ownership of funds from their identity as signers.  Though such\n> mechanisms already exist as theoretical constructs, so \"just needs\n> implementing\".\n>\n> But then again: if you own funds in the mechanism, you *should* be a\n> signer (else you are trusting a federation).  So a basic fact here is\n> that if you are a participant in some offchain mechanism, you are\n> likely (approaching 100% probability) to own money in it.\n\nNotice that we are negotiating whether or not to apply generic\ntransactions to a shared state. This also means that there is no direct\nrelationship between the ownership of an output and the ID signing off\non a change.\n\nThe privacy guarantees are identical to Bitcoin on-chain, with the one\ncaveat that we may identify the proposing participant, but we can defend\nagainst this by mixing as you propose.\n\n>> liveness:\n>> * if signers know they will be offline, can they pre-sign updates that just commit their own outputs, rather then splice out?\n>> * contingent tap-leafs to splice out non-responsive signers\n>\n> It might be possible to create a new mechanism-within-mechanism layer,\n> if a signer knows they will be offline.\n>\n> For example, suppose entities A, B, and C have an offchain update\n> mechanism, which we shall call a \"factory\".  Suppose this factory\n> contains an A-B channel, a B-C channel, a A-C channel, and some funds\n> owned by B only.  Then suppose A knows he or she will be offline for\n> some time.  Before A goes offline, they can move from this UTXO set:\n>\n> * A-B channel\n> * B-C channel\n> * A-C channel\n> * B funds\n>\n> To this UTXO set:\n>\n> * A-B channel\n> * A-C channel\n> * B-C offchain update mechanism (sub-factory), which itself has its own UTXO set:\n>   * B-C channel\n>   * B funds\n>\n> This allows B and C to manage the B-C channels and B funds without\n> cooperation of A.  Then, later, when A returns online, the B-C\n> offchain update mechanism is collapsed back to the parent A-B-C\n> offchain update mechanism.\n>\n> This assumes A knows it will be offline (which it might do for\n> e.g. regular maintenance, or software updates).\n\nWe could theoretically play this game, having each participant create\ntwo updates with the same state-number at each update:\n\n 1) A normal one that just keeps them in the contract\n 2) A fallback splice all outputs they own (direct ones, HTLCs, ...) and\n    putting the rest back into a channel without them.\n\nIn case of one user becoming inactive the others can sign the splice,\ndropping the inactive participant and continue like nothing\nhappened. The worst case scenario is that the normal update gets\nbroadcast and confirmed instead, which means we are back to the\nunilateral close that we'd have to do anyway without this mechanism.\n\nNotice however that this only works if participants drop off one by one,\notherwise we get a combinatorial explosion for the fallback cases where\neach combination of inactive participants needs to splice themselves\nout. It also adds the complexity of having to identify which participant\nis the co-owner of an output, otherwise I can claim ownership of an\nunrelated output and force that to move on-chain by including it in my\nfallback and then becoming unresponsive (added rounds of communication\ncan help here, but are cumbersome).\n\nIt may be a bit much added complexity for a small complexity to be\nhonest, hopefully this won't be needed too often :-)\n\nCheers,\nChristian"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-19T02:01:54",
                "message_text_only": "Good morning Christian, and list,\n\n\n> > > uncooperative membership change:\n> > >\n> > > -   a subset of channel parties might want to cooperatively sign a channel splicing transaction to 'splice out' uncooperative parties\n> >\n> > I believe this is currently considered unsafe.\n> > https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-April/001975.html\n> > Unless you refer to another mechanism...?\n> > I believe this will end up requiring deep confirmation of the\n> > uncooperative close followed by a new mechanism open.\n>\n> Not necessarily. If we have an escape hatch in the scripts that allows\n> to spend any output attached to the settlement transaction by n-1\n> participants we could reclaim these into a new open right away.\n\nThis would have to be very very carefully designed.\nThe entire point of requiring an n-of-n signature is:\n\n* By using an n-of-n signatory where *you* are a signer, you are completely immune to Sybil attacks: even if everybody other than *you* in the signatory set is secretly just one entity, this is no different from doing a 2-of-2 bog-standard boring sleepy Zzzzzz Poon-Dryja Lightning Network channel.\n  * Any m-of-n signatory where strictly m < n allows anybody with the ability to run m nodes to outright steal money from you.\n    * As processing power is cheap nowadays, there is no m that can be considered safe.\n      Your alternative is to fall back on proof-of-work, but that just means going onchain, so you might as well just do things onchain.\n  * This is why 2-of-2 channels work so well, it's the minimum useable construction and any multiparty construction, when Sybilled, devolves to a 2-of-2 channel.\n\nSo the n-1 participants would have to be very very very carefully limited in what they can do.\nAnd if the only \"right\" the n-1 participants can do is to force the nth participant to claim its funds onchain, then that is implementable with a transaction doing just that, which is pre-signed by the nth participant and given to participants 1..n-1.\n\n> > > mining, mining reward and difficulty adjustment\n> > >\n> > > -   no equivalent concept for multi-party channels\n> >\n> > Fees for each update. Consider how HTLC routing in Lightning\n> > implicitly pays forwarding nodes to cooperate with the forwarding. I\n> > imagine most nodes in a multiparticipant offchain system will want to\n> > be paid for cooperation, even if just a nominal sub-satoshi amount.\n>\n> If we allow generic contracts on top of the base update mechanism it'll\n> be rather difficult to identify the beneficiary of an update, so it's\n> hard to know who should pay a fee. I'd rather argue that cooperating is\n> in the interest of all participants since they'd eventually want to\n> create an update of their own, and there is no upside to become\n> unresponsive.\n>\n> Notice that the fees we leverage in LN are because we expose our funds\n> to the risk of not being available by allocating them to an HTLC, not\n> for the updates themselves. Since in the forwarding scenario we're only\n> exposing the funds of the forwarding nodes to this risk it's only\n> natural that they'd be the ones leveraging a fee, not the other\n> participants that simply sign off on the change.\n\nI suppose that could be argued.\n\nHowever, I imagine it is possible for some of the updates to be implementable via HTLCs within sub-mechanisms of the higher mechanism.\nIf so, a participant may refuse to sign for the higher mechanism in order to force others to use HTLCs on the lower mechanisms, and thereby earn fees due to HTLC usage.\nI believe I argue as much here: https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-July/002055.html\n\n> ZmnSCPxj can request a factory channel reorganization to move some funds from the ZmnSCPxj<->Rene channel to the ZmnSCPxj<->YAijbOJA channel.\n> This has the same effect, i.e. it allows a forwarding attempt to push through, that would not be possible without the factory-level channel reorganization.\n>\n> Further, assuming only ZmnSCPxj, YAijbOJA, and Rene are in the channel factory, then it is the same: all three need to be online in order for the JIT-routing to work.\n>\n> But I observed above that, in a channel rebalance using current channels (without factories) Rene cannot be convinced to waive the fee.\n\nThe counterargument above is that if rebalances can be made fee-free, then the above argument disappears.\n\n\n>\n> > > privacy:\n> > >\n> > > -   disassociate a particular update from signer(s)\n> > > -   disassociate IP address of signers from signature\n> > > -   using SIGHASH_ALL for cooperative closes\n> >\n> > I suppose Tor can be used to disassociate IP address from signers if\n> > everyone is from a hidden service. However, we need to include some\n> > kind of mix mechanism to allow individual signers to disassociate\n> > their ownership of funds from their identity as signers. Though such\n> > mechanisms already exist as theoretical constructs, so \"just needs\n> > implementing\".\n> > But then again: if you own funds in the mechanism, you should be a\n> > signer (else you are trusting a federation). So a basic fact here is\n> > that if you are a participant in some offchain mechanism, you are\n> > likely (approaching 100% probability) to own money in it.\n>\n> Notice that we are negotiating whether or not to apply generic\n> transactions to a shared state. This also means that there is no direct\n> relationship between the ownership of an output and the ID signing off\n> on a change.\n>\n> The privacy guarantees are identical to Bitcoin on-chain, with the one\n> caveat that we may identify the proposing participant, but we can defend\n> against this by mixing as you propose.\n\nYes, but if we later combine this with allowing multiilateral kick-out of a member that is unresponsive (i.e. we splice out the outputs it has at least partial ownership of, and keep only those that are owned only by the remaining members), then each member would have to honestly claim which UTXOs it is interested in keeping after it is kicked out of the membership set, defeating this point entirely.\nI believe this is roughly what you propose in the next point, and roughly what you would want with the \"n-1 participants\" earlier.\n\n>\n> > > liveness:\n> > >\n> > > -   if signers know they will be offline, can they pre-sign updates that just commit their own outputs, rather then splice out?\n> > > -   contingent tap-leafs to splice out non-responsive signers\n> >\n> > It might be possible to create a new mechanism-within-mechanism layer,\n> > if a signer knows they will be offline.\n> > For example, suppose entities A, B, and C have an offchain update\n> > mechanism, which we shall call a \"factory\". Suppose this factory\n> > contains an A-B channel, a B-C channel, a A-C channel, and some funds\n> > owned by B only. Then suppose A knows he or she will be offline for\n> > some time. Before A goes offline, they can move from this UTXO set:\n> >\n> > -   A-B channel\n> > -   B-C channel\n> > -   A-C channel\n> > -   B funds\n> >\n> > To this UTXO set:\n> >\n> > -   A-B channel\n> > -   A-C channel\n> > -   B-C offchain update mechanism (sub-factory), which itself has its own UTXO set:\n> >     -   B-C channel\n> >     -   B funds\n> >\n> > This allows B and C to manage the B-C channels and B funds without\n> > cooperation of A. Then, later, when A returns online, the B-C\n> > offchain update mechanism is collapsed back to the parent A-B-C\n> > offchain update mechanism.\n> > This assumes A knows it will be offline (which it might do for\n> > e.g. regular maintenance, or software updates).\n>\n> We could theoretically play this game, having each participant create\n> two updates with the same state-number at each update:\n>\n> 1.  A normal one that just keeps them in the contract\n> 2.  A fallback splice all outputs they own (direct ones, HTLCs, ...) and\n>     putting the rest back into a channel without them.\n>\n>     In case of one user becoming inactive the others can sign the splice,\n>     dropping the inactive participant and continue like nothing\n>     happened. The worst case scenario is that the normal update gets\n>     broadcast and confirmed instead, which means we are back to the\n>     unilateral close that we'd have to do anyway without this mechanism.\n>\n>     Notice however that this only works if participants drop off one by one,\n>     otherwise we get a combinatorial explosion for the fallback cases where\n>     each combination of inactive participants needs to splice themselves\n>     out. It also adds the complexity of having to identify which participant\n>     is the co-owner of an output, otherwise I can claim ownership of an\n>     unrelated output and force that to move on-chain by including it in my\n>     fallback and then becoming unresponsive (added rounds of communication\n>     can help here, but are cumbersome).\n\nThis might be a plausible way of implementing the \"n-1 participants can kick out nth participant\".\n\n>\n>     It may be a bit much added complexity for a small complexity to be\n>     honest, hopefully this won't be needed too often :-)\n\nStatement makes no sense, unless you meant to say \"It may be a bit much complexity for a small benefit\" or similar?\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Christian Decker",
                "date": "2019-09-19T10:26:13",
                "message_text_only": "ZmnSCPxj <ZmnSCPxj at protonmail.com> writes:\n>> Not necessarily. If we have an escape hatch in the scripts that allows\n>> to spend any output attached to the settlement transaction by n-1\n>> participants we could reclaim these into a new open right away.\n>\n> This would have to be very very carefully designed.\n> The entire point of requiring an n-of-n signature is:\n>\n> * By using an n-of-n signatory where *you* are a signer, you are completely immune to Sybil attacks: even if everybody other than *you* in the signatory set is secretly just one entity, this is no different from doing a 2-of-2 bog-standard boring sleepy Zzzzzz Poon-Dryja Lightning Network channel.\n>   * Any m-of-n signatory where strictly m < n allows anybody with the ability to run m nodes to outright steal money from you.\n>     * As processing power is cheap nowadays, there is no m that can be considered safe.\n>       Your alternative is to fall back on proof-of-work, but that just means going onchain, so you might as well just do things onchain.\n>   * This is why 2-of-2 channels work so well, it's the minimum useable construction and any multiparty construction, when Sybilled, devolves to a 2-of-2 channel.\n>\n> So the n-1 participants would have to be very very very carefully limited in what they can do.\n> And if the only \"right\" the n-1 participants can do is to force the nth participant to claim its funds onchain, then that is implementable with a transaction doing just that, which is pre-signed by the nth participant and given to participants 1..n-1.\n\nJust to be clear, I do *not* want to support uncooperative splice-outs.\nThis is due to their need to either pre-sign a splice-out of the party\nlike I explained further down, or it requires encumbering whatever we\nbuild on top in order to do a fast-reopen.\n\nBut I do think there is value in exploring what the options are :-)\n\n>> Notice that we are negotiating whether or not to apply generic\n>> transactions to a shared state. This also means that there is no direct\n>> relationship between the ownership of an output and the ID signing off\n>> on a change.\n>>\n>> The privacy guarantees are identical to Bitcoin on-chain, with the one\n>> caveat that we may identify the proposing participant, but we can defend\n>> against this by mixing as you propose.\n>\n> Yes, but if we later combine this with allowing multiilateral kick-out\n> of a member that is unresponsive (i.e. we splice out the outputs it\n> has at least partial ownership of, and keep only those that are owned\n> only by the remaining members), then each member would have to\n> honestly claim which UTXOs it is interested in keeping after it is\n> kicked out of the membership set, defeating this point entirely.  I\n> believe this is roughly what you propose in the next point, and\n> roughly what you would want with the \"n-1 participants\" earlier.\n\nThat is indeed the issue I explained further down:\n\n> It also adds the complexity of having to identify which participant is\n> the co-owner of an output, otherwise I can claim ownership of an\n> unrelated output and force that to move on-chain by including it in my\n> fallback and then becoming unresponsive (added rounds of communication\n> can help here, but are cumbersome).\n\nClaiming ownership would then involve providing a valid input script\n(disregarding any timelocks) that could spend the output under some\ncondition. Others would have to verify this proof-of-ownership before\naccepting the node's self-splice-out before accepting it.\n\n>>     It may be a bit much added complexity for a small complexity to be\n>>     honest, hopefully this won't be needed too often :-)\n>\n> Statement makes no sense, unless you meant to say \"It may be a bit\n> much complexity for a small benefit\" or similar?\n\nIndeed, that was a weird sentence :-) I did mean that it is a lot of\ncomplexity for very little benefit :-)\n\nCheers,\nChristian"
            }
        ],
        "thread_summary": {
            "title": "Reconciling the off-chain and on-chain models with eltoo",
            "categories": [
                "bitcoin-dev",
                "Lightning-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Christian Decker"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 38422
        }
    },
    {
        "title": "[bitcoin-dev] [BIP-able idea] Regular testnet reset",
        "thread_messages": [
            {
                "author": "Emil Engler",
                "date": "2019-09-13T23:57:12",
                "message_text_only": "Hello, I'm thinking about writing a BIP about resetting the testnet on\nregular/scheduled basis\n\nThe idea works like this:\n* Every 210000 block is being used as the genesis of a completely new chain.\n* The old one gets forgotten\n* No chain can be longer than 210000 blocks\n\nThe problems are:\n* How to get this working with testnet3? Only a hardfork probably.\n* Is it that easy to change the chain while Bitcoin Core is running?\nProbably the blocks need to be appended to the cureent one. After a\nrestart it would get patched\n* Could the the chain derive into multiple once at every reset? (Planned\nattacks)\n\nWhat do you think about the idea?\n\nGreetings,\nEmil Engler\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: pEpkey.asc\nType: application/pgp-keys\nSize: 3147 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20190914/26a11cd7/attachment.bin>"
            },
            {
                "author": "Bryan Bishop",
                "date": "2019-09-15T13:49:30",
                "message_text_only": "On Sun, Sep 15, 2019 at 8:49 AM Emil Engler via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hello, I'm thinking about writing a BIP about resetting the testnet on\n> regular/scheduled basis\n>\n\nAs a reminder, here is where you last brought up the idea, and the feedback:\n\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-June/017014.html\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-June/017031.html\n\nSince then, here is some new material on signet:\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/signet/\n\n- Bryan\nhttp://heybryan.org/\n1 512 203 0507\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20190915/07505fd9/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Regular testnet reset",
            "categories": [
                "bitcoin-dev",
                "BIP-able idea"
            ],
            "authors": [
                "Emil Engler",
                "Bryan Bishop"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 1743
        }
    },
    {
        "title": "[bitcoin-dev] Introcing a side memory network to bitcoin for ads",
        "thread_messages": [
            {
                "author": "Tamas Blummer",
                "date": "2019-09-14T13:21:28",
                "message_text_only": "I introduced you to the pattern of a side memory to bitcoin in [1] and\npromised an implementation of it.\n\nHere you are.\n\ndefiads is a side memory network to bitcoin, implemented in Rust, built\non top of rust-bitcoin, murmel, hammersbald, rust-bitcoinconsenus,\nrust-wallet, all Rust open source free to grab at\nhttps://github.com/defiads/defiads\n\ndefiads builds a peer-to-peer network to distribute textual ads, as\nfirst suggested by ZmnSCPxj[4]. I hope that it will serve \ndecentralized finance applications with an infrastructure to distribute\nads, order books, coinjoin proposals etc.\n\nEvery defiads node maintains a copy of a network-wide shared 1GB memory\npool of current ads.\n\nAn ad is replicated to other nodes as long as there is some bitcoin\nlocked to it on the bitcoin network. Locking means someone transferred\nsome sats to an address that is associated with the ad using the\npay-to-contract protocol[2]. The address does not release the bitcoins\nuntil a predefined time span that is the duration of the advertizement,\nthis is accomplished with OP_CSV. The ad will be evicted from the pool\nas soon as the coins locked to it are spendable again.\n\ndefiads  ranks advertizements by the ratio of used space divided by\nbitcoins locked and will only replicate the top 1GB of this ranked list.\n\nYou may read the ads by starting a defiads process of your own and\nthe query the content through its JSON-RPC API.\n\nYou may place ads by performing the following steps, with its JSON-RPC API\n\n1. deposit some bitcoins into your defiads node's wallet\n2. prepare an ad, providing its category, abstract and content\n3. fund the ad by locking some of the bitcoins to it for a limited term\nof the advertizement\n4. you may withdraw your coins from the defiads node's wallet after the\nadvertizement expires\n\ndefiads handles the association with ads, locking and unlocking coins.\n\nImplementation notes\ndefiads connects to both the bitcoin and its own peer-to-peer network.\nYou do not need to run a bitcoin node as defiads\u00a0 only needs a small\nfraction of the information on the bictoin blockchain and retrieves that\non its own, as an SPV node. \n\nThe defiads node's wallet is compatibe with that of TREZOR, Ledger,\nGreenwallet and many other wallets that support BIP38, BIP44, BIP48,\nBIP84 key generation and use standards.\n\ndefiads uses Invertible Bloom Lookup Tables[3] to synchronize the ads\npool with its peers.\n\nStatus\nIt seems to work, but you should not yet use with real bitcoins,\ntherefore by default it connects the bitcoin's test network.\n\nThere is no discovery for the network yet, so you will have to know some\npeer in the network to see other than your own ads. Write me a direct\nemail if you'd like to connect to my node.\n\n\nFuture developent\nShould the use become popular then 1GB pool become tight, then people\nwill have to compete for its use. Some might not have enough bitcoin's\nto lock and might therefore pay others to lock theirs to fund an\nadvertizement. defiads network could match both sides and thereby give\nrise to bitcoin's first truly risk less interest rate market.\n\ndefiads is currently downloading, but not storing, \nthe blocks after its birth date. This will no longer be needed once\nBIP158 filters are served and committed by Bitcoin Core.\n\nI hope that someone builds a nice UI on top of the JSON RPC as that is\nnot my area of expertise.\n\nTamas Blummer\n\n[1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-August/017264.html\n\n[2] https://arxiv.org/pdf/1212.3257.pdf\n\n[3] https://arxiv.org/pdf/1101.2245.pdf\n\n[4] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-July/017083.html"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-17T01:54:41",
                "message_text_only": "Good morning Tamas,\n\nThank you for taking the time to implement my idea.\n\nI filed an issue proposing a feature to add a \"contact point\" fixed-length field to all advertisements.\nhttps://github.com/defiads/defiads/issues/1\nI believe this gives me the right to say: First post.\n\nI will try to take a look at building some kind of UI at some point in the next few months or years.\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Tuesday, September 17, 2019 8:04 AM, Tamas Blummer via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I introduced you to the pattern of a side memory to bitcoin in [1] and\n> promised an implementation of it.\n>\n> Here you are.\n>\n> defiads is a side memory network to bitcoin, implemented in Rust, built\n> on top of rust-bitcoin, murmel, hammersbald, rust-bitcoinconsenus,\n> rust-wallet, all Rust open source free to grab at\n> https://github.com/defiads/defiads\n>\n> defiads builds a peer-to-peer network to distribute textual ads, as\n> first suggested by ZmnSCPxj[4]. I hope that it will serve\n> decentralized finance applications with an infrastructure to distribute\n> ads, order books, coinjoin proposals etc.\n>\n> Every defiads node maintains a copy of a network-wide shared 1GB memory\n> pool of current ads.\n>\n> An ad is replicated to other nodes as long as there is some bitcoin\n> locked to it on the bitcoin network. Locking means someone transferred\n> some sats to an address that is associated with the ad using the\n> pay-to-contract protocol[2]. The address does not release the bitcoins\n> until a predefined time span that is the duration of the advertizement,\n> this is accomplished with OP_CSV. The ad will be evicted from the pool\n> as soon as the coins locked to it are spendable again.\n>\n> defiads ranks advertizements by the ratio of used space divided by\n> bitcoins locked and will only replicate the top 1GB of this ranked list.\n>\n> You may read the ads by starting a defiads process of your own and\n> the query the content through its JSON-RPC API.\n>\n> You may place ads by performing the following steps, with its JSON-RPC API\n>\n> 1.  deposit some bitcoins into your defiads node's wallet\n> 2.  prepare an ad, providing its category, abstract and content\n> 3.  fund the ad by locking some of the bitcoins to it for a limited term\n>     of the advertizement\n>\n> 4.  you may withdraw your coins from the defiads node's wallet after the\n>     advertizement expires\n>\n>     defiads handles the association with ads, locking and unlocking coins.\n>\n>     Implementation notes\n>     defiads connects to both the bitcoin and its own peer-to-peer network.\n>     You do not need to run a bitcoin node as defiads\u00a0 only needs a small\n>     fraction of the information on the bictoin blockchain and retrieves that\n>     on its own, as an SPV node.\n>\n>     The defiads node's wallet is compatibe with that of TREZOR, Ledger,\n>     Greenwallet and many other wallets that support BIP38, BIP44, BIP48,\n>     BIP84 key generation and use standards.\n>\n>     defiads uses Invertible Bloom Lookup Tables[3] to synchronize the ads\n>     pool with its peers.\n>\n>     Status\n>     It seems to work, but you should not yet use with real bitcoins,\n>     therefore by default it connects the bitcoin's test network.\n>\n>     There is no discovery for the network yet, so you will have to know some\n>     peer in the network to see other than your own ads. Write me a direct\n>     email if you'd like to connect to my node.\n>\n>     Future developent\n>     Should the use become popular then 1GB pool become tight, then people\n>     will have to compete for its use. Some might not have enough bitcoin's\n>     to lock and might therefore pay others to lock theirs to fund an\n>     advertizement. defiads network could match both sides and thereby give\n>     rise to bitcoin's first truly risk less interest rate market.\n>\n>     defiads is currently downloading, but not storing,\n>     the blocks after its birth date. This will no longer be needed once\n>     BIP158 filters are served and committed by Bitcoin Core.\n>\n>     I hope that someone builds a nice UI on top of the JSON RPC as that is\n>     not my area of expertise.\n>\n>     Tamas Blummer\n>\n>     [1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-August/017264.html\n>\n>     [2] https://arxiv.org/pdf/1212.3257.pdf\n>\n>     [3] https://arxiv.org/pdf/1101.2245.pdf\n>\n>     [4] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-July/017083.html\n>\n>\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-18T04:41:15",
                "message_text_only": "Good morning list,\n\nIn case it is not obvious how this mechanism can be used, let me give me some short discussion.\n\nMany decentralized coin-mixing services require some concept of \"maker\", which serves as a temporary centralization in order to allow clients of the mixing service to find each other.\n\nSuch makers might advertise themselves, backing their advertisements with locked coins.\n\nThe text of the advertisement may very well be a machine-readable description, such as JSON, including information about the maker in the coin-mixing service.\n\nEscrow services for decentralized real-good-to-digital-good marketplaces (e.g. decentralized exchanges) might advertise themselves over this mechanism also.\nThe actual advertising of marketplace offers might also be done via this mechanism.\n\nAgain, machine-readable descriptions might be transported over the advertisement text mechanism, in order to allow programs to present the \"most natural\" interface to end-users.\n\nRegards,\nZmnSCPxj\n\n\n> Good morning Tamas,\n>\n> Thank you for taking the time to implement my idea.\n>\n> I filed an issue proposing a feature to add a \"contact point\" fixed-length field to all advertisements.\n> https://github.com/defiads/defiads/issues/1\n> I believe this gives me the right to say: First post.\n>\n> I will try to take a look at building some kind of UI at some point in the next few months or years.\n>\n> Regards,\n> ZmnSCPxj\n>\n> Sent with ProtonMail Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Tuesday, September 17, 2019 8:04 AM, Tamas Blummer via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:\n>\n> > I introduced you to the pattern of a side memory to bitcoin in [1] and\n> > promised an implementation of it.\n> > Here you are.\n> > defiads is a side memory network to bitcoin, implemented in Rust, built\n> > on top of rust-bitcoin, murmel, hammersbald, rust-bitcoinconsenus,\n> > rust-wallet, all Rust open source free to grab at\n> > https://github.com/defiads/defiads\n> > defiads builds a peer-to-peer network to distribute textual ads, as\n> > first suggested by ZmnSCPxj[4]. I hope that it will serve\n> > decentralized finance applications with an infrastructure to distribute\n> > ads, order books, coinjoin proposals etc.\n> > Every defiads node maintains a copy of a network-wide shared 1GB memory\n> > pool of current ads.\n> > An ad is replicated to other nodes as long as there is some bitcoin\n> > locked to it on the bitcoin network. Locking means someone transferred\n> > some sats to an address that is associated with the ad using the\n> > pay-to-contract protocol[2]. The address does not release the bitcoins\n> > until a predefined time span that is the duration of the advertizement,\n> > this is accomplished with OP_CSV. The ad will be evicted from the pool\n> > as soon as the coins locked to it are spendable again.\n> > defiads ranks advertizements by the ratio of used space divided by\n> > bitcoins locked and will only replicate the top 1GB of this ranked list.\n> > You may read the ads by starting a defiads process of your own and\n> > the query the content through its JSON-RPC API.\n> > You may place ads by performing the following steps, with its JSON-RPC API\n> >\n> > 1.  deposit some bitcoins into your defiads node's wallet\n> >\n> > 2.  prepare an ad, providing its category, abstract and content\n> >\n> > 3.  fund the ad by locking some of the bitcoins to it for a limited term\n> >     of the advertizement\n> >\n> > 4.  you may withdraw your coins from the defiads node's wallet after the\n> >     advertizement expires\n> >     defiads handles the association with ads, locking and unlocking coins.\n> >     Implementation notes\n> >     defiads connects to both the bitcoin and its own peer-to-peer network.\n> >     You do not need to run a bitcoin node as defiads\u00a0 only needs a small\n> >     fraction of the information on the bictoin blockchain and retrieves that\n> >     on its own, as an SPV node.\n> >     The defiads node's wallet is compatibe with that of TREZOR, Ledger,\n> >     Greenwallet and many other wallets that support BIP38, BIP44, BIP48,\n> >     BIP84 key generation and use standards.\n> >     defiads uses Invertible Bloom Lookup Tables[3] to synchronize the ads\n> >     pool with its peers.\n> >     Status\n> >     It seems to work, but you should not yet use with real bitcoins,\n> >     therefore by default it connects the bitcoin's test network.\n> >     There is no discovery for the network yet, so you will have to know some\n> >     peer in the network to see other than your own ads. Write me a direct\n> >     email if you'd like to connect to my node.\n> >     Future developent\n> >     Should the use become popular then 1GB pool become tight, then people\n> >     will have to compete for its use. Some might not have enough bitcoin's\n> >     to lock and might therefore pay others to lock theirs to fund an\n> >     advertizement. defiads network could match both sides and thereby give\n> >     rise to bitcoin's first truly risk less interest rate market.\n> >     defiads is currently downloading, but not storing,\n> >     the blocks after its birth date. This will no longer be needed once\n> >     BIP158 filters are served and committed by Bitcoin Core.\n> >     I hope that someone builds a nice UI on top of the JSON RPC as that is\n> >     not my area of expertise.\n> >     Tamas Blummer\n> >     [1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-August/017264.html\n> >     [2] https://arxiv.org/pdf/1212.3257.pdf\n> >     [3] https://arxiv.org/pdf/1101.2245.pdf\n> >     [4] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-July/017083.html\n> >\n> >\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            }
        ],
        "thread_summary": {
            "title": "Introcing a side memory network to bitcoin for ads",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Tamas Blummer"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 14170
        }
    },
    {
        "title": "[bitcoin-dev] Transcripts from Scaling Bitcoin 2019",
        "thread_messages": [
            {
                "author": "Bryan Bishop",
                "date": "2019-09-16T14:29:05",
                "message_text_only": "Hi,\n\nHere are some transcripts of talks from Scaling Bitcoin 2019 Tel Aviv. Any\nerrors are most likely my own.\n\nTraining material\n============\n\nTraining materials for bitcoin developers:\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/\n\nFoundation topics:\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/bitcoin-data-structures/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/blockchain-design-patterns/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/hardware-wallet-design-best-practices/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/privacy-concepts/\n\nDeveloping Bitcoin Core:\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/bitcoin-core-functional-test-framework/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/debugging-bitcoin/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/rebroadcasting/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/signet/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/wallet-architecture/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/libbitcoin/\n\nLightning network:\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/lightning-network-routing/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/lightning-network-sphinx-and-onion-routing/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/lightning-network-topology/\n\nUpgrades:\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/accumulators/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/taproot/\n\nScaling Bitcoin conference\n====================\n\nLN, payment networks and hubs:\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/anonymous-atomic-locks/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/atomic-multi-channel-updates/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/payment-channel-recovery-with-seeds/\n\nUpgrades:\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/bip-securethebag/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/erlay/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/secure-fountain-architecture/\n\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/elastic-block-caps/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/plasma-cash/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/prism/\n\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/proof-of-necessary-work/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/proof-of-verification-for-proof-of-work/\n\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/threshold-scriptless-scripts/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/scriptless-lotteries/\n\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/survey-of-progress-in-zero-knowledge-proofs-towards-trustless-snarks/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/zkvm/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/bitml/\n\nPrivate information retrieval methods for lightweight clients:\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/private-information-retrieval/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/scaling-oblivious-read-write/\n\nMore privacy:\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/zerolink-sudoku/\nhttps://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/txprobe/\n\n- Bryan\nhttp://heybryan.org/\n1 512 203 0507\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20190916/c98c8f18/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-18T04:33:46",
                "message_text_only": "Good morning Bryan,\n\nThank you very much for these.\n\nI appreciate greatly this effort to make transcripts more easily available.\nFor myself, I find it faster to read such transcript than to watch the video.\n\nRegards,\nZmnSCPxj\n\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Monday, September 16, 2019 10:29 PM, Bryan Bishop via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi,\n>\n> Here are some transcripts of talks from Scaling Bitcoin 2019 Tel Aviv. Any errors are most likely my own.\n>\n> Training material\n> ============\n>\n> Training materials for bitcoin developers:\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/\n>\n> Foundation topics:\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/bitcoin-data-structures/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/blockchain-design-patterns/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/hardware-wallet-design-best-practices/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/privacy-concepts/\n>\n> Developing Bitcoin Core:\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/bitcoin-core-functional-test-framework/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/debugging-bitcoin/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/rebroadcasting/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/signet/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/wallet-architecture/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/libbitcoin/\n>\n> Lightning network:\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/lightning-network-routing/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/lightning-network-sphinx-and-onion-routing/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/lightning-network-topology/\n>\n> Upgrades:\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/accumulators/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/taproot/\n> Scaling Bitcoin conference\n> ====================\n>\n> LN, payment networks and hubs:\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/anonymous-atomic-locks/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/atomic-multi-channel-updates/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/payment-channel-recovery-with-seeds/\n>\n> Upgrades:\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/bip-securethebag/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/erlay/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/secure-fountain-architecture/\n>\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/elastic-block-caps/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/plasma-cash/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/prism/\n>\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/proof-of-necessary-work/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/proof-of-verification-for-proof-of-work/\n>\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/threshold-scriptless-scripts/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/scriptless-lotteries/\n>\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/survey-of-progress-in-zero-knowledge-proofs-towards-trustless-snarks/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/zkvm/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/bitml/\n>\n> Private information retrieval methods for lightweight clients:\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/private-information-retrieval/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/scaling-oblivious-read-write/\n>\n> More privacy:\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/zerolink-sudoku/\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/txprobe/\n>\n> - Bryan\n> http://heybryan.org/\n> 1 512 203 0507"
            }
        ],
        "thread_summary": {
            "title": "Transcripts from Scaling Bitcoin 2019",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Bryan Bishop"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 8455
        }
    },
    {
        "title": "[bitcoin-dev] Taproot proposal",
        "thread_messages": [
            {
                "author": "Greg Sanders",
                "date": "2019-09-16T16:18:35",
                "message_text_only": "> I'd prefer to not support P2SH-nested TR. P2SH wrapping was useful for\nsegwit\nv0 for compatibility reasons. Most wallets/exchanges/services now support\nsending\nto native segwit addresses (https://en.bitcoin.it/wiki/Bech32_adoption) and\nthat\nwill be even more true if Schnorr/Taproot activate in 12+ months time.\n\nApologies for necroing an ancient thread, but I'm echoing my agreement with\nJohn here.\nWe still have plenty of time to have ecosystem upgrade by the time taproot\nis likely to activate.\n\n\n\nOn Wed, May 22, 2019 at 10:30 AM John Newbery via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi,\n>\n> > A Taproot output is a SegWit output [...]  with\n> > version number 1, and a 33-byte witness program whose first byte is 0 or\n> 1.\n>\n> Given a secret key k and public key P=(x,y), a signer with the knowledge\n> of k\n> can sign for -P=(x,p-y) since -k is the secret key for that point.\n> Encoding the\n> y value of the public key therefore adds no security. As an alternative to\n> providing the y value of the taproot output key Q when constructing the\n> taproot\n> output, the signer can provide it when signing. We can also restrict the y\n> value\n> of the internal key P to be even (or high, or a quadratic residue). That\n> gives\n> us 4 options for how to set the y signs for P and Q.\n>\n> 1. Q sign is explictly set in the witness program, P sign is explicitly\n> set in the control block\n>     => witness program is 33 bytes, 32 possible leaf versions (one for\n> each pair of 0xc0..0xff)\n> 2. Q sign is explictly set in the witness program, P sign is implicitly\n> even\n>     => witness program is 33 bytes, 64 possible leaf versions (one for\n> each 0xc0..0xff)\n> 3. Q sign is explictly set in the control block, P sign is explicitly set\n> in the control block\n>     => witness program is 32 bytes, 16 possible leaf versions (one for\n> each 4-tuple of 0xc0..0xff)\n> 4. Q sign is explictly set in the control block, P sign is implicitly even\n>     => witness program is 32 bytes, 32 possible leaf versions (one for\n> pair of 0xc0..0xff)\n>\n> The current proposal uses (1). Using (3) or (4) would reduce the size of a\n> taproot output by one byte to be the same size as a P2WSH output. That\n> means\n> that it's not more expensive for senders compared to sending to P2WSH.\n>\n> (Credit to James Chiang for suggesting omitting the y sign from the public\n> key and\n> to sipa for pointing out the 4 options above)\n>\n> > (native or P2SH-nested, see BIP141)\n>\n> I'd prefer to not support P2SH-nested TR. P2SH wrapping was useful for\n> segwit\n> v0 for compatibility reasons. Most wallets/exchanges/services now support\n> sending\n> to native segwit addresses (https://en.bitcoin.it/wiki/Bech32_adoption)\n> and that\n> will be even more true if Schnorr/Taproot activate in 12+ months time.\n>\n> On Mon, May 6, 2019 at 2:36 PM Pieter Wuille via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hello everyone,\n>>\n>> Here are two BIP drafts that specify a proposal for a Taproot\n>> softfork. A number of ideas are included:\n>>\n>> * Taproot to make all outputs and cooperative spends indistinguishable\n>> from eachother.\n>> * Merkle branches to hide the unexecuted branches in scripts.\n>> * Schnorr signatures enable wallet software to use key\n>> aggregation/thresholds within one input.\n>> * Improvements to the signature hashing algorithm (including signing\n>> all input amounts).\n>> * Replacing OP_CHECKMULTISIG(VERIFY) with OP_CHECKSIGADD, to support\n>> batch validation.\n>> * Tagged hashing for domain separation (avoiding issues like\n>> CVE-2012-2459 in Merkle trees).\n>> * Extensibility through leaf versions, OP_SUCCESS opcodes, and\n>> upgradable pubkey types.\n>>\n>> The BIP drafts can be found here:\n>> * https://github.com/sipa/bips/blob/bip-schnorr/bip-taproot.mediawiki\n>> specifies the transaction input spending rules.\n>> * https://github.com/sipa/bips/blob/bip-schnorr/bip-tapscript.mediawiki\n>> specifies the changes to Script inside such spends.\n>> * https://github.com/sipa/bips/blob/bip-schnorr/bip-schnorr.mediawiki\n>> is the Schnorr signature proposal that was discussed earlier on this\n>> list (See\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-July/016203.html\n>> )\n>>\n>> An initial reference implementation of the consensus changes, plus\n>> preliminary construction/signing tests in the Python framework can be\n>> found on https://github.com/sipa/bitcoin/commits/taproot. All\n>> together, excluding the Schnorr signature module in libsecp256k1, the\n>> consensus changes are around 520 LoC.\n>>\n>> While many other ideas exist, not everything is incorporated. This\n>> includes several ideas that can be implemented separately without loss\n>> of effectiveness. One such idea is a way to integrate SIGHASH_NOINPUT,\n>> which we're working on as an independent proposal.\n>>\n>> The document explains basic wallet operations, such as constructing\n>> outputs and signing. However, a wide variety of more complex\n>> constructions exist. Standardizing these is useful, but out of scope\n>> for now. It is likely also desirable to define extensions to PSBT\n>> (BIP174) for interacting with Taproot. That too is not included here.\n>>\n>> Cheers,\n>>\n>> --\n>> Pieter\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20190916/1c5c29f3/attachment-0001.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-17T04:09:50",
                "message_text_only": "Good morning Greg and John,\n\nI am not as sanguine here; SegWit activation was already delayed relative to commonly-broadcast expectations, yet many services *still* do not support sending to SegWit v0 addresses even now.\n\nOn the other hand, the major benefit of taproot is the better privacy and homogeneity afforded by Taproot, and supporting both P2SH-wrapped and non-wrapped SegWit v1 addresses simply increases the number of places that a user may be characterized and potentially identified.\n\nThus while I disagree with your reasoning, I do agree with your conclusion: no P2SH-wrapped SegWit v1.\n\nRegards,\nZmnSCPxj\n\nSent with ProtonMail Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Tuesday, September 17, 2019 12:18 AM, Greg Sanders via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> > I'd prefer to not support P2SH-nested TR. P2SH wrapping was useful for segwit\n> v0 for compatibility reasons. Most wallets/exchanges/services now support sending\n> to native segwit addresses (https://en.bitcoin.it/wiki/Bech32_adoption) and that\n> will be even more true if Schnorr/Taproot\u00a0activate in 12+ months time.\n>\n> Apologies for necroing an ancient thread, but I'm echoing my agreement with John here.\n> We still have plenty of time to have ecosystem upgrade by the time taproot is likely to activate.\n>\n> On Wed, May 22, 2019 at 10:30 AM John Newbery via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> > Hi,\n> >\n> > > A Taproot output is a SegWit output [...] \u00a0with\n> > > version number 1, and a 33-byte witness program whose first byte is 0 or 1.\n> >\n> > Given a secret key k and public key P=(x,y), a signer with the knowledge of k\n> > can sign for -P=(x,p-y) since -k is the secret key for that point. Encoding the\n> > y value of the public key therefore adds no security. As an alternative to\n> > providing the y value of the taproot output key Q when constructing the taproot\n> > output, the signer can provide it when signing. We can also restrict the y value\n> > of the internal key P to be even (or high, or a quadratic residue). That gives\n> > us 4 options for how to set the y signs for P and Q.\n> >\n> > 1. Q sign is explictly set in the witness program, P sign is explicitly set in the control block\n> > \u00a0 \u00a0 => witness program is 33 bytes, 32 possible leaf versions (one for each pair of 0xc0..0xff)\n> > 2. Q sign is explictly set in the witness program, P sign is implicitly even\n> > \u00a0 \u00a0 => witness program is 33 bytes, 64 possible leaf versions (one for each 0xc0..0xff)\n> > 3. Q sign is explictly set in the control block, P sign is explicitly set in the control block\n> > \u00a0 \u00a0 => witness program is 32 bytes, 16 possible leaf versions (one for each 4-tuple of 0xc0..0xff)\n> > 4. Q sign is explictly set in the control block, P sign is implicitly even\n> > \u00a0 \u00a0 => witness program is 32 bytes, 32 possible leaf versions (one for pair of 0xc0..0xff)\n> >\n> > The current proposal uses (1). Using (3) or (4) would reduce the size of a\n> > taproot output by one byte to be the same size as a P2WSH output. That means\n> > that it's not more expensive for senders compared to sending to P2WSH.\n> > \u00a0\n> > (Credit to James Chiang for suggesting omitting the y sign from the public key and\n> > to sipa for pointing out the 4 options above)\n> >\n> > > (native or P2SH-nested, see BIP141)\n> >\n> > I'd prefer to not support P2SH-nested TR. P2SH wrapping was useful for segwit\n> > v0 for compatibility reasons. Most wallets/exchanges/services now support sending\n> > to native segwit addresses (https://en.bitcoin.it/wiki/Bech32_adoption) and that\n> > will be even more true if Schnorr/Taproot activate in 12+ months time.\n> >\n> > On Mon, May 6, 2019 at 2:36 PM Pieter Wuille via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >\n> > > Hello everyone,\n> > >\n> > > Here are two BIP drafts that specify a proposal for a Taproot\n> > > softfork. A number of ideas are included:\n> > >\n> > > * Taproot to make all outputs and cooperative spends indistinguishable\n> > > from eachother.\n> > > * Merkle branches to hide the unexecuted branches in scripts.\n> > > * Schnorr signatures enable wallet software to use key\n> > > aggregation/thresholds within one input.\n> > > * Improvements to the signature hashing algorithm (including signing\n> > > all input amounts).\n> > > * Replacing OP_CHECKMULTISIG(VERIFY) with OP_CHECKSIGADD, to support\n> > > batch validation.\n> > > * Tagged hashing for domain separation (avoiding issues like\n> > > CVE-2012-2459 in Merkle trees).\n> > > * Extensibility through leaf versions, OP_SUCCESS opcodes, and\n> > > upgradable pubkey types.\n> > >\n> > > The BIP drafts can be found here:\n> > > * https://github.com/sipa/bips/blob/bip-schnorr/bip-taproot.mediawiki\n> > > specifies the transaction input spending rules.\n> > > * https://github.com/sipa/bips/blob/bip-schnorr/bip-tapscript.mediawiki\n> > > specifies the changes to Script inside such spends.\n> > > * https://github.com/sipa/bips/blob/bip-schnorr/bip-schnorr.mediawiki\n> > > is the Schnorr signature proposal that was discussed earlier on this\n> > > list (See https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-July/016203.html)\n> > >\n> > > An initial reference implementation of the consensus changes, plus\n> > > preliminary construction/signing tests in the Python framework can be\n> > > found on https://github.com/sipa/bitcoin/commits/taproot. All\n> > > together, excluding the Schnorr signature module in libsecp256k1, the\n> > > consensus changes are around 520 LoC.\n> > >\n> > > While many other ideas exist, not everything is incorporated. This\n> > > includes several ideas that can be implemented separately without loss\n> > > of effectiveness. One such idea is a way to integrate SIGHASH_NOINPUT,\n> > > which we're working on as an independent proposal.\n> > >\n> > > The document explains basic wallet operations, such as constructing\n> > > outputs and signing. However, a wide variety of more complex\n> > > constructions exist. Standardizing these is useful, but out of scope\n> > > for now. It is likely also desirable to define extensions to PSBT\n> > > (BIP174) for interacting with Taproot. That too is not included here.\n> > >\n> > > Cheers,\n> > >\n> > > --\n> > > Pieter\n> > > _______________________________________________\n> > > bitcoin-dev mailing list\n> > > bitcoin-dev at lists.linuxfoundation.org\n> > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Pieter Wuille",
                "date": "2019-09-18T21:21:56",
                "message_text_only": "On Mon, 16 Sep 2019 at 21:10, ZmnSCPxj via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> > I'd prefer to not support P2SH-nested TR. P2SH wrapping was useful for segwit\n> > v0 for compatibility reasons. Most wallets/exchanges/services now support sending\n> > to native segwit addresses (https://en.bitcoin.it/wiki/Bech32_adoption) and that\n> > will be even more true if Schnorr/Taproot activate in 12+ months time.\n> >\n> > Apologies for necroing an ancient thread, but I'm echoing my agreement with John here.\n> > We still have plenty of time to have ecosystem upgrade by the time taproot is likely to activate.\n\n> On the other hand, the major benefit of taproot is the better privacy and homogeneity afforded by Taproot, and supporting both P2SH-wrapped and non-wrapped SegWit v1 addresses simply increases the number of places that a user may be characterized and potentially identified.\n\nI'm starting to lean towards not allowing P2SH wrapped Taproot as well.\n\nGiven the progress bech32 adoption has made in the past year or so, I\ndon't think adding P2SH support would result in many more software\nauthors deciding to implement receive-to-taproot functionality. And\nwithout that advantage, having the option of supporting P2SH wrapping\nactually risks degrading the privacy goals it aims for (see ZmnSCPxj's\nargument above).\n\nMy main intuition for keeping P2SH is that Segwit was really designed\nto support both, and I expect that disallowing P2SH would actually\nrequire (very slightly) more complex validation code. I don't think\nthis is a sufficiently strong reason, especially as keeping P2SH\nsupport does increase the number of combinations software needs to\ntest (both in consensus code and wallets).\n\nCheers,\n\n-- \nPieter"
            }
        ],
        "thread_summary": {
            "title": "Taproot proposal",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Pieter Wuille",
                "Greg Sanders"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 14189
        }
    },
    {
        "title": "[bitcoin-dev] bip-tapscript resource limits",
        "thread_messages": [
            {
                "author": "Pieter Wuille",
                "date": "2019-09-18T20:50:48",
                "message_text_only": "Hi all,\n\nIn the draft for bip-tapscript (see [1], current version [2]), we\npropose removing the per-block sigops limit for tapscript scripts, and\nreplacing it with a \"every script gets a budget of sigops based on its\nwitness size (one per 50 WU)\". Since signatures (plus pubkeys) take\nmore WU than that, this is not a restriction for anything but\npathologically constructed scripts. Simultaneously, it removes the\nmulti-dimensional optimization problem that theoretically needs to be\nsolved to maximize revenue in block template construction.\n\nWith our recent work on Miniscript (see [3]), we discovered that the\nvariety of other script resource limits also introduce (weaker)\ncomplex optimization requirements, but for script constructors instead\nof miners. An overview:\n1) Scripts are limited to 10000 bytes (and 3600 by standardness currently)\n2) The total number of non-push opcodes in a script + the number of\nkeys participating in executed OP_CHECKMULTISIG(VERIFY) opcodes must\nnot exceed 201.\n3) The size of the stack + altstack combined cannot exceed 1000\nelements during execution (and the initial stack is limited to 100\nelements by standardness currently)\n4) The maximum size of elements on the stack is 520 bytes (and 80\nbytes in the initial stack by standardness)\n\nIn a discussion about this with Andrew Poelstra we wondered whether\nall these limits are still necessary in bip-tapscript. I believe the\nonly relevant ones are those that reduce total memory usage, or\nverification CPU usage per witness byte. Total script verification CPU\nusage isn't relevant I believe, because the same effect can be\naccomplished by having a transaction (or block) with multiple inputs.\n\nSo let's go over the above resource limits, and see how they help with\nlimiting memory usage or CPu usage per byte.\n\n# Script size limit\n\nMemory usage for validation can grow with larger scripts, but only\nindirectly by constructing extra stack data. Since those are\nindependently limited by (3), we don't need to consider those here.\n\nThere used to be a way through which larger scripts would cause larger\nper byte verification cost, but it no longer applies, I believe. Due\nto the scriptCode being replaced with a pre-hashed tapleaf hash, the\nper-sigop hashing cost is now easily made independent of the size of\nthe script in implementations.\n\nMy suggestion is to drop the script size limit in tapscript, and\ninstead have it only be implicitly limited by transaction size limits.\n\n# The 201 non-push opcodes limit\n\nIgnoring how more opcodes can grow the stack and altstack (which are\nalready restricted by 3), I believe there is only one way that\nadditional (executed) opcodes can increase per-opcode execution time\nin the current Bitcoin Core implementation [4], namely the \"vfExec\"\nstack that keeps track of what sides of IF/NOTIF/ELSE/ENDIF execution\nis currently passing through. As pointed out by Sergio Demian Lerner\n[5], an O(1) algorithm can do this just as well (a variant of which is\nimplemented in PR 16902 [6]).\n\nTaking such a patch into account, I don't think there are any problems\nwith removing the 201 ops limit for bip-tapscript scripts. Especially\ngiven its strange semantics around OP_CHECKMULTISIG(VERIFY) (the keys\nparticipating in those are each counted as 1 towards the 201 limit,\nbut only when executed, while all non-push opcodes are counted as 1\neven when not executed), I think this is a nice simplification.\n\n# The 1000 element limit for stack + altstack\n\nA limit for the number of elements on the stack/altstack directly\naffects memory usage. In a naive implementation without deduplication\nas is used in Bitcoin Core now, every OP_3DUP can add 120 bytes of\nmemory usage plus the size of the data in the created elements\nthemselves (which can be a multiple of that number), leading to\nseveral GB of memory usage for executing a maximal 4 MB script\n(multiplied by the number of parallel executions). Even when using\nreference-counting techniques to reduce duplication, 100 MB memory\nusage is not unreasonable. I don't think those are acceptable numbers.\n\nThe stack size can also directly affect per-opcode execution time for\nOP_ROLL, again shown by [5]. A block full of the most tightly packed\nOP_ROLLS (which I believe is a repetition of OP_3DUP OP_ROLL OP_ROLL\nOP_ROLL) operating on a stack of 1000 elements for me takes around 4.3\ns of CPU time to verify. That's significant, but it's surprisingly\nclose to what a block packed with OP_CHECKSIGs (taking the 1 sigop /\n50 WU limit into account) takes to verify on the same machine (3.8 s).\nEven more remarkably, that time is also very close to how long a block\nfull of most tightly packed OP_HASH256s on 520 byte inputs take to\nverify when disabling SHA256 hardware acceleration (3.6 s).\n\nI believe we should keep this 1000 element stack limit for these\nreasons. The 100 limit on input stacks can be increased to 1000 for\nuniformity with the during-execution limit.\n\n# The 520 byte stack element size limit\n\nGiven that there are no known use cases for stack elements larger than\n65 bytes (and no opcodes apart from hashes that can even operate on\nthem), plus their impact on memory usage the execution time of\npathologically constructed scripts full of hashes (see above), I think\nwe should keep this limit.\n\nNote that this limit can be changed using the OP_SUCCESSx mechanism, if need be.\n\n# Summary\n\nI propose the following changes to resource limits in bip-tapscript\n(compared to segwit v0 scripts):\n\n* Replace the separate sigops counter with a \"executed sigops must not\nexceed (witness size / 50 WU) + 1\" rule (already in the BIP).\n* Drop the 10000 byte limit for script size (and 3600 byte standardness limit)\n* Drop the 201 non-push ops limit per script.\n* Drop the 100 input stack elements standardness limit, and replace\nwith a (consensus) 1000 limit.\n\nThe rules limiting the stack + altstack number of elements during\nexecution to 1000 remains, as well as the 520 byte limit for elements\non the stack.\n\n# References\n\n  [1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-May/016914.html\n  [2] https://github.com/sipa/bips/blob/bip-schnorr/bip-tapscript.mediawiki\n  [3] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-August/017270.html\n  [4] https://github.com/bitcoin/bitcoin/blob/v0.18.1/src/script/interpreter.cpp#L281L1084\n  [5] https://bitslog.com/2017/04/17/new-quadratic-delays-in-bitcoin-scripts/\n  [6] https://github.com/bitcoin/bitcoin/pull/16902\n\nCheers,\n\n-- \nPieter"
            }
        ],
        "thread_summary": {
            "title": "bip-tapscript resource limits",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Pieter Wuille"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 6477
        }
    },
    {
        "title": "[bitcoin-dev] Timelocks and Lightning on MimbleWimble",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-19T07:52:11",
                "message_text_only": "Good morning list,\n\nI was reading transcript of recent talk: https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/blockchain-design-patterns/\n\nAnd in section \"Taproot: main idea\":\n\n> Q: Can you do timelocks iwth adaptor signatures?\n>\n> ...\n>\n> A: This is one way it's being proposed by mimblewimble; but this requires the ability to aggregate signatures across transactions.\n>\n> Q: No, there's two transactions already existing. Before locktime, you can spend wit hthe adaptor signature one like atomic swaps. After locktime, the other one becomes valid and you can spend with that. They just double spend each other.\n>\n> A: You'd have to diagram that out for me. There's a few ways to do this, some that I know, but yours isn't one of them.\n\nI believe what is being referred to here is to simply have an `nLockTime` transaction that is signed by all participants first, and serves as the \"timelock\" path.\nThen, another transaction is created, for which adaptor signatures are given, before completing the ritual to create a \"hashlock\" path.\n\nI find it surprising that this is not well-known.\nI describe it here tangentially, for instance: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-April/016888.html\nThe section \"Payjoin2swap Swap Protocol\" refers to \"pre-swap transaction\" and \"pre-swap backout transaction\", which are `nLockTime`d transactions.\nLater transactions then use a Scriptless Script-like construction to transfer information about a secret scalar x.\n\nMy understanding of MimbleWimble is that:\n\n* There must exist a proof-of-knowledge of the sum of blinding factors used.\n  This can be trivially had by using a signature of this sum, signing an empty message or \"kernel\".\n* I believe I have seen at least one proposal (I cannot find it again now) where the \"kernel\" is replaced with an `nLockTime`-equivalent.\n  Basically, the `nLockTime` would have to be explicitly published, and it would be rejected for a block if the `nLockTime` was less than the block height.\n  * There may or may not exist some kind of proof where the message being signed is an integer that is known to be no greater than a particular value, and multiple signatures that signed a lower value can somehow be aggregated to a higher value, which serves this purpose as well, but is compressible.\n\nMy understanding is thus that the above `nLockTime` technique is what is indeed intended for MimbleWimble cross-system atomic swaps.\n\n--------\n\nHowever, I believe that Lightning and similar offchain protocols are **not possible** on MimbleWimble, at least if we want to retain its \"magical shrinking blockchain\" property.\n\nAll practical channel constructions with indefinite lifetime require the use of *relative* locktime.\nOf note is that `nLockTime` represents an *absolute* lifetime.\n\nThe only practical channel constructions I know of that do not require *relative* locktime (mostly various variants of Spilman channels) have a fixed lifetime, i.e. the channel will have to be closed before the lifetime arrives.\nThis is impractical for a scaling network.\n\nIt seems to me that some kind of \"timeout\" is always necessary, similar to the timeout used in SPV-proof sidechains, in order to allow an existing claimed-latest-state to be proven as not-actually-latest.\n\n* In Poon-Dryja, knowledge of the revocation key by the other side proves the published claimed-latest-state is not-actually-latest and awards the entire amount to the other party.\n  * This key can only be presented during the timeout, a security parameter.\n* In Decker-Wattenhofer decrementing-`nSequence` channels, a kickoff starts this timeout, and only the smallest-timeout state gets onchain, due to it having a time advantage over all other versions.\n* In indefinite-lifetime Spilman channels (also described in the Decker-Wattenhofer paper), the absolute-timelock initial backoff transaction is replaced with a kickoff + relative-locktime transaction.\n* In Decker-Russell-Osuntokun, each update transaction has an imposed `nSequence` that forces a state transaction to be delayed compared to the update transaction it is paired with.\n\nIt seems that all practical offchain updateable cryptocurrency systems, some kind of \"timeout\" is needed during which participants have an opportunity to claim an alternative version of some previous claim of correct state.\n\nThis timeout could be implemented as either relative or absolute lock time, but obviously an absolute locktime would create a limit on the lifetime of the channel.\nThus, if we were to target an indefinite-lifetime channel, we must use relative lock times, with the timeout starting only when the unilateral close is initiated by one participant.\n\nNow, let us turn back to the MimbleWimble.\nAs it happens, we do *not* actually need SCRIPT to implement these offchain updateable cryptocurrency systems.\n2-of-2 is often enough (and with Schnorr and other homomorphic signatures, this is possible without explicit script, only pubkeys and signatures, which MimbleWimble supports).\n\n* Poon-Dryja revocation can be rewritten as an HTLC-like construct (indeed this was the original formulation).\n  * Since we have shown that, by use of two transaction alternatives, one timelocked and the other hashlocked, we can implement an HTLC-like construct on MimbleWimble, that is enough.\n* Relative locktimes in Decker-Wattenhofer are imposed by simple `nSequence`, not by `OP_CSV`.\n  HTLCs hosted inside such constructions can again use the two-transactions construct in MimbleWimble.\n* Ditto with indefinite-lifetime Spilman.\n* Ditto with Decker-Russell-Osuntokun.\n  * The paper shows the use of `OP_CSV`, but aj notes it is redundant, and I agree: https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-March/001933.html\n\nThus, it is not the \"nonexistence of SCRIPT\" that prevents Lightning from being deployed on MimbleWimble.\n\nInstead, it is the \"nonexistence of **relative** locktime\" that prevents Lightning over MimbleWimble.\n\nWhy would **relative** locktimes not possibly exist?\nIn order to **validate** a relative locktime, we need to know the blockheight that the output we are spending was confirmed in.\n\nBut the entire point of the \"magical shrinking blockchain\" is that already-spent outputs can be removed completely and all that needs to be validated by a new node is:\n\n* The coin-creation events.\n* The current UTXO set (plus attached rangeproofs).\n* The blinding keys.\n* Signatures of the blinding keys, and the kernels they sign (if we use the \"kernels encode `nLockTime`\" technique in some way, they should not exceed the current supposed blockheight).\n\nThe problem is that an output that exists in the UTXO set might be invalid, if it appears \"too near\" to an `nSequence` minimum spend of a previous output that was spent in its creation.\nThat is, the above does not allow validation of **relative** locktimes, only **absolute locktimes**.\n(At least as far as I understand: there may be special cryptographic constructs that allow signatures to reliably commit to some relative locktime).\n\nThis means that relative locktimes need to be implemented by showing the transactions that spend previous UTXOS and create the current UTXOs, and so no backwards to coin-creation events.\nThis forces us back to the old \"validate all transactions\" model of starting a new node (and seriously damaging the entire point of using MimbleWimble anyway).\n\nI do not believe it is the lack of SCRIPT that prevents Lightning-over-MimbleWimble, but rather the lack of relative locktime, which seems difficult to validate without knowing the individual transactions and when they were confirmed.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Martin Schwarz",
                "date": "2019-09-19T08:39:00",
                "message_text_only": "Isn't there some way to \"rebase\" a relative lock-time to some anchor even\nfurther in the past while cancelling out the intermediate transactions?\n\nbest regards,\nMartin\n\nOn Thu, Sep 19, 2019 at 9:52 AM ZmnSCPxj via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning list,\n>\n> I was reading transcript of recent talk:\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/blockchain-design-patterns/\n>\n> And in section \"Taproot: main idea\":\n>\n> > Q: Can you do timelocks iwth adaptor signatures?\n> >\n> > ...\n> >\n> > A: This is one way it's being proposed by mimblewimble; but this\n> requires the ability to aggregate signatures across transactions.\n> >\n> > Q: No, there's two transactions already existing. Before locktime, you\n> can spend wit hthe adaptor signature one like atomic swaps. After locktime,\n> the other one becomes valid and you can spend with that. They just double\n> spend each other.\n> >\n> > A: You'd have to diagram that out for me. There's a few ways to do this,\n> some that I know, but yours isn't one of them.\n>\n> I believe what is being referred to here is to simply have an `nLockTime`\n> transaction that is signed by all participants first, and serves as the\n> \"timelock\" path.\n> Then, another transaction is created, for which adaptor signatures are\n> given, before completing the ritual to create a \"hashlock\" path.\n>\n> I find it surprising that this is not well-known.\n> I describe it here tangentially, for instance:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-April/016888.html\n> The section \"Payjoin2swap Swap Protocol\" refers to \"pre-swap transaction\"\n> and \"pre-swap backout transaction\", which are `nLockTime`d transactions.\n> Later transactions then use a Scriptless Script-like construction to\n> transfer information about a secret scalar x.\n>\n> My understanding of MimbleWimble is that:\n>\n> * There must exist a proof-of-knowledge of the sum of blinding factors\n> used.\n>   This can be trivially had by using a signature of this sum, signing an\n> empty message or \"kernel\".\n> * I believe I have seen at least one proposal (I cannot find it again now)\n> where the \"kernel\" is replaced with an `nLockTime`-equivalent.\n>   Basically, the `nLockTime` would have to be explicitly published, and it\n> would be rejected for a block if the `nLockTime` was less than the block\n> height.\n>   * There may or may not exist some kind of proof where the message being\n> signed is an integer that is known to be no greater than a particular\n> value, and multiple signatures that signed a lower value can somehow be\n> aggregated to a higher value, which serves this purpose as well, but is\n> compressible.\n>\n> My understanding is thus that the above `nLockTime` technique is what is\n> indeed intended for MimbleWimble cross-system atomic swaps.\n>\n> --------\n>\n> However, I believe that Lightning and similar offchain protocols are **not\n> possible** on MimbleWimble, at least if we want to retain its \"magical\n> shrinking blockchain\" property.\n>\n> All practical channel constructions with indefinite lifetime require the\n> use of *relative* locktime.\n> Of note is that `nLockTime` represents an *absolute* lifetime.\n>\n> The only practical channel constructions I know of that do not require\n> *relative* locktime (mostly various variants of Spilman channels) have a\n> fixed lifetime, i.e. the channel will have to be closed before the lifetime\n> arrives.\n> This is impractical for a scaling network.\n>\n> It seems to me that some kind of \"timeout\" is always necessary, similar to\n> the timeout used in SPV-proof sidechains, in order to allow an existing\n> claimed-latest-state to be proven as not-actually-latest.\n>\n> * In Poon-Dryja, knowledge of the revocation key by the other side proves\n> the published claimed-latest-state is not-actually-latest and awards the\n> entire amount to the other party.\n>   * This key can only be presented during the timeout, a security\n> parameter.\n> * In Decker-Wattenhofer decrementing-`nSequence` channels, a kickoff\n> starts this timeout, and only the smallest-timeout state gets onchain, due\n> to it having a time advantage over all other versions.\n> * In indefinite-lifetime Spilman channels (also described in the\n> Decker-Wattenhofer paper), the absolute-timelock initial backoff\n> transaction is replaced with a kickoff + relative-locktime transaction.\n> * In Decker-Russell-Osuntokun, each update transaction has an imposed\n> `nSequence` that forces a state transaction to be delayed compared to the\n> update transaction it is paired with.\n>\n> It seems that all practical offchain updateable cryptocurrency systems,\n> some kind of \"timeout\" is needed during which participants have an\n> opportunity to claim an alternative version of some previous claim of\n> correct state.\n>\n> This timeout could be implemented as either relative or absolute lock\n> time, but obviously an absolute locktime would create a limit on the\n> lifetime of the channel.\n> Thus, if we were to target an indefinite-lifetime channel, we must use\n> relative lock times, with the timeout starting only when the unilateral\n> close is initiated by one participant.\n>\n> Now, let us turn back to the MimbleWimble.\n> As it happens, we do *not* actually need SCRIPT to implement these\n> offchain updateable cryptocurrency systems.\n> 2-of-2 is often enough (and with Schnorr and other homomorphic signatures,\n> this is possible without explicit script, only pubkeys and signatures,\n> which MimbleWimble supports).\n>\n> * Poon-Dryja revocation can be rewritten as an HTLC-like construct (indeed\n> this was the original formulation).\n>   * Since we have shown that, by use of two transaction alternatives, one\n> timelocked and the other hashlocked, we can implement an HTLC-like\n> construct on MimbleWimble, that is enough.\n> * Relative locktimes in Decker-Wattenhofer are imposed by simple\n> `nSequence`, not by `OP_CSV`.\n>   HTLCs hosted inside such constructions can again use the\n> two-transactions construct in MimbleWimble.\n> * Ditto with indefinite-lifetime Spilman.\n> * Ditto with Decker-Russell-Osuntokun.\n>   * The paper shows the use of `OP_CSV`, but aj notes it is redundant, and\n> I agree:\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-March/001933.html\n>\n> Thus, it is not the \"nonexistence of SCRIPT\" that prevents Lightning from\n> being deployed on MimbleWimble.\n>\n> Instead, it is the \"nonexistence of **relative** locktime\" that prevents\n> Lightning over MimbleWimble.\n>\n> Why would **relative** locktimes not possibly exist?\n> In order to **validate** a relative locktime, we need to know the\n> blockheight that the output we are spending was confirmed in.\n>\n> But the entire point of the \"magical shrinking blockchain\" is that\n> already-spent outputs can be removed completely and all that needs to be\n> validated by a new node is:\n>\n> * The coin-creation events.\n> * The current UTXO set (plus attached rangeproofs).\n> * The blinding keys.\n> * Signatures of the blinding keys, and the kernels they sign (if we use\n> the \"kernels encode `nLockTime`\" technique in some way, they should not\n> exceed the current supposed blockheight).\n>\n> The problem is that an output that exists in the UTXO set might be\n> invalid, if it appears \"too near\" to an `nSequence` minimum spend of a\n> previous output that was spent in its creation.\n> That is, the above does not allow validation of **relative** locktimes,\n> only **absolute locktimes**.\n> (At least as far as I understand: there may be special cryptographic\n> constructs that allow signatures to reliably commit to some relative\n> locktime).\n>\n> This means that relative locktimes need to be implemented by showing the\n> transactions that spend previous UTXOS and create the current UTXOs, and so\n> no backwards to coin-creation events.\n> This forces us back to the old \"validate all transactions\" model of\n> starting a new node (and seriously damaging the entire point of using\n> MimbleWimble anyway).\n>\n> I do not believe it is the lack of SCRIPT that prevents\n> Lightning-over-MimbleWimble, but rather the lack of relative locktime,\n> which seems difficult to validate without knowing the individual\n> transactions and when they were confirmed.\n>\n> Regards,\n> ZmnSCPxj\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20190919/28cb2694/attachment.html>"
            },
            {
                "author": "Lloyd Fournier",
                "date": "2019-09-19T18:54:34",
                "message_text_only": "Hi ZmnSCPxj,\n\nI can give some context on the exchange during the talk. I was the \"Q\" and\nAndrew Polestra was the \"A\".\n\nI followed up with Andrew after and he indeed knew about the pre-signed\nnlocktime transaction double spend technique (actually, I thought he was\nthe one who originally came up with that idea for scriptless atomic swaps).\nHe clarified saying that you can do that with locktime (absolute time\nlocks) but not with sequence numbers (relative time locks). i.e. to enforce\nsequence numbers you need to use OP_CHECKSEQUENCEVERIFY. He said that it\nwould make sense to change that so it's enforced regardless of script.\n\nHowever, I talked to Antoine Riard later who was adamant that sequence\nnumbers already worked as expected. He pointed to the fact that BIP68\nalready describes it as an independent constraint [1]\n\nSo if things do work as described in BIP68 then we should be able to do\nlightning on Bitcoin without any script once we have Schnorr. I'm keen to\nactually figure out all the details of how to do this. It works in my head\nbut I think I should write it down somewhere to make sure it works.\n\n [1] https://github.com/bitcoin/bips/blob/master/bip-0068.mediawiki\n\nLL\n\n\nOn Thu, Sep 19, 2019 at 5:52 PM ZmnSCPxj via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Good morning list,\n>\n> I was reading transcript of recent talk:\n> https://diyhpl.us/wiki/transcripts/scalingbitcoin/tel-aviv-2019/edgedevplusplus/blockchain-design-patterns/\n>\n> And in section \"Taproot: main idea\":\n>\n> > Q: Can you do timelocks iwth adaptor signatures?\n> >\n> > ...\n> >\n> > A: This is one way it's being proposed by mimblewimble; but this\n> requires the ability to aggregate signatures across transactions.\n> >\n> > Q: No, there's two transactions already existing. Before locktime, you\n> can spend wit hthe adaptor signature one like atomic swaps. After locktime,\n> the other one becomes valid and you can spend with that. They just double\n> spend each other.\n> >\n> > A: You'd have to diagram that out for me. There's a few ways to do this,\n> some that I know, but yours isn't one of them.\n>\n> I believe what is being referred to here is to simply have an `nLockTime`\n> transaction that is signed by all participants first, and serves as the\n> \"timelock\" path.\n> Then, another transaction is created, for which adaptor signatures are\n> given, before completing the ritual to create a \"hashlock\" path.\n>\n> I find it surprising that this is not well-known.\n> I describe it here tangentially, for instance:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-April/016888.html\n> The section \"Payjoin2swap Swap Protocol\" refers to \"pre-swap transaction\"\n> and \"pre-swap backout transaction\", which are `nLockTime`d transactions.\n> Later transactions then use a Scriptless Script-like construction to\n> transfer information about a secret scalar x.\n>\n> My understanding of MimbleWimble is that:\n>\n> * There must exist a proof-of-knowledge of the sum of blinding factors\n> used.\n>   This can be trivially had by using a signature of this sum, signing an\n> empty message or \"kernel\".\n> * I believe I have seen at least one proposal (I cannot find it again now)\n> where the \"kernel\" is replaced with an `nLockTime`-equivalent.\n>   Basically, the `nLockTime` would have to be explicitly published, and it\n> would be rejected for a block if the `nLockTime` was less than the block\n> height.\n>   * There may or may not exist some kind of proof where the message being\n> signed is an integer that is known to be no greater than a particular\n> value, and multiple signatures that signed a lower value can somehow be\n> aggregated to a higher value, which serves this purpose as well, but is\n> compressible.\n>\n> My understanding is thus that the above `nLockTime` technique is what is\n> indeed intended for MimbleWimble cross-system atomic swaps.\n>\n> --------\n>\n> However, I believe that Lightning and similar offchain protocols are **not\n> possible** on MimbleWimble, at least if we want to retain its \"magical\n> shrinking blockchain\" property.\n>\n> All practical channel constructions with indefinite lifetime require the\n> use of *relative* locktime.\n> Of note is that `nLockTime` represents an *absolute* lifetime.\n>\n> The only practical channel constructions I know of that do not require\n> *relative* locktime (mostly various variants of Spilman channels) have a\n> fixed lifetime, i.e. the channel will have to be closed before the lifetime\n> arrives.\n> This is impractical for a scaling network.\n>\n> It seems to me that some kind of \"timeout\" is always necessary, similar to\n> the timeout used in SPV-proof sidechains, in order to allow an existing\n> claimed-latest-state to be proven as not-actually-latest.\n>\n> * In Poon-Dryja, knowledge of the revocation key by the other side proves\n> the published claimed-latest-state is not-actually-latest and awards the\n> entire amount to the other party.\n>   * This key can only be presented during the timeout, a security\n> parameter.\n> * In Decker-Wattenhofer decrementing-`nSequence` channels, a kickoff\n> starts this timeout, and only the smallest-timeout state gets onchain, due\n> to it having a time advantage over all other versions.\n> * In indefinite-lifetime Spilman channels (also described in the\n> Decker-Wattenhofer paper), the absolute-timelock initial backoff\n> transaction is replaced with a kickoff + relative-locktime transaction.\n> * In Decker-Russell-Osuntokun, each update transaction has an imposed\n> `nSequence` that forces a state transaction to be delayed compared to the\n> update transaction it is paired with.\n>\n> It seems that all practical offchain updateable cryptocurrency systems,\n> some kind of \"timeout\" is needed during which participants have an\n> opportunity to claim an alternative version of some previous claim of\n> correct state.\n>\n> This timeout could be implemented as either relative or absolute lock\n> time, but obviously an absolute locktime would create a limit on the\n> lifetime of the channel.\n> Thus, if we were to target an indefinite-lifetime channel, we must use\n> relative lock times, with the timeout starting only when the unilateral\n> close is initiated by one participant.\n>\n> Now, let us turn back to the MimbleWimble.\n> As it happens, we do *not* actually need SCRIPT to implement these\n> offchain updateable cryptocurrency systems.\n> 2-of-2 is often enough (and with Schnorr and other homomorphic signatures,\n> this is possible without explicit script, only pubkeys and signatures,\n> which MimbleWimble supports).\n>\n> * Poon-Dryja revocation can be rewritten as an HTLC-like construct (indeed\n> this was the original formulation).\n>   * Since we have shown that, by use of two transaction alternatives, one\n> timelocked and the other hashlocked, we can implement an HTLC-like\n> construct on MimbleWimble, that is enough.\n> * Relative locktimes in Decker-Wattenhofer are imposed by simple\n> `nSequence`, not by `OP_CSV`.\n>   HTLCs hosted inside such constructions can again use the\n> two-transactions construct in MimbleWimble.\n> * Ditto with indefinite-lifetime Spilman.\n> * Ditto with Decker-Russell-Osuntokun.\n>   * The paper shows the use of `OP_CSV`, but aj notes it is redundant, and\n> I agree:\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-March/001933.html\n>\n> Thus, it is not the \"nonexistence of SCRIPT\" that prevents Lightning from\n> being deployed on MimbleWimble.\n>\n> Instead, it is the \"nonexistence of **relative** locktime\" that prevents\n> Lightning over MimbleWimble.\n>\n> Why would **relative** locktimes not possibly exist?\n> In order to **validate** a relative locktime, we need to know the\n> blockheight that the output we are spending was confirmed in.\n>\n> But the entire point of the \"magical shrinking blockchain\" is that\n> already-spent outputs can be removed completely and all that needs to be\n> validated by a new node is:\n>\n> * The coin-creation events.\n> * The current UTXO set (plus attached rangeproofs).\n> * The blinding keys.\n> * Signatures of the blinding keys, and the kernels they sign (if we use\n> the \"kernels encode `nLockTime`\" technique in some way, they should not\n> exceed the current supposed blockheight).\n>\n> The problem is that an output that exists in the UTXO set might be\n> invalid, if it appears \"too near\" to an `nSequence` minimum spend of a\n> previous output that was spent in its creation.\n> That is, the above does not allow validation of **relative** locktimes,\n> only **absolute locktimes**.\n> (At least as far as I understand: there may be special cryptographic\n> constructs that allow signatures to reliably commit to some relative\n> locktime).\n>\n> This means that relative locktimes need to be implemented by showing the\n> transactions that spend previous UTXOS and create the current UTXOs, and so\n> no backwards to coin-creation events.\n> This forces us back to the old \"validate all transactions\" model of\n> starting a new node (and seriously damaging the entire point of using\n> MimbleWimble anyway).\n>\n> I do not believe it is the lack of SCRIPT that prevents\n> Lightning-over-MimbleWimble, but rather the lack of relative locktime,\n> which seems difficult to validate without knowing the individual\n> transactions and when they were confirmed.\n>\n> Regards,\n> ZmnSCPxj\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20190920/9e42ffd9/attachment-0001.html>"
            },
            {
                "author": "Andrew Poelstra",
                "date": "2019-09-20T12:22:20",
                "message_text_only": "On Fri, Sep 20, 2019 at 04:54:34AM +1000, Lloyd Fournier via bitcoin-dev wrote:\n> Hi ZmnSCPxj,\n> \n> I can give some context on the exchange during the talk. I was the \"Q\" and\n> Andrew Polestra was the \"A\".\n> \n> I followed up with Andrew after and he indeed knew about the pre-signed\n> nlocktime transaction double spend technique (actually, I thought he was\n> the one who originally came up with that idea for scriptless atomic swaps).\n> He clarified saying that you can do that with locktime (absolute time\n> locks) but not with sequence numbers (relative time locks). i.e. to enforce\n> sequence numbers you need to use OP_CHECKSEQUENCEVERIFY. He said that it\n> would make sense to change that so it's enforced regardless of script.\n> \n> However, I talked to Antoine Riard later who was adamant that sequence\n> numbers already worked as expected. He pointed to the fact that BIP68\n> already describes it as an independent constraint [1]\n> \n> So if things do work as described in BIP68 then we should be able to do\n> lightning on Bitcoin without any script once we have Schnorr. I'm keen to\n> actually figure out all the details of how to do this. It works in my head\n> but I think I should write it down somewhere to make sure it works.\n> \n>  [1] https://github.com/bitcoin/bips/blob/master/bip-0068.mediawiki\n> \n> LL\n>\n\nYep, during the recorded exchange I was confused about the content of\nthe BIP. Later I described the exchange to Dan Robinson, who showed me\nthe actual text :).\n\nSorry for the confusion - Lloyd was totally right and you can do\nrelative locktimes this way in Taproot without needing to expose a\nscript.\n\n\nHaving said this, there is the important caveat that your \"emergency\nbackout\" keys are online to produce a pre-signed transaction, and\nthat a suitable destination is known beforehand. This makes sense for\nLightning or most atomic swap protocols where the money simply returns\nto the original owner, but not e.g. for Liquid, where the emergency\nkeys have never been brought online (and anyway the contents of any\ntransaction they might sign depends on facts and circumstances that\naren't known ahead of time).\n\n\n-- \nAndrew Poelstra\nDirector of Research, Blockstream\nEmail: apoelstra at wpsoftware.net\nWeb:   https://www.wpsoftware.net/andrew\n\nThe sun is always shining in space\n    -Justin Lewis-Webster\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 488 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20190920/b1a4b294/attachment.sig>"
            },
            {
                "author": "John Tromp",
                "date": "2019-09-19T11:16:36",
                "message_text_only": "> However, I believe that Lightning and similar offchain protocols are **not possible** on MimbleWimble, at least if we want to retain its \"magical shrinking blockchain\" property.\n\nMimbleWimble can easily incorporate relative lock heights, in addition\nto absolute lock heights. Grin and Beam have included the latter since\nlaunch.\n\nGrin's proposal for relative lock heights is at [1] with discussion at [2].\nBased on these, Grin also has a rough design for payment channels at [3].\n\nBeam included relative lock heights in its recent HardFork [4] and has\na payment channel design at [5].\n\nregards,\n-John\n\n[1] https://github.com/antiochp/grin-rfcs/blob/relative_lock_heights/text/0000-relative-kernels.md\n[2] https://github.com/mimblewimble/grin-rfcs/pull/19\n[3] https://gist.github.com/antiochp/e54fece52dc408d738bf434a14680988\n[4] https://github.com/BeamMW/beam/releases/tag/beam-3.0.5654\n[5] https://docs.beam.mw/laser_beam.pdf"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-19T15:15:00",
                "message_text_only": "Good morning John,\n\n\n> > However, I believe that Lightning and similar offchain protocols are not possible on MimbleWimble, at least if we want to retain its \"magical shrinking blockchain\" property.\n>\n> MimbleWimble can easily incorporate relative lock heights, in addition\n> to absolute lock heights. Grin and Beam have included the latter since\n> launch.\n>\n> Grin's proposal for relative lock heights is at [1] with discussion at [2].\n> Based on these, Grin also has a rough design for payment channels at [3].\n>\n> Beam included relative lock heights in its recent HardFork [4] and has\n> a payment channel design at [5].\n>\n\nThank you for this information.\nI am aware that absolute locktimes were possible in MimbleWimble.\n\nHowever, it does seem to imply that kernels are not compressible (unlike the original MimbleWimble where the kernel is just an empty string and thus never stored).\nSo at least for kernels of relative locktimes, are not pruneable and will contribute to blockchain size.\n(I believe I saw some proposal for absolute locktimes that allow some amount of aggregation/pruning of absolute-locktime kernels from the mimblewimble.pdf by andytoshi.)\n\nWhich I suppose is my point: you lose some of the \"magic shrinking blockchain\" property in implementing relative locktimes, as you now increase the data you have to store forever (i.e. the kernels).\nIt is not a *total* loss of the \"magic shrinking blockchain\", I see now, however.\n\nStill, it does see worth the cost of accepting having to store kernels forever in exchange for being able to layer on top of a MimbleWimble blockchain.\n\nIt seems to me that Poon-Dryja and Decker-Wattenhofer can be \"directly\" ported over to any MimbleWimble blockchain with relative locktimes.\nReference [5] seems to be Poon-Dryja ported over to using relative locktimes for MimbleWimble.\n\n\nDecker-Russell-Osuntokun (\"eltoo\") is harder due to the `SIGHASH_NOINPUT` requirement.\nI have tried to derive an equivalent to this `SIGHASH_NOINPUT` somehow by considering that the \"reference to previous kernel\" as being akin to the Bitcoin transaction input referring to a previous output, however it seems to be not easy to create a retargatable \"reference to previous kernel\" in this way.\n\n\nIn any case, it seems to me that the loss of SCRIPT does not prevent a MimbleWimble blockchain from using an offchain updateable cryptocurrency system.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "John Tromp",
                "date": "2019-09-19T15:47:12",
                "message_text_only": "dear ZmnSCPxj,\n\n> Which I suppose is my point: you lose some of the \"magic shrinking blockchain\" property in implementing relative locktimes, as you now increase the data you have to store forever (i.e. the kernels).\n\nThe \"magic shrinking\" of MW never applied to kernels. To validate the\ncurrent UTXO set, you need to validate *all* the kernels, each of\nwhich is a Pedersen commitment to zero together with a Schnorr\nsignature using said commitment as public key. Then you need to check\nthat the sum of UTXO commitments (outputs) minus the summed block\nrewards times G (inputs) equals the sum of kernel commitments.\nBasically, the same check that is applied to individual transactions.\n\n> It seems to me that Poon-Dryja and Decker-Wattenhofer can be \"directly\" ported over to any MimbleWimble blockchain with relative locktimes.\n> Reference [5] seems to be Poon-Dryja ported over to using relative locktimes for MimbleWimble.\n\nYes, Beam's design is a straightforward port of Poon-Dryja.\n\n> Decker-Russell-Osuntokun (\"eltoo\") is harder due to the `SIGHASH_NOINPUT` requirement.\n> I have tried to derive an equivalent to this `SIGHASH_NOINPUT` somehow by considering that the \"reference to previous kernel\" as being akin to the Bitcoin transaction input referring to a previous output, however it seems to be not easy to create a retargatable \"reference to previous kernel\" in this way.\n\nThe Grin \"Elder channel\" design of [3] is similar in spirit to eltoo\nthough, as the revocation transaction can be combined with the final\nclose transaction to counter any closing attempt to an obsolete state.\nThe design also offers some bandwidth savings compared to the\nPoon-Dryja design.\n\n> In any case, it seems to me that the loss of SCRIPT does not prevent a MimbleWimble blockchain from using an offchain updateable cryptocurrency system.\n\nCorrect; lack of scripts is not as much of a handicap for MW as it\nappears. Multi-sig, atomic swaps, and payment channels are all\npossible.\n\nregards,\n-John"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-20T05:14:59",
                "message_text_only": "Good morning John,\n\n> dear ZmnSCPxj,\n>\n> > Which I suppose is my point: you lose some of the \"magic shrinking blockchain\" property in implementing relative locktimes, as you now increase the data you have to store forever (i.e. the kernels).\n>\n> The \"magic shrinking\" of MW never applied to kernels. To validate the\n> current UTXO set, you need to validate all the kernels, each of\n> which is a Pedersen commitment to zero together with a Schnorr\n> signature using said commitment as public key.\n\nHowever, my understanding is that, at least with the original mimblewimble.txt from Jedusor, the signatures and the Pedersen-commitment-to-0 could all be aggregated into a single signature and Pedersen-commitment-to-0, if we were to use Schnorr-like signatures.\n(it is possible I misunderstand this; I am not in fact a cryptographer.\nIndeed, the original mimblewimble.txt mentions having to store every `k*G` and every signature attesting to it, although does not mention Schnorr and might not have considered the possibility of signature aggregation when using Schnorr-like signatures.\nThere could be security issues I am unaware of, for example.)\n\nIn addition, the mimblewimble.pdf from andytoshi includes a \"Sinking Signatures\" section, which to my understanding, combines absolute-locktime kernels with partial O(log n) aggregation of the signatures that attest it.\nAgain, it is possible I misunderstand this.\n\nIt seems to me that neither technique is possible with relative locktime kernels.\nAgain, this may be merely my ignorance of such.\n\nIn any case, this is mostly moot and I ask only out of curiosity in order to know more about kernels in non-relative-locktime MimbleWimble chains.\n\n\n>Then you need to check\n> that the sum of UTXO commitments (outputs) minus the summed block\n> rewards times G (inputs) equals the sum of kernel commitments.\n> Basically, the same check that is applied to individual transactions.\n> > Decker-Russell-Osuntokun (\"eltoo\") is harder due to the `SIGHASH_NOINPUT` requirement.\n> > I have tried to derive an equivalent to this `SIGHASH_NOINPUT` somehow by considering that the \"reference to previous kernel\" as being akin to the Bitcoin transaction input referring to a previous output, however it seems to be not easy to create a retargatable \"reference to previous kernel\" in this way.\n>\n> The Grin \"Elder channel\" design of [3] is similar in spirit to eltoo\n> though, as the revocation transaction can be combined with the final\n> close transaction to counter any closing attempt to an obsolete state.\n> The design also offers some bandwidth savings compared to the\n> Poon-Dryja design.\n\nThis seems interesting.\nI shall look into this further.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Timelocks and Lightning on MimbleWimble",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Lloyd Fournier",
                "ZmnSCPxj",
                "Andrew Poelstra",
                "John Tromp",
                "Martin Schwarz"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 36562
        }
    },
    {
        "title": "[bitcoin-dev] Block Batch Filters for Light Clients",
        "thread_messages": [
            {
                "author": "admin at bitaps.com",
                "date": "2019-09-19T17:20:13",
                "message_text_only": "Hello list, \n\nHere is a link for a draft of a BIP for  compact probabilistic block filters alternative of BIP 158\n\nhttps://docs.google.com/document/d/1jH9tEUyb9w2OZd4-kxfGuyNIIZzmgkEb_z0qSxv80ik/edit?usp=sharing <https://docs.google.com/document/d/1jH9tEUyb9w2OZd4-kxfGuyNIIZzmgkEb_z0qSxv80ik/edit?usp=sharing>\n\nSummary:\n\n - BIP 158  false positive rate is low, we can achieve lower bandwidth with higher false positive rate filter while sync blockchain\n\n - BIP 158 not do not support filter batching by design of used parameters for siphash and Golomb coding optimal parameters\n\n - Alternative compression with delta coding and splitting data to 2 bit string  sequences. First for data without prefixes, second one for information about  bit length written to first sequence.\n   Second sequence have a lot of duplicates,  compressed with 2 round of Huffman algorithm. (Effectivity about 98% vs Golomb with optimal parameters)\n\n - Block filters batching reduce filter size significantly\n\n- Separation of filters by address type allows lite client not to download redundant information without compromising privacy.\n\n- Lite client filters download strategy: get biggest filter (smallest blocks/size rate) for blocks range, in case positive test  -> get medium filters to reduce blocks range ->  get block filters for affected range -> download affected blocks over TOR \n\nImplementation (python): https://github.com/bitaps-com/pybtc/blob/bugfix/pybtc/functions/filters.py#L172 <https://github.com/bitaps-com/pybtc/blob/bugfix/pybtc/functions/filters.py#L172>\n\nExactly information from mainnet  about size for separated filters by address types and batch size will be added within few days.\n\nThanks for any feedback.\n      Aleksey Karpov\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20190919/bdd152e6/attachment.html>"
            },
            {
                "author": "Tamas Blummer",
                "date": "2019-09-21T21:16:25",
                "message_text_only": "Hi Aleksey,\n\nYes, BIP158 uses the block hash to seed the hash function, which makes distinct block filters non-aggregatable \nfor common values. Aggregate fiters on ranges of blocks would have to use some other seed and then \nachive significant savings using the same design.\n\nI think that the most likely use of filters is to decide if a newly announced block should be downloaded and \nnot scanning over the entire chain, where aggregate filters would help. I also suspect that whole chain \nscans would be better served with plain sequential reads in map-reduce style.\n\nTypical clients do not care of filters for blocks before the birth date of their wallet\u2019s keys, so they skip over the \nmajority of history which is a bigger saving than any aggregate filter.\n\nI wish we get a filter committed as commitment would unlock more utility than any marginal savings through\nmore elaborate design.\n\nTamas Blummer\n\n> On Sep 19, 2019, at 19:20, admin--- via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Hello list, \n> \n> Here is a link for a draft of a BIP for  compact probabilistic block filters alternative of BIP 158\n> \n> https://docs.google.com/document/d/1jH9tEUyb9w2OZd4-kxfGuyNIIZzmgkEb_z0qSxv80ik/edit?usp=sharing <https://docs.google.com/document/d/1jH9tEUyb9w2OZd4-kxfGuyNIIZzmgkEb_z0qSxv80ik/edit?usp=sharing>\n> \n> Summary:\n> \n>  - BIP 158  false positive rate is low, we can achieve lower bandwidth with higher false positive rate filter while sync blockchain\n> \n>  - BIP 158 not do not support filter batching by design of used parameters for siphash and Golomb coding optimal parameters\n> \n>  - Alternative compression with delta coding and splitting data to 2 bit string  sequences. First for data without prefixes, second one for information about  bit length written to first sequence.\n>    Second sequence have a lot of duplicates,  compressed with 2 round of Huffman algorithm. (Effectivity about 98% vs Golomb with optimal parameters)\n> \n>  - Block filters batching reduce filter size significantly\n> \n> - Separation of filters by address type allows lite client not to download redundant information without compromising privacy.\n> \n> - Lite client filters download strategy: get biggest filter (smallest blocks/size rate) for blocks range, in case positive test  -> get medium filters to reduce blocks range ->  get block filters for affected range -> download affected blocks over TOR \n> \n> Implementation (python): https://github.com/bitaps-com/pybtc/blob/bugfix/pybtc/functions/filters.py#L172 <https://github.com/bitaps-com/pybtc/blob/bugfix/pybtc/functions/filters.py#L172>\n> \n> Exactly information from mainnet  about size for separated filters by address types and batch size will be added within few days.\n> \n> Thanks for any feedback.\n>       Aleksey Karpov\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20190921/ecea43cc/attachment.html>"
            },
            {
                "author": "nopara73",
                "date": "2019-09-23T05:20:31",
                "message_text_only": "Please also take a look at \"Applying Private Information Retrieval to\nLightweight Bitcoin Clients\" Scaling Bitcoin talk. The academics were not\naware of BIP158 at all, yet came up with a similar scheme independently.\n\nOn Sat, Sep 21, 2019 at 11:40 PM Tamas Blummer via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Aleksey,\n>\n> Yes, BIP158 uses the block hash to seed the hash function, which makes\n> distinct block filters non-aggregatable\n> for common values. Aggregate fiters on ranges of blocks would have to use\n> some other seed and then\n> achive significant savings using the same design.\n>\n> I think that the most likely use of filters is to decide if a newly\n> announced block should be downloaded and\n> not scanning over the entire chain, where aggregate filters would help. I\n> also suspect that whole chain\n> scans would be better served with plain sequential reads in map-reduce\n> style.\n>\n> Typical clients do not care of filters for blocks before the birth date of\n> their wallet\u2019s keys, so they skip over the\n> majority of history which is a bigger saving than any aggregate filter.\n>\n> I wish we get a filter committed as commitment would unlock more utility\n> than any marginal savings through\n> more elaborate design.\n>\n> Tamas Blummer\n>\n> On Sep 19, 2019, at 19:20, admin--- via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Hello list,\n>\n> Here is a link for a draft of a BIP for  compact probabilistic block\n> filters alternative of BIP 158\n>\n>\n> https://docs.google.com/document/d/1jH9tEUyb9w2OZd4-kxfGuyNIIZzmgkEb_z0qSxv80ik/edit?usp=sharing\n>\n> Summary:\n>\n>  - BIP 158  false positive rate is low, we can achieve lower bandwidth\n> with higher false positive rate filter while sync blockchain\n>\n>  - BIP 158 not do not support filter batching by design of used parameters\n> for siphash and Golomb coding optimal parameters\n>\n>  - Alternative compression with delta coding and splitting data to 2 bit\n> string  sequences. First for data without prefixes, second one for\n> information about  bit length written to first sequence.\n>    Second sequence have a lot of duplicates,  compressed with 2 round of\n> Huffman algorithm. (Effectivity about 98% vs Golomb with optimal parameters)\n>\n>  - Block filters batching reduce filter size significantly\n>\n> - Separation of filters by address type allows lite client not to download\n> redundant information without compromising privacy.\n>\n> - Lite client filters download strategy: get biggest filter (smallest\n> blocks/size rate) for blocks range, in case positive test  -> get medium\n> filters to reduce blocks range ->  get block filters for affected range ->\n> download affected blocks over TOR\n>\n> Implementation (python):\n> https://github.com/bitaps-com/pybtc/blob/bugfix/pybtc/functions/filters.py#L172\n>\n> Exactly information from mainnet  about size for separated filters by\n> address types and batch size will be added within few days.\n>\n> Thanks for any feedback.\n>       Aleksey Karpov\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n-- \nBest,\n\u00c1d\u00e1m\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20190923/4e98ec12/attachment.html>"
            },
            {
                "author": "admin at bitaps.com",
                "date": "2019-09-24T13:36:26",
                "message_text_only": "Last version updated draft\n\n https://github.com/bitaps-com/bips/blob/master/bip-block-batch-filters.mediawiki <https://github.com/bitaps-com/bips/blob/master/bip-block-batch-filters.mediawiki>\n\nSummary changes:\n\n- return back to Golomb coding \n- implemented more simple and effective shema\n- Total filters size  is smaller then BIP 158 at all total estimated savings more than 20% (exactly info will be soon)\n- filter is deterministic  and could be committed as commitment in coinbase transaction in future\n- flexible GCS parameters to to maintain the necessary FPS\n- spliting filter for 2 parts: unique elements and duplicated elements\n- duplicated elements could be encoded more effective\n\nOpen questions:\n\n- Optimal range for batch?\n- Why we need sip has instead of just use first 64 bits from pub key/script hash?\n- Downloading unique/duplicated elements separately? Just add filter types for these purposes?\n\n\nThanks for any feedback or discussions \n    Aleksey Karpov\n\n\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20190924/5861d2f2/attachment.html>"
            },
            {
                "author": "admin at bitaps.com",
                "date": "2019-09-28T17:21:47",
                "message_text_only": "Block Batch Filters draft :\n\nhttps://github.com/bitaps-com/bips/blob/master/bip-block-batch-filters.mediawiki <https://github.com/bitaps-com/bips/blob/master/bip-block-batch-filters.mediawiki>\n\nBIP 157 unlike BIP 37 not allow apply filters to mempool and check zero confirmation transactions.\nLight client that refused to use BIP 37 due to privacy leaks can process unconfirmed transactions only one way and this is loading the entire mempool transaction flow.\n\nMempool Transaction Filters draft:\n\nhttps://github.com/bitaps-com/bips/blob/master/bip-mempool-transactions-filters.mediawiki <https://github.com/bitaps-com/bips/blob/master/bip-mempool-transactions-filters.mediawiki>\n\nSummary:\n    - improved Block Batch Filters definition\n    - unlocked ability to filter unconfirmed transaction for SPV nodes used BIP 157 instead of BIP 37 due privacy leak in BIP 37\n    - more bandwidth consumption reduced in contrast with block filters and downloading full blocks for affected addresses\n    - proposal for future consensus layer soft-fork to make block filters commitment one of the block validation rule to protect light nodes from payment hiding attack\n\n\n\n\n\n\n> 23 \u0441\u0435\u043d\u0442. 2019 \u0433., \u0432 15:00, bitcoin-dev-request at lists.linuxfoundation.org \u043d\u0430\u043f\u0438\u0441\u0430\u043b(\u0430):\n> \n> Re: Block Batch Filters for Light Clients\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20190928/5d399a03/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Block Batch Filters for Light Clients",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Tamas Blummer",
                "nopara73",
                "admin at bitaps.com"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 11321
        }
    },
    {
        "title": "[bitcoin-dev] bitcoin-dev Digest, Vol 52, Issue 15",
        "thread_messages": [
            {
                "author": "John Tromp",
                "date": "2019-09-20T12:47:37",
                "message_text_only": "> However, my understanding is that, at least with the original mimblewimble.txt from Jedusor, the signatures and the Pedersen-commitment-to-0 could all be aggregated into a single signature and Pedersen-commitment-to-0, if we were to use Schnorr-like signatures.\n\nNon-interactive aggregatability depends on the signature scheme.\nSchnorr doesn't support it, whereas something like BLS signatures does.\nThe original paper excludes the use of the latter with the remark\n\"And also imagine that we must not pairing-based cryptography or new\nhypotheses, just regular discrete logarithms signatures like Bitcoin.\"\n\n> Indeed, the original mimblewimble.txt mentions having to store every `k*G` and every signature attesting to it, although does not mention Schnorr and might not have considered the possibility of signature aggregation when using Schnorr-like signatures.\n\nSchnorr signatures can only be aggregated interactively though, and is\nthus limited to individual transactions which are built interactively.\n\n> In addition, the mimblewimble.pdf from andytoshi includes a \"Sinking Signatures\" section, which to my understanding, combines absolute-locktime kernels with partial O(log n) aggregation of the signatures that attest it.\n\nI must admit to never having quite understood Sinking Signatures, but\nthey were deemed\nto have too many drawbacks for practical use.\n\n> It seems to me that neither technique is possible with relative locktime kernels.\n\nKernels already sign for optional additional attributes such as fee\nand lock height. A relative kernel would just add a reference to\nanother kernel as an additional attribute. Which doesn't seem to\naffect its aggregatability.\n\n-John"
            }
        ],
        "thread_summary": {
            "title": "bitcoin-dev Digest, Vol 52, Issue 15",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "John Tromp"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1682
        }
    },
    {
        "title": "[bitcoin-dev] New BIP for p2p messages/state enabling reconciliation-based protocols (Erlay)",
        "thread_messages": [
            {
                "author": "Gleb Naumenko",
                "date": "2019-09-25T11:28:00",
                "message_text_only": "We are opening for review a draft of the new BIP, which describes low-level specifications for the reconciliation-based transaction announcement protocol.\nhttps://github.com/naumenkogs/bips/blob/bip-reconcil/bip-reconcil.mediawiki\n\nAgreeing on this spec would enable integration of more bandwidth-efficient relay protocols, like Erlay (https://arxiv.org/abs/1905.10518).\n\nThe draft has all the background necessary to understand the work, so please read and review.\nIt introduces salted short transaction IDs (required to do reconciliation efficiently) and demonstrates how to compute sketches based on these IDs (including simple python scripts).\nIt also introduces wtxid-based truncated transaction IDs (to trivially save significant fraction of the bandwidth).\nFinally, it specifies all the messages to be used by an efficient reconciliation-based protocol, and new state variables required for the protocol.\n\nPlease note that, comparing to the Erlay paper, we decided to add extra round, where 2 parties explicitly map 32-bit short IDs to 128-bit truncated IDs, because otherwise peers which take >1s to reconcile would cause transmitting duplicate transactions (extra bandwidth), and we cannot assume <1s latency in Bitcoin, especially over Tor.\nAccording to my estimates, the bandwidth overhead due to the measure from the BIP (extra communication round) is only extra 10% comparing to the original Erlay estimates.\n\nIt is possible that we missed some of the state variables required to handle corner cases of the protocol, because the spec is based on my prototype code, and it might evolve when we will be building an actual production-ready implementation.\n\nOverall, I believe that this spec is ready for review.\n\nEven though this work does not require a fork, the change is quite significant, and peer-review is critical for the system, so please take a look. Feel free to reach out for questions and comments here or directly over email.\n\n\u2013 gleb\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20190925/90bfdb64/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2019-09-27T02:08:27",
                "message_text_only": "Hi Gleb,\n\n        Minor feedback on reading the draft:\n\n> sendrecon:\n> uint32 \tversion \tMust be exactly 1 currently.\n\nAt risk of quoting myself[1]: data doesn't have requirements.  Actors do.\nIn this case, I assume you mean \"writers must set this to 1\".  What do\nreaders do if it's not?\n\n> reqreconcil\n> uint8 \tq \tCoefficient used to estimate set difference.\n\nYou describe how to calculate q (as a floating point value), but not how\nto encode it?\n\n> Every node stores sets of 128-bit truncated IDs per every peer\n\n\"*a* set...\" or is it \"two sets\" (if you include the snapshot?).\n\nAnd \" *for* every peer\" (maybe \"which supports tx reconciliation?\")\n\n> To the best of our knowledge, PinSketch is more bandwidth efficient\n> than IBLT, especially for the small differences in sets we expect to\n> operate over.\n\nRemove \"To the best of our knowledge, \": that makes it sound like it's\nup for debate.  I've implemented and experimented with IBLT, and it's\nworse.\n\nCheers,\nRusty.\n\n[1] https://github.com/lightningnetwork/lightning-rfc/blob/master/CONTRIBUTING.md#writing-the-requirements"
            }
        ],
        "thread_summary": {
            "title": "New BIP for p2p messages/state enabling reconciliation-based protocols (Erlay)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Gleb Naumenko"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 3217
        }
    },
    {
        "title": "[bitcoin-dev] Continuing the discussion about noinput / anyprevout",
        "thread_messages": [
            {
                "author": "Christian Decker",
                "date": "2019-09-30T13:23:56",
                "message_text_only": "With the recently renewed interest in eltoo, a proof-of-concept implementation\n[1], and the discussions regarding clean abstractions for off-chain protocols\n[2,3], I thought it might be time to revisit the `sighash_noinput` proposal\n(BIP-118 [4]), and AJ's `bip-anyprevout` proposal [5].\n\n(sorry for the long e-mail. I wanted to give enough context and describe the\nvarious tradeoffs so people don't have to stitch them together from memory. If\nyou're impatient there are a couple of open questions at the bottom)\n\nBoth proposals are ways to allow rebinding of transactions to new outputs, by\nadding a sighash flag that excludes the output when signing. This allows the\ntransaction to be bound to any output, without needing a new signature, as\nlong as output script and input script are compatible, e.g., the signature\nmatches the public key specified in the output.\n\nBIP-118 is limited to explaining the details of signature verification, and\nomits anything related to deployment and dependency on other proposals. This\nwas done in order not to depend on bip-taproot which is also in draft-phase\ncurrently, and to allow deployment alongside the next version of segwit\nscript. `bip-anyprevout` builds on top of BIP-118, adding integration with\n`bip-taproot`, chaperone signatures, limits the use of the sighash flag to\nscript path spends, as well as a new pubkey serialization which uses the first\nbyte to signal opt-in.\n\nI'd like to stress that both proposals are complementary and not competing,\nwhich is something that I've heard a couple of times.\n\nThere remain a couple of unclear points which I hope we can address in the\ncoming days, to get this thing moving again, and hopefully get a new tool in\nour toolbox soon(ish).\n\nIn the following I will quote a couple of things that were discussed during\nthe CoreDev meeting earlier this year, but not everybody could join, and it is\nimportant that we engage the wider community, to get a better picture, and I\nthink not everybody is up-to-date about the current state.\n\n\n## Dangers of `sighash_noinput`\n\nAn argument I have heard against noinput is that it is slightly less complex\nor compute intensive than `sighash_all` signatures, which may encourage wallet\ncreators to only implement the noinput variant, and use it indiscrimi-\nnately. This is certainly a good argument, and indeed we have seen at least\none developer proposing to use noinput for all transactions to discourage\naddress reuse.\n\nThis was also mentioned at CoreDev [6]:\n\n> When [...] said he wanted to write a wallet that only used SIGHASH\\_NOINPUT,\n> that was pause for concern. Some people might want to use SIGHASH\\_NOINPUT as a\n> way to cheapen or reduce the complexity of making a wallet\n> implementation. SIGHASH\\_NOINPUT is from a purely procedural point of view\n> easier than doing a SIGHASH\\_ALL, that's all I'm saying. So you're hashing\n> less. It's way faster. That concern has been brought to my attention and it's\n> something I can see. Do we want to avoid people being stupid and shooting\n> themselves and their customers in the foot? Or do we treat this as a special\n> case where you mark we're aware of how it should be used and we just try to\n> get that awareness out?\n\nAnother issue that is sometimes brought up is that an external user may\nattempt to send funds to a script that was really part of a higher-level\nprotocol. This leads to those funds becoming inaccessible unless you gather\nall the participants and sign off on those funds. I don't believe this is\nanything new, and if users really want to shoot themselves in the foot and\nsend funds to random addresses they fish out of a blockexplorer there's little\nwe can do. What we could do is make the scripts used internally in our\nprotocols unaddressable (see output tagging below), removing this issue\naltogether.\n\n\n## Chaperone signatures\n\nChaperone signatures are signatures that ensure that there is no third-party\nmalleability of transactions. The idea is to have an additional signature,\nthat doesn't use noinput, or any of its variants, and therefore needs to be\nauthored by one of the pubkeys in the output script, i.e., one or more of the\nparticipants of the contract the transaction belongs to. Concretely in eltoo\nwe'd be using a shared key known to all participants in the eltoo instance, so\nany participant can sign an update to rebind it to the desired output.\n\nChaperone signatures have a number of downsides however:\n\n-   Additional size: both the public key and the signature actually need to be\n    stored along with the real noinput signature, resulting in transfer,\n    computational and storage overhead. We can't reuse the same pubkey from the\n    noinput signature since that'd require access to the matching privkey which\n    is what we want to get rid of using noinput in the first place.\n-   Protocols can still simply use a globally known privkey, voiding the\n    benefit of chaperone signatures, since third-parties can sign again. I\n    argue that third-party malleability is a subset of first-party\n    malleability, and we should protect against first-party malleability first\n    and foremost. My counterparty has the incentive to trick me, a third-party\n    may not.\n\nOn the plus side chaperone signatures certainly address the lazy-wallet-dev\nscenario, and as AJ points out in [bip-anyprevout] we get back the same\nsecurity guarantees as we had without noinput.\n\n>From what I remember and the transcript (thanks Kanzure for your awesome work\nby the way), there was no strong support for chaperone signatures during the\nmeeting [6], but feedback from people that were not present is needed:\n\n> if everyone who wanted to use NOINPUT was convinced there was a problem, then\n> they would pick the right thing, but clearly people aren't. It's not a\n> foot-gun defense mechanism because it's easily bypassed, and it's easier to\n> bypass it than to use it. Whereas for tagged outputs, it's that if you want\n> any NOINPUT then you must tag.\n\n\n## Output tagging\n\nOne proposal that I found rather fascinating during the discussion in\nAmsterdam was that we could achieve the same disincentive to use on\nnon-smart-contract cases by simply making the output scripts\nunaddressable. This can be done by specifying a version of taproot outputs for\nwhich the bech32 addressing scheme simply doesn't have a representation [6]:\n\n> The tagged outputs idea is that we don't have NOINPUT ANYPREVOUT supported for\n> taproot v1 outputs, instead we have a segwit version 16 v16 that supports\n> taproot. The reason for v16 is that we redefine bech32 to not cover\n> v16. There's no addresses for this type of output. If you're an exchange and\n> receive a bech32 address, you declare it invalid. You make it less user\n> friendly here; and there shouldn't be an address anyway. You might want to see\n> it on a block explorer, but you don't want to pass it around to anyone.\n\nWe don't need addresses in our contract constructions because we deal directly\nwith the scripts. This would also have the desired effect of no allowing\ngeneric wallets to send to these addresses, or users accidentally sending\nfunds to what was supposed to be a one-off script used internally in the\noff-chain contract.\n\nNotice that this idea was already used by Russell O'Connor when performing a\ntransaction on elements using his new scripting language simplicity\n[7]:\n\n> For this experimental development, we created an improper segwit version,\n> \"version 31\" for Simplicity addresses. The payload of this segwit version 31\n> address contains a commitment Merkle root of a Simplicity program to control\n> the UTXO.\n\nThe concern with output tagging is that it hurts fungibility, marking outputs\nused in a contract as such and making them identifiable. But maybe it would be\na good idea to create two domains anyway: one for user-addressable\ndestinations which users can use with their general purpose wallets, and one\ndomain for contracts, which users cannot send to directly.\n\nThis also came up during the CoreDev meeting [ams-coredev]:\n\n> these sort of NOINPUT signatures are only things that are within some\n> application or within some protocol that gets negotiated between participants,\n> but they don't cross-independent domains where you see a wallet or a protocol\n> as a kind of domain. You can't tell the difference, is this an address I can\n> give to someone else or not? It's all scripts, no real addresses. There are\n> types of outputs that are completely insecure unconditionally; there are\n> things that are protected and I can give to anyone, you don't want to reuse\n> it, but there's no security issue from doing so. This is an additional class\n> that is secure perfectly but only when used in the right way.\n\n\n## Open questions\n\nThe questions that remain to be addressed are the following:\n\n1.  General agreement on the usefulness of noinput / anyprevoutanyscript /\n    anyprevout. While at the CoreDev meeting I think everybody agreed that\n    these proposals a useful, also beyond eltoo, not everybody could be\n    there. I'd therefore like to elicit some feedback from the wider community.\n2.  Is there strong support or opposition to the chaperone signatures\n    introduced in anyprevout / anyprevoutanyscript? I think it'd be best to\n    formulate a concrete set of pros and contras, rather than talk about\n    abstract dangers or advantages.\n3.  The same for output tagging / explicit opt-in. What are the advantages and\n    disadvantages?\n4.  Shall we merge BIP-118 and bip-anyprevout. This would likely reduce the\n    confusion and make for simpler discussions in the end.\n5.  Anything I forgot to mention :-)\n\nCheers,\nChristian\n\n[1] <https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-September/002131.html>\n[2] <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-September/017285.html>\n[3] <https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-August/001383.html>\n[4] <https://github.com/bitcoin/bips/blob/master/bip-0118.mediawiki>\n[5] <https://github.com/ajtowns/bips/blob/bip-anyprevout/bip-anyprevout.mediawiki>\n[6] <http://diyhpl.us/wiki/transcripts/bitcoin-core-dev-tech/2019-06-06-noinput-etc/>\n[7] <https://lists.ozlabs.org/pipermail/simplicity/2019/000018.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-30T16:00:35",
                "message_text_only": "Good morning Christian,\n\n> The concern with output tagging is that it hurts fungibility, marking outputs\n> used in a contract as such and making them identifiable. But maybe it would be\n> a good idea to create two domains anyway: one for user-addressable\n> destinations which users can use with their general purpose wallets, and one\n> domain for contracts, which users cannot send to directly.\n\nI rather strongly oppose output tagging.\n\nThe entire point of for example Taproot was to reduce the variability of how outputs look like, so that unspent Taproot outputs look exactly like other unspent Taproot outputs regardless of the SCRIPT (or lack of SCRIPT) used to protect the outputs.\nThat is the reason why we would prefer to not support P2SH-wrapped Taproot even though P2SH-wrapping was intended to cover all future uses of SegWit, including SegWit v1 that Taproot will eventually get.\n\nIndeed, if it is output tagging that gets into Bitcoin base layer, I would strongly suggest the below for all Decker-Russell-Osuntokun implementations:\n\n* A standard MuSig 2-of-2 bip-schnorr SegWit v1 Funding Transaction Output, confirmed onchain\n* A \"translator transaction\" spending the above and paying out to a SegWit v16 output-tagged output, kept offchain.\n* Decker-Russell-Osuntokun update transaction, signed with `SIGHASH_NOINPUT` spending the translator transaction output.\n* Decker-Russell-Osuntokun state transaction, signed with `SIGHASH_NOINPUT` spending the update transaction output.\n\nThe point regarding use of a commonly-known privkey to work around chaperone signatures is appropriate to the above, incidentally.\nIn short: this is a workaround, plain and simple, and one wonders the point of adding *either* chaperones *or* output tagging if we will, in practice, just work around them anyway.\n\nAgain, the *more* important point is that special blockchain constructions should only be used in the \"bad\" unilateral close case.\nIn the cooperative case, we want to use simple plain bip-schnorr-signed outputs getting spent to further bip-schnor/Taproot SegWit v1 addresses, to increase the anonymity set of all uses of Decker-Russell-Osuntokun and other applications that might use `SIGHASH_NOINPUT` in some edge case (but which resolve down to simple bip-schnorr-signed n-of-n cases when the protocol is completed successfully by all participants).\n\nWe already have the issue in current Lightning where the blockchain-explorer-revealed address for current, existing Poon-Dryja channels is unsafe to send any amount to.\nGranted, we should work to make things safer; but I suggest that we should be willing to sacrifice some amount of safety against arguably-stupid decisions in order to have better privacy for larger sets of users.\n\n>\n> This also came up during the CoreDev meeting [ams-coredev]:\n>\n> > these sort of NOINPUT signatures are only things that are within some\n> > application or within some protocol that gets negotiated between participants,\n> > but they don't cross-independent domains where you see a wallet or a protocol\n> > as a kind of domain. You can't tell the difference, is this an address I can\n> > give to someone else or not? It's all scripts, no real addresses. There are\n> > types of outputs that are completely insecure unconditionally; there are\n> > things that are protected and I can give to anyone, you don't want to reuse\n> > it, but there's no security issue from doing so. This is an additional class\n> > that is secure perfectly but only when used in the right way.\n\nI submit that a Taproot whose internal Taproot point is a NUMS point (thus nobody knows its scalar) is similarly \"secure perfectly but only when used in the right way\".\nYet the point of Taproot is to hide these outputs until they are spent, improving their privacy while unspent.\n\nI submit also that a Taproot whose internal Taproot point is an n-of-n of all participants, with script branches enforcing particular modes, are similarly \"secure perfectly but only when used in the right way\", and again the point of Taproot is to allow the n-of-n \"everybody agrees\" path to hide among the 1-of-1 whale HODLers.\n\nIn short: I do not see how you can coherently argue for \"we should separate `SIGHASH_NOINPUT` types to a new script type\" while simultaneously arguing \"we should merge all kinds of SCRIPT usage (and non-usage) together into a single script type\".\nIf we will separate `SIGHASH_NOINPUT`-enabled outputs, we should not implement Taproot, as the existing separation of P2WSH and P2WPKH is congruent to the proposed separation of `SIGHASH_NOINPUT`-enablement.\n\n>\n> Open questions\n>\n> ---------------\n>\n> The questions that remain to be addressed are the following:\n>\n> 1.  General agreement on the usefulness of noinput / anyprevoutanyscript /\n>     anyprevout. While at the CoreDev meeting I think everybody agreed that\n>     these proposals a useful, also beyond eltoo, not everybody could be\n>     there. I'd therefore like to elicit some feedback from the wider community.\n\nI strongly agree that `NOINPUT` is useful, and I was not able to attend CoreDev (at least, not with any human fleshbot already known to you --- I checked).\n\n>\n> 2.  Is there strong support or opposition to the chaperone signatures\n>     introduced in anyprevout / anyprevoutanyscript? I think it'd be best to\n>     formulate a concrete set of pros and contras, rather than talk about\n>     abstract dangers or advantages.\n\nNo opposition, we will just work around this by publishing a common known private key to use for all chaperone signatures, since all the important security is in the `NOINPUT` signature anyway.\n\n>\n> 3.  The same for output tagging / explicit opt-in. What are the advantages and\n>     disadvantages?\n\nStrongly oppose, see above about my argument.\n\n>\n> 4.  Shall we merge BIP-118 and bip-anyprevout. This would likely reduce the\n>     confusion and make for simpler discussions in the end.\n\nAmbivalent, mildly support.\n\n>\n> 5.  Anything I forgot to mention :-)\n\nCats are very interesting creatures, and are irrelevant to `SIGHASH_NOINPUT` discussion, but are extremely cute nonetheless.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-09-30T23:28:43",
                "message_text_only": "Good morning list,\n\nTo elucidate further ---\n\nSuppose rather than `SIGHASH_NOINPUT`, we created a new opcode, `OP_CHECKSIG_WITHOUT_INPUT`.\n\nThis new opcode ignores any `SIGHASH` flags, if present, on a signature, but instead hashes the current transaction without the input references, then checks that hash to the signature.\n\nThis is equivalent to `SIGHASH_NOINPUT`.\n\nYet as an opcode, it would be possible to embed in a Taproot script.\n\nFor example, a Decker-Russell-Osuntokun would have an internal Taproot point be a 2-of-2, then have a script `OP_1 OP_CHECKSIG_WITHOUT_INPUT`.\nUnilateral closes would expose the hidden script, but cooperative closes would use the 2-of-2 directly.\n\nOf note, is that any special SCRIPT would already be supportable by Taproot.\nThis includes SCRIPTs that may potentially lose funds for the user.\nYet such SCRIPTs are already targetable by a Taproot address.\n\nIf we are so concerned about `SIGHASH_NOINPUT` abuse, why are we not so concerned about Taproot abuse?\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "Continuing the discussion about noinput / anyprevout",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Christian Decker"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 17345
        }
    }
]