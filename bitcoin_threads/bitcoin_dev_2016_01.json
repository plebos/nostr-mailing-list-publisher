[
    {
        "title": "[bitcoin-dev] Segregated witnesses and validationless mining",
        "thread_messages": [
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2016-01-02T16:37:54",
                "message_text_only": "Is there a link to the IRC discussion?\nOn Jan 1, 2016 12:49 AM, \"Peter Todd via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> On Tue, Dec 22, 2015 at 05:31:19PM -0800, Peter Todd via bitcoin-dev\nwrote:\n> > # Summary\n>\n> Updates from IRC discussion:\n\nIs there a link to the IRC discussion?\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160102/209a13ac/attachment.html>"
            },
            {
                "author": "Bryan Bishop",
                "date": "2016-01-02T16:54:43",
                "message_text_only": "On Sat, Jan 2, 2016 at 10:37 AM, Jorge Tim\u00f3n\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > Updates from IRC discussion:\n>\n> Is there a link to the IRC discussion?\n\nprior-block possession proofs, fraud proofs, non-fraud correctness\nproofs, commitments and segwit:\nhttps://botbot.me/freenode/bitcoin-core-dev/2015-12-28/?msg=56907496&page=2\n\n- Bryan\nhttp://heybryan.org/\n1 512 203 0507"
            }
        ],
        "thread_summary": {
            "title": "Segregated witnesses and validationless mining",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Bryan Bishop",
                "Jorge Tim\u00f3n"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 884
        }
    },
    {
        "title": "[bitcoin-dev] An implementation of BIP102 as a softfork.",
        "thread_messages": [
            {
                "author": "joe2015 at openmailbox.org",
                "date": "2016-01-03T03:51:26",
                "message_text_only": "On 2016-01-03 02:46, Marco Falke wrote:\n> 2015-12-30 17:27 GMT+01:00  <joe2015 at openmailbox.org>:\n>> On 2015-12-30 18:33, Marco Falke wrote:\n>>> \n>>> This is an interesting approach but I don't see how this is a soft\n>>> fork. (Just because something is not a hard fork, doesn't make it a\n>>> soft fork by definition)\n>>> Softforks don't require any nodes to upgrade. [1]\n>>> Nonetheless, as I understand your approach, it requires nodes to\n>>> upgrade. Otherwise they are missing all transactions but the coinbase\n>>> transactions. Thus, they cannot update their utxoset and are easily\n>>> susceptible to double spends...\n>>> \n>>> Am I missing something obvious?\n>>> \n>>> -- Marco\n>>> \n>>> \n>>> [1] https://en.bitcoin.it/wiki/Softfork#Implications\n>> \n>> \n>> It just depends how you define \"softfork\".  In my original write-up I \n>> called\n>> it a \"generalized\" softfork, Peter suggested a \"firm\" fork, and there \n>> are\n>> some suggestions for other names.  Ultimately what you call it is not \n>> very\n>> important.\n>> \n>> --joe.\n> \n> joe, indeed it is not important how you call it, but please, let's not\n> call it \"soft fork\".\n\nThis kind of fork (whatever it is called) has all the traditional \nproperties of a softfork except meaningful backwards compatibility for \nnon-upgraded clients.  So I think it is reasonable to call it a softfork \nwith some qualification.\n\n> Besides my initial question about the coinbase\n> tx, I was also wondering how non-updated nodes would verify the\n> collected fees without the actual txs at hand. (They only have the\n> coinbase tx, don't they?)\n\nYes this appears to be an oversight in my proof-of-concept \nimplementation.  The unintended consequence being that all transactions \nwould have to be zero-fee...\n\nThe simplest fix would be make the new rules add the fees implicitly.  \nThere are other solutions.\n\n> Moreover, I can't see the benefits over a hard fork. A hard fork is\n> much cleaner in regard to code changes. As one of the intends of\n> \"generalized soft forks\" is to force user to update, at least a hard\n> fork doesn't lie about the fact. Am I missing any obvious advantages\n> of a \"generalized soft fork\" over a \"clean\" hard fork?\n\nA \"firm soft fork\" also does not lie about that fact -- you must \nupgrade.  I don't see it dishonest if it was never claimed otherwise.\n\nI agree that hardforks can be \"cleaner\".\n\nHowever the obvious disadvantage of a hardfork is the risk of the \nnetwork splitting between upgraded and non-upgraded clients.  This is \nnot a problem if there is 100% consensus behind the hardfork, but I am \nnot sure if 100% is realistically achievable for contentious issues such \nas the blocksize limit.\n\nIf 100% consensus is never achieved, then the options are:\n1. Never upgrade and keep the blocksize limit unchanged forever.\n2. Use a firm softfork to resolve the deadlock.\n3. Hardfork anyway and split the network.\n\nMy argument is simply that 2 is better than 3 and possibly 1.\n\n--joe"
            },
            {
                "author": "Nick ODell",
                "date": "2016-01-04T18:04:29",
                "message_text_only": "How are you collecting fees from the transactions in the block?\n\nOn Sat, Jan 2, 2016 at 8:51 PM, joe2015--- via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> On 2016-01-03 02:46, Marco Falke wrote:\n>>\n>> 2015-12-30 17:27 GMT+01:00  <joe2015 at openmailbox.org>:\n>>>\n>>> On 2015-12-30 18:33, Marco Falke wrote:\n>>>>\n>>>>\n>>>> This is an interesting approach but I don't see how this is a soft\n>>>> fork. (Just because something is not a hard fork, doesn't make it a\n>>>> soft fork by definition)\n>>>> Softforks don't require any nodes to upgrade. [1]\n>>>> Nonetheless, as I understand your approach, it requires nodes to\n>>>> upgrade. Otherwise they are missing all transactions but the coinbase\n>>>> transactions. Thus, they cannot update their utxoset and are easily\n>>>> susceptible to double spends...\n>>>>\n>>>> Am I missing something obvious?\n>>>>\n>>>> -- Marco\n>>>>\n>>>>\n>>>> [1] https://en.bitcoin.it/wiki/Softfork#Implications\n>>>\n>>>\n>>>\n>>> It just depends how you define \"softfork\".  In my original write-up I\n>>> called\n>>> it a \"generalized\" softfork, Peter suggested a \"firm\" fork, and there are\n>>> some suggestions for other names.  Ultimately what you call it is not\n>>> very\n>>> important.\n>>>\n>>> --joe.\n>>\n>>\n>> joe, indeed it is not important how you call it, but please, let's not\n>> call it \"soft fork\".\n>\n>\n> This kind of fork (whatever it is called) has all the traditional properties\n> of a softfork except meaningful backwards compatibility for non-upgraded\n> clients.  So I think it is reasonable to call it a softfork with some\n> qualification.\n>\n>> Besides my initial question about the coinbase\n>> tx, I was also wondering how non-updated nodes would verify the\n>> collected fees without the actual txs at hand. (They only have the\n>> coinbase tx, don't they?)\n>\n>\n> Yes this appears to be an oversight in my proof-of-concept implementation.\n> The unintended consequence being that all transactions would have to be\n> zero-fee...\n>\n> The simplest fix would be make the new rules add the fees implicitly.  There\n> are other solutions.\n>\n>> Moreover, I can't see the benefits over a hard fork. A hard fork is\n>> much cleaner in regard to code changes. As one of the intends of\n>> \"generalized soft forks\" is to force user to update, at least a hard\n>> fork doesn't lie about the fact. Am I missing any obvious advantages\n>> of a \"generalized soft fork\" over a \"clean\" hard fork?\n>\n>\n> A \"firm soft fork\" also does not lie about that fact -- you must upgrade.  I\n> don't see it dishonest if it was never claimed otherwise.\n>\n> I agree that hardforks can be \"cleaner\".\n>\n> However the obvious disadvantage of a hardfork is the risk of the network\n> splitting between upgraded and non-upgraded clients.  This is not a problem\n> if there is 100% consensus behind the hardfork, but I am not sure if 100% is\n> realistically achievable for contentious issues such as the blocksize limit.\n>\n> If 100% consensus is never achieved, then the options are:\n> 1. Never upgrade and keep the blocksize limit unchanged forever.\n> 2. Use a firm softfork to resolve the deadlock.\n> 3. Hardfork anyway and split the network.\n>\n> My argument is simply that 2 is better than 3 and possibly 1.\n>\n> --joe\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "joe2015 at openmailbox.org",
                "date": "2016-01-05T01:26:59",
                "message_text_only": "On 2016-01-05 02:04, Nick ODell wrote:\n> How are you collecting fees from the transactions in the block?\n\nProbably the simplest way to do this is to map the new-rules coinbase tx \n(which collects the block reward and fees) into an old-rules legacy \ncoinbase tx (which collects the block reward only).  Care must be taken \nto ensure the mapping is not reversible.  I will update my \nimplementation in due course.\n\n--joe."
            },
            {
                "author": "joe2015 at openmailbox.org",
                "date": "2016-01-12T03:58:13",
                "message_text_only": "On 2016-01-05 09:26, joe2015--- via bitcoin-dev wrote:\n> On 2016-01-05 02:04, Nick ODell wrote:\n>> How are you collecting fees from the transactions in the block?\n> \n> Probably the simplest way to do this is to map the new-rules coinbase\n> tx (which collects the block reward and fees) into an old-rules legacy\n> coinbase tx (which collects the block reward only).  Care must be\n> taken to ensure the mapping is not reversible.  I will update my\n> implementation in due course.\n\nThe redesigned implementation is here:\n\nhttps://github.com/ZoomT/bitcoin/tree/2015_2mb_blocksize\nhttps://github.com/jgarzik/bitcoin/compare/2015_2mb_blocksize...ZoomT:2015_2mb_blocksize\n\nThe new version maps the Merkle root onto a 'legacy' coinbase \ntransaction, solving the problem with fees.\n\n--joe."
            }
        ],
        "thread_summary": {
            "title": "An implementation of BIP102 as a softfork.",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Nick ODell",
                "joe2015 at openmailbox.org"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 7571
        }
    },
    {
        "title": "[bitcoin-dev] [BIP Draft] Decentralized Improvement Proposals",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2016-01-03T23:31:26",
                "message_text_only": "Luke Dashjr via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> writes:\n> On Wednesday, December 30, 2015 6:22:59 PM Tomas wrote:\n>> > The specification itself looks like an inefficient and bloaty reinvention\n>> > of version bits.\n>> \n>> The actual assignment of version bits isn't clear from the\n>> specification. Are you saying that any implementation that wants to\n>> propose a change is encouraged to pick a free version bit and use it?\n>\n> That should probably be clarified in the BIP, I agree. Perhaps it ought to be \n> assigned the same as BIP numbers themselves, by the BIP editor? (Although as a \n> limited resource, maybe that's not the best solution.)\n\nI thought about it, but it's subject to change.  Frankly, the number of\ndeployed forks is low enough that they can sort it out themselves.  If\nwe need something more robust, I'm happy to fill that role.\n\nCheers,\nRusty."
            }
        ],
        "thread_summary": {
            "title": "Decentralized Improvement Proposals",
            "categories": [
                "bitcoin-dev",
                "BIP Draft"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 889
        }
    },
    {
        "title": "[bitcoin-dev] Increasing the blocksize as a (generalized) softfork.",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2016-01-04T21:53:36",
                "message_text_only": "On Sunday, December 20, 2015 10:56:33 AM joe2015--- via bitcoin-dev wrote:\n> \"generalized\" softfork.\n\nFWIW, this is something I've been planning to proposed (in a nicer form) for a \nwhile, tentatively called a \"soft hardfork\" (or less-seriously a \"softserve \nhardfork\"). The big piece missing that I've been holding off on publishing it \nas a BIP until complete, is a planned-out defensive reaction for a community \nwhich wishes to reject the hardfork. I guess I should probably prioritise this \na bit more now...\n\nLuke"
            }
        ],
        "thread_summary": {
            "title": "Increasing the blocksize as a (generalized) softfork.",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Luke Dashjr"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 519
        }
    },
    {
        "title": "[bitcoin-dev] Segregated Witness BIPs",
        "thread_messages": [
            {
                "author": "jl2012",
                "date": "2016-01-05T05:43:41",
                "message_text_only": "A new BIP, as part of the SW softfork, is pending BIP number assignment:\n\nhttps://github.com/bitcoin/bips/pull/270\n\nThis proposal defines a new transaction digest algorithm for signature \nverification in version 0 and version 1 witness program, in order to \nminimize redundant data hashing in verification (solving the O(n^2) \nissue), and to cover the input value by the signature (a frequently \nrequested feature for cold wallet).\n\njl2012 via bitcoin-dev \u65bc 2015-12-24 09:22 \u5beb\u5230:\n> The SW payment address format BIP draft is ready and is pending BIP\n> number assignment:\n> https://github.com/bitcoin/bips/pull/267\n> \n> This is the 3rd BIP for segwit. The 2nd one for Peer Services is being\n> prepared by Eric Lombrozo\n> \n> Eric Lombrozo via bitcoin-dev \u65bc 2015-12-23 10:22 \u5beb\u5230:\n>> I've been working with jl2012 on some SEGWIT BIPs based on earlier\n>> discussions Pieter Wuille's implementation. We're considering\n>> submitting three separate BIPs:\n>> \n>> CONSENSUS BIP: witness structures and how they're committed to blocks,\n>> cost metrics and limits, the scripting system (witness programs), and\n>> the soft fork mechanism.\n>> \n>> PEER SERVICES BIP: relay message structures, witnesstx serialization,\n>> and other issues pertaining to the p2p protocol such as IBD,\n>> synchronization, tx and block propagation, etc...\n>> \n>> APPLICATIONS BIP: scriptPubKey encoding formats and other wallet\n>> interoperability concerns.\n>> \n>> The Consensus BIP is submitted as a draft and is pending BIP number\n>> assignment: https://github.com/bitcoin/bips/pull/265 [1]\n>> The other two BIPS will be drafted soon.\n>> \n>> ---\n>> Eric\n>> \n>> Links:\n>> ------\n>> [1] https://github.com/bitcoin/bips/pull/265\n>> \n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            }
        ],
        "thread_summary": {
            "title": "Segregated Witness BIPs",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "jl2012"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2070
        }
    },
    {
        "title": "[bitcoin-dev] Confidential Transactions as a soft fork (using segwit)",
        "thread_messages": [
            {
                "author": "Felix Weis",
                "date": "2016-01-06T15:18:56",
                "message_text_only": "Since the release of sidechains alpha, confidential transactions[1] by Greg\nMaxwell have show how they could greatly improve transaction privacy and\nfungibility of bitcoin. Unfortunately without a hardfork or pegged\nsidechain it was not easy to enable them in bitcoin.\n\nThe segregated witness[2] proposal by Pieter Wuille allows to reduce the\nblockchain to a mere utxo changeset while putting all cryptographic proofs\n(redeemscript/pubkeys/signatures) for the inputs into a witness part.\nSegwit also allows upgradable scripting language. All can be done with a\nsoft fork.\n\nWe propose an upgrade to segwit to allow transactions to have both\nwitnessIns and witnessOuts.\n\nWe also propose 3 new transactions types: blinding, unblinding and\nconfidential. Valid blocks containing any of these new transactions MUST\nalso include a mandatory special output in their coinbase transaction and a\nnew special confidential base transaction.\n\nThe basic idea for confidential transaction is to use 0 value inputs and\noutputs while having the encrypted amounts (petersen-commitment +\nrange-proof) in the witnessOut part. These transactions are valid under old\nrules (but currently non-standard). For blinding, unblinding and miner fees\nwe use a single anyone-can-spend output (GCTXO) which will be updated in\nevery block containing confidential transactions.\n\nBlinding transaction:\n  Ins:\n    All non-confidential inputs are valid\n  Outs:\n  - 0..N: (new confidential outputs)\n    amount: 0\n    scriptPubkey: OP_2 <0x{32-byte-hash-value}>\n    witnessOut: <0x{petersen-commitment}> <0x{range-proof}>\n  - last:\n    amount: 0\n    scriptPubkey: OP_RETURN OP_2 {blinding-fee-amount}\n  Fee: Sum of the all inputs value\nThe last output's script is also a marker of the transaction being a\nblinding tx. After the soft fork, a block is invalid if the miner claims\nthe fees for himself instead of putting it into a special coinbase output.\n\n\nCoinbase transaction:\nIf the block contains blinding transactions, it MUST send the sum of all\ntheir fees to a new output: GCTXO[coinbase]\nThe scriptPubkey does not really matter since it will be only spendable\nunder strict rules in the same block's confidential base transaction. Maybe\nOP_TRUE.\n\n\nUnblinding transaction:\n  Ins:\n    prev: CTXO[n]\n    scriptSig: (empty)\n    witnessIn: <signature> <0x{redeemscript}>\n  Outs:\n  - 0..N:\n    amount: 0\n  scriptPubkey: OP_RETURN OP_2 {amount-to-be-unblinded} {p2sh-destination}\n    witnessOut: (empty)\n  - last:\n    amount: 0\n    scriptPubkey: OP_RETURN OP_2 {unblinding-fee-amount}\n  Fee: 0\n\nThis transaction remove removes the confidential outputs from the utxo set.\nThis outpoint itself is not spendable (it's OP_RETURN), but the same block\nwill contain a confidential base transaction created by the miner that will\nsatisfy the amount and p2sh-destination (refunded using GCTXO).\nConfidential transaction:\n  Ins:\n  - 0..N:\n    prev: CTXO[n]\n    scriptSig: (empty)\n    witnessIn: <signature> <0x{redeemscript}>\n  Outs:\n  - 0..N:\n    amount: 0\n    scriptPubkey: OP_2 <0x{32-byte-hash-value}>\n    witnessOut: <0x{petersen-commitment}> <0x{range-proof}>\n  - last:\n    amount: 0\n    scriptPubkey: OP_RETURN OP_2 {confidential-fee-amount}\n  Fee: 0\n\nAll inputs and outputs and have amount 0 and are everyone can spend V2\nsegwit, thus valid under old rules. Transaction valid under new rules\nobviously only if petersen commitment and range-proof in witnessOut valid.\nMinerfee for this transaction is expressed as one extra output:\n\n\nConfidential base transaction:\n  Ins:\n    GCTXO[last_block],\n    GCTXO[coinbase]\n  Outs:\n    0: GCTXO[current_block]\n    amount: {last_block + coinbase - unblindings}\n    scriptPubkey: OP_TRUE\n    1..N:\n    amount/scriptPubkey: as requested by unblinding transactions in this\nblock\n  Fee:\n    Sum of all the explicit OP_RETURN OP_2 {...} expressed fees from\n    confidential transactions in this block\n\nThis special transaction in last position in every block that contains at\nleast one of the new transaction types. Created by the miner of the block\nand used to do the actual unblinding and redeeming transaction fees for all\nconfidential transactions.\n\nThere will always be only 1 GCTXO in the utxo set. This allows for full\naccountability for 21 million bitcoin. Should a vulnerability in CT be\ndiscovered all unconfidential bitcoins remain safe. Under these new rules,\na block is only valid if all amounts/commitments/range-proofs match. A a\nminer trying use GCTXO other than allowed in the single confidential base\ntransaction\nwill be orphaned.\n\n[1] https://people.xiph.org/~greg/confidential_values.txt\n[2]\nhttps://github.com/CodeShark/bips/blob/segwit/bip-codeshark-jl2012-segwit.mediawiki\n\n\nSorry for the form, this is just a quick draft of a thought I had today.\nPlease comment.\n\nFelix Weis\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160106/94ee558a/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Confidential Transactions as a soft fork (using segwit)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Felix Weis"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4971
        }
    },
    {
        "title": "[bitcoin-dev] SegWit testnet is live",
        "thread_messages": [
            {
                "author": "Eric Lombrozo",
                "date": "2016-01-07T13:28:18",
                "message_text_only": "I am pleased to report that as of December 31, 2015 we have been successfully running a segregated witness testnet, called segnet, and have already implemented rudimentary wallets with support.\n\nFor source code, please look at sipa's github repo:\nhttps://github.com/sipa/bitcoin/tree/segwit\n\nAnd some example signing code at my repo:\nhttps://github.com/CodeShark/BitcoinScriptExperiments/blob/master/src/signwitnesstx.cpp\n\nSeveral wallets have already committed to supporting it including mSIGNA, GreenAddress, GreenBits, Blocktrail, and NBitcoin. More wallets are expected to be added to this list soon. If you're a wallet dev and are interested in developing and testing on segnet please contact me.\n\nWe're right on schedule and are very excited about the fundamental improvements to bitcoin that segwit will enable.\n\n---\nEric\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160107/b6f64fe3/attachment.html>"
            },
            {
                "author": "Eric Lombrozo",
                "date": "2016-01-07T13:56:57",
                "message_text_only": "I have been informed that Breadwallet has also committed to supporting segwit.\n\nThe list now includes Blocktrail, Breadwallet, GreenAddress, GreenBits, mSIGNA, and NBitcoin.\n\n---\nEric\n\nOn January 7, 2016 5:28:18 AM PST, Eric Lombrozo <elombrozo at gmail.com> wrote:\n>I am pleased to report that as of December 31, 2015 we have been\n>successfully running a segregated witness testnet, called segnet, and\n>have already implemented rudimentary wallets with support.\n>\n>For source code, please look at sipa's github repo:\n>https://github.com/sipa/bitcoin/tree/segwit\n>\n>And some example signing code at my repo:\n>https://github.com/CodeShark/BitcoinScriptExperiments/blob/master/src/signwitnesstx.cpp\n>\n>Several wallets have already committed to supporting it including\n>mSIGNA, GreenAddress, GreenBits, Blocktrail, and NBitcoin. More wallets\n>are expected to be added to this list soon. If you're a wallet dev and\n>are interested in developing and testing on segnet please contact me.\n>\n>We're right on schedule and are very excited about the fundamental\n>improvements to bitcoin that segwit will enable.\n>\n>---\n>Eric\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160107/300c0445/attachment.html>"
            },
            {
                "author": "Matthieu Riou",
                "date": "2016-01-08T02:17:03",
                "message_text_only": "Not strictly speaking a wallet but we (BlockCypher) will also go down the\nsegwit path as soon as the BIP and branch are mature enough.  All\ntransactions built from our APIs should eventually be segwitted (just made\nup a verb).\n\nThanks,\nMatthieu\n*CTO and Founder, Blockcypher*\nI have been informed that Breadwallet has also committed to supporting\nsegwit.\n\nThe list now includes Blocktrail, Breadwallet, GreenAddress, GreenBits,\nmSIGNA, and NBitcoin.\n\n---\nEric\n\nOn January 7, 2016 5:28:18 AM PST, Eric Lombrozo <elombrozo at gmail.com>\nwrote:\n>\n> I am pleased to report that as of December 31, 2015 we have been\n> successfully running a segregated witness testnet, called segnet, and have\n> already implemented rudimentary wallets with support.\n>\n> For source code, please look at sipa's github repo:\n> https://github.com/sipa/bitcoin/tree/segwit\n>\n> And some example signing code at my repo:\n>\n> https://github.com/CodeShark/BitcoinScriptExperiments/blob/master/src/signwitnesstx.cpp\n>\n> Several wallets have already committed to supporting it including mSIGNA,\n> GreenAddress, GreenBits, Blocktrail, and NBitcoin. More wallets are\n> expected to be added to this list soon. If you're a wallet dev and are\n> interested in developing and testing on segnet please contact me.\n>\n> We're right on schedule and are very excited about the fundamental\n> improvements to bitcoin that segwit will enable.\n>\n> ---\n> Eric\n>\n>\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160107/5c49eacf/attachment.html>"
            },
            {
                "author": "Jameson Lopp",
                "date": "2016-01-08T15:35:27",
                "message_text_only": "BitGo also intends to support SegWit transactions as soon as possible.\n\n- Jameson\n\nOn Thu, Jan 7, 2016 at 9:17 PM, Matthieu Riou via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Not strictly speaking a wallet but we (BlockCypher) will also go down the\n> segwit path as soon as the BIP and branch are mature enough.  All\n> transactions built from our APIs should eventually be segwitted (just made\n> up a verb).\n>\n> Thanks,\n> Matthieu\n> *CTO and Founder, Blockcypher*\n> I have been informed that Breadwallet has also committed to supporting\n> segwit.\n>\n> The list now includes Blocktrail, Breadwallet, GreenAddress, GreenBits,\n> mSIGNA, and NBitcoin.\n>\n> ---\n> Eric\n>\n> On January 7, 2016 5:28:18 AM PST, Eric Lombrozo <elombrozo at gmail.com>\n> wrote:\n>>\n>> I am pleased to report that as of December 31, 2015 we have been\n>> successfully running a segregated witness testnet, called segnet, and have\n>> already implemented rudimentary wallets with support.\n>>\n>> For source code, please look at sipa's github repo:\n>> https://github.com/sipa/bitcoin/tree/segwit\n>>\n>> And some example signing code at my repo:\n>>\n>> https://github.com/CodeShark/BitcoinScriptExperiments/blob/master/src/signwitnesstx.cpp\n>>\n>> Several wallets have already committed to supporting it including mSIGNA,\n>> GreenAddress, GreenBits, Blocktrail, and NBitcoin. More wallets are\n>> expected to be added to this list soon. If you're a wallet dev and are\n>> interested in developing and testing on segnet please contact me.\n>>\n>> We're right on schedule and are very excited about the fundamental\n>> improvements to bitcoin that segwit will enable.\n>>\n>> ---\n>> Eric\n>>\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160108/708ab045/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "SegWit testnet is live",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jameson Lopp",
                "Eric Lombrozo",
                "Matthieu Riou"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 6316
        }
    },
    {
        "title": "[bitcoin-dev] New BIP editor, and request for information",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2016-01-07T17:10:55",
                "message_text_only": "Greg has requested that I take over as the BIP editor responsible for \nassigning BIP numbers. Before I begin, I would like to ensure I have a correct \nrecord of what has already been assigned or soft-assigned so I don't overlap \nthem, as the BIPs repository appears that it may possibly be incomplete.\n\nIf you have been assigned (or soft-assigned) a BIP number - or any other \ninformation that may be relevant to my performing this role, please reply and \nlet me know, preferably within the next 24 hours if possible (as there are \nmany BIP drafts awaiting assignments).\n\nGetting into some specifics...\n\n- BIP 46 is missing from the repository, but apparently self-soft-assigned by \nTier Nolan in https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2014-April/005545.html ; if this was later assigned official, or if he is still \ninterested in pursuing this, it seems logical to just keep it at BIP 46.\n\n- BIPs 80 and 81 are currently part of an open pull request \nhttps://github.com/bitcoin/bips/pull/170, but it is unclear if they were \nformally assigned or not.\n\n- BIP 82 is currently officially assigned and pending in \nhttps://github.com/bitcoin/bips/pull/171 ; I personally think this is outside \nthe scope of BIPs since it does not deal with Bitcoin, and encourage Justus to \nmove it to the SLIP standard, but will honour this assignment unless he tells \nme he is moving it. (But understand this will not set a precedent for strictly \nnon-Bitcoin things being assigned BIPs...)\n\n- BIP 100 is missing from the repository, and I am uncertain if it was ever \nproperly assigned. Considering that the 10x block has mostly been used for \nsimilar proposals, and BIP 100 is fairly well-established as \"BIP 100\", it \nseems logical to just make this its official assignment.\n\n- BIP 104 is missing from the repository, but was apparently used unofficially \nby https://drive.google.com/file/d/0BwEbhrQ4ELzBX3hCekFRSUVySWs/view at one \ntime. But I do not see an actual specification in this PDF, so as far as I \nknow BIP 104 appears to be available?\n\n- BIP 109 was soft-assigned for \nhttps://gist.github.com/erasmospunk/23040383b7620b525df0, but as this doesn't \nfit with the rest of 10x, I am inclined to give it a new number outside that \nrange unless there are objections.\n\n- BIP 122 is missing from the repository, and was self-soft-assigned by Chris \nPriest for \"ScaleNet\" in https://github.com/bitcoin/bips/pull/222 ; there are \nconcerns whether testnets are appropriate for standardisation at all, but \nsince it has received sufficient discussion on the mailing list and others \nappear to agree with the effort, it seems reasonable to err in favour of \nassigning it a BIP number (not necessarily 122) if Chris wishes to further \npursue the idea and add an actual specification to the draft.\n\nTo be clear: except for BIPs 82 and 109, and those appearing in the \nhttps://github.com/bitcoin/bips repository at present, anyone (preferably the \nauthor, but not necessarily if they are away) aware of any other BIP \nassignments should reply to this message indicating the status of such BIPs \nand their assigned numbers.\n\nThanks,\n\nLuke"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-01-12T00:09:46",
                "message_text_only": "On Thu, Jan 7, 2016 at 5:10 PM, Luke Dashjr <luke at dashjr.org> wrote:\n\n> - BIP 46 is missing from the repository, but apparently self-soft-assigned\n> by\n> Tier Nolan in\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2014-April/005545.html\n> ; if this was later assigned official, or if he is still\n> interested in pursuing this, it seems logical to just keep it at BIP 46.\n>\n\nI was never officially assigned any number for this.\n\nSubsequent P2SH changes give the required functionality in an alternative\nway.  This renders the BIP obsolete.\n\nI suggest marking the number as nonassignable, in order to prevent\nconfusion with archive searches.  I assume that new BIP numbers will be\ngreater than 100 anyway.\n\nAs was pointed out at the time, I shouldn't have used a number in the\noriginal git branch before being assigned it officially.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160112/4632ff10/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "New BIP editor, and request for information",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Tier Nolan",
                "Luke Dashjr"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 4163
        }
    },
    {
        "title": "[bitcoin-dev] Time to worry about 80-bit collision attacks or not?",
        "thread_messages": [
            {
                "author": "Gavin Andresen",
                "date": "2016-01-07T19:02:05",
                "message_text_only": "I'm hoisting this from some private feedback I sent on the segregated\nwitness BIP:\n\nI said:\n\n\"I'd also use RIPEMD160(SHA256()) as the hash function and save the 12\nbytes-- a successful preimage attack against that ain't gonna happen before\nwe're all dead. I'm probably being dense, but I just don't see how a\ncollision attack is relevant here.\"\n\nPieter responded:\n\n\"The problem case is where someone in a contract setup shows you a script,\nwhich you accept as being a payment to yourself. An attacker could use a\ncollision attack to construct scripts with identical hashes, only one of\nwhich does have the property you want, and steal coins.\n\nSo you really want collision security, and I don't think 80 bits is\nsomething we should encourage for that. Normal pubkey hashes don't have\nthat problem, as they can't be constructed to pay to you.\"\n... but I'm unconvinced:\n\n\"But it is trivial for contract wallets to protect against collision\nattacks-- if you give me a script that is \"gavin_pubkey CHECKSIG\narbitrary_data OP_DROP\" with \"I promise I'm not trying to rip you off, just\nignore that arbitrary data\" a wallet can just refuse. Even more likely, a\ncontract wallet won't even recognize that as a pay-to-gavin transaction.\n\nI suppose it could be looking for some form of \"gavin_pubkey\nsomebody_else_pubkey CHECKMULTISIG ... with the attacker using\nsomebody_else_pubkey to force the collision, but, again, trivial contract\nprotocol tweaks (\"send along a proof you have the private key corresponding\nto the public key\" or \"everybody pre-commits pubkeys they'll use at\nprotocol start\") would protect against that.\n\nAdding an extra 12 bytes to every segwit to prevent an attack that takes\n2^80 computation and 2^80 storage, is unlikely to be a problem in practice,\nand is trivial to protect against is the wrong tradeoff to make.\"\n\n20 bytes instead of 32 bytes is a savings of almost 40%, which is\nsignificant.\n\nThe general question I'd like to raise on this list is:\n\nShould we be worried, today, about collision attacks against RIPEMD160 (our\n160-bit hash)?\n\nMounting a successful brute-force collision attack would require at least\nO(2^80) CPU, which is kinda-sorta feasible (Pieter pointed out that Bitcoin\nPOW has computed more SHA256 hashes than that). But it also requires\nO(2^80) storage, which is utterly infeasible (there is something on the\norder of 2^35 bytes of storage in the entire world).  Even assuming\ndoubling every single year (faster than Moore's Law), we're four decades\naway from an attacker with THE ENTIRE WORLD's storage capacity being able\nto mount a collision attack.\n\n\nReferences:\n\nhttps://en.wikipedia.org/wiki/Collision_attack\n\nhttps://vsatglobalseriesblog.wordpress.com/2013/06/21/in-2013-the-amount-of-data-generated-worldwide-will-reach-four-zettabytes/\n\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160107/09860830/attachment.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2016-01-07T19:13:22",
                "message_text_only": "We absolutely should be worried about 80-bit collision resistance.\nCollisions only take 2**80 work if the hash is theoretically perfect,\nwhich is never the case, not to mention that collision resistance is\nalmost always the first thing to go for hash functions, and often starts\nto get easier slowly long, long before anyone is truly worried about the\nsecurity of the hash function.\n\nI would never assume RIPEMD160's collision resistance is 2**80, and\nwould definitely never wager a significant amount of money that this\nremains true for, say, five years.\n\nMatt\n\nOn 01/07/16 19:02, Gavin Andresen via bitcoin-dev wrote:\n> I'm hoisting this from some private feedback I sent on the segregated\n> witness BIP:\n> \n> I said:\n> \n> \"I'd also use RIPEMD160(SHA256()) as the hash function and save the 12\n> bytes-- a successful preimage attack against that ain't gonna happen\n> before we're all dead. I'm probably being dense, but I just don't see\n> how a collision attack is relevant here.\"\n> \n> Pieter responded:\n> \n> \"The problem case is where someone in a contract setup shows you a\n> script, which you accept as being a payment to yourself. An attacker\n> could use a collision attack to construct scripts with identical hashes,\n> only one of which does have the property you want, and steal coins.\n> \n> So you really want collision security, and I don't think 80 bits is\n> something we should encourage for that. Normal pubkey hashes don't have\n> that problem, as they can't be constructed to pay to you.\"\n> \n> ... but I'm unconvinced:\n> \n> \"But it is trivial for contract wallets to protect against collision\n> attacks-- if you give me a script that is \"gavin_pubkey CHECKSIG\n> arbitrary_data OP_DROP\" with \"I promise I'm not trying to rip you off,\n> just ignore that arbitrary data\" a wallet can just refuse. Even more\n> likely, a contract wallet won't even recognize that as a pay-to-gavin\n> transaction.\n> \n> I suppose it could be looking for some form of \"gavin_pubkey\n> somebody_else_pubkey CHECKMULTISIG ... with the attacker using\n> somebody_else_pubkey to force the collision, but, again, trivial\n> contract protocol tweaks (\"send along a proof you have the private key\n> corresponding to the public key\" or \"everybody pre-commits pubkeys\n> they'll use at protocol start\") would protect against that.\n> \n> Adding an extra 12 bytes to every segwit to prevent an attack that takes\n> 2^80 computation and 2^80 storage, is unlikely to be a problem in\n> practice, and is trivial to protect against is the wrong tradeoff to make.\"\n> \n> 20 bytes instead of 32 bytes is a savings of almost 40%, which is\n> significant.\n> \n> The general question I'd like to raise on this list is:\n> \n> Should we be worried, today, about collision attacks against RIPEMD160\n> (our 160-bit hash)?\n> \n> Mounting a successful brute-force collision attack would require at\n> least O(2^80) CPU, which is kinda-sorta feasible (Pieter pointed out\n> that Bitcoin POW has computed more SHA256 hashes than that). But it also\n> requires O(2^80) storage, which is utterly infeasible (there is\n> something on the order of 2^35 bytes of storage in the entire world). \n> Even assuming doubling every single year (faster than Moore's Law),\n> we're four decades away from an attacker with THE ENTIRE WORLD's storage\n> capacity being able to mount a collision attack.\n> \n> \n> References: \n> \n> https://en.wikipedia.org/wiki/Collision_attack\n> \n> https://vsatglobalseriesblog.wordpress.com/2013/06/21/in-2013-the-amount-of-data-generated-worldwide-will-reach-four-zettabytes/\n> \n> \n> -- \n> --\n> Gavin Andresen\n> \n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Adam Back",
                "date": "2016-01-07T19:19:42",
                "message_text_only": "You could say 256 bit ECDSA is overkill lets go to 160 equivalently.\nSaves even more bytes.\n\nThe problem with arguing down is where to stop.\n\nAs Matt said these things dont degrade gracefully so a best practice\nis to aim for a bit of extra margin.\n\n256-bit is quite common at this point since AES, SHA256 etc even in\nthings with much less at stake than Bitcoin.\n\nYou could send the compressed (unhashed) pubkey then there's no hash\n(and omit it from the sig).  Greg had mentioned that in the past.\n\nI think it might be possible to do both (reclaim the hash bits in the\nserialisation of the pub key).\n\nAdam\n\nOn 7 January 2016 at 20:02, Gavin Andresen via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> I'm hoisting this from some private feedback I sent on the segregated\n> witness BIP:\n>\n> I said:\n>\n> \"I'd also use RIPEMD160(SHA256()) as the hash function and save the 12\n> bytes-- a successful preimage attack against that ain't gonna happen before\n> we're all dead. I'm probably being dense, but I just don't see how a\n> collision attack is relevant here.\"\n>\n> Pieter responded:\n>\n> \"The problem case is where someone in a contract setup shows you a script,\n> which you accept as being a payment to yourself. An attacker could use a\n> collision attack to construct scripts with identical hashes, only one of\n> which does have the property you want, and steal coins.\n>\n> So you really want collision security, and I don't think 80 bits is\n> something we should encourage for that. Normal pubkey hashes don't have that\n> problem, as they can't be constructed to pay to you.\"\n>\n> ... but I'm unconvinced:\n>\n> \"But it is trivial for contract wallets to protect against collision\n> attacks-- if you give me a script that is \"gavin_pubkey CHECKSIG\n> arbitrary_data OP_DROP\" with \"I promise I'm not trying to rip you off, just\n> ignore that arbitrary data\" a wallet can just refuse. Even more likely, a\n> contract wallet won't even recognize that as a pay-to-gavin transaction.\n>\n> I suppose it could be looking for some form of \"gavin_pubkey\n> somebody_else_pubkey CHECKMULTISIG ... with the attacker using\n> somebody_else_pubkey to force the collision, but, again, trivial contract\n> protocol tweaks (\"send along a proof you have the private key corresponding\n> to the public key\" or \"everybody pre-commits pubkeys they'll use at protocol\n> start\") would protect against that.\n>\n> Adding an extra 12 bytes to every segwit to prevent an attack that takes\n> 2^80 computation and 2^80 storage, is unlikely to be a problem in practice,\n> and is trivial to protect against is the wrong tradeoff to make.\"\n>\n> 20 bytes instead of 32 bytes is a savings of almost 40%, which is\n> significant.\n>\n> The general question I'd like to raise on this list is:\n>\n> Should we be worried, today, about collision attacks against RIPEMD160 (our\n> 160-bit hash)?\n>\n> Mounting a successful brute-force collision attack would require at least\n> O(2^80) CPU, which is kinda-sorta feasible (Pieter pointed out that Bitcoin\n> POW has computed more SHA256 hashes than that). But it also requires O(2^80)\n> storage, which is utterly infeasible (there is something on the order of\n> 2^35 bytes of storage in the entire world).  Even assuming doubling every\n> single year (faster than Moore's Law), we're four decades away from an\n> attacker with THE ENTIRE WORLD's storage capacity being able to mount a\n> collision attack.\n>\n>\n> References:\n>\n> https://en.wikipedia.org/wiki/Collision_attack\n>\n> https://vsatglobalseriesblog.wordpress.com/2013/06/21/in-2013-the-amount-of-data-generated-worldwide-will-reach-four-zettabytes/\n>\n>\n> --\n> --\n> Gavin Andresen\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Dave Scotese",
                "date": "2016-01-07T20:56:33",
                "message_text_only": "Maybe I'm being dense, but I don't see why 2**80 storage is required for\nthis attack.  Also, I don't see why the attacker ever needs to get the\nvictim to accept \"arbitrary_data\".  Perhaps I'm wrong about how the\ncollision attack works:\n\n   1. Create a script which is perfectly acceptable and would pass the\n   sniff test Gavin proposed (no arbitrary_data).\n   2. Set off CPU power to construct a second script that lets attacker\n   keep his coins and has the same hash. (This is where you get\n   \"arbitrary_data\").\n   3. Send a transaction with the first script to the seller as payment.\n   4. Wait for the transaction to be included in a block.\n   5. Redeem the transaction with the second script, thus stealing the\n   coins back.\n\nSo the seller would never see the I'd appreciate any correction to my\nunderstanding here.  Where do you need 2**80 storage?  And when does the\nseller have to accept \"arbitrary_data\"?\nThanks!\n\nOn Thu, Jan 7, 2016 at 11:19 AM, Adam Back via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> You could say 256 bit ECDSA is overkill lets go to 160 equivalently.\n> Saves even more bytes.\n>\n> The problem with arguing down is where to stop.\n>\n> As Matt said these things dont degrade gracefully so a best practice\n> is to aim for a bit of extra margin.\n>\n> 256-bit is quite common at this point since AES, SHA256 etc even in\n> things with much less at stake than Bitcoin.\n>\n> You could send the compressed (unhashed) pubkey then there's no hash\n> (and omit it from the sig).  Greg had mentioned that in the past.\n>\n> I think it might be possible to do both (reclaim the hash bits in the\n> serialisation of the pub key).\n>\n> Adam\n>\n> On 7 January 2016 at 20:02, Gavin Andresen via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > I'm hoisting this from some private feedback I sent on the segregated\n> > witness BIP:\n> >\n> > I said:\n> >\n> > \"I'd also use RIPEMD160(SHA256()) as the hash function and save the 12\n> > bytes-- a successful preimage attack against that ain't gonna happen\n> before\n> > we're all dead. I'm probably being dense, but I just don't see how a\n> > collision attack is relevant here.\"\n> >\n> > Pieter responded:\n> >\n> > \"The problem case is where someone in a contract setup shows you a\n> script,\n> > which you accept as being a payment to yourself. An attacker could use a\n> > collision attack to construct scripts with identical hashes, only one of\n> > which does have the property you want, and steal coins.\n> >\n> > So you really want collision security, and I don't think 80 bits is\n> > something we should encourage for that. Normal pubkey hashes don't have\n> that\n> > problem, as they can't be constructed to pay to you.\"\n> >\n> > ... but I'm unconvinced:\n> >\n> > \"But it is trivial for contract wallets to protect against collision\n> > attacks-- if you give me a script that is \"gavin_pubkey CHECKSIG\n> > arbitrary_data OP_DROP\" with \"I promise I'm not trying to rip you off,\n> just\n> > ignore that arbitrary data\" a wallet can just refuse. Even more likely, a\n> > contract wallet won't even recognize that as a pay-to-gavin transaction.\n> >\n> > I suppose it could be looking for some form of \"gavin_pubkey\n> > somebody_else_pubkey CHECKMULTISIG ... with the attacker using\n> > somebody_else_pubkey to force the collision, but, again, trivial contract\n> > protocol tweaks (\"send along a proof you have the private key\n> corresponding\n> > to the public key\" or \"everybody pre-commits pubkeys they'll use at\n> protocol\n> > start\") would protect against that.\n> >\n> > Adding an extra 12 bytes to every segwit to prevent an attack that takes\n> > 2^80 computation and 2^80 storage, is unlikely to be a problem in\n> practice,\n> > and is trivial to protect against is the wrong tradeoff to make.\"\n> >\n> > 20 bytes instead of 32 bytes is a savings of almost 40%, which is\n> > significant.\n> >\n> > The general question I'd like to raise on this list is:\n> >\n> > Should we be worried, today, about collision attacks against RIPEMD160\n> (our\n> > 160-bit hash)?\n> >\n> > Mounting a successful brute-force collision attack would require at least\n> > O(2^80) CPU, which is kinda-sorta feasible (Pieter pointed out that\n> Bitcoin\n> > POW has computed more SHA256 hashes than that). But it also requires\n> O(2^80)\n> > storage, which is utterly infeasible (there is something on the order of\n> > 2^35 bytes of storage in the entire world).  Even assuming doubling every\n> > single year (faster than Moore's Law), we're four decades away from an\n> > attacker with THE ENTIRE WORLD's storage capacity being able to mount a\n> > collision attack.\n> >\n> >\n> > References:\n> >\n> > https://en.wikipedia.org/wiki/Collision_attack\n> >\n> >\n> https://vsatglobalseriesblog.wordpress.com/2013/06/21/in-2013-the-amount-of-data-generated-worldwide-will-reach-four-zettabytes/\n> >\n> >\n> > --\n> > --\n> > Gavin Andresen\n> >\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n\n-- \nI like to provide some work at no charge to prove my value. Do you need a\ntechie?\nI own Litmocracy <http://www.litmocracy.com> and Meme Racing\n<http://www.memeracing.net> (in alpha).\nI'm the webmaster for The Voluntaryist <http://www.voluntaryist.com> which\nnow accepts Bitcoin.\nI also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n\"He ought to find it more profitable to play by the rules\" - Satoshi\nNakamoto\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160107/b5c2e636/attachment.html>"
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-01-07T21:06:30",
                "message_text_only": "Maybe I'm asking this question on the wrong mailing list:\n\nMatt/Adam: do you have some reason to think that RIPEMD160 will be broken\nbefore SHA256?\nAnd do you have some reason to think that they will be so broken that the\nnested hash construction RIPEMD160(SHA256()) will be vulnerable?\n\nAdam: re: \"where to stop\"  :  I'm suggesting we stop exactly at the current\nstatus quo, where we use RIPEMD160 for P2SH and P2PKH.\n\nEthan:  your algorithm will find two arbitrary values that collide. That\nisn't useful as an attack in the context we're talking about here (both of\nthose values will be useless as coin destinations with overwhelming\nprobability).\n\nDave: you described a first preimage attack, which is 2**160 cpu time and\nno storage.\n\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160107/a777b3e1/attachment.html>"
            },
            {
                "author": "Ethan Heilman",
                "date": "2016-01-07T22:56:38",
                "message_text_only": ">Ethan:  your algorithm will find two arbitrary values that collide. That isn't useful as an attack in the context we're talking about here (both of those values will be useless as coin destinations with overwhelming probability).\n\nI'm not sure exactly the properties you want here and determining\nthese properties is not an easy task, but the case is far worse than\njust two random values. For instance: (a). with a small modification\nmy algorithm can also find collisions containing targeted substrings,\n(b). length extension attacks are possible with RIPEMD160.\n\n(a). targeted cycles:\n\ntarget1 = \"str to prepend\"\ntarget2 = \"str to end with\"\n\nseed = {0,1}^160\nx = hash(seed)\n\nfor i in 2^80:\n....x = hash(target1||x||target2)\nx_final = x\n\ny = hash(tartget1||x_final||target2)\n\nfor j in 2^80:\n....if y == x_final:\n........print \"cycle len: \"+j\n........break\n....y = hash(target1||y||target2)\n\nIf a collision is found, the two colliding inputs must both start with\n\"str to prepend\" and end with the phrase \"str to end with\". As before\nthis only requires 2^81.5 computations and no real memory. For an\nadditional 2**80 an adversary has an good change of finding two\ndifferent targeted substrings which collide. Consider the case where\nthe attacker mixes the targeted strings with the hash output:\n\nhash(\"my name is=0x329482039483204324423\"+x[1]+\", my favorite number\nis=\"+x) where x[1] is the first bit of x.\n\n(b). length extension attacks\n\nEven if all the adversary can do is create two random values that\ncollide, you can append substrings to the input and get collisions.\nOnce you find two random values hash(x) = hash(y), you could use a\nlength extension attack on RIPEMD-160 to find hash(x||z) = hash(y||z).\n\nNow the bitcoin wiki says:\n\"The padding scheme is identical to MD4 using Merkle\u2013Damg\u00e5rd\nstrengthening to prevent length extension attacks.\"[1]\n\nWhich is confusing to me because:\n\n1. MD4 is vulnerable to length extension attacks\n2. Merkle\u2013Damg\u00e5rd strengthening does not protect against length\nextension: \"Indeed, we already pointed out that none of the 64\nvariants above can withstand the 'extension' attack on the MAC\napplication, even with the Merkle-Damgard strengthening\" [2]\n3. RIPEMD-160 is vulnerable to length extension attacks, is Bitcoin\nusing a non-standard version of RIPEMD-160.\n\nRIPEMD160(SHA256()) does not protect against length extension attacks\non SHA256, but should protect RIPEMD-160 against length extension\nattacks as RIPEMD-160 uses 512-bit message blocks. That being said we\nshould be very careful here. Research has been done that shows that\ncascading the same hash function twice is weaker than using HMAC[3]. I\ncan't find results on cascading RIPEMD160(SHA256()).\n\nRIPEMD160(SHA256()) seems better than RIPEMD160() though, but security\nshould not rest on the notion that an attacker requires 2**80 memory,\nmany targeted collision attacks can work without much memory.\n\n[1]: https://en.bitcoin.it/wiki/RIPEMD-160\n[2]: \"Merkle-Damgard Revisited: How to Construct a Hash Function\"\nhttps://www.cs.nyu.edu/~puniya/papers/merkle.pdf\n[3]: https://www.cs.nyu.edu/~dodis/ps/h-of-h.pdf\n\nOn Thu, Jan 7, 2016 at 4:06 PM, Gavin Andresen via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Maybe I'm asking this question on the wrong mailing list:\n>\n> Matt/Adam: do you have some reason to think that RIPEMD160 will be broken\n> before SHA256?\n> And do you have some reason to think that they will be so broken that the\n> nested hash construction RIPEMD160(SHA256()) will be vulnerable?\n>\n> Adam: re: \"where to stop\"  :  I'm suggesting we stop exactly at the current\n> status quo, where we use RIPEMD160 for P2SH and P2PKH.\n>\n> Ethan:  your algorithm will find two arbitrary values that collide. That\n> isn't useful as an attack in the context we're talking about here (both of\n> those values will be useless as coin destinations with overwhelming\n> probability).\n>\n> Dave: you described a first preimage attack, which is 2**160 cpu time and no\n> storage.\n>\n>\n> --\n> --\n> Gavin Andresen\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-01-07T23:39:58",
                "message_text_only": "Thanks, Ethan, that's helpful and I'll stop thinking that collision attacks\nrequire 2^(n/2) memory...\n\nSo can we quantify the incremental increase in security of SHA256(SHA256)\nover RIPEMD160(SHA256) versus the incremental increase in security of\nhaving a simpler implementation of segwitness?\n\nI'm going to claim that the difference in the first case is very, very,\nvery small-- the risk of an implementation error caused by having multiple\nways of interpreting the segwitness hash in the scriptPubKey is much, much\ngreater.\n\nAnd even if there IS some risk of collision attack now or at some point in\nthe future, I claim that it is easy for wallets to mitigate that risk. In\nfact, the principle of security in depth means wallets that don't\ncompletely control the scriptPubKeys they're creating on behalf of users\nSHOULD be coded to mitigate that risk (e.g. not allowing arbitrary data\naround a user's public key in a Script so targeted substring attacks are\neliminated entirely).\n\nPurely from a security point of view, I think a single 20-byte segwitness\nin the scriptPubKey is the best design.\n\"Keep the design as simple and small as possible\"\nhttps://www.securecoding.cert.org/confluence/plugins/servlet/mobile#content/view/2426\n\nAdd in the implied capacity increase of smaller scriptPubKeys and I still\nthink it is a no-brainer.\n\n\nOn Thu, Jan 7, 2016 at 5:56 PM, Ethan Heilman <eth3rs at gmail.com> wrote:\n\n> >Ethan:  your algorithm will find two arbitrary values that collide. That\n> isn't useful as an attack in the context we're talking about here (both of\n> those values will be useless as coin destinations with overwhelming\n> probability).\n>\n> I'm not sure exactly the properties you want here and determining\n> these properties is not an easy task, but the case is far worse than\n> just two random values. For instance: (a). with a small modification\n> my algorithm can also find collisions containing targeted substrings,\n> (b). length extension attacks are possible with RIPEMD160.\n>\n> (a). targeted cycles:\n>\n> target1 = \"str to prepend\"\n> target2 = \"str to end with\"\n>\n> seed = {0,1}^160\n> x = hash(seed)\n>\n> for i in 2^80:\n> ....x = hash(target1||x||target2)\n> x_final = x\n>\n> y = hash(tartget1||x_final||target2)\n>\n> for j in 2^80:\n> ....if y == x_final:\n> ........print \"cycle len: \"+j\n> ........break\n> ....y = hash(target1||y||target2)\n>\n> If a collision is found, the two colliding inputs must both start with\n> \"str to prepend\" and end with the phrase \"str to end with\". As before\n> this only requires 2^81.5 computations and no real memory. For an\n> additional 2**80 an adversary has an good change of finding two\n> different targeted substrings which collide. Consider the case where\n> the attacker mixes the targeted strings with the hash output:\n>\n> hash(\"my name is=0x329482039483204324423\"+x[1]+\", my favorite number\n> is=\"+x) where x[1] is the first bit of x.\n>\n> (b). length extension attacks\n>\n> Even if all the adversary can do is create two random values that\n> collide, you can append substrings to the input and get collisions.\n> Once you find two random values hash(x) = hash(y), you could use a\n> length extension attack on RIPEMD-160 to find hash(x||z) = hash(y||z).\n>\n> Now the bitcoin wiki says:\n> \"The padding scheme is identical to MD4 using Merkle\u2013Damg\u00e5rd\n> strengthening to prevent length extension attacks.\"[1]\n>\n> Which is confusing to me because:\n>\n> 1. MD4 is vulnerable to length extension attacks\n> 2. Merkle\u2013Damg\u00e5rd strengthening does not protect against length\n> extension: \"Indeed, we already pointed out that none of the 64\n> variants above can withstand the 'extension' attack on the MAC\n> application, even with the Merkle-Damgard strengthening\" [2]\n> 3. RIPEMD-160 is vulnerable to length extension attacks, is Bitcoin\n> using a non-standard version of RIPEMD-160.\n>\n> RIPEMD160(SHA256()) does not protect against length extension attacks\n> on SHA256, but should protect RIPEMD-160 against length extension\n> attacks as RIPEMD-160 uses 512-bit message blocks. That being said we\n> should be very careful here. Research has been done that shows that\n> cascading the same hash function twice is weaker than using HMAC[3]. I\n> can't find results on cascading RIPEMD160(SHA256()).\n>\n> RIPEMD160(SHA256()) seems better than RIPEMD160() though, but security\n> should not rest on the notion that an attacker requires 2**80 memory,\n> many targeted collision attacks can work without much memory.\n>\n> [1]: https://en.bitcoin.it/wiki/RIPEMD-160\n> [2]: \"Merkle-Damgard Revisited: How to Construct a Hash Function\"\n> https://www.cs.nyu.edu/~puniya/papers/merkle.pdf\n> [3]: https://www.cs.nyu.edu/~dodis/ps/h-of-h.pdf\n>\n> On Thu, Jan 7, 2016 at 4:06 PM, Gavin Andresen via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > Maybe I'm asking this question on the wrong mailing list:\n> >\n> > Matt/Adam: do you have some reason to think that RIPEMD160 will be broken\n> > before SHA256?\n> > And do you have some reason to think that they will be so broken that the\n> > nested hash construction RIPEMD160(SHA256()) will be vulnerable?\n> >\n> > Adam: re: \"where to stop\"  :  I'm suggesting we stop exactly at the\n> current\n> > status quo, where we use RIPEMD160 for P2SH and P2PKH.\n> >\n> > Ethan:  your algorithm will find two arbitrary values that collide. That\n> > isn't useful as an attack in the context we're talking about here (both\n> of\n> > those values will be useless as coin destinations with overwhelming\n> > probability).\n> >\n> > Dave: you described a first preimage attack, which is 2**160 cpu time\n> and no\n> > storage.\n> >\n> >\n> > --\n> > --\n> > Gavin Andresen\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n>\n\n\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160107/39e4d3d6/attachment-0001.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2016-01-08T01:26:22",
                "message_text_only": "So just because other attacks are possible we should weaken the crypto\nwe use? You may feel comfortable weakening crypto used to protect a few\nbillion dollars of other peoples' money, but I dont.\n\nOn 01/07/16 23:39, Gavin Andresen via bitcoin-dev wrote:\n> Thanks, Ethan, that's helpful and I'll stop thinking that collision\n> attacks require 2^(n/2) memory...\n> \n> So can we quantify the incremental increase in security of\n> SHA256(SHA256) over RIPEMD160(SHA256) versus the incremental increase in\n> security of having a simpler implementation of segwitness?\n> \n> I'm going to claim that the difference in the first case is very, very,\n> very small-- the risk of an implementation error caused by having\n> multiple ways of interpreting the segwitness hash in the scriptPubKey is\n> much, much greater.\n> \n> And even if there IS some risk of collision attack now or at some point\n> in the future, I claim that it is easy for wallets to mitigate that\n> risk. In fact, the principle of security in depth means wallets that\n> don't completely control the scriptPubKeys they're creating on behalf of\n> users SHOULD be coded to mitigate that risk (e.g. not allowing arbitrary\n> data around a user's public key in a Script so targeted substring\n> attacks are eliminated entirely).\n> \n> Purely from a security point of view, I think a single 20-byte\n> segwitness in the scriptPubKey is the best design.\n> \"Keep the design as simple and small as possible\"\n> https://www.securecoding.cert.org/confluence/plugins/servlet/mobile#content/view/2426\n> \n> Add in the implied capacity increase of smaller scriptPubKeys and I\n> still think it is a no-brainer.\n> \n> \n> On Thu, Jan 7, 2016 at 5:56 PM, Ethan Heilman <eth3rs at gmail.com\n> <mailto:eth3rs at gmail.com>> wrote:\n> \n>     >Ethan:  your algorithm will find two arbitrary values that collide. That isn't useful as an attack in the context we're talking about here (both of those values will be useless as coin destinations with overwhelming probability).\n> \n>     I'm not sure exactly the properties you want here and determining\n>     these properties is not an easy task, but the case is far worse than\n>     just two random values. For instance: (a). with a small modification\n>     my algorithm can also find collisions containing targeted substrings,\n>     (b). length extension attacks are possible with RIPEMD160.\n> \n>     (a). targeted cycles:\n> \n>     target1 = \"str to prepend\"\n>     target2 = \"str to end with\"\n> \n>     seed = {0,1}^160\n>     x = hash(seed)\n> \n>     for i in 2^80:\n>     ....x = hash(target1||x||target2)\n>     x_final = x\n> \n>     y = hash(tartget1||x_final||target2)\n> \n>     for j in 2^80:\n>     ....if y == x_final:\n>     ........print \"cycle len: \"+j\n>     ........break\n>     ....y = hash(target1||y||target2)\n> \n>     If a collision is found, the two colliding inputs must both start with\n>     \"str to prepend\" and end with the phrase \"str to end with\". As before\n>     this only requires 2^81.5 computations and no real memory. For an\n>     additional 2**80 an adversary has an good change of finding two\n>     different targeted substrings which collide. Consider the case where\n>     the attacker mixes the targeted strings with the hash output:\n> \n>     hash(\"my name is=0x329482039483204324423\"+x[1]+\", my favorite number\n>     is=\"+x) where x[1] is the first bit of x.\n> \n>     (b). length extension attacks\n> \n>     Even if all the adversary can do is create two random values that\n>     collide, you can append substrings to the input and get collisions.\n>     Once you find two random values hash(x) = hash(y), you could use a\n>     length extension attack on RIPEMD-160 to find hash(x||z) = hash(y||z).\n> \n>     Now the bitcoin wiki says:\n>     \"The padding scheme is identical to MD4 using Merkle\u2013Damg\u00e5rd\n>     strengthening to prevent length extension attacks.\"[1]\n> \n>     Which is confusing to me because:\n> \n>     1. MD4 is vulnerable to length extension attacks\n>     2. Merkle\u2013Damg\u00e5rd strengthening does not protect against length\n>     extension: \"Indeed, we already pointed out that none of the 64\n>     variants above can withstand the 'extension' attack on the MAC\n>     application, even with the Merkle-Damgard strengthening\" [2]\n>     3. RIPEMD-160 is vulnerable to length extension attacks, is Bitcoin\n>     using a non-standard version of RIPEMD-160.\n> \n>     RIPEMD160(SHA256()) does not protect against length extension attacks\n>     on SHA256, but should protect RIPEMD-160 against length extension\n>     attacks as RIPEMD-160 uses 512-bit message blocks. That being said we\n>     should be very careful here. Research has been done that shows that\n>     cascading the same hash function twice is weaker than using HMAC[3]. I\n>     can't find results on cascading RIPEMD160(SHA256()).\n> \n>     RIPEMD160(SHA256()) seems better than RIPEMD160() though, but security\n>     should not rest on the notion that an attacker requires 2**80 memory,\n>     many targeted collision attacks can work without much memory.\n> \n>     [1]: https://en.bitcoin.it/wiki/RIPEMD-160\n>     [2]: \"Merkle-Damgard Revisited: How to Construct a Hash Function\"\n>     https://www.cs.nyu.edu/~puniya/papers/merkle.pdf\n>     [3]: https://www.cs.nyu.edu/~dodis/ps/h-of-h.pdf\n> \n>     On Thu, Jan 7, 2016 at 4:06 PM, Gavin Andresen via bitcoin-dev\n>     <bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>     > Maybe I'm asking this question on the wrong mailing list:\n>     >\n>     > Matt/Adam: do you have some reason to think that RIPEMD160 will be\n>     broken\n>     > before SHA256?\n>     > And do you have some reason to think that they will be so broken\n>     that the\n>     > nested hash construction RIPEMD160(SHA256()) will be vulnerable?\n>     >\n>     > Adam: re: \"where to stop\"  :  I'm suggesting we stop exactly at\n>     the current\n>     > status quo, where we use RIPEMD160 for P2SH and P2PKH.\n>     >\n>     > Ethan:  your algorithm will find two arbitrary values that\n>     collide. That\n>     > isn't useful as an attack in the context we're talking about here\n>     (both of\n>     > those values will be useless as coin destinations with overwhelming\n>     > probability).\n>     >\n>     > Dave: you described a first preimage attack, which is 2**160 cpu\n>     time and no\n>     > storage.\n>     >\n>     >\n>     > --\n>     > --\n>     > Gavin Andresen\n>     >\n>     > _______________________________________________\n>     > bitcoin-dev mailing list\n>     > bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>     > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>     >\n> \n> \n> \n> \n> -- \n> --\n> Gavin Andresen\n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-01-08T01:54:00",
                "message_text_only": "On Thu, Jan 7, 2016 at 8:26 PM, Matt Corallo <lf-lists at mattcorallo.com>\nwrote:\n\n> So just because other attacks are possible we should weaken the crypto\n> we use? You may feel comfortable weakening crypto used to protect a few\n> billion dollars of other peoples' money, but I dont.\n>\n\nNo...\n\nI'm saying we can eliminate one somewhat unlikely attack (that there is a\nbug in the code or test cases, today or some future version, that has to\ndecide what to do with \"version 0\" versus \"version 1\" witness programs) by\naccepting the risk of another insanely, extremely unlikely attack.\n\nReference for those who are lost:\n\nhttps://github.com/CodeShark/bips/blob/segwit/bip-codeshark-jl2012-segwit.mediawiki#witness-program\n\nMy proposal would be to just do a version 0 witness program now, that is\nRIPEMD160(SHA256(script)).\n\nAnd ten or twenty years from now, if there is a plausible attack on\nRIPEMD160 and/or SHA256, revisit and do a version 11 (or whatever).\n\nIt will simplify the BIP, means half as many test cases have to be written,\nmeans a little more scalability, and is as secure as the P2SH and P2PKH\neverybody is using to secure their bitcoin today.\n\nTell you what:  I'll change my mind if anybody can describe a plausible\nattack if we were using MD5(SHA256), given what we know about how MD5 is\nbroken.\n\n\n---\n\nI'm really disappointed with the \"Here's the spec, take it or leave it\"\nattitude. What's the point of having a BIP process if the discussion just\ncomes down to \"We think more is better. We don't care what you think.\"\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160107/ba55bae0/attachment.html>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2016-01-08T17:38:34",
                "message_text_only": "On Fri, Jan 8, 2016 at 2:54 AM, Gavin Andresen via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n> I'm saying we can eliminate one somewhat unlikely attack (that there is a\n> bug in the code or test cases, today or some future version, that has to\n> decide what to do with \"version 0\" versus \"version 1\" witness programs) by\n> accepting the risk of another insanely, extremely unlikely attack.\n\nOk, just having one witness program version now is a somewhat different\nproposal. It would be simpler for sure. The reasoning was that you'd need\nthis to not add significant overhead to small scripts, but that may not be\nthe case anymore. I wouldn't mind seeing numbers.\n\n> My proposal would be to just do a version 0 witness program now, that is\n> RIPEMD160(SHA256(script)).\n\nI don't think that is wise. Bitcoin has a 128-bit security target for\neverything else. We did not know that P2SH and similar constructs were\nvulnerable to a collision attack at the time, but now we do, so the obvious\nchoice is to pick a size that is sufficiently large to maintain the 128-bit\nsecurity target. This is a no brainer to me; we're not proposing switching\nto a 160-bit EC curve either, right?\n\n> I'm really disappointed with the \"Here's the spec, take it or leave it\"\n> attitude. What's the point of having a BIP process if the discussion just\n> comes down to \"We think more is better. We don't care what you think.\"\n\nIt is a proposal and we are discussing it. You first brought up some\ncriticisms in private, and I agreed with several things you said.\n\nBut it remains the proposal of a few people including me, and I do not\nagree with the specific suggestion of reducing the security target for\nwitness scripts to 80 bits.\n\nWe are not deciding what the system will be. We're making a proposal, and\nhope that due to its technical merit, the ecosystem will adopt it. You're\nfree to participate in that discussion.\n\n-- \nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160108/2420393c/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-01-08T18:41:15",
                "message_text_only": "On Thu, Jan 07, 2016 at 08:54:00PM -0500, Gavin Andresen via bitcoin-dev wrote:\n> ---\n> \n> I'm really disappointed with the \"Here's the spec, take it or leave it\"\n> attitude. What's the point of having a BIP process if the discussion just\n> comes down to \"We think more is better. We don't care what you think.\"\n\nI'll point out that I personally raised an issue with segpregated\nwitnesses quite recently - my concern that it could make validationless\nmining easier and more profitable(1). Neither Pieter Wuille nor Gregory\nMaxwell believed my concern to be important at first in private\ncommunication. However, it was still discussed on IRC, with Pieter,\nGreg, and others contributing valuable input on the problem and my\nproposed fix. Right now I think the next step for me is to write the\ncode to implement my fix and submit a pull-req against the segwit\nbranch.\n\nI certainly wouldn't describe that experience as \"Here's the spec, take\nit or leave it; We don't what what you think.\"\n\n1) \"Segregated witnesses and validationless mining\",\n    Peter Todd, Dec 23 2015, Bitcoin-dev mailing list,\n    http://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-December/012103.html\n\n-- \n'peter'[:-1]@petertodd.org\n000000000000000004aea2cfdb89c4816b7a42208dca1f3cfd66a1c9b5df4506\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160108/d491f65e/attachment.sig>"
            },
            {
                "author": "Ethan Heilman",
                "date": "2016-01-07T20:40:03",
                "message_text_only": "Based on current GH/s count of 775,464,121 Bitcoin tests 2^80 every 19 days.\nlog2(775464121*(1000*1000*1000*60*60*24*19)) = ~80.07\n\nI don't fully understand the security model of segwit, so my analysis\nwill assume that any collision is bad.\n\n>But it also requires O(2^80) storage, which is utterly infeasible\n\nYou don't store all 2^80 previous hashes, instead you just hash a seed\nvalue 2^80 times, then look for a cycle.\n\nseed = {0,1}^160\nx = hash(seed)\n\nfor i in 2^80:\n....x = hash(x)\nx_final = x\n\ny = hash(x_final)\n\nfor j in 2^80:\n....if y == x_final:\n........print \"cycle len: \"+j\n........break\n....y = hash(y)\n\nIf at any point x collides with a prior value of x it will form a\ncycle. Thus y will also cycle and collide with x_final. j gives you\nthe cycle length, which allows you find the collision:\nhash^(2^80-j)(seed) == hash^(j)(hash^(2^80-j)(seed)).\n\nWorst case:\nFirst loop costs 2**80, second loop costs 2**80=j, finding the\ncolliding value is 2**80. Total cost 2**80+2**80+2**80 = 2**81.5 and\nrequires storing less than a kilobyte.\n\nThis is a toy example, does not exploit parallelism, time memory trade\noffs, can be easily made better, etc...\n\nOn Thu, Jan 7, 2016 at 2:02 PM, Gavin Andresen via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> I'm hoisting this from some private feedback I sent on the segregated\n> witness BIP:\n>\n> I said:\n>\n> \"I'd also use RIPEMD160(SHA256()) as the hash function and save the 12\n> bytes-- a successful preimage attack against that ain't gonna happen before\n> we're all dead. I'm probably being dense, but I just don't see how a\n> collision attack is relevant here.\"\n>\n> Pieter responded:\n>\n> \"The problem case is where someone in a contract setup shows you a script,\n> which you accept as being a payment to yourself. An attacker could use a\n> collision attack to construct scripts with identical hashes, only one of\n> which does have the property you want, and steal coins.\n>\n> So you really want collision security, and I don't think 80 bits is\n> something we should encourage for that. Normal pubkey hashes don't have that\n> problem, as they can't be constructed to pay to you.\"\n>\n> ... but I'm unconvinced:\n>\n> \"But it is trivial for contract wallets to protect against collision\n> attacks-- if you give me a script that is \"gavin_pubkey CHECKSIG\n> arbitrary_data OP_DROP\" with \"I promise I'm not trying to rip you off, just\n> ignore that arbitrary data\" a wallet can just refuse. Even more likely, a\n> contract wallet won't even recognize that as a pay-to-gavin transaction.\n>\n> I suppose it could be looking for some form of \"gavin_pubkey\n> somebody_else_pubkey CHECKMULTISIG ... with the attacker using\n> somebody_else_pubkey to force the collision, but, again, trivial contract\n> protocol tweaks (\"send along a proof you have the private key corresponding\n> to the public key\" or \"everybody pre-commits pubkeys they'll use at protocol\n> start\") would protect against that.\n>\n> Adding an extra 12 bytes to every segwit to prevent an attack that takes\n> 2^80 computation and 2^80 storage, is unlikely to be a problem in practice,\n> and is trivial to protect against is the wrong tradeoff to make.\"\n>\n> 20 bytes instead of 32 bytes is a savings of almost 40%, which is\n> significant.\n>\n> The general question I'd like to raise on this list is:\n>\n> Should we be worried, today, about collision attacks against RIPEMD160 (our\n> 160-bit hash)?\n>\n> Mounting a successful brute-force collision attack would require at least\n> O(2^80) CPU, which is kinda-sorta feasible (Pieter pointed out that Bitcoin\n> POW has computed more SHA256 hashes than that). But it also requires O(2^80)\n> storage, which is utterly infeasible (there is something on the order of\n> 2^35 bytes of storage in the entire world).  Even assuming doubling every\n> single year (faster than Moore's Law), we're four decades away from an\n> attacker with THE ENTIRE WORLD's storage capacity being able to mount a\n> collision attack.\n>\n>\n> References:\n>\n> https://en.wikipedia.org/wiki/Collision_attack\n>\n> https://vsatglobalseriesblog.wordpress.com/2013/06/21/in-2013-the-amount-of-data-generated-worldwide-will-reach-four-zettabytes/\n>\n>\n> --\n> --\n> Gavin Andresen\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2016-01-07T23:52:27",
                "message_text_only": "> \"The problem case is where someone in a contract setup shows you a\nscript, which you accept as being a payment to yourself. An attacker could\nuse a collision attack to construct scripts with identical hashes, only one\nof which does have the property you want, and steal coins.\n>\n> So you really want collision security, and I don't think 80 bits is\nsomething we should encourage for that. Normal pubkey hashes don't have\nthat problem, as they can't be constructed to pay to you.\"\n>\n> ... but I'm unconvinced:\n>\n> \"But it is trivial for contract wallets to protect against collision\nattacks-- if you give me a script that is \"gavin_pubkey CHECKSIG\narbitrary_data OP_DROP\" with \"I promise I'm not trying to rip you off, just\nignore that arbitrary data\" a wallet can just refuse. Even more likely, a\ncontract wallet won't even recognize that as a pay-to-gavin transaction.\n>\n> I suppose it could be looking for some form of \"gavin_pubkey\nsomebody_else_pubkey CHECKMULTISIG ... with the attacker using\nsomebody_else_pubkey to force the collision, but, again, trivial contract\nprotocol tweaks (\"send along a proof you have the private key corresponding\nto the public key\" or \"everybody pre-commits pubkeys they'll use at\nprotocol start\") would protect against that.\n\nYes, this is what I worry about. We're constructing a 2-of-2 multisig\nescrow in a contract. I reveal my public key A, you do a 80-bit search for\nB and C such that H(A and B) = H(B and C). You tell me your keys B, and I\nhappily send to H(A and B), which you steal with H(B and C).\n\nSending along a proof does not help, you can't prove that you do not know\nof a collision. Pre-committing does help, but is a very non-obvious\nsecurity requirement, something I strongly believe is far riskier in\npractice.\n\nBitcoin does have parts that rely on economic arguments for security or\nprivacy, but can we please stick to using cryptography that is up to par\nfor parts where we can? It's a small constant factor of data, and it\ncategorically removes the worry about security levels.\n\n-- \nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160108/e2e921fb/attachment.html>"
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-01-08T01:00:42",
                "message_text_only": "On Thu, Jan 7, 2016 at 6:52 PM, Pieter Wuille <pieter.wuille at gmail.com>\nwrote:\n\n> Bitcoin does have parts that rely on economic arguments for security or\n> privacy, but can we please stick to using cryptography that is up to par\n> for parts where we can? It's a small constant factor of data, and it\n> categorically removes the worry about security levels.\n>\nOur message may have crossed in the mod queue:\n\n\"So can we quantify the incremental increase in security of SHA256(SHA256)\nover RIPEMD160(SHA256) versus the incremental increase in security of\nhaving a simpler implementation of segwitness?\"\n\nI believe the history of computer security is that implementation errors\nand sidechannel attacks are much, much more common than brute-force breaks.\nKEEP IT SIMPLE.\n\n(and a quibble:  \"do a 80-bit search for B and C such that H(A and B) = H(B\nand C)\"  isn't enough, you have to end up with a C public key for which you\nknow the corresponding private key or the attacker just succeeds in burning\nthe funds)\n\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160107/f73f2f2c/attachment.html>"
            },
            {
                "author": "Watson Ladd",
                "date": "2016-01-08T01:27:02",
                "message_text_only": "On Jan 7, 2016 5:22 PM, \"Gavin Andresen via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> On Thu, Jan 7, 2016 at 6:52 PM, Pieter Wuille <pieter.wuille at gmail.com>\nwrote:\n>>\n>> Bitcoin does have parts that rely on economic arguments for security or\nprivacy, but can we please stick to using cryptography that is up to par\nfor parts where we can? It's a small constant factor of data, and it\ncategorically removes the worry about security levels.\n>\n> Our message may have crossed in the mod queue:\n>\n> \"So can we quantify the incremental increase in security of\nSHA256(SHA256) over RIPEMD160(SHA256) versus the incremental increase in\nsecurity of having a simpler implementation of segwitness?\"\n\nThere are several clever ways to exploit even chosen prefix collisions\nusing the scripting language. One could search for collisions where one\nmessage is some data and the other is a jump over a critical check.\n\n>\n> I believe the history of computer security is that implementation errors\nand sidechannel attacks are much, much more common than brute-force breaks.\nKEEP IT SIMPLE.\n\nAsk the Iranian nuclear program. Or those brainwallet users.\n>\n> (and a quibble:  \"do a 80-bit search for B and C such that H(A and B) =\nH(B and C)\"  isn't enough, you have to end up with a C public key for which\nyou know the corresponding private key or the attacker just succeeds in\nburning the funds)\n>\n>\n> --\n> --\n> Gavin Andresen\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160107/9bdcb94f/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2016-01-08T03:30:11",
                "message_text_only": "Pieter Wuille via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nwrites:\n> Yes, this is what I worry about. We're constructing a 2-of-2 multisig\n> escrow in a contract. I reveal my public key A, you do a 80-bit search for\n> B and C such that H(A and B) = H(B and C). You tell me your keys B, and I\n> happily send to H(A and B), which you steal with H(B and C).\n\nFWIW, this attack would effect the current lightning-network \"deployable\nlightning\" design at channel establishment; we reveal our pubkey in the\nopening packet (which is used to redeem a P2SH using normal 2of2).\n\nAt least you need to grind before replying (which will presumably time\nout), rather than being able to do it once the channel is open.\n\nWe could pre-commit by exchanging hashes of pubkeys first, but contracts\non bitcoin are hard enough to get right that I'm reluctant to add more\nhoops.\n\nCheers,\nRusty."
            },
            {
                "author": "Matt Corallo",
                "date": "2016-01-08T03:41:34",
                "message_text_only": "Indeed, anything which uses P2SH is obviously vulnerable if there is an attack on RIPEMD160 which reduces it's security only marginally. While no one thought hard about these attacks when P2SH was designed, we realized later this was not such a good idea to reuse the structure from P2PKH. Hence why this discussion came up.\n\nOn January 7, 2016 7:30:11 PM PST, Rusty Russell via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>Pieter Wuille via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n>writes:\n>> Yes, this is what I worry about. We're constructing a 2-of-2 multisig\n>> escrow in a contract. I reveal my public key A, you do a 80-bit\n>search for\n>> B and C such that H(A and B) = H(B and C). You tell me your keys B,\n>and I\n>> happily send to H(A and B), which you steal with H(B and C).\n>\n>FWIW, this attack would effect the current lightning-network\n>\"deployable\n>lightning\" design at channel establishment; we reveal our pubkey in the\n>opening packet (which is used to redeem a P2SH using normal 2of2).\n>\n>At least you need to grind before replying (which will presumably time\n>out), rather than being able to do it once the channel is open.\n>\n>We could pre-commit by exchanging hashes of pubkeys first, but\n>contracts\n>on bitcoin are hard enough to get right that I'm reluctant to add more\n>hoops.\n>\n>Cheers,\n>Rusty.\n>_______________________________________________\n>bitcoin-dev mailing list\n>bitcoin-dev at lists.linuxfoundation.org\n>https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Rusty Russell",
                "date": "2016-01-08T12:02:01",
                "message_text_only": "Matt Corallo <lf-lists at mattcorallo.com> writes:\n> Indeed, anything which uses P2SH is obviously vulnerable if there is\n> an attack on RIPEMD160 which reduces it's security only marginally.\n\nI don't think this is true?  Even if you can generate a collision in\nRIPEMD160, that doesn't help you since you need to create a specific\nSHA256 hash for the RIPEMD160 preimage.\n\nEven a preimage attack only helps if it leads to more than one preimage\nfairly cheaply; that would make grinding out the SHA256 preimage easier.\nAFAICT even MD4 isn't this broken.\n\nBut just with Moore's law (doubling every 18 months), we'll worry about\neconomically viable attacks in 20 years.[1]\n\nThat's far enough away that I would choose simplicity, and have all SW\nscriptPubKeys simply be \"<0> RIPEMD(SHA256(WP))\" for now, but it's\nnot a no-brainer.\n\nCheers,\nRusty.\n\n[1] Assume bitcoin-network-level compute (collision in 19 days) costs\n    $1B to build today.  Assume there will be 100 million dollars a day\n    in vulnerable txs, and you're on one end of all of them (or can MITM\n    if you find a collision), *and* can delay them all by 10 seconds,\n    and none are in parallel so you can attack all of them.  IOW, just\n    like a single $100M opportunity for 3650 seconds each year.\n\n    Our machine has a 0.11% chance of finding a collision in 1 hour, so\n    it's worth about $110,000.  We can build it for that in about 20\n    years."
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-01-08T12:38:50",
                "message_text_only": "On Fri, Jan 8, 2016 at 7:02 AM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n\n> Matt Corallo <lf-lists at mattcorallo.com> writes:\n> > Indeed, anything which uses P2SH is obviously vulnerable if there is\n> > an attack on RIPEMD160 which reduces it's security only marginally.\n>\n> I don't think this is true?  Even if you can generate a collision in\n> RIPEMD160, that doesn't help you since you need to create a specific\n> SHA256 hash for the RIPEMD160 preimage.\n>\n> Even a preimage attack only helps if it leads to more than one preimage\n> fairly cheaply; that would make grinding out the SHA256 preimage easier.\n> AFAICT even MD4 isn't this broken.\n>\n\nIt feels like we've gone over that before, but I can never remember where\nor when. I believe consensus was that if we were using the broken MD5 in\nall the places we use RIPEMD160 we'd still be secure today because of\nSatoshi's use of nested hash functions everywhere.\n\n\n> But just with Moore's law (doubling every 18 months), we'll worry about\n> economically viable attacks in 20 years.[1]\n\n\n> That's far enough away that I would choose simplicity, and have all SW\n> scriptPubKeys simply be \"<0> RIPEMD(SHA256(WP))\" for now, but it's\n> not a no-brainer.\n\n\nLets see if I've followed the specifics of the collision attack correctly,\nEthan (or somebody) please let me know if I'm missing something:\n\nSo attacker is in the middle of establishing a payment channel with\nsomebody. Victim gives their public key, attacker creates the innocent\nfund-locking script  '2 V A 2 CHECKMULTISIG' (V is victim's public key, A\nis attacker's) but doesn't give it to the victim yet.\n\nInstead they then generate about 2^81scripts that are some form of\npay-to-attacker ....\n... wait, no that doesn't work, because SHA256 is used as the inner hash\nfunction.  They'd have to generate 2^129 to find a cycle in SHA256.\n\nInstead, they .. what? I don't see a viable attack unless RIPEMD160 and\nSHA256 (or the combination) suffers a cryptographic break.\n\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160108/aec650d3/attachment.html>"
            },
            {
                "author": "Watson Ladd",
                "date": "2016-01-08T14:34:09",
                "message_text_only": "On Fri, Jan 8, 2016 at 4:38 AM, Gavin Andresen via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> On Fri, Jan 8, 2016 at 7:02 AM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n>>\n>> Matt Corallo <lf-lists at mattcorallo.com> writes:\n>> > Indeed, anything which uses P2SH is obviously vulnerable if there is\n>> > an attack on RIPEMD160 which reduces it's security only marginally.\n>>\n>> I don't think this is true?  Even if you can generate a collision in\n>> RIPEMD160, that doesn't help you since you need to create a specific\n>> SHA256 hash for the RIPEMD160 preimage.\n>>\n>> Even a preimage attack only helps if it leads to more than one preimage\n>> fairly cheaply; that would make grinding out the SHA256 preimage easier.\n>> AFAICT even MD4 isn't this broken.\n>\n>\n> It feels like we've gone over that before, but I can never remember where or\n> when. I believe consensus was that if we were using the broken MD5 in all\n> the places we use RIPEMD160 we'd still be secure today because of Satoshi's\n> use of nested hash functions everywhere.\n>\n>>\n>> But just with Moore's law (doubling every 18 months), we'll worry about\n>> economically viable attacks in 20 years.[1]\n>>\n>>\n>> That's far enough away that I would choose simplicity, and have all SW\n>> scriptPubKeys simply be \"<0> RIPEMD(SHA256(WP))\" for now, but it's\n>> not a no-brainer.\n>\n>\n> Lets see if I've followed the specifics of the collision attack correctly,\n> Ethan (or somebody) please let me know if I'm missing something:\n>\n> So attacker is in the middle of establishing a payment channel with\n> somebody. Victim gives their public key, attacker creates the innocent\n> fund-locking script  '2 V A 2 CHECKMULTISIG' (V is victim's public key, A is\n> attacker's) but doesn't give it to the victim yet.\n>\n> Instead they then generate about 2^81scripts that are some form of\n> pay-to-attacker ....\n> ... wait, no that doesn't work, because SHA256 is used as the inner hash\n> function.  They'd have to generate 2^129 to find a cycle in SHA256.\n\nFor 2^80 they simply generate 2^80 scripts that look innocent, and\n2^80 that are not. With high probability there is a collision. I agree\nthat most cryptanalysis won't work because of the nesting, but 2^80 is\nnot good.\n>\n> Instead, they .. what? I don't see a viable attack unless RIPEMD160 and\n> SHA256 (or the combination) suffers a cryptographic break.\n>\n>\n> --\n> --\n> Gavin Andresen\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n\n-- \n\"Man is born free, but everywhere he is in chains\".\n--Rousseau."
            },
            {
                "author": "Adam Back",
                "date": "2016-01-08T15:26:50",
                "message_text_only": "Tricky choice. On the one hand I had spotted this too before and maybe\none or two more exceptions to bitcoin's 128-bit security target and\nbeen vaguely tut-tutting about them in the background.  It's kind of a\nviolation of crypto rule of thumb that you want to balance things and\nnot have odd weak points as Watson was implying, it puts you closer to\nthe margin if there is a slip or other problem so you have an\nimbalanced crypto format.\n\nOn the other hand it's not currently a problem as such and it's less\nchange and slightly more compact.\n\nRIPEMD probably is less well reviewed than SHA2.  However SHA1 has\nproblems, and SHA2 is a bigger SHA1 basically so, hence the NIST\nmotivation for SHA3 designed to fix the design flaw in SHA1 (and SHA2\nin principle).\n\nSo then if we agree with this rule of thumb (and not doing so would\nfly against best practices which we probably shouldnt look to do in\nsuch a security focussed domain) then what this discussion is more\nabout is when is a good time to write down tech debt.\n\nI think that comes to segregated-witness itself which writes down a\ntidily organised by lines of code robust fix to a bunch of long\nstanding problems.\n\nDoing a 2MB hard-fork in comparison fixes nothing really.  Leaving\nknown issues to bake in for another N years eventually builds up on\nyou (not even in security just in software engineering) as another\nrule of thumb.  I mean if we dont fix it now that we are making a\nchange that connects, when will we?\n\nIn software projects I ran we always disguised the cost of tech-debt\nas non-negotiable baked into our estimates without a line item to\nescape the PHB syndrome of haggling for features instead of tech debt\n(which is _never_ a good idea:)\n\nPragmatism vs refactoring as you go.\n\nBut for scale I think segregated-witness does offer the intriguing\nnext step of being able to do 2 of 2, 3 of 3 and N of N which give\nsize of one sig multisig (indistinguishable even for privacy) as well\nas K of N key tree sigs, which are also significantly more compact.\n\nThere was also the other thing I mentioned further up the thread that\nif we want to take an approach of living with little bit of bloat from\ngetting back to a universal 128-bit target, there are still some\nfixable bloat things going on:\na) sending pubKey in the signature vs recovery (modulo interference\nwith Schnorr batch verify compatibility*);\nb) using the PubKey instead of PKH in the ScriptPubKey, though that\nloses the nice property of of not having the key to do DL attacks on\nuntil the signed transaction is broadcast;\nc) I think there might be a way to combine hash & PubKey to keep the\ndelayed PubKey publication property and yet still save the bloat of\nhaving both.\n\n* I did suggest to Pieter that you could let the miner decide to forgo\nSchnorr batch verifiability to get compaction from recovery - the pub\nkey could be optionally elided from the scriptSig serialisation by the\nminer.\n\nThe other thing we could consider is variable sized hashes (& a few\npubkey size choices) that is software complexity however.  We might be\nbetter of focussing on the bigger picture like IBLT/weak-blocks and\nbigger wins like MAST, multiSig Schnorr & key tree sigs.\n\nDidnt get time to muse on c) but a nice crypto question for someone :)\n\nAnother thing to note is combining has been known to be fragile to bad\ninteractions or unexpected behaviours.  This paper talks about things\ntradeoffs and weaknesses in hash combiners.\nhttp://tuprints.ulb.tu-darmstadt.de/2094/1/thesis.lehmann.pdf\n\nWeak concept NACK I think for losing a cleanup opportunity to store it\nup for the future when there is a reasonable opportunity to fix it?\n\nAdam\n\n\nOn 8 January 2016 at 15:34, Watson Ladd via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> On Fri, Jan 8, 2016 at 4:38 AM, Gavin Andresen via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> On Fri, Jan 8, 2016 at 7:02 AM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n>>>\n>>> Matt Corallo <lf-lists at mattcorallo.com> writes:\n>>> > Indeed, anything which uses P2SH is obviously vulnerable if there is\n>>> > an attack on RIPEMD160 which reduces it's security only marginally.\n>>>\n>>> I don't think this is true?  Even if you can generate a collision in\n>>> RIPEMD160, that doesn't help you since you need to create a specific\n>>> SHA256 hash for the RIPEMD160 preimage.\n>>>\n>>> Even a preimage attack only helps if it leads to more than one preimage\n>>> fairly cheaply; that would make grinding out the SHA256 preimage easier.\n>>> AFAICT even MD4 isn't this broken.\n>>\n>>\n>> It feels like we've gone over that before, but I can never remember where or\n>> when. I believe consensus was that if we were using the broken MD5 in all\n>> the places we use RIPEMD160 we'd still be secure today because of Satoshi's\n>> use of nested hash functions everywhere.\n>>\n>>>\n>>> But just with Moore's law (doubling every 18 months), we'll worry about\n>>> economically viable attacks in 20 years.[1]\n>>>\n>>>\n>>> That's far enough away that I would choose simplicity, and have all SW\n>>> scriptPubKeys simply be \"<0> RIPEMD(SHA256(WP))\" for now, but it's\n>>> not a no-brainer.\n>>\n>>\n>> Lets see if I've followed the specifics of the collision attack correctly,\n>> Ethan (or somebody) please let me know if I'm missing something:\n>>\n>> So attacker is in the middle of establishing a payment channel with\n>> somebody. Victim gives their public key, attacker creates the innocent\n>> fund-locking script  '2 V A 2 CHECKMULTISIG' (V is victim's public key, A is\n>> attacker's) but doesn't give it to the victim yet.\n>>\n>> Instead they then generate about 2^81scripts that are some form of\n>> pay-to-attacker ....\n>> ... wait, no that doesn't work, because SHA256 is used as the inner hash\n>> function.  They'd have to generate 2^129 to find a cycle in SHA256.\n>\n> For 2^80 they simply generate 2^80 scripts that look innocent, and\n> 2^80 that are not. With high probability there is a collision. I agree\n> that most cryptanalysis won't work because of the nesting, but 2^80 is\n> not good.\n>>\n>> Instead, they .. what? I don't see a viable attack unless RIPEMD160 and\n>> SHA256 (or the combination) suffers a cryptographic break.\n>>\n>>\n>> --\n>> --\n>> Gavin Andresen\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n>\n>\n> --\n> \"Man is born free, but everywhere he is in chains\".\n> --Rousseau.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Anthony Towns",
                "date": "2016-01-08T15:33:29",
                "message_text_only": "On Fri, Jan 08, 2016 at 07:38:50AM -0500, Gavin Andresen via bitcoin-dev wrote:\n> Lets see if I've followed the specifics of the collision attack correctly,\n> Ethan (or somebody) please let me know if I'm missing something:\n> \n> So attacker is in the middle of establishing a payment channel with\n> somebody. Victim gives their public key, attacker creates the innocent\n> fund-locking script  '2 V A 2 CHECKMULTISIG' (V is victim's public key, A\n> is attacker's) but doesn't give it to the victim yet.\n\nUsing Ethan Heilman's procedure, the attacker can create two scripts:\n\n  2 V __A1__ 2 CHECKMULTISIG\n\n  2 V __A2__ 2 CHECKMULTISIG\n\nand find values A1 and A2 which hash the scripts to the same result\nwith under 3*2**80 work. I think you can do that by setting the next\nprivate key as the result of RIPEMD(SHA256(script with pubkey)), so you\ncould still spend either. But it doesn't change the script, so it's not\n*that* helpful -- you've just got two different keys you can use.\n\nAh, but you can make the form of the script be a function of your key, so:\n\n  if privkey % 2 == 0:\n    script = \"2 V %s 2 CHECKMULTISIG\" % (pubkey)\n  else:\n    script = \"%s CHECKSIG\" % (pubkey)\n  hash = ripemd160(sha256(script))\n\n  nextprivkey = hash\n\nThen you have a 50% chance of your cycle giving you a matching hash for\none script with A1 and the other script with A2, and you can find the\ncycle with under 3*2**80 work. Doing five attempts should give you ~96%\nchance of hitting a usable pair, and should take under 15*2**80 work ~=\n2**84 work, with trivial memory use.\n\nTrying that in python with a vastly weakened hash function (namely,\nthe first five bytes of ripemd160(sha256()), with 40 bits of security\nand 3*2**20 work) works as expected -- I got a \"useful\" collision on my\nsecond try in about 7 seconds, seeding with \"grumpycat3\" (\"grumpycat2\"\ndidn't work) with the result being:\n\n hexlify(ripemd160(sha256(\"foo%sbar\"%unhexlify(\"86f9fbac1a\")))[:5])\n 'ae94d9f908'\n\n hexlify(ripemd160(sha256(\"baz%squux\"%unhexlify(\"104fc5093f\")))[:5])\n 'ae94d9f908'\n\nCheers,\naj"
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-01-08T15:46:53",
                "message_text_only": "Thanks, Anthony, that works!\n\nSo...\n\nHow many years until we think a 2^84 attack where the work is an ECDSA\nprivate->public key derivation will take a reasonable amount of time?\n\nAnd Ethan or Anthony:  can you think of a similar attack scheme if you\nassume we had switched to Schnorr 2-of-2 signatures by then?\n\n\nAnd to everybody who might not be reading this closely:  All of the above\nis discussing collision attacks; none of it is relevant in the normal case\nwhere your wallet generates the scriptPubKey.\n\n\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160108/8f69988f/attachment.html>"
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-01-08T15:50:06",
                "message_text_only": "And to fend off the messag that I bet somebody is composing right now:\n\nYes, I know about a \"security first\" mindset.  But as I said earlier in the\nthread, there is a tradeoff here between crypto strength and code\ncomplexity, and \"the strength of the crypto is all that matters\" is NOT\nsecurity first.\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160108/b0d965ec/attachment.html>"
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-01-08T15:59:21",
                "message_text_only": "On Fri, Jan 8, 2016 at 10:50 AM, Gavin Andresen <gavinandresen at gmail.com>\nwrote:\n\n> But as I said earlier in the thread, there is a tradeoff here between\n> crypto strength and code complexity, and \"the strength of the crypto is all\n> that matters\" is NOT security first.\n\n\nI should be more explicit about code complexity:\n\nThe big picture is \"segwitness will help scale in the very short term.\"\n\nSo the spec gives two ways of stuffing the segwitness hash into the\nscriptPubKey -- one way that uses a 32-bit hash, but if used would actually\nmake scalability a bit worse as coins moved into segwitness-locked\ntransactions (DUP HASH160 EQUALVERIFY pay-to-script-hash scriptpubkeys are\njust 24 bytes).\n\nAnd another way that add just one byte to the scriptpubkey.\n\nTHAT is the code complexity I'm talking about.  Better to always move the\nscript into the witness data, in my opinion, on the keep the design as\nsimple as possible principle.\n\nIt could be a 32-byte hash... but then the short-term scalability goal is\ncompromised.\n\nMaybe I'm being dense, but I still think it is a no-brainer....\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160108/49bd0b02/attachment.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2016-01-11T20:32:15",
                "message_text_only": "On Fri, Jan 8, 2016 at 4:50 PM, Gavin Andresen via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> And to fend off the messag that I bet somebody is composing right now:\n>\n> Yes, I know about a \"security first\" mindset.  But as I said earlier in the\n> thread, there is a tradeoff here between crypto strength and code\n> complexity, and \"the strength of the crypto is all that matters\" is NOT\n> security first.\n\nIf the crypto code is properly encapsulated, the code complexity costs\nof choosing one hashing function over another should be non-existent.\nYou made the space argument which is valid, but in my opinion code\ncomplexity shouldn't be a valid concern in this discussion.\n\nAs a maybe uninteresting anecdote, I proposed the asset IDs in\nhttps://github.com/ElementsProject/elements/tree/alpha-0.10-multi-asset\nto do the same ```ripemd160 . sha256``` choice that Mark Friedenbach\nhad proposed and I had approved for\nhttps://github.com/jtimon/freimarkets/blob/master/doc/freimarkets_specs.org#asset-tags\n. More humble than me, he admitted he had made a design mistake much\nearlier than me, who (maybe paradoxically) probably had less knowledge\nfor making crypto choices at the low level. In the end I was convinced\nwith examples I failed to write down for documentation and can't\nremember.\n\nThat's not to say I have anything to say in this debate other than\ncode complexity (which I do feel qualified to talk about) shouldn't be\na concern in this debate. Just want to focus the discussion on what it\nshould be: security vs space tradeoff.\nSince I am admittedly in doubt, I tend to prefer to play safe, but\nneither my feelings nor my anecdote are logical arguments and should,\ntherefore, be ignored for any conclusions in the ```ripemd160 .\nsha256``` vs sha256d debate. Just like you non-sequitor \"sha256d will\nlead to more code complexity\", if anything, sha256d should be simpler\nthan ```ripemd160 . sha256``` (but not simpler enough that it matters\nmuch)."
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-01-08T16:06:34",
                "message_text_only": "On Fri, Jan 8, 2016 at 10:46 AM, Gavin Andresen <gavinandresen at gmail.com>\nwrote:\n\n> And Ethan or Anthony:  can you think of a similar attack scheme if you\n> assume we had switched to Schnorr 2-of-2 signatures by then?\n\n\nDon't answer that, I was being dense again, Anthony's scheme works with\nSchnorr...\n\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160108/f1c01274/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2016-01-11T03:57:15",
                "message_text_only": "Gavin Andresen via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> writes:\n> How many years until we think a 2^84 attack where the work is an ECDSA\n> private->public key derivation will take a reasonable amount of time?\n\nvanitygen can generate keypairs pretty fast (on my CPU it's comparable\nwith hashing time), and there are ways to make it faster.  Since you can\ngenerate multiple script variations, too, I think hashing is the\nbottleneck.\n\nAntminer S7 can do 4.73 Terahash per second for $1.2k.  (Double SHA, but\nlet's assume RIPEMD160(SHA256()) is the same speed).\n\n766,760,562,123 seconds to do 3*2^80, so you'd need over 200 million\nS7s to do it in an hour.[1] If you want to do that for $1M, wait 27\nyears and hope Moore's Law holds?\n\nAlso, a colleague points out you could use this attack against a site\nlike bitrated.com which publishes one side's pubkey, giving you a much\nlonger attack window.\n     \nCheers,\nRusty.\n[1] Weirdly, the bitcoin network is doing this much work every 57\n    days, for about $92M.  If that's all the attack costs, it's under\n    1M in 10 years."
            },
            {
                "author": "Peter Todd",
                "date": "2016-01-11T06:57:42",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\n\n\nOn 10 January 2016 22:57:15 GMT-05:00, Rusty\n>Cheers,\n>Rusty.\n>[1] Weirdly, the bitcoin network is doing this much work every 57\n>    days, for about $92M.  If that's all the attack costs, it's under\n>    1M in 10 years.\n\nDon't get too caught up in Moore's law here - more likely the attack will become feasible because SHA2 is partially weakened, as happened with SHA1. Having industry standard safety margins would make such a weakening be an academic problem rather than an emergency.\n-----BEGIN PGP SIGNATURE-----\n\niQE9BAEBCgAnIBxQZXRlciBUb2RkIDxwZXRlQHBldGVydG9kZC5vcmc+BQJWk1Jc\nAAoJEMCF8hzn9Lncz4MH/RYReh4+oPkt8D4uW2FhiB/BlzY5Q1FP94nyi/jQAAh9\ner3cUA47RhSLLd2ukC2XDgbw8CZzhnzECs7vBVsXacc3dGpzV59n8L/pnX47IRJh\ni1BPWHzEl/UeE/uBYUVgmy+kCVkJ80gnL2GGgZ3IXL5P+CHYY9dvhBrr53Q3HSpi\naEXVivBvBnX0GeATMVY5TAiailUfsUbUmPdEHu0x5hqqTh0sUpi+R+wXWJfPESB2\nhzMVZd8ALz1SJhDqbkmBNHy2CX0fhGlnMSapm6EkQksfshkcwJ7tj8s2CEOYD68T\n4mR7Xh+FsOA2bbZP8M/lMd3rrXbwFzXi0rWPa70mxqI=\n=2W58\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-01-11T23:57:59",
                "message_text_only": "On Fri, Jan 8, 2016 at 3:46 PM, Gavin Andresen via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> How many years until we think a 2^84 attack where the work is an ECDSA\n> private->public key derivation will take a reasonable amount of time?\n>\n\nI think the EC multiply is not actually required.  With compressed public\nkeys, the script selection rule can just be a sha256 call instead.\n\nV is the public key of the victim, and const_pub_key is the attacker's\npublic key.\n\n     if prev_hash % 2 == 0:\n        script = \"2 V 0x02%s 2 CHECKMULTISIG\" % (sha256(prev_hash)))\n    else:\n        script = \"CHECKSIG %s OP_DROP\" % (prev_hash, const_pub_key)\n\n    next_hash = ripemd160(sha256(script))\n\nIf a collision is found, there is a 50% chance that the two scripts have\ndifferent parity and there is a 50% chance that a compressed key is a valid\nkey.\n\nThis means that you need to run the algorithm 4 times instead of 2.\n\nThe advantage is that each step is 2 sha256 calls and a ripemd160 call.  No\nEC multiply is required.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160111/be7bd486/attachment.html>"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-01-12T00:00:08",
                "message_text_only": "On Mon, Jan 11, 2016 at 11:57 PM, Tier Nolan <tier.nolan at gmail.com> wrote:\n>\n>     else:\n>         script = \"CHECKSIG %s OP_DROP\" % (prev_hash, const_pub_key)\n>\n\nThat should be\n\nscript = \"%s CHECKSIG %s OP_DROP\" % (const_pub_key, prev_hash)\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160112/f404e9db/attachment.html>"
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-01-12T12:08:18",
                "message_text_only": "I'm convinced-- it is a good idea to worry about 80-bit collision attacks\nnow.\n\nThanks to all the people smarter than me who contributed to this\ndiscussion, I learned a lot about collision attacks that I didn't know\nbefore.\n\nWould this be a reasonable \"executive summary\" :\n\nIf you are agreeing to lock up funds with somebody else, and they control\nwhat public key to use, you are susceptible to collision attacks.\n\nIt is very likely an 80-bit-collision-in-ten-minutes attack will cost less\nthan $1million in 10 to twenty years (possibly sooner if there are crypto\nbreaks in that time).\n\nIf you don't trust the person with whom you're locking up funds and you're\nlocking up a significant amount of money (tens of millions of dollars\ntoday, tens of thousands of dollars in a few years):\n\nThen you should avoid using pay-to-script-hash addresses and instead use\nthe payment protocol and \"raw\" multisig outputs.\n\nAND/OR\n\nHave them give you a hierarchical deterministic (BIP32) seed, and derive a\npublic key for them to use.\n\n\n----------\n\nFollowing the security in depth and validate all input secure coding\nprinciples would mean doing both-- avoid p2sh AND have all parties to a\ntransaction exchange HD seeds, add randomness, and use the resulting public\nkeys in the transaction.\n\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160112/866bc47e/attachment.html>"
            },
            {
                "author": "Zooko Wilcox-O'Hearn",
                "date": "2016-01-12T23:22:17",
                "message_text_only": "Folks:\n\nI don't fully understand this thread, but it sounds like to me it\nmight be omitting consideration of multi-target attacks. For example,\nTier Nolan's attack\n(http://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-January/012230.html),\nwhich seems to be the best attack on this thread, seems to start with\none specific public key of an intended victim, but if the attacker is\nhappy to find a collision with *any* one out of a large number of\npotential victims, he gets an advantage proportional to the number of\npotential victims.\n\nSo it would be wise, in addition to the kind of analysis already done\non this thread (which appears to have already settled at \"Yes, we need\n> 80-bit security.\"), to make a nice optimistic estimate of how many\npublic keys we could eventually have in use. 2\u2074\u2070? 2\u2075\u2070? Or maybe be\n*very* optimistic, with some added IoT [*] goodness, and budget for\n2\u2076\u2070?\n\nThen we need to budget that many more bits of security to keep the\nfuture attacker's chances of success low enough that the attacker will\nnever succeed. (Assuming that's our requirement.)\n\nYou might enjoy this recent blog post by DJB, legendary cryptographer\nwho works in this niche of cryptography as well as several other\nniches:\n\nhttp://blog.cr.yp.to/20151120-batchattacks.html\n\nIt has some interesting philosophical musings about the \"Attacker\nEconomist\" approach. (N.B. My respect for DJB's accomplishments is\ntremendous, but that doesn't mean I automatically agree with\neverything he says. I haven't made up my mind what I think about this\nparticular philosophical argument.)\n\nSincerely,\n\nZooko\n\n[*] The Internet of Targets"
            },
            {
                "author": "Peter Todd",
                "date": "2016-01-08T18:52:54",
                "message_text_only": "On Fri, Jan 08, 2016 at 02:00:11PM +1030, Rusty Russell via bitcoin-dev wrote:\n> Pieter Wuille via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n> writes:\n> > Yes, this is what I worry about. We're constructing a 2-of-2 multisig\n> > escrow in a contract. I reveal my public key A, you do a 80-bit search for\n> > B and C such that H(A and B) = H(B and C). You tell me your keys B, and I\n> > happily send to H(A and B), which you steal with H(B and C).\n> \n> FWIW, this attack would effect the current lightning-network \"deployable\n> lightning\" design at channel establishment; we reveal our pubkey in the\n> opening packet (which is used to redeem a P2SH using normal 2of2).\n> \n> At least you need to grind before replying (which will presumably time\n> out), rather than being able to do it once the channel is open.\n> \n> We could pre-commit by exchanging hashes of pubkeys first, but contracts\n> on bitcoin are hard enough to get right that I'm reluctant to add more\n> hoops.\n\nNote how this is a good example where trying to avoid the relatively\nsmall amount of complexity of having two different segregated witness\nschemes to allow for 128bit security could lead to a significant amount\nof upper level complexity trying to regain security. I wouldn't be\nsurprised at all if this upper level complexity leads to exploits; at\nthe very least it'll lead to a lot of wasted mental effort from\ncryptographers concerned about the potential weakness, both within and\nexternal to the Bitcoin development community.\n\n-- \n'peter'[:-1]@petertodd.org\n000000000000000004aea2cfdb89c4816b7a42208dca1f3cfd66a1c9b5df4506\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160108/070f712d/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Time to worry about 80-bit collision attacks or not?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Adam Back",
                "Anthony Towns",
                "Peter Todd",
                "Dave Scotese",
                "Tier Nolan",
                "Zooko Wilcox-O'Hearn",
                "Jorge Tim\u00f3n",
                "Ethan Heilman",
                "Matt Corallo",
                "Gavin Andresen",
                "Pieter Wuille",
                "Watson Ladd"
            ],
            "messages_count": 34,
            "total_messages_chars_count": 80827
        }
    },
    {
        "title": "[bitcoin-dev] Libconsensus phase 2",
        "thread_messages": [
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2016-01-12T17:53:24",
                "message_text_only": "After talking to some people about libconsensus in the last Hong Kong\nconference I realized that my initial plan of exposing one more thing\nat a time would actually probably slow things down.\n\nThere's still a promised pdf with pictures that will be released, and\nactually drafting the UML pictures helped realize that the whole\nexplanation could be much simpler if #7091 was merged first as the\nlast step in phase 1 (that phase has so many contributors that I will\nprobably never get finished documenting it). Matt Corallo's idea of\nexposing VerifyScript() through a C API certainly helped a lot in\ncementing the more-minimal-than-earlier dependencies (thanks to Cory\nFields among many other people before him) that are not part of the\nincomplete but existing libbitcoinconsensus library.\n\nGiven this success in protecting encapsulation by exposing things in a\nnew library, my instinct was to expose more things: VerifyHeader(),\nVerifyTx() and VerifyBlock() [in that order].\nBut all those three new functions depend on storage in one way or\nanother. That was part of my reasoning to expose VerifyHeader() first,\nbecause I believe there will be less discussion on a common interface\nfor the stored longest chain than for the utxo view (which may depend\non other transactions spent within the same block).\nIn any case, I realized we should finish putting all the consensus\ncritical code in the libconsensus lib and then worry about its \"final\"\nAPI.\n\nTherefore I changed the goal of the phase 2 in my libconsensus\nencapsulation planning from \"expose VerifyHeader() in the existing\nlibconsensus library\" to \"build all the consensus critical code within\nthe existing libconsensus library, even if we don't expose anything\nelse\". I believe this is much feasible for a single Bitcoin Core\nrelease cycle and also more of a priority. Other implementations\nexperimenting with libconsensus like\nhttps://github.com/libbitcoin/libbitcoin-consensus will have the\nchance to compare their reimplementations with the future complete\nlibbitcoinconsensus without having to worry about the C API, which\nideally they will help to define.\n\nI repeat, the goal of phase 2 in my upcoming libconsensus\nencapsulation plan is to fully decouple libconsensus from Bitcoin\nCore.\nIn phase 3, we can refine the storage interfaces and focus on a\nquasi-final C API.\nIn phase 4, we can refine and take out code that doesn't belong in\nlibconsensus like CTxOut::GetDustThreshold() in\nprimitives/transaction.h and move all those consensus files to the\nconsensus folder before creating a separate sub-repository like for\nlibsecp256k1. Note that most of the file-moving work can be in\nparallel to phases 2 and 3 and, in fact, by any new developer that is\nwilling to exchange rebase-patience for meaningless github stats (I'll\ndo it if nobody else wants, but I'm more than happy to delegate there:\nI have more than enough github meaningless stats already).\n\nAs said, the document with pictures and the update to #6714 are still\npromised, but until they're ready, merging/reviewing #7091, #7287,\n#7310 and #7311 could do a great deal to make later steps in\nlibconsensus phase 2 more readable.\nMost reviewers probably don't need to see any \"big picture\" to tell\nwhether certain functions on Bitcoin Core are consensus-critical or\nnot, or whether consensus critical code needs to depend on util.o or\nnot.\nBut I wouldn't be writing to the mailing list without a plan with\nfurther words nor pictures if I didn't had what I believe is a\ncomplete implementation of what I just defined as \"libconsensus phase\n2\".\n\nPhase 3 should finish long pending discussions like \"should\nlibconsensus be C++14 or plain C\" which should NOT delay phase 2.\nPhase 4 should be mostly trivial: rename files to the target dir and\nmove the remaining unused code out of libconsensus.\nPhase 5 should make Bitcoin Core eat its own dog food and use\nlibbitcoinconsensus oonly by its generic C API (I'm sorry if this\nlooks too far away for me to even think about detailing it).\n\nThe work in progress branch (but hopefully being finished, nit and\nmerged within the 0.12.99 cycle) can be found in:\nhttps://github.com/jtimon/bitcoin/commits/libconsensus-f2\n\nBefore sipa asks, signing code may make it into a new library but\nSHOULDN'T BE PART OF LIBBITCOINCONSENSUS. Ideally, all exposed\nfunctions will return true or false and an error string. It is based\non last-0.12.99 3cd836c1 but by popular demand I can open it as a\n\"DEPENDENT-tagged\" PR linking to smaller steps and keeping track of\nsteps done. Analogous to the about to be replaced (for a simpler and\nmore maintainable example of testchain) #6382. If people like\nWladimir, Cory and Pieter cannot see that I've been able to reduce my\noverall cry-for-review noise thanks to github adoption of emacs'\norg-mode's [ ] vs [X] I can alwways leave those \"big picture\" branches\nas \"private\" branches out of the pull request count.\n\nI expect to publish a phase 3 branch very shortly. But as said I\nexpect a lot of discussion on the API part, so I don't expect big\nmovements in phase 3 until phase 2 is done (as said phase 4 is\northogonal to anything, this time git will say \"verified MOVEONLY\" for\nus).\n\nTo finish this long mail, if you are new to free software and would\nlike to get familiarized with Bitcoin Core development in particular,\nmoving one file is a simple task that you can always besure you can do\nright.\nThe way I plan to hand this to you, you won't need to convince anyone\nto publicly confirm that your \"MOVEONLY\" commit being legit, because\nall your remaining work will be to build on one platform (ideally you\nshould do a gitian build, but embarrassingly enough for someone\ntouching consensus code I just trust travis ) and trust travis (as\nsaid, that's what I do from my laptop, but I plan to buy my own\nbuilding machine [and maybe outsource it for free in some protocol\nthat hasn't been invented, sorry again for the distraction]) and fix\nthe includes that have stopped working.\n\nI intend to create an issue to move all the files in this list one by one:\n\nhttps://github.com/bitcoin/bitcoin/pull/7091/files#diff-480477e89f9b6ddafb30c4383dcdd705R250\n\nBut don't hesitate to contact me if are eager for moving some files,\nbecause I believe we can save a few lines of total diff if we chose\nthe order of the movements properly.\n\nSorry, I forgot many people read this list again.\nHappy to answer any question.\n\nSpecially about https://github.com/jtimon/bitcoin/commits/libconsensus-f2"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-01-12T19:17:20",
                "message_text_only": "Jorge, first, thanks again for your work on this.\n\nWithout creating and using a public blockchain interface in phase 2, how\nwill you isolate the database dependency from consensus critical code?\nIs it that the interface will exist but you will recommend against its use?\n\nThis work presumes that the users of the library reject the argument\nthat the database implementation is consensus critical code. Faithful\nreproduction of stored data is a prerequisite for a validity. But a\ncommon store implementation is only slightly more reasonable for this\nlibrary than a common RAM implementation.\n\ne\n\nOn 01/12/2016 09:53 AM, Jorge Tim\u00f3n wrote:\n> After talking to some people about libconsensus in the last Hong Kong\n> conference I realized that my initial plan of exposing one more thing\n> at a time would actually probably slow things down.\n> \n> There's still a promised pdf with pictures that will be released, and\n> actually drafting the UML pictures helped realize that the whole\n> explanation could be much simpler if #7091 was merged first as the\n> last step in phase 1 (that phase has so many contributors that I will\n> probably never get finished documenting it). Matt Corallo's idea of\n> exposing VerifyScript() through a C API certainly helped a lot in\n> cementing the more-minimal-than-earlier dependencies (thanks to Cory\n> Fields among many other people before him) that are not part of the\n> incomplete but existing libbitcoinconsensus library.\n> \n> Given this success in protecting encapsulation by exposing things in a\n> new library, my instinct was to expose more things: VerifyHeader(),\n> VerifyTx() and VerifyBlock() [in that order].\n> But all those three new functions depend on storage in one way or\n> another. That was part of my reasoning to expose VerifyHeader() first,\n> because I believe there will be less discussion on a common interface\n> for the stored longest chain than for the utxo view (which may depend\n> on other transactions spent within the same block).\n> In any case, I realized we should finish putting all the consensus\n> critical code in the libconsensus lib and then worry about its \"final\"\n> API.\n> \n> Therefore I changed the goal of the phase 2 in my libconsensus\n> encapsulation planning from \"expose VerifyHeader() in the existing\n> libconsensus library\" to \"build all the consensus critical code within\n> the existing libconsensus library, even if we don't expose anything\n> else\". I believe this is much feasible for a single Bitcoin Core\n> release cycle and also more of a priority. Other implementations\n> experimenting with libconsensus like\n> https://github.com/libbitcoin/libbitcoin-consensus will have the\n> chance to compare their reimplementations with the future complete\n> libbitcoinconsensus without having to worry about the C API, which\n> ideally they will help to define.\n> \n> I repeat, the goal of phase 2 in my upcoming libconsensus\n> encapsulation plan is to fully decouple libconsensus from Bitcoin\n> Core.\n> In phase 3, we can refine the storage interfaces and focus on a\n> quasi-final C API.\n> In phase 4, we can refine and take out code that doesn't belong in\n> libconsensus like CTxOut::GetDustThreshold() in\n> primitives/transaction.h and move all those consensus files to the\n> consensus folder before creating a separate sub-repository like for\n> libsecp256k1. Note that most of the file-moving work can be in\n> parallel to phases 2 and 3 and, in fact, by any new developer that is\n> willing to exchange rebase-patience for meaningless github stats (I'll\n> do it if nobody else wants, but I'm more than happy to delegate there:\n> I have more than enough github meaningless stats already).\n> \n> As said, the document with pictures and the update to #6714 are still\n> promised, but until they're ready, merging/reviewing #7091, #7287,\n> #7310 and #7311 could do a great deal to make later steps in\n> libconsensus phase 2 more readable.\n> Most reviewers probably don't need to see any \"big picture\" to tell\n> whether certain functions on Bitcoin Core are consensus-critical or\n> not, or whether consensus critical code needs to depend on util.o or\n> not.\n> But I wouldn't be writing to the mailing list without a plan with\n> further words nor pictures if I didn't had what I believe is a\n> complete implementation of what I just defined as \"libconsensus phase\n> 2\".\n> \n> Phase 3 should finish long pending discussions like \"should\n> libconsensus be C++14 or plain C\" which should NOT delay phase 2.\n> Phase 4 should be mostly trivial: rename files to the target dir and\n> move the remaining unused code out of libconsensus.\n> Phase 5 should make Bitcoin Core eat its own dog food and use\n> libbitcoinconsensus oonly by its generic C API (I'm sorry if this\n> looks too far away for me to even think about detailing it).\n> \n> The work in progress branch (but hopefully being finished, nit and\n> merged within the 0.12.99 cycle) can be found in:\n> https://github.com/jtimon/bitcoin/commits/libconsensus-f2\n> \n> Before sipa asks, signing code may make it into a new library but\n> SHOULDN'T BE PART OF LIBBITCOINCONSENSUS. Ideally, all exposed\n> functions will return true or false and an error string. It is based\n> on last-0.12.99 3cd836c1 but by popular demand I can open it as a\n> \"DEPENDENT-tagged\" PR linking to smaller steps and keeping track of\n> steps done. Analogous to the about to be replaced (for a simpler and\n> more maintainable example of testchain) #6382. If people like\n> Wladimir, Cory and Pieter cannot see that I've been able to reduce my\n> overall cry-for-review noise thanks to github adoption of emacs'\n> org-mode's [ ] vs [X] I can alwways leave those \"big picture\" branches\n> as \"private\" branches out of the pull request count.\n> \n> I expect to publish a phase 3 branch very shortly. But as said I\n> expect a lot of discussion on the API part, so I don't expect big\n> movements in phase 3 until phase 2 is done (as said phase 4 is\n> orthogonal to anything, this time git will say \"verified MOVEONLY\" for\n> us).\n> \n> To finish this long mail, if you are new to free software and would\n> like to get familiarized with Bitcoin Core development in particular,\n> moving one file is a simple task that you can always besure you can do\n> right.\n> The way I plan to hand this to you, you won't need to convince anyone\n> to publicly confirm that your \"MOVEONLY\" commit being legit, because\n> all your remaining work will be to build on one platform (ideally you\n> should do a gitian build, but embarrassingly enough for someone\n> touching consensus code I just trust travis ) and trust travis (as\n> said, that's what I do from my laptop, but I plan to buy my own\n> building machine [and maybe outsource it for free in some protocol\n> that hasn't been invented, sorry again for the distraction]) and fix\n> the includes that have stopped working.\n> \n> I intend to create an issue to move all the files in this list one by one:\n> \n> https://github.com/bitcoin/bitcoin/pull/7091/files#diff-480477e89f9b6ddafb30c4383dcdd705R250\n> \n> But don't hesitate to contact me if are eager for moving some files,\n> because I believe we can save a few lines of total diff if we chose\n> the order of the movements properly.\n> \n> Sorry, I forgot many people read this list again.\n> Happy to answer any question.\n> \n> Specially about https://github.com/jtimon/bitcoin/commits/libconsensus-f2\n> \n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 473 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160112/8976d566/attachment.sig>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2016-01-13T08:37:46",
                "message_text_only": "On Tue, Jan 12, 2016 at 8:17 PM, Eric Voskuil <eric at voskuil.org> wrote:\n> Jorge, first, thanks again for your work on this.\n>\n> Without creating and using a public blockchain interface in phase 2, how\n> will you isolate the database dependency from consensus critical code?\n> Is it that the interface will exist but you will recommend against its use?\n\nThe interface will exist but it will be a C++ interface that fits\nbetter with Bitcoin Core internals.\nSee an initial draft of what could be the storage interface:\nhttps://github.com/jtimon/bitcoin/blob/1717db89c6db17ea65ddbd5eb19034315db0b059/src/consensus/storage_interfaces_cpp.h\n\nPhase 3 will consist on discussing and refining that interface to also\ndefine the C interfaces using structs of function pointers instead of\nclasses (see https://github.com/jtimon/bitcoin/blob/2bcc07c014e5dd000030e666be047dfa11f54c10/src/consensus/interfaces.h\nfor an early draft) that is needed for the \"final\" C API.\nBut since I think there will be more discussion and work defining\nthose interfaces, I would rather start with ANY interface that allows\nus to decouple the consensus code from chain.o and coins.o, which we\ndon't want to be built as part of the consensus building package\n(which is used for building both libbitcoinconsensus and Bitcoin\nCore).\nFuture potential users are more than welcomed to draft their own C\nAPIs and that experience should be useful for phase 3.\nI was expecting you, for example, to include the whole consensus code\n(even if it lacks a C API) in\nhttps://github.com/libbitcoin/libbitcoin-consensus for better testing\nof the equivalent code in libbitcoin. You are kind of taking the C API\npart out already, so this time you will just have less things to\ndelete/ignore.\n\n> This work presumes that the users of the library reject the argument\n> that the database implementation is consensus critical code. Faithful\n> reproduction of stored data is a prerequisite for a validity. But a\n> common store implementation is only slightly more reasonable for this\n> library than a common RAM implementation.\n\nThis is a concern that has been risen repeatedly.\nI am aware that faithful reproduction of the stored data is a\nprerequisite for consensus validity. On the other hand, my presumption\nis that a libbitcoinconsensus that forces its users to a given unifrom\nstorage will likely had much less users and any alternative\nimplementation that wants to implement its own custom storage would\nhave to necessarily reimplement the consensus validation code.\nDoing it this way is more flexible. We can relatively easily implement\nanother library (if I remember correctly, last time we talked about it\nwe reffered to it as \"libconsensus plus\", but there's probably better\nnames) also takes care of storage for the users that don't want to\ntake the risks of reimplementing the storage (probably just using\nBitcoin Core's structures).\n\nUnlike me, Luke Dashjr, for example, advocated for the\nstorage-dependent version, but I believe that implementing both\nversions was an acceptable solution to him.\nIt is certainly an acceptable solution for me. I don't want to force\nanyone that doesn't want or need to take the risks reimplementing the\nconsensus storage part to do so. But at the same time I really believe\nthat it would be a mistake to not allow it optionally.\n\nDoes that make sense?"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-01-13T22:47:44",
                "message_text_only": "On 01/13/2016 12:37 AM, Jorge Tim\u00f3n wrote:\n> On Tue, Jan 12, 2016 at 8:17 PM, Eric Voskuil <eric at voskuil.org> wrote:\n>> Jorge, first, thanks again for your work on this.\n>>\n>> Without creating and using a public blockchain interface in phase 2, how\n>> will you isolate the database dependency from consensus critical code?\n>> Is it that the interface will exist but you will recommend against its use?\n> \n> The interface will exist but it will be a C++ interface that fits\n> better with Bitcoin Core internals.\n> See an initial draft of what could be the storage interface:\n> https://github.com/jtimon/bitcoin/blob/1717db89c6db17ea65ddbd5eb19034315db0b059/src/consensus/storage_interfaces_cpp.h\n> \n> Phase 3 will consist on discussing and refining that interface to also\n> define the C interfaces using structs of function pointers instead of\n> classes (see https://github.com/jtimon/bitcoin/blob/2bcc07c014e5dd000030e666be047dfa11f54c10/src/consensus/interfaces.h\n> for an early draft) that is needed for the \"final\" C API.\n> But since I think there will be more discussion and work defining\n> those interfaces, I would rather start with ANY interface that allows\n> us to decouple the consensus code from chain.o and coins.o, which we\n> don't want to be built as part of the consensus building package\n> (which is used for building both libbitcoinconsensus and Bitcoin\n> Core).\n\nOkay.\n\n> Future potential users are more than welcomed to draft their own C\n> APIs and that experience should be useful for phase 3.\n> I was expecting you, for example, to include the whole consensus code\n> (even if it lacks a C API) in\n> https://github.com/libbitcoin/libbitcoin-consensus for better testing\n> of the equivalent code in libbitcoin. You are kind of taking the C API\n> part out already, so this time you will just have less things to\n> delete/ignore.\n\nGeneralization of the store interface may be more challenging than you\nanticipate, but the objective makes sense.\n\n>> This work presumes that the users of the library reject the argument\n>> that the database implementation is consensus critical code. Faithful\n>> reproduction of stored data is a prerequisite for a validity. But a\n>> common store implementation is only slightly more reasonable for this\n>> library than a common RAM implementation.\n> \n> This is a concern that has been risen repeatedly.\n> I am aware that faithful reproduction of the stored data is a\n> prerequisite for consensus validity. On the other hand, my presumption\n> is that a libbitcoinconsensus that forces its users to a given unifrom\n> storage will likely had much less users and any alternative\n> implementation that wants to implement its own custom storage would\n> have to necessarily reimplement the consensus validation code.\n> Doing it this way is more flexible. We can relatively easily implement\n> another library (if I remember correctly, last time we talked about it\n> we reffered to it as \"libconsensus plus\", but there's probably better\n> names) also takes care of storage for the users that don't want to\n> take the risks of reimplementing the storage (probably just using\n> Bitcoin Core's structures).\n> \n> Unlike me, Luke Dashjr, for example, advocated for the\n> storage-dependent version, but I believe that implementing both\n> versions was an acceptable solution to him.\n> It is certainly an acceptable solution for me. I don't want to force\n> anyone that doesn't want or need to take the risks reimplementing the\n> consensus storage part to do so. But at the same time I really believe\n> that it would be a mistake to not allow it optionally.\n> \n> Does that make sense?\n\nWe would not offer libbitcoinconsensus integration if it required us to\nincorporate the store. These are distinct logical components, as are p2p\nnetworking and client-server networking (e.g. RPC), for example. I would\nnot think of these as multiple versions of libbitcoinconsensus but\ninstead as distinct components of a bitcoin node. It doesn't make sense\nto me that you would ship this as two consensus variants. I would work\ntoward shipping independent component libraries (i.e. consensus and store).\n\ne\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 473 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160113/6383f5b8/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Libconsensus phase 2",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Eric Voskuil",
                "Jorge Tim\u00f3n"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 21859
        }
    },
    {
        "title": "[bitcoin-dev] Fwd: Wallet Lock, Unlock BIP idea",
        "thread_messages": [
            {
                "author": "Scott Morgan",
                "date": "2016-01-13T23:47:50",
                "message_text_only": "Hi All,\n\n   Here is a suggestion which is similar to bip-0065, but slightly\ndifferent.\nIn a nutshell I under stand bip-0065 to do this;\nCreate a transaction adding a lock time, that the recipient user must wait\nbefore they can spend the coins.\n\nMy proposal is to do this;\nCreate an entry in the blocks to lock entire wallet addresses indefinitely,\nwith a specified unlock period.\nLater on create / modify an entry in the blocks to acknowledge the wallet\nis being unlocked.\nRemove the lock on the wallet after the unlock period has transpired.\n\n  I think it is technically feasible since many wallet addresses are in\neach block at the transaction level.  However, it would have huge\nimplications to the entire Bitcion ecosystem, so it would probably need a\nstart date at least a year in the future after it was developed.\n\nbip-0065 would not allow the following;\n  This would allow users holding coins for long periods to monitor the\nblockchain to see if someone else is unlocking their wallets (which may\nhave been stolen/copied etc), giving them some time to react to a\nintrusion.  Perhaps there should also be a re-lock (during unlock) feature.\n\nMy original message is attached.\n\nCheers,\nScott\n\n---------- Forwarded message ----------\nFrom: Scott Morgan <scott at adligo.com>\nDate: Tue, Jan 12, 2016 at 3:35 PM\nSubject: Wallet Lock, Unlock BIP idea\nTo: bitcoin-dev at lists.linuxfoundation.org\n\n\nHi All,\n\n   It seems to me that one of the large issues with bitcoin is that they\ncan be stolen like cash.   This issue also culminates with the fact that\nmost miners probably need to hold their coins for some time to be\nprofitable due to the large interest in mining.\n   I think it may be possible to reduce some of this theft by adding a BIP\nto lock and unlock wallets.  Here is the basic idea (probably with some\nholes);\n\n   1) Users could 'lock' their wallet specifying a unlock period (i.e. 15\ndays)\n       The information that a particular wallet is locked would get added\nto the blocks and confirmed like other transactions.\n    2) During transaction creation and mining (to be sure a locked wallet\nisn't drained) the top blocks would be checked to see if the wallet is\nlocked.  Locked wallet transactions would not be confirmed.\n    3)  Users would eventually 'unlock' their wallet.\n        This would put a unlocking as of date time in the blocks to specify\na wallet is unlocking.  Eventually the wallet would not have any lock or\nunlocking entries in the blocks.\n    4) The users would wait the unlock period (i.e. 15 days)\n    5) The Users could then spend their coins.\n\n\n   This would also have some other consequences on the bitcoin system,\nsince anyone could check the transactions to locked wallets to see how many\nBTC are being held, or are being unlocked soon.   This could effect the\nprice of BTC in fiat as supply would change similar to the way mining\nchanges it.  Also it will slow transaction creation a little and mining a\nfair amount.\n   Also locking a wallet might incur a fee.\n\n  What are your thoughts, does this idea qualify for a BIP?\n  If so, I would appreciate it if someone takes it and runs with it.\n\nCheers,\nScott\n\nPS A bit about me, I am a Privacy and Java evangelist, so I will not be\ndoing any work on the main bitcoin core.  I have been doing a little mining\nto attempt to help fund my companies (Adligo Inc) open source Java projects\nTests4j and Fabricate and hopefully in the future Taxi, Sanctum and\nIntelligence4j.\n\nDonations are always welcome;\n\nhttp://www.plumfund.com/crowdfunding/adligoorg\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160113/08c2eb43/attachment.html>"
            },
            {
                "author": "Bastiaan van den Berg",
                "date": "2016-01-14T08:38:29",
                "message_text_only": "You might not be aware, but the wallet supports encrypting. Which then\nmeans that when Mr Badguy steals your wallet.dat, he cannot do anything\nwith it without the passphrase. See RPC calls 'encryptwallet'\n'walletpassphrase' and 'walletlock'.\n\nAlso i'd like to say, that adding a big waving flag in the blockchain to\nsay you are locking/unlocking your wallet might not match good privacy\nethics ;)\n\u200b\n--\nbuZz\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160114/1d659519/attachment.html>"
            },
            {
                "author": "Scott Morgan",
                "date": "2016-01-14T18:26:57",
                "message_text_only": "Hi Again (buZz),\n\n   I am aware of wallet encryption, even if encryptwallet was NOT there you\ncould always copy wallet.dat and use a third party encryption /decryption\ntool.   Also any encryption can be broken, although this may not be\nprofitable.   I know a few people who still have problems with intruders\ntaking copper pipe out of buildings in Chicago, which is also unprofitable\nsince commodity prices have crashed.\n   Your right that a big waving flag in the block chain may be a bad idea,\nI figured there would be a good way to obsfucate the information through\nsome one way encryption.  Then anyone could check if wallet '1ABC...' is\nlocked by encrypting the wallet address and comparing it to a list of\nencrypted wallet addresses, but couldn't easily obtain a list of locked or\nunlocking wallets.   I haven't done any detailed work on implementation\nthough, as I mentioned.\n\nCheers,\nScott\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160114/750ce265/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Fwd: Wallet Lock, Unlock BIP idea",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Bastiaan van den Berg",
                "Scott Morgan"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 5385
        }
    },
    {
        "title": "[bitcoin-dev] [BIP Draft] A modest proposal to increase maximum transactions per block without requiring a hardfork",
        "thread_messages": [
            {
                "author": "Robert Grosse",
                "date": "2016-01-16T18:20:13",
                "message_text_only": "Summary: This describes a new transaction format which allows most\ntransactions to take up less space (and thus fit more per block) and a\nmethod to implement it requiring only a (non generalized) softfork.\n\n= Compressed transactions =\nThis format is designed to allow the majority of transactions to take up\nless space, by removing flexibility and unnecessary data. The requirements\nto use a compressed transaction are\n\n* Non-coinbase\n* 1-8 inputs and 1-8 outputs\n* Pay to pubkey hash only\n\nTransactions which want to use arbitrary scripts or a larger number of\ninputs and outputs can still use the existing transaction format.\n\nA compressed transaction consists of\nheader byte, compressed inputs, compressed outputs, optional lock_time\n\nheader byte has the following format\n* bit 7: Always 1, to make it easy to distinguish compressed and\nuncompressed transactions\n* bit 6: 1 if lock_time is used, otherwise 0\n* bit 5-3: Number of inputs - 1\n* bit 2-0: Number of outputs - 1\n\nThis saves 5+ bytes from omitting the version number and the input and\noutput count fields. Additionally, most transactions will not have\nlock_time, saving another 4 bytes.\n\nCompressed input:\nprevious transaction hash, index byte, signature, pubkey, optional\nsequence_no\n\nThis has the following differences from a normal input: Index is only 1\nbyte, since it is at most 8 anyway. The top bit of the index byte indicates\nwhether the input has a sequence number. ScriptSig length is completely\nomitted, and signature and public key are included directly, saving space\nfrom the data push and check opcodes. And as before, sequence_no is\noptional and usually omitted.\n\nCompressed output:\ncompressed value (1-7 bytes), pubkeyhash\n\ncompressed value format: The high 3 bits of the first byte give the number\nof following bytes. The lower 5 bits and the n following bytes comprise the\noutput value. The maximum possible value is 2099999997690000 satoshis,\nwhich requires 7 bytes to encode, but most values will be far shorter. For\nexample, a value of 0.01 BTC could be encoded in just 3 bytes, saving 5.\n\nAs before the script length field is completely omitted, and the pubkeyhash\nis included directly, without extra opcodes.\n\n\n= Consensus =\n\nLike all softforks, adoption by a minority of miners would cause problems.\nTherefore, these changes would only take effect after a consensus. Miners\ncan advertise support for the new format by increment the version code.\nOnce X% of Y consecutive blocks have this version, the new changes take\neffect. Users who do not upgrade will still work but will not always see\naccurate balances in other addresses and miners who do not upgrade risk\nmining an invalid block, encouraging them to upgrade.\n\n= The Shadow Chain =\n\nNow for the interesting part: Implementing the new format with only a\nsoftfork. In order to qualify as a softfork, every valid block under the\nnew rules also has to be valid under the old rules.\n\nAmong other things this means that compressed transactions can't just be\nincluded in place of an ordinary transaction in a block, since the legacy\n(non-upgraded) clients will consider that invalid. Instead, they will be\nhidden as extra data inside the coinbase transaction, which is allowed to\ncontain arbitrary data.\n\nAdditionally, in order to support interoperability between compressed and\nuncompressed transactions, uncompressed transactions can hide compressed\ninputs and ouputs inside of the normal inputs and outputs using a currently\nunused opcode (OP_NOP1, hereafter referred to as OP_SHADOW). OP_SHADOW\nisn't a script operation per se; instead it marked scripts that should be\ninterpreted differently under the new rules.\n\n\nIn the following, shadow input/output refers to a compressed input/output,\nwhich is hidden as metadata and hence not visible to legacy clients.\n\nThe blockchain must also still be valid when all the hidden data is\nignored. When moving money from the visible to the shadow chain, there is\nno problem, but when moving money back, things get trickier, since the\nlegacy client won't know about any of the shadow transactions. Therefore,\nwhen sending money to the shadow chain, the transaction includes a\nspecially marked anyone-can-spend output. When moving money back from the\nshadow chain, the transaction \"spends\" any available such outputs.\n\nSince an arbitrary amount of splitting and combining can occur inside the\nshadow chain, these will not be 1:1. Instead a pool of available ouputs is\nmaintained with a total balance equal to the total balance inside the\nshadow chain. The validation rules of upgraded clients ensure that this is\nalways maintained. A legacy client may try to spend these outputs, but it\nwould fail validation under the new rules and quickly become orphaned.\n\n= Sending money from the visible to the shadow chain =\nAn uncompressed transaction is created with a specially formatted output.\n\nOP_SHADOW OP_PUSHDATA1 <shadow output>\n\nWhere <shadow output> is a compressed output using the format described in\nthe previous section.\n\nA legacy client will interpret this as an anyone-can-spend output. An\nupgraded client will see the OP_SHADOW and interpret this specially, rather\nthan as a normal script. Instead it will interpret the data as a compressed\noutput, and add it as a shadow UTXO, which can be spent by compressed\ntransactions. Additionally, it will note that the visible output can be\nused later when withdrawing from the shadow chain.\n\n= Sending money from the shadow chain to the visible chain =\nAn uncompressed transaction is created with a specially formatted input.\n\nOP_SHADOW OP_PUSHDATA1 <shadow input>\n\nWhere <shadow input> is a compressed input using the format described in\nthe previous section.\n\nThe legacy client will interpret this as spending one of the\nanyone-can-spend outputs from earlier. The upgraded client will see the\nleading OP_SHADOW and recognize that it should be interpreted specially. It\nwill perform all the normal verification that <shadow input> is a valid\ninput and not already spent in the shadow chain, etc. Thus the blockchain\nis seen as valid by both legacy and upgraded clients.\n\nNote: These scripts are currently considered nonstandard and will not be\nrelayed by legacy clients. As part of implementing the new protocol,\nupgraded clients will obviously be modified to relay these transactions.\nSince the consensus step earlier ensures that these are a majority of the\nnetwork before the changes take effect, this shouldn't be much of a problem.\n\n= Combining and splitting inputs =\n\nThe above illustrates the simplest case. In practice, it will often by the\ncase that the available pool of OP_SHADOW marked anyone-can-spend UTXOs\ndoesn't match up exactly with the amount being withdrawn.\n\nIf the amounts available are too small, the uncompressed transaction can\ninclude multiple inputs. The first one will contain the shadow input data\nas above, and the subsequent inputs will just say\n\nOP_SHADOW OP_TRUE\n\nLikewise, the left over change will be included as an extra output with the\nscript\nOP_SHADOW\n\nEach uncompressed transaction can include up to 8 shadow inputs and up to 8\nshadow outputs. The validation rules require that the total amount of\nmarked anyone-can-spend outputs being spent and created matches up with the\ntotal balance leaving and entering the shadow chain.\n\nWhat if you want to create an actual anyone-can-spend output under the new\nrules? Just include an empty script as before. Only scripts that begin with\nOP_SHADOW take part in the shadow deposit/withdrawal process.\n\nI hope I explained my idea well enough. It's fairly complex, but I think it\nworks. Unlike the \"generalized softfork\" proposals, this is a true\nsoftfork, as the new blockchain is still valid under the old rules, just\ninterpreted a bit differently.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160116/136367b7/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "A modest proposal to increase maximum transactions per block without requiring a hardfork",
            "categories": [
                "bitcoin-dev",
                "BIP Draft"
            ],
            "authors": [
                "Robert Grosse"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 7941
        }
    },
    {
        "title": "[bitcoin-dev] Some more lightning-related git repos",
        "thread_messages": [
            {
                "author": "Bryan Bishop",
                "date": "2016-01-17T08:02:29",
                "message_text_only": "I saw these two repositories through the -wizards IRC channel earlier\ntoday. I have not reviewed any of the source code for quality, security or\nfunctionality, so I don't have word to offer regarding status of these.\n\nhttps://github.com/LightningNetwork/lnd\nhttps://github.com/LightningNetwork/lightning-onion\n\nAlso other git repositories with related work:\nhttps://github.com/ElementsProject/lightning\nhttps://github.com/matsjj/thundernetwork\n\n- Bryan\nhttp://heybryan.org/\n1 512 203 0507\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160117/62dee7f2/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Some more lightning-related git repos",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Bryan Bishop"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 671
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Core 0.12.0 release candidate 1 available",
        "thread_messages": [
            {
                "author": "Wladimir J. van der Laan",
                "date": "2016-01-17T10:08:08",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nBinaries for bitcoin Core version 0.12.0rc1 are available from:\n\n    https://bitcoin.org/bin/bitcoin-core-0.12.0/test/\n\nSource code can be found on github under the signed tag\n\n    https://github.com/bitcoin/bitcoin/tree/v0.12.0rc1\n\nThis is a release candidate for a new major version release, bringing new\nfeatures, bug fixes, as well as other improvements.\n\nPreliminary release notes for the release can be found here:\n\n    https://github.com/bitcoin/bitcoin/blob/0.12/doc/release-notes.md\n\nRelease candidates are test versions for releases. When no critical problems\nare found, this release candidate will be tagged as 0.12.0.\n\nPlease report bugs using the issue tracker at github:\n\n    https://github.com/bitcoin/bitcoin/issues\n\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1\n\niQEcBAEBCgAGBQJWm2fGAAoJEHSBCwEjRsmm274H/2BH3QD4AlJ87mQ8g6bzzv7h\nS8m/EEDmpOuMgM6uF5PzWQ84yNfSyMItq7Y3cU8p9Fv+JD6ic1ZQPPQ0MQc3KtDx\nEeF3wQ2iJe/ggBFcwrz0eIxfEOEo1mi5ooWMVSsnCKQU0IpMtq7ToMvhi/39ACnj\nGsVRBJYlFoRCBh1LKkcyID7Fh7JstMgMrLEcrCy46T9h2EQEevlLydkwY26ENYUO\nBasWXMaysdeKieO5S6tM6MD/50Bd19jHvjzvkeRY5+nZIdrNR1b5n7diCLEUa7b4\n79oIqjdKF+4ns5Qgc+iVhIktthRyrHLrWxX7N8Ky+hSVj1OAKFZfdp4skgAzQUE=\n=oVOV\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "xor at freenetproject.org",
                "date": "2016-01-17T22:57:28",
                "message_text_only": "On Sunday, January 17, 2016 11:08:08 AM Wladimir J. van der Laan via bitcoin-\ndev wrote:\n> Preliminary release notes for the release can be found here:\n> \n>     https://github.com/bitcoin/bitcoin/blob/0.12/doc/release-notes.md\n\n\nThe part which lists raw Git pull requests says:\n> #6057 ac5476e re-enable wallet in autoprune\n\nBut the main, handwritten part does not mention this.\nIs pruning really finished, i.e. could I safely use it as a wallet \"end-user\"?\n\nIMHO it would be one of the most interesting feature for users, as it could \nfix the issue of taking >60 GB of disk space.\n\nSo if it is finished, please mention that\n- it's finished\n- how to enable it.\n\n\nThanks for your hard work! :)\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 836 bytes\nDesc: This is a digitally signed message part.\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160117/8190b24a/attachment.sig>"
            },
            {
                "author": "Wladimir J. van der Laan",
                "date": "2016-01-18T11:14:16",
                "message_text_only": "On Sun, Jan 17, 2016 at 11:57:28PM +0100, xor--- via bitcoin-dev wrote:\n> On Sunday, January 17, 2016 11:08:08 AM Wladimir J. van der Laan via bitcoin-\n> dev wrote:\n> > Preliminary release notes for the release can be found here:\n> > \n> >     https://github.com/bitcoin/bitcoin/blob/0.12/doc/release-notes.md\n> \n> \n> The part which lists raw Git pull requests says:\n> > #6057 ac5476e re-enable wallet in autoprune\n> \n> But the main, handwritten part does not mention this.\n> Is pruning really finished, i.e. could I safely use it as a wallet \"end-user\"?\n\nIt has been tested in git for almost half a year. This RC is the first binary\nrelease that contains the functionality.\n\nIt is extremely unlikely that the wallet will eat your coins (always backup\nnevertheless), but I can't guarantee there won't be some issue where the wallet\nand chain get out of sync and you're forced to redownload the blockchain.\n\n> IMHO it would be one of the most interesting feature for users, as it could \n> fix the issue of taking >60 GB of disk space.\n> \n> So if it is finished, please mention that\n> - it's finished\n> - how to enable it.\n\nHow to enable it is still the same as mentioned in the 0.11 release notes:\nhttps://github.com/bitcoin/bitcoin/blob/v0.11.0/doc/release-notes.md#block-file-pruning\n\nWladimir"
            },
            {
                "author": "xor at freenetproject.org",
                "date": "2016-01-19T06:06:50",
                "message_text_only": "On Monday, January 18, 2016 12:14:16 PM Wladimir J. van der Laan wrote:\n> It has been tested in git for almost half a year. This RC is the first\n> binary release that contains the functionality.\n> \n> It is extremely unlikely that the wallet will eat your coins (always backup\n> nevertheless), but I can't guarantee there won't be some issue where the\n> wallet and chain get out of sync and you're forced to redownload the\n> blockchain.\n\nI think I asked the wrong way, sorry: My question was not really meant at \nwhether it is bug-free (testing that is the purpose of a release candidate, so \nwe of course don't know yet), but rather whether it is at least feature \ncomplete now.\n\nRemember, the previous v0.11.0 release notes said:\n> Block pruning is currently incompatible with running a wallet due to the\n> fact that block data is used for rescanning the wallet and importing keys\n> or addresses (which require a rescan.) However, running the wallet with\n> block pruning will be supported in the near future, subject to those\n> limitations.\n\nSo I'm interested whether this limitation has been lifted, and the whole \nfeature is considered as finished.\n\nIf yes, I would highly recommend advertising it in the new release notes - as \nsaid, the disk space reduction is a big deal.\n\n\nThank you!\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 836 bytes\nDesc: This is a digitally signed message part.\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160119/54b4bd69/attachment-0001.sig>"
            },
            {
                "author": "Wladimir J. van der Laan",
                "date": "2016-01-25T12:03:17",
                "message_text_only": "> \n> So I'm interested whether this limitation has been lifted, and the whole \n> feature is considered as finished.\n\nYes, it's exactly that limitation that has been lifted!\n\n> If yes, I would highly recommend advertising it in the new release notes - as \n> said, the disk space reduction is a big deal.\n\nGood idea, has been added by Marco Falke in commit fa31133,\n\nWladimir"
            },
            {
                "author": "xor at freenetproject.org",
                "date": "2016-01-25T12:27:18",
                "message_text_only": "On Monday, January 25, 2016 01:03:17 PM Wladimir J. van der Laan wrote:\n> > If yes, I would highly recommend advertising it in the new release notes -\n> > as said, the disk space reduction is a big deal.\n> \n> Good idea, has been added by Marco Falke in commit fa31133,\n\nThanks. The RC2 changelog now says:\n\n> To enable block pruning set prune=<N> on the command line or in\n> bitcoin.conf, where N is the number of MiB to allot for raw block & undo\n> data.\n\nFrom having read the Bitcoin whitepaper quite a few months ago ago, I have the \nvery very basic understanding that pruning is meant to:\n- delete old transaction data which merely \"moves coins around\"\n- instead only store the \"origin\" (= block where coins were mined) and \n\"current location\" of the coins, i.e. the unspent transactions. Notably, I \nunderstood it as \"this is as secure as storing everything, since we know where \nthe coins were created, and where they are\".\n\nSo from that point of view, I would assume that there is a \"natural\" amount of \nmegabytes which a fully pruned blockchain consists of: It would be defined by \nthe final amount of unspent coins.\nI thereby am confused why it is possible to configure a number of megabytes \n\"to allot for raw block & undo data\". I would rather expect pruning just to be \na boolean on/off flag, and the number of megabytes to be an automatically \ncomputed result from the natural size of the dataset.\nAnd especially, I fear that I could set N too low, and as a result, it would \ndelete \"too much\". I mean could this result in even security relevant \ntransaction data being deleted?\n\nThus, it would be nice if you could yet once more edit the release notes to:\n- explain why a N must be given\n- what a \"safe\" value of N is. I.e. how large must N be at least to not delete \nsecurity-relevant stuff?\n- maybe mention if there is a \"auto\" setting for N to ensure that it choses a \nsafe value on its own?\n\nSorry if my descriptions are from a layman's point of view. I intentionally \ndid *not* re-read the Bitcoin whitepaper to have a better understanding:\nI think having a layman's understanding is a good usability test for such \nstuff.\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 836 bytes\nDesc: This is a digitally signed message part.\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160125/87785117/attachment.sig>"
            },
            {
                "author": "Marco Falke",
                "date": "2016-01-25T14:44:08",
                "message_text_only": "All of this is already implemented in the bitcoind and bitcoin gui.\n\nThe theoretic minimum for the prune target would be 0 (just the header\nof the current best block) as Bitcoin Core already stores the\nchainstate (about 2 GiB) regardless of what you set for -prune=<N>.\n\nIn practice, the minimum is 510, so reorgs and small rescans (may not\nbe implemented in 0.12) are still possible.\n\nThe clients won't let you set it below that target:\n\"Prune configured below the minimum of 550 MiB. Please use a higher number.\"\n\nAlso, keep in mind Bitcoin Core comes with a help message explaining\n-prune and other command line options\n\n--Marco\n\n2016-01-25 13:27 GMT+01:00 xor--- via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org>:\n> On Monday, January 25, 2016 01:03:17 PM Wladimir J. van der Laan wrote:\n>> > If yes, I would highly recommend advertising it in the new release notes -\n>> > as said, the disk space reduction is a big deal.\n>>\n>> Good idea, has been added by Marco Falke in commit fa31133,\n>\n> Thanks. The RC2 changelog now says:\n>\n>> To enable block pruning set prune=<N> on the command line or in\n>> bitcoin.conf, where N is the number of MiB to allot for raw block & undo\n>> data.\n>\n> From having read the Bitcoin whitepaper quite a few months ago ago, I have the\n> very very basic understanding that pruning is meant to:\n> - delete old transaction data which merely \"moves coins around\"\n> - instead only store the \"origin\" (= block where coins were mined) and\n> \"current location\" of the coins, i.e. the unspent transactions. Notably, I\n> understood it as \"this is as secure as storing everything, since we know where\n> the coins were created, and where they are\".\n>\n> So from that point of view, I would assume that there is a \"natural\" amount of\n> megabytes which a fully pruned blockchain consists of: It would be defined by\n> the final amount of unspent coins.\n> I thereby am confused why it is possible to configure a number of megabytes\n> \"to allot for raw block & undo data\". I would rather expect pruning just to be\n> a boolean on/off flag, and the number of megabytes to be an automatically\n> computed result from the natural size of the dataset.\n> And especially, I fear that I could set N too low, and as a result, it would\n> delete \"too much\". I mean could this result in even security relevant\n> transaction data being deleted?\n>\n> Thus, it would be nice if you could yet once more edit the release notes to:\n> - explain why a N must be given\n> - what a \"safe\" value of N is. I.e. how large must N be at least to not delete\n> security-relevant stuff?\n> - maybe mention if there is a \"auto\" setting for N to ensure that it choses a\n> safe value on its own?\n>\n> Sorry if my descriptions are from a layman's point of view. I intentionally\n> did *not* re-read the Bitcoin whitepaper to have a better understanding:\n> I think having a layman's understanding is a good usability test for such\n> stuff.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Wladimir J. van der Laan",
                "date": "2016-01-25T15:05:59",
                "message_text_only": "> > To enable block pruning set prune=<N> on the command line or in\n> > bitcoin.conf, where N is the number of MiB to allot for raw block & undo\n> > data.\n> \n\n> From having read the Bitcoin whitepaper quite a few months ago ago, I have the \n> very very basic understanding that pruning is meant to:\n> - delete old transaction data which merely \"moves coins around\"\n> - instead only store the \"origin\" (= block where coins were mined) and \n> \"current location\" of the coins, i.e. the unspent transactions. Notably, I \n> understood it as \"this is as secure as storing everything, since we know where \n> the coins were created, and where they are\".\n> \n> So from that point of view, I would assume that there is a \"natural\" amount of \n> megabytes which a fully pruned blockchain consists of: It would be defined by \n> the final amount of unspent coins.\n> I thereby am confused why it is possible to configure a number of megabytes \n> \"to allot for raw block & undo data\". I would rather expect pruning just to be \n> a boolean on/off flag, and the number of megabytes to be an automatically \n> computed result from the natural size of the dataset.\n> And especially, I fear that I could set N too low, and as a result, it would \n> delete \"too much\". I mean could this result in even security relevant \n> transaction data being deleted?\n\nThe term 'pruning', unfortunately is very much overused and overloaded in the\nbitcoin ecosystem. Satoshi's paper refers to UTXO pruning. This is Pieter Wuille's \"ultraprune\",\nwhich has been part of Bitcoin Core for more than three years.\n\nBlock pruning is not mentioned in that paper because it is just administrative,\nthe only reason that nodes store historical blocks at all is to serve it to other nodes,\nas well as to catch up the wallet status and for -reindexes.\n\n> Thus, it would be nice if you could yet once more edit the release notes to:\n\nI don't have time to work on the release notes right now, but if someone else\nwants to contribute that'd be awesome.\n\n> - explain why a N must be given\n\nTo give a quotum. The point is that the user can choose how much harddisk space they want to\ndedicate to block storage.\n\nBlock data that is stored can be used by other software, or potentially be\nserved to other nodes. The latter is not implemented at the moment - it would require\na change to the P2P protocol, thus right now pruning nodes don't serve block\ndata at all.\n\n> - what a \"safe\" value of N is. I.e. how large must N be at least to not delete \n> security-relevant stuff?\n\nThere is no security compromise with pruning. Any value of N is intended to be safe.\n\nVery low values would delete undo data that may be necessary in a reorganization,\nbut this is prohibited by argument checks.\n\nRelease notes are not meant as a replacement or supplement for documentation.\nThe documentation for -prune is this:\n\n  -prune=<n>\n       Reduce storage requirements by pruning (deleting) old blocks. This mode\n       is incompatible with -txindex and -rescan. Warning: Reverting this\n       setting requires re-downloading the entire blockchain. (default: 0 =\n       disable pruning blocks, >550 = target size in MiB to use for block\n       files)\n\n> - maybe mention if there is a \"auto\" setting for N to ensure that it choses a \n> safe value on its own?\n\nAs said, there is no safe or unsafe value. The lowest acceptable value is just as safe\nas storing everything.\n\nWladimir"
            },
            {
                "author": "Simon Selitsky",
                "date": "2016-01-25T15:57:53",
                "message_text_only": ">> Block data that is stored can be used by other software, or potentially be\n>> served to other nodes. The latter is not implemented at the moment - it would require a change to the P2P protocol, thus right now pruning nodes don't serve block data at all.\n\nWhy is the minimum storage quota of 550 MiB necessary for pruning nodes\nif the block data is not served to other nodes ? Could the client just do transaction verification and transaction relaying and only keep the block(s) \nbeing verified on disk ?\n\n\nOn Jan 25, 2016, at 10:05 AM, Wladimir J. van der Laan via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>>> To enable block pruning set prune=<N> on the command line or in\n>>> bitcoin.conf, where N is the number of MiB to allot for raw block & undo\n>>> data.\n> \n>> From having read the Bitcoin whitepaper quite a few months ago ago, I have the \n>> very very basic understanding that pruning is meant to:\n>> - delete old transaction data which merely \"moves coins around\"\n>> - instead only store the \"origin\" (= block where coins were mined) and \n>> \"current location\" of the coins, i.e. the unspent transactions. Notably, I \n>> understood it as \"this is as secure as storing everything, since we know where \n>> the coins were created, and where they are\".\n>> \n>> So from that point of view, I would assume that there is a \"natural\" amount of \n>> megabytes which a fully pruned blockchain consists of: It would be defined by \n>> the final amount of unspent coins.\n>> I thereby am confused why it is possible to configure a number of megabytes \n>> \"to allot for raw block & undo data\". I would rather expect pruning just to be \n>> a boolean on/off flag, and the number of megabytes to be an automatically \n>> computed result from the natural size of the dataset.\n>> And especially, I fear that I could set N too low, and as a result, it would \n>> delete \"too much\". I mean could this result in even security relevant \n>> transaction data being deleted?\n> \n> The term 'pruning', unfortunately is very much overused and overloaded in the\n> bitcoin ecosystem. Satoshi's paper refers to UTXO pruning. This is Pieter Wuille's \"ultraprune\",\n> which has been part of Bitcoin Core for more than three years.\n> \n> Block pruning is not mentioned in that paper because it is just administrative,\n> the only reason that nodes store historical blocks at all is to serve it to other nodes,\n> as well as to catch up the wallet status and for -reindexes.\n> \n>> Thus, it would be nice if you could yet once more edit the release notes to:\n> \n> I don't have time to work on the release notes right now, but if someone else\n> wants to contribute that'd be awesome.\n> \n>> - explain why a N must be given\n> \n> To give a quotum. The point is that the user can choose how much harddisk space they want to\n> dedicate to block storage.\n> \n> Block data that is stored can be used by other software, or potentially be\n> served to other nodes. The latter is not implemented at the moment - it would require\n> a change to the P2P protocol, thus right now pruning nodes don't serve block\n> data at all.\n> \n>> - what a \"safe\" value of N is. I.e. how large must N be at least to not delete \n>> security-relevant stuff?\n> \n> There is no security compromise with pruning. Any value of N is intended to be safe.\n> \n> Very low values would delete undo data that may be necessary in a reorganization,\n> but this is prohibited by argument checks.\n> \n> Release notes are not meant as a replacement or supplement for documentation.\n> The documentation for -prune is this:\n> \n>  -prune=<n>\n>       Reduce storage requirements by pruning (deleting) old blocks. This mode\n>       is incompatible with -txindex and -rescan. Warning: Reverting this\n>       setting requires re-downloading the entire blockchain. (default: 0 =\n>       disable pruning blocks, >550 = target size in MiB to use for block\n>       files)\n> \n>> - maybe mention if there is a \"auto\" setting for N to ensure that it choses a \n>> safe value on its own?\n> \n> As said, there is no safe or unsafe value. The lowest acceptable value is just as safe\n> as storing everything.\n> \n> Wladimir\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Jonas Schnelli",
                "date": "2016-01-25T16:12:01",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\n\n> Why is the minimum storage quota of 550 MiB necessary for pruning\n> nodes if the block data is not served to other nodes ? Could the\n> client just do transaction verification and transaction relaying\n> and only keep the block(s) being verified on disk ?\n> \n\nWe try to allow reorgs ~288 blocks deep also in pruning:\n\n- From code comments:\nRequire that user allocate at least 550MB for block & undo files\n(blk???.dat and rev???.dat)\nAt 1MB per block, 288 blocks = 288MB.\nAdd 15% for Undo data = 331MB\nAdd 20% for Orphan block rate = 397MB\nWe want the low water mark after pruning to be at least 397 MB and\nsince we prune in\nfull block file chunks, we need the high water mark which triggers the\nprune to be\none 128MB block file + added 15% undo data = 147MB greater for a total\nof 545MB\nSetting the target to > than 550MB will make it likely we can respect\nthe target.\n\n\n</jonas>\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v2\n\niQIcBAEBCAAGBQJWpklQAAoJECnUvLZBb1Ps464P+gNqN+Rs5MnAFg5Hukxcj9BU\nf+Zm5B99VMT3qWjJUjk05NTPLoa6vS6I6pkanWNlzmquZSardW0rW/7JS8wu8BiA\nILP3gMWMiF2w//0o+4uEhQt5FhUKQGUVgtXDprc/6WeOfpEBunk+/YTmFPpSMQym\nw9roH+vrMBHNogSXjdIsn3qPGdVWWuc1PeeluMthN/f7Y5Y5kcyUJvvJmhNbNspG\nUaGqh7vCDBvaHmxKuPRvqPlSqvwXjA3kxDP1s+VBtLGKnJzVoBqBEsody0UscQQO\nRRvxbEdaRL1iTVgA0orsDCOMsBaUcKiZ4tlJUd+Z+ifHCVJ5Szl5fsqIIElF8vOk\nhy8++T4XqPEZqlDnAIpOxE0eGnByvdkUrFew60nA+A+ivY7GkCFhMz8AP4VHrhFS\nUOU2wDuBOsA6ssqkxMmc5Vizyb6CmL2Ho0csPqabvfRYk5VZACc63FbJ2xcdjDZz\nCufvfJZ3O5dgSy29fn9XQHsU8qSn0DteSU/9OiHAJmvkqrvB0yT21kIQXUWiqYGk\nxDvc/SVpttYqaW2hAgjFG9NGJ/D2dpliYNUjgwmijUVZuI9bkJ68l5CfpOzXYnNJ\ne1AFzBeHVCKSn0advmTVdyybslU32g7ytzJQcQP2b8a4GQYEI6DNhTA5HTxWaj//\nO+Cm0CkAbW1vNJqSolnU\n=lDcA\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "xor at freenetproject.org",
                "date": "2016-01-25T17:33:09",
                "message_text_only": "On Monday, January 25, 2016 04:05:59 PM Wladimir J. van der Laan wrote:\n> I don't have time to work on the release notes right now, but if someone\n> else wants to contribute that'd be awesome.\n\nI cooked my first pull request to resolve this:\nhttps://github.com/bitcoin/bitcoin/pull/7416\n\nThanks for all the explanations you folks provided! :)\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 836 bytes\nDesc: This is a digitally signed message part.\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160125/603d7652/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Core 0.12.0 release candidate 1 available",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Simon Selitsky",
                "Wladimir J. van der Laan",
                "xor at freenetproject.org",
                "Jonas Schnelli",
                "Marco Falke"
            ],
            "messages_count": 11,
            "total_messages_chars_count": 21176
        }
    },
    {
        "title": "[bitcoin-dev] Capacity increases for the Bitcoin system.",
        "thread_messages": [
            {
                "author": "Anthony Towns",
                "date": "2016-01-18T12:02:51",
                "message_text_only": "TLDR:\n\n  1.7MB effective block size is a better estimate than 1.6MB for p2pkh\n  with segwit. 2MB for 2/2 multisig still seems accurate.\n\n  Additional post-segwit soft forked script improvements can improve\n  the effective block size for p2pkh txns from 1.7MB to 1.9MB, and for\n  2/2 multisig from 2MB to 2.5MB/3MB.\n\n  (To the best of my knowledge, anyway; if I've made a mistake in my\n  maths or assumptions, corrections appreciated)\n\nOn Tue, Dec 08, 2015 at 02:58:03PM +1000, Anthony Towns via bitcoin-dev wrote:\n> So from IRC, this doesn't seem quite right -- capacity is constrained as\n>   base_size + witness_size/4 <= 1MB\n..\n> That would be 1.6MB and 2MB of total actual data if you hit the limits\n> with real transactions, so it's more like a 1.8x increase for real\n> transactions afaics, even with substantial use of multisig addresses.\n\nI think these numbers are slightly mistaken -- I was only aware of version\n1 segwit scripts at the time, and assumed 256 bit hashes would be used\nfor all segwit transaction, however version 0 segwit txns would be more\nefficient for p2pkh, with the same security as bitcoin currently has\n(which seems fine).\n\nAlso, segwit will make two additional soft-fork improvements possible that\nwould have a positive effect on transactions per block without requiring\nmore data per block: ecdsa public key recovery (more space efficient for\n*both* multisig and p2pkh) and schnorr signatures (more space efficient\nmultisig) which might also improve things. I don't know how soon they're\nplanned to be worked on post segwit's roll out; basic Schnorr signatures\nare in the Elements sidechain, but I don't think key recovery has been\nimplemented anywhere? (Actually, I guess they could both be done already\nvia softforking OP_NOP opcodes, though segwit makes them slightly\ncleaner)\n\nAnyhoo here's some revised figures, working explained in the footnotes.\nIf I've made mistakes, corrections appreciated, of course.\n\np2pkh:\n\n  now: 10+146i+34o [0]\n  segwit: 10+41i+36o + 0.25*105*i [1]\n  ecdsa recovery: 10+41i+33o + 0.25*71*i [2]\n  80-bit schnorr: 10+41i+33o + 0.25*71*i (same as ecdsa recovery imo [3])\n  128-bit schnorr: 10+41i+43o + 0.25*106*i [4]\n\n(128-bit schnorr provides a not very useful increase in security here)\n\n2-of-2 multisig:\n\n  now: 10+254i+32o [5]\n  segwit: 10+43i+43o + 0.25*213*i [6]\n  ecdsa recovery: 10+43i+43o + 0.25+187*i [7]\n  80-bit schnorr: 10+41i+33o + 0.25*71*i (same as p2pkh)\n  128-bit schnorr: 10+41i+43o + 0.25*106*i (same as p2pkh)\n\n(segwit, ecdsa recovery and 128-bit schnorr all provide a beneficial\nsecurity increase here, as per the \"Time to worry about 80-bit collision\nattacks\" thread; 80-bit schnorr provides the same security as current\np2sh multisig)\n\nUsing the same assumptions in the previous mail, ie that over the long\nterm number inputs is about the same as number of outputs, these\nsimplify to:\n\n        p2pkh           2-of-2 msig\nnow     10+180i         10+286i\nsegwit  10+104i         10+140i\nrecov   10+92i          10+133i\nsch80   10+92i          10+92i\nsch128  10+111i         10+111i\n\nTranslating \"now\" to 100%, the scaling factors work out to be:\n\ni=1, i->inf\n\n        p2pkh           2-of-2 msig\nnow     100%            100%\nsegwit  166%-173%       197%-204%\nrecov   186%-195%       207%-215%\nsch80   186%-195%       290%-310%\nsch128  157%-162%       244%-257%\n\nSo 170% for p2pkh (rather my original estimate of 160%) and 200% for\nmultisig (same as my original estimate), which can rise via further\nsoft-forks up to 190% for p2pkh and 250% or 300% for 2-of-2 multisig\n(depending on whether you want additional security for 2/2 multisig\nbeyond what's currently available).\n\n(I'm assuming people are mostly interested in the number of transactions\nper block (or tx/second or tx/day); if miners are worried about the\nactual data per block (which effects orphan rates) implied by the above,\nbut don't want to work it out themselves, I could do the maths for that\ntoo pretty easily. Let me know)\n\n\nIf a 2MB hard fork is done first, then the 1/4 discount for segwit could\nmean up to 8MB of total data per block -- from what I understand this\nis currently infeasible; so I presume that segwit on top of a hardfork\nand prior to IBLT/weak blocks would need to have a smaller discount or\nno discount applied so as to ensure total data per block remains at 4MB\nor less. With no discount for witness data (ie, no \"accounting tricks\")\nthose figures look like:\n\n        p2pkh           2-of-2 msig\nnow     100%            100%\nsegwit  99%             95%\nrecov   122%-124%       104%\nsch80   122%-124%       191%-198%\nsch128  94%-95%         148%-150%\n\nThat is, without discounting, segwit comes at a slight cost in\ntransactions per block, and additional soft forks will only result in\n25% gain for p2pkh (via key recovery) and 50%-100% for 2-of-2 multisig\n(through the use of schnorr sigs and key recovery, and depending on\nwhether you want 128 bits of security rather than 80 bits).\n\n(So without the discounting factor, with a 2MB block size, 2MB per block\nwith segwit and key recovery gives you 25% more p2pkh transactions than\njust 2MB per block now; while segwit and schnorr signatures gives you\n50%-100% more 2/2 multisig transactions in the same 2MB. Likewise with\n1MB or 4MB and no discounting. Discounting has the indirect benefit of\nproviding a monetary incentive to limit UTXO sizes however)\n\n\n(2 of 3 multisig for escrow payments would probably be interesting to\nwork out too; I think ecdsa key recovery combined with 1/4 discounting\nwould provide a substantial improvement there. I don't think Schnorr\nhelps at all for that case, unfortunately; and it's probably too small\nscale for merkle-ised abstract syntax trees to do any good either)\n\n\nA caveat: I'm only counting the script data from witnesses here; but it's\npossible that additional metadata (such as a length for each witness\nsignature, or the value of the input, or even some/all of the merkle\nhashes) should also be accounted for. I don't think any of them need to\nbe accounted for segwit as proposed, but I'm not sure. And it might well\nbe different for a hardforked segwit; there I have no idea at all. I\ndon't think a byte or two for length would make much difference, at least.\n\nCheers,\naj\n\n[0] 10 bytes for version (4), input count (1), output count (1) and\n    locktime (4); 146 bytes per input consisting of tx hash (32), txout\n    index (4), script length (1), scriptsig (signature and pubkey =\n    105), CHECKSIG = 25), and sequence number (4); 34 bytes per output\n    consisting of value (8), script length (1) and scriptpubkey (DUP\n    HASH160 PUSH20 EQVERIFY CHECKSIG = 25).\n\n[1] Same as now, except two extra bytes per output script (segwit push and\n    segwit version byte), and moving the 105 bytes of signature script\n    directly into the segregated witness\n\n[2] Allowing ECDSA recovery requires an additional soft-fork post segwit\n    to change the CHECKSIG operation; this requires bumping the\n    segwit script version to 2 or higher and possibly using a different\n    opcode, but allows the scriptsig to just be the 70 byte signature,\n    without also including the 33 byte pubkey. The 33 byte pubkey is\n    automatically calculated from the signature, and verified against\n    the hash provided in the scriptpubkey to maintain security, with a\n    scriptpubkey like: [PUSH (20 byte pubkey hash) CHECKSIG_RECOVER] (22\n    bytes versus 25 bytes), and a scriptsig like [PUSH (70 byte sig)]\n    (71 bytes versus 105 bytes).\n\n[3] libsecp256k1 has a function to recover a pubkey from a schnorr\n    signature, so I'm assuming that means pubkey recovery with schnorr\n    is possible :) -- I haven't actually verified the maths\n    https://github.com/bitcoin/secp256k1/blob/master/include/secp256k1_schnorr.h\n\n[4] The witness scriptpubkey is limited to 32 bytes (plus push op and\n    version byte for a total of 34 bytes, so 128 bit security requires\n    version 1 segwit, and p2sh-style constuction. Hence: 10 bytes\n    (version, input and output counts and locktime); 41 base bytes per\n    input (tx hash, tx index, script length, and sequence number); 106\n    witness bytes per input (sig (70 bytes) plus witness script (PUSH\n    schnorr merged pubkey (32 bytes) plus CHECKSCHNORR), plus PUSH ops);\n    and 43 bytes per output (value, script length, and 34 bytes for the\n    v1-style witness script).\n\n[5] Per input is (32 bytes tx hash, 4 bytes tx index, 4 bytes nsequence,\n    1 byte scriptsig length, 143 bytes for actual signature (2x70\n    for the sigs, 3 bytes for OP_0 and two OP_PUSH), and 70 bytes for\n    the redeemscript (2 pub pub 2 OP_CHECKMULTISIG)) for 254 bytes;\n    per output is (8 bytes value, 1 byte length, 23 bytes for HASH160\n    [20 byte hash] OP_EQUAL) for 32 bytes.\n\n[6] Per input is (34 bytes tx hash, 4 bytes tx index, 4 bytes nsequence,\n    1 byte scriptsig length) for 43 bytes in the base block and (143\n    bytes for the actual signature, plus 70 bytes for the redeemscript)\n    for 213 bytes of witness data; per output is (8 bytes value, 1 byte\n    length, and 34 bytes for version 1 segwit scriptpubkey) for 43\n    bytes.\n\n[7] Same as [6], but with key recovery on a MULTISIG op, rather than 33\n    bytes per pubkey, this could be reduced to a 20 byte pubkey hash\n    per pubkey, for a saving of 26 bytes of witness data."
            },
            {
                "author": "Anthony Towns",
                "date": "2016-01-22T09:46:18",
                "message_text_only": "On Mon, Jan 18, 2016 at 10:02:51PM +1000, Anthony Towns via bitcoin-dev wrote:\n> I think these numbers are slightly mistaken -- I was only aware of version\n> 1 segwit scripts at the time, and assumed 256 bit hashes would be used\n> for all segwit transaction, however version 0 segwit txns would be more\n> efficient for p2pkh, with the same security as bitcoin currently has\n> (which seems fine).\n\nLatest segwit code just has version 0 witness format, and treats a 32\nbyte push as the sha256 of a script, and a 20 byte push as the hash of\nthe pub key. Also, the witness scriptPubKey format uses \"OP_0 [hash]\" to\npush the version and hash to the script separately, rather than \"[0x00\nscript]\" or \"[0x01 hash]\" (this changes allows segwit transactions to\nbe encoded backwards compatibly as a p2sh payment).\n\n> p2pkh:\n>   segwit: 10+41i+36o + 0.25*105*i [1]\n\n> [0] 10 bytes for version (4), input count (1), output count (1) and\n>     locktime (4); 146 bytes per input consisting of tx hash (32), txout\n>     index (4), script length (1), scriptsig (signature and pubkey =\n>     105), CHECKSIG = 25), and sequence number (4); 34 bytes per output\n>     consisting of value (8), script length (1) and scriptpubkey (DUP\n>     HASH160 PUSH20 EQVERIFY CHECKSIG = 25).\n\n> [1] Same as [0], except two extra bytes per output script (segwit push\n>     and segwit version byte), and moving the 105 bytes of signature\n>     script directly into the segregated witness\n\nSo this change means segwit p2pkh needs 31 bytes per output not 36 bytes (value,\nlength stay the same, scriptpubkey becomes \"OP_0 PUSH20\" for 22 bytes\ninstead of 25+2 bytes). This gives another couple of percent gain, so:\n\n    segwit: 10+41i+31o + 0.25*105*i [1]\n\nSetting i=o makes:\n\n>         p2pkh           2-of-2 msig\n> now     10+180i         10+286i\n> segwit  10+104i         10+140i\n\nbecome:\n\nsegwit    10+99i          10+140i\n\nand therefore,\n\n>         p2pkh           2-of-2 msig\n> now     100%            100%\n> segwit  166%-173%       197%-204%\n\nbecomes:\n\nsegwit    174%-181%       197%-204%\n\nConstantly creeping up! Pretty nice.\n\nAlso, p2pkh with segwit-via-p2sh is probably interesting, those numbers\nwork out as:\n\nsegwit:   10+41i+31o + 0.25*105*i (for comparison)\nsegp2sh:  10+60i+32o + 0.25*105*i [0]\n  ->      10+119i\n  ->      147%-151%\n\nSo that still looks like a reasonable improvement even if (eg) in the\nshort term merchants are the only ones that upgrade, and customers just\nuse non-segwit-aware wallets with a p2sh address that's only redeemable\nby a segwit-aware wallet.\n\nCheers,\naj\n\n[0] 10 bytes standard. For each input, tx hash (32) plus index (4),\n    script length (1) and scriptsig which is a push of the standard segwit\n    pubscript (22+1) totaling to 60, and witness data is the same as for\n    normal segwit (105). Each output is standard p2sh, which is value\n    (8), length (1) and script (23) for a total of 32.\n\nCheers,\naj"
            }
        ],
        "thread_summary": {
            "title": "Capacity increases for the Bitcoin system.",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Anthony Towns"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 12232
        }
    },
    {
        "title": "[bitcoin-dev] What is OpenSSL still used for?",
        "thread_messages": [
            {
                "author": "Andrew C",
                "date": "2016-01-19T01:39:19",
                "message_text_only": "In the release notes for 0.12, it says that we have moved from using\nOpenSSL to libsecp256k1 for signature validation. So what else is it being\nused for that we need to keep it as a dependency?\n\nThanks,\nAndrew\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160119/2cc15d41/attachment.html>"
            },
            {
                "author": "Ethan Heilman",
                "date": "2016-01-19T03:58:22",
                "message_text_only": "I believe libsecp256k1 just performs Elliptic Curve operations\nrequired by Bitcoin. OpenSSL is used for all other crypto.\n\nFor instance the PRNG appears to be OpenSSL:\nhttps://github.com/bitcoin/bitcoin/blob/master/src/random.h\n\n\nOn Mon, Jan 18, 2016 at 8:39 PM, Andrew C via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> In the release notes for 0.12, it says that we have moved from using OpenSSL\n> to libsecp256k1 for signature validation. So what else is it being used for\n> that we need to keep it as a dependency?\n>\n> Thanks,\n> Andrew\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Douglas Roark",
                "date": "2016-01-21T02:57:23",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nOn 2016/1/18 19:58, Ethan Heilman via bitcoin-dev wrote:\n> I believe libsecp256k1 just performs Elliptic Curve operations \n> required by Bitcoin. OpenSSL is used for all other crypto.\n\nThe exact answer, as I understand it, is a bit more nuanced. In\nparticular, you referenced the PRNG. I believe libsecp256k1, as\ncurrently written, relies on an implementation of RFC 6979 instead of\nusing a PRNG. I'm guessing this is done for portability reasons (no\nneed to hook into the OS's RNG).\n\nOtherwise, yes, I believe this answer is basically correct. There are\nstill some crypto functions not covered by libsecp256k1, at least at\nthe API level. But, for consensus-critical functionality, I think 0.12\nwill be rid of OpenSSL.\n\n- -- \n- ---\nDouglas Roark\nCryptocurrency, network security, travel, and art.\nhttps://onename.com/droark\njoroark at vt.edu\nPGP key ID: 26623924\n-----BEGIN PGP SIGNATURE-----\nComment: GPGTools - https://gpgtools.org\n\niQIcBAEBCgAGBQJWoEkTAAoJEEOBHRomYjkkoR0QAKmvgmoOdCw7SLP9cFURltXw\nRo8mOfikjp04C6tsshtiKQ1+jq80wBhioVYIL7XiyNU7ZUNdAWSc/wGBCG+YkMeQ\n6h02WJZQtTe0PvGVHIgUw6SiV4ZzXBuapXQX0BgEl0pInvQkRRqWtgrqDlWbqJVg\nNKzm8Kh+c8JUHEKbhnC45Jgh2JYHpyXcByLHSyGYsPOprjHmsupCPC6qydrRnuaO\nr7YHtObK2myOglJ1h6BXir//+XNbk6RiRNf5voONNAR9L+69BBV7hMVVO3eiDZ12\nvrNaOIKhDjhDs1kmkFYi7ML/zKBQRXlb7iM8AEpfCUKl/zK9bSNeblP4ZBGPqjCm\n9TGCqGjmKEbg7AYXjyMvmw+jZReediJMNYpCdxaSJi+XJZO6EC28pcKsb6pu/9gX\nNCLf1T/f2NoyXxc57aTuHNo0SnVaee1z0+IlGSh+5foxhZGbFmPhxOy3WNIubuou\ntm0guAXloCCERwVg0OhhQ3YyrlOWz7VnUrT8cteQC+yP353zdnxay7ZmQh9swcyR\nVX7yu4xLcxgbQmBIhMyKs9iQnycOrdNhZEfGx4vQ2ZKAj1CPVqrgKxbtY3KuPfvb\nYAzfs/iXaqBHH7FN9juLMRGqkzyVzJ9mIsFyLldADvSoc8RSa1IQiZtfPsIU1w1i\nUKEl9Qasje80EojNZNz0\n=glL2\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "Jonas Schnelli",
                "date": "2016-01-21T07:42:56",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\nHi Andrew\n\n> In the release notes for 0.12, it says that we have moved from\n> using OpenSSL to libsecp256k1 for signature validation. So what\n> else is it being used for that we need to keep it as a dependency?\n\nOpenssl was dropped from the consensus layer (ECC) in 0.12, though, it\nstill used for...\n\n1) ... getting random numbers (randomize the ECC signing context)\n2) [wallet only] ... AES256 encryption of private keys\n3) [GUI only] ... SSL/X.509 for BIP70 (payment protocol)\n\nOpenssl dependency for 1) and 2) could be removed. There are some \u2013\noutdated \u2013 relevant PRs:\n\nEntropy: https://github.com/bitcoin/bitcoin/pull/5885\nAES: https://github.com/bitcoin/bitcoin/pull/5949\n\nI guess for point 3) [BIP70] it makes sense to keep openssl.\n\n/jonas\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v2\n\niQIcBAEBCAAGBQJWoIwAAAoJECnUvLZBb1PsWSMP/2VyURcUUmnFodX1UUkkTQSu\nKmEMqRe3Ak1v4B5S+7raodYE+7ePONedHrciUgNfj0GBDu7/5Wl3LD0GnFb0//Nl\nJEHPzNQB8xhRjhXux17rq+Kf60qjc+uybJQDDs9KfQQYS+hFTUKXX61s7wwY/QAy\n6Vi5FxZRThzFUFWFZvG9KbRLWEbBVONnXLaA4pB0o7UnU2wAHkmPP5wyeCJLy3cW\nuggeLYh3X6GBF/+IQ0ndO4yFJ09ROXBS7N1VisJy2Z4zTJr0y6rAVVG9XcPtlkMc\nSvMULeiB34odvlZMRMFdCYLHCuff30jN2+aEJST/d+lr4IB2ai8veXwt69yya4p2\n4UUL5ueOzKWfgcxVT/qDDcVkZJFqrhdHmMaEggelRakQCSdLly+4X7Mdo/Dx/RC2\nPYUDQVGGFephTpzBTQ3fpRGtZu2JX45T2RKyF2qcVlzXrRW7SjqzwGWWuutwbbrS\nV9cSMMVS7NU90mgCE4e3G2oqi40H8dOzg+opf5ynChEccgJwUlxrfjj4kJbQZRH1\nX00tGeVs93MxQes+vacYq7VYX4pzM1kiU3EMNStyAvCzd8FbGxmiv3C1VKhRj3xK\nOo98Yg18OBL2jQCWHza3nOU5jN8AnjlkXNvrqsaGedjVNirlnR6a+qmklNIiY1lE\nkBxMbfAhTLPY3ukqtaSh\n=4GfM\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "Wladimir J. van der Laan",
                "date": "2016-01-25T11:58:29",
                "message_text_only": "> > In the release notes for 0.12, it says that we have moved from\n> > using OpenSSL to libsecp256k1 for signature validation. So what\n> > else is it being used for that we need to keep it as a dependency?\n> \n> Openssl was dropped from the consensus layer (ECC) in 0.12, though, it\n> still used for...\n> \n> 1) ... getting random numbers (randomize the ECC signing context)\n> 2) [wallet only] ... AES256 encryption of private keys\n> 3) [GUI only] ... SSL/X.509 for BIP70 (payment protocol)\n> \n> Openssl dependency for 1) and 2) could be removed. There are some \u2013\n> outdated \u2013 relevant PRs:\n> \n> Entropy: https://github.com/bitcoin/bitcoin/pull/5885\n> AES: https://github.com/bitcoin/bitcoin/pull/5949\n> \n> I guess for point 3) [BIP70] it makes sense to keep openssl.\n\nExactly - the plan is that OpenSSL will, in due time, be a dependency only if the\nGUI is enabled. Most of the work for that is already done but it has to be made\nup to date and carefully tested and integrated.\n\nWladimir"
            }
        ],
        "thread_summary": {
            "title": "What is OpenSSL still used for?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Andrew C",
                "Ethan Heilman",
                "Wladimir J. van der Laan",
                "Douglas Roark",
                "Jonas Schnelli"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 5494
        }
    },
    {
        "title": "[bitcoin-dev] [BIP/Draft] BIP Acceptance Process",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2016-01-19T02:12:29",
                "message_text_only": "On Saturday, September 05, 2015 9:19:51 PM Andy Chase wrote:\n> Okay for sure yeah writing another proposal that reflects the current state\n> of affairs as people see it might provide some interesting perspective on\n> this proposal. I would welcome that.\n\nAre you saying your proposal is intentionally not intended to reflect the \nreality? I wasn't talking about a \"current state of affairs\" for BIPs as much \nas that that the acceptance of BIPs is *defined by* the state of affairs.\n\nOverall, I think something *similar to* this proposal is a good idea, but I \ndisagree with how this proposal currently approaches the problem. Instead, \nwhat I would recommend is a specification based on BIP 123 that specifies the \nconditions under which a proposal is *known to be* accepted by the community \n(ie, discerning, not deciding), and establishes a way for a committee to \nreview the BIP and *determine* if these conditions have been met. This would \navoid a \"disconnect\" between the \"official status\" and reality, making the BIP \nprocess more useful to everyone.\n\nReviewing your current proposal:\n\n> * It sets up '''committees''' for reviewing comments and indicating\n> acceptance under precise conditions.\n\nAs mentioned, IMO a committee shouldn't be indicating acceptance, as much as \nit should be *determining* acceptance.\n\n> ** Committees are authorized groups that represent client authors, miners,\n> merchants, and users (each as a segment). Each one must represent at least\n> 1% stake in the Bitcoin ecosystem.\n\n1% seems like an awful lot to dedicate to BIP status changes.\n\n> A committee system is used to organize the essential concerns of each\n> segment of the Bitcoin ecosystem. Although each segment may have many\n> different viewpoints on each BIP, in order to seek a decisive yes/no on a\n> BIP, a representational authoritative structure is sought. This structure\n> should be fluid, allowing people to move away from committees that do not\n> reflect their views and should be re-validated on each BIP evaluation.\n\nThat sounds very time consuming. And what happens if these committees don't \nrepresent the community? What about when only part of the community - let's \nsay 10% - decides to adopt a BIP that doesn't require consensus? Logically \nthat BIP should still proceed...\n\n> ** Proof of claim and minimum 1% stake via:\n> *** Software: proof of ownership and user base (Min 1% of Bitcoin userbase)\n\nBut the Bitcoin user base is completely unknown, and tracking software user \nbase is a privacy violation.\n\n> ** Merchant: proof of economic activity (Min 1% of Bitcoin economic\n> activity)\n\nBitcoin economic activity is also unknown, and it seems likely that merchants \nconsider their own activity confidential.\n\n> Mining: proof of work (Min 1% of Hashpower)\n\nThis needs a proper specification. How do miners express their positions?\n\n> A BIP Process Manager should be chosen who is in charge of:\n\nChosen how, and by whom?\n\n> == Conditions for activation ==\n>\n> In order for this process BIP to become active, it must succeed by its own\n> rules. At least a 4% sample of the Bitcoin community must be represented,\n> with at least one committee in each segment included. Once at least one\n> committee has submitted a declaration, a request for comments will be called\n> and the process should be completed from there.\n\nUntil this BIP is active, its rules do not apply, so this would be a form of \ncircular reasoning. I like the idea of putting conditions for activation in \nthe BIP text, but I don't think we can just let the author set any conditions \nthey like either...\n\nLuke"
            },
            {
                "author": "Andy Chase",
                "date": "2016-01-19T04:23:31",
                "message_text_only": "Thanks for your comments Luke.\n\n> Are you saying your proposal is intentionally not intended to reflect the\nreality?\n\nThat's right. I want to be able to include more voices and be able to get a\nclearer idea of acceptance then the process currently has available.\n\nThis process should work alongside the current one; not replace it.\n\n> conditions under which a proposal is *known to be* accepted by the\ncommunity\n\n*known to be* Is what I'm working towards; yes; but I think we need\nadditional tools/processes to determine that then what we currently have\navailable.\n\n> As mentioned, IMO a committee shouldn't be indicating acceptance, as much\nas\nit should be *determining* acceptance.\n\nThe committee determine acceptance when taking their opinions in aggregate.\nThe source of their indication might be similar to what we currently have\n(esp for Core Devs, etc.)\n\n> That sounds very time consuming\n\nOk\n\n> And what happens if these committees don't represent the community?\n\nThe committee structures are fluid-- that is users are able to re-organize\nat any time.\n\n> What about when only part of the community - let's say 10% - decides to\nadopt a BIP that doesn't require consensus\n\nThis might happen, but is not a flaw in my process. My process makes it\nclear they are going against the acceptance of the rest of the community. I\ndon't intend to \"force\" anyone to implement or use an accepted BIP. If that\nis desired that's outside the scope of this BIP.\n\n> But the Bitcoin user base is completely unknown, and tracking software\nuser base is a privacy violation.\n\nI made a suggestion for this here:\nhttps://gist.github.com/andychase/dddb83c294295879308b\n\nIf there are other ways for honest but anonymous voting mechanisms (that\naren't proof-of-stake since that's proof-of-most-money) I'd be all ears.\n\n> Bitcoin economic activity is also unknown\n> This needs a proper specification. How do miners express their positions?\n\nI agree these are flaws in the proposal. I'm not sure that one way of\nindicating should be considered valid forever, but may have to change over\ntime.\n\n> Chosen how, and by whom?\n\nI think the process could be used to determine this.\n\n> but I don't think we can just let the author set any conditions they like\neither\n\nI'm not sure what you mean here but would love more information.\n\nOn Mon, Jan 18, 2016 at 6:12 PM, Luke Dashjr <luke at dashjr.org> wrote:\n\n> On Saturday, September 05, 2015 9:19:51 PM Andy Chase wrote:\n> > Okay for sure yeah writing another proposal that reflects the current\n> state\n> > of affairs as people see it might provide some interesting perspective on\n> > this proposal. I would welcome that.\n>\n> Are you saying your proposal is intentionally not intended to reflect the\n> reality? I wasn't talking about a \"current state of affairs\" for BIPs as\n> much\n> as that that the acceptance of BIPs is *defined by* the state of affairs.\n>\n> Overall, I think something *similar to* this proposal is a good idea, but I\n> disagree with how this proposal currently approaches the problem. Instead,\n> what I would recommend is a specification based on BIP 123 that specifies\n> the\n> conditions under which a proposal is *known to be* accepted by the\n> community\n> (ie, discerning, not deciding), and establishes a way for a committee to\n> review the BIP and *determine* if these conditions have been met. This\n> would\n> avoid a \"disconnect\" between the \"official status\" and reality, making the\n> BIP\n> process more useful to everyone.\n>\n> Reviewing your current proposal:\n>\n> > * It sets up '''committees''' for reviewing comments and indicating\n> > acceptance under precise conditions.\n>\n> As mentioned, IMO a committee shouldn't be indicating acceptance, as much\n> as\n> it should be *determining* acceptance.\n>\n> > ** Committees are authorized groups that represent client authors,\n> miners,\n> > merchants, and users (each as a segment). Each one must represent at\n> least\n> > 1% stake in the Bitcoin ecosystem.\n>\n> 1% seems like an awful lot to dedicate to BIP status changes.\n>\n> > A committee system is used to organize the essential concerns of each\n> > segment of the Bitcoin ecosystem. Although each segment may have many\n> > different viewpoints on each BIP, in order to seek a decisive yes/no on a\n> > BIP, a representational authoritative structure is sought. This structure\n> > should be fluid, allowing people to move away from committees that do not\n> > reflect their views and should be re-validated on each BIP evaluation.\n>\n> That sounds very time consuming. And what happens if these committees don't\n> represent the community? What about when only part of the community - let's\n> say 10% - decides to adopt a BIP that doesn't require consensus? Logically\n> that BIP should still proceed...\n>\n> > ** Proof of claim and minimum 1% stake via:\n> > *** Software: proof of ownership and user base (Min 1% of Bitcoin\n> userbase)\n>\n> But the Bitcoin user base is completely unknown, and tracking software user\n> base is a privacy violation.\n>\n> > ** Merchant: proof of economic activity (Min 1% of Bitcoin economic\n> > activity)\n>\n> Bitcoin economic activity is also unknown, and it seems likely that\n> merchants\n> consider their own activity confidential.\n>\n> > Mining: proof of work (Min 1% of Hashpower)\n>\n> This needs a proper specification. How do miners express their positions?\n>\n> > A BIP Process Manager should be chosen who is in charge of:\n>\n> Chosen how, and by whom?\n>\n> > == Conditions for activation ==\n> >\n> > In order for this process BIP to become active, it must succeed by its\n> own\n> > rules. At least a 4% sample of the Bitcoin community must be represented,\n> > with at least one committee in each segment included. Once at least one\n> > committee has submitted a declaration, a request for comments will be\n> called\n> > and the process should be completed from there.\n>\n> Until this BIP is active, its rules do not apply, so this would be a form\n> of\n> circular reasoning. I like the idea of putting conditions for activation in\n> the BIP text, but I don't think we can just let the author set any\n> conditions\n> they like either...\n>\n> Luke\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160118/7b057fc4/attachment-0001.html>"
            },
            {
                "author": "Dave Scotese",
                "date": "2016-01-19T06:07:52",
                "message_text_only": "This seems like a good place to point out that attempts to identify\nindividuals (either by name or simply as an individual human being) are\nfutile as well as destructive.  \"1%\" usually means \"one out of every 100\npeople\" but this requires identification of individuals as individuals.\nOne person can look like many in Bitcoin, which is why such an effort is\nfutile.  Additionally, one person may be far more affected by a decision\nthan others, which is why it's destructive.\n\nI like the idea of measuring consensus, and there are proto-ideas in my\nhead about how that can be done, based not on individual people, but on\namounts of bitcoin.  Many will argue that we don't want the system to be\ncontrolled by those who hold the most bitcoin.  I understand that\nsentiment, but A) I simply disagree, and B) Finding something better seems\nimpossible to me.\n\nA simple method is the following:\nA message can be constructed saying: \"As of block X, the holder(s) of Y BTC\ncontrolled by [public key] agrees that Z,\" where X, Y, Z, and the [public\nkey] are the only things that change.  This message can be signed by the\nprivate key matching the [public key] in the message.  Anyone interested in\nmeasuring consensus on anything relative to bitcoin holders can advertise\nfor such signed messages to be sent to a repository of their choice which\nwould validate each message (that [public key] (still) holds Y BTC and that\nthe signature is valid) and provide a measure of agreement about Z.  Change\nyour mind?  Just move your BTC to a different address.\n\nOn Mon, Jan 18, 2016 at 6:12 PM, Luke Dashjr via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Saturday, September 05, 2015 9:19:51 PM Andy Chase wrote:\n> > Okay for sure yeah writing another proposal that reflects the current\n> state\n> > of affairs as people see it might provide some interesting perspective on\n> > this proposal. I would welcome that.\n>\n> Are you saying your proposal is intentionally not intended to reflect the\n> reality? I wasn't talking about a \"current state of affairs\" for BIPs as\n> much\n> as that that the acceptance of BIPs is *defined by* the state of affairs.\n>\n> Overall, I think something *similar to* this proposal is a good idea, but I\n> disagree with how this proposal currently approaches the problem. Instead,\n> what I would recommend is a specification based on BIP 123 that specifies\n> the\n> conditions under which a proposal is *known to be* accepted by the\n> community\n> (ie, discerning, not deciding), and establishes a way for a committee to\n> review the BIP and *determine* if these conditions have been met. This\n> would\n> avoid a \"disconnect\" between the \"official status\" and reality, making the\n> BIP\n> process more useful to everyone.\n>\n> Reviewing your current proposal:\n>\n> > * It sets up '''committees''' for reviewing comments and indicating\n> > acceptance under precise conditions.\n>\n> As mentioned, IMO a committee shouldn't be indicating acceptance, as much\n> as\n> it should be *determining* acceptance.\n>\n> > ** Committees are authorized groups that represent client authors,\n> miners,\n> > merchants, and users (each as a segment). Each one must represent at\n> least\n> > 1% stake in the Bitcoin ecosystem.\n>\n> 1% seems like an awful lot to dedicate to BIP status changes.\n>\n> > A committee system is used to organize the essential concerns of each\n> > segment of the Bitcoin ecosystem. Although each segment may have many\n> > different viewpoints on each BIP, in order to seek a decisive yes/no on a\n> > BIP, a representational authoritative structure is sought. This structure\n> > should be fluid, allowing people to move away from committees that do not\n> > reflect their views and should be re-validated on each BIP evaluation.\n>\n> That sounds very time consuming. And what happens if these committees don't\n> represent the community? What about when only part of the community - let's\n> say 10% - decides to adopt a BIP that doesn't require consensus? Logically\n> that BIP should still proceed...\n>\n> > ** Proof of claim and minimum 1% stake via:\n> > *** Software: proof of ownership and user base (Min 1% of Bitcoin\n> userbase)\n>\n> But the Bitcoin user base is completely unknown, and tracking software user\n> base is a privacy violation.\n>\n> > ** Merchant: proof of economic activity (Min 1% of Bitcoin economic\n> > activity)\n>\n> Bitcoin economic activity is also unknown, and it seems likely that\n> merchants\n> consider their own activity confidential.\n>\n> > Mining: proof of work (Min 1% of Hashpower)\n>\n> This needs a proper specification. How do miners express their positions?\n>\n> > A BIP Process Manager should be chosen who is in charge of:\n>\n> Chosen how, and by whom?\n>\n> > == Conditions for activation ==\n> >\n> > In order for this process BIP to become active, it must succeed by its\n> own\n> > rules. At least a 4% sample of the Bitcoin community must be represented,\n> > with at least one committee in each segment included. Once at least one\n> > committee has submitted a declaration, a request for comments will be\n> called\n> > and the process should be completed from there.\n>\n> Until this BIP is active, its rules do not apply, so this would be a form\n> of\n> circular reasoning. I like the idea of putting conditions for activation in\n> the BIP text, but I don't think we can just let the author set any\n> conditions\n> they like either...\n>\n> Luke\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n\n-- \nI like to provide some work at no charge to prove my value. Do you need a\ntechie?\nI own Litmocracy <http://www.litmocracy.com> and Meme Racing\n<http://www.memeracing.net> (in alpha).\nI'm the webmaster for The Voluntaryist <http://www.voluntaryist.com> which\nnow accepts Bitcoin.\nI also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n\"He ought to find it more profitable to play by the rules\" - Satoshi\nNakamoto\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160118/da355e45/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP Acceptance Process",
            "categories": [
                "bitcoin-dev",
                "BIP/Draft"
            ],
            "authors": [
                "Andy Chase",
                "Dave Scotese",
                "Luke Dashjr"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 16082
        }
    },
    {
        "title": "[bitcoin-dev] Segregated Witness App Development",
        "thread_messages": [
            {
                "author": "Eric Lombrozo",
                "date": "2016-01-19T11:54:15",
                "message_text_only": "Hello, folks.\n\nI wanted to let all of you know a new IRC channel has been created called #segwit-dev where we welcome all discussion pertaining to integrating and supporting segregated witness transactions in wallets as well as comments or suggestions for improvement to the spec. Please come join us. :)\n\n\n\u2014\u2014\nEric"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2016-01-19T16:27:09",
                "message_text_only": "Wouldn't this be entirely on topic for #bitcoin-dev? It's probably better\nnot to fragment the communication channels and associated infrastructure\n(logs, bots, etc.)\n\nOn Tue, Jan 19, 2016 at 3:54 AM, Eric Lombrozo via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hello, folks.\n>\n> I wanted to let all of you know a new IRC channel has been created called\n> #segwit-dev where we welcome all discussion pertaining to integrating and\n> supporting segregated witness transactions in wallets as well as comments\n> or suggestions for improvement to the spec. Please come join us. :)\n>\n>\n> \u2014\u2014\n> Eric\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160119/8e206798/attachment.html>"
            },
            {
                "author": "Bryan Bishop",
                "date": "2016-01-19T16:31:17",
                "message_text_only": "On Tue, Jan 19, 2016 at 10:27 AM, Mark Friedenbach via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Wouldn't this be entirely on topic for #bitcoin-dev? It's probably better\n> not to fragment the communication channels and associated infrastructure\n> (logs, bots, etc.)\n\n\nYeah, I agree that this is on topic for #bitcoin-dev. I think that if\nsegwit discussion got to the point of clouding out all other development\ndiscussions, then perhaps it would be time for a new channel. I would\ndefinitely like to see segwit discussion not fragmented into a separate\nvenue.\n\n- Bryan\nhttp://heybryan.org/\n1 512 203 0507\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160119/79cd5c1d/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Segregated Witness App Development",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Eric Lombrozo",
                "Bryan Bishop",
                "Mark Friedenbach"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 2109
        }
    },
    {
        "title": "[bitcoin-dev] Three Month bitcoin-dev Moderation Review",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2016-01-21T00:50:46",
                "message_text_only": "Hi all!\n\n        As planned, this is the three month review[1]: discussion of how\nmoderation should change is encouraged in this thread.\n\n        First, thanks to everyone for the restraint shown in sending\n(and responding to!) inflammatory or sand-in-the-gears mails, and being\ntolerant with our mistakes and variances in moderation.\n\nThe only changes we made to the plan so far:\n1) We've stopped clearing the \"needs mod\" bit after first posts, and\n2) Trivially answerable emails or proposals have been answered in the\n   reject message itself.\n\nYou can see almost all (there was some lossage) rejects at:\n        https://lists.ozlabs.org/pipermail/bitcoin-dev-moderation/\n\nSo, what should moderation look like from now on?\n- Stop moderating altogether?\n- Moderate <topic> more/less harshly?\n- Use a different method/criteria for moderation?\n- Add/remove moderators?\n- Other improvements?\n\nThanks,\nRusty.\n[1] http://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-October/011591.html"
            },
            {
                "author": "xor at freenetproject.org",
                "date": "2016-01-21T02:25:50",
                "message_text_only": "On Thursday, January 21, 2016 11:20:46 AM Rusty Russell via bitcoin-dev wrote:\n> So, what should moderation look like from now on?\n\nThe original mail which announced moderation contains this rule:\n> - Generally discouraged: [...], +1s, [...]\n\nI assume \"+1s\" means statements such as \"I agree with doing X\".\n\nAny sane procedure of deciding something includes asking the involved people \nwhether they're for or against it.\nIf there are dozens of proposals on how to solve a particular technical \nproblem, how else do you want to decide it than having a vote?\nIt's very strange that this is not allowed - especially if we consider that \nthe Bitcoin community is in a state of constant dissent currently.\nThe effect is likely that you push the actual decision-making to IRC, which \nless people have access to (since it's difficult to bear the high traffic), \nand thus form some kind of \"inner circle\" - which makes decisions seem even \nmore as if they're being dictated.\n\nSo please consider allowing people to say whether they agree with something \nsomething or don't.\n\n\nOther than that, thanks for the good latency of moderation, I guess you're \ndoing hard work there :)\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 836 bytes\nDesc: This is a digitally signed message part.\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160121/aee4edba/attachment.sig>"
            },
            {
                "author": "Dave Scotese",
                "date": "2016-01-21T04:35:39",
                "message_text_only": "I agree with the prohibition of +1s.  The core competency of those who\nprovide this list are moderation and technology, not managing a process\nthrough which \"involved people [indicate] whether they're for or against\nit.\"\n\nThat is certainly an excellent function, but it can be offered by anyone\nwho wants to run a system for collecting and displaying those indications.\nThe email list itself is intended to be information rich, and such\n\"approval voting\" is not information-rich enough in my view.\n\nIt is a shame that the moderated messages require so many steps to\nretrieve.  Is it possible to have the \"downloadable version\" from\nhttps://lists.ozlabs.org/pipermail/bitcoin-dev-moderation/ for each month\ncontain the text of the moderated emails?  They do contain the subjects, so\nthat helps.\n\nOn Wed, Jan 20, 2016 at 6:25 PM, xor--- via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Thursday, January 21, 2016 11:20:46 AM Rusty Russell via bitcoin-dev\n> wrote:\n> > So, what should moderation look like from now on?\n>\n> The original mail which announced moderation contains this rule:\n> > - Generally discouraged: [...], +1s, [...]\n>\n> I assume \"+1s\" means statements such as \"I agree with doing X\".\n>\n> Any sane procedure of deciding something includes asking the involved\n> people\n> whether they're for or against it.\n> If there are dozens of proposals on how to solve a particular technical\n> problem, how else do you want to decide it than having a vote?\n> It's very strange that this is not allowed - especially if we consider that\n> the Bitcoin community is in a state of constant dissent currently.\n> The effect is likely that you push the actual decision-making to IRC, which\n> less people have access to (since it's difficult to bear the high traffic),\n> and thus form some kind of \"inner circle\" - which makes decisions seem even\n> more as if they're being dictated.\n>\n> So please consider allowing people to say whether they agree with something\n> something or don't.\n>\n>\n> Other than that, thanks for the good latency of moderation, I guess you're\n> doing hard work there :)\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n\n\n-- \nI like to provide some work at no charge to prove my value. Do you need a\ntechie?\nI own Litmocracy <http://www.litmocracy.com> and Meme Racing\n<http://www.memeracing.net> (in alpha).\nI'm the webmaster for The Voluntaryist <http://www.voluntaryist.com> which\nnow accepts Bitcoin.\nI also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n\"He ought to find it more profitable to play by the rules\" - Satoshi\nNakamoto\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160120/89ab35ee/attachment.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2016-01-21T05:00:20",
                "message_text_only": "Dave Scotese via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> writes:\n> It is a shame that the moderated messages require so many steps to\n> retrieve.  Is it possible to have the \"downloadable version\" from\n> https://lists.ozlabs.org/pipermail/bitcoin-dev-moderation/ for each month\n> contain the text of the moderated emails?  They do contain the subjects, so\n> that helps.\n\nYes, it's because we simply forward them to the bitcoin-dev-moderation\nmailing list, and it strips them out as attachments.\n\nI'd really love a filter which I could run them through (on ozlabs.org)\nto fix this.  Volunteers welcome :)\n\nCheers,\nRusty."
            },
            {
                "author": "Rusty Russell",
                "date": "2016-01-21T04:44:47",
                "message_text_only": "xor--- via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> writes:\n> On Thursday, January 21, 2016 11:20:46 AM Rusty Russell via bitcoin-dev wrote:\n>> So, what should moderation look like from now on?\n>\n> The original mail which announced moderation contains this rule:\n>> - Generally discouraged: [...], +1s, [...]\n>\n> I assume \"+1s\" means statements such as \"I agree with doing X\".\n>\n> Any sane procedure of deciding something includes asking the involved people \n> whether they're for or against it.\n> If there are dozens of proposals on how to solve a particular technical \n> problem, how else do you want to decide it than having a vote?\n\n+1s here means simpling say \"+1\" or \"me too\" that carries no additional\ninformation.  ie. if you like an idea, that's great, but it's not worth\ninterruping the entire list for.\n\nIf you say \"I prefer proposal X over Y because <reasons>\" that's\ndifferent.  As is \"I dislike X because <reasons>\" or \"I need X because\n<reasons>\".\n\nHope that clarifies!\nRusty."
            },
            {
                "author": "xor at freenetproject.org",
                "date": "2016-01-23T05:33:56",
                "message_text_only": "On Thursday, January 21, 2016 03:14:47 PM Rusty Russell wrote:\n> +1s here means simpling say \"+1\" or \"me too\" that carries no additional\n> information.  ie. if you like an idea, that's great, but it's not worth\n> interruping the entire list for.\n> \n> If you say \"I prefer proposal X over Y because <reasons>\" that's\n> different.  As is \"I dislike X because <reasons>\" or \"I need X because\n> <reasons>\".\n\nSo \"+1\"ing is OK as long as I provide a technical explanation of why I agree?\nWhile I still think that this is too much of a restriction because it prevents \npeer-review, I would say that I could live with it as a last resort if you \ndon't plan to abolish this rule altogether.\n\nSo in that case, to foster peer review, I would recommend you amend the rules \nto clarify this.\nExample: \"+1s are not allowed unless you provide an explanation of why you \nagree with something\".\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 836 bytes\nDesc: This is a digitally signed message part.\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160123/710d3845/attachment.sig>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-01-23T20:59:53",
                "message_text_only": "On Sat, Jan 23, 2016 at 06:33:56AM +0100, xor--- via bitcoin-dev wrote:\n> So \"+1\"ing is OK as long as I provide a technical explanation of why I agree?\n> While I still think that this is too much of a restriction because it prevents \n> peer-review, I would say that I could live with it as a last resort if you \n> don't plan to abolish this rule altogether.\n> \n> So in that case, to foster peer review, I would recommend you amend the rules \n> to clarify this.\n> Example: \"+1s are not allowed unless you provide an explanation of why you \n> agree with something\".\n\nI would extend this to say that the technical explanation also should\ncontribute uniquely to the conversation; a +1 with an explanation\nthe last +1 gave isn't useful.\n\n-- \n'peter'[:-1]@petertodd.org\n000000000000000007e2005be0ce25b3f3de67b2dc35fd810b0ccd77b33eb7be\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160123/7aa2753d/attachment.sig>"
            },
            {
                "author": "Gavin",
                "date": "2016-01-23T21:38:44",
                "message_text_only": "> On Jan 23, 2016, at 3:59 PM, Peter Todd via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> I would extend this to say that the technical explanation also should\n> contribute uniquely to the conversation; a +1 with an explanation\n> the last +1 gave isn't useful.\n\nYes, comments should contribute to the discussion, with either technical discussion or additional relevant data. I think a +1 like the following should be encouraged:\n\n\"+1: we had eleven customer support tickets in just the last week that would have been prevented if XYZ.\n\nJane Doe, CTO CoinBitChainBasely.com\""
            },
            {
                "author": "Dave Scotese",
                "date": "2016-01-24T01:06:23",
                "message_text_only": "+1\nThe distinction we are making importantly requires that contributors\nprovide readers with another thing to say in favor of something - another\nthing which is different than \"X people support this instead of only X-1\npeople.\"  Evidence trumps votes.\n\nOn Sat, Jan 23, 2016 at 1:38 PM, Gavin via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> > On Jan 23, 2016, at 3:59 PM, Peter Todd via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >\n> > I would extend this to say that the technical explanation also should\n> > contribute uniquely to the conversation; a +1 with an explanation\n> > the last +1 gave isn't useful.\n>\n> Yes, comments should contribute to the discussion, with either technical\n> discussion or additional relevant data. I think a +1 like the following\n> should be encouraged:\n>\n> \"+1: we had eleven customer support tickets in just the last week that\n> would have been prevented if XYZ.\n>\n> Jane Doe, CTO CoinBitChainBasely.com\"\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n\n-- \nI like to provide some work at no charge to prove my value. Do you need a\ntechie?\nI own Litmocracy <http://www.litmocracy.com> and Meme Racing\n<http://www.memeracing.net> (in alpha).\nI'm the webmaster for The Voluntaryist <http://www.voluntaryist.com> which\nnow accepts Bitcoin.\nI also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n\"He ought to find it more profitable to play by the rules\" - Satoshi\nNakamoto\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160123/573d40da/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Three Month bitcoin-dev Moderation Review",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Gavin",
                "Peter Todd",
                "Dave Scotese",
                "xor at freenetproject.org"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 11675
        }
    },
    {
        "title": "[bitcoin-dev] nSequence multiple uses",
        "thread_messages": [
            {
                "author": "Andrew C",
                "date": "2016-01-22T16:36:58",
                "message_text_only": "With 0.12 and opt-in RBF, nSequence will have multiple uses. It can be used\nfor locktime and now signaling for opting in to RBF. However, there is\nnothing that I could find that distinguishes the uses for nSequence.\nSpending a time locked output requires setting nSequence to less than\nMAX_INT but opting into RBF also requires setting nSequence to less than\nMAX_INT. By spending a time locked output, you would also be opting into\nRBF, which may not be desired behavior. Since using nSequence to signal a\ncertain behavior will probably be used in the future, is there any plan to\nchange nSequence so that the features the transaction is using can be\ndistinguished? Perhaps something like version bits?\n\nThanks,\nAndrew\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160122/790e817d/attachment.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2016-01-23T04:10:42",
                "message_text_only": "On Fri, Jan 22, 2016 at 04:36:58PM +0000, Andrew C via bitcoin-dev wrote:\n> Spending a time locked output requires setting nSequence to less than\n> MAX_INT but opting into RBF also requires setting nSequence to less than\n> MAX_INT. \n\nHi Andrew,\n\nOpt-in RBF requires setting nSequence to less than MAX-1 (not merely\nless than MAX), so an nSequence of exactly MAX-1 (which appears in\nhex-encoded serialized transactions as feffffff) enables locktime\nenforcement but doesn't opt in to RBF.\n\nFor more information, please see BIP125:\n\n    https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki\n\n-Dave\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 473 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160122/151c0b39/attachment.sig>"
            },
            {
                "author": "Andrew C",
                "date": "2016-01-23T04:41:55",
                "message_text_only": "Ahh. I see. Thanks, I must have missed that when going through the BIP.\nGuess I need to read more carefully next time.\n\nThanks,\nAndrew\n\nOn Fri, Jan 22, 2016 at 11:11 PM David A. Harding <dave at dtrt.org> wrote:\n\n> On Fri, Jan 22, 2016 at 04:36:58PM +0000, Andrew C via bitcoin-dev wrote:\n> > Spending a time locked output requires setting nSequence to less than\n> > MAX_INT but opting into RBF also requires setting nSequence to less than\n> > MAX_INT.\n>\n> Hi Andrew,\n>\n> Opt-in RBF requires setting nSequence to less than MAX-1 (not merely\n> less than MAX), so an nSequence of exactly MAX-1 (which appears in\n> hex-encoded serialized transactions as feffffff) enables locktime\n> enforcement but doesn't opt in to RBF.\n>\n> For more information, please see BIP125:\n>\n>     https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki\n>\n> -Dave\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160123/1fa99b48/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "nSequence multiple uses",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Andrew C",
                "David A. Harding"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 2809
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Core 0.12.0 release candidate 2 available",
        "thread_messages": [
            {
                "author": "Wladimir J. van der Laan",
                "date": "2016-01-25T12:09:38",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nBinaries for bitcoin Core version 0.12.0rc2 are available from:\n\n    https://bitcoin.org/bin/bitcoin-core-0.12.0/test/\n\nSource code can be found on github under the signed tag\n\n    https://github.com/bitcoin/bitcoin/tree/v0.12.0rc2\n\nThis is a release candidate for a new major version release, bringing new\nfeatures, bug fixes, as well as other improvements.\n\nPreliminary release notes for the release can be found here:\n\n    https://github.com/bitcoin/bitcoin/blob/0.12/doc/release-notes.md\n\nRelease candidates are test versions for releases. When no critical problems\nare found, this release candidate will be tagged as 0.12.0.\n\nDiff since rc1:\n- - #7222 `e25b158` RPC: indicate which transactions are replaceable\n- - #7386 `da83ecd` Add option `-permitrbf` to set transaction replacement policy\n- - #7290 `b16b5bc` Add missing options help\n- - #7387 `f4b2ce8` Get rid of inaccurate ScriptSigArgsExpected\n- - #7381 `621bbd8` [walletdb] Fix syntax error in key parser\n- - #7327 `b16b5bc` [Wallet] Transaction View: LastMonth calculation fixed\n- - #7364 `7726c48` [qt] Windows: Make rpcconsole monospace font larger\n\nPlease report bugs using the issue tracker at github:\n\n    https://github.com/bitcoin/bitcoin/issues\n\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1\n\niQEcBAEBCgAGBQJWphBHAAoJEHSBCwEjRsmmh0EIALopACCwaCYRt9vl6fadDLxL\nJMTyEPsGUaEX82iwuXeAhdReyvZDlC00ACZy6agp7oOuS1ryqOeYAsc33N+WtHE0\niETNyvRZVD1ASopHkdJrRW1a9X63Yvcvk/d6nVbO5auUAG5gPUFLrSTrqpSzR2D4\nQtY1ofifXrYdqdQmPFJ5hnWg/Z1rko99sD8Pu3ebD6Dof5zuvJKHkLmXunGGXn/n\nGOn8roS5LXEFHwCcL0zgNzfDywt/dhKiUHMKSNPsnz5qEDRg7WPzsNiQA/HVDlcp\nv6akQ4ykZ56Lik8cVLi0NRW2dozSDti/XKBfWQHqWjGUJGUOS+lPJaWLv81oMwc=\n=WlQm\n-----END PGP SIGNATURE-----"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Core 0.12.0 release candidate 2 available",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Wladimir J. van der Laan"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1740
        }
    },
    {
        "title": "[bitcoin-dev] [BIP Draft] Allow zero value OP_RETURN in Payment Protocol",
        "thread_messages": [
            {
                "author": "Toby Padilla",
                "date": "2016-01-26T01:02:44",
                "message_text_only": "Hi all,\n\nI'm submitting a new BIP draft for consideration and discussion. I've put a\npull request up on Github that implements this BIP (with discussion from\nthe Core team):\n\nhttps://github.com/bitcoin/bitcoin/pull/7376\n\nMy original discussion of this issue:\n\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-December/011874.html\n\nBIP draft as follows...\n\n--\n\n```\nTitle: Allow zero value OP_RETURN in Payment Protocol\nAuthor: Toby Padilla <tobypadilla at gmail.com>\n```\n\n## Abstract\n\nThis BIP alters the Payment Protocol to allow for zero value OP_RETURN\noutputs in serialized PaymentRequests.\n\n## Motivation\n\nThe Payment Protocol (defined in BIP70) gives merchants a way to build\nsophisticated transactions by serializing one or more outputs in the form\nof a PaymentRequest. The PaymentRequest is then served over http/https to a\ncustomer's wallet where the serialized transaction can be executed.\n\nWhile the Payment Protocol allows for any valid script in its outputs, it\nalso ignores outputs with zero value. This means BIP70 implementations can\nencode an OP_RETURN script but must provide a greater than dust value for\nthat output. The end result is a successful PaymentRequest transaction with\nan OP_RETURN but the value assigned to that output is lost forever.\n\nThis BIP allows for zero value OP_RETURN outputs in serialized\nPaymentRequests. The change means that OP_RETURN scripts will work as they\nwere originally intended from within PaymentRequests without permanently\ndestroying Bitcoin value. Zero value non-OP_RETURN scripts should continue\nto be ignored and positive value OP_RETURN outputs should now be rejected.\n\nIn addition to fixing the issue of destroyed value, this change opens up\nnew use cases that were previously impossible.\n\nWhile storing data on the blockchain is controversial, when used\nresponsibly OP_RETURN provides a powerful mechanism for attaching metadata\nto a transaction. This BIP effectively decouples the creation of\ntransactions containing OP_RETURN data from the execution of those\ntransactions. The result are positive benefits for both merchants and\nwallets/customers.\n\nBy supporting this BIP, wallets can participate in current and future,\nunforeseen use cases that benefit from metadata stored in OP_RETURN. Until\nnow OP_RETURN transactions have typically been created and submitted by\ncustom software. If a wallet can process a PaymentRequest with OP_RETURN\ndata as proposed by this BIP, it will support potentially sophisticated\nBitcoin applications without the wallet developer having to have prior\nknowledge of that application.\n\nAn example might be a merchant that adds the hash of a plain text invoice\nto the checkout transaction. The merchant could construct the\nPaymentRequest with the invoice hash in an OP_RETURN and pass it to the\ncustomer's wallet. The wallet could then submit the transaction, including\nthe invoice hash from the PaymentRequest. The wallet will have encoded a\nproof of purchase to the blockchain without the wallet developer having to\ncoordinate with the merchant software or add features beyond this BIP.\n\nMerchants and Bitcoin application developers benefit from this BIP because\nthey can now construct transactions that include OP_RETURN data in a\nkeyless environment. Again, prior to this BIP, transactions that used\nOP_RETURN (with zero value) needed to be constructed and executed in the\nsame software. By separating the two concerns, this BIP allows merchant\nsoftware to create transactions with OP_RETURN metadata on a server without\nstoring public or private Bitcoin keys. This greatly enhances security\nwhere OP_RETURN applications currently need access to a private key to sign\ntransactions.\n\n## Specification\n\nThe specification for this BIP is straightforward. BIP70 should be fully\nimplemented with two changes:\n\n1. Outputs where the script is an OP_RETURN and the value is zero should be\naccepted by the wallet.\n2. Outputs where the script is an OP_RETURN and the value is greater than\nzero should be rejected.\n\nThis is a change from the BIP70 requirement that all zero value outputs be\nignored.\n\n## Rationale\n\nAs with the discussion around vanilla OP_RETURN, the practice of storing\ndata on the blockchain is controversial. While blockchain and network bloat\nis an undeniable issue, the benefits that come from attaching metadata to\ntransactions has proven to be too powerful to dismiss entirely. In the\nabsence of OP_RETURN support the Bitcoin ecosystem has seen alternative,\nless elegant and more wasteful methods employed for Blockchain data storage.\n\nAs it exists today, BIP70 allows for OP_RETURN data storage at the expense\nof permanently destroyed Bitcoin. Even fully removing support for OP_RETURN\nvalues in the Payment Protocol would still leave the door open to\nsuboptimal data encoding via burning a larger than dust value to an output\nwith a false address designed to encode data.\n\nThis BIP offers all of the same benefits that come from the OP_RETURN\ncompromise. Mainly that OP_RETURN scripts are provably unspendable and thus\ncan be pruned from the UTXO pool. Without supporting this BIP, wallets that\nsupport BIP70 will allow for wasteful data storage.\n\n## Compatibility\n\nWhile not in widespread use, existing BIP70 PaymentRequest outputs that\nhave a greater than zero value with an OP_RETURN script (burning Bitcoin)\nwill need to have their values changed to zero or they will be rejected by\nwallets implementing this BIP.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160125/e25484bd/attachment.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-01-26T02:24:16",
                "message_text_only": "This is a bad idea. OP_RETURN attachments are tolerated (not encouraged!) for \nthe sake of the network, since the spam cannot be outright stopped. If it \ncould be outright stopped, it would not be reasonable to allow OP_RETURN. When \nit comes to the payment protocol, however, changing the current behaviour has \nliterally no benefit to the network at all, and the changes proposed herein \nare clearly detrimental since it would both encourage spam, and potentially \nmake users unwilling (maybe even unaware) participants in it. For these \nreasons, *I highly advise against publishing or implementing this BIP, even if \nthe later mentioned issues are fixed.*\n\nOn Tuesday, January 26, 2016 1:02:44 AM Toby Padilla wrote:\n> An example might be a merchant that adds the hash of a plain text invoice\n> to the checkout transaction. The merchant could construct the\n> PaymentRequest with the invoice hash in an OP_RETURN and pass it to the\n> customer's wallet. The wallet could then submit the transaction, including\n> the invoice hash from the PaymentRequest. The wallet will have encoded a\n> proof of purchase to the blockchain without the wallet developer having to\n> coordinate with the merchant software or add features beyond this BIP.\n\nSuch a \"proof\" is useless without wallet support. Even if you argue it could \nbe implemented later on, it stands to reason that a scammer will simply encode \ngarbage if the wallet is not checking the proof-of-purchase upfront. To check \nit, you would also need further protocol extensions which are not included in \nthis draft.\n\n> Merchants and Bitcoin application developers benefit from this BIP because\n> they can now construct transactions that include OP_RETURN data in a\n> keyless environment. Again, prior to this BIP, transactions that used\n> OP_RETURN (with zero value) needed to be constructed and executed in the\n> same software. By separating the two concerns, this BIP allows merchant\n> software to create transactions with OP_RETURN metadata on a server without\n> storing public or private Bitcoin keys. This greatly enhances security\n> where OP_RETURN applications currently need access to a private key to sign\n> transactions.\n\nI don't see how this has any relevance to keys at all...\n\n> ## Specification\n> \n> The specification for this BIP is straightforward. BIP70 should be fully\n> implemented with two changes:\n> \n> 1. Outputs where the script is an OP_RETURN and the value is zero should be\n> accepted by the wallet.\n> 2. Outputs where the script is an OP_RETURN and the value is greater than\n> zero should be rejected.\n> \n> This is a change from the BIP70 requirement that all zero value outputs be\n> ignored.\n\nThis does not appear to be backward nor even forward compatible. Old clients \nwill continue to use the previous behaviour and transparently omit any \ncommitments. New clients on the other hand will fail to include commitments \nproduced by old servers. In other words, it is impossible to produce software \ncompatible with both BIP 70 and this draft, and implementing either would \nresult in severe consequences.\n\n> As it exists today, BIP70 allows for OP_RETURN data storage at the expense\n> of permanently destroyed Bitcoin.\n\nIt is better for the spammers to lose burned bitcoins, than have a way to \navoid them.\n\nLuke"
            },
            {
                "author": "Toby Padilla",
                "date": "2016-01-26T02:54:16",
                "message_text_only": "It looks like my draft hasn't been approved by the mailing list so if\nanyone would like to read it it's also on Gist:\n\nhttps://gist.github.com/toby/9e71811d387923a71a53\n\nLuke - As stated in the Github thread, I totally understand where you're\ncoming from but the fact is people *will* encode data on the blockchain\nusing worse methods. For all of the reasons that OP_RETURN was a good idea\nin the first place, it's a good idea to support it in PaymentRequests.\n\nAs for keyless - there's no way (that I know of) to construct a transaction\nwith a zero value OP_RETURN in an environment without keys since the\nPayment Protocol is what defines the method for getting a transaction from\na server to a wallet. You can make a custom transaction and execute it in\nthe same application but without Payments there's no way to move\ntransactions between two applications. You need to build the transaction\nwhere you execute it and thus need a key.\n\n\n\nOn Mon, Jan 25, 2016 at 6:24 PM, Luke Dashjr <luke at dashjr.org> wrote:\n\n> This is a bad idea. OP_RETURN attachments are tolerated (not encouraged!)\n> for\n> the sake of the network, since the spam cannot be outright stopped. If it\n> could be outright stopped, it would not be reasonable to allow OP_RETURN.\n> When\n> it comes to the payment protocol, however, changing the current behaviour\n> has\n> literally no benefit to the network at all, and the changes proposed herein\n> are clearly detrimental since it would both encourage spam, and potentially\n> make users unwilling (maybe even unaware) participants in it. For these\n> reasons, *I highly advise against publishing or implementing this BIP,\n> even if\n> the later mentioned issues are fixed.*\n>\n> On Tuesday, January 26, 2016 1:02:44 AM Toby Padilla wrote:\n> > An example might be a merchant that adds the hash of a plain text invoice\n> > to the checkout transaction. The merchant could construct the\n> > PaymentRequest with the invoice hash in an OP_RETURN and pass it to the\n> > customer's wallet. The wallet could then submit the transaction,\n> including\n> > the invoice hash from the PaymentRequest. The wallet will have encoded a\n> > proof of purchase to the blockchain without the wallet developer having\n> to\n> > coordinate with the merchant software or add features beyond this BIP.\n>\n> Such a \"proof\" is useless without wallet support. Even if you argue it\n> could\n> be implemented later on, it stands to reason that a scammer will simply\n> encode\n> garbage if the wallet is not checking the proof-of-purchase upfront. To\n> check\n> it, you would also need further protocol extensions which are not included\n> in\n> this draft.\n>\n> > Merchants and Bitcoin application developers benefit from this BIP\n> because\n> > they can now construct transactions that include OP_RETURN data in a\n> > keyless environment. Again, prior to this BIP, transactions that used\n> > OP_RETURN (with zero value) needed to be constructed and executed in the\n> > same software. By separating the two concerns, this BIP allows merchant\n> > software to create transactions with OP_RETURN metadata on a server\n> without\n> > storing public or private Bitcoin keys. This greatly enhances security\n> > where OP_RETURN applications currently need access to a private key to\n> sign\n> > transactions.\n>\n> I don't see how this has any relevance to keys at all...\n>\n> > ## Specification\n> >\n> > The specification for this BIP is straightforward. BIP70 should be fully\n> > implemented with two changes:\n> >\n> > 1. Outputs where the script is an OP_RETURN and the value is zero should\n> be\n> > accepted by the wallet.\n> > 2. Outputs where the script is an OP_RETURN and the value is greater than\n> > zero should be rejected.\n> >\n> > This is a change from the BIP70 requirement that all zero value outputs\n> be\n> > ignored.\n>\n> This does not appear to be backward nor even forward compatible. Old\n> clients\n> will continue to use the previous behaviour and transparently omit any\n> commitments. New clients on the other hand will fail to include commitments\n> produced by old servers. In other words, it is impossible to produce\n> software\n> compatible with both BIP 70 and this draft, and implementing either would\n> result in severe consequences.\n>\n> > As it exists today, BIP70 allows for OP_RETURN data storage at the\n> expense\n> > of permanently destroyed Bitcoin.\n>\n> It is better for the spammers to lose burned bitcoins, than have a way to\n> avoid them.\n>\n> Luke\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160125/3d421af4/attachment-0001.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-01-26T02:56:54",
                "message_text_only": "On Tuesday, January 26, 2016 2:54:16 AM Toby Padilla wrote:\n> Luke - As stated in the Github thread, I totally understand where you're\n> coming from but the fact is people *will* encode data on the blockchain\n> using worse methods. For all of the reasons that OP_RETURN was a good idea\n> in the first place, it's a good idea to support it in PaymentRequests.\n\nAs I explained, none of those reasons apply to PaymentRequests.\n\n> As for keyless - there's no way (that I know of) to construct a transaction\n> with a zero value OP_RETURN in an environment without keys since the\n> Payment Protocol is what defines the method for getting a transaction from\n> a server to a wallet. You can make a custom transaction and execute it in\n> the same application but without Payments there's no way to move\n> transactions between two applications. You need to build the transaction\n> where you execute it and thus need a key.\n\nI have no idea what you are trying to say here.\n\nLuke"
            },
            {
                "author": "Toby Padilla",
                "date": "2016-01-26T03:01:13",
                "message_text_only": "> As I explained, none of those reasons apply to PaymentRequests.\n\nAs they exist today PaymentRequests allow for essentially the same types of\ntransactions as non-PaymentRequest based transactions with the limitation\nthat OP_RETURN values must be greater. In that sense they're basically a\npre-OP_RETURN environment. OP_RETURN serves a purpose and it can't be used\nwith PaymentRequest transactions.\n\n> I have no idea what you are trying to say here.\n\nI think if you think through how you would create an OP_RETURN transaction\ntoday without this BIP you'll see you need a key at some point if you want\na zero value.\n\nOn Mon, Jan 25, 2016 at 6:56 PM, Luke Dashjr <luke at dashjr.org> wrote:\n\n> On Tuesday, January 26, 2016 2:54:16 AM Toby Padilla wrote:\n> > Luke - As stated in the Github thread, I totally understand where you're\n> > coming from but the fact is people *will* encode data on the blockchain\n> > using worse methods. For all of the reasons that OP_RETURN was a good\n> idea\n> > in the first place, it's a good idea to support it in PaymentRequests.\n>\n> As I explained, none of those reasons apply to PaymentRequests.\n>\n> > As for keyless - there's no way (that I know of) to construct a\n> transaction\n> > with a zero value OP_RETURN in an environment without keys since the\n> > Payment Protocol is what defines the method for getting a transaction\n> from\n> > a server to a wallet. You can make a custom transaction and execute it in\n> > the same application but without Payments there's no way to move\n> > transactions between two applications. You need to build the transaction\n> > where you execute it and thus need a key.\n>\n> I have no idea what you are trying to say here.\n>\n> Luke\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160125/cd6c0b93/attachment.html>"
            },
            {
                "author": "Andreas Schildbach",
                "date": "2016-01-26T14:37:15",
                "message_text_only": "Discussion about reasoning of OP_RETURN aside, I think your\nspecification needs to be more precise/less ambiguous.\n\nHere is what BIP70 currently says about PaymentDetails.outputs:\n\n\"one or more outputs where Bitcoins are to be sent. If the sum of\noutputs.amount is zero, the customer will be asked how much to pay, and\nthe bitcoin client may choose any or all of the Outputs (if there are\nmore than one) for payment. If the sum of outputs.amount is non-zero,\nthen the customer will be asked to pay the sum, and the payment shall be\nsplit among the Outputs with non-zero amounts (if there are more than\none; Outputs with zero amounts shall be ignored).\"\n\nAs you can see, zero outputs are not ignored at all. They are used as an\nindication to allow the user to set an amount. So if you'd come up with\none zero-amount OP_RETURN output, it would pop up an amount dialog.\nCertainly not what you want, right?\n\n\nOn 01/26/2016 03:54 AM, Toby Padilla via bitcoin-dev wrote:\n> It looks like my draft hasn't been approved by the mailing list so if\n> anyone would like to read it it's also on Gist:\n> \n> https://gist.github.com/toby/9e71811d387923a71a53\n> \n> Luke - As stated in the Github thread, I totally understand where you're\n> coming from but the fact is people *will* encode data on the blockchain\n> using worse methods. For all of the reasons that OP_RETURN was a good\n> idea in the first place, it's a good idea to support it in PaymentRequests.\n> \n> As for keyless - there's no way (that I know of) to construct a\n> transaction with a zero value OP_RETURN in an environment without keys\n> since the Payment Protocol is what defines the method for getting a\n> transaction from a server to a wallet. You can make a custom transaction\n> and execute it in the same application but without Payments there's no\n> way to move transactions between two applications. You need to build the\n> transaction where you execute it and thus need a key.\n> \n> \n> \n> On Mon, Jan 25, 2016 at 6:24 PM, Luke Dashjr <luke at dashjr.org\n> <mailto:luke at dashjr.org>> wrote:\n> \n>     This is a bad idea. OP_RETURN attachments are tolerated (not\n>     encouraged!) for\n>     the sake of the network, since the spam cannot be outright stopped.\n>     If it\n>     could be outright stopped, it would not be reasonable to allow\n>     OP_RETURN. When\n>     it comes to the payment protocol, however, changing the current\n>     behaviour has\n>     literally no benefit to the network at all, and the changes proposed\n>     herein\n>     are clearly detrimental since it would both encourage spam, and\n>     potentially\n>     make users unwilling (maybe even unaware) participants in it. For these\n>     reasons, *I highly advise against publishing or implementing this\n>     BIP, even if\n>     the later mentioned issues are fixed.*\n> \n>     On Tuesday, January 26, 2016 1:02:44 AM Toby Padilla wrote:\n>     > An example might be a merchant that adds the hash of a plain text invoice\n>     > to the checkout transaction. The merchant could construct the\n>     > PaymentRequest with the invoice hash in an OP_RETURN and pass it to the\n>     > customer's wallet. The wallet could then submit the transaction, including\n>     > the invoice hash from the PaymentRequest. The wallet will have encoded a\n>     > proof of purchase to the blockchain without the wallet developer having to\n>     > coordinate with the merchant software or add features beyond this BIP.\n> \n>     Such a \"proof\" is useless without wallet support. Even if you argue\n>     it could\n>     be implemented later on, it stands to reason that a scammer will\n>     simply encode\n>     garbage if the wallet is not checking the proof-of-purchase upfront.\n>     To check\n>     it, you would also need further protocol extensions which are not\n>     included in\n>     this draft.\n> \n>     > Merchants and Bitcoin application developers benefit from this BIP because\n>     > they can now construct transactions that include OP_RETURN data in a\n>     > keyless environment. Again, prior to this BIP, transactions that used\n>     > OP_RETURN (with zero value) needed to be constructed and executed in the\n>     > same software. By separating the two concerns, this BIP allows merchant\n>     > software to create transactions with OP_RETURN metadata on a server without\n>     > storing public or private Bitcoin keys. This greatly enhances security\n>     > where OP_RETURN applications currently need access to a private key to sign\n>     > transactions.\n> \n>     I don't see how this has any relevance to keys at all...\n> \n>     > ## Specification\n>     >\n>     > The specification for this BIP is straightforward. BIP70 should be fully\n>     > implemented with two changes:\n>     >\n>     > 1. Outputs where the script is an OP_RETURN and the value is zero should be\n>     > accepted by the wallet.\n>     > 2. Outputs where the script is an OP_RETURN and the value is greater than\n>     > zero should be rejected.\n>     >\n>     > This is a change from the BIP70 requirement that all zero value outputs be\n>     > ignored.\n> \n>     This does not appear to be backward nor even forward compatible. Old\n>     clients\n>     will continue to use the previous behaviour and transparently omit any\n>     commitments. New clients on the other hand will fail to include\n>     commitments\n>     produced by old servers. In other words, it is impossible to produce\n>     software\n>     compatible with both BIP 70 and this draft, and implementing either\n>     would\n>     result in severe consequences.\n> \n>     > As it exists today, BIP70 allows for OP_RETURN data storage at the expense\n>     > of permanently destroyed Bitcoin.\n> \n>     It is better for the spammers to lose burned bitcoins, than have a\n>     way to\n>     avoid them.\n> \n>     Luke\n> \n> \n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Toby Padilla",
                "date": "2016-01-26T17:41:01",
                "message_text_only": "The wording is a little strange and I think it *should* work as you state,\nbut Bitcoin Core will actually reject any output that has zero value (even\na single OP_RETURN output -- I just tested again to make sure).\n\nHere's the blocking code:\n\nhttps://github.com/bitcoin/bitcoin/blob/master/src/qt/paymentserver.cpp#L584\n\nI agree that this should be made more clear in my BIP though, I'll clean up\nthe language.\n\nOn Tue, Jan 26, 2016 at 6:37 AM, Andreas Schildbach via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Discussion about reasoning of OP_RETURN aside, I think your\n> specification needs to be more precise/less ambiguous.\n>\n> Here is what BIP70 currently says about PaymentDetails.outputs:\n>\n> \"one or more outputs where Bitcoins are to be sent. If the sum of\n> outputs.amount is zero, the customer will be asked how much to pay, and\n> the bitcoin client may choose any or all of the Outputs (if there are\n> more than one) for payment. If the sum of outputs.amount is non-zero,\n> then the customer will be asked to pay the sum, and the payment shall be\n> split among the Outputs with non-zero amounts (if there are more than\n> one; Outputs with zero amounts shall be ignored).\"\n>\n> As you can see, zero outputs are not ignored at all. They are used as an\n> indication to allow the user to set an amount. So if you'd come up with\n> one zero-amount OP_RETURN output, it would pop up an amount dialog.\n> Certainly not what you want, right?\n>\n>\n> On 01/26/2016 03:54 AM, Toby Padilla via bitcoin-dev wrote:\n> > It looks like my draft hasn't been approved by the mailing list so if\n> > anyone would like to read it it's also on Gist:\n> >\n> > https://gist.github.com/toby/9e71811d387923a71a53\n> >\n> > Luke - As stated in the Github thread, I totally understand where you're\n> > coming from but the fact is people *will* encode data on the blockchain\n> > using worse methods. For all of the reasons that OP_RETURN was a good\n> > idea in the first place, it's a good idea to support it in\n> PaymentRequests.\n> >\n> > As for keyless - there's no way (that I know of) to construct a\n> > transaction with a zero value OP_RETURN in an environment without keys\n> > since the Payment Protocol is what defines the method for getting a\n> > transaction from a server to a wallet. You can make a custom transaction\n> > and execute it in the same application but without Payments there's no\n> > way to move transactions between two applications. You need to build the\n> > transaction where you execute it and thus need a key.\n> >\n> >\n> >\n> > On Mon, Jan 25, 2016 at 6:24 PM, Luke Dashjr <luke at dashjr.org\n> > <mailto:luke at dashjr.org>> wrote:\n> >\n> >     This is a bad idea. OP_RETURN attachments are tolerated (not\n> >     encouraged!) for\n> >     the sake of the network, since the spam cannot be outright stopped.\n> >     If it\n> >     could be outright stopped, it would not be reasonable to allow\n> >     OP_RETURN. When\n> >     it comes to the payment protocol, however, changing the current\n> >     behaviour has\n> >     literally no benefit to the network at all, and the changes proposed\n> >     herein\n> >     are clearly detrimental since it would both encourage spam, and\n> >     potentially\n> >     make users unwilling (maybe even unaware) participants in it. For\n> these\n> >     reasons, *I highly advise against publishing or implementing this\n> >     BIP, even if\n> >     the later mentioned issues are fixed.*\n> >\n> >     On Tuesday, January 26, 2016 1:02:44 AM Toby Padilla wrote:\n> >     > An example might be a merchant that adds the hash of a plain text\n> invoice\n> >     > to the checkout transaction. The merchant could construct the\n> >     > PaymentRequest with the invoice hash in an OP_RETURN and pass it\n> to the\n> >     > customer's wallet. The wallet could then submit the transaction,\n> including\n> >     > the invoice hash from the PaymentRequest. The wallet will have\n> encoded a\n> >     > proof of purchase to the blockchain without the wallet developer\n> having to\n> >     > coordinate with the merchant software or add features beyond this\n> BIP.\n> >\n> >     Such a \"proof\" is useless without wallet support. Even if you argue\n> >     it could\n> >     be implemented later on, it stands to reason that a scammer will\n> >     simply encode\n> >     garbage if the wallet is not checking the proof-of-purchase upfront.\n> >     To check\n> >     it, you would also need further protocol extensions which are not\n> >     included in\n> >     this draft.\n> >\n> >     > Merchants and Bitcoin application developers benefit from this BIP\n> because\n> >     > they can now construct transactions that include OP_RETURN data in\n> a\n> >     > keyless environment. Again, prior to this BIP, transactions that\n> used\n> >     > OP_RETURN (with zero value) needed to be constructed and executed\n> in the\n> >     > same software. By separating the two concerns, this BIP allows\n> merchant\n> >     > software to create transactions with OP_RETURN metadata on a\n> server without\n> >     > storing public or private Bitcoin keys. This greatly enhances\n> security\n> >     > where OP_RETURN applications currently need access to a private\n> key to sign\n> >     > transactions.\n> >\n> >     I don't see how this has any relevance to keys at all...\n> >\n> >     > ## Specification\n> >     >\n> >     > The specification for this BIP is straightforward. BIP70 should be\n> fully\n> >     > implemented with two changes:\n> >     >\n> >     > 1. Outputs where the script is an OP_RETURN and the value is zero\n> should be\n> >     > accepted by the wallet.\n> >     > 2. Outputs where the script is an OP_RETURN and the value is\n> greater than\n> >     > zero should be rejected.\n> >     >\n> >     > This is a change from the BIP70 requirement that all zero value\n> outputs be\n> >     > ignored.\n> >\n> >     This does not appear to be backward nor even forward compatible. Old\n> >     clients\n> >     will continue to use the previous behaviour and transparently omit\n> any\n> >     commitments. New clients on the other hand will fail to include\n> >     commitments\n> >     produced by old servers. In other words, it is impossible to produce\n> >     software\n> >     compatible with both BIP 70 and this draft, and implementing either\n> >     would\n> >     result in severe consequences.\n> >\n> >     > As it exists today, BIP70 allows for OP_RETURN data storage at the\n> expense\n> >     > of permanently destroyed Bitcoin.\n> >\n> >     It is better for the spammers to lose burned bitcoins, than have a\n> >     way to\n> >     avoid them.\n> >\n> >     Luke\n> >\n> >\n> >\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160126/ccf44462/attachment-0001.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-01-26T03:04:33",
                "message_text_only": "On Tuesday, January 26, 2016 3:01:13 AM Toby Padilla wrote:\n> > As I explained, none of those reasons apply to PaymentRequests.\n> \n> As they exist today PaymentRequests allow for essentially the same types of\n> transactions as non-PaymentRequest based transactions with the limitation\n> that OP_RETURN values must be greater. In that sense they're basically a\n> pre-OP_RETURN environment. OP_RETURN serves a purpose and it can't be used\n> with PaymentRequest transactions.\n\nOP_RETURN can be used, but you need to burn coins. I don't see any benefit to \nchanging that. It is better that coins are burned.\n\n> > I have no idea what you are trying to say here.\n> \n> I think if you think through how you would create an OP_RETURN transaction\n> today without this BIP you'll see you need a key at some point if you want\n> a zero value.\n\nYou *always* need a key, to redeem inputs... regardless of values.\n\nLuke"
            },
            {
                "author": "Toby Padilla",
                "date": "2016-01-26T03:07:40",
                "message_text_only": "> I don't see any benefit to\nchanging that. It is better that coins are burned.\n\nI think this is our fundamental disagreement. People will burn coins to\nencode data, why allow this when there's a better alternative?\n\n> You *always* need a key, to redeem inputs... regardless of values.\n\nCorrect, but with BIP70 that key is in the user's wallet and you can\nconstruct transactions on another machine (thus not needing a key during\nconstruction). Right now there's no way to do the transaction construction\non another machine with zero value OP_RETURNs.\n\nOn Mon, Jan 25, 2016 at 7:04 PM, Luke Dashjr <luke at dashjr.org> wrote:\n\n> On Tuesday, January 26, 2016 3:01:13 AM Toby Padilla wrote:\n> > > As I explained, none of those reasons apply to PaymentRequests.\n> >\n> > As they exist today PaymentRequests allow for essentially the same types\n> of\n> > transactions as non-PaymentRequest based transactions with the limitation\n> > that OP_RETURN values must be greater. In that sense they're basically a\n> > pre-OP_RETURN environment. OP_RETURN serves a purpose and it can't be\n> used\n> > with PaymentRequest transactions.\n>\n> OP_RETURN can be used, but you need to burn coins. I don't see any benefit\n> to\n> changing that. It is better that coins are burned.\n>\n> > > I have no idea what you are trying to say here.\n> >\n> > I think if you think through how you would create an OP_RETURN\n> transaction\n> > today without this BIP you'll see you need a key at some point if you\n> want\n> > a zero value.\n>\n> You *always* need a key, to redeem inputs... regardless of values.\n>\n> Luke\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160125/b17c123c/attachment.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-01-26T03:12:24",
                "message_text_only": "On Tuesday, January 26, 2016 3:07:40 AM Toby Padilla wrote:\n> > I don't see any benefit to changing that. It is better that coins are\n> > burned.\n> \n> I think this is our fundamental disagreement. People will burn coins to\n> encode data, why allow this when there's a better alternative?\n\nMy point is that there isn't a better alternative. The coins being burned, is \nstrictly better than it being gratis.\n\n> > You *always* need a key, to redeem inputs... regardless of values.\n> \n> Correct, but with BIP70 that key is in the user's wallet and you can\n> construct transactions on another machine (thus not needing a key during\n> construction). Right now there's no way to do the transaction construction\n> on another machine with zero value OP_RETURNs.\n\nThis is also a good thing. Spam should not be made easier or cheaper.\n\nLuke"
            },
            {
                "author": "Toby Padilla",
                "date": "2016-01-26T03:17:12",
                "message_text_only": "I don't think every application of OP_RETURN could be classified as \"spam\".\nI also don't think burning the value is going to dissuade anyone from going\ndown that route. I don't think lost value is better for anyone.\n\nOn Mon, Jan 25, 2016 at 7:12 PM, Luke Dashjr <luke at dashjr.org> wrote:\n\n> On Tuesday, January 26, 2016 3:07:40 AM Toby Padilla wrote:\n> > > I don't see any benefit to changing that. It is better that coins are\n> > > burned.\n> >\n> > I think this is our fundamental disagreement. People will burn coins to\n> > encode data, why allow this when there's a better alternative?\n>\n> My point is that there isn't a better alternative. The coins being burned,\n> is\n> strictly better than it being gratis.\n>\n> > > You *always* need a key, to redeem inputs... regardless of values.\n> >\n> > Correct, but with BIP70 that key is in the user's wallet and you can\n> > construct transactions on another machine (thus not needing a key during\n> > construction). Right now there's no way to do the transaction\n> construction\n> > on another machine with zero value OP_RETURNs.\n>\n> This is also a good thing. Spam should not be made easier or cheaper.\n>\n> Luke\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160125/69e50f07/attachment.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-01-26T03:23:13",
                "message_text_only": "On Tuesday, January 26, 2016 3:17:12 AM Toby Padilla wrote:\n> I don't think every application of OP_RETURN could be classified as \"spam\".\n\nPerhaps not, but in this context I cannot think of any non-spam use cases.\nUse cases should come before changes to support them.\n\n> I also don't think burning the value is going to dissuade anyone from going\n> down that route. I don't think lost value is better for anyone.\n\nLost value is better because it has a cost to the spammer, and deflates the \nrest of the bitcoins.\n\nLuke"
            },
            {
                "author": "Toby Padilla",
                "date": "2016-01-26T03:30:38",
                "message_text_only": "There are already valid use cases for OP_RETURN, it only makes sense to\nfully support the feature. The only reason it's not supported now is\nbecause the Payments protocol came before OP_RETURN.\n\nI give one example use case in the BIP. I agree that special wallet support\nwould make the feature even better, but if someone tried to use Core the\ntransaction would at least not be rejected.\n\nI've also been exploring this area with key.run (\nhttps://git.playgrub.com/toby/keyrun) and want the functionality for voting\nbased on aggregate OP_RETURN value. *Not* to store data on the blockchain,\nbut to associate content pointers with transactions.\n\nI think that since OP_RETURN has already been approved and supported it\ndoesn't make much sense for me to have to re-defend it from scratch here.\n\nOn Mon, Jan 25, 2016 at 7:23 PM, Luke Dashjr <luke at dashjr.org> wrote:\n\n> On Tuesday, January 26, 2016 3:17:12 AM Toby Padilla wrote:\n> > I don't think every application of OP_RETURN could be classified as\n> \"spam\".\n>\n> Perhaps not, but in this context I cannot think of any non-spam use cases.\n> Use cases should come before changes to support them.\n>\n> > I also don't think burning the value is going to dissuade anyone from\n> going\n> > down that route. I don't think lost value is better for anyone.\n>\n> Lost value is better because it has a cost to the spammer, and deflates the\n> rest of the bitcoins.\n>\n> Luke\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160125/a1a5ce6c/attachment.html>"
            },
            {
                "author": "Thomas Kerin",
                "date": "2016-01-26T16:19:18",
                "message_text_only": "On 26/01/16 03:30, Toby Padilla via bitcoin-dev wrote:\n> There are already valid use cases for OP_RETURN, it only makes sense\n> to fully support the feature. The only reason it's not supported now\n> is because the Payments protocol came before OP_RETURN.\n>\nYou keep saying OP_RETURN is new, but it has been there from day one.\nIt's purpose is causing script execution to end if encountered.\n\nSince then, we have tolerated putting pushdata's after it, and even\nraised the limit for the size of this data. It still doesn't mean every\nproposal has to be rewritten to cater for a new allowance we give\nOP_RETURN.\n\n\n> I've also been exploring this area with key.run\n> (https://git.playgrub.com/toby/keyrun) and want the functionality for\n> voting based on aggregate OP_RETURN value. *Not* to store data on the\n> blockchain, but to associate content pointers with transactions.\n>\n> I think that since OP_RETURN has already been approved and supported\n> it doesn't make much sense for me to have to re-defend it from scratch\n> here.\n\nI'd generally agree with Luke. Removing the cost of this hurts bitcoin,\nand ironically, your application to a certain degree. Just because you\ncan do a thing one way, it doesn't mean you should. Especially if your\napplications success depends on people spamming OP_RETURN hashes of\nevery torrent they like."
            },
            {
                "author": "Toby Padilla",
                "date": "2016-01-26T17:44:48",
                "message_text_only": "OP_RETURN was not part of isStandard? from day one. Once it was supported\nby Core it became necessary to actually support it, not try to support it\nin one part of the software and not in others. The whole reason it was\nsupported is because without it people will use more heinous methods to\nencode data on the blockchain. There's no way to stop people from doing\nthat, so this compromise seemed best for everyone.\n\nI think we should actually define \"spam\". To me a valid transaction someone\nwilling pays for is never spam. Also PaymentRequests would be a very\ninefficient way to spam. It would be much easier to write a script to\nautomatically create and submit transactions yourself. With PaymentRequests\n customers have to initiate the transaction and submit/pay for it one by\none.\n\nWhat is actually the worst case scenario that those opposed to this are\nconcerned about? That this takes off like wild fire and all of the sudden\nmillions of people are using PaymentRequests and creating small\ntransactions? That seems like a win for Bitcoin. It will help spread\nsupport for the Payment protocol and IF it becomes a problem it's because\nso many people are using it. In which case there's a very valid use case\nfor Bitcoin that people are obviously excited about.\n\nI really don't like the idea of policing other people's use of the\nprotocol. If a transaction pays its fee and has a greater than dust value,\nit makes no sense to object to it.\n\nOn Tue, Jan 26, 2016 at 8:19 AM, Thomas Kerin via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> On 26/01/16 03:30, Toby Padilla via bitcoin-dev wrote:\n> > There are already valid use cases for OP_RETURN, it only makes sense\n> > to fully support the feature. The only reason it's not supported now\n> > is because the Payments protocol came before OP_RETURN.\n> >\n> You keep saying OP_RETURN is new, but it has been there from day one.\n> It's purpose is causing script execution to end if encountered.\n>\n> Since then, we have tolerated putting pushdata's after it, and even\n> raised the limit for the size of this data. It still doesn't mean every\n> proposal has to be rewritten to cater for a new allowance we give\n> OP_RETURN.\n>\n>\n> > I've also been exploring this area with key.run\n> > (https://git.playgrub.com/toby/keyrun) and want the functionality for\n> > voting based on aggregate OP_RETURN value. *Not* to store data on the\n> > blockchain, but to associate content pointers with transactions.\n> >\n> > I think that since OP_RETURN has already been approved and supported\n> > it doesn't make much sense for me to have to re-defend it from scratch\n> > here.\n>\n> I'd generally agree with Luke. Removing the cost of this hurts bitcoin,\n> and ironically, your application to a certain degree. Just because you\n> can do a thing one way, it doesn't mean you should. Especially if your\n> applications success depends on people spamming OP_RETURN hashes of\n> every torrent they like.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160126/4a59a363/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Allow zero value OP_RETURN in Payment Protocol",
            "categories": [
                "bitcoin-dev",
                "BIP Draft"
            ],
            "authors": [
                "Andreas Schildbach",
                "Thomas Kerin",
                "Luke Dashjr",
                "Toby Padilla"
            ],
            "messages_count": 15,
            "total_messages_chars_count": 41097
        }
    },
    {
        "title": "[bitcoin-dev] Fee smoothing",
        "thread_messages": [
            {
                "author": "Luzius Meisser",
                "date": "2016-01-26T17:42:25",
                "message_text_only": "This post serves to convince you of the economic benefits of smoothing\nthe payout of fees across blocks. It incentivizes decentralization and\nsupports the establishment of a fee market.\n\nIdea: currently, the total amount of fees collected in a block is paid\nout in full to whoever mined that block. I propose to only pay out,\nsay, 10% of the collected fees, and to add the remaining 90% to the\ncollected fees of the next block. Thus, the payout to the miner\nconstitutes a rolling average of collected fees from the current and\npast blocks. This reduces the marginal benefit of including an\nadditional transaction into a block by an order of magnitude and thus\naligns the incentives of individual miners better with those of the\nwhole network. As a side-effect, the disadvantage of mining with a\nslow connection is reduced.\n\nExample: currently, given a transaction with a fee of 1000 Satoshis\nand global processing cost per transaction of 5000 Satoshis, an\nindividual miner would still include the transaction if it costs him\n500 Satoshis to do so, as the remaining burden of 4500 Satoshis is\ncarried by others (a classic externality). However, with fee\nsmoothing, the immediate benefit of including that particular\ntransaction is reduced to 100 Satoshis, aligning the economic\nincentives of the miner better with the whole network and leading the\nminer to skip it. Generally, the fraction that is paid out immediately\n(here 10%) can be used to adjust the incentive, but not arbitrarily.\n\nBenefits:\n1. The disadvantage of mining with a slow connection is reduced by an\norder of magnitude. If it takes 30 seconds to download the latest\nblock, a miner loses 5% of the potential income from fees as he does\nnot know yet which transactions to include in the next block. With fee\nsmoothing, that loss is reduced to 0.5% as he would still earn 90% of\nthe average fees per block by mining an empty one based on the latest\nheader.\n2. This is a step towards a free fee market. In an ideal market,\nprices form where supply and demand meet, with the fees asymptotically\napproaching the marginal costs of a transaction. Currently, supply is\ncapped and only demand can adjust. Should we ever consider to let\nminers decide about supply, it is essential that their marginal\nbenefit of including an additional transaction is aligned with the\nglobal marginal cost incurred by that additional transaction. Fee\nsmoothing is a step in this direction.\n3. The incentive to form mining pools is reduced. Currently,\nsolo-mining yields a very volatile income stream due to the random\nnature of mining, leading to the formation of pools. This volatility\nwill increase to even higher levels once the amount of Bitcoins earned\nper block is dominated by (volatile) collected fees and not by\n(constant) freshly minted coins, thus increasing the economic pressure\nto join a large pool. Fee smoothing reduces that volatility and\npressure.\n\nProblems: touching anything related to fee distribution is a political\nminefield. This proposal probably requires a hard fork. Its technical\nfeasibility was only superficially verified.\n\nThis is my first post to this list and I am looking forward to your\ncomments. In case this proposal is received well, I plan to\nspecify/implement the idea more formally in order to kick off the\nusual process for improvements.\n\n-- \nLuzius Meisser\nPresident of Bitcoin Association Switzerland\nMSc in Computer Science and MA in Economics"
            },
            {
                "author": "Warren Togami Jr.",
                "date": "2016-01-27T02:45:51",
                "message_text_only": "On Tue, Jan 26, 2016 at 9:42 AM, Luzius Meisser via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> This post serves to convince you of the economic benefits of smoothing\n> the payout of fees across blocks. It incentivizes decentralization and\n> supports the establishment of a fee market.\n>\n> Idea: currently, the total amount of fees collected in a block is paid\n> out in full to whoever mined that block. I propose to only pay out,\n> say, 10% of the collected fees, and to add the remaining 90% to the\n> collected fees of the next block. Thus, the payout to the miner\n> constitutes a rolling average of collected fees from the current and\n> past blocks. This\n> *reduces the marginal benefit of including an additional transaction into\n> a block* by an order of magnitude and thus\n> aligns the incentives of individual miners better with those of the\n> whole network. As a side-effect,\n>\n> *the disadvantage of mining with a slow connection is reduced.*\n\n\nI do not believe your logic is correct.  Reducing the marginal benefit of\nincluding an additional transaction is problematic because it\nsimultaneously increases the orphan risk while it reduces the reward.  90%\nof the fee going to the next block would also create new incentive problems\nlike mining an empty block to minimize the chance of losing 90% of the fees\nfrom the previous block to an orphan.  Another major issue with mandatory\nsharing is if the miner doesn't want to share, nothing stops them from\ntaking payment out-of-band and confirming the transaction with little or no\nfees visible in the block.\n\nI had been thinking recently about fee deferral for a different reason.  In\nthe future when the subsidy is much smaller in proportion to the fees,\nthere may be little incentive to confirm on top of someone else's block in\ncases when the expected value of replacing the current tip is higher.  I\nthink smoothing fees between the current and subsequent 5 blocks (for\nexample) might reduce the incentive of this type of behavior.  The main\nrisk here might be in weakening too far the incentive of adding more\ntransactions to the current block, as I believe your 10% current and 90%\nsubsequent reward split would do.  I think my idea of a mandatory split\nbetween six blocks might also be a failure because of the high incentive to\nconduct out-of-band payments.\n\n\n> Benefits:\n>\n2. This is a step towards a free fee market. In an ideal market,\n> prices form where supply and demand meet, with the fees asymptotically\n> approaching the marginal costs of a transaction. Currently, supply is\n> capped and only demand can adjust. Should we ever consider to let\n> miners decide about supply, it is\n>\n> *essential that their marginal benefit of including an additional\n> transaction is aligned with the global marginal cost incurred by that\n> additional transaction.* Fee\n> smoothing is a step in this direction.\n>\n\nWhile I don't agree with the rest of your logic, it is agreeable that you\ncare about aligning the miner's supply incentives with the global marginal\ncost.  If you believe that is an important goal, you might like the Flex\nCap approach as presented by Mark Friedenbach at Scaling Bitcoin Hong Kong.\n\nUnder the general idea of the Flex Cap approach block size is no longer\nfixed, it can be bursted higher on a per-block basis if the miner is\nwilling to defer a tiny portion of the current block subsidy to pay out to\nthe miner of later blocks.  If conditions are such that there is genuine\ndemand then some are willing to pay higher fees for time preference.  Some\nformula would balance the cost and reward in some manner like: add the\nvalue of newly included fees, subtract the expected marginal cost of orphan\nrisk, then subtract the portion of subsidy deferred.  Flex cap has periodic\nblock size retargets to allow for a temporary limit to rise or fall to\nsomething resembling actual market demand.  This temporary limit is never a\n\"wall\" that can be hit as miners can choose to burst past it if the cost is\nworth the reward.\n\nFlex Cap is an area of ongoing research that I strongly believe would\nbenefit Bitcoin in the long-term.  For this reason it requires careful\nstudy and simulations to figure out specifics.\n\n3. The incentive to form mining pools is reduced. Currently,\n> solo-mining yields a very volatile income stream due to the random\n> nature of mining, leading to the formation of pools. This volatility\n> will increase to even higher levels once the amount of Bitcoins earned\n> per block is dominated by (volatile) collected fees and not by\n> (constant) freshly minted coins, thus increasing the economic pressure\n> to join a large pool. Fee smoothing reduces that volatility and\n> pressure.\n>\n\nYou seem to not recognize that orphan cost is a major reason why pools are\nattractive.\n\nWarren Togami\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160126/c2d01aac/attachment-0001.html>"
            },
            {
                "author": "Luzius Meisser",
                "date": "2016-01-27T10:12:02",
                "message_text_only": "2016-01-27 3:45 GMT+01:00 Warren Togami Jr. <wtogami at gmail.com>:\n> On Tue, Jan 26, 2016 at 9:42 AM, Luzius Meisser via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> Idea: currently, the total amount of fees collected in a block is paid\n>> out in full to whoever mined that block. I propose to only pay out,\n>> say, 10% of the collected fees, and to add the remaining 90% to the\n>> collected fees of the next block. Thus, the payout to the miner\n>> constitutes a rolling average of collected fees from the current and\n>> past blocks.\n>\n> [...] Another major issue with mandatory sharing is\n> if the miner doesn't want to share, nothing stops them from taking payment\n> out-of-band and confirming the transaction with little or no fees visible in\n> the block.\n\nWhile I find the other points you raised debatable, the out-of-band\nargument looks strong enough to kill the idea. To work around it, one\nwould need to create rules about the transactions that can be included\nin a block, for example by mandating that all included transactions\nmust have a fee at least as high as 0.9 times the 5th percentile of\nthe transactions in the previous 10 blocks. However, having to tell\nthe miners what fees they are allowed to accept destroys some of the\nelegance of the idea. Maybe I should put it to rest for now and see if\na more elegant solution comes to mind later.\n\n> While I don't agree with the rest of your logic, it is agreeable that you\n> care about aligning the miner's supply incentives with the global marginal\n> cost.  If you believe that is an important goal, you might like the Flex Cap\n> approach as presented by Mark Friedenbach at Scaling Bitcoin Hong Kong.\n> Under the general idea of the Flex Cap approach block size is no longer\n> fixed, it can be bursted higher on a per-block basis if the miner is willing\n> to defer a tiny portion of the current block subsidy to pay out to the miner\n> of later blocks.\n> [...]\n> Flex Cap is an area of ongoing research that I strongly believe would\n> benefit Bitcoin in the long-term.  For this reason it requires careful study\n> and simulations to figure out specifics.\n\nI agree that flex cap is promising. However, for it to be a viable\nlong-term solution, it must not depend on significant block subsidies\nto work as the block subsidy will become less and less relevant over\ntime.\n\nPicking up your thoughts, I guess this is how flex cap should be done:\n1. There is a flexible block cap (e.g. 1 MB). This first MB is free to fill.\n2. Miners can buy additional space for an exponentially increasing\nfee. For example, the first KiB might cost 200 Satoshis, the second\nKiB 400 Satoshis, the tenth KiB 102400 Satoshis etc.\n3. The price of the purchased space is subtracted from the collected\nfees and added to the reward of the next block.\n4. The amount miners are willing to spend on additional space allows\nto calculate the marginal costs of a transaction of a miner. For\nexample, if a miner pays 6000 Satoshis to include a 1 KB transaction\nwith a fee of 6100 Satoshis, the marginal costs must be below 100\nSatoshis, assuming a rational miner. This cost is multiplied by say 50\nto account for the costs of decentralization to get a global cost\nestimate of 5000 Satoshis per KB.\n5. Every 1000 blocks or so, the basic cap is adjusted upwards or\ndownwards (e.g. by 10%) depending on whether the average fees per KB\nwere above or below the global cost estimate.\n\nUnder such a scheme, prices should get very close to free market\nprices. However, ruthless competition can get ugly in markets where\nfixed costs dominate. We can currently witness this in the oil\nindustry. Thus, from an economic point of view, it might be more\nadvisable to simply let miners vote on block size, as has been\nproposed by others. The drawback of voting is that it allows miners to\nenforce a cartel among themselves and to charge monopoly prices\ninstead of competitive prices. However, monopoly prices would already\nbe much better than having an artificial cap.\n\nWarren, thank you for your thoughts! I appreciate the opportunity to\ndiscuss ideas at such a high level.\n\n--\nLuzius Meisser\nPresident of Bitcoin Association Switzerland\nMSc in Computer Science and MA in Economics"
            },
            {
                "author": "Warren Togami Jr.",
                "date": "2016-01-27T23:11:04",
                "message_text_only": "On Wed, Jan 27, 2016 at 2:12 AM, Luzius Meisser <luzius.meisser at gmail.com>\nwrote:\n\n> I agree that flex cap is promising. However, for it to be a viable\n> long-term solution, it must not depend on significant block subsidies\n> to work as the block subsidy will become less and less relevant over\n> time\n\n\nThere is another variant of the Flex Cap approach that allows miners to pay\nwith a slightly higher difficulty target instead of deferring a portion of\nsubsidy to later blocks.  I think the HK presentation was about the subsidy\ndeferral variant because of miner feedback that they preferred that\napproach.\n\nMyself and a few other developers think proposals like BIP100 where the\nblock size is subject to a vote by the miners is suboptimal because this\ntype of vote is costless.  You were astute in recognizing in your post it's\na good thing to somehow align the global marginal cost with the miner's\nincentive.  I feel a costless vote is not great because it aligns only to\nthe miner's marginal cost, and not the marginal cost to the entire flood\nnetwork.  Flex Cap is superior as \"vote\" mechanism as there is an actual\ncost associated, allowing block size to grow with actual demand.\n\nWarren\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160127/dfc770d0/attachment.html>"
            },
            {
                "author": "Luzius Meisser",
                "date": "2016-01-28T20:16:41",
                "message_text_only": "2016-01-28 13:00 GMT+01:00  Warren Togami Jr. <wtogami at gmail.com>:\n> Myself and a few other developers think proposals like BIP100 where the\n> block size is subject to a vote by the miners is suboptimal because this\n> type of vote is costless.\n\nThe cost of the vote is completely irrelevant. What matters are the\nresulting block sizes and transaction fees. Assuming rational,\nprofit-maximizing miners, BIP100 would allow them to effectively\nenforce a cartel and to set block sizes (and thereby indirectly also\nfees) at monopoly price levels. Charging something for a vote would\nnot affect that equilibrium and thus also neither affect block sizes\nnor fees. Also note that monopoly prices are always at least as high\nas competitive market prices. In other words: the transaction fees\nthat emerge under BIP100 will be higher than those that would emerge\nwith a flex cap mechanism that is based on the total marginal costs of\nthe miners. If you do not believe that, I'll happily go into the gory\ndetails.\n\n> You were astute in recognizing in your post it's\n> a good thing to somehow align the global marginal cost with the miner's\n> incentive.  I feel a costless vote is not great because it aligns only to\n> the miner's marginal cost, and not the marginal cost to the entire flood\n> network.  Flex Cap is superior as \"vote\" mechanism as there is an actual\n> cost associated, allowing block size to grow with actual demand.\n\nThere are two types of flex cap mechanisms: First, there mechanisms\nlike the one I described previously which ensures that supply is based\non the actual costs of the miners. If done right, they can lead to a\ncompetitive equilibrium with free market prices. Second, there are\nflex cap mechanisms that simply replace todays centrally planned\nconstant cap with a centrally planned supply curve. If you believe in\ncentral planning, that's ok. I for one prefer to avoid it. Also, it is\nnot much better than the constant cap, maybe even worse.\n\nNote that neither type of flex cap adjusts to the marginal cost of the\nentire network, simply because none of them can measure the cost of\nrunning a full node, yet alone reliably detect the number of running\nfull nodes. Any attempt to do so would be futile anyway because it\nwould too easy to pretend-run full nodes in order to manipulate the\nmechanism. When reasoning about full nodes, completely different\nforces are at play. The only connection between full nodes and the fee\nmarket is that larger blocks make it more expensive to run a full\nnode.\n\nHowever, a holistic analysis must also reason about the benefits of\nrunning a full node. I often see one-sided arguments saying that\nincreasing block sizes will make running one more expensive and thus\nthere will be fewer nodes. This logic is flawed because the economic\nreasons for running a full node are not understood and taken into\naccount. An example reason could be the ability to monitor the network\nand to verify transactions, which is very valuable to exchanges,\nmerchants and wallet services. To them, this value of running a full\nnode even grows with the number of customers. Thus, depending on the\ncircumstances, increase block sizes can counter-intuitively make it\nmore attractive to run a full node. The big picture from a systemic\nperspective can look completely different than the conventional\nmicro-view that only sees first-order effects. Unfortunately, most\npeople are not great systems-thinkers.\n\n\n\n2016-01-27 11:12 GMT+01:00 Luzius Meisser <luzius.meisser at gmail.com>:\n> 2016-01-27 3:45 GMT+01:00 Warren Togami Jr. <wtogami at gmail.com>:\n>> On Tue, Jan 26, 2016 at 9:42 AM, Luzius Meisser via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>> Idea: currently, the total amount of fees collected in a block is paid\n>>> out in full to whoever mined that block. I propose to only pay out,\n>>> say, 10% of the collected fees, and to add the remaining 90% to the\n>>> collected fees of the next block. Thus, the payout to the miner\n>>> constitutes a rolling average of collected fees from the current and\n>>> past blocks.\n>>\n>> [...] Another major issue with mandatory sharing is\n>> if the miner doesn't want to share, nothing stops them from taking payment\n>> out-of-band and confirming the transaction with little or no fees visible in\n>> the block.\n>\n> While I find the other points you raised debatable, the out-of-band\n> argument looks strong enough to kill the idea. To work around it, one\n> would need to create rules about the transactions that can be included\n> in a block, for example by mandating that all included transactions\n> must have a fee at least as high as 0.9 times the 5th percentile of\n> the transactions in the previous 10 blocks. However, having to tell\n> the miners what fees they are allowed to accept destroys some of the\n> elegance of the idea. Maybe I should put it to rest for now and see if\n> a more elegant solution comes to mind later.\n>\n>> While I don't agree with the rest of your logic, it is agreeable that you\n>> care about aligning the miner's supply incentives with the global marginal\n>> cost.  If you believe that is an important goal, you might like the Flex Cap\n>> approach as presented by Mark Friedenbach at Scaling Bitcoin Hong Kong.\n>> Under the general idea of the Flex Cap approach block size is no longer\n>> fixed, it can be bursted higher on a per-block basis if the miner is willing\n>> to defer a tiny portion of the current block subsidy to pay out to the miner\n>> of later blocks.\n>> [...]\n>> Flex Cap is an area of ongoing research that I strongly believe would\n>> benefit Bitcoin in the long-term.  For this reason it requires careful study\n>> and simulations to figure out specifics.\n>\n> I agree that flex cap is promising. However, for it to be a viable\n> long-term solution, it must not depend on significant block subsidies\n> to work as the block subsidy will become less and less relevant over\n> time.\n>\n> Picking up your thoughts, I guess this is how flex cap should be done:\n> 1. There is a flexible block cap (e.g. 1 MB). This first MB is free to fill.\n> 2. Miners can buy additional space for an exponentially increasing\n> fee. For example, the first KiB might cost 200 Satoshis, the second\n> KiB 400 Satoshis, the tenth KiB 102400 Satoshis etc.\n> 3. The price of the purchased space is subtracted from the collected\n> fees and added to the reward of the next block.\n> 4. The amount miners are willing to spend on additional space allows\n> to calculate the marginal costs of a transaction of a miner. For\n> example, if a miner pays 6000 Satoshis to include a 1 KB transaction\n> with a fee of 6100 Satoshis, the marginal costs must be below 100\n> Satoshis, assuming a rational miner. This cost is multiplied by say 50\n> to account for the costs of decentralization to get a global cost\n> estimate of 5000 Satoshis per KB.\n> 5. Every 1000 blocks or so, the basic cap is adjusted upwards or\n> downwards (e.g. by 10%) depending on whether the average fees per KB\n> were above or below the global cost estimate.\n>\n> Under such a scheme, prices should get very close to free market\n> prices. However, ruthless competition can get ugly in markets where\n> fixed costs dominate. We can currently witness this in the oil\n> industry. Thus, from an economic point of view, it might be more\n> advisable to simply let miners vote on block size, as has been\n> proposed by others. The drawback of voting is that it allows miners to\n> enforce a cartel among themselves and to charge monopoly prices\n> instead of competitive prices. However, monopoly prices would already\n> be much better than having an artificial cap.\n>\n> Warren, thank you for your thoughts! I appreciate the opportunity to\n> discuss ideas at such a high level.\n>\n> --\n> Luzius Meisser\n> President of Bitcoin Association Switzerland\n> MSc in Computer Science and MA in Economics\n\n\n\n-- \nLuzius Meisser\nluzius.meisser at gmail.com"
            }
        ],
        "thread_summary": {
            "title": "Fee smoothing",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Warren Togami Jr.",
                "Luzius Meisser"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 21924
        }
    },
    {
        "title": "[bitcoin-dev] Segwit Upgrade Procedures & Block Extension Data",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2016-01-28T18:51:24",
                "message_text_only": "A few notes on upgrade procedures associated with segregated witnesses:\n\n\nInitial Deployment\n==================\n\nWhile segregated witnesses is a soft-fork, because it adds new data\nblocks that old nodes don't relay segwit nodes can't sync from\nnon-segwit nodes and still be fully validating; once the segwit softfork\nhas activated full nodes need witness data to function. This poses a\nmajor problem during deployment: if full node adoption lags miner\nadoption, the segwit-supporting P2P network can partition and lose\nconsensus.\n\nWhile Pieter Wuille's segwit branch(1) doesn't yet implement a fix for\nthe above problem, the obvious thing to do is to add a new service bit\nsuch as NODE_SEGWIT, and/or bump the protocol version, and for outgoing\npeers only connect to peers with segwit support. Interestingly, a\nclosely related problem already exists in Bitcoin Core: neither addrman\nnor the outgoing connection thread takes what service bits a peer\nadvertises into account. So if a large number of non-block-relaying\nnodes joined the network and advertised their addresses the network\ncould, in theory, partition even without an explicit attack. (My own\nfull-RBF fork of Bitcoin Core does fix(2) this issue, though by\naccident!)\n\nNote how because of this the segwit soft-fork has properties not unlike\nhard-forks in terms of the need for nodes to upgrade with regard to the\nP2P layer. Even with the above fix, the worst case would be for segwit\nto not be adopted widely by full node operators, resulting in a network\nmuch more vulnerable to attacks such as DoSing nodes. This is one of the\n(many) reasons why hard-forks are generally significantly more dangerous\nthan soft-forks.\n\n\nFuture Upgrades\n===============\n\nSegwit isn't going to be the last thing that adds new block data. For\nexample, my own prev-block-proof proposal(3) requires that blocks commit\nto another tree, which itself is calculated using a nonce that must be\npassed along with the block data. (U)TXO commitments are another\npossible future example.\n\nBIP141 (currently) suggests an Extensible Commitment Structure(4)\nconsisting of a hashed linked list of consensus-critical commitments,\nwith a redefinable nonce at the end of the list for future soft-forks.\nCurrently this nonce is put into the otherwise useless, and non-hashed,\nwitness for the coinbase transaction(6) and a block is invalid if its\nwitness contains more than that single nonce.(7)\n\nUnfortunately, this means that the next soft-fork upgrade to add\nadditional data will have the above relaying problem all over again!\nEven a minimal upgrade adding a new commitment - like my\nprev-block-proof proposal - needs to at least add another nonce for\nfuture upgrades. In addition to having to upgrade full nodes, this also\nrequires systems like the relay network to upgrade, even though they may\nnot themselves otherwise need to care about the contents of blocks.\n\nA more subtle implication of this problem is how do you handle parallel\nupgrades, as proposed by BIP9? Splitting the P2P network into\nnon-upgraded nodes, and a much smaller group of upgraded nodes, is bad\nenough when done every once in a awhile. How does this look with more\nfrequent upgrades, not necessarily done by teams that are working\nclosely with each other?\n\n\nProposal: Unvalidated Block Extension Data\n==========================================\n\n1) Remove the restriction that the coinbase witness contain exactly one\n   32byte value.\n\n2) Hash the contents of the coinbase witness (e.g. as a merkle tree) and\n   commit them in place of the current nonce commitment.\n\n3) Include that data in the blocksize limit (to prevent abuse).\n\nNow future soft-forks can simply add additional data, which non-upgraded\nnodes simply see as extension data that they don't know how to fully\nvalidate. All nodes can however validate that data came from the miner,\nand thus they can freely propagate that data without risk of attack\n(Bitcoin Core used to allow additional data to be included with\ntransactions, which was used in a DoS attack (CVE-2013-4627)).\n\nThis is more efficient than it may appear at first glace. As most future\nupgrades are expected to be additional commitments where full nodes can\ndeterministically recalculate the commitment, the additional data for\neach new commitment is just 32 bytes.\n\nA significant design consideration is that if arbitrary data can be\nadded, it is very likely that miners will make use of that ability for\nnon-Bitcoin purposes; we've already run into problems deploying segwit\nitself because of pools using the coinbase space for advertising and\nmerge-mining. Avoiding this problem is easiest with a merkelized\nkey:value mapping, with the ability to use collision-resistant ID's as\nkeys (e.g. UUID).\n\nSecondly, does using the coinbase witness for this really make sense?\nLogically it'd make more sense to change the way blocks are serialized,\nmuch the same way transaction serialization was changed to accomodate\nsegwit; stuffing this in the coinbase witness smells like a hack. (along\nthose lines, note how witnesses themselves could have been implemented\nthis way - probably too late to change now)\n\n\nReferences\n==========\n\n1) https://github.com/sipa/bitcoin/tree/segwit\n\n2) https://github.com/petertodd/bitcoin/blob/replace-by-fee-v0.12.0rc2/src/net.cpp#L1616\n\n3) http://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-December/012103.html\n\n5) https://github.com/bitcoin/bips/blob/6a315c023f13d83c58aab98cf8668d74cf7566c7/bip-0141.mediawiki#Extensible_commitment_structure\n\n6) https://github.com/sipa/bitcoin/blob/37973bf2efd7a558c86bf35455a1355e5b0d5d64/src/main.cpp#L3212\n\n7) https://github.com/sipa/bitcoin/blob/37973bf2efd7a558c86bf35455a1355e5b0d5d64/src/main.cpp#L3209\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n0000000000000000003b293f5507f7787f1ba64ba58a21c46ba4454c21a88710\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160128/961968b0/attachment.sig>"
            },
            {
                "author": "Anthony Towns",
                "date": "2016-01-30T15:32:26",
                "message_text_only": "On Thu, Jan 28, 2016 at 01:51:24PM -0500, Peter Todd via bitcoin-dev wrote:\n> While Pieter Wuille's segwit branch(1) doesn't yet implement a fix for\n> the above problem, the obvious thing to do is to add a new service bit\n> such as NODE_SEGWIT, and/or bump the protocol version, and for outgoing\n> peers only connect to peers with segwit support.\n\nIf I'm following the code right, the segwit branch has a fHaveWitness\nflag for each connection, which is set when a HAVEWITNESS message comes\nfrom the peer, and HAVEWITNESS is sent as part of handshaking. BIP144\nsuggests maybe this should be changed to a service bit though:\n\nhttps://github.com/bitcoin/bips/blob/master/bip-0144.mediawiki\n\nIf you've got a limit of 8 outgoing connections and >4 of them don't\nsupport witnesses, would it be enough to just drop a non-witness\nconnection and try a new one? Or is anything less than 8 of 8 outgoing\nwitness supporting connections likely to be bad for the network?\n\n> Future Upgrades\n> ===============\n> Segwit isn't going to be the last thing that adds new block data. For\n> example, my own prev-block-proof proposal(3) requires that blocks commit\n> to another tree, which itself is calculated using a nonce that must be\n> passed along with the block data. (U)TXO commitments are another\n> possible future example.\n\nCommitments to a merkle sum tree of transaction bytes, sigops, sighash\nbytes, fees, priority, etc for small fraud proofs also fit here,\ndon't they?\n\n> Unfortunately, this means that the next soft-fork upgrade to add\n> additional data will have the above relaying problem all over again!\n\nThis isn't necessarily true -- you could just make the coinbase witness\nnonce become HASH(newinformation | newnonce), and put newnonce back into\nthe coinbase as an additional OP_RETURN, so that it can be verified.\n\nIf you want to have layered soft-forks adding new commitments, I think\nyou have to keep adding 32 byte hashed nonces; dropping them would be\na hard fork as far as I can see. So if there might eventually be three\nor four of them, putting them in the witness block rather than the base\nblock seems sensible to me.\n\n> Proposal: Unvalidated Block Extension Data\n> ==========================================\n> 1) Remove the restriction that the coinbase witness contain exactly one\n>    32byte value.\n\n+1.\n\nIf the linked list approach in BIP141 is used, then I think the logic\ncould be something like this:\n\n * suppose there have been a few soft-forks and the coinbase witness\n   now handles three commitments: segwit, prevblockproof, fraudproofs\n\n * then the coinbase witness stack should have at least 3 32-byte\n   values pushed on it, which should evaluate to:\n\n     s[1] = HASH( fraudproof-info ; s[2] )\n     s[0] = HASH( prevblockproof-info ; s[1] )\n\n   and the coinbase should include\n\n     OP_RETURN SHA256d( segwit-info ; s[0] )\n\n * old segwit code works fine (assuming the stack.size() != 1 check is\n   changed to == 0), just treating s[0] as a meaningless nonce\n\n * old prevblockproof supporting nodes check s[0], treating s[1] as a\n   meaningless nonce, but still validating the prevblock proofs\n\n * nodes running the latest code validate all three checks, and will\n   continue to work if new checks are soft-forked in later\n\n> 2) Hash the contents of the coinbase witness (e.g. as a merkle tree) and\n>    commit them in place of the current nonce commitment.\n\nBut I think this seems just as good, and a fair bit simpler. ie with the\nsame three commitments, the coinbase witness contains:\n\n     s[2] = nonce\n     s[1] = fraudproof-info-hash\n     s[0] = prevblockproof-info-hash\n\nand coinbase includes:\n\n     OP_RETURN SHA256d( HASH(segwit-info) ; s[0] ; s[1] ; s[2] ; ... )\n\nI'm not sure if the use of a nonce has any value if done this way.\n\nWith this apporach, the commitments could be ordered arbitrarily --\nyou only have to check that \"fraudproof-info-hash\" is somewhere on the\nstack of the coinbase witness, not that it's s[1] in particular.\n\nI think it makes sense to plan on cleaning these up with infrequent\nhard forks, eg one that combines the transactions hashMerkleRoot\nand the witnessMerkleRoot and the fraudProofMerkleSumRoot and the\nprevBLockProofHash into a single entry in the block header, but being\nable to add features with soft-forks in the meantime seems like a win.\n\n> 3) Include that data in the blocksize limit (to prevent abuse).\n\nIncluding it in the coinbase witness already includes it in the blocksize\nlimit, albeit discounted, no? If someone wants to propose a soft-fork\nadding 500kB of extra consensus-critical data to each block for some\nreason, sticking it in the coinbase witness seems about the least\noffensive way to do it?\n\n> Secondly, does using the coinbase witness for this really make sense?\n\nIf you look at the witness as a proof of \"this is why it's okay to\naccept this transaction\" in general, and the coinbase witness is \"this\nis why it's okay to accept this block\", then including prevblock proofs\nand fraud proof info in the coinbase witness seems pretty logical... Or\nat least, it does to me.\n\nThis topic seems to be being discussed in a PR on the segwit branch:\n\n  https://github.com/sipa/bitcoin/pull/48\n\nwhere there's a proposal to have the coinbase witness include the merkle\npath to the segwit data, so, if I understand it right, the coinbase\ncommitment might be:\n\n  OP_RETURN Hash( s[0] || Hash( Hash( s[2] || segwit-data ) || s[1] ) )\n\nif the path to the segwit data happened to be right-left-right. That\nwould still make it hard to work out the path to some proof that happened\nto be in position right-right-left, though, so it seems inferior to the\napproaches described above to me...\n\nCheers,\naj\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 801 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160131/7cb0c5c1/attachment.sig>"
            },
            {
                "author": "Anthony Towns",
                "date": "2016-01-30T15:48:57",
                "message_text_only": "On Sun, Jan 31, 2016 at 01:32:26AM +1000, Anthony Towns via bitcoin-dev wrote:\n> On Thu, Jan 28, 2016 at 01:51:24PM -0500, Peter Todd via bitcoin-dev wrote:\n> > While Pieter Wuille's segwit branch(1) doesn't yet implement a fix for\n> > the above problem, the obvious thing to do is to add a new service bit\n> > such as NODE_SEGWIT, and/or bump the protocol version, and for outgoing\n> > peers only connect to peers with segwit support.\n> If I'm following the code right, the segwit branch has a fHaveWitness\n> flag for each connection, which is set when a HAVEWITNESS message comes\n> from the peer, and HAVEWITNESS is sent as part of handshaking. BIP144\n> suggests maybe this should be changed to a service bit though:\n\nOh, there's a PR to change this to a NODE_WITNESS service bit:\n\nhttps://github.com/sipa/bitcoin/pull/55\n\nCheers,\naj\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 801 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160131/ef5edc4f/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Segwit Upgrade Procedures & Block Extension Data",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Anthony Towns",
                "Peter Todd"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 13162
        }
    },
    {
        "title": "[bitcoin-dev] BIP Classification Process",
        "thread_messages": [
            {
                "author": "Eric Lombrozo",
                "date": "2016-01-29T00:52:53",
                "message_text_only": "Folks,\n\nI think the current situation with forks could have been avoided with a better process that can distinguish between different layers for bitcoin modification proposals.\n\nFor instance, BIP64 was proposed by Mike Hearn, which does not affect the consensus layer at all. Many Core devs disliked the proposal and Mike had lots of pushback. Regardless of whether or not you agree with the merits of Mike\u2019s ideas here, fact is having nodes that support BIP64 would not fundamentally break the Bitcoin network.\n\nThis issue prompted Mike to break off from Core and create XT as the applications he was developing required BIP64 to work. With this split, Gavin found a new home for his big block ideas\u2026and the two teamed up.\n\nWe need to have a process that clearly distinguishes these different layers and allows much more freedom in the upper layers while requiring agreement at the consensus layer. Many of these fork proposals are actually conflating different features, only some of which would actually be consensus layer changes. When people proposing nonconsensus features get pushback from Core developers they feel rejected and are likely to team up with others trying to push for hard forks and the like.\n\nA while back I had submitted a BIP -  BIP123 - that addresses this issue. I have updated it to include all the currently proposed and accepted BIPs and have submitted a PR: https://github.com/bitcoin/bips/pull/311 <https://github.com/bitcoin/bips/pull/311>\n\nI urge everyone to seriously consider getting this BIP accepted as a top priority before we get more projects all trying their hand at stuff and not understanding these critical distinctions.\n\n\n- Eric\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160128/2e877491/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 842 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160128/2e877491/attachment-0001.sig>"
            },
            {
                "author": "Btc Drak",
                "date": "2016-01-29T07:21:10",
                "message_text_only": "Your proposal does not solve the issue related to Mike creating his own\nfork. He created his own for because he had a non-consensus feature set\nthat Bitcoin Core disagreed with and he wanted. That is to be _encouraged_.\nI also maintain my own Bitcoin fork with a specific (non-consensus) feature\nfor the same reason and I am perfectly happy with the arrangement, as are\nmy userbase.\n\nClassification of BIPs is fine, I have no problem with that and I support\nyour BIP, but your proposition it would have stopped Mike from creating his\nown distribution is false (nor desirable): it was down to a strong\ndiffering of technical opinions between Mike and a dozen other developers\nas well as node security concerns (which were proved correct).\n\n\nOn Fri, Jan 29, 2016 at 12:52 AM, Eric Lombrozo via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Folks,\n>\n> I think the current situation with forks could have been avoided with a\n> better process that can distinguish between different layers for bitcoin\n> modification proposals.\n>\n> For instance, BIP64 was proposed by Mike Hearn, which does not affect the\n> consensus layer at all. Many Core devs disliked the proposal and Mike had\n> lots of pushback. Regardless of whether or not you agree with the merits of\n> Mike\u2019s ideas here, fact is having nodes that support BIP64 would not\n> fundamentally break the Bitcoin network.\n>\n> This issue prompted Mike to break off from Core and create XT as the\n> applications he was developing required BIP64 to work. With this split,\n> Gavin found a new home for his big block ideas\u2026and the two teamed up.\n>\n> We need to have a process that clearly distinguishes these different\n> layers and allows much more freedom in the upper layers while requiring\n> agreement at the consensus layer. Many of these fork proposals are actually\n> conflating different features, only some of which would actually be\n> consensus layer changes. When people proposing nonconsensus features get\n> pushback from Core developers they feel rejected and are likely to team up\n> with others trying to push for hard forks and the like.\n>\n> A while back I had submitted a BIP -  BIP123 - that addresses this issue.\n> I have updated it to include all the currently proposed and accepted BIPs\n> and have submitted a PR: https://github.com/bitcoin/bips/pull/311\n>\n> I urge everyone to seriously consider getting this BIP accepted as a top\n> priority before we get more projects all trying their hand at stuff and not\n> understanding these critical distinctions.\n>\n>\n> - Eric\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160129/cbfbca9f/attachment.html>"
            },
            {
                "author": "Eric Lombrozo",
                "date": "2016-01-29T07:57:00",
                "message_text_only": "Codebase forks with nonconsensus features are totally fine! It\u2019s the bitterness and resentment that arose out of the need to get everyone to agree on something that not everyone really needs to agree on that\u2019s the problem.\n\n> On Jan 28, 2016, at 11:21 PM, Btc Drak <btcdrak at gmail.com> wrote:\n> \n> Your proposal does not solve the issue related to Mike creating his own fork. He created his own for because he had a non-consensus feature set that Bitcoin Core disagreed with and he wanted. That is to be _encouraged_. I also maintain my own Bitcoin fork with a specific (non-consensus) feature for the same reason and I am perfectly happy with the arrangement, as are my userbase.\n> \n> Classification of BIPs is fine, I have no problem with that and I support your BIP, but your proposition it would have stopped Mike from creating his own distribution is false (nor desirable): it was down to a strong differing of technical opinions between Mike and a dozen other developers as well as node security concerns (which were proved correct).\n> \n> \n> On Fri, Jan 29, 2016 at 12:52 AM, Eric Lombrozo via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> Folks,\n> \n> I think the current situation with forks could have been avoided with a better process that can distinguish between different layers for bitcoin modification proposals.\n> \n> For instance, BIP64 was proposed by Mike Hearn, which does not affect the consensus layer at all. Many Core devs disliked the proposal and Mike had lots of pushback. Regardless of whether or not you agree with the merits of Mike\u2019s ideas here, fact is having nodes that support BIP64 would not fundamentally break the Bitcoin network.\n> \n> This issue prompted Mike to break off from Core and create XT as the applications he was developing required BIP64 to work. With this split, Gavin found a new home for his big block ideas\u2026and the two teamed up.\n> \n> We need to have a process that clearly distinguishes these different layers and allows much more freedom in the upper layers while requiring agreement at the consensus layer. Many of these fork proposals are actually conflating different features, only some of which would actually be consensus layer changes. When people proposing nonconsensus features get pushback from Core developers they feel rejected and are likely to team up with others trying to push for hard forks and the like.\n> \n> A while back I had submitted a BIP -  BIP123 - that addresses this issue. I have updated it to include all the currently proposed and accepted BIPs and have submitted a PR: https://github.com/bitcoin/bips/pull/311 <https://github.com/bitcoin/bips/pull/311>\n> \n> I urge everyone to seriously consider getting this BIP accepted as a top priority before we get more projects all trying their hand at stuff and not understanding these critical distinctions.\n> \n> \n> - Eric\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n> \n> \n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160128/a8c4af1d/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 842 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160128/a8c4af1d/attachment-0001.sig>"
            }
        ],
        "thread_summary": {
            "title": "BIP Classification Process",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Eric Lombrozo",
                "Btc Drak"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 8810
        }
    },
    {
        "title": "[bitcoin-dev] Best (block nr % 2016) for hard fork activation?",
        "thread_messages": [
            {
                "author": "Jannes Faber",
                "date": "2016-01-29T02:31:05",
                "message_text_only": "Hi,\n\nQuestion if you'll allow me. This is not about Gavin's latest hard fork\nproposal but in general about any hard (or soft) fork.\n\nI was surprised to see a period expressed in human time instead of in block\ntime:\n\n> Blocks with timestamps greater than or equal to the triggering block's\ntimestamp plus 28 days (60*60*24*28 seconds) shall have the new limits.\n\nBut even more so I would expect there to be significant differences in\neffects on non-updated clients depending on the moment (expressed as block\nnumber) of applying the new rules. I see a few options, all relating to the\n2016 blocks recalibration window.\n\n1) the first block after difficulty adjustment.\n2) the last block before the difficulty adjustment.\n3) in the middle\n4) n blocks before the adjustment with n the smallest number of blocks\ncalculated such that the adjustment can just manage to do the maximum\npossible drop in difficulty.\n\nOne of the effects I'm thinking of would be in case of an evil contentious\n75-25 hard fork. If that activates at 1) or 2) it will take an awful long\ntime for the 25% chain to get to 2016 for the next adjustment all the while\nhaving 40 minutes block times. Option 4) sounds a lot better for the\nconservative chain. The attacking fork clearly has a choice to make it as\nhard as possible for them.\n\nOn the other hand when a non-contentious hard fork is rolled out, one could\nargue that it's actually best for everyone if the remaining 1% chain\ndoesn't stand a chance of ever reaching 2016 blocks anymore (not even by a\ndecent sized attacker trying to double spend on stragglers). Also causing\nall alarm bells to go off in the non-updated clients.\n\nHave people thought through all the different scenarios yet?\n\nAnd would it not make sense to define whatever the best choice is as\nmandatory for any hard fork proposal? BIP9? (Realising attackers won't\nnecessarily follow BIPs anyway.)\n\nDoes something like this also play a role for soft forks?\n\nI do realise that it's quite possible for the first few blocks, mined after\nthe new rules become valid, to still be old style blocks. Thus maybe\ndefeating the whole planning.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160129/09171b31/attachment.html>"
            },
            {
                "author": "Gavin Andresen",
                "date": "2016-01-29T16:39:14",
                "message_text_only": "On Thu, Jan 28, 2016 at 9:31 PM, Jannes Faber via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi,\n>\n> Question if you'll allow me. This is not about Gavin's latest hard fork\n> proposal but in general about any hard (or soft) fork.\n>\n> I was surprised to see a period expressed in human time instead of in\n> block time:\n>\n> > Blocks with timestamps greater than or equal to the triggering block's\n> timestamp plus 28 days (60*60*24*28 seconds) shall have the new limits.\n>\n>\nBlock timestamps are in the 80-byte block header, so activation is\ncompletely deterministic and can be determined from just the sequence of\nblock headers. There are no edge cases to worry about.\n\nBut even more so I would expect there to be significant differences in\n> effects on non-updated clients depending on the moment (expressed as block\n> number) of applying the new rules. I see a few options, all relating to the\n> 2016 blocks recalibration window.\n>\n\nIt doesn't matter much where in the difficulty period the fork happens; if\nit happens in the middle, the lower-power fork's difficulty will adjust a\nlittle quicker.\n\nExample:  (check my math, I'm really good at screwing up at basic\narithmetic):\n\nFork at block%2016:  25% hashpower will take 8 weeks to produce 2016\nblocks, difficulty drops by 4.\n\nFork one-week (halfway) into difficulty period:  25% hashpower will take 4\nweeks to adjust, difficulty drops by 5/2 = 2.5\nIt will then take another 3.2 weeks to get to the next difficult adjustment\nperiod and normal 10-minute blocks.\n\nThat's an unrealisitic scenario, though-- there will not be 25% of hash\npower on a minority fork. I wrote about why in a blog post today:\n\nhttp://gavinandresen.ninja/minority-branches\n\nIf you assume a more realistic single-digit-percentage of hash power on the\nminority fork, then the numbers get silly (e.g. two or three months of an\nhour or three between blocks before a difficulty adjustment).\n\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160129/9d042bb9/attachment.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2016-01-29T18:50:14",
                "message_text_only": "On Fri, Jan 29, 2016 at 5:39 PM, Gavin Andresen via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> On Thu, Jan 28, 2016 at 9:31 PM, Jannes Faber via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> It doesn't matter much where in the difficulty period the fork happens; if\n> it happens in the middle, the lower-power fork's difficulty will adjust a\n> little quicker.\n\nThe reason why BIP9 (versionbits) only checks for new activations\nduring difficulty retargettings is a simple optimization to only check\n1/2016 of the blocks.\nI suspect the check itself is not that costly for Bitcoin Core, which\nhas all the block headers in memory anyway, but I don't think we\nshould assume that will be the case for all implementations.\n\n<BIP99 aside comment>\nAs an aside, BIP99 never recommends a 75% mining signaling activation\nthreshold: it recommends 95% for uncontroversial rule changes and no\nminer signaling at all for controversial hardforks.\nI still have to update BIP99 with some later changes I commented at\nScaling Bitcoin HK like signaling hardfork activation with the\n\"negative int32_t bit\" so that old clients are forced to\nupgrade/decide. We could start deploying better ways to inform users\nabout a hardfork event, but of course those changes cannot be applied\nto older software that is already deployed (but hopefully they will\nstill notice something is weird is happening if the longest chain that\nkeeps growing is invalid because it contained a block with a negative\nversion in it).\nBut I'm yet to see a single hardfork proposal that follows BIP99's\nrecommendations besides the hardfork proposed in BIP99 itself, which\nshould consist on a manageable list of very simple to deploy fixes\nlike the timewarp fix forward-ported from Freicoin 0.8 for the BIP. I\nhaven't seen much interest in growing that little list of \"a few fixes\nnobody disagrees are bugs or sub-optimal design decisions, plus the\nchanges are easy to implement both separately and as a whole\" either.\nI cannot say I have seen any opposition at all to BIP99 as a hardfork\neither, but I naively expected people would ask me to implement more\nthings for BIP99 besides\nhttps://github.com/bitcoin/bitcoin/compare/0.11...jtimon:hardfork-timewarp-0.11\nor even contribute the patches themselves. For all that, I don't\nconsider BIP99 a priority to work on and I plan to complete it at some\npoint later, unless there's a time limit for a BIP to be in the\n\"draft\" state or something.\nIf someone else considers completing BIP99 a priority, I'm happy to\nreview and integrate things, though. Thanks again to all the reviewers\nand contributors to the BIP at this time and I'm sorry that it has\nbeen stuck for some time. Maybe the classification/recommendations\nshould have been a BIP without code and the hardfork proposal itself\nshould have been another one and that would have been clearer. I just\nwanted to have some code on my first BIP (and as said the plan is\nstill to put more code at some point).\n</BIP99 aside comment>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-01-29T19:11:52",
                "message_text_only": "On Fri, Jan 29, 2016 at 03:31:05AM +0100, Jannes Faber via bitcoin-dev wrote:\n> On the other hand when a non-contentious hard fork is rolled out, one could\n> argue that it's actually best for everyone if the remaining 1% chain\n> doesn't stand a chance of ever reaching 2016 blocks anymore (not even by a\n> decent sized attacker trying to double spend on stragglers). Also causing\n> all alarm bells to go off in the non-updated clients.\n> \n> Have people thought through all the different scenarios yet?\n\nI wrote up some of those risks in my \"Soft Forks Are Safer Than Hard\nForks\" post the other week:\n\nhttps://petertodd.org/2016/soft-forks-are-safer-than-hard-forks\n\nI was writing mainly in terms of technical risks for deployment\nnon-controversial forks; for controversial forks there's many more\nfailure scenarios. In any case, on technical grounds alone it's obvious\nthat hard-forks without very high - 95% or so - activation thresholds\nare quite dangerous.\n\nIn general, it should be remembered that high activation thresholds for\nhard-forks can always be soft-forked down after the fact. For instance,\nsuppose we initially used 100% support over the past one month of blocks\nas a hard-fork threshold, but can't get more than 96% support. A\nsoft-fork with the following rule can be implemented:\n\n    If 95% of the past blocks vote yes, voting against the hard-fork is\n    not allowed.\n\nAs soft-forks can be rolled out quite quickly, implementing this in the\nevent that a hard-fork isn't getting sufficient support won't add much\ndelay to the overall process; as it is a soft-fork, only miners need to\nadopt it for it to take effect.\n\nFor this reason I'd suggest any hard fork use 99%+ activation\nthresholds, measured over multi-week timespan. Hard-forks should not be\ncontroversial for good social/political reasons anyway, so there's\nlittle harm in most cases to at worst delaying the fork by two or three\nmonths if stragglers won't upgrade (in very rare cases like security\nissues there may be exceptions; blocksize is certainly not one of those\ncases).\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n000000000000000005822b77a904129795a3ff4167c57ed1044f5a93512c830f\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20160129/14717ba2/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Best (block nr % 2016) for hard fork activation?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Peter Todd",
                "Jorge Tim\u00f3n",
                "Jannes Faber",
                "Gavin Andresen"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 9915
        }
    },
    {
        "title": "[bitcoin-dev] SegWit GBT updates",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2016-01-30T18:50:02",
                "message_text_only": "I've completed an initial draft of a BIP for updating getblocktemplate for \nsegregated witness here:\n    https://github.com/luke-jr/bips/blob/segwit_gbt/bip-segwit-gbt.mediawiki\n\nPlease review and comment (especially with regard to the changes in the \nsigoplimits handling).\n\n(Note: libblkmaker's reference implementation is at this time incompatible \nwith the \"last output\" rule in this BIP.)\n\nThanks,\n\nLuke"
            }
        ],
        "thread_summary": {
            "title": "SegWit GBT updates",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Luke Dashjr"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 408
        }
    }
]