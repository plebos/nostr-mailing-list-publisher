[
    {
        "title": "[bitcoin-dev] On adaptor security (in protocols)",
        "thread_messages": [
            {
                "author": "Lloyd Fournier",
                "date": "2023-05-01T04:23:30",
                "message_text_only": "Hi waxwing,\n\nI think your view of the uselessness of single signer adaptors is too\npessimistic. The claim you make is that they \"don't provide a way to\ncreate  enforcement that the publication of signature on a pre-defined\nmessage will reveal a secret'' and so are useless. I think this is wrong.\nIf I hold a secret key for X and create a signature adaptor with some\nencryption key Y with message m and do not create any further signatures\n(adaptor or otherwise) on m, then any signature on m that is published\nnecessarily reveals the secret on Y to me. This is very useful and has\nalready been used for years by DLCs in production.\n\nI haven't read the proofs in detail but I am optimistic about your\napproach. One thing I was considering while reading is that you could make\na general proof against all secure Schnorr signing scheme in the ROM by\nsimply extending the ROM forwarding approach from Aumayer et al to all\n\"tweak\" operations on the elements that go into the Schnorr challenge hash\ni.e. the public key and the nonce. After all whether it's MuSig2, MuSig,\nFROST they all must call some RO. I think we can prove that if we apply any\nbijective map to the (X,R) tuple before they go into the challenge hash\nfunction then any Schnorr-like scheme that was secure before will be secure\nwhen bip32/TR tweaking (i.e. tweaking X) and adaptor tweaking (tweaking R)\nis applied to it. This would be cool because then we could prove all these\nvariants secure for all schemes past and present in one go. I haven't got a\nconcrete approach but the proofs I've looked at all seem to share this\nstructure.\n\nCheers,\n\nLL\n\nOn Sun, 30 Apr 2023 at 00:20, AdamISZ via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi list,\n> I was motivated to look more carefully at the question of the security of\n> using signature adaptors after recently getting quite enthused about the\n> idea of using adaptors across N signing sessions to do a kind of multiparty\n> swap. But of course security analysis is also much more important for the\n> base case of 2 party swapping, which is of .. some considerable practical\n> importance :)\n>\n> There is work (referenced in Section 3 here) that's pretty substantial on\n> \"how secure are adaptors\" (think in terms of security reductions) already\n> from I guess the 2019-2021 period. But I wanted to get into scenarios of\n> multiple adaptors at once or multiple signing sessions at once with the\n> *same* adaptor (as mentioned above, probably this is the most important\n> scenario).\n>\n> To be clear this is the work of an amateur and is currently unreviewed -\n> hence (a) me posting it here and (b) putting the paper on github so people\n> can easily add specific corrections or comments if they like:\n>\n> https://github.com/AdamISZ/AdaptorSecurityDoc/blob/main/adaptorsecurity.pdf\n>\n> I'll note that I did the analysis only around MuSig, not MuSig2.\n>\n> The penultimate (\"third case\"), that as mentioned, of \"multiple signing\n> sessions, same adaptor\" proved to be the most interesting: in trying to\n> reduce this to ECDLP I found an issue around sequencing. It may just be\n> irrelevant but I'd be curious to hear what others think about that.\n>\n> If nothing else, I'd be very interested to hear what experts in the field\n> have to say about security reductions for this primitive in the case of\n> multiple concurrent signing sessions (which of course has been analyzed\n> very carefully already for base MuSig(2)).\n>\n> Cheers,\n> AdamISZ/waxwing\n>\n>\n>\n>\n> Sent with Proton Mail secure email.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230501/5c70f1ea/attachment.html>"
            },
            {
                "author": "AdamISZ",
                "date": "2023-05-01T18:37:27",
                "message_text_only": "Hi Lloyd,\nthanks for taking a look.\n\n> I think your view of the uselessness of single signer adaptors is too pessimistic. The claim you make is that they \"don't provide a way to create enforcement that the publication of signature on a pre-defined message will reveal a secret'' and so are useless. I think this is wrong. If I hold a secret key for X and create a signature adaptor with some encryption key Y with message m and do not create any further signatures (adaptor or otherwise) on m, then any signature on m that is published necessarily reveals the secret on Y to me. This is very useful and has already been used for years by DLCs in production.\n\nI'm struggling with this one - say I hold privkey x for pubkey X. And I publish adaptor for a point Y (DL y) for message m, like: s' = k - y + H(R|X|m)x with k the nonce and R the nonce point.\n\nAnd to get the basics clear first, if I publish s = k + H(R|X|m)x then of course the secret y is revealed.\n\nWhat do you mean in saying \"any signature on m that is published reveals y\"? Clearly you don't mean any signature on any key (i.e. not the key X). But I also can't parse it if you mean \"any signature on m using key X\", because if I go ahead and publish s = k_2 + H(R_2|X|m)x, it has no algebraic relationship to the adaptor s' as defined above, right?\n\nI think the point of confusion is maybe about the DLC construct? I referenced that in Section 4.2, parenthetically, because it's analogous in one sense - in MuSig(2) you're fixing R via a negotiation, whereas in Dryja's construct you're fixing R \"by definition\". When I was talking about single key Schnorr, I was saying that's what's missing, and thereby making them useless.\n\nI think I must have missed some implicit concept in your argument otherwise?\n\n> I haven't read the proofs in detail but I am optimistic about your approach\n\nAppreciate it, but I fear the optimism is misplaced; as you can see from some notes I made in Issue 1, I think I had a pretty substantially invalid line of reasoning in those proof. Probably I need to revert to the forking lemma style arguments that you and Aumayr et al (and some others) took. I also am revisiting a clearer definition of what security threats need to be addressed. It all seems very nuanced.\n\nBut hey, that's why I published it and asked for feedback - if nothing else it made *me* think more carefully :)\n\n> One thing I was considering while reading is that you could make a general proof against all secure Schnorr signing scheme in the ROM by simply extending the ROM forwarding approach from Aumayer et al to all \"tweak\" operations on the elements that go into the Schnorr challenge hash i.e. the public key and the nonce. After all whether it's MuSig2, MuSig, FROST they all must call some RO. I think we can prove that if we apply any bijective map to the (X,R) tuple before they go into the challenge hash function then any Schnorr-like scheme that was secure before will be secure when bip32/TR tweaking (i.e. tweaking X) and adaptor tweaking (tweaking R) is applied to it. This would be cool because then we could prove all these variants secure for all schemes past and present in one go. I haven't got a concrete approach but the proofs I've looked at all seem to share this structure.\nAppreciate these thoughts. In particular your point about \"generalization of tweaking\" is clearly important, I bet other people have thought about it before me. Btw are there any papers on tweaking in general? I'm suddenly reminded of Poelstra's paper on taproot itself, which istr was an entirely different approach.\n\nSent with [Proton Mail](https://proton.me/) secure email.\n\n------- Original Message -------\nOn Sunday, April 30th, 2023 at 22:23, Lloyd Fournier via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi waxwing,\n>\n> I think your view of the uselessness of single signer adaptors is too pessimistic. The claim you make is that they \"don't provide a way to create enforcement that the publication of signature on a pre-defined message will reveal a secret'' and so are useless. I think this is wrong. If I hold a secret key for X and create a signature adaptor with some encryption key Y with message m and do not create any further signatures (adaptor or otherwise) on m, then any signature on m that is published necessarily reveals the secret on Y to me. This is very useful and has already been used for years by DLCs in production.\n>\n> I haven't read the proofs in detail but I am optimistic about your approach. One thing I was considering while reading is that you could make a general proof against all secure Schnorr signing scheme in the ROM by simply extending the ROM forwarding approach from Aumayer et al to all \"tweak\" operations on the elements that go into the Schnorr challenge hash i.e. the public key and the nonce. After all whether it's MuSig2, MuSig, FROST they all must call some RO. I think we can prove that if we apply any bijective map to the (X,R) tuple before they go into the challenge hash function then any Schnorr-like scheme that was secure before will be secure when bip32/TR tweaking (i.e. tweaking X) and adaptor tweaking (tweaking R) is applied to it. This would be cool because then we could prove all these variants secure for all schemes past and present in one go. I haven't got a concrete approach but the proofs I've looked at all seem to share this structure.\n>\n> Cheers,\n>\n> LL\n>\n> On Sun, 30 Apr 2023 at 00:20, AdamISZ via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi list,\n>> I was motivated to look more carefully at the question of the security of using signature adaptors after recently getting quite enthused about the idea of using adaptors across N signing sessions to do a kind of multiparty swap. But of course security analysis is also much more important for the base case of 2 party swapping, which is of .. some considerable practical importance :)\n>>\n>> There is work (referenced in Section 3 here) that's pretty substantial on \"how secure are adaptors\" (think in terms of security reductions) already from I guess the 2019-2021 period. But I wanted to get into scenarios of multiple adaptors at once or multiple signing sessions at once with the *same* adaptor (as mentioned above, probably this is the most important scenario).\n>>\n>> To be clear this is the work of an amateur and is currently unreviewed - hence (a) me posting it here and (b) putting the paper on github so people can easily add specific corrections or comments if they like:\n>>\n>> https://github.com/AdamISZ/AdaptorSecurityDoc/blob/main/adaptorsecurity.pdf\n>>\n>> I'll note that I did the analysis only around MuSig, not MuSig2.\n>>\n>> The penultimate (\"third case\"), that as mentioned, of \"multiple signing sessions, same adaptor\" proved to be the most interesting: in trying to reduce this to ECDLP I found an issue around sequencing. It may just be irrelevant but I'd be curious to hear what others think about that.\n>>\n>> If nothing else, I'd be very interested to hear what experts in the field have to say about security reductions for this primitive in the case of multiple concurrent signing sessions (which of course has been analyzed very carefully already for base MuSig(2)).\n>>\n>> Cheers,\n>> AdamISZ/waxwing\n>>\n>> Sent with Proton Mail secure email.\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230501/bf1c368a/attachment-0001.html>"
            },
            {
                "author": "AdamISZ",
                "date": "2023-05-03T12:58:21",
                "message_text_only": "Hi Lloyd and list,\n\nWhile on the road and re-downloading the papers, I realised there is a \"new\" paper published December 2022 by Wei Dai, Okamoto and Yamamoto on this same topic:\n\nhttps://eprint.iacr.org/2022/1687\n\nand, strikingly, it focuses on the exact same point I made here in Section 3 - namely that the aEUF-CMA definition of the Aumayr paper doesn't address the possibility of multiple-adaptors-on-the-same-message-at-once.\n\nA pretty big facepalm moment that I didn't bother to search carefully enough to find that!\n\nAlso it's cool that such renowned cryptographers are turning their heads towards this subject :)\n\nIt does have a nice illustration of why that definition (which as you know has been reused by other researchers) is insufficient, by making up a malicious version of the \"preSign\" (i.e. adaptor-sign) algorithm which leaks an arbitrary signature after two calls, while it still fits the definition of aEUF-CMA!\n\nThe paper has a *lot* of meat in terms of security definitions (only had a brief chance to read parts of it, as I'm on the road, so this is high level vague perspective), but afaict it is not actually attempting to rewrite reductions(?), so perhaps more work is needed on that(?).\n\nCheers,Adam\n\nSent with [Proton Mail](https://proton.me/) secure email.\n\n------- Original Message -------\nOn Monday, May 1st, 2023 at 12:37, AdamISZ via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Lloyd,\n> thanks for taking a look.\n>\n>> I think your view of the uselessness of single signer adaptors is too pessimistic. The claim you make is that they \"don't provide a way to create enforcement that the publication of signature on a pre-defined message will reveal a secret'' and so are useless. I think this is wrong. If I hold a secret key for X and create a signature adaptor with some encryption key Y with message m and do not create any further signatures (adaptor or otherwise) on m, then any signature on m that is published necessarily reveals the secret on Y to me. This is very useful and has already been used for years by DLCs in production.\n>\n> I'm struggling with this one - say I hold privkey x for pubkey X. And I publish adaptor for a point Y (DL y) for message m, like: s' = k - y + H(R|X|m)x with k the nonce and R the nonce point.\n>\n> And to get the basics clear first, if I publish s = k + H(R|X|m)x then of course the secret y is revealed.\n>\n> What do you mean in saying \"any signature on m that is published reveals y\"? Clearly you don't mean any signature on any key (i.e. not the key X). But I also can't parse it if you mean \"any signature on m using key X\", because if I go ahead and publish s = k_2 + H(R_2|X|m)x, it has no algebraic relationship to the adaptor s' as defined above, right?\n>\n> I think the point of confusion is maybe about the DLC construct? I referenced that in Section 4.2, parenthetically, because it's analogous in one sense - in MuSig(2) you're fixing R via a negotiation, whereas in Dryja's construct you're fixing R \"by definition\". When I was talking about single key Schnorr, I was saying that's what's missing, and thereby making them useless.\n>\n> I think I must have missed some implicit concept in your argument otherwise?\n>\n>> I haven't read the proofs in detail but I am optimistic about your approach\n>\n> Appreciate it, but I fear the optimism is misplaced; as you can see from some notes I made in Issue 1, I think I had a pretty substantially invalid line of reasoning in those proof. Probably I need to revert to the forking lemma style arguments that you and Aumayr et al (and some others) took. I also am revisiting a clearer definition of what security threats need to be addressed. It all seems very nuanced.\n>\n> But hey, that's why I published it and asked for feedback - if nothing else it made *me* think more carefully :)\n>\n>> One thing I was considering while reading is that you could make a general proof against all secure Schnorr signing scheme in the ROM by simply extending the ROM forwarding approach from Aumayer et al to all \"tweak\" operations on the elements that go into the Schnorr challenge hash i.e. the public key and the nonce. After all whether it's MuSig2, MuSig, FROST they all must call some RO. I think we can prove that if we apply any bijective map to the (X,R) tuple before they go into the challenge hash function then any Schnorr-like scheme that was secure before will be secure when bip32/TR tweaking (i.e. tweaking X) and adaptor tweaking (tweaking R) is applied to it. This would be cool because then we could prove all these variants secure for all schemes past and present in one go. I haven't got a concrete approach but the proofs I've looked at all seem to share this structure.\n> Appreciate these thoughts. In particular your point about \"generalization of tweaking\" is clearly important, I bet other people have thought about it before me. Btw are there any papers on tweaking in general? I'm suddenly reminded of Poelstra's paper on taproot itself, which istr was an entirely different approach.\n>\n> Sent with [Proton Mail](https://proton.me/) secure email.\n>\n> ------- Original Message -------\n> On Sunday, April 30th, 2023 at 22:23, Lloyd Fournier via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi waxwing,\n>>\n>> I think your view of the uselessness of single signer adaptors is too pessimistic. The claim you make is that they \"don't provide a way to create enforcement that the publication of signature on a pre-defined message will reveal a secret'' and so are useless. I think this is wrong. If I hold a secret key for X and create a signature adaptor with some encryption key Y with message m and do not create any further signatures (adaptor or otherwise) on m, then any signature on m that is published necessarily reveals the secret on Y to me. This is very useful and has already been used for years by DLCs in production.\n>>\n>> I haven't read the proofs in detail but I am optimistic about your approach. One thing I was considering while reading is that you could make a general proof against all secure Schnorr signing scheme in the ROM by simply extending the ROM forwarding approach from Aumayer et al to all \"tweak\" operations on the elements that go into the Schnorr challenge hash i.e. the public key and the nonce. After all whether it's MuSig2, MuSig, FROST they all must call some RO. I think we can prove that if we apply any bijective map to the (X,R) tuple before they go into the challenge hash function then any Schnorr-like scheme that was secure before will be secure when bip32/TR tweaking (i.e. tweaking X) and adaptor tweaking (tweaking R) is applied to it. This would be cool because then we could prove all these variants secure for all schemes past and present in one go. I haven't got a concrete approach but the proofs I've looked at all seem to share this structure.\n>>\n>> Cheers,\n>>\n>> LL\n>>\n>> On Sun, 30 Apr 2023 at 00:20, AdamISZ via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Hi list,\n>>> I was motivated to look more carefully at the question of the security of using signature adaptors after recently getting quite enthused about the idea of using adaptors across N signing sessions to do a kind of multiparty swap. But of course security analysis is also much more important for the base case of 2 party swapping, which is of .. some considerable practical importance :)\n>>>\n>>> There is work (referenced in Section 3 here) that's pretty substantial on \"how secure are adaptors\" (think in terms of security reductions) already from I guess the 2019-2021 period. But I wanted to get into scenarios of multiple adaptors at once or multiple signing sessions at once with the *same* adaptor (as mentioned above, probably this is the most important scenario).\n>>>\n>>> To be clear this is the work of an amateur and is currently unreviewed - hence (a) me posting it here and (b) putting the paper on github so people can easily add specific corrections or comments if they like:\n>>>\n>>> https://github.com/AdamISZ/AdaptorSecurityDoc/blob/main/adaptorsecurity.pdf\n>>>\n>>> I'll note that I did the analysis only around MuSig, not MuSig2.\n>>>\n>>> The penultimate (\"third case\"), that as mentioned, of \"multiple signing sessions, same adaptor\" proved to be the most interesting: in trying to reduce this to ECDLP I found an issue around sequencing. It may just be irrelevant but I'd be curious to hear what others think about that.\n>>>\n>>> If nothing else, I'd be very interested to hear what experts in the field have to say about security reductions for this primitive in the case of multiple concurrent signing sessions (which of course has been analyzed very carefully already for base MuSig(2)).\n>>>\n>>> Cheers,\n>>> AdamISZ/waxwing\n>>>\n>>> Sent with Proton Mail secure email.\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230503/549203d7/attachment-0001.html>"
            },
            {
                "author": "Lloyd Fournier",
                "date": "2023-05-08T04:37:48",
                "message_text_only": "Hi Waxwing,\n\nOn Tue, 2 May 2023 at 02:37, AdamISZ <AdamISZ at protonmail.com> wrote:\n\n> Hi Lloyd,\n> thanks for taking a look.\n>\n> > I think your view of the uselessness of single signer adaptors is too\n> pessimistic. The claim you make is that they \"don't provide a way to create\n> enforcement that the publication of signature on a pre-defined message will\n> reveal a secret'' and so are useless. I think this is wrong. If I hold a\n> secret key for X and create a signature adaptor with some encryption key Y\n> with message m and do not create any further signatures (adaptor or\n> otherwise) on m, then any signature on m that is published necessarily\n> reveals the secret on Y to me. This is very useful and has already been\n> used for years by DLCs in production.\n>\n> I'm struggling with this one - say I hold privkey x for pubkey X. And I\n> publish adaptor for a point Y (DL y) for message m, like: s' = k - y +\n> H(R|X|m)x with k the nonce and R the nonce point.\n>\n> And to get the basics clear first, if I publish s = k + H(R|X|m)x then of\n> course the secret y is revealed.\n>\n> What do you mean in saying \"any signature on m that is published reveals\n> y\"? Clearly you don't mean any signature on any key (i.e. not the key X).\n> But I also can't parse it if you mean \"any signature on m using key X\",\n> because if I go ahead and publish s = k_2 + H(R_2|X|m)x, it has no\n> algebraic relationship to the adaptor s' as defined above, right?\n>\n\nYes but suppose you do *not* create another signature adaptor or otherwise\non m. Since you've only generated one adaptor signature on m and no other\nsignatures on m there is no possibility that a signature on m that appears\nunder your key would not reveal y to you. This is an useful property in\ntheory and in practice.\n\n\n>\n> I think the point of confusion is maybe about the DLC construct? I\n> referenced that in Section 4.2, parenthetically, because it's analogous in\n> one sense - in MuSig(2) you're fixing R via a negotiation, whereas in\n> Dryja's construct you're fixing R \"by definition\". When I was talking about\n> single key Schnorr, I was saying that's what's missing, and thereby making\n> them useless.\n>\n>\nI was not referencing the DLC oracle attestation protocol - I am pointing\nout that DLC client implementations have been using single signer adaptor\nsignatures as signature encryption in practice for years for the\ntransaction signatures. There are even channel implementations using them\nas well as atomic swaps doing this iirc. It's a pretty useful thing!\n\nCheers,\n\nLL\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/3bfa2b54/attachment-0001.html>"
            },
            {
                "author": "AdamISZ",
                "date": "2023-05-11T05:12:39",
                "message_text_only": "Hi Lloyd,\n\n> Yes but suppose you do *not* create another signature adaptor or otherwise on m. Since you've only generated one adaptor signature on m and no other signatures on m there is no possibility that a signature on m that appears under your key would not reveal y to you. This is an useful property in theory and in practice.\n\nAh yes, this is a pretty big error on my part! Thanks for walking it through. It's where this is analogous to asymmetric encryption. I remember you framing it like that, in terms of asymmetric encryption (but with the one-time, a bit like symmetric, twist), in your paper. I should have re-read it a lot more thoroughly! :)\n\nI must have had this misconception floating around in my head about adaptors for years.\n\nIt's interesting that it didn't help choosing the framing : s' = k - t +H(R|P|m)x instead of s' = k + H(R+T|P|m)x although, as I noted there, they're equivalent (indeed, the former framing was also used in e.g. the description of the atomic swap in the scriptless-scripts writeups repo). But in the latter framing it's much more obvious that you can do this, given that you can just plug T into the hash directly.\n\nA sidebar, but it immediately brings it to mind: the canonical adaptor based swap, you can do it with only one half being multisig like this, right? Alice can encrypt the single-key signature for her payment to Bob, with the encryption key being T= sG, where s is the partial signature of Bob, on the payout from a multisig, to Alice. That way Bob only gets his money in the single sig (A->B) tx, if he reveals his partial sig on the multisig. I don't think it's of practical interest (1 multisig instead of 2? meh), but .. I don't see anywhere that potential variant being written down? Is there some obvious flaw with that?\n\nCheers,\nwaxwing/AdamISZ\n\nSent with [Proton Mail](https://proton.me/) secure email.\n\n------- Original Message -------\nOn Monday, May 8th, 2023 at 05:37, Lloyd Fournier via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Waxwing,\n>\n> On Tue, 2 May 2023 at 02:37, AdamISZ <AdamISZ at protonmail.com> wrote:\n>\n>> Hi Lloyd,\n>> thanks for taking a look.\n>>\n>>> I think your view of the uselessness of single signer adaptors is too pessimistic. The claim you make is that they \"don't provide a way to create enforcement that the publication of signature on a pre-defined message will reveal a secret'' and so are useless. I think this is wrong. If I hold a secret key for X and create a signature adaptor with some encryption key Y with message m and do not create any further signatures (adaptor or otherwise) on m, then any signature on m that is published necessarily reveals the secret on Y to me. This is very useful and has already been used for years by DLCs in production.\n>>\n>> I'm struggling with this one - say I hold privkey x for pubkey X. And I publish adaptor for a point Y (DL y) for message m, like: s' = k - y + H(R|X|m)x with k the nonce and R the nonce point.\n>>\n>> And to get the basics clear first, if I publish s = k + H(R|X|m)x then of course the secret y is revealed.\n>>\n>> What do you mean in saying \"any signature on m that is published reveals y\"? Clearly you don't mean any signature on any key (i.e. not the key X). But I also can't parse it if you mean \"any signature on m using key X\", because if I go ahead and publish s = k_2 + H(R_2|X|m)x, it has no algebraic relationship to the adaptor s' as defined above, right?\n>\n> Yes but suppose you do *not* create another signature adaptor or otherwise on m. Since you've only generated one adaptor signature on m and no other signatures on m there is no possibility that a signature on m that appears under your key would not reveal y to you. This is an useful property in theory and in practice.\n>\n>> I think the point of confusion is maybe about the DLC construct? I referenced that in Section 4.2, parenthetically, because it's analogous in one sense - in MuSig(2) you're fixing R via a negotiation, whereas in Dryja's construct you're fixing R \"by definition\". When I was talking about single key Schnorr, I was saying that's what's missing, and thereby making them useless.\n>\n> I was not referencing the DLC oracle attestation protocol - I am pointing out that DLC client implementations have been using single signer adaptor signatures as signature encryption in practice for years for the transaction signatures. There are even channel implementations using them as well as atomic swaps doing this iirc. It's a pretty useful thing!\n>\n> Cheers,\n>\n> LL\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230511/8d136b60/attachment-0001.html>"
            },
            {
                "author": "Lloyd Fournier",
                "date": "2023-05-11T11:41:14",
                "message_text_only": "On Thu, 11 May 2023 at 13:12, AdamISZ <AdamISZ at protonmail.com> wrote:\n\n>\n> A sidebar, but it immediately brings it to mind: the canonical adaptor\n> based swap, you can do it with only one half being multisig like this,\n> right? Alice can encrypt the single-key signature for her payment to Bob,\n> with the encryption key being T= sG, where s is the partial signature of\n> Bob, on the payout from a multisig, to Alice. That way Bob only gets his\n> money in the single sig (A->B) tx, if he reveals his partial sig on the\n> multisig. I don't think it's of practical interest (1 multisig instead of\n> 2? meh), but .. I don't see anywhere that potential variant being written\n> down? Is there some obvious flaw with that?\n>\n\nI think the problem is that Alice can still move the funds even if Bob\ndecrypts and broadcasts by revealing s if she gets confirmed first. I think\nyou always need a multisig in these kinds of situations but it need not be\na key aggregated multisig like MuSig -- this was the point I wanted to make\n(in retrospect clumsily). I don't think I can name a useful use of a single\nsigner adaptor signature in Bitcoin at least not without some kind of other\nspending constraint. So your intuitive point holds in practice most of the\ntime.\n\nLL\n\nCheers,\n> waxwing/AdamISZ\n>\n> Sent with Proton Mail <https://proton.me/> secure email.\n>\n> ------- Original Message -------\n> On Monday, May 8th, 2023 at 05:37, Lloyd Fournier via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Hi Waxwing,\n>\n> On Tue, 2 May 2023 at 02:37, AdamISZ <AdamISZ at protonmail.com> wrote:\n>\n>> Hi Lloyd,\n>> thanks for taking a look.\n>>\n>> > I think your view of the uselessness of single signer adaptors is too\n>> pessimistic. The claim you make is that they \"don't provide a way to create\n>> enforcement that the publication of signature on a pre-defined message will\n>> reveal a secret'' and so are useless. I think this is wrong. If I hold a\n>> secret key for X and create a signature adaptor with some encryption key Y\n>> with message m and do not create any further signatures (adaptor or\n>> otherwise) on m, then any signature on m that is published necessarily\n>> reveals the secret on Y to me. This is very useful and has already been\n>> used for years by DLCs in production.\n>>\n>> I'm struggling with this one - say I hold privkey x for pubkey X. And I\n>> publish adaptor for a point Y (DL y) for message m, like: s' = k - y +\n>> H(R|X|m)x with k the nonce and R the nonce point.\n>>\n>> And to get the basics clear first, if I publish s = k + H(R|X|m)x then of\n>> course the secret y is revealed.\n>>\n>> What do you mean in saying \"any signature on m that is published reveals\n>> y\"? Clearly you don't mean any signature on any key (i.e. not the key X).\n>> But I also can't parse it if you mean \"any signature on m using key X\",\n>> because if I go ahead and publish s = k_2 + H(R_2|X|m)x, it has no\n>> algebraic relationship to the adaptor s' as defined above, right?\n>>\n>\n> Yes but suppose you do *not* create another signature adaptor or otherwise\n> on m. Since you've only generated one adaptor signature on m and no other\n> signatures on m there is no possibility that a signature on m that appears\n> under your key would not reveal y to you. This is an useful property in\n> theory and in practice.\n>\n>\n>> I think the point of confusion is maybe about the DLC construct? I\n>> referenced that in Section 4.2, parenthetically, because it's analogous in\n>> one sense - in MuSig(2) you're fixing R via a negotiation, whereas in\n>> Dryja's construct you're fixing R \"by definition\". When I was talking about\n>> single key Schnorr, I was saying that's what's missing, and thereby making\n>> them useless.\n>>\n>> I was not referencing the DLC oracle attestation protocol - I am pointing\n> out that DLC client implementations have been using single signer adaptor\n> signatures as signature encryption in practice for years for the\n> transaction signatures. There are even channel implementations using them\n> as well as atomic swaps doing this iirc. It's a pretty useful thing!\n>\n> Cheers,\n>\n> LL\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230511/d9dce7e2/attachment-0001.html>"
            },
            {
                "author": "AdamISZ",
                "date": "2023-05-14T08:37:50",
                "message_text_only": "> I think the problem is that Alice can still move the funds even if Bob decrypts and broadcasts by revealing s if she gets confirmed first.\nIndeed. Imagine forgetting that, couldn't be me :)\n\n> I think you always need a multisig in these kinds of situations but it need not be a key aggregated multisig like MuSig -- this was the point I wanted to make (in retrospect clumsily). I don't think I can name a useful use of a single signer adaptor signature in Bitcoin at least not without some kind of other spending constraint. So your intuitive point holds in practice most of the time.\n\nIndeed I do have a similar memory of earlier discussions/thoughts that: the finesse is that it only needs to be multisig, which is not\u200b the same as it needing to be musig, or let's say aggregated. The conversation has shifted over time because a lot of the first ideas (and papers) were pre-BIP340 activation and included ECDSA variants. A good example of the lack of clarity on this is the aforementioned Wei Dai paper, in which their base example is a swap without any multisig, thus ignoring the double spend issue (forgiveable, they are focused on different things in that paper). It's striking how unclear all this is (perhaps, just for me!) ...\n\n... so let's see if I have it right:\n(1) - single key signature adaptor in isolation is basically useless, in a Bitcoin context (signature is on a utxo) **\n(2) - single key signature adaptor in combination with another locking condition on the utxo, such as another pubkey lock (e.g. op_checksigadd/op_checkmultisig), is useful in swapping a signature for a secret, but it requires using the variant of the primitive in which the non-secret-owner is the one encrypting (i.e. asymmetric encryption analog), and the secret owner is giving the decryption.\n(3) - most natural scenario, using aggregated signature schemes like MuSig1/2, can allow the above, but can also allow the variant in which the secret owner starts by providing the encryption, and then at a later stage of the protocol, releases the decryption (this option is not available for (2), since the provision of an adaptor for my own\u200b signature does not force me, in that case to use the same R, and therefore a corresponding signature). (the canonical description in [1] for any reader who's not familiar, outlines this case).\n\n(the difference between (2) and (3) can maybe best be grokked as the choice between \"I need any signature of yours\u200b\u200b - I can get one by decrypting it using my secret key, or you can just give me one\" vs \"I need a specific signature of yours, I'll get it when you decrypt, using your own secret, the other signature\" - and here you see that the second one has a requirement that I can't let you use an alternate for the first signature, because then I get nothing.)\n\n\u200b** But now I'm confused about your earlier reference to DLC implementations using single signer constructions in the previous mail (your phrase was \"using single signer adaptor signatures as signature encryption in practice for years for the transaction signatures\") - can you link me to something about that? I couldn't immediately find something in the DLC specs repo, though I'm probably just missing it. I'm just really interested to know if there's another functionality I'm missing here, (since you said it wasn't oracle attestation, that you meant).\n\n[1] https://github.com/BlockstreamResearch/scriptless-scripts/blob/master/md/atomic-swap.md#atomic-swaps-using-adaptor-signatures\n\nCheers,\nAdamISZ/waxwing\n\nSent with [Proton Mail](https://proton.me/) secure email.\n\n------- Original Message -------\nOn Thursday, May 11th, 2023 at 12:41, Lloyd Fournier <lloyd.fourn at gmail.com> wrote:\n\n> On Thu, 11 May 2023 at 13:12, AdamISZ <AdamISZ at protonmail.com> wrote:\n>\n>> A sidebar, but it immediately brings it to mind: the canonical adaptor based swap, you can do it with only one half being multisig like this, right? Alice can encrypt the single-key signature for her payment to Bob, with the encryption key being T= sG, where s is the partial signature of Bob, on the payout from a multisig, to Alice. That way Bob only gets his money in the single sig (A->B) tx, if he reveals his partial sig on the multisig. I don't think it's of practical interest (1 multisig instead of 2? meh), but .. I don't see anywhere that potential variant being written down? Is there some obvious flaw with that?\n>\n> I think the problem is that Alice can still move the funds even if Bob decrypts and broadcasts by revealing s if she gets confirmed first. I think you always need a multisig in these kinds of situations but it need not be a key aggregated multisig like MuSig -- this was the point I wanted to make (in retrospect clumsily). I don't think I can name a useful use of a single signer adaptor signature in Bitcoin at least not without some kind of other spending constraint. So your intuitive point holds in practice most of the time.\n>\n> LL\n>\n>> Cheers,\n>> waxwing/AdamISZ\n>>\n>> Sent with [Proton Mail](https://proton.me/) secure email.\n>>\n>> ------- Original Message -------\n>> On Monday, May 8th, 2023 at 05:37, Lloyd Fournier via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Hi Waxwing,\n>>>\n>>> On Tue, 2 May 2023 at 02:37, AdamISZ <AdamISZ at protonmail.com> wrote:\n>>>\n>>>> Hi Lloyd,\n>>>> thanks for taking a look.\n>>>>\n>>>>> I think your view of the uselessness of single signer adaptors is too pessimistic. The claim you make is that they \"don't provide a way to create enforcement that the publication of signature on a pre-defined message will reveal a secret'' and so are useless. I think this is wrong. If I hold a secret key for X and create a signature adaptor with some encryption key Y with message m and do not create any further signatures (adaptor or otherwise) on m, then any signature on m that is published necessarily reveals the secret on Y to me. This is very useful and has already been used for years by DLCs in production.\n>>>>\n>>>> I'm struggling with this one - say I hold privkey x for pubkey X. And I publish adaptor for a point Y (DL y) for message m, like: s' = k - y + H(R|X|m)x with k the nonce and R the nonce point.\n>>>>\n>>>> And to get the basics clear first, if I publish s = k + H(R|X|m)x then of course the secret y is revealed.\n>>>>\n>>>> What do you mean in saying \"any signature on m that is published reveals y\"? Clearly you don't mean any signature on any key (i.e. not the key X). But I also can't parse it if you mean \"any signature on m using key X\", because if I go ahead and publish s = k_2 + H(R_2|X|m)x, it has no algebraic relationship to the adaptor s' as defined above, right?\n>>>\n>>> Yes but suppose you do *not* create another signature adaptor or otherwise on m. Since you've only generated one adaptor signature on m and no other signatures on m there is no possibility that a signature on m that appears under your key would not reveal y to you. This is an useful property in theory and in practice.\n>>>\n>>>> I think the point of confusion is maybe about the DLC construct? I referenced that in Section 4.2, parenthetically, because it's analogous in one sense - in MuSig(2) you're fixing R via a negotiation, whereas in Dryja's construct you're fixing R \"by definition\". When I was talking about single key Schnorr, I was saying that's what's missing, and thereby making them useless.\n>>>\n>>> I was not referencing the DLC oracle attestation protocol - I am pointing out that DLC client implementations have been using single signer adaptor signatures as signature encryption in practice for years for the transaction signatures. There are even channel implementations using them as well as atomic swaps doing this iirc. It's a pretty useful thing!\n>>>\n>>> Cheers,\n>>>\n>>> LL\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230514/3029371b/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "On adaptor security (in protocols)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "AdamISZ",
                "Lloyd Fournier"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 40476
        }
    },
    {
        "title": "[bitcoin-dev] proposal: new opcode OP_ZKP to enable ZKP-based spending authorization",
        "thread_messages": [
            {
                "author": "Weiji Guo",
                "date": "2023-05-01T12:46:30",
                "message_text_only": "Hi ZmnSCPxj,\n\nThank you very much for your insights. You are definitely right about\nmaking the verification keys consensus-critical and about how the weight\nunits. I totally agree that the weighting of ZKP the witness should be\nhigher. We will carry out some benchmarking to recommend a reasonable\nweight when we start to develop a GitHub PR.\n\nMeanwhile, as we can potentially aggregate many proofs or recursively\nverify even more, the average cost might still be manageable.\n\nRegards,\nWeiji\n\nOn Sun, Apr 30, 2023 at 10:16\u202fAM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Weiji,\n>\n> Have not completed reading, but this jumped out to me:\n>\n>\n>\n> > 3.  Dealing with system limitation: verification keys could be very long\n> and exceed the MAX_SCRIPT_ELEMENT_SIZE (520 bytes). They could be put into\n> configurations and only use their hash in the scriptPubKey. The\n> configuration information such as new verification keys could be propagated\n> through P2P messages (we might need a separate BIP for this);\n>\n> `scriptPubKey` is consensus-critical, and these new P2P messages would\n> have to be consensus-critical.\n>\n> As all nodes need to learn the new verification keys, we should consider\n> how much resources are spent on each node just to maintain and forever\n> remember verification keys.\n>\n> Currently our resource-tracking methodology is via the synthetic \"weight\n> units\" computation.\n> This reflects resources spent on acquiring block data, as well as\n> maintaining the UTXO database.\n> For instance, the \"witness discount\" where witness data (i.e. modern\n> equivalent of `scriptSig`) is charged 1/4 the weight units of other data,\n> exists because spending a UTXO reduces the resources spent in the UTXO\n> database, although still consumes resources in downloading block data\n> (hence only a discount, not free or negative/rebate).\n>\n> Similarly, any propagation of verification keys would need a similar\n> adjustment for weight units.\n>\n> As verification keys MUST be seen by all nodes before they can validate an\n> `OP_ZKP`, I would suggest that it is best included in block data (which\n> similarly needs to be seen by all nodes), together with some weight unit\n> adjustment for that data, depending on how much resources verification keys\n> would consume.\n> This is similar to how `scriptPubKey`s and amounts are included in block\n> data, as those data are kept in the UTXO database, which nodes must\n> maintain in order to validate the blockchain.\n>\n> If verification keys are permanent, they should probably be weighted\n> heavier than `scriptPubKey`s and amounts --- UTXOs can theoretically be\n> deleted later by spending the UTXO (which reduces UTXO database size),\n> while any data that must be permanently stored in a database must\n> correspondingly be weighted higher.\n>\n> Similarly, my understanding is that the CPU resources needed by validation\n> of generic ZKPs is higher than that required for validation of ECC\n> signatures.\n> Much of the current weight calculation assumes that witness data is\n> primarily ECC signatures, so if ZKP witnesses translate to higher resource\n> consumption, the weighting of ZKP witnesses should also be higher (i.e.\n> greater than the 1/4 witness-discounted weight of current witness data).\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230501/b08ce64e/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2023-05-02T15:01:01",
                "message_text_only": "Good morning Weiji,\n\n> Meanwhile, as we can potentially aggregate many proofs or recursively verify even more, the average cost might still be manageable.\n\nAre miners supposed to do this aggregation?\n\nIf miners do this aggregation, then that implies that all fullnodes must also perform the **non**-aggregated validation as transactions flow from transaction creators to miners, and that is the cost (viz. the **non**-aggregated cost) that must be reflected in the weight.\nWe should note that fullnodes are really miners with 0 hashpower, and any cost you impose on miners is a cost you impose on all fullnodes.\n\nIf you want to aggregate, you might want to do that in a separate network that does ***not*** involve Bitcoin fullnodes, and possibly allow for some kind of extraction of fees to do aggregation, then have already-aggregated transactions in the Bitcoin mempool, so that fullnodes only need validate already-aggregated transactions.\n\nRemember, validation is run when a transaction enters the mempool, and is **not** re-run when an in-mempool transaction is seen in a block (`blocksonly` of course does not follow this as it has no mempool, but most fullnodes are not `blocksonly`).\nIf you intend to aggregate transactions in the mempool, then at the worst case a fullnode will be validating every non-aggregated transaction, and that is what we want to limit by increasing the weight of heavy-validation transactions.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Weiji Guo",
                "date": "2023-05-04T15:31:22",
                "message_text_only": "Hi ZmnSCPxj,\n\nI do mean to have specialized computing power vendors, which could happen\nto be miners, or not. Optiming ZKP computations is rather different from\nBitcoin mining so I expect those vendors to be from more research-driven\nteams focused in cryptographic engineering.\n\nI am open to whether to put those transactions in mempool or not. I\napologize for giving an inaccurate number earlier about the verification\ncost. I just ran gnark-bench on my Mac M2, it turns out the cost for\nGroth16 verification could be as fast as 1ms. For Plonk it is around 1.6ms.\nSo it seems even a common fullnode could handle thousands of OP_ZKP\ntransactions. In that case, the ZKP transactions could be put into mempool,\nand be open to be aggregated by some vendor. Fullnodes should verify these\ntransactions as well. It does not seem a good idea to treat them with\nspecial rules as there is no guarantee that certain OP_ZKP transactions\nwill be aggregated or recursively verified. Of course, the weighting should\nbe well benchmarked and calculated. The cost for those *standalone* OP_ZKP\ntransactions might be higher due to more data and/or higher weighting. This\nincentivizes vendors to develop aggregation / recursive verification\nservices to drive down the fee requirements and profit from doing so (fee\nextraction). I also expect to see an open market where various vendors can\ncompete against each other, so it makes sense to have these transactions\nopenly visible to all participants.\n\nMeanwhile, some transactions are meant to be off-chain. For example, a\nwould-be smart contract can aggregate many related transactions in a OP_ZKP\ntransaction. Those aggregated transactions should *not* be transmitted\nwithin the Bitcoin network. They could even be *not* valid Bitcoin\ntransactions. Usually the smart contract operator or its community could\nhost such a service.\n\nConsider a potential situation in a few years: there are thousands of\nactive smart contracts based on OP_ZKP, and each block contains a few\nhundred OP_ZKP transactions, each one of them aggregates / recursively\nverifies many transactions. The effective TPS of the Bitcoin network could\nfar exceed the current value, reaching the range of thousands or even more.\n\nHope this clarifies.\nWeiji\n\nOn Tue, May 2, 2023 at 11:01\u202fPM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n>\n> Good morning Weiji,\n>\n> > Meanwhile, as we can potentially aggregate many proofs or recursively\n> verify even more, the average cost might still be manageable.\n>\n> Are miners supposed to do this aggregation?\n>\n> If miners do this aggregation, then that implies that all fullnodes must\n> also perform the **non**-aggregated validation as transactions flow from\n> transaction creators to miners, and that is the cost (viz. the\n> **non**-aggregated cost) that must be reflected in the weight.\n> We should note that fullnodes are really miners with 0 hashpower, and any\n> cost you impose on miners is a cost you impose on all fullnodes.\n>\n> If you want to aggregate, you might want to do that in a separate network\n> that does ***not*** involve Bitcoin fullnodes, and possibly allow for some\n> kind of extraction of fees to do aggregation, then have already-aggregated\n> transactions in the Bitcoin mempool, so that fullnodes only need validate\n> already-aggregated transactions.\n>\n> Remember, validation is run when a transaction enters the mempool, and is\n> **not** re-run when an in-mempool transaction is seen in a block\n> (`blocksonly` of course does not follow this as it has no mempool, but most\n> fullnodes are not `blocksonly`).\n> If you intend to aggregate transactions in the mempool, then at the worst\n> case a fullnode will be validating every non-aggregated transaction, and\n> that is what we want to limit by increasing the weight of heavy-validation\n> transactions.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230504/ccc94da5/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2023-05-04T17:13:09",
                "message_text_only": "Good morning Weiji,\n\nThe issue here is that non-aggregated transaction are a potential attack vector.\n\nAs the network is pseudonymous, an anonymous attacker can flood the fullnode mempool network with large numbers of non-aggregated transactions, then in cooperation with a miner confirm a single aggregated transaction with lower feerate than what it put in the several non-aggregated transactions.\nThe attacker ends up paying lower for the single confirmed transaction, even though it cost the fullnode network a significant amount of CPU to process and validate all the non-aggregated transactions.\n\nOnce the single aggregate transaction is confirmed, the fullnodes will remove the non-aggregated transactions from the mempool, clearing out their mempool limit.\nThen the attacker can once again flood the fullnode mempool network with more non-aggregated transactions, and again repeat with an aggregated transaction that pays below the total of the non-aggregated transactions, repeatedly increasing the load on the mempool.\n\nThus, we should really make transactions that could appear in the mempool non-aggregatable with other transactions in the mempool.\nYou should arrange for aggregation before the blockchain-level transaction hits the mempool.\n\nOne can compare cross-input signature aggregation designs.\nSignature aggregation is only allowed within a single blockchain-level transaction, not across transactions, precisely so that a transaction that appears in the mempool cannot have its signatures aggregated with other transactions, and preventing the above attack.\nAnyone trying to take advantage of signature aggregation needs to cooperatively construct the blockchain-level transaction outside of the mempool with other cooperating actors, all of which perform the validation themselves before anything hits the mempool.\n\nSimilarly I can imagine that cross-input ZKP aggregation would be acceptable, but not cross-transaction ZKP aggregation.\n(And if you want to push for ZKP aggregation, you should probably push for cross-input signature aggregation first, as you would probably need to solve similar problems in detail and I imagine signature aggregation is simpler than general ZKP aggregation.)\n\nAlways expect that the blockchain and its supporting network is attackable.\nDo ***NOT*** focus on blocks --- focus on the load on the mempool (the block weight limit is a limit on the mempool load, not a limit on the block CPU load!).\nThe mempool is a free service, we should take care not to make it abusable.\nOn the other hand, blockspace is a paid service, so load on it is less important; it is already paid for.\nI strongly recommend **DISALLOWING** aggregation of ZKPs once a transaction is in a form that could potentially hit the mempool, and to require paid services for aggregation, outside of the unpaid, free mempool.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Weiji Guo",
                "date": "2023-05-05T23:06:51",
                "message_text_only": "Hi ZmnSCPxy,\n\n> As the network is pseudonymous, an anonymous attacker can flood the\nfullnode mempool network with large numbers of non-aggregated transactions,\nthen in cooperation with a miner confirm a single aggregated transaction\nwith lower feerate than what it put in the several non-aggregated\ntransactions.\n\nArguably this is hardly a feasible attack. Let's suppose the attacker\ncreates 1000 such transactions, and attaches each transaction with a small\namount of transaction fee X. The total fee will be 1000*X collectible by\nthe aggregation vendor, who pays the miner a fee Y. We can reasonably\nassume that 1000*X is much larger than Y, yet X is much smaller than Y.\nNote that Y is already much larger than the regular fee for other\ntransactions as the aggregated transaction should contain many inputs and\nmany outputs, thus very large in size.\n\nNow, the attacker will have to generate proofs for these 1000 transactions,\nwhich is non-trivial; and pay for 1000*X upfront. The aggregation vendor\nhas to spend more computing power doing the aggregation (or recursive\nverification) and take (1000*X - Y) as profit. Miner gets Y.\n\nMiners are unlikely to collude with the attacker. I don't think the vendor\nwould, given profit of 1000*X - Y. Or the attacker could play the vendor,\nhowever, it is still not a trivial attack after spending lots of computing\npower generating all the proofs and aggregation/recursion, and paying at\nleast Y, which is also non-trivial given the size.\n\nAll that being said, let's focus on the OP_ZKP for now and leave\naggregation or recursive verification for future discussion. I brought up\nthe scalability issue just to stress that there is potential room for\nfurther improvements. The research and implementation might take much\nlonger. As far as I know, CISA (cross input signature aggregation) is still\nexperimental. Again, thank you very much for detailed analysis and replies.\n\nRegards,\nWeiji\n\nOn Fri, May 5, 2023 at 1:13\u202fAM ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n> Good morning Weiji,\n>\n> The issue here is that non-aggregated transaction are a potential attack\n> vector.\n>\n> As the network is pseudonymous, an anonymous attacker can flood the\n> fullnode mempool network with large numbers of non-aggregated transactions,\n> then in cooperation with a miner confirm a single aggregated transaction\n> with lower feerate than what it put in the several non-aggregated\n> transactions.\n> The attacker ends up paying lower for the single confirmed transaction,\n> even though it cost the fullnode network a significant amount of CPU to\n> process and validate all the non-aggregated transactions.\n>\n> Once the single aggregate transaction is confirmed, the fullnodes will\n> remove the non-aggregated transactions from the mempool, clearing out their\n> mempool limit.\n> Then the attacker can once again flood the fullnode mempool network with\n> more non-aggregated transactions, and again repeat with an aggregated\n> transaction that pays below the total of the non-aggregated transactions,\n> repeatedly increasing the load on the mempool.\n>\n> Thus, we should really make transactions that could appear in the mempool\n> non-aggregatable with other transactions in the mempool.\n> You should arrange for aggregation before the blockchain-level transaction\n> hits the mempool.\n>\n> One can compare cross-input signature aggregation designs.\n> Signature aggregation is only allowed within a single blockchain-level\n> transaction, not across transactions, precisely so that a transaction that\n> appears in the mempool cannot have its signatures aggregated with other\n> transactions, and preventing the above attack.\n> Anyone trying to take advantage of signature aggregation needs to\n> cooperatively construct the blockchain-level transaction outside of the\n> mempool with other cooperating actors, all of which perform the validation\n> themselves before anything hits the mempool.\n>\n> Similarly I can imagine that cross-input ZKP aggregation would be\n> acceptable, but not cross-transaction ZKP aggregation.\n> (And if you want to push for ZKP aggregation, you should probably push for\n> cross-input signature aggregation first, as you would probably need to\n> solve similar problems in detail and I imagine signature aggregation is\n> simpler than general ZKP aggregation.)\n>\n> Always expect that the blockchain and its supporting network is attackable.\n> Do ***NOT*** focus on blocks --- focus on the load on the mempool (the\n> block weight limit is a limit on the mempool load, not a limit on the block\n> CPU load!).\n> The mempool is a free service, we should take care not to make it abusable.\n> On the other hand, blockspace is a paid service, so load on it is less\n> important; it is already paid for.\n> I strongly recommend **DISALLOWING** aggregation of ZKPs once a\n> transaction is in a form that could potentially hit the mempool, and to\n> require paid services for aggregation, outside of the unpaid, free mempool.\n>\n> Regards,\n> ZmnSCPxj\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230506/68fe13b2/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2023-05-06T02:51:33",
                "message_text_only": "Good Morning Weiji,\n\n\n> Hi ZmnSCPxy,\n> > As the network is pseudonymous, an anonymous attacker can flood the fullnode mempool network with large numbers of non-aggregated transactions, then in cooperation with a miner confirm a single aggregated transaction with lower feerate than what it put in the several non-aggregated transactions.\n> \n> Arguably this is hardly a feasible attack. Let's suppose the attacker creates 1000 such transactions, and attaches each transaction with a small amount of transaction fee X. The total fee will be 1000*X collectible by the aggregation vendor, who pays the miner a fee Y. We can reasonably assume that 1000*X is much larger than Y, yet X is much smaller than Y. Note that Y is already much larger than the regular fee for other transactions as the aggregated transaction should contain many inputs and many outputs, thus very large in size.\n> \n> Now, the attacker will have to generate proofs for these 1000 transactions, which is non-trivial; and pay for 1000*X upfront. The aggregation vendor has to spend more computing power doing the aggregation (or recursive verification) and take (1000*X - Y) as profit. Miner gets Y.\n\nThe entire point is that there has to be a separate, paid aggregator, in order to ensure that the free mempool service is not overloaded.\nBasically, keep the aggregation outside the mempool, not in the mempool.\nIf aggregation is paid for, that is indeed sufficient to stop the attack, as you noted.\n\nRegards,\nZmnSCPxj"
            }
        ],
        "thread_summary": {
            "title": "proposal: new opcode OP_ZKP to enable ZKP-based spending authorization",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Weiji Guo"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 18449
        }
    },
    {
        "title": "[bitcoin-dev] Merkleize All The Things",
        "thread_messages": [
            {
                "author": "Salvatore Ingala",
                "date": "2023-05-01T13:11:08",
                "message_text_only": "Hi Johan,\n\nThanks for your message.\n\nI think games where all the possible futures can be enumerated are\nnot ideal to showcase MATT, as one could just fully represent them\nwith just CTV or COCV, and not use the \"data embedding\" at all.\n\nPerhaps rock-paper-scissors could be a better academic example. [1]\n\nI'm not sure this will fully address your question; however I think\nit's quite an instructive example, and I wanted to work it out for\nquite some time.\n\nIt would be interesting to explore some contracts where the size\nof the embedded data is substantially larger, and that could be\na natural next step to think about.\n\n\n### Rock paper scissors\n\nWe want a protocol between Alice and Bob, where they bet 1 coin each:\n\n1. Alice chooses and publishes her move;\n2. Bob chooses his move, and the pot is adjudicated as per the rules.\n\nOf course, if implemented naively, this wouldn't be a very fun game:\nBob would just wait to see Alice's move and play accordingly.\n\nThat's easy to fix, though:\n\n1. Alice publishes a commitment to her move\n2. Bob publishes his move in clear\n3. Alice reveals her move, and the pot is adjudicated.\n\nWe can encode Rock = 0, Paper = 1, Scissors = 2. Let m_A, m_B be\nAlice's and Bob's move, respectively. Then, it's easy to verify that:\n\u2212 m_B - m_A == 0 (mod 3) ==> it's a tie\n\u2212 m_B - m_A == 1 (mod 3) ==> Bob wins\n\u2212 m_B - m_A == 2 (mod 3) ==> Alice wins\n\nIn order to create a hiding commitment for Alice, she can choose a\n256-bit random number r_A, and compute:\n\n  c_A = SHA256(m_A || r_A)\n\nWith that in mind, the full protocol can go like this:\n\n1. Alice chooses her move m_A and a large random number r_A;\n   she posts c_A computed as above;\n2. Bob chooses m_B and publishes it;\n3. Alice publishes m_A and r_A, then the winner is adjudicated.\n\n\n### MATT playing RPS\n\nTo implement this with CICV/COCV, we can use just 3 transactions: in\nfact, Alice can already compute c_A and share it with Bob before they\nboth commit their coins into an encumbered UTXO. That also means that\nc_A can actually be hardcoded in the Scripts, rather than taking\nspace in the UTXO's embedded data.\n\nTherefore, they both put one coin each, and they send to an output\nwhose script is the state S0 described below.\n\nWe assume that the keypath in the P2TR defined below is either a NUMS\npoint, or perhaps a Musig2 aggregate key that can be used to settle\nthe game collaboratively.\n\nNote that there are 3 possible payout options that are fully known\nwhen the game starts: either Alice takes all the money, or they split\nevenly, or Bob takes all the money.\nSimilarly to the vault implementation [2], this seems to be another\ncase where CTV fits very well, as it allows to very efficiently\ndescribe the three possible outcomes by their CTV hashes. Let them\nbe <ctv-alice-wins>, <ctv-split>, <ctv-bob-wins>, respectively.\n\nTherefore, this avoids the need for 64-bit maths, and explicit amount\nintrospection \u2212 at least for these contracts.\n\n\n[State S0] (Start of the game, Alice moved; Bob's turn)\nSpending conditions:\n - after <forfait-delay>, Alice takes the money    // (Bob forfaits)\n - Bob posts m_B (0, 1 or 2); the next output is [S1] with data m_B\n\nThe first script is:\n  // witness: []\n  <forfait-delay>\n  OP_CHECKSEQUENCEVERIFY\n  OP_DROP\n  <ctv-alice-wins>\n  OP_CHECKTEMPLATEVERIFY\n\nThe second is\n  // witness: [<bob_sig> <m_B>]\n  OP_DUP 0 3 OP_WITHIN     // check that m_B is 0, 1 or 2\n\n  <internal_pubkey> OP_SWAP\n  <S1's taptree>\n  OP_CHECKOUTPUTCONTRACTVERIFY // check that the output is correct\n\n  <bob_pubkey>\n  OP_CHECKSIG\n\n\n[State S1] (Alice reveals m_A and adjudicates)\n - after <forfait-timeout>, Bob takes the money    // (Alice forfaits)\n - Alice posts correct m_A and r_A compatible with c_A;\n\n\nThe first script is symmetric to Bob's forfait script above.\n\nThe second condition can be split into three leaf scripts, one for\neach possible value of m_B - m_A (mod 3):\n\n  // witness: [<m_B> <m_A> <r_A>]\n\n  OP_OVER OP_DUP OP_TOALTSTACK  // save m_A\n  0 3 OP_WITHIN OP_VERIFY       // check that m_A is 0, 1 or 2\n\n  // check that SHA256(m_A || r_A) equals c_A\n  OP_2DUP\n  OP_CAT OP_SHA256\n  <c_A>\n  OP_EQUALVERIFY\n\n  OP_DUP\n  <internal_pubkey>, OP_SWAP\n  OP_CHECKINPUTCONTRACTVERIFY\n\n  OP_FROMALTSTACK\n  OP_SUB           // stack now contains m_B - m_A\n\n  OP_DUP           // if the result is negative, add 3\n  0 OP_LESSTHAN\n  OP_IF\n    3\n    OP_ADD\n  OP_ENDIF\n\n  {0, 1, 2}       // draw / Bob wins / Alice wins, respectively\n  OP_EQUALVERIFY\n\n  {<ctv-split>, <ctv-bob-wins>, <ctv-alice-wins>}  // respectively\n  OP_CHECKTEMPLATEVERIFY\n\n\n### Comments\n\nIn general, we would have to worry about the possible\nmalleability of the witness elements, when they are not signatures\nor preimages themselves. Here, in particular, it might seem that's\nan issue when <m_B> is provided while spending the state [S0].\nHowever, here the value of <m_B> is also committed to in the output\nthanks to COCV; therefore, Bob's signature prevents malleability\nalso for m_B.\n\nIn general, it seems to be the case in MATT contracts that one would\nwant the signature of the authorized party performing a transition to\nsome other state of the smart contract with contains embedded data;\nthis makes the malleability issue less of a problem in practice than\nI initially thought.\n\nIf the internal_pubkey is a musig-aggregated key of Alice and Bob,\nthe game can be settled entirely offline after the first transaction.\nSimply, Bob communicates his move to Alice, Alice reveals her move to\nBob, and they can settle the bet. The game would be played without\nany script being executed, therefore all transactions could look like\nany other P2TR, with the only possible fingerprinting being due to the\ninput amounts.\n\nIt should be possible to generalize the protocol so that many rounds\ncan be played off-chain within the same UTXO, but I didn't try to\nfigure out the details.\n\nBest,\nSalvatore Ingala\n\n\n[1] - https://en.wikipedia.org/wiki/Rock_paper_scissors\n[2] -\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-April/021588.html\n\nOn Fri, 28 Apr 2023 at 10:48, Johan Tor\u00e5s Halseth <johanth at gmail.com> wrote:\n\n> Hi, Salvatore.\n>\n> I find this proposal very interesting. Especially since you seemingly\n> can achieve such powerful capabilities by such simple opcodes.\n>\n> I'm still trying to grok how this would look like on-chain (forget\n> about the off-chain part for now), if we were to play out such a\n> computation.\n>\n> Let's say you have a simple game like \"one player tic-tac-toe\" with\n> only two tiles: [ _ | _ ]. The player wins if he can get two in a row\n> (pretty easy game tbh).\n>\n> Could you give a complete example how you would encode one such state\n> transition (going from [ X, _ ] -> [ X, X ] for instance) in Bitcoin\n> script?\n>\n> Feel free to choose a different game or program if you prefer :)\n>\n> Thanks!\n> Johan\n>\n>\n>\n> On Tue, Dec 13, 2022 at 2:08\u202fPM Billy Tetrud via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >\n> > Re Verkle trees, that's a very interesting construction that would be\n> super useful as a tool for something like Utreexo. A potentially\n> substantial downside is that it seems the cryptography used to get those\n> nice properties of Verkle trees isn't quantum safe. While a lot of things\n> in Bitcoin seems to be going down the path of quantum-unsafe (I'm looking\n> at you, taproot), there are still a lot of people who think quantum safety\n> is important in a lot of contexts.\n> >\n> > On Thu, Dec 1, 2022 at 5:52 AM Salvatore Ingala via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>\n> >> Hello Rijndael,\n> >>\n> >>\n> >>\n> >> On Wed, 30 Nov 2022 at 23:09, Rijndael <rot13maxi at protonmail.com>\n> wrote:\n> >>>\n> >>> Hello Salvatore,\n> >>>\n> >>> I found my answer re-reading your original post:\n> >>> > During the arbitration phase (say at the i-th leaf node of M_T), any\n> party can win the challenge by providing correct values for tr_i = (st_i,\n> op_i, st_{i + 1}). Crucially, only one party is able to provide correct\n> values, and Script can verify that indeed the state moves from st_i to\n> st_{i + 1} by executing op_i. The challenge is over.\n> >>\n> >> You are correct, the computation step encoded in a leaf needs to be\n> simple enough for Script to verify it.\n> >>\n> >> For the academic purpose of proving completeness (that is, any\n> computation can be successfully \"proved\" by the availability of the\n> corresponding fraud proof), one can imagine reducing the computation all\n> the way down to a circuit, where each step (leaf) is as simple as what can\n> be checked with {OP_NOT, OP_BOOLAND, OP_BOOLOR, OP_EQUAL}.\n> >>\n> >> In practice, you would want to utilize Script to its fullest, so for\n> example you wouldn't compile a SHA256 computation to something else \u2013 you'd\n> rather use OP_SHA256 directly.\n> >>\n> >>>\n> >>> That raises leads to a different question: Alice initially posts a\n> commitment to an execution trace of `f(x) = y`, `x`, and `y`. Bob Disagrees\n> with `y` so starts the challenge protocol. Is there a commitment to `f`? In\n> other words, the dispute protocol (as I read it) finds the leftmost step in\n> Alice and Bob's execution traces that differ, and then rewards the coins to\n> the participant who's \"after-value\" is computed by the step's operation\n> applied to the \"before value\". But if the participants each present valid\n> steps but with different operations, who wins? In other words, Alice could\n> present [64, DECREMENT, 63] and Bob could present [64, INCREMENT, 65].\n> Those steps don't match, but both are valid. Is there something to ensure\n> that before the challenge protocol starts, that the execution trace that\n> Alice posts is for the right computation and not a different computation\n> that yields a favorable result for her (and for which she can generate a\n> valid merkle tree)?\n> >>\n> >>\n> >> The function f is already hard-coded in the contract itself, by means\n> of the tree of scripts \u2212 that already commits to the possible futures.\n> Therefore, once you are at state S14, you know that you are verifying the\n> 6th step of the computation; and the operation in the 6th step of the\n> computation depends solely on f, not its inputs. In fact, you made me\n> realize that I could drop op_i from the i-th leaf commitment, and just\n> embed the information in the Script of that corresponding state.\n> >>\n> >> Note that the states S0 to S14 of the 256x game are not _all_ the\n> possible states, but only the ones that occurred in that execution of the\n> contract (corresponding to a path from the root to the leaf of the Merkle\n> tree of the computation trace), and therefore the ones that materialized in\n> a UTXO. Different choices made by the parties (by providing different data,\n> and therefore choosing different branches) would lead to a different leaf,\n> and therefore to different (but in a certain sense \"symmetric\") states.\n> >>\n> >> ========\n> >>\n> >> Since we are talking about the fact that f is committed to in the\n> contract, I'll take the chance to extend on this a bit with a fun\n> construction on top.\n> >> It is well-known in the academic literature of state channels that you\n> can create contracts where even the function (\"program\", or \"contract\") is\n> not decided when the channel is created.\n> >>\n> >> Since f is generic, we can choose f itself to be a universal Turing\n> machine. That is, we can imagine a function f(code, data) that executes a\n> program (\"code\") on the \"data\" given to it as input.\n> >> Since we can do fraud proofs on statements \"f(code, data) == output\",\n> we could build contracts where the \"code\" itself is chosen later.\n> >>\n> >> For example, one could build a universal state channel, where parties\n> can enter any contract among themselves (e.g.: start playing a chess game)\n> entirely inside the channel. The state of this universal channel would\n> contain all the states of the individual contracts that are currently open\n> in the channel, and even starting/closing contracts can happen entirely\n> off-chain.\n> >>\n> >> I believe these constructions are practical (the code of universal\n> Turing machines is not really complicated), so it might be worth exploring\n> further to figure out useful applications of this approach (supercharging\n> lightning?).\n> >>\n> >> We should probably start by implementing testnet rock-paper-scissors in\n> MATT, though :)\n> >>\n> >> Best,\n> >> Salvatore Ingala\n> >> _______________________________________________\n> >> bitcoin-dev mailing list\n> >> bitcoin-dev at lists.linuxfoundation.org\n> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230501/2f7ae5a8/attachment-0001.html>"
            },
            {
                "author": "Salvatore Ingala",
                "date": "2023-05-01T21:15:20",
                "message_text_only": "Hi all,\n\nI apologize for a couple of oversights in my last e-mail.\n\nThe first is that m_B can't be committed as-is in the contract's\nembedded data, with the current semantics of OP_COCV, which\nonly allows 32-byte values. A solution could be to store its\nhash SHA256(m_B), instead.\n\n(I didn't test the Scripts, so there could be other bugs \u2212 hopefully the\ngeneral idea is clear, anyway)\n\nOn Mon, 1 May 2023 at 15:11, Salvatore Ingala <salvatore.ingala at gmail.com>\nwrote:\n\n> If the internal_pubkey is a musig-aggregated key of Alice and Bob,\n> the game can be settled entirely offline after the first transaction.\n> Simply, Bob communicates his move to Alice, Alice reveals her move to\n> Bob, and they can settle the bet. The game would be played without\n> any script being executed, therefore all transactions could look like\n> any other P2TR, with the only possible fingerprinting being due to the\n> input amounts.\n>\n\nThis is incomplete: Alice can't trust Bob by revealing her move, as\nhe could then cheat on-chain and play a different move.\n\nThe fix should be straightforward, after adding the requirement that the\ninternal pubkey of [S1] is a musig2 of both players.\nAfter Bob reveals his move (say, Rock), Alice will only agree to continue\nthe game off-chain if Bob pre-signs transactions for the state [S1] (where\nm_B = Paper, and m_B = Scissors) that send all the money to Alice.\nThis guarantees that a cheating Bob is punished.\n\nBest,\nSalvatore Ingala\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230501/a850251d/attachment.html>"
            },
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2023-05-04T08:34:07",
                "message_text_only": "Thank you for the example.\n\nIt sounds like we can generalize the description of the construct to:\nAccess to (the hash of) embedded data of inputs and outputs, and the\nenforcement of output keys and (static) taptrees. In other words, as\nlong as you can dynamically compute the output embedded data in\nScript, you can enforce more or less anything (since you can make the\noutput script enforce presenting a witness \"satisfying\" the embedded\ndata).\n\nDoes that sound about right?\n\nFor instance, I believe you could simulate coin pools pretty easily:\nCommit to the set of pubkeys and amounts owned by the participants in\nthe pool, and an output taptree where each participant has their own\nspending path. Now, to exit the pool unilaterally, the participant\nmust present a proof that their pubkey+amount is committed to in the\ninput and an output where it is no longer committed.\n\nA question that arises is how one would efficiently (in Script) prove\nthe inclusion/exclusion of the data in the commitment. One could\nnaively hash all the data twice during script execution (once for the\ninput, once for the output), but that is costly. It would be natural\nto show merkle tree inclusion/exclusion in script, but perhaps there\nare more efficient ways to prove it?\n\n- Johan\n\n\nOn Tue, May 2, 2023 at 12:44\u202fAM Salvatore Ingala via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Hi all,\n>\n> I apologize for a couple of oversights in my last e-mail.\n>\n> The first is that m_B can't be committed as-is in the contract's\n> embedded data, with the current semantics of OP_COCV, which\n> only allows 32-byte values. A solution could be to store its\n> hash SHA256(m_B), instead.\n>\n> (I didn't test the Scripts, so there could be other bugs \u2212 hopefully the\n> general idea is clear, anyway)\n>\n> On Mon, 1 May 2023 at 15:11, Salvatore Ingala <salvatore.ingala at gmail.com> wrote:\n>>\n>> If the internal_pubkey is a musig-aggregated key of Alice and Bob,\n>> the game can be settled entirely offline after the first transaction.\n>> Simply, Bob communicates his move to Alice, Alice reveals her move to\n>> Bob, and they can settle the bet. The game would be played without\n>> any script being executed, therefore all transactions could look like\n>> any other P2TR, with the only possible fingerprinting being due to the\n>> input amounts.\n>\n>\n> This is incomplete: Alice can't trust Bob by revealing her move, as\n> he could then cheat on-chain and play a different move.\n>\n> The fix should be straightforward, after adding the requirement that the\n> internal pubkey of [S1] is a musig2 of both players.\n> After Bob reveals his move (say, Rock), Alice will only agree to continue\n> the game off-chain if Bob pre-signs transactions for the state [S1] (where\n> m_B = Paper, and m_B = Scissors) that send all the money to Alice.\n> This guarantees that a cheating Bob is punished.\n>\n> Best,\n> Salvatore Ingala\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Salvatore Ingala",
                "date": "2023-05-05T21:18:16",
                "message_text_only": "On Thu, 4 May 2023 at 10:34, Johan Tor\u00e5s Halseth <johanth at gmail.com> wrote:\n>\n> It sounds like we can generalize the description of the construct to:\n> Access to (the hash of) embedded data of inputs and outputs, and the\n> enforcement of output keys and (static) taptrees. In other words, as\n> long as you can dynamically compute the output embedded data in\n> Script, you can enforce more or less anything (since you can make the\n> output script enforce presenting a witness \"satisfying\" the embedded\n> data).\n>\n> Does that sound about right?\n\nYes. Fraud proofs allow us to extend beyond what Script can do (with the\nnecessary tradeoffs), but there is plenty that can be done without them.\n\n\n> For instance, I believe you could simulate coin pools pretty easily:\n> Commit to the set of pubkeys and amounts owned by the participants in\n> the pool, and an output taptree where each participant has their own\n> spending path. Now, to exit the pool unilaterally, the participant\n> must present a proof that their pubkey+amount is committed to in the\n> input and an output where it is no longer committed.\n\nI don't think one would want to have a tapleaf for each participant:\nthat would make you pay log n hashes just to reveal the tapleaf, and\nthen you still need to pay log n hashes to access the embedded data.\n\nInstead, the \"unilateral withdrawal Script\" can be the same for all the\nparticipants. The witness would be the Merkle proof, plus perhaps some\nadditional information to identify the leaf in the tree (depending on\nhow the Merkle tree is implemented). In a complete Merkle tree for\nN = 2^n participants, the witness could contain the n hashes that allow\nto prove the value of the leaf, plus n bits to identify the path to the\nleaf (0/1 for 'left/right\" child), since Script doesn't have enough\nopcodes to extract the bits from the leaf index.\n\nThe data in the leaf can contain a commitment to all the information\nrelevant for that participant (e.g.: their balance and pubkey, in a\nCoinPool construction).\n\nThen, the same witness can easily be reused to compute the new Merkle\nroot after the data in the leaf is modified (for example, setting the\namount to 0 for one participant).\n\n\n> A question that arises is how one would efficiently (in Script) prove\n> the inclusion/exclusion of the data in the commitment. One could\n> naively hash all the data twice during script execution (once for the\n> input, once for the output), but that is costly. It would be natural\n> to show merkle tree inclusion/exclusion in script, but perhaps there\n> are more efficient ways to prove it?\n\nA Merkle tree as described above commits to an entire vector that you\ncan index positionally. That's quite versatile, and easier to handle\nthan more complex constructions like accumulators with exclusion proofs.\n\nA Merkle proof for 2^7 = 128 participants requires about 8 hashes, so\naround 250 bytes in total of witness size; 2^10 = 1024 should bring that\nto the ballpark of 350 bytes.\n\nBest,\nSalvatore Ingala\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230505/ab517fd1/attachment-0001.html>"
            },
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2023-05-26T11:45:17",
                "message_text_only": "Hi, Salvatore.\n\nAs a further exploration of this idea, I implemented a\nproof-of-concept of OP_CICV and OP_COCV in btcd[1] that together with\nOP_CAT enables a set of interesting use cases.\n\nOne such use case is, as mentioned earlier, CoinPools[2]. The opcodes\nlet you easily check the \"dynamically committed data\" of an input you\nare spending, and enforce a new commitment on the output. The idea is\nto have the set of participants in the pool, and their balances, be\nthe UTXOs committed data, and  use this to validate the legitimacy of\na transaction, determining whether it permits a peer to exit with a\nportion of the pooled funds.\n\nDoing what you suggested above, having the input and output commit to\na merkle tree of participants and balances, we are able to quite\nelegantly verify the coin pool exit clause. Here is a working example\nof how that could look like: [3]. Obviously this lacks a lot before it\nis a working CoinPool implementation, but it demonstrates how\nOP_C[I/O]V introduces \"memory\" to Bitcoin script.\n\nHaving done this exercise, I have a few suggestions on how one could\nfurther extend the proposal:\n\n1. In the current proposal for OP_CHECKOUTPUTCONTRACTVERIFY, the\nopcodes check whether the output key Q is key X tweaked with data D\nand taproot T: Q == tweak(tweak(X,D), T).\n\nOP_CHECKINPUTCONTRACTVERIFY on the other hand, works on the input\ninternal key, and does not care about the taptree on the input: P ==\ntweak(X,D), where Q = tweak(P, T). In most cases this is probably good\nenough, since you are already executing the current script and that\nway know the spender has provided the correct taproot.\n\nHowever, in the coin pool script mentioned above, I found that I\nwanted to re-use the same taproot for the output (recursively). I\nbelieve this would be a quite common use case. To solve this I\ncommitted the taproot as part of the data itself: D' = hash(T+D),\nwhich was then verified by OP_CICV. If you are aware of more efficient\nalternatives, I am eager to hear them.\n\nA simpler way IMO, would be to make OP_CICV and OP_COCV symmetrical:\nHave OP_CICV take an optional taproot and do the same check as is done\nfor the output: Q == tweak(tweak(X,D), T).\n\n2.To make fully functioning CoinPools, one would need functionality\nsimilar to OP_MERKLESUB[4]: remove some data from the merkle tree, and\nremove a key from the aggregated internal key.This suggestion may\nsurpass the intended scope of this proposal, and would likely\nnecessitate the availability of multiple EC operations to accommodate\nvarious key schemes. If we had opcodes for adding and removing keys\nfrom the internal key this would be even more powerful.\n\nI look forward to hearing your thoughts on these suggestions and\nfurther exploring the possibilities of the proposal!\n\nCheers,\nJohan\n\n[1] https://github.com/halseth/btcd/pull/1/commits/90a4065bdcd8029fe3325514a250490cba66fddd\n[2] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-June/017964.html\n[3] https://github.com/halseth/tapsim/tree/matt-demo/examples/matt/coinpool\n[4] https://github.com/ariard/bips/blob/coinpool-bips/bip-merklesub.mediawiki\n\n\nOn Fri, May 5, 2023 at 11:18\u202fPM Salvatore Ingala\n<salvatore.ingala at gmail.com> wrote:\n>\n> On Thu, 4 May 2023 at 10:34, Johan Tor\u00e5s Halseth <johanth at gmail.com> wrote:\n> >\n> > It sounds like we can generalize the description of the construct to:\n> > Access to (the hash of) embedded data of inputs and outputs, and the\n> > enforcement of output keys and (static) taptrees. In other words, as\n> > long as you can dynamically compute the output embedded data in\n> > Script, you can enforce more or less anything (since you can make the\n> > output script enforce presenting a witness \"satisfying\" the embedded\n> > data).\n> >\n> > Does that sound about right?\n>\n> Yes. Fraud proofs allow us to extend beyond what Script can do (with the\n> necessary tradeoffs), but there is plenty that can be done without them.\n>\n>\n> > For instance, I believe you could simulate coin pools pretty easily:\n> > Commit to the set of pubkeys and amounts owned by the participants in\n> > the pool, and an output taptree where each participant has their own\n> > spending path. Now, to exit the pool unilaterally, the participant\n> > must present a proof that their pubkey+amount is committed to in the\n> > input and an output where it is no longer committed.\n>\n> I don't think one would want to have a tapleaf for each participant:\n> that would make you pay log n hashes just to reveal the tapleaf, and\n> then you still need to pay log n hashes to access the embedded data.\n>\n> Instead, the \"unilateral withdrawal Script\" can be the same for all the\n> participants. The witness would be the Merkle proof, plus perhaps some\n> additional information to identify the leaf in the tree (depending on\n> how the Merkle tree is implemented). In a complete Merkle tree for\n> N = 2^n participants, the witness could contain the n hashes that allow\n> to prove the value of the leaf, plus n bits to identify the path to the\n> leaf (0/1 for 'left/right\" child), since Script doesn't have enough\n> opcodes to extract the bits from the leaf index.\n>\n> The data in the leaf can contain a commitment to all the information\n> relevant for that participant (e.g.: their balance and pubkey, in a\n> CoinPool construction).\n>\n> Then, the same witness can easily be reused to compute the new Merkle\n> root after the data in the leaf is modified (for example, setting the\n> amount to 0 for one participant).\n>\n>\n> > A question that arises is how one would efficiently (in Script) prove\n> > the inclusion/exclusion of the data in the commitment. One could\n> > naively hash all the data twice during script execution (once for the\n> > input, once for the output), but that is costly. It would be natural\n> > to show merkle tree inclusion/exclusion in script, but perhaps there\n> > are more efficient ways to prove it?\n>\n> A Merkle tree as described above commits to an entire vector that you\n> can index positionally. That's quite versatile, and easier to handle\n> than more complex constructions like accumulators with exclusion proofs.\n>\n> A Merkle proof for 2^7 = 128 participants requires about 8 hashes, so\n> around 250 bytes in total of witness size; 2^10 = 1024 should bring that\n> to the ballpark of 350 bytes.\n>\n> Best,\n> Salvatore Ingala"
            },
            {
                "author": "Salvatore Ingala",
                "date": "2023-05-28T10:24:14",
                "message_text_only": "Hi Johan,\n\nExciting to finally see some merkleization, which was only confined\nwithin the meme, up to this point!\n\n> A simpler way IMO, would be to make OP_CICV and OP_COCV symmetrical:\n> Have OP_CICV take an optional taproot and do the same check as is\n> done for the output: Q == tweak(tweak(X,D), T).\n\nI think that's an excellent suggestion, which I was already exploring\nfor a different purpose: bringing externally signed data onto the\nstack. My goal there was to allow eltoo-style replacement.\n\nUntil recently, I thought that a clean/efficient version of eltoo\nwould require OP_CHECKSIGFROMSTACK or ANYPREVOUT. However, extending\nOP_CHECKINPUTCONTRACTVERIFY to enable introspection of other inputs\nallows a reasonable workaround: producing a separate UTXO signed with\nANYONECANPAY, with the required data embedded as usual. Spending that\nUTXO together with the channel's UTXO allows one to get that data\non the stack (with its signature already checked by consensus rules).\nI drafted this idea in a gist [1].\n\nRemark: it still seems easier (and probably slightly more efficient)\nto build eltoo replacement with CSFS or APO in addition to MATT\nopcodes.\n\nA possible semantics for OP_CHECKINPUTCONTRACTVERIFY could then be\nexactly symmetrical to that of OP_CHECKOUTPUTCONTRACTVERIFY, with\nthe exception that the special input index -1 would represent the\ncurrent input.\n\nPushing this further, another option that could be be worth exploring\nis to have a single OP_CHECK_IN_OUT_CONTRACT_VERIFY opcode, with the\nsame semantics as OP_CHECKOUTPUTCONTRACTVERIFY from [2], but with an\nadditional `flags` argument, which is a bitmap where:\n- the lowest-significant bit determines if the index refers to inputs\n  or outputs (where input index -1 refers to the current input)\n- the second bit specifies if amounts should be preserved with\n  deferred checks as described in [2] (only applicable to outputs)\n- other bits are OP_SUCCESS and reserved for future behaviors.\n\nThis would make the opcodes 1-2 bytes larger, but might allow greater\nflexibility, and keep some room for future extensions.\n\n> 2.To make fully functioning CoinPools, one would need functionality\n> similar to OP_MERKLESUB[4]: remove some data from the merkle tree,\n> and remove a key from the aggregated internal key.\n\nIt seems likely that efficient use of the taproot internal pubkey with\n\"dynamic key aggregation\" is not possible with the current semantics\n(unless one ventures into the fraud proof machinery, which seems\noverkill!).\n\nHowever, in constructions with MATT opcodes, I would never expect the\nneed for data to be stored in the taptree. In particular, for the case\nof CoinPools, the pubkeys of the members could also be stored in the\nembedded data, having a single \"unilateral withdrawal\" tapleaf.\nRemoving a key would then amount to replacing it with a fixed NUMS key\nand computing the new root (re-using the same Merkle proof).\nNote that this is not a lot costlier than using a tapleaf per user:\ninstead of paying the cost for the Merkle proof in the control block,\nyou pay for it explicitly in the Script witness.\n\nTherefore, I would expect there to be reasonable CoinPools designs\nwithout additional opcodes \u2212 but I am only moderately confident as\nthis is beyond the level of sophistication I've been exploring so far.\n\nBest,\nSalvatore\n\n[1] - https://gist.github.com/bigspider/041ebd0842c0dcc74d8af087c1783b63\n[2] -\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-April/021588.html\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230528/e5be3369/attachment.html>"
            },
            {
                "author": "Johan Tor\u00e5s Halseth",
                "date": "2023-05-30T07:34:09",
                "message_text_only": "I should clarify: the current proposal already achieves the first part\nneeded for coin pools: removing some data from the merkle tree (I was\nindeed referring to the embedded data, not the taptree).\n\nThe thing that is missing is removal of a public key from the taproot\ninternal key, but as mentioned I do agree that this is out of scope\nfor this proposal.\n\nI believe you can get many of the benefits by falling back to \"old\nstyle multisig\" in case someone exits the pool, by having a tap leaf\ndefining a multisig check amongst the remaining pubkeys.\n\nCheers,\nJohan\n\n> It seems likely that efficient use of the taproot internal pubkey with\n> \"dynamic key aggregation\" is not possible with the current semantics\n> (unless one ventures into the fraud proof machinery, which seems\n> overkill!).\n>\n> However, in constructions with MATT opcodes, I would never expect the\n> need for data to be stored in the taptree. In particular, for the case\n> of CoinPools, the pubkeys of the members could also be stored in the\n> embedded data, having a single \"unilateral withdrawal\" tapleaf.\n> Removing a key would then amount to replacing it with a fixed NUMS key\n> and computing the new root (re-using the same Merkle proof).\n> Note that this is not a lot costlier than using a tapleaf per user:\n> instead of paying the cost for the Merkle proof in the control block,\n> you pay for it explicitly in the Script witness.\n>\n> Therefore, I would expect there to be reasonable CoinPools designs\n> without additional opcodes \u2212 but I am only moderately confident as\n> this is beyond the level of sophistication I've been exploring so far.\n\n\nOn Sun, May 28, 2023 at 12:24\u202fPM Salvatore Ingala\n<salvatore.ingala at gmail.com> wrote:\n>\n> Hi Johan,\n>\n> Exciting to finally see some merkleization, which was only confined\n> within the meme, up to this point!\n>\n> > A simpler way IMO, would be to make OP_CICV and OP_COCV symmetrical:\n> > Have OP_CICV take an optional taproot and do the same check as is\n> > done for the output: Q == tweak(tweak(X,D), T).\n>\n> I think that's an excellent suggestion, which I was already exploring\n> for a different purpose: bringing externally signed data onto the\n> stack. My goal there was to allow eltoo-style replacement.\n>\n> Until recently, I thought that a clean/efficient version of eltoo\n> would require OP_CHECKSIGFROMSTACK or ANYPREVOUT. However, extending\n> OP_CHECKINPUTCONTRACTVERIFY to enable introspection of other inputs\n> allows a reasonable workaround: producing a separate UTXO signed with\n> ANYONECANPAY, with the required data embedded as usual. Spending that\n> UTXO together with the channel's UTXO allows one to get that data\n> on the stack (with its signature already checked by consensus rules).\n> I drafted this idea in a gist [1].\n>\n> Remark: it still seems easier (and probably slightly more efficient)\n> to build eltoo replacement with CSFS or APO in addition to MATT\n> opcodes.\n>\n> A possible semantics for OP_CHECKINPUTCONTRACTVERIFY could then be\n> exactly symmetrical to that of OP_CHECKOUTPUTCONTRACTVERIFY, with\n> the exception that the special input index -1 would represent the\n> current input.\n>\n> Pushing this further, another option that could be be worth exploring\n> is to have a single OP_CHECK_IN_OUT_CONTRACT_VERIFY opcode, with the\n> same semantics as OP_CHECKOUTPUTCONTRACTVERIFY from [2], but with an\n> additional `flags` argument, which is a bitmap where:\n> - the lowest-significant bit determines if the index refers to inputs\n>   or outputs (where input index -1 refers to the current input)\n> - the second bit specifies if amounts should be preserved with\n>   deferred checks as described in [2] (only applicable to outputs)\n> - other bits are OP_SUCCESS and reserved for future behaviors.\n>\n> This would make the opcodes 1-2 bytes larger, but might allow greater\n> flexibility, and keep some room for future extensions.\n>\n> > 2.To make fully functioning CoinPools, one would need functionality\n> > similar to OP_MERKLESUB[4]: remove some data from the merkle tree,\n> > and remove a key from the aggregated internal key.\n>\n> It seems likely that efficient use of the taproot internal pubkey with\n> \"dynamic key aggregation\" is not possible with the current semantics\n> (unless one ventures into the fraud proof machinery, which seems\n> overkill!).\n>\n> However, in constructions with MATT opcodes, I would never expect the\n> need for data to be stored in the taptree. In particular, for the case\n> of CoinPools, the pubkeys of the members could also be stored in the\n> embedded data, having a single \"unilateral withdrawal\" tapleaf.\n> Removing a key would then amount to replacing it with a fixed NUMS key\n> and computing the new root (re-using the same Merkle proof).\n> Note that this is not a lot costlier than using a tapleaf per user:\n> instead of paying the cost for the Merkle proof in the control block,\n> you pay for it explicitly in the Script witness.\n>\n> Therefore, I would expect there to be reasonable CoinPools designs\n> without additional opcodes \u2212 but I am only moderately confident as\n> this is beyond the level of sophistication I've been exploring so far.\n>\n> Best,\n> Salvatore\n>\n> [1] - https://gist.github.com/bigspider/041ebd0842c0dcc74d8af087c1783b63\n> [2] - https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-April/021588.html"
            }
        ],
        "thread_summary": {
            "title": "Merkleize All The Things",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Salvatore Ingala",
                "Johan Tor\u00e5s Halseth"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 36149
        }
    },
    {
        "title": "[bitcoin-dev] Proposal to Remove BIP35 P2P 'mempool' Message",
        "thread_messages": [
            {
                "author": "0xB10C",
                "date": "2023-05-01T13:24:26",
                "message_text_only": "Hi Will,\n\nI shared some numbers and feedback as comment [0] on your PR wanted to\nanswer question 1. for completeness here too.\n\n> Its original intention was to be publicly callable, but it is now (in\nBitcoin Core) gated behind stricter Net Permissions which make it\naccessible to trusted peers only.\n\nBitcoin Core does only gate processing of mempool messages on\nNetPermissionFlags::Mempool when bloom filters are disabled [1]. While\nthese are disabled by default, more than 20% (see PR comment) of nodes\non the network have bloom filters enabled. These nodes all respond to\nmempool messages with INV messages.\n\n> 1. Are there any parties who still directly rely on the BIP35 P2P\n`mempool` message?\n\nI've been receiving on average about 20 mempool messages per hour to a\nwell-connected NODE_BLOOM Bitcoin Core node. I've seen multiple messages\nfrom the user agent /BitcoinKit:0.1.0/, /bitcoinj:0.*.*/Bitcoin\nWallet:*/, /WalletKit:0.1.0/, and /bread:2.1/. Similarly, the node\nresponds to the clients with INVs up to the max number of 50k entries\nand with smaller (bloom) filtered INVs.\n\n\n0xB10C\n\n[0]: https://github.com/bitcoin/bitcoin/pull/27426#issuecomment-1529678174\n[1]:\nhttps://github.com/bitcoin/bitcoin/blob/d89aca1bdbe52406f000e3fa8dda12c46dca9bdd/src/net_processing.cpp#LL4603C52-L4603\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: OpenPGP_0x188CBB2648416AD5.asc\nType: application/pgp-keys\nSize: 10796 bytes\nDesc: OpenPGP public key\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230501/7deb635c/attachment.bin>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: OpenPGP_signature\nType: application/pgp-signature\nSize: 833 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230501/7deb635c/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Proposal to Remove BIP35 P2P 'mempool' Message",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "0xB10C"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1875
        }
    },
    {
        "title": "[bitcoin-dev] Vaults in the MATT framework",
        "thread_messages": [
            {
                "author": "Michael Folkson",
                "date": "2023-05-01T14:18:29",
                "message_text_only": "Hi Salvatore\n\nCan you clarify for me which bucket this proposal sits? We have APO, CTV, OP_VAULT etc that are proposals to add additional functionality to SegWit version 1, Tapleaf version 0 scripts. We have Simplicity that would need a new Tapleaf version (e.g. Tapleaf version 1). And then there are CISA like proposals that would need a new SegWit version (e.g. SegWit version 2). It looks to me like your proposal is in the first bucket (same as APO, CTV etc) as it is just introducing new opcode functionality to existing script with no deeper introspection needed but previous and current discussion of fraud proofs, MATT frameworks etc made me initially think it was going to require more than that.\n\nThanks\nMichael\n\n--\nMichael Folkson\nEmail: michaelfolkson at [protonmail.com](http://protonmail.com/)\nGPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n\nLearn about Bitcoin: https://www.youtube.com/@portofbitcoin\n\n------- Original Message -------\nOn Monday, April 24th, 2023 at 20:37, Salvatore Ingala via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hello list,\n>\n> TL;DR: the core opcodes of MATT can build vaults with a very similar design\n> to OP_VAULT. Code example here:\n>\n> https://github.com/bitcoin-inquisition/bitcoin/compare/24.0...bigspider:bitcoin-inquisition:matt-vault\n>\n> In my previous emails about the MATT proposal for smart contracts in\n> bitcoin [1], I mostly focused on proving its generality; that is, it\n> allows arbitrary smart contracts thanks to fraud proofs.\n>\n> While I still find this \"completeness\" result compelling, I spent more time\n> thinking about the framework itself; the construction is not very interesting\n> if it turns simple things into complicated ones. Luckily, this is not the case.\n> In particular, in this email we will not merkleize anything (other than taptrees).\n>\n> This post describes some progress into formalizing the semantics of the core\n> opcodes, and demonstrates how they could be used to create vaults that seem\n> comparable to the ones built with OP_VAULT [2], despite using general purpose\n> opcodes.\n>\n> An implementation and some minimal tests matching the content of this\n> e-mail can be found in the link above, using the bitcoin-inquisition as the\n> base branch.\n>\n> Note that the linked code is not well tested and is only intended for\n> exploratory and demonstrative purposes; therefore, bugs are likely at this\n> stage.\n>\n> ##########################\n> # PART 1: MATT's core\n> ##########################\n>\n> In this section, I will discuss plausible semantics for the core opcodes for MATT.\n>\n> The two core opcodes are defined below as OP_CHECKINPUTCONTRACTVERIFY and\n> OP_CHECKOUTPUTCONTRACTVERIFY.\n>\n> (the initial posts named them OP_CHECK{INPUT,OUTPUT}COVENANTVERIFY)\n>\n> They enhance Script with the following capabilities:\n> - decide the taptree of the output\n> - embed some (dynamically computed) data in the output\n> - access the embedded data in the current UTXO (if any)\n>\n> The opcodes below are incomplete, as they only control the output's Script and\n> not the amounts; more on that below.\n>\n> Other than that, the semantics should be quite close to the \"right\" one for\n> the MATT framework.\n>\n> ### The opcodes\n>\n> case OP_CHECKINPUTCONTRACTVERIFY:\n> {\n> // OP_CHECKINPUTCONTRACTVERIFY is only available in Tapscript\n> if (sigversion == SigVersion::BASE || sigversion == SigVersion::WITNESS_V0) return set_error(serror, SCRIPT_ERR_BAD_OPCODE);\n> // (x d -- )\n> if (stack.size() < 2)\n> return set_error(serror, SCRIPT_ERR_INVALID_STACK_OPERATION);\n> valtype& x = stacktop(-2);\n> valtype& d = stacktop(-1);\n> if (x.size() != 32 || d.size() != 32)\n> return set_error(serror, SCRIPT_ERR_INVALID_STACK_OPERATION);\n> const XOnlyPubKey nakedXOnlyKey{Span<const unsigned char>{x.data(), x.data() + 32}};\n> const uint256 data(d);\n> if (!execdata.m_internal_key.has_value())\n> return set_error(serror, SCRIPT_ERR_UNKNOWN_ERROR); // TODO\n> // Verify that tweak(lift_x(x), d) equals the internal pubkey\n> if (!execdata.m_internal_key.value().CheckDoubleTweak(nakedXOnlyKey, &data, nullptr))\n> return set_error(serror, SCRIPT_ERR_WRONGCONTRACTDATA);\n> popstack(stack);\n> popstack(stack);\n> }\n> break;\n> case OP_CHECKOUTPUTCONTRACTVERIFY:\n> {\n> // OP_CHECKOUTPUTCONTRACTVERIFY is only available in Tapscript\n> if (sigversion == SigVersion::BASE || sigversion == SigVersion::WITNESS_V0) return set_error(serror, SCRIPT_ERR_BAD_OPCODE);\n> // (out_i x taptree d -- )\n> if (stack.size() < 4)\n> return set_error(serror, SCRIPT_ERR_INVALID_STACK_OPERATION);\n> int out_i = CScriptNum(stacktop(-4), fRequireMinimal).getint();\n> valtype& x = stacktop(-3);\n> valtype& taptree = stacktop(-2);\n> valtype& d = stacktop(-1);\n> auto outps = checker.GetTxvOut();\n> // Return error if the evaluation context is unavailable\n> if (!outps)\n> return set_error(serror, SCRIPT_ERR_UNKNOWN_ERROR); // TODO\n> if (x.size() != 32 || taptree.size() != 32 || (d.size() != 0 && d.size() != 32))\n> return set_error(serror, SCRIPT_ERR_INVALID_STACK_OPERATION);\n> if (out_i < 0 || out_i >= (int)outps->size())\n> return set_error(serror, SCRIPT_ERR_INVALID_STACK_OPERATION);\n> const XOnlyPubKey nakedXOnlyKey{Span<const unsigned char>{x.data(), x.data() + 32}};\n> const uint256 data(d);\n> const uint256 *data_ptr = (d.size() == 0 ? nullptr : &data);\n> const uint256 merkle_tree(taptree);\n> CScript scriptPubKey = outps->at(out_i).scriptPubKey;\n> if (scriptPubKey.size() != 1 + 1 + 32 || scriptPubKey[0] != OP_1 || scriptPubKey[1] != 32)\n> return set_error(serror, SCRIPT_ERR_WRONGCONTRACTDATA);\n> const XOnlyPubKey outputXOnlyKey{Span<const unsigned char>{scriptPubKey.data() + 2, scriptPubKey.data() + 34}};\n> // Verify that taptweak(tweak(lift_x(x), d), taptree) equals the internal pubkey\n> if (!outputXOnlyKey.CheckDoubleTweak(nakedXOnlyKey, data_ptr, &merkle_tree))\n> return set_error(serror, SCRIPT_ERR_WRONGCONTRACTDATA);\n> popstack(stack);\n> popstack(stack);\n> popstack(stack);\n> popstack(stack);\n> }\n> break;\n>\n> ### Commentary\n>\n> CheckDoubleTweak function (implemented in the branch) gets an x-only pubkey,\n> optionally some data, and optionally taptree's merkle root.\n> It verifies that the x-only pubkey being tested equals the given naked pubkey,\n> optionally tweaked with the embedded data, optionally tweaked with the tagged\n> hash of the merkle tree per BIP-0341 [3].\n> Making both the tweaks optional allows to simplify the code, and also to obtain\n> more compact scripts in some spending paths.\n>\n> In words:\n>\n> - OP_CHECKINPUTCONTRACTVERIFY: verify that the current input's internal key\n> contains some embedded data (which would typically be passed through the\n> witness stack)\n> - OP_CHECKOUTPUTCONTRACTVERIFY: verify that a given output is a certain P2TR\n> output script containing the desired embedded data.\n>\n> TBD if the tweaking used for the embedded data tweak should use a tagged hash;\n> omitted for simplicity in this demo implementation.\n>\n> ### Amount preservation\n>\n> In the code above and in the linked demo implementation, the opcodes only\n> operate on the scriptPubkey; a complete implementation would want to make sure\n> that amounts are correctly preserved.\n>\n> The most direct and general way to address this would be to allow direct\n> introspection on the output amounts. This has the complication that output\n> amounts require 64-bits arithmetics, as discussed in the context of other\n> proposals, for example: [4].\n>\n> One more limited approach that works well for many interesting contracts\n> is that of the deferred checks, implemented in OP_VAULT [2].\n> The idea is that all the amounts of the inputs that commit to the same output\n> script with OP_CHECKOUTPUTCONTRACTVERIFY are added together, and the script\n> interpreter requires that the amount of that output is not smaller than the\n> total amount of those inputs. This check is therefore transaction-wide rather\n> than being tested during the input's script evaluation.\n>\n> This behaviour is adequate for vaults and likely suitable for many other\n> applications; however, it's not the most general approach. I didn't try to\n> implement it yet, and defer the decision on the best approach to a later time.\n>\n> ### Extensions\n>\n> The opcodes above are not enough for the full generality of MATT: one would\n> need to add an opcode like OP_SHA256CAT to allow the data embedding to commit\n> to multiple pieces of data.\n> This is not used in today's post, therefore I left it out of these code examples.\n>\n> It would be easy to extend OP_CHECKOUTPUTCONTRACTVERIFY to also apply for\n> an arbitrary input (typically, different from the currently executed one); there\n> are likely use cases for that, allowing to define contracts with more complex\n> cross-input semantics, but I preferred to keep things simple.\n>\n> Of course, one could also entirely replace CICV/COCV with generic full\n> introspection on inputs/output's program, plus opcodes for elliptic curve math\n> and tagged hashes.\n>\n> ##########################\n> # PART 2: Vaults with MATT\n> ##########################\n>\n> In the rest of this post, I will document the first attempt at creating a vault\n> using the opcodes described.\n>\n> While not an attempt at cloning exactly the functionality of OP_VAULT [2],\n> it borrows heavily from the excellent work that was done there.\n>\n> In particular, it also inherits the choice of using OP_CTV as a primitive,\n> building on top of the bitcoin-inquisition's current branch that has already\n> merged OP_CTV. Reasonable vaults would be possible without CTV, but they\n> would be less efficient, particularly in the case of sending to many addresses\n> in a single unvaulting flow.\n>\n> ### Distilling OP_VAULT\n>\n> Abstracting from the implementation details, I mentally model a vault as a\n> simple state machine with 2 states: [V] and [U]:\n>\n> [V]: the initial vault UTXO(s);\n> [U]: the utxo produced by the \"trigger transaction\" during unvaulting.\n>\n> On the typical path: one or more [V] UTXOs are sent to the [U] state, and after\n> a timelock set on [U] expires, [U] is spent to one or several destinations.\n> Crucially, the destination outputs and amounts are already decided when [V] is\n> spent into [U].\n>\n> At any time before the funds are spent from [U], they can always be spent by\n> sending them to some specified recovery path.\n>\n> There are two key elements that are part of OP_VAULT's semantics, and could be\n> generalized:\n>\n> \u2212 Forcing the script/amount of the next stepon\n> \u2212 Storing some data for future Script's access (in the vault's case, a hash\n> that commits to the final withdrawal transaction).\n>\n> CICV/COCV generalize both to arbitrary scripts (taptrees) and state machines,\n> and to dynamical and witness-dependent data embedded in the pubkey of a P2TR\n> output.\n>\n> ### Vault parameters\n>\n> A contract that represents a vault has the following parameters (hardcoded in\n> the script when the vault is created):\n>\n> - alternate_pk: a key that can be used any time.\n> - spend_delay: the relative timelock before the withdrawal can be finalized;\n> - recover_pk: a pubkey for a P2TR output where funds can be sent at any time.\n>\n> The alternate_pk is a pubkey that can optionally be used as the key-path\n> spending condition for both states [V] and [U]. If such a spending condition is not\n> desired, it can be replaced with a NUMS point, making the key-path unspendable.\n>\n> The spend_delay is the number of blocks that must be mined before the final\n> withdrawal transaction\n>\n> In this example we also use an unvault_pk needed to authorize the unvaulting\n> process (that is, spend [V] into [U]); this could be replaced with any miniscript\n> or other conditions expressible in Script.\n>\n> ### P2TR structure for [V] (vault)\n>\n> internal key: alternate_pk\n>\n> Script 1: \"trigger\"\n> # witness: <out_i> <ctv-hash>\n> {\n> <alternate_pk>,\n> <merkle root of U's taptree>,\n> 2, OP_ROLL,\n> OP_CHECKOUTPUTCONTRACTVERIFY,\n>\n> <unvault_pk>\n> OP_CHECKSIG\n> }\n>\n> Script 2: \"recover\"\n> # witness: <out_i>\n> {\n> recover_pk,\n> OP_0, # no data tweak\n> OP_0, # no taptweak\n> OP_CHECKOUTPUTCONTRACTVERIFY,\n> OP_TRUE\n> }\n>\n> The \"trigger\" script requires in the witness an output index and the ctv-hash\n> that describes the withdrawal transaction.\n> COCV forces the output to contain the ctv-hash as embedded data.\n> That's followed by the unvaulting condition \u2212 in this example, a simple\n> signature check.\n>\n> The \"recover\" script doesn't require any signature, and it simply forces\n> the output specified in the witness to be a P2TR output with recover_pk as its\n> pubkey.\n>\n> (Omitting the \"recover\" script in [V] would reduce the size of the witness by\n> 32 bytes in the expected case, and might be preferred for some users)\n>\n> ### P2TR structure for [U] (unvaulting state)\n>\n> internal key: alternate_pk (tweaked with ctv_hash)\n>\n> Script 1: \"withdrawal\"\n> # witness: <ctv_hash>\n> {\n> OP_DUP,\n>\n> # check that the top of the stack is the\n> # embedded data in the current input\n> <alternate_pk>, OP_SWAP,\n> OP_CHECKINPUTCONTRACTVERIFY,\n>\n> # Check timelock\n> <spend_delay>,\n> OP_CHECKSEQUENCEVERIFY,\n> OP_DROP,\n>\n> # Check that the transaction output is as expected\n> OP_CHECKTEMPLATEVERIFY\n> }\n>\n> Script 2: \"recover\"\n> # witness: <out_i>\n> {\n> <recover_pk>,\n> OP_0,\n> OP_0,\n> OP_CHECKOUTPUTCONTRACTVERIFY,\n> OP_TRUE\n> }\n>\n> The \"withdrawal\" finalizes the transaction, by checking that the timelock expired and\n> the outputs satisfy the CTV hash that was committed to in the previous transaction.\n>\n> The \"recover\" script is identical as before.\n>\n> ### Differences with OP_VAULT vaults\n>\n> Here I refer to the latest version of OP_VAULT at the time of writing. [5]\n> It is not a thorough analysis.\n>\n> Unlike the implementation based on OP_VAULT, the [V] utxos don't have an option\n> to add an additional output that is sent back to the same exact vault.\n> Supporting this use case seems to require a more general way of handling the\n> distribution of amounts than what I discussed in the section above: that would\n> in fact need to be generalized to the case of multiple\n> OP_CHECKOUTPUTCONTRACTVERIFY opcodes executed for the same input.\n>\n> By separating the ctv-hash (which is considered \"data\") from the scripts in the\n> taptree, one entirely avoids the need to dynamically create taptrees and\n> replace leaves in the covenant-encumbered UTXOs; in fact, the taptrees of [V]\n> and [U] are already set in stone when [V] utxos are created, and only the\n> \"data\" portion of [U]'s scriptPubKey is dynamically computed. In my opinion,\n> this makes it substantially easier to program \"state machines\" that control the\n> behavior of coins, of which vaults are a special case.\n>\n> I hope you'll find this interesting, and look forward to your comments.\n>\n> Salvatore Ingala\n>\n> [1] - https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-November/021223.html\n> [2] - https://github.com/bitcoin/bips/pull/1421\n> [3] - https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki\n> [4] - https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019420.html\n> [5] - https://github.com/bitcoin/bips/blob/7112f308b356cdf0c51d917dbdc1b98e30621f80/bip-0345.mediawiki\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230501/6f94a2a7/attachment-0001.html>"
            },
            {
                "author": "Salvatore Ingala",
                "date": "2023-05-02T08:21:01",
                "message_text_only": "Hi Michael,\n\nI can't make any claim of expertise on the field (especially on the\nother proposals that you mentioned), so this post necessarily includes\nmy opinions \u2212 and possibly my biases.\n\nThe core functionality of MATT is quite simple, and could be adapted\nto any version of the scripting system: basically, COCV allows to\n\"embed\" some data in the next output, and decide its script; CICV\nallows \"reading\" this data.\nThe design I proposed on taproot is surely not the only possible way,\nbut it's the most simple/elegant I could come up with. Moreover, it\ndoesn't seem very useful to spend time trying to get it to work on\npre-taproot Script, due to the obvious advantages of those ideas when\ndeployed on taproot (like having taptrees, and all the nice properties\nof Schnorr signatures).\n\nCICV/COCV can certainly be considered an additional form of\nintrospection: you're checking that the script of an input/output\nequals a certain value, which is not possible in today's Script.\nI think that's generally true for all covenant proposals.\n\nUnlike some other proposals, MATT is not yet fully formalized, so I\ngenerally call \"MATT\" the combination of CICV+COCV, plus some other\nsmall set of opcodes that is yet to be defined exactly. I would say it\nfits in the same family as APO/OP_CTV/OP_VAULT, per your bucketization.\n\nThe previous posts about MATT, fraud proofs, etc. are an exploration of\nthe deeper things that are enabled by the MATT opcodes. The claim is\nthat a set of changes that is (arguably) quite small and easy to analyze\nis enough to express general smart contracts \u2212 thanks to fraud proofs.\nHowever, fraud proofs themselves are a quite advanced application of\nthe new opcodes, and are not needed for most/all of the things that\npeople are trying to build today with the other covenant proposals.\n\n\nSince you mention Simplicity: my current understanding is that its\nendeavour of replacing Script with a better language is orthogonal to\nthe discussion about what features (e.g.: introspection, covenants)\nshould be in the language.\n\nAll the covenant proposals listed above are technically a lot smaller\nand easier to audit than both the SegWit and the Taproot soft forks,\nboth in terms of code and conceptual complexity.\n\nTherefore, if we _do_ want the features that they enable, the required\nengineering for a soft-fork is relatively straightforward, and there is\nnot much of a reason to wait for Simplicity. It will be trivial to \"port\"\nany\nconstructions we might create today with covenants to Simplicity scripts.\n\nIf we _do not_ want those features, then the decision would rather be\nguided by other considerations, like potential risks to bitcoin caused\nby the effect of those features on miners' incentives. These\nconcerns are not answered by Simplicity, as far as I understand:\nyou would then want to implement Simplicity _without_ those features.\n\nBest,\nSalvatore\n\nOn Mon, 1 May 2023 at 16:18, Michael Folkson <michaelfolkson at protonmail.com>\nwrote:\n\n> Hi Salvatore\n>\n> Can you clarify for me which bucket this proposal sits? We have APO, CTV,\n> OP_VAULT etc that are proposals to add additional functionality to SegWit\n> version 1, Tapleaf version 0 scripts. We have Simplicity that would need a\n> new Tapleaf version (e.g. Tapleaf version 1). And then there are CISA like\n> proposals that would need a new SegWit version (e.g. SegWit version 2). It\n> looks to me like your proposal is in the first bucket (same as APO, CTV\n> etc) as it is just introducing new opcode functionality to existing script\n> with no deeper introspection needed but previous and current discussion of\n> fraud proofs, MATT frameworks etc made me initially think it was going to\n> require more than that.\n>\n> Thanks\n> Michael\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n>\n> Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n>\n> ------- Original Message -------\n> On Monday, April 24th, 2023 at 20:37, Salvatore Ingala via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Hello list,\n>\n> TL;DR: the core opcodes of MATT can build vaults with a very similar design\n> to OP_VAULT. Code example here:\n>\n>\n> https://github.com/bitcoin-inquisition/bitcoin/compare/24.0...bigspider:bitcoin-inquisition:matt-vault\n>\n>\n> In my previous emails about the MATT proposal for smart contracts in\n> bitcoin [1], I mostly focused on proving its generality; that is, it\n> allows arbitrary smart contracts thanks to fraud proofs.\n>\n> While I still find this \"completeness\" result compelling, I spent more time\n> thinking about the framework itself; the construction is not very\n> interesting\n> if it turns simple things into complicated ones. Luckily, this is not the\n> case.\n> In particular, in this email we will not merkleize anything (other than\n> taptrees).\n>\n> This post describes some progress into formalizing the semantics of the\n> core\n> opcodes, and demonstrates how they could be used to create vaults that seem\n> comparable to the ones built with OP_VAULT [2], despite using general\n> purpose\n> opcodes.\n>\n> An implementation and some minimal tests matching the content of this\n> e-mail can be found in the link above, using the bitcoin-inquisition as the\n> base branch.\n>\n> Note that the linked code is not well tested and is only intended for\n> exploratory and demonstrative purposes; therefore, bugs are likely at this\n> stage.\n>\n>\n> ##########################\n> # PART 1: MATT's core\n> ##########################\n>\n> In this section, I will discuss plausible semantics for the core opcodes\n> for MATT.\n>\n> The two core opcodes are defined below as OP_CHECKINPUTCONTRACTVERIFY and\n> OP_CHECKOUTPUTCONTRACTVERIFY.\n>\n> (the initial posts named them OP_CHECK{INPUT,OUTPUT}COVENANTVERIFY)\n>\n> They enhance Script with the following capabilities:\n> - decide the taptree of the output\n> - embed some (dynamically computed) data in the output\n> - access the embedded data in the current UTXO (if any)\n>\n> The opcodes below are incomplete, as they only control the output's Script\n> and\n> not the amounts; more on that below.\n>\n> Other than that, the semantics should be quite close to the \"right\" one for\n> the MATT framework.\n>\n>\n> ### The opcodes\n>\n> case OP_CHECKINPUTCONTRACTVERIFY:\n> {\n> // OP_CHECKINPUTCONTRACTVERIFY is only available in Tapscript\n> if (sigversion == SigVersion::BASE || sigversion ==\n> SigVersion::WITNESS_V0) return set_error(serror, SCRIPT_ERR_BAD_OPCODE);\n> // (x d -- )\n> if (stack.size() < 2)\n> return set_error(serror, SCRIPT_ERR_INVALID_STACK_OPERATION);\n> valtype& x = stacktop(-2);\n> valtype& d = stacktop(-1);\n> if (x.size() != 32 || d.size() != 32)\n> return set_error(serror, SCRIPT_ERR_INVALID_STACK_OPERATION);\n> const XOnlyPubKey nakedXOnlyKey{Span<const unsigned char>{x.data(),\n> x.data() + 32}};\n> const uint256 data(d);\n> if (!execdata.m_internal_key.has_value())\n> return set_error(serror, SCRIPT_ERR_UNKNOWN_ERROR); // TODO\n> // Verify that tweak(lift_x(x), d) equals the internal pubkey\n> if (!execdata.m_internal_key.value().CheckDoubleTweak(nakedXOnlyKey,\n> &data, nullptr))\n> return set_error(serror, SCRIPT_ERR_WRONGCONTRACTDATA);\n> popstack(stack);\n> popstack(stack);\n> }\n> break;\n> case OP_CHECKOUTPUTCONTRACTVERIFY:\n> {\n> // OP_CHECKOUTPUTCONTRACTVERIFY is only available in Tapscript\n> if (sigversion == SigVersion::BASE || sigversion ==\n> SigVersion::WITNESS_V0) return set_error(serror, SCRIPT_ERR_BAD_OPCODE);\n> // (out_i x taptree d -- )\n> if (stack.size() < 4)\n> return set_error(serror, SCRIPT_ERR_INVALID_STACK_OPERATION);\n> int out_i = CScriptNum(stacktop(-4), fRequireMinimal).getint();\n> valtype& x = stacktop(-3);\n> valtype& taptree = stacktop(-2);\n> valtype& d = stacktop(-1);\n> auto outps = checker.GetTxvOut();\n> // Return error if the evaluation context is unavailable\n> if (!outps)\n> return set_error(serror, SCRIPT_ERR_UNKNOWN_ERROR); // TODO\n> if (x.size() != 32 || taptree.size() != 32 || (d.size() != 0 && d.size()\n> != 32))\n> return set_error(serror, SCRIPT_ERR_INVALID_STACK_OPERATION);\n> if (out_i < 0 || out_i >= (int)outps->size())\n> return set_error(serror, SCRIPT_ERR_INVALID_STACK_OPERATION);\n> const XOnlyPubKey nakedXOnlyKey{Span<const unsigned char>{x.data(),\n> x.data() + 32}};\n> const uint256 data(d);\n> const uint256 *data_ptr = (d.size() == 0 ? nullptr : &data);\n> const uint256 merkle_tree(taptree);\n> CScript scriptPubKey = outps->at(out_i).scriptPubKey;\n> if (scriptPubKey.size() != 1 + 1 + 32 || scriptPubKey[0] != OP_1 ||\n> scriptPubKey[1] != 32)\n> return set_error(serror, SCRIPT_ERR_WRONGCONTRACTDATA);\n> const XOnlyPubKey outputXOnlyKey{Span<const unsigned\n> char>{scriptPubKey.data() + 2, scriptPubKey.data() + 34}};\n> // Verify that taptweak(tweak(lift_x(x), d), taptree) equals the internal\n> pubkey\n> if (!outputXOnlyKey.CheckDoubleTweak(nakedXOnlyKey, data_ptr,\n> &merkle_tree))\n> return set_error(serror, SCRIPT_ERR_WRONGCONTRACTDATA);\n> popstack(stack);\n> popstack(stack);\n> popstack(stack);\n> popstack(stack);\n> }\n> break;\n>\n> ### Commentary\n>\n> CheckDoubleTweak function (implemented in the branch) gets an x-only\n> pubkey,\n> optionally some data, and optionally taptree's merkle root.\n> It verifies that the x-only pubkey being tested equals the given naked\n> pubkey,\n> optionally tweaked with the embedded data, optionally tweaked with the\n> tagged\n> hash of the merkle tree per BIP-0341 [3].\n> Making both the tweaks optional allows to simplify the code, and also to\n> obtain\n> more compact scripts in some spending paths.\n>\n> In words:\n>\n> - OP_CHECKINPUTCONTRACTVERIFY: verify that the current input's internal key\n> contains some embedded data (which would typically be passed through the\n> witness stack)\n> - OP_CHECKOUTPUTCONTRACTVERIFY: verify that a given output is a certain\n> P2TR\n> output script containing the desired embedded data.\n>\n> TBD if the tweaking used for the embedded data tweak should use a tagged\n> hash;\n> omitted for simplicity in this demo implementation.\n>\n> ### Amount preservation\n>\n> In the code above and in the linked demo implementation, the opcodes only\n> operate on the scriptPubkey; a complete implementation would want to make\n> sure\n> that amounts are correctly preserved.\n>\n> The most direct and general way to address this would be to allow direct\n> introspection on the output amounts. This has the complication that output\n> amounts require 64-bits arithmetics, as discussed in the context of other\n> proposals, for example: [4].\n>\n> One more limited approach that works well for many interesting contracts\n> is that of the deferred checks, implemented in OP_VAULT [2].\n> The idea is that all the amounts of the inputs that commit to the same\n> output\n> script with OP_CHECKOUTPUTCONTRACTVERIFY are added together, and the script\n> interpreter requires that the amount of that output is not smaller than the\n> total amount of those inputs. This check is therefore transaction-wide\n> rather\n> than being tested during the input's script evaluation.\n>\n> This behaviour is adequate for vaults and likely suitable for many other\n> applications; however, it's not the most general approach. I didn't try to\n> implement it yet, and defer the decision on the best approach to a later\n> time.\n>\n> ### Extensions\n>\n> The opcodes above are not enough for the full generality of MATT: one would\n> need to add an opcode like OP_SHA256CAT to allow the data embedding to\n> commit\n> to multiple pieces of data.\n> This is not used in today's post, therefore I left it out of these code\n> examples.\n>\n> It would be easy to extend OP_CHECKOUTPUTCONTRACTVERIFY to also apply for\n> an arbitrary input (typically, different from the currently executed one);\n> there\n> are likely use cases for that, allowing to define contracts with more\n> complex\n> cross-input semantics, but I preferred to keep things simple.\n>\n> Of course, one could also entirely replace CICV/COCV with generic full\n> introspection on inputs/output's program, plus opcodes for elliptic curve\n> math\n> and tagged hashes.\n>\n>\n> ##########################\n> # PART 2: Vaults with MATT\n> ##########################\n>\n> In the rest of this post, I will document the first attempt at creating a\n> vault\n> using the opcodes described.\n>\n> While not an attempt at cloning exactly the functionality of OP_VAULT [2],\n> it borrows heavily from the excellent work that was done there.\n>\n> In particular, it also inherits the choice of using OP_CTV as a primitive,\n> building on top of the bitcoin-inquisition's current branch that has\n> already\n> merged OP_CTV. Reasonable vaults would be possible without CTV, but they\n> would be less efficient, particularly in the case of sending to many\n> addresses\n> in a single unvaulting flow.\n>\n> ### Distilling OP_VAULT\n>\n> Abstracting from the implementation details, I mentally model a vault as a\n> simple state machine with 2 states: [V] and [U]:\n>\n> [V]: the initial vault UTXO(s);\n> [U]: the utxo produced by the \"trigger transaction\" during unvaulting.\n>\n> On the typical path: one or more [V] UTXOs are sent to the [U] state, and\n> after\n> a timelock set on [U] expires, [U] is spent to one or several destinations.\n> Crucially, the destination outputs and amounts are already decided when\n> [V] is\n> spent into [U].\n>\n> At any time before the funds are spent from [U], they can always be spent\n> by\n> sending them to some specified recovery path.\n>\n> There are two key elements that are part of OP_VAULT's semantics, and\n> could be\n> generalized:\n>\n> \u2212 Forcing the script/amount of the next stepon\n> \u2212 Storing some data for future Script's access (in the vault's case, a hash\n> that commits to the final withdrawal transaction).\n>\n> CICV/COCV generalize both to arbitrary scripts (taptrees) and state\n> machines,\n> and to dynamical and witness-dependent data embedded in the pubkey of a\n> P2TR\n> output.\n>\n> ### Vault parameters\n>\n> A contract that represents a vault has the following parameters (hardcoded\n> in\n> the script when the vault is created):\n>\n> - alternate_pk: a key that can be used any time.\n> - spend_delay: the relative timelock before the withdrawal can be\n> finalized;\n> - recover_pk: a pubkey for a P2TR output where funds can be sent at any\n> time.\n>\n> The alternate_pk is a pubkey that can optionally be used as the key-path\n> spending condition for both states [V] and [U]. If such a spending\n> condition is not\n> desired, it can be replaced with a NUMS point, making the key-path\n> unspendable.\n>\n> The spend_delay is the number of blocks that must be mined before the final\n> withdrawal transaction\n>\n> In this example we also use an unvault_pk needed to authorize the\n> unvaulting\n> process (that is, spend [V] into [U]); this could be replaced with any\n> miniscript\n> or other conditions expressible in Script.\n>\n> ### P2TR structure for [V] (vault)\n>\n> internal key: alternate_pk\n>\n> Script 1: \"trigger\"\n> # witness: <out_i> <ctv-hash>\n> {\n> <alternate_pk>,\n> <merkle root of U's taptree>,\n> 2, OP_ROLL,\n> OP_CHECKOUTPUTCONTRACTVERIFY,\n>\n> <unvault_pk>\n> OP_CHECKSIG\n> }\n>\n> Script 2: \"recover\"\n> # witness: <out_i>\n> {\n> recover_pk,\n> OP_0, # no data tweak\n> OP_0, # no taptweak\n> OP_CHECKOUTPUTCONTRACTVERIFY,\n> OP_TRUE\n> }\n>\n> The \"trigger\" script requires in the witness an output index and the\n> ctv-hash\n> that describes the withdrawal transaction.\n> COCV forces the output to contain the ctv-hash as embedded data.\n> That's followed by the unvaulting condition \u2212 in this example, a simple\n> signature check.\n>\n> The \"recover\" script doesn't require any signature, and it simply forces\n> the output specified in the witness to be a P2TR output with recover_pk as\n> its\n> pubkey.\n>\n> (Omitting the \"recover\" script in [V] would reduce the size of the witness\n> by\n> 32 bytes in the expected case, and might be preferred for some users)\n>\n> ### P2TR structure for [U] (unvaulting state)\n>\n> internal key: alternate_pk (tweaked with ctv_hash)\n>\n> Script 1: \"withdrawal\"\n> # witness: <ctv_hash>\n> {\n> OP_DUP,\n>\n> # check that the top of the stack is the\n> # embedded data in the current input\n> <alternate_pk>, OP_SWAP,\n> OP_CHECKINPUTCONTRACTVERIFY,\n>\n> # Check timelock\n> <spend_delay>,\n> OP_CHECKSEQUENCEVERIFY,\n> OP_DROP,\n>\n> # Check that the transaction output is as expected\n> OP_CHECKTEMPLATEVERIFY\n> }\n>\n> Script 2: \"recover\"\n> # witness: <out_i>\n> {\n> <recover_pk>,\n> OP_0,\n> OP_0,\n> OP_CHECKOUTPUTCONTRACTVERIFY,\n> OP_TRUE\n> }\n>\n> The \"withdrawal\" finalizes the transaction, by checking that the timelock\n> expired and\n> the outputs satisfy the CTV hash that was committed to in the previous\n> transaction.\n>\n> The \"recover\" script is identical as before.\n>\n>\n> ### Differences with OP_VAULT vaults\n>\n> Here I refer to the latest version of OP_VAULT at the time of writing. [5]\n> It is not a thorough analysis.\n>\n> Unlike the implementation based on OP_VAULT, the [V] utxos don't have an\n> option\n> to add an additional output that is sent back to the same exact vault.\n> Supporting this use case seems to require a more general way of handling\n> the\n> distribution of amounts than what I discussed in the section above: that\n> would\n> in fact need to be generalized to the case of multiple\n> OP_CHECKOUTPUTCONTRACTVERIFY opcodes executed for the same input.\n>\n> By separating the ctv-hash (which is considered \"data\") from the scripts\n> in the\n> taptree, one entirely avoids the need to dynamically create taptrees and\n> replace leaves in the covenant-encumbered UTXOs; in fact, the taptrees of\n> [V]\n> and [U] are already set in stone when [V] utxos are created, and only the\n> \"data\" portion of [U]'s scriptPubKey is dynamically computed. In my\n> opinion,\n> this makes it substantially easier to program \"state machines\" that\n> control the\n> behavior of coins, of which vaults are a special case.\n>\n> I hope you'll find this interesting, and look forward to your comments.\n>\n> Salvatore Ingala\n>\n>\n> [1] -\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-November/021223.html\n> [2] - https://github.com/bitcoin/bips/pull/1421\n> [3] - https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki\n> [4] -\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019420.html\n> [5] -\n> https://github.com/bitcoin/bips/blob/7112f308b356cdf0c51d917dbdc1b98e30621f80/bip-0345.mediawiki\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230502/c7f0f38b/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Vaults in the MATT framework",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Salvatore Ingala",
                "Michael Folkson"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 33811
        }
    },
    {
        "title": "[bitcoin-dev] Civ Kit: A Peer-to-Peer Electronic Market System",
        "thread_messages": [
            {
                "author": "Antoine Riard",
                "date": "2023-05-01T17:47:46",
                "message_text_only": "Hi all,\n\nOne of the most relevant feedback I received on the paper publication\nwas the lack of underscoring front-running resistance as a fundamental\nproperty wished for a peer-to-peer marketplace.\n\nIt is expected the level of front-running resistance aimed by the\nmarket participants to be heavily functioned by the types of trades\nconsidered: fiat currencies, real goods, services. For some classes of\ngoods, e.g commodities one cannot expect the same level of item\nliquidity due to cycle of production and exogenous factors like\nweather. Some types of trades marketplaces might be exposed to far\nless front-running risks and rather would have to deal with accurate\nrisk modelling of the underlying goods. E.g attest there is a\ndecentralized identifier or any other linkage proof of the physical\ngood existence staying valid for the duration of offer lifetime.\nOffers conditions themselves might be far more verbose and precise\nspecial Bitcoin Script paths to morph the shipment risks.\n\nOn the other hand, the types of trades like fiat currencies or bitcoin\nfinancial contracts (e.g discreet log contracts or submarine swaps),\nfront-running risk by the bulletin board sounds a qualified concern.\nIn traditional finance, front-running is defined as \"entering into an\nequity trade, options or future contracts with advance knowledge of a\nblock transaction that will influence the price of the underlying\nsecurity to capitlize on the trade\" [0]. In Bitcoin/Civkit parlance, a\nfront-running could be a board on the discovery of a batch of market\noffers increasing liquidity for a fiat-2-btc pair, seizing the\nopportunity by forwarding a HTLC across a Lightning payment path to\nenter into the trade, before publishing the offer on its board.\n\nI think you have at least two security paradigms to mitigate\nfront-running happening peer-to-peer marketplace. The first one is to\nduplicate the announcement of the offers to a number of concurrent\nboard operated by independent identities and in parallel monitor the\nlatency. Latency anomalies should be spotted on by watchtower-like\ninfrastructure at the service of makers/takers and in case of repeated\nanomalies a maker should disqualify the misbehaving board from future\nannouncements. As all statistical mitigation it is not perfect and\nopen the way to some margin of exploitation by the boards, as the\nwatchtower monitoring frequency can be guessed. Additionally, this\nlatency monitoring paradigm sounds to be valid under the assumption\nthat at least one board is \"honest\" and board might have a holistic\ninterest to silently collude. Running or accessing monitoring\ninfrastructure comes with a new liveliness requirement or additional\ncost for mobile clients.\n\nAnother paradigm can be to run the bulletin boards as a federation e.g\nunder Honey Badger BFT as used by Fedimint [1]. The incoming board\noffers become consensus items that must be announced to all the\nfederations members onion gateway and which are not announced before a\nconsensus proposal has been adopted. The e-cash tokens can be rather\nBitcoin-paid credentials required by the board federation for\npublication. The federation members earn an income as a group to\nfollow the consensus rules and be paid only when there is \"consensus\"\npublication. The federation could adopt some \"DynFed\" techniques to\nextend the federation set [2]. One can imagine a federation consisting\nof all the significant market participants, leveling the field for\nall.\n\nIs there another security paradigm direction to mitigate front-running\nand other asymmetries of information ? I can't immediately imagine\nmore though I believe it stays an interesting open question.\n\nIn fine, the Civkit proposes a flexible framework for peer-to-peer\nmarketplace, where propagation latency monitoring and federation set\nand rules can be tweaked as \"front-running resistance\" parameters,\nadapting to the types of trades and market participants tolerance.\nConfiguration of those parameters will at the end be function of\nreal-world deployments. Somehow mass front-running on the board is a\n\"champagne\" issue  I'll be happy to have.\n\nBest,\nAntoine\n\n[0] https://www.finra.org/investors/insights/getting-speed-high-frequency-trading\n[1] https://fedimint.org/docs/CommonTerms/HBBFTConsensus\n[2] https://blockstream.com/assets/downloads/pdf/liquid-whitepaper.pdf\n\n\nLe jeu. 13 avr. 2023 \u00e0 15:10, Antoine Riard <antoine.riard at gmail.com> a\n\u00e9crit :\n\n> Hi list,\n>\n> We have been working since a while with Nicholas Gregory (Commerce Block),\n> Ray Youssef (the Built With Bitcoin foundation) and few others on a new\n> peer-to-peer market system to enable censorship-resistant and\n> permissionless global trading in all parts of the world. While the design\n> aims in priority to serve on-ramp/off-ramp trading, it can be extended to\n> support any kind of trading: goods, services, bitcoin financial derivatives\n> like discreet log contracts.\n>\n> The design combines the Nostr architecture of simple relays announcing\n> trade orders to their clients with Lightning onion routing infrastructure,\n> therefore granting high-level of confidentiality to the market\n> participants. The market boards are Nostr relays with a Lightning gateway,\n> each operating autonomously and in competition. The market boards can be\n> runned as a federation however there is no \"decentralized orderbook\" logged\n> into the blockchain. The trades are escrowed under Bitcoin Script\n> contracts, relying on moderations and know your peer oracles for\n> adjudication.\n>\n> The scoring of trades, counterparties and services operators should be\n> enabled by the introduction of a Web-of-Stakes, assembled from previous\n> ideas [0]. From the Bitcoin UTXO set servicing as a trustless source of\n> truth, an economic weight can be assigned to each market entity. This\n> reputation paradigm could be composed with state-of-the-art Web-of-Trust\n> techniques like decentralized identifiers [1].\n>\n> A consistent incentive framework for service operators is proposed by the\n> intermediary of privacy-preserving credentials backed by Bitcoin payments,\n> following the lineaments of IETF's Privacy Pass [2]. Services operators\n> like market boards and oracles are incentivized to thrive for efficiency,\n> akin to routing hops on Lightning and miners on the base layer.\n>\n> The whitepaper goes deep in the architecture of the system [3] (Thanks to\n> the peer reviewers!).\n>\n> We'll gradually release code and modules, extensively building on top of\n> the Lightning Dev Kit [4] and Nostr libraries. All according to the best\n> Bitcoin open-source and decentralized standards established by Bitcoin Core\n> and we're looking forward to collaborating with everyone in the community\n> to standardize libraries and guarantee interoperability between clients\n> with long-term thinking.\n>\n> Feedback is very welcome!\n>\n> Cheers,\n> Nick, Ray and Antoine\n>\n> [0]\n> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-November/002884.html\n> [1] https://www.w3.org/TR/2022/REC-did-core-20220719/\n> [2] https://privacypass.github.io\n> [3] https://github.com/civkit/paper/blob/main/civ_kit_paper.pdf\n> [4] https://lightningdevkit.org\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230501/fb6966e8/attachment.html>"
            },
            {
                "author": "Chris Stewart",
                "date": "2023-05-09T15:09:16",
                "message_text_only": ">In traditional finance, front-running is defined as \"entering into an\nequity trade, options or future contracts with advance knowledge of a block\ntransaction that will influence the price of the underlying security to\ncapitlize on the trade\" [0]. In Bitcoin/Civkit parlance, a front-running\ncould be a board on the discovery of a batch of market offers increasing\nliquidity for a fiat-2-btc pair, seizing the opportunity by forwarding a\nHTLC across a Lightning payment path to enter into the trade, before\npublishing the offer on its board.\n\nTo summarize, assume we have Mary the Maker, Terry the Taker, and Bob the\nbulletin board operator\n\n1. Mary the Maker publishes a limit order to buy a derivative\n2. Bob the bulletin board operator has the option to execute against Mary's\norder\n3. If Bob doesn't want to execute against the order, he relays the order to\nTerry the Taker (and other subscribers to Bob's market)\n4. Terry has the option to execute a trade against Mary's limit order\n5. If Terry decides not to execute, Mary's order sits on the bulletin board.\n\nI personally don't think this is that big of a concern, if Bob can collect\noutsized profits from his trusted position as the bulletin board operator,\nTerry will eventually move to other markets because Bob is only relaying\nwhat Bob perceives to be unprofitable orders.\n\n>From the perspective of Mary, she is happy. Her order got executed at the\nprice she specified. Terry is the one that loses here. This model ends up\nlooking much more like a brokerage rather than an exchange market\nstructure. Terry should open up his own brokerage (bulletin board) and\ncompete on quoting prices with Bob.\n\nBob and Terry can then be compared on metrics like execution quality\n<https://clearingcustody.fidelity.com/trade-execution-quality>, which then\ndraws more market activity since they are providing better prices.\n\n>Somehow mass front-running on the board is a \"champagne\" issue I'll be\nhappy to have.\n\nThis. Frontrunning is a good problem to have, that means your market has\nactive participants and liquidity. Finding what products people are\ninterested in trading, and giving them a good user experience is more\nimportant. Everything else will fall in line after that.\n\n\nOn Mon, May 1, 2023 at 1:06\u202fPM Antoine Riard via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi all,\n>\n> One of the most relevant feedback I received on the paper publication was the lack of underscoring front-running resistance as a fundamental property wished for a peer-to-peer marketplace.\n>\n> It is expected the level of front-running resistance aimed by the market participants to be heavily functioned by the types of trades considered: fiat currencies, real goods, services. For some classes of goods, e.g commodities one cannot expect the same level of item liquidity due to cycle of production and exogenous factors like weather. Some types of trades marketplaces might be exposed to far less front-running risks and rather would have to deal with accurate risk modelling of the underlying goods. E.g attest there is a decentralized identifier or any other linkage proof of the physical good existence staying valid for the duration of offer lifetime. Offers conditions themselves might be far more verbose and precise special Bitcoin Script paths to morph the shipment risks.\n>\n> On the other hand, the types of trades like fiat currencies or bitcoin financial contracts (e.g discreet log contracts or submarine swaps), front-running risk by the bulletin board sounds a qualified concern. In traditional finance, front-running is defined as \"entering into an equity trade, options or future contracts with advance knowledge of a block transaction that will influence the price of the underlying security to capitlize on the trade\" [0]. In Bitcoin/Civkit parlance, a front-running could be a board on the discovery of a batch of market offers increasing liquidity for a fiat-2-btc pair, seizing the opportunity by forwarding a HTLC across a Lightning payment path to enter into the trade, before publishing the offer on its board.\n>\n> I think you have at least two security paradigms to mitigate front-running happening peer-to-peer marketplace. The first one is to duplicate the announcement of the offers to a number of concurrent board operated by independent identities and in parallel monitor the latency. Latency anomalies should be spotted on by watchtower-like infrastructure at the service of makers/takers and in case of repeated anomalies a maker should disqualify the misbehaving board from future announcements. As all statistical mitigation it is not perfect and open the way to some margin of exploitation by the boards, as the watchtower monitoring frequency can be guessed. Additionally, this latency monitoring paradigm sounds to be valid under the assumption that at least one board is \"honest\" and board might have a holistic interest to silently collude. Running or accessing monitoring infrastructure comes with a new liveliness requirement or additional cost for mobile clients.\n>\n> Another paradigm can be to run the bulletin boards as a federation e.g under Honey Badger BFT as used by Fedimint [1]. The incoming board offers become consensus items that must be announced to all the federations members onion gateway and which are not announced before a consensus proposal has been adopted. The e-cash tokens can be rather Bitcoin-paid credentials required by the board federation for publication. The federation members earn an income as a group to follow the consensus rules and be paid only when there is \"consensus\" publication. The federation could adopt some \"DynFed\" techniques to extend the federation set [2]. One can imagine a federation consisting of all the significant market participants, leveling the field for all.\n>\n> Is there another security paradigm direction to mitigate front-running and other asymmetries of information ? I can't immediately imagine more though I believe it stays an interesting open question.\n>\n> In fine, the Civkit proposes a flexible framework for peer-to-peer marketplace, where propagation latency monitoring and federation set and rules can be tweaked as \"front-running resistance\" parameters, adapting to the types of trades and market participants tolerance. Configuration of those parameters will at the end be function of real-world deployments. Somehow mass front-running on the board is a \"champagne\" issue  I'll be happy to have.\n>\n> Best,\n> Antoine\n>\n> [0] https://www.finra.org/investors/insights/getting-speed-high-frequency-trading\n> [1] https://fedimint.org/docs/CommonTerms/HBBFTConsensus\n> [2] https://blockstream.com/assets/downloads/pdf/liquid-whitepaper.pdf\n>\n>\n> Le jeu. 13 avr. 2023 \u00e0 15:10, Antoine Riard <antoine.riard at gmail.com> a\n> \u00e9crit :\n>\n>> Hi list,\n>>\n>> We have been working since a while with Nicholas Gregory (Commerce\n>> Block), Ray Youssef (the Built With Bitcoin foundation) and few others on a\n>> new peer-to-peer market system to enable censorship-resistant and\n>> permissionless global trading in all parts of the world. While the design\n>> aims in priority to serve on-ramp/off-ramp trading, it can be extended to\n>> support any kind of trading: goods, services, bitcoin financial derivatives\n>> like discreet log contracts.\n>>\n>> The design combines the Nostr architecture of simple relays announcing\n>> trade orders to their clients with Lightning onion routing infrastructure,\n>> therefore granting high-level of confidentiality to the market\n>> participants. The market boards are Nostr relays with a Lightning gateway,\n>> each operating autonomously and in competition. The market boards can be\n>> runned as a federation however there is no \"decentralized orderbook\" logged\n>> into the blockchain. The trades are escrowed under Bitcoin Script\n>> contracts, relying on moderations and know your peer oracles for\n>> adjudication.\n>>\n>> The scoring of trades, counterparties and services operators should be\n>> enabled by the introduction of a Web-of-Stakes, assembled from previous\n>> ideas [0]. From the Bitcoin UTXO set servicing as a trustless source of\n>> truth, an economic weight can be assigned to each market entity. This\n>> reputation paradigm could be composed with state-of-the-art Web-of-Trust\n>> techniques like decentralized identifiers [1].\n>>\n>> A consistent incentive framework for service operators is proposed by the\n>> intermediary of privacy-preserving credentials backed by Bitcoin payments,\n>> following the lineaments of IETF's Privacy Pass [2]. Services operators\n>> like market boards and oracles are incentivized to thrive for efficiency,\n>> akin to routing hops on Lightning and miners on the base layer.\n>>\n>> The whitepaper goes deep in the architecture of the system [3] (Thanks to\n>> the peer reviewers!).\n>>\n>> We'll gradually release code and modules, extensively building on top of\n>> the Lightning Dev Kit [4] and Nostr libraries. All according to the best\n>> Bitcoin open-source and decentralized standards established by Bitcoin Core\n>> and we're looking forward to collaborating with everyone in the community\n>> to standardize libraries and guarantee interoperability between clients\n>> with long-term thinking.\n>>\n>> Feedback is very welcome!\n>>\n>> Cheers,\n>> Nick, Ray and Antoine\n>>\n>> [0]\n>> https://lists.linuxfoundation.org/pipermail/lightning-dev/2020-November/002884.html\n>> [1] https://www.w3.org/TR/2022/REC-did-core-20220719/\n>> [2] https://privacypass.github.io\n>> [3] https://github.com/civkit/paper/blob/main/civ_kit_paper.pdf\n>> [4] https://lightningdevkit.org\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230509/1f6e47ee/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Civ Kit: A Peer-to-Peer Electronic Market System",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Chris Stewart",
                "Antoine Riard"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 17309
        }
    },
    {
        "title": "[bitcoin-dev] Advances in Hashrate Derivatives Contracts",
        "thread_messages": [
            {
                "author": "Thomas Hartman",
                "date": "2023-05-01T23:48:14",
                "message_text_only": "Greetings!\n\nWe are presenting a paper: \u201cBlockrate Binaries on Bitcoin mainnet.\u201d\nThis is a formalization of the previously known Powswap[1] protocol.\nThese hashrate derivatives are off-chain contracts to make\npeer-to-peer binary contracts on the future rates of block discovery\nbetween two users.\n\nLink: https://github.com/blockrate-binaries/paper/blob/master/blockrate-binaries-paper.pdf\n    (also attached here)\nSha256 of current version of paper:\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n\nWe describe protocol steps in detail and the threat model, which\nlargely overlaps with other protocols (e.g., eclipse, pinning, miner\nbribe). A unique characteristic of this protocol is contentions -- ie\ntransaction confirmation racing --  in edge cases. We discuss issues\naround contention at the most basic level, leaving advanced\nmining-related game theory for future research.\n\nDeploying these contracts at scale would require novel infrastructure\nfor counterparty discovery and selection, which we describe in the\npaper. Part of this infrastructure could be shared with Discreet Log\nContracts or other protocols.\n\nBlockrate Binary Options could operate on top of Lightning payment\nchannels, although the exact construction requires further protocol\ndesign, especially for the routed version. We briefly discuss this, as\nwell as other potential advancements for these contracts.\n\nIt is yet to be established whether Blockrate Binary options are\nuseful financial tools for Bitcoin users. We believe that they may be\nuseful to miners for hedging their operations; and to all Bitcoin\nusers by making Bitcoin a more salable asset through bridging it to\nreal-world energy flows and providing a decentralized price indicator\nand a means of derivative trading.\n\nWe welcome protocol researchers to help us solve the remaining\nblockers. Most important are contention and lightning compatibility.\nWe also invite experienced core and lightning software developers who\ncan work out a beta implementation to start trying this out\n\"recklessly\" in the not too distant future.\n\nIf there is interest, we will set up infrastructure for community\nforums and contributions soon.\n\nThanks Gleb Naumenko and Antoine Riard for so much careful thought and\nwork. And thanks to Nadav Kohen for review before publication.\n\nPrivate inquiries can be directed to myself at this email.\n\n1 Powswap was originally introduced by Jeremy Rubin. See powswap.com\nand Advent Day 24.\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: blockrate-binaries-paper.pdf\nType: application/pdf\nSize: 482931 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230501/6d45ee2c/attachment-0001.pdf>"
            }
        ],
        "thread_summary": {
            "title": "Advances in Hashrate Derivatives Contracts",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Thomas Hartman"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2747
        }
    },
    {
        "title": "[bitcoin-dev] Formosa --- proposed improvement upon BIP39",
        "thread_messages": [
            {
                "author": "yurisvb at pm.me",
                "date": "2023-05-02T08:31:19",
                "message_text_only": "Dear colleagues,\nThe following is a password format that improves upon BIP39 by allowing meaningful, themed sentences with a regular grammatical structure instead of semantically disconnected words, while keeping the same entropy/checksum and total bits/non-repeating leading digits ratios (of 32/1 and 11/4 respectively).\n\nhttps://github.com/Yuri-SVB/formosa\n\nAnecdotal experiments suggest that less than one hour of moderate concentration is enough for long term memorization of 128 + 4 bits (equivalent to the 12 words standard of BIP39) if a theme of interest is employed.\n\nI hereby offer it to your scrutiny as a Bitcoin Improvement Proposal. Please don't hesitate to ask whatever issue about the project there might be.\n\nFaithfully yours, Yuri S VB.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230502/a9b52f02/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: publickey - yurisvb at pm.me - 0x535F445D.asc\nType: application/pgp-keys\nSize: 1678 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230502/a9b52f02/attachment.bin>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 509 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230502/a9b52f02/attachment.sig>"
            },
            {
                "author": "Keagan McClelland",
                "date": "2023-05-19T21:24:45",
                "message_text_only": "Good day Yuri,\n\nThis is a very cool idea. After reviewing the repository it seems that\nthere lacks a BIP style specification for this, so it is possible that some\nof my takeaways may not be correct but I figured I'd comment with some\nobservations anyway. Feel free to correct me where I've made a mistake.\n\nI think to make an idea like this work it would be necessary for it to\n\"extend\" BIP39 rather than \"replace\" it. What I mean by this is that BIP39\nis heavily entrenched in the ecosystem and so in order for you to sidestep\nthe need to get everyone in the ecosystem to adopt a new standard, you'd\nwant this process to be able to output a standard BIP39 seed sequence. This\nbecomes even more important when you allow these different \"themes\" that\nare mentioned later in the document. The notion of themes practically\nprecludes the standardization of the technique since customization really\nis the antithesis of standardization.\n\nThe largest value proposition of these schemes is that it allows\nsignificant wallet interoperability. This is achieved if process for\ntranslating these phrases to the underlying wallet seed is deterministic.\nThemes may prove to make this harder to solve. I also do not believe that\nthemes meaningfully increase the ability to remember the phrase: the fact\nthat the phrase has a valid semantic at all is a massive step up from an\nundifferentiated sequence of words that is the current state of BIP39. The\nbenefits afforded by the themes here are little by comparison.\n\nOverall, I think exploring this idea further is a good idea. However, there\nmay be concerns about whether the increased memorability is a good thing.\nIt would certainly make $5 wrench attacks more viable, not less. I can't\nhelp but ask myself the question whether more Bitcoin is lost because of\nseed phrases not being memorized, or because of social engineering\nexercises used to scrape these phrases from the brains of users. I have a\nhunch that loss is a larger problem than theft, but it is a very real\npossibility that a wide deployment of this type of tech could change that.\n\nStay Inspired,\nKeags\n\nOn Tue, May 2, 2023 at 6:05\u202fAM Yuri S VB via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Dear colleagues,\n>\n> The following is a password format that improves upon BIP39 by allowing\n> meaningful, themed sentences with a regular grammatical structure instead\n> of semantically disconnected words, while keeping the same entropy/checksum\n> and total bits/non-repeating leading digits ratios (of 32/1 and 11/4\n> respectively).\n>\n> https://github.com/Yuri-SVB/formosa\n>\n> Anecdotal experiments suggest that less than one hour of moderate\n> concentration is enough for long term memorization of 128 + 4 bits\n> (equivalent to the 12 words standard of BIP39) if a theme of interest is\n> employed.\n>\n> I hereby offer it to your scrutiny as a Bitcoin Improvement Proposal.\n> Please don't hesitate to ask whatever issue about the project there might\n> be.\n>\n> Faithfully yours, Yuri S VB.\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230519/398213db/attachment-0001.html>"
            },
            {
                "author": "yurisvb at pm.me",
                "date": "2023-05-19T23:08:36",
                "message_text_only": "Good day, Keagan and all!\n\nFirst of all, thank you for your feedback! Yes, I made it so that Formosa does accomplish that: BIP39 is a particular case; a degenerate 'theme' in which you have sentences of just 11 bits (instead of 33 in a typical Formosa sentence), and they are made up of just one (11 bits) word with no syntactic structure. The sublist of possibilities for this one field does not impact and is not impacted by any other (because there is no other). Therefore it is rather a list (without 'sub') and it consists of the original BIP39 word list.\n\nIn addition to that, we make it so that themes (including BIP39) are convertible into one another. The conversion is straightforward: just map the words back into the array of bits that originated it and derive the new seed from it using the new theme. This is why I made sure to have sentences have a number of bits multiple of 11. Moreover, in order to enable forwards and backwards compatibility and facilitate adoption, we set the original BIP39 as standard for key derivation. Meaning: in order to derive keys from a seed, we first convert back to BIP39 and then proceed the KDF step as originally specified in BIP39. This way legacy addresses can be kept even if a user wants to choose a theme. Finally, as a bonus, one could argue that a hyper customization would allow for a(n additional, dispensable, non-critical) layer of obscurity (which, therefore, wouldn't violate Kerckhoff's principle). Example: consider, for example, that a one hyper-customized seed could be (just an extra tool) more easily stenographed in human speech or written text.\n\nI hope this answers your objections concerning loss of standardization. Thank you for bringing about the issue of coercion resistance! Here is my response to that: a user willing to avoid the additional vulnerability to coercion that an effective brain wallet would ensue could just not put up the effort to memorize the seed for long term, and just take advantage of the easier transcription and checking (ie: short-term memorization). Right now I could anticipate a response in the lines of \"Such a format might as well be so much easier to long-term memorize that a user either ends up doing that accidentally, and/or the denial of that becomes less plausible.\". If that is the objection, well, thank you, and, however self-serving it is my saying it, I tend to agree that that would,\u00a0in fact,\u00a0be the case. My response to it is that:\n\n1.  knowledge-based authentication, whether or not for Bitcoin, still have some properties that possession-based authentication doesn't. Whatever master password you memorize, in whatever context, you'd better have an efficient format, with uniformly high entropy density (and even possibly checksum), and not having to resort to a silly meme about a staple, a battery and a horse.\n2.  Mitigating the shortcomings of KBA can arguably be done better with 2FA, instead of PBA. Having a superior format just as beneficial as before.\n3.  Once again, thank you for bringing up coercion resistance! I'd like to point out to an elephant in the room: To this day, and to the best of my knowledge there is no scheme, protocol or ceremony that simultaneously achieves self-custody and coercion resistance with\u00a0non-obscurity. IMHO this is an critical problem for various reasons and I'll be making a thread about it shortly.\n\n\nThank you again for your inputs and be my guest to further debate your points! I hope this could have been of help!\n\nFaithfully yours, Yuri S VB.\n------- Original Message -------\nOn Friday, May 19th, 2023 at 11:24 PM, Keagan McClelland <keagan.mcclelland at gmail.com> wrote:\n\n\n> Good day Yuri,\n> \n\n> This is a very cool idea. After reviewing the repository it seems that there lacks a BIP style specification for this, so it is possible that some of my takeaways may not be correct but I figured I'd comment with some observations anyway. Feel free to correct me where I've made a mistake.\n> I think to make an idea like this work it would be necessary for it to \"extend\" BIP39 rather than \"replace\" it. What I mean by this is that BIP39 is heavily entrenched in the ecosystem and so in order for you to sidestep the need to get everyone in the ecosystem to adopt a new standard, you'd want this process to be able to output a standard BIP39 seed sequence. This becomes even more important when you allow these different \"themes\" that are mentioned later in the document. The notion of themes practically precludes the standardization of the technique since customization really is the antithesis of standardization.\n> \n\n> The largest value proposition of these schemes is that it allows significant wallet interoperability. This is achieved if process for translating these phrases to the underlying wallet seed is deterministic. Themes may prove to make this harder to solve. I also do not believe that themes meaningfully increase the ability to remember the phrase: the fact that the phrase has a valid semantic at all is a massive step up from an undifferentiated sequence of words that is the current state of BIP39. The benefits afforded by the themes here are little by comparison.\n> \n\n> Overall, I think exploring this idea further is a good idea. However, there may be concerns about whether the increased memorability is a good thing. It would certainly make $5 wrench attacks more viable, not less. I can't help but ask myself the question whether more Bitcoin is lost because of seed phrases not being memorized, or because of social engineering exercises used to scrape these phrases from the brains of users. I have a hunch that loss is a larger problem than theft, but it is a very real possibility that a wide deployment of this type of tech could change that.\n> \n\n> Stay Inspired,\n> Keags\n> \n\n> On Tue, May 2, 2023 at 6:05\u202fAM Yuri S VB via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n\n> > Dear colleagues,\n> > The following is a password format that improves upon BIP39 by allowing meaningful, themed sentences with a regular grammatical structure instead of semantically disconnected words, while keeping the same entropy/checksum and total bits/non-repeating leading digits ratios (of 32/1 and 11/4 respectively).\n> > \n\n> > https://github.com/Yuri-SVB/formosa\n> > \n\n> > Anecdotal experiments suggest that less than one hour of moderate concentration is enough for long term memorization of 128 + 4 bits (equivalent to the 12 words standard of BIP39) if a theme of interest is employed.\n> > \n\n> > I hereby offer it to your scrutiny as a Bitcoin Improvement Proposal. Please don't hesitate to ask whatever issue about the project there might be.\n> > \n\n> > Faithfully yours, Yuri S VB.\n> > \n\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230519/195f8cf8/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: publickey - yurisvb at pm.me - 0x535F445D.asc\nType: application/pgp-keys\nSize: 1678 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230519/195f8cf8/attachment-0001.bin>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 509 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230519/195f8cf8/attachment-0001.sig>"
            }
        ],
        "thread_summary": {
            "title": "Formosa --- proposed improvement upon BIP39",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Keagan McClelland",
                "yurisvb at pm.me"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 12587
        }
    },
    {
        "title": "[bitcoin-dev] A payout scheme for a non custodial mining pool",
        "thread_messages": [
            {
                "author": "F M",
                "date": "2023-05-03T15:48:46",
                "message_text_only": "https://docs.google.com/document/d/1qiOOSOT7epX658_nhjz-jj0DlnSRvytemOv_u_OtMcc/edit?usp=sharing\n\n\nDear community,\n\nIn the last months there have been several discussions about the topic of\ncovenants and payment pools\n\n[0]. It has been difficult to approach these topics as it seems that there\nis no agreement in a precise\n\ndefinition on what is a covenant or what is a payment pool. This is\nprobably due to the great generality\n\nof these two concepts. Perhaps, a good approach to study them is to look at\nsome different use-cases\n\nand see which are the properties that appear more often and enclose them in\na clear definition. About\n\npayment pools, that may be considered themself as a covenant, we\nspecialized further, studying a payment\n\npool\u2019s scheme that may be used for the miners of a mining pool in order to\nshare the ownership of the\n\ncoinbase reward [1]. This would make the pool non-custodial.\n\nThe main pools now are custodial, in the sense that they collect the\nrewards of mining, and use them\n\nsubsequently to pay the miners. As there are few large pools that find\nalmost all the blocks, custodial\n\npolls increase the level of centralization in a protocol born to be\ndecentralized and consensus ruled.\n\nThis is why we generally want non-custodial pools.\n\nThe only non-custodial payment pool that appeared is P2Pool, active some\nyears ago, that was also decentralized.\n\nIn P2Pool, the miners were paid directly by an output of the coinbase\ntransaction. This implies a very\n\nlarge coinbase, preventing the inclusion of more transactions in the block,\nand therefore collecting\n\nless fees and making the mining less profitable, compared to a custodial\npool. This makes the P2Pool\n\npayout scheme inappropriate considering also that there is big effort in\nkeeping blockchain light, with\n\nseveral off-chain protocols.\n\nOur scheme uses ANYPREVOUT signatures and it is based on the idea of\npayment trees. A payment tree is\n\na tree of transactions that redistributes the funds to the payment pool\nparticipants, having their address\n\nto the leaves. The root contains the funds of the payment pool on n-of-n\nmultisig. We allow payment trees\n\nfor future payment pools, in which the input\u2019s references of the\ntransactions are left empty and the\n\nsignatures are ANYPREVOUT.\n\nThis makes it possible to safely create a payment pool, merge two payment\npools and withdraw funds from\n\na payment pool.\n\nWhy do we use ANYPREVOUT? Most payment pool structures use precompiled\ntransactions for allowing safe\n\nwithdrawal. The signatures of these transactions clearly commits to the\nextranonce of the coinbase. So,\n\nif the payment pool is set for the co-ownership of the mining reward, there\nmust be a set of precompiled\n\ntransactions for every extranonce tried by every miner, that may not be\nfeasible.\n\nThe use of ANYPREVOUT allow the miners to collectively construct a payment\ntree that \u201cwaits\u201d the rewards,\n\nin the case that some miners finds a block. This payment tree is unique for\nall miners.\n\nWe assume the pool to be centralized, even though our payment pool scheme\nperhaps can be generalized\n\nto decentralized pools. We compared the average space occupied on the\nblockchain and compared with the\n\none of P2Pool. The results seem to be promising in this aspect, and are\neven better if the Pool is KYC.\n\nClearly, this is just a very brief summary of our work, that is enclosed\nand labeled as an RFC. So, every\n\nremark or comment may be very appreciated.\n\n\nAuthors:\n\n   -\n\n   Lorban (HRF), https://github.com/lorbax/, lorenzo.bonax at gmail.com\n   -\n\n   Fi3, https://github.com/fi3/\n   -\n\n   Rachel Rybarczyk (Galaxy Digital), https://github.com/rrybarczyk\n\nPS\nPlease note that although the linked document bears some resemblance to a\nresearch paper, it is presented as an RFC. We chose to publish it as an RFC\nbecause it is not intended to be a comprehensive work.\n\n[0]\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-July/020763.html\n\n[1]\nhttps://docs.google.com/document/d/1qiOOSOT7epX658_nhjz-jj0DlnSRvytemOv_u_OtMcc/edit?usp=sharing\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230503/dcdb342b/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2023-05-22T01:27:41",
                "message_text_only": "Hi Lorban,\n\nThe RFC is very clear and consistent on presenting payments pools in\nthe context of non-custodial mining pools, congrats to the authoring\nteam.\n\nFew feedbacks, on the technical definition of a payment pool, the\ncommon idea between all payment pools ideas presented so far\n(Joinpool, Radixpool, Coinpool) is the pool tree (what you're calling\nthe payment tree) enabling a compact withdrawal from the pool, with\nmore or less conservation of the pooling after a withdrawal.\n\nIn 2., for the observation of the group of properties, there is one\nmore which matters a lot if you would like to have off-chain novation\nof the pool tree, it's replay security, where a pool participant\ncannot replay its withdrawal, partially or in whole, after withdrawing\nall its balances.\n\nIn 2.1, \"as, for an integer n, the n! rapidly grows in size, it\nfollows that the number of pre-signed transactions that has to be\ncomputed rapidly becomes too large\".\"This problem seems to not have\nbeen considered in [14]\". The factorial complexity of the number of\nstates (transactions/balances) in function of the number pool\nparticipants is mentioned in a footnote of the paper: \"These\nrestrictions could be also achieved by pre-signing all possible\nsequences of state transitions (producing, storing and exchanging all\nthese signatures), which scales poorly (factorial) with the number of\nparticipants.\" and in the original mail post about Coinpool:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-June/017964.html\n:)\n\nIn 2.7, in the rational about using ANYPREVOUT, I think if you're\nusing the ANYPREVOUT variant, the spent output amount is committed by\nthe signature digest and I think this is introducing an\ninterdependency between the validity of the payment tree and the block\ntemplate of transactions, as in function of this latter the coinbase\nreward fluctuates ? I believe ANYPREVOUTANYSCRIPT is better as there\nis no such\ncommitment to the spent amount/scriptPubkey iirc.\n\nAbout the attacks, effectively the lack of cooperation of pool\nparticipants to enable cooperative withdrawal is a huge DoS factor, it\ncan be fought by fees to enter in the pool. Another deterrence is the\ntimelocking of the balance in case of non-cooperative closure. Past\nforce-closure of pools can be consumed as a proof of good-conduct by\nfuture co-participants in a payment pool.\n\nBest,\nAntoine\n\n\nLe mer. 3 mai 2023 \u00e0 17:05, F M via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n>\n> https://docs.google.com/document/d/1qiOOSOT7epX658_nhjz-jj0DlnSRvytemOv_u_OtMcc/edit?usp=sharing\n>\n>\n> Dear community,\n>\n> In the last months there have been several discussions about the topic of\n> covenants and payment pools\n>\n> [0]. It has been difficult to approach these topics as it seems that there\n> is no agreement in a precise\n>\n> definition on what is a covenant or what is a payment pool. This is\n> probably due to the great generality\n>\n> of these two concepts. Perhaps, a good approach to study them is to look\n> at some different use-cases\n>\n> and see which are the properties that appear more often and enclose them\n> in a clear definition. About\n>\n> payment pools, that may be considered themself as a covenant, we\n> specialized further, studying a payment\n>\n> pool\u2019s scheme that may be used for the miners of a mining pool in order to\n> share the ownership of the\n>\n> coinbase reward [1]. This would make the pool non-custodial.\n>\n> The main pools now are custodial, in the sense that they collect the\n> rewards of mining, and use them\n>\n> subsequently to pay the miners. As there are few large pools that find\n> almost all the blocks, custodial\n>\n> polls increase the level of centralization in a protocol born to be\n> decentralized and consensus ruled.\n>\n> This is why we generally want non-custodial pools.\n>\n> The only non-custodial payment pool that appeared is P2Pool, active some\n> years ago, that was also decentralized.\n>\n> In P2Pool, the miners were paid directly by an output of the coinbase\n> transaction. This implies a very\n>\n> large coinbase, preventing the inclusion of more transactions in the\n> block, and therefore collecting\n>\n> less fees and making the mining less profitable, compared to a custodial\n> pool. This makes the P2Pool\n>\n> payout scheme inappropriate considering also that there is big effort in\n> keeping blockchain light, with\n>\n> several off-chain protocols.\n>\n> Our scheme uses ANYPREVOUT signatures and it is based on the idea of\n> payment trees. A payment tree is\n>\n> a tree of transactions that redistributes the funds to the payment pool\n> participants, having their address\n>\n> to the leaves. The root contains the funds of the payment pool on n-of-n\n> multisig. We allow payment trees\n>\n> for future payment pools, in which the input\u2019s references of the\n> transactions are left empty and the\n>\n> signatures are ANYPREVOUT.\n>\n> This makes it possible to safely create a payment pool, merge two payment\n> pools and withdraw funds from\n>\n> a payment pool.\n>\n> Why do we use ANYPREVOUT? Most payment pool structures use precompiled\n> transactions for allowing safe\n>\n> withdrawal. The signatures of these transactions clearly commits to the\n> extranonce of the coinbase. So,\n>\n> if the payment pool is set for the co-ownership of the mining reward,\n> there must be a set of precompiled\n>\n> transactions for every extranonce tried by every miner, that may not be\n> feasible.\n>\n> The use of ANYPREVOUT allow the miners to collectively construct a payment\n> tree that \u201cwaits\u201d the rewards,\n>\n> in the case that some miners finds a block. This payment tree is unique\n> for all miners.\n>\n> We assume the pool to be centralized, even though our payment pool scheme\n> perhaps can be generalized\n>\n> to decentralized pools. We compared the average space occupied on the\n> blockchain and compared with the\n>\n> one of P2Pool. The results seem to be promising in this aspect, and are\n> even better if the Pool is KYC.\n>\n> Clearly, this is just a very brief summary of our work, that is enclosed\n> and labeled as an RFC. So, every\n>\n> remark or comment may be very appreciated.\n>\n>\n> Authors:\n>\n>    -\n>\n>    Lorban (HRF), https://github.com/lorbax/, lorenzo.bonax at gmail.com\n>    -\n>\n>    Fi3, https://github.com/fi3/\n>    -\n>\n>    Rachel Rybarczyk (Galaxy Digital), https://github.com/rrybarczyk\n>\n> PS\n> Please note that although the linked document bears some resemblance to a\n> research paper, it is presented as an RFC. We chose to publish it as an RFC\n> because it is not intended to be a comprehensive work.\n>\n> [0]\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-July/020763.html\n>\n> [1]\n> https://docs.google.com/document/d/1qiOOSOT7epX658_nhjz-jj0DlnSRvytemOv_u_OtMcc/edit?usp=sharing\n>\n>\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230522/8f480697/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "A payout scheme for a non custodial mining pool",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "F M",
                "Antoine Riard"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 11357
        }
    },
    {
        "title": "[bitcoin-dev] [Lightning-dev] A new Bitcoin implementation integrated with Core Lightning",
        "thread_messages": [
            {
                "author": "Matt Corallo",
                "date": "2023-05-06T05:58:55",
                "message_text_only": "An HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230505/2a696346/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "A new Bitcoin implementation integrated with Core Lightning",
            "categories": [
                "bitcoin-dev",
                "Lightning-dev"
            ],
            "authors": [
                "Matt Corallo"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 142
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Core maintainers and communication on merge decisions",
        "thread_messages": [
            {
                "author": "Michael Folkson",
                "date": "2023-05-07T07:03:02",
                "message_text_only": "There has been a proposed new maintainer on Bitcoin Core (ryanofsky). In the Core dev IRC meeting [0] yesterday it received multiple ACKs.\n\nThe decision process for adding a new maintainer was according to the IRC meeting that the maintainers decided privately there was a need for a maintainer \u201cwho understood our interfaces and modularization efforts well\u201d and that ryanofsky was a \u201cgood fit for that\u201d. I don\u2019t know whether this was decided in a private IRC channel or was decided at the recent in person Core Dev meeting. Regardless, many have had no input into the discussion on what kind of maintainer the project needs going forward and it seems the maintainers do not want to discuss that aspect of the decision.\n\nI posted a couple of questions in advance [1] of the meeting (I was unable to attend) that remained unanswered during the meeting. Essentially my concern is going forward current maintainers will decide which proposed new maintainers to add and which to block. If you aren\u2019t anointed by the current maintainers you won\u2019t get added as a maintainer and a half baked rationale will be provided to justify that decision. Longer term this will determine the pull requests that will ultimately get merged and which don't get merged because maintainers merge pull requests.\n\nOne of the justifications for blocking Vasil Dimov as a new maintainer despite many initial ACKs from maintainers (including Andrew Chow) and long term contributors was according to Andrew [2]:\n\n\u201cMaintainers inherently need to look at the things that everyone else has already looked at, if only to give it a final once over before merging (but hopefully, an actual review, not just looking it over).\u201d\n\nI follow the Bitcoin Core repo pretty closely and I haven\u2019t seen ryanofsky do this any more than Vasil does. This is not a criticism of ryanofsky, just as I wouldn\u2019t use it as a criticism for Vasil. It would get pretty annoying if everyone who wasn\u2019t a maintainer posted an ACK once many long term contributors had already ACKed to display supposed \u201cdesired maintainer traits\u201d. Especially if you are essentially just ACKing that others have done the work to review the PR and you just want to get your ACK on it to increase your ACK count without doing a fraction of what previous reviewers have done.\n\n\u201cI also want to mention that the people who have become maintainers in the past have had this kind of maintainer attitude towards review prior to becoming a maintainer\u201d\n\nAssuming ryanofsky hasn\u2019t had this maintainer attitude in the past (again not a criticism from me at least) does this mean this was a reason to block Vasil but not a reason to block ryanofsky? That seems inconsistent to me. When you\u2019re anointed you don\u2019t need to meet requirements but when you\u2019re blocked these requirements will be used to block your addition as a new maintainer?\n\nFor what it is worth from a personal perspective I don\u2019t see any reason for blocking ryanofsky as a maintainer especially if there is broad agreement amongst maintainers and long term contributors that we need a new maintainer who understands interfaces and modularization on the project. For that framing ryanofsky perfectly meets those requirements. But once again the (public) discussion element on the addition of maintainers is essentially a fa\u00e7ade, a framing for what the new maintainer needs to be has been decided in advance (in private) and an anointed individual who just so happens to align with that convenient framing will get added as a new maintainer.\n\nOn a more positive note there does seem to be more energy and momentum for collaboration and open communication on the project since I discussed communication in a previous post [3]. Hopefully this will continue. It doesn\u2019t address my concerns on maintainers and ultimately merge decisions but it definitely seems to me to be a step in a positive direction for the project.\n\n[0]: https://gnusha.org/bitcoin-core-dev/2023-05-04.log\n\n[1]: https://gnusha.org/bitcoin-core-dev/2023-05-01.log\n\n[2]: https://github.com/bitcoin/bitcoin/pull/25871#issuecomment-1382334059\n\n[3]:https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-April/021565.html\n\n--\nMichael Folkson\nEmail: michaelfolkson at [protonmail.com](http://protonmail.com/)\nGPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n\nLearn about Bitcoin: https://www.youtube.com/@portofbitcoin\n\n------- Original Message -------\nOn Tuesday, April 18th, 2023 at 13:40, Michael Folkson <michaelfolkson at protonmail.com> wrote:\n\n> Communication has been a challenge on Bitcoin Core for what I can tell the entire history of the project. Maintainers merge a pull request and provide no commentary on why they\u2019ve merged it. Maintainers leave a pull request with many ACKs and few (if any) NACKs for months and provide no commentary on why they haven't merged it. I can only speculate on why and it probably depends on the individual maintainer. Sometimes it will be poor communication skills, sometimes it will be a desire to avoid accountability, sometimes it will be fear of unreasonable and spiteful legal action if they mistakenly merge a pull request that ends up containing a bug. But search through the pull requests on Bitcoin Core and you will rarely see a rationale for a merge decision. The difference between say previous maintainers like Wladimir and some of the current maintainers is that previous maintainers were extremely responsive on IRC. If you disagreed with a merge decision or thought it had been merged prematurely they would be happy to discuss it on IRC. In present times at least a subset of the current maintainers are not responsive on IRC and will refuse to discuss a merge decision. One farcical recent example [0] was the pull request to add Vasil Dimov as a maintainer where despite many ACKs from other maintainers and other long term contributors two maintainers (fanquake and Gloria) refused to discuss it on the pull request or on IRC. It took almost 5 months for Gloria to comment on the pull request despite many requests from me on the PR and on IRC. I even requested that they attend the weekly Core Dev IRC meeting to discuss it which they didn\u2019t attend.\n>\n> A pull request to add a maintainer isn\u2019t a normal pull request. Generally pull requests contain a lot more lines of code than a single line adding a trusted key. Not merging a pull request for a long period of time can be extremely frustrating for a pull request author especially when maintainers and long term contributors don\u2019t comment on the pull request and the pull request is stuck in \u201crebase hell\u201d. Clearly it is the lesser evil when compared to merging a harmful or bug ridden pull request but poor non-existent communication is not the only way to prevent this. Indeed it creates as many problems as it solves.\n>\n> Another farcical recent(ish) example was the CTV pull request [1] that ultimately led to a contentious soft fork activation attempt that was called off at the last minute. If you look at the comments on the pull request there were 3 individuals (including myself) who NACKed the pull request and I think it is fair to say that none of us would be considered long term contributors to Bitcoin Core. I have criticised Jeremy Rubin multiple times for continuing to pursue a soft fork activation attempt when it was clear it was contentious [3] but if you look at the pull request comments it certainly isn\u2019t clear it was. Maintainers and long term contributors (if they commented at all) were gently enthusiastic (Concept ACKing etc) without ACKing that it was ready to merge. A long term observer of the Core repo would have known that it wasn\u2019t ready to merge or ready to attempt to activate (especially given it was a consensus change) but a casual observer would have only seen Concept ACKs and ACKs with 3 stray NACKs. Many of these casual observers inflated the numbers on the utxos.org site [4] signalling support for a soft fork activation attempt.\n>\n> I set out originally to write about the controls and processes around merges on the default signet (bitcoin-inquisition [5]) but it quickly became obvious to me that if communication around Core merges/non-merges is this weak you can hardly expect it to be any better on bitcoin-inquisition/default signet where there is no real monetary value at stake. I will probably write about bitcoin-inquisition/default signet in a future email as I do think the perception that it is \u201cthe one and only\u201d staging ground for consensus changes is dangerous [6] if the maintainer(s) on that project have the same inclinations as a subset of the Core maintainers.\n>\n> As I stated at the beginning there is an element to this which is not individual(s) specific and an adverse reaction to outright malicious actors external to any of these projects. I do not think any of the current maintainers on Core or bitcoin-inquisition are outright malicious even if a subset of them consistently frustrate me with their lack of transparency and accountability. But this issue isn't going away and I'm sure we'll hear more on this from others in the coming months. To me it is a straight choice of taking transparency and accountability much more seriously or failing that investing more heavily (time and resources) in consensus compatible forks of Core and treating Core like it is a proprietary \"open source\" project where merge decisions are not explained or justified in the open.\n>\n> [0]: https://github.com/bitcoin/bitcoin/pull/25871\n>\n> [1]: https://github.com/bitcoin/bitcoin/pull/21702\n>\n> [2]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020386.html\n>\n> [3]: https://gist.github.com/michaelfolkson/352a503f4f9fc5de89af528d86a1b718\n>\n> [4]: https://utxos.org/signals/\n>\n> [5]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-September/020921.html\n>\n> [6]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-September/020948.html\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at [protonmail.com](http://protonmail.com/)\n> Keybase: michaelfolkson\n> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230507/5230485a/attachment-0001.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2023-05-07T17:35:52",
                "message_text_only": "On 2023-05-06 21:03, Michael Folkson via bitcoin-dev wrote:\n> Essentially my concern is going forward current maintainers will\n> decide which proposed new maintainers to add and which to block.\n\nThis is how a large percentage of organizations are run.  The current \nmembers of a board or other governance group choose who will become a \nnew board member.\n\nOne alternative to self-perpetuating governance is membership voting, \nbut building and maintaining democratic institutions is hard and not a \ngood fit for many types of endeavors---the building of highly technical \nsoftware being one of those cases IMO.\n\nI think the questions we want to ask is whether the current set of \nmaintainers is capable of moving Bitcoin Core in the direction we want \nand what we can do about it if we conclude that they are ill-suited (or \nmalicious).  For the first question, I think that's something everyone \nneeds to answer for themselves, as we may each have different visions \nfor the future of the project.  That said, I note that several \ninitiatives championed by the current maintainers in the IRC meeting you \nmention received overwhelmingly positive support from a significant \nnumber of current contributors, which seems like a healthy sign to me.\n\nFor the second question, I think AJ Towns already answered that quite \nwell (though he was talking about a different project): \nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-April/021578.html\n\nFinally, I don't think this matter warranted a post to this mailing \nlist.  Discussion about internal project decisions, such as who should \nhave merge access and what maintainers should communicate in PRs, belong \nin communication channels dedicated to that project.\n\n-Dave"
            },
            {
                "author": "Michael Folkson",
                "date": "2023-05-08T09:36:27",
                "message_text_only": "Hi David\n\n>> Essentially my concern is going forward current maintainers will decide which proposed new maintainers to add and which to block.\n\n> This is how a large percentage of organizations are run.  The current members of a board or other governance group choose who will become a new board member.\n\nSo long term contributors who aren't maintainers don't get input into the decision? It is starting to seem like the maintainer role is moving from a janitorial one to where maintainers make decisions without discussing those decisions with long term contributors and in some cases even bothering to explain the rationale for those decisions to a broader audience that includes long term contributors. This unfortunately makes the decision on who becomes a maintainer even more important. \n\nDecisions have to be made but I was always under the impression that they would be discussed in open, public IRC meetings with at least other long term contributors present and then decisions would be made based on the views expressed in that meeting. An appointed board or governance group (\"the maintainers\") wasn't how I thought the project was run or should be run.\n\n> Finally, I don't think this matter warranted a post to this mailing list.  Discussion about internal project decisions, such as who should have merge access and what maintainers should communicate in PRs, belong in communication channels dedicated to that project.\n\nI have tried. As I said in previous emails in the Vasil maintainer case I asked fanquake, Gloria repeatedly over a period of 5 months why Vasil was being blocked. They refused to comment. I get called \"rude\" and \"aggressive\" for asking. So I'd rather post my thoughts and observations here than risk being accused of being \"rude\" and \"aggressive\" again for asking questions on this topic on IRC. Especially as I expect they'll be ignored anyway as they were in last week's Core Dev IRC meeting.\n\nUntil the Vasil situation I thought that we had a common sense approach of any long term contributor who had demonstrated they could add value to the project and had shown good temperament could become a maintainer. Blocking Vasil as a maintainer was a red flag for me that we no longer have that. And fanquake, Gloria not being willing to discuss why publicly for 5 months was a second red flag. If that is the precedent for merge decisions anything is possible in the future including in the worst case contentious consensus change merges with no justification and no rationale.\n\nThanks\nMichael\n\n--\nMichael Folkson\nEmail: michaelfolkson at protonmail.com\nGPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n\n\nLearn about Bitcoin: https://www.youtube.com/@portofbitcoin\n\n\n------- Original Message -------\nOn Sunday, May 7th, 2023 at 18:35, David A. Harding <dave at dtrt.org> wrote:\n\n\n> On 2023-05-06 21:03, Michael Folkson via bitcoin-dev wrote:\n> \n> > Essentially my concern is going forward current maintainers will\n> > decide which proposed new maintainers to add and which to block.\n> \n> \n> This is how a large percentage of organizations are run. The current\n> members of a board or other governance group choose who will become a\n> new board member.\n> \n> One alternative to self-perpetuating governance is membership voting,\n> but building and maintaining democratic institutions is hard and not a\n> good fit for many types of endeavors---the building of highly technical\n> software being one of those cases IMO.\n> \n> I think the questions we want to ask is whether the current set of\n> maintainers is capable of moving Bitcoin Core in the direction we want\n> and what we can do about it if we conclude that they are ill-suited (or\n> malicious). For the first question, I think that's something everyone\n> needs to answer for themselves, as we may each have different visions\n> for the future of the project. That said, I note that several\n> initiatives championed by the current maintainers in the IRC meeting you\n> mention received overwhelmingly positive support from a significant\n> number of current contributors, which seems like a healthy sign to me.\n> \n> For the second question, I think AJ Towns already answered that quite\n> well (though he was talking about a different project):\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-April/021578.html\n> \n> Finally, I don't think this matter warranted a post to this mailing\n> list. Discussion about internal project decisions, such as who should\n> have merge access and what maintainers should communicate in PRs, belong\n> in communication channels dedicated to that project.\n> \n> -Dave"
            },
            {
                "author": "Bryan Bishop",
                "date": "2023-05-08T12:03:10",
                "message_text_only": "On Sun, May 7, 2023 at 12:36\u202fPM David A. Harding via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On 2023-05-06 21:03, Michael Folkson via bitcoin-dev wrote:\n> > Essentially my concern is going forward current maintainers will\n> > decide which proposed new maintainers to add and which to block.\n>\n> This is how a large percentage of organizations are run.  The current\n> members of a board or other governance group choose who will become a\n> new board member.\n>\n\nYes but it's unrelated to what Bitcoin Core is-- a volunteer project of\nindependent contributors merging different pull requests or patches. The\ngithub controls are merely because that is how github works. There is also\na secondary issue of people tending to confuse Bitcoin Core with the\nbitcoin protocol in general:\nhttps://blog.lopp.net/who-controls-bitcoin-core/\nhttps://medium.com/@bergealex4/the-tao-of-bitcoin-development-ff093c6155cd\nhttps://bitcoinmagazine.com/culture/a-primer-on-bitcoin-governance-or-why-developers-aren-t-in-charge-of-the-protocol-1473270427\n\n- Bryan\nhttps://twitter.com/kanzure\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/bb17ae25/attachment.html>"
            },
            {
                "author": "Steve Lee",
                "date": "2023-05-10T02:44:59",
                "message_text_only": "Isn't this as simple as anyone (in particular Core project contributors)\ncan express their view in this PR?\nhttps://github.com/bitcoin/bitcoin/pull/27604\n\nOn Mon, May 8, 2023 at 5:03\u202fAM Bryan Bishop via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Sun, May 7, 2023 at 12:36\u202fPM David A. Harding via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> On 2023-05-06 21:03, Michael Folkson via bitcoin-dev wrote:\n>> > Essentially my concern is going forward current maintainers will\n>> > decide which proposed new maintainers to add and which to block.\n>>\n>> This is how a large percentage of organizations are run.  The current\n>> members of a board or other governance group choose who will become a\n>> new board member.\n>>\n>\n> Yes but it's unrelated to what Bitcoin Core is-- a volunteer project of\n> independent contributors merging different pull requests or patches. The\n> github controls are merely because that is how github works. There is also\n> a secondary issue of people tending to confuse Bitcoin Core with the\n> bitcoin protocol in general:\n> https://blog.lopp.net/who-controls-bitcoin-core/\n> https://medium.com/@bergealex4/the-tao-of-bitcoin-development-ff093c6155cd\n>\n> https://bitcoinmagazine.com/culture/a-primer-on-bitcoin-governance-or-why-developers-aren-t-in-charge-of-the-protocol-1473270427\n>\n> - Bryan\n> https://twitter.com/kanzure\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230509/6a00e388/attachment-0001.html>"
            },
            {
                "author": "Michael Folkson",
                "date": "2023-05-10T15:55:25",
                "message_text_only": "Hi Steve\n\n> Isn't this as simple as anyone (in particular Core project contributors) can express their view in this PR?https://github.com/bitcoin/bitcoin/pull/27604\n\nNope. The extent to which the rationale for blocking Vasil as a maintainer applies or doesn't apply to ryanofsky (or future potential maintainers) isn't discussed. From now on the precedent is proposed maintainers can be blocked for unknown and/or potentially inconsistent reasons by the existing maintainers.\n\nThanks\nMichael\n\n--\nMichael Folkson\nEmail: michaelfolkson at [protonmail.com](http://protonmail.com/)\nGPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n\nLearn about Bitcoin: https://www.youtube.com/@portofbitcoin\n\n------- Original Message -------\nOn Wednesday, May 10th, 2023 at 03:44, Steve Lee via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Isn't this as simple as anyone (in particular Core project contributors) can express their view in this PR? https://github.com/bitcoin/bitcoin/pull/27604\n>\n> On Mon, May 8, 2023 at 5:03\u202fAM Bryan Bishop via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> On Sun, May 7, 2023 at 12:36\u202fPM David A. Harding via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> On 2023-05-06 21:03, Michael Folkson via bitcoin-dev wrote:\n>>>> Essentially my concern is going forward current maintainers will\n>>>> decide which proposed new maintainers to add and which to block.\n>>>\n>>> This is how a large percentage of organizations are run. The current\n>>> members of a board or other governance group choose who will become a\n>>> new board member.\n>>\n>> Yes but it's unrelated to what Bitcoin Core is-- a volunteer project of independent contributors merging different pull requests or patches. The github controls are merely because that is how github works. There is also a secondary issue of people tending to confuse Bitcoin Core with the bitcoin protocol in general:\n>> https://blog.lopp.net/who-controls-bitcoin-core/\n>> https://medium.com/@bergealex4/the-tao-of-bitcoin-development-ff093c6155cd\n>> https://bitcoinmagazine.com/culture/a-primer-on-bitcoin-governance-or-why-developers-aren-t-in-charge-of-the-protocol-1473270427\n>>\n>> - Bryan\n>> https://twitter.com/kanzure\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230510/4e8ac883/attachment.html>"
            },
            {
                "author": "Steve Lee",
                "date": "2023-05-10T16:36:54",
                "message_text_only": "Blocking Vasil was discussed on a similar GitHub PR. Whether or not one\nagrees or disagrees, the same process is being used. Anyone can NACK and\ngive a reason for Russ as well.\n\nOn Wed, May 10, 2023 at 8:55\u202fAM Michael Folkson <\nmichaelfolkson at protonmail.com> wrote:\n\n> Hi Steve\n>\n> > Isn't this as simple as anyone (in particular Core project\n> contributors) can express their view in this PR?\n> https://github.com/bitcoin/bitcoin/pull/27604\n>\n> Nope. The extent to which the rationale for blocking Vasil as a maintainer\n> applies or doesn't apply to ryanofsky (or future potential maintainers)\n> isn't discussed. From now on the precedent is proposed maintainers can be\n> blocked for unknown and/or potentially inconsistent reasons by the existing\n> maintainers.\n>\n> Thanks\n> Michael\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n>\n> Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n>\n> ------- Original Message -------\n> On Wednesday, May 10th, 2023 at 03:44, Steve Lee via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Isn't this as simple as anyone (in particular Core project contributors)\n> can express their view in this PR?\n> https://github.com/bitcoin/bitcoin/pull/27604\n>\n> On Mon, May 8, 2023 at 5:03\u202fAM Bryan Bishop via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> On Sun, May 7, 2023 at 12:36\u202fPM David A. Harding via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> On 2023-05-06 21:03, Michael Folkson via bitcoin-dev wrote:\n>>> > Essentially my concern is going forward current maintainers will\n>>> > decide which proposed new maintainers to add and which to block.\n>>>\n>>> This is how a large percentage of organizations are run. The current\n>>> members of a board or other governance group choose who will become a\n>>> new board member.\n>>>\n>>\n>> Yes but it's unrelated to what Bitcoin Core is-- a volunteer project of\n>> independent contributors merging different pull requests or patches. The\n>> github controls are merely because that is how github works. There is also\n>> a secondary issue of people tending to confuse Bitcoin Core with the\n>> bitcoin protocol in general:\n>> https://blog.lopp.net/who-controls-bitcoin-core/\n>> https://medium.com/@bergealex4/the-tao-of-bitcoin-development-ff093c6155cd\n>>\n>> https://bitcoinmagazine.com/culture/a-primer-on-bitcoin-governance-or-why-developers-aren-t-in-charge-of-the-protocol-1473270427\n>>\n>> - Bryan\n>> https://twitter.com/kanzure\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230510/6bf5a3f0/attachment-0001.html>"
            },
            {
                "author": "Michael Folkson",
                "date": "2023-05-10T17:22:37",
                "message_text_only": "> Blocking Vasil was discussed on a similar GitHub PR. Whether or not one agrees or disagrees, the same process is being used. Anyone can NACK and give a reason for Russ as well.\n\nWith respect Steve the process for Vasil was keeping Vasil's PR open for up to 5 months with zero NACKs and two maintainers refusing to engage on why it wasn't being merged or what it needed for it to be merged. Followed by a later justification for blocking it that they've refused to discuss whether it applies to Russ.\n\nThe process for Russ was the maintainers deciding privately there was a need for a maintainer \"who understood our interfaces and modularization efforts well\" and his PR was merged within 2 days.\n\nIf that's the same process to you I don't know what to say. We have different perspectives on what constitutes a decision process.\n\n(I'm sure this is clear but just to reiterate in case it isn't none of this is a criticism of Russ.)\n\nThanks\nMichael\n\n--\nMichael Folkson\nEmail: michaelfolkson at [protonmail.com](http://protonmail.com/)\nGPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n\nLearn about Bitcoin: https://www.youtube.com/@portofbitcoin\n\n------- Original Message -------\nOn Wednesday, May 10th, 2023 at 17:36, Steve Lee <steven.j.lee at gmail.com> wrote:\n\n> Blocking Vasil was discussed on a similar GitHub PR. Whether or not one agrees or disagrees, the same process is being used. Anyone can NACK and give a reason for Russ as well.\n>\n> On Wed, May 10, 2023 at 8:55\u202fAM Michael Folkson <michaelfolkson at protonmail.com> wrote:\n>\n>> Hi Steve\n>>\n>>> Isn't this as simple as anyone (in particular Core project contributors) can express their view in this PR?https://github.com/bitcoin/bitcoin/pull/27604\n>>\n>> Nope. The extent to which the rationale for blocking Vasil as a maintainer applies or doesn't apply to ryanofsky (or future potential maintainers) isn't discussed. From now on the precedent is proposed maintainers can be blocked for unknown and/or potentially inconsistent reasons by the existing maintainers.\n>>\n>> Thanks\n>> Michael\n>>\n>> --\n>> Michael Folkson\n>> Email: michaelfolkson at [protonmail.com](http://protonmail.com/)\n>> GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n>>\n>> Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n>>\n>> ------- Original Message -------\n>> On Wednesday, May 10th, 2023 at 03:44, Steve Lee via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Isn't this as simple as anyone (in particular Core project contributors) can express their view in this PR? https://github.com/bitcoin/bitcoin/pull/27604\n>>>\n>>> On Mon, May 8, 2023 at 5:03\u202fAM Bryan Bishop via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> On Sun, May 7, 2023 at 12:36\u202fPM David A. Harding via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>\n>>>>> On 2023-05-06 21:03, Michael Folkson via bitcoin-dev wrote:\n>>>>>> Essentially my concern is going forward current maintainers will\n>>>>>> decide which proposed new maintainers to add and which to block.\n>>>>>\n>>>>> This is how a large percentage of organizations are run. The current\n>>>>> members of a board or other governance group choose who will become a\n>>>>> new board member.\n>>>>\n>>>> Yes but it's unrelated to what Bitcoin Core is-- a volunteer project of independent contributors merging different pull requests or patches. The github controls are merely because that is how github works. There is also a secondary issue of people tending to confuse Bitcoin Core with the bitcoin protocol in general:\n>>>> https://blog.lopp.net/who-controls-bitcoin-core/\n>>>> https://medium.com/@bergealex4/the-tao-of-bitcoin-development-ff093c6155cd\n>>>> https://bitcoinmagazine.com/culture/a-primer-on-bitcoin-governance-or-why-developers-aren-t-in-charge-of-the-protocol-1473270427\n>>>>\n>>>> - Bryan\n>>>> https://twitter.com/kanzure\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230510/02964e68/attachment-0001.html>"
            },
            {
                "author": "Steve Lee",
                "date": "2023-05-10T18:29:56",
                "message_text_only": "I see it was merged since my original post. I agree that is a very short\nwindow of time. In particular, if a long-time Core contributor wasn't able\nto attend the in-person meeting or last week's IRC meeting, they'd have had\nto really been on the ball.\n\nOn Wed, May 10, 2023 at 10:22\u202fAM Michael Folkson <\nmichaelfolkson at protonmail.com> wrote:\n\n> > Blocking Vasil was discussed on a similar GitHub PR. Whether or not one\n> agrees or disagrees, the same process is being used. Anyone can NACK and\n> give a reason for Russ as well.\n>\n> With respect Steve the process for Vasil was keeping Vasil's PR open for\n> up to 5 months with zero NACKs and two maintainers refusing to engage on\n> why it wasn't being merged or what it needed for it to be merged. Followed\n> by a later justification for blocking it that they've refused to discuss\n> whether it applies to Russ.\n>\n> The process for Russ was the maintainers deciding privately there was a\n> need for a maintainer \"who understood our interfaces and modularization\n> efforts well\" and his PR was merged within 2 days.\n>\n> If that's the same process to you I don't know what to say. We have\n> different perspectives on what constitutes a decision process.\n>\n> (I'm sure this is clear but just to reiterate in case it isn't none of\n> this is a criticism of Russ.)\n>\n> Thanks\n> Michael\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n>\n> Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n>\n> ------- Original Message -------\n> On Wednesday, May 10th, 2023 at 17:36, Steve Lee <steven.j.lee at gmail.com>\n> wrote:\n>\n> Blocking Vasil was discussed on a similar GitHub PR. Whether or not one\n> agrees or disagrees, the same process is being used. Anyone can NACK and\n> give a reason for Russ as well.\n>\n> On Wed, May 10, 2023 at 8:55\u202fAM Michael Folkson <\n> michaelfolkson at protonmail.com> wrote:\n>\n>> Hi Steve\n>>\n>> > Isn't this as simple as anyone (in particular Core project\n>> contributors) can express their view in this PR?\n>> https://github.com/bitcoin/bitcoin/pull/27604\n>>\n>> Nope. The extent to which the rationale for blocking Vasil as a\n>> maintainer applies or doesn't apply to ryanofsky (or future potential\n>> maintainers) isn't discussed. From now on the precedent is proposed\n>> maintainers can be blocked for unknown and/or potentially inconsistent\n>> reasons by the existing maintainers.\n>>\n>> Thanks\n>> Michael\n>>\n>> --\n>> Michael Folkson\n>> Email: michaelfolkson at protonmail.com\n>> GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n>>\n>> Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n>>\n>> ------- Original Message -------\n>> On Wednesday, May 10th, 2023 at 03:44, Steve Lee via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> Isn't this as simple as anyone (in particular Core project contributors)\n>> can express their view in this PR?\n>> https://github.com/bitcoin/bitcoin/pull/27604\n>>\n>> On Mon, May 8, 2023 at 5:03\u202fAM Bryan Bishop via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> On Sun, May 7, 2023 at 12:36\u202fPM David A. Harding via bitcoin-dev <\n>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> On 2023-05-06 21:03, Michael Folkson via bitcoin-dev wrote:\n>>>> > Essentially my concern is going forward current maintainers will\n>>>> > decide which proposed new maintainers to add and which to block.\n>>>>\n>>>> This is how a large percentage of organizations are run. The current\n>>>> members of a board or other governance group choose who will become a\n>>>> new board member.\n>>>>\n>>>\n>>> Yes but it's unrelated to what Bitcoin Core is-- a volunteer project of\n>>> independent contributors merging different pull requests or patches. The\n>>> github controls are merely because that is how github works. There is also\n>>> a secondary issue of people tending to confuse Bitcoin Core with the\n>>> bitcoin protocol in general:\n>>> https://blog.lopp.net/who-controls-bitcoin-core/\n>>>\n>>> https://medium.com/@bergealex4/the-tao-of-bitcoin-development-ff093c6155cd\n>>>\n>>> https://bitcoinmagazine.com/culture/a-primer-on-bitcoin-governance-or-why-developers-aren-t-in-charge-of-the-protocol-1473270427\n>>>\n>>> - Bryan\n>>> https://twitter.com/kanzure\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230510/b5e0c073/attachment-0001.html>"
            },
            {
                "author": "Andrew Chow",
                "date": "2023-05-10T21:24:52",
                "message_text_only": "On 05/07/23 03:03 AM, Michael Folkson via bitcoin-dev wrote:\n\n> The decision process for adding a new maintainer was according to the IRC meeting that the maintainers decided privately there was a need for a maintainer \u201cwho understood our interfaces and modularization efforts well\u201d and that ryanofsky was a \u201cgood fit for that\u201d. I don\u2019t know whether this was decided in a private IRC channel or was decided at the recent in person Core Dev meeting. Regardless, many have had no input into the discussion on what kind of maintainer the project needs going forward and it seems the maintainers do not want to discuss that aspect of the decision.\n\nSince the project began, the decision to seek out and then add a maintainer has always been made by existing maintainers. When the maintainers feel that there is a need for additional maintainers, they may have an open call for volunteers, or may have a candidate already in mind and suggest that specific person for maintainership. Contributors generally are not consulted in the decision to seek a new maintainer as they would not know whether there are things that are being overlooked or that there is maintainership load that needs to be distributed. Even so, it wouldn't be appropriate to add a maintainer if many contributors disagreed with it, just as with any other PR.\n\nWe can take a look at how previous maintainers were added to see how this has played out in the past. I think our modern concept of maintainers with nominal scopes began in 2015 with Jonas Schnelli. Both Jonas Schnelli and Marco Falke were simply announced by Wladimir. There was no public discussion, and some IRC logs refer to private emails between the them and the current maintainers at that time. After that, meshcollider was added as a maintainer after a public \"call for maintainers\" where a recurring topic for a while was finding a maintainer for the wallet. He had volunteered to do it by contacting Wladimir privately before it was discussed during an IRC meeting and then on Github. Fanquake was added as a maintainer during a CoreDev event in Amsterdam during a discussion initiated and led by the maintainers. This was also \"private\" insofar as the discussion was limited to those in attendance, although there was some opportunity for public discussion in the PR opened on Github. For myself, it was also initially private as I messaged Wladimir to volunteer for it after meshcollider stepped down. There was some discussion on IRC and on Github, but it was also obvious that many already expected me to be the wallet maintainer after meshcollider. Hebasto was added with basically no fanfare or discussion - the only mention I can find is the PR itself. My understanding is that the maintainers asked him he wanted to do it before the PR was opened. Glozow was nominated to be a maintainer by some of the current maintainers, and her nomination was really the first time that there was significant public discussion about it.\n\nOf the past 7 maintainer additions, 5 were nominations/announcements from the current maintainers, one was volunteering following an actual \"call for maintainer\", and one was an obvious successor. It's obvious and common sense that the maintainers decide when they need help shouldering the load, and then find somebody to help them. There was and always will be some level of private communication prior to any public announcement of the nomination or volunteering of a maintainer. It doesn't make sense to blindside somebody with a nomination without talking to them beforehand. The fact that most of these were non-controversial speaks to how well the maintainers were considering their nominations before publicly announcing them.\n\nIt's also clear that we have been moving towards more open discussion about maintainership and who should be maintainers. The process is fundamentally more public than it was previously. We now have public discussion with contributors about the merits of a person, even if that results in said person not becoming a maintainer. Over time, there's been more public participation in the PRs and on IRC meetings when maintainer nominations are brought up. We have nominations as topics during meetings now when they occur. The PRs to add keys are left open for longer to get more discussion.\n\nUltimately, if you disagree with how the project operates, then you are free to leave and start your own fork that is run in a way that you think is appropriate. This is open source software, no one is beholden to you, and no one is required to do anything.\n\n***\n\nSince you are intent on discussing and re-litigating the decision about Vasil, I will agree that we (the maintainers) could have done a better job of communicating. However we stand by the decision that was made in the end, and we did have a chat with him about it during CoreDev.\n\nIt really boils down to three things: 1) we did not ask for a P2P maintainer, 2) some of those who have reviewed Vasil's work expressed discomfort with him being a maintainer, and 3) some contributors and maintainers were uncomfortable with his responses about how he would merge things. You repeatedly insist that it's only the current maintainers who blocked Vasil, but that is not the case. There were concerns brought up by other contributors that contributed to the decision to ultimately NACK his nomination.\n\n> One of the justifications for blocking Vasil Dimov as a new maintainer despite many initial ACKs from maintainers (including Andrew Chow) and long term contributors was according to Andrew [2]:\n\nTo be honest, my initial ACK was given without knowing enough information. It was given when he was mostly a name that showed up in my notification emails, and his work had seemed to be fine with me. At that time, I did not think we had a need for a P2P maintainer, but I also did not think that having one would be harmful. However I later spoke to a few others privately who were more familiar with Vasil's work and they had told me that they were not comfortable with Vasil being P2P maintainer.\n\n> \u201cMaintainers inherently need to look at the things that everyone else has already looked at, if only to give it a final once over before merging (but hopefully, an actual review, not just looking it over).\u201d\n>\n> I follow the Bitcoin Core repo pretty closely and I haven\u2019t seen ryanofsky do this any more than Vasil does. This is not a criticism of ryanofsky, just as I wouldn\u2019t use it as a criticism for Vasil. It would get pretty annoying if everyone who wasn\u2019t a maintainer posted an ACK once many long term contributors had already ACKed to display supposed \u201cdesired maintainer traits\u201d. Especially if you are essentially just ACKing that others have done the work to review the PR and you just want to get your ACK on it to increase your ACK count without doing a fraction of what previous reviewers have done.\n\nThis opinion was formed not from observing his behavior towards ACK'ing, but rather from his responses to questions about reviewing, in addition to thoughts shared by other contributors.\n\nFrom having received plenty of reviews from ryanofsky, I can certainly say that his reviews are in depth. He has pointed out subtle bugs, asks questions about very low level details, and has well reasoned critiques and discussions about design decisions. His reviews are high quality, and he's not afraid of being the first person to ACK a pr, the last person to ACK it, or the person to prevent one from being merged even when it already has a few ACKs. We also had a separate discussion with ryanofsky about his approaches to reviewing and merging.\n\n> \u201cI also want to mention that the people who have become maintainers in the past have had this kind of maintainer attitude towards review prior to becoming a maintainer\u201d\n>\n> Assuming ryanofsky hasn\u2019t had this maintainer attitude in the past (again not a criticism from me at least) does this mean this was a reason to block Vasil but not a reason to block ryanofsky? That seems inconsistent to me.\n\nI don't know why you assume the ryanofsky hasn't had this maintainer attitude? Your claim of inconsistency stems from this assumption that ryanofsky doesn't have a maintainer attitude, but I would argue that he does, as I mentioned above. The idea of adding him as a maintainer has been floated around before, although never really seriously proposed until now, AFAIK.\n\n> When you\u2019re anointed you don\u2019t need to meet requirements but when you\u2019re blocked these requirements will be used to block your addition as a new maintainer?\n\nIt seems obvious to me that when the current maintainers approach and nominate a contributor to be a maintainer that that person already meets these requirements. I don't know why you would assume bad faith in that someone who isn't qualified would be nominated by the current maintainers. It's quite frustrating that you seem to just jump straight to the negative conclusion rather than considering that there might be actual reasons based on the merits of the person.\n\n> On a more positive note there does seem to be more energy and momentum for collaboration and open communication on the project since I discussed communication in a previous post [3]. Hopefully this will continue. It doesn\u2019t address my concerns on maintainers and ultimately merge decisions but it definitely seems to me to be a step in a positive direction for the project.\n\nDon't take credit for what you didn't do. The group-wide effort to move towards public discussion again is the result of a discussion that was had at CoreDev. Many cited your behavior as a primary reason to stop discussing things publicly, with things such as dragging project meta discussions onto the mailing list and twitter. These have invited abuse towards maintainers and contributors, which in turn makes them takes those discussions to more private settings. People feel like they're getting sealioned by you (and a few others) when they post publicly, and so they have stopped doing so.\n\nAndrew\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230510/8e187ee4/attachment-0001.html>"
            },
            {
                "author": "Michael Folkson",
                "date": "2023-05-11T12:34:57",
                "message_text_only": "Thanks for this Andrew.\n\n> However I later spoke to a few others privately who were more familiar with Vasil's work and they had told me that they were not comfortable with Vasil being P2P maintainer.\n\nSome individuals who will stay anonymous and who were more familiar with Vasil's work than you weren't happy with the standard of his work. Ok I hope they have communicated this to him directly and provided specific examples where he can improve.\n\n> From having received plenty of reviews from ryanofsky, I can certainly say that his reviews are in depth. He has pointed out subtle bugs, asks questions about very low level details, and has well reasoned critiques and discussions about design decisions.\n\nAnd Vasil didn't provide as in depth reviews when compared to ryanofsky. Again I hope they have communicated this to him directly.\n\n> Many cited your behavior as a primary reason to stop discussing things publicly, with things such as dragging project meta discussions onto the mailing list and twitter. These have invited abuse towards maintainers and contributors, which in turn makes them takes those discussions to more private settings. People feel like they're getting sealioned by you (and a few others) when they post publicly, and so they have stopped doing so.\n\nI have tried over and over again on IRC and on GitHub and I've been ignored. To claim discussions on the bitcoin-dev mailing list invite abuse is just laughable. It is public just like IRC logs and GitHub. If people don't like discussing in public we should give up the pretense and put on the Core README that all important discussions on decision making are done in private and are invite only.\n\n> People feel like they're getting sealioned by you (and a few others) when they post publicly, and so they have stopped doing so.\n\nThis is the \"rude\" and \"aggressive\" accusation, right. Someone asks questions that maintainers don't want to answer, maintainers accuse them of being \"rude\" and \"aggressive\" and then use that as a justification for not answering those questions in the first place. It is a pretty effective strategy. Don't even need to provide examples, just label them and then you can ignore them.\n\n> Since you are intent on discussing and re-litigating the decision about Vasil, I will agree that we (the maintainers) could have done a better job of communicating. However we stand by the decision that was made in the end, and we did have a chat with him about it during CoreDev.\n\nThanks for at least admitting this on the communication point. If Vasil has been spoken to and is happy with the situation then the situation is much better than I feared. You might think this is re-litigating but the addition, rejection and removal of maintainers is among the most important decisions you can make as a maintainer and perhaps only dwarfed by the merging of consensus changes that can cause chain splits. If anything should be \"re-litigated\" it should be this.\n\nThanks\nMichael\n\n--\nMichael Folkson\nEmail: michaelfolkson at [protonmail.com](http://protonmail.com/)\nGPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n\nLearn about Bitcoin: https://www.youtube.com/@portofbitcoin\n\n------- Original Message -------\nOn Wednesday, May 10th, 2023 at 22:24, Andrew Chow via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On 05/07/23 03:03 AM, Michael Folkson via bitcoin-dev wrote:\n>\n>> The decision process for adding a new maintainer was according to the IRC meeting that the maintainers decided privately there was a need for a maintainer \u201cwho understood our interfaces and modularization efforts well\u201d and that ryanofsky was a \u201cgood fit for that\u201d. I don\u2019t know whether this was decided in a private IRC channel or was decided at the recent in person Core Dev meeting. Regardless, many have had no input into the discussion on what kind of maintainer the project needs going forward and it seems the maintainers do not want to discuss that aspect of the decision.\n>\n> Since the project began, the decision to seek out and then add a maintainer has always been made by existing maintainers. When the maintainers feel that there is a need for additional maintainers, they may have an open call for volunteers, or may have a candidate already in mind and suggest that specific person for maintainership. Contributors generally are not consulted in the decision to seek a new maintainer as they would not know whether there are things that are being overlooked or that there is maintainership load that needs to be distributed. Even so, it wouldn't be appropriate to add a maintainer if many contributors disagreed with it, just as with any other PR.\n>\n> We can take a look at how previous maintainers were added to see how this has played out in the past. I think our modern concept of maintainers with nominal scopes began in 2015 with Jonas Schnelli. Both Jonas Schnelli and Marco Falke were simply announced by Wladimir. There was no public discussion, and some IRC logs refer to private emails between the them and the current maintainers at that time. After that, meshcollider was added as a maintainer after a public \"call for maintainers\" where a recurring topic for a while was finding a maintainer for the wallet. He had volunteered to do it by contacting Wladimir privately before it was discussed during an IRC meeting and then on Github. Fanquake was added as a maintainer during a CoreDev event in Amsterdam during a discussion initiated and led by the maintainers. This was also \"private\" insofar as the discussion was limited to those in attendance, although there was some opportunity for public discussion in the PR opened on Github. For myself, it was also initially private as I messaged Wladimir to volunteer for it after meshcollider stepped down. There was some discussion on IRC and on Github, but it was also obvious that many already expected me to be the wallet maintainer after meshcollider. Hebasto was added with basically no fanfare or discussion - the only mention I can find is the PR itself. My understanding is that the maintainers asked him he wanted to do it before the PR was opened. Glozow was nominated to be a maintainer by some of the current maintainers, and her nomination was really the first time that there was significant public discussion about it.\n>\n> Of the past 7 maintainer additions, 5 were nominations/announcements from the current maintainers, one was volunteering following an actual \"call for maintainer\", and one was an obvious successor. It's obvious and common sense that the maintainers decide when they need help shouldering the load, and then find somebody to help them. There was and always will be some level of private communication prior to any public announcement of the nomination or volunteering of a maintainer. It doesn't make sense to blindside somebody with a nomination without talking to them beforehand. The fact that most of these were non-controversial speaks to how well the maintainers were considering their nominations before publicly announcing them.\n>\n> It's also clear that we have been moving towards more open discussion about maintainership and who should be maintainers. The process is fundamentally more public than it was previously. We now have public discussion with contributors about the merits of a person, even if that results in said person not becoming a maintainer. Over time, there's been more public participation in the PRs and on IRC meetings when maintainer nominations are brought up. We have nominations as topics during meetings now when they occur. The PRs to add keys are left open for longer to get more discussion.\n>\n> Ultimately, if you disagree with how the project operates, then you are free to leave and start your own fork that is run in a way that you think is appropriate. This is open source software, no one is beholden to you, and no one is required to do anything.\n>\n> ***\n>\n> Since you are intent on discussing and re-litigating the decision about Vasil, I will agree that we (the maintainers) could have done a better job of communicating. However we stand by the decision that was made in the end, and we did have a chat with him about it during CoreDev.\n>\n> It really boils down to three things: 1) we did not ask for a P2P maintainer, 2) some of those who have reviewed Vasil's work expressed discomfort with him being a maintainer, and 3) some contributors and maintainers were uncomfortable with his responses about how he would merge things. You repeatedly insist that it's only the current maintainers who blocked Vasil, but that is not the case. There were concerns brought up by other contributors that contributed to the decision to ultimately NACK his nomination.\n>\n>> One of the justifications for blocking Vasil Dimov as a new maintainer despite many initial ACKs from maintainers (including Andrew Chow) and long term contributors was according to Andrew [2]:\n>\n> To be honest, my initial ACK was given without knowing enough information. It was given when he was mostly a name that showed up in my notification emails, and his work had seemed to be fine with me. At that time, I did not think we had a need for a P2P maintainer, but I also did not think that having one would be harmful. However I later spoke to a few others privately who were more familiar with Vasil's work and they had told me that they were not comfortable with Vasil being P2P maintainer.\n>\n>> \u201cMaintainers inherently need to look at the things that everyone else has already looked at, if only to give it a final once over before merging (but hopefully, an actual review, not just looking it over).\u201d\n>>\n>> I follow the Bitcoin Core repo pretty closely and I haven\u2019t seen ryanofsky do this any more than Vasil does. This is not a criticism of ryanofsky, just as I wouldn\u2019t use it as a criticism for Vasil. It would get pretty annoying if everyone who wasn\u2019t a maintainer posted an ACK once many long term contributors had already ACKed to display supposed \u201cdesired maintainer traits\u201d. Especially if you are essentially just ACKing that others have done the work to review the PR and you just want to get your ACK on it to increase your ACK count without doing a fraction of what previous reviewers have done.\n>\n> This opinion was formed not from observing his behavior towards ACK'ing, but rather from his responses to questions about reviewing, in addition to thoughts shared by other contributors.\n>\n> From having received plenty of reviews from ryanofsky, I can certainly say that his reviews are in depth. He has pointed out subtle bugs, asks questions about very low level details, and has well reasoned critiques and discussions about design decisions. His reviews are high quality, and he's not afraid of being the first person to ACK a pr, the last person to ACK it, or the person to prevent one from being merged even when it already has a few ACKs. We also had a separate discussion with ryanofsky about his approaches to reviewing and merging.\n>\n>> \u201cI also want to mention that the people who have become maintainers in the past have had this kind of maintainer attitude towards review prior to becoming a maintainer\u201d\n>>\n>> Assuming ryanofsky hasn\u2019t had this maintainer attitude in the past (again not a criticism from me at least) does this mean this was a reason to block Vasil but not a reason to block ryanofsky? That seems inconsistent to me.\n>\n> I don't know why you assume the ryanofsky hasn't had this maintainer attitude? Your claim of inconsistency stems from this assumption that ryanofsky doesn't have a maintainer attitude, but I would argue that he does, as I mentioned above. The idea of adding him as a maintainer has been floated around before, although never really seriously proposed until now, AFAIK.\n>\n>> When you\u2019re anointed you don\u2019t need to meet requirements but when you\u2019re blocked these requirements will be used to block your addition as a new maintainer?\n>\n> It seems obvious to me that when the current maintainers approach and nominate a contributor to be a maintainer that that person already meets these requirements. I don't know why you would assume bad faith in that someone who isn't qualified would be nominated by the current maintainers. It's quite frustrating that you seem to just jump straight to the negative conclusion rather than considering that there might be actual reasons based on the merits of the person.\n>\n>> On a more positive note there does seem to be more energy and momentum for collaboration and open communication on the project since I discussed communication in a previous post [3]. Hopefully this will continue. It doesn\u2019t address my concerns on maintainers and ultimately merge decisions but it definitely seems to me to be a step in a positive direction for the project.\n>\n> Don't take credit for what you didn't do. The group-wide effort to move towards public discussion again is the result of a discussion that was had at CoreDev. Many cited your behavior as a primary reason to stop discussing things publicly, with things such as dragging project meta discussions onto the mailing list and twitter. These have invited abuse towards maintainers and contributors, which in turn makes them takes those discussions to more private settings. People feel like they're getting sealioned by you (and a few others) when they post publicly, and so they have stopped doing so.\n>\n> Andrew\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230511/54ab6d65/attachment-0001.html>"
            },
            {
                "author": "alicexbt",
                "date": "2023-05-11T16:49:36",
                "message_text_only": "Hi Andrew,\n\n> We can take a look at how previous maintainers were added to see how this has played out in the past.\n\nCan we learn something from past?\n\nBitcoin's initial release was in 2009 with one developer and few others experimenting with it. It is considered decentralized in 2023 however we have 99% of nodes using bitcoin core, 5 developers deciding what's merged or not and this includes some trying to implement their ideas without soft fork using mempool policies.\n\nWe need better process to add maintainers. I am disappointed with the way last last pull request was merged. It says more about maintainers and leader Michael Ford. If you are so scared about opinions on a pull request why not just make him maintainer without pull request?\n\nMaybe you will understand this if your PR to add maintainer was kept open for 4 months.\n\n/dev/fd0\nfloppy disk\n\nSent with [Proton Mail](https://proton.me/) secure email.\n\n------- Original Message -------\nOn Thursday, May 11th, 2023 at 2:54 AM, Andrew Chow via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On 05/07/23 03:03 AM, Michael Folkson via bitcoin-dev wrote:\n>\n>> The decision process for adding a new maintainer was according to the IRC meeting that the maintainers decided privately there was a need for a maintainer \u201cwho understood our interfaces and modularization efforts well\u201d and that ryanofsky was a \u201cgood fit for that\u201d. I don\u2019t know whether this was decided in a private IRC channel or was decided at the recent in person Core Dev meeting. Regardless, many have had no input into the discussion on what kind of maintainer the project needs going forward and it seems the maintainers do not want to discuss that aspect of the decision.\n>\n> Since the project began, the decision to seek out and then add a maintainer has always been made by existing maintainers. When the maintainers feel that there is a need for additional maintainers, they may have an open call for volunteers, or may have a candidate already in mind and suggest that specific person for maintainership. Contributors generally are not consulted in the decision to seek a new maintainer as they would not know whether there are things that are being overlooked or that there is maintainership load that needs to be distributed. Even so, it wouldn't be appropriate to add a maintainer if many contributors disagreed with it, just as with any other PR.\n>\n> We can take a look at how previous maintainers were added to see how this has played out in the past. I think our modern concept of maintainers with nominal scopes began in 2015 with Jonas Schnelli. Both Jonas Schnelli and Marco Falke were simply announced by Wladimir. There was no public discussion, and some IRC logs refer to private emails between the them and the current maintainers at that time. After that, meshcollider was added as a maintainer after a public \"call for maintainers\" where a recurring topic for a while was finding a maintainer for the wallet. He had volunteered to do it by contacting Wladimir privately before it was discussed during an IRC meeting and then on Github. Fanquake was added as a maintainer during a CoreDev event in Amsterdam during a discussion initiated and led by the maintainers. This was also \"private\" insofar as the discussion was limited to those in attendance, although there was some opportunity for public discussion in the PR opened on Github. For myself, it was also initially private as I messaged Wladimir to volunteer for it after meshcollider stepped down. There was some discussion on IRC and on Github, but it was also obvious that many already expected me to be the wallet maintainer after meshcollider. Hebasto was added with basically no fanfare or discussion - the only mention I can find is the PR itself. My understanding is that the maintainers asked him he wanted to do it before the PR was opened. Glozow was nominated to be a maintainer by some of the current maintainers, and her nomination was really the first time that there was significant public discussion about it.\n>\n> Of the past 7 maintainer additions, 5 were nominations/announcements from the current maintainers, one was volunteering following an actual \"call for maintainer\", and one was an obvious successor. It's obvious and common sense that the maintainers decide when they need help shouldering the load, and then find somebody to help them. There was and always will be some level of private communication prior to any public announcement of the nomination or volunteering of a maintainer. It doesn't make sense to blindside somebody with a nomination without talking to them beforehand. The fact that most of these were non-controversial speaks to how well the maintainers were considering their nominations before publicly announcing them.\n>\n> It's also clear that we have been moving towards more open discussion about maintainership and who should be maintainers. The process is fundamentally more public than it was previously. We now have public discussion with contributors about the merits of a person, even if that results in said person not becoming a maintainer. Over time, there's been more public participation in the PRs and on IRC meetings when maintainer nominations are brought up. We have nominations as topics during meetings now when they occur. The PRs to add keys are left open for longer to get more discussion.\n>\n> Ultimately, if you disagree with how the project operates, then you are free to leave and start your own fork that is run in a way that you think is appropriate. This is open source software, no one is beholden to you, and no one is required to do anything.\n>\n> ***\n>\n> Since you are intent on discussing and re-litigating the decision about Vasil, I will agree that we (the maintainers) could have done a better job of communicating. However we stand by the decision that was made in the end, and we did have a chat with him about it during CoreDev.\n>\n> It really boils down to three things: 1) we did not ask for a P2P maintainer, 2) some of those who have reviewed Vasil's work expressed discomfort with him being a maintainer, and 3) some contributors and maintainers were uncomfortable with his responses about how he would merge things. You repeatedly insist that it's only the current maintainers who blocked Vasil, but that is not the case. There were concerns brought up by other contributors that contributed to the decision to ultimately NACK his nomination.\n>\n>> One of the justifications for blocking Vasil Dimov as a new maintainer despite many initial ACKs from maintainers (including Andrew Chow) and long term contributors was according to Andrew [2]:\n>\n> To be honest, my initial ACK was given without knowing enough information. It was given when he was mostly a name that showed up in my notification emails, and his work had seemed to be fine with me. At that time, I did not think we had a need for a P2P maintainer, but I also did not think that having one would be harmful. However I later spoke to a few others privately who were more familiar with Vasil's work and they had told me that they were not comfortable with Vasil being P2P maintainer.\n>\n>> \u201cMaintainers inherently need to look at the things that everyone else has already looked at, if only to give it a final once over before merging (but hopefully, an actual review, not just looking it over).\u201d\n>>\n>> I follow the Bitcoin Core repo pretty closely and I haven\u2019t seen ryanofsky do this any more than Vasil does. This is not a criticism of ryanofsky, just as I wouldn\u2019t use it as a criticism for Vasil. It would get pretty annoying if everyone who wasn\u2019t a maintainer posted an ACK once many long term contributors had already ACKed to display supposed \u201cdesired maintainer traits\u201d. Especially if you are essentially just ACKing that others have done the work to review the PR and you just want to get your ACK on it to increase your ACK count without doing a fraction of what previous reviewers have done.\n>\n> This opinion was formed not from observing his behavior towards ACK'ing, but rather from his responses to questions about reviewing, in addition to thoughts shared by other contributors.\n>\n> From having received plenty of reviews from ryanofsky, I can certainly say that his reviews are in depth. He has pointed out subtle bugs, asks questions about very low level details, and has well reasoned critiques and discussions about design decisions. His reviews are high quality, and he's not afraid of being the first person to ACK a pr, the last person to ACK it, or the person to prevent one from being merged even when it already has a few ACKs. We also had a separate discussion with ryanofsky about his approaches to reviewing and merging.\n>\n>> \u201cI also want to mention that the people who have become maintainers in the past have had this kind of maintainer attitude towards review prior to becoming a maintainer\u201d\n>>\n>> Assuming ryanofsky hasn\u2019t had this maintainer attitude in the past (again not a criticism from me at least) does this mean this was a reason to block Vasil but not a reason to block ryanofsky? That seems inconsistent to me.\n>\n> I don't know why you assume the ryanofsky hasn't had this maintainer attitude? Your claim of inconsistency stems from this assumption that ryanofsky doesn't have a maintainer attitude, but I would argue that he does, as I mentioned above. The idea of adding him as a maintainer has been floated around before, although never really seriously proposed until now, AFAIK.\n>\n>> When you\u2019re anointed you don\u2019t need to meet requirements but when you\u2019re blocked these requirements will be used to block your addition as a new maintainer?\n>\n> It seems obvious to me that when the current maintainers approach and nominate a contributor to be a maintainer that that person already meets these requirements. I don't know why you would assume bad faith in that someone who isn't qualified would be nominated by the current maintainers. It's quite frustrating that you seem to just jump straight to the negative conclusion rather than considering that there might be actual reasons based on the merits of the person.\n>\n>> On a more positive note there does seem to be more energy and momentum for collaboration and open communication on the project since I discussed communication in a previous post [3]. Hopefully this will continue. It doesn\u2019t address my concerns on maintainers and ultimately merge decisions but it definitely seems to me to be a step in a positive direction for the project.\n>\n> Don't take credit for what you didn't do. The group-wide effort to move towards public discussion again is the result of a discussion that was had at CoreDev. Many cited your behavior as a primary reason to stop discussing things publicly, with things such as dragging project meta discussions onto the mailing list and twitter. These have invited abuse towards maintainers and contributors, which in turn makes them takes those discussions to more private settings. People feel like they're getting sealioned by you (and a few others) when they post publicly, and so they have stopped doing so.\n>\n> Andrew\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230511/77f1f78a/attachment-0001.html>"
            },
            {
                "author": "Steve Lee",
                "date": "2023-05-11T18:04:08",
                "message_text_only": "I don't see any reason to be antagonistic in your responses.\n\nOne piece of advice I'd offer to you and Michael is to consider whether\nyour responses are effective. To persuade other people it takes more than\nmaking good points or being right, but you need to find a communication\nstyle and communication path that is effective. My observation is that your\nstyles need reflection.\n\n\nOn Thu, May 11, 2023 at 10:15\u202fAM alicexbt via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Andrew,\n>\n> We can take a look at how previous maintainers were added to see how this\n> has played out in the past.\n>\n>\n> Can we learn something from past?\n>\n> Bitcoin's initial release was in 2009 with one developer and few others\n> experimenting with it. It is considered decentralized in 2023 however we\n> have 99% of nodes using bitcoin core, 5 developers deciding what's merged\n> or not and this includes some trying to implement their ideas without soft\n> fork using mempool policies.\n>\n> We need better process to add maintainers. I am disappointed with the way\n> last last pull request was merged. It says more about maintainers and\n> leader Michael Ford. If you are so scared about opinions on a pull request\n> why not just make him maintainer without pull request?\n>\n> Maybe you will understand this if your PR to add maintainer was kept open\n> for 4 months.\n>\n> /dev/fd0\n> floppy disk\n>\n>\n> Sent with Proton Mail <https://proton.me/> secure email.\n>\n> ------- Original Message -------\n> On Thursday, May 11th, 2023 at 2:54 AM, Andrew Chow via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> On 05/07/23 03:03 AM, Michael Folkson via bitcoin-dev wrote:\n>\n>\n> The decision process for adding a new maintainer was according to the IRC\n> meeting that the maintainers decided privately there was a need for a\n> maintainer \u201cwho understood our interfaces and modularization efforts well\u201d\n> and that ryanofsky was a \u201cgood fit for that\u201d. I don\u2019t know whether this was\n> decided in a private IRC channel or was decided at the recent in person\n> Core Dev meeting. Regardless, many have had no input into the discussion on\n> what kind of maintainer the project needs going forward and it seems the\n> maintainers do not want to discuss that aspect of the decision.\n>\n> Since the project began, the decision to seek out and then add a\n> maintainer has always been made by existing maintainers. When the\n> maintainers feel that there is a need for additional maintainers, they may\n> have an open call for volunteers, or may have a candidate already in mind\n> and suggest that specific person for maintainership. Contributors generally\n> are not consulted in the decision to seek a new maintainer as they would\n> not know whether there are things that are being overlooked or that there\n> is maintainership load that needs to be distributed. Even so, it wouldn't\n> be appropriate to add a maintainer if many contributors disagreed with it,\n> just as with any other PR.\n>\n> We can take a look at how previous maintainers were added to see how this\n> has played out in the past. I think our modern concept of maintainers with\n> nominal scopes began in 2015 with Jonas Schnelli. Both Jonas Schnelli and\n> Marco Falke were simply announced by Wladimir. There was no public\n> discussion, and some IRC logs refer to private emails between the them and\n> the current maintainers at that time. After that, meshcollider was added as\n> a maintainer after a public \"call for maintainers\" where a recurring topic\n> for a while was finding a maintainer for the wallet. He had volunteered to\n> do it by contacting Wladimir privately before it was discussed during an\n> IRC meeting and then on Github. Fanquake was added as a maintainer during a\n> CoreDev event in Amsterdam during a discussion initiated and led by the\n> maintainers. This was also \"private\" insofar as the discussion was limited\n> to those in attendance, although there was some opportunity for public\n> discussion in the PR opened on Github. For myself, it was also initially\n> private as I messaged Wladimir to volunteer for it after meshcollider\n> stepped down. There was some discussion on IRC and on Github, but it was\n> also obvious that many already expected me to be the wallet maintainer\n> after meshcollider. Hebasto was added with basically no fanfare or\n> discussion - the only mention I can find is the PR itself. My understanding\n> is that the maintainers asked him he wanted to do it before the PR was\n> opened. Glozow was nominated to be a maintainer by some of the current\n> maintainers, and her nomination was really the first time that there was\n> significant public discussion about it.\n>\n> Of the past 7 maintainer additions, 5 were nominations/announcements from\n> the current maintainers, one was volunteering following an actual \"call for\n> maintainer\", and one was an obvious successor. It's obvious and common\n> sense that the maintainers decide when they need help shouldering the load,\n> and then find somebody to help them. There was and always will be some\n> level of private communication prior to any public announcement of the\n> nomination or volunteering of a maintainer. It doesn't make sense to\n> blindside somebody with a nomination without talking to them beforehand.\n> The fact that most of these were non-controversial speaks to how well the\n> maintainers were considering their nominations before publicly announcing\n> them.\n>\n> It's also clear that we have been moving towards more open discussion\n> about maintainership and who should be maintainers. The process is\n> fundamentally more public than it was previously. We now have public\n> discussion with contributors about the merits of a person, even if that\n> results in said person not becoming a maintainer. Over time, there's been\n> more public participation in the PRs and on IRC meetings when maintainer\n> nominations are brought up. We have nominations as topics during meetings\n> now when they occur. The PRs to add keys are left open for longer to get\n> more discussion.\n>\n> Ultimately, if you disagree with how the project operates, then you are\n> free to leave and start your own fork that is run in a way that you think\n> is appropriate. This is open source software, no one is beholden to you,\n> and no one is required to do anything.\n>\n> ***\n>\n> Since you are intent on discussing and re-litigating the decision about\n> Vasil, I will agree that we (the maintainers) could have done a better job\n> of communicating. However we stand by the decision that was made in the\n> end, and we did have a chat with him about it during CoreDev.\n>\n> It really boils down to three things: 1) we did not ask for a P2P\n> maintainer, 2) some of those who have reviewed Vasil's work expressed\n> discomfort with him being a maintainer, and 3) some contributors and\n> maintainers were uncomfortable with his responses about how he would merge\n> things. You repeatedly insist that it's only the current maintainers who\n> blocked Vasil, but that is not the case. There were concerns brought up by\n> other contributors that contributed to the decision to ultimately NACK his\n> nomination.\n>\n> One of the justifications for blocking Vasil Dimov as a new maintainer\n> despite many initial ACKs from maintainers (including Andrew Chow) and long\n> term contributors was according to Andrew [2]:\n>\n> To be honest, my initial ACK was given without knowing enough information.\n> It was given when he was mostly a name that showed up in my notification\n> emails, and his work had seemed to be fine with me. At that time, I did not\n> think we had a need for a P2P maintainer, but I also did not think that\n> having one would be harmful. However I later spoke to a few others\n> privately who were more familiar with Vasil's work and they had told me\n> that they were not comfortable with Vasil being P2P maintainer.\n>\n> \u201cMaintainers inherently need to look at the things that everyone else has\n> already looked at, if only to give it a final once over before merging (but\n> hopefully, an actual review, not just looking it over).\u201d\n>\n>\n> I follow the Bitcoin Core repo pretty closely and I haven\u2019t seen ryanofsky\n> do this any more than Vasil does. This is not a criticism of ryanofsky,\n> just as I wouldn\u2019t use it as a criticism for Vasil. It would get pretty\n> annoying if everyone who wasn\u2019t a maintainer posted an ACK once many long\n> term contributors had already ACKed to display supposed \u201cdesired maintainer\n> traits\u201d. Especially if you are essentially just ACKing that others have\n> done the work to review the PR and you just want to get your ACK on it to\n> increase your ACK count without doing a fraction of what previous reviewers\n> have done.\n>\n> This opinion was formed not from observing his behavior towards ACK'ing,\n> but rather from his responses to questions about reviewing, in addition to\n> thoughts shared by other contributors.\n>\n> From having received plenty of reviews from ryanofsky, I can certainly say\n> that his reviews are in depth. He has pointed out subtle bugs, asks\n> questions about very low level details, and has well reasoned critiques and\n> discussions about design decisions. His reviews are high quality, and he's\n> not afraid of being the first person to ACK a pr, the last person to ACK\n> it, or the person to prevent one from being merged even when it already has\n> a few ACKs. We also had a separate discussion with ryanofsky about his\n> approaches to reviewing and merging.\n>\n> \u201cI also want to mention that the people who have become maintainers in the\n> past have had this kind of maintainer attitude towards review prior to\n> becoming a maintainer\u201d\n>\n>\n> Assuming ryanofsky hasn\u2019t had this maintainer attitude in the past (again\n> not a criticism from me at least) does this mean this was a reason to block\n> Vasil but not a reason to block ryanofsky? That seems inconsistent to me.\n>\n> I don't know why you assume the ryanofsky hasn't had this maintainer\n> attitude? Your claim of inconsistency stems from this assumption that\n> ryanofsky doesn't have a maintainer attitude, but I would argue that he\n> does, as I mentioned above. The idea of adding him as a maintainer has been\n> floated around before, although never really seriously proposed until now,\n> AFAIK.\n>\n> When you\u2019re anointed you don\u2019t need to meet requirements but when you\u2019re\n> blocked these requirements will be used to block your addition as a new\n> maintainer?\n>\n> It seems obvious to me that when the current maintainers approach and\n> nominate a contributor to be a maintainer that that person already meets\n> these requirements. I don't know why you would assume bad faith in that\n> someone who isn't qualified would be nominated by the current maintainers.\n> It's quite frustrating that you seem to just jump straight to the negative\n> conclusion rather than considering that there might be actual reasons based\n> on the merits of the person.\n>\n> On a more positive note there does seem to be more energy and momentum for\n> collaboration and open communication on the project since I discussed\n> communication in a previous post [3]. Hopefully this will continue. It\n> doesn\u2019t address my concerns on maintainers and ultimately merge decisions\n> but it definitely seems to me to be a step in a positive direction for the\n> project.\n>\n> Don't take credit for what you didn't do. The group-wide effort to move\n> towards public discussion again is the result of a discussion that was had\n> at CoreDev. Many cited your behavior as a primary reason to stop discussing\n> things publicly, with things such as dragging project meta discussions onto\n> the mailing list and twitter. These have invited abuse towards maintainers\n> and contributors, which in turn makes them takes those discussions to more\n> private settings. People feel like they're getting sealioned by you (and a\n> few others) when they post publicly, and so they have stopped doing so.\n>\n>\n> Andrew\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230511/fa7ff9bb/attachment-0001.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2023-05-11T18:48:39",
                "message_text_only": "i agree 100%.   effective communication is challenging, especially in an\nenvironment like this.   that being said, alicexbt is probably right that\nwe\n\n - probably need a well written spec, RFC-style perhaps\n - need more anon or nym maintainers where the online reputation isn't\ntrivially linked to real-world reputation\n - github should be replaced with something p2p (maybe move to\nhttps://radicle.xyz/)\n\nmeta-stuff like that is probably just as important as picking the next cool\ncovenant opcode to ignore\n\nOn Thu, May 11, 2023 at 2:06\u202fPM Steve Lee via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I don't see any reason to be antagonistic in your responses.\n>\n> One piece of advice I'd offer to you and Michael is to consider whether\n> your responses are effective. To persuade other people it takes more than\n> making good points or being right, but you need to find a communication\n> style and communication path that is effective. My observation is that your\n> styles need reflection.\n>\n>\n> On Thu, May 11, 2023 at 10:15\u202fAM alicexbt via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi Andrew,\n>>\n>> We can take a look at how previous maintainers were added to see how this\n>> has played out in the past.\n>>\n>>\n>> Can we learn something from past?\n>>\n>> Bitcoin's initial release was in 2009 with one developer and few others\n>> experimenting with it. It is considered decentralized in 2023 however we\n>> have 99% of nodes using bitcoin core, 5 developers deciding what's merged\n>> or not and this includes some trying to implement their ideas without soft\n>> fork using mempool policies.\n>>\n>> We need better process to add maintainers. I am disappointed with the way\n>> last last pull request was merged. It says more about maintainers and\n>> leader Michael Ford. If you are so scared about opinions on a pull request\n>> why not just make him maintainer without pull request?\n>>\n>> Maybe you will understand this if your PR to add maintainer was kept open\n>> for 4 months.\n>>\n>> /dev/fd0\n>> floppy disk\n>>\n>>\n>> Sent with Proton Mail <https://proton.me/> secure email.\n>>\n>> ------- Original Message -------\n>> On Thursday, May 11th, 2023 at 2:54 AM, Andrew Chow via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> On 05/07/23 03:03 AM, Michael Folkson via bitcoin-dev wrote:\n>>\n>>\n>> The decision process for adding a new maintainer was according to the IRC\n>> meeting that the maintainers decided privately there was a need for a\n>> maintainer \u201cwho understood our interfaces and modularization efforts well\u201d\n>> and that ryanofsky was a \u201cgood fit for that\u201d. I don\u2019t know whether this was\n>> decided in a private IRC channel or was decided at the recent in person\n>> Core Dev meeting. Regardless, many have had no input into the discussion on\n>> what kind of maintainer the project needs going forward and it seems the\n>> maintainers do not want to discuss that aspect of the decision.\n>>\n>> Since the project began, the decision to seek out and then add a\n>> maintainer has always been made by existing maintainers. When the\n>> maintainers feel that there is a need for additional maintainers, they may\n>> have an open call for volunteers, or may have a candidate already in mind\n>> and suggest that specific person for maintainership. Contributors generally\n>> are not consulted in the decision to seek a new maintainer as they would\n>> not know whether there are things that are being overlooked or that there\n>> is maintainership load that needs to be distributed. Even so, it wouldn't\n>> be appropriate to add a maintainer if many contributors disagreed with it,\n>> just as with any other PR.\n>>\n>> We can take a look at how previous maintainers were added to see how this\n>> has played out in the past. I think our modern concept of maintainers with\n>> nominal scopes began in 2015 with Jonas Schnelli. Both Jonas Schnelli and\n>> Marco Falke were simply announced by Wladimir. There was no public\n>> discussion, and some IRC logs refer to private emails between the them and\n>> the current maintainers at that time. After that, meshcollider was added as\n>> a maintainer after a public \"call for maintainers\" where a recurring topic\n>> for a while was finding a maintainer for the wallet. He had volunteered to\n>> do it by contacting Wladimir privately before it was discussed during an\n>> IRC meeting and then on Github. Fanquake was added as a maintainer during a\n>> CoreDev event in Amsterdam during a discussion initiated and led by the\n>> maintainers. This was also \"private\" insofar as the discussion was limited\n>> to those in attendance, although there was some opportunity for public\n>> discussion in the PR opened on Github. For myself, it was also initially\n>> private as I messaged Wladimir to volunteer for it after meshcollider\n>> stepped down. There was some discussion on IRC and on Github, but it was\n>> also obvious that many already expected me to be the wallet maintainer\n>> after meshcollider. Hebasto was added with basically no fanfare or\n>> discussion - the only mention I can find is the PR itself. My understanding\n>> is that the maintainers asked him he wanted to do it before the PR was\n>> opened. Glozow was nominated to be a maintainer by some of the current\n>> maintainers, and her nomination was really the first time that there was\n>> significant public discussion about it.\n>>\n>> Of the past 7 maintainer additions, 5 were nominations/announcements from\n>> the current maintainers, one was volunteering following an actual \"call for\n>> maintainer\", and one was an obvious successor. It's obvious and common\n>> sense that the maintainers decide when they need help shouldering the load,\n>> and then find somebody to help them. There was and always will be some\n>> level of private communication prior to any public announcement of the\n>> nomination or volunteering of a maintainer. It doesn't make sense to\n>> blindside somebody with a nomination without talking to them beforehand.\n>> The fact that most of these were non-controversial speaks to how well the\n>> maintainers were considering their nominations before publicly announcing\n>> them.\n>>\n>> It's also clear that we have been moving towards more open discussion\n>> about maintainership and who should be maintainers. The process is\n>> fundamentally more public than it was previously. We now have public\n>> discussion with contributors about the merits of a person, even if that\n>> results in said person not becoming a maintainer. Over time, there's been\n>> more public participation in the PRs and on IRC meetings when maintainer\n>> nominations are brought up. We have nominations as topics during meetings\n>> now when they occur. The PRs to add keys are left open for longer to get\n>> more discussion.\n>>\n>> Ultimately, if you disagree with how the project operates, then you are\n>> free to leave and start your own fork that is run in a way that you think\n>> is appropriate. This is open source software, no one is beholden to you,\n>> and no one is required to do anything.\n>>\n>> ***\n>>\n>> Since you are intent on discussing and re-litigating the decision about\n>> Vasil, I will agree that we (the maintainers) could have done a better job\n>> of communicating. However we stand by the decision that was made in the\n>> end, and we did have a chat with him about it during CoreDev.\n>>\n>> It really boils down to three things: 1) we did not ask for a P2P\n>> maintainer, 2) some of those who have reviewed Vasil's work expressed\n>> discomfort with him being a maintainer, and 3) some contributors and\n>> maintainers were uncomfortable with his responses about how he would merge\n>> things. You repeatedly insist that it's only the current maintainers who\n>> blocked Vasil, but that is not the case. There were concerns brought up by\n>> other contributors that contributed to the decision to ultimately NACK his\n>> nomination.\n>>\n>> One of the justifications for blocking Vasil Dimov as a new maintainer\n>> despite many initial ACKs from maintainers (including Andrew Chow) and long\n>> term contributors was according to Andrew [2]:\n>>\n>> To be honest, my initial ACK was given without knowing enough\n>> information. It was given when he was mostly a name that showed up in my\n>> notification emails, and his work had seemed to be fine with me. At that\n>> time, I did not think we had a need for a P2P maintainer, but I also did\n>> not think that having one would be harmful. However I later spoke to a few\n>> others privately who were more familiar with Vasil's work and they had told\n>> me that they were not comfortable with Vasil being P2P maintainer.\n>>\n>> \u201cMaintainers inherently need to look at the things that everyone else has\n>> already looked at, if only to give it a final once over before merging (but\n>> hopefully, an actual review, not just looking it over).\u201d\n>>\n>>\n>> I follow the Bitcoin Core repo pretty closely and I haven\u2019t seen\n>> ryanofsky do this any more than Vasil does. This is not a criticism of\n>> ryanofsky, just as I wouldn\u2019t use it as a criticism for Vasil. It would get\n>> pretty annoying if everyone who wasn\u2019t a maintainer posted an ACK once many\n>> long term contributors had already ACKed to display supposed \u201cdesired\n>> maintainer traits\u201d. Especially if you are essentially just ACKing that\n>> others have done the work to review the PR and you just want to get your\n>> ACK on it to increase your ACK count without doing a fraction of what\n>> previous reviewers have done.\n>>\n>> This opinion was formed not from observing his behavior towards ACK'ing,\n>> but rather from his responses to questions about reviewing, in addition to\n>> thoughts shared by other contributors.\n>>\n>> From having received plenty of reviews from ryanofsky, I can certainly\n>> say that his reviews are in depth. He has pointed out subtle bugs, asks\n>> questions about very low level details, and has well reasoned critiques and\n>> discussions about design decisions. His reviews are high quality, and he's\n>> not afraid of being the first person to ACK a pr, the last person to ACK\n>> it, or the person to prevent one from being merged even when it already has\n>> a few ACKs. We also had a separate discussion with ryanofsky about his\n>> approaches to reviewing and merging.\n>>\n>> \u201cI also want to mention that the people who have become maintainers in\n>> the past have had this kind of maintainer attitude towards review prior to\n>> becoming a maintainer\u201d\n>>\n>>\n>> Assuming ryanofsky hasn\u2019t had this maintainer attitude in the past (again\n>> not a criticism from me at least) does this mean this was a reason to block\n>> Vasil but not a reason to block ryanofsky? That seems inconsistent to me.\n>>\n>> I don't know why you assume the ryanofsky hasn't had this maintainer\n>> attitude? Your claim of inconsistency stems from this assumption that\n>> ryanofsky doesn't have a maintainer attitude, but I would argue that he\n>> does, as I mentioned above. The idea of adding him as a maintainer has been\n>> floated around before, although never really seriously proposed until now,\n>> AFAIK.\n>>\n>> When you\u2019re anointed you don\u2019t need to meet requirements but when you\u2019re\n>> blocked these requirements will be used to block your addition as a new\n>> maintainer?\n>>\n>> It seems obvious to me that when the current maintainers approach and\n>> nominate a contributor to be a maintainer that that person already meets\n>> these requirements. I don't know why you would assume bad faith in that\n>> someone who isn't qualified would be nominated by the current maintainers.\n>> It's quite frustrating that you seem to just jump straight to the negative\n>> conclusion rather than considering that there might be actual reasons based\n>> on the merits of the person.\n>>\n>> On a more positive note there does seem to be more energy and momentum\n>> for collaboration and open communication on the project since I discussed\n>> communication in a previous post [3]. Hopefully this will continue. It\n>> doesn\u2019t address my concerns on maintainers and ultimately merge decisions\n>> but it definitely seems to me to be a step in a positive direction for the\n>> project.\n>>\n>> Don't take credit for what you didn't do. The group-wide effort to move\n>> towards public discussion again is the result of a discussion that was had\n>> at CoreDev. Many cited your behavior as a primary reason to stop discussing\n>> things publicly, with things such as dragging project meta discussions onto\n>> the mailing list and twitter. These have invited abuse towards maintainers\n>> and contributors, which in turn makes them takes those discussions to more\n>> private settings. People feel like they're getting sealioned by you (and a\n>> few others) when they post publicly, and so they have stopped doing so.\n>>\n>>\n>> Andrew\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230511/0fbe9ce6/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Core maintainers and communication on merge decisions",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Steve Lee",
                "Bryan Bishop",
                "Michael Folkson",
                "David A. Harding",
                "alicexbt",
                "Erik Aronesty",
                "Andrew Chow"
            ],
            "messages_count": 14,
            "total_messages_chars_count": 94781
        }
    },
    {
        "title": "[bitcoin-dev] [Mempool spam] Should we as developers reject non-standard Taproot transactions from full nodes?",
        "thread_messages": [
            {
                "author": "Ali Sherief",
                "date": "2023-05-07T17:22:23",
                "message_text_only": "Hi guys,\n\nI think everyone on this list knows what has happened to the Bitcoin mempool during the past 96 hours. Due to side projects such as BRC-20 having such a high volume, real bitcoin transactions are being priced out and that is what is causing the massive congestion that has arguable not been seen since December 2017. I do not count the March 2021 congestion because that was only with 1-5sat/vbyte.\n\nSuch justifiably worthless (\"worthless\" is not even my word - that's how its creator described them[1]) tokens threaten the smooth and normal use of the Bitcoin network as a peer-to-pear digital currency, as it was intended to be used as.\n\nIf the volume does not die down over the next few weeks, should we take an action? The bitcoin network is a triumvirate of developers, miners, and users. Considering that miners are largely the entities at fault for allowing the system to be abused like this, the harmony of Bitcoin transactions is being disrupted right now. Although this community has a strong history of not putting its fingers into pies unless absolutely necessary - an example being during the block size wars and Segwit - should similar action be taken now, in the form of i) BIPs and/or ii) commits into the Bitcoin Core codebase, to curtail the loophole in BIP 342 (which defines the validation rules for Taproot scripts) which has allowed these unintended consequences?\n\nAn alternative would be to enforce this \"censorship\" at the node level and introduce a run-time option to instantly prune all non-standard Taproot transactions. This will be easier to implement, but won't hit the road until minimum next release.\n\nI know that some people will have their criticisms about this, absolutists/libertarians/maximum-freedom advocates, which is fine, but we need to find a solution for this that fits everyone's common ground. We indirectly allowed this to happen, which previously wasn't possible before. So we also have a responsibility to do something to ensure that this kind of congestion can never happen again using Taproot.\n\n-Ali\n\n---\n\n[1]: [https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/](https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/?outputType=amp)\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230507/99acad23/attachment-0001.html>"
            },
            {
                "author": "Michael Folkson",
                "date": "2023-05-08T12:33:40",
                "message_text_only": "Hi Ali\n\nI'd point you to Andrew Poelstra's post from January 2023 [0] and a Bitcoin StackExchange answer I recently posted [1].\n\n> Considering that miners are largely the entities at fault for allowing the system to be abused like this, the harmony of Bitcoin transactions is being disrupted right now.\n\nMiners are as far as I understand including high fee rate, consensus compatible transactions in mined blocks as the system has been set up for them to do. As I say in that StackExchange answer if you don't like it:\n\n\"There are theoretically two options: a consensus change or a policy change. A consensus change disallowing a certain kind of transaction that is acceptable under current consensus rules would need a soft fork and hence would be extremely difficult to pull off assuming that it was a considered a good idea by the broader community. Embedding arbitrary data in transactions would still be possible after this hypothetical soft fork and so its effectiveness would be limited. A default policy change (or custom policy option) would attempt to prevent a certain kind of transaction from propagating across the network without needing a consensus change. However, it would still be possible to submit these kinds of consensus compatible transactions directly to miners bypassing the P2P network.\"\n\n> I know that some people will have their criticisms about this, absolutists/libertarians/maximum-freedom advocates, which is fine, but we need to find a solution for this that fits everyone's common ground. We indirectly allowed this to happen, which previously wasn't possible before. So we also have a responsibility to do something to ensure that this kind of congestion can never happen again using Taproot.\n\nIt isn't a philosophy or ideology consideration, it is a purely technical one. Congestion can happen using Taproot addresses or pre-Taproot addresses. There is fixed, limited block space and variable demand for that block space. You may not like how that block space is being used but if transactions are consensus compatible and paying fees at the market rate the system is working how it should.\n\n> to curtail the loophole in BIP 342 (which defines the validation rules for Taproot scripts) which has allowed these unintended consequences?\n\nThere were technical reasons for the design decisions in BIP 342. As Andrew says in his post [0]:\n\n\"If we ban \"useless data\" then it would be easy for would-be data storers\nto instead embed their data inside \"useful\" data such as dummy\nsignatures or public keys. Doing so would incur a ~2x cost to them, but\nif 2x is enough to disincentivize storage, then there's no need to have\nthis discussion because they will will be forced to stop due to fee\nmarket competition anyway. (And if not, it means there is little demand\nfor Bitcoin blockspace, so what's the problem with paying miners to fill\nit with data that validators don't even need to perform real computation\non?).\n\nBut if we were to ban \"useful\" data, for example, saying that a witness\ncan't have more than 20 signatures in it, then we are into the same\nproblem we had pre-Taproot: that it is effectively impossible construct\nsigning policies in a general and composeable way, because any software\nthat does so will need to account for multiple independent limits. We\ndeliberately replaced such limits with \"you need to pay 50 weight for\neach signature\" to makes this sort of analysis tractable.\"\n\nI personally get the desire to \"do something\". Fee spikes aren't fun especially for some Lightning use cases and many of us don't like how people are using the limited block space currently. But a game of whack-a-mole with blunt tools such as policy rules and especially consensus rules is ineffective at best and harmful at worst. You may not like this use case but assuming you embark on a game of whack-a-mole what's to stop a group of people popping up in a year declaring their opposition to your use case and trying to prevent your use case? Consensus rules are set and the rest is left to the market.\n\nThanks\n\nMichael\n\n[0]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-January/021372.html\n[1]: https://bitcoin.stackexchange.com/questions/118197/ddos-attack-via-brc-20-ordinals-on-bitcoin\n\n--\nMichael Folkson\nEmail: michaelfolkson at [protonmail.com](http://protonmail.com/)\nGPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n\nLearn about Bitcoin: https://www.youtube.com/@portofbitcoin\n\n------- Original Message -------\nOn Sunday, May 7th, 2023 at 18:22, Ali Sherief via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi guys,\n>\n> I think everyone on this list knows what has happened to the Bitcoin mempool during the past 96 hours. Due to side projects such as BRC-20 having such a high volume, real bitcoin transactions are being priced out and that is what is causing the massive congestion that has arguable not been seen since December 2017. I do not count the March 2021 congestion because that was only with 1-5sat/vbyte.\n>\n> Such justifiably worthless (\"worthless\" is not even my word - that's how its creator described them[1]) tokens threaten the smooth and normal use of the Bitcoin network as a peer-to-pear digital currency, as it was intended to be used as.\n>\n> If the volume does not die down over the next few weeks, should we take an action? The bitcoin network is a triumvirate of developers, miners, and users. Considering that miners are largely the entities at fault for allowing the system to be abused like this, the harmony of Bitcoin transactions is being disrupted right now. Although this community has a strong history of not putting its fingers into pies unless absolutely necessary - an example being during the block size wars and Segwit - should similar action be taken now, in the form of i) BIPs and/or ii) commits into the Bitcoin Core codebase, to curtail the loophole in BIP 342 (which defines the validation rules for Taproot scripts) which has allowed these unintended consequences?\n>\n> An alternative would be to enforce this \"censorship\" at the node level and introduce a run-time option to instantly prune all non-standard Taproot transactions. This will be easier to implement, but won't hit the road until minimum next release.\n>\n> I know that some people will have their criticisms about this, absolutists/libertarians/maximum-freedom advocates, which is fine, but we need to find a solution for this that fits everyone's common ground. We indirectly allowed this to happen, which previously wasn't possible before. So we also have a responsibility to do something to ensure that this kind of congestion can never happen again using Taproot.\n>\n> -Ali\n>\n> ---\n>\n> [1]: [https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/](https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/?outputType=amp)\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/6643e7e1/attachment-0001.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2023-05-08T12:58:28",
                "message_text_only": "probably easier just to reject any transaction where the fee is higher than\nthe sum of the outputs\n\n\n\nOn Mon, May 8, 2023, 7:55 AM Ali Sherief via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi guys,\n>\n> I think everyone on this list knows what has happened to the Bitcoin\n> mempool during the past 96 hours. Due to side projects such as BRC-20\n> having such a high volume, real bitcoin transactions are being priced out\n> and that is what is causing the massive congestion that has arguable not\n> been seen since December 2017. I do not count the March 2021 congestion\n> because that was only with 1-5sat/vbyte.\n>\n> Such justifiably worthless (\"worthless\" is not even my word - that's how\n> its creator described them[1]) tokens threaten the smooth and normal use of\n> the Bitcoin network as a peer-to-pear digital currency, as it was intended\n> to be used as.\n>\n> If the volume does not die down over the next few weeks, should we take an\n> action? The bitcoin network is a triumvirate of developers, miners, and\n> users. Considering that miners are largely the entities at fault for\n> allowing the system to be abused like this, the harmony of Bitcoin\n> transactions is being disrupted right now. Although this community has a\n> strong history of not putting its fingers into pies unless absolutely\n> necessary - an example being during the block size wars and Segwit - should\n> similar action be taken now, in the form of i) BIPs and/or ii) commits into\n> the Bitcoin Core codebase, to curtail the loophole in BIP 342 (which\n> defines the validation rules for Taproot scripts) which has allowed these\n> unintended consequences?\n>\n> An alternative would be to enforce this \"censorship\" at the node level and\n> introduce a run-time option to instantly prune all non-standard Taproot\n> transactions. This will be easier to implement, but won't hit the road\n> until minimum next release.\n>\n> I know that some people will have their criticisms about this,\n> absolutists/libertarians/maximum-freedom advocates, which is fine, but we\n> need to find a solution for this that fits everyone's common ground. We\n> indirectly allowed this to happen, which previously wasn't possible before.\n> So we also have a responsibility to do something to ensure that this kind\n> of congestion can never happen again using Taproot.\n>\n> -Ali\n>\n> ---\n>\n> [1]:\n> https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/\n> <https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/?outputType=amp>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/7b2576ed/attachment.html>"
            },
            {
                "author": "Michael Folkson",
                "date": "2023-05-08T17:13:20",
                "message_text_only": "> probably easier just to reject any transaction where the fee is higher than the sum of the outputs\n\nAnd prevent perfectly reasonable transfers of value and attempted Lightning channel closes during fee spikes? If I want\u200b to close my Lightning channel during a protracted fee spike where I have to pay an onchain transaction fee greater than the amount I am receiving you want to stop me doing that? You are impinging on a valid use case as well as requiring a consensus rule change.\n\n--\nMichael Folkson\nEmail: michaelfolkson at [protonmail.com](http://protonmail.com/)\nGPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n\nLearn about Bitcoin: https://www.youtube.com/@portofbitcoin\n\n------- Original Message -------\nOn Monday, May 8th, 2023 at 13:58, Erik Aronesty via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> probably easier just to reject any transaction where the fee is higher than the sum of the outputs\n>\n> On Mon, May 8, 2023, 7:55 AM Ali Sherief via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi guys,\n>>\n>> I think everyone on this list knows what has happened to the Bitcoin mempool during the past 96 hours. Due to side projects such as BRC-20 having such a high volume, real bitcoin transactions are being priced out and that is what is causing the massive congestion that has arguable not been seen since December 2017. I do not count the March 2021 congestion because that was only with 1-5sat/vbyte.\n>>\n>> Such justifiably worthless (\"worthless\" is not even my word - that's how its creator described them[1]) tokens threaten the smooth and normal use of the Bitcoin network as a peer-to-pear digital currency, as it was intended to be used as.\n>>\n>> If the volume does not die down over the next few weeks, should we take an action? The bitcoin network is a triumvirate of developers, miners, and users. Considering that miners are largely the entities at fault for allowing the system to be abused like this, the harmony of Bitcoin transactions is being disrupted right now. Although this community has a strong history of not putting its fingers into pies unless absolutely necessary - an example being during the block size wars and Segwit - should similar action be taken now, in the form of i) BIPs and/or ii) commits into the Bitcoin Core codebase, to curtail the loophole in BIP 342 (which defines the validation rules for Taproot scripts) which has allowed these unintended consequences?\n>>\n>> An alternative would be to enforce this \"censorship\" at the node level and introduce a run-time option to instantly prune all non-standard Taproot transactions. This will be easier to implement, but won't hit the road until minimum next release.\n>>\n>> I know that some people will have their criticisms about this, absolutists/libertarians/maximum-freedom advocates, which is fine, but we need to find a solution for this that fits everyone's common ground. We indirectly allowed this to happen, which previously wasn't possible before. So we also have a responsibility to do something to ensure that this kind of congestion can never happen again using Taproot.\n>>\n>> -Ali\n>>\n>> ---\n>>\n>> [1]: [https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/](https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/?outputType=amp)\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/c13a41a2/attachment-0001.html>"
            },
            {
                "author": "Ali Sherief",
                "date": "2023-05-08T19:31:09",
                "message_text_only": "I think one of the bigger problems facing the broader Bitcoin ecosystem is the lack of Lightning wallets for desktop. Mobile wallets are not really an issue, but as far as I know for desktop builds, there's really only Electrum, and Zap Wallet which support Lightning.\n\nThe alternative is interacting with the LN node directly, which probably won't be so bad, but it would be better if they carried GUI wallets like BItcoin Core does. Because windows and buttons help with mass adoption of pretty much everything.\n\nI may even consider developing a Lighting wallet given the circumstances.\n\n-Ali\n\nOn Mon, May 8, 2023 at 8:13 PM, Michael Folkson <michaelfolkson at protonmail.com> wrote:\n\n>> probably easier just to reject any transaction where the fee is higher than the sum of the outputs\n>\n> And prevent perfectly reasonable transfers of value and attempted Lightning channel closes during fee spikes? If I want\u200b to close my Lightning channel during a protracted fee spike where I have to pay an onchain transaction fee greater than the amount I am receiving you want to stop me doing that? You are impinging on a valid use case as well as requiring a consensus rule change.\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at [protonmail.com](http://protonmail.com/)\n> GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n>\n> Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n>\n> ------- Original Message -------\n> On Monday, May 8th, 2023 at 13:58, Erik Aronesty via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> probably easier just to reject any transaction where the fee is higher than the sum of the outputs\n>>\n>> On Mon, May 8, 2023, 7:55 AM Ali Sherief via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Hi guys,\n>>>\n>>> I think everyone on this list knows what has happened to the Bitcoin mempool during the past 96 hours. Due to side projects such as BRC-20 having such a high volume, real bitcoin transactions are being priced out and that is what is causing the massive congestion that has arguable not been seen since December 2017. I do not count the March 2021 congestion because that was only with 1-5sat/vbyte.\n>>>\n>>> Such justifiably worthless (\"worthless\" is not even my word - that's how its creator described them[1]) tokens threaten the smooth and normal use of the Bitcoin network as a peer-to-pear digital currency, as it was intended to be used as.\n>>>\n>>> If the volume does not die down over the next few weeks, should we take an action? The bitcoin network is a triumvirate of developers, miners, and users. Considering that miners are largely the entities at fault for allowing the system to be abused like this, the harmony of Bitcoin transactions is being disrupted right now. Although this community has a strong history of not putting its fingers into pies unless absolutely necessary - an example being during the block size wars and Segwit - should similar action be taken now, in the form of i) BIPs and/or ii) commits into the Bitcoin Core codebase, to curtail the loophole in BIP 342 (which defines the validation rules for Taproot scripts) which has allowed these unintended consequences?\n>>>\n>>> An alternative would be to enforce this \"censorship\" at the node level and introduce a run-time option to instantly prune all non-standard Taproot transactions. This will be easier to implement, but won't hit the road until minimum next release.\n>>>\n>>> I know that some people will have their criticisms about this, absolutists/libertarians/maximum-freedom advocates, which is fine, but we need to find a solution for this that fits everyone's common ground. We indirectly allowed this to happen, which previously wasn't possible before. So we also have a responsibility to do something to ensure that this kind of congestion can never happen again using Taproot.\n>>>\n>>> -Ali\n>>>\n>>> ---\n>>>\n>>> [1]: [https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/](https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/?outputType=amp)\n>>>\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/227a4f1c/attachment-0001.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2023-05-08T19:47:48",
                "message_text_only": "im unclear as to the purpose paying an onchain transaction fee greater than\nthe amount receiving could possibly serve.\n\nwhat benefit do you get aside from losing bitcoin?\n\nare there any, non-theoretical, benefits to facilitating dust transactions?\n\nwe could, of course, have it be non-consensus (no route dust) to start with\n\n\n\n\n\nOn Mon, May 8, 2023 at 1:13\u202fPM Michael Folkson <\nmichaelfolkson at protonmail.com> wrote:\n\n> > probably easier just to reject any transaction where the fee is higher\n> than the sum of the outputs\n>\n> And prevent perfectly reasonable transfers of value and attempted\n> Lightning channel closes during fee spikes? If I *want*\u200b to close my\n> Lightning channel during a protracted fee spike where I have to pay an\n> onchain transaction fee greater than the amount I am receiving you want to\n> stop me doing that? You are impinging on a valid use case as well as\n> requiring a consensus rule change.\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n>\n> Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n>\n> ------- Original Message -------\n> On Monday, May 8th, 2023 at 13:58, Erik Aronesty via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> probably easier just to reject any transaction where the fee is higher\n> than the sum of the outputs\n>\n>\n>\n> On Mon, May 8, 2023, 7:55 AM Ali Sherief via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi guys,\n>>\n>> I think everyone on this list knows what has happened to the Bitcoin\n>> mempool during the past 96 hours. Due to side projects such as BRC-20\n>> having such a high volume, real bitcoin transactions are being priced out\n>> and that is what is causing the massive congestion that has arguable not\n>> been seen since December 2017. I do not count the March 2021 congestion\n>> because that was only with 1-5sat/vbyte.\n>>\n>> Such justifiably worthless (\"worthless\" is not even my word - that's how\n>> its creator described them[1]) tokens threaten the smooth and normal use of\n>> the Bitcoin network as a peer-to-pear digital currency, as it was intended\n>> to be used as.\n>>\n>> If the volume does not die down over the next few weeks, should we take\n>> an action? The bitcoin network is a triumvirate of developers, miners, and\n>> users. Considering that miners are largely the entities at fault for\n>> allowing the system to be abused like this, the harmony of Bitcoin\n>> transactions is being disrupted right now. Although this community has a\n>> strong history of not putting its fingers into pies unless absolutely\n>> necessary - an example being during the block size wars and Segwit - should\n>> similar action be taken now, in the form of i) BIPs and/or ii) commits into\n>> the Bitcoin Core codebase, to curtail the loophole in BIP 342 (which\n>> defines the validation rules for Taproot scripts) which has allowed these\n>> unintended consequences?\n>>\n>> An alternative would be to enforce this \"censorship\" at the node level\n>> and introduce a run-time option to instantly prune all non-standard Taproot\n>> transactions. This will be easier to implement, but won't hit the road\n>> until minimum next release.\n>>\n>> I know that some people will have their criticisms about this,\n>> absolutists/libertarians/maximum-freedom advocates, which is fine, but we\n>> need to find a solution for this that fits everyone's common ground. We\n>> indirectly allowed this to happen, which previously wasn't possible before.\n>> So we also have a responsibility to do something to ensure that this kind\n>> of congestion can never happen again using Taproot.\n>>\n>> -Ali\n>>\n>> ---\n>>\n>> [1]:\n>> https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/\n>> <https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/?outputType=amp>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/cf095863/attachment-0001.html>"
            },
            {
                "author": "Michael Folkson",
                "date": "2023-05-08T20:36:11",
                "message_text_only": "> im unclear as to the purposepaying an onchain transaction fee greater than the amount receiving could possibly serve.\n\nIf you expect fees to continue to rise and be sustained at abnormally high levels for a long period of time you might seek to close your Lightning channel(s) and move whatever value you can from these Lightning channel(s) onchain even if it means paying a higher fee than the amount you are receiving.\n\nI don't necessarily recommend doing this (it would depend on a number of factors, both personal and external) but there is no reason to prevent someone in say the consensus rules from doing this if they wish.\n\n--\nMichael Folkson\nEmail: michaelfolkson at [protonmail.com](http://protonmail.com/)\nGPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n\nLearn about Bitcoin: https://www.youtube.com/@portofbitcoin\n\n------- Original Message -------\nOn Monday, May 8th, 2023 at 20:47, Erik Aronesty <erik at q32.com> wrote:\n\n> im unclear as to the purpose paying an onchain transaction fee greater than the amount receiving could possibly serve.\n>\n> what benefit do you get aside from losing bitcoin?\n>\n> are there any, non-theoretical, benefits to facilitating dust transactions?\n>\n> we could, of course, have it be non-consensus (no route dust) to start with\n>\n> On Mon, May 8, 2023 at 1:13\u202fPM Michael Folkson <michaelfolkson at protonmail.com> wrote:\n>\n>>> probably easier just to reject any transaction where the fee is higher than the sum of the outputs\n>>\n>> And prevent perfectly reasonable transfers of value and attempted Lightning channel closes during fee spikes? If I want\u200b to close my Lightning channel during a protracted fee spike where I have to pay an onchain transaction fee greater than the amount I am receiving you want to stop me doing that? You are impinging on a valid use case as well as requiring a consensus rule change.\n>>\n>> --\n>> Michael Folkson\n>> Email: michaelfolkson at [protonmail.com](http://protonmail.com/)\n>> GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n>>\n>> Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n>>\n>> ------- Original Message -------\n>> On Monday, May 8th, 2023 at 13:58, Erik Aronesty via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> probably easier just to reject any transaction where the fee is higher than the sum of the outputs\n>>>\n>>> On Mon, May 8, 2023, 7:55 AM Ali Sherief via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> Hi guys,\n>>>>\n>>>> I think everyone on this list knows what has happened to the Bitcoin mempool during the past 96 hours. Due to side projects such as BRC-20 having such a high volume, real bitcoin transactions are being priced out and that is what is causing the massive congestion that has arguable not been seen since December 2017. I do not count the March 2021 congestion because that was only with 1-5sat/vbyte.\n>>>>\n>>>> Such justifiably worthless (\"worthless\" is not even my word - that's how its creator described them[1]) tokens threaten the smooth and normal use of the Bitcoin network as a peer-to-pear digital currency, as it was intended to be used as.\n>>>>\n>>>> If the volume does not die down over the next few weeks, should we take an action? The bitcoin network is a triumvirate of developers, miners, and users. Considering that miners are largely the entities at fault for allowing the system to be abused like this, the harmony of Bitcoin transactions is being disrupted right now. Although this community has a strong history of not putting its fingers into pies unless absolutely necessary - an example being during the block size wars and Segwit - should similar action be taken now, in the form of i) BIPs and/or ii) commits into the Bitcoin Core codebase, to curtail the loophole in BIP 342 (which defines the validation rules for Taproot scripts) which has allowed these unintended consequences?\n>>>>\n>>>> An alternative would be to enforce this \"censorship\" at the node level and introduce a run-time option to instantly prune all non-standard Taproot transactions. This will be easier to implement, but won't hit the road until minimum next release.\n>>>>\n>>>> I know that some people will have their criticisms about this, absolutists/libertarians/maximum-freedom advocates, which is fine, but we need to find a solution for this that fits everyone's common ground. We indirectly allowed this to happen, which previously wasn't possible before. So we also have a responsibility to do something to ensure that this kind of congestion can never happen again using Taproot.\n>>>>\n>>>> -Ali\n>>>>\n>>>> ---\n>>>>\n>>>> [1]: [https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/](https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/?outputType=amp)\n>>>>\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/41755b0a/attachment-0001.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2023-05-08T20:59:05",
                "message_text_only": "> value you can from these Lightning channel(s) onchain even if it means\npaying a higher fee than the amount you are receiving.\n\nin that case, you're not getting any value - you're losing value.   the\nonly benefit i could imagine would be to prevent the other party from\nhaving access to the funds should the channel expire.\n\nregardless, this is an edge case.   it's clear that a utxo whose value is\nless than the fee paid to move it is dust, and we already have plenty of\ncode to censor dust transactions\n\n> no reason to prevent\n\nthe reason to prevent them is to prevent something that has more value than\nthe bitcoin itself from being stored on-chain.  that is to say:\nreal-estate ownership, nfts, or any other thing that isn't \"using bitcoin\nas money\"\n\nby going at the \"incentive/economic layer\", rather than pointlessly forcing\nbrc-20 and ordinals users to obfuscate their transactions, we can provide a\npermanent incentive to keep that stuff off of bitcoin\n\npersonally, i'm not sure it's desirable to keep it off of bitcoin, but if\nit is, the only sure way to disincentivize it is to go at it in this way or\nsimilar\n\ni suspect all the opcode validation suggestions are just silly.   ordinals\ncan time their fork to the same moment, and store data in a less efficient,\nbut still functional, way using any number of mechanisms.   we've had\nsimilar things posted on-chain since 2010 (my favorite was a software\nlicense key - in an attempt to make bitcoin nodes illegal.   it's still in\nthere)\n\n\nOn Mon, May 8, 2023 at 4:36\u202fPM Michael Folkson <\nmichaelfolkson at protonmail.com> wrote:\n\n> > im unclear as to the purpose paying an onchain transaction fee greater\n> than the amount receiving could possibly serve.\n>\n> If you expect fees to continue to rise and be sustained at abnormally high\n> levels for a long period of time you might seek to close your Lightning\n> channel(s) and move whatever value you can from these Lightning channel(s)\n> onchain even if it means paying a higher fee than the amount you are\n> receiving.\n>\n> I don't necessarily recommend doing this (it would depend on a number of\n> factors, both personal and external) but there is no reason to prevent\n> someone in say the consensus rules from doing this if they wish.\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n>\n> Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n>\n> ------- Original Message -------\n> On Monday, May 8th, 2023 at 20:47, Erik Aronesty <erik at q32.com> wrote:\n>\n> im unclear as to the purpose paying an onchain transaction fee greater\n> than the amount receiving could possibly serve.\n>\n> what benefit do you get aside from losing bitcoin?\n>\n> are there any, non-theoretical, benefits to facilitating dust transactions?\n>\n> we could, of course, have it be non-consensus (no route dust) to start with\n>\n>\n>\n>\n>\n> On Mon, May 8, 2023 at 1:13\u202fPM Michael Folkson <\n> michaelfolkson at protonmail.com> wrote:\n>\n>> > probably easier just to reject any transaction where the fee is higher\n>> than the sum of the outputs\n>>\n>> And prevent perfectly reasonable transfers of value and attempted\n>> Lightning channel closes during fee spikes? If I *want*\u200b to close my\n>> Lightning channel during a protracted fee spike where I have to pay an\n>> onchain transaction fee greater than the amount I am receiving you want to\n>> stop me doing that? You are impinging on a valid use case as well as\n>> requiring a consensus rule change.\n>>\n>> --\n>> Michael Folkson\n>> Email: michaelfolkson at protonmail.com\n>> GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n>>\n>> Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n>>\n>> ------- Original Message -------\n>> On Monday, May 8th, 2023 at 13:58, Erik Aronesty via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> probably easier just to reject any transaction where the fee is higher\n>> than the sum of the outputs\n>>\n>>\n>>\n>> On Mon, May 8, 2023, 7:55 AM Ali Sherief via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Hi guys,\n>>>\n>>> I think everyone on this list knows what has happened to the Bitcoin\n>>> mempool during the past 96 hours. Due to side projects such as BRC-20\n>>> having such a high volume, real bitcoin transactions are being priced out\n>>> and that is what is causing the massive congestion that has arguable not\n>>> been seen since December 2017. I do not count the March 2021 congestion\n>>> because that was only with 1-5sat/vbyte.\n>>>\n>>> Such justifiably worthless (\"worthless\" is not even my word - that's how\n>>> its creator described them[1]) tokens threaten the smooth and normal use of\n>>> the Bitcoin network as a peer-to-pear digital currency, as it was intended\n>>> to be used as.\n>>>\n>>> If the volume does not die down over the next few weeks, should we take\n>>> an action? The bitcoin network is a triumvirate of developers, miners, and\n>>> users. Considering that miners are largely the entities at fault for\n>>> allowing the system to be abused like this, the harmony of Bitcoin\n>>> transactions is being disrupted right now. Although this community has a\n>>> strong history of not putting its fingers into pies unless absolutely\n>>> necessary - an example being during the block size wars and Segwit - should\n>>> similar action be taken now, in the form of i) BIPs and/or ii) commits into\n>>> the Bitcoin Core codebase, to curtail the loophole in BIP 342 (which\n>>> defines the validation rules for Taproot scripts) which has allowed these\n>>> unintended consequences?\n>>>\n>>> An alternative would be to enforce this \"censorship\" at the node level\n>>> and introduce a run-time option to instantly prune all non-standard Taproot\n>>> transactions. This will be easier to implement, but won't hit the road\n>>> until minimum next release.\n>>>\n>>> I know that some people will have their criticisms about this,\n>>> absolutists/libertarians/maximum-freedom advocates, which is fine, but we\n>>> need to find a solution for this that fits everyone's common ground. We\n>>> indirectly allowed this to happen, which previously wasn't possible before.\n>>> So we also have a responsibility to do something to ensure that this kind\n>>> of congestion can never happen again using Taproot.\n>>>\n>>> -Ali\n>>>\n>>> ---\n>>>\n>>> [1]:\n>>> https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/\n>>> <https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/?outputType=amp>\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/76ba5981/attachment-0001.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2023-05-08T21:01:27",
                "message_text_only": "the more i think about it, the more that this is essential.   consider that\nbitcoin is secured by mining and mining is secured by fees.   all of that\nis relative to the value of bitcoin itself.   but consider the incentive\nfor a reorg if a single ordinal is worth 1 billion dollars and is being\ntransferred.  now all the incentive logic is thrown to the wind.\n non-monetary use is quite dangerous to network stability, and the game\ntheory underpinning it, imo.\n\nOn Mon, May 8, 2023 at 4:59\u202fPM Erik Aronesty <erik at q32.com> wrote:\n\n> > value you can from these Lightning channel(s) onchain even if it means\n> paying a higher fee than the amount you are receiving.\n>\n> in that case, you're not getting any value - you're losing value.   the\n> only benefit i could imagine would be to prevent the other party from\n> having access to the funds should the channel expire.\n>\n> regardless, this is an edge case.   it's clear that a utxo whose value is\n> less than the fee paid to move it is dust, and we already have plenty of\n> code to censor dust transactions\n>\n> > no reason to prevent\n>\n> the reason to prevent them is to prevent something that has more value\n> than the bitcoin itself from being stored on-chain.  that is to say:\n> real-estate ownership, nfts, or any other thing that isn't \"using bitcoin\n> as money\"\n>\n> by going at the \"incentive/economic layer\", rather than pointlessly\n> forcing brc-20 and ordinals users to obfuscate their transactions, we can\n> provide a permanent incentive to keep that stuff off of bitcoin\n>\n> personally, i'm not sure it's desirable to keep it off of bitcoin, but if\n> it is, the only sure way to disincentivize it is to go at it in this way or\n> similar\n>\n> i suspect all the opcode validation suggestions are just silly.   ordinals\n> can time their fork to the same moment, and store data in a less efficient,\n> but still functional, way using any number of mechanisms.   we've had\n> similar things posted on-chain since 2010 (my favorite was a software\n> license key - in an attempt to make bitcoin nodes illegal.   it's still in\n> there)\n>\n>\n> On Mon, May 8, 2023 at 4:36\u202fPM Michael Folkson <\n> michaelfolkson at protonmail.com> wrote:\n>\n>> > im unclear as to the purpose paying an onchain transaction fee greater\n>> than the amount receiving could possibly serve.\n>>\n>> If you expect fees to continue to rise and be sustained at abnormally\n>> high levels for a long period of time you might seek to close your\n>> Lightning channel(s) and move whatever value you can from these Lightning\n>> channel(s) onchain even if it means paying a higher fee than the amount you\n>> are receiving.\n>>\n>> I don't necessarily recommend doing this (it would depend on a number of\n>> factors, both personal and external) but there is no reason to prevent\n>> someone in say the consensus rules from doing this if they wish.\n>>\n>> --\n>> Michael Folkson\n>> Email: michaelfolkson at protonmail.com\n>> GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n>>\n>> Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n>>\n>> ------- Original Message -------\n>> On Monday, May 8th, 2023 at 20:47, Erik Aronesty <erik at q32.com> wrote:\n>>\n>> im unclear as to the purpose paying an onchain transaction fee greater\n>> than the amount receiving could possibly serve.\n>>\n>> what benefit do you get aside from losing bitcoin?\n>>\n>> are there any, non-theoretical, benefits to facilitating dust\n>> transactions?\n>>\n>> we could, of course, have it be non-consensus (no route dust) to start\n>> with\n>>\n>>\n>>\n>>\n>>\n>> On Mon, May 8, 2023 at 1:13\u202fPM Michael Folkson <\n>> michaelfolkson at protonmail.com> wrote:\n>>\n>>> > probably easier just to reject any transaction where the fee is\n>>> higher than the sum of the outputs\n>>>\n>>> And prevent perfectly reasonable transfers of value and attempted\n>>> Lightning channel closes during fee spikes? If I *want* to close my\n>>> Lightning channel during a protracted fee spike where I have to pay an\n>>> onchain transaction fee greater than the amount I am receiving you want to\n>>> stop me doing that? You are impinging on a valid use case as well as\n>>> requiring a consensus rule change.\n>>>\n>>> --\n>>> Michael Folkson\n>>> Email: michaelfolkson at protonmail.com\n>>> GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n>>>\n>>> Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n>>>\n>>> ------- Original Message -------\n>>> On Monday, May 8th, 2023 at 13:58, Erik Aronesty via bitcoin-dev <\n>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>> probably easier just to reject any transaction where the fee is higher\n>>> than the sum of the outputs\n>>>\n>>>\n>>>\n>>> On Mon, May 8, 2023, 7:55 AM Ali Sherief via bitcoin-dev <\n>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> Hi guys,\n>>>>\n>>>> I think everyone on this list knows what has happened to the Bitcoin\n>>>> mempool during the past 96 hours. Due to side projects such as BRC-20\n>>>> having such a high volume, real bitcoin transactions are being priced out\n>>>> and that is what is causing the massive congestion that has arguable not\n>>>> been seen since December 2017. I do not count the March 2021 congestion\n>>>> because that was only with 1-5sat/vbyte.\n>>>>\n>>>> Such justifiably worthless (\"worthless\" is not even my word - that's\n>>>> how its creator described them[1]) tokens threaten the smooth and normal\n>>>> use of the Bitcoin network as a peer-to-pear digital currency, as it was\n>>>> intended to be used as.\n>>>>\n>>>> If the volume does not die down over the next few weeks, should we take\n>>>> an action? The bitcoin network is a triumvirate of developers, miners, and\n>>>> users. Considering that miners are largely the entities at fault for\n>>>> allowing the system to be abused like this, the harmony of Bitcoin\n>>>> transactions is being disrupted right now. Although this community has a\n>>>> strong history of not putting its fingers into pies unless absolutely\n>>>> necessary - an example being during the block size wars and Segwit - should\n>>>> similar action be taken now, in the form of i) BIPs and/or ii) commits into\n>>>> the Bitcoin Core codebase, to curtail the loophole in BIP 342 (which\n>>>> defines the validation rules for Taproot scripts) which has allowed these\n>>>> unintended consequences?\n>>>>\n>>>> An alternative would be to enforce this \"censorship\" at the node level\n>>>> and introduce a run-time option to instantly prune all non-standard Taproot\n>>>> transactions. This will be easier to implement, but won't hit the road\n>>>> until minimum next release.\n>>>>\n>>>> I know that some people will have their criticisms about this,\n>>>> absolutists/libertarians/maximum-freedom advocates, which is fine, but we\n>>>> need to find a solution for this that fits everyone's common ground. We\n>>>> indirectly allowed this to happen, which previously wasn't possible before.\n>>>> So we also have a responsibility to do something to ensure that this kind\n>>>> of congestion can never happen again using Taproot.\n>>>>\n>>>> -Ali\n>>>>\n>>>> ---\n>>>>\n>>>> [1]:\n>>>> https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/\n>>>> <https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/?outputType=amp>\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>\n>>>\n>>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/978ca007/attachment-0001.html>"
            },
            {
                "author": "Tom Harding",
                "date": "2023-05-09T15:21:46",
                "message_text_only": "> And prevent perfectly reasonable transfers of value\n\n\nSuch a transfer can only be reasonable when off-chain value is attached \nto the coins.\u00a0 A rule like this is the embodiment of the philosophy that \nthe Bitcoin network is for onchain-economic transactions.\n\nParties could get around the rule by paying miners off-network, and that \nwould be an appropriate penalty for using non-onchain-economic transactions.\n\n\n\nOn 5/8/23 10:13, Michael Folkson via bitcoin-dev wrote:\n> > probably easier just to reject any transaction where the fee is \n> higher than the sum of the outputs\n>\n> And prevent perfectly reasonable transfers of value and attempted \n> Lightning channel closes during fee spikes? If I *want*\u200b to close my \n> Lightning channel during a protracted fee spike where I have to pay an \n> onchain transaction fee greater than the amount I am receiving you \n> want to stop me doing that? You are impinging on a valid use case as \n> well as requiring a consensus rule change.\n>\n> -- Michael Folkson\n> Email: michaelfolkson at protonmail.com <http://protonmail.com/>\n> GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n> Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n>\n> ------- Original Message -------\n> On Monday, May 8th, 2023 at 13:58, Erik Aronesty via bitcoin-dev \n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> probably easier just to reject any transaction where the fee is \n>> higher than the sum of the outputs\n>>\n>>\n>>\n>> On Mon, May 8, 2023, 7:55 AM Ali Sherief via bitcoin-dev \n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>     Hi guys,\n>>\n>>     I think everyone on this list knows what has happened to the\n>>     Bitcoin mempool during the past 96 hours. Due to side projects\n>>     such as BRC-20 having such a high volume, real bitcoin\n>>     transactions are being priced out and that is what is causing the\n>>     massive congestion that has arguable not been seen since December\n>>     2017. I do not count the March 2021 congestion because that was\n>>     only with 1-5sat/vbyte.\n>>\n>>     Such justifiably worthless (\"worthless\" is not even my word -\n>>     that's how its creator described them[1]) tokens threaten the\n>>     smooth and normal use of the Bitcoin network as a peer-to-pear\n>>     digital currency, as it was intended to be used as.\n>>\n>>     If the volume does not die down over the next few weeks, should\n>>     we take an action? The bitcoin network is a triumvirate of\n>>     developers, miners, and users. Considering that miners are\n>>     largely the entities at fault for allowing the system to be\n>>     abused like this, the harmony of Bitcoin transactions is being\n>>     disrupted right now. Although this community has a strong history\n>>     of not putting its fingers into pies unless absolutely necessary\n>>     - an example being during the block size wars and Segwit - should\n>>     similar action be taken now, in the form of i) BIPs and/or ii)\n>>     commits into the Bitcoin Core codebase, to curtail the loophole\n>>     in BIP 342 (which defines the validation rules for Taproot\n>>     scripts) which has allowed these unintended consequences?\n>>\n>>     An alternative would be to enforce this \"censorship\" at the node\n>>     level and introduce a run-time option to instantly prune all\n>>     non-standard Taproot transactions. This will be easier to\n>>     implement, but won't hit the road until minimum next release.\n>>\n>>     I know that some people will have their criticisms about this,\n>>     absolutists/libertarians/maximum-freedom advocates, which is\n>>     fine, but we need to find a solution for this that fits\n>>     everyone's common ground. We indirectly allowed this to happen,\n>>     which previously wasn't possible before. So we also have a\n>>     responsibility to do something to ensure that this kind of\n>>     congestion can never happen again using Taproot.\n>>\n>>     -Ali\n>>\n>>     ---\n>>\n>>     [1]:\n>>     https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/\n>>     <https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/?outputType=amp>\n>>     _______________________________________________\n>>     bitcoin-dev mailing list\n>>     bitcoin-dev at lists.linuxfoundation.org\n>>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230509/54e03016/attachment.html>"
            },
            {
                "author": "Melvin Carvalho",
                "date": "2023-05-08T16:37:07",
                "message_text_only": "po 8. 5. 2023 v 13:55 odes\u00edlatel Ali Sherief via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> napsal:\n\n> Hi guys,\n>\n> I think everyone on this list knows what has happened to the Bitcoin\n> mempool during the past 96 hours. Due to side projects such as BRC-20\n> having such a high volume, real bitcoin transactions are being priced out\n> and that is what is causing the massive congestion that has arguable not\n> been seen since December 2017. I do not count the March 2021 congestion\n> because that was only with 1-5sat/vbyte.\n>\n> Such justifiably worthless (\"worthless\" is not even my word - that's how\n> its creator described them[1]) tokens threaten the smooth and normal use of\n> the Bitcoin network as a peer-to-pear digital currency, as it was intended\n> to be used as.\n>\n> If the volume does not die down over the next few weeks, should we take an\n> action? The bitcoin network is a triumvirate of developers, miners, and\n> users. Considering that miners are largely the entities at fault for\n> allowing the system to be abused like this, the harmony of Bitcoin\n> transactions is being disrupted right now. Although this community has a\n> strong history of not putting its fingers into pies unless absolutely\n> necessary - an example being during the block size wars and Segwit - should\n> similar action be taken now, in the form of i) BIPs and/or ii) commits into\n> the Bitcoin Core codebase, to curtail the loophole in BIP 342 (which\n> defines the validation rules for Taproot scripts) which has allowed these\n> unintended consequences?\n>\n> An alternative would be to enforce this \"censorship\" at the node level and\n> introduce a run-time option to instantly prune all non-standard Taproot\n> transactions. This will be easier to implement, but won't hit the road\n> until minimum next release.\n>\n> I know that some people will have their criticisms about this,\n> absolutists/libertarians/maximum-freedom advocates, which is fine, but we\n> need to find a solution for this that fits everyone's common ground. We\n> indirectly allowed this to happen, which previously wasn't possible before.\n> So we also have a responsibility to do something to ensure that this kind\n> of congestion can never happen again using Taproot.\n>\n\nThis is a nuanced and sensitive topic that has been discussed previously,\nas far back as 2010, in a conversation between Gavin and Satoshi:\n\nhttps://bitcointalk.org/index.php?topic=195.msg1617#msg1617\n\nGavin: That's a cool feature until it gets popular and somebody decides it\nwould be fun to flood the payment network with millions of transactions to\ntransfer the latest Lady Gaga video to all their friends...\nSatoshi: That's one of the reasons for transaction fees.  There are other\nthings we can do if necessary.\n\nHigh fees could be viewed as disruptive to the network, but less disruptive\nthan regular large reorgs, or a network split.\n\nIt might be beneficial to brainstorm the \"other things we can do if\nnecessary\".\n\nA simple observation is that increasing the block size could make it more\nchallenging to spam, though it may come at the expense of some\ndecentralization.\n\n\n> -Ali\n>\n> ---\n>\n> [1]:\n> https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/\n> <https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/?outputType=amp>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/2b4d1b46/attachment-0001.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2023-05-08T22:37:34",
                "message_text_only": "Action should have been taken months ago. Spam filtration has been a \nstandard part of Bitcoin Core since day 1. It's a mistake that the \nexisting filters weren't extended to Taproot transactions. We can \naddress that, or try a more narrow approach like OP_RETURN (ie, what \n\"Ordisrespector\" does). Since this is a bugfix, it doesn't really even \nneed to wait for a major release.\n\n(We already have pruning. It's not an alternative to spam filtering.)\n\nLuke\n\n\nOn 5/7/23 13:22, Ali Sherief via bitcoin-dev wrote:\n> Hi guys,\n>\n> I think everyone on this list knows what has happened to the Bitcoin \n> mempool during the past 96 hours. Due to side projects such as BRC-20 \n> having such a high volume, real bitcoin transactions are being priced \n> out and that is what is causing the massive congestion that has \n> arguable not been seen since December 2017. I do not count the March \n> 2021 congestion because that was only with 1-5sat/vbyte.\n>\n> Such justifiably worthless (\"worthless\" is not even my word - that's \n> how its creator described them[1]) tokens threaten the smooth and \n> normal use of the Bitcoin network as a peer-to-pear digital currency, \n> as it was intended to be used as.\n>\n> If the volume does not die down over the next few weeks, should we \n> take an action? The bitcoin network is a triumvirate of developers, \n> miners, and users. Considering that miners are largely the entities at \n> fault for allowing the system to be abused like this, the harmony of \n> Bitcoin transactions is being disrupted right now. Although this \n> community has a strong history of not putting its fingers into pies \n> unless absolutely necessary - an example being during the block size \n> wars and Segwit - should similar action be taken now, in the form of \n> i) BIPs and/or ii) commits into the Bitcoin Core codebase, to curtail \n> the loophole in BIP 342 (which defines the validation rules for \n> Taproot scripts) which has allowed these unintended consequences?\n>\n> An alternative would be to enforce this \"censorship\" at the node level \n> and introduce a run-time option to instantly prune all non-standard \n> Taproot transactions. This will be easier to implement, but won't hit \n> the road until minimum next release.\n>\n> I know that some people will have their criticisms about this, \n> absolutists/libertarians/maximum-freedom advocates, which is fine, but \n> we need to find a solution for this that fits everyone's common \n> ground. We indirectly allowed this to happen, which previously wasn't \n> possible before. So we also have a responsibility to do something to \n> ensure that this kind of congestion can never happen again using Taproot.\n>\n> -Ali\n>\n> ---\n>\n> [1]: \n> https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/ \n> <https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/?outputType=amp>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/6fa702e3/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2023-05-09T00:02:51",
                "message_text_only": "On Mon, May 08, 2023 at 06:37:34PM -0400, Luke Dashjr via bitcoin-dev wrote:\n> Action should have been taken months ago. Spam filtration has been a\n> standard part of Bitcoin Core since day 1. It's a mistake that the existing\n> filters weren't extended to Taproot transactions. We can address that, or\n> try a more narrow approach like OP_RETURN (ie, what \"Ordisrespector\" does).\n> Since this is a bugfix, it doesn't really even need to wait for a major\n> release.\n\nMiners are making millions of dollars from these inscription transactions.\nMiners can and do run their own nodes and interconnect to each other. Many\npeople like myself will continue to run nodes that do not attempt to block\ninscriptions. And of course, the current flood of BRC-20 transactions embed\nvery little data in the chain per transaction and could easily be adapted to\nuse OP_RETURN or any number of other data embedding schemes; if they were\nmodified to embed no data at all they wouldn't be much smaller, and I'm sure\nyou'd still be complaining that they were spam.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230509/a70a0c54/attachment.sig>"
            },
            {
                "author": "Ali Sherief",
                "date": "2023-05-09T01:43:09",
                "message_text_only": "Hey guys,\n\nI'm more of the opinion that if this particular format the spam transactions are using is addressed, it will not only cause the mempool to relax, but it will also give us time to regroup and work on Layer 2 before the next onslaught of spam transactions using a (slightly) different format begins.\n\n-Ali\n\nOn Tue, May 9, 2023 at 3:02 AM, Peter Todd <pete at petertodd.org> wrote:\n\n> On Mon, May 08, 2023 at 06:37:34PM -0400, Luke Dashjr via bitcoin-dev wrote:\n>> Action should have been taken months ago. Spam filtration has been a\n>> standard part of Bitcoin Core since day 1. It's a mistake that the existing\n>> filters weren't extended to Taproot transactions. We can address that, or\n>> try a more narrow approach like OP_RETURN (ie, what \"Ordisrespector\" does).\n>> Since this is a bugfix, it doesn't really even need to wait for a major\n>> release.\n>\n> Miners are making millions of dollars from these inscription transactions.\n> Miners can and do run their own nodes and interconnect to each other. Many\n> people like myself will continue to run nodes that do not attempt to block\n> inscriptions. And of course, the current flood of BRC-20 transactions embed\n> very little data in the chain per transaction and could easily be adapted to\n> use OP_RETURN or any number of other data embedding schemes; if they were\n> modified to embed no data at all they wouldn't be much smaller, and I'm sure\n> you'd still be complaining that they were spam.\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230509/9f3282f4/attachment-0001.html>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2023-05-09T16:32:09",
                "message_text_only": ">\n>\n> > no data at all\n\n\nexactly, which is why a relationship between \"cpfp-inclusive outputs\" and\n\"fees\" makes sense.   it's clear that's a good definition of dust, and not\ntoo hard to get a working pr up for the network-layer.   i get that your\nnode will still route.   i get that it would break timestamps, indeed, it\nwould break all non-economic use cases if we made it a consensus change.\n\nbut that's the point of the discussion.\n\nthe question is whether breaking all non-economic use cases is the right\nmove, given the game-theory of what underpins bitcoin\n\ni'm sad (honestly) to say that it might be\n\nit may very well be that bitcoin *cannot* be a \"global ledger of all\nthings\" in order to remain useful and decentralized, and instead the\nmonetary use case must be it's only goal\n\nalso, i'm not really advocating for this solution so much as i would like a\n\n- rational conversation about the incentives\n- whether this solution would be an effective enough barrier to keep most\nnon-economic tx off bitcoin\n\nobviously it's easy enough to evade if every non-economic user simply keeps\nenough bitcoin around and sends it back to himself\n\nso maybe it's a useless idea?   but maybe that's enough of a hassle to stop\npeople (it certainly breaks ordinals, since it can never be 1 sat)\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230509/d7ecc659/attachment-0001.html>"
            },
            {
                "author": "Tom Harding",
                "date": "2023-05-09T21:06:00",
                "message_text_only": "On 5/9/23 09:32, Erik Aronesty via bitcoin-dev wrote:\n\n> obviously it's easy enough to evade if every non-economic user simply  > keeps enough bitcoin around and sends it back to himself > > so \nmaybeit's a useless idea? but maybe that's enough of a hassle to stop > \npeople (it certainly breaks ordinals, since it can never be 1 sat)\n\nPadding the change is not just a hassle, it requires holding extra BTC \nin a hot wallet, which has a cost.\n\nSpenders could also get around the rule by paying miners off-network, \nbut having to do so would be an appropriate penalty for broadcasting a \nnon-economic transaction."
            },
            {
                "author": "Keagan McClelland",
                "date": "2023-05-10T20:44:05",
                "message_text_only": "Erik,\n\nI'm curious about what you believe to be \"non-economic\" txs. As far as I\ncan tell, any transaction included in the blockchain is economically\nmotivated by the very evidence of fees paid. That said, for the sake of\nargument if we assume that there exists a category of information that\nconstitutes \"non-economic\" information, then so long as there is any\nvariance in the way to express a single economic intention, there exists a\nvector for including \"non-economic\" information. I'll add beyond this that\nthere must always be variance in the way to express the same intent because\nthe signature data must be indistinguishable from entropy for Bitcoin's\nsecurity to hold.\n\nEven if we eliminate small UTXOs, OP_RETURN, or whatever other vector of\nthe day that is currently being used to propagate such \"non-economic\"\ninformation, we will always have the potential variance in the signature\ndata to do so. The best you can hope for is to make such means so\ninefficient that the real cost-per-bit is expensive enough that there are\nfewer distinct use cases. However, this isn't enough to actually *prevent*\nthe \"spam\". By increasing the cost-per-bit, it may limit it to only\n\"non-economic\" information of extremely high value (note the\ncontradiction), it limits the number of use cases while also increasing the\nimpact of the use cases that make it past that threshold. Thus, it isn't\nthe impact of spam that is being reduced so much as it is reducing the\nnumber of distinct use cases that result in \"spam\". Perhaps this is enough\nto make spam more intermittent, and maybe on those grounds alone it could\nbe worth it, but I doubt it.\n\nIMO the proper way to handle things like this isn't to introduce consensus\nor relay policy to incentivize the expansion of the chain weight these\n\"non-economic\" use cases require, but rather to reduce the necessary chain\nfootprint of supposed \"economically motivated\" transactions, which\nincidentally is the entire point of all layered scaling tech. The current\nfees we are experiencing are still significantly lower than they need to be\nif Bitcoin is going to survive in a post-subsidy era. If our layered\nprotocols can't survive the current fee environment, the answer is to fix\nthe layered protocols.\n\nFood for thought.\n\nStay Inspired,\nKeags\n\nOn Tue, May 9, 2023 at 12:38\u202fPM Erik Aronesty via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n>> > no data at all\n>\n>\n> exactly, which is why a relationship between \"cpfp-inclusive outputs\" and\n> \"fees\" makes sense.   it's clear that's a good definition of dust, and not\n> too hard to get a working pr up for the network-layer.   i get that your\n> node will still route.   i get that it would break timestamps, indeed, it\n> would break all non-economic use cases if we made it a consensus change.\n>\n> but that's the point of the discussion.\n>\n> the question is whether breaking all non-economic use cases is the right\n> move, given the game-theory of what underpins bitcoin\n>\n> i'm sad (honestly) to say that it might be\n>\n> it may very well be that bitcoin *cannot* be a \"global ledger of all\n> things\" in order to remain useful and decentralized, and instead the\n> monetary use case must be it's only goal\n>\n> also, i'm not really advocating for this solution so much as i would like\n> a\n>\n> - rational conversation about the incentives\n> - whether this solution would be an effective enough barrier to keep most\n> non-economic tx off bitcoin\n>\n> obviously it's easy enough to evade if every non-economic user simply\n> keeps enough bitcoin around and sends it back to himself\n>\n> so maybe it's a useless idea?   but maybe that's enough of a hassle to\n> stop people (it certainly breaks ordinals, since it can never be 1 sat)\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230510/f3213116/attachment.html>"
            },
            {
                "author": "jk_14 at op.pl",
                "date": "2023-05-09T08:41:13",
                "message_text_only": "Ok, I need to highlight one important thing well proven by this discussion (like it or not)...\n\nNot the spam itself is the real reason of feeling: \"something must be done\"\nThe reason is: $30 fee per transaction (I hope you all agree)\n\n\nLet me paraphrase some quotes used in this discussion, then:\n\n1. Lack of block subsidy long term and necessity of $40 tx fee to compensate it - \"threaten the smooth and normal use of the Bitcoin network as a peer-to-pear digital currency, as it was intended to be used as.\"\n\n2. \"the harmony of Bitcoin transactions is being disrupted right now\" due to lack of block subsidy and due to exorbitant $40 tx fees as an effect necessary to keep the network security untouched\n\n3. \"Fee spikes aren't fun\" and it's obvious that keeping the network security only on enormous tx fees of active users and having passive users as free-riders - isn't fun, too\n\n4. by ignoring Bitcoin long-term security budget problem - \"we indirectly allowed this to happen, which previously wasn't possible before. So we also have a responsibility to do something to ensure that this kind of tremendous $40 tx fees can never happen again\"\n\n5. \"Action against exorbitant fees should have been taken months ago. (...) It's a mistake that the\" tail emission or other necessary solution - weren't implemented on time\n\n6. \"we need to find a solution for long-term horrible fees problem - that fits everyone's common ground.\"\n\n\nYes, we need - instead of being still in a heavy denial state.\n\nNo additional comment then, except this little one:\nDelay of halving in case of 4 years long network difficulty regression situation.\n\n\nRegards,\nJaroslaw\n\n\n\n\n\nW dniu 2023-05-09 00:37:57 u\u017cytkownik Luke Dashjr via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> napisa\u0142:\n\nAction should have been taken months ago. Spam filtration has been a standard part of Bitcoin Core since day 1. It's a mistake that the existing filters weren't extended to Taproot transactions. We can address that, or try a more narrow approach like OP_RETURN (ie, what \"Ordisrespector\" does). Since this is a bugfix, it doesn't really even need to wait for a major release.\n\n(We already have pruning. It's not an alternative to spam filtering.)\n\nLuke\n\n\n\n\nOn 5/7/23 13:22, Ali Sherief via bitcoin-dev wrote:\nHi guys,\n\n\nI think everyone on this list knows what has happened to the Bitcoin mempool during the past 96 hours. Due to side projects such as BRC-20 having such a high volume, real bitcoin transactions are being priced out and that is what is causing the massive congestion that has arguable not been seen since December 2017. I do not count the March 2021 congestion because that was only with 1-5sat/vbyte.\n\n\nSuch justifiably worthless (\"worthless\" is not even my word - that's how its creator described them[1]) tokens threaten the smooth and normal use of the Bitcoin network as a peer-to-pear digital currency, as it was intended to be used as.\n\n\nIf the volume does not die down over the next few weeks, should we take an action? The bitcoin network is a triumvirate of developers, miners, and users. Considering that miners are largely the entities at fault for allowing the system to be abused like this, the harmony of Bitcoin transactions is being disrupted right now. Although this community has a strong history of not putting its fingers into pies unless absolutely necessary - an example being during the block size wars and Segwit - should similar action be taken now, in the form of i) BIPs and/or ii) commits into the Bitcoin Core codebase, to curtail the loophole in BIP 342 (which defines the validation rules for Taproot scripts) which has allowed these unintended consequences?\n\n\nAn alternative would be to enforce this \"censorship\" at the node level and introduce a run-time option to instantly prune all non-standard Taproot transactions. This will be easier to implement, but won't hit the road until minimum next release.\n\n\nI know that some people will have their criticisms about this, absolutists/libertarians/maximum-freedom advocates, which is fine, but we need to find a solution for this that fits everyone's common ground. We indirectly allowed this to happen, which previously wasn't possible before. So we also have a responsibility to do something to ensure that this kind of congestion can never happen again using Taproot.\n\n\n-Ali\n\n\n---\n\n\n[1]:\u00a0https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/\n\n\n\n\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Erik Aronesty",
                "date": "2023-05-09T12:50:03",
                "message_text_only": "I would like to point out that I'm not an advocate for doing anything at\nthis point aside from working on l2\n\njust to make it inconvenient for people\n\nI just think the discussion of outputs and fees is interesting and related\nto the game theory portion of Bitcoin\n\n\n\nOn Tue, May 9, 2023, 8:23 AM Jaroslaw via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n>\n> Ok, I need to highlight one important thing well proven by this discussion\n> (like it or not)...\n>\n> Not the spam itself is the real reason of feeling: \"something must be done\"\n> The reason is: $30 fee per transaction (I hope you all agree)\n>\n>\n> Let me paraphrase some quotes used in this discussion, then:\n>\n> 1. Lack of block subsidy long term and necessity of $40 tx fee to\n> compensate it - \"threaten the smooth and normal use of the Bitcoin network\n> as a peer-to-pear digital currency, as it was intended to be used as.\"\n>\n> 2. \"the harmony of Bitcoin transactions is being disrupted right now\" due\n> to lack of block subsidy and due to exorbitant $40 tx fees as an effect\n> necessary to keep the network security untouched\n>\n> 3. \"Fee spikes aren't fun\" and it's obvious that keeping the network\n> security only on enormous tx fees of active users and having passive users\n> as free-riders - isn't fun, too\n>\n> 4. by ignoring Bitcoin long-term security budget problem - \"we indirectly\n> allowed this to happen, which previously wasn't possible before. So we also\n> have a responsibility to do something to ensure that this kind of\n> tremendous $40 tx fees can never happen again\"\n>\n> 5. \"Action against exorbitant fees should have been taken months ago.\n> (...) It's a mistake that the\" tail emission or other necessary solution -\n> weren't implemented on time\n>\n> 6. \"we need to find a solution for long-term horrible fees problem - that\n> fits everyone's common ground.\"\n>\n>\n> Yes, we need - instead of being still in a heavy denial state.\n>\n> No additional comment then, except this little one:\n> Delay of halving in case of 4 years long network difficulty regression\n> situation.\n>\n>\n> Regards,\n> Jaroslaw\n>\n>\n>\n>\n>\n> W dniu 2023-05-09 00:37:57 u\u017cytkownik Luke Dashjr via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> napisa\u0142:\n>\n> Action should have been taken months ago. Spam filtration has been a\n> standard part of Bitcoin Core since day 1. It's a mistake that the existing\n> filters weren't extended to Taproot transactions. We can address that, or\n> try a more narrow approach like OP_RETURN (ie, what \"Ordisrespector\" does).\n> Since this is a bugfix, it doesn't really even need to wait for a major\n> release.\n>\n> (We already have pruning. It's not an alternative to spam filtering.)\n>\n> Luke\n>\n>\n>\n>\n> On 5/7/23 13:22, Ali Sherief via bitcoin-dev wrote:\n> Hi guys,\n>\n>\n> I think everyone on this list knows what has happened to the Bitcoin\n> mempool during the past 96 hours. Due to side projects such as BRC-20\n> having such a high volume, real bitcoin transactions are being priced out\n> and that is what is causing the massive congestion that has arguable not\n> been seen since December 2017. I do not count the March 2021 congestion\n> because that was only with 1-5sat/vbyte.\n>\n>\n> Such justifiably worthless (\"worthless\" is not even my word - that's how\n> its creator described them[1]) tokens threaten the smooth and normal use of\n> the Bitcoin network as a peer-to-pear digital currency, as it was intended\n> to be used as.\n>\n>\n> If the volume does not die down over the next few weeks, should we take an\n> action? The bitcoin network is a triumvirate of developers, miners, and\n> users. Considering that miners are largely the entities at fault for\n> allowing the system to be abused like this, the harmony of Bitcoin\n> transactions is being disrupted right now. Although this community has a\n> strong history of not putting its fingers into pies unless absolutely\n> necessary - an example being during the block size wars and Segwit - should\n> similar action be taken now, in the form of i) BIPs and/or ii) commits into\n> the Bitcoin Core codebase, to curtail the loophole in BIP 342 (which\n> defines the validation rules for Taproot scripts) which has allowed these\n> unintended consequences?\n>\n>\n> An alternative would be to enforce this \"censorship\" at the node level and\n> introduce a run-time option to instantly prune all non-standard Taproot\n> transactions. This will be easier to implement, but won't hit the road\n> until minimum next release.\n>\n>\n> I know that some people will have their criticisms about this,\n> absolutists/libertarians/maximum-freedom advocates, which is fine, but we\n> need to find a solution for this that fits everyone's common ground. We\n> indirectly allowed this to happen, which previously wasn't possible before.\n> So we also have a responsibility to do something to ensure that this kind\n> of congestion can never happen again using Taproot.\n>\n>\n> -Ali\n>\n>\n> ---\n>\n>\n> [1]:\n> https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/\n>\n>\n>\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230509/c994e465/attachment.html>"
            },
            {
                "author": "Weiji Guo",
                "date": "2023-05-10T03:08:15",
                "message_text_only": "> I would like to point out that I'm not an advocate for doing anything at\nthis point aside from working on l2\n\nSpeaking of L2, I had recently proposed a new opcode OP_ZKP to enable\npayments based on ZKP proof. I wonder if it has drawn enough attention but\nit seems to me a viable way to address transaction fee issues, in addition\nto enabling more smart contracts. And it will be a Bitcoin native L2, not a\nside chain, not pegging.\n\n      scriptPubKey: <hash of the verification key> <scheme_id> OP_ZKP\n      scriptSig:         <pubInput_1> <pubInput_2> ... <pubInput_n> <n>\n<proof>\n\nI haven't figured out how to use OP_ZKP to incentivize BRC-20, inscription\netc. to move to L2. But I like to bring it up here and I am open to your\nfeedback and comments.\n\nThanks,\nWeiji\n\nOn Tue, May 9, 2023 at 8:51\u202fPM Erik Aronesty via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I would like to point out that I'm not an advocate for doing anything at\n> this point aside from working on l2\n>\n> just to make it inconvenient for people\n>\n> I just think the discussion of outputs and fees is interesting and related\n> to the game theory portion of Bitcoin\n>\n>\n>\n> On Tue, May 9, 2023, 8:23 AM Jaroslaw via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>>\n>>\n>> Ok, I need to highlight one important thing well proven by this\n>> discussion (like it or not)...\n>>\n>> Not the spam itself is the real reason of feeling: \"something must be\n>> done\"\n>> The reason is: $30 fee per transaction (I hope you all agree)\n>>\n>>\n>> Let me paraphrase some quotes used in this discussion, then:\n>>\n>> 1. Lack of block subsidy long term and necessity of $40 tx fee to\n>> compensate it - \"threaten the smooth and normal use of the Bitcoin network\n>> as a peer-to-pear digital currency, as it was intended to be used as.\"\n>>\n>> 2. \"the harmony of Bitcoin transactions is being disrupted right now\" due\n>> to lack of block subsidy and due to exorbitant $40 tx fees as an effect\n>> necessary to keep the network security untouched\n>>\n>> 3. \"Fee spikes aren't fun\" and it's obvious that keeping the network\n>> security only on enormous tx fees of active users and having passive users\n>> as free-riders - isn't fun, too\n>>\n>> 4. by ignoring Bitcoin long-term security budget problem - \"we indirectly\n>> allowed this to happen, which previously wasn't possible before. So we also\n>> have a responsibility to do something to ensure that this kind of\n>> tremendous $40 tx fees can never happen again\"\n>>\n>> 5. \"Action against exorbitant fees should have been taken months ago.\n>> (...) It's a mistake that the\" tail emission or other necessary solution -\n>> weren't implemented on time\n>>\n>> 6. \"we need to find a solution for long-term horrible fees problem - that\n>> fits everyone's common ground.\"\n>>\n>>\n>> Yes, we need - instead of being still in a heavy denial state.\n>>\n>> No additional comment then, except this little one:\n>> Delay of halving in case of 4 years long network difficulty regression\n>> situation.\n>>\n>>\n>> Regards,\n>> Jaroslaw\n>>\n>>\n>>\n>>\n>>\n>> W dniu 2023-05-09 00:37:57 u\u017cytkownik Luke Dashjr via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> napisa\u0142:\n>>\n>> Action should have been taken months ago. Spam filtration has been a\n>> standard part of Bitcoin Core since day 1. It's a mistake that the existing\n>> filters weren't extended to Taproot transactions. We can address that, or\n>> try a more narrow approach like OP_RETURN (ie, what \"Ordisrespector\" does).\n>> Since this is a bugfix, it doesn't really even need to wait for a major\n>> release.\n>>\n>> (We already have pruning. It's not an alternative to spam filtering.)\n>>\n>> Luke\n>>\n>>\n>>\n>>\n>> On 5/7/23 13:22, Ali Sherief via bitcoin-dev wrote:\n>> Hi guys,\n>>\n>>\n>> I think everyone on this list knows what has happened to the Bitcoin\n>> mempool during the past 96 hours. Due to side projects such as BRC-20\n>> having such a high volume, real bitcoin transactions are being priced out\n>> and that is what is causing the massive congestion that has arguable not\n>> been seen since December 2017. I do not count the March 2021 congestion\n>> because that was only with 1-5sat/vbyte.\n>>\n>>\n>> Such justifiably worthless (\"worthless\" is not even my word - that's how\n>> its creator described them[1]) tokens threaten the smooth and normal use of\n>> the Bitcoin network as a peer-to-pear digital currency, as it was intended\n>> to be used as.\n>>\n>>\n>> If the volume does not die down over the next few weeks, should we take\n>> an action? The bitcoin network is a triumvirate of developers, miners, and\n>> users. Considering that miners are largely the entities at fault for\n>> allowing the system to be abused like this, the harmony of Bitcoin\n>> transactions is being disrupted right now. Although this community has a\n>> strong history of not putting its fingers into pies unless absolutely\n>> necessary - an example being during the block size wars and Segwit - should\n>> similar action be taken now, in the form of i) BIPs and/or ii) commits into\n>> the Bitcoin Core codebase, to curtail the loophole in BIP 342 (which\n>> defines the validation rules for Taproot scripts) which has allowed these\n>> unintended consequences?\n>>\n>>\n>> An alternative would be to enforce this \"censorship\" at the node level\n>> and introduce a run-time option to instantly prune all non-standard Taproot\n>> transactions. This will be easier to implement, but won't hit the road\n>> until minimum next release.\n>>\n>>\n>> I know that some people will have their criticisms about this,\n>> absolutists/libertarians/maximum-freedom advocates, which is fine, but we\n>> need to find a solution for this that fits everyone's common ground. We\n>> indirectly allowed this to happen, which previously wasn't possible before.\n>> So we also have a responsibility to do something to ensure that this kind\n>> of congestion can never happen again using Taproot.\n>>\n>>\n>> -Ali\n>>\n>>\n>> ---\n>>\n>>\n>> [1]:\n>> https://www.coindesk.com/consensus-magazine/2023/05/05/pump-the-brcs-the-promise-and-peril-of-bitcoin-backed-tokens/\n>>\n>>\n>>\n>>\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230510/fa7b3d30/attachment.html>"
            },
            {
                "author": "Aleksandr Kwaskoff",
                "date": "2023-05-11T13:12:22",
                "message_text_only": "if we forget about backward compatibility and the impact of other types of\ntransactions, then the following two options would be possible:\na) allocate only up to 10% of the space in the block for non-standard\ntransactions - then all senders of non-standard transactions will compete\nwith each other and it's only 10% with other types of transactions. In the\nabsence of non-standard transactions, all space of the block will be given\nto standard ones. And in the absence of standard transactions - all space\nof the block will be given to non-standard ones. If bitcoin-chain was\ncreated primarily for standard transactions, then such a model will have to\nbe supported by the majority.\nb) change the architecture in such a way that the onchain ordinals\ntransaction became much more expensive, which would force them to go to\ntheir own type of the LN - this would be a kind of justice, like the\ndisplacement of small transactions from the onchain to the LN happening\nalready now\n\n\n-- \n\nThank you, we will succeed! | Dzi\u0119kujemy, uda nam si\u0119!\n\nPresident of NGO FinTechAssociation | Prezes organizacji pozarz\u0105dowej\nFinTechStowarzyszenie\n\n*Dipl.-Ing. *Aleksandr Kwaskoff\n\nTelegram t.me/kwaskoff\n\nPoland, Warsaw | Polska, Warszawa\n\n\n\n\n\n[image: --]\n\nPresident of NGO FinTechAssociation <http://t.me/finteh>\n\nAleksandr Kwaskoff\n[image: https://]about.me/kwaskoff\n<https://about.me/kwaskoff?promo=email_sig&utm_source=email_sig&utm_medium=email_sig&utm_campaign=external_links>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230511/b83c2b82/attachment.html>"
            },
            {
                "author": "jk_14 at op.pl",
                "date": "2023-05-12T09:36:57",
                "message_text_only": "W dniu 2023-05-11 13:57:11 u\u017cytkownik Keagan McClelland via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> napisa\u0142:\n\n> The current fees we are experiencing are still significantly lower than they need to be if Bitcoin is going to survive in a post-subsidy era. If our layered protocols can't survive the current fee environment, the answer is to fix the layered protocols.\n\n\nI also believe that this discussion should be expanded to the problem of Bitcoin's survival in the post-subsidy era, because it's very related, i.e. also directly related to the high transaction fees. The only difference is that the current $30 fee situation is probably temporary, and the future $40 (today's price tag) fee situation in post-subsidy era will be hopeless for change other than to reduce the difficulty of the network and hence its security and the marketcap/price in the end of day.\n\nBecause if the current network hashrate (current level of security) would drop e.g. to half of what it was in the past - the Store-of-Value feature simply collapse, while it's one of the most important (if not: the most important) long term feature of Bitcoin and as such advertised...\nIf you really care about SoV - you can't accept network security regression. Period.\n\nI am a committed supporter of the free market. And Bitcoin is not the e-mail system, where sending is free and therefore spam which costs nothing to the sender - becomes a problem. In Bitcoin, every transaction costs - and in such a situation, distinguishing paid transactions into the good ones and the bad ones - would be a mistake and contradict the idea of the free market.\n\nWe should not interfere where the free market intervenes: the same way how small transfers are migrating to LN, the same way \"non-economic\", low value informations will migrate to Layer2 (RGB, Taro or maybe something else yet)\n\nBut, we should intervene there, where there is no free market. And I am not alone in alarming that there is such a place in Bitcoin.\nIn the post-subsidy era There Is No Free Market between: active users (overtaxed) and pasive users (free riders).\n\nOne of possible (very conservative) option to introduce free market there - is to delay halving in case of 4 years network difficulty regression situation.\nSuch a long-term regression of network difficulty means nothing else that transaction revenue from active users is not able to fund current network security anymore for both active and passive users. Delaying of halving is simply: not introducing additional more damage to the network security (really conservative approach)\nAnother option is: demurrage (but I'm not very sure it will work fine, at least before \"hyperbitcoinzation\")\n\nAgain, from my almost 50yo experience:\nBitcoin network difficulty can be more-less constant or can be slightly increasing (both options are \"good for Bitcoin\") but we should do our best - to avoid the network security regression.\nI did.\n\n\nRegards\nJaroslaw\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            }
        ],
        "thread_summary": {
            "title": "Should we as developers reject non-standard Taproot transactions from full nodes?",
            "categories": [
                "bitcoin-dev",
                "Mempool spam"
            ],
            "authors": [
                "jk_14 at op.pl",
                "Weiji Guo",
                "Michael Folkson",
                "Ali Sherief",
                "Keagan McClelland",
                "Aleksandr Kwaskoff",
                "Peter Todd",
                "Erik Aronesty",
                "Luke Dashjr",
                "Melvin Carvalho",
                "Tom Harding"
            ],
            "messages_count": 22,
            "total_messages_chars_count": 88168
        }
    },
    {
        "title": "[bitcoin-dev] tx max fee",
        "thread_messages": [
            {
                "author": "Erik Aronesty",
                "date": "2023-05-07T23:59:40",
                "message_text_only": "possible to change tx \"max fee\"  to output amounts?\n\nseems like the only use case that would support such a tx is spam/dos type\nstuff that satoshi warned about\n\nits not a fix for everything, but it seems could help a bit with certain\nattacks\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230507/0be17aef/attachment-0001.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2023-05-08T23:57:59",
                "message_text_only": "On Sun, May 07, 2023 at 07:59:40PM -0400, Erik Aronesty via bitcoin-dev wrote:\n> possible to change tx \"max fee\"  to output amounts?\n> \n> seems like the only use case that would support such a tx is spam/dos type\n> stuff that satoshi warned about\n> \n> its not a fix for everything, but it seems could help a bit with certain\n> attacks\n\nWith CPFP it often makes sense for a transaction to have a fee larger than the\noutput amounts.\n\nThis proposal would also screw over applications like my OpenTimestamps\nservice.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/b9252c85/attachment-0001.sig>"
            },
            {
                "author": "Erik Aronesty",
                "date": "2023-05-09T00:04:19",
                "message_text_only": "fair.   i suppose you could support cpfp in any dust filtering.   im not a\nfan, but I think its the only legit way to defend the chain from non money\nuse cases\n\nOn Mon, May 8, 2023, 7:58 PM Peter Todd <pete at petertodd.org> wrote:\n\n> On Sun, May 07, 2023 at 07:59:40PM -0400, Erik Aronesty via bitcoin-dev\n> wrote:\n> > possible to change tx \"max fee\"  to output amounts?\n> >\n> > seems like the only use case that would support such a tx is spam/dos\n> type\n> > stuff that satoshi warned about\n> >\n> > its not a fix for everything, but it seems could help a bit with certain\n> > attacks\n>\n> With CPFP it often makes sense for a transaction to have a fee larger than\n> the\n> output amounts.\n>\n> This proposal would also screw over applications like my OpenTimestamps\n> service.\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/ef79bcc2/attachment.html>"
            },
            {
                "author": "vjudeu at gazeta.pl",
                "date": "2023-05-10T16:19:01",
                "message_text_only": "> possible to change tx \"max fee\"  to output amounts?\n\nIs it possible? Yes. Should we do that? My first thought was \"maybe\", but after thinking more about it, I would say \"no\", here is why:\n\nStarting point: 1 BTC on some output.\nCurrent situation: A single transaction moving 0.99999000 BTC as fees, and creating 1000 satoshis as some output (I know, allowed dust values are lower and depend on address type, but let's say it is 1k sats to make things simpler).\n\nAnd then, there is a room for other solutions, for example your rule, mentioned in other posts, like this one: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-May/021626.html\n\n> probably easier just to reject any transaction where the fee is higher than the sum of the outputs\n\nPossible situation after introducing your proposal, step-by-step:\n\n1) Someone wants to move 1 BTC, and someone wants to pay 0.99999000 BTC as fees. Assuming your rules are on consensus level, the first transaction creates 0.5 BTC output and 0.5 BTC fee.\n2) That person still wants to move 0.5 remaining BTC, and still is willing to pay 0.49999000 BTC as fees. Guess what will happen: you will see another transaction, creating 0.25 BTC output, and paying 0.25 BTC fee.\n...\nN) Your proposal replaced one transaction, consuming maybe one kilobyte, with a lot of transactions, doing exactly the same, but where fees are distributed between many transactions.\n\nBefore thinking about improving that system, consider one simple thing: is it possible to avoid \"max fee rule\", no matter in what way it will be defined? Because as shown above, the answer seems to be \"yes\", because you can always replace a single transaction moving 1 BTC as fees with multiple transactions, each paying one satoshi per virtual byte, and then instead of consuming around one kilobyte, it would consume around 1 MvB per 0.01 BTC, so 100 MvB per 1 BTC mentioned in the example above.\n\n\n\nOn 2023-05-08 13:55:18 user Erik Aronesty via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\npossible to change tx \"max fee\"\u00a0 to output amounts?\n\n\nseems like the only use case that would support such a tx is spam/dos type stuff that satoshi warned about\n\n\nits not a fix for everything, but it seems could help a bit with certain attacks"
            },
            {
                "author": "Erik Aronesty",
                "date": "2023-05-10T17:42:37",
                "message_text_only": "confused.   the rule was \"cannot pay a fee > sum of outputs with\nconsideration of cpfp in the mempool\"\n\nyour example is of someone paying a fee \"< sum\"  which wouldn't be blocked\n\nnote: again, i'm not a fan of this, i like the discussion of \"bitcoin as\nmoney only\" and using fee as a lever to do that\n\nshow me how someone could move 1 btc and pay 2 btc as fees... i think we\ncan block it at the network or even the consensus layer, and leave anything\nbut \"non-monetary use cases\" intact.   the only way around it is to\nmaintain balances and use change addresses.   which would force nft and\ntimestamp users to maintain these balances and would be a deterrent\n\nim am much more in favor of doing something like op_ctv which allows many\nusers to pool fees and essentially \"share\" a single utxo.\n.\n\n\nOn Wed, May 10, 2023 at 12:19\u202fPM <vjudeu at gazeta.pl> wrote:\n\n> > possible to change tx \"max fee\"  to output amounts?\n>\n> Is it possible? Yes. Should we do that? My first thought was \"maybe\", but\n> after thinking more about it, I would say \"no\", here is why:\n>\n> Starting point: 1 BTC on some output.\n> Current situation: A single transaction moving 0.99999000 BTC as fees, and\n> creating 1000 satoshis as some output (I know, allowed dust values are\n> lower and depend on address type, but let's say it is 1k sats to make\n> things simpler).\n>\n> And then, there is a room for other solutions, for example your rule,\n> mentioned in other posts, like this one:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-May/021626.html\n>\n> > probably easier just to reject any transaction where the fee is higher\n> than the sum of the outputs\n>\n> Possible situation after introducing your proposal, step-by-step:\n>\n> 1) Someone wants to move 1 BTC, and someone wants to pay 0.99999000 BTC as\n> fees. Assuming your rules are on consensus level, the first transaction\n> creates 0.5 BTC output and 0.5 BTC fee.\n> 2) That person still wants to move 0.5 remaining BTC, and still is willing\n> to pay 0.49999000 BTC as fees. Guess what will happen: you will see another\n> transaction, creating 0.25 BTC output, and paying 0.25 BTC fee.\n> ...\n> N) Your proposal replaced one transaction, consuming maybe one kilobyte,\n> with a lot of transactions, doing exactly the same, but where fees are\n> distributed between many transactions.\n>\n> Before thinking about improving that system, consider one simple thing: is\n> it possible to avoid \"max fee rule\", no matter in what way it will be\n> defined? Because as shown above, the answer seems to be \"yes\", because you\n> can always replace a single transaction moving 1 BTC as fees with multiple\n> transactions, each paying one satoshi per virtual byte, and then instead of\n> consuming around one kilobyte, it would consume around 1 MvB per 0.01 BTC,\n> so 100 MvB per 1 BTC mentioned in the example above.\n>\n>\n>\n> On 2023-05-08 13:55:18 user Erik Aronesty via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> possible to change tx \"max fee\"  to output amounts?\n>\n>\n> seems like the only use case that would support such a tx is spam/dos type\n> stuff that satoshi warned about\n>\n>\n> its not a fix for everything, but it seems could help a bit with certain\n> attacks\n>\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230510/b05e5857/attachment-0001.html>"
            },
            {
                "author": "vjudeu at gazeta.pl",
                "date": "2023-05-11T11:02:57",
                "message_text_only": "> confused.   the rule was \"cannot pay a fee > sum of outputs with consideration of cpfp in the mempool\"\n> your example is of someone paying a fee \"< sum\"  which wouldn't be blocked\n\nEvery transaction paying \"fee > sum\" can be replaced by N transactions paying \"fee <= sum\", where the sum of all fees will be the same. That means, someone will still do the same thing, but it will be just expanded into N transactions, so you will reach the same outcome, but splitted into more transactions. That means, mempool will be even more congested, because for example instead of 1kB transaction with huge fee, you will see 100 such transactions with smaller fees, that will add to the same amount, but will just consume more space.\n\n> show me how someone could move 1 btc and pay 2 btc as fees...\n\nIn the previous example, I explained how someone could move 1k sats and pay almost 1 BTC as fees. But again, assuming that you have 3 BTC, and you move 1 BTC with 2 BTC fee, that will be rejected by your rules if and only if that will be done in a single transaction. But hey, the same owner can prepare N transactions upfront, and release them all at the same time, Segwit makes it possible without worrying about malleability.\n\nSo, instead of:\n\n3 BTC -> 1 BTC\n\nYou can see this:\n\n3 BTC -> 2 BTC -> 1 BTC\n\nIf that second transaction will not pass CPFP, more outputs could be used:\n\n+--------------------+--------------------+--------------------+\n| 3.0 BTC -> 0.5 BTC | 0.5 BTC -> 0.5 BTC | 0.5 BTC -> 0.5 BTC |\n|            0.5 BTC | 0.5 BTC    0.5 BTC | 0.5 BTC            |\n|            0.5 BTC | 0.5 BTC            +--------------------+\n|                    +--------------------+\n|            0.5 BTC | 0.5 BTC -> 0.5 BTC |\n|            0.5 BTC | 0.5 BTC            |\n+--------------------+--------------------+\n\nAs you can see, there are four transactions, each paying 0.5 BTC fee, so the total fee is 2 BTC. However, even if you count it as CPFP, you will get 1.5 BTC in fees for the third transaction in the chain. Note that more outputs could be used, or they could be wired a bit differently, and then if you will look at the last transaction, the sum of all fees from 10 or 15 transactions in that chain, could still pass your limits, but the whole tree will exceed that. If you have 1.5 BTC limit for that 3 BTC, then you could have 20 separate chains of transactions, each paying 0.1 BTC in fees, and it will still sum up to 2 BTC.\n\n> the only way around it is to maintain balances and use change addresses.   which would force nft and timestamp users to maintain these balances and would be a deterrent\n\nNot really, because you can prepare all of those transactions upfront, as the part of your protocol, and release all of them at once. You don't have to maintain all UTXOs in between, you can create the whole transaction tree first, sign it, and broadcast everything at once. More than that: if you have HD wallet, you only need to store a single key, and generate all addresses in-between on-the-fly, as needed. Or even use some algorithm to deterministically recreate the whole transaction tree.\n\n\n\nOn 2023-05-10 19:42:49 user Erik Aronesty <erik at q32.com> wrote:\nconfused.\u00a0 \u00a0the rule was \"cannot pay a fee > sum of outputs with consideration of cpfp in the mempool\"\n\n\nyour example is of someone paying a fee \"< sum\"\u00a0 which wouldn't be blocked\n\n\nnote: again, i'm not a fan of this, i like the discussion\u00a0of \"bitcoin as money only\" and using fee as a lever to do that\n\n\nshow me how someone could move 1 btc and pay 2 btc as fees... i think we can block it at the network or even the consensus layer, and leave anything but \"non-monetary use cases\" intact.\u00a0 \u00a0the only way around it is to maintain balances and use change addresses.\u00a0 \u00a0which would force nft and timestamp users to maintain these balances and would be a deterrent\n\n\nim am much more in favor of\u00a0doing\u00a0something like op_ctv which allows many users to pool fees and essentially \"share\" a single utxo.\n.\n\u00a0\u00a0\n\n\nOn Wed, May 10, 2023 at 12:19\u202fPM <vjudeu at gazeta.pl> wrote:\n\n> possible to change tx \"max fee\"\u00a0 to output amounts?\n\nIs it possible? Yes. Should we do that? My first thought was \"maybe\", but after thinking more about it, I would say \"no\", here is why:\n\nStarting point: 1 BTC on some output.\nCurrent situation: A single transaction moving 0.99999000 BTC as fees, and creating 1000 satoshis as some output (I know, allowed dust values are lower and depend on address type, but let's say it is 1k sats to make things simpler).\n\nAnd then, there is a room for other solutions, for example your rule, mentioned in other posts, like this one: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-May/021626.html\n\n> probably easier just to reject any transaction where the fee is higher than the sum of the outputs\n\nPossible situation after introducing your proposal, step-by-step:\n\n1) Someone wants to move 1 BTC, and someone wants to pay 0.99999000 BTC as fees. Assuming your rules are on consensus level, the first transaction creates 0.5 BTC output and 0.5 BTC fee.\n2) That person still wants to move 0.5 remaining BTC, and still is willing to pay 0.49999000 BTC as fees. Guess what will happen: you will see another transaction, creating 0.25 BTC output, and paying 0.25 BTC fee.\n...\nN) Your proposal replaced one transaction, consuming maybe one kilobyte, with a lot of transactions, doing exactly the same, but where fees are distributed between many transactions.\n\nBefore thinking about improving that system, consider one simple thing: is it possible to avoid \"max fee rule\", no matter in what way it will be defined? Because as shown above, the answer seems to be \"yes\", because you can always replace a single transaction moving 1 BTC as fees with multiple transactions, each paying one satoshi per virtual byte, and then instead of consuming around one kilobyte, it would consume around 1 MvB per 0.01 BTC, so 100 MvB per 1 BTC mentioned in the example above.\n\n\n\nOn 2023-05-08 13:55:18 user Erik Aronesty via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\npossible to change tx \"max fee\"\u00a0 to output amounts?\n\n\nseems like the only use case that would support such a tx is spam/dos type stuff that satoshi warned about\n\n\nits not a fix for everything, but it seems could help a bit with certain attacks"
            },
            {
                "author": "Kalle Rosenbaum",
                "date": "2023-05-11T12:32:01",
                "message_text_only": "Another use case for paying more fees than outputs is to incentivize\nhonest mining when Bitcoin is under a state-level censorship attack.\nIf it's really important to me that my transaction goes through, I\nmight be willing to set a fee at 99x the output value. It's the only\nway bitcoin could work in an adversarial environment.\n\n/Kalle\n\nOn Thu, 11 May 2023 at 13:55, vjudeu via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> > confused.   the rule was \"cannot pay a fee > sum of outputs with consideration of cpfp in the mempool\"\n> > your example is of someone paying a fee \"< sum\"  which wouldn't be blocked\n>\n> Every transaction paying \"fee > sum\" can be replaced by N transactions paying \"fee <= sum\", where the sum of all fees will be the same. That means, someone will still do the same thing, but it will be just expanded into N transactions, so you will reach the same outcome, but splitted into more transactions. That means, mempool will be even more congested, because for example instead of 1kB transaction with huge fee, you will see 100 such transactions with smaller fees, that will add to the same amount, but will just consume more space.\n>\n> > show me how someone could move 1 btc and pay 2 btc as fees...\n>\n> In the previous example, I explained how someone could move 1k sats and pay almost 1 BTC as fees. But again, assuming that you have 3 BTC, and you move 1 BTC with 2 BTC fee, that will be rejected by your rules if and only if that will be done in a single transaction. But hey, the same owner can prepare N transactions upfront, and release them all at the same time, Segwit makes it possible without worrying about malleability.\n>\n> So, instead of:\n>\n> 3 BTC -> 1 BTC\n>\n> You can see this:\n>\n> 3 BTC -> 2 BTC -> 1 BTC\n>\n> If that second transaction will not pass CPFP, more outputs could be used:\n>\n> +--------------------+--------------------+--------------------+\n> | 3.0 BTC -> 0.5 BTC | 0.5 BTC -> 0.5 BTC | 0.5 BTC -> 0.5 BTC |\n> |            0.5 BTC | 0.5 BTC    0.5 BTC | 0.5 BTC            |\n> |            0.5 BTC | 0.5 BTC            +--------------------+\n> |                    +--------------------+\n> |            0.5 BTC | 0.5 BTC -> 0.5 BTC |\n> |            0.5 BTC | 0.5 BTC            |\n> +--------------------+--------------------+\n>\n> As you can see, there are four transactions, each paying 0.5 BTC fee, so the total fee is 2 BTC. However, even if you count it as CPFP, you will get 1.5 BTC in fees for the third transaction in the chain. Note that more outputs could be used, or they could be wired a bit differently, and then if you will look at the last transaction, the sum of all fees from 10 or 15 transactions in that chain, could still pass your limits, but the whole tree will exceed that. If you have 1.5 BTC limit for that 3 BTC, then you could have 20 separate chains of transactions, each paying 0.1 BTC in fees, and it will still sum up to 2 BTC.\n>\n> > the only way around it is to maintain balances and use change addresses.   which would force nft and timestamp users to maintain these balances and would be a deterrent\n>\n> Not really, because you can prepare all of those transactions upfront, as the part of your protocol, and release all of them at once. You don't have to maintain all UTXOs in between, you can create the whole transaction tree first, sign it, and broadcast everything at once. More than that: if you have HD wallet, you only need to store a single key, and generate all addresses in-between on-the-fly, as needed. Or even use some algorithm to deterministically recreate the whole transaction tree.\n>\n>\n>\n> On 2023-05-10 19:42:49 user Erik Aronesty <erik at q32.com> wrote:\n> confused.   the rule was \"cannot pay a fee > sum of outputs with consideration of cpfp in the mempool\"\n>\n>\n> your example is of someone paying a fee \"< sum\"  which wouldn't be blocked\n>\n>\n> note: again, i'm not a fan of this, i like the discussion of \"bitcoin as money only\" and using fee as a lever to do that\n>\n>\n> show me how someone could move 1 btc and pay 2 btc as fees... i think we can block it at the network or even the consensus layer, and leave anything but \"non-monetary use cases\" intact.   the only way around it is to maintain balances and use change addresses.   which would force nft and timestamp users to maintain these balances and would be a deterrent\n>\n>\n> im am much more in favor of doing something like op_ctv which allows many users to pool fees and essentially \"share\" a single utxo.\n> .\n>\n>\n>\n> On Wed, May 10, 2023 at 12:19\u202fPM <vjudeu at gazeta.pl> wrote:\n>\n> > possible to change tx \"max fee\"  to output amounts?\n>\n> Is it possible? Yes. Should we do that? My first thought was \"maybe\", but after thinking more about it, I would say \"no\", here is why:\n>\n> Starting point: 1 BTC on some output.\n> Current situation: A single transaction moving 0.99999000 BTC as fees, and creating 1000 satoshis as some output (I know, allowed dust values are lower and depend on address type, but let's say it is 1k sats to make things simpler).\n>\n> And then, there is a room for other solutions, for example your rule, mentioned in other posts, like this one: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-May/021626.html\n>\n> > probably easier just to reject any transaction where the fee is higher than the sum of the outputs\n>\n> Possible situation after introducing your proposal, step-by-step:\n>\n> 1) Someone wants to move 1 BTC, and someone wants to pay 0.99999000 BTC as fees. Assuming your rules are on consensus level, the first transaction creates 0.5 BTC output and 0.5 BTC fee.\n> 2) That person still wants to move 0.5 remaining BTC, and still is willing to pay 0.49999000 BTC as fees. Guess what will happen: you will see another transaction, creating 0.25 BTC output, and paying 0.25 BTC fee.\n> ...\n> N) Your proposal replaced one transaction, consuming maybe one kilobyte, with a lot of transactions, doing exactly the same, but where fees are distributed between many transactions.\n>\n> Before thinking about improving that system, consider one simple thing: is it possible to avoid \"max fee rule\", no matter in what way it will be defined? Because as shown above, the answer seems to be \"yes\", because you can always replace a single transaction moving 1 BTC as fees with multiple transactions, each paying one satoshi per virtual byte, and then instead of consuming around one kilobyte, it would consume around 1 MvB per 0.01 BTC, so 100 MvB per 1 BTC mentioned in the example above.\n>\n>\n>\n> On 2023-05-08 13:55:18 user Erik Aronesty via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> possible to change tx \"max fee\"  to output amounts?\n>\n>\n> seems like the only use case that would support such a tx is spam/dos type stuff that satoshi warned about\n>\n>\n> its not a fix for everything, but it seems could help a bit with certain attacks\n>\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Andrew Baine",
                "date": "2023-05-11T15:20:43",
                "message_text_only": "Regardless of the submitter's rationale, it is easy to work around any rule\nthat denies mempool inclusion based on fee proportion: if you have plenty,\nadd inputs from your own wallet and return to yourself; if not, borrow them\nand return to the lender, maybe with interest.\n\nOn Thu, May 11, 2023 at 9:27\u202fAM Kalle Rosenbaum via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Another use case for paying more fees than outputs is to incentivize\n> honest mining when Bitcoin is under a state-level censorship attack.\n> If it's really important to me that my transaction goes through, I\n> might be willing to set a fee at 99x the output value. It's the only\n> way bitcoin could work in an adversarial environment.\n>\n> /Kalle\n>\n> On Thu, 11 May 2023 at 13:55, vjudeu via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >\n> > > confused.   the rule was \"cannot pay a fee > sum of outputs with\n> consideration of cpfp in the mempool\"\n> > > your example is of someone paying a fee \"< sum\"  which wouldn't be\n> blocked\n> >\n> > Every transaction paying \"fee > sum\" can be replaced by N transactions\n> paying \"fee <= sum\", where the sum of all fees will be the same. That\n> means, someone will still do the same thing, but it will be just expanded\n> into N transactions, so you will reach the same outcome, but splitted into\n> more transactions. That means, mempool will be even more congested, because\n> for example instead of 1kB transaction with huge fee, you will see 100 such\n> transactions with smaller fees, that will add to the same amount, but will\n> just consume more space.\n> >\n> > > show me how someone could move 1 btc and pay 2 btc as fees...\n> >\n> > In the previous example, I explained how someone could move 1k sats and\n> pay almost 1 BTC as fees. But again, assuming that you have 3 BTC, and you\n> move 1 BTC with 2 BTC fee, that will be rejected by your rules if and only\n> if that will be done in a single transaction. But hey, the same owner can\n> prepare N transactions upfront, and release them all at the same time,\n> Segwit makes it possible without worrying about malleability.\n> >\n> > So, instead of:\n> >\n> > 3 BTC -> 1 BTC\n> >\n> > You can see this:\n> >\n> > 3 BTC -> 2 BTC -> 1 BTC\n> >\n> > If that second transaction will not pass CPFP, more outputs could be\n> used:\n> >\n> > +--------------------+--------------------+--------------------+\n> > | 3.0 BTC -> 0.5 BTC | 0.5 BTC -> 0.5 BTC | 0.5 BTC -> 0.5 BTC |\n> > |            0.5 BTC | 0.5 BTC    0.5 BTC | 0.5 BTC            |\n> > |            0.5 BTC | 0.5 BTC            +--------------------+\n> > |                    +--------------------+\n> > |            0.5 BTC | 0.5 BTC -> 0.5 BTC |\n> > |            0.5 BTC | 0.5 BTC            |\n> > +--------------------+--------------------+\n> >\n> > As you can see, there are four transactions, each paying 0.5 BTC fee, so\n> the total fee is 2 BTC. However, even if you count it as CPFP, you will get\n> 1.5 BTC in fees for the third transaction in the chain. Note that more\n> outputs could be used, or they could be wired a bit differently, and then\n> if you will look at the last transaction, the sum of all fees from 10 or 15\n> transactions in that chain, could still pass your limits, but the whole\n> tree will exceed that. If you have 1.5 BTC limit for that 3 BTC, then you\n> could have 20 separate chains of transactions, each paying 0.1 BTC in fees,\n> and it will still sum up to 2 BTC.\n> >\n> > > the only way around it is to maintain balances and use change\n> addresses.   which would force nft and timestamp users to maintain these\n> balances and would be a deterrent\n> >\n> > Not really, because you can prepare all of those transactions upfront,\n> as the part of your protocol, and release all of them at once. You don't\n> have to maintain all UTXOs in between, you can create the whole transaction\n> tree first, sign it, and broadcast everything at once. More than that: if\n> you have HD wallet, you only need to store a single key, and generate all\n> addresses in-between on-the-fly, as needed. Or even use some algorithm to\n> deterministically recreate the whole transaction tree.\n> >\n> >\n> >\n> > On 2023-05-10 19:42:49 user Erik Aronesty <erik at q32.com> wrote:\n> > confused.   the rule was \"cannot pay a fee > sum of outputs with\n> consideration of cpfp in the mempool\"\n> >\n> >\n> > your example is of someone paying a fee \"< sum\"  which wouldn't be\n> blocked\n> >\n> >\n> > note: again, i'm not a fan of this, i like the discussion of \"bitcoin as\n> money only\" and using fee as a lever to do that\n> >\n> >\n> > show me how someone could move 1 btc and pay 2 btc as fees... i think we\n> can block it at the network or even the consensus layer, and leave anything\n> but \"non-monetary use cases\" intact.   the only way around it is to\n> maintain balances and use change addresses.   which would force nft and\n> timestamp users to maintain these balances and would be a deterrent\n> >\n> >\n> > im am much more in favor of doing something like op_ctv which allows\n> many users to pool fees and essentially \"share\" a single utxo.\n> > .\n> >\n> >\n> >\n> > On Wed, May 10, 2023 at 12:19\u202fPM <vjudeu at gazeta.pl> wrote:\n> >\n> > > possible to change tx \"max fee\"  to output amounts?\n> >\n> > Is it possible? Yes. Should we do that? My first thought was \"maybe\",\n> but after thinking more about it, I would say \"no\", here is why:\n> >\n> > Starting point: 1 BTC on some output.\n> > Current situation: A single transaction moving 0.99999000 BTC as fees,\n> and creating 1000 satoshis as some output (I know, allowed dust values are\n> lower and depend on address type, but let's say it is 1k sats to make\n> things simpler).\n> >\n> > And then, there is a room for other solutions, for example your rule,\n> mentioned in other posts, like this one:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-May/021626.html\n> >\n> > > probably easier just to reject any transaction where the fee is higher\n> than the sum of the outputs\n> >\n> > Possible situation after introducing your proposal, step-by-step:\n> >\n> > 1) Someone wants to move 1 BTC, and someone wants to pay 0.99999000 BTC\n> as fees. Assuming your rules are on consensus level, the first transaction\n> creates 0.5 BTC output and 0.5 BTC fee.\n> > 2) That person still wants to move 0.5 remaining BTC, and still is\n> willing to pay 0.49999000 BTC as fees. Guess what will happen: you will see\n> another transaction, creating 0.25 BTC output, and paying 0.25 BTC fee.\n> > ...\n> > N) Your proposal replaced one transaction, consuming maybe one kilobyte,\n> with a lot of transactions, doing exactly the same, but where fees are\n> distributed between many transactions.\n> >\n> > Before thinking about improving that system, consider one simple thing:\n> is it possible to avoid \"max fee rule\", no matter in what way it will be\n> defined? Because as shown above, the answer seems to be \"yes\", because you\n> can always replace a single transaction moving 1 BTC as fees with multiple\n> transactions, each paying one satoshi per virtual byte, and then instead of\n> consuming around one kilobyte, it would consume around 1 MvB per 0.01 BTC,\n> so 100 MvB per 1 BTC mentioned in the example above.\n> >\n> >\n> >\n> > On 2023-05-08 13:55:18 user Erik Aronesty via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > possible to change tx \"max fee\"  to output amounts?\n> >\n> >\n> > seems like the only use case that would support such a tx is spam/dos\n> type stuff that satoshi warned about\n> >\n> >\n> > its not a fix for everything, but it seems could help a bit with certain\n> attacks\n> >\n> >\n> >\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230511/b1e6113e/attachment.html>"
            },
            {
                "author": "Tom Harding",
                "date": "2023-05-12T00:06:51",
                "message_text_only": "On 5/11/23 04:02, vjudeu via bitcoin-dev wrote:\n> Every transaction paying \"fee > sum\" can be replaced by N transactions \n> paying \"fee <= sum\", where the sum of all fees will be the same.\n\n\nThese N transactions will generally have a lower feerate than the \noriginal, and the lowest feerate of the N could be drastically lower \nthan the original.\n\nAs a group, in the current environment (for example), they could take \ndays or weeks longer to be mined than the original."
            }
        ],
        "thread_summary": {
            "title": "tx max fee",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Andrew Baine",
                "Peter Todd",
                "Kalle Rosenbaum",
                "vjudeu at gazeta.pl",
                "Erik Aronesty",
                "Tom Harding"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 29979
        }
    },
    {
        "title": "[bitcoin-dev] Witness script validation to reject arbitrary data",
        "thread_messages": [
            {
                "author": "Moth",
                "date": "2023-05-08T20:16:41",
                "message_text_only": "From what I understand, things like inscriptions can only be inserted between two specific flags - OP_FALSE and OP_IF. Having a validation check to reject witness scripts that have arbitrary data between these two flags could be used to reject inscriptions while still allowing all the benefits of taproot. This will prevent people from overloading the network with txns geared solely for ordinals and brc-20 tokens.\n\nIs there a reason such a validation check is a bad idea? We already have OP_RETURN to store arbitrary data that is limited to 80kb. Was it an oversight that arbitrary data can be inserted between OP_FALSE and OP_IF when the size limit for witness scripts was lifted as part of taproot?\nThanks,\nMoth\n\nSent from Proton Mail for iOS\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/777d31ac/attachment.html>"
            },
            {
                "author": "angus",
                "date": "2023-05-08T21:33:24",
                "message_text_only": "> Is there a reason such a validation check is a bad idea? We already have OP_RETURN to store arbitrary data that is limited to 80kb.\n\n\nA reason to not ban storing arbitrary/non-functional data is that people will still want to store things, so will start (ab)using useful data to do so, which is worse -- see Stamps[1], which stores Inscription-like data in fake outputs that consume UTXO set storage (using the Counterparty spec IIRC).\n\nThe UTXO set getting 'too big' is a much bigger problem than the chain getting bigger at closer to 4MB/10mins than the 'expected' ~1MB/10mins is (some nuance/argument to be had here, though).\n\n\n> Was it an oversight that arbitrary data can be inserted between OP_FALSE and OP_IF when the size limit for witness scripts\u00a0was lifted as part of taproot?\n\n\nKinda? But if we want Taproot to enable large useful scripts, it's probably hard/impossible to have an undefeatable definition of 'not useful' to then filter out. You could say \"scripts must not have any unreachable code (dead code)\" but then it'd be easy to come up with Inscriptions 2.0 where the code is reachable but never used, rinse and repeat in a game of whack-a-mole.\n\nIn my opinion, it'd be wise to not incentivize people to do something worse by attempting to censor what they're currently doing, given that it could be a fair bit worse!\n\n[1]: https://github.com/mikeinspace/stamps/blob/main/BitcoinStamps.md\n\nAngus\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/13d8dff3/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 249 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/13d8dff3/attachment-0001.sig>"
            },
            {
                "author": "Christopher Allen",
                "date": "2023-05-08T21:43:06",
                "message_text_only": "On May 8, 2023 at 1:16:41 PM, Moth via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> From what I understand, things like inscriptions can only be inserted\n> between two specific flags - OP_FALSE and OP_IF. Having a validation check\n> to reject witness scripts that have arbitrary data between these two flags\n> could be used to reject inscriptions while still allowing all the benefits\n> of taproot. This will prevent people from overloading the network with txns\n> geared solely for ordinals and brc-20 tokens.\n>\n\nUnfortunately, there are many other ways to \u201cinscribe\u201d other than that\nparticular trick.\n\n>\n> Is there a reason such a validation check is a bad idea? We already have\n> OP_RETURN to store arbitrary data that is limited to 80kb. Was it an\n> oversight that arbitrary data can be inserted between OP_FALSE and OP_IF\n> when the size limit for witness scripts was lifted as part of taproot?\n>\n\nThere have been some of us that had hoped for a slightly larger OP_RETURN\nsuch that we can store a tagged root of a hash-tree (~128-512 bytes). For\ninstance, open time-stamps, ION, and my own privacy-focused Gordian\nEnvelope (https://www.blockchaincommons.com/introduction/Envelope-Intro/),\nall consolidate large sets of proofs into a hash, which we use for L2\nproofs-of-inclusion. My own preference is that the size can be large enough\nso you can store the hash, optionally have a signature on it, and have a\nfew bytes for self-describing data (we like CBOR as it is quite small).\n\nAll of us held off for years asking for larger OP_RETURN or standardizing\non a pay-to-contract BIP for the techniques we do use because of objections\nto putting anything on-chain. But now we are dismayed by the inscription\ntechnique that freeloads on the network mempool, the validation network,\nand volunteer unpruned full nodes.\n\nFor instance, I host an alternative explora instance (the source code base\nused by blockstream.info), offering it publicly via Tor so that there is\nmore than a single server offering its details. Inscriptions combined with\nDOS attacks on Tor is making it more expensive for me to host and maintain\nthis free privacy service.\n\nThere was a recent thread discussing raising the limit on OP_RETURN\nhttps://github.com/bitcoin/bitcoin/issues/27043\n\nHere is an old relevant thread from open time-stamps:\nhttps://github.com/opentimestamps/python-opentimestamps/pull/14\n\nI\u2019m not sure what the solution is. I feel like I\u2019ve been a good neighbor\nfor some time on this topic, always recommending minimal on-chain data, and\nnow I feel frustrated with this free-rider problem.\n\n\u2014 Christopher Allen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/be4a7f25/attachment-0001.html>"
            },
            {
                "author": "Aymeric Vitte",
                "date": "2023-05-09T17:45:11",
                "message_text_only": "Le 08/05/2023 \u00e0 23:43, Christopher Allen via bitcoin-dev a \u00e9crit :\n> There was a recent thread discussing raising the limit on\n> OP_RETURN https://github.com/bitcoin/bitcoin/issues/27043\nIndeed we already discussed all of this, and the conclusion was: there\nare no reasons to impose limits, because people will find some deviant\n(or not) workarounds (like Stamps), and fees will regulate this\n\nAnd how to control the value of what is stored? If I store e=mc2, the\nway I like since as many said it's super easy to find plenty of ways to\nstore in bitcoin, this one is short and supposed to have more value than\nbitcoin, no?\n\nPersonnally I think of course that you should store a reference to\nsomething and not the something, so a few hashes and/or signatures which\nyou cannot do with OP_RETURN today (80B Moth, not 80kB)\n\nI don't see very well what can be done against the freeriders, except\navoiding that they impact the whole network (a bit \u00e0 la bittorrent),\nmaybe the issue is more about decentralization rather than trying to\nimpose limitations, so the decentralized miners can't have the whole\nimage of the whole txs and hold low fees txs, which is not the case at\nall today, but it seems a bit utopic right now\n\nOr maybe when the ordinal meme stuff/BRC20 will be proven to have\nfinally zero value the market will self regulate\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230509/a1edd728/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2023-05-08T23:55:57",
                "message_text_only": "On Mon, May 08, 2023 at 08:16:41PM +0000, Moth via bitcoin-dev wrote:\n> From what I understand, things like inscriptions can only be inserted between two specific flags - OP_FALSE and OP_IF.\n\nThat's just an artifical limitation of the current inscription protocol. There\nare endless ways to embed arbitrary data in Bitcoin transactions. Blocking them\nall is a hopeless task.\n\n> Having a validation check to reject witness scripts that have arbitrary data between these two flags could be used to reject inscriptions while still allowing all the benefits of taproot. This will prevent people from overloading the network with txns geared solely for ordinals and brc-20 tokens.\n> \n> Is there a reason such a validation check is a bad idea? We already have OP_RETURN to store arbitrary data that is limited to 80kb. Was it an oversight that arbitrary data can be inserted between OP_FALSE and OP_IF when the size limit for witness scripts was lifted as part of taproot?\n\nIt's pointless to even try.\n\nThe current flood of inscription txs are very small, about 150vB, and embed\nvery little data in the chain. They could have just as easily used OP_RETURN\noutputs or any number of other data encoding techniques. Blocking that kind of\nuse-case is hopeless.\n\nThe _purpose_ of the current flood of BRC-20 inscriptions - tl;dr the creation\nof a new set of assets via an auction - is something that doesn't even require\nany data to be embedded in the chain at all. They could have implemented them\nwith perfectly normal transactions indistinguishable from any other\ntransaction. Blocking that is truly hopeless.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230508/d4716aa5/attachment-0001.sig>"
            },
            {
                "author": "Moth",
                "date": "2023-05-09T12:20:20",
                "message_text_only": "> They could have just as easily used OP_RETURN\noutputs or any number of other data encoding techniques.\n\nBut doesn't OP_RETURN render the UTXO unspendable, thereby making it impossible to \"trade\" the minted BTC-20 tokens?\n\nMoth\n\nSent from Proton Mail for iOS\n\nOn Mon, May 8, 2023 at 7:55 PM, Peter Todd <[pete at petertodd.org](mailto:On Mon, May 8, 2023 at 7:55 PM, Peter Todd <<a href=)> wrote:\n\n> On Mon, May 08, 2023 at 08:16:41PM +0000, Moth via bitcoin-dev wrote:\n>> From what I understand, things like inscriptions can only be inserted between two specific flags - OP_FALSE and OP_IF.\n>\n> That's just an artifical limitation of the current inscription protocol. There\n> are endless ways to embed arbitrary data in Bitcoin transactions. Blocking them\n> all is a hopeless task.\n>\n>> Having a validation check to reject witness scripts that have arbitrary data between these two flags could be used to reject inscriptions while still allowing all the benefits of taproot. This will prevent people from overloading the network with txns geared solely for ordinals and brc-20 tokens.\n>>\n>> Is there a reason such a validation check is a bad idea? We already have OP_RETURN to store arbitrary data that is limited to 80kb. Was it an oversight that arbitrary data can be inserted between OP_FALSE and OP_IF when the size limit for witness scripts was lifted as part of taproot?\n>\n> It's pointless to even try.\n>\n> The current flood of inscription txs are very small, about 150vB, and embed\n> very little data in the chain. They could have just as easily used OP_RETURN\n> outputs or any number of other data encoding techniques. Blocking that kind of\n> use-case is hopeless.\n>\n> The _purpose_ of the current flood of BRC-20 inscriptions - tl;dr the creation\n> of a new set of assets via an auction - is something that doesn't even require\n> any data to be embedded in the chain at all. They could have implemented them\n> with perfectly normal transactions indistinguishable from any other\n> transaction. Blocking that is truly hopeless.\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230509/ff13a5f9/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Witness script validation to reject arbitrary data",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Christopher Allen",
                "Peter Todd",
                "Aymeric Vitte",
                "angus",
                "Moth"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 11359
        }
    },
    {
        "title": "[bitcoin-dev] Responsible disclosures and Bitcoin development",
        "thread_messages": [
            {
                "author": "alicexbt",
                "date": "2023-05-09T02:47:24",
                "message_text_only": "Hi Bitcoin Developers,\n\nThere is an open issue in bitcoin core repository which was created last week: https://github.com/bitcoin/bitcoin/issues/27586\n\nI think this should have been reported privately as vulnerability instead of creating a GitHub issue even if it worked only in debug mode. Some users in the comments have also experienced similar issues without debug build used for bitcoind. I have not noticed any decline in the number of listening nodes on bitnodes.io in last 24 hours so I am assuming this is not an issue with majority of bitcoin core nodes. However, things could have been worse and there is nothing wrong in reporting something privately if there is even 1% possibility of it being a vulnerability. I had recently reported something to LND security team based on a closed issue on GitHub which eventually was not considered a vulnerability: https://github.com/lightningnetwork/lnd/issues/7449\n\nIn the CPU usage issue, maybe the users can run bitcoind with bigger mempool or try other things shared in the issue by everyone.\n\nThis isn't the first time either when vulnerability was reported publicly: https://gist.github.com/chjj/4ff628f3a0d42823a90edf47340f0db9 and this was even exploited on mainnet which affected some projects.\n\nThis email is just a request to consider the impact of any vulnerability if gets exploited could affect lot of things. Even the projects with no financial activity involved follow better practices.\n\n/dev/fd0\nfloppy disk guy\n\nSent with [Proton Mail](https://proton.me/) secure email.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230509/c664f3f5/attachment-0001.html>"
            },
            {
                "author": "Michael Folkson",
                "date": "2023-05-11T19:44:18",
                "message_text_only": "Hi alicexbt\n\nThe vulnerability reporting process requires communication and resolution via a small group of individuals [0] rather than through open collaboration between any contributors on the repo. There are clearly examples where the process is critically needed, the most obvious past example being the 2018 inflation bug [1]. However, it doesn't scale for all bug reports and investigations to go through this tiny funnel. For an issue that isn't going to result in loss of onchain funds and doesn't seem to present a systemic issue (e.g. network DoS attack, inflation bug) I'm of the view that opening a public issue was appropriate in this case especially as the issue initially assumed it was only impacting nodes running in debug mode (not a mode a node in production is likely to be running in).\n\nAn interesting question though and I'm certainly happy to be corrected by those who have been investigating the issue. Some delicate trade-offs involved including understanding and resolving the issue faster through wider collaboration versus keeping knowledge of the issue within a smaller group.\n\nThanks\nMichael\n\n[0]: https://github.com/bitcoin/bitcoin/blob/master/SECURITY.md\n[1]: https://bitcoincore.org/en/2018/09/20/notice/\n\n--\nMichael Folkson\nEmail: michaelfolkson at [protonmail.com](http://protonmail.com/)\nGPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n\nLearn about Bitcoin: https://www.youtube.com/@portofbitcoin\n\n------- Original Message -------\nOn Tuesday, May 9th, 2023 at 03:47, alicexbt via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Bitcoin Developers,\n>\n> There is an open issue in bitcoin core repository which was created last week: https://github.com/bitcoin/bitcoin/issues/27586\n>\n> I think this should have been reported privately as vulnerability instead of creating a GitHub issue even if it worked only in debug mode. Some users in the comments have also experienced similar issues without debug build used for bitcoind. I have not noticed any decline in the number of listening nodes on bitnodes.io in last 24 hours so I am assuming this is not an issue with majority of bitcoin core nodes. However, things could have been worse and there is nothing wrong in reporting something privately if there is even 1% possibility of it being a vulnerability. I had recently reported something to LND security team based on a closed issue on GitHub which eventually was not considered a vulnerability: https://github.com/lightningnetwork/lnd/issues/7449\n>\n> In the CPU usage issue, maybe the users can run bitcoind with bigger mempool or try other things shared in the issue by everyone.\n>\n> This isn't the first time either when vulnerability was reported publicly: https://gist.github.com/chjj/4ff628f3a0d42823a90edf47340f0db9 and this was even exploited on mainnet which affected some projects.\n>\n> This email is just a request to consider the impact of any vulnerability if gets exploited could affect lot of things. Even the projects with no financial activity involved follow better practices.\n>\n> /dev/fd0\n> floppy disk guy\n>\n> Sent with [Proton Mail](https://proton.me/) secure email.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230511/021610dd/attachment.html>"
            },
            {
                "author": "alicexbt",
                "date": "2023-05-16T22:39:53",
                "message_text_only": "Hi Michael,\n\nA disagreement and some thoughts already shared in an email although its not clear to some \"open source\" devs:\n\nImpact of this vulnerability:\n\n- Denial of Service\n- Stale blocks affecting mining pool revenue\nWhy it should have been reported privately to security at bitcoincore.org, even if initially found affecting only debug build?\n\nExample: https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-3129\n\nCVE is a different process and I am aware of it. It would be good for certain developers in the core team to reflect on their own approach to security, regardless of whether their work receives CVE recognition or not.\n\n/dev/fd0\nfloppy disk guy\n\nSent with [Proton Mail](https://proton.me/) secure email.\n\n------- Original Message -------\nOn Friday, May 12th, 2023 at 1:14 AM, Michael Folkson <michaelfolkson at protonmail.com> wrote:\n\n> Hi alicexbt\n>\n> The vulnerability reporting process requires communication and resolution via a small group of individuals [0] rather than through open collaboration between any contributors on the repo. There are clearly examples where the process is critically needed, the most obvious past example being the 2018 inflation bug [1]. However, it doesn't scale for all bug reports and investigations to go through this tiny funnel. For an issue that isn't going to result in loss of onchain funds and doesn't seem to present a systemic issue (e.g. network DoS attack, inflation bug) I'm of the view that opening a public issue was appropriate in this case especially as the issue initially assumed it was only impacting nodes running in debug mode (not a mode a node in production is likely to be running in).\n>\n> An interesting question though and I'm certainly happy to be corrected by those who have been investigating the issue. Some delicate trade-offs involved including understanding and resolving the issue faster through wider collaboration versus keeping knowledge of the issue within a smaller group.\n>\n> Thanks\n> Michael\n>\n> [0]: https://github.com/bitcoin/bitcoin/blob/master/SECURITY.md\n> [1]: https://bitcoincore.org/en/2018/09/20/notice/\n>\n> --\n> Michael Folkson\n> Email: michaelfolkson at [protonmail.com](http://protonmail.com/)\n> GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n>\n> Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n>\n> ------- Original Message -------\n> On Tuesday, May 9th, 2023 at 03:47, alicexbt via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi Bitcoin Developers,\n>>\n>> There is an open issue in bitcoin core repository which was created last week: https://github.com/bitcoin/bitcoin/issues/27586\n>>\n>> I think this should have been reported privately as vulnerability instead of creating a GitHub issue even if it worked only in debug mode. Some users in the comments have also experienced similar issues without debug build used for bitcoind. I have not noticed any decline in the number of listening nodes on bitnodes.io in last 24 hours so I am assuming this is not an issue with majority of bitcoin core nodes. However, things could have been worse and there is nothing wrong in reporting something privately if there is even 1% possibility of it being a vulnerability. I had recently reported something to LND security team based on a closed issue on GitHub which eventually was not considered a vulnerability: https://github.com/lightningnetwork/lnd/issues/7449\n>>\n>> In the CPU usage issue, maybe the users can run bitcoind with bigger mempool or try other things shared in the issue by everyone.\n>>\n>> This isn't the first time either when vulnerability was reported publicly: https://gist.github.com/chjj/4ff628f3a0d42823a90edf47340f0db9 and this was even exploited on mainnet which affected some projects.\n>>\n>> This email is just a request to consider the impact of any vulnerability if gets exploited could affect lot of things. Even the projects with no financial activity involved follow better practices.\n>>\n>> /dev/fd0\n>> floppy disk guy\n>>\n>> Sent with [Proton Mail](https://proton.me/) secure email.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230516/f9af5f1d/attachment.html>"
            },
            {
                "author": "Michael Folkson",
                "date": "2023-05-17T12:44:41",
                "message_text_only": "Hi alicexbt\n\n\"Open source\" has the word \"open\" in it. Pushing everything into closed, private channels of communication and select groups of individuals is what I've been trying to push back upon. As I said in my initial response \"it doesn't scale for all bug reports and investigations to go through this tiny funnel\" though \"there are clearly examples where the process is critically needed\".\n\nNow that's not to say you may not have a point about better documentation and guidance on what should go through the vulnerability reporting process and what shouldn't. Or even that this particular issue could ultimately end up being classed a CVE. But rather than merely complaining and putting \"open source\" into quote marks perhaps suggest what class of bug reports should go through the tiny funnel and what shouldn't. Unless you think everything should go through the funnel in which case you are advocating for less openness whilst simultaneously complaining it isn't \"open source\". Square that circle.\n\nThanks\nMichael\n\n--\nMichael Folkson\nEmail: michaelfolkson at [protonmail.com](http://protonmail.com/)\nGPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n\nLearn about Bitcoin: https://www.youtube.com/@portofbitcoin\n\n------- Original Message -------\nOn Tuesday, May 16th, 2023 at 23:39, alicexbt <alicexbt at protonmail.com> wrote:\n\n> Hi Michael,\n>\n> A disagreement and some thoughts already shared in an email although its not clear to some \"open source\" devs:\n>\n> Impact of this vulnerability:\n>\n> - Denial of Service\n> - Stale blocks affecting mining pool revenue\n> Why it should have been reported privately to security at bitcoincore.org, even if initially found affecting only debug build?\n>\n> Example: https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-3129\n>\n> CVE is a different process and I am aware of it. It would be good for certain developers in the core team to reflect on their own approach to security, regardless of whether their work receives CVE recognition or not.\n>\n> /dev/fd0\n> floppy disk guy\n>\n> Sent with [Proton Mail](https://proton.me/) secure email.\n>\n> ------- Original Message -------\n> On Friday, May 12th, 2023 at 1:14 AM, Michael Folkson <michaelfolkson at protonmail.com> wrote:\n>\n>> Hi alicexbt\n>>\n>> The vulnerability reporting process requires communication and resolution via a small group of individuals [0] rather than through open collaboration between any contributors on the repo. There are clearly examples where the process is critically needed, the most obvious past example being the 2018 inflation bug [1]. However, it doesn't scale for all bug reports and investigations to go through this tiny funnel. For an issue that isn't going to result in loss of onchain funds and doesn't seem to present a systemic issue (e.g. network DoS attack, inflation bug) I'm of the view that opening a public issue was appropriate in this case especially as the issue initially assumed it was only impacting nodes running in debug mode (not a mode a node in production is likely to be running in).\n>>\n>> An interesting question though and I'm certainly happy to be corrected by those who have been investigating the issue. Some delicate trade-offs involved including understanding and resolving the issue faster through wider collaboration versus keeping knowledge of the issue within a smaller group.\n>>\n>> Thanks\n>> Michael\n>>\n>> [0]: https://github.com/bitcoin/bitcoin/blob/master/SECURITY.md\n>> [1]: https://bitcoincore.org/en/2018/09/20/notice/\n>>\n>> --\n>> Michael Folkson\n>> Email: michaelfolkson at [protonmail.com](http://protonmail.com/)\n>> GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n>>\n>> Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n>>\n>> ------- Original Message -------\n>> On Tuesday, May 9th, 2023 at 03:47, alicexbt via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Hi Bitcoin Developers,\n>>>\n>>> There is an open issue in bitcoin core repository which was created last week: https://github.com/bitcoin/bitcoin/issues/27586\n>>>\n>>> I think this should have been reported privately as vulnerability instead of creating a GitHub issue even if it worked only in debug mode. Some users in the comments have also experienced similar issues without debug build used for bitcoind. I have not noticed any decline in the number of listening nodes on bitnodes.io in last 24 hours so I am assuming this is not an issue with majority of bitcoin core nodes. However, things could have been worse and there is nothing wrong in reporting something privately if there is even 1% possibility of it being a vulnerability. I had recently reported something to LND security team based on a closed issue on GitHub which eventually was not considered a vulnerability: https://github.com/lightningnetwork/lnd/issues/7449\n>>>\n>>> In the CPU usage issue, maybe the users can run bitcoind with bigger mempool or try other things shared in the issue by everyone.\n>>>\n>>> This isn't the first time either when vulnerability was reported publicly: https://gist.github.com/chjj/4ff628f3a0d42823a90edf47340f0db9 and this was even exploited on mainnet which affected some projects.\n>>>\n>>> This email is just a request to consider the impact of any vulnerability if gets exploited could affect lot of things. Even the projects with no financial activity involved follow better practices.\n>>>\n>>> /dev/fd0\n>>> floppy disk guy\n>>>\n>>> Sent with [Proton Mail](https://proton.me/) secure email.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230517/519f60b6/attachment-0001.html>"
            },
            {
                "author": "alicexbt",
                "date": "2023-05-22T12:56:13",
                "message_text_only": "Hi Michael,\n\n> Now that's not to say you may not have a point about better documentation and guidance on what should go through the vulnerability reporting process and what shouldn't.\n\nYes, this can be improved.\n\n> Or even that this particular issue could ultimately end up being classed a CVE.\n\nIt has been assigned CVE-2023-33297\n\n\n/dev/fd0\nfloppy disk guy\n\nSent with Proton Mail secure email.\n\n------- Original Message -------\nOn Wednesday, May 17th, 2023 at 6:14 PM, Michael Folkson <michaelfolkson at protonmail.com> wrote:\n\n\n> Hi alicexbt\n> \n> \"Open source\" has the word \"open\" in it. Pushing everything into closed, private channels of communication and select groups of individuals is what I've been trying to push back upon. As I said in my initial response \"it doesn't scale for all bug reports and investigations to go through this tiny funnel\" though \"there are clearly examples where the process is critically needed\".\n> \n> \n> Now that's not to say you may not have a point about better documentation and guidance on what should go through the vulnerability reporting process and what shouldn't. Or even that this particular issue could ultimately end up being classed a CVE. But rather than merely complaining and putting \"open source\" into quote marks perhaps suggest what class of bug reports should go through the tiny funnel and what shouldn't. Unless you think everything should go through the funnel in which case you are advocating for less openness whilst simultaneously complaining it isn't \"open source\". Square that circle.\n> \n> \n> Thanks\n> Michael\n> \n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n> \n> \n> Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n> \n> \n> ------- Original Message -------\n> On Tuesday, May 16th, 2023 at 23:39, alicexbt <alicexbt at protonmail.com> wrote:\n> \n> \n> > Hi Michael,\n> > \n> > A disagreement and some thoughts already shared in an email although its not clear to some \"open source\" devs:\n> > \n> > Impact of this vulnerability:\n> > \n> > - Denial of Service\n> > - Stale blocks affecting mining pool revenue\n> > \n> > Why it should have been reported privately to security at bitcoincore.org, even if initially found affecting only debug build?\n> > \n> > \n> > Example:\u00a0https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-3129\n> > \n> > \n> > CVE is a different process\u00a0and I am aware of it.\u00a0It would be good for certain developers in the core team to reflect on their own approach to security, regardless of whether their work receives CVE recognition or not.\n> > \n> > /dev/fd0\n> > floppy disk guy\n> > \n> > \n> > Sent with Proton Mail secure email.\n> > \n> > ------- Original Message -------\n> > On Friday, May 12th, 2023 at 1:14 AM, Michael Folkson <michaelfolkson at protonmail.com> wrote:\n> > \n> > \n> > > Hi alicexbt\n> > > \n> > > The vulnerability reporting process requires communication and resolution via a small group of individuals [0] rather than through open collaboration between any contributors on the repo. There are clearly examples where the process is critically needed, the most obvious past example being the 2018 inflation bug [1]. However, it doesn't scale for all bug reports and investigations to go through this tiny funnel. For an issue that isn't going to result in loss of onchain funds and doesn't seem to present a systemic issue (e.g. network DoS attack, inflation bug) I'm of the view that opening a public issue was appropriate in this case especially as the issue initially assumed it was only impacting nodes running in debug mode (not a mode a node in production is likely to be running in).\n> > > \n> > > An interesting question though and I'm certainly happy to be corrected by those who have been investigating the issue. Some delicate trade-offs involved including understanding and resolving the issue faster through wider collaboration versus keeping knowledge of the issue within a smaller group.\n> > > \n> > > Thanks\n> > > Michael\n> > > \n> > > [0]:\u00a0https://github.com/bitcoin/bitcoin/blob/master/SECURITY.md\n> > > [1]:\u00a0https://bitcoincore.org/en/2018/09/20/notice/\n> > > \n> > > --\n> > > Michael Folkson\n> > > Email: michaelfolkson at protonmail.com\n> > > GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n> > > \n> > > \n> > > Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n> > > \n> > > \n> > > ------- Original Message -------\n> > > On Tuesday, May 9th, 2023 at 03:47, alicexbt via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > > \n> > > \n> > > > Hi Bitcoin Developers,\n> > > > \n> > > > There is an open issue in bitcoin core repository which was created last week:\u00a0https://github.com/bitcoin/bitcoin/issues/27586\n> > > > \n> > > > I think this should have been reported privately as vulnerability instead of creating a GitHub issue even if it worked only in debug mode. Some users in the comments have also experienced similar issues without debug build used for bitcoind. I have not noticed any decline in the number of listening nodes on bitnodes.io in last 24 hours so I am assuming this is not an issue with majority of bitcoin core nodes. However, things could have been worse and there is nothing wrong in reporting something privately if there is even 1% possibility of it being a vulnerability. I had recently reported something to LND security team based on a closed issue on GitHub which eventually was not considered a vulnerability:\u00a0https://github.com/lightningnetwork/lnd/issues/7449\u00a0\n> > > > \n> > > > In the CPU usage issue, maybe the users can run bitcoind with bigger mempool or try other things shared in the issue by everyone.\n> > > > \n> > > > This isn't the first time either when vulnerability was reported publicly:\u00a0https://gist.github.com/chjj/4ff628f3a0d42823a90edf47340f0db9\u00a0and this was even exploited on mainnet which affected some projects.\n> > > > \n> > > > \n> > > > This email is just a request to consider the impact of any vulnerability if gets exploited could affect lot of things. Even the projects with no financial activity involved follow better practices.\n> > > > \n> > > > /dev/fd0\n> > > > floppy disk guy\u00a0\n> > > > \n> > > > \n> > > > Sent with Proton Mail secure email."
            },
            {
                "author": "Michael Folkson",
                "date": "2023-05-23T16:17:55",
                "message_text_only": "Hi alicexbt\n\n> It has been assigned CVE-2023-33297\n\nDid you personally request the CVE ID? Say via here [0]? Did you confirm with someone listed on the vulnerability reporting process [1] for Bitcoin Core that it made sense to do that at this time? I'm not sure whether completely bypassing that list and requesting CVE IDs for the project as an individual is the way to go. If you have already contacted one of them and they've given you the go ahead to start the CVE process then fine. You weren't particularly clear with what has occurred.\n\nThanks\nMichael\n\n[0]: https://cve.mitre.org/cve/request_id.html\n[1]: https://github.com/bitcoin/bitcoin/blob/master/SECURITY.md\n\n--\nMichael Folkson\nEmail: michaelfolkson at protonmail.com\nGPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n\n\nLearn about Bitcoin: https://www.youtube.com/@portofbitcoin\n\n\n------- Original Message -------\nOn Monday, May 22nd, 2023 at 13:56, alicexbt <alicexbt at protonmail.com> wrote:\n\n\n> Hi Michael,\n> \n> > Now that's not to say you may not have a point about better documentation and guidance on what should go through the vulnerability reporting process and what shouldn't.\n> \n> \n> Yes, this can be improved.\n> \n> > Or even that this particular issue could ultimately end up being classed a CVE.\n> \n> \n> It has been assigned CVE-2023-33297\n> \n> \n> /dev/fd0\n> floppy disk guy\n> \n> Sent with Proton Mail secure email.\n> \n> ------- Original Message -------\n> On Wednesday, May 17th, 2023 at 6:14 PM, Michael Folkson michaelfolkson at protonmail.com wrote:\n> \n> \n> \n> > Hi alicexbt\n> > \n> > \"Open source\" has the word \"open\" in it. Pushing everything into closed, private channels of communication and select groups of individuals is what I've been trying to push back upon. As I said in my initial response \"it doesn't scale for all bug reports and investigations to go through this tiny funnel\" though \"there are clearly examples where the process is critically needed\".\n> > \n> > Now that's not to say you may not have a point about better documentation and guidance on what should go through the vulnerability reporting process and what shouldn't. Or even that this particular issue could ultimately end up being classed a CVE. But rather than merely complaining and putting \"open source\" into quote marks perhaps suggest what class of bug reports should go through the tiny funnel and what shouldn't. Unless you think everything should go through the funnel in which case you are advocating for less openness whilst simultaneously complaining it isn't \"open source\". Square that circle.\n> > \n> > Thanks\n> > Michael\n> > \n> > --\n> > Michael Folkson\n> > Email: michaelfolkson at protonmail.com\n> > GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n> > \n> > Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n> > \n> > ------- Original Message -------\n> > On Tuesday, May 16th, 2023 at 23:39, alicexbt alicexbt at protonmail.com wrote:\n> > \n> > > Hi Michael,\n> > > \n> > > A disagreement and some thoughts already shared in an email although its not clear to some \"open source\" devs:\n> > > \n> > > Impact of this vulnerability:\n> > > \n> > > - Denial of Service\n> > > - Stale blocks affecting mining pool revenue\n> > > \n> > > Why it should have been reported privately to security at bitcoincore.org, even if initially found affecting only debug build?\n> > > \n> > > Example: https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-3129\n> > > \n> > > CVE is a different process and I am aware of it. It would be good for certain developers in the core team to reflect on their own approach to security, regardless of whether their work receives CVE recognition or not.\n> > > \n> > > /dev/fd0\n> > > floppy disk guy\n> > > \n> > > Sent with Proton Mail secure email.\n> > > \n> > > ------- Original Message -------\n> > > On Friday, May 12th, 2023 at 1:14 AM, Michael Folkson michaelfolkson at protonmail.com wrote:\n> > > \n> > > > Hi alicexbt\n> > > > \n> > > > The vulnerability reporting process requires communication and resolution via a small group of individuals 0 rather than through open collaboration between any contributors on the repo. There are clearly examples where the process is critically needed, the most obvious past example being the 2018 inflation bug 1. However, it doesn't scale for all bug reports and investigations to go through this tiny funnel. For an issue that isn't going to result in loss of onchain funds and doesn't seem to present a systemic issue (e.g. network DoS attack, inflation bug) I'm of the view that opening a public issue was appropriate in this case especially as the issue initially assumed it was only impacting nodes running in debug mode (not a mode a node in production is likely to be running in).\n> > > > \n> > > > An interesting question though and I'm certainly happy to be corrected by those who have been investigating the issue. Some delicate trade-offs involved including understanding and resolving the issue faster through wider collaboration versus keeping knowledge of the issue within a smaller group.\n> > > > \n> > > > Thanks\n> > > > Michael\n> > > > \n> > > > --\n> > > > Michael Folkson\n> > > > Email: michaelfolkson at protonmail.com\n> > > > GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n> > > > \n> > > > Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n> > > > \n> > > > ------- Original Message -------\n> > > > On Tuesday, May 9th, 2023 at 03:47, alicexbt via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:\n> > > > \n> > > > > Hi Bitcoin Developers,\n> > > > > \n> > > > > There is an open issue in bitcoin core repository which was created last week: https://github.com/bitcoin/bitcoin/issues/27586\n> > > > > \n> > > > > I think this should have been reported privately as vulnerability instead of creating a GitHub issue even if it worked only in debug mode. Some users in the comments have also experienced similar issues without debug build used for bitcoind. I have not noticed any decline in the number of listening nodes on bitnodes.io in last 24 hours so I am assuming this is not an issue with majority of bitcoin core nodes. However, things could have been worse and there is nothing wrong in reporting something privately if there is even 1% possibility of it being a vulnerability. I had recently reported something to LND security team based on a closed issue on GitHub which eventually was not considered a vulnerability: https://github.com/lightningnetwork/lnd/issues/7449\n> > > > > \n> > > > > In the CPU usage issue, maybe the users can run bitcoind with bigger mempool or try other things shared in the issue by everyone.\n> > > > > \n> > > > > This isn't the first time either when vulnerability was reported publicly: https://gist.github.com/chjj/4ff628f3a0d42823a90edf47340f0db9 and this was even exploited on mainnet which affected some projects.\n> > > > > \n> > > > > This email is just a request to consider the impact of any vulnerability if gets exploited could affect lot of things. Even the projects with no financial activity involved follow better practices.\n> > > > > \n> > > > > /dev/fd0\n> > > > > floppy disk guy\n> > > > > \n> > > > > Sent with Proton Mail secure email."
            },
            {
                "author": "alicexbt",
                "date": "2023-05-23T16:45:58",
                "message_text_only": "Hi Michael,\n\nYes, I had requested CVE ID after v24.1 was released as Anthony Towns being the discoverer.\n\nI would follow the process shared here: https://github.com/bitcoin/bitcoin/blob/master/SECURITY.md when bitcoin core developers do not disclose vulnerabilities publicly as GitHub issues which are read by everyone including 3 letter agencies. I don't think there was anything left in the issue after discussing it for days for me to add anything new. I was clear about some things the moment I read the issue and its one of the reasons I created this thread on May 9 (public) about a public GitHub issue after following it for a few days.\n\nIt would still qualify as a vulnerability if it only affected debug builds.\n\n> You weren't particularly clear with what has occurred.\n\nIt would be better we have less assumptions about such things.\n\n/dev/fd0\nfloppy disk guy\n\nSent with Proton Mail secure email.\n\n------- Original Message -------\nOn Tuesday, May 23rd, 2023 at 9:47 PM, Michael Folkson <michaelfolkson at protonmail.com> wrote:\n\n\n> Hi alicexbt\n> \n> > It has been assigned CVE-2023-33297\n> \n> \n> Did you personally request the CVE ID? Say via here [0]? Did you confirm with someone listed on the vulnerability reporting process [1] for Bitcoin Core that it made sense to do that at this time? I'm not sure whether completely bypassing that list and requesting CVE IDs for the project as an individual is the way to go. If you have already contacted one of them and they've given you the go ahead to start the CVE process then fine. You weren't particularly clear with what has occurred.\n> \n> Thanks\n> Michael\n> \n> [0]: https://cve.mitre.org/cve/request_id.html\n> [1]: https://github.com/bitcoin/bitcoin/blob/master/SECURITY.md\n> \n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n> \n> \n> Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n> \n> \n> ------- Original Message -------\n> On Monday, May 22nd, 2023 at 13:56, alicexbt alicexbt at protonmail.com wrote:\n> \n> \n> \n> > Hi Michael,\n> > \n> > > Now that's not to say you may not have a point about better documentation and guidance on what should go through the vulnerability reporting process and what shouldn't.\n> > \n> > Yes, this can be improved.\n> > \n> > > Or even that this particular issue could ultimately end up being classed a CVE.\n> > \n> > It has been assigned CVE-2023-33297\n> > \n> > /dev/fd0\n> > floppy disk guy\n> > \n> > Sent with Proton Mail secure email.\n> > \n> > ------- Original Message -------\n> > On Wednesday, May 17th, 2023 at 6:14 PM, Michael Folkson michaelfolkson at protonmail.com wrote:\n> > \n> > > Hi alicexbt\n> > > \n> > > \"Open source\" has the word \"open\" in it. Pushing everything into closed, private channels of communication and select groups of individuals is what I've been trying to push back upon. As I said in my initial response \"it doesn't scale for all bug reports and investigations to go through this tiny funnel\" though \"there are clearly examples where the process is critically needed\".\n> > > \n> > > Now that's not to say you may not have a point about better documentation and guidance on what should go through the vulnerability reporting process and what shouldn't. Or even that this particular issue could ultimately end up being classed a CVE. But rather than merely complaining and putting \"open source\" into quote marks perhaps suggest what class of bug reports should go through the tiny funnel and what shouldn't. Unless you think everything should go through the funnel in which case you are advocating for less openness whilst simultaneously complaining it isn't \"open source\". Square that circle.\n> > > \n> > > Thanks\n> > > Michael\n> > > \n> > > --\n> > > Michael Folkson\n> > > Email: michaelfolkson at protonmail.com\n> > > GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n> > > \n> > > Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n> > > \n> > > ------- Original Message -------\n> > > On Tuesday, May 16th, 2023 at 23:39, alicexbt alicexbt at protonmail.com wrote:\n> > > \n> > > > Hi Michael,\n> > > > \n> > > > A disagreement and some thoughts already shared in an email although its not clear to some \"open source\" devs:\n> > > > \n> > > > Impact of this vulnerability:\n> > > > \n> > > > - Denial of Service\n> > > > - Stale blocks affecting mining pool revenue\n> > > > \n> > > > Why it should have been reported privately to security at bitcoincore.org, even if initially found affecting only debug build?\n> > > > \n> > > > Example: https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-3129\n> > > > \n> > > > CVE is a different process and I am aware of it. It would be good for certain developers in the core team to reflect on their own approach to security, regardless of whether their work receives CVE recognition or not.\n> > > > \n> > > > /dev/fd0\n> > > > floppy disk guy\n> > > > \n> > > > Sent with Proton Mail secure email.\n> > > > \n> > > > ------- Original Message -------\n> > > > On Friday, May 12th, 2023 at 1:14 AM, Michael Folkson michaelfolkson at protonmail.com wrote:\n> > > > \n> > > > > Hi alicexbt\n> > > > > \n> > > > > The vulnerability reporting process requires communication and resolution via a small group of individuals 0 rather than through open collaboration between any contributors on the repo. There are clearly examples where the process is critically needed, the most obvious past example being the 2018 inflation bug 1. However, it doesn't scale for all bug reports and investigations to go through this tiny funnel. For an issue that isn't going to result in loss of onchain funds and doesn't seem to present a systemic issue (e.g. network DoS attack, inflation bug) I'm of the view that opening a public issue was appropriate in this case especially as the issue initially assumed it was only impacting nodes running in debug mode (not a mode a node in production is likely to be running in).\n> > > > > \n> > > > > An interesting question though and I'm certainly happy to be corrected by those who have been investigating the issue. Some delicate trade-offs involved including understanding and resolving the issue faster through wider collaboration versus keeping knowledge of the issue within a smaller group.\n> > > > > \n> > > > > Thanks\n> > > > > Michael\n> > > > > \n> > > > > --\n> > > > > Michael Folkson\n> > > > > Email: michaelfolkson at protonmail.com\n> > > > > GPG: A2CF5D71603C92010659818D2A75D601B23FEE0F\n> > > > > \n> > > > > Learn about Bitcoin: https://www.youtube.com/@portofbitcoin\n> > > > > \n> > > > > ------- Original Message -------\n> > > > > On Tuesday, May 9th, 2023 at 03:47, alicexbt via bitcoin-dev bitcoin-dev at lists.linuxfoundation.org wrote:\n> > > > > \n> > > > > > Hi Bitcoin Developers,\n> > > > > > \n> > > > > > There is an open issue in bitcoin core repository which was created last week: https://github.com/bitcoin/bitcoin/issues/27586\n> > > > > > \n> > > > > > I think this should have been reported privately as vulnerability instead of creating a GitHub issue even if it worked only in debug mode. Some users in the comments have also experienced similar issues without debug build used for bitcoind. I have not noticed any decline in the number of listening nodes on bitnodes.io in last 24 hours so I am assuming this is not an issue with majority of bitcoin core nodes. However, things could have been worse and there is nothing wrong in reporting something privately if there is even 1% possibility of it being a vulnerability. I had recently reported something to LND security team based on a closed issue on GitHub which eventually was not considered a vulnerability: https://github.com/lightningnetwork/lnd/issues/7449\n> > > > > > \n> > > > > > In the CPU usage issue, maybe the users can run bitcoind with bigger mempool or try other things shared in the issue by everyone.\n> > > > > > \n> > > > > > This isn't the first time either when vulnerability was reported publicly: https://gist.github.com/chjj/4ff628f3a0d42823a90edf47340f0db9 and this was even exploited on mainnet which affected some projects.\n> > > > > > \n> > > > > > This email is just a request to consider the impact of any vulnerability if gets exploited could affect lot of things. Even the projects with no financial activity involved follow better practices.\n> > > > > > \n> > > > > > /dev/fd0\n> > > > > > floppy disk guy\n> > > > > > \n> > > > > > Sent with Proton Mail secure email."
            }
        ],
        "thread_summary": {
            "title": "Responsible disclosures and Bitcoin development",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "alicexbt",
                "Michael Folkson"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 36673
        }
    },
    {
        "title": "[bitcoin-dev] Package Relay Proposal",
        "thread_messages": [
            {
                "author": "Tom Trevethan",
                "date": "2023-05-10T15:12:04",
                "message_text_only": "The submitpackage RPC is available on regtest in the current core release.\nIs there any plan or timeline for deploying this on mainnet in the next\nrelease? Can't find any recent discussion. It would be very helpful given\ncurrent (and likely future) issues with mempool purge.\n\nTom\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230510/58d866dc/attachment-0001.html>"
            },
            {
                "author": "Greg Sanders",
                "date": "2023-05-10T15:42:34",
                "message_text_only": "Hi Tom,\n\nYesterday a PR was opened to do just that, with caveats:\nhttps://github.com/bitcoin/bitcoin/pull/27609\n\nFor higher level tracking of the project:\nhttps://github.com/bitcoin/bitcoin/issues/27463\n\nCheers,\nGreg\n\nOn Wed, May 10, 2023 at 11:39\u202fAM Tom Trevethan via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> The submitpackage RPC is available on regtest in the current core\n> release. Is there any plan or timeline for deploying this on mainnet in the\n> next release? Can't find any recent discussion. It would be very helpful\n> given current (and likely future) issues with mempool purge.\n>\n> Tom\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230510/fbcf4d0f/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Package Relay Proposal",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Tom Trevethan",
                "Greg Sanders"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 1462
        }
    },
    {
        "title": "[bitcoin-dev] Interactive Payment Batching w/ Payjoin",
        "thread_messages": [
            {
                "author": "Dan Gould",
                "date": "2023-05-10T15:26:38",
                "message_text_only": "Hi list, The following message details a number of examples using payjoin P2EP to coordinate payment batches. I stray from the original shape of stenographic payjoin, what I call \"canonical payjoin\" with 2 inputs and many outputs, to describe what I believe are novel structures that break heuristics used to track batched payments. The later examples match typical batch structure while breaking common input heuristic.\n\nI'm curious to hear any feedback or concerns with these methods. This work is written in a less technical register than this list may be used to, but bitcoin-dev is the best forum to request for a critique of the thinking.\n\nThanks,\nDan\n\n\u2014\n\nINTERACTIVE PAYMENT BATCHING IS BETTER\n\n## Payjoin for More Than Privacy\n\nA high fee bitcoin always [triggers](https://twitter.com/BTCsessions/status/1655733065426296832) a [search](https://twitter.com/w_s_bitcoin/status/1655885695762808832) for more efficient use of blockspace. Blockchain is a slow database, and batching has got to be one of the oldest ways to optimize a database. Lightning is interactive payment batching based on intermittent settlement. Payjoin is interactive settlement batching. Merchant to customer payjoin is what led to the formal spec. No surprise then that a merchant / customer frame stuck versus a frame payment batching like lightning. Lightning has been batching for scaling all along. The following outlines how payjoin fits into batched transfer settlement infrastructure and how it helps prepare for the next wave of blockspace scarcity.\n\nThe term \"payjoin\" is used to describe both an interactive way to build transactions between peers on the web, aka Pay-to-Endpoint (P2EP), and an ambiguous transaction structure, typically with many inputs and two outputs that I dub *canonical payjoin*. Canonical payjoin looks like transaction behavior that any wallet could make, but its inputs actually come from more than one person. Breaking the assumption that all transaction inputs belong to the same person breaks the foundation of blockchain surveillance and the sole privacy problem left open in Satoshi's whitepaper. In an effort to improve bitcoin's privacy through payjoin adoption, I outline a number of ways payjoin can significantly reduce fee expenditure and blockchain throughput in individual and enterprise circumstances. Some of these new techniques preserve privacy for transactions otherwise thought of as unambiguous and certainly traceable. The examples mostly ignore mining fees for the sake of simplicity.\n\n## Before the Batch\n\n### Paying Naively\n\nPayjoin without the joi is just payn. ouch.\n\n```\nA's input0:    2 btc\nA's input1:    3 btc\n---\nB's output0:   4 btc B's address0\nA's output1:   1 btc A's change\n```\n\nA typical bitcoin transfer from `A`lice to `B`ob looks like this. Note that only the addresses and amounts are posted to chain with no further relation between inputs and outputs. The named labels are not. Third party analysts assume both inputs come from the same entity (because they usually do). They also assume `output0` is the payment because neither input is alone sufficient to make a payment of 4 btc.\n\n### Canonical Payjoin\n\nPayjoin foils that assumption because it lets Alice and Bob both contribute inputs. What would be interpreted as a naive payment might actually be a payjoin. Assuming both inputs always come from either Bob or Alice is wrong.\n\n```pre\nA's input0:      2 btc\nB's input1:     3 btc\n---\nA's output1:   1 btc A's change\nB's output0:   4 btc B's address0\n```\n\n\nAlice only paid 1 btc to `output0`'s 4 btc while merging it with Bob's 3 btc input txo too. Bob's 4 btc is not the 1 btc amount Alice paid, which is not visible.\n\n## Enter Output Substitution\n\nPayjoin [payment output substitution](https://github.com/bitcoin/bips/blob/master/bip-0078.mediawiki#payment-output-substitution) (`pjos`) lets a receiver like Bob substitute a proposed output with any outputs of equal amount. BIP 78 `pjos` is insecure over relayed communications and thus forbidden. BIP 78 receivers must run their own authenticated server to use `pjos`. [Serverless Payjoin](https://gist.github.com/DanGould/243e418752fff760c9f6b23bba8a32f9) secures relayed `pjos`.\n\nThe following examines the use of this technique to prevent address reuse, redirect funds to cold storage, forward payments, and batch transactions for massive fee savings.\n\n### The Minimum Effective Interaction\n\nLet's make not-quite-payjoin but something still fun. Call that Payjoi. Get it? Joy again? Hah \ud83e\udd41\ud83d\udca5.\n\nIf Bob's wallet is empty or he's using a cold wallet this would still work.\n\nImagine Bob's a bartender who posts the QR code for `bitcoin:address0?pj=https://payjoin.bob.cash` on an the wall at the bar.\n\nAlice would scan it to propose the transaction as before, but Bob returns the payjoin proposal with one tiny change. In this way he keeps his tip private from nosy neighbors at the bar.\n\n```pre\nA's input0:    2 btc\nA's input1:    3 btc\n---\nB's output0:   4 btc B's address1\nA's output1:   1 btc A's change\n\n```\n\nSee, Bob swapped `output0`'s `address0` for `address1`. Other patrons do not know of `address1` since Bob sent it online as a payjoin proposal. They can't look up what they don't know.\n\n### Payment forwarding\n\nToys aside, substitution is powerful. What if Bob planned to pay his `C`loud provider next time he got paid. He could substitute `C`loudy's address instead of his `address1`.\n\n```pre\nA's input0:    2 btc\nA's input1:    3 btc\n---\nC's output0:   4 btc C's address\nA's output1:   1 btc A's change\n\n```\n\nAlice only sees `C`'s address as unique, and the payjoin proposal is authenticated by Bob, so both of them agree that this payjoin pays Bob. Since transactions are atomic, Bob takes no custody of the funds going to `C`loudy either.\n\nBob could also turn this into a canonical payjoin by adding input. Or instead, Bob could forward funds to his cold storage rather than to Cloudy. That could be valuable if Bob's payjoin server hot wallet had more funds than he was comfortable with keeping online. Alice even still pays the miner fee as she would in any case. Bob saves the blockspace, time, money and hassle of a making separate transaction to forward.\n\n### Receiver side Payment Batching\n\nWe're going to make this more complex, because it scales bitcoin and it's fun.\n\nImagine Bob is an exchange sitting on a few low-priority withdrawal orders from `D`an of 0.6 btc and and `E`rin of 0.4 btc. When Alice proposes a deposit, Bob may substitute a single output with many, spreading the inbound amount across multiple addresses. Instead of just *address* substitution he substitutes the entire output with new ones.\n\n```\nA's input0:    2 btc\nA's input1:    3 btc\n---\nB's output0:   0.99 btc B's address0\nA's output1:   3 btc A's change\nD's output2:   0.4 btc D's address\nE's output3:   0.6 btc E's address\n\n```\n\nBatching saves mining fees for Bob since Alice already pays for some transaction fee. Bob can take any remaining mining fee costs from his increased transaction's size out of his own output, `address0` shown here receiving 0.99 btc to pay an additional 0.01 btc fee. Not shown, Bob could even split Cloudy's output from the prior example to forward Cloudy an exact invoice amount and keep the change.\n\n[Prior](https://www.bullbitcoin.com/blog/announcing-batcher-by-bull-bitcoin-open-source-non-custodial-on-chain-wallet-batching-plugin-for-high-volume-bitcoin-enterprise-users) [art](https://blog.bitgo.com/utxo-management-for-enterprise-wallets-5357dad08dd1) [all](https://medium.com/@hasufly/an-analysis-of-batching-in-bitcoin-9bdf81a394e0) [explores](https://bitcoinops.org/en/payment-batching/) sender-batched transactions. It follows that inputs to batched transactions are assumed to belong to the cluster of the entity making payments (Bob, in this case). Receiver side payment batching kills this heuristic analysis, providing multiple new interpretations for payments of few inputs and many outputs.\n\n### Lightning Channels\n\nYes, even [lightning channel payjoin](https://chaincase.app/words/lightning-payjoin) outputs are viable. Lightning channels are posted as 2-of-2 P2SH or P2TR addresses.\n\n```\nA's input0:    5 btc\n---\nB's output0:   2 btc B & his peer's \u26a1\ufe0f channel\nA's output1:   3 btc A's change\n\n```\n\nBob's lightning output helps preserve privacy even moreso because it belongs to two parties, both Bob and his channel peer. When P2TR channels are the norm, a stranger would not even know that `output0` is for lightning. New standard lightning protocols allow for payjoin output splicing and dual funded channels to achieve the common input assumption-busting result even without BIP 78 as well.\n\n### Mix and Batch \ud83e\udd63\n\nCombining it all forces multiple ambiguous interpretations of the transaction graph. With basic networking, and no coordinator, Both Alice and Bob can pay multiple parties beyond themselves, combine inputs and consolidate funds without fear for being censored.\n\nInteraction lets multiple ambiguous possibilities converge to preserve bitcoin's inherent fungibility. No inconvenient, fee intensive, pre-scheduled, time consuming mixing step required.\n\n#### Batch Sender and Receiver Transactions to Put a Cherry on Top \ud83c\udf70\n\n```\nA's input0:    2 btc\nB's input1:    4 btc\nB's input2:    3 btc\n---\nB's output0:   1.5 btc B's address1\nA's output1:   2 btc A's change\nB's output2:   0.4 btc B's \u26a1\ufe0f channel\nC's output3:   2.5 btc C's address\nE's output4:   1 btc E's address\nD's output5:   0.6 btc D's address\nF's output6:   1 btc F's address\n\n```\n\nEven though amounts aren't equal, these new payjoin constructions provide significant ambiguity to foil vast swaths of heuristic analysis being done today by breaking their most basic assumptions. Because of payjoin's intra-transaction transfers from Alice to Bob, [CoinJoin sudoku](http://www.coinjoinsudoku.com/advisory/) analysis does not apply.\n\nEven Alice and Bob preserve some privacy in the other's view. Even though one knows the other's inputs, they cannot be certain that any of their counterpart's outputs will end up in their counterpart's wallet or if output substitution has been used.\n\n## Progress before rainbows \ud83c\udf08 and unicorns \ud83e\udd84\n\nBob and Alice still know the subtransactions of their counterpart. As of today, Bob still needs to run a server. They each know which inputs belong to which counterpart. While p2p can do a lot, an adversarial counterparty could still report the other's chosen inputs and outputs to build a cluster with an analysis firm. I know those problems need to be solved, but look how far ahead a simple HTTP interaction can take us.\n\n**Thanks** to Hunter Beast, Andrew \"Kukks\" Camilleri, Ishi, Kexkey, Francis Pouliot, and Yashraj for reading drafts of this."
            }
        ],
        "thread_summary": {
            "title": "Interactive Payment Batching w/ Payjoin",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Dan Gould"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 10720
        }
    },
    {
        "title": "[bitcoin-dev] Seeking concept ACKs for transaction terminology BIP",
        "thread_messages": [
            {
                "author": "Keagan McClelland",
                "date": "2023-05-10T20:20:53",
                "message_text_only": "Concept ACK,\n\nThe only way we can hope to have productive discussion is to minimize the\namount of effort spent in miscommunication especially that which arises\nfrom unclear terminology. Which exact words refer to which meanings is\nsomewhat arbitrary, (look at math, particularly abstract math), but what\nmatters is that there is precision in their use to whatever degree is\npossible. Having a document of shared terminology helps us communicate with\none another and speeds up the process of coming to social consensus on\nissues.\n\nStay Inspired,\nKeags\n\nOn Wed, Apr 5, 2023 at 2:54\u202fPM Murch via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hey everyone,\n>\n> Over the years, I have participated in a few conversations about various\n> aspects of transactions. Often a chunk of the conversation is spent on\n> establishing a shared vocabulary. There are many competing terms\u2014e.g. I\n> can think of at least three additional terms that refer to `scriptPubKey`.\n>\n> I\u2019ve drafted an informational BIP that proposes terminology for various\n> components and aspects of transactions. As some established terms are\n> already contradictory, the proposal does not aim for a perfectly\n> consistent selection of terms, but rather just to establish a shared\n> vocabulary to avoid confusion.\n>\n> Draft: https://github.com/Xekyo/bips/pull/1\n>\n> Please let me know whether you\u2019d be interested in the creation of such a\n> BIP.\n>\n> Cheers,\n> Murch\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230510/3928ae0e/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Seeking concept ACKs for transaction terminology BIP",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Keagan McClelland"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1814
        }
    },
    {
        "title": "[bitcoin-dev] ZeroSync: Introducing Validity Proofs to Bitcoin",
        "thread_messages": [
            {
                "author": "Robin Linus",
                "date": "2023-05-12T12:12:03",
                "message_text_only": "Hi all,\n\nToday we are publishing a summary of our research on \"ZeroSync: Introducing Validity Proofs to Bitcoin\".\n\n\nHere's the preface:\n\nWe introduce ZeroSync, the first-ever proof system addressing Bitcoin\u2019s scalability challenges with Succinct Non-Interactive Argument of Knowledge (SNARKs). ZeroSync compresses the entire Bitcoin blockchain into a compact proof of validity, enabling instant verification and unlocking various innovative applications. We discuss our prototype implementation of a chain state proof, utilizing the Cairo language, Utreexo, and recursive STARKs. Our work enables diverse applications, including quick bootstrapping of full nodes, trustless light clients, enhanced Lightning Network privacy, and secure cross-chain bridges. Chain state proofs require no consensus changes, which is crucial as forks in Bitcoin are challenging to implement and achieve consensus for. Despite the existing bottleneck of prover performance, we present a range of optimization strategies and demonstrate the practicality of generating a complete chain state proof. \nFinally, we introduce zkCoins, a client-side validation protocol combined with zeroknowledge SNARKs, drastically improving privacy and throughput of token transactions. In combination with future Bitcoin features, such as Simplicity, zkCoins also enables private and more scalable BTC transactions. \nThe groundbreaking compression capabilities of SNARKs initiated a paradigm shift in cryptocurrency design, and ZeroSync is pioneering their application to Bitcoin.\n\n\nYou can find the full paper here: https://zerosync.org/zerosync.pdf <https://zerosync.org/zerosync.pdf>\nHappy to receive any comments and answer any questions the bitcoin dev community may have about the paper!\n\n\n\nBest regards,\nRobin Linus\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230512/877a4e9c/attachment.html>"
            },
            {
                "author": "Weiji Guo",
                "date": "2023-05-12T15:32:55",
                "message_text_only": "Hi Robin,\n\nCould you please expand more on how you plan to \"implement a SNARK verifier\non Bitcoin\u2019s base layer\"?\n\nFor your information, I happen to be the one proposing a new opcode OP_ZKP\nto enable the Bitcoin network to verify zkp proofs. My proposal requires a\nsoft fork. You may find more information from the email archive here:\nhttps://www.mail-archive.com/bitcoin-dev@lists.linuxfoundation.org/msg12601.html\n\nWe might be tackling similar issues and probably could benefit from each\nother.\n\nThanks,\nWeiji\n\nOn Fri, May 12, 2023 at 9:16\u202fPM Robin Linus via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi all,\n>\n> Today we are publishing a summary of our research on \"ZeroSync:\n> Introducing Validity Proofs to Bitcoin\".\n>\n>\n> Here's the preface:\n>\n> *We introduce ZeroSync, the first-ever proof system addressing Bitcoin\u2019s\n> scalability challenges with Succinct Non-Interactive Argument of Knowledge\n> (SNARKs). ZeroSync compresses the entire Bitcoin blockchain into a compact\n> proof of validity, enabling instant verification and unlocking various\n> innovative applications. We discuss our prototype implementation of a chain\n> state proof, utilizing the Cairo language, Utreexo, and recursive STARKs.\n> Our work enables diverse applications, including quick bootstrapping of\n> full nodes, trustless light clients, enhanced Lightning Network privacy,\n> and secure cross-chain bridges. Chain state proofs require no consensus\n> changes, which is crucial as forks in Bitcoin are challenging to implement\n> and achieve consensus for. Despite the existing bottleneck of prover\n> performance, we present a range of optimization strategies and demonstrate\n> the practicality of generating a complete chain state proof. *\n> *Finally, we introduce zkCoins, a client-side validation protocol combined\n> with zeroknowledge SNARKs, drastically improving privacy and throughput of\n> token transactions. In combination with future Bitcoin features, such as\n> Simplicity, zkCoins also enables private and more scalable BTC\n> transactions. *\n> *The groundbreaking compression capabilities of SNARKs initiated a\n> paradigm shift in cryptocurrency design, and ZeroSync is pioneering their\n> application to Bitcoin.*\n>\n>\n> You can find the full paper here: https://zerosync.org/zerosync.pdf\n> Happy to receive any comments and answer any questions the bitcoin dev\n> community may have about the paper!\n>\n>\n>\n> Best regards,\n> Robin Linus\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230512/108d3ca1/attachment.html>"
            },
            {
                "author": "Robin Linus",
                "date": "2023-05-12T16:03:06",
                "message_text_only": "Hi Weiji,\n\n> Could you please expand more on how you plan to \"implement a SNARK verifier on Bitcoin\u2019s base layer\"?\nFirst, I should clarify that I see this as a long-term option, which will take years. If Simplicity gets activated, we could use it to implement a SNARK verifier on Bitcoin's base layer. But for now, we just plan to experiment with Simplicity on the Liquid sidechain when it gets activated.\n\n\n> For your information, I happen to be the one proposing a new opcode OP_ZKP to enable the Bitcoin network to verify zkp proofs. My proposal requires a soft fork. You may find more information from the email archive here: https://www.mail-archive.com/bitcoin-dev@lists.linuxfoundation.org/msg12601.html <https://www.mail-archive.com/bitcoin-dev@lists.linuxfoundation.org/msg12601.html>\nI've seen it; however, I suppose it is hard to establish consensus over some particular kind of op_snark_verify opcode because there are so many competing proof systems with different trade-offs. For example, STARKs are great for a chain state proof as they are scalable and allow for processing huge circuits; however, I would not favor STARKs for an on-chain verifier because there are other proof systems, such as Plonky2, with much smaller proof sizes.\n\nA nice thing about SNARK verifiers is that once we have any verifier, we can use it to wrap other proofs. E.g., we could \"compress\" the size of a STARK by verifying it in a Plonky2 proof.\nStill, Simplicity offers much more flexibility and allows to update verifiers as the research advances.\n\n\n> We might be tackling similar issues and probably could benefit from each other. \n\nSounds good! Please join our Telegram group, if you would like to chat about SNARKs on Bitcoin https://t.me/zerosync_chat <https://t.me/zerosync_chat>\n\n\n\nCheers,\nRobin \n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230512/4ff96f5d/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "ZeroSync: Introducing Validity Proofs to Bitcoin",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Robin Linus",
                "Weiji Guo"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 6763
        }
    },
    {
        "title": "[bitcoin-dev] libsecp256k1 0.3.2 released",
        "thread_messages": [
            {
                "author": "Tim Ruffing",
                "date": "2023-05-14T17:35:38",
                "message_text_only": "Hello,\n\nWe'd like to announce the release of version 0.3.2 of libsecp256k1:\n\n  https://github.com/bitcoin-core/secp256k1/releases/tag/v0.3.2\n\nThis is a bugfix release after 0.3.1. The impetus for this release is\nthe discovery that GCC 13 became smart enough to optimize out a\nspecific timing side-channel protection mechanism in the ECDH code that\ncould leave applications vulnerable to a side-channel attack. This has\nbeen fixed in 0.3.2 [1].\n\nFor the full changelog, see\n  https://github.com/bitcoin-core/secp256k1/blob/master/CHANGELOG.md\n\nWe strongly recommend any users of the library to upgrade if their code\nmay end up being compiled with GCC >=13. Bitcoin Core is not affected\nbecause it does not use libsecp256k1's ECDH module.\n\nNote: The underlying side-channel issue is very similar to the issue\nthat lead to the previous 0.3.1 release. Unfortunately, there is no\ngeneric way to prevent compilers from \"optimizing\" code by adding\nsecret-dependent branches (which are undesired in cryptographic\napplications), and it is hard to predict what optimizations future\ncompiler versions will add. There's ongoing work [2] to test on\nunreleased development snapshots of GCC and Clang, which would make it\npossible to catch similar cases earlier in the future.\n\n[1]: https://github.com/bitcoin-core/secp256k1/pull/1303\n[2]: https://github.com/bitcoin-core/secp256k1/pull/1313"
            }
        ],
        "thread_summary": {
            "title": "libsecp256k1 0.3.2 released",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Tim Ruffing"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1376
        }
    },
    {
        "title": "[bitcoin-dev] Stake Certificates and Web-of-Stakes: privacy-preserving proving UTXOs attributes in P2P systems",
        "thread_messages": [
            {
                "author": "Antoine Riard",
                "date": "2023-05-18T06:08:46",
                "message_text_only": "Hi list,\n\nOne obvious usage of zero-knowledge proof cryptosystems in the Bitcoin\necosystem (e.g Bulletproofs) is the construction of privacy-preserving\nUTXO ownership proofs. UTXO ownership proofs are already used in\nproduction across the Lightning ecosystem to authenticate the channels\nannouncements over the peer-to-peer gossip network. Additionally, UTXO\nownership proofs have been considered in the past for Lightning\njamming mitigations.\n\nThis type of mitigations dubbed \"Stakes Certificates\" while limited as\npure jamming mitigations are very interesting to solve counterparty\nsearch in peer-to-peer marketplaces for decentralized Bitcoin\nfinancial contracts (e.g coinjoins market-matching).\n\n# Stakes Certificates\n\nStakes Certificates is a protocol (crypto-systems + validation\nalgorithms) enabling to prove a set of attributes about a UTXO in a\nprivacy-preserving fashion. Attributes are arbitrary strings about\nUTXO characteristics such as the amount in satoshis and the\nscriptPubkeys. From access to the UTXO set only, additional attributes\ncan be asserted such as the Script spending policy, if the\nwitnessScript (or equivalent for the scriptPubkey type) is revealed by\nthe prover, I think.\n\nAdvanced attributes could be asserted such as the UTXO age in height\nor a timestamp in UNIX epoch if a merkle proof to show the inclusion\nof the UTXO in the header chain constitutes the encrypted plaintext\nbeyond the UTXO itself. One more attribute can be the UTXO lineage of\nsome block-depth N if the chain of spent TXOs is part of the\nplaintext, I believe. UTXO lineage can be a criteria of relevance for\ncoinjoins\nmarketplace.\n\nThe Stakes Certificates protocol flow works in the following way:\n- the verifier and prover negotiate the system and security parameters\n- the verifier announce constraints to reduce the set of attributes\nfrom the combinations of information universes (e.g \"UTXO of amount\nsuperiors to 10000 sats\")\n- the prover build a statement and a witness corresponding to the set\nof attributes selected under the constraints\n- the verifier accepts or rejects the pair of statement and witness\n\nBeyond the UTXO attributes, the scheme can respect additional security\nproperties such as uniqueness, e.g the UTXO should be unique in the\nset of UTXOs from a session defined by the verifier. Another security\nproperty can be \"value upper bounding\" for a series of concurrent\nproofs verification. I think it would be logically analogous to a\nconfidential transaction session where the ledger supply is defined by\nthe verifier. This property can be useful for a coinjoin coordinator\nto enforce some intersection characteristics of UTXO lineage.\n\nOnce the Stakes Certificates protocol flow session is over, the\nverifier can store the validation result in its internal state. E.g if\nit's a Lightning channel announcement, the proved channel can be\nstored as a valid entry in the routing database for further\nconsumptions by the scoring algorithms.\n\n# Web-of-Stakes\n\nOn top of the Stake Certificates protocol, a Web-of-Stakes protocol\ncan be laid out. A Web-of-Stakes protocol enables an entity to prove a\nset of attributes for a set of UTXOs across Bitcoin contexts (e.g\ncombining UTXO attributes across swaps and lightning sessions). The\nentity can be composed   from multiple sub-entities, such as a\nLightning Service Provider and its spokes clients.\n\nA Web-of-Stakes protocol flow works in the following way:\n- the prover announces a public key respecting some public\nverifiability (public verifiability in the sense of a client-server\ncryptographic protocol like Privacy Pass)\n- the prover realizes a sequence of Stakes Certificates validation\nwith the verifier where the public key is committed as part of the\nstatement/witness\n- the verifier accumulates the result of each Stakes Certificates\n- if the accumulation satisfies verifier authorization policy, a\ncredential is yielded back to the prover\n\nThis Web-of-Stakes protocol can be leveraged to build counterparty and\ntrades search among peer-to-peer marketplaces where the prover can\nselectively reveal attributes of its economic behavior based on the\nUTXO footprint in the chain. E.g, a coinjoin maker can choose to\nreveal the trace of its past coinjoin contributions as a way to build\n\"good market faith\" for the takers.\n\nThis Web-of-Stakes protocol can be combined with modern techniques\nfrom Web-of-Trust like decentralized identifiers where a chain of\nsigned PGP messages can be transposed in a unique entity \"score\" as\npart of the verifier authorization policy evaluation. E.g, a cluster\nof Nostr clients with an interest in collaborative transaction\nconstruction can bless a set of Lightning Service Providers\nspecialized in splicing.\n\nThis Web-of-Stakes protocol can be combined with a client-server\nframework for the providence of privacy-preserving credentials e.g\nStaking Credentials. E.g a \"signature-of-stakes\" is generated and\nbased on the economic weight the credential fee required to publish on\na Nostr relay is adjusted.\n\n# Zero-Knowledge Proofs Protocols\n\nA zero-knowledge proof of knowledge is a protocol in which a prover\ncan convince a verifier that some statement holds without revealing\nany information about why it holds. For Stakes Certificates, the level\nof expressivity expected is to be superior to set membership, where a\nwide-range of computational statements about the UTXO attributes can\nbe made.\n\nZero-knowledge proof systems have been designed under diverse\ncryptographic assumptions: collision-resistant hash, elliptic curve\nDLP and knowledge of exponent. Each one comes with a set of trade-offs\nin terms of size proofs, generation time and verification time. While\nthe Stakes Certificates can be deployed on hosts and configuration\nwith different requirements (e.g mobile with low bandwidth), if we\nhave multiple practical ZKP systems for the Bitcoin use-cases, the\ncryptosystems could be negotiated by the clients to suit their\ncomputational resources.\n\n# Applications\n\nBeyond the Web-of-Stakes as a generic application aiming to solve\ncounterparty search in peer-to-peer marketplace, the Stakes\nCertificate protocol can be used for another set of applications.\n\n## Proof-of-liabilites for Ecash Mint\n\nThere has been a renewed interest for Chaumian mint across the Bitcoin\necosystem during the last years. One of the hard issues is ensuring\nthe supply of ecash tokens does not grow more than the stack of\nsatoshis represented by the UTXOs. Stakes Certificates could be used\nto ensure there has always been a 1-to-1 mapping between the ecash\ntokens and the UTXOs ownership.\n\n## Privacy-Preserving Lightning Channel Announcement\n\nThe Stakes Certificates could be used to replace the plaintext\nLightning gossip where the Lightning routing hops are announcing all\ntheir connections. With P2TR, the gossip announcement receiver can be\ninterested to verify some tapscript policy, and as such there is no\nthird-party able to force-close the channel.\n\n## Scarce Computational Resources in P2P Systems\n\nThe UTXOs can be used as DoS mitigations in peer-to-peer systems where\nrequiring the payment of a fee prevents bootstrapping of its state by\na new participant or there can be exploitable asymmetries, e.g a\nBitcoin node sending spam transactions, where \"fresh\" UTXOs are\nrequested in replacement of `min_relay_tx_fee`.\n\nCheers,\nAntoine\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230518/6d3dc98b/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Stake Certificates and Web-of-Stakes: privacy-preserving proving UTXOs attributes in P2P systems",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Antoine Riard"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 7523
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Core 24.1 released",
        "thread_messages": [
            {
                "author": "Michael Ford",
                "date": "2023-05-19T10:56:14",
                "message_text_only": "Bitcoin Core version 24.1 is now available from:\n\n  <https://bitcoincore.org/bin/bitcoin-core-24.1/>\n\nOr through BitTorrent:\n\n  magnet:?xt=urn:btih:ebb58d7495a8aaed2f20ec4ce3e5ae27aff69529&dn=bitcoin-core-24.1&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969%2Fannounce&tr=udp%3A%2F%2Ftracker.leechers-paradise.org%3A6969%2Fannounce&tr=udp%3A%2F%2Fexplodie.org%3A6969%2Fannounce&tr=udp%3A%2F%2Ftracker.torrent.eu.org%3A451%2Fannounce&tr=udp%3A%2F%2Ftrakcer.bitcoin.sprovoost.nl%3A6969\n\nThis release includes various bug fixes and performance\nimprovements, as well as updated translations.\n\nPlease report bugs using the issue tracker at GitHub:\n\n  <https://github.com/bitcoin/bitcoin/issues>\n\nTo receive security and update notifications, please subscribe to:\n\n  <https://bitcoincore.org/en/list/announcements/join/>\n\nHow to Upgrade\n==============\n\nIf you are running an older version, shut it down. Wait until it has completely\nshut down (which might take a few minutes in some cases), then run the\ninstaller (on Windows) or just copy over `/Applications/Bitcoin-Qt` (on macOS)\nor `bitcoind`/`bitcoin-qt` (on Linux).\n\nUpgrading directly from a version of Bitcoin Core that has reached its EOL is\npossible, but it might take some time if the data directory needs to\nbe migrated. Old\nwallet versions of Bitcoin Core are generally supported.\n\nCompatibility\n==============\n\nBitcoin Core is supported and extensively tested on operating systems\nusing the Linux kernel, macOS 10.15+, and Windows 7 and newer.  Bitcoin\nCore should also work on most other Unix-like systems but is not as\nfrequently tested on them.  It is not recommended to use Bitcoin Core on\nunsupported systems.\n\n### P2P\n\n- #26878 I2P network optimizations\n- #26909 net: prevent peers.dat corruptions by only serializing once\n- #27608 p2p: Avoid prematurely clearing download state for other peers\n- #27610 Improve performance of p2p inv to send queues\n\n### RPC and other APIs\n\n- #26515 rpc: Require NodeStateStats object in getpeerinfo\n- #27279 doc: fix/improve warning helps in {create,load,unload,restore}wallet\n- #27468 rest: avoid segfault for invalid URI\n\n### Build System\n\n- #26944 depends: fix systemtap download URL\n- #27462 depends: fix compiling bdb with clang-16 on aarch64\n\n### Wallet\n\n- #26595 wallet: be able to specify a wallet name and passphrase to\nmigratewallet\n- #26675 wallet: For feebump, ignore abandoned descendant spends\n- #26679 wallet: Skip rescanning if wallet is more recent than tip\n- #26761 wallet: fully migrate address book entries for\nwatchonly/solvable wallets\n- #27053 wallet: reuse change dest when re-creating TX with avoidpartialspends\n- #27080 wallet: Zero out wallet master key upon locking so it doesn't\npersist in memory\n- #27473 wallet: Properly handle \"unknown\" Address Type\n\n### GUI changes\n\n- gui#687 Load PSBTs using istreambuf_iterator rather than istream_iterator\n- gui#704 Correctly limit overview transaction list\n\n### Miscellaneous\n\n- #26880 ci: replace Intel macOS CI job\n- #26924 refactor: Add missing includes to fix gcc-13 compile error\n\nCredits\n=======\n\nThanks to everyone who directly contributed to this release:\n\n- Andrew Chow\n- Anthony Towns\n- Hennadii Stepanov\n- John Moffett\n- Jon Atack\n- Marco Falke\n- Martin Zumsande\n- Matthew Zipkin\n- Michael Ford\n- pablomartin4btc\n- Sebastian Falbesoner\n- Suhas Daftuar\n- Thomas Nguyen\n- Vasil Dimov\n\nAs well as to everyone that helped with translations on\n[Transifex](https://www.transifex.com/bitcoin/bitcoin/)."
            },
            {
                "author": "Sjors Provoost",
                "date": "2023-05-19T11:20:26",
                "message_text_only": "There's a typo in the tracker subdomain: trakcer.bitcoin.sprovoost.nl <http://trakcer.bitcoin.sprovoost.nl/> should be tracker.bitcoin.sprovoost.nl <http://tracker.bitcoin.sprovoost.nl/>, but I'll just add that subdomain now.\n\n- Sjors\n\n> Op 19 mei 2023, om 12:56 heeft Michael Ford via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:\n> \n> Bitcoin Core version 24.1 is now available from:\n> \n>  <https://bitcoincore.org/bin/bitcoin-core-24.1/>\n> \n> Or through BitTorrent:\n> \n>  magnet:?xt=urn:btih:ebb58d7495a8aaed2f20ec4ce3e5ae27aff69529&dn=bitcoin-core-24.1&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969%2Fannounce&tr=udp%3A%2F%2Ftracker.leechers-paradise.org%3A6969%2Fannounce&tr=udp%3A%2F%2Fexplodie.org%3A6969%2Fannounce&tr=udp%3A%2F%2Ftracker.torrent.eu.org%3A451%2Fannounce&tr=udp%3A%2F%2Ftrakcer.bitcoin.sprovoost.nl%3A6969\n\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230519/b1700b61/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Core 24.1 released",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Michael Ford",
                "Sjors Provoost"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 4831
        }
    },
    {
        "title": "[bitcoin-dev] Full-RBF Peering Bitcoin Core v24.1 Released",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2023-05-21T21:21:33",
                "message_text_only": "On Fri, May 19, 2023 at 11:56:14AM +0100, Michael Ford via bitcoin-dev wrote:\n> Bitcoin Core version 24.1 is now available from:\n> \n>   <https://bitcoincore.org/bin/bitcoin-core-24.1/>\n\nAvailable from: https://github.com/petertodd/bitcoin/tree/full-rbf-v24.1\n\neg:\n\n    git clone -b full-rbf-v24.1 https://github.com/petertodd/bitcoin.git\n\nWhat is this? It's Bitcoin Core v24.1, with Antoine Riard's full-rbf peering\ncode, and some additional minor updates to it. This does two things for\nfull-rbf nodes:\n\n1) Advertises a FULL_RBF service bit when mempoolfullrbf=1 is set.\n2) Connects to four additional FULL_RBF peers.\n\nDoing this ensures that a core group of nodes are reliably propagating full-rbf\nreplacements. We don't need everyone to run this. But it'd be helpful if more\npeople did.\n\nAs for why you should run full-rbf, see my blog post:\n\nhttps://petertodd.org/2023/why-you-should-run-mempoolfullrbf\n\n\nWe even have hats! :D\n\nhttps://twitter.com/peterktodd/status/1659996011086110720/photo/1\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230521/7de5e4eb/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Full-RBF Peering Bitcoin Core v24.1 Released",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Peter Todd"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1324
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Core 23.2 released",
        "thread_messages": [
            {
                "author": "Michael Ford",
                "date": "2023-05-19T10:59:51",
                "message_text_only": "Bitcoin Core version 23.2 is now available from:\n\n  <https://bitcoincore.org/bin/bitcoin-core-23.2/>\n\nOr through BitTorrent:\n\n  magnet:?xt=urn:btih:e672796b257f0d3d3043d9022c4df57b2c9f6ede&dn=bitcoin-core-23.2&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969%2Fannounce&tr=udp%3A%2F%2Ftracker.leechers-paradise.org%3A6969%2Fannounce&tr=udp%3A%2F%2Fexplodie.org%3A6969%2Fannounce&tr=udp%3A%2F%2Ftracker.torrent.eu.org%3A451%2Fannounce&tr=udp%3A%2F%2Ftrakcer.bitcoin.sprovoost.nl%3A6969\n\nThis release includes various bug fixes and performance\nimprovements, as well as updated translations.\n\nPlease report bugs using the issue tracker at GitHub:\n\n  <https://github.com/bitcoin/bitcoin/issues>\n\nTo receive security and update notifications, please subscribe to:\n\n  <https://bitcoincore.org/en/list/announcements/join/>\n\nHow to Upgrade\n==============\n\nIf you are running an older version, shut it down. Wait until it has completely\nshut down (which might take a few minutes in some cases), then run the\ninstaller (on Windows) or just copy over `/Applications/Bitcoin-Qt` (on macOS)\nor `bitcoind`/`bitcoin-qt` (on Linux).\n\nUpgrading directly from a version of Bitcoin Core that has reached its EOL is\npossible, but it might take some time if the data directory needs to\nbe migrated. Old\nwallet versions of Bitcoin Core are generally supported.\n\nCompatibility\n==============\n\nBitcoin Core is supported and extensively tested on operating systems\nusing the Linux kernel, macOS 10.15+, and Windows 7 and newer.  Bitcoin\nCore should also work on most other Unix-like systems but is not as\nfrequently tested on them.  It is not recommended to use Bitcoin Core on\nunsupported systems.\n\n### P2P\n\n- #26909 net: prevent peers.dat corruptions by only serializing once\n- #27608 p2p: Avoid prematurely clearing download state for other peers\n- #27610 Improve performance of p2p inv to send queues\n\n### Build system\n\n- #25436 build: suppress array-bounds errors in libxkbcommon\n- #25763 bdb: disable Werror for format-security\n- #26944 depends: fix systemtap download URL\n- #27462 depends: fix compiling bdb with clang-16 on aarch64\n\n### Miscellaneous\n\n- #25444 ci: macOS task imrovements\n- #26388 ci: Use macos-ventura-xcode:14.1 image for \"macOS native\" task\n- #26924 refactor: Add missing includes to fix gcc-13 compile error\n\nCredits\n=======\n\nThanks to everyone who directly contributed to this release:\n\n- Anthony Towns\n- Hennadii Stepanov\n- MacroFake\n- Martin Zumsande\n- Michael Ford\n- Suhas Daftuar\n\nAs well as to everyone that helped with translations on\n[Transifex](https://www.transifex.com/bitcoin/bitcoin/)."
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Core 23.2 released",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Michael Ford"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2701
        }
    },
    {
        "title": "[bitcoin-dev] Ark: An Alternative Privacy-preserving Second Layer Solution",
        "thread_messages": [
            {
                "author": "Burak Keceli",
                "date": "2023-05-22T07:54:03",
                "message_text_only": "Hi list,\nI'm excited to publicly publish a new second-layer protocol design I've been working on over the past few months called Ark.\n \nArk is an alternative second-layer scaling approach that allows the protocol users to send and receive funds without introducing liquidity constraints. This means a recipient can get paid without an onboarding setup, such as acquiring inbound liquidity. The protocol also consumes orders of magnitude less on-chain footprint than Lightning, as there is no concept of opening and closing channels.\n \nArk has a UTXO set that lives off the chain. These UTXOs are referred to as virtual UTXOs or vTXOs in short. Virtual UTXOs are like short-lived notes that expire after four weeks. Users must spend their vTXOs upon receiving them within this four-week timeframe or return them to themselves to reset the four-week timer. Virtual UTXOs live under a shared UTXO and can be revealed on-chain.\n \nWhen a payment is made on the protocol, existing vTXOs are redeemed, and new vTXOs are created, similar to how on-chain funds flow. To improve the anonymity set of the coin ownership, vTXOs values are restricted to a set of sats values ranging from one sat to a million sats.\n \nUsers can acquire vTXOs from someone who already owns them or use a process called lifting, an atomic two-way peg mechanism that doesn't require trust. Lifting lets users lift their on-chain UTXOs off the chain for a 1:1 virtual UTXO. Users can unilaterally redeem a virtual UTXO for an on-chain UTXO without asking for cooperation. \n \nWhen sending funds, users coin-select & destroy their virtual UTXOs and create new ones for the recipient (plus change) in an off-chain mixing round. Keys for each new virtual UTXO are tweaked with a shared secret that reveals proof of payment when spent. The payment destination is a dedicated well-known public key similar to silent payments; however, the payment trace is obfuscated through plain tweaking and blinded mixing.\n \nArk enables anonymous, off-chain payments through an untrusted intermediary called the Ark Service Provider (ASP). ASPs are always-on servers that provide liquidity to the network and charge liquidity fees, similar to how Lightning service providers work. ASPs on Ark are both (1) liquidity providers, (2) blinded coinjoin coordinators, and (3) Lightning service providers. ASPs main job is to create rapid, blinded coinjoin sessions every five seconds, also known as pools. A user joins a pool session to make a payment, initially coin-selecting and registering their vTXOs to spend, registering vTXOs for intended recipients, and finally co-signing from their vTXOs to redeem them.\n \nArk can be built on Bitcoin today, but we have to compromise on non-interactivity to do so. Recipients must be online to sign from n-of-n multisig to constrain the outputs of a shared UTXO, outputs as in vTXOs. With this approach, users won\u2019t be able to receive offline payments; they need to self-host an Ark client (like Lightning). To make Ark work without running a server, we need a covenant primitive such as BIP-118 or BIP-119. \n \nBIP-118 ANYPREVOUTANYSCRIPT can constrain outputs of a spending transaction by hardcoding a 65-byte signature and a 33-byte unknown public key type in a script. Alternatively, BIP-119 CTV can directly constrain transaction outputs to a template hash. Other alternatives would be (1) TXHASH, (2) CAT + CSFS + TAGGEDHASH, or (3) XOR + CSFS + TAGGEDHASH combinations. \n \nArk uses a new locktype primitive called txlock to ensure the absolute atomicity of a transfer schedule. Txlock is a condition in which only the existence of a mutually agreed transaction identifier can unlock the condition. A txlock condition could be satisfied by a hypothetical opcode called OP_CHECKPREVTXIDFROMTHEUTXOSETVERIFY. However, Ark uses an alternative approach to achieving the same outcome using connectors. Connectors are a special output type on the protocol. The primitive is that if we want the Bitcoin script to check if a particular transaction id exists, we simply attach an output from that transaction into our spending transaction and check a pre-signed signature against prevouts of our spending transaction. The connector outpoint in the sighash preimage commits to the transaction id for which we want to satisfy the txlock condition. In the Ark context, this is the pool transaction containing vTXOs of intended recipients. Txlocks are used in Anchor Time Locked Contracts (ATLCs) to provide an atomic single-hub payment schedule.\n \nAnchor Time Locked Contracts (ATLCs) are conditional payments used on the Ark protocol. When a vTXO was created in the first place, an ATLC was attached to it, similar to how an eltoo:trigger is attached to a funding output during Eltoo channel formation. When a vTXO is spent, the pre-attached ATLC connects to a connector to form a txlock. \n \nThis txlock formation ensures that, for the attached ATLC to be claimed by the service provider, the outpoint context of its connector must remain unchanged. In other words, Ark service providers should not double-spend pool transactions they create. This provides an atomic payout construction for senders, as payout vTXOs nest under the same transaction of connectors. The link between connectors and newly created vTXOs is obfuscated through blinded mixing between those.\n \n\u200dPool transactions are created by Ark service providers perpetually every five seconds, which are effectively blinded, footprint-minimal, rapid coinjoin rounds. ASP funds the pool with their own on-chain funds in exchange for vTXOs redemptions. Therefore, the pool transaction that hits on-chain has only one or a few inputs the ASP provides. The pool transaction has three outputs: vTXOs output, connectors output, and ASP change. Service providers place vTXOs for the intended recipients to claim (under the vTXOs output) and connectors for senders to connect (under the connectors output) in their pool transactions.\n \nThe first output of the pool transaction, vTXOs output, contains newly created vTXOs of the coinjoin round. vTXOs are bundled and nested under this shared output and can be revealed on-chain. vTXOs output expires four weeks after its creation, and once it expires, the ASP who funded this output in the first place can solely sweep it. Nested vTXOs under the vTXOs output are expected to be redeemed by their owners in this window period. Nested vTXOs may be revealed in this four-week timeframe if the factory operator happens to be non-collaborative or non-responsive for a long period. Upon revealing a vTXO, a unilateral exit window can be triggered by attaching the pre-signed ATLC, similar to Eltoo. In the optimistic big picture, however, the final result is almost always a pool transaction with few inputs and three outputs where pool content is rarely revealed on-chain. Therefore, vTXOs & connectors remain almost always off the chain.\n\nArk can interoperate with Lightning by attaching HTLCs and PTLCs to a pool transaction, just like ATLCs and connectors. The attached HTLCs live under another shared UTXO called the HTLCs outputs, which also expire after four weeks. Ark service providers forward HTLCs to the broader Lightning Network the moment after they them to their pool transaction. This means Ark service providers are also Lightning service providers. Ark users can also get paid from Lightning using HTLC-nested vTXOs.\n \nArk is an open network where anyone can run their own ASP infrastructure. This means a user can have a vTXO set associated with different ASPs. The Ark protocol design allows users to pay lightning invoices from different vTXO sources using multi-part payments (MPP). Upon attaching HTLCs (or PTLCs) to multiple pools operated by various ASPs, HTLCs can be forwarded to the end destination via MPP.\n \nA pool transaction can be double-spent by the Ark service provider while it remains in the mempool. However, in the meantime, the recipient can pay a lightning invoice with their incoming zero-conf vTXOs, so it\u2019s a footgun for the service operator to double-spend in this case. \n \nA transfer schedule from a sender to a receiver is atomic in nature. ASPs cannot redeem senders' vTXOs if they double-spend recipients' vTXOs under the mutually agreed pool transaction id. A future extension of Ark can utilize a hypothetical data manipulation opcode (OP_XOR or OP_CAT) to constrain the ASP's nonce in their signatures to disincentivize double-spending. Users can forge ASP's signature to claim their previously redeemed vTXOs if a double-spend occurs in a pool transaction. This is effectively an inbound liquidity-like tradeoff without compromising on the protocol design.\n \nOn Ark, payments are credited every five seconds but settled every ten minutes. Payments are credited immediately because users don\u2019t have to wait for on-chain confirmations to spend their zero-conf vTXOs further. They can hand over zero-conf vTXOs to others or pay lightning invoices with them. This is because the ASP who can double-spend users' incoming vTXOs is the same ASP who routes Lightning payments. \n \nYou can find more info at https://arkpill.me/deep-dive https://www.arkpill.me/deep-dive.\n \n- Burak\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230522/2609b1b5/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2023-05-22T13:03:00",
                "message_text_only": "Good morning Burak,\n\nI have not gone through the deep dive fully yet, but I find myself confused about this particular claim:\n\n> A pool transaction can be double-spent by the Ark service provider while it remains in the mempool. However, in the meantime, the recipient can pay a lightning invoice with their incoming zero-conf vTXOs, so it\u2019s a footgun for the service operator to double-spend in this case.\u00a0\n\nGiven that you make this claim:\n\n> ASPs on Ark are both (1) liquidity providers, (2) blinded coinjoin coordinators, and (3) Lightning service providers. ASPs main job is to create rapid, blinded coinjoin sessions every five seconds, also known as pools.\n\nAs the access to Lightning is also by the (same?) ASP, it seems to me that the ASP will simply fail to forward the payment on the broader Lightning network after it has replaced the in-mempool transaction, preventing recipients from actually being able to rely on any received funds existing until the next pool transaction is confirmed.\n\nEven if the Lightning access is somehow different from the ASP you are receiving funds on, one ASP cannot prove that another ASP is not its sockpuppet except via some expensive process (i.e. locking funds or doing proof-of-work).\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Burak Keceli",
                "date": "2023-05-23T04:31:24",
                "message_text_only": "> As the access to Lightning is also by the (same?) ASP, it seems to me that the ASP will simply fail to forward the payment on the broader Lightning network after it has replaced the in-mempool transaction, preventing recipients from actually being able to rely on any received funds existing until the next pool transaction is confirmed.\n\nYes, that's correct. Lightning payments are routed through ASPs. ASP may not cooperate in forwarding HTLC(s) AFTER double-spending their pool transaction. However, it's a footgun if ASP forwards HTLC(s) BEFORE double-spending their pool transaction. \n\nWhat makes Ark magical is, in the collaborative case, users' ability to pay lightning invoices with their zero-conf vTXOs, without waiting for on-chain confirmations. \n\nThis is the opposite of swap-ins, where users SHOULD wait for on-chain confirmations before revealing their preimage of the HODL invoice; otherwise, the swap service provider can steal users' sats by double-spending their zero-conf HTLC."
            },
            {
                "author": "G. Andrew Stone",
                "date": "2023-05-23T22:06:02",
                "message_text_only": "Do you have any write up that presents a fully detailed architecture,\nincluding mechanisms like bitcoin scripts, transactions and L2 protocols,\nand then derives claims from that base?\n\nOn Tue, May 23, 2023, 5:59 AM Burak Keceli via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> > As the access to Lightning is also by the (same?) ASP, it seems to me\n> that the ASP will simply fail to forward the payment on the broader\n> Lightning network after it has replaced the in-mempool transaction,\n> preventing recipients from actually being able to rely on any received\n> funds existing until the next pool transaction is confirmed.\n>\n> Yes, that's correct. Lightning payments are routed through ASPs. ASP may\n> not cooperate in forwarding HTLC(s) AFTER double-spending their pool\n> transaction. However, it's a footgun if ASP forwards HTLC(s) BEFORE\n> double-spending their pool transaction.\n>\n> What makes Ark magical is, in the collaborative case, users' ability to\n> pay lightning invoices with their zero-conf vTXOs, without waiting for\n> on-chain confirmations.\n>\n> This is the opposite of swap-ins, where users SHOULD wait for on-chain\n> confirmations before revealing their preimage of the HODL invoice;\n> otherwise, the swap service provider can steal users' sats by\n> double-spending their zero-conf HTLC.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230523/0870c6d9/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2023-05-24T00:40:42",
                "message_text_only": "Good morning Burak,\n\n> > As the access to Lightning is also by the (same?) ASP, it seems to me that the ASP will simply fail to forward the payment on the broader Lightning network after it has replaced the in-mempool transaction, preventing recipients from actually being able to rely on any received funds existing until the next pool transaction is confirmed.\n> \n> \n> Yes, that's correct. Lightning payments are routed through ASPs. ASP may not cooperate in forwarding HTLC(s) AFTER double-spending their pool transaction. However, it's a footgun if ASP forwards HTLC(s) BEFORE double-spending their pool transaction.\n\nThis is why competent coders test their code for footguns before deploying in production.\n\n> What makes Ark magical is, in the collaborative case, users' ability to pay lightning invoices with their zero-conf vTXOs, without waiting for on-chain confirmations.\n\nYou can also do the same in Lightning, with the same risk profile: the LSP opens a 0-conf channel to you, you receive over Lightning, send out over Lightning again, without waiting for onchain confirmations.\nAgain the LSP can also steal the funds by double-spending the 0-conf channel open, like in the Ark case.\n\nThe difference here is that once confirmed, the LSP can no longer attack you.\nAs I understand Ark, there is always an unconfirmed transaction that can be double-spent by the ASP, so that the ASP can attack at any time.\n\n> This is the opposite of swap-ins, where users SHOULD wait for on-chain confirmations before revealing their preimage of the HODL invoice; otherwise, the swap service provider can steal users' sats by double-spending their zero-conf HTLC.\n\nIf by \"swap-in\" you mean \"onchain-to-offchain swap\" then it is the user who can double-spend their onchain 0-conf HTLC, not the swap service provider.\nAs the context is receiving money and then sending it out, I think that is what you mean, but I think you also misunderstand the concept.\n\nRegards,\nZmnSPCxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2023-05-24T00:45:49",
                "message_text_only": "Here is an old write-up that should be read by everyone trying to design a NON-custodial L2: https://zmnscpxj.github.io/offchain/safety.html\n\n\n\n\nSent with Proton Mail secure email.\n\n------- Original Message -------\nOn Wednesday, May 24th, 2023 at 12:40 AM, ZmnSCPxj via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n\n> Good morning Burak,\n> \n> > > As the access to Lightning is also by the (same?) ASP, it seems to me that the ASP will simply fail to forward the payment on the broader Lightning network after it has replaced the in-mempool transaction, preventing recipients from actually being able to rely on any received funds existing until the next pool transaction is confirmed.\n> > \n> > Yes, that's correct. Lightning payments are routed through ASPs. ASP may not cooperate in forwarding HTLC(s) AFTER double-spending their pool transaction. However, it's a footgun if ASP forwards HTLC(s) BEFORE double-spending their pool transaction.\n> \n> \n> This is why competent coders test their code for footguns before deploying in production.\n> \n> > What makes Ark magical is, in the collaborative case, users' ability to pay lightning invoices with their zero-conf vTXOs, without waiting for on-chain confirmations.\n> \n> \n> You can also do the same in Lightning, with the same risk profile: the LSP opens a 0-conf channel to you, you receive over Lightning, send out over Lightning again, without waiting for onchain confirmations.\n> Again the LSP can also steal the funds by double-spending the 0-conf channel open, like in the Ark case.\n> \n> The difference here is that once confirmed, the LSP can no longer attack you.\n> As I understand Ark, there is always an unconfirmed transaction that can be double-spent by the ASP, so that the ASP can attack at any time.\n> \n> > This is the opposite of swap-ins, where users SHOULD wait for on-chain confirmations before revealing their preimage of the HODL invoice; otherwise, the swap service provider can steal users' sats by double-spending their zero-conf HTLC.\n> \n> \n> If by \"swap-in\" you mean \"onchain-to-offchain swap\" then it is the user who can double-spend their onchain 0-conf HTLC, not the swap service provider.\n> As the context is receiving money and then sending it out, I think that is what you mean, but I think you also misunderstand the concept.\n> \n> Regards,\n> ZmnSPCxj\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Burak Keceli",
                "date": "2023-05-24T07:53:50",
                "message_text_only": "> 0-conf transactions are unsafe since it is possible to double-spend the inputs they consume, invalidating the 0-conf transaction.\n\nA future extension of Ark can potentially utilize a hypothetical data manipulation opcode (OP_XOR or OP_CAT) to constrain the ASP's nonce in their signatures to disincentivize double-spending. If a double-spend occurs in a pool transaction, users can forge ASP's signature to claim their previously redeemed vTXOs. This is effectively an inbound liquidity-like tradeoff without compromising on the protocol design.\n\nFor the time being, you have to wait for on-chain confirmations to consider a payment 'final'. However, this doesn't prevent you from paying lightning invoices with your zero-conf coins. Ark has immediate availability with delayed finality.\n\nBest,\nBurak"
            },
            {
                "author": "Burak Keceli",
                "date": "2023-05-24T06:28:08",
                "message_text_only": "> You can also do the same in Lightning, with the same risk profile: the LSP opens a 0-conf channel to you, you receive over Lightning, send out over Lightning again, without waiting for onchain confirmations.\n\nThis is not correct. If an LSP opens a zero-conf channel to me, I cannot receive over lightning immediately because I have to wait for that channel to confirm before revealing my preimage for the payment. If I don\u2019t, LSP takes the sender\u2019s money yet double-spends my channel.\n\nThis is not the case with Ark. Ark ensures \"absolute atomicity\" by using ATLCs instead of HTLCs. Users can receive payments and forward them further without waiting for on-chain confirmations. A double-spend attempt breaks the entire atomicity. An ASP cannot redeem senders\u2019 vTXO(s) if they double-spend recipients' vTXO(s)."
            },
            {
                "author": "adiabat",
                "date": "2023-05-24T20:20:35",
                "message_text_only": "Hi - thanks for the Ark write up; I have a bunch of questions but here's 2:\n\n---\nQ1:\n\"Pool transactions are created by ark service providers perpetually\nevery 5 seconds\"\n\nWhat exactly happens every 5 seconds?  From the 15.44.21-p-1080.png\ndiagram [1], a pool transaction is a bitcoin transaction, with all the\ninputs coming from the ASP.  My understanding is that every 5 seconds,\nwe progress from PoolTx(N) to PoolTx(N+1).  Does the ASP sign a new\ntransaction which spends the same ASP funding inputs as the previous\npool transaction, which is a double spend or fee bump?  Or does it\nspend the outputs from the previous PoolTx?\n\nIn other words, does PoolTx(2) replace PoolTx(1) RBF-style, spending\nthe same inputs (call this method A), or does PoolTx(2) spend an\noutput Of Pooltx(1) such that PoolTx(1) must be confirmed in order for\nPoolTx(2) to become valid (method B)?  Or are they completely separate\ntransactions with unconflicting inputs (method C)?\n\nWhen the ASP creates a pool transaction, what do they do with it?  Do\nthey broadcast it to the gossip network?  Or share it with other pool\nparticipants?\n\nWith method A, if the ASP shares pool transactions with other people,\nthere Doesn't seem to be any way to ensure which PoolTx gets\nconfirmed, invalidating all the other ones.  They're all valid so\nwhichever gets into a block first wins.\n\nWith method B, there seems to be a large on-chain load, with ~120\nchained transactions trying to get in every block. This wouldn't play\nnicely with mempool standardness and doesn't seem like you could ever\n\"catch up\".\n\nWith method C, ASPs would need a pretty large number of inputs but\ncould recycle them as blocks confirm.  It would cost a lot but maybe\ncould work.\n\n---\nQ2:\n\nThe other part I'm missing is: what prevents the ASP from taking all\nthe money?  Before even getting to vTXOs and connector outputs, from\nthe diagram there are only ASP inputs funding the pool transaction.\nIf the pool transaction is confirmed, the vTXOs are locked in place,\nsince the vTXO output cannot be changed and commits to all\n\"constrained outs\" via OP_CTV.  If the pool transaction is\nunconfirmed, the ASP can create & sign a transaction spending all ASP\nfunding inputs sending the money back to the ASP, or anywhere else.\nIn this case, users don't have any assurance that their vTXO can ever\nturn into a real UTXO; the ASP can \"rug-pull\" at any time, taking all\nthe money in the pool.  Adding other inputs not controlled by the ASP\nto the transaction wouldn't seem to fix the problem, because then any\nuser removing their inputs would cancel the whole transaction.\n\nMore detail about how these transactions work would be appreciated, thanks!\n\n-Tadge\n\n[1] https://uploads-ssl.webflow.com/645ae2e299ba34372614141d/6467d1f1bf91e0bf2c2eddef_Screen%20Shot%202023-05-19%20at%2015.44.21-p-1080.png"
            },
            {
                "author": "David A. Harding",
                "date": "2023-05-24T23:02:40",
                "message_text_only": "Hi Burak,\n\nThanks for this really interesting protocol!  I tend to analyze\ncomplicated ideas like this by writing about them in my own words, so\nI've pasted my summary of your idea to the end of this email in case\nit's useful, either to other people or to you in helping understand my\none concern.\n\nMy concern is the same one I think Olaoluwa Osuntokun mentioned on\nTwitter[1] and (less clear to me) might be related to ZmnSCPxj's\nconcern[2]:\n\nIt seems to me that receiving a payment on the protocol, including\nconditional payments using HTLC, PTLC, or Anchor-TLC, requires waiting\nfor the transaction containing that payment to confirm to a sufficient\ndepth (e.g., I'd wait 6 blocks for small payments and longer for huge\npayments).  Am I missing something?\n\nMy summary of how I think that part of the protocol works is in the\nsections labeled \"Make an unconditioned payment\" and \"Make a conditional\npayment\" below.  In short, it's clear to me how the service provider and\nthe customer can make instant atomic swaps with each other---they can\neither spend instantly cooperatively, or they have to wait for a\ntimeout.  But how can a receiver of funds be assured that they will\nactually get those funds unless there's already a timelock and\ncooperative spend path placed on those funds?\n\n-Dave\n\nRough initial summary of Ark protocol:\n\nAlice runs an Ark service provider.  Every 5 seconds, she broadcasts a\nnew unconfirmed onchain transaction that pays three outputs (the\nthree Cs):\n\n1. *Change Output:* money not used for the other two Cs that gets sent\n    back to the the transaction creator.\n\n2. *Connector Output:* an output that will be used in a future\n    transaction created by Alice as protection against double spends.\n\n3. *Commitment Output:* a CTV-style commitment to a set of outputs that\n    can be published later in a descendant transaction (alternatively,\n    the commitment output may be spent unilaterally by Alice after 4\n    weeks).\n\nBob wants to deposit 1 BTC with Alice.  He sends her an unsigned PSBT\nwith an input of his and a change output.  She updates the PSBT with a\ncommitment output that refunds Bob the 1 BTC and a connector output with\nsome minimum value.  They both sign the PBST and it is broadcast.  We'll\nignore fees in our examples, both onchain transaction fees and fees paid\nto Alice.\n\n From here, there are several things that Bob can do:\n\n- *Unilaterally withdraw:* Bob can spend from the commitment output to\n   put his refund onchain.  The refund can only be spent after a 24-hour\n   time delay, allowing Bob to optionally come to an agreement with Alice\n   about how to spend the funds before Bob can spend them unilaterally\n   (as we'll see in a moment).  For example, the script might be[3]:\n\n     pk(B) && (older(1 day) || pk(A))\n\n- *Collaboratively withdraw:* as seen above, Bob has the ability to come\n   to a trustless agreement with Alice about how to spend his funds.\n   They can use that ability to allow Bob to trade his (unpublished) UTXO\n   for a UTXO that Alice funds and broadcasts.  For example:\n\n     - Alice creates an unsigned PSBT that uses as one of its inputs the\n       connector from Bob's deposit transaction.  This will ensure that\n       any attempt by Bob to double-spend his deposit transaction will\n       invalidate this withdrawal transaction, preventing Bob from being\n       able to steal any of Alice's funds.\n\n         Also included in Alice's unsigned PSBT is another connector\n         output plus the output that pays Bob his 1 BTC.\n\n     - Bob receives Alice's unsigned PSBT and creates a separate PSBT\n       that includes his unpublished UTXO as an input, giving its value\n       to Alice in an output.  The PSBT also includes as an input the\n       connector output from Alice's PSBT.  This will ensure that any\n       attempt by Alice to double spend her transaction paying him will\n       invalidate his transaction paying her.\n\n     - Bob signs his PSBT and gives it to Alice.  After verifying it,\n       Alice signs her PSBT and broadcasts it.\n\n- *Collaboratively trade commitments:* as mentioned, the commitment\n   output that pays Bob may be claimed instead by Alice after 4 weeks, so\n   Bob will need to either withdraw or obtain a new commitment within \nthat\n   time.  To trade his existing commitment for a new commitment looks\n   similar to the collaborative withdrawal procedure but without the\n   creation of an immediately-spendable onchain output:\n\n     - Alice creates an unsigned PSBT that uses as one of its inputs the\n       connector from Bob's deposit transaction, again preventing double\n       spending by Bob.  Alice also includes a new connector and a new\n       commitment that again allows Bob to later claim 1 BTC.\n\n     - Bob receives Alice's PSBT and creates a PSBT transferring his\n       existing commitment to her, with the new connector again being\n       included as an input to ensure atomicity.\n\n     - Bob signs; Alice signs and broadcasts.\n\n- *Make an unconditioned payment:* using the mechanisms described above,\n   it's possible to make either an onchain payment or an offchain\n   payment---just have Carol receive the new output or commitment rather\n   than Bob.  That payment would have no conditions (except its\n   atomicity).\n\n- *Make a conditional payment:* imagine that Carol knows a secret (e.g.\n   a preimage) that Bob is willing to pay for.\n\n      - Alice creates an unsigned PSBT depending on the connector from\n        Bob's deposit transaction and creating a new connector.  The PSBT\n        includes an output paying Carol (either onchain or via a\n        commitment) with an HTLC, allowing Carol to claim the funds if \nshe\n        reveals the secret or allowing Bob to claim the funds after a\n        timeout.\n\n      - Bob receives Alice's PSBT and creates a PSBT transferring his\n        existing commitment to her with the HTLC condition attached and,\n        again, with connectors being used to ensure atomicity.\n\n      - Bob signs; Alice signs and broadcasts.\n\n      - Carol can settle her HTLC by either revealing the secret onchain\n        or by trading her commitment containing the HTLC clause for a\n        commitment from Alice that doesn't contain the clause (which\n        Alice will only accept by learning the secret, since Alice has\n        to settle with Bob).  Alice can then either settle onchain or\n        trade commitments with Bob after giving him the secret.\n\n- *Do nothing for 4 weeks:* if Bob does nothing for four weeks, Alice\n   can claim the funds from the commitment output (i.e., takes his\n   money).\n\n     If Bob did actually do something, and if every other user who also\n     had an unpublished output in the commitment transaction did\n     something, then they all exchanged their portion of the funds in\n     this output to Alice, so Alice can now claim all of those funds\n     onchain in a highly efficient manner.\n\nRegarding the connector outputs, although all of the examples above show\nAlice directly spending from the connector output in Bob's deposit\ntransaction, atomicity is also ensured if Alice spends from any output\ndescended from Bob's connector output.  Connector outputs from different\ndeposits can be used as inputs into the same transaction, merging their\nhistories.  This allows all operations made by Alice to be fully atomic,\nensuring that she doesn't lose any money during a reorg of any length.\n\nUsers are not so well protected during reorgs, e.g. if Bob double-spends\na transaction whose funds were later used in a payment to Carol, then\nCarol loses the money.  For this reason, Alice will probably want to\nprove to users that no funds they receive in a payment derive from any\ndeposit less than safe_confirmation_depth blocks.\n\n[1] https://twitter.com/roasbeef/status/1661266771784126464\n\n[2] \nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-May/021710.html\n\n[3] \nhttps://min.sc/#c=pk%28B%29%20%26%26%20%28older%281%20day%29%20%7C%7C%20pk%28A%29%29"
            },
            {
                "author": "Burak Keceli",
                "date": "2023-05-26T11:56:00",
                "message_text_only": "Hi David, \n\nArk can be used for three purposes:\n\n1. Mixing coins.\nArk is a scalable, footprint-minimal off-chain mixer. People can use Ark to mix their coins with others. This doesn\u2019t require waiting for on-chain confirmations since you\u2019re mixing your own coins with others.\n\n2. Paying lightning invoices\nArk is interoperable with Lightning, and you can use your Ark funds to pay Lightning invoices in a conjoin. This also doesn\u2019t require waiting for on-chain confirmations since you consider your payment \u201cdone\u201d when you obtain the vendor's preimage.\n\n3. Making internal transfers\nYou can use your Ark funds to make internal money transfers without introducing inbound liquidity assumptions. The recipient-end has to wait for several on-chain confirmations to consider their payment \u201cfinal\u201d, however, their payment has immediate availability to them. Recipients can spend their zero-conf funds to pay Lightning invoices in coordination with their service provider. If we want to enable Lightning-style instant settlement assurances for the internal transfers, we need OP_XOR or OP_CAT on the base layer [1].\n\n\nI think you get the gist of it, but I lost you after \u201dBob wants to deposit 1 BTC with Alice.\u201d sorry.\n\nThe initial onboarding phase is non-interactive, and there is no PSBT involved. Onboarding (or lifting) is as simple as funding a Bitcoin address. \n\nHere I have refactored it for you:\nBob wants to deposit 1 BTC with Alice. Bob asks his friend Charlie to send 1 BTC to an on-chain Bitcoin address whose script is:\npk(B) && (older(4 weeks) || pk(A))\n\n From here, there are several things that Bob can do:\n- *Unilaterally withdraw:*\nIf Alice happens to be non-collaborative or non-responsive, Bob can simply take his 1 BTC back after four weeks. \n\n- *Collaboratively withdraw:*\nBob and Alice can sign from the 2-of-2 to collaboratively withdraw 1 BTC anytime.\n\n- *Collaboratively trade commitments:*\nAlice crafts a transaction containing three outputs; (a) a commitment output, (b) a connector output, and (c) a change output. We call this transaction \u201cpool\u201d.\n(a) commitment output\nCommitment output (either using CTV or n-of-n multisig) constrains its descendant transaction to a set of transaction outputs. To simplify things, let\u2019s say there are no other participants in this transaction besides Bob, and the descendant transaction has only one output. We call this output Bob\u2019s vTXO. Bob\u2019s vTXO also constrains (using CTV or 2-of-2 multisig) its descendant transaction to a single transaction output called Bob\u2019s ATLC. Bob\u2019s ATLC contains the following script:\npk(B) && (older(4 weeks) || pk(A))\nAs you realize \u201cATLC\u201d script is identical to the \u201cFunding address\u201d script. \n\n(b) connectors output\nConnectors output is simply a single-sig output spendable by Alice herself:\npk(A)\n\nAlice locally crafts a descending transaction from this output, spending \u201cconnectors output\u201d to fund a new output. We call this output a \u201dconnector,\u201d which always carries a dust value  and is spendable by Alice herself:\npk(A)\n\nIn short, Alice crafts a Bitcoin transaction that spends an input that she controls and funds an output that she controls. Alice does not broadcast this transaction and keeps it secret.\n\n(c) change output\nmoney not used for the other two outputs gets sent back to Alice.\n\n1. Alice places one (or more) input(s) to her \u201cpool\u201d transaction to supply funds to commitment output, connectors output, change output, and transaction fees.\n\n2. Bob creates an unsigned PSBT, placing the input that Charlie was previously funded.\n\n3. Bob passes his PSBT to Alice. \n\n4. Alice places one input to PSBT, the \u201dconnector output,\u201d  which is a descendant of the (b) connectors output she is crafting.\n\n5. Alice places one output to PSBT, a single-sig output that sweeps all money to herself (pk(A)).\n\n6. Alice passes PSBT to Bob. Alice and Bob sign the PSBT and keeps this transaction private. This transaction is not valid yet, since the connector\u2019s outpoint context does not exist.\n\n7. Alice signs her one-in, three-out and broadcasts it. \n\n8. Alice can now claim 1 BTC Charlie has previously funded by revealing the descendant transaction of (b) connectors output. She should claim this before four weeks.\n \n9. Bob now has a 1 BTC worth UTXO representation as a descendant of the (a) commitment output (a virtual UTXO). He can unilaterally claim this 1 BTC by revealing the child (Bob\u2019s vTXO) and grandchild (Bob\u2019s ATLC) of the (a) commitments output, then waiting a 24-hour window period.\n\nSo far, Charlie polluted on-chain by funding an address, and Alice by claiming funds from that address. Further steps from here will be footprint minimal. \n\n1. Say, Bob wants to send 1 BTC to Dave. \n\n2. Alice crafts a transaction containing three outputs; (a) a commitment output, (b) a connector output, and (c) a change output. This time descendant of (a) commitment output is Daves\u2019s vTXO instead of Bob\u2019s. Similarly descendant of Daves\u2019s vTXO is Dave\u2019s ATLC. Dave\u2019s ATLC is:\npk(D) && (older(4 weeks) || pk(A))\n\n3. Alice places one connector output as a descendant of (b) connectors output, just like before. \n\n4. Alice places one input to her one-in, three-out transaction to supply funds to commitment output, connectors output, change output, and transaction fees.\n\n5. Bob creates an unsigned PSBT, placing his 1-BTC-worth virtual UTXO from the (a) commitment output descendants that Alice previously \n\n6. Bob passes his PSBT to Alice. \n\n7. Alice places one input to PSBT, the \u201dconnector output,\u201d  which is a descendant of the (b) connectors output she is crafting. \n\n8. Alice places one output to PSBT, a single-sig output that sweeps all money to herself (pk(A)).\n\n9. Alice passes PSBT to Bob. Alice and Bob sign the PSBT and keeps this transaction private. \n\n10. Alice signs her one-in, three-out transaction and broadcasts it. \n\n11. Bob lets Dave know about this transaction (Alice\u2019s transaction id, Dave\u2019s vTXO output index) out-of-band. \n\n12. When Dave comes back online, he sees from the out-of-band message that Bob sent him 1-BTC. He then verifies whether Alice\u2019s transaction id exists, whether his vTXO output index is correct, and a set of other validations.\n\n13. If Dave had been online all this time, he would have had to wait for enough confirmations to consider his payment \u201cfinal.\u201d\n\n[1] https://eprint.iacr.org/2017/394.pdf"
            },
            {
                "author": "David A. Harding",
                "date": "2023-05-27T20:36:47",
                "message_text_only": "Hi Burak,\n\nThanks for your response!  I found it very helpful.  I'm going to reply\nto your email a bit out of order.\n\n> 4. Alice places one input to her one-in, three-out transaction to\n>    supply funds to commitment output, connectors output, change\n>    output, and transaction fees.\n\nYou don't mention it in your reply, but was I correct in my earlier\nemail in assuming that Alice can claim any funds paid to a commitment\noutput after four weeks if its commitments haven't been published\nonchain?  E.g., that in the best case this allows a ~50 vbyte commitment\noutput that pays an arbitrary number of users to be spent as a ~100\nvbyte input (P2TR scriptpath for pk(A) && older(4 weeks))?\n\n> 1. Mixing coins.\n> 2. Paying lightning invoices\n> 3. Making internal transfers\n\nIf commitment outputs can't normally be spent by Alice for four weeks,\nthen Alice needs to keep enough capital on hand to pay out all amounts\ninvolved in the activities listed above.  I've seen many people make\nthis point, but I wanted to run some rough numbers to estimate the\nextent of that capital load.\n\nLet's say Alice has a million customers who each receive all of their\nincome and pay all of their expenses with her.  In my country, the\nmedian income is a bit less than $36,000 USD, or about $3,000 a month.\nI imagine spending is not evenly distributed over time, so let's say\nAlice needs to hold 3x the average to be prepared for a busy period.\nThat implies Alice's capital requirements are about $9 billion USD (3 *\n3000 * 1e6).\n\nAt a hypothetical risk-free interest rate of 1.5% annual, that's about\n$135 that will need to be recovered from each user per year (9e9 * 0.015\n/ 1e6).\n\nAdditionally, if we assume the cost of an onchain transaction is $100\nand the service creates one transaction per five seconds, that's $630 in\nfee costs that will need to be recovered from each user per year ((60 /\n5) * 60 * 24 * 365 * 100 / 1e6).\n\nI'll come back to this financial analysis later.\n\n> If we want to enable Lightning-style instant settlement assurances for\n> the internal transfers, we need OP_XOR or OP_CAT on the base layer\n> [...] https://eprint.iacr.org/2017/394.pdf\n\nWhat do you mean by \"instant\"?  Do you mean \"settlement as soon as the\nnext onchain pool transaction is published\"?  For example, within 5\nseconds if the coinjoining completes on time?  That's significantly\nslower than LN today, at least in the typical case for a well-connected\nnode.[1]\n\nI think 5 seconds is fine for a lot of purposes (at both point-of-sale\nterminals and on websites, I very often need to wait >5 seconds for a\ncredit card transaction to process), but I think it's worth noting the\nspeed difference in a technical discussion.\n\nAdditionally, I think the idea described significantly predates that\npaper's publication, e.g.:\n\n\"Well while you can't prevent it you could render it insecure enabling\nminers to take funds.  That could work via a one-show signature\n[...]\"[2]\n\nA problem with the idea of using one-show signatures as double-spend\nprotection is that miner-claimable fidelity bonds don't work as well\nagainst adversaries that are not just counterparties but also miners\nthemselves.  This same problem has been described for other ideas[3],\nbut to summarize:\n\nBob has something valuable.  Alice offers him the output of an\nunconfirmed transaction in exchange for that thing.  She also provides a\nbond that will pay its amount to any miner who can prove that Alice\ndouble spent her input to the unconfirmed transaction.\n\nIf Alice is miner, she can privately create candidate blocks that double\nspend the payment to Bob and which also claim the bond.  If she fails to\nfind a PoW solution for those candidate blocks, she lets Bob have his\nmoney.  If she does find a PoW solution, she publishes the block, taking\nBob's money, securing her bond, and also receiving all the regular block\nrewards (sans the fees from whatever space she used for her\ntransaction).\n\nI haven't exactly[4] seen this mentioned before, but I think it's\npossible to weaken Alice's position by putting a timelock on the\nspending of the bond, preventing it from being spent in the same block\nas the double-spend.  For example, a one-block timelock (AKA: 1 CSV)\nwould mean that she would need to mine both the block containing her\nunconfirmed transactions (to double spend them) and the next block (to\npay the fidelity bonds back to herself).\n\nIgnoring fee-sniping (bond-sniping in this case), selfish mining, and\n51% attacks, her chance of success at claiming the fidelity bond is\nequal to her portion of the network hashrate, e.g. if she has 33%, she's\n33% likely to succeed at double spending without paying a penalty.  The\nvalue of the fidelity bond can be scaled to compensate for that, e.g. if\nyou're worried about Alice controlling up to 50% of hashrate, you make\nthe fidelity bond at least 2x the base amount (1 / 50%).  Let's again\nassume that Alice has a million users making $3,000 USD of payments per\nmonth (28 days), or about on average $75,000 per minute (1e6 * 3000 / 28\n/ 24 / 60).  If Alice bonds 2x the payment value and her bonds don't\nexpire for 6 blocks (which might take 3 hours), she needs an additional\n$27 million worth of BTC on hand (75000 * 2 * (3 * 60)), which I admit\nis trivial compared to the other capital requirements mentioned above.\n\n* * *\n\nTaken all together, it seems to me that Alice might need to keep several\nbillion dollars worth of BTC in a hot wallet in order to serve a million\nusers.  The per-user cost in fees and capital service would be around\n$1,000 per year.  If we assume onchain transaction costs are about $100,\nthat would be equal to 10 channels that could be opened or closed by\neach user for the same amount (i.e. an average of 5 channel rotations\nper year).\n\nDid I miss something in my analysis that would indicate the capital\ncosts would be significantly lower or that there wouldn't be other\ntradeoffs (slower settlement than LN and a need to use a timelocked\nfidelity bond)?\n\nThanks!,\n\n-Dave\n\n[1] https://twitter.com/Leishman/status/1661138737009442818\n\n[2] \nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2014-December/007038.html\n\n[3] \nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-June/018010.html\n\n[4] Years ago, I think I saw a reply by Peter Todd to some idea about\n     paying money to miners in a fair way and he noted that it was\n     critical to pay miners far enough in the future that the current set\n     of miners wouldn't be incentivized to manipulate who got the money\n     by choosing which block to include the transaction in now.  I wasn't\n     able to quickly find that post, but it definitely influenced my\n     thinking here."
            },
            {
                "author": "Ali Sherief",
                "date": "2023-05-25T12:12:43",
                "message_text_only": "Regarding this:\n\n> Users are not so well protected during reorgs, e.g. if Bob double-spends\n> a transaction whose funds were later used in a payment to Carol, then\n> Carol loses the money. For this reason, Alice will probably want to\n> prove to users that no funds they receive in a payment derive from any\n> deposit less than safe_confirmation_depth blocks.\n\nI'm of the opinion that any L2 protocol having a similar concept of block mining but for L2 transactions is a pretty good idea, but the reorgs trapdoor you mentioned could theoretically be mitigated ARK nodes considering their settling transactions on L1 as final after say, 3 blocks, or maybe even 6 blocks.\n\nI'm leaning towards the standard 6 blocks, as this delay is invisible to users anyway, and only node operators will really notice it.\n\nIt is kind of the same way how miners can't spend coinbase transactions for 100 blocks.\n\nIt's a pretty good idea from Burak though, and I can't wait to see nodes in action with this.\n\n- Ali\n\n> Hi Burak,\n> \n> Thanks for this really interesting protocol! I tend to analyze\n> complicated ideas like this by writing about them in my own words, so\n> I've pasted my summary of your idea to the end of this email in case\n> it's useful, either to other people or to you in helping understand my\n> one concern.\n> \n> My concern is the same one I think Olaoluwa Osuntokun mentioned on\n> Twitter[1] and (less clear to me) might be related to ZmnSCPxj's\n> concern[2]:\n> \n> It seems to me that receiving a payment on the protocol, including\n> conditional payments using HTLC, PTLC, or Anchor-TLC, requires waiting\n> for the transaction containing that payment to confirm to a sufficient\n> depth (e.g., I'd wait 6 blocks for small payments and longer for huge\n> payments). Am I missing something?\n> \n> My summary of how I think that part of the protocol works is in the\n> sections labeled \"Make an unconditioned payment\" and \"Make a conditional\n> payment\" below. In short, it's clear to me how the service provider and\n> the customer can make instant atomic swaps with each other---they can\n> either spend instantly cooperatively, or they have to wait for a\n> timeout. But how can a receiver of funds be assured that they will\n> actually get those funds unless there's already a timelock and\n> cooperative spend path placed on those funds?\n> \n> -Dave\n> \n> Rough initial summary of Ark protocol:\n> \n> Alice runs an Ark service provider. Every 5 seconds, she broadcasts a\n> new unconfirmed onchain transaction that pays three outputs (the\n> three Cs):\n> \n> 1. Change Output: money not used for the other two Cs that gets sent\n> back to the the transaction creator.\n> \n> 2. Connector Output: an output that will be used in a future\n> transaction created by Alice as protection against double spends.\n> \n> 3. Commitment Output: a CTV-style commitment to a set of outputs that\n> can be published later in a descendant transaction (alternatively,\n> the commitment output may be spent unilaterally by Alice after 4\n> weeks).\n> \n> Bob wants to deposit 1 BTC with Alice. He sends her an unsigned PSBT\n> with an input of his and a change output. She updates the PSBT with a\n> commitment output that refunds Bob the 1 BTC and a connector output with\n> some minimum value. They both sign the PBST and it is broadcast. We'll\n> ignore fees in our examples, both onchain transaction fees and fees paid\n> to Alice.\n> \n> From here, there are several things that Bob can do:\n> \n> - Unilaterally withdraw: Bob can spend from the commitment output to\n> put his refund onchain. The refund can only be spent after a 24-hour\n> time delay, allowing Bob to optionally come to an agreement with Alice\n> about how to spend the funds before Bob can spend them unilaterally\n> (as we'll see in a moment). For example, the script might be[3]:\n> \n> pk(B) && (older(1 day) || pk(A))\n> \n> - Collaboratively withdraw: as seen above, Bob has the ability to come\n> to a trustless agreement with Alice about how to spend his funds.\n> They can use that ability to allow Bob to trade his (unpublished) UTXO\n> for a UTXO that Alice funds and broadcasts. For example:\n> \n> - Alice creates an unsigned PSBT that uses as one of its inputs the\n> connector from Bob's deposit transaction. This will ensure that\n> any attempt by Bob to double-spend his deposit transaction will\n> invalidate this withdrawal transaction, preventing Bob from being\n> able to steal any of Alice's funds.\n> \n> Also included in Alice's unsigned PSBT is another connector\n> output plus the output that pays Bob his 1 BTC.\n> \n> - Bob receives Alice's unsigned PSBT and creates a separate PSBT\n> that includes his unpublished UTXO as an input, giving its value\n> to Alice in an output. The PSBT also includes as an input the\n> connector output from Alice's PSBT. This will ensure that any\n> attempt by Alice to double spend her transaction paying him will\n> invalidate his transaction paying her.\n> \n> - Bob signs his PSBT and gives it to Alice. After verifying it,\n> Alice signs her PSBT and broadcasts it.\n> \n> - Collaboratively trade commitments: as mentioned, the commitment\n> output that pays Bob may be claimed instead by Alice after 4 weeks, so\n> Bob will need to either withdraw or obtain a new commitment within\n> that\n> time. To trade his existing commitment for a new commitment looks\n> similar to the collaborative withdrawal procedure but without the\n> creation of an immediately-spendable onchain output:\n> \n> - Alice creates an unsigned PSBT that uses as one of its inputs the\n> connector from Bob's deposit transaction, again preventing double\n> spending by Bob. Alice also includes a new connector and a new\n> commitment that again allows Bob to later claim 1 BTC.\n> \n> - Bob receives Alice's PSBT and creates a PSBT transferring his\n> existing commitment to her, with the new connector again being\n> included as an input to ensure atomicity.\n> \n> - Bob signs; Alice signs and broadcasts.\n> \n> - Make an unconditioned payment: using the mechanisms described above,\n> it's possible to make either an onchain payment or an offchain\n> payment---just have Carol receive the new output or commitment rather\n> than Bob. That payment would have no conditions (except its\n> atomicity).\n> \n> - Make a conditional payment: imagine that Carol knows a secret (e.g.\n> a preimage) that Bob is willing to pay for.\n> \n> - Alice creates an unsigned PSBT depending on the connector from\n> Bob's deposit transaction and creating a new connector. The PSBT\n> includes an output paying Carol (either onchain or via a\n> commitment) with an HTLC, allowing Carol to claim the funds if\n> she\n> reveals the secret or allowing Bob to claim the funds after a\n> timeout.\n> \n> - Bob receives Alice's PSBT and creates a PSBT transferring his\n> existing commitment to her with the HTLC condition attached and,\n> again, with connectors being used to ensure atomicity.\n> \n> - Bob signs; Alice signs and broadcasts.\n> \n> - Carol can settle her HTLC by either revealing the secret onchain\n> or by trading her commitment containing the HTLC clause for a\n> commitment from Alice that doesn't contain the clause (which\n> Alice will only accept by learning the secret, since Alice has\n> to settle with Bob). Alice can then either settle onchain or\n> trade commitments with Bob after giving him the secret.\n> \n> - Do nothing for 4 weeks: if Bob does nothing for four weeks, Alice\n> can claim the funds from the commitment output (i.e., takes his\n> money).\n> \n> If Bob did actually do something, and if every other user who also\n> had an unpublished output in the commitment transaction did\n> something, then they all exchanged their portion of the funds in\n> this output to Alice, so Alice can now claim all of those funds\n> onchain in a highly efficient manner.\n> \n> Regarding the connector outputs, although all of the examples above show\n> Alice directly spending from the connector output in Bob's deposit\n> transaction, atomicity is also ensured if Alice spends from any output\n> descended from Bob's connector output. Connector outputs from different\n> deposits can be used as inputs into the same transaction, merging their\n> histories. This allows all operations made by Alice to be fully atomic,\n> ensuring that she doesn't lose any money during a reorg of any length.\n> \n> Users are not so well protected during reorgs, e.g. if Bob double-spends\n> a transaction whose funds were later used in a payment to Carol, then\n> Carol loses the money. For this reason, Alice will probably want to\n> prove to users that no funds they receive in a payment derive from any\n> deposit less than safe_confirmation_depth blocks.\n> \n> [1] https://twitter.com/roasbeef/status/1661266771784126464\n> \n> [2]\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-May/021710.html\n> \n> [3]\n> https://min.sc/#c=pk(B) %26%26 (older(1 day) || pk(A))"
            },
            {
                "author": "jk_14 at op.pl",
                "date": "2023-05-26T07:33:42",
                "message_text_only": "An HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230526/dc200fd3/attachment-0001.html>"
            },
            {
                "author": "Ali Sherief",
                "date": "2023-05-28T06:02:58",
                "message_text_only": "Burak, I don't remember if this has been mentioned previously in the conversation about Ark, but a disadvantage in the protocol as it is currently is that \"Ark require users to come online and \"refresh\" their coins every few weeks, otherwise the ASP can sweep the funds.\" (putting that in quotes because although I copied this from a forum, it may have originally been said on this list.)\n\nHowever, yesterday I have come up with a scheme to mitigate this disadvantage, in a way that works similar to LN watchtowers.\n\nThis watchtower program for Ark would be made that runs on an internet-connected server and inputs your wallet password and the date in the future to perform the refreshing. A child process can then be spawned that acts similar to a cronjob, and stores the wallet password with AES encryption in memory.\n\nThe key to this cipher is the time stored in ISO 8601 format as a byte string. It is promptly discarded from memory.\n\nEvery second, the watchtower child process will attempt to decrypt the cipher using the current ISO 8601 time looking like \"YYYY-mm-ddTHH:MM:SSZ\" as the key.\n\nNaturally this will only succeed at the requisite time at which the wallet is to be unlocked by the watchtower child process - following which the coins inside the ASP are refreshed, and the watchtower child process is terminated and the encrypted wallet password destroyed.\n\nOf course, memory scrubbing should be applied to the region that has the decrypted wallet password.\nIf at any point the user comes online by themselves, they can simply cancel the watchtower refreshing task, which will terminate the watchtower child process without opening your wallet and refreshing coins.\n\nThe key feature is that nobody will be able to decrypt the wallet password unless they know the exact time it is to be unlocked as an ISO 8601 string. It cannot be unlocked at any time in the future, just at that particular instant, as long as the key is discarded and the software randomly guesses the decryption by attempting each second the new time as the encryption key. Even if the watchtower is hacked after the task has been made, the hacker still won't be able to decrypt the wallet password unless they brute-force the encryption key by exhaustively trying all timestamps in the future.\n\nAlternatively, instead of encrypting the wallet password, it can encrypt a signed transaction which is used by Ark to refresh the coins. In this case, the wallet password would still need to be collected, but only for the purpose of signing the transaction, after which the password is promptly erased from memory.\n\nHow this can be extended to repeatedly arming the watchtower program with refreshes remains to be seen, but using the wallet password as the encryption directly is one option albeit not a secure one A better and more secure option would be to take note of the UTXOs created by the coin refreshing transaction, use those as inputs to a second refreshing transaction that is created immediately after the first one, sign it, and similarly create a third, fourth, etc. as many as are desirable for the user. Then every 4 weeks, one of these transactions can be broadcasted, in the order that they were created obviously.\n\nLooking forward to your feedback on this.\n-Ali\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230528/451dd264/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Ark: An Alternative Privacy-preserving Second Layer Solution",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "jk_14 at op.pl",
                "adiabat",
                "David A. Harding",
                "Ali Sherief",
                "ZmnSCPxj",
                "G. Andrew Stone",
                "Burak Keceli"
            ],
            "messages_count": 15,
            "total_messages_chars_count": 55683
        }
    },
    {
        "title": "[bitcoin-dev] Coinjoin with less steps using ALL|ANYONECANPAY",
        "thread_messages": [
            {
                "author": "alicexbt",
                "date": "2023-05-22T12:51:22",
                "message_text_only": "Hi Bitcoin Developers,\n\nI recently experimented with different sighash flags, PSBTs and realized ALL|ANYONECANPAY could be used to reduce some steps in coinjoin.\n\nSteps:\n\n- Register outputs.\n- One user creates a signed PSBT with 1 input, all registered outputs and ALL|ANYONECANPAY sighash flag. Other participants keep adding their inputs to PSBT.\n- Finalize and broadcast the transaction.\n\nProof of Concept (Aice and Bob):\u00a0https://gitlab.com/-/snippets/2542297\n\nTx: https://mempool.space/testnet/tx/c6dd626591dca7e25bbd516f01b23171eb0f2b623471fcf8e073c87c1179c492\n\nI plan to use this in joinstr if there are no major drawbacks and it can even be implemented by other coinjoin implementations. \n\n/dev/fd0\nfloppy disk guy\n\nSent with Proton Mail secure email."
            },
            {
                "author": "Ben Carman",
                "date": "2023-05-22T22:51:49",
                "message_text_only": "The problem with using ALL|ANYONECANPAY is that you cannot verify beforehand that the other inputs are the inputs you want added to the transaction.\n\nSome examples of bad things that could happen:\n\n\n  *   Coordinator adds its own inputs, you still get your outputs but effectively paid fees for no privacy gain\n  *   The inputs added could be paying at a lower fee rate than expected, causing the tx to take longer than what you paid for\n  *   Different input types or amount are added so you no longer have the same uniformity across the inputs\n  *   (if you care) An input from a sanctioned address is added, causing you to get \"tainted\" coins.\n\nThis is the code in ln-vortex that verifies the psbt on the client side if you are curious\n\nhttps://github.com/ln-vortex/ln-vortex/blob/master/client/src/main/scala/com/lnvortex/client/VortexClient.scala#L616\n\n\nBest,\n\nbenthecarman\n\n________________________________\nFrom: bitcoin-dev <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of alicexbt via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Monday, May 22, 2023 7:51 AM\nTo: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\nSubject: [bitcoin-dev] Coinjoin with less steps using ALL|ANYONECANPAY\n\nHi Bitcoin Developers,\n\nI recently experimented with different sighash flags, PSBTs and realized ALL|ANYONECANPAY could be used to reduce some steps in coinjoin.\n\nSteps:\n\n- Register outputs.\n- One user creates a signed PSBT with 1 input, all registered outputs and ALL|ANYONECANPAY sighash flag. Other participants keep adding their inputs to PSBT.\n- Finalize and broadcast the transaction.\n\nProof of Concept (Aice and Bob): https://gitlab.com/-/snippets/2542297\n\nTx: https://mempool.space/testnet/tx/c6dd626591dca7e25bbd516f01b23171eb0f2b623471fcf8e073c87c1179c492\n\nI plan to use this in joinstr if there are no major drawbacks and it can even be implemented by other coinjoin implementations.\n\n/dev/fd0\nfloppy disk guy\n\nSent with Proton Mail secure email.\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230522/9d45d394/attachment-0001.html>"
            },
            {
                "author": "Lucas Ontivero",
                "date": "2023-05-23T12:17:23",
                "message_text_only": "Hi all,\n\nIn some coinjoin implementations inputs are registered first because in\nthat way, if the user fails or refuses to sign the transaction the input is\nbanned and denial of service is made a bit more expensive, in the sense\nthat an attacker needs more and more utxos to keep the attack going.\n\nYour proposal can work if you find an alternative mechanism for mitigating\nthe DoS attacks or when DoS attacks are not a problem (I can imagine there\nare scenarios where it is not really important).\n\nBest\n\n- Lucas\n\n\nOn Mon, May 22, 2023 at 7:53\u202fPM Ben Carman via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> The problem with using ALL|ANYONECANPAY is that you cannot verify\n> beforehand that the other inputs are the inputs you want added to the\n> transaction.\n>\n> Some examples of bad things that could happen:\n>\n>\n>    - Coordinator adds its own inputs, you still get your outputs but\n>    effectively paid fees for no privacy gain\n>    - The inputs added could be paying at a lower fee rate than expected,\n>    causing the tx to take longer than what you paid for\n>    - Different input types or amount are added so you no longer have the\n>    same uniformity across the inputs\n>    - (if you care) An input from a sanctioned address is added, causing\n>    you to get \"tainted\" coins.\n>\n> This is the code in ln-vortex that verifies the psbt on the client side if\n> you are curious\n>\n>\n> https://github.com/ln-vortex/ln-vortex/blob/master/client/src/main/scala/com/lnvortex/client/VortexClient.scala#L616\n>\n>\n> Best,\n>\n> benthecarman\n>\n> ------------------------------\n> *From:* bitcoin-dev <bitcoin-dev-bounces at lists.linuxfoundation.org> on\n> behalf of alicexbt via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n> *Sent:* Monday, May 22, 2023 7:51 AM\n> *To:* Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\n> *Subject:* [bitcoin-dev] Coinjoin with less steps using ALL|ANYONECANPAY\n>\n> Hi Bitcoin Developers,\n>\n> I recently experimented with different sighash flags, PSBTs and realized\n> ALL|ANYONECANPAY could be used to reduce some steps in coinjoin.\n>\n> Steps:\n>\n> - Register outputs.\n> - One user creates a signed PSBT with 1 input, all registered outputs and\n> ALL|ANYONECANPAY sighash flag. Other participants keep adding their inputs\n> to PSBT.\n> - Finalize and broadcast the transaction.\n>\n> Proof of Concept (Aice and Bob): https://gitlab.com/-/snippets/2542297\n>\n> Tx:\n> https://mempool.space/testnet/tx/c6dd626591dca7e25bbd516f01b23171eb0f2b623471fcf8e073c87c1179c492\n>\n> I plan to use this in joinstr if there are no major drawbacks and it can\n> even be implemented by other coinjoin implementations.\n>\n> /dev/fd0\n> floppy disk guy\n>\n> Sent with Proton Mail secure email.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230523/4bc0294c/attachment-0001.html>"
            },
            {
                "author": "alicexbt",
                "date": "2023-05-23T12:48:02",
                "message_text_only": "Hi Lucas,\n\n> In some coinjoin implementations inputs are registered first because in that way, if the user fails or refuses to sign the transaction the input is banned and denial of service is made a bit more expensive, in the sense that an attacker needs more and more utxos to keep the attack going.\n\nDoS attacks are even possible in later stages of a coinjoin round. Example: Double spend inputs after signing\n\nInputs could be banned in second step if ALL|ANYONECANPAY sighash flag is used and outputs are registered initially.\n\n/dev/fd0\nfloppy disk guy\n\nSent with Proton Mail secure email.\n\n------- Original Message -------\nOn Tuesday, May 23rd, 2023 at 5:47 PM, Lucas Ontivero <lucasontivero at gmail.com> wrote:\n\n\n> Hi all,\n> In some coinjoin implementations inputs are registered first because in that way, if the user fails or refuses to sign the transaction the input is banned and denial of service is made a bit more expensive, in the sense that an attacker needs more and more utxos to keep the attack going.\n> \n> Your proposal can work if you find an alternative mechanism for mitigating the DoS attacks or when DoS attacks are not a problem (I can imagine there are scenarios where it is not really important).\n> Best\n> - Lucas\n> \n> \n> \n> On Mon, May 22, 2023 at 7:53\u202fPM Ben Carman via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> > The problem with using ALL|ANYONECANPAY is that you cannot verify beforehand that the other inputs are the inputs you want added to the transaction.\n> > \n> > Some examples of bad things that could happen:\n> > \n> > \n> > -   Coordinator adds its own inputs, you still get your outputs but effectively paid fees for no privacy gain\n> > -   The inputs added could be paying at a lower fee rate than expected, causing the tx to take longer than what you paid for\n> > -   Different input types or amount are added so you no longer have the same uniformity across the inputs\n> > -   (if you care) An input from a sanctioned address is added, causing you to get \"tainted\" coins.\n> >     \n> > \n> > This is the code in ln-vortex that verifies the psbt on the client side if you are curious\n> > \n> > https://github.com/ln-vortex/ln-vortex/blob/master/client/src/main/scala/com/lnvortex/client/VortexClient.scala#L616\n> > \n> > \n> > Best,\n> > \n> > benthecarman\n> > \n> > \n> > \n> > From: bitcoin-dev <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of alicexbt via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n> > Sent: Monday, May 22, 2023 7:51 AM\n> > To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\n> > Subject: [bitcoin-dev] Coinjoin with less steps using ALL|ANYONECANPAY\n> > \n> > Hi Bitcoin Developers,\n> > \n> > I recently experimented with different sighash flags, PSBTs and realized ALL|ANYONECANPAY could be used to reduce some steps in coinjoin.\n> > \n> > Steps:\n> > \n> > - Register outputs.\n> > - One user creates a signed PSBT with 1 input, all registered outputs and ALL|ANYONECANPAY sighash flag. Other participants keep adding their inputs to PSBT.\n> > - Finalize and broadcast the transaction.\n> > \n> > Proof of Concept (Aice and Bob): https://gitlab.com/-/snippets/2542297\n> > \n> > Tx: https://mempool.space/testnet/tx/c6dd626591dca7e25bbd516f01b23171eb0f2b623471fcf8e073c87c1179c492\n> > \n> > I plan to use this in joinstr if there are no major drawbacks and it can even be implemented by other coinjoin implementations.\n> > \n> > /dev/fd0\n> > floppy disk guy\n> > \n> > Sent with Proton Mail secure email.\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> > \n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "alicexbt",
                "date": "2023-05-23T12:34:03",
                "message_text_only": "Hi Ben,\n\nThanks for the feedback.\n\n> -   Coordinator adds its own inputs, you still get your outputs but effectively paid fees for no privacy gain\n\nWhat will be the incentive for a coordinator to add its inputs in coinjoin? Is this possible without ALL|ANYONECANPAY as well? Even if there is an incentive its unlikely to work in joinstr as there is no centralized coordinator. Multiple common relays are used to coordinate a coinjoin round.\n\n> -   The inputs added could be paying at a lower fee rate than expected, causing the tx to take longer than what you paid for\n> -   Different input types or amount are added so you no longer have the same uniformity across the inputs\n\n> This is the code in ln-vortex that verifies the psbt on the client side if you are curious\n> \n> https://github.com/ln-vortex/ln-vortex/blob/master/client/src/main/scala/com/lnvortex/client/VortexClient.scala#L616\n\nThese 2 are important things and could be managed with client side validation by keeping min-max amounts for inputs in a round and disallow different types of inputs. Thanks for sharing the code that validates PSBT.\n\nJoinstr will also use NIP38/48 channels for coinjoin rounds so that only participants in a coinjoin round are aware of details.\n\n/dev/fd0\nfloppy disk guy\n\nSent with Proton Mail secure email.\n\n------- Original Message -------\nOn Tuesday, May 23rd, 2023 at 4:21 AM, Ben Carman <benthecarman at live.com> wrote:\n\n\n> The problem with using ALL|ANYONECANPAY is that you cannot verify beforehand that the other inputs are the inputs you want added to the transaction.\n> \n> Some examples of bad things that could happen:\n> \n> \n> -   Coordinator adds its own inputs, you still get your outputs but effectively paid fees for no privacy gain\n> -   The inputs added could be paying at a lower fee rate than expected, causing the tx to take longer than what you paid for\n> -   Different input types or amount are added so you no longer have the same uniformity across the inputs\n> -   (if you care) An input from a sanctioned address is added, causing you to get \"tainted\" coins.\n>     \n> \n> This is the code in ln-vortex that verifies the psbt on the client side if you are curious\n> \n> https://github.com/ln-vortex/ln-vortex/blob/master/client/src/main/scala/com/lnvortex/client/VortexClient.scala#L616\n> \n> \n> Best,\n> \n> benthecarman\n> \n> \n> \n> From: bitcoin-dev <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of alicexbt via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n> Sent: Monday, May 22, 2023 7:51 AM\n> To: Bitcoin Protocol Discussion <bitcoin-dev at lists.linuxfoundation.org>\n> Subject: [bitcoin-dev] Coinjoin with less steps using ALL|ANYONECANPAY\n> \n> Hi Bitcoin Developers,\n> \n> I recently experimented with different sighash flags, PSBTs and realized ALL|ANYONECANPAY could be used to reduce some steps in coinjoin.\n> \n> Steps:\n> \n> - Register outputs.\n> - One user creates a signed PSBT with 1 input, all registered outputs and ALL|ANYONECANPAY sighash flag. Other participants keep adding their inputs to PSBT.\n> - Finalize and broadcast the transaction.\n> \n> Proof of Concept (Aice and Bob):\u00a0https://gitlab.com/-/snippets/2542297\n> \n> Tx: https://mempool.space/testnet/tx/c6dd626591dca7e25bbd516f01b23171eb0f2b623471fcf8e073c87c1179c492\n> \n> I plan to use this in joinstr if there are no major drawbacks and it can even be implemented by other coinjoin implementations.\n> \n> /dev/fd0\n> floppy disk guy\n> \n> Sent with Proton Mail secure email.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            }
        ],
        "thread_summary": {
            "title": "Coinjoin with less steps using ALL|ANYONECANPAY",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "alicexbt",
                "Lucas Ontivero",
                "Ben Carman"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 14008
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Transaction Relay over Nostr",
        "thread_messages": [
            {
                "author": "Joost Jager",
                "date": "2023-05-23T07:19:17",
                "message_text_only": "Hi,\n\n\nI write to get your thoughts on an alternative approach for Bitcoin\ntransaction relay, addressing some of the limitations in the current\npeer-to-peer transaction relay system. To the best of my knowledge, the\ncredit for the original concept goes to Ben Carman. I felt it would be\nbeneficial to share the idea on this list to garner wider perspectives and\nfeedback.\n\n\nThe existing peer-to-peer (P2P) transaction relay system comes with a set\nof limitations that may negatively impact applications, notably those like\nLightning that make extensive use of pre-signed transactions. A key\nlimitation lies in the system's inability to relay transaction packages.\nThis constraint can lead to HTLCs expiring before being swept, thereby\nrisking fund losses. In addition, the P2P system falls short in supporting\nnon-standard transactions, despite an established demand for such\ntransactions in the marketplace.\n\n\nNostr, an open and decentralized network of relays for public and ephemeral\nmessages between pseudonymous entities, could help address these\nshortcomings. With the standards defined in NIP-89 [1], it becomes possible\nto broadcast arbitrary Bitcoin transaction packages, overcoming one of the\nkey hurdles in the current relay system.\n\n\nIn this proposed alternative relay mechanism, miners would listen for these\nbroadcasted transaction packages and insert the packages into their local\nmempool. They can take advantage of the `submitpackage` RPC, limited to\nsafe topologies only - specifically child and direct parents, tree only\n[2]. This feature could serve as an interim solution for package relay\nuntil it becomes available through the traditional P2P method.\n\n\nA notable advantage of this approach is that it delegates the\nresponsibility of dealing with Denial-of-Service (DoS) threats to the\nrelays themselves. They could, for example, require a payment to mitigate\nsuch concerns. There are in fact paid nostr relays already in operation.\nThis partitioning would result in a clear separation between the Bitcoin\ntransaction layer and DoS protection, introducing more flexibility in the\nsystem and potentially boosting its resilience.\n\n\nImplementing Nostr as a relay mechanism also has the potential to\ndemocratize access to miner mempools, thus leveling the playing field in\nthe Bitcoin network. In the current state, those with direct connections or\ncertain privileges can more readily submit transactions to miners, perhaps\neven through means as informal as email.\n\n\nI have been working on a prototype of this concept (based on [3]) and have\ncaptured its workings in a demonstration video [4].\n\n\nJoost\n\n\n[1] https://github.com/nostr-protocol/nips/pull/476\n\n[2] https://github.com/bitcoin/bitcoin/pull/27609#issuecomment-1544414801\n\n[3] https://github.com/benthecarman/nostr-tx-broadcast\n\n[4] https://twitter.com/joostjgr/status/1658487013237211155\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230523/6866548f/attachment.html>"
            },
            {
                "author": "alicexbt",
                "date": "2023-05-23T13:25:31",
                "message_text_only": "Hi Joost,\n\nTransaction relay over nostr sounds interesting. I have 2 suggestions:\n\n- Transactions could be encrypted when published as nostr events initially except size, fee rate and offer. This can be used by different clients to show them as external mempool with transactions sorted by fee rate without affecting privacy of users.\n- Mining pools will be incentivized to include these transaction in their blocks if they are using a higher fee rate compared to transactions in normal mempool used by bitcoin nodes or there is a mechanism to accept published offers, NIP4 is used to privately coordinate everything between user and pool. User can lock some sats in a 2of2 multisig and release it to mining pool on confirmation.\n\n/dev/fd0\nfloppy disk guy\n\nSent with Proton Mail secure email.\n\n------- Original Message -------\nOn Tuesday, May 23rd, 2023 at 12:49 PM, Joost Jager via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n\n> Hi,\n> \n> \n> \n> I write to get your thoughts on an alternative approach for Bitcoin transaction relay, addressing some of the limitations in the current peer-to-peer transaction relay system. To the best of my knowledge, the credit for the original concept goes to Ben Carman. I felt it would be beneficial to share the idea on this list to garner wider perspectives and feedback.\n> \n> \n> \n> The existing peer-to-peer (P2P) transaction relay system comes with a set of limitations that may negatively impact applications, notably those like Lightning that make extensive use of pre-signed transactions. A key limitation lies in the system's inability to relay transaction packages. This constraint can lead to HTLCs expiring before being swept, thereby risking fund losses. In addition, the P2P system falls short in supporting non-standard transactions, despite an established demand for such transactions in the marketplace.\n> \n> \n> \n> Nostr, an open and decentralized network of relays for public and ephemeral messages between pseudonymous entities, could help address these shortcomings. With the standards defined in NIP-89 [1], it becomes possible to broadcast arbitrary Bitcoin transaction packages, overcoming one of the key hurdles in the current relay system.\n> \n> \n> \n> In this proposed alternative relay mechanism, miners would listen for these broadcasted transaction packages and insert the packages into their local mempool. They can take advantage of the `submitpackage` RPC, limited to safe topologies only - specifically child and direct parents, tree only [2]. This feature could serve as an interim solution for package relay until it becomes available through the traditional P2P method.\n> \n> \n> \n> A notable advantage of this approach is that it delegates the responsibility of dealing with Denial-of-Service (DoS) threats to the relays themselves. They could, for example, require a payment to mitigate such concerns. There are in fact paid nostr relays already in operation. This partitioning would result in a clear separation between the Bitcoin transaction layer and DoS protection, introducing more flexibility in the system and potentially boosting its resilience.\n> \n> \n> \n> Implementing Nostr as a relay mechanism also has the potential to democratize access to miner mempools, thus leveling the playing field in the Bitcoin network. In the current state, those with direct connections or certain privileges can more readily submit transactions to miners, perhaps even through means as informal as email.\n> \n> \n> \n> I have been working on a prototype of this concept (based on [3]) and have captured its workings in a demonstration video [4].\n> \n> \n> \n> Joost\n> \n> \n> \n> [1] https://github.com/nostr-protocol/nips/pull/476\n> \n> [2] https://github.com/bitcoin/bitcoin/pull/27609#issuecomment-1544414801\n> \n> [3] https://github.com/benthecarman/nostr-tx-broadcast\n> \n> [4] https://twitter.com/joostjgr/status/1658487013237211155"
            },
            {
                "author": "Joost Jager",
                "date": "2023-05-23T15:26:18",
                "message_text_only": "Hi fd0,\n\n\n> - Transactions could be encrypted when published as nostr events initially\n> except size, fee rate and offer. This can be used by different clients to\n> show them as external mempool with transactions sorted by fee rate without\n> affecting privacy of users.\n>\n\nI don't think this will work because those encrypted transactions could all\nbe fake and distort the view clients have on this 'mempool'?\n\n\n> - Mining pools will be incentivized to include these transaction in their\n> blocks if they are using a higher fee rate compared to transactions in\n> normal mempool used by bitcoin nodes or there is a mechanism to accept\n> published offers, NIP4 is used to privately coordinate everything between\n> user and pool. User can lock some sats in a 2of2 multisig and release it to\n> mining pool on confirmation.\n>\n\nI believe you are suggesting out-of-band payment in case the fee included\nin the transaction itself is insufficient and CPFP/RBF is impossible or\nimpractical? The question is why would the miner trust you to indeed\nrelease after confirmation? The 2-of-2 presumably has a clawback clause\nwith a timeout that could be used by the user to avoid paying.\n\nJoost\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230523/30d85a52/attachment.html>"
            },
            {
                "author": "David A. Harding",
                "date": "2023-05-28T02:37:12",
                "message_text_only": "On 2023-05-22 21:19, Joost Jager via bitcoin-dev wrote:\n> A notable advantage of this approach is that it delegates the\n> responsibility of dealing with Denial-of-Service (DoS) threats to the\n> relays themselves. They could, for example, require a payment to\n> mitigate such concerns.\n\nHi Joost,\n\nThanks for working on this!  One quick thought I had was that a possibly\ninteresting avenue for exploration would be that, in addition to\nrelaying individual transactions or packages, it might be worth relaying\nblock templates and weak blocks as both of those provide inherent DoS\nresistance and can offer useful features.\n\nA block template is an ordered list of raw transactions that can all be\nincluded in the next block (with some space reserved for a coinbase\ntransaction).  A full node can validate those transactions and calculate\nhow much fee they pay.  A Nostr relay can simply relay almost[1] any\ntemplate that pays more fees than the previous best template it saw for\nthe next block.  That can be more flexible than the current\nimplementation of submitblock with package relay which still enforces a\nlot of the rules that helps keep a regular relay node safe from DoS and\na miner node able to select mineable transactions quickly.\n\nA weak block is a block whose header doesn't quite hash to low enough of\na value to be included on the chain.  It still takes an extraordinary\namount of hashrate to produce, so it's inherently DoS resistant.  If\nminers are producing block that include transactions not seen by typical\nrelay nodes, that can reduce the efficiency and effectiveness of BIP152\ncompact block relay, which hurts the profitability of miners of custom\nblocks.  To compensate, miners could relay weak blocks through Nostr to\nfull nodes and other miners so that they could quickly relay and accept\ncomplete blocks that later included the same custom transactions.  This\nwould also help fee estimation and provide valuable insights to those\ntrying to get their transactions included into the next block.\n\nRegarding size, the block template and weak block could both be sent in\nBIP152 compact block format as a diff against the expected contents of a\ntypical node, allowing Alice to send just a small amount of additional\ndata for relay over what she'd have to send anyway for each transaction\nin a package.  (Although it's quite possible that BetterHash or Stratum\nv2 have even better solutions, possibly already implemented.)\n\nIf nothing else, I think Nostr could provide an interesting playground\nfor experimenting with various relay and mining ideas we've talked about\nfor years, so thanks again for working on this!\n\n-Dave\n\n[1] In addition to validating transactions, a relay would probably want\n     to reject templates that contained transactions that took\n     excessively long to validate (which could cause a block including\n     them to become stale) or that included features reserved for\n     upgrades (as a soft fork that happened before the relay's node was\n     upgraded might make that block invalid)."
            },
            {
                "author": "Joost Jager",
                "date": "2023-05-30T12:30:51",
                "message_text_only": "Hi David,\n\n\n> A block template is an ordered list of raw transactions that can all be\n> included in the next block (with some space reserved for a coinbase\n> transaction).  A full node can validate those transactions and calculate\n> how much fee they pay.  A Nostr relay can simply relay almost[1] any\n> template that pays more fees than the previous best template it saw for\n> the next block.  That can be more flexible than the current\n> implementation of submitblock with package relay which still enforces a\n> lot of the rules that helps keep a regular relay node safe from DoS and\n> a miner node able to select mineable transactions quickly.\n>\n\nInteresting idea! This would also make it easy for external services to try\nto do the best possible block building using advanced algorithms. Miners\nwould just select the best template available from various sources\nincluding nostr.\n\n\n> A weak block is a block whose header doesn't quite hash to low enough of\n> a value to be included on the chain.  It still takes an extraordinary\n> amount of hashrate to produce, so it's inherently DoS resistant.  If\n> miners are producing block that include transactions not seen by typical\n> relay nodes, that can reduce the efficiency and effectiveness of BIP152\n> compact block relay, which hurts the profitability of miners of custom\n> blocks.  To compensate, miners could relay weak blocks through Nostr to\n> full nodes and other miners so that they could quickly relay and accept\n> complete blocks that later included the same custom transactions.  This\n> would also help fee estimation and provide valuable insights to those\n> trying to get their transactions included into the next block.\n>\n\nI believe this would be useful right away, wouldn't it? Looking at\nmempool.space's block audit, there are definitely blocks that have a\n\"surprising\" content and might take long to download.\n\nThe anti-dos measures that you describe for both weak blocks and block\ntemplates seem very robust, but they would require a more intelligent nostr\nrelay to enforce. Not sure if it is still allowed to call it nostr at that\npoint. Perhaps it becomes more of a specialised bitcoin relay. btcstr -\n\"bitcoin stuff transmitted by relays\".\n\nRegarding size, the block template and weak block could both be sent in\n> BIP152 compact block format as a diff against the expected contents of a\n> typical node, allowing Alice to send just a small amount of additional\n> data for relay over what she'd have to send anyway for each transaction\n> in a package.  (Although it's quite possible that BetterHash or Stratum\n> v2 have even better solutions, possibly already implemented.)\n>\n\nSounds like a great way to repurpose what already exists to reduce resource\nusage for these additional message types.\n\n\n> If nothing else, I think Nostr could provide an interesting playground\n> for experimenting with various relay and mining ideas we've talked about\n> for years, so thanks again for working on this!\n>\n\nI think so too! The main question on my mind though is how to actually make\nthis work. There is a bit of a chicken-egg problem here with users and\nminers possibly waiting for each other to adopt.\n\nJoost\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230530/1f001ed5/attachment.html>"
            },
            {
                "author": "Greg Sanders",
                "date": "2023-05-30T13:30:32",
                "message_text_only": "Hi Joost, David,\n\nIn my mind, weak blocks' main benefit would be that it improves block relay\nby giving PoW-hints on what are in miner's mempools. Non-standard\ntransactions could even be cached(even if not validated until block\ninclusion), which would tolerate more heterogeneity in policies without\ndrastically increasing relay times. Of course, it can also have the side\neffect of gossiping better transaction packages, though I think this would\nbe a ton of work to really take advantage of. Perhaps we might be able to\ndo better in a post-cluster-mempool world, gossiping chunks.\n\nAt present I think energy would be best spent writing a weak blocks BIP\nproposal, since one has never been written before(?), and it would be\nfairly trivial to swap out p2p things with RPC calls if so desired for fast\nexperimentation over alternative relays.\n\nCheers,\nGreg\n\n\n\nOn Tue, May 30, 2023 at 8:58\u202fAM Joost Jager via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi David,\n>\n>\n>> A block template is an ordered list of raw transactions that can all be\n>> included in the next block (with some space reserved for a coinbase\n>> transaction).  A full node can validate those transactions and calculate\n>> how much fee they pay.  A Nostr relay can simply relay almost[1] any\n>> template that pays more fees than the previous best template it saw for\n>> the next block.  That can be more flexible than the current\n>> implementation of submitblock with package relay which still enforces a\n>> lot of the rules that helps keep a regular relay node safe from DoS and\n>> a miner node able to select mineable transactions quickly.\n>>\n>\n> Interesting idea! This would also make it easy for external services to\n> try to do the best possible block building using advanced algorithms.\n> Miners would just select the best template available from various sources\n> including nostr.\n>\n>\n>> A weak block is a block whose header doesn't quite hash to low enough of\n>> a value to be included on the chain.  It still takes an extraordinary\n>> amount of hashrate to produce, so it's inherently DoS resistant.  If\n>> miners are producing block that include transactions not seen by typical\n>> relay nodes, that can reduce the efficiency and effectiveness of BIP152\n>> compact block relay, which hurts the profitability of miners of custom\n>> blocks.  To compensate, miners could relay weak blocks through Nostr to\n>> full nodes and other miners so that they could quickly relay and accept\n>> complete blocks that later included the same custom transactions.  This\n>> would also help fee estimation and provide valuable insights to those\n>> trying to get their transactions included into the next block.\n>>\n>\n> I believe this would be useful right away, wouldn't it? Looking at\n> mempool.space's block audit, there are definitely blocks that have a\n> \"surprising\" content and might take long to download.\n>\n> The anti-dos measures that you describe for both weak blocks and block\n> templates seem very robust, but they would require a more intelligent nostr\n> relay to enforce. Not sure if it is still allowed to call it nostr at that\n> point. Perhaps it becomes more of a specialised bitcoin relay. btcstr -\n> \"bitcoin stuff transmitted by relays\".\n>\n> Regarding size, the block template and weak block could both be sent in\n>> BIP152 compact block format as a diff against the expected contents of a\n>> typical node, allowing Alice to send just a small amount of additional\n>> data for relay over what she'd have to send anyway for each transaction\n>> in a package.  (Although it's quite possible that BetterHash or Stratum\n>> v2 have even better solutions, possibly already implemented.)\n>>\n>\n> Sounds like a great way to repurpose what already exists to reduce\n> resource usage for these additional message types.\n>\n>\n>> If nothing else, I think Nostr could provide an interesting playground\n>> for experimenting with various relay and mining ideas we've talked about\n>> for years, so thanks again for working on this!\n>>\n>\n> I think so too! The main question on my mind though is how to actually\n> make this work. There is a bit of a chicken-egg problem here with users and\n> miners possibly waiting for each other to adopt.\n>\n> Joost\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230530/5d9a838f/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Transaction Relay over Nostr",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "alicexbt",
                "David A. Harding",
                "Joost Jager",
                "Greg Sanders"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 19298
        }
    },
    {
        "title": "[bitcoin-dev] bitcoin-dev Digest, Vol 96, Issue 58",
        "thread_messages": [
            {
                "author": "ecurrencyhodler",
                "date": "2023-05-25T16:06:31",
                "message_text_only": "Date: Wed, 24 May 2023\nFrom: ecurrencyhodler<ecurrencyhodler at gmail.com>\nTo: Bitcoin Protocol Discussion\n        <bitcoin-dev at lists.linuxfoundation.org>\nSubject: Re: [bitcoin-dev] Ark: An Alternative Privacy-preserving\n        Second  Layer Solution (ecurrencyhodler)\n\nThanks David for your write up. Clear, concise, and super understandable as\nalways.\n\nIt sounds like to me that ARK is using PSBT's + covenants to secure\nunconfirmed txns.\n\nI see how this significantly reduces onchain footprint. But wouldn't this\nalso have a massive impact at scale to the mempool filling it with\nunconfirmed txns? Couple concerns I have are:\n\n   1. It would create an ever growing fee environment within the 10-minute\n   block. Therefore it would be possible for the first settlement txn in the\n   first 5 seconds to get pushed out of the mempool by later settlement txns\n   closer to the 10 minute mark.\n   2. Mempools would have to drastically increase their size to capture all\n   the 5-second settlement unconfirmed txns and default bitcoin core nodes\n   would get flooded.\n\nThanks again burak for your ARK proposal. There seems to be a good amount\nof excitement about what this could unlock in the future which is quite\nrefreshing to see.\n\nOn Thu, May 25, 2023 at 5:01\u202fAM <\nbitcoin-dev-request at lists.linuxfoundation.org> wrote:\n\n> Send bitcoin-dev mailing list submissions to\n>         bitcoin-dev at lists.linuxfoundation.org\n>\n> To subscribe or unsubscribe via the World Wide Web, visit\n>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> or, via email, send a message with subject or body 'help' to\n>         bitcoin-dev-request at lists.linuxfoundation.org\n>\n> You can reach the person managing the list at\n>         bitcoin-dev-owner at lists.linuxfoundation.org\n>\n> When replying, please edit your Subject line so it is more specific\n> than \"Re: Contents of bitcoin-dev digest...\"\n>\n>\n> Today's Topics:\n>\n>    1. Re: Ark: An Alternative Privacy-preserving Second Layer\n>       Solution (adiabat)\n>    2. Re: Ark: An Alternative Privacy-preserving Second Layer\n>       Solution (David A. Harding)\n>\n>\n> ----------------------------------------------------------------------\n>\n> Message: 1\n> Date: Wed, 24 May 2023 16:20:35 -0400\n> From: adiabat <rx at awsomnet.org>\n> To: Bitcoin Protocol Discussion\n>         <bitcoin-dev at lists.linuxfoundation.org>\n> Subject: Re: [bitcoin-dev] Ark: An Alternative Privacy-preserving\n>         Second  Layer Solution\n> Message-ID:\n>         <CAKEeUhg1qeZOv-Lk8SSTxdkgfSee_E6_4fwNV=\n> hfwsxLgwWkUw at mail.gmail.com>\n> Content-Type: text/plain; charset=\"UTF-8\"\n>\n> Hi - thanks for the Ark write up; I have a bunch of questions but here's 2:\n>\n> ---\n> Q1:\n> \"Pool transactions are created by ark service providers perpetually\n> every 5 seconds\"\n>\n> What exactly happens every 5 seconds?  From the 15.44.21-p-1080.png\n> diagram [1], a pool transaction is a bitcoin transaction, with all the\n> inputs coming from the ASP.  My understanding is that every 5 seconds,\n> we progress from PoolTx(N) to PoolTx(N+1).  Does the ASP sign a new\n> transaction which spends the same ASP funding inputs as the previous\n> pool transaction, which is a double spend or fee bump?  Or does it\n> spend the outputs from the previous PoolTx?\n>\n> In other words, does PoolTx(2) replace PoolTx(1) RBF-style, spending\n> the same inputs (call this method A), or does PoolTx(2) spend an\n> output Of Pooltx(1) such that PoolTx(1) must be confirmed in order for\n> PoolTx(2) to become valid (method B)?  Or are they completely separate\n> transactions with unconflicting inputs (method C)?\n>\n> When the ASP creates a pool transaction, what do they do with it?  Do\n> they broadcast it to the gossip network?  Or share it with other pool\n> participants?\n>\n> With method A, if the ASP shares pool transactions with other people,\n> there Doesn't seem to be any way to ensure which PoolTx gets\n> confirmed, invalidating all the other ones.  They're all valid so\n> whichever gets into a block first wins.\n>\n> With method B, there seems to be a large on-chain load, with ~120\n> chained transactions trying to get in every block. This wouldn't play\n> nicely with mempool standardness and doesn't seem like you could ever\n> \"catch up\".\n>\n> With method C, ASPs would need a pretty large number of inputs but\n> could recycle them as blocks confirm.  It would cost a lot but maybe\n> could work.\n>\n> ---\n> Q2:\n>\n> The other part I'm missing is: what prevents the ASP from taking all\n> the money?  Before even getting to vTXOs and connector outputs, from\n> the diagram there are only ASP inputs funding the pool transaction.\n> If the pool transaction is confirmed, the vTXOs are locked in place,\n> since the vTXO output cannot be changed and commits to all\n> \"constrained outs\" via OP_CTV.  If the pool transaction is\n> unconfirmed, the ASP can create & sign a transaction spending all ASP\n> funding inputs sending the money back to the ASP, or anywhere else.\n> In this case, users don't have any assurance that their vTXO can ever\n> turn into a real UTXO; the ASP can \"rug-pull\" at any time, taking all\n> the money in the pool.  Adding other inputs not controlled by the ASP\n> to the transaction wouldn't seem to fix the problem, because then any\n> user removing their inputs would cancel the whole transaction.\n>\n> More detail about how these transactions work would be appreciated, thanks!\n>\n> -Tadge\n>\n> [1]\n> https://uploads-ssl.webflow.com/645ae2e299ba34372614141d/6467d1f1bf91e0bf2c2eddef_Screen%20Shot%202023-05-19%20at%2015.44.21-p-1080.png\n>\n>\n> ------------------------------\n>\n> Message: 2\n> Date: Wed, 24 May 2023 13:02:40 -1000\n> From: \"David A. Harding\" <dave at dtrt.org>\n> To: Burak Keceli <burak at buraks.blog>, Bitcoin Protocol Discussion\n>         <bitcoin-dev at lists.linuxfoundation.org>\n> Subject: Re: [bitcoin-dev] Ark: An Alternative Privacy-preserving\n>         Second Layer Solution\n> Message-ID: <3c6c3b8b562bb56bbb855dc2b2b71f78 at dtrt.org>\n> Content-Type: text/plain; charset=US-ASCII; format=flowed\n>\n> Hi Burak,\n>\n> Thanks for this really interesting protocol!  I tend to analyze\n> complicated ideas like this by writing about them in my own words, so\n> I've pasted my summary of your idea to the end of this email in case\n> it's useful, either to other people or to you in helping understand my\n> one concern.\n>\n> My concern is the same one I think Olaoluwa Osuntokun mentioned on\n> Twitter[1] and (less clear to me) might be related to ZmnSCPxj's\n> concern[2]:\n>\n> It seems to me that receiving a payment on the protocol, including\n> conditional payments using HTLC, PTLC, or Anchor-TLC, requires waiting\n> for the transaction containing that payment to confirm to a sufficient\n> depth (e.g., I'd wait 6 blocks for small payments and longer for huge\n> payments).  Am I missing something?\n>\n> My summary of how I think that part of the protocol works is in the\n> sections labeled \"Make an unconditioned payment\" and \"Make a conditional\n> payment\" below.  In short, it's clear to me how the service provider and\n> the customer can make instant atomic swaps with each other---they can\n> either spend instantly cooperatively, or they have to wait for a\n> timeout.  But how can a receiver of funds be assured that they will\n> actually get those funds unless there's already a timelock and\n> cooperative spend path placed on those funds?\n>\n> -Dave\n>\n> Rough initial summary of Ark protocol:\n>\n> Alice runs an Ark service provider.  Every 5 seconds, she broadcasts a\n> new unconfirmed onchain transaction that pays three outputs (the\n> three Cs):\n>\n> 1. *Change Output:* money not used for the other two Cs that gets sent\n>     back to the the transaction creator.\n>\n> 2. *Connector Output:* an output that will be used in a future\n>     transaction created by Alice as protection against double spends.\n>\n> 3. *Commitment Output:* a CTV-style commitment to a set of outputs that\n>     can be published later in a descendant transaction (alternatively,\n>     the commitment output may be spent unilaterally by Alice after 4\n>     weeks).\n>\n> Bob wants to deposit 1 BTC with Alice.  He sends her an unsigned PSBT\n> with an input of his and a change output.  She updates the PSBT with a\n> commitment output that refunds Bob the 1 BTC and a connector output with\n> some minimum value.  They both sign the PBST and it is broadcast.  We'll\n> ignore fees in our examples, both onchain transaction fees and fees paid\n> to Alice.\n>\n>  From here, there are several things that Bob can do:\n>\n> - *Unilaterally withdraw:* Bob can spend from the commitment output to\n>    put his refund onchain.  The refund can only be spent after a 24-hour\n>    time delay, allowing Bob to optionally come to an agreement with Alice\n>    about how to spend the funds before Bob can spend them unilaterally\n>    (as we'll see in a moment).  For example, the script might be[3]:\n>\n>      pk(B) && (older(1 day) || pk(A))\n>\n> - *Collaboratively withdraw:* as seen above, Bob has the ability to come\n>    to a trustless agreement with Alice about how to spend his funds.\n>    They can use that ability to allow Bob to trade his (unpublished) UTXO\n>    for a UTXO that Alice funds and broadcasts.  For example:\n>\n>      - Alice creates an unsigned PSBT that uses as one of its inputs the\n>        connector from Bob's deposit transaction.  This will ensure that\n>        any attempt by Bob to double-spend his deposit transaction will\n>        invalidate this withdrawal transaction, preventing Bob from being\n>        able to steal any of Alice's funds.\n>\n>          Also included in Alice's unsigned PSBT is another connector\n>          output plus the output that pays Bob his 1 BTC.\n>\n>      - Bob receives Alice's unsigned PSBT and creates a separate PSBT\n>        that includes his unpublished UTXO as an input, giving its value\n>        to Alice in an output.  The PSBT also includes as an input the\n>        connector output from Alice's PSBT.  This will ensure that any\n>        attempt by Alice to double spend her transaction paying him will\n>        invalidate his transaction paying her.\n>\n>      - Bob signs his PSBT and gives it to Alice.  After verifying it,\n>        Alice signs her PSBT and broadcasts it.\n>\n> - *Collaboratively trade commitments:* as mentioned, the commitment\n>    output that pays Bob may be claimed instead by Alice after 4 weeks, so\n>    Bob will need to either withdraw or obtain a new commitment within\n> that\n>    time.  To trade his existing commitment for a new commitment looks\n>    similar to the collaborative withdrawal procedure but without the\n>    creation of an immediately-spendable onchain output:\n>\n>      - Alice creates an unsigned PSBT that uses as one of its inputs the\n>        connector from Bob's deposit transaction, again preventing double\n>        spending by Bob.  Alice also includes a new connector and a new\n>        commitment that again allows Bob to later claim 1 BTC.\n>\n>      - Bob receives Alice's PSBT and creates a PSBT transferring his\n>        existing commitment to her, with the new connector again being\n>        included as an input to ensure atomicity.\n>\n>      - Bob signs; Alice signs and broadcasts.\n>\n> - *Make an unconditioned payment:* using the mechanisms described above,\n>    it's possible to make either an onchain payment or an offchain\n>    payment---just have Carol receive the new output or commitment rather\n>    than Bob.  That payment would have no conditions (except its\n>    atomicity).\n>\n> - *Make a conditional payment:* imagine that Carol knows a secret (e.g.\n>    a preimage) that Bob is willing to pay for.\n>\n>       - Alice creates an unsigned PSBT depending on the connector from\n>         Bob's deposit transaction and creating a new connector.  The PSBT\n>         includes an output paying Carol (either onchain or via a\n>         commitment) with an HTLC, allowing Carol to claim the funds if\n> she\n>         reveals the secret or allowing Bob to claim the funds after a\n>         timeout.\n>\n>       - Bob receives Alice's PSBT and creates a PSBT transferring his\n>         existing commitment to her with the HTLC condition attached and,\n>         again, with connectors being used to ensure atomicity.\n>\n>       - Bob signs; Alice signs and broadcasts.\n>\n>       - Carol can settle her HTLC by either revealing the secret onchain\n>         or by trading her commitment containing the HTLC clause for a\n>         commitment from Alice that doesn't contain the clause (which\n>         Alice will only accept by learning the secret, since Alice has\n>         to settle with Bob).  Alice can then either settle onchain or\n>         trade commitments with Bob after giving him the secret.\n>\n> - *Do nothing for 4 weeks:* if Bob does nothing for four weeks, Alice\n>    can claim the funds from the commitment output (i.e., takes his\n>    money).\n>\n>      If Bob did actually do something, and if every other user who also\n>      had an unpublished output in the commitment transaction did\n>      something, then they all exchanged their portion of the funds in\n>      this output to Alice, so Alice can now claim all of those funds\n>      onchain in a highly efficient manner.\n>\n> Regarding the connector outputs, although all of the examples above show\n> Alice directly spending from the connector output in Bob's deposit\n> transaction, atomicity is also ensured if Alice spends from any output\n> descended from Bob's connector output.  Connector outputs from different\n> deposits can be used as inputs into the same transaction, merging their\n> histories.  This allows all operations made by Alice to be fully atomic,\n> ensuring that she doesn't lose any money during a reorg of any length.\n>\n> Users are not so well protected during reorgs, e.g. if Bob double-spends\n> a transaction whose funds were later used in a payment to Carol, then\n> Carol loses the money.  For this reason, Alice will probably want to\n> prove to users that no funds they receive in a payment derive from any\n> deposit less than safe_confirmation_depth blocks.\n>\n> [1] https://twitter.com/roasbeef/status/1661266771784126464\n>\n> [2]\n>\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-May/021710.html\n>\n> [3]\n>\n> https://min.sc/#c=pk%28B%29%20%26%26%20%28older%281%20day%29%20%7C%7C%20pk%28A%29%29\n>\n>\n> ------------------------------\n>\n> Subject: Digest Footer\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n> ------------------------------\n>\n> End of bitcoin-dev Digest, Vol 96, Issue 58\n> *******************************************\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230525/45564862/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "bitcoin-dev Digest, Vol 96, Issue 58",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ecurrencyhodler"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 14882
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Core 25.0 released",
        "thread_messages": [
            {
                "author": "Michael Ford",
                "date": "2023-05-26T10:39:17",
                "message_text_only": "Bitcoin Core version v25.0 is now available from:\n\n    https://bitcoincore.org/bin/bitcoin-core-25.0/\n\nOr through BitTorrent:\n\n    magnet:?xt=urn:btih:092358777175c4306602f9b1b523738df4b4610b&dn=bitcoin-core-25.0&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969%2Fannounce&tr=udp%3A%2F%2Ftracker.leechers-paradise.org%3A6969%2Fannounce&tr=udp%3A%2F%2Fexplodie.org%3A6969%2Fannounce&tr=udp%3A%2F%2Ftracker.torrent.eu.org%3A451%2Fannounce&tr=udp%3A%2F%2Ftracker.bitcoin.sprovoost.nl%3A6969&ws=http%3A%2F%2Fbitcoincore.org%2Fbin%2F\n\nThis release includes new features, various bug fixes and performance\nimprovements, as well as updated translations.\n\nPlease report bugs using the issue tracker at GitHub:\n\n  <https://github.com/bitcoin/bitcoin/issues>\n\nTo receive security and update notifications, please subscribe to:\n\n  <https://bitcoincore.org/en/list/announcements/join/>\n\nHow to Upgrade\n==============\n\nIf you are running an older version, shut it down. Wait until it has completely\nshut down (which might take a few minutes in some cases), then run the\ninstaller (on Windows) or just copy over `/Applications/Bitcoin-Qt` (on macOS)\nor `bitcoind`/`bitcoin-qt` (on Linux).\n\nUpgrading directly from a version of Bitcoin Core that has reached its EOL is\npossible, but it might take some time if the data directory needs to\nbe migrated. Old\nwallet versions of Bitcoin Core are generally supported.\n\nCompatibility\n==============\n\nBitcoin Core is supported and extensively tested on operating systems\nusing the Linux kernel, macOS 10.15+, and Windows 7 and newer.  Bitcoin\nCore should also work on most other Unix-like systems but is not as\nfrequently tested on them.  It is not recommended to use Bitcoin Core on\nunsupported systems.\n\nNotable changes\n===============\n\nP2P and network changes\n-----------------------\n\n- Transactions of non-witness size 65 bytes and above are now allowed by mempool\n  and relay policy. This is to better reflect the actual afforded protections\n  against CVE-2017-12842 and open up additional use-cases of smaller\ntransaction sizes. (#26265)\n\nNew RPCs\n--------\n\n- The scanblocks RPC returns the relevant blockhashes from a set of\ndescriptors by\n  scanning all blockfilters in the given range. It can be used in\ncombination with\n  the getblockheader and rescanblockchain RPCs to achieve fast wallet\nrescans. Note\n  that this functionality can only be used if a compact block filter index\n  (-blockfilterindex=1) has been constructed by the node. (#23549)\n\nUpdated RPCs\n------------\n\n- All JSON-RPC methods accept a new [named\n  parameter](https://github.com/bitcoin/bitcoin/blob/master/doc/JSON-RPC-interface.md#parameter-passing)\ncalled `args` that can\n  contain positional parameter values. This is a convenience to allow some\n  parameter values to be passed by name without having to name every value. The\n  python test framework and `bitcoin-cli` tool both take advantage of this, so\n  for example:\n\n```sh\nbitcoin-cli -named createwallet wallet_name=mywallet load_on_startup=1\n```\n\nCan now be shortened to:\n\n```sh\nbitcoin-cli -named createwallet mywallet load_on_startup=1\n```\n\n- The `verifychain` RPC will now return `false` if the checks didn't fail,\n  but couldn't be completed at the desired depth and level. This could be due\n  to missing data while pruning, due to an insufficient dbcache or due to\n  the node being shutdown before the call could finish. (#25574)\n\n- `sendrawtransaction` has a new, optional argument, `maxburnamount`\nwith a default value of `0`.\n  Any transaction containing an unspendable output with a value\ngreater than `maxburnamount` will\n  not be submitted. At present, the outputs deemed unspendable are\nthose with scripts that begin\n  with an `OP_RETURN` code (known as 'datacarriers'), scripts that\nexceed the maximum script size,\n  and scripts that contain invalid opcodes.\n\n- The `testmempoolaccept` RPC now returns 2 additional results within\nthe \"fees\" result:\n  \"effective-feerate\" is the feerate including fees and sizes of\ntransactions validated together if\n  package validation was used, and also includes any modified fees\nfrom prioritisetransaction. The\n  \"effective-includes\" result lists the wtxids of transactions whose\nmodified fees and sizes were used\n  in the effective-feerate (#26646).\n\n- `decodescript` may now infer a Miniscript descriptor under P2WSH\ncontext if it is not lacking\n  information. (#27037)\n\n- `finalizepsbt` is now able to finalize a transaction with inputs\nspending Miniscript-compatible\n  P2WSH scripts. (#24149)\n\nChanges to wallet related RPCs can be found in the Wallet section below.\n\nBuild System\n------------\n\n- The `--enable-upnp-default` and `--enable-natpmp-default` options\n  have been removed. If you want to use port mapping, you can\n  configure it using a .conf file, or by passing the relevant\n  options at runtime. (#26896)\n\nUpdated settings\n----------------\n\n- If the `-checkblocks` or `-checklevel` options are explicitly provided by the\nuser, but the verification checks cannot be completed due to an insufficient\ndbcache, Bitcoin Core will now return an error at startup. (#25574)\n\n- Ports specified in `-port` and `-rpcport` options are now validated\nat startup.\n  Values that previously worked and were considered valid can now\nresult in errors. (#22087)\n\n- Setting `-blocksonly` will now reduce the maximum mempool memory\n  to 5MB (users may still use `-maxmempool` to override). Previously,\n  the default 300MB would be used, leading to unexpected memory usage\n  for users running with `-blocksonly` expecting it to eliminate\n  mempool memory usage.\n\n  As unused mempool memory is shared with dbcache, this also reduces\n  the dbcache size for users running with `-blocksonly`, potentially\n  impacting performance.\n- Setting `-maxconnections=0` will now disable `-dnsseed`\n  and `-listen` (users may still set them to override).\n\nChanges to GUI or wallet related settings can be found in the GUI or\nWallet section below.\n\nNew settings\n------------\n\n- The `shutdownnotify` option is used to specify a command to execute\nsynchronously\nbefore Bitcoin Core has begun its shutdown sequence. (#23395)\n\n\nWallet\n------\n\n- The `minconf` option, which allows a user to specify the minimum number\nof confirmations a UTXO being spent has, and the `maxconf` option,\nwhich allows specifying the maximum number of confirmations, have been\nadded to the following RPCs in #25375:\n  - `fundrawtransaction`\n  - `send`\n  - `walletcreatefundedpsbt`\n  - `sendall`\n\n- Added a new `next_index` field in the response in `listdescriptors` to\n  have the same format as `importdescriptors` (#26194)\n\n- RPC `listunspent` now has a new argument `include_immature_coinbase`\n  to include coinbase UTXOs that don't meet the minimum spendability\n  depth requirement (which before were silently skipped). (#25730)\n\n- Rescans for descriptor wallets are now significantly faster if compact\n  block filters (BIP158) are available. Since those are not constructed\n  by default, the configuration option \"-blockfilterindex=1\" has to be\n  provided to take advantage of the optimization. This improves the\n  performance of the RPC calls `rescanblockchain`, `importdescriptors`\n  and `restorewallet`. (#25957)\n\n- RPC `unloadwallet` now fails if a rescan is in progress. (#26618)\n\n- Wallet passphrases may now contain null characters.\n  Prior to this change, only characters up to the first\n  null character were recognized and accepted. (#27068)\n\n- Address Purposes strings are now restricted to the currently known\nvalues of \"send\",\n  \"receive\", and \"refund\". Wallets that have unrecognized purpose\nstrings will have\n  loading warnings, and the `listlabels` RPC will raise an error if an\nunrecognized purpose\n  is requested. (#27217)\n\n- In the `createwallet`, `loadwallet`, `unloadwallet`, and\n`restorewallet` RPCs, the\n  \"warning\" string field is deprecated in favor of a \"warnings\" field that\n  returns a JSON array of strings to better handle multiple warning messages and\n  for consistency with other wallet RPCs. The \"warning\" field will be fully\n  removed from these RPCs in v26. It can be temporarily re-enabled during the\n  deprecation period by launching bitcoind with the configuration option\n  `-deprecatedrpc=walletwarningfield`. (#27279)\n\n- Descriptor wallets can now spend coins sent to P2WSH Miniscript\ndescriptors. (#24149)\n\nGUI changes\n-----------\n\n- The \"Mask values\" is a persistent option now. (gui#701)\n- The \"Mask values\" option affects the \"Transaction\" view now, in\naddition to the\n  \"Overview\" one. (gui#708)\n\nREST\n----\n\n- A new `/rest/deploymentinfo` endpoint has been added for fetching various\n  state info regarding deployments of consensus changes. (#25412)\n\nBinary verification\n----\n\n- The binary verification script has been updated. In previous releases it\n  would verify that the binaries had been signed with a single \"release key\".\n  In this release and moving forward it will verify that the binaries are\n  signed by a _threshold of trusted keys_. For more details and\n  examples, see:\n  https://github.com/bitcoin/bitcoin/blob/master/contrib/verify-binaries/README.md\n  (#27358)\n\nLow-level changes\n=================\n\nRPC\n---\n\n- The JSON-RPC server now rejects requests where a parameter is\nspecified multiple\n  times with the same name, instead of silently overwriting earlier\nparameter values\n  with later ones. (#26628)\n- RPC `listsinceblock` now accepts an optional `label` argument\n  to fetch incoming transactions having the specified label. (#25934)\n- Previously `setban`, `addpeeraddress`, `walletcreatefundedpsbt`, methods\n  allowed non-boolean and non-null values to be passed as boolean parameters.\n  Any string, number, array, or object value that was passed would be treated\n  as false. After this change, passing any value except `true`, `false`, or\n  `null` now triggers a JSON value is not of expected type error. (#26213)\n\nCredits\n=======\n\nThanks to everyone who directly contributed to this release:\n\n- 0xb10c\n- 721217.xyz\n- @RandyMcMillan\n- amadeuszpawlik\n- Amiti Uttarwar\n- Andrew Chow\n- Andrew Toth\n- Anthony Towns\n- Antoine Poinsot\n- Aur\u00e8le Oul\u00e8s\n- Ben Woosley\n- Bitcoin Hodler\n- brunoerg\n- Bushstar\n- Carl Dong\n- Chris Geihsler\n- Cory Fields\n- David Gumberg\n- dergoegge\n- Dhruv Mehta\n- Dimitris Tsapakidis\n- dougEfish\n- Douglas Chimento\n- ekzyis\n- Elichai Turkel\n- Ethan Heilman\n- Fabian Jahr\n- FractalEncrypt\n- furszy\n- Gleb Naumenko\n- glozow\n- Greg Sanders\n- Hennadii Stepanov\n- hernanmarino\n- ishaanam\n- ismaelsadeeq\n- James O'Beirne\n- jdjkelly at gmail.com\n- Jeff Ruane\n- Jeffrey Czyz\n- Jeremy Rubin\n- Jesse Barton\n- Jo\u00e3o Barbosa\n- JoaoAJMatos\n- John Moffett\n- Jon Atack\n- Jonas Schnelli\n- jonatack\n- Joshua Kelly\n- josibake\n- Juan Pablo Civile\n- kdmukai\n- klementtan\n- Kolby ML\n- kouloumos\n- Kristaps Kaupe\n- laanwj\n- Larry Ruane\n- Leonardo Araujo\n- Leonardo Lazzaro\n- Luke Dashjr\n- MacroFake\n- MarcoFalke\n- Martin Leitner-Ankerl\n- Martin Zumsande\n- Matt Whitlock\n- Matthew Zipkin\n- Michael Ford\n- Miles Liu\n- mruddy\n- Murray Nesbitt\n- muxator\n- omahs\n- pablomartin4btc\n- Pasta\n- Pieter Wuille\n- Pttn\n- Randall Naar\n- Riahiamirreza\n- roconnor-blockstream\n- Russell O'Connor\n- Ryan Ofsky\n- S3RK\n- Sebastian Falbesoner\n- Seibart Nedor\n- sinetek\n- Sjors Provoost\n- Skuli Dulfari\n- SomberNight\n- Stacie Waleyko\n- stickies-v\n- stratospher\n- Suhas Daftuar\n- Suriyaa Sundararuban\n- TheCharlatan\n- Vasil Dimov\n- Vasil Stoyanov\n- virtu\n- w0xlt\n- willcl-ark\n- yancy\n- Yusuf Sahin HAMZA\n\nAs well as to everyone that helped with translations on\n[Transifex](https://www.transifex.com/bitcoin/bitcoin/)."
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Core 25.0 released",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Michael Ford"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 11634
        }
    },
    {
        "title": "[bitcoin-dev] Encrypted (like BIP38) master private key",
        "thread_messages": [
            {
                "author": "Ali Sherief",
                "date": "2023-05-30T10:08:02",
                "message_text_only": "Just like we have BIPP38 encrypted keys for singular private keys, I was wondering if it would be possible to come up with a way to encrypt an extended private key using reversible encryption.\n\nBIP38 was designed with physical coins in mind, and in particular covers the cases for lot and sequence numbers in detail.\n\nThere is a case to be made that in an encrypted extended private key, the lot and sequence numbers can be placed in the HD derivation path. In particular they can be derived like this: m/lot'/sequence' and both of them use hardened derivation.\n\nThe advantage would be that coinmakers would only have to generate one master private key during manufacturing instead of a ton of private keys.\n\nBut this is not a very convincing advantage so I'd like to hear what is other people's take on this.\n\n-Ali\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20230530/59054c47/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Encrypted (like BIP38) master private key",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Ali Sherief"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 998
        }
    }
]