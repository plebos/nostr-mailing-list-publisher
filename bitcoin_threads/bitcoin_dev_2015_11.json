[
    {
        "title": "[bitcoin-dev] Compatibility requirements for hard or soft forks",
        "thread_messages": [
            {
                "author": "Justus Ranvier",
                "date": "2015-11-01T14:36:35",
                "message_text_only": "On 10/30/2015 10:43 PM, Rusty Russell via bitcoin-dev wrote:\n> By that benchmark, we should aim for \"reasonable certainty\".  A\n> transaction which would never have been generated by any known software\n> is the minimum bar.  Adding \"...which would have to be deliberately\n> stupid with many redundant OP_CHECKSIG etc\" surpasses it.  The only extra\n> safeguard I can think of is clear, widespread notification of the\n> change.\n\nIf the policy of Bitcoin Core development includes a willingness to\nmakes the utxos created by software other than Bitcoin Core unspendable,\nthen it certainly merits clear, widespread notification.\n\nEven if that is actually a good policy, the reasons why should be made\nabundantly clear.\n\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: 0xEAD9E623.asc\nType: application/pgp-keys\nSize: 23337 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151101/1034f016/attachment.bin>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 801 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151101/1034f016/attachment.sig>"
            },
            {
                "author": "jl2012 at xbt.hk",
                "date": "2015-11-01T17:28:39",
                "message_text_only": "My answer is simply \"No\", you don't have to maintain backward \ncompatibility for non-standard tx.\n\nThe same question applies to P2SH. Before the deployment of BIP16, one \ncould have created a time-locked tx with one of the output was in the \nform of HASH160 <hash> EQUAL. The <hash>, however, is not a hash of a \nvalid serialized script, so the output is now permanently frozen.\n\nIt also applies to all the OP codes disabled by Satoshi: one could have \ncreated a time-locked tx with those now disabled OP codes.\n\nSame for BIP65 with the use of OP_NOP2. Following your logic, we can't \nmake any softfork related to the script system.\n\nI think it is very important to make it clear that non-standard txs and \nnon-standard scripts may become invalid in the future\n\nGavin Andresen via bitcoin-dev \u65bc 2015-10-28 10:06 \u5beb\u5230:\n> I'm hoping this fits under the moderation rule of \"short-term changes\n> to the Bitcoin protcol\" (I'm not exactly clear on what is meant by\n> \"short-term\"; it would be lovely if the moderators would start a\n> thread on bitcoin-discuss to clarify that):\n> \n> Should it be a requirement that ANY one-megabyte transaction that is\n> valid\n> under the existing rules also be valid under new rules?\n> \n> Pro:  There could be expensive-to-validate transactions created and\n> given a\n> lockTime in the future stored somewhere safe. Their owners may have no\n> other way of spending the funds (they might have thrown away the\n> private\n> keys), and changing validation rules to be more strict so that those\n> transactions are invalid would be an unacceptable confiscation of\n> funds.\n> \n> Con: It is extremely unlikely there are any such large, timelocked\n> transactions, because the Core code has had a clear policy for years\n> that\n> 100,000-byte transactions are &quot;standard&quot; and are relayed and\n> mined, and\n> larger transactions are not. The requirement should be relaxed so that\n> only\n> valid 100,000-byte transaction under old consensus rules must be valid\n> under new consensus rules (larger transactions may or may not be\n> valid).\n> \n> I had to wrestle with that question when I implemented BIP101/Bitcoin\n> XT\n> when deciding on a limit for signature hashing (and decided the right\n> answer was to support any \"non-attack\"1MB transaction; see\n> https://bitcoincore.org/~gavin/ValidationSanity.pdf [1] for more\n> details).\n> \n> --\n> \n> --\n> Gavin Andresen\n> \n> \n> Links:\n> ------\n> [1] https://bitcoincore.org/~gavin/ValidationSanity.pdf\n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Tier Nolan",
                "date": "2015-11-01T23:46:39",
                "message_text_only": "On Sun, Nov 1, 2015 at 5:28 PM, jl2012 via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I think it is very important to make it clear that non-standard txs and\n> non-standard scripts may become invalid in the future\n>\n\nThere can be unavoidable situations which cause locked coins become\nunspendable.\n\nIn an ideal world, soft forks that make UTXOs unspendable should increase\nthe tx version number.  BIP-13 should have done that.  That would make the\nchange opt-in.\n\nThe disabled opcodes like OP_CAT were a DOS/network security change.\n\nInvalidating locked coins is another reason that they shouldn't have been\ndisabled permanently.\n\nIt would have been better to disable them for six months, so at least\npeople can get their coins back after that.  Inherently, protecting the\nnetwork required some limitations being added so that nodes couldn't be\ncrashed.\n\nFor guidelines\n\n* Transaction version numbers will be increased, if possible\n* Transactions with unknown/large version numbers are unsafe to use with\nlocktime\n* Reasonable notice is given that the change is being contemplated\n* Non-opt-in changes will only be to protect the integrity of the network\n\nLocked transaction that can be validated without excessive load on the\nnetwork should be safe to use, even if non-standard.\n\nAn OP_CAT script that requires TBs of RAM to validate crosses the threshold\nof reasonableness.\n\n\n\n>\n> Gavin Andresen via bitcoin-dev \u65bc 2015-10-28 10:06 \u5beb\u5230:\n>\n>> I'm hoping this fits under the moderation rule of \"short-term changes\n>> to the Bitcoin protcol\" (I'm not exactly clear on what is meant by\n>> \"short-term\"; it would be lovely if the moderators would start a\n>> thread on bitcoin-discuss to clarify that):\n>>\n>> Should it be a requirement that ANY one-megabyte transaction that is\n>> valid\n>> under the existing rules also be valid under new rules?\n>>\n>> Pro:  There could be expensive-to-validate transactions created and\n>> given a\n>> lockTime in the future stored somewhere safe. Their owners may have no\n>> other way of spending the funds (they might have thrown away the\n>> private\n>> keys), and changing validation rules to be more strict so that those\n>> transactions are invalid would be an unacceptable confiscation of\n>> funds.\n>>\n>> Con: It is extremely unlikely there are any such large, timelocked\n>> transactions, because the Core code has had a clear policy for years\n>> that\n>> 100,000-byte transactions are &quot;standard&quot; and are relayed and\n>> mined, and\n>> larger transactions are not. The requirement should be relaxed so that\n>> only\n>> valid 100,000-byte transaction under old consensus rules must be valid\n>> under new consensus rules (larger transactions may or may not be\n>> valid).\n>>\n>> I had to wrestle with that question when I implemented BIP101/Bitcoin\n>> XT\n>> when deciding on a limit for signature hashing (and decided the right\n>> answer was to support any \"non-attack\"1MB transaction; see\n>> https://bitcoincore.org/~gavin/ValidationSanity.pdf [1] for more\n>> details).\n>>\n>> --\n>>\n>> --\n>> Gavin Andresen\n>>\n>>\n>> Links:\n>> ------\n>> [1] https://bitcoincore.org/~gavin/ValidationSanity.pdf\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151101/ba76df82/attachment.html>"
            },
            {
                "author": "Justus Ranvier",
                "date": "2015-11-02T00:23:27",
                "message_text_only": "On 11/01/2015 05:46 PM, Tier Nolan via bitcoin-dev wrote:\n> An OP_CAT script that requires TBs of RAM to validate crosses the\n> threshold of reasonableness. \n\nAre there actually any OP_CAT scripts currently in the utxo set?\n\nIt's one thing to have a theoretical scripting ability that gets removed\nbefore anyone actually uses it - that doesn't put anyone in the position\nof retroactively making decisions about the validity of someone else's\nmoney.\n\nPresently the utxo set is about $5 billion worth of other people's money.\n\nIt's a lot easier to justify the position: \"nobody has the right to\nchange the meaning of someone else's outputs\", than it is to justify,\n\"some small group of people gets to decide what's standard and what\nisn't, and if you choose to use the network in a valid but nonstandard\nway, that group of people might choose to deny you access to your money\nin the future\"\n\nIn other words, how close to the shores of \"administrators of a virtual\ncurrency\" do Bitcoin developers want to sail?\n\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: 0xEAD9E623.asc\nType: application/pgp-keys\nSize: 23337 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151101/173b3946/attachment-0001.bin>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 801 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151101/173b3946/attachment-0001.sig>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2015-11-02T00:33:18",
                "message_text_only": "On Monday, November 02, 2015 12:23:27 AM Justus Ranvier via bitcoin-dev wrote:\n> It's a lot easier to justify the position: \"nobody has the right to\n> change the meaning of someone else's outputs\", than it is to justify,\n> \"some small group of people gets to decide what's standard and what\n> isn't, and if you choose to use the network in a valid but nonstandard\n> way, that group of people might choose to deny you access to your money\n> in the future\"\n\nThe reality is presently \"some small group of people gets to decide how and if \nyou can access your money\"... and it's getting worse.\n\n> In other words, how close to the shores of \"administrators of a virtual\n> currency\" do Bitcoin developers want to sail?\n\nBitcoin developers don't make this decision, miners do.\n\nLuke"
            },
            {
                "author": "Tier Nolan",
                "date": "2015-11-02T01:30:51",
                "message_text_only": "On Mon, Nov 2, 2015 at 12:23 AM, Justus Ranvier via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Are there actually any OP_CAT scripts currently in the utxo set?\n>\n\nA locked transaction could pay to an OP_CAT script with the private key\nbeing lost.\n\nEven if it is only in theory, it is still worth trying to prevent rule\nchanges which permanently prevent outputs being spendable.\n\n\n> It's a lot easier to justify the position: \"nobody has the right to\n> change the meaning of someone else's outputs\", than it is to justify,\n> \"some small group of people gets to decide what's standard and what\n> isn't, and if you choose to use the network in a valid but nonstandard\n> way, that group of people might choose to deny you access to your money\n> in the future\"\n>\n\nIf at least one year's notice was given, then people aren't going to lose\ntheir money, since they have notice.\n\nLocked transactions could have a difference expectation than non-locked\nones.\n\n\n> In other words, how close to the shores of \"administrators of a virtual\n> currency\" do Bitcoin developers want to sail?\n>\n\nMiners can collectively vote to disable specific UTXOs and change the\nacceptance rules.\n\n\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151102/5514cf3c/attachment.html>"
            },
            {
                "author": "Justus Ranvier",
                "date": "2015-11-02T04:15:36",
                "message_text_only": "I guess by \"locked transaction\" you must mean a P2SH output?\n\nIf so, that's a rather bizarre use of terms since outputs and\ntransactions are very different things.\n\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: 0xEAD9E623.asc\nType: application/pgp-keys\nSize: 23337 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151101/f3ff4eea/attachment-0001.bin>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 801 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151101/f3ff4eea/attachment-0001.sig>"
            },
            {
                "author": "Justus Ranvier",
                "date": "2015-11-02T06:12:16",
                "message_text_only": "On 11/01/2015 07:30 PM, Tier Nolan via bitcoin-dev wrote:\n> If at least one year's notice was given, then people aren't going to\n> lose their money, since they have notice.\n\nSo after realizing that I misread substantial portions of this thread\ndue to a lack of attention to detail I'd like to point out this:\n\nBitcoin nodes have the capability to validate blocks going back to the\ngenesis block, including blocks which would not be valid if mined today\nunder current rules.\n\nTherefore it must be the case that all the old consensus rules are\npreserved somewhere in the current code bases of the various\nimplementations.\n\nGiven that, there shouldn't be any technical barrier to validating input\nscripts according to the consensus rules that were in effect at the time\nthe input being spent was added to the blockchain.\n\nMaybe dealing with output is more difficult.\n\nHad every consensus rule change (deliberate and accidental) been\naccompanied by a version number bump, it would have been possible to\nphase out old versions without invaliding signed-but-unbroadcast\ntransactions by saying \"as of block height x, transactions with version\ny or lower are invalid unless their inputs are exclusively sourced from\nblocks with heights < x\"\n\nIf there already have been rule changes which have retroactively\ninvalided unbroadcast transactions which were valid at the time they\nwere signed, those rules could be relaxed to not apply to transactions\nwhich exclusively spend inputs that existed before the rule change.\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: 0xEAD9E623.asc\nType: application/pgp-keys\nSize: 23337 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151102/30e16f8d/attachment-0001.bin>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 801 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151102/30e16f8d/attachment-0001.sig>"
            },
            {
                "author": "Gavin Andresen",
                "date": "2015-11-02T20:33:47",
                "message_text_only": "On Sun, Nov 1, 2015 at 6:46 PM, Tier Nolan via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> For guidelines\n>\n> * Transaction version numbers will be increased, if possible\n> * Transactions with unknown/large version numbers are unsafe to use with\n> locktime\n> * Reasonable notice is given that the change is being contemplated\n> * Non-opt-in changes will only be to protect the integrity of the network\n>\n> Locked transaction that can be validated without excessive load on the\n> network should be safe to use, even if non-standard.\n>\n> An OP_CAT script that requires TBs of RAM to validate crosses the\n> threshold of reasonableness.\n>\n\nI like those guidelines, although I'm sure there may be lots of arguing\nover what fits under \"protects the integrity of the network\" or what\nconstitutes \"reasonable notice\" (publish a BIP at least 30 days before\nrolling out a change? 60 days? a year?)\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151102/193dffef/attachment.html>"
            },
            {
                "author": "Justus Ranvier",
                "date": "2015-11-02T22:12:29",
                "message_text_only": "On 02/11/15 14:33, Gavin Andresen via bitcoin-dev wrote:\n> I like those guidelines, although I'm sure there may be lots of arguing\n> over what fits under \"protects the integrity of the network\" or what\n> constitutes \"reasonable notice\" (publish a BIP at least 30 days before\n> rolling out a change? 60 days? a year?)\n\nIf Bitcoin were perfect. then it would be the case that any transaction\nthat was valid at the time it was signed would always remain valid until\nspent regardless of any protocol changes which occurred in the interim.\n\nCertainly, that property, if it was possible to achieve, would give\nBitcoin maximum possible utility compared to alternative properties.\n\nThere are cases in which that guarantee can be met, and there are some\npathological cases where it can not be met.\n\nIt's not possible to know if the pathological cases are actually a real\nproblem in practice, because the possible existence of unbroadcast\ntransactions which would trigger them is unknowable.\n\nA possible lazy/optimistic strategy is to implement as much\nnon-pathological backward compatibility as possible, and treat unhandled\ncases as outstanding bugs whose resolution is deferred unless and until\nthey are actually triggered.\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: 0xEAD9E623.asc\nType: application/pgp-keys\nSize: 18442 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151102/79c74617/attachment-0001.bin>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 801 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151102/79c74617/attachment-0001.sig>"
            },
            {
                "author": "jl2012 at xbt.hk",
                "date": "2015-11-03T05:32:18",
                "message_text_only": "The other strategy is to have an informational BIP to define \"safe\" use \nof Bitcoin.\n\n1. scriptPubKey must be one of the following types: P2PK, P2PKH, P2SH, \nn-of-m multisig with m < 4 (with or without CLTV or CSV, we should \ndefine standard use of CLTV and CSV)\n\n2. For P2SH, the serialized script must be one of the standard type\n\n3. No use of unknown transaction version\n\n4. Tx size < 100k\n\n5. If conditions 1-4 are all satisfied, the locktime must not be longer \nthan 4 years from the creation of the tx\n\n6. If at least one of the conditions 1-4 is not satisfied, the lock time \nmust not be longer than 6 months from the creation of the tx\n\n7. A chain of unconfirmed transactions is unsafe due the malleability\n\n8. Tx created by wallet software last updated 1 year ago is unsafe\n\n9. Permanently deleting a private key is unsafe (that might be safe if \nstricter practice is followed)\n\nWe must not introduce a new rule that may permanently invalidate a safe \ntx, unless in emergency. Even in emergency, we should try to preserve \nbackward compatibility as much as possible (see the example at the end \nof my message)\n\nBeing unsafe means there is a chance that the tx may become \nunconfirmable, outputs become unspendable, or funds may be stolen \nwithout a private key.\n\nA grace period of 5 years must be given for \"soft-fork\" type change of \nany of the rules. For example it is ok to introduce new standard script \nanytime but not to remove.\n\n----------------------\n\nBack to Gavin's original question. If you want to somehow keep backward \ncompatibility for expensive-to-validate transactions in the future, you \nmay have rules like there could only be at most one \nexpensive-to-validate transaction in every 10 blocks, until year 2025. I \nknow this is over-complicated but it's a possible way to address your \nconcern.\n\n\n\nGavin Andresen via bitcoin-dev \u65bc 2015-11-02 15:33 \u5beb\u5230:\n> On Sun, Nov 1, 2015 at 6:46 PM, Tier Nolan via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n>> For guidelines\n>> \n>> * Transaction version numbers will be increased, if possible\n>> \n>> * Transactions with unknown/large version numbers are unsafe to use\n>> with locktime\n>> \n>> * Reasonable notice is given that the change is being contemplated\n>> \n>> * Non-opt-in changes will only be to protect the integrity of the\n>> network\n>> \n>> Locked transaction that can be validated without excessive load on\n>> the network should be safe to use, even if non-standard.\n>> \n>> An OP_CAT script that requires TBs of RAM to validate crosses the\n>> threshold of reasonableness.\n> \n> I like those guidelines, although I'm sure there may be lots of\n> arguing over what fits under \"protects the integrity of the network\"\n> or what constitutes \"reasonable notice\" (publish a BIP at least 30\n> days before rolling out a change? 60 days? a year?)\n> \n> --\n> \n> --\n> Gavin Andresen\n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            }
        ],
        "thread_summary": {
            "title": "Compatibility requirements for hard or soft forks",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Tier Nolan",
                "Luke Dashjr",
                "Gavin Andresen",
                "jl2012 at xbt.hk",
                "Justus Ranvier"
            ],
            "messages_count": 11,
            "total_messages_chars_count": 20305
        }
    },
    {
        "title": "[bitcoin-dev] BIP 113: Median time-past is a HARDfork, not a softfork!",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2015-11-01T19:06:43",
                "message_text_only": "BIP 113 makes things valid which currently are not (any transaction with a \nlocktime between the median time past, and the block nTime). Therefore it is a \nhardfork. Yet the current BIP describes and deploys it as a softfork.\n\nFurthermore, Bitcoin Core one week ago merged #6566 adding BIP 113 logic to \nthe mempool and block creation. This will probably produce invalid blocks \n(which CNB's safety TestBlockValidity call should catch), and should be \nreverted until an appropriate solution is determined.\n\nRusty suggested something like adding N hours to the median time past for \ncomparison, and to be a proper hardfork, this must be max()'d with the block \nnTime. On the other hand, if we will have a hardfork in the next year or so, \nit may be best to just hold off and deploy as part of that.\n\nFurther thoughts/input?\n\nLuke"
            },
            {
                "author": "jl2012 at xbt.hk",
                "date": "2015-11-02T04:27:50",
                "message_text_only": "Currently, a tx maybe included in a block only if its locktime (x) is \nsmaller than the timestamp of a block (y)\n\nBIP113 says that a tx maybe included in a block only if x is smaller \nthan the median-time-past (z)\n\nIt is already a consensus rule that y > z. Therefore, if x < z, x < y\n\nThe new rule is absolutely stricter than the old rule, so it is a \nsoftfork. Anything wrong with my interpretation?\n\nLuke Dashjr via bitcoin-dev \u65bc 2015-11-01 14:06 \u5beb\u5230:\n> BIP 113 makes things valid which currently are not (any transaction \n> with a\n> locktime between the median time past, and the block nTime). Therefore \n> it is a\n> hardfork. Yet the current BIP describes and deploys it as a softfork.\n> \n> Furthermore, Bitcoin Core one week ago merged #6566 adding BIP 113 \n> logic to\n> the mempool and block creation. This will probably produce invalid \n> blocks\n> (which CNB's safety TestBlockValidity call should catch), and should be\n> reverted until an appropriate solution is determined.\n> \n> Rusty suggested something like adding N hours to the median time past \n> for\n> comparison, and to be a proper hardfork, this must be max()'d with the \n> block\n> nTime. On the other hand, if we will have a hardfork in the next year \n> or so,\n> it may be best to just hold off and deploy as part of that.\n> \n> Further thoughts/input?\n> \n> Luke\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Luke Dashjr",
                "date": "2015-11-02T05:06:36",
                "message_text_only": "On Monday, November 02, 2015 4:27:50 AM jl2012 at xbt.hk wrote:\n> Currently, a tx maybe included in a block only if its locktime (x) is\n> smaller than the timestamp of a block (y)\n> \n> BIP113 says that a tx maybe included in a block only if x is smaller\n> than the median-time-past (z)\n> \n> It is already a consensus rule that y > z. Therefore, if x < z, x < y\n> \n> The new rule is absolutely stricter than the old rule, so it is a\n> softfork. Anything wrong with my interpretation?\n\nI agree, false alarm. Somehow I had confused the comparison of locktimes this \nmorning. :(\n\nSorry about that,\n\nLuke"
            }
        ],
        "thread_summary": {
            "title": "BIP 113: Median time-past is a HARDfork, not a softfork!",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "jl2012 at xbt.hk",
                "Luke Dashjr"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 2941
        }
    },
    {
        "title": "[bitcoin-dev] #bitcoin-dev Weekly Development Meeting Minutes 2015-10-29",
        "thread_messages": [
            {
                "author": "Daniel Stadulis",
                "date": "2015-11-02T10:55:38",
                "message_text_only": "Google Docs formatted version:\nhttps://docs.google.com/document/d/1t3kGkAUQ-Yui57P29YhDll5WyJuTiGrUhCW8so-E-iQ/edit?usp=sharing\n\n\nMeeting Title:\n#bitcoin-dev Weekly Development Meeting\nMeeting Date:\n2015-10-29\nMeeting Time:\n19:00-20:00 UTC\n\nParticipants in Attendance:\ndstadulis\nmorcos\nsipa\njgarzik\nrusty\nwarren\njeremyrubin\nevoskuil\nLuke-Jr\ndcousens\ngmaxwell\njtimon\nmcelrath\nbtcdrak\n\nIRC Chat Logs:\nhttp://bitcoinstats.com/irc/bitcoin-dev/logs/2015/10/29#l1446145135.0\n\n--------------------------------------------------------------------------------\n\nTopics discussed:\n\n1. Upcoming softfork\n1.1 Solely CLTV (morcos, petertodd, dcousens)\n1.2 Softfork coordination with other clients\n2. Chain Limits Agreement Status\n2.1 What should be sufficient consensus for merges?\n3. Backporting Policy\n4. Leveldb Replacement\n4.1 Can be considered when code is abstracted, allows for testing,\nalternative implementations exist. Testing encouraged, no future moves\nplanned.\n5. Clang format\n5.1 History review:  Proposal a while ago was to clang-format file set <a b\nc ...>   Once done, maintain those files' formatting with automation (git\nhook checks or whatnot)\n5.2 Clang format behavior changes \"randomly\" from version to version.\n6. BIP-68: \u201cMempool-only sequence number constraint verification\u201d\nImplementation PR #6312\n6.1 Concern regarding skipping missing inputs\n7. BIP-112: Mempool-only CHECKSEQUENCEVERIFY PR #6564\n\n\n2015-10-29 Meeting Conclusions:\n\n#\nAction items\nResponsible Parties\nETA/Due Date\n1\nMorcos to report chain stats\n\n\n2\nReview BIP68 implementation #6312\nsipa, rusty\n\n--------------------------------------------------------------------------------\n\nMeetingbot Minutes\nMinutes(HTML)\nhttp://www.erisian.com.au/meetbot/bitcoin-dev/2015/bitcoin-dev.2015-10-29-19.02.html\nMinutes(text)\nhttp://www.erisian.com.au/meetbot/bitcoin-dev/2015/bitcoin-dev.2015-10-29-19.02.txt\nIRC Log:\nhttp://www.erisian.com.au/meetbot/bitcoin-dev/2015/bitcoin-dev.2015-10-29-19.02.log.html\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151102/c44e94e9/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "#bitcoin-dev Weekly Development Meeting Minutes 2015-10-29",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Daniel Stadulis"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2153
        }
    },
    {
        "title": "[bitcoin-dev] Ramping up with bitcoin core engineering?",
        "thread_messages": [
            {
                "author": "Panos Sakkos",
                "date": "2015-11-02T13:30:48",
                "message_text_only": "Hey,\n\nI'm interested in helping out with the development of Bitcoin Core.\nI'm used to getting involved with huge projects by starting to write unit\ntests (in order to get familiar with the project's tools, infrastructure\netc).\n\nIs there any ramp up process (like for example any documentation) that I\ncan start with?\n\nAlso, if you are a leading a test effort and you need a hand, please 'r' me\n:)\n\nThanks in advance!\n:panos\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151102/ae151b8d/attachment.html>"
            },
            {
                "author": "Eric Martindale",
                "date": "2015-11-02T21:05:39",
                "message_text_only": "The Bitcoin.org Development Guide has grown by leaps in bounds this year,\nand has two great introductions:\n\n1. https://bitcoin.org/en/development for an overview of how a developer\ncan contribute,\n2. https://bitcoin.org/en/developer-reference for in-detail reference to\nhow the whole system works.\n\nOther great places to get involved or find more detail include the Bitcoin\nWiki <https://en.bitcoin.it/wiki/Main_Page> and the #bitcoin-dev room on\nFreenode <irc://irc.freenode.net/bitcoin-dev>.\n\nHope that helps!\n\nOn Mon, Nov 2, 2015 at 6:03 AM Panos Sakkos via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hey,\n>\n> I'm interested in helping out with the development of Bitcoin Core.\n> I'm used to getting involved with huge projects by starting to write unit\n> tests (in order to get familiar with the project's tools, infrastructure\n> etc).\n>\n> Is there any ramp up process (like for example any documentation) that I\n> can start with?\n>\n> Also, if you are a leading a test effort and you need a hand, please 'r'\n> me :)\n>\n> Thanks in advance!\n> :panos\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151102/b79cc42e/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Ramping up with bitcoin core engineering?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Eric Martindale",
                "Panos Sakkos"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 2050
        }
    },
    {
        "title": "[bitcoin-dev] [BIP] Normalized transaction IDs",
        "thread_messages": [
            {
                "author": "Christian Decker",
                "date": "2015-11-03T20:37:44",
                "message_text_only": "Ok, getting the ball rolling again after some downtime. I amended the\nproposal to use a simple version number instead of the binary flags, added\nthe normalization of inputs before computing the signaturehash and added\nSchnorr signatures as requested.\n\nThe BIP has also been assigned number 130 :-)\n\nI am still very much intrigued by Luke's idea of having empty scriptsigs\nand ship the signatures in external scripts, however the proposal uses the\non-the-fly normalization because we have no good way of relaying the\nexternal scripts. Since we are still in the drafting phase I am open to\nsuggestions and if there is a good/working solution I can amend/withdraw\nthe proposal.\n\nAs for open venues for malleability, I'm not sure we can fix them at all,\nafter all the ability of a single signer to doublespend by\nappending/replacing inputs/outputs in an arbitrary fashion is not fixable\nIMHO and will cause any future transaction building on its outputs to be\norphaned. What would the perfect properties for such a fix be?\n\nRegards,\nChristian\n\nOn Thu, Oct 22, 2015 at 11:05 AM Luke Dashjr <luke at dashjr.org> wrote:\n\n> On Thursday, October 22, 2015 8:26:58 AM Christian Decker wrote:\n> > I think the scenario of the single signer re-ordering the outputs and\n> > inputs and then re-signing the transaction is in the same category of\n> > simple double-spends. The signer could just as well sign a completely\n> > different transaction spending the same coins to somewhere else, so I\n> don't\n> > think there is a lot we can do about it even if we instate a canonical\n> > ordering. Even if we order the inputs and outputs the signer can just\n> add a\n> > new input and output and we would have a different transaction.\n> >\n> > Normalized transaction IDs do help in the case that the single signer\n> wants\n> > to immediately follow up its transaction with another transaction\n> spending\n> > the first one's change output, and it prevents any modification in the\n> > multi-signer scenario.\n>\n> Except that unlike malicious double spending, adding more outputs to\n> unconfirmed transactions is what wallets *should ideally be doing every\n> time\n> they send another transaction*. Spending unconfirmed change is the wrong\n> approach. So half-fixing malleability as this PR would, encourages\n> inefficient behaviour in multiple ways (first, by not making it\n> malleability-\n> safe; second, by encouraging spending unconfirmed change).\n>\n> Luke\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151103/be9e24b3/attachment.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2015-11-03T20:48:17",
                "message_text_only": "On Tuesday, November 03, 2015 8:37:44 PM Christian Decker wrote:\n> I am still very much intrigued by Luke's idea of having empty scriptsigs\n> and ship the signatures in external scripts, however the proposal uses the\n> on-the-fly normalization because we have no good way of relaying the\n> external scripts. Since we are still in the drafting phase I am open to\n> suggestions and if there is a good/working solution I can amend/withdraw\n> the proposal.\n\nChanging the network protocol is trivial in comparison to making a permanent \nincrease in UTXO set costs.\n\n> As for open venues for malleability, I'm not sure we can fix them at all,\n> after all the ability of a single signer to doublespend by\n> appending/replacing inputs/outputs in an arbitrary fashion is not fixable\n> IMHO and will cause any future transaction building on its outputs to be\n> orphaned. What would the perfect properties for such a fix be?\n\nThe problem isn't changing inputs/outputs, but that such changes invalidate \nlater spends. In particular, note that wallets *should ideally* be actively \ntrying to make transfers using multiple malleated versions of the same \npayment.\n\nSo the way to make an anti-malleable wallet, would be to strictly enforce the \nno-address-reuse rule on payments received (note this has no effect on \nother/current wallets) and rely only on the hash of that scriptPubKey+value \nfor the input in subsequent transactions. This way, no matter what inputs or \nother outputs the transaction paying the address/invoice uses, the subsequent \ntransaction ignores them and remains valid. (I am not suggesting this as a \nmandatory change that all wallets must adopt to receive the current semi-\nmalleability protection you propose - only that it be *possible* for wallets \nto upgrade to or offer in the future.)\n\nLuke"
            },
            {
                "author": "Christian Decker",
                "date": "2015-11-03T21:44:02",
                "message_text_only": "On Tue, Nov 3, 2015 at 9:49 PM Luke Dashjr <luke at dashjr.org> wrote:\n\n> On Tuesday, November 03, 2015 8:37:44 PM Christian Decker wrote:\n> > I am still very much intrigued by Luke's idea of having empty scriptsigs\n> > and ship the signatures in external scripts, however the proposal uses\n> the\n> > on-the-fly normalization because we have no good way of relaying the\n> > external scripts. Since we are still in the drafting phase I am open to\n> > suggestions and if there is a good/working solution I can amend/withdraw\n> > the proposal.\n>\n> Changing the network protocol is trivial in comparison to making a\n> permanent\n> increase in UTXO set costs.\n>\n\nOk, so assuming we can get a connected component of upgraded nodes that\nrelay both the transaction and the associated external scripts then we\ncould just piggyback the external scripts on top of the normal messages.\nNon-upgraded nodes will read the entire two-part message but only parse the\nclassical transaction, dropping the external script. Validation rules for\nupgraded nodes are the same as before: if the attached signatures are\ninvalid the entire TX is dropped. We have to commit to the external scripts\nused during the creation of a block. I think the easiest way to add this\ncommitment is the coinbase input I guess, and following the transaction\nlist a new list of signature lists is shipped with the rest of the block.\nNon-upgraded will ignore it as before.\n\nWould that work? It all hinges on having upgraded miners in a connected\ncomponent otherwise non-upgraded nodes will drop the external scripts on\nthe way (since they parse and then reconstruct the messages along the\npath). But if it works this could be a much nicer solution.\n\n\n>\n> > As for open venues for malleability, I'm not sure we can fix them at all,\n> > after all the ability of a single signer to doublespend by\n> > appending/replacing inputs/outputs in an arbitrary fashion is not fixable\n> > IMHO and will cause any future transaction building on its outputs to be\n> > orphaned. What would the perfect properties for such a fix be?\n>\n> The problem isn't changing inputs/outputs, but that such changes invalidate\n> later spends. In particular, note that wallets *should ideally* be actively\n> trying to make transfers using multiple malleated versions of the same\n> payment.\n>\n\nSo this is indeed a form of desired malleability we will likely not be able\nto fix. I'd argue that this goes more into the direction of double-spending\nthan a form of malleability, and is mostly out of scope for this BIP. As\nthe abstract mentions this BIP attempts to eliminate damage incurred by\nmalleability in the third party modification scenario and in the multisig\nscenario, with the added benefit of enabling transaction templating. If we\ncan get the segregated witnesses approach working all the better, we don't\neven have the penalty of increased UTXO size. The problem of singlesig\nusers doublespending their outputs to update transactions remains a problem\neven then.\n\n\n>\n> So the way to make an anti-malleable wallet, would be to strictly enforce\n> the\n> no-address-reuse rule on payments received (note this has no effect on\n> other/current wallets) and rely only on the hash of that scriptPubKey+value\n> for the input in subsequent transactions. This way, no matter what inputs\n> or\n> other outputs the transaction paying the address/invoice uses, the\n> subsequent\n> transaction ignores them and remains valid. (I am not suggesting this as a\n> mandatory change that all wallets must adopt to receive the current semi-\n> malleability protection you propose - only that it be *possible* for\n> wallets\n> to upgrade to or offer in the future.)\n>\n\nSounds very interesting. That would then be a new signature checking opcode\nI guess that would allow the transaction hash in the input be replaced by\nthe hash of the serialized output it is spending? That way the transaction\nwould not be detached from the coins unless the amount or the scriptpubkey\n(containing the address) is modified. So a user may add new outputs and\ninputs to an existing transaction like you mentioned. This does not help\nsomeone receiving funds from a sender to build new transactions on top\nsince the sender may simply doublespend its output before it is confirmed.\nI think this is probably best addressed in a separate proposal.\n\n\n>\n> Luke\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151103/63439a8f/attachment.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2015-11-03T22:01:20",
                "message_text_only": "On Tuesday, November 03, 2015 9:44:02 PM Christian Decker wrote:\n> Ok, so assuming we can get a connected component of upgraded nodes that\n> relay both the transaction and the associated external scripts then we\n> could just piggyback the external scripts on top of the normal messages.\n> Non-upgraded nodes will read the entire two-part message but only parse the\n> classical transaction, dropping the external script. Validation rules for\n> upgraded nodes are the same as before: if the attached signatures are\n> invalid the entire TX is dropped. We have to commit to the external scripts\n> used during the creation of a block. I think the easiest way to add this\n> commitment is the coinbase input I guess, and following the transaction\n> list a new list of signature lists is shipped with the rest of the block.\n> Non-upgraded will ignore it as before.\n\nI'd throw it in the merged-mining tree; it's not ideal, but it can be swapped \nout for something better when it's ready (I'm working on such a BIP - \nhopefully it can be before or at the same time as a SW deployment).\n\n> Would that work? It all hinges on having upgraded miners in a connected\n> component otherwise non-upgraded nodes will drop the external scripts on\n> the way (since they parse and then reconstruct the messages along the\n> path). But if it works this could be a much nicer solution.\n\nIt's actually better than that. If miners don't get the SW transactions, then \nthey just won't mine them, and the wallets will continue to rebroadcast until \nthey do. But realistically, the entire network will likely be running SW-\ncapable nodes long before any wallets have deployed SW transactions.\n\n> > > As for open venues for malleability, I'm not sure we can fix them at\n> > > all, after all the ability of a single signer to doublespend by\n> > > appending/replacing inputs/outputs in an arbitrary fashion is not\n> > > fixable IMHO and will cause any future transaction building on its\n> > > outputs to be orphaned. What would the perfect properties for such a\n> > > fix be?\n> > \n> > The problem isn't changing inputs/outputs, but that such changes\n> > invalidate later spends. In particular, note that wallets *should\n> > ideally* be actively trying to make transfers using multiple malleated\n> > versions of the same payment.\n> \n> So this is indeed a form of desired malleability we will likely not be able\n> to fix. I'd argue that this goes more into the direction of double-spending\n> than a form of malleability, and is mostly out of scope for this BIP. As\n> the abstract mentions this BIP attempts to eliminate damage incurred by\n> malleability in the third party modification scenario and in the multisig\n> scenario, with the added benefit of enabling transaction templating. If we\n> can get the segregated witnesses approach working all the better, we don't\n> even have the penalty of increased UTXO size. The problem of singlesig\n> users doublespending their outputs to update transactions remains a problem\n> even then.\n\nI don't know what you're trying to say here. Double spending to the same \ndestination(s) and malleability are literally the same thing. Things affected \nby malleability are still just as broken even with this BIP - whether it is \ntriggered by a third-party or not is not very relevant.\n\n> > So the way to make an anti-malleable wallet, would be to strictly enforce\n> > the\n> > no-address-reuse rule on payments received (note this has no effect on\n> > other/current wallets) and rely only on the hash of that\n> > scriptPubKey+value for the input in subsequent transactions. This way,\n> > no matter what inputs or\n> > other outputs the transaction paying the address/invoice uses, the\n> > subsequent\n> > transaction ignores them and remains valid. (I am not suggesting this as\n> > a mandatory change that all wallets must adopt to receive the current\n> > semi- malleability protection you propose - only that it be *possible*\n> > for wallets\n> > to upgrade to or offer in the future.)\n> \n> Sounds very interesting. That would then be a new signature checking opcode\n> I guess that would allow the transaction hash in the input be replaced by\n> the hash of the serialized output it is spending? That way the transaction\n> would not be detached from the coins unless the amount or the scriptpubkey\n> (containing the address) is modified. So a user may add new outputs and\n> inputs to an existing transaction like you mentioned. \n\nCorrect...\n\n> This does not help someone receiving funds from a sender to build new\n> transactions on top since the sender may simply doublespend its output\n> before it is confirmed. I think this is probably best addressed in a\n> separate proposal.\n\nHuh??\n\nLuke"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-05T15:27:37",
                "message_text_only": "On Tue, Nov 3, 2015 at 11:01 PM, Luke Dashjr via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> On Tuesday, November 03, 2015 9:44:02 PM Christian Decker wrote:\n>> So this is indeed a form of desired malleability we will likely not be able\n>> to fix. I'd argue that this goes more into the direction of double-spending\n>> than a form of malleability, and is mostly out of scope for this BIP. As\n>> the abstract mentions this BIP attempts to eliminate damage incurred by\n>> malleability in the third party modification scenario and in the multisig\n>> scenario, with the added benefit of enabling transaction templating. If we\n>> can get the segregated witnesses approach working all the better, we don't\n>> even have the penalty of increased UTXO size. The problem of singlesig\n>> users doublespending their outputs to update transactions remains a problem\n>> even then.\n>\n> I don't know what you're trying to say here. Double spending to the same\n> destination(s) and malleability are literally the same thing. Things affected\n> by malleability are still just as broken even with this BIP - whether it is\n> triggered by a third-party or not is not very relevant.\n\nI think this is just a terminology confusion.\nThere's conflicting spends of the same outputs (aka unconfirmed\ndouble-spends), and there's signature malleability which Segregated\nWitnesses solves.\nIf we want to define malleability as signature malleability +\nconflicting spends, then that's fine.\nBut it seems Christian is mostly interested in signature malleability,\nwhich is what SW can solve.\nIn fact, creating conflicting spends is sometimes useful for some\ncontracts (ie to cancel the contract when that's supposed to be\nallowed).\nMaybe it is \"incorrect\" that people use \"malleability\" when they're\nspecifically talking about \"signature malleability\", but I think that\nin this case it's clear that we're talking about transactions having\nan id that cannot be changed just by signing with a different nonce\n(what SW provides).\n\nPlease, Christian, correct me if you mean something else."
            },
            {
                "author": "Luke Dashjr",
                "date": "2015-11-05T19:36:08",
                "message_text_only": "On Thursday, November 05, 2015 3:27:37 PM Jorge Tim\u00f3n wrote:\n> On Tue, Nov 3, 2015 at 11:01 PM, Luke Dashjr via bitcoin-dev\n> \n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > On Tuesday, November 03, 2015 9:44:02 PM Christian Decker wrote:\n> >> So this is indeed a form of desired malleability we will likely not be\n> >> able to fix. I'd argue that this goes more into the direction of\n> >> double-spending than a form of malleability, and is mostly out of scope\n> >> for this BIP. As the abstract mentions this BIP attempts to eliminate\n> >> damage incurred by malleability in the third party modification\n> >> scenario and in the multisig scenario, with the added benefit of\n> >> enabling transaction templating. If we can get the segregated witnesses\n> >> approach working all the better, we don't even have the penalty of\n> >> increased UTXO size. The problem of singlesig users doublespending\n> >> their outputs to update transactions remains a problem even then.\n> > \n> > I don't know what you're trying to say here. Double spending to the same\n> > destination(s) and malleability are literally the same thing. Things\n> > affected by malleability are still just as broken even with this BIP -\n> > whether it is triggered by a third-party or not is not very relevant.\n> \n> I think this is just a terminology confusion.\n> There's conflicting spends of the same outputs (aka unconfirmed\n> double-spends), and there's signature malleability which Segregated\n> Witnesses solves.\n> If we want to define malleability as signature malleability +\n> conflicting spends, then that's fine.\n> But it seems Christian is mostly interested in signature malleability,\n> which is what SW can solve.\n> In fact, creating conflicting spends is sometimes useful for some\n> contracts (ie to cancel the contract when that's supposed to be\n> allowed).\n> Maybe it is \"incorrect\" that people use \"malleability\" when they're\n> specifically talking about \"signature malleability\", but I think that\n> in this case it's clear that we're talking about transactions having\n> an id that cannot be changed just by signing with a different nonce\n> (what SW provides).\n\nOk, then my point is that \"signature malleability\" is not particularly \nproblematic or interesting alone, and the only way to get a practically-useful \nsolution, is to address all kinds of malleability.\n\nLuke"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-05T20:25:33",
                "message_text_only": "On Thu, Nov 5, 2015 at 8:36 PM, Luke Dashjr <luke at dashjr.org> wrote:\n> Ok, then my point is that \"signature malleability\" is not particularly\n> problematic or interesting alone, and the only way to get a practically-useful\n> solution, is to address all kinds of malleability.\n\nI disagree. Segregated witnesses, for example, doesn't solve all kinds\nof malleability and is very useful in some practical cases by solving\nall signature malleability.\nAs said, we don't want to eliminate all forms of malleability (for\nexample, replace by fee), although we may want to \"address them\" at\nsome level.\nAs you have said, wallets should be looking at scriptPubKeys, not\ntransaction ID, but that is orthogonal to SW, a normalized tx ID and\nsignature malleability."
            },
            {
                "author": "s7r",
                "date": "2015-11-05T22:46:19",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\nRight. Wallets are covering malleability in acceptable ways. Normal\nuser to user payments aren't (or at least shouldn't be) affected by\nmalleability.\n\nProblems appear in second level and third level malleability, when\nAlice sends txB to Bob which spends from txA which is unconfirmed. If\ntxA changes txid, txB becomes useless and invalidates Alice's payment.\nLooking at scriptPubKeys instead of transaction IDs doesn't help in\nthis context.\n\nThis is the reason why some type of contracts are not workable or not\n100% safe. One can't pre-sign a refund transaction with an nLockTime\nin the future: the payer will provide the funding transaction ID from\nwhich the refund tx will spend, but if the transaction ID of the\nfunding transaction is affected by malleability (third party\nmalleability, since the signer doesn't have interest to do so) the\nrefund tx becomes useless.\n\nOn 11/5/2015 10:25 PM, Jorge Tim\u00f3n via bitcoin-dev wrote:\n> On Thu, Nov 5, 2015 at 8:36 PM, Luke Dashjr <luke at dashjr.org>\n> wrote:\n>> Ok, then my point is that \"signature malleability\" is not\n>> particularly problematic or interesting alone, and the only way\n>> to get a practically-useful solution, is to address all kinds of\n>> malleability.\n> \n> I disagree. Segregated witnesses, for example, doesn't solve all\n> kinds of malleability and is very useful in some practical cases by\n> solving all signature malleability. As said, we don't want to\n> eliminate all forms of malleability (for example, replace by fee),\n> although we may want to \"address them\" at some level. As you have\n> said, wallets should be looking at scriptPubKeys, not transaction\n> ID, but that is orthogonal to SW, a normalized tx ID and signature\n> malleability.\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v2.0.22 (MingW32)\n\niQEcBAEBCAAGBQJWO9w7AAoJEIN/pSyBJlsR2BsH+gMwxJ/isiWfJF12LJ9s4wat\nBd/K2Ld+Lyk5BRs+6rQzv5NeeYjYC3FtNFV+z1Z1dMDd752cUfEZqQA9dt9nl0E7\nBEia3RSFii1k2L/4xwiIWKZM20qoiykou41J56GZrJa9SoP+9kg8iLq8CokahakP\nPLjfBrTylJBsgq34foPPaOH9ckOa/RJpx3WHrRFTPhxbTCm1Ezv6jAZmYr9tTi1h\nafzU0YayzLUIb9xH8vfODY2qMJ91uguTUZYCGuopDYhom5GMw8zss0kG5FdEZrEQ\nZ7srQmKQ0SRMtiSlg6lg3d8TS5Mv1gIp1HcL+gtMFroi38pJS8dXT65nGjg0Epc=\n=ZhVA\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "Adam Back",
                "date": "2015-11-05T22:29:46",
                "message_text_only": "About the conflicting spends by the private key holder (self signature\nmalleability) that is in principle kind of fixable.\n\nYou make a new pub key type which is r,Q (where r is the DSA signature\ncomponent but chosen at key gen time, Q=xG is the pub key, r is point\ncompressed R = (r,f(r)) = kG ), r is the pre-computable part of an\nECDSA signature (unrelated to the message which can be decided later).\n\nYou make a new address type which is a = H(r,Q).\n\nThen you make a new signature type which requires that the r from\nsig=(r,s) matches the r committed to in the address.\n\nAs the ECDSA signature is s=(H(m)+r*x)/k mod n, if they sign two\ndifferent messages with the same r value they reveal the private key\nvia simultaneous equation, as s=(H(m)+r*x)/k and s'=(H(m')+r*x)/k and\nsolving k=(H(m)-H(m'))/(s-s') and x=(sk-H(m))/r allowing anyone who\nsees both double spends to spend as they can replace the signature\nwith their own one.  That converts double signatures into miner can\nspend.\n\nIt doesnt necessarily enforce no pubkey reuse (Q), as a=H(r,Q) and\na'=H(r',Q) are different addresses, though it does enforce no\nextended-address reuse (H=(r,Q)).\nBinary failure address reuse could be an issue.  Puts pressure on\ntransactional storage on wallets.\n\nAdam\n\nOn 5 November 2015 at 20:36, Luke Dashjr via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> On Thursday, November 05, 2015 3:27:37 PM Jorge Tim\u00f3n wrote:\n>> On Tue, Nov 3, 2015 at 11:01 PM, Luke Dashjr via bitcoin-dev\n>>\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> > On Tuesday, November 03, 2015 9:44:02 PM Christian Decker wrote:\n>> >> So this is indeed a form of desired malleability we will likely not be\n>> >> able to fix. I'd argue that this goes more into the direction of\n>> >> double-spending than a form of malleability, and is mostly out of scope\n>> >> for this BIP. As the abstract mentions this BIP attempts to eliminate\n>> >> damage incurred by malleability in the third party modification\n>> >> scenario and in the multisig scenario, with the added benefit of\n>> >> enabling transaction templating. If we can get the segregated witnesses\n>> >> approach working all the better, we don't even have the penalty of\n>> >> increased UTXO size. The problem of singlesig users doublespending\n>> >> their outputs to update transactions remains a problem even then.\n>> >\n>> > I don't know what you're trying to say here. Double spending to the same\n>> > destination(s) and malleability are literally the same thing. Things\n>> > affected by malleability are still just as broken even with this BIP -\n>> > whether it is triggered by a third-party or not is not very relevant.\n>>\n>> I think this is just a terminology confusion.\n>> There's conflicting spends of the same outputs (aka unconfirmed\n>> double-spends), and there's signature malleability which Segregated\n>> Witnesses solves.\n>> If we want to define malleability as signature malleability +\n>> conflicting spends, then that's fine.\n>> But it seems Christian is mostly interested in signature malleability,\n>> which is what SW can solve.\n>> In fact, creating conflicting spends is sometimes useful for some\n>> contracts (ie to cancel the contract when that's supposed to be\n>> allowed).\n>> Maybe it is \"incorrect\" that people use \"malleability\" when they're\n>> specifically talking about \"signature malleability\", but I think that\n>> in this case it's clear that we're talking about transactions having\n>> an id that cannot be changed just by signing with a different nonce\n>> (what SW provides).\n>\n> Ok, then my point is that \"signature malleability\" is not particularly\n> problematic or interesting alone, and the only way to get a practically-useful\n> solution, is to address all kinds of malleability.\n>\n> Luke\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Christian Decker",
                "date": "2015-11-06T14:52:49",
                "message_text_only": "On Thu, Nov 5, 2015 at 4:27 PM Jorge Tim\u00f3n <jtimon at jtimon.cc> wrote:\n\n> I think this is just a terminology confusion.\n> There's conflicting spends of the same outputs (aka unconfirmed\n> double-spends), and there's signature malleability which Segregated\n> Witnesses solves.\n> If we want to define malleability as signature malleability +\n> conflicting spends, then that's fine.\n> But it seems Christian is mostly interested in signature malleability,\n> which is what SW can solve.\n> In fact, creating conflicting spends is sometimes useful for some\n> contracts (ie to cancel the contract when that's supposed to be\n> allowed).\n> Maybe it is \"incorrect\" that people use \"malleability\" when they're\n> specifically talking about \"signature malleability\", but I think that\n> in this case it's clear that we're talking about transactions having\n> an id that cannot be changed just by signing with a different nonce\n> (what SW provides).\n>\n> Please, Christian, correct me if you mean something else.\n>\n\nYes, your differentiation is spot on. My main goal is to eliminate the risk\nof detaching transactions in  off-blockchain protocols that rely on a\nnumber of transactions being chained, hence solving signature malleability\nmight be the correct term. Canonical encodings do address part of the\nproblem, however they do nothing in the case of one of the signers\nre-signing a transaction and detaching any followup transaction. Also\nhaving transaction templates is a nice way to reduce the complexity of\nprotocols by eliminating some of the \"who signs what when\" gotchas.\nSegregated witnesses would be a perfect solution, we just need to find a\ngood migration plan for Bitcoin :-)\n\nSorry for the confusion caused by me misusing the term malleability, I'll\nuse signature malleability in the future :-)\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151106/1a49d31c/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2015-11-04T04:00:33",
                "message_text_only": "On Tue, Nov 03, 2015 at 09:44:02PM +0000, Christian Decker via bitcoin-dev wrote:\n> Ok, so assuming we can get a connected component of upgraded nodes that\n> relay both the transaction and the associated external scripts then we\n> could just piggyback the external scripts on top of the normal messages.\n> Non-upgraded nodes will read the entire two-part message but only parse the\n> classical transaction, dropping the external script. Validation rules for\n> upgraded nodes are the same as before: if the attached signatures are\n> invalid the entire TX is dropped. We have to commit to the external scripts\n> used during the creation of a block. I think the easiest way to add this\n> commitment is the coinbase input I guess, and following the transaction\n> list a new list of signature lists is shipped with the rest of the block.\n> Non-upgraded will ignore it as before.\n> \n> Would that work? It all hinges on having upgraded miners in a connected\n> component otherwise non-upgraded nodes will drop the external scripts on\n> the way (since they parse and then reconstruct the messages along the\n> path). But if it works this could be a much nicer solution.\n\nFWIW my replace-by-fee fork does preferential peering with other RBF\nnodes to ensure that you'll always be connected to at least some\nfull-RBF peers. In practice this works very well, and I'm sure a similar\nscheme could be used in this situation as well.\n\nBasically, conceptually unless you're connected to peers that advertise\nthat they relay the new data, you treat the situation as though you're\nnot connected to any peers at all. No different than if for some reason\nnone of your peers were advertising NODE_NETWORK.\n\n-- \n'peter'[:-1]@petertodd.org\n00000000000000000247b0e7436a5169ac6f9087be0295d10b07bf0bcbd4c0cc\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151103/cea084c1/attachment.sig>"
            },
            {
                "author": "Christian Decker",
                "date": "2015-11-05T09:38:03",
                "message_text_only": "This does indeed sound reasonable. The chances of having a cut in the\nnetwork consisting of non-upgraded nodes partitioning the network and not\nforwarding the segregated witnesses should be minimal, given a long rollout\nphase before the activation.\n\nIf everybody agrees that this is a better way to approach the normalization\nissue we should probably start writing it up and see if we can get critical\nmass behind it :-)\n\nOn Wed, Nov 4, 2015 at 5:00 AM Peter Todd <pete at petertodd.org> wrote:\n\n> On Tue, Nov 03, 2015 at 09:44:02PM +0000, Christian Decker via bitcoin-dev\n> wrote:\n> > Ok, so assuming we can get a connected component of upgraded nodes that\n> > relay both the transaction and the associated external scripts then we\n> > could just piggyback the external scripts on top of the normal messages.\n> > Non-upgraded nodes will read the entire two-part message but only parse\n> the\n> > classical transaction, dropping the external script. Validation rules for\n> > upgraded nodes are the same as before: if the attached signatures are\n> > invalid the entire TX is dropped. We have to commit to the external\n> scripts\n> > used during the creation of a block. I think the easiest way to add this\n> > commitment is the coinbase input I guess, and following the transaction\n> > list a new list of signature lists is shipped with the rest of the block.\n> > Non-upgraded will ignore it as before.\n> >\n> > Would that work? It all hinges on having upgraded miners in a connected\n> > component otherwise non-upgraded nodes will drop the external scripts on\n> > the way (since they parse and then reconstruct the messages along the\n> > path). But if it works this could be a much nicer solution.\n>\n> FWIW my replace-by-fee fork does preferential peering with other RBF\n> nodes to ensure that you'll always be connected to at least some\n> full-RBF peers. In practice this works very well, and I'm sure a similar\n> scheme could be used in this situation as well.\n>\n> Basically, conceptually unless you're connected to peers that advertise\n> that they relay the new data, you treat the situation as though you're\n> not connected to any peers at all. No different than if for some reason\n> none of your peers were advertising NODE_NETWORK.\n>\n> --\n> 'peter'[:-1]@petertodd.org\n> 00000000000000000247b0e7436a5169ac6f9087be0295d10b07bf0bcbd4c0cc\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151105/5e7c974c/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Normalized transaction IDs",
            "categories": [
                "bitcoin-dev",
                "BIP"
            ],
            "authors": [
                "Adam Back",
                "s7r",
                "Peter Todd",
                "Jorge Tim\u00f3n",
                "Luke Dashjr",
                "Christian Decker"
            ],
            "messages_count": 12,
            "total_messages_chars_count": 31565
        }
    },
    {
        "title": "[bitcoin-dev] A validation-cost metric for aggregate limits and fee determination",
        "thread_messages": [
            {
                "author": "Mark Friedenbach",
                "date": "2015-11-04T22:47:35",
                "message_text_only": "At the first Scaling Bitcoin workshop in Montreal I presented on the topic\nof \"bad blocks\" that take an excessive amount of time to validate. You can\nread a transcript of this talk here:\n\nhttp://diyhpl.us/wiki/transcripts/scalingbitcoin/alternatives-to-block-size-as-aggregate-resource-limits/\n\nThe core message was that the assumption made by the design parameters of\nthe system, namely that validation costs scale linearly with transaction or\nblock size, is wrong. In particular, in certain kinds of transactions there\nare validation costs which scale quadraticly with size. For example, the\nconstruction of SIGHASH_ALL results in each input signing a different\nmessage digest, meaning that the entire transaction (minus the scriptSigs)\nis rehashed for each input. As another example, the number of signature\noperation performed during block validation is unlimited if the validations\nare contained within the scriptPubKey (this scales linearly but with a very\nlarge constant factor). The severity of these issues increase as the\naggregate limits in place on maximum transaction and block size increase.\n\nThere have been various solutions suggested, and I would like to start a\npublic discussion to see if consensus can be reached over a viable approach.\n\nGavin, for example, has written code that tracks the number of bytes hashed\nand enforces a separate limit for a block over this aggregate value. Other\ncosts could be constrained in a similar whack-a-mole way. I have two\nconcerns with this approach:\n\n1. There would still exist a gap between the average-case validation cost\nof a full block and the worst case validation cost of a block that was\nspecifically constructed to hit every limit.\n\n2. Transaction selection and by extension fee determination would become\nmuch more complicated multi-dimensional optimization problems. Since fee\nmanagement in particular is code replicated in a lot of infrastructure, I\nwould be very concerned over making optimal behavior greatly more difficult.\n\nMy own suggestion, which I submit for consideration, is to use a linear\nfunction of the various costs involved (signatures verified, bytes hashed,\ninputs consumed, script opcodes executed, etc.). The various algorithms\nused for transaction selection and fee determination can then be reused,\nusing the output of this new linear function as the \"size\" of the\ntransaction.\n\nSeparately, many others including Greg Maxwell have advocated for a\n\"net-UTXO\" metric instead of, or in combination with a validation-cost\nmetric. In the pure form the block size limit would be replaced with a\nmaximum UTXO set increase, thereby applying a cost in extra fee required to\ncreate unspent outputs. This has the distinct advantage of making dust\noutputs considerably more expensive than regular spend outputs.\n\nFor myself, I remain open to the possibility of adding a UTXO set size\ncorrective factor to a chiefly validation-cost metric. It would be nice to\nreward users for cleaning up scattered small output, reward miners for\nincluding dust-be-gone outputs, and make spam attacks more costly. But\ndoing so requires setting aside some unused validation resources in order\nto reward miners who clean up the UTXO, which means it widens the gap\nbetween average and worst case block validation times. Also, worry over the\nsize of the UTXO database is only a concern for how Bitcoin Core is\ncurrently structured -- with e.g. UTXO or STXO commitments it could be the\ncase that in the future full nodes do not store the UTXO and instead carry\nproofs of their inputs as prunable witness data. If we choose a net-UTXO\nmetric however, we will be stuck with it for some time.\n\nI will be submitting a talk proposal for Scaling Bitcoin on this topic, but\nI would like to get some feedback from the developer community first.\nAnyone have any thoughts to add?\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151104/036ee438/attachment.html>"
            },
            {
                "author": "Gavin Andresen",
                "date": "2015-11-05T09:23:44",
                "message_text_only": "I have several thoughts:\n\nWeighing CPU validation cost should be reasonably straightforward-- just\npick some arbitrary, commonly-available, recent hardware and then benchmark\nthe two things that take the bulk of validation time (hashing to create the\nsignature hash, then ECDSA validation), and weigh the terms in the\nvalidation cost equation appropriately (e.g. hashing X GB of data takes the\nsame amount of CPU time as one libsecp256k1 validation, so count cpu cost\nof an OP_CHECKSIG as 1 + X/actual_bytes_hashed).\n\nBut how should bandwidth cost be counted? There isn't an obvious \"Y GB of\nbandwidth-per-month equals 1 ECDSA validation. We need to find common units\nfor the terms in the validation cost equation for it to make sense,\notherwise we're adding apples and oranges.\n\nI think the only units that will work is \"percentage of maximum validation\nability for some reference hardware running with a network connection\ncapable of some reference bandwidth.\"\n\nFor example, imagine the reference was the typical home computer being sold\ntoday running with some multiple or fraction of the average global\nbroadband connection speed of 5Mbps. CPU cost to validate a block can then\nbe expressed as a percentage of maximum capacity, as can bandwidth--\nhooray, two metrics with the same units, so they can be added up.  If the\nresult is less than 100%, then the block is valid-- it can be received and\nvalidated in a reasonable amount of time.\n\n\nRolling in UTXO growth is harder, for two reasons:\n1) UTXO changes per block can be negative or positive, as opposed to\nbandwidth/CPU costs.\n2) It is not clear how to choose or benchmark \"reference UTXO growth\"\n\n(1) could be finessed to just treat UTXO shrinkage as zero.\n(2) could just be decided by picking a reasonable growth number. Since we\nwant the UTXO set to fit into main memory, something a bit below the\nlong-ish term price/performance trend of main memory would be a good target.\n\nSo, starting with that growth rate and an initial UTXO size in bytes,\ndivide by the number of blocks in a year to get a maximum UTXO growth in\nbytes per block.\n\nWhen validating a block, take the actual UTXO growth, express it as a\npercentage of the maximum allowed (make it zero if it is negative), and\ncombine with the CPU and bandwidth percentages.\n\nIf the total is less than 100%, block is valid. Otherwise, invalid.\n\n----------------\n\nNow.... all of that worked through, I'm not 100% sure it solves the \"do\nminers or wallet have to solve a bin-packing problem to determine which\ntransactions to put into their blocks or what fees to attach.\"\n\nI think it mostly works out-- instead of fee-per-kilobyte, it would be\nfee-per-validation-cost (which is in the weird units \"fraction of 100%\nvalidation cost\").\n\nBut the UTXO term might be a problem-- transactions that create more UTXOs\nthan they spend might end up being costly. I'm traveling right now, perhaps\nsomebody could pick some arbitrary reference points and try to get a rough\nidea of what different transactions might pay in fees (e.g. if a\none-input-two-output had a cost of X, two-output-one-input would have a\ncost of X/something).\n\nI'm not convinced that a single validation cost metric is the best\napproach-- it might be better to break the cost into three (UTXO growth,\nCPU, and bandwidth) and just let miners set reasonable transaction\nselection policies that keep each of the three under whatever caps are\nimposed on each. If a miner comes up with a clever algorithm that lets them\npack in more transactions and get more fees, good for them!\n\nBut I do like the simplicity of a single validation cost metric.\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151105/541ff3fc/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "A validation-cost metric for aggregate limits and fee determination",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Gavin Andresen",
                "Mark Friedenbach"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 7825
        }
    },
    {
        "title": "[bitcoin-dev] Call for Proposals for Scaling Bitcoin Hong Kong",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2015-11-05T15:32:39",
                "message_text_only": "The second Scaling Bitcoin Workshop will take place December 6th-7th at the\nCyberport in Hong Kong. We are accepting technical proposals for improving\nBitcoin performance including designs, experimental results, and\ncomparisons against other proposals. The goals are twofold: 1) to present\npotential solutions to scalability challenges while identifying key areas\nfor further research and 2) provide a venue where researchers, developers,\nand miners can communicate about Bitcoin development.\n\nWe are accepting two types of proposals: one in which accepted authors will\nhave an opportunity to give a 20-30 minute presentation at the workshop,\nand another where accepted authors can run an hour-long interactive\nworkshop.\n\nTopics of interest include:\n\nImproving Bitcoin throughput\nLayer 2 ideas (i.e. payment channels, etc.)\nSecurity and privacy\nIncentives and fee structures\nTesting, simulation, and modeling\nNetwork resilience\nAnti-spam measures\nBlock size proposals\nMining concerns\nCommunity coordination\n\n\nAll as related to the scalability of Bitcoin.\n\nImportant Dates\n\nNovember 9th - Last day for submission\nNovember 16th - Last day for notification of acceptance and feedback\n\nFormatting\n\nWe are doing rolling acceptance, so submit your proposal as soon as you\ncan. Proposals may be submitted as a BIP or as a 1-2 page extended abstract\ndescribing ideas, designs, and expected experimental results. Indicate in\nthe proposal whether you are interested in speaking, running an interactive\nworkshop, or both. If you are interested in running an interactive\nworkshop, please include an agenda.\n\nProposals should be submitted to proposals at scalingbitcoin.org by November\n9th.\n\nAll talks will be livestreamed and published online, including slide decks.\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151105/c69c40bd/attachment.html>"
            },
            {
                "author": "Pindar Wong",
                "date": "2015-11-10T00:52:44",
                "message_text_only": "Dear All,\n\nJust a note that we've extended the last day for submissions by two days.\n\ni.e. Proposals should be submitted to proposals at scalingbitcoin.org by November\n11th 23:59 UTC\n\nCheers,\n\np.\n\n\nOn Thu, Nov 5, 2015 at 11:32 PM, Jeremy via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> The second Scaling Bitcoin Workshop will take place December 6th-7th at\n> the Cyberport in Hong Kong. We are accepting technical proposals for\n> improving Bitcoin performance including designs, experimental results, and\n> comparisons against other proposals. The goals are twofold: 1) to present\n> potential solutions to scalability challenges while identifying key areas\n> for further research and 2) provide a venue where researchers, developers,\n> and miners can communicate about Bitcoin development.\n>\n> We are accepting two types of proposals: one in which accepted authors\n> will have an opportunity to give a 20-30 minute presentation at the\n> workshop, and another where accepted authors can run an hour-long\n> interactive workshop.\n>\n> Topics of interest include:\n>\n> Improving Bitcoin throughput\n> Layer 2 ideas (i.e. payment channels, etc.)\n> Security and privacy\n> Incentives and fee structures\n> Testing, simulation, and modeling\n> Network resilience\n> Anti-spam measures\n> Block size proposals\n> Mining concerns\n> Community coordination\n>\n>\n> All as related to the scalability of Bitcoin.\n>\n> Important Dates\n>\n> November 9th - Last day for submission\n> November 16th - Last day for notification of acceptance and feedback\n>\n> Formatting\n>\n> We are doing rolling acceptance, so submit your proposal as soon as you\n> can. Proposals may be submitted as a BIP or as a 1-2 page extended abstract\n> describing ideas, designs, and expected experimental results. Indicate in\n> the proposal whether you are interested in speaking, running an interactive\n> workshop, or both. If you are interested in running an interactive\n> workshop, please include an agenda.\n>\n> Proposals should be submitted to proposals at scalingbitcoin.org by November\n> 9th.\n>\n> All talks will be livestreamed and published online, including slide decks.\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151110/cc258a3d/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Call for Proposals for Scaling Bitcoin Hong Kong",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy",
                "Pindar Wong"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 4631
        }
    },
    {
        "title": "[bitcoin-dev] summarising security assumptions (re cost metrics)",
        "thread_messages": [
            {
                "author": "Adam Back",
                "date": "2015-11-05T23:03:32",
                "message_text_only": "Some thoughts, hope this is not off-topic.\n\nMaybe we should summarise the security assumptions and design\nrequirements.  It is often easier to have clear design discussions by\nfirst articulating assumptions and requirements.\n\nValidators: Economically dependent full nodes are an important part of\nBitcoin's security model because they assure Bitcoin security by\nenforcing consensus rules.  While full nodes do not have orphan\nrisk, we also dont want maliciously crafted blocks with pathological\nvalidation cost to erode security by knocking reasonable spec full\nnodes off the network on CPU (or bandwidth grounds).\n\nMiners: Miners are in a commodity economics competitive environment\nwhere various types of attacks and collusion, even with small\nadvantage, may see actual use due to the advantage being significant\nrelative to the at times low profit margin\n\nIt is quite important for bitcoin decentralisation security that small\nminers not be significantly disadvantaged vs large miners.  Similarly\nit is important that there not be significant collusion advantages\nthat create policy centralisation as a side-effect (for example what\nhappened with \"SPV mining\" or validationless mining during BIP66\ndeployment).  Examples of attacks include selfish-mining and\namplifying that kind of attack via artificially large or\npathologically expensive to validate blocks.  Or elevating orphan risk\nfor others (a miner or collusion of miners is not at orphan risk for a\nblock they created).\n\nValidators vs Miner decentralisation balance:\n\nThere is a tradeoff where we can tolerate weak miner decentralisation\nif we can rely on good validator decentralisation or vice versa.  But\nboth being weak is risky.  Currently given mining centralisation\nitself is weak, that makes validator decentralisation a critical\nremaining defence - ie security depends more on validator\ndecentralisation than it would if mining decentralisation was in a\nbetter shape.\n\nSecurity:\n\nWe should consider the pathological case not average or default behaviour\nbecause we can not assume people will follow the defaults, only the\nconsensus-enforced rules.\n\nWe should not discount attacks that have not seen exploitation to\ndate.  We have maybe benefitted from universal good-will (everybody\nthinks Bitcoin is cool, particularly people with skills to find and\nexploit attacks).\n\nWe can consider a hierarchy of defences most secure to least:\n\n1. consensus rule enforced (attacker loses block reward)\n2. economic alignment (attacker loses money)\n3. overt (profitable, but overt attacks are less likely to be exploited)\n4. meta-incentive (relying on meta-incentive to not damage the ecosystem only)\n\nBest practices:\n\nWe might want to list some best practices that are important for the\nhealth and security of the Bitcoin network.\n\nRule of thumb KISS stuff:\n\nWe should aim to keep things simple in general and to avoid creating\ncomplex optimisation problems for transaction processors, wallets,\nminers.\n\nWe may want to consider an incremental approach (shorter-time frame or\nless technically ambitious) in the interests of simplifying and\ngetting something easier to arrive at consensus, and thus faster to\ndeploy.\n\nWe should not let the perfect be the enemy of the good.  But we should\nnot store new problems for the future, costs are stacked in favour of\ngetting it right vs A/B testing on the live network.\n\nNot everything maybe fixable in one go for complexity reasons or for\nthe reason that there is no clear solution for some issues.  We should\nwork incrementally.\n\nAdam"
            },
            {
                "author": "Eric Voskuil",
                "date": "2015-11-05T23:33:26",
                "message_text_only": "On 11/05/2015 03:03 PM, Adam Back via bitcoin-dev wrote:\n> ...\n> Validators: Economically dependent full nodes are an important part of\n> Bitcoin's security model because they assure Bitcoin security by\n> enforcing consensus rules.  While full nodes do not have orphan\n> risk, we also dont want maliciously crafted blocks with pathological\n> validation cost to erode security by knocking reasonable spec full\n> nodes off the network on CPU (or bandwidth grounds).\n> ...\n> Validators vs Miner decentralisation balance:\n> \n> There is a tradeoff where we can tolerate weak miner decentralisation\n> if we can rely on good validator decentralisation or vice versa.  But\n> both being weak is risky.  Currently given mining centralisation\n> itself is weak, that makes validator decentralisation a critical\n> remaining defence - ie security depends more on validator\n> decentralisation than it would if mining decentralisation was in a\n> better shape.\n\nThis side of the security model seems underappreciated, if not poorly\nunderstood. Weakening is not just occurring because of the proliferation\nof non-validating wallet software and centralized (web) wallets, but\nalso centralized Bitcoin APIs.\n\nOver time developers tend to settle on a couple of API providers for a\ngiven problem. Bing and Google for search and mapping, for example. All\napplications and users of them, depending on an API service, reduce to a\nsingle validator. Imagine most Bitcoin applications built on the\nequivalent of Bing and Google.\n\ne\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 473 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151105/cabe5605/attachment.sig>"
            },
            {
                "author": "Jeremy",
                "date": "2015-11-06T01:56:49",
                "message_text_only": "I'd also like to see some more formal analysis of the notion that \"$10 in\nthe hand of 10 people is more than $50 in the hand of two, or $100 in the\nhand of one\". I think this encapsulates the security assumption on why we\nwant decentralization at all.\n\nThis is a very critical property bitcoin exploits for being able to\ntransact large amounts, among other things. (Closely related is the notion\nthat defecting will destroy all the value...)\n\n\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\nOn Thu, Nov 5, 2015 at 6:33 PM, Eric Voskuil via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On 11/05/2015 03:03 PM, Adam Back via bitcoin-dev wrote:\n> > ...\n> > Validators: Economically dependent full nodes are an important part of\n> > Bitcoin's security model because they assure Bitcoin security by\n> > enforcing consensus rules.  While full nodes do not have orphan\n> > risk, we also dont want maliciously crafted blocks with pathological\n> > validation cost to erode security by knocking reasonable spec full\n> > nodes off the network on CPU (or bandwidth grounds).\n> > ...\n> > Validators vs Miner decentralisation balance:\n> >\n> > There is a tradeoff where we can tolerate weak miner decentralisation\n> > if we can rely on good validator decentralisation or vice versa.  But\n> > both being weak is risky.  Currently given mining centralisation\n> > itself is weak, that makes validator decentralisation a critical\n> > remaining defence - ie security depends more on validator\n> > decentralisation than it would if mining decentralisation was in a\n> > better shape.\n>\n> This side of the security model seems underappreciated, if not poorly\n> understood. Weakening is not just occurring because of the proliferation\n> of non-validating wallet software and centralized (web) wallets, but\n> also centralized Bitcoin APIs.\n>\n> Over time developers tend to settle on a couple of API providers for a\n> given problem. Bing and Google for search and mapping, for example. All\n> applications and users of them, depending on an API service, reduce to a\n> single validator. Imagine most Bitcoin applications built on the\n> equivalent of Bing and Google.\n>\n> e\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151105/fcb5bbd4/attachment.html>"
            },
            {
                "author": "Chris Priest",
                "date": "2015-11-06T08:05:23",
                "message_text_only": "On 11/5/15, Eric Voskuil via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> On 11/05/2015 03:03 PM, Adam Back via bitcoin-dev wrote:\n>> ...\n>> Validators: Economically dependent full nodes are an important part of\n>> Bitcoin's security model because they assure Bitcoin security by\n>> enforcing consensus rules.  While full nodes do not have orphan\n>> risk, we also dont want maliciously crafted blocks with pathological\n>> validation cost to erode security by knocking reasonable spec full\n>> nodes off the network on CPU (or bandwidth grounds).\n>> ...\n>> Validators vs Miner decentralisation balance:\n>>\n>> There is a tradeoff where we can tolerate weak miner decentralisation\n>> if we can rely on good validator decentralisation or vice versa.  But\n>> both being weak is risky.  Currently given mining centralisation\n>> itself is weak, that makes validator decentralisation a critical\n>> remaining defence - ie security depends more on validator\n>> decentralisation than it would if mining decentralisation was in a\n>> better shape.\n>\n> This side of the security model seems underappreciated, if not poorly\n> understood. Weakening is not just occurring because of the proliferation\n> of non-validating wallet software and centralized (web) wallets, but\n> also centralized Bitcoin APIs.\n>\n> Over time developers tend to settle on a couple of API providers for a\n> given problem. Bing and Google for search and mapping, for example. All\n> applications and users of them, depending on an API service, reduce to a\n> single validator. Imagine most Bitcoin applications built on the\n> equivalent of Bing and Google.\n>\n> e\n>\n>\n\nI disagree. I think blockchain APIs are a good thing for\ndecentralization. There aren't just 3 or 4 blockexplorer APIs out\nthere, there are dozens. Each API returns essentially the same data,\nso they are all interchangeable. Take a look at this python package:\nhttps://github.com/priestc/moneywagon"
            },
            {
                "author": "Adam Back",
                "date": "2015-11-06T14:08:10",
                "message_text_only": "You're right that it is better that there be more APIs than fewer,\nthat is less of a single point of failure.  It also depends what you\nmean by APIs: using an API to have a second cross-check of information\nis quite different to building a wallet or business that only\ninterfaces with the blockchain via a 3rd party API.  There are\ndifferent APIs also: some are additive eg they add a second signature\nvia multisig, but even those models while better can still be a mixed\nstory for security, if the user is not also checking their own\nfull-node or checking SPV to make the first signature.\n\nPower users and businesses using APIs instead of running a full-node,\nor instead of doing SPV checks, should be clear about the API and what\nsecurity they are delegating to a third party, and whether they have a\nreason to trust the governance and security competence of the third\nparty: in the simplest case it can reduce their and their users\nsecurity below SPV.\n\nThe bigger point however, which Erik explained, was: widespread use of\nAPIs as a sole means of interfacing with the blockchain also\ncontributes to reducing network security for everyone, because it\nerodes the consensus rule validation security described under\n\"Validators\" in the OP.\n\nAdam\n\n\nOn 6 November 2015 at 09:05, Chris Priest <cp368202 at ohiou.edu> wrote:\n> On 11/5/15, Eric Voskuil via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> On 11/05/2015 03:03 PM, Adam Back via bitcoin-dev wrote:\n>>> ...\n>>> Validators: Economically dependent full nodes are an important part of\n>>> Bitcoin's security model because they assure Bitcoin security by\n>>> enforcing consensus rules.  While full nodes do not have orphan\n>>> risk, we also dont want maliciously crafted blocks with pathological\n>>> validation cost to erode security by knocking reasonable spec full\n>>> nodes off the network on CPU (or bandwidth grounds).\n>>> ...\n>>> Validators vs Miner decentralisation balance:\n>>>\n>>> There is a tradeoff where we can tolerate weak miner decentralisation\n>>> if we can rely on good validator decentralisation or vice versa.  But\n>>> both being weak is risky.  Currently given mining centralisation\n>>> itself is weak, that makes validator decentralisation a critical\n>>> remaining defence - ie security depends more on validator\n>>> decentralisation than it would if mining decentralisation was in a\n>>> better shape.\n>>\n>> This side of the security model seems underappreciated, if not poorly\n>> understood. Weakening is not just occurring because of the proliferation\n>> of non-validating wallet software and centralized (web) wallets, but\n>> also centralized Bitcoin APIs.\n>>\n>> Over time developers tend to settle on a couple of API providers for a\n>> given problem. Bing and Google for search and mapping, for example. All\n>> applications and users of them, depending on an API service, reduce to a\n>> single validator. Imagine most Bitcoin applications built on the\n>> equivalent of Bing and Google.\n>>\n>> e\n>>\n>>\n>\n> I disagree. I think blockchain APIs are a good thing for\n> decentralization. There aren't just 3 or 4 blockexplorer APIs out\n> there, there are dozens. Each API returns essentially the same data,\n> so they are all interchangeable. Take a look at this python package:\n> https://github.com/priestc/moneywagon"
            },
            {
                "author": "Chris Priest",
                "date": "2015-11-06T23:41:36",
                "message_text_only": "> The bigger point however, which Erik explained, was: widespread use of\n> APIs as a sole means of interfacing with the blockchain also\n> contributes to reducing network security for everyone, because it\n> erodes the consensus rule validation security described under\n> \"Validators\" in the OP.\n\nI completely disagree with this. You are implying that there is some\nsort of ideal ratio of full nodes to 'client only' nodes that the\nnetwork must maintain. You seem to be implying that if that ideal\nratio is to somehow be disrupted, then security suffers. My question\nto you is what is that ideal ratio and what methodology did you use to\ncome up with it?\n\nThe way I see it, the security of the system is independent on ratio\nbetween full nodes and lightweight nodes.\n\nIn other words, if there are 100,000 lightweight wallets to 100 full\nnodes, then you have the same security profile as one with 100,000\nfull nodes to 100 lightweight wallets.\n\nI think most 'big blockers' think the same way I do, hence the rub\nbetween the two camps.\n\nSmall block people need to make a better case as to how exactly full\nnode ratio relates to network security (especially the 'for everyone'\npart), because the link is not clear to me at all. Small block people\nseem to take this simple fact as self evident, but I just don't see\nit.\n\nOn 11/6/15, Adam Back <adam at cypherspace.org> wrote:\n> You're right that it is better that there be more APIs than fewer,\n> that is less of a single point of failure.  It also depends what you\n> mean by APIs: using an API to have a second cross-check of information\n> is quite different to building a wallet or business that only\n> interfaces with the blockchain via a 3rd party API.  There are\n> different APIs also: some are additive eg they add a second signature\n> via multisig, but even those models while better can still be a mixed\n> story for security, if the user is not also checking their own\n> full-node or checking SPV to make the first signature.\n>\n> Power users and businesses using APIs instead of running a full-node,\n> or instead of doing SPV checks, should be clear about the API and what\n> security they are delegating to a third party, and whether they have a\n> reason to trust the governance and security competence of the third\n> party: in the simplest case it can reduce their and their users\n> security below SPV.\n>\n> The bigger point however, which Erik explained, was: widespread use of\n> APIs as a sole means of interfacing with the blockchain also\n> contributes to reducing network security for everyone, because it\n> erodes the consensus rule validation security described under\n> \"Validators\" in the OP.\n>\n> Adam\n>\n>\n> On 6 November 2015 at 09:05, Chris Priest <cp368202 at ohiou.edu> wrote:\n>> On 11/5/15, Eric Voskuil via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> On 11/05/2015 03:03 PM, Adam Back via bitcoin-dev wrote:\n>>>> ...\n>>>> Validators: Economically dependent full nodes are an important part of\n>>>> Bitcoin's security model because they assure Bitcoin security by\n>>>> enforcing consensus rules.  While full nodes do not have orphan\n>>>> risk, we also dont want maliciously crafted blocks with pathological\n>>>> validation cost to erode security by knocking reasonable spec full\n>>>> nodes off the network on CPU (or bandwidth grounds).\n>>>> ...\n>>>> Validators vs Miner decentralisation balance:\n>>>>\n>>>> There is a tradeoff where we can tolerate weak miner decentralisation\n>>>> if we can rely on good validator decentralisation or vice versa.  But\n>>>> both being weak is risky.  Currently given mining centralisation\n>>>> itself is weak, that makes validator decentralisation a critical\n>>>> remaining defence - ie security depends more on validator\n>>>> decentralisation than it would if mining decentralisation was in a\n>>>> better shape.\n>>>\n>>> This side of the security model seems underappreciated, if not poorly\n>>> understood. Weakening is not just occurring because of the proliferation\n>>> of non-validating wallet software and centralized (web) wallets, but\n>>> also centralized Bitcoin APIs.\n>>>\n>>> Over time developers tend to settle on a couple of API providers for a\n>>> given problem. Bing and Google for search and mapping, for example. All\n>>> applications and users of them, depending on an API service, reduce to a\n>>> single validator. Imagine most Bitcoin applications built on the\n>>> equivalent of Bing and Google.\n>>>\n>>> e\n>>>\n>>>\n>>\n>> I disagree. I think blockchain APIs are a good thing for\n>> decentralization. There aren't just 3 or 4 blockexplorer APIs out\n>> there, there are dozens. Each API returns essentially the same data,\n>> so they are all interchangeable. Take a look at this python package:\n>> https://github.com/priestc/moneywagon\n>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2015-11-07T00:44:48",
                "message_text_only": "On 11/06/2015 03:41 PM, Chris Priest wrote:\n>> The bigger point however, which Erik explained, was: widespread use of\n>> APIs as a sole means of interfacing with the blockchain also\n>> contributes to reducing network security for everyone, because it\n>> erodes the consensus rule validation security described under\n>> \"Validators\" in the OP.\n> \n> I completely disagree with this. You are implying that there is some\n> sort of ideal ratio of full nodes to 'client only' nodes that the\n> network must maintain. You seem to be implying that if that ideal\n> ratio is to somehow be disrupted, then security suffers. My question\n> to you is what is that ideal ratio and what methodology did you use to\n> come up with it?\n\nNobody has advocated a golden ratio.\n\n> The way I see it, the security of the system is independent on ratio\n> between full nodes and lightweight nodes.\n> \n> In other words, if there are 100,000 lightweight wallets to 100 full\n> nodes, then you have the same security profile as one with 100,000\n> full nodes to 100 lightweight wallets.\n\nThis is a false dichotomy. Both scenarios are poor for security, as\nnobody with a wallet is validating. It's entirely possible, even\nprobable, that one person controls all of the nodes.\n\n> I think most 'big blockers' think the same way I do, hence the rub\n> between the two camps.\n> \n> Small block people need to make a better case as to how exactly full\n> node ratio relates to network security (especially the 'for everyone'\n> part), because the link is not clear to me at all. Small block people\n> seem to take this simple fact as self evident, but I just don't see\n> it.\n\nFewer people independently validating their own transactions means trust\nis placed in fewer people. The degenerate case of one validator and\neveryone trusting it is dispositive, and equates roughly to the Federal\nReserve.\n\n> On 11/6/15, Adam Back <adam at cypherspace.org> wrote:\n>> You're right that it is better that there be more APIs than fewer,\n>> that is less of a single point of failure.  It also depends what you\n>> mean by APIs: using an API to have a second cross-check of information\n>> is quite different to building a wallet or business that only\n>> interfaces with the blockchain via a 3rd party API.  There are\n>> different APIs also: some are additive eg they add a second signature\n>> via multisig, but even those models while better can still be a mixed\n>> story for security, if the user is not also checking their own\n>> full-node or checking SPV to make the first signature.\n>>\n>> Power users and businesses using APIs instead of running a full-node,\n>> or instead of doing SPV checks, should be clear about the API and what\n>> security they are delegating to a third party, and whether they have a\n>> reason to trust the governance and security competence of the third\n>> party: in the simplest case it can reduce their and their users\n>> security below SPV.\n>>\n>> The bigger point however, which Erik explained, was: widespread use of\n>> APIs as a sole means of interfacing with the blockchain also\n>> contributes to reducing network security for everyone, because it\n>> erodes the consensus rule validation security described under\n>> \"Validators\" in the OP.\n>>\n>> Adam\n>>\n>>\n>> On 6 November 2015 at 09:05, Chris Priest <cp368202 at ohiou.edu> wrote:\n>>> On 11/5/15, Eric Voskuil via bitcoin-dev\n>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>> On 11/05/2015 03:03 PM, Adam Back via bitcoin-dev wrote:\n>>>>> ...\n>>>>> Validators: Economically dependent full nodes are an important part of\n>>>>> Bitcoin's security model because they assure Bitcoin security by\n>>>>> enforcing consensus rules.  While full nodes do not have orphan\n>>>>> risk, we also dont want maliciously crafted blocks with pathological\n>>>>> validation cost to erode security by knocking reasonable spec full\n>>>>> nodes off the network on CPU (or bandwidth grounds).\n>>>>> ...\n>>>>> Validators vs Miner decentralisation balance:\n>>>>>\n>>>>> There is a tradeoff where we can tolerate weak miner decentralisation\n>>>>> if we can rely on good validator decentralisation or vice versa.  But\n>>>>> both being weak is risky.  Currently given mining centralisation\n>>>>> itself is weak, that makes validator decentralisation a critical\n>>>>> remaining defence - ie security depends more on validator\n>>>>> decentralisation than it would if mining decentralisation was in a\n>>>>> better shape.\n>>>>\n>>>> This side of the security model seems underappreciated, if not poorly\n>>>> understood. Weakening is not just occurring because of the proliferation\n>>>> of non-validating wallet software and centralized (web) wallets, but\n>>>> also centralized Bitcoin APIs.\n>>>>\n>>>> Over time developers tend to settle on a couple of API providers for a\n>>>> given problem. Bing and Google for search and mapping, for example. All\n>>>> applications and users of them, depending on an API service, reduce to a\n>>>> single validator. Imagine most Bitcoin applications built on the\n>>>> equivalent of Bing and Google.\n>>>>\n>>>> e\n>>>>\n>>>>\n>>>\n>>> I disagree. I think blockchain APIs are a good thing for\n>>> decentralization. There aren't just 3 or 4 blockexplorer APIs out\n>>> there, there are dozens. Each API returns essentially the same data,\n>>> so they are all interchangeable. Take a look at this python package:\n>>> https://github.com/priestc/moneywagon\n>>\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 473 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151106/1cfc4dae/attachment.sig>"
            },
            {
                "author": "Gavin Andresen",
                "date": "2015-11-08T14:54:04",
                "message_text_only": "On Thu, Nov 5, 2015 at 11:03 PM, Adam Back via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Some thoughts, hope this is not off-topic.\n>\n> Maybe we should summarise the security assumptions and design\n> requirements.  It is often easier to have clear design discussions by\n> first articulating assumptions and requirements.\n>\n> Validators: Economically dependent full nodes are an important part of\n> Bitcoin's security model because they assure Bitcoin security by\n> enforcing consensus rules.  While full nodes do not have orphan\n> risk, we also dont want maliciously crafted blocks with pathological\n> validation cost to erode security by knocking reasonable spec full\n> nodes off the network on CPU (or bandwidth grounds).\n>\n\nAgreed. That is why BIP101 / BitcoinXT includes code to limit the relay and\nvalidation cost of blocks.\n\n\n>\n> Miners: Miners are in a commodity economics competitive environment\n> where various types of attacks and collusion, even with small\n> advantage, may see actual use due to the advantage being significant\n> relative to the at times low profit margin\n>\n\nAgreed, with a quibble: mining economics means they will ALWAYS have a low\nprofit margin.\n\n\n>\n> It is quite important for bitcoin decentralisation security that small\n> miners not be significantly disadvantaged vs large miners.  Similarly\n> it is important that there not be significant collusion advantages\n> that create policy centralisation as a side-effect (for example what\n> happened with \"SPV mining\" or validationless mining during BIP66\n> deployment).  Examples of attacks include selfish-mining and\n> amplifying that kind of attack via artificially large or\n> pathologically expensive to validate blocks.  Or elevating orphan risk\n> for others (a miner or collusion of miners is not at orphan risk for a\n> block they created).\n>\n\nOkey dokey-- perhaps we should have another discussion about SPV mining, as\nfar as I know it harmed nobody besides the miners who mindlessly created\ninvalid, empty blocks (well, and besides being very annoying for developers\nwho had to figure out what was happening and get the offending miners to do\nthe right thing).\n\nIn any case, it seems to me all of this (except perhaps selfish mining) is\nindependent of the maximum block size, and solutions for all of the above\n(including selfish mining) should be pursued regardless of what is done\nwith the max block size (e.g. I sent Ittay and Gun email a few minutes ago\nwith some might-be-wong-ideas for how weak block announcements might be\nused to detect selfish mining).\n\n\n>\n> Validators vs Miner decentralisation balance:\n>\n> There is a tradeoff where we can tolerate weak miner decentralisation\n> if we can rely on good validator decentralisation or vice versa.  But\n> both being weak is risky.  Currently given mining centralisation\n> itself is weak, that makes validator decentralisation a critical\n> remaining defence - ie security depends more on validator\n> decentralisation than it would if mining decentralisation was in a\n> better shape.\n>\n\nI'm very disappointed you don't mention the tradeoff at \"the other end of\nthe bathtub\" -- Key-holder versus Validator decentralization balance. Did\nyou see the excellent Poon/Dryja \"bathtub\" presentation at Montreal?\n\nhttps://scalingbitcoin.org/montreal2015/presentations/Day2/3-JosephPoonAndThaddeusDryja.pdf\n\nSecurity:\n>\n> We should consider the pathological case not average or default behaviour\n> because we can not assume people will follow the defaults, only the\n> consensus-enforced rules.\n>\n\nAgreed, which is why BIP101/XT consider pathological behavior.\n\n\n>\n> We should not discount attacks that have not seen exploitation to\n> date.  We have maybe benefitted from universal good-will (everybody\n> thinks Bitcoin is cool, particularly people with skills to find and\n> exploit attacks).\n>\n\nDisagree on wording: we should not ignore attacks that have not seen\nexploitation. But in the never-ending-list of things to be worried about\nand to write code for, attacks that have not been seen should be lower\npriority than attacks that have been seen, either in Bitcoin or elsewhere.\n\nE.g. Bitcoin has never seen a buffer-overflow attack, but we absolutely\npositively need to put a very high priority on the network attack surface\n-- we know buffer-overflow attacks are commonly exploited.\n\nOn the other hand, Bitcoin has never seen a \"Goldfinger attack\" (take a big\nshort position on Bitcoin, then find a way to destroy confidence so the\nprice drops and you can profit), and \"Goldfinger attacks\" don't seem to be\ncommon anywhere (you don't see people taking huge short positions in\ncompanies and then bombing their factories). There might be a reason\nBitcoin is more vulnerable, or the same checks-and-balances (e.g. whoever\ntook the other side of the large short has a strong incentive to report\nyou, and assuming you got paid in something other than Bitcoin that is\nprobably possible).\n  (Aside: anybody who wants to talk about the likelihood of \"Goldfinger\nattacks\" please start a thread somewhere else, I don't think that's\nappropriate for bitcoin-dev).\n\n\n>\n> We can consider a hierarchy of defences most secure to least:\n>\n> 1. consensus rule enforced (attacker loses block reward)\n> 2. economic alignment (attacker loses money)\n> 3. overt (profitable, but overt attacks are less likely to be exploited)\n> 4. meta-incentive (relying on meta-incentive to not damage the ecosystem\n> only)\n>\n\nAgreed.\n\n\n> Best practices:\n>\n> We might want to list some best practices that are important for the\n> health and security of the Bitcoin network.\n>\n> Rule of thumb KISS stuff:\n>\n> We should aim to keep things simple in general and to avoid creating\n> complex optimisation problems for transaction processors, wallets,\n> miners.\n>\n\nI agree with KISS.\n\nI think we can't avoid creating complex optimization problems sometimes--\nsee, for example, the difficulty of a wallet predicting what transaction\nfee is needed for a transaction to get confirmed in X blocks (lots of\nfactors involved-- max block size, time since last block, miner policy as\nexpressed in previous blocks, transactions currently waiting in\nmempool....).  I do agree we should prefer simple optimization problems\nover complex wherever we can.\n\n\n\n> We may want to consider an incremental approach (shorter-time frame or\n> less technically ambitious) in the interests of simplifying and\n> getting something easier to arrive at consensus, and thus faster to\n> deploy.\n>\n\nOr we may want to go with something that is already tested and deployed...\n\n\n>\n> We should not let the perfect be the enemy of the good.  But we should\n> not store new problems for the future, costs are stacked in favour of\n> getting it right vs A/B testing on the live network.\n>\n\nI disagree about \"storing new problems for the future.\"  We don't know what\nthe problems will be in the future, so there is alway a leap of faith that\nfuture engineers will be smart enough to fix the engineering problems that\narise (see the worries over quantum computing advances making ECDSA\nobsolete) -- ESPECIALLY if we have thumbnail sketches of solutions that\nwe're reasonably certain will work (e.g. switching to a quantum-resistant\nsignature algorithm via soft-fork).\n\n\n>\n> Not everything maybe fixable in one go for complexity reasons or for\n> the reason that there is no clear solution for some issues.  We should\n> work incrementally.\n> <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n\n\nI think the disagreement is how big a change fits into the definition of\n\"incrementally.\"\n\nAs Jeff Garzik has pointed out, the recent change from \"we never hit the\nmaximum block size limit\" to \"we regularly run into the maximum block size\nlimit\" was a large, NON-incremental change...\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151108/25830bce/attachment.html>"
            },
            {
                "author": "Bryan Bishop",
                "date": "2015-11-08T17:19:15",
                "message_text_only": "On Sun, Nov 8, 2015 at 8:54 AM, Gavin Andresen via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I'm very disappointed you don't mention the tradeoff at \"the other end of\n> the bathtub\" -- Key-holder versus Validator decentralization balance\n\n\nGavin, could you please provide some clarity around the definition and\nmeaning of \"key-holder [decentralization]\"? Is this about the absolute\nnumber of key-holders? or rather about the number of transactions (per unit\ntime?) that key-holders make? Both/other?\n\nAnyone can generate a private key, and anyone can sign a transaction\nspending to a new commitment. Child-pays-for-parent could be used when\ntransaction fees are too high. Perhaps more interesting would be something\nlike lightning network payment channels, where only the commitment\ntransaction needs to be in the blockchain history; does that count as\nkey-holder decentralization at all?\n\nAlso, consider the following scenario. Suppose there's a bunch of\nmerge-mined sidechains that are mainnet BTC-pegged, and these sidechains\nare accessible by the lightning network protocol (multi-chain payments).\nSuppose also that on the different sidechains there are different\ntransaction fee trends because of various technical differences underlying\nconsensus or a different blockchain implementation (who knows). When\nsomeone routes payments to one of those different sidechains, because UTXOs\ncould be cheaper over there due to different fee pressures, ... would that\ncount as key-holder decentralization? Some of this scenario is described\nhere, although not in more detail:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-September/010909.html\n\nPreviously there has been the suggestion to use BTC-pegged merge-mined\nchains to handle excess transaction demand:\nhttp://diyhpl.us/wiki/transcripts/scalingbitcoin/sharding-the-blockchain/\nhttps://github.com/vbuterin/scalability_paper/blob/master/scalability.pdf\nhttp://lists.linuxfoundation.org/pipermail/bitcoin-dev/2014-March/004797.html\n\nI notice that in the Poon file there is a concern regarding \"only 10 key\nholders\", but how does that scenario really work? I think the actual\nscenario they mean to describe is \"there's always a transaction backlog\nwhere the fees are so high that lower fee transactions can never get\nconfirmations\". So, more specifically, the scenario would have to be\n\"lightning network exists and is working, and no lightning node can ever\nroute enough different payments to commit to the blockchain under any\ncircumstance\". How would that be possible? Wouldn't most participants\nprefer the relatively instantaneous transactions of lightning, even if they\ncan afford extremely high fees? Seems like the settlements have all\nnecessary reason to actually happen, don't know what your concern is,\nplease send help.\n\nI don't mean to put words in anyone's mouth, everything above is mostly\nasking for clarification around definitions. Some of these questions are\nrepeats from:\nhttp://gnusha.org/bitcoin-wizards/2015-11-08.log\n\nThank you.\n\n- Bryan\nhttp://heybryan.org/\n1 512 203 0507\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151108/e90b51a1/attachment-0001.html>"
            },
            {
                "author": "Gavin Andresen",
                "date": "2015-11-09T16:27:22",
                "message_text_only": "On Sun, Nov 8, 2015 at 12:19 PM, Bryan Bishop <kanzure at gmail.com> wrote:\n\n> Gavin, could you please provide some clarity around the definition and\n> meaning of \"key-holder [decentralization]\"? Is this about the absolute\n> number of key-holders? or rather about the number of transactions (per unit\n> time?) that key-holders make? Both/other?\n>\n\nBoth.  If few transactions are possible, then that limits the number of\nkey-holders who can participate in the system.\n\nImagine the max block size was really small, and stretch your imagination\nand just assume there would be enough demand that those small number of\ntransactions pay enough transaction fees to secure the network. Each\ntransaction must, therefore, pay a high fee. That limits the number of\nkeyholders to institutions with very-large-value transactions-- it is the\n\"Bitcoin as a clearing network for big financial players\" model.\n\nUsing the Lightning Network doesn't help, since every Lightning Network\ntransaction IS a set of Bitcoin transactions, ready to be dropped onto the\nmain chain. If those Lightning Network transactions don't have enough fees,\nthen the whole security of the Lightning Protocol falls apart (since it\nrelies on being able to get timelocked transactions confirmed on the main\nchain in case your trading partner cheats).\n\nThere is video of the Poon/Dryja talk:\nhttps://youtu.be/TgjrS-BPWDQ?t=41m58s\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151109/4b351799/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "summarising security assumptions (re cost metrics)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Bryan Bishop",
                "Eric Voskuil",
                "Jeremy",
                "Adam Back",
                "Chris Priest",
                "Gavin Andresen"
            ],
            "messages_count": 10,
            "total_messages_chars_count": 36418
        }
    },
    {
        "title": "[bitcoin-dev] Dealing with OP_IF and OP_NOTIF malleability",
        "thread_messages": [
            {
                "author": "jl2012 at xbt.hk",
                "date": "2015-11-06T08:13:10",
                "message_text_only": "I have a new BIP draft for fixing OP_IF and OP_NOTIF malleability. \nPlease comment: \nhttps://github.com/jl2012/bips/blob/master/opifmalleability.mediawiki\n\nCopied below:\n\nBIP: x\n   Title: Dealing with OP_IF and OP_NOTIF malleability\n   Author: jl2012 <jl2012 at xbt.hk>\n   Status: Draft\n   Type: Standards Track\n   Created: 2015-11-06\n\nAbstract\n\nAs an supplement to BIP62, this document specifies proposed changes to \nthe Bitcoin transaction validity rules in order to make malleability of \ntransactions with OP_IF and OP_NOTIF impossible.\n\nMotivation\n\nOP_IF and OP_NOTIF are flow control codes in the Bitcoin script system. \nThe programme flow is decided by whether the top stake value is 0 or \nnot. However, this behavior opens a source of malleability as a third \nparty may alter a non-zero flow control value to any other non-zero \nvalue without invalidating the transaction.\n\nAs of November 2015, OP_IF and OP_NOTIF are not commonly used in the \nblockchain. However, as more sophisticated functions such as \nOP_CHECKLOCKTIMEVERITY are being introduced, OP_IF and OP_NOTIF will \nbecome more popular and the related malleability should be fixed. This \nproposal serves as a supplement to BIP62 and should be implemented with \nother malleability fixes together.\n\nSpecification\n\nIf the transaction version is 3 or above, the flow control value for \nOP_IF and OP_NOTIF must be either 0 or 1, or the transaction fails.\n\nThis is to be implemented with BIP62.\n\nCompatibility\n\nThis is a softfork. To ensure OP_IF and OP_NOTIF transactions created \nbefore the introduction of this BIP will still be accpeted by the \nnetwork, the new rules only apply to transactions of version 3 or above.\n\nFor people who want to preserve the original behaviour of OP_IF and \nOP_NOTIF, an OP_0NOTEQUAL could be  used before the flow control code to \ntransform any non-zero value to 1.\n\nReference\n\nBIP62: https://github.com/bitcoin/bips/blob/master/bip-0062.mediawiki"
            },
            {
                "author": "Nick ODell",
                "date": "2015-11-06T09:22:27",
                "message_text_only": "Your suggested modification seems sound.\n\nThough, a script author could do something similar right now by\nprefacing his IF with this:\n\n    OP_DUP OP_DUP OP_0 OP_EQUAL OP_SWAP OP_1 OP_EQUAL OP_BOOLOR\nOP_NOTIF OP_RETURN OP_ENDIF [actual OP_IF goes here]\n\nThat checks whether the input is 0 or 1, and runs OP_RETURN if not.\nYour way is cleaner, though.\n\nOn Fri, Nov 6, 2015 at 1:13 AM, jl2012 via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> I have a new BIP draft for fixing OP_IF and OP_NOTIF malleability. Please\n> comment:\n> https://github.com/jl2012/bips/blob/master/opifmalleability.mediawiki\n>\n> Copied below:\n>\n> BIP: x\n>   Title: Dealing with OP_IF and OP_NOTIF malleability\n>   Author: jl2012 <jl2012 at xbt.hk>\n>   Status: Draft\n>   Type: Standards Track\n>   Created: 2015-11-06\n>\n> Abstract\n>\n> As an supplement to BIP62, this document specifies proposed changes to the\n> Bitcoin transaction validity rules in order to make malleability of\n> transactions with OP_IF and OP_NOTIF impossible.\n>\n> Motivation\n>\n> OP_IF and OP_NOTIF are flow control codes in the Bitcoin script system. The\n> programme flow is decided by whether the top stake value is 0 or not.\n> However, this behavior opens a source of malleability as a third party may\n> alter a non-zero flow control value to any other non-zero value without\n> invalidating the transaction.\n>\n> As of November 2015, OP_IF and OP_NOTIF are not commonly used in the\n> blockchain. However, as more sophisticated functions such as\n> OP_CHECKLOCKTIMEVERITY are being introduced, OP_IF and OP_NOTIF will become\n> more popular and the related malleability should be fixed. This proposal\n> serves as a supplement to BIP62 and should be implemented with other\n> malleability fixes together.\n>\n> Specification\n>\n> If the transaction version is 3 or above, the flow control value for OP_IF\n> and OP_NOTIF must be either 0 or 1, or the transaction fails.\n>\n> This is to be implemented with BIP62.\n>\n> Compatibility\n>\n> This is a softfork. To ensure OP_IF and OP_NOTIF transactions created before\n> the introduction of this BIP will still be accpeted by the network, the new\n> rules only apply to transactions of version 3 or above.\n>\n> For people who want to preserve the original behaviour of OP_IF and\n> OP_NOTIF, an OP_0NOTEQUAL could be  used before the flow control code to\n> transform any non-zero value to 1.\n>\n> Reference\n>\n> BIP62: https://github.com/bitcoin/bips/blob/master/bip-0062.mediawiki\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Tier Nolan",
                "date": "2015-11-06T09:27:24",
                "message_text_only": "One and zero should be defined as arrays of length one.  Otherwise, it is\nstill possible to mutate the transaction by changing the length of the\narray.\n\nThey should also be minimally encoded but that is covered by previous rules.\n\nOn Fri, Nov 6, 2015 at 8:13 AM, jl2012 via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I have a new BIP draft for fixing OP_IF and OP_NOTIF malleability. Please\n> comment:\n> https://github.com/jl2012/bips/blob/master/opifmalleability.mediawiki\n>\n> Copied below:\n>\n> BIP: x\n>   Title: Dealing with OP_IF and OP_NOTIF malleability\n>   Author: jl2012 <jl2012 at xbt.hk>\n>   Status: Draft\n>   Type: Standards Track\n>   Created: 2015-11-06\n>\n> Abstract\n>\n> As an supplement to BIP62, this document specifies proposed changes to the\n> Bitcoin transaction validity rules in order to make malleability of\n> transactions with OP_IF and OP_NOTIF impossible.\n>\n> Motivation\n>\n> OP_IF and OP_NOTIF are flow control codes in the Bitcoin script system.\n> The programme flow is decided by whether the top stake value is 0 or not.\n> However, this behavior opens a source of malleability as a third party may\n> alter a non-zero flow control value to any other non-zero value without\n> invalidating the transaction.\n>\n> As of November 2015, OP_IF and OP_NOTIF are not commonly used in the\n> blockchain. However, as more sophisticated functions such as\n> OP_CHECKLOCKTIMEVERITY are being introduced, OP_IF and OP_NOTIF will become\n> more popular and the related malleability should be fixed. This proposal\n> serves as a supplement to BIP62 and should be implemented with other\n> malleability fixes together.\n>\n> Specification\n>\n> If the transaction version is 3 or above, the flow control value for OP_IF\n> and OP_NOTIF must be either 0 or 1, or the transaction fails.\n>\n> This is to be implemented with BIP62.\n>\n> Compatibility\n>\n> This is a softfork. To ensure OP_IF and OP_NOTIF transactions created\n> before the introduction of this BIP will still be accpeted by the network,\n> the new rules only apply to transactions of version 3 or above.\n>\n> For people who want to preserve the original behaviour of OP_IF and\n> OP_NOTIF, an OP_0NOTEQUAL could be  used before the flow control code to\n> transform any non-zero value to 1.\n>\n> Reference\n>\n> BIP62: https://github.com/bitcoin/bips/blob/master/bip-0062.mediawiki\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151106/d815e1ae/attachment.html>"
            },
            {
                "author": "Oleg Andreev",
                "date": "2015-11-06T09:32:02",
                "message_text_only": "> One and zero should be defined as arrays of length one. Otherwise, it is still possible to mutate the transaction by changing the length of the array. \n> \n> They should also be minimally encoded but that is covered by previous rules.\n\nThese two lines contradict each other. Minimally-encoded \"zero\" is an array of length zero, not one. I'd suggest defining this explicitly here as \"IF/NOTIF argument must be either zero-length array or a single byte 0x01\"."
            },
            {
                "author": "Tier Nolan",
                "date": "2015-11-06T09:37:58",
                "message_text_only": "I meant not to use the OP_PUSH opcodes to do the push.\n\nDoes OP_0 give a zero length byte array?\n\nWould this script return true?\n\nOP_0\nOP_PUSHDATA1 (length = 1, data = 0)\nOP_EQUAL\n\nThe easiest definition is that OP_0 and OP_1 must be used to push the data\nand not any other push opcodes.\n\n\nOn Fri, Nov 6, 2015 at 9:32 AM, Oleg Andreev <oleganza at gmail.com> wrote:\n\n>\n> > One and zero should be defined as arrays of length one. Otherwise, it is\n> still possible to mutate the transaction by changing the length of the\n> array.\n> >\n> > They should also be minimally encoded but that is covered by previous\n> rules.\n>\n> These two lines contradict each other. Minimally-encoded \"zero\" is an\n> array of length zero, not one. I'd suggest defining this explicitly here as\n> \"IF/NOTIF argument must be either zero-length array or a single byte 0x01\".\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151106/435de781/attachment.html>"
            },
            {
                "author": "jl2012 at xbt.hk",
                "date": "2015-11-06T10:16:46",
                "message_text_only": "I assume this proposal is implemented at the same time as BIP62. As long \nas OP_IF/OP_NOTIF interprets the argument as a number, zero-padded \nnumber and negative zero are already prohibited in BIP62\n\nTier Nolan via bitcoin-dev \u65bc 2015-11-06 04:37 \u5beb\u5230:\n> I meant not to use the OP_PUSH opcodes to do the push.\n> \n> Does OP_0 give a zero length byte array?\n> \n> Would this script return true?\n> \n> OP_0\n> \n> OP_PUSHDATA1 (length = 1, data = 0)\n> \n> OP_EQUAL\n> \n> The easiest definition is that OP_0 and OP_1 must be used to push the\n> data and not any other push opcodes.\n> \n> On Fri, Nov 6, 2015 at 9:32 AM, Oleg Andreev <oleganza at gmail.com>\n> wrote:\n> \n>>> One and zero should be defined as arrays of length one.\n>> Otherwise, it is still possible to mutate the transaction by\n>> changing the length of the array.\n>>> \n>>> They should also be minimally encoded but that is covered by\n>> previous rules.\n>> \n>> These two lines contradict each other. Minimally-encoded \"zero\" is\n>> an array of length zero, not one. I'd suggest defining this\n>> explicitly here as \"IF/NOTIF argument must be either zero-length\n>> array or a single byte 0x01\".\n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Oleg Andreev",
                "date": "2015-11-10T10:52:46",
                "message_text_only": "OP_0 gives a zero length byte array because OP_0 == 0x00 which is equivalent to pushdata with zero length.\n\nOP_EQUAL compares byte strings as-is. So it will push \"false\" because empty string is not the same as a single-byte string with 0x00 byte in it. Value \"false\" in turn is encoded as empty string, just like result of OP_0.\n\n> On 06 Nov 2015, at 10:37, Tier Nolan via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> I meant not to use the OP_PUSH opcodes to do the push.\n> \n> Does OP_0 give a zero length byte array?\n> \n> Would this script return true?\n> \n> OP_0\n> OP_PUSHDATA1 (length = 1, data = 0)\n> OP_EQUAL\n> \n> The easiest definition is that OP_0 and OP_1 must be used to push the data and not any other push opcodes.\n> \n> \n> On Fri, Nov 6, 2015 at 9:32 AM, Oleg Andreev <oleganza at gmail.com <mailto:oleganza at gmail.com>> wrote:\n> \n> > One and zero should be defined as arrays of length one. Otherwise, it is still possible to mutate the transaction by changing the length of the array.\n> >\n> > They should also be minimally encoded but that is covered by previous rules.\n> \n> These two lines contradict each other. Minimally-encoded \"zero\" is an array of length zero, not one. I'd suggest defining this explicitly here as \"IF/NOTIF argument must be either zero-length array or a single byte 0x01\".\n> \n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151110/8c16a920/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Dealing with OP_IF and OP_NOTIF malleability",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "jl2012 at xbt.hk",
                "Nick ODell",
                "Oleg Andreev",
                "Tier Nolan"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 11855
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin-NG whitepaper.",
        "thread_messages": [
            {
                "author": "Ittay",
                "date": "2015-11-06T20:48:08",
                "message_text_only": "On Tue, Oct 27, 2015 at 10:08 PM, Matt Corallo <lf-lists at mattcorallo.com>\nwrote:\n\n> Oops, just realized I never responded to this...\n>\n> On 10/15/15 15:09, Ittay wrote:\n> > Thanks, Matt. Response inline.\n> >\n> > On Wed, Oct 14, 2015 at 2:57 PM, Matt Corallo <lf-lists at mattcorallo.com\n> > <mailto:lf-lists at mattcorallo.com>> wrote:\n> >\n> >     That conversation missed a second issue. Namely that there is no way\n> >     to punish people if there is a double spend in a micro block that\n> >     happens in key block which reorg'd away the first transaction. eg\n> >     one miner mines a transaction in a micro block, another miner\n> >     (either by not having seen the first yet, or being malicious -\n> >     potentially the same miner) mines a key block which reorgs away the\n> >     first micro block and then, in their first micro block, mines a\n> >     double spend. This can happen at any time, so you end up having to\n> >     fall back to regular full blocks for confirmation times :(.\n> >\n> >\n> > If NG is to be used efficiently, microblocks are going to be very\n> > frequent, and so such forks should occur at almost every key-block\n> > publication. Short reorgs as you described are the norm. A user should\n> > wait before accepting a transaction to make sure there was no key-block\n> > she missed. The wait time is chosen according to the network propagation\n> > delay (+as much slack as the user feels necessary). This is similar to\n> > the situation in Bitcoin when you receive a block. To be confident that\n> > you have one confirmation you should wait for the propagation time of\n> > the network to make sure there is no branch you missed.\n>\n> I think you're overstating how short the wait times can be. They need to\n> be much longer than the network propagation delay.\n>\n> > As for the malicious case: the attacker has to win the key-block, have\n> > the to-be-inverted transaction in the previous epoch, and withhold his\n> > key-block for a while. That being said, indeed our fraud proof scheme\n> > doesn't catch such an event, as it is indistinguishable from benign\n> > behavior.\n>\n> The attacker does not need to withold their keyblock at all. All the\n> attacker does is, for every transaction they ever send, after it is\n> included in a microblock, set their hashpower to start mining a keyblock\n> immediately prior to this microblock. When they find a keyblock, they\n> immediately announce it and start creating microblocks, the first of\n> which double-spends the previous transaction. If they dont win the key\n> block, oh well, their payment went through normally and they couldn't\n> double-spend.\n>\n> In chatting with Glenn about this, we roughly agreed that the\n> confirmation time for microblocks possibly doesn't need to be a full\n> key-block, but it needs to be a reasonable period after which such an\n> attacker would lose more in fees than the value of their double-spend\n> (ie because the key-block afterwards gets 20% more in fees than the\n> key-block before hand). In any case, the game theory here starts to get\n> rather complicated and it doesn't make me want to suggest accepting\n> microblocks as confirmations is safe.\n>\n\nYes, an attacker can continuously try to do this, losing all (and only)\nfees.\nThey will succeed every time they mine a block after the to-be-double-spent\ntransaction is placed by the current leader. So a microblock + delay is\nstronger\nthan a zero-confirmation transaction, but not as strong as a first-block\nconfirmation.\n\nA game theory analysis is indeed difficult here, mainly since the\nassumptions\nare not entirely clear. We are working towards this, starting with\nformalizing\nthe attacker's incentive structure.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151106/c5d8d279/attachment.html>"
            },
            {
                "author": "Emin G\u00fcn Sirer",
                "date": "2015-11-09T18:33:27",
                "message_text_only": "Hi everyone,\n\nThanks to everyone for a very friendly and scientifically-oriented\ndiscussion. We have collated all the issues that have been raised related\nto NG, and placed them in context, here:\n    http://hackingdistributed.com/2015/11/09/bitcoin-ng-followup/\n\nOverall, NG has a unique insight: turning the block creation process upside\ndown can provide many benefits. Most notably, throughput can go as high as\nthe network will allow, providing scalability benefits that increase as the\nnetwork improves. There are many other side benefits, including fast\nconfirmations that are stronger than 0-conf in Core, and come much more\nquickly than Core's 1-confirmations. And there are ancillary benefits as\nwell, such as resilience to fluctuations in mining power, and healthier\nincentives for participants to ferry transactions. We believe that a fresh\nnew permission-less blockchain protocol, designed today, would end up\nlooking more like NG than Core. Of course, if NG could possibly be layered\non top of Bitcoin, that would be the ultimate combination.\n\nMany thanks for an interesting discussion, and as always, we're happy to\nhear constructive suggestions and feedback,\n- egs\n\n\nOn Wed, Oct 14, 2015 at 2:02 PM, Emin G\u00fcn Sirer <el33th4x0r at gmail.com>\nwrote:\n\n> Hi everyone,\n>\n> We just released the whitepaper describing Bitcoin-NG, a new technique for\n> addressing some of the scalability challenges faced by Bitcoin.\n> Surprisingly, Bitcoin-NG can simultaneously increase throughput while\n> reducing latency, and do so without impacting Bitcoin's open architecture\n> or changing its trust model. This post illustrates the core technique:\n>      http://hackingdistributed.com/2015/10/14/bitcoin-ng/\n> while the whitepaper has all the nitty gritty details:\n>      http://arxiv.org/abs/1510.02037\n>\n> Fitting NG on top of the current Bitcoin blockchain is future work that we\n> think is quite possible. NG is compatible with both Bitcoin as is, as well\n> as Blockstream-like sidechains, and we currently are not planning to\n> compete commercially with either technology -- we see NG as being\n> complementary to both efforts. This is pure science, published and shared\n> with the community to advance the state of blockchains and to help them\n> reach throughputs and latencies required of cutting edge fintech\n> applications. Perhaps it can be adopted, or perhaps it can provide the\n> spark of inspiration for someone else to come up with even better solutions.\n>\n> We would be delighted to hear your feedback.\n> - Ittay Eyal and E. G\u00fcn Sirer.\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151109/df19652c/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin-NG whitepaper.",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Emin G\u00fcn Sirer",
                "Ittay"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 6594
        }
    },
    {
        "title": "[bitcoin-dev] How wallets can handle real transaction fees",
        "thread_messages": [
            {
                "author": "Bram Cohen",
                "date": "2015-11-07T01:25:53",
                "message_text_only": "(My apologies for a 'drive-by' posting. I'm not subscribed to this mailing\nlist but this post may be of interest here. If you'd like to make sure I\nsee a response send it to me directly. This post was originally posted to\nthe web at\nhttps://medium.com/@bramcohen/how-wallets-can-handle-transaction-fees-ff5d020d14fb\n )\n\nSince transaction fees are a good thing (see\nhttps://medium.com/@bramcohen/bitcoin-s-ironic-crisis-32226a85e39f ), that\nbrings up the question: How should wallets handle them? This essay is an\nexpansion of my talk at the bitcoin scaling conference (see\nhttps://www.youtube.com/watch?v=iKDC2DpzNbw&t=13m17s and\nhttps://scalingbitcoin.org/montreal2015/presentations/Day1/11-bram_wallet_fees.pdf\n ).\n\nGround Rules\n\nTo answer this question we first need to lay down some ground rules of what\nwe\u2019re trying to solve. We\u2019ll focus on trying to solve the problem for\nconsumer wallets only. We\u2019ll be ignoring microchannels, which dramatically\nreduce the number of transactions used but still have to put some on the\nblockchain. We\u2019ll also be assuming that full replace by fee is in effect\n(see\nhttps://medium.com/@bramcohen/the-inevitable-demise-of-unconfirmed-bitcoin-transactions-8b5f66a44a35\n)\nbecause the best solution uses that fairly aggressively.\n\nWhat should transaction fees be?\n\nBefore figuring out how wallets should calculate transaction fees, we first\nneed to know what transaction fees should be. The obvious solution to that\nquestion is straightforward: It should be determined by supply and demand.\nThe price is set at the point where the supply and demand curves meet. But\nsupply and demand curves, while mostly accurate, are a little too simple of\na model to use, because they don\u2019t take into account time. In the real\nworld, the supply of space for transactions is extremely noisy, because\nmore becomes available (and has to be immediately consumed or it\u2019s lost\nforever) every time a block is minted, and block minting is an\nintentionally random process, that randomness being essential for\nconsensus. Demand is random and cyclical. Random because each transaction\nis generated individually so the total amount is noisy (although that\naverages out to be somewhat smooth at scale) and has both daily and weekly\ncycles, with more transactions done during the day than at night.\n\nWhat all these result in is that there should be a reward for patience. If\nyou want or need to get your transaction in quicker you should have to pay\non average a higher fee, and if you\u2019re willing to wait longer it should on\naverage cost less. Inevitably this will result in transactions taking on\naverage longer than one block to go through, but it doesn\u2019t require it of\neveryone. Those who wish to offer high fees to be sure of getting into the\nvery next block are free to do so, but if everyone were to do that the\nsystem would fall apart.\n\nWhat should the wallet user interface be?\n\nIdeally transaction fees would be handled in a way which didn\u2019t require\nchanges to a wallet\u2019s user interface at all. Unfortunately that isn\u2019t\npossible. At a minimum it\u2019s necessary to have a maximum fee which the user\nis willing to spend in order to make a transaction go through, which of\ncourse means that some transactions will fail because they aren\u2019t willing\nto pay enough, which is the whole point of having transaction fees in the\nfirst place.\n\nBecause transaction fees should be lower for people willing to wait longer,\nthere should be some kind of patience parameter as well. The simplest form\nof this is an amount of time which the wallet will spend trying to make the\ntransaction go through before giving up (Technically it may make sense to\nspecify block height instead of wall clock time, but that\u2019s close enough to\nnot change anything meaningful). This results in fairly understandable\nconcepts of a transaction being \u2018pending\u2019 and \u2018failed\u2019 which happen at\npredictable times.\n\nTransactions eventually getting into a \u2018failed\u2019 state instead of going into\npermanent limbo is an important part of the wallet fee user experience.\nUnfortunately right now the only way to make sure that a transaction is\npermanently failed is to spend its input on something else, but that\nrequires spending a transaction fee on the canceling transaction, which of\ncourse would be just as big as the fee you weren\u2019t willing to spend to make\nthe real transaction go through in the first place.\n\nWhat\u2019s needed is a protocol extension so a transaction can make it\nimpossible for it to be committed once a certain block height has been\nreached. The current lack of such an extension is somewhat intentional\nbecause there are significant potential problems with transactions going\nbad because a block reorganization happened and some previously accepted\ntransactions can\u2019t ever be recommitted because their max block height got\nsurpassed. To combat this, when a transaction with a max block height gets\ncommitted near its cutoff it\u2019s necessary to wait a longer than usual number\nof blocks to be sure that it\u2019s safe (I\u2019m intentionally not giving specific\nnumbers here, some developers have suggested extremely conservative\nvalues). This waiting is annoying but should only apply in the edge case of\nfailed transactions and is straightforward to implement. The really big\nproblem is that given the way Bitcoin works today it\u2019s very hard to add\nthis sort of extension. If any backwards-incompatible change to Bitcoin is\ndone, it would be a very good idea to use that opportunity to improve\nBitcoin\u2019s extension mechanisms in general and this one in particular.\n\nWhat information to use\n\nThe most obvious piece of information to use for setting transaction fees\nis past transaction fees from the last few blocks. This has a number of\nproblems. If the fee rate goes high, it can get stuck there and take a\nwhile to come down, if ever, even though the equilibrium price should be\nlower. A telltale sign of this is high fee blocks which aren\u2019t full, but\nit\u2019s trivial for miners to get around that by padding their blocks with\nself-paying transactions. To some extent this sort of monopoly pricing is\ninherent, but normally it would require a cabal of most miners to pull it\noff, because any one miner can make more money in the short term by\naccepting every transaction they can instead of restricting the supply of\navailable transaction space. If transaction fees are sticky, a large but\nstill minority miner can make money for themselves even in the short term\nby artificially pumping fees in one of their blocks because fees will\nprobably still be high by the time of their next block.\n\nPast fees also create problems for SPV clients, who have to trust the full\nnodes they connect to to report past fees accurately. That could be\nmitigated by making an extension to the block format to, for example,\nreport what the minimum fee per bytes paid in this block is in the headers.\nIt isn\u2019t clear exactly what that extension should do though. Maybe you want\nto know the minimum, or the median, or the 25th percentile, or all of the\nabove. It\u2019s also possible for miners to game the system by making a bunch\nof full nodes which only report blocks which are a few back when fees have\nrecently dropped. There are already some incentives to do that sort of bad\nbehavior, and it can be mitigated by having SPV clients connect to more\nfull nodes than they currently do and always go with the max work, but SPV\nclients don\u2019t currently do that properly, and it\u2019s unfortunate to create\nmore incentives for bad behavior.\n\nAnother potential source of information for transaction fees is currently\npending transactions in the network. This has a whole lot of problems. It\u2019s\nextremely noisy, much more so than regular transaction fees, because (a)\nsometimes a backlog of transactions builds up if no blocks happen to have\nhappened in a while (b) sometimes there aren\u2019t many transactions if a bunch\nof blocks went through quickly, and (c) in the future full nodes can and\nshould have a policy of only forwarding transactions which are likely to\nget accepted sometime soon given the other transactions in their pools.\nMempool is also trivially gameable, in exactly the same way as the last few\nblocks are gameable, but worse: A miner who wishes to increase fees can run\na whole lot of full nodes and report much higher fees than are really\nhappening. Unlike with fee reporting in blocks, there\u2019s no way for SPV\nclients to audit this properly, even with a protocol extension, and it\u2019s\npossible for full nodes to lie in a much more precise and targetted manner.\nCreating such a strong incentive for such a trivial and potentially\nlucrative attack seems like a very bad idea.\n\nA wallet\u2019s best information to use when setting price are the things which\ncan be absolutely verified locally: The amount it\u2019s hand to pay in the\npast, the current time, how much it\u2019s willing to pay by when. All of these\nhave unambiguous meanings, precise mathematical values, and no way for\nanybody else to game them. A wallet can start at a minimum value, and every\ntime a new block is minted which doesn\u2019t accept its transaction increase\nits fee a little, until finally reaching its maximum value at the very end.\nFull nodes can then follow the behavior of storing and forwarding along\nseveral blocks\u2019s worth of transactions, ten times sounds reasonable,\nignoring transactions which pay less per byte than the ones they have\nstored, and further requiring that a new block be minted between times when\na single transaction gets replaced by fee. That policy both has the\nproperty of being extremely denial-of-service resistant and minimizing the\ndamage to zeroconf. (Zeroconf is a bad idea, but if something is a good\nidea to do for other reasons reducing the pain to those stuck with zeroconf\nis a nice bonus.)\n\nAn actual formula\n\nAt long last, here is the formula I advocate using:\n\nPick a starting point which is de minimis for your first transaction or 1/2\n(or less, configurable) your last fee paid if you\u2019ve sent coin before\n\nLet B = max number of blocks from start before giving up, S = starting fee,\nM = max fee\n\nFor each new block at height H from the start, post a new transaction with\nfee e^(lg(S) + (lg(M) \u2014 lg(S)) * H/B)\n\nTo avoid artifacts when multiple wallets use the same magic numbers, do\nthis before the first block: pick V uniformly in [0, 1], let S = e^(lg(S) +\n(lg(M) \u2014 lg(S)) * (V/(V+B)))\n\nThe very first time you send coin it makes sense to give it a longer time\nto do the transaction because it\u2019s starting from a very low value and you\ndon\u2019t want to way overshoot the amount necessary. But if you start from the\nstandard absolute minimum fee in Bitcoin and put the maximum time at\nseveral hours it will increase by less than 10% per block, so exponential\ngrowth is on your side.\n\nIt might be reasonable to, for example, start at a value which is a\ndiscount to the minimum paid in the last block if that value is less than\nwhat you would start with otherwise and if there\u2019s a protocol extension to\nput that information in the block headers. Such possibilities should be\nstudied and discussed more, but the formula I gave above should be the\ndefault starting point if you simply want something which works and is\nconservative and reliable.\n\nSidebar: Handling utxo combining\n\nWhenever a wallet makes a payment, it needs to decide how to structure the\ninputs and outputs of the new transaction. Generally the output consists of\ntwo utxos, one of them going to the recipient and one of them going back\ninto the original wallet. Which input or inputs to use is less clear.\nUsually an attempt is made to optimize for anonymity, or at least leaking\nas little information as possible, and there\u2019s usually a comment in the\ncode saying what amounts to \u2018I can\u2019t clearly justify any particular\nstrategy here but this is what I\u2019m doing\u2019.\n\nWhen there are real transaction fees, one might consider trying to optimize\nutxo combining for fees. The strategy used turns out to matter surprisingly\nlittle for fees in the long run. For every separate utxo in your wallet,\nyou\u2019ll eventually have to pay the fee to combine it with something else,\nand the amount of increase in fee will be the same regardless of whether\nyou do it in the current transaction or a later transaction. It does make\nsense to include more inputs in earlier versions of a payment though,\nbecause the fees at that time are lower, and drop them in later versions\nonce the fees have gone up, in the hopes that the utxo consolidation can be\ndone for cheaper in some later transaction. It may also make sense to do\ncompletely separate purely consolidation transactions with no external\noutput during off-peak times. That puts more bytes on the blockchain\nbecause of the unnecessary intermediary value it generates though, so there\nneeds to be a significant difference in fees between peak and off-peak\ntimes for it to make sense. Both of those techniques have significant and\nunclear privacy implications and should be studied more.\n\nThere are also signing tricks which could potentially save significant\namounts of bytes on the blockchain, thus lowering fees. The most elegant\nwould be to create a new extension so that when there are multiple inputs\nto a transaction which all use Schnorr the signature can be a single\ncombination signature instead of separate signatures for each of them. This\nhas very little downside and I\u2019m strongly in favor of it being done.\n\nA simpler, less elegant trick which saves more bytes would be to allow\nmultiple inputs to the same transaction which use the same key to only\nresult in a single signature. This lowers privacy, because it gives away\nthe association between utxos before they\u2019re consolidated, but if used\nproperly would only push back that reveal a little bit. The danger is that\nwallets would instead use it improperly and use the same key all the time,\nwhich would always save as many bytes as possible but be a privacy disaster.\n\nA trick which is a just plain bad idea, although it would save even more\nbytes, would be not count the bytes of the reveal of a p2sh script to count\nif that exact same script has ever been used before. This is clearly a bad\nidea, because it directly encourages extremely privacy-averse behavior, and\nbecause it necessitates a data structure of all p2sh scripts which have\never been done before for validation, which is quite large and costly to\nmaintain.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151106/f9ea4b51/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "How wallets can handle real transaction fees",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Bram Cohen"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 14520
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Core 0.11.2 release candidate 1 available",
        "thread_messages": [
            {
                "author": "Wladimir J. van der Laan",
                "date": "2015-11-09T10:41:17",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nBinaries for bitcoin Core version 0.11.2rc1 are now available from:\n\n    https://bitcoin.org/bin/bitcoin-core-0.11.2/test/\n\nSource code can be found on github under the signed tag\n\n    https://github.com/bitcoin/bitcoin/tree/v0.11.2rc1\n\nThis is a new minor version release, bringing bug fixes, the BIP65 (CLTV)\nconsensus change, and relay policy preparation for BIP113.\n\nPreliminary release notes for the 0.11.2 release can be found here:\n\n    https://github.com/bitcoin/bitcoin/blob/0.11/doc/release-notes.md\n\nRelease candidates are test versions for releases. When no critical problems\nare found, this release candidate will be tagged as 0.11.2.\n\nPlease report bugs using the issue tracker at github:\n\n    https://github.com/bitcoin/bitcoin/issues\n\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1\n\niQEcBAEBCgAGBQJWQHgdAAoJEHSBCwEjRsmmkZkH/joklzUWXNCS/CKjfhnDaSAL\nkTuGpcBPcmGyLZ+n7YHIwXKi5Jjuy91ADbYKUQHtOI5oDK+5XY0SD5YDfQv+jx8a\nm3J5rxePV6VXcXKtNURXRmmk71zGhIZvZ0ynUlgLqvP7WFM+FcH5BJF2sk2amFlK\n2WIzJapJMXzOyYehb9ISb2qXtuSGDyevpfeDJVMNIqoQekS1r8jOPXJiT66G4HZZ\nSvUMPZAjgOtjKUQK98nF1xzRggkWiP1rjeBVdvlYiTmCopYrNiB5scPmSf2guCrx\n7IH5fLbQ7JDow49dcd2ILTYFgMF03HvPvtlwz9dvOx5JYOaCw0He5CnXzZgFmV0=\n=uO43\n-----END PGP SIGNATURE-----"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Core 0.11.2 release candidate 1 available",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Wladimir J. van der Laan"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1272
        }
    },
    {
        "title": "[bitcoin-dev] request BIP number for: \"Support for Datastream Compression\"",
        "thread_messages": [
            {
                "author": "Peter Tschipper",
                "date": "2015-11-09T19:18:10",
                "message_text_only": "This is my first time through this process so please bear with me. \n\nI opened a PR #6973 this morning for Zlib Block Compression for block\nrelay and at the request of @sipa  this should have a BIP associated\nwith it.   The idea is simple, to compress the datastream before\nsending, initially for blocks only but it could theoretically be done\nfor transactions as well.  Initial results show an average of 20% block\ncompression and taking 90 milliseconds for a full block (on a very slow\nlaptop) to compress.  The savings will be mostly in terms of less\nbandwidth used, but I would expect there to be a small performance gain\nduring the transmission of the blocks particularly where network latency\nis higher. \n\nI think the BIP title, if accepted should be the more generic, \"Support\nfor Datastream Compression\"  rather than the PR title of \"Zlib\nCompression for block relay\" since it could also be used for\ntransactions as well at a later time.\n\nThanks for your time..."
            },
            {
                "author": "Johnathan Corgan",
                "date": "2015-11-09T20:41:17",
                "message_text_only": "On Mon, Nov 9, 2015 at 11:18 AM, Peter Tschipper via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n\n> I opened a PR #6973 this morning for Zlib Block Compression for block\n> relay and at the request of @sipa  this should have a BIP associated\n> with it.   The idea is simple, to compress the datastream before\n> sending, initially for blocks only but it could theoretically be done\n> for transactions as well.  Initial results show an average of 20% block\n> compression and taking 90 milliseconds for a full block (on a very slow\n> laptop) to compress.  The savings will be mostly in terms of less\n> bandwidth used, but I would expect there to be a small performance gain\n> during the transmission of the blocks particularly where network latency\n> is higher.\n>\n\n\u200bThe trade-off decisions among bandwidth savings, CPU performance, and\nlatency are local, and I think it shouldn't be assumed that any particular\nnode will want to support it.  I recommend that if P2P message compression\nis implemented, it should be negotiated via the services field at\nconnection time.\n\n-- \nJohnathan Corgan\nCorgan Labs - SDR Training and Development Services\nhttp://corganlabs.com\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151109/ba80d6bb/attachment.html>"
            },
            {
                "author": "Bob McElrath",
                "date": "2015-11-09T21:04:49",
                "message_text_only": "I would expect that since a block contains mostly hashes and crypto signatures,\nit would be almost totally incompressible.  I just calculated compression ratios:\n\nzlib    -15%    (file is LARGER)\ngzip     28%\nbzip2    25%\n\nSo zlib compression is right out.  How much is ~25% bandwidth savings worth to\npeople?  This seems not worth it to me.  :-/\n\nPeter Tschipper via bitcoin-dev [bitcoin-dev at lists.linuxfoundation.org] wrote:\n> This is my first time through this process so please bear with me. \n> \n> I opened a PR #6973 this morning for Zlib Block Compression for block\n> relay and at the request of @sipa  this should have a BIP associated\n> with it.   The idea is simple, to compress the datastream before\n> sending, initially for blocks only but it could theoretically be done\n> for transactions as well.  Initial results show an average of 20% block\n> compression and taking 90 milliseconds for a full block (on a very slow\n> laptop) to compress.  The savings will be mostly in terms of less\n> bandwidth used, but I would expect there to be a small performance gain\n> during the transmission of the blocks particularly where network latency\n> is higher. \n> \n> I think the BIP title, if accepted should be the more generic, \"Support\n> for Datastream Compression\"  rather than the PR title of \"Zlib\n> Compression for block relay\" since it could also be used for\n> transactions as well at a later time.\n> \n> Thanks for your time...\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n> \n> !DSPAM:5640ff47206804314022622!\n--\nCheers, Bob McElrath\n\n\"For every complex problem, there is a solution that is simple, neat, and wrong.\"\n    -- H. L. Mencken"
            },
            {
                "author": "gladoscc",
                "date": "2015-11-10T01:58:41",
                "message_text_only": "I think 25% bandwidth savings is certainly considerable, especially for\npeople running full nodes in countries like Australia where internet\nbandwidth is lower and there are data caps.\n\nI absolutely would not dismiss 25% compression. gzip and bzip2 compression\nis relatively standard, and I'd consider the point of implementation\ncomplexity tradeoff to be somewhere along 5-10%.\n\nOn Tue, Nov 10, 2015 at 8:04 AM, Bob McElrath via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I would expect that since a block contains mostly hashes and crypto\n> signatures,\n> it would be almost totally incompressible.  I just calculated compression\n> ratios:\n>\n> zlib    -15%    (file is LARGER)\n> gzip     28%\n> bzip2    25%\n>\n> So zlib compression is right out.  How much is ~25% bandwidth savings\n> worth to\n> people?  This seems not worth it to me.  :-/\n>\n> Peter Tschipper via bitcoin-dev [bitcoin-dev at lists.linuxfoundation.org]\n> wrote:\n> > This is my first time through this process so please bear with me.\n> >\n> > I opened a PR #6973 this morning for Zlib Block Compression for block\n> > relay and at the request of @sipa  this should have a BIP associated\n> > with it.   The idea is simple, to compress the datastream before\n> > sending, initially for blocks only but it could theoretically be done\n> > for transactions as well.  Initial results show an average of 20% block\n> > compression and taking 90 milliseconds for a full block (on a very slow\n> > laptop) to compress.  The savings will be mostly in terms of less\n> > bandwidth used, but I would expect there to be a small performance gain\n> > during the transmission of the blocks particularly where network latency\n> > is higher.\n> >\n> > I think the BIP title, if accepted should be the more generic, \"Support\n> > for Datastream Compression\"  rather than the PR title of \"Zlib\n> > Compression for block relay\" since it could also be used for\n> > transactions as well at a later time.\n> >\n> > Thanks for your time...\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n> >\n> > !DSPAM:5640ff47206804314022622!\n> --\n> Cheers, Bob McElrath\n>\n> \"For every complex problem, there is a solution that is simple, neat, and\n> wrong.\"\n>     -- H. L. Mencken\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151110/0d844af0/attachment.html>"
            },
            {
                "author": "Johnathan Corgan",
                "date": "2015-11-10T05:40:13",
                "message_text_only": "On Mon, Nov 9, 2015 at 5:58 PM, gladoscc via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n\n> I think 25% bandwidth savings is certainly considerable, especially for\n> people running full nodes in countries like Australia where internet\n> bandwidth is lower and there are data caps.\n>\n\n\u200bThis reinforces the idea that such trade-off decisions should be be local\nand negotiated between peers, not a required feature of the network P2P.\u200b\n\n\n-- \nJohnathan Corgan\nCorgan Labs - SDR Training and Development Services\nhttp://corganlabs.com\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151109/17db381d/attachment.html>"
            },
            {
                "author": "Tier Nolan",
                "date": "2015-11-10T09:44:11",
                "message_text_only": "The network protocol is not quite consensus critical, but it is important.\n\nTwo implementations of the decompressor might not be bug for bug\ncompatible.  This (potentially) means that a block could be designed that\nwon't decode properly for some version of the client but would work for\nanother.  This would fork the network.\n\nA \"raw\" network library is unlikely to have the same problem.\n\nRather than just compress the stream, you could compress only block\nmessages only.  A new \"cblock\" message could be created that is a\ncompressed block.  This shouldn't reduce efficiency by much.\n\nIf a client fails to decode a cblock, then it can ask for the block to be\nre-sent as a standard \"block\" message.\n\nThis means that it is a pure performance improvement.  If problems occur,\nthen the client can just switch back to uncompressed mode for that block.\n\nYou should look into the block relay system.  This gives a larger\nimprovement than simply compressing the stream.  The main benefit is\nlatency but it means that actual blocks don't have to be sent, so gives a\npotential 50% compression ratio.  Normally, a node receives all the\ntransactions and then those transactions are included later in the block.\n\n\n\nOn Tue, Nov 10, 2015 at 5:40 AM, Johnathan Corgan via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Mon, Nov 9, 2015 at 5:58 PM, gladoscc via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>\n>> I think 25% bandwidth savings is certainly considerable, especially for\n>> people running full nodes in countries like Australia where internet\n>> bandwidth is lower and there are data caps.\n>>\n>\n> \u200bThis reinforces the idea that such trade-off decisions should be be local\n> and negotiated between peers, not a required feature of the network P2P.\u200b\n>\n>\n> --\n> Johnathan Corgan\n> Corgan Labs - SDR Training and Development Services\n> http://corganlabs.com\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151110/81ba0c7c/attachment-0001.html>"
            },
            {
                "author": "Peter Tschipper",
                "date": "2015-11-10T16:17:40",
                "message_text_only": "On 10/11/2015 8:11 AM, Peter Tschipper wrote:\n> On 10/11/2015 1:44 AM, Tier Nolan via bitcoin-dev wrote:\n>> The network protocol is not quite consensus critical, but it is\n>> important.\n>>\n>> Two implementations of the decompressor might not be bug for bug\n>> compatible.  This (potentially) means that a block could be designed\n>> that won't decode properly for some version of the client but would\n>> work for another.  This would fork the network.\n>>\n>> A \"raw\" network library is unlikely to have the same problem.\n>>\n>> Rather than just compress the stream, you could compress only block\n>> messages only.  A new \"cblock\" message could be created that is a\n>> compressed block.  This shouldn't reduce efficiency by much.\n>>\n> I chose the more generic datastream compression so we could in the\n> future apply to possibly to transactions but currently all that is\n> planned, is to compress blocks, and that was really my only original\n> intent until I saw that there might be some bandwidth savings for\n> transactions as well. \n>\n> The compression  however could be applied to any datastream but is not\n> *forced* .  Basically it would just be a method call in CDatastream so\n> we could do ss.compress and ss.decompress and apply that to blocks and\n> possibly transactions if worthwhile and only IF compression is turned\n> on.  But there is no intend to apply this to every type of message\n> since most would be too small to benefit from compression.\n>\n> Here are some results of using the code in the PR to\n> compress/decompress blocks using zlib compression level = 6.  This\n> data was taken from the first 275K blocks in the mainnet blockchain. \n> Clearly once we get past 10KB we get pretty decent compression but\n> even below that there is some benefit.  I'm still collecting data and\n> will get the same for the whole blockchain.\n>\n> range = block size range\n> ubytes = average size of uncompressed blocks\n> cbytes = average size of compressed blocks\n> ctime = average time to compress\n> dtime = average time to decompress\n> cmp_ratio% = compression ratio\n> datapoints = number of datapoints taken\n>\n> range       ubytes    cbytes    ctime    dtime    cmp_ratio%    datapoints\n> 0-250b      215         189    0.001    0.000    12.41            79498\n> 250-500b    440         405    0.001    0.000    7.82            11903\n> 500-1KB     762         702    0.001    0.000    7.83            10448\n> 1KB-10KB    4166    3561    0.001    0.000    14.51            50572\n> 10KB-100KB  40820    31597    0.005    0.001    22.59            75555\n> 100KB-200KB 146238    106320    0.015    0.001    27.30            25024\n> 200KB-300KB 242913    175482    0.025    0.002    27.76            20450\n> 300KB-400KB 343430    251760    0.034    0.003    26.69            2069\n> 400KB-500KB 457448    343495    0.045    0.004    24.91            1889\n> 500KB-600KB 540736    424255    0.056    0.007    21.54            90\n> 600KB-700KB 647851    506888    0.063    0.007    21.76            59\n> 700KB-800KB 749513    586551    0.073    0.007    21.74            48\n> 800KB-900KB 859439    652166    0.086    0.008    24.12            39\n> 900KB-1MB   952333    725191    0.089    0.009    23.85            78\n>\n>> If a client fails to decode a cblock, then it can ask for the block\n>> to be re-sent as a standard \"block\" message. \n> interesting idea.\n>>\n>> This means that it is a pure performance improvement.  If problems\n>> occur, then the client can just switch back to uncompressed mode for\n>> that block.\n>>\n>> You should look into the block relay system.  This gives a larger\n>> improvement than simply compressing the stream.  The main benefit is\n>> latency but it means that actual blocks don't have to be sent, so\n>> gives a potential 50% compression ratio.  Normally, a node receives\n>> all the transactions and then those transactions are included later\n>> in the block.\n>>\n> There are better ways of sending new blocks, that's certainly true but\n> for sending historical blocks and seding transactions I don't think\n> so.  This PR is really designed to save bandwidth and not intended to\n> be a huge performance improvement in terms of time spent sending.\n>>\n>> On Tue, Nov 10, 2015 at 5:40 AM, Johnathan Corgan via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>     On Mon, Nov 9, 2015 at 5:58 PM, gladoscc via bitcoin-dev\n>>     <bitcoin-dev at lists.linuxfoundation.org\n>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>      \n>>\n>>         I think 25% bandwidth savings is certainly considerable,\n>>         especially for people running full nodes in countries like\n>>         Australia where internet bandwidth is lower and there are\n>>         data caps.\n>>\n>>\n>>     \u200bThis reinforces the idea that such trade-off decisions should be\n>>     be local and negotiated between peers, not a required feature of\n>>     the network P2P.\u200b\n>>      \n>>\n>>     -- \n>>     Johnathan Corgan\n>>     Corgan Labs - SDR Training and Development Services\n>>     http://corganlabs.com\n>>\n>>     _______________________________________________\n>>     bitcoin-dev mailing list\n>>     bitcoin-dev at lists.linuxfoundation.org\n>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151110/a9fefde7/attachment.html>"
            },
            {
                "author": "Jonathan Toomim",
                "date": "2015-11-10T16:21:56",
                "message_text_only": "Quick observation: block transmission would be compress-once, send-multiple-times, which makes the tradeoff a little better.\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 496 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151110/2af4a58c/attachment.sig>"
            },
            {
                "author": "Tier Nolan",
                "date": "2015-11-10T16:30:57",
                "message_text_only": "On Tue, Nov 10, 2015 at 4:11 PM, Peter Tschipper <peter.tschipper at gmail.com>\nwrote:\n\n> There are better ways of sending new blocks, that's certainly true but for\n> sending historical blocks and seding transactions I don't think so.  This\n> PR is really designed to save bandwidth and not intended to be a huge\n> performance improvement in terms of time spent sending.\n>\n\nIf the main point is for historical data, then sticking to just blocks is\nthe best plan.\n\nSince small blocks don't compress well, you could define a \"cblocks\"\nmessage that handles multiple blocks (just concatenate the block messages\nas payload before compression).\n\nThe sending peer could combine blocks so that each cblock is compressing at\nleast 10kB of block data (or whatever is optimal).  It is probably worth\nspecifying a maximum size for network buffer reasons (either 1MB or 1 block\nmaximum).\n\nSimilarly, transactions could be combined together and compressed \"ctxs\".\nThe inv messages could be modified so that you can request groups of 10-20\ntransactions.  That would depend on how much of an improvement compressed\ntransactions would represent.\n\nMore generally, you could define a message which is a compressed message\nholder.  That is probably to complex to be worth the effort though.\n\n\n\n>\n> On Tue, Nov 10, 2015 at 5:40 AM, Johnathan Corgan via bitcoin-dev <\n> <bitcoin-dev at lists.linuxfoundation.org>\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> On Mon, Nov 9, 2015 at 5:58 PM, gladoscc via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>\n>>> I think 25% bandwidth savings is certainly considerable, especially for\n>>> people running full nodes in countries like Australia where internet\n>>> bandwidth is lower and there are data caps.\n>>>\n>>\n>> \u200bThis reinforces the idea that such trade-off decisions should be be\n>> local and negotiated between peers, not a required feature of the network\n>> P2P.\u200b\n>>\n>>\n>> --\n>> Johnathan Corgan\n>> Corgan Labs - SDR Training and Development Services\n>> http://corganlabs.com\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing listbitcoin-dev at lists.linuxfoundation.orghttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151110/77204283/attachment-0001.html>"
            },
            {
                "author": "Jeff Garzik",
                "date": "2015-11-10T16:46:15",
                "message_text_only": "Comments:\n\n1) cblock seems a reasonable way to extend the protocol.  Further wrapping\nshould probably be done at the stream level.\n\n2) zlib has crappy security track record.\n\n3) A fallback path to non-compressed is required, should compression fail\nor crash.\n\n4) Most blocks and transactions have runs of zeroes and/or highly common\nbit-patterns, which contributes to useful compression even at smaller\nsizes.  Peter Ts's most recent numbers bear this out.  zlib has a\ndictionary (32K?) which works well with repeated patterns such as those you\nsee with concatenated runs of transactions.\n\n5) LZO should provide much better compression, at a cost of CPU performance\nand using a less-reviewed, less-field-tested library.\n\n\n\n\n\nOn Tue, Nov 10, 2015 at 11:30 AM, Tier Nolan via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n>\n> On Tue, Nov 10, 2015 at 4:11 PM, Peter Tschipper <\n> peter.tschipper at gmail.com> wrote:\n>\n>> There are better ways of sending new blocks, that's certainly true but\n>> for sending historical blocks and seding transactions I don't think so.\n>> This PR is really designed to save bandwidth and not intended to be a huge\n>> performance improvement in terms of time spent sending.\n>>\n>\n> If the main point is for historical data, then sticking to just blocks is\n> the best plan.\n>\n> Since small blocks don't compress well, you could define a \"cblocks\"\n> message that handles multiple blocks (just concatenate the block messages\n> as payload before compression).\n>\n> The sending peer could combine blocks so that each cblock is compressing\n> at least 10kB of block data (or whatever is optimal).  It is probably worth\n> specifying a maximum size for network buffer reasons (either 1MB or 1 block\n> maximum).\n>\n> Similarly, transactions could be combined together and compressed \"ctxs\".\n> The inv messages could be modified so that you can request groups of 10-20\n> transactions.  That would depend on how much of an improvement compressed\n> transactions would represent.\n>\n> More generally, you could define a message which is a compressed message\n> holder.  That is probably to complex to be worth the effort though.\n>\n>\n>\n>>\n>> On Tue, Nov 10, 2015 at 5:40 AM, Johnathan Corgan via bitcoin-dev <\n>> <bitcoin-dev at lists.linuxfoundation.org>\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> On Mon, Nov 9, 2015 at 5:58 PM, gladoscc via bitcoin-dev <\n>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>\n>>>> I think 25% bandwidth savings is certainly considerable, especially for\n>>>> people running full nodes in countries like Australia where internet\n>>>> bandwidth is lower and there are data caps.\n>>>>\n>>>\n>>> \u200bThis reinforces the idea that such trade-off decisions should be be\n>>> local and negotiated between peers, not a required feature of the network\n>>> P2P.\u200b\n>>>\n>>>\n>>> --\n>>> Johnathan Corgan\n>>> Corgan Labs - SDR Training and Development Services\n>>> http://corganlabs.com\n>>>\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>>\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing listbitcoin-dev at lists.linuxfoundation.orghttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151110/d0474410/attachment.html>"
            },
            {
                "author": "Peter Tschipper",
                "date": "2015-11-10T17:09:06",
                "message_text_only": "On 10/11/2015 8:46 AM, Jeff Garzik via bitcoin-dev wrote:\n> Comments:\n>\n> 1) cblock seems a reasonable way to extend the protocol.  Further\n> wrapping should probably be done at the stream level.\nagreed.\n>\n> 2) zlib has crappy security track record.\n>\nZlib had a bad buffer overflow bug but that was in 2005 and it got a lot\nof press at the time.  It's was fixed in version 1.2.3...we're on 1.2.8\nnow.  I'm not aware of any other current issues with zlib. Do you have a\ncitation?\n\n> 3) A fallback path to non-compressed is required, should compression\n> fail or crash.\nagreed.\n>\n> 4) Most blocks and transactions have runs of zeroes and/or highly\n> common bit-patterns, which contributes to useful compression even at\n> smaller sizes.  Peter Ts's most recent numbers bear this out.  zlib\n> has a dictionary (32K?) which works well with repeated patterns such\n> as those you see with concatenated runs of transactions.\n>\n> 5) LZO should provide much better compression, at a cost of CPU\n> performance and using a less-reviewed, less-field-tested library.\nI don't think LZO will give as good compression here but I will do some\nbenchmarking when I can.\n\n>\n>\n>\n>\n>\n> On Tue, Nov 10, 2015 at 11:30 AM, Tier Nolan via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org\n> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>\n>\n>\n>     On Tue, Nov 10, 2015 at 4:11 PM, Peter Tschipper\n>     <peter.tschipper at gmail.com <mailto:peter.tschipper at gmail.com>> wrote:\n>\n>         There are better ways of sending new blocks, that's certainly\n>         true but for sending historical blocks and seding transactions\n>         I don't think so.  This PR is really designed to save\n>         bandwidth and not intended to be a huge performance\n>         improvement in terms of time spent sending.\n>\n>\n>     If the main point is for historical data, then sticking to just\n>     blocks is the best plan.\n>\n>     Since small blocks don't compress well, you could define a\n>     \"cblocks\" message that handles multiple blocks (just concatenate\n>     the block messages as payload before compression). \n>\n>     The sending peer could combine blocks so that each cblock is\n>     compressing at least 10kB of block data (or whatever is optimal). \n>     It is probably worth specifying a maximum size for network buffer\n>     reasons (either 1MB or 1 block maximum).\n>\n>     Similarly, transactions could be combined together and compressed\n>     \"ctxs\".  The inv messages could be modified so that you can\n>     request groups of 10-20 transactions.  That would depend on how\n>     much of an improvement compressed transactions would represent.\n>\n>     More generally, you could define a message which is a compressed\n>     message holder.  That is probably to complex to be worth the\n>     effort though.\n>\n>      \n>\n>>\n>>         On Tue, Nov 10, 2015 at 5:40 AM, Johnathan Corgan via\n>>         bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org\n>>         <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>\n>>             On Mon, Nov 9, 2015 at 5:58 PM, gladoscc via bitcoin-dev\n>>             <bitcoin-dev at lists.linuxfoundation.org\n>>             <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>              \n>>\n>>                 I think 25% bandwidth savings is certainly\n>>                 considerable, especially for people running full\n>>                 nodes in countries like Australia where internet\n>>                 bandwidth is lower and there are data caps.\n>>\n>>\n>>             \u200b This reinforces the idea that such trade-off decisions\n>>             should be be local and negotiated between peers, not a\n>>             required feature of the network P2P.\u200b\n>>              \n>>\n>>             -- \n>>             Johnathan Corgan\n>>             Corgan Labs - SDR Training and Development Services\n>>             http://corganlabs.com\n>>\n>>             _______________________________________________\n>>             bitcoin-dev mailing list\n>>             bitcoin-dev at lists.linuxfoundation.org\n>>             <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>             https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>>\n>>\n>>         _______________________________________________\n>>         bitcoin-dev mailing list\n>>         bitcoin-dev at lists.linuxfoundation.org\n>>         <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n>     _______________________________________________\n>     bitcoin-dev mailing list\n>     bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151110/1688b581/attachment.html>"
            },
            {
                "author": "Peter Tschipper",
                "date": "2015-11-11T18:35:01",
                "message_text_only": "Here are the latest results on compression ratios for the first 295,000\nblocks, compressionlevel=6.  I think there are more than enough\ndatapoints for statistical significance. \n\nResults are very much similar to the previous test.   I'll work on\ngetting a comparison between how much time savings/loss in time there is\nwhen syncing the blockchains: compressed vs uncompressed.  Still, I\nthink it's clear that serving up compressed blocks, at least historical\nblocks, will be of benefit for those that have bandwidth caps on their\ninternet connections.\n\nThe proposal, so far is fairly simple:\n1) compress blocks with some compression library: currently zlib but I\ncan investigate other possiblities\n2) As a fall back we need to advertise compression as a service.  That\nway we can turn off compression AND decompression completely if needed.\n3) Do the compression at the datastream level in the code.  CDataStream\nis the obvious place.\n\n\nTest Results:\n\nrange = block size range\nubytes = average size of uncompressed blocks\ncbytes = average size of compressed blocks\nctime = average time to compress\ndtime = average time to decompress\ncmp_ratio% = compression ratio\ndatapoints = number of datapoints taken\n\nrange       ubytes    cbytes    ctime    dtime    cmp_ratio%    datapoints\n0-250b      215            189    0.001    0.000    12.40             91280\n250-500b    438            404    0.001    0.000    7.85             13217\n500-1KB     761            701    0.001    0.000    7.86               11434\n1KB-10KB    4149    3547    0.001    0.000      14.51             52180\n10KB-100KB  41934    32604    0.005    0.001    22.25         82890\n100KB-200KB 146303    108080    0.016    0.001    26.13    29886\n200KB-300KB 243299    179281    0.025    0.002    26.31    25066\n300KB-400KB 344636    266177    0.036    0.003    22.77    4956\n400KB-500KB 463201    356862    0.046    0.004    22.96    3167\n500KB-600KB 545123    429854    0.056    0.005    21.15    366\n600KB-700KB 647736    510931    0.065    0.006    21.12    254\n700KB-800KB 746540    587287    0.073    0.008    21.33    294\n800KB-900KB 868121    682650    0.087    0.008    21.36    199\n900KB-1MB   945747    726307    0.091    0.010    23.20    304\n\nOn 10/11/2015 8:46 AM, Jeff Garzik via bitcoin-dev wrote:\n> Comments:\n>\n> 1) cblock seems a reasonable way to extend the protocol.  Further\n> wrapping should probably be done at the stream level.\n>\n> 2) zlib has crappy security track record.\n>\n> 3) A fallback path to non-compressed is required, should compression\n> fail or crash.\n>\n> 4) Most blocks and transactions have runs of zeroes and/or highly\n> common bit-patterns, which contributes to useful compression even at\n> smaller sizes.  Peter Ts's most recent numbers bear this out.  zlib\n> has a dictionary (32K?) which works well with repeated patterns such\n> as those you see with concatenated runs of transactions.\n>\n> 5) LZO should provide much better compression, at a cost of CPU\n> performance and using a less-reviewed, less-field-tested library.\n>\n>\n>\n>\n>\n> On Tue, Nov 10, 2015 at 11:30 AM, Tier Nolan via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org\n> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>\n>\n>\n>     On Tue, Nov 10, 2015 at 4:11 PM, Peter Tschipper\n>     <peter.tschipper at gmail.com <mailto:peter.tschipper at gmail.com>> wrote:\n>\n>         There are better ways of sending new blocks, that's certainly\n>         true but for sending historical blocks and seding transactions\n>         I don't think so.  This PR is really designed to save\n>         bandwidth and not intended to be a huge performance\n>         improvement in terms of time spent sending.\n>\n>\n>     If the main point is for historical data, then sticking to just\n>     blocks is the best plan.\n>\n>     Since small blocks don't compress well, you could define a\n>     \"cblocks\" message that handles multiple blocks (just concatenate\n>     the block messages as payload before compression). \n>\n>     The sending peer could combine blocks so that each cblock is\n>     compressing at least 10kB of block data (or whatever is optimal). \n>     It is probably worth specifying a maximum size for network buffer\n>     reasons (either 1MB or 1 block maximum).\n>\n>     Similarly, transactions could be combined together and compressed\n>     \"ctxs\".  The inv messages could be modified so that you can\n>     request groups of 10-20 transactions.  That would depend on how\n>     much of an improvement compressed transactions would represent.\n>\n>     More generally, you could define a message which is a compressed\n>     message holder.  That is probably to complex to be worth the\n>     effort though.\n>\n>      \n>\n>>\n>>         On Tue, Nov 10, 2015 at 5:40 AM, Johnathan Corgan via\n>>         bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org\n>>         <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>\n>>             On Mon, Nov 9, 2015 at 5:58 PM, gladoscc via bitcoin-dev\n>>             <bitcoin-dev at lists.linuxfoundation.org\n>>             <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>              \n>>\n>>                 I think 25% bandwidth savings is certainly\n>>                 considerable, especially for people running full\n>>                 nodes in countries like Australia where internet\n>>                 bandwidth is lower and there are data caps.\n>>\n>>\n>>             \u200b This reinforces the idea that such trade-off decisions\n>>             should be be local and negotiated between peers, not a\n>>             required feature of the network P2P.\u200b\n>>              \n>>\n>>             -- \n>>             Johnathan Corgan\n>>             Corgan Labs - SDR Training and Development Services\n>>             http://corganlabs.com\n>>\n>>             _______________________________________________\n>>             bitcoin-dev mailing list\n>>             bitcoin-dev at lists.linuxfoundation.org\n>>             <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>             https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>>\n>>\n>>         _______________________________________________\n>>         bitcoin-dev mailing list\n>>         bitcoin-dev at lists.linuxfoundation.org\n>>         <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n>     _______________________________________________\n>     bitcoin-dev mailing list\n>     bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151111/b008e0c1/attachment.html>"
            },
            {
                "author": "Marco Pontello",
                "date": "2015-11-11T18:49:49",
                "message_text_only": "A random thought: aren't most communication over a data link already\ncompressed, at some point?\nWhen I used a modem, we had the V.42bis protocol. Now, nearly all ADSL\nconnections using PPPoE, surely are. And so on.\nI'm not sure another level of generic, data agnostic kind of compression\nwill really give us some real-life practical advantage over that.\n\nSomething that could take advantage of of special knowledge of the specific\ndata, instead, would be an entirely different matter.\n\nJust my 2c.\n\nOn Wed, Nov 11, 2015 at 7:35 PM, Peter Tschipper via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Here are the latest results on compression ratios for the first 295,000\n> blocks, compressionlevel=6.  I think there are more than enough datapoints\n> for statistical significance.\n>\n> Results are very much similar to the previous test.   I'll work on getting\n> a comparison between how much time savings/loss in time there is when\n> syncing the blockchains: compressed vs uncompressed.  Still, I think it's\n> clear that serving up compressed blocks, at least historical blocks, will\n> be of benefit for those that have bandwidth caps on their internet\n> connections.\n>\n> The proposal, so far is fairly simple:\n> 1) compress blocks with some compression library: currently zlib but I can\n> investigate other possiblities\n> 2) As a fall back we need to advertise compression as a service.  That way\n> we can turn off compression AND decompression completely if needed.\n> 3) Do the compression at the datastream level in the code.  CDataStream is\n> the obvious place.\n>\n>\n> Test Results:\n>\n> range = block size range\n> ubytes = average size of uncompressed blocks\n> cbytes = average size of compressed blocks\n> ctime = average time to compress\n> dtime = average time to decompress\n> cmp_ratio% = compression ratio\n> datapoints = number of datapoints taken\n>\n> range       ubytes    cbytes    ctime    dtime    cmp_ratio%    datapoints\n> 0-250b      215            189    0.001    0.000    12.40             91280\n> 250-500b    438            404    0.001    0.000    7.85             13217\n> 500-1KB     761            701    0.001    0.000    7.86\n> 11434\n> 1KB-10KB    4149    3547    0.001    0.000      14.51             52180\n> 10KB-100KB  41934    32604    0.005    0.001    22.25         82890\n> 100KB-200KB 146303    108080    0.016    0.001    26.13    29886\n> 200KB-300KB 243299    179281    0.025    0.002    26.31    25066\n> 300KB-400KB 344636    266177    0.036    0.003    22.77    4956\n> 400KB-500KB 463201    356862    0.046    0.004    22.96    3167\n> 500KB-600KB 545123    429854    0.056    0.005    21.15    366\n> 600KB-700KB 647736    510931    0.065    0.006    21.12    254\n> 700KB-800KB 746540    587287    0.073    0.008    21.33    294\n> 800KB-900KB 868121    682650    0.087    0.008    21.36    199\n> 900KB-1MB   945747    726307    0.091    0.010    23.20    304\n>\n> On 10/11/2015 8:46 AM, Jeff Garzik via bitcoin-dev wrote:\n>\n> Comments:\n>\n> 1) cblock seems a reasonable way to extend the protocol.  Further wrapping\n> should probably be done at the stream level.\n>\n> 2) zlib has crappy security track record.\n>\n> 3) A fallback path to non-compressed is required, should compression fail\n> or crash.\n>\n> 4) Most blocks and transactions have runs of zeroes and/or highly common\n> bit-patterns, which contributes to useful compression even at smaller\n> sizes.  Peter Ts's most recent numbers bear this out.  zlib has a\n> dictionary (32K?) which works well with repeated patterns such as those you\n> see with concatenated runs of transactions.\n>\n> 5) LZO should provide much better compression, at a cost of CPU\n> performance and using a less-reviewed, less-field-tested library.\n>\n>\n>\n>\n>\n> On Tue, Nov 10, 2015 at 11:30 AM, Tier Nolan via bitcoin-dev <\n> <bitcoin-dev at lists.linuxfoundation.org>\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>>\n>>\n>> On Tue, Nov 10, 2015 at 4:11 PM, Peter Tschipper <\n>> <peter.tschipper at gmail.com>peter.tschipper at gmail.com> wrote:\n>>\n>>> There are better ways of sending new blocks, that's certainly true but\n>>> for sending historical blocks and seding transactions I don't think so.\n>>> This PR is really designed to save bandwidth and not intended to be a huge\n>>> performance improvement in terms of time spent sending.\n>>>\n>>\n>> If the main point is for historical data, then sticking to just blocks is\n>> the best plan.\n>>\n>> Since small blocks don't compress well, you could define a \"cblocks\"\n>> message that handles multiple blocks (just concatenate the block messages\n>> as payload before compression).\n>>\n>> The sending peer could combine blocks so that each cblock is compressing\n>> at least 10kB of block data (or whatever is optimal).  It is probably worth\n>> specifying a maximum size for network buffer reasons (either 1MB or 1 block\n>> maximum).\n>>\n>> Similarly, transactions could be combined together and compressed\n>> \"ctxs\".  The inv messages could be modified so that you can request groups\n>> of 10-20 transactions.  That would depend on how much of an improvement\n>> compressed transactions would represent.\n>>\n>> More generally, you could define a message which is a compressed message\n>> holder.  That is probably to complex to be worth the effort though.\n>>\n>>\n>>\n>>>\n>>> On Tue, Nov 10, 2015 at 5:40 AM, Johnathan Corgan via bitcoin-dev <\n>>> <bitcoin-dev at lists.linuxfoundation.org>\n>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> On Mon, Nov 9, 2015 at 5:58 PM, gladoscc via bitcoin-dev <\n>>>> <bitcoin-dev at lists.linuxfoundation.org>\n>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>\n>>>>\n>>>>> I think 25% bandwidth savings is certainly considerable, especially\n>>>>> for people running full nodes in countries like Australia where internet\n>>>>> bandwidth is lower and there are data caps.\n>>>>>\n>>>>\n>>>> \u200b This reinforces the idea that such trade-off decisions should be be\n>>>> local and negotiated between peers, not a required feature of the network\n>>>> P2P.\u200b\n>>>>\n>>>>\n>>>> --\n>>>> Johnathan Corgan\n>>>> Corgan Labs - SDR Training and Development Services\n>>>> <http://corganlabs.com>http://corganlabs.com\n>>>>\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>\n>>>>\n>>>\n>>>\n>>> _______________________________________________\n>>> bitcoin-dev mailing listbitcoin-dev at lists.linuxfoundation.orghttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>>\n>>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing listbitcoin-dev at lists.linuxfoundation.orghttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n\n\n-- \nTry the Online TrID File Identifier\nhttp://mark0.net/onlinetrid.aspx\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151111/0430cab2/attachment-0001.html>"
            },
            {
                "author": "Jonathan Toomim",
                "date": "2015-11-11T19:05:29",
                "message_text_only": "Data compression adds latency and reduces predictability, so engineers have decided to leave compression to application layers instead of transport layer or lower in order to let the application designer decide what tradeoffs to make.\n\nOn Nov 11, 2015, at 10:49 AM, Marco Pontello via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> A random thought: aren't most communication over a data link already compressed, at some point?\n> When I used a modem, we had the V.42bis protocol. Now, nearly all ADSL connections using PPPoE, surely are. And so on.\n> I'm not sure another level of generic, data agnostic kind of compression will really give us some real-life practical advantage over that.\n> \n> Something that could take advantage of of special knowledge of the specific data, instead, would be an entirely different matter.\n> \n> Just my 2c.\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 496 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151111/a0171c49/attachment.sig>"
            },
            {
                "author": "Peter Tschipper",
                "date": "2015-11-11T19:11:13",
                "message_text_only": "If that were true then we wouldn't need to gzip large files before\nsending them over the internet.  Data compression generally helps\ntransmission speed as long as the amount of compression is high enough\nand the time it takes is low enough to make it worthwhile.  On a\ncorporate LAN it's generally not worthwhile unless you're dealing with\nvery large files, but over a corporate WAN or the internet where network\nlatency can be high it is IMO a worthwhile endevor.\n\n\n\nOn 11/11/2015 10:49 AM, Marco Pontello wrote:\n> A random thought: aren't most communication over a data link already\n> compressed, at some point?\n> When I used a modem, we had the V.42bis protocol. Now, nearly all ADSL\n> connections using PPPoE, surely are. And so on.\n> I'm not sure another level of generic, data agnostic kind of\n> compression will really give us some real-life practical advantage\n> over that.\n>\n> Something that could take advantage of of special knowledge of the\n> specific data, instead, would be an entirely different matter.\n>\n> Just my 2c.\n>\n> On Wed, Nov 11, 2015 at 7:35 PM, Peter Tschipper via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org\n> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>\n>     Here are the latest results on compression ratios for the first\n>     295,000 blocks, compressionlevel=6.  I think there are more than\n>     enough datapoints for statistical significance. \n>\n>     Results are very much similar to the previous test.   I'll work on\n>     getting a comparison between how much time savings/loss in time\n>     there is when syncing the blockchains: compressed vs\n>     uncompressed.  Still, I think it's clear that serving up\n>     compressed blocks, at least historical blocks, will be of benefit\n>     for those that have bandwidth caps on their internet connections.\n>\n>     The proposal, so far is fairly simple:\n>     1) compress blocks with some compression library: currently zlib\n>     but I can investigate other possiblities\n>     2) As a fall back we need to advertise compression as a service. \n>     That way we can turn off compression AND decompression completely\n>     if needed.\n>     3) Do the compression at the datastream level in the code. \n>     CDataStream is the obvious place.\n>\n>\n>     Test Results:\n>\n>     range = block size range\n>     ubytes = average size of uncompressed blocks\n>     cbytes = average size of compressed blocks\n>     ctime = average time to compress\n>     dtime = average time to decompress\n>     cmp_ratio% = compression ratio\n>     datapoints = number of datapoints taken\n>\n>     range       ubytes    cbytes    ctime    dtime    cmp_ratio%   \n>     datapoints\n>     0-250b      215            189    0.001    0.000    12.40        \n>         91280\n>     250-500b    438            404    0.001    0.000    7.85          \n>       13217\n>     500-1KB     761            701    0.001    0.000   \n>     7.86               11434\n>     1KB-10KB    4149    3547    0.001    0.000      14.51            \n>     52180\n>     10KB-100KB  41934    32604    0.005    0.001    22.25         82890\n>     100KB-200KB 146303    108080    0.016    0.001    26.13    29886\n>     200KB-300KB 243299    179281    0.025    0.002    26.31    25066\n>     300KB-400KB 344636    266177    0.036    0.003    22.77    4956\n>     400KB-500KB 463201    356862    0.046    0.004    22.96    3167\n>     500KB-600KB 545123    429854    0.056    0.005    21.15    366\n>     600KB-700KB 647736    510931    0.065    0.006    21.12    254\n>     700KB-800KB 746540    587287    0.073    0.008    21.33    294\n>     800KB-900KB 868121    682650    0.087    0.008    21.36    199\n>     900KB-1MB   945747    726307    0.091    0.010    23.20    304\n>\n>     On 10/11/2015 8:46 AM, Jeff Garzik via bitcoin-dev wrote:\n>>     Comments:\n>>\n>>     1) cblock seems a reasonable way to extend the protocol.  Further\n>>     wrapping should probably be done at the stream level.\n>>\n>>     2) zlib has crappy security track record.\n>>\n>>     3) A fallback path to non-compressed is required, should\n>>     compression fail or crash.\n>>\n>>     4) Most blocks and transactions have runs of zeroes and/or highly\n>>     common bit-patterns, which contributes to useful compression even\n>>     at smaller sizes.  Peter Ts's most recent numbers bear this out.\n>>      zlib has a dictionary (32K?) which works well with repeated\n>>     patterns such as those you see with concatenated runs of\n>>     transactions.\n>>\n>>     5) LZO should provide much better compression, at a cost of CPU\n>>     performance and using a less-reviewed, less-field-tested library.\n>>\n>>\n>>\n>>\n>>\n>>     On Tue, Nov 10, 2015 at 11:30 AM, Tier Nolan via bitcoin-dev\n>>     <bitcoin-dev at lists.linuxfoundation.org\n>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>\n>>\n>>\n>>         On Tue, Nov 10, 2015 at 4:11 PM, Peter Tschipper\n>>         <peter.tschipper at gmail.com\n>>         <mailto:peter.tschipper at gmail.com>> wrote:\n>>\n>>             There are better ways of sending new blocks, that's\n>>             certainly true but for sending historical blocks and\n>>             seding transactions I don't think so.  This PR is really\n>>             designed to save bandwidth and not intended to be a huge\n>>             performance improvement in terms of time spent sending.\n>>\n>>\n>>         If the main point is for historical data, then sticking to\n>>         just blocks is the best plan.\n>>\n>>         Since small blocks don't compress well, you could define a\n>>         \"cblocks\" message that handles multiple blocks (just\n>>         concatenate the block messages as payload before compression). \n>>\n>>         The sending peer could combine blocks so that each cblock is\n>>         compressing at least 10kB of block data (or whatever is\n>>         optimal).  It is probably worth specifying a maximum size for\n>>         network buffer reasons (either 1MB or 1 block maximum).\n>>\n>>         Similarly, transactions could be combined together and\n>>         compressed \"ctxs\".  The inv messages could be modified so\n>>         that you can request groups of 10-20 transactions.  That\n>>         would depend on how much of an improvement compressed\n>>         transactions would represent.\n>>\n>>         More generally, you could define a message which is a\n>>         compressed message holder.  That is probably to complex to be\n>>         worth the effort though.\n>>\n>>          \n>>\n>>>\n>>>             On Tue, Nov 10, 2015 at 5:40 AM, Johnathan Corgan via\n>>>             bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org\n>>>             <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>>\n>>>                 On Mon, Nov 9, 2015 at 5:58 PM, gladoscc via\n>>>                 bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org\n>>>                 <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>>                  \n>>>\n>>>                     I think 25% bandwidth savings is certainly\n>>>                     considerable, especially for people running full\n>>>                     nodes in countries like Australia where internet\n>>>                     bandwidth is lower and there are data caps.\n>>>\n>>>\n>>>                 \u200b This reinforces the idea that such trade-off\n>>>                 decisions should be be local and negotiated between\n>>>                 peers, not a required feature of the network P2P.\u200b\n>>>                  \n>>>\n>>>                 -- \n>>>                 Johnathan Corgan\n>>>                 Corgan Labs - SDR Training and Development Services\n>>>                 http://corganlabs.com\n>>>\n>>>                 _______________________________________________\n>>>                 bitcoin-dev mailing list\n>>>                 bitcoin-dev at lists.linuxfoundation.org\n>>>                 <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>>                 https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>>\n>>>\n>>>\n>>>             _______________________________________________\n>>>             bitcoin-dev mailing list\n>>>             bitcoin-dev at lists.linuxfoundation.org\n>>>             <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>>             https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>>\n>>         _______________________________________________\n>>         bitcoin-dev mailing list\n>>         bitcoin-dev at lists.linuxfoundation.org\n>>         <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>>\n>>\n>>     _______________________________________________\n>>     bitcoin-dev mailing list\n>>     bitcoin-dev at lists.linuxfoundation.org\n>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>     _______________________________________________\n>     bitcoin-dev mailing list\n>     bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n>\n> -- \n> Try the Online TrID File Identifier\n> http://mark0.net/onlinetrid.aspx\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151111/89fce255/attachment-0001.html>"
            },
            {
                "author": "Peter Tschipper",
                "date": "2015-11-10T16:46:54",
                "message_text_only": "On 10/11/2015 8:45 AM, Peter Tschipper wrote:\n> On 10/11/2015 8:30 AM, Tier Nolan via bitcoin-dev wrote:\n>>\n>>\n>> On Tue, Nov 10, 2015 at 4:11 PM, Peter Tschipper\n>> <peter.tschipper at gmail.com> wrote:\n>>\n>>     There are better ways of sending new blocks, that's certainly\n>>     true but for sending historical blocks and seding transactions I\n>>     don't think so.  This PR is really designed to save bandwidth and\n>>     not intended to be a huge performance improvement in terms of\n>>     time spent sending.\n>>\n>>\n>> If the main point is for historical data, then sticking to just\n>> blocks is the best plan.\n>>\n> at the beginning yes.\n>> Since small blocks don't compress well, you could define a \"cblocks\"\n>> message that handles multiple blocks (just concatenate the block\n>> messages as payload before compression). \n>>\n> Small block are rare these days (but plenty of historical block), but\n> still they get a 10% compression, not bad and I think worthwhile and\n> the time it takes to compress small blocks is less that a millisecond\n> so no loss there in time.   But still you have a good point and\n> something worthy of doing after getting compression to work.  I think\n> it's wise to keep it simple at first and build on the success later.\n>> The sending peer could combine blocks so that each cblock is\n>> compressing at least 10kB of block data (or whatever is optimal).  It\n>> is probably worth specifying a maximum size for network buffer\n>> reasons (either 1MB or 1 block maximum).\n> Good idea. Same answer as above.\n>> Similarly, transactions could be combined together and compressed\n>> \"ctxs\".  The inv messages could be modified so that you can request\n>> groups of 10-20 transactions.  That would depend on how much of an\n>> improvement compressed transactions would represent.\n>>\n> Good idea. Same answer as above.\n>> More generally, you could define a message which is a compressed\n>> message holder.  That is probably to complex to be worth the effort\n>> though.\n> That's actually pretty easy to do and part of the plan.  Sending a\n> cmp_block rather than a block makes it all easier to implement.  It's\n> just a matter of doing pnode->pushmessage(\"cmp_block\",\n> compressed_block); and handling the \"cmp_block\" command string at the\n> other end.\n>>\n>>  \n>>\n>>>\n>>>     On Tue, Nov 10, 2015 at 5:40 AM, Johnathan Corgan via\n>>>     bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org\n>>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>>\n>>>         On Mon, Nov 9, 2015 at 5:58 PM, gladoscc via bitcoin-dev\n>>>         <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>          \n>>>\n>>>             I think 25% bandwidth savings is certainly considerable,\n>>>             especially for people running full nodes in countries\n>>>             like Australia where internet bandwidth is lower and\n>>>             there are data caps.\n>>>\n>>>\n>>>         \u200b This reinforces the idea that such trade-off decisions\n>>>         should be be local and negotiated between peers, not a\n>>>         required feature of the network P2P.\u200b\n>>>          \n>>>\n>>>         -- \n>>>         Johnathan Corgan\n>>>         Corgan Labs - SDR Training and Development Services\n>>>         http://corganlabs.com\n>>>\n>>>         _______________________________________________\n>>>         bitcoin-dev mailing list\n>>>         bitcoin-dev at lists.linuxfoundation.org\n>>>         <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>>\n>>>\n>>>\n>>>     _______________________________________________\n>>>     bitcoin-dev mailing list\n>>>     bitcoin-dev at lists.linuxfoundation.org\n>>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151110/1aebeb1f/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "request BIP number for: \"Support for Datastream Compression\"",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeff Garzik",
                "Peter Tschipper",
                "Tier Nolan",
                "Johnathan Corgan",
                "Jonathan Toomim",
                "Bob McElrath",
                "Marco Pontello",
                "gladoscc"
            ],
            "messages_count": 16,
            "total_messages_chars_count": 56558
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Core 0.10.4 release candidate 1 available",
        "thread_messages": [
            {
                "author": "Wladimir J. van der Laan",
                "date": "2015-11-10T14:02:22",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nBinaries for bitcoin Core version 0.10.4rc1 are now available from:\n\n    https://bitcoin.org/bin/bitcoin-core-0.10.4/test/\n\nSource code can be found on github under the signed tag\n\n    https://github.com/bitcoin/bitcoin/tree/v0.10.4rc1\n\nThis is a new minor version release, bringing bug fixes, the BIP65 (CLTV)\nconsensus change, and relay policy preparation for BIP113.\n\nPreliminary release notes for the 0.10.4 release can be found here:\n\n    https://github.com/bitcoin/bitcoin/blob/0.10/doc/release-notes.md\n\nRelease candidates are test versions for releases. When no critical problems\nare found, this release candidate will be tagged as 0.10.4.\n\nPlease report bugs using the issue tracker at github:\n\n    https://github.com/bitcoin/bitcoin/issues\n\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1\n\niQEcBAEBCgAGBQJWQfjkAAoJEHSBCwEjRsmmEPIIAJPrtqsFZ8h9yZ9z4zKyarT7\n1TLdr5Pvd0j5JRtqE6ZlKrHNTNu5QON4vM7Nk/JXIb0kZGSjjMYevBzlWJxkqn7G\nEM9EwmDwInRFgTnYiPG5/L/i0PZkeZn/8GIHZUHeRQ1MPhuy1t7fUmJ3ZXgQmrQp\nimwg5ZKqF6HwHEb89nvxKCsqHEntUxP4uZaWcapWL7nKyDRtXjBuyWwNzceixlpo\nc8cy944V2aXjjFQh4NStfEoxYHMgkcxyRAm9RWOt2v6PfV0l6SuYSaNsSgLWVhuv\nGTsO6CX1gdqNpctEl8g3fkfihhN+eY7A+WBbyj+i//6kQb03xMZiy+CRmUfA31g=\n=xKpy\n-----END PGP SIGNATURE-----"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Core 0.10.4 release candidate 1 available",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Wladimir J. van der Laan"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1272
        }
    },
    {
        "title": "[bitcoin-dev] Block Compression (Datastream Compression) test results using the PR#6973 compression prototype",
        "thread_messages": [
            {
                "author": "Peter Tschipper",
                "date": "2015-11-13T21:58:06",
                "message_text_only": "Some further Block Compression tests results that compare performance\nwhen network latency is added to the mix.\n\nRunning two nodes, windows 7, compressionlevel=6, syncing the first\n200000 blocks from one node to another.  Running on a highspeed wireless\nLAN with no connections to the outside world.\nNetwork latency was added by using Netbalancer to induce the 30ms and\n60ms latencies.\n\n>From the data not only are bandwidth savings seen but also a small\nperformance savings as well.  However, the overall the value in\ncompressing blocks appears to be in terms of saving bandwidth.  \n\nI was also surprised to see that there was no real difference in\nperformance when no latency was present; apparently the time it takes to\ncompress is about equal to the performance savings in such a situation.\n\n\nThe following results compare the tests in terms of how long it takes to\nsync the blockchain, compressed vs uncompressed and with varying latencies.\nuncmp = uncompressed\ncmp = compressed\n\nnum blocks sync'd \tuncmp (secs) \tcmp (secs) \tuncmp 30ms (secs) \tcmp 30ms\n(secs) \tuncmp 60ms (secs) \tcmp 60ms (secs)\n10000 \t264 \t269 \t265 \t257 \t274 \t275\n20000 \t482 \t492 \t479 \t467 \t499 \t497\n30000 \t703 \t717 \t693 \t676 \t724 \t724\n40000 \t918 \t939 \t902 \t886 \t947 \t944\n50000 \t1140 \t1157 \t1114 \t1094 \t1171 \t1167\n60000 \t1362 \t1380 \t1329 \t1310 \t1400 \t1395\n70000 \t1583 \t1597 \t1547 \t1526 \t1637 \t1627\n80000 \t1810 \t1817 \t1767 \t1745 \t1872 \t1862\n90000 \t2031 \t2036 \t1985 \t1958 \t2109 \t2098\n100000 \t2257 \t2260 \t2223 \t2184 \t2385 \t2355\n110000 \t2553 \t2486 \t2478 \t2422 \t2755 \t2696\n120000 \t2800 \t2724 \t2849 \t2771 \t3345 \t3254\n130000 \t3078 \t2994 \t3356 \t3257 \t4125 \t4006\n140000 \t3442 \t3365 \t3979 \t3870 \t5032 \t4904\n150000 \t3803 \t3729 \t4586 \t4464 \t5928 \t5797\n160000 \t4148 \t4075 \t5168 \t5034 \t6801 \t6661\n170000 \t4509 \t4479 \t5768 \t5619 \t7711 \t7557\n180000 \t4947 \t4924 \t6389 \t6227 \t8653 \t8479\n190000 \t5858 \t5855 \t7302 \t7107 \t9768 \t9566\n200000 \t6980 \t6969 \t8469 \t8220 \t10944 \t10724\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151113/885c94a1/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Block Compression (Datastream Compression) test results using the PR#6973 compression prototype",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Peter Tschipper"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2119
        }
    },
    {
        "title": "[bitcoin-dev] More findings: Block Compression (Datastream Compression) test results using the PR#6973 compression prototype",
        "thread_messages": [
            {
                "author": "Peter Tschipper",
                "date": "2015-11-18T14:00:35",
                "message_text_only": "Hi all,\n\nI'm still doing a little more investigation before opening up a formal\nbip PR, but getting close.  Here are some more findings.\n\nAfter moving the compression from main.cpp to streams.h (CDataStream) it\nwas a simple matter to add compression to transactions as well. Results\nas follows:\n\nrange = block size range\nubytes = average size of uncompressed transactions\ncbytes = average size of compressed transactions\ncmp_ratio% = compression ratio\ndatapoints = number of datapoints taken\n\nrange \tubytes \tcbytes \tcmp_ratio% \tdatapoints\n0-250b \t220 \t227 \t-3.16 \t23780\n250-500b \t356 \t354 \t0.68 \t20882\n500-600 \t534 \t505 \t5.29 \t2772\n600-700 \t653 \t608 \t6.95 \t1853\n700-800 \t757 \t649 \t14.22 \t578\n800-900  \t822 \t758 \t7.77 \t661\n900-1KB \t954 \t862 \t9.69 \t906\n1KB-10KB  \t2698 \t2222 \t17.64 \t3370\n10KB-100KB \t15463 \t12092 \t21.8 \t15429\n\n\nA couple of obvious observations.  Transactions don't compress well\nbelow 500 bytes but do very well beyond 1KB where there are a great deal\nof those large spam type transactions.   However, most transactions\nhappen to be in the < 500 byte range.  So the next step was to appy\nbundling, or the creating of a \"blob\" for those smaller transactions, if\nand only if there are multiple tx's in the getdata receive queue for a\npeer.  Doing that yields some very good compression ratios.  Some\nexamples as follows:\n\nThe best one I've seen so far was the following where 175 transactions\nwere bundled into one blob before being compressed.  That yielded a 20%\ncompression ratio, but that doesn't take into account the savings from\nthe unneeded 174 message headers (24 bytes each) as well as 174 TCP\nACK's of 52 bytes each which yields and additional 76*174=13224 bytes,\nmaking the overall bandwidth savings 32%, in this particular case.\n\n*2015-11-18 01:09:09.002061 compressed blob from 79890 to 67426 txcount:175*\n\nTo be sure, this was an extreme example.  Most transaction blobs were in\nthe 2 to 10 transaction range.  Such as the following:\n\n*2015-11-17 21:08:28.469313 compressed blob from 3199 to 2876 txcount:10*\n\nBut even here the savings are 10%, far better than the \"nothing\" we\nwould get without bundling, but add to that the 76 byte * 9 transaction\nsavings and we have a total 20% savings in bandwidth for transactions\nthat otherwise would not be compressible.\n\nThe same bundling was applied to blocks and very good compression ratios\nare seen when sync'ing the blockchain.\n\nOverall the bundling or blobbing of tx's and blocks seems to be a good\nidea for improving bandwith use but also there is a scalability factor\nhere, when the system is busy, transactions are bundled more often,\ncompressed, sent faster, keeping message queue and network chatter to a\nminimum.\n\nI think I have enough information to put together a formal BIP with the\nexception of which compression library to implement.  These tests were\ndone using ZLib but I'll also be running tests in the coming days with\nLZO (Jeff Garzik's suggestion) and perhaps Snappy.  If there are any\nother libraries that people would like me to get results for please let\nme know and I'll pick maybe the top 2 or 3 and get results back to the\ngroup.\n\n\n\nOn 13/11/2015 1:58 PM, Peter Tschipper wrote:\n> Some further Block Compression tests results that compare performance\n> when network latency is added to the mix.\n>\n> Running two nodes, windows 7, compressionlevel=6, syncing the first\n> 200000 blocks from one node to another.  Running on a highspeed\n> wireless LAN with no connections to the outside world.\n> Network latency was added by using Netbalancer to induce the 30ms and\n> 60ms latencies.\n>\n> From the data not only are bandwidth savings seen but also a small\n> performance savings as well.  However, the overall the value in\n> compressing blocks appears to be in terms of saving bandwidth.  \n>\n> I was also surprised to see that there was no real difference in\n> performance when no latency was present; apparently the time it takes\n> to compress is about equal to the performance savings in such a situation.\n>\n>\n> The following results compare the tests in terms of how long it takes\n> to sync the blockchain, compressed vs uncompressed and with varying\n> latencies.\n> uncmp = uncompressed\n> cmp = compressed\n>\n> num blocks sync'd \tuncmp (secs) \tcmp (secs) \tuncmp 30ms (secs) \tcmp\n> 30ms (secs) \tuncmp 60ms (secs) \tcmp 60ms (secs)\n> 10000 \t264 \t269 \t265 \t257 \t274 \t275\n> 20000 \t482 \t492 \t479 \t467 \t499 \t497\n> 30000 \t703 \t717 \t693 \t676 \t724 \t724\n> 40000 \t918 \t939 \t902 \t886 \t947 \t944\n> 50000 \t1140 \t1157 \t1114 \t1094 \t1171 \t1167\n> 60000 \t1362 \t1380 \t1329 \t1310 \t1400 \t1395\n> 70000 \t1583 \t1597 \t1547 \t1526 \t1637 \t1627\n> 80000 \t1810 \t1817 \t1767 \t1745 \t1872 \t1862\n> 90000 \t2031 \t2036 \t1985 \t1958 \t2109 \t2098\n> 100000 \t2257 \t2260 \t2223 \t2184 \t2385 \t2355\n> 110000 \t2553 \t2486 \t2478 \t2422 \t2755 \t2696\n> 120000 \t2800 \t2724 \t2849 \t2771 \t3345 \t3254\n> 130000 \t3078 \t2994 \t3356 \t3257 \t4125 \t4006\n> 140000 \t3442 \t3365 \t3979 \t3870 \t5032 \t4904\n> 150000 \t3803 \t3729 \t4586 \t4464 \t5928 \t5797\n> 160000 \t4148 \t4075 \t5168 \t5034 \t6801 \t6661\n> 170000 \t4509 \t4479 \t5768 \t5619 \t7711 \t7557\n> 180000 \t4947 \t4924 \t6389 \t6227 \t8653 \t8479\n> 190000 \t5858 \t5855 \t7302 \t7107 \t9768 \t9566\n> 200000 \t6980 \t6969 \t8469 \t8220 \t10944 \t10724\n>\n>\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151118/7d8123e1/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "More findings: Block Compression (Datastream Compression) test results using the PR#6973 compression prototype",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Peter Tschipper"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 5380
        }
    },
    {
        "title": "[bitcoin-dev] further test results for : \"Datastream Compression of Blocks and Tx's\"",
        "thread_messages": [
            {
                "author": "Peter Tschipper",
                "date": "2015-11-28T14:48:41",
                "message_text_only": "Hi All,\n\nHere are some final results of testing with the reference implementation\nfor compressing blocks and transactions. This implementation also\nconcatenates blocks and transactions when possible so you'll see data\nsizes in the 1-2MB ranges.\n\nResults below show the time it takes to sync the first part of the\nblockchain, comparing Zlib to the LZOx library.  (LZOf was also tried\nbut wasn't found to be as good as LZOx).  The following shows tests run\nwith and without latency.  With latency on the network, all compression\nlibraries performed much better than without compression.\n\nI don't think it's entirely obvious which is better, Zlib or LZO. \nAlthough I prefer the higher compression of Zlib, overall I would have\nto give the edge to LZO.  With LZO we have the fastest most scalable\noption when at the lowest compression setting which will be a boost in\nperformance for users that want peformance over compression, and then at\nthe high end LZO provides decent compression which approaches Zlib,\n(although at a higher cost) but good for those that want to save more\nbandwidth.\n\nUncompressed 60ms \tZlib-1 (60ms) \tZlib-6 (60ms) \tLZOx-1 (60ms) \tLZOx-999\n(60ms)\n219 \t299 \t296 \t294 \t291\n432 \t568 \t565 \t558 \t548\n652 \t835 \t836 \t819 \t811\n866 \t1106 \t1107 \t1081 \t1071\n1082 \t1372 \t1381 \t1341 \t1333\n1309 \t1644 \t1654 \t1605 \t1600\n1535 \t1917 \t1936 \t1873 \t1875\n1762 \t2191 \t2210 \t2141 \t2141\n1992 \t2463 \t2486 \t2411 \t2411\n2257 \t2748 \t2780 \t2694 \t2697\n2627 \t3034 \t3076 \t2970 \t2983\n3226 \t3416 \t3397 \t3266 \t3302\n4010 \t3983 \t3773 \t3625 \t3703\n4914 \t4503 \t4292 \t4127 \t4287\n5806 \t4928 \t4719 \t4529 \t4821\n6674 \t5249 \t5164 \t4840 \t5314\n7563 \t5603 \t5669 \t5289 \t6002\n8477 \t6054 \t6268 \t5858 \t6638\n9843 \t7085 \t7278 \t6868 \t7679\n11338 \t8215 \t8433 \t8044 \t8795\n\n\n\nThese results from testing on a highspeed wireless LAN (very small latency)\n\nResults in seconds \t\n\t\n\t\n\t\n\t\nNum blocks sync'd \tUncompressed \tZlib-1 \tZlib-6 \tLZOx-1 \tLZOx-999\n10000 \t255 \t232 \t233 \t231 \t257\n20000 \t464 \t414 \t420 \t407 \t453\n30000 \t677 \t594 \t611 \t585 \t650\n40000 \t887 \t782 \t795 \t760 \t849\n50000 \t1099 \t961 \t977 \t933 \t1048\n60000 \t1310 \t1145 \t1167 \t1110 \t1259\n70000 \t1512 \t1330 \t1362 \t1291 \t1470\n80000 \t1714 \t1519 \t1552 \t1469 \t1679\n90000 \t1917 \t1707 \t1747 \t1650 \t1882\n100000 \t2122 \t1905 \t1950 \t1843 \t2111\n110000 \t2333 \t2107 \t2151 \t2038 \t2329\n120000 \t2560 \t2333 \t2376 \t2256 \t2580\n130000 \t2835 \t2656 \t2679 \t2558 \t2921\n140000 \t3274 \t3259 \t3161 \t3051 \t3466\n150000 \t3662 \t3793 \t3547 \t3440 \t3919\n160000 \t4040 \t4172 \t3937 \t3767 \t4416\n170000 \t4425 \t4625 \t4379 \t4215 \t4958\n180000 \t4860 \t5149 \t4895 \t4781 \t5560\n190000 \t5855 \t6160 \t5898 \t5805 \t6557\n200000 \t7004 \t7234 \t7051 \t6983 \t7770\n\n\n\nThe following show the compression ratio acheived for various sizes of\ndata.  Zlib is the clear\nwinner for compressibility, with LZOx-999 coming close but at a cost.\n\nrange \tZlib-1 cmp%\n\tZlib-6 cmp% \tLZOx-1 cmp% \tLZOx-999 cmp%\n0-250b \t12.44 \t12.86 \t10.79 \t14.34\n250-500b  \t19.33 \t12.97 \t10.34 \t11.11\n600-700 \t16.72 \tn/a \t12.91 \t17.25\n700-800 \t6.37 \t7.65 \t4.83 \t8.07\n900-1KB \t6.54 \t6.95 \t5.64 \t7.9\n1KB-10KB \t25.08 \t25.65 \t21.21 \t22.65\n10KB-100KB \t19.77 \t21.57 \t14.37 \t19.02\n100KB-200KB \t21.49 \t23.56 \t15.37 \t21.55\n200KB-300KB \t23.66 \t24.18 \t16.91 \t22.76\n300KB-400KB \t23.4 \t23.7 \t16.5 \t21.38\n400KB-500KB \t24.6 \t24.85 \t17.56 \t22.43\n500KB-600KB \t25.51 \t26.55 \t18.51 \t23.4\n600KB-700KB \t27.25 \t28.41 \t19.91 \t25.46\n700KB-800KB \t27.58 \t29.18 \t20.26 \t27.17\n800KB-900KB \t27 \t29.11 \t20 \t27.4\n900KB-1MB \t28.19 \t29.38 \t21.15 \t26.43\n1MB -2MB \t27.41 \t29.46 \t21.33 \t27.73\n\n\nThe following shows the time in seconds to compress data of various\nsizes.  LZO1x is the\nfastest and as file sizes increase, LZO1x time hardly increases at all. \nIt's interesing\nto note as compression ratios increase LZOx-999 performs much worse than\nZlib.  So LZO is faster\non the low end and slower (5 to 6 times slower) on the high end.\n\nrange \tZlib-1 \tZlib-6 \tLZOx-1 \tLZOx-999 cmp%\n0-250b    \t0.001 \t0 \t0 \t0\n250-500b   \t0 \t0 \t0 \t0.001\n500-1KB     \t0 \t0 \t0 \t0.001\n1KB-10KB    \t0.001 \t0.001 \t0 \t0.002\n10KB-100KB   \t0.004 \t0.006 \t0.001 \t0.017\n100KB-200KB  \t0.012 \t0.017 \t0.002 \t0.054\n200KB-300KB  \t0.018 \t0.024 \t0.003 \t0.087\n300KB-400KB  \t0.022 \t0.03 \t0.003 \t0.121\n400KB-500KB  \t0.027 \t0.037 \t0.004 \t0.151\n500KB-600KB  \t0.031 \t0.044 \t0.004 \t0.184\n600KB-700KB  \t0.035 \t0.051 \t0.006 \t0.211\n700KB-800KB  \t0.039 \t0.057 \t0.006 \t0.243\n800KB-900KB  \t0.045 \t0.064 \t0.006 \t0.27\n900KB-1MB   \t0.049 \t0.072 \t0.006 \t0.307\n\n\nOn 10/11/2015 8:46 AM, Jeff Garzik via bitcoin-dev wrote:\n> Comments:\n>\n> 1) cblock seems a reasonable way to extend the protocol.  Further\n> wrapping should probably be done at the stream level.\n>\n> 2) zlib has crappy security track record.\n>\n> 3) A fallback path to non-compressed is required, should compression\n> fail or crash.\n>\n> 4) Most blocks and transactions have runs of zeroes and/or highly\n> common bit-patterns, which contributes to useful compression even at\n> smaller sizes.  Peter Ts's most recent numbers bear this out.  zlib\n> has a dictionary (32K?) which works well with repeated patterns such\n> as those you see with concatenated runs of transactions.\n>\n> 5) LZO should provide much better compression, at a cost of CPU\n> performance and using a less-reviewed, less-field-tested library.\n>\n>\n>\n>\n>\n> On Tue, Nov 10, 2015 at 11:30 AM, Tier Nolan via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org\n> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>\n>\n>\n>     On Tue, Nov 10, 2015 at 4:11 PM, Peter Tschipper\n>     <peter.tschipper at gmail.com <mailto:peter.tschipper at gmail.com>> wrote:\n>\n>         There are better ways of sending new blocks, that's certainly\n>         true but for sending historical blocks and seding transactions\n>         I don't think so.  This PR is really designed to save\n>         bandwidth and not intended to be a huge performance\n>         improvement in terms of time spent sending.\n>\n>\n>     If the main point is for historical data, then sticking to just\n>     blocks is the best plan.\n>\n>     Since small blocks don't compress well, you could define a\n>     \"cblocks\" message that handles multiple blocks (just concatenate\n>     the block messages as payload before compression). \n>\n>     The sending peer could combine blocks so that each cblock is\n>     compressing at least 10kB of block data (or whatever is optimal). \n>     It is probably worth specifying a maximum size for network buffer\n>     reasons (either 1MB or 1 block maximum).\n>\n>     Similarly, transactions could be combined together and compressed\n>     \"ctxs\".  The inv messages could be modified so that you can\n>     request groups of 10-20 transactions.  That would depend on how\n>     much of an improvement compressed transactions would represent.\n>\n>     More generally, you could define a message which is a compressed\n>     message holder.  That is probably to complex to be worth the\n>     effort though.\n>\n>      \n>\n>>\n>>         On Tue, Nov 10, 2015 at 5:40 AM, Johnathan Corgan via\n>>         bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org\n>>         <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>\n>>             On Mon, Nov 9, 2015 at 5:58 PM, gladoscc via bitcoin-dev\n>>             <bitcoin-dev at lists.linuxfoundation.org\n>>             <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>              \n>>\n>>                 I think 25% bandwidth savings is certainly\n>>                 considerable, especially for people running full\n>>                 nodes in countries like Australia where internet\n>>                 bandwidth is lower and there are data caps.\n>>\n>>\n>>             \u200b This reinforces the idea that such trade-off decisions\n>>             should be be local and negotiated between peers, not a\n>>             required feature of the network P2P.\u200b\n>>              \n>>\n>>             -- \n>>             Johnathan Corgan\n>>             Corgan Labs - SDR Training and Development Services\n>>             http://corganlabs.com\n>>\n>>             _______________________________________________\n>>             bitcoin-dev mailing list\n>>             bitcoin-dev at lists.linuxfoundation.org\n>>             <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>             https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>>\n>>\n>>         _______________________________________________\n>>         bitcoin-dev mailing list\n>>         bitcoin-dev at lists.linuxfoundation.org\n>>         <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n>     _______________________________________________\n>     bitcoin-dev mailing list\n>     bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151128/66db15c2/attachment-0001.html>"
            },
            {
                "author": "Jonathan Toomim",
                "date": "2015-11-29T00:30:20",
                "message_text_only": "It appears you're using the term \"compression ratio\" to mean \"size reduction\". A compression ratio is the ratio (compressed / uncompressed). A 1 kB file compressed with a 10% compression ratio would be 0.1 kB. It seems you're using (1 - compressed/uncompressed), meaning that the compressed file would be 0.9 kB.\n\nOn Nov 28, 2015, at 6:48 AM, Peter Tschipper via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> The following show the compression ratio acheived for various sizes of data.  Zlib is the clear\n> winner for compressibility, with LZOx-999 coming close but at a cost.\n> \n> range\tZlib-1 cmp%\n> Zlib-6 cmp%\tLZOx-1 cmp%\tLZOx-999 cmp%\n> 0-250b\t12.44\t12.86\t10.79\t14.34\n> 250-500b \t19.33\t12.97\t10.34\t11.11\n> \n> \n> \n> \n> \n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151128/7d5fb307/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 496 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151128/7d5fb307/attachment.sig>"
            },
            {
                "author": "Peter Tschipper",
                "date": "2015-11-29T05:15:32",
                "message_text_only": "yes, you're right, it's just the percentage compressed (size reduction)\n\nOn 28/11/2015 4:30 PM, Jonathan Toomim wrote:\n> It appears you're using the term \"compression ratio\" to mean \"size\n> reduction\". A compression ratio is the ratio (compressed /\n> uncompressed). A 1 kB file compressed with a 10% compression ratio\n> would be 0.1 kB. It seems you're using (1 - compressed/uncompressed),\n> meaning that the compressed file would be 0.9 kB.\n>\n> On Nov 28, 2015, at 6:48 AM, Peter Tschipper via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org\n> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>\n>> The following show the compression ratio acheived for various sizes\n>> of data.  Zlib is the clear\n>> winner for compressibility, with LZOx-999 coming close but at a cost.\n>>\n>> range \tZlib-1 cmp%\n>> \tZlib-6 cmp% \tLZOx-1 cmp% \tLZOx-999 cmp%\n>> 0-250b \t12.44 \t12.86 \t10.79 \t14.34\n>> 250-500b  \t19.33 \t12.97 \t10.34 \t11.11\n>>\n>> \t\n>> \t\n>> \t\n>> \t\n>>\n>\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151128/38398a67/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "further test results for : \"Datastream Compression of Blocks and Tx's\"",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jonathan Toomim",
                "Peter Tschipper"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 11540
        }
    },
    {
        "title": "[bitcoin-dev] Proposal - Mandatory Weak Blocks",
        "thread_messages": [
            {
                "author": "David Vorick",
                "date": "2015-11-10T20:37:21",
                "message_text_only": "Prior discussion: http://gnusha.org/bitcoin-wizards/2015-11-09.log\n\nGoal: Increase transaction throughput without increasing miner\ncentralization pressure, and without putting undue burden on full\nvalidating nodes.\n\n'Weak Block': a block which meets a target with a lower difficulty,\ntypically some fraction such as 5%.\n\n'Strong Block': a block that meets the full target. Also called a block.\n\n---\n\nIntroduction:\n\nOne of the key sources of miner centralization is the orphan rate. Miners\nwith 33% hash power are guaranteed to instantly validate 33% of the blocks,\nwhile miners with only 1% hashrate only get this advantage for 1% of the\nblocks. If the average orphan rate on the network is high, miners with\nsignificantly more hashpower will have a substantial advantage over smaller\nminers.\n\nOne of the strongest reasons to keep the block size small is to keep the\norphan rate low. This is to protect smaller miners. Numerous pre-consensus\nschemes have been discussed which attempt to drive the orphan rate down.\nWhen considering these schemes, the adversarial case must be considered as\nwell as the average case.\n\nThe circulation of weak blocks has been discussed as a form of\npreconsensus. Upon finding a weak block, miners circulate the block to the\nother miners, and then when a full block is found, a diff between the weak\nblock and full block can be circulated instead of just the full block. This\ndiff is both quicker to validate and quicker to circulate, resulting in\nsubstantially improved block propagation times and a reduced orphan rate,\nthus reduced miner centralization pressure.\n\nThe adversarial case is not addressed by this scheme. It is still possible\nto find and circulate a large, difficult-to-verify block that slowly\npropagates through the network and drives up the orphan rate for smaller\nminers. A new construction (below) introduces a set of new consensus rules\nwhich protect small miners even from the adversarial case.\n\n---\n\nConstruction:\n\nAfter a block is found, pre-consensus for the next block begins.\nPre-consensus consists of building a chain of weak blocks which meet a\ntarget that has 5% the difficulty of a full block. Each weak block can\nintroduce at most 200kb of new transactions to the weak-block chain. On\naverage, a new weak block will appear every 30 seconds. When the next\nstrong block is found, it must be at the head of a weak block chain and it\nmust itself introduce a maximum of 200kb in transactions new to the\nweak-block chain. The maximum size of a strong block is 16mb, but can be\ncomposed of any number of weak blocks.\n\nExample:\n\n[strong block] -> [weak block - 200kb] -> [weak block - 400kb] -> [strong\nblock - 600kb] -> [weak block - 200kb]...\n\n---\n\nAnalysis:\n\nOn average, weak blocks will be found every 30 seconds and each block will\nbuild on top of 20 weak blocks. The average block size will be 4mb. 80 weak\nblocks are required to construct a block of the maximum size of 16mb, which\nwill probably happen 3 out of every 1000 blocks. The race-size for blocks\nis kept low, and as explained later, adversarial mining is inherently\ndecentivized.\n\nThis construction establishes a 'pre-consensus' that allows miners to do\nfaster validation when a new block is found. Assuming that the miner has\nseen most of the precursor weak blocks, only a few hundred kilobytes of\nvalidation must be performed even when the blocks are multiple megabytes in\nsize. In the usual case, only 100kb of validation needs to be performed.\n\nMore consistent transaction throughput is achieved. Strong blocks that are\nfound in rapid succession are likely to each be small, due to having a\nsmall number of weak blocks that they build on top of. Strong blocks that\nare found a long time after the previous strong block are likely to have\nmany weak blocks that they build on top of.\n\nBetter censorship resistance is achieved. Creating large blocks requires\nbuilding on top of weak blocks. A miner actively trying to censor certain\ntransactions will have to ignore all weak-block chains that contain the\noffensive transaction, and thus will be at a disadvantage due to\nconsistently producing smaller (and less fee-rich) blocks.\n\nAn attacker that is trying to flood the network with intentionally\nslow-validating blocks can no longer easily construct blocks at the maximum\nsize, and instead must create and hide weak blocks which build up to a\nstrong block that has many unseen transactions. Hiding weak blocks has an\nopportunity cost, because in building a chain of weak block is exclusive to\nthe attacker, the attacker is missing out on the opportunity of building on\ntop of the other weak blocks being produced.\n\nCompared to Bitcoin-NG, this construction lacks the vulnerability where a\nsingle, more easily-targeted leader is elected and placed in charge of the\nnext round of consensus.\n\nEveryone has incentive to build on top of the most recent weak block. In\nthe event that the next weak block discovered is also a strong block, the\nfees reaped by the miner will be maximized.\n\nLarger miners appear to have an incentive to withhold weak blocks in an\nattempt to drive smaller miners off of the network. Large miners\nwithholding weak blocks will gain an advantage that amounts to (% chance of\nfinding a weak block) * (% chance of finding the full block) * (average fee\naddition of a weak block) / (average total block reward). Assuming that\nfees make up entire block reward, the advantage for a miner performing a\nwithholding attack is (hashrate^2 * weak block difficulty). For a 50%\nminer, that advantage comes to 1.25%. For a 20% miner, this advantage is\njust 0.2%. There are probably multiple ways to decentivize this behavior,\nthe simplest of which involves directly rewarding miners for announcing\nweak blocks.\n\nThe orphan rate for weak blocks is going to be substantially higher for\nsmaller miner, due to the increased rate of appearance. I do not think that\nthis is going to create any issues, because small miners are still going to\nhave high visibility of the longest weak-block chain, and are still going\nto be able to create blocks that are nearly as full as the blocks created\nby larger miners.\n\nThe more time that passes between mining blocks, the more a block is worth\n(because it will have more weak-blocks, and therefore more transactions).\nHashrate is therefore more valuable when a block has not been found for a\nwhile, and may result in hashrate hopping, where hashrate is disabled or\nclocked-down immediately after a block is found and then clocked-up if a\nblock is not found for a while. This is only a problem while fees from new\ntransactions make up a significant portion of the block reward.\n\n---\n\nConclusion:\n\nA forced-weak-blocks scheme potentially provides a powerful way to reduce\nthe orphan rate, increasing the safety margins on miner centralization\npressure and allowing the overall transaction throughput to be increased as\na result.\n\nAdditional analysis is needed to be certain that there are not new attack\nvectors or mal-aligned incentives that have been introduced.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151110/cb13678f/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Proposal - Mandatory Weak Blocks",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "David Vorick"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 7215
        }
    },
    {
        "title": "[bitcoin-dev] Post-conference hacking in Hong Kong",
        "thread_messages": [
            {
                "author": "Cory Fields",
                "date": "2015-11-12T18:16:03",
                "message_text_only": "Hi all\n\nAs some of you may recall, I tried to throw together a small\ncode-sprint after the Scaling Bitcoin event in Montreal. There were\nseveral problems stemming from the last-minute-ness and some confusion\nabout the scope and goals, but I think it was a good thing overall.\nMost importantly, it pointed out that many devs are interested in\nface-time for technical/code discussions.\n\nFor those of you attending the Hong Kong conference next month, I'd\nlike to invite you to stay an extra day or two and join in on some\nin-person hacking, code-review, and technical discussion.\n\nIf there was one take-away from the Montreal sprint, it was this:\ntrying to stick to a pre-defined set of goals with so many people is\ncounter-productive. The plan was to review a few long-standing Bitcoin\nCore pull-requests in-person in order to knock them out quickly, but I\nthink it was the organic tangents and ad-hoc discussions that proved\nto be more interesting. So let's encourage that!\n\nThe plan:\n\nThanks to Pindar and Cyberport, we have two rooms available the two\ndays after the conference. These will be treated as general meeting\nrooms for technical discussion; anything goes as long as it's\ntechnical and Bitcoin-related. Personally, I'll be bringing my laptop\nand demoing some recent code to others who might be interested (or\nanyone who will listen!). It's also a great opportunity for nascent\ndevs to ask veterans questions questions about development processes,\nhard-to-understand code, etc. Miners are encouraged to come as well,\nfor discussing any technical hurdles or questions that may benefit\nfrom some real-time technical discussion or debugging.\n\nAttendees are encouraged to self-organize and huddle up as necessary.\nTopics are by no means limited to Bitcoin Core, so feel free to\ndiscuss/learn about projects outside of your usual bubble. If you find\nyourself saying \"I'd like to look at that code with you later\" at the\nconference, plan a time to meet and do it! While this isn't associated\nwith Scaling Bitcoin or its organizers, it's obviously meant to\npiggy-back off of the event. If it becomes too chaotic, we may throw\ntogether a sign-up sheet, but the intent is to let things happen\norganically.\n\nWhat it's not:\n\nThis is a venue for technical discussion. It should not be treated as\na place for discussing politics, agendas, plans for world domination,\netc. Let your code speak for you!\n\n\nThe location:\nVideo Conferencing Rooms 2 and 3, Level 3, Core C\nCyberport 3\n100 Cyberport Rd,\nTelegraph Bay,\nHong Kong\n\nRoom 2 seats 20 people around a conference table, room 3 seats 12.\n\nThe time:\nTuesday December 8 at 8:00am - Wednesday December 9 at midnight.\n\nExtras:\nCoffee/tea/water will be provided, but food is not arranged. Likely\nsome herds will form and venture out for food, but we can also order\nin. Wifi/whiteboards provided as well.\n\nSee you all in Hong Kong!\n\nCory"
            }
        ],
        "thread_summary": {
            "title": "Post-conference hacking in Hong Kong",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Cory Fields"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2881
        }
    },
    {
        "title": "[bitcoin-dev] Upcoming Transaction Priority Changes",
        "thread_messages": [
            {
                "author": "Matt Corallo",
                "date": "2015-11-12T19:47:50",
                "message_text_only": "On the IRC meeting today there was a long discussion on how to handle\nthe old \"transaction priority\" stuff in 0.12. Over time the \"transaction\npriority\" stuff has added a huge amount of code and taken a bunch of\notherwise-useful developer effort. There is still some debate about its\nusefulness going forward, but there was general agreement that it will\neither be removed entirely or replaced with something a bit less costly\nto maintain some time around 0.13.\n\nWith the mempool limiting stuff already in git master, high-priority\nrelay is disabled when mempools are full. In addition, there was\nagreement to take the following steps for 0.12:\n\n * Mining code will use starting priority for ease of implementation\n * Default block priority size will be 0\n * Wallet will no longer create 0-fee transactions when mempool limiting\nis in effect.\n\nWhat this means for you is, essentially, be more careful when relying on\npriority to mine your transactions. If mempools are full, your\ntransactions will be increasingly less likely to be relayed and more\nminers may start disabling high-priority block space. Make sure you\nanalyze previous blocks to determine if high-priority mining is still\nenabled and ensure your transactions will be relayed.\n\nMatt"
            },
            {
                "author": "Luke Dashjr",
                "date": "2015-11-12T20:12:28",
                "message_text_only": "On Thursday, November 12, 2015 7:47:50 PM Matt Corallo via bitcoin-dev wrote:\n> With the mempool limiting stuff already in git master, high-priority\n> relay is disabled when mempools are full. In addition, there was\n> agreement to take the following steps for 0.12:\n> \n>  * Mining code will use starting priority for ease of implementation\n\nThis should be optional, at least for 0.12.\n\n>  * Default block priority size will be 0\n\nWe should not be influencing miner policy by changing defaults.\n\nLuke"
            },
            {
                "author": "Chun Wang",
                "date": "2015-11-12T20:20:45",
                "message_text_only": "I doubt changing the default value is useful as casual mining had long\ndead, and pools all have their own customized policies. But I think\nchange the priority size to 0 is the right way to do. The sort by\npriority part in the block is always the best place for spam nowadays.\nI would think about to merge the priority, feerate, and probably\nsigoprate into one number, probably 576 priorities trade for 1 satoshi\nper kb?\n\nOn Fri, Nov 13, 2015 at 4:12 AM, Luke Dashjr via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> On Thursday, November 12, 2015 7:47:50 PM Matt Corallo via bitcoin-dev wrote:\n>> With the mempool limiting stuff already in git master, high-priority\n>> relay is disabled when mempools are full. In addition, there was\n>> agreement to take the following steps for 0.12:\n>>\n>>  * Mining code will use starting priority for ease of implementation\n>\n> This should be optional, at least for 0.12.\n>\n>>  * Default block priority size will be 0\n>\n> We should not be influencing miner policy by changing defaults.\n>\n> Luke\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Luke Dashjr",
                "date": "2015-11-12T20:25:23",
                "message_text_only": "On Thursday, November 12, 2015 8:20:45 PM Chun Wang wrote:\n> The sort by priority part in the block is always the best place for spam\n> nowadays.\n\nWhat are you saying here? Spammers generally can't use the priority space at \nall, and it is a major way for legitimate users to get their transactions \nmined cheaply despite ongoing spam attempts. You're suggesting the exact \nopposite is true?? Please explain.\n\nLuke"
            },
            {
                "author": "James Hilliard",
                "date": "2015-11-12T20:35:05",
                "message_text_only": "The priority space is causing major mempool bloating and GBT latency right\nnow since many of the free transactions aren't getting mined and cleared\nout of the mempool anymore. From my testing setting minrelaytxfee=0.0001 is\nnot enough to prevent the mempool from getting large during a spam attack,\nit is also necessary to set limitfreerelay=0 in order to prevent GBT\nlatency degradation. Without setting limitfreerelay=0 GBT degrades\nsignificantly for every hour bitcoind is running.\n\nOn Thu, Nov 12, 2015 at 2:25 PM, Luke Dashjr via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Thursday, November 12, 2015 8:20:45 PM Chun Wang wrote:\n> > The sort by priority part in the block is always the best place for spam\n> > nowadays.\n>\n> What are you saying here? Spammers generally can't use the priority space\n> at\n> all, and it is a major way for legitimate users to get their transactions\n> mined cheaply despite ongoing spam attempts. You're suggesting the exact\n> opposite is true?? Please explain.\n>\n> Luke\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151112/fa4cfe8d/attachment.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-12T20:43:17",
                "message_text_only": "On Thu, Nov 12, 2015 at 9:12 PM, Luke Dashjr via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> On Thursday, November 12, 2015 7:47:50 PM Matt Corallo via bitcoin-dev wrote:\n>>  * Mining code will use starting priority for ease of implementation\n>\n> This should be optional, at least for 0.12.\n\nThe ease of implementation is not gained if it's maintained optionally.\n\n>>  * Default block priority size will be 0\n>\n> We should not be influencing miner policy by changing defaults.\n\nI agree changing policy defaults is meaningless, but in this case it\nis supposed to signal deprecation of the policy option.\n\nOn Thu, Nov 12, 2015 at 9:20 PM, Chun Wang via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> I would think about to merge the priority, feerate, and probably\n> sigoprate into one number, probably 576 priorities trade for 1 satoshi\n> per kb?\n\nI am in favor of having customizable cost (currently tx size but it\nhas been proposed to also include sigoprate) and reward (currently\nfeerate). The main problem I see for keep maintaining the code is that\npriority is not integrated in the reward function and cannot easily be\nwith its current functionality unchanged (which slows down other very\nnecessary improvements in the mempool limits)."
            },
            {
                "author": "Luke Dashjr",
                "date": "2015-11-12T21:10:45",
                "message_text_only": "On Thursday, November 12, 2015 8:43:17 PM Jorge Tim\u00f3n wrote:\n> On Thu, Nov 12, 2015 at 9:12 PM, Luke Dashjr via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > On Thursday, November 12, 2015 7:47:50 PM Matt Corallo via bitcoin-dev\n> > wrote:\n> >>  * Mining code will use starting priority for ease of implementation\n> > \n> > This should be optional, at least for 0.12.\n> \n> The ease of implementation is not gained if it's maintained optionally.\n\nIt has come to my attention maintaining the current priority algorithm is not \neven expensive, so I think I'm inclined to NACK using starting priority \naltogether. Since I am the mining maintainer for Core, I believe it's \nreasonable for me to decide on maintenance tradeoffs...\n\nTherefore, my goal in this matter will be to review #6357 in depth to be \nmerged, and follow up with #6898 based on the current default policies.\n\n> >>  * Default block priority size will be 0\n> > \n> > We should not be influencing miner policy by changing defaults.\n> \n> I agree changing policy defaults is meaningless, but in this case it\n> is supposed to signal deprecation of the policy option.\n\nThis is a bad idea anyway, since priority is the best metric we have right now \nfor ensuring legitimate transactions get mined despite spam attacks.\n\nLuke"
            },
            {
                "author": "Alex Morcos",
                "date": "2015-11-12T21:21:57",
                "message_text_only": "To be clear Luke, its not THAT complicated to maintain the mining policy,\nbut preserving the ability of people to place priority based transactions\nin a limited mempool world is quite complicated.  See recently closed\n#6992.\nI think the biggest issue with #6357 is being sure the logic doesn't break\nin future changes.  There are a lot of things that need to be updated in\nthe right order when blocks are connected or disconnected.\nAnd whats the point of having even that added extra complication if its not\neasy to place free transactions and starting priority is a decent\napproximation for mining anyway (txs can just be rebroadcast in the worst\ncase).\n\n\nOn Thu, Nov 12, 2015 at 4:10 PM, Luke Dashjr via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Thursday, November 12, 2015 8:43:17 PM Jorge Tim\u00f3n wrote:\n> > On Thu, Nov 12, 2015 at 9:12 PM, Luke Dashjr via bitcoin-dev\n> > <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > > On Thursday, November 12, 2015 7:47:50 PM Matt Corallo via bitcoin-dev\n> > > wrote:\n> > >>  * Mining code will use starting priority for ease of implementation\n> > >\n> > > This should be optional, at least for 0.12.\n> >\n> > The ease of implementation is not gained if it's maintained optionally.\n>\n> It has come to my attention maintaining the current priority algorithm is\n> not\n> even expensive, so I think I'm inclined to NACK using starting priority\n> altogether. Since I am the mining maintainer for Core, I believe it's\n> reasonable for me to decide on maintenance tradeoffs...\n>\n> Therefore, my goal in this matter will be to review #6357 in depth to be\n> merged, and follow up with #6898 based on the current default policies.\n>\n> > >>  * Default block priority size will be 0\n> > >\n> > > We should not be influencing miner policy by changing defaults.\n> >\n> > I agree changing policy defaults is meaningless, but in this case it\n> > is supposed to signal deprecation of the policy option.\n>\n> This is a bad idea anyway, since priority is the best metric we have right\n> now\n> for ensuring legitimate transactions get mined despite spam attacks.\n>\n> Luke\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151112/e994acb0/attachment.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2015-11-12T21:26:38",
                "message_text_only": "On Thursday, November 12, 2015 9:21:57 PM Alex Morcos wrote:\n> To be clear Luke, its not THAT complicated to maintain the mining policy,\n> but preserving the ability of people to place priority based transactions\n> in a limited mempool world is quite complicated.  See recently closed\n> #6992.\n> I think the biggest issue with #6357 is being sure the logic doesn't break\n> in future changes.  There are a lot of things that need to be updated in\n> the right order when blocks are connected or disconnected.\n\nThat's what unit tests are for. :)\n\n> And whats the point of having even that added extra complication if its not\n> easy to place free transactions and starting priority is a decent\n> approximation for mining anyway (txs can just be rebroadcast in the worst\n> case).\n\nI'm not sure what you're getting at here, but rebroadcasting won't work if \nthey're still in the memory pools (unless we open the door to DoS from \nreprocessing the same tx over and over).\n\nLuke"
            }
        ],
        "thread_summary": {
            "title": "Upcoming Transaction Priority Changes",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "James Hilliard",
                "Jorge Tim\u00f3n",
                "Luke Dashjr",
                "Alex Morcos",
                "Matt Corallo",
                "Chun Wang"
            ],
            "messages_count": 9,
            "total_messages_chars_count": 10829
        }
    },
    {
        "title": "[bitcoin-dev] New lower policy limits for unconfirmed transaction chains or packages",
        "thread_messages": [
            {
                "author": "Alex Morcos",
                "date": "2015-11-12T21:44:57",
                "message_text_only": "I just wanted to let everyone know that after much considered review, new\nlower policy limits on the number and size of related unconfirmed\ntransactions that will be accepted in to the mempool and relayed have been\nmerged into the master branch of Bitcoin Core for 0.12 release.\n\nThe actual limits were merged in PR 6771\n<https://github.com/bitcoin/bitcoin/pull/6771> and discussion of these\nlimits can be found in this previous email\n<https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-August/010221.html>\nto the dev list and discussion of the new lower limits here\n<https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-October/011401.html>\n.\n\nThe new limits are:\n25 unconfirmed ancestors\n25 unconfirmed descendants\n101kb total size with unconfirmed ancestors\n101kb total size with unconfirmed descendants.\n\nThese limits are just policy and do not affect consensus.\nThey can be modified by command line arguments.\n\n\nThanks,\nAlex\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151112/90b6a2ad/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "New lower policy limits for unconfirmed transaction chains or packages",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Alex Morcos"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1130
        }
    },
    {
        "title": "[bitcoin-dev] BIP - Block size doubles at each reward halving with max block size of 32M",
        "thread_messages": [
            {
                "author": "John Sacco",
                "date": "2015-11-12T23:47:31",
                "message_text_only": "Hi Devs,\n\n\nPlease consider the draft proposal below for peer review.\n\n\nThanks,\n\n\nJohn\n\n\nBIP\n\n  BIP: ?\n\n  Title: Block size doubles at each reward halving with max block size of\n32M\n\n  Author: John Sacco <johnsock at gmail.com>\n\n  Status: Draft\n\n  Type: Standards Track\n\n  Created: 2015-11-11\n\nAbstract\n\nChange max block size to 2MB at next block subsidy halving, and double the\nblock size at each subsidy halving until reaching 32MB.\n\nCopyright\n\nThis proposal belongs in the public domain. Anyone can use this text for\nany purpose with proper attribution to the author.\n\nMotivation\n\n1.    Gradually restores block size to the default 32 MB setting originally\nimplemented by Satoshi.\n\n2.    Initial increase to 2MB at block halving in July 2016 would have\nminimal impact to existing nodes running on most hardware and networks.\n\n3.    Long term solution that does not make enthusiastic assumptions\nregarding future bandwidth and storage availability estimates.\n\n4.    Maximum block size of 32MB allows peak usage of ~100 tx/sec by year\n2031.\n\n5.    Exercise network upgrade procedure during subsidy reward halving, a\nmilestone event with the goal of increasing awareness among miners and node\noperators.\n\nSpecification\n\n1.    Increase the maximum block size to 2MB when block 630,000 is reached\nand 75% of the last 1,000 blocks have signaled support.\n\n2.    Increase maximum block size to 4MB at block 840,000.\n\n3.    Increase maximum block size to 8MB at block 1,050,000.\n\n4.    Increase maximum block size to 16MB at block 1,260,000.\n\n5.    Increase maximum block size to 32MB at block 1,470,000.\n\nBackward compatibility\n\nAll older clients are not compatible with this change. The first block\nlarger than 1M will create a network partition excluding not-upgraded\nnetwork nodes and miners.\n\nRationale\n\nWhile more comprehensive solutions are developed, an increase to the block\nsize is needed to continue network growth. A longer term solution is needed\nto prevent complications associated with additional hard forks. It should\nalso increase at a gradual rate that retains and allows a large\ndistribution of full nodes.  Scheduling this hard fork to occur no earlier\nthan the subsidy halving in 2016 has the goal of simplifying the\ncommunication outreach needed to achieve consensus, while also providing a\nbuffer of time to make necessary preparations.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151112/c00ed906/attachment-0001.html>"
            },
            {
                "author": "Chun Wang",
                "date": "2015-11-13T02:56:55",
                "message_text_only": "How about these specs:\n* 1 MB, height < 210000;\n* 2 MB, 210000 <= height < 420000;\n* 4 MB, 420000 <= height < 630000;\n* 8 MB, 630000 <= height < 840000;\n* 16 MB, 840000 <= height < 1050000;\n* 32 MB, height >= 1050000.\n\n\nOn Fri, Nov 13, 2015 at 7:47 AM, John Sacco via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Hi Devs,\n>\n>\n> Please consider the draft proposal below for peer review.\n>\n>\n> Thanks,\n>\n>\n> John\n>\n>\n> BIP\n>\n>   BIP: ?\n>\n>   Title: Block size doubles at each reward halving with max block size of\n> 32M\n>\n>   Author: John Sacco <johnsock at gmail.com>\n>\n>   Status: Draft\n>\n>   Type: Standards Track\n>\n>   Created: 2015-11-11\n>\n> Abstract\n>\n> Change max block size to 2MB at next block subsidy halving, and double the\n> block size at each subsidy halving until reaching 32MB.\n>\n> Copyright\n>\n> This proposal belongs in the public domain. Anyone can use this text for any\n> purpose with proper attribution to the author.\n>\n> Motivation\n>\n> 1.    Gradually restores block size to the default 32 MB setting originally\n> implemented by Satoshi.\n>\n> 2.    Initial increase to 2MB at block halving in July 2016 would have\n> minimal impact to existing nodes running on most hardware and networks.\n>\n> 3.    Long term solution that does not make enthusiastic assumptions\n> regarding future bandwidth and storage availability estimates.\n>\n> 4.    Maximum block size of 32MB allows peak usage of ~100 tx/sec by year\n> 2031.\n>\n> 5.    Exercise network upgrade procedure during subsidy reward halving, a\n> milestone event with the goal of increasing awareness among miners and node\n> operators.\n>\n> Specification\n>\n> 1.    Increase the maximum block size to 2MB when block 630,000 is reached\n> and 75% of the last 1,000 blocks have signaled support.\n>\n> 2.    Increase maximum block size to 4MB at block 840,000.\n>\n> 3.    Increase maximum block size to 8MB at block 1,050,000.\n>\n> 4.    Increase maximum block size to 16MB at block 1,260,000.\n>\n> 5.    Increase maximum block size to 32MB at block 1,470,000.\n>\n> Backward compatibility\n>\n> All older clients are not compatible with this change. The first block\n> larger than 1M will create a network partition excluding not-upgraded\n> network nodes and miners.\n>\n> Rationale\n>\n> While more comprehensive solutions are developed, an increase to the block\n> size is needed to continue network growth. A longer term solution is needed\n> to prevent complications associated with additional hard forks. It should\n> also increase at a gradual rate that retains and allows a large distribution\n> of full nodes.  Scheduling this hard fork to occur no earlier than the\n> subsidy halving in 2016 has the goal of simplifying the communication\n> outreach needed to achieve consensus, while also providing a buffer of time\n> to make necessary preparations.\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "John Sacco",
                "date": "2015-11-13T03:37:34",
                "message_text_only": "I like your suggestion for the continuity and it gets us up to 2 MB in the\nshorter term. Also I just noticed the math error.\n\nHere is a revised spec (incorporating suggestions from Chun Wang):\n\nSpecification\n\n* 1 MB, height < 210,000;\n* 2 MB, height 210,000 < 420,000; (when 75% of last 1,000 blocks signal\nsupport)\n* 4 MB, height 420,000 < 630,000; (year 2016)\n* 8 MB, height 630,000 < 840,000; (year ~2020)\n* 16 MB, height 840,000 < 1,050,000; (year ~2024)\n* 32 MB, height >= 1,050,000. (year ~2028)\n\n\nOn Thu, Nov 12, 2015 at 9:56 PM, Chun Wang <1240902 at gmail.com> wrote:\n\n> How about these specs:\n> * 1 MB, height < 210000;\n> * 2 MB, 210000 <= height < 420000;\n> * 4 MB, 420000 <= height < 630000;\n> * 8 MB, 630000 <= height < 840000;\n> * 16 MB, 840000 <= height < 1050000;\n> * 32 MB, height >= 1050000.\n>\n>\n> On Fri, Nov 13, 2015 at 7:47 AM, John Sacco via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > Hi Devs,\n> >\n> >\n> > Please consider the draft proposal below for peer review.\n> >\n> >\n> > Thanks,\n> >\n> >\n> > John\n> >\n> >\n> > BIP\n> >\n> >   BIP: ?\n> >\n> >   Title: Block size doubles at each reward halving with max block size of\n> > 32M\n> >\n> >   Author: John Sacco <johnsock at gmail.com>\n> >\n> >   Status: Draft\n> >\n> >   Type: Standards Track\n> >\n> >   Created: 2015-11-11\n> >\n> > Abstract\n> >\n> > Change max block size to 2MB at next block subsidy halving, and double\n> the\n> > block size at each subsidy halving until reaching 32MB.\n> >\n> > Copyright\n> >\n> > This proposal belongs in the public domain. Anyone can use this text for\n> any\n> > purpose with proper attribution to the author.\n> >\n> > Motivation\n> >\n> > 1.    Gradually restores block size to the default 32 MB setting\n> originally\n> > implemented by Satoshi.\n> >\n> > 2.    Initial increase to 2MB at block halving in July 2016 would have\n> > minimal impact to existing nodes running on most hardware and networks.\n> >\n> > 3.    Long term solution that does not make enthusiastic assumptions\n> > regarding future bandwidth and storage availability estimates.\n> >\n> > 4.    Maximum block size of 32MB allows peak usage of ~100 tx/sec by year\n> > 2031.\n> >\n> > 5.    Exercise network upgrade procedure during subsidy reward halving, a\n> > milestone event with the goal of increasing awareness among miners and\n> node\n> > operators.\n> >\n> > Specification\n> >\n> > 1.    Increase the maximum block size to 2MB when block 630,000 is\n> reached\n> > and 75% of the last 1,000 blocks have signaled support.\n> >\n> > 2.    Increase maximum block size to 4MB at block 840,000.\n> >\n> > 3.    Increase maximum block size to 8MB at block 1,050,000.\n> >\n> > 4.    Increase maximum block size to 16MB at block 1,260,000.\n> >\n> > 5.    Increase maximum block size to 32MB at block 1,470,000.\n> >\n> > Backward compatibility\n> >\n> > All older clients are not compatible with this change. The first block\n> > larger than 1M will create a network partition excluding not-upgraded\n> > network nodes and miners.\n> >\n> > Rationale\n> >\n> > While more comprehensive solutions are developed, an increase to the\n> block\n> > size is needed to continue network growth. A longer term solution is\n> needed\n> > to prevent complications associated with additional hard forks. It should\n> > also increase at a gradual rate that retains and allows a large\n> distribution\n> > of full nodes.  Scheduling this hard fork to occur no earlier than the\n> > subsidy halving in 2016 has the goal of simplifying the communication\n> > outreach needed to achieve consensus, while also providing a buffer of\n> time\n> > to make necessary preparations.\n> >\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151112/4aa7457b/attachment.html>"
            },
            {
                "author": "Btc Drak",
                "date": "2015-11-13T07:49:02",
                "message_text_only": "> * 2 MB, height 210,000 < 420,000; (when 75% of last 1,000 blocks signal\nsupport)\n\nThis doesnt give anyone a chance to upgrade and would cause a hard fork the\nmoment a miner created a >1MB block. Flag day (hard fork) upgrades must\nstart the change at a sufficient time in the future (greater than the\ncurrent block height) to give all nodes the chance to upgrade.\n\nOn Fri, Nov 13, 2015 at 3:37 AM, John Sacco via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I like your suggestion for the continuity and it gets us up to 2 MB in the\n> shorter term. Also I just noticed the math error.\n>\n> Here is a revised spec (incorporating suggestions from Chun Wang):\n>\n> Specification\n>\n> * 1 MB, height < 210,000;\n> * 2 MB, height 210,000 < 420,000; (when 75% of last 1,000 blocks signal\n> support)\n> * 4 MB, height 420,000 < 630,000; (year 2016)\n> * 8 MB, height 630,000 < 840,000; (year ~2020)\n> * 16 MB, height 840,000 < 1,050,000; (year ~2024)\n> * 32 MB, height >= 1,050,000. (year ~2028)\n>\n>\n> On Thu, Nov 12, 2015 at 9:56 PM, Chun Wang <1240902 at gmail.com> wrote:\n>\n>> How about these specs:\n>> * 1 MB, height < 210000;\n>> * 2 MB, 210000 <= height < 420000;\n>> * 4 MB, 420000 <= height < 630000;\n>> * 8 MB, 630000 <= height < 840000;\n>> * 16 MB, 840000 <= height < 1050000;\n>> * 32 MB, height >= 1050000.\n>>\n>>\n>> On Fri, Nov 13, 2015 at 7:47 AM, John Sacco via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> > Hi Devs,\n>> >\n>> >\n>> > Please consider the draft proposal below for peer review.\n>> >\n>> >\n>> > Thanks,\n>> >\n>> >\n>> > John\n>> >\n>> >\n>> > BIP\n>> >\n>> >   BIP: ?\n>> >\n>> >   Title: Block size doubles at each reward halving with max block size\n>> of\n>> > 32M\n>> >\n>> >   Author: John Sacco <johnsock at gmail.com>\n>> >\n>> >   Status: Draft\n>> >\n>> >   Type: Standards Track\n>> >\n>> >   Created: 2015-11-11\n>> >\n>> > Abstract\n>> >\n>> > Change max block size to 2MB at next block subsidy halving, and double\n>> the\n>> > block size at each subsidy halving until reaching 32MB.\n>> >\n>> > Copyright\n>> >\n>> > This proposal belongs in the public domain. Anyone can use this text\n>> for any\n>> > purpose with proper attribution to the author.\n>> >\n>> > Motivation\n>> >\n>> > 1.    Gradually restores block size to the default 32 MB setting\n>> originally\n>> > implemented by Satoshi.\n>> >\n>> > 2.    Initial increase to 2MB at block halving in July 2016 would have\n>> > minimal impact to existing nodes running on most hardware and networks.\n>> >\n>> > 3.    Long term solution that does not make enthusiastic assumptions\n>> > regarding future bandwidth and storage availability estimates.\n>> >\n>> > 4.    Maximum block size of 32MB allows peak usage of ~100 tx/sec by\n>> year\n>> > 2031.\n>> >\n>> > 5.    Exercise network upgrade procedure during subsidy reward halving,\n>> a\n>> > milestone event with the goal of increasing awareness among miners and\n>> node\n>> > operators.\n>> >\n>> > Specification\n>> >\n>> > 1.    Increase the maximum block size to 2MB when block 630,000 is\n>> reached\n>> > and 75% of the last 1,000 blocks have signaled support.\n>> >\n>> > 2.    Increase maximum block size to 4MB at block 840,000.\n>> >\n>> > 3.    Increase maximum block size to 8MB at block 1,050,000.\n>> >\n>> > 4.    Increase maximum block size to 16MB at block 1,260,000.\n>> >\n>> > 5.    Increase maximum block size to 32MB at block 1,470,000.\n>> >\n>> > Backward compatibility\n>> >\n>> > All older clients are not compatible with this change. The first block\n>> > larger than 1M will create a network partition excluding not-upgraded\n>> > network nodes and miners.\n>> >\n>> > Rationale\n>> >\n>> > While more comprehensive solutions are developed, an increase to the\n>> block\n>> > size is needed to continue network growth. A longer term solution is\n>> needed\n>> > to prevent complications associated with additional hard forks. It\n>> should\n>> > also increase at a gradual rate that retains and allows a large\n>> distribution\n>> > of full nodes.  Scheduling this hard fork to occur no earlier than the\n>> > subsidy halving in 2016 has the goal of simplifying the communication\n>> > outreach needed to achieve consensus, while also providing a buffer of\n>> time\n>> > to make necessary preparations.\n>> >\n>> >\n>> > _______________________________________________\n>> > bitcoin-dev mailing list\n>> > bitcoin-dev at lists.linuxfoundation.org\n>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> >\n>>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151113/f716f43a/attachment.html>"
            },
            {
                "author": "John Sacco",
                "date": "2015-11-13T09:50:47",
                "message_text_only": "Revised spec below to put us back at 2 MB at next halving in 2016\n(addressing Luke & Drak's points). This is more in line with intent of the\noriginal proposal and provides sufficient time to gain consensus.\n\nSpecification\n>\n>\n> * 2 MB, height 420,000 < 630,000; (fork active when 75% of last 1,000\nblocks signal support and block 420,000 reached, ~July 2016)\n\n\n* 4 MB, height 630,000 < 840,000; (year ~2020)\n\n\n* 8 MB, height 840,000 < 1,050,000; (year ~2024)\n\n\n* 16 MB, height 1,050,000 < 1,260,000; (year ~2028)\n\n\n* 32 MB, height >= 1,260,000. (year ~2032)\n\n\n\n\nOn Fri, Nov 13, 2015 at 2:49 AM, Btc Drak <btcdrak at gmail.com> wrote:\n\n> > * 2 MB, height 210,000 < 420,000; (when 75% of last 1,000 blocks signal\n> support)\n>\n> This doesnt give anyone a chance to upgrade and would cause a hard fork\n> the moment a miner created a >1MB block. Flag day (hard fork) upgrades must\n> start the change at a sufficient time in the future (greater than the\n> current block height) to give all nodes the chance to upgrade.\n>\n> On Fri, Nov 13, 2015 at 3:37 AM, John Sacco via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> I like your suggestion for the continuity and it gets us up to 2 MB in\n>> the shorter term. Also I just noticed the math error.\n>>\n>> Here is a revised spec (incorporating suggestions from Chun Wang):\n>>\n>> Specification\n>>\n>> * 1 MB, height < 210,000;\n>> * 2 MB, height 210,000 < 420,000; (when 75% of last 1,000 blocks signal\n>> support)\n>> * 4 MB, height 420,000 < 630,000; (year 2016)\n>> * 8 MB, height 630,000 < 840,000; (year ~2020)\n>> * 16 MB, height 840,000 < 1,050,000; (year ~2024)\n>> * 32 MB, height >= 1,050,000. (year ~2028)\n>>\n>>\n>> On Thu, Nov 12, 2015 at 9:56 PM, Chun Wang <1240902 at gmail.com> wrote:\n>>\n>>> How about these specs:\n>>> * 1 MB, height < 210000;\n>>> * 2 MB, 210000 <= height < 420000;\n>>> * 4 MB, 420000 <= height < 630000;\n>>> * 8 MB, 630000 <= height < 840000;\n>>> * 16 MB, 840000 <= height < 1050000;\n>>> * 32 MB, height >= 1050000.\n>>>\n>>>\n>>> On Fri, Nov 13, 2015 at 7:47 AM, John Sacco via bitcoin-dev\n>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> > Hi Devs,\n>>> >\n>>> >\n>>> > Please consider the draft proposal below for peer review.\n>>> >\n>>> >\n>>> > Thanks,\n>>> >\n>>> >\n>>> > John\n>>> >\n>>> >\n>>> > BIP\n>>> >\n>>> >   BIP: ?\n>>> >\n>>> >   Title: Block size doubles at each reward halving with max block size\n>>> of\n>>> > 32M\n>>> >\n>>> >   Author: John Sacco <johnsock at gmail.com>\n>>> >\n>>> >   Status: Draft\n>>> >\n>>> >   Type: Standards Track\n>>> >\n>>> >   Created: 2015-11-11\n>>> >\n>>> > Abstract\n>>> >\n>>> > Change max block size to 2MB at next block subsidy halving, and double\n>>> the\n>>> > block size at each subsidy halving until reaching 32MB.\n>>> >\n>>> > Copyright\n>>> >\n>>> > This proposal belongs in the public domain. Anyone can use this text\n>>> for any\n>>> > purpose with proper attribution to the author.\n>>> >\n>>> > Motivation\n>>> >\n>>> > 1.    Gradually restores block size to the default 32 MB setting\n>>> originally\n>>> > implemented by Satoshi.\n>>> >\n>>> > 2.    Initial increase to 2MB at block halving in July 2016 would have\n>>> > minimal impact to existing nodes running on most hardware and networks.\n>>> >\n>>> > 3.    Long term solution that does not make enthusiastic assumptions\n>>> > regarding future bandwidth and storage availability estimates.\n>>> >\n>>> > 4.    Maximum block size of 32MB allows peak usage of ~100 tx/sec by\n>>> year\n>>> > 2031.\n>>> >\n>>> > 5.    Exercise network upgrade procedure during subsidy reward\n>>> halving, a\n>>> > milestone event with the goal of increasing awareness among miners and\n>>> node\n>>> > operators.\n>>> >\n>>> > Specification\n>>> >\n>>> > 1.    Increase the maximum block size to 2MB when block 630,000 is\n>>> reached\n>>> > and 75% of the last 1,000 blocks have signaled support.\n>>> >\n>>> > 2.    Increase maximum block size to 4MB at block 840,000.\n>>> >\n>>> > 3.    Increase maximum block size to 8MB at block 1,050,000.\n>>> >\n>>> > 4.    Increase maximum block size to 16MB at block 1,260,000.\n>>> >\n>>> > 5.    Increase maximum block size to 32MB at block 1,470,000.\n>>> >\n>>> > Backward compatibility\n>>> >\n>>> > All older clients are not compatible with this change. The first block\n>>> > larger than 1M will create a network partition excluding not-upgraded\n>>> > network nodes and miners.\n>>> >\n>>> > Rationale\n>>> >\n>>> > While more comprehensive solutions are developed, an increase to the\n>>> block\n>>> > size is needed to continue network growth. A longer term solution is\n>>> needed\n>>> > to prevent complications associated with additional hard forks. It\n>>> should\n>>> > also increase at a gradual rate that retains and allows a large\n>>> distribution\n>>> > of full nodes.  Scheduling this hard fork to occur no earlier than the\n>>> > subsidy halving in 2016 has the goal of simplifying the communication\n>>> > outreach needed to achieve consensus, while also providing a buffer of\n>>> time\n>>> > to make necessary preparations.\n>>> >\n>>> >\n>>> > _______________________________________________\n>>> > bitcoin-dev mailing list\n>>> > bitcoin-dev at lists.linuxfoundation.org\n>>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>> >\n>>>\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151113/f0652a2e/attachment-0001.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2015-11-13T10:52:57",
                "message_text_only": "On Friday, November 13, 2015 9:50:47 AM John Sacco wrote:\n> * 2 MB, height 420,000 < 630,000; (fork active when 75% of last 1,000 blocks\n> signal support and block 420,000 reached, ~July 2016)\n\nI'd leave out the block signalling. It isn't really useful, complicates the \nwhole BIP, and mistakenly gives people the idea that miners have a choice in \nhardforks.\n\nLuke"
            },
            {
                "author": "Luke Dashjr",
                "date": "2015-11-13T06:39:51",
                "message_text_only": "On Friday, November 13, 2015 2:56:55 AM Chun Wang via bitcoin-dev wrote:\n> * 2 MB, 210000 <= height < 420000;\n\nIt's impossible to have the entire network upgraded in the past.\n\nFurthermore, 1 MB is already too large a block size today. While blocks don't \nneed to be as big as the limit, it's better to have the limit approximate what \nis reasonably possible without straining the network. So while your proposed \nschedule change might be workable (if miners can be trusted to keep actual \nblock size under 50% pending future improvements), I prefer the proposal \nbeginning at the next subsidy halving (which we're well on the way to).\n\nLuke"
            },
            {
                "author": "Luke Dashjr",
                "date": "2015-11-13T22:28:46",
                "message_text_only": "On Friday, November 13, 2015 4:01:09 PM digitsu at gmail.com wrote:\n> Forgive the frankness but I don't see why signaling your intent to support\n> an upgrade to one side of a hard fork can be seen as a bad thing.  If for\n> nothing else doesn't this make for a smoother flag day? (Because once you\n> signal your intention, it makes it hard to back out on the commitment.)\n\nIt isn't a commitment in any sense, nor does it make it smoother, because for \na hardfork to be successful, it is the *economy* that must switch entirely. \nThe miners are unimportant.\n\n> If miners don't have any choice in hard forks, who does? Just the core\n> devs? \n\nDevs have even less of a choice in the matter. What is relevant is the \neconomy: who do people want to spend their bitcoins with? There is no \nprogrammatic way to determine this, especially not in advance, so the best we \ncan do is a flag day that gets called off if there isn't clear consensus.\n\nLuke"
            },
            {
                "author": "digitsu at gmail.com",
                "date": "2015-11-14T00:02:01",
                "message_text_only": "Well I'd like to think that with an economy all parts of it interact with each other in ways more complex than simplistic imperative logic.\u00a0\n\n\n\n\nI agree that the economic majority is essentially what matters in a hard fork but everyone (miners,devs,public thought leaders,businesses) is part of that economy. Additionally what miners signal as their intention affects the decision of that economic majority (and vice versa). \u00a0You can see the effects of this in traditional political processes in how preliminary vote polling results affect (reinforce) the final vote.\u00a0\n\nWe also can see the results of this in (dare I mention) the whole XT affair which had the signed intent of many of the economy (payment processors and wallets and one miner pool) and the rest of the miners did not go along with it. This experiment either means that the rest of the miners couldn't be bothered to signal at all (because they didn't know how) or they were affected by the influence of core devs or the opinions of others on the matter and rejected the economic majority. \u00a0(Which would imply core devs have some power by way of indirect influence) I would be inclined to believe the latter was more likely.\u00a0\n\n\n\n\nThe conclusion which this would seem to imply is that at the very least, miners matter (to what exact extent is debatable). \u00a0And although there is no direct control of any party over the other in the strict sense, the public vocal opinions of any part of the Bitcoin economy does have an effect in its ability to sway the opinions of the other parts.\u00a0\n\n\n\n\nDigitsu\n\n\n\n\u2014\nRegards,\n\nOn Sat, Nov 14, 2015 at 7:29 AM, Luke Dashjr <luke at dashjr.org> wrote:\n\n> On Friday, November 13, 2015 4:01:09 PM digitsu at gmail.com wrote:\n>> Forgive the frankness but I don't see why signaling your intent to support\n>> an upgrade to one side of a hard fork can be seen as a bad thing.  If for\n>> nothing else doesn't this make for a smoother flag day? (Because once you\n>> signal your intention, it makes it hard to back out on the commitment.)\n> It isn't a commitment in any sense, nor does it make it smoother, because for \n> a hardfork to be successful, it is the *economy* that must switch entirely. \n> The miners are unimportant.\n>> If miners don't have any choice in hard forks, who does? Just the core\n>> devs? \n> Devs have even less of a choice in the matter. What is relevant is the \n> economy: who do people want to spend their bitcoins with? There is no \n> programmatic way to determine this, especially not in advance, so the best we \n> can do is a flag day that gets called off if there isn't clear consensus.\n> Luke\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151113/5cadc0d6/attachment.html>"
            },
            {
                "author": "Adam Back",
                "date": "2015-11-14T09:31:18",
                "message_text_only": "There is a difference between miners signalling intent (as they have\nbeen for various BIPs, which is mostly informational only - they are\nmostly not running the code, and in some cases it is not implemented,\nso they cant be) there is a difference between that and a 95% miner\nmajority consensus rule.  Former can be useful information as you\nsaid, latter implies as Luke described something that is not really\naccurate, it is not strictly only a miner upgrade needed for basic\nsafety as with soft-forks.  If you look at BIP 103 for example it is\nflag day based, and I think this is a more accurate approach.  Also\nwith miner votes they can be misleading - vote for one thing, but run\nsomething else; what they are running is not generally\ndetectable/enforceable - see for example what happened with the BIP66\naccidental fork due to \"SPV mining\" (ie validationless mining).\n\nA hard-fork is for everyone to upgrade and talk with each other to see\nthat the vast majority is on the same plan which includes users,\necosystem companies & miners.\n\nAdam\n\nOn 14 November 2015 at 01:02, digitsu412 via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Well I'd like to think that with an economy all parts of it interact with\n> each other in ways more complex than simplistic imperative logic.\n>\n> I agree that the economic majority is essentially what matters in a hard\n> fork but everyone (miners,devs,public thought leaders,businesses) is part of\n> that economy. Additionally what miners signal as their intention affects the\n> decision of that economic majority (and vice versa).  You can see the\n> effects of this in traditional political processes in how preliminary vote\n> polling results affect (reinforce) the final vote.\n> We also can see the results of this in (dare I mention) the whole XT affair\n> which had the signed intent of many of the economy (payment processors and\n> wallets and one miner pool) and the rest of the miners did not go along with\n> it. This experiment either means that the rest of the miners couldn't be\n> bothered to signal at all (because they didn't know how) or they were\n> affected by the influence of core devs or the opinions of others on the\n> matter and rejected the economic majority.  (Which would imply core devs\n> have some power by way of indirect influence) I would be inclined to believe\n> the latter was more likely.\n>\n> The conclusion which this would seem to imply is that at the very least,\n> miners matter (to what exact extent is debatable).  And although there is no\n> direct control of any party over the other in the strict sense, the public\n> vocal opinions of any part of the Bitcoin economy does have an effect in its\n> ability to sway the opinions of the other parts.\n>\n> Digitsu\n>\n> \u2014 Regards,\n>\n>\n> On Sat, Nov 14, 2015 at 7:29 AM, Luke Dashjr <luke at dashjr.org> wrote:\n>>\n>> On Friday, November 13, 2015 4:01:09 PM digitsu at gmail.com wrote:\n>> > Forgive the frankness but I don't see why signaling your intent to\n>> > support\n>> > an upgrade to one side of a hard fork can be seen as a bad thing. If for\n>> > nothing else doesn't this make for a smoother flag day? (Because once\n>> > you\n>> > signal your intention, it makes it hard to back out on the commitment.)\n>>\n>> It isn't a commitment in any sense, nor does it make it smoother, because\n>> for\n>> a hardfork to be successful, it is the *economy* that must switch\n>> entirely.\n>> The miners are unimportant.\n>>\n>> > If miners don't have any choice in hard forks, who does? Just the core\n>> > devs?\n>>\n>> Devs have even less of a choice in the matter. What is relevant is the\n>> economy: who do people want to spend their bitcoins with? There is no\n>> programmatic way to determine this, especially not in advance, so the best\n>> we\n>> can do is a flag day that gets called off if there isn't clear consensus.\n>>\n>> Luke\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-14T10:52:12",
                "message_text_only": "Currently bip99 recommends 95% miner upgrade confirmation with version bits\n(bip9) for uncontroversial hardforks just like it does for uncontroversial\nsoftforks. It is true that in the case of hardforks miners don't decide and\nit's the whole economy who has to upgrade before activation, but \"the whole\neconomy\" and \"all users\" includes miners, so why not use the only upgrade\nconfirmation mechanism that we have available?\n\nThe way I see it, uncontroversial softforks are also expected to be\nupgraded to by everyone eventually. The advantage of softforks is that\nnon-miners don't need to do it before activation like with hardforks.\nThat's the only important difference I see between uncontroversial\nsoftforks and hardforks (unilateral softforks and schism hardforks are\nanother thing though).\n\nPlease let's discuss this generally within the context of bip99 instead of\ndiscussing different deployment details with every proposal. There's a\ncouple of threads in the ml, a couple of now merged bip99 prs in\nbitcoin/bips...\nOn Nov 14, 2015 10:31 AM, \"Adam Back via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> There is a difference between miners signalling intent (as they have\n> been for various BIPs, which is mostly informational only - they are\n> mostly not running the code, and in some cases it is not implemented,\n> so they cant be) there is a difference between that and a 95% miner\n> majority consensus rule.  Former can be useful information as you\n> said, latter implies as Luke described something that is not really\n> accurate, it is not strictly only a miner upgrade needed for basic\n> safety as with soft-forks.  If you look at BIP 103 for example it is\n> flag day based, and I think this is a more accurate approach.  Also\n> with miner votes they can be misleading - vote for one thing, but run\n> something else; what they are running is not generally\n> detectable/enforceable - see for example what happened with the BIP66\n> accidental fork due to \"SPV mining\" (ie validationless mining).\n>\n> A hard-fork is for everyone to upgrade and talk with each other to see\n> that the vast majority is on the same plan which includes users,\n> ecosystem companies & miners.\n>\n> Adam\n>\n> On 14 November 2015 at 01:02, digitsu412 via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > Well I'd like to think that with an economy all parts of it interact with\n> > each other in ways more complex than simplistic imperative logic.\n> >\n> > I agree that the economic majority is essentially what matters in a hard\n> > fork but everyone (miners,devs,public thought leaders,businesses) is\n> part of\n> > that economy. Additionally what miners signal as their intention affects\n> the\n> > decision of that economic majority (and vice versa).  You can see the\n> > effects of this in traditional political processes in how preliminary\n> vote\n> > polling results affect (reinforce) the final vote.\n> > We also can see the results of this in (dare I mention) the whole XT\n> affair\n> > which had the signed intent of many of the economy (payment processors\n> and\n> > wallets and one miner pool) and the rest of the miners did not go along\n> with\n> > it. This experiment either means that the rest of the miners couldn't be\n> > bothered to signal at all (because they didn't know how) or they were\n> > affected by the influence of core devs or the opinions of others on the\n> > matter and rejected the economic majority.  (Which would imply core devs\n> > have some power by way of indirect influence) I would be inclined to\n> believe\n> > the latter was more likely.\n> >\n> > The conclusion which this would seem to imply is that at the very least,\n> > miners matter (to what exact extent is debatable).  And although there\n> is no\n> > direct control of any party over the other in the strict sense, the\n> public\n> > vocal opinions of any part of the Bitcoin economy does have an effect in\n> its\n> > ability to sway the opinions of the other parts.\n> >\n> > Digitsu\n> >\n> > \u2014 Regards,\n> >\n> >\n> > On Sat, Nov 14, 2015 at 7:29 AM, Luke Dashjr <luke at dashjr.org> wrote:\n> >>\n> >> On Friday, November 13, 2015 4:01:09 PM digitsu at gmail.com wrote:\n> >> > Forgive the frankness but I don't see why signaling your intent to\n> >> > support\n> >> > an upgrade to one side of a hard fork can be seen as a bad thing. If\n> for\n> >> > nothing else doesn't this make for a smoother flag day? (Because once\n> >> > you\n> >> > signal your intention, it makes it hard to back out on the\n> commitment.)\n> >>\n> >> It isn't a commitment in any sense, nor does it make it smoother,\n> because\n> >> for\n> >> a hardfork to be successful, it is the *economy* that must switch\n> >> entirely.\n> >> The miners are unimportant.\n> >>\n> >> > If miners don't have any choice in hard forks, who does? Just the core\n> >> > devs?\n> >>\n> >> Devs have even less of a choice in the matter. What is relevant is the\n> >> economy: who do people want to spend their bitcoins with? There is no\n> >> programmatic way to determine this, especially not in advance, so the\n> best\n> >> we\n> >> can do is a flag day that gets called off if there isn't clear\n> consensus.\n> >>\n> >> Luke\n> >\n> >\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151114/9ef5c0fd/attachment-0001.html>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2015-11-14T21:11:22",
                "message_text_only": "On Saturday, November 14, 2015 10:52:12 AM Jorge Tim\u00f3n via bitcoin-dev wrote:\n> Currently bip99 recommends 95% miner upgrade confirmation with version bits\n> (bip9) for uncontroversial hardforks just like it does for uncontroversial\n> softforks. It is true that in the case of hardforks miners don't decide and\n> it's the whole economy who has to upgrade before activation, but \"the whole\n> economy\" and \"all users\" includes miners, so why not use the only upgrade\n> confirmation mechanism that we have available?\n\nActually, the economy does not necessarily include miners, and in fact the \npresent miner community for the most part does not overlap significantly with \neconomic activity. And at the same time, miners also have a tendency to \nupgrade at a different rate than the economy. It might make sense to \nincorporate a miner-trigger, but *only if* the flag is enabled in nodes by an \noption disabled by default, and the BIP clearly specifies that miners must not \nenable it until they perceive complete economic adoption of the change.\n\nLuke"
            },
            {
                "author": "Luke Dashjr",
                "date": "2015-11-14T21:27:51",
                "message_text_only": "On Saturday, November 14, 2015 9:15:07 PM Angel Leon wrote:\n> \"the economy does not necessarily include miners\"\n> so the money supply isn't part of the economy?\n\nNot in the context of economic majority deciding hardforks. After all, the \noutcome of the hardfork *determines* the money supply. So the former money \nsupply not supporting the change would just mean they cease to be involved in \nthat capacity. But even aside from that, the more relevant factor in terms of \neconomic involvement is /acceptance/ of bitcoins as payment for real goods.\n\nLuke"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-15T12:16:56",
                "message_text_only": "On Sat, Nov 14, 2015 at 10:11 PM, Luke Dashjr <luke at dashjr.org> wrote:\n> On Saturday, November 14, 2015 10:52:12 AM Jorge Tim\u00f3n via bitcoin-dev wrote:\n>> Currently bip99 recommends 95% miner upgrade confirmation with version bits\n>> (bip9) for uncontroversial hardforks just like it does for uncontroversial\n>> softforks. It is true that in the case of hardforks miners don't decide and\n>> it's the whole economy who has to upgrade before activation, but \"the whole\n>> economy\" and \"all users\" includes miners, so why not use the only upgrade\n>> confirmation mechanism that we have available?\n>\n> Actually, the economy does not necessarily include miners, and in fact the\n> present miner community for the most part does not overlap significantly with\n> economic activity.\n\nMaybe we should define \"the bitcoin economy\" is first. In my\ndefinition, miners are definitely part of the economy (and also users\nof the system).\n\nOn Sat, Nov 14, 2015 at 10:27 PM, Luke Dashjr <luke at dashjr.org> wrote:\n> On Saturday, November 14, 2015 9:15:07 PM Angel Leon wrote:\n>> \"the economy does not necessarily include miners\"\n>> so the money supply isn't part of the economy?\n>\n> Not in the context of economic majority deciding hardforks. After all, the\n> outcome of the hardfork *determines* the money supply. So the former money\n> supply not supporting the change would just mean they cease to be involved in\n> that capacity. But even aside from that, the more relevant factor in terms of\n> economic involvement is /acceptance/ of bitcoins as payment for real goods.\n\nMiners accept bitcoins as payment for a real service (with real costs\nlike electricity) to the network: extending the longest valid chain\nwith their proof of work.\nIn the context of BIP99, there's no concept of \"an economic majority\"\ndeciding hardforks. Hardforks are either uncontroversial, in which\ncase BIP99 recommends 95% miner upgrade confirmation in addition to a\ntime threshold, or are schism hardforks (for example, an anti-miner\nhardfork), in which case BIP99 recommends using a time threshold\nalone. But no majority can force the dissenting users to use one\nvalidation rule set or the other: users will always be free to run\nwhatever free software they like.\n\n> And at the same time, miners also have a tendency to\n> upgrade at a different rate than the economy.\n\nThat alone seems like a very good reason in favor to confirm that\nminers have upgraded in addition to a minimal activation block median\ntime, not a reason against it\n\n> It might make sense to\n> incorporate a miner-trigger, but *only if* the flag is enabled in nodes by an\n> option disabled by default, and the BIP clearly specifies that miners must not\n> enable it until they perceive complete economic adoption of the change.\n\nI'm not sure I understand this. The trigger mechanism must be uniform\nfor each rule change, it cannot be optionally different or consensus\ncan fail.\nHow are miners supposed to \"perceive\" adoption?\nThe time threshold must be set enough in the future to give users time\nto upgrade. But we can perceive miners' adoption, so if the system\nknows they haven't upgraded, it should wait for them to upgrade (it\nwould be nice to have an equivalent mechanism to wait for the rest of\nthe users, but unfortunately there's none).\nPlease, remember that this is in the context of uncontroversial\nhardforks for which all users (including all miners) are expected to\nupgrade to.\nTo reiterate, schism hardforks are treated differently and the miner\nupgrade confirmation becomes completely irrelevant."
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-18T10:15:54",
                "message_text_only": "On Wed, Nov 18, 2015 at 10:13 AM, Shuning Hong <hongshuning at gmail.com> wrote:\n> 2015-11-15 20:16 GMT+08:00 Jorge Tim\u00f3n <bitcoin-dev at lists.linuxfoundation.org>:\n>> The time threshold must be set enough in the future to give users time to upgrade. But we can perceive miners' adoption, so if the system knows they haven't upgraded, it should wait for them to upgrade (it would be nice to have an equivalent mechanism to wait for the rest of the users, but unfortunately there's none).\n>\n> If the majority of the miners never upgrade, how could we treat that\n> BIP? Wait forever?\n\nAssuming it was deployed as an uncontroversial hardfork as recommended\nin BIP99, the deployment would use versionbits (BIP9) and the hardfork\nwould timeout.\nBut this timeout would clearly signal that either the minimum\nactivation threshold wasn't giving enough time for all users to\nupgrade (apparently miners didn't had time) or the hardfork is not\nreally an uncontroversial hardfork but rather a schism one. Then,\nassuming some people still want to deploy it as a schism hardfork,\nbip99 recommends using only a mediantime threshold without versionbits\nnor miner upgrade confirmation."
            }
        ],
        "thread_summary": {
            "title": "BIP - Block size doubles at each reward halving with max block size of 32M",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Adam Back",
                "digitsu at gmail.com",
                "John Sacco",
                "Jorge Tim\u00f3n",
                "Btc Drak",
                "Luke Dashjr",
                "Chun Wang"
            ],
            "messages_count": 15,
            "total_messages_chars_count": 40818
        }
    },
    {
        "title": "[bitcoin-dev] Ads on bitcoin.org website",
        "thread_messages": [
            {
                "author": "Jonas Schnelli",
                "date": "2015-11-13T07:27:48",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\nHi all\n\nI'm a little bit concerned about the future of bitcoin.org.\nA neutral website that informs about bitcoin, bitcoin-applications and\nbitcoin-exchanges is important at this \"early stage\".\n\nYou might have seen that bitcoin.com does not claim to be neutral and\ninformative. As counterweight, a neutral and ad-free bitcoin.org site\nis even more important.\n\nRecently, bitcoin.org did merge a PR [1] that enables Google analytics\nfor bitcoin.org. The PR comments did show disagreement for this step.\nFor me, this seems to be against the about-us rules [2] in about \"who\nis in charge of bitcoin\".\nPersonally I think allowing Google to collect data of bitcoin.org\nvisitors is against the bitcoin \"philosophy\".\n\nAnother PR [3] (not merged yet) would enable the technical base to\ndisplay ads on the site.\n\nWhat ads would be displayed there?\nIf an ad provider would be implemented (like Google Ads), very likely\nbitcoin related things like bitcoin application vendors or bitcoin\nexchanges would be shown there.\nWouldn't this attack the neutrality model of bitcoin.org?\n\nI think, it would move bitcoin.org in the wrong direction, towards\nsites like bitcoin.com and it would loose the neutral \"feeling\" and\nusers and press very likely will see this as a \"greedy\" step.\n\nI'd like to know, how changes on bitcoin.org happen? Do they follow\nconsensus-agreement among bitcoin-space contributors or does a group\nof people decide what to merge and what not?\n\nIf site operators or contributers need to get payed for their (highly\nappreciated) work or need to pay for infrastructure, we should address\nthis root problem.\nI'm pretty sure we can raise funds for a such purpose and I'm offering\nmy help to speak to bitcoin businesses and individuals.\n\n\n[1] https://github.com/bitcoin-dot-org/bitcoin.org/pull/1087\n[2] https://bitcoin.org/en/about-us\n[3] https://github.com/bitcoin-dot-org/bitcoin.org/pull/1136\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v2\n\niQIcBAEBCAAGBQJWRZD0AAoJECnUvLZBb1PsrBoQALebNL8OUIucB/MqtI8JK9Fa\nRctlDuJlPeLCOC0oXjM4WKu/mzYATSuc/2y1xxWQLgRgteKRMd1+4ZcCIz0fqbIk\nM4RsEr24klybRl7A4+vMmuL0OsXd3vXjU52AUDrSokdaCEITxeSpsRROX+t+tKz4\nIt5CXRdZS9gyaDswCiWsnDTDbSSbpOiz7DzaBQTMziOQYr+VKQg5G0FSsVGrGNso\nN2LpKtADBwpPbVP57S6NwAkOERcVQnIdJ2Ag6NgLLkdIA8z3lSgd+Yvn1rdbdKQh\nNkPWy1e0QHUPS6gCunKguJA46UdO0vuIY+ZLNIaOtnnEQFKtSn3VYERghWPY9WQ2\nPhBZXGuSsLyQg9/3qKeae9e11S+bz7xJpNOwJC8FnOOOS4h6W74O5UG4B7QXd3Ap\n0eQZd2+iRlp59RNaKMbiXIHodmbB/nbefbH7HK+qNvKvL4i01Ar8FBPjXPXf3tOA\nU5WHb6h7ClmOJ+tWsgB4RdhUISE/ryzyA4s59troQlIWRm7aWF9cjq1JWRqKWhfy\nCfjVsRje9QBYnX3aS5Y9Vh8lGuArr8ZxiBbXgA7bL951GgWge747vxadvESeimCv\nW2qf7oFzQ1QKAm8NbTzLHJEjq0HVop1KBjGS0rjyf0upA0Xtdu4u1cfTvhK0ULAe\nZCkR3m2qdxJ/JqtUbioq\n=ZXsV\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "David A. Harding",
                "date": "2015-11-13T15:59:16",
                "message_text_only": "On Fri, Nov 13, 2015 at 08:27:48AM +0100, Jonas Schnelli via bitcoin-dev wrote:\n> I'm a little bit concerned about the future of bitcoin.org.\n\nBitcoin.org hosts the Bitcoin Core binaries refered to in release\nannouncements, so this subject is conceivably on-topic for bitcoin-dev.\nHowever, I think questions about how Bitcoin.org operates are best asked\non bitcoin-discuss[1] (or somewhere else) and issues about the\nadvertising are best addressed in the PRs you referenced.\n\nSo, as one of the Bitcoin.org maintainers, here are my suggestions:\n\n1. I'm on bitcoin-discuss.  Please feel free to ask any questions there.\n\n2. I just opened a GitHub issue for discussing advertising on Bitcoin.org[2]\n\n    - I will reply to your specific questions there after I've sent this\n      mail.\n\n3. If advertisements are added to Bitcoin.org and there is general\n   dissatisfaction about that, maybe then we can come back to\n   bitcoin-dev to discuss moving the Bitcoin Core binaries\n   somewhere else.\n\nThanks,\n\n-Dave\n\n[1] https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-discuss\n\n[2] https://github.com/bitcoin-dot-org/bitcoin.org/issues/1139\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 473 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151113/2c4e0c39/attachment-0001.sig>"
            }
        ],
        "thread_summary": {
            "title": "Ads on bitcoin.org website",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "David A. Harding",
                "Jonas Schnelli"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 4179
        }
    },
    {
        "title": "[bitcoin-dev] Announcing Jonas Schnelli as GUI maintainer",
        "thread_messages": [
            {
                "author": "Wladimir J. van der Laan",
                "date": "2015-11-13T07:30:53",
                "message_text_only": "Hello,\n\nI'd like to announce Jonas Schnelli as the new GUI maintainer of Bitcoin Core.\n\nHe's been very active in this area for the last year, as one example he\nredesigned all the icons for 0.11.0, has visualized various network statistics,\nand has been continuously improving the user experience. Something Bitcoin Core\nvery much needs, in my opinion.\n\nUnofficially he has been giving direction in GUI matters for quite a while\nalready, so this only makes it 'official'.\n\nHe will be handling GUI related issues on the github tracker, and assisting on and\nmerging GUI-related pull requests.\n\nWelcome Jonas to the team!\n\nWladimir"
            },
            {
                "author": "Jonas Schnelli",
                "date": "2015-11-13T08:13:24",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\n> I'd like to announce Jonas Schnelli as the new GUI maintainer of\n> Bitcoin Core.\n> \n> He's been very active in this area for the last year, as one\n> example he redesigned all the icons for 0.11.0, has visualized\n> various network statistics, and has been continuously improving the\n> user experience. Something Bitcoin Core very much needs, in my\n> opinion.\n> \n> Unofficially he has been giving direction in GUI matters for quite\n> a while already, so this only makes it 'official'.\n> \n> He will be handling GUI related issues on the github tracker, and\n> assisting on and merging GUI-related pull requests.\n> \n> Welcome Jonas to the team!\n> \n\nThanks Wladimir!\n\nMy long term vision for bitcoin-core was always a more user friendly\nUI without loosing the security and privacy features bitcoin-core offers\n.\nHowever, it has shown that this is relatively hard to achieve. Its\nunclear to me, what role wallets (and related UIs) will play in the\nfuture of bitcoin. I think it needs several years until something like\nbitcoin can be used to \"pay for every coffee in the world\" [1].\nBut I'm happy to explore this path!\n\nThat was and is also the reason why I'm often focus on non-UI-related\nchanges that keep bitcoin healthy and form a more defined role for the U\nI.\n\nShort words to myself:\nI'm a senior software developer, 35 years old, living in Switzerland\n(UTC+1).\n\nThanks for the trust and I try to give my best to maintain and improve\nthe GUI.\n\n[1] https://twitter.com/ronmckown/status/643101952763658240\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v2\n\niQIcBAEBCAAGBQJWRZukAAoJECnUvLZBb1PsbEAP/jERgMowXP7rSV8FXwQ6mR+r\nCdO4xs3OHKuRyZJKLhXq/aC48ThshzDynRcKAJifcxhoIN0Msnt2oz/kwyfJSssT\nFHB2dZVmuSXSNdOKVjwemiIQJ1xVENrfBNEINNVkix3LNgbi/3vwPuNj/ImHjWOc\nmTAcD+JkzZSdkWL53TWPY5noizl3hd/LJD0lJ357FZlzmnpt9UiiZw6+X3+n5aJI\n7J5avpeEa36hppdej5Jh9V0Kq8JMkXgip/jSq9uP009Nki9RNywFQL+Pa26AgJvu\nVxAyJRjq6Dcb8D6dux8QcC8K114tAWncR6Lh2Z9DepNHhytk/TYBSi9+MWbnuWci\nJiN6fRCeBTt2A/m7IsUbVegfrmPgBiHAS5Mx+Q9vjTBzOOmpBbL2ZXOXR9wE3t3d\n9hBodZxnK37gU8UwKsoOiWuB4+rTp4rlt5iz32jd+/r6zUXv3whOy11HuICzVR0c\nll2aHfvr8TkqTRds0cvrb5ZroT63mmGFaqJIrskVruVoMxVWjdqnOIiNxtXWSnCd\nT9jmxdojqrSwtM+3A60UmrSNVwyhZudZFmyJsjHZGAK6aV/eGYb595vXUDvx8mtH\nfzeqmpivONDrNhqFrbLPR1V8kBx0UCN5FreMjdXtmU81UTqLd4o5lCh0AFZ7upCq\n2DiMpEgittqOtxDwb8YY\n=Q5KE\n-----END PGP SIGNATURE-----"
            }
        ],
        "thread_summary": {
            "title": "Announcing Jonas Schnelli as GUI maintainer",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jonas Schnelli",
                "Wladimir J. van der Laan"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 2999
        }
    },
    {
        "title": "[bitcoin-dev] BIP proposal - Max block size",
        "thread_messages": [
            {
                "author": "Erik",
                "date": "2015-11-13T13:07:33",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\nHi devs. I was discussing the BIP proposals concerning max block size\nyesterday in the #bitcoin channel. I believe that BIP101 fully utilized\nwill outperform consumer hardware soon or later and thereby centralize\nBitcoin. I would therefore like to do a different proposal:\n\nMotivations:\n* BIP101 propose a doubling of the block max size every second year.\nThis is very fast and may make the blockchain to grow faster than\nconsumer hardware can cope with.\n* BIP102 is only a one-time solution, thus a new discussion of the next\nblock max size will need to arise soon after it has been implemented.\n* BIP100 is an interesting solution in that the miners vote on the block\nmax size. Althoigh it has several cons: 1) The block max size can never\nextend 32 MiB, even if we are so far in the future that it is need for\nlarger blocks. 2) The block max size could reach a size of 32 MiB in a\nrather fast manner if pools vote for it, even though consumer hardware\ntoday isn't really ready for the growth it implicates. 3) Block max size\ncan be pushed backwards, which will make TX fees higher, cause a lot of\norphaned low-fee TXes. It could make some smaller mining pools dependant\non lots of TXes with fees unprofitable. It is a serious flaw which could\ndamage the trust of the network.\n* We does not for sure know how the evolution will proceed and if there\nwill be storage for the larger block chain in the future.\n* There is a benefit of having a limit on the amount of transactions\nthat will be processed in that the fees will rise.\n* Also there is a large problem if the fees rise too high because it\nwill prevent mainstream users from using the network. There will also be\na lot of orphan TXes which will cause uncertainity and fear of losses\namong users that don't know how bitcoin works.\n* Pruning is a problem if the blockchain grows too fast because some,\nalthough a few, nodes still must store the complete data -> centralization.\n\nConcepts:\nThere is always a growth in the block max size. Never a decrease.\nThe growth rate desicion should be in the hands of the miners.\nIt's good to have limits on the block max size to keep back spam TXes.\nUse rules that makes a more smooth and predictable growth.\n\nRules:\n1) Main target growth is 2^(1/2) every second year, or a doubling of the\nblock max size every four years.\n2) The growth rate every second year will strictly be limited by the\nformula 2^2 > growth > linear growth.\n3) The target growth could be modified with positive or negative votes,\nbut it will not exceed the limits of 2) in any direction. Miners could\nalso choose to not vote.\n4) The linear y=kx+m will be formed from the genesis block date with\nsize 1 MiB (m) through the last retarget block date with current size.\n5) Target growth is based on votes from the last 26280 blocks (half a year).\n6) Block max size grows at the same time as block difficulty retarget\n(2016 blocks) with the formula 2^(((1/2)+(1/2*amount positive\nvotes)-(1/2*amount negative votes))/52). If the votes propose a lower\ngrowth than the linear, use the linear growth instead. Block size is\nfloored to byte precision.\n7) Amount positive/negative votes are calculated as following: number of\nvotes, positive or negative / 26280.\n8) When this rule are put in force, the block max size will immidiately\nbe set to 4 MiB.\n\nNotes:\n* The number 52 came from 52 weeks/year * 2 years / 2 weeks. It measures\nnumber of week pairs or difficulty retargets per two years.\n* When there are no votes, the growth speed is set as main target as in\n1). Also blocks mined before the implementation counts as blocks with no\nvotes.\n\nExamples:\n* After implementation, the block max size will be 4 MiB.\n* At the first retarget, if no miner has left a vote, or equal number of\nvotes exists for positive and negative side. Then the next block max\nsize is 4096 KiB*2^((1/2)/52)=4123.3905 KiB (or exactly 4 222 351 bytes)\n* If the block max size is exactly 11 MiB, it has been exactly 10 years\nand 2 weeks since the genesis block, the next block is a retarget and\nevery vote is negative. Then 2^(((1/2)-(1/2))/52) = 1. It is lower than\nthe linear, then the next block max size will follow the linear derived\nfrom: (11 MiB - 1 MiB) / (10.00 years) = 1 = k. Formula for a linear is\ny=kx+m. m is the genesis block max size in MiB. Then y = 1 * (10+1/52) +\n1 = 11.019 [MiB] (or exactly 11 554 500 bytes)\n* If everyone in the past example continue voting negative for the next\nfour years, then the block max size will then be y = 1*14 + 1 = 15 [MiB].\n* If the block max size was 10 MiB four years ago and every miner\ninstead has put positive votes into the block chain since 4.5 years,\nthen the block max size now is 10 MiB * 2^( ((1/2+1/2)/(52)) * 2) = 10\nMiB * 4 = 40 MiB\n* If there was 2628 negative votes and 5256 positive votes in the last\n26280 blocks, then the formula will look like:\nsize*2^(((1/2)+(1/2*0.2)-(1/2*0.1))/52)\n\nPros:\nProvides a long term solution that give opportunities to the network to\nitself cope with the actual state and hardware limits of the future\nnetwork. No need to make a hard fork to adapt to other growth rates\nwithin this proposal's limits.\nProvides a smooth growth rate based on a large consensus, thus making\nthe growth for the near future almost predictable. No big jumps in block\nmax size provides stability to the network.\nMiners can choose pools that votes in a way that conforms to the miners\ninterest.\nEliminates fluctuating block size as could happen with BIP100 proposal.\n\nCons:\nA few single, large entities could either vote for smaller growth of\nblocks for a long time, causing TX congestion and mistrust in the\nbitcoin network. On the contrary they could vote for a larger growth of\nblocks, causing the blockchain to be too large for consumer hardware. It\nwill then result in fewer nodes and in worst cases closing of small\npools. These cases seems to be extremely unlikely partly because of the\ntime and mining power that will be needed, partly also because of limits\nin how much the votes can adjust the growth rate. It would therefore not\npose a large risk.\n\nSincerely,\nErik Fors\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v2.0.22 (GNU/Linux)\n\niQIcBAEBAgAGBQJWReCVAAoJEJ51csApon2oLBgP/jn7mL5AzvU7/PCeAD39Kmc3\nIsgFwh9LrHin/SaerPebusRGbjKXezP86kbiQVGEsSu3K3BxUAf9O09UoQiWECoc\ng2EOw5E1XrtzBopxYTO06daM/2CqDydpLVIVv6NwwLMpXKvmbixdqaD6vOKfzhNF\n1B5tmg9Vh1zqEkBj7exnuypagG/3llkCt3DRb0+siVzkIM/O9GzgHbGtt8rtDEnH\nXHIhwLw+ySGuHg6hRhLo3uHs3gCUQmarxx1AoqR6AyvzgR6TGhJcy22vXct7QK5G\nB2K4+JseyVD0bvkBeIpjuqJpGoCq4lmNu/AmI/nQ82TmqqzvOBi/ljFF/Q+HArjZ\nUQO6p28lE7rmXf80GB6L117QLHktA5CdY++vW4Gwz3KDYEafs6H3CptvSmj9JbQz\nSVAt/eVvvdnVkRcYw++b0WrRuOS3Z+105QIX4yqt0Kyghr87LQ76LXnZHPMKZeHt\nIRX3wv7ZFqrJEpmGrTK4ZMZUAPVpkGe0kPms5kLHjEtjU92rvZJA726JJFoaAv5S\nrFDiGUupLvHttZLTYfTdyFhCo6ZStOI095qDZ69awVCLMmYpC9aR/tjQ5zMu5eNS\ny4hQdrX0Z4sdrJ2mTB+OXO7broLDn2G9dIqfpZwcIU493ljcXk/Uma4lj3oDrGTA\noc5Q5ie/OVUclWB6GIho\n=cocM\n-----END PGP SIGNATURE-----\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: 0x29A27DA8.asc\nType: application/pgp-keys\nSize: 3117 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151113/2b1ae0ad/attachment.bin>"
            },
            {
                "author": "Luke Dashjr",
                "date": "2015-11-13T19:37:02",
                "message_text_only": "On Friday, November 13, 2015 1:07:33 PM Erik via bitcoin-dev wrote:\n> Hi devs. I was discussing the BIP proposals concerning max block size\n> yesterday in the #bitcoin channel. I believe that BIP101 fully utilized\n> will outperform consumer hardware soon or later and thereby centralize\n> Bitcoin. I would therefore like to do a different proposal:\n\nIt doesn't look like you've considered BIP103 or newer BIPs? Especially, I'd \nsuggest you look at and work with John Sacco who just the other day posted a \nBIP draft very similar-looking to yours. My overall impression of your summary \nis that it is unnecessarily over-complicated and underspecified. How does the \n2^(1/2) block size limit actually work? This is not a very precise number, so \nit seems liable to produce rounding errors in different implementations. \nAdditionally, the miner voting thing seems pointless since miners can already \nsoftfork lower limits. It would be beneficial to express the current \npossibility so full nodes can enforce it, but this would be expressed as an \nunlimited simple-majority vote to reduce the limit. Probably it would be ideal \nto separate this off from the hardfork BIP, since it's fairly tangent to it.\n\nLuke"
            },
            {
                "author": "Erik",
                "date": "2015-11-14T15:25:19",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n\nI've seen two different BIP103's and choose to not write about it\nbecause risk of ambiguity. One of them are proposing a linear growth and\nthe other one is proposing an exponential growth. The all-linear growth\nis an option that will not work well in the future because the growth\nwill be too slow soon or later. The exponential growth assumes that the\ntechnology will rise in a certain growth, which may be too slow or too\nfast in accordance to the technical evolution. None of the BIP103\nproposals will actually handle an unexpected future case.\n\nBIP105 has another feature not mentioned in my proposal that is to place\na vote requires a cost as a difficulty increase. I do not think it's a\ngood option since it will make users refrain from voting to \"earn\" a\ndifficulty lowering. The votes are the (yet) only soft way I see to let\nthe blockchain know if it should allow growing faster or slower. I also\ndon't see a benefit of having the opportunity to lower the block max\nsize in comparison to the risks involved with that. Then it proposes a\nlimit to how much it can increase at all which will need a new hard fork\nwhen we need to increase the limits of the proposal.\n\nI don't see how John Sacco's BIP proposal is similar to this one since\nthere is no voting mechanism to make the increase dynamic. Also John\nproposes that the size will double at each halving instead of each\ndifficulty retarget. This could, in contrary to increase the fees by\nmaking larger spaces in the blocks, decrease the fees because of that\nthe fee required to enter the next block will be lowered. Also it\nproposes a hard limit at 32 MB which, again, need a new hard fork later.\n\nThe formula I've provided isn't actually complicated. The 2^(1/2...)\nformula creates a number in the interval 1 to 2. The formula can tell if\nthe block max size every second year shall double or be the same based\non the last 6 month of votes. Because i believe there should always be\nan increase to secure a stable growth of the network, there is also a\nlinear formula that the growth cannot be lower than. If the 2^(1/2...)\nformula gives a lower increase than the linear value for the next\nretarget, then the linear value should be used instead.\n\nThere will not be a rounding error since the implementation shall floor\nthe value to a whole byte. The next size should be calculated on that\nvalue. Also, if the block max size is included in the retarget block,\nthere would be an extra correcting method to uncertain clients. The\nformula isn't very different in complexity from the difficulty retarget\nformula and will still need the last recalculated value to be computed.\n\nOne of the benefits of using an exponential formula is that it could\neasily be fit for any arbitrary block period by changing the divisor. I\npersonally think the two week interval will be smooth enough.\n\nErik\n\nDen 2015-11-13 kl. 20:37, skrev Luke Dashjr:\n> On Friday, November 13, 2015 1:07:33 PM Erik via bitcoin-dev wrote:\n>> Hi devs. I was discussing the BIP proposals concerning max block size\n>> yesterday in the #bitcoin channel. I believe that BIP101 fully utilized\n>> will outperform consumer hardware soon or later and thereby centralize\n>> Bitcoin. I would therefore like to do a different proposal:\n>\n> It doesn't look like you've considered BIP103 or newer BIPs?\nEspecially, I'd\n> suggest you look at and work with John Sacco who just the other day\nposted a\n> BIP draft very similar-looking to yours. My overall impression of your\nsummary\n> is that it is unnecessarily over-complicated and underspecified. How\ndoes the\n> 2^(1/2) block size limit actually work? This is not a very precise\nnumber, so\n> it seems liable to produce rounding errors in different implementations.\n> Additionally, the miner voting thing seems pointless since miners can\nalready\n> softfork lower limits. It would be beneficial to express the current\n> possibility so full nodes can enforce it, but this would be expressed\nas an\n> unlimited simple-majority vote to reduce the limit. Probably it would\nbe ideal\n> to separate this off from the hardfork BIP, since it's fairly tangent\nto it.\n>\n> Luke\n\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v2.0.22 (GNU/Linux)\n\niQIcBAEBAgAGBQJWR1JfAAoJEJ51csApon2o1zkP/1Ik/VjakUII+2iXvPB+DSJ6\ncekIC4A8zlgltSmFyE74IuQBlV/5LumNMCzXoKUaDRuKSedlyh1mUrt8hPFfISfr\nyvIeWmXUQhd7s34mTTc9mBvz/TDuxuNYAFe1FYQhNzuV3GaLTysBAXScY5rGIkHf\nhdgxG3mPtzaqse1I5e+3jpwlPUYpLn/0A2nmF0iXCoOv1LnTvrlV3thP8Fp/YMt3\niLsiWFQFf1jpA4mDoCC/G5bfYiqvFbtXdOKKZC12Dp3hTZZCzJ21FQ6+o/v4BT7y\nMfW9kl3aWf3VSxbkvHppIrX1+HqDwTsn5u9kNcbYn8xBMRpFXFddFnsg/v6ai++L\nmev+kIUrXvvDqvRSfQYmHIUKCwo+tzXbHcumydxBp412TOKW5bT1CmCRYMOvY/+C\n45VWBj6foUYG/kq3QISm+lptVDQlESlAizHdWNkc9HJpKZG3VkNmmxEEXm3o7J07\nLbBQ7bR2MELE6lP2Z3ImTXxZe0ZBdjyjDDV3qsIGK9D7LCK31KE70ZIueE3bePmR\n9xWBfzKbm6Y3cQ6+4E8p8US7woVs9LGWXzLdKQyKEoiDx16bF7SOGvSyYcnOPsNu\nO7lVpGh8Pezb0ZLEx5UnM5ONm35PzmzAT9Ng2iMEhche3AQS4s/b+wVWpyclQ62e\nX4UVSr2O1mbfI9CmCPfI\n=qcA8\n-----END PGP SIGNATURE-----\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151114/ece596e0/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP proposal - Max block size",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Erik",
                "Luke Dashjr"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 13633
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Core 0.11.2 released",
        "thread_messages": [
            {
                "author": "Wladimir J. van der Laan",
                "date": "2015-11-13T13:13:54",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nBitcoin Core version 0.11.2 is now available from:\n\n  <https://bitcoin.org/bin/bitcoin-core-0.11.2/>\n\nAlternatively, through bittorrent:\n\n    magnet:?xt=urn:btih:d6d3387160f7e14f6f27dc40ae84cf566ebf631b&dn=bitcoin-core-0.11.2&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.publicbt.com%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.ccc.de%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969&tr=udp%3A%2F%2Fopen.demonii.com%3A1337&ws=https%3A%2F%2Fbitcoin.org%2Fbin%2F \n\nThis is a new minor version release, bringing bug fixes, the BIP65\n(CLTV) consensus change, and relay policy preparation for BIP113. It is\nrecommended to upgrade to this version as soon as possible.\n\nPlease report bugs using the issue tracker at github:\n\n  <https://github.com/bitcoin/bitcoin/issues>\n\nUpgrading and downgrading\n=========================\n\nHow to Upgrade\n- --------------\n\nIf you are running an older version, shut it down. Wait until it has completely\nshut down (which might take a few minutes for older versions), then run the\ninstaller (on Windows) or just copy over /Applications/Bitcoin-Qt (on Mac) or\nbitcoind/bitcoin-qt (on Linux).\n\nDowngrade warning\n- ------------------\n\nBecause release 0.10.0 and later makes use of headers-first synchronization and\nparallel block download (see further), the block files and databases are not\nbackwards-compatible with pre-0.10 versions of Bitcoin Core or other software:\n\n* Blocks will be stored on disk out of order (in the order they are\nreceived, really), which makes it incompatible with some tools or\nother programs. Reindexing using earlier versions will also not work\nanymore as a result of this.\n\n* The block index database will now hold headers for which no block is\nstored on disk, which earlier versions won't support.\n\nIf you want to be able to downgrade smoothly, make a backup of your entire data\ndirectory. Without this your node will need start syncing (or importing from\nbootstrap.dat) anew afterwards. It is possible that the data from a completely\nsynchronised 0.10 node may be usable in older versions as-is, but this is not\nsupported and may break as soon as the older version attempts to reindex.\n\nThis does not affect wallet forward or backward compatibility. There are no\nknown problems when downgrading from 0.11.x to 0.10.x.\n\nNotable changes since 0.11.1\n============================\n\nBIP65 soft fork to enforce OP_CHECKLOCKTIMEVERIFY opcode\n- --------------------------------------------------------\n\nThis release includes several changes related to the [BIP65][] soft fork\nwhich redefines the existing OP_NOP2 opcode as OP_CHECKLOCKTIMEVERIFY\n(CLTV) so that a transaction output can be made unspendable until a\nspecified point in the future.\n\n1. This release will only relay and mine transactions spending a CLTV\n   output if they comply with the BIP65 rules as provided in code.\n\n2. This release will produce version 4 blocks by default. Please see the\n   *notice to miners* below.\n\n3. Once 951 out of a sequence of 1,001 blocks on the local node's best block\n   chain contain version 4 (or higher) blocks, this release will no\n   longer accept new version 3 blocks and it will only accept version 4\n   blocks if they comply with the BIP65 rules for CLTV.\n\nFor more information about the soft-forking change, please see\n<https://github.com/bitcoin/bitcoin/pull/6351>\n\nGraphs showing the progress towards block version 4 adoption may be\nfound at the URLs below:\n\n- - Block versions over the last 50,000 blocks as progress towards BIP65\n  consensus enforcement: <http://bitcoin.sipa.be/ver-50k.png>\n\n- - Block versions over the last 2,000 blocks showing the days to the\n  earliest possible BIP65 consensus-enforced block: <http://bitcoin.sipa.be/ver-2k.png>\n\n**Notice to miners:** Bitcoin Core\u2019s block templates are now for\nversion 4 blocks only, and any mining software relying on its\ngetblocktemplate must be updated in parallel to use libblkmaker either\nversion 0.4.3 or any version from 0.5.2 onward.\n\n- - If you are solo mining, this will affect you the moment you upgrade\n  Bitcoin Core, which must be done prior to BIP65 achieving its 951/1001\n  status.\n\n- - If you are mining with the stratum mining protocol: this does not\n  affect you.\n\n- - If you are mining with the getblocktemplate protocol to a pool: this\n  will affect you at the pool operator\u2019s discretion, which must be no\n  later than BIP65 achieving its 951/1001 status.\n\n[BIP65]: https://github.com/bitcoin/bips/blob/master/bip-0065.mediawiki\n\nBIP113 mempool-only locktime enforcement using GetMedianTimePast()\n- ----------------------------------------------------------------\n\nBitcoin transactions currently may specify a locktime indicating when\nthey may be added to a valid block.  Current consensus rules require\nthat blocks have a block header time greater than the locktime specified\nin any transaction in that block.\n\nMiners get to choose what time they use for their header time, with the\nconsensus rule being that no node will accept a block whose time is more\nthan two hours in the future.  This creates a incentive for miners to\nset their header times to future values in order to include locktimed\ntransactions which weren't supposed to be included for up to two more\nhours.\n\nThe consensus rules also specify that valid blocks may have a header\ntime greater than that of the median of the 11 previous blocks.  This\nGetMedianTimePast() time has a key feature we generally associate with\ntime: it can't go backwards.\n\n[BIP113][] specifies a soft fork (**not enforced in this release**) that\nweakens this perverse incentive for individual miners to use a future\ntime by requiring that valid blocks have a computed GetMedianTimePast()\ngreater than the locktime specified in any transaction in that block.\n\nMempool inclusion rules currently require transactions to be valid for\nimmediate inclusion in a block in order to be accepted into the mempool.\nThis release begins applying the BIP113 rule to received transactions,\nso transaction whose time is greater than the GetMedianTimePast() will\nno longer be accepted into the mempool.\n\n**Implication for miners:** you will begin rejecting transactions that\nwould not be valid under BIP113, which will prevent you from producing\ninvalid blocks if/when BIP113 is enforced on the network. Any\ntransactions which are valid under the current rules but not yet valid\nunder the BIP113 rules will either be mined by other miners or delayed\nuntil they are valid under BIP113. Note, however, that time-based\nlocktime transactions are more or less unseen on the network currently.\n\n**Implication for users:** GetMedianTimePast() always trails behind the\ncurrent time, so a transaction locktime set to the present time will be\nrejected by nodes running this release until the median time moves\nforward. To compensate, subtract one hour (3,600 seconds) from your\nlocktimes to allow those transactions to be included in mempools at\napproximately the expected time.\n\n[BIP113]: https://github.com/bitcoin/bips/blob/master/bip-0113.mediawiki\n\nWindows bug fix for corrupted UTXO database on unclean shutdowns\n- ----------------------------------------------------------------\n\nSeveral Windows users reported that they often need to reindex the\nentire blockchain after an unclean shutdown of Bitcoin Core on Windows\n(or an unclean shutdown of Windows itself). Although unclean shutdowns\nremain unsafe, this release no longer relies on memory-mapped files for\nthe UTXO database, which significantly reduced the frequency of unclean\nshutdowns leading to required reindexes during testing.\n\nFor more information, see: <https://github.com/bitcoin/bitcoin/pull/6917>\n\nOther fixes for database corruption on Windows are expected in the\nnext major release.\n\n0.11.2 Change log\n=================\n\nDetailed release notes follow. This overview includes changes that affect\nbehavior, not code moves, refactors and string updates. For convenience in locating\nthe code changes and accompanying discussion, both the pull request and\ngit merge commit are mentioned.\n\n- - #6124 `684636b` Make CScriptNum() take nMaxNumSize as an argument\n- - #6124 `4fa7a04` Replace NOP2 with CHECKLOCKTIMEVERIFY (BIP65)\n- - #6124 `6ea5ca4` Enable CHECKLOCKTIMEVERIFY as a standard script verify flag\n- - #6351 `5e82e1c` Add CHECKLOCKTIMEVERIFY (BIP65) soft-fork logic\n- - #6353 `ba1da90` Show softfork status in getblockchaininfo\n- - #6351 `6af25b0` Add BIP65 to getblockchaininfo softforks list\n- - #6688 `01878c9` Fix locking in GetTransaction\n- - #6653 `b3eaa30` [Qt] Raise debug window when requested\n- - #6600 `1e672ae` Debian/Ubuntu: Include bitcoin-tx binary\n- - #6600 `2394f4d` Debian/Ubuntu: Split bitcoin-tx into its own package\n- - #5987 `33d6825` Bugfix: Allow mining on top of old tip blocks for testnet\n- - #6852 `21e58b8` build: make sure OpenSSL heeds noexecstack\n- - #6846 `af6edac` alias `-h` for `--help`\n- - #6867 `95a5039` Set TCP_NODELAY on P2P sockets.\n- - #6856 `dfe55bd` Do not allow blockfile pruning during reindex.\n- - #6566 `a1d3c6f` Add rules--presently disabled--for using GetMedianTimePast as end point for lock-time calculations\n- - #6566 `f720c5f` Enable policy enforcing GetMedianTimePast as the end point of lock-time constraints\n- - #6917 `0af5b8e` leveldb: Win32WritableFile without memory mapping\n- - #6948 `4e895b0` Always flush block and undo when switching to new file\n\nCredits\n=======\n\nThanks to everyone who directly contributed to this release:\n\n- - Alex Morcos\n- - \u0e3ftcDrak\n- - Chris Kleeschulte\n- - Daniel Cousens\n- - Diego Viola\n- - Eric Lombrozo\n- - Esteban Ordano\n- - Gregory Maxwell\n- - Luke Dashjr\n- - Marco Falke\n- - Mark Friedenbach\n- - Matt Corallo\n- - Micha\n- - Mitchell Cash\n- - Peter Todd\n- - Pieter Wuille\n- - Wladimir J. van der Laan\n- - Zak Wilcox\n\nAnd those who contributed additional code review and/or security research.\n\nAs well as everyone that helped translating on [Transifex](https://www.transifex.com/projects/p/bitcoin/).\n\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1\n\niQEcBAEBCgAGBQJWReHOAAoJEHSBCwEjRsmmTAAH/iZQGklLHLIM6a2tTOj4d/O6\nxHg5bJhXGjtzO284Uy3phTzvk+e4mqBTjI8BrSr4D+Vw7mJrfWihdTLlgZYCwso3\nAyAk8ud1H42QanAfUvciY5uXd7cyzr8tCnCIBkvwJT5O8tI3FFhSMM5Fs86WnsP1\nY10+93sxaVJUave2xm1bmgiwApFZKQ2MNU1IVgFaW8agB59fuqtPRnBdKiK/j+AO\nJn1LKsObsINYhjtkAFiC66mUOBZ2N3rdhbN3LFl+u7EriTLoYk1OtZZhlC+rOueo\nnxl1H5SHStjrD27vE9Hv2qD5Ckrwo3zib8hZNIVs6MJjFnWUCwNtNg0nqDEvpn4=\n=xXdY\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "Dave Scotese",
                "date": "2015-11-14T02:10:29",
                "message_text_only": "I decided to try to certify Wladimir's PGP keys (the old one (2346C9A6)\nfirst, and then the new one (36C2E964), since it was signed with the old\none).\n\nI visited\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-June/009045.html\nto see that the new key was referenced in a message signed by the old one.\nI figure it's safe to assume that if the old key actually signed that\nmessage, then the core dev using <laanwj at gmail.com\n<https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>> is an\nactual core dev (that's all I'd be worried about).  So I copied the text\nfrom ------BEGIN PGP SIGNED MESSAGE----- to -----END PGP SIGNATURE----- to\nmy clipboard and asked Kleopatra (on Windows) to verify it.  It says the\nsignature is bad.  If I alter the text of the email (so the signature would\nbe have to be different to be valid), it says exactly the same thing.  So\nmaybe something is wrong with Kleopatra on Windows.\n\nHowever, the SHA256SUMS.asc file I got from the magnet link posted in the\nemail (below)  verifies just fine using the new key (36C2E964).  So I\nfigure Kleopatra is not broken.  It recognizes that the old key was used to\ncreate the signature in that old email, but it says it's invalid.  Has\nWladimir been secretly replaced by someone who doesn't have access to the\nprivate key for 2346C9A6?  Can you make a (bad) signature look like it was\nmade using a key you don't have? The whole reason for signing is so that we\nwill know if something like that happened.  So did I do something wrong?\n(I mean, besides using Windows).\n\nI believe this is the expected result if someone took something Wladimir\nsigned and ripped off the signature and pasted it below this new message to\nmake everyone think the new message was genuine.  Maybe Wladimir made an\nedit after the signature was attached.  Or maybe it got changed when it\nwent through the email system.  It would be nice to know.  Anyway, I fell\nback on Windows security and ran the install because it said it verified\nthat the publisher was \"The Bitcoin Foundation\".\n\n\nOn Fri, Nov 13, 2015 at 5:13 AM, Wladimir J. van der Laan via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> -----BEGIN PGP SIGNED MESSAGE-----\n> Hash: SHA512\n>\n> Bitcoin Core version 0.11.2 is now available from:\n>\n>   <https://bitcoin.org/bin/bitcoin-core-0.11.2/>\n>\n> Alternatively, through bittorrent:\n>\n>\n> magnet:?xt=urn:btih:d6d3387160f7e14f6f27dc40ae84cf566ebf631b&dn=bitcoin-core-0.11.2&tr=udp%3A%2F%\n> 2Ftracker.openbittorrent.com%3A80%2Fannounce&tr=udp%3A%2F%\n> 2Ftracker.publicbt.com%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.ccc.de\n> %3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.coppersurfer.tk\n> %3A6969&tr=udp%3A%2F%2Fopen.demonii.com\n> %3A1337&ws=https%3A%2F%2Fbitcoin.org%2Fbin%2F\n>\n> This is a new minor version release, bringing bug fixes, the BIP65\n> (CLTV) consensus change, and relay policy preparation for BIP113. It is\n> recommended to upgrade to this version as soon as possible.\n>\n> Please report bugs using the issue tracker at github:\n>\n>   <https://github.com/bitcoin/bitcoin/issues>\n>\n> Upgrading and downgrading\n> =========================\n>\n> How to Upgrade\n> - --------------\n>\n> If you are running an older version, shut it down. Wait until it has\n> completely\n> shut down (which might take a few minutes for older versions), then run the\n> installer (on Windows) or just copy over /Applications/Bitcoin-Qt (on Mac)\n> or\n> bitcoind/bitcoin-qt (on Linux).\n>\n> Downgrade warning\n> - ------------------\n>\n> Because release 0.10.0 and later makes use of headers-first\n> synchronization and\n> parallel block download (see further), the block files and databases are\n> not\n> backwards-compatible with pre-0.10 versions of Bitcoin Core or other\n> software:\n>\n> * Blocks will be stored on disk out of order (in the order they are\n> received, really), which makes it incompatible with some tools or\n> other programs. Reindexing using earlier versions will also not work\n> anymore as a result of this.\n>\n> * The block index database will now hold headers for which no block is\n> stored on disk, which earlier versions won't support.\n>\n> If you want to be able to downgrade smoothly, make a backup of your entire\n> data\n> directory. Without this your node will need start syncing (or importing\n> from\n> bootstrap.dat) anew afterwards. It is possible that the data from a\n> completely\n> synchronised 0.10 node may be usable in older versions as-is, but this is\n> not\n> supported and may break as soon as the older version attempts to reindex.\n>\n> This does not affect wallet forward or backward compatibility. There are no\n> known problems when downgrading from 0.11.x to 0.10.x.\n>\n> Notable changes since 0.11.1\n> ============================\n>\n> BIP65 soft fork to enforce OP_CHECKLOCKTIMEVERIFY opcode\n> - --------------------------------------------------------\n>\n> This release includes several changes related to the [BIP65][] soft fork\n> which redefines the existing OP_NOP2 opcode as OP_CHECKLOCKTIMEVERIFY\n> (CLTV) so that a transaction output can be made unspendable until a\n> specified point in the future.\n>\n> 1. This release will only relay and mine transactions spending a CLTV\n>    output if they comply with the BIP65 rules as provided in code.\n>\n> 2. This release will produce version 4 blocks by default. Please see the\n>    *notice to miners* below.\n>\n> 3. Once 951 out of a sequence of 1,001 blocks on the local node's best\n> block\n>    chain contain version 4 (or higher) blocks, this release will no\n>    longer accept new version 3 blocks and it will only accept version 4\n>    blocks if they comply with the BIP65 rules for CLTV.\n>\n> For more information about the soft-forking change, please see\n> <https://github.com/bitcoin/bitcoin/pull/6351>\n>\n> Graphs showing the progress towards block version 4 adoption may be\n> found at the URLs below:\n>\n> - - Block versions over the last 50,000 blocks as progress towards BIP65\n>   consensus enforcement: <http://bitcoin.sipa.be/ver-50k.png>\n>\n> - - Block versions over the last 2,000 blocks showing the days to the\n>   earliest possible BIP65 consensus-enforced block: <\n> http://bitcoin.sipa.be/ver-2k.png>\n>\n> **Notice to miners:** Bitcoin Core\u2019s block templates are now for\n> version 4 blocks only, and any mining software relying on its\n> getblocktemplate must be updated in parallel to use libblkmaker either\n> version 0.4.3 or any version from 0.5.2 onward.\n>\n> - - If you are solo mining, this will affect you the moment you upgrade\n>   Bitcoin Core, which must be done prior to BIP65 achieving its 951/1001\n>   status.\n>\n> - - If you are mining with the stratum mining protocol: this does not\n>   affect you.\n>\n> - - If you are mining with the getblocktemplate protocol to a pool: this\n>   will affect you at the pool operator\u2019s discretion, which must be no\n>   later than BIP65 achieving its 951/1001 status.\n>\n> [BIP65]: https://github.com/bitcoin/bips/blob/master/bip-0065.mediawiki\n>\n> BIP113 mempool-only locktime enforcement using GetMedianTimePast()\n> - ----------------------------------------------------------------\n>\n> Bitcoin transactions currently may specify a locktime indicating when\n> they may be added to a valid block.  Current consensus rules require\n> that blocks have a block header time greater than the locktime specified\n> in any transaction in that block.\n>\n> Miners get to choose what time they use for their header time, with the\n> consensus rule being that no node will accept a block whose time is more\n> than two hours in the future.  This creates a incentive for miners to\n> set their header times to future values in order to include locktimed\n> transactions which weren't supposed to be included for up to two more\n> hours.\n>\n> The consensus rules also specify that valid blocks may have a header\n> time greater than that of the median of the 11 previous blocks.  This\n> GetMedianTimePast() time has a key feature we generally associate with\n> time: it can't go backwards.\n>\n> [BIP113][] specifies a soft fork (**not enforced in this release**) that\n> weakens this perverse incentive for individual miners to use a future\n> time by requiring that valid blocks have a computed GetMedianTimePast()\n> greater than the locktime specified in any transaction in that block.\n>\n> Mempool inclusion rules currently require transactions to be valid for\n> immediate inclusion in a block in order to be accepted into the mempool.\n> This release begins applying the BIP113 rule to received transactions,\n> so transaction whose time is greater than the GetMedianTimePast() will\n> no longer be accepted into the mempool.\n>\n> **Implication for miners:** you will begin rejecting transactions that\n> would not be valid under BIP113, which will prevent you from producing\n> invalid blocks if/when BIP113 is enforced on the network. Any\n> transactions which are valid under the current rules but not yet valid\n> under the BIP113 rules will either be mined by other miners or delayed\n> until they are valid under BIP113. Note, however, that time-based\n> locktime transactions are more or less unseen on the network currently.\n>\n> **Implication for users:** GetMedianTimePast() always trails behind the\n> current time, so a transaction locktime set to the present time will be\n> rejected by nodes running this release until the median time moves\n> forward. To compensate, subtract one hour (3,600 seconds) from your\n> locktimes to allow those transactions to be included in mempools at\n> approximately the expected time.\n>\n> [BIP113]: https://github.com/bitcoin/bips/blob/master/bip-0113.mediawiki\n>\n> Windows bug fix for corrupted UTXO database on unclean shutdowns\n> - ----------------------------------------------------------------\n>\n> Several Windows users reported that they often need to reindex the\n> entire blockchain after an unclean shutdown of Bitcoin Core on Windows\n> (or an unclean shutdown of Windows itself). Although unclean shutdowns\n> remain unsafe, this release no longer relies on memory-mapped files for\n> the UTXO database, which significantly reduced the frequency of unclean\n> shutdowns leading to required reindexes during testing.\n>\n> For more information, see: <https://github.com/bitcoin/bitcoin/pull/6917>\n>\n> Other fixes for database corruption on Windows are expected in the\n> next major release.\n>\n> 0.11.2 Change log\n> =================\n>\n> Detailed release notes follow. This overview includes changes that affect\n> behavior, not code moves, refactors and string updates. For convenience in\n> locating\n> the code changes and accompanying discussion, both the pull request and\n> git merge commit are mentioned.\n>\n> - - #6124 `684636b` Make CScriptNum() take nMaxNumSize as an argument\n> - - #6124 `4fa7a04` Replace NOP2 with CHECKLOCKTIMEVERIFY (BIP65)\n> - - #6124 `6ea5ca4` Enable CHECKLOCKTIMEVERIFY as a standard script verify\n> flag\n> - - #6351 `5e82e1c` Add CHECKLOCKTIMEVERIFY (BIP65) soft-fork logic\n> - - #6353 `ba1da90` Show softfork status in getblockchaininfo\n> - - #6351 `6af25b0` Add BIP65 to getblockchaininfo softforks list\n> - - #6688 `01878c9` Fix locking in GetTransaction\n> - - #6653 `b3eaa30` [Qt] Raise debug window when requested\n> - - #6600 `1e672ae` Debian/Ubuntu: Include bitcoin-tx binary\n> - - #6600 `2394f4d` Debian/Ubuntu: Split bitcoin-tx into its own package\n> - - #5987 `33d6825` Bugfix: Allow mining on top of old tip blocks for\n> testnet\n> - - #6852 `21e58b8` build: make sure OpenSSL heeds noexecstack\n> - - #6846 `af6edac` alias `-h` for `--help`\n> - - #6867 `95a5039` Set TCP_NODELAY on P2P sockets.\n> - - #6856 `dfe55bd` Do not allow blockfile pruning during reindex.\n> - - #6566 `a1d3c6f` Add rules--presently disabled--for using\n> GetMedianTimePast as end point for lock-time calculations\n> - - #6566 `f720c5f` Enable policy enforcing GetMedianTimePast as the end\n> point of lock-time constraints\n> - - #6917 `0af5b8e` leveldb: Win32WritableFile without memory mapping\n> - - #6948 `4e895b0` Always flush block and undo when switching to new file\n>\n> Credits\n> =======\n>\n> Thanks to everyone who directly contributed to this release:\n>\n> - - Alex Morcos\n> - - \u0e3ftcDrak\n> - - Chris Kleeschulte\n> - - Daniel Cousens\n> - - Diego Viola\n> - - Eric Lombrozo\n> - - Esteban Ordano\n> - - Gregory Maxwell\n> - - Luke Dashjr\n> - - Marco Falke\n> - - Mark Friedenbach\n> - - Matt Corallo\n> - - Micha\n> - - Mitchell Cash\n> - - Peter Todd\n> - - Pieter Wuille\n> - - Wladimir J. van der Laan\n> - - Zak Wilcox\n>\n> And those who contributed additional code review and/or security research.\n>\n> As well as everyone that helped translating on [Transifex](\n> https://www.transifex.com/projects/p/bitcoin/).\n>\n> -----BEGIN PGP SIGNATURE-----\n> Version: GnuPG v1\n>\n> iQEcBAEBCgAGBQJWReHOAAoJEHSBCwEjRsmmTAAH/iZQGklLHLIM6a2tTOj4d/O6\n> xHg5bJhXGjtzO284Uy3phTzvk+e4mqBTjI8BrSr4D+Vw7mJrfWihdTLlgZYCwso3\n> AyAk8ud1H42QanAfUvciY5uXd7cyzr8tCnCIBkvwJT5O8tI3FFhSMM5Fs86WnsP1\n> Y10+93sxaVJUave2xm1bmgiwApFZKQ2MNU1IVgFaW8agB59fuqtPRnBdKiK/j+AO\n> Jn1LKsObsINYhjtkAFiC66mUOBZ2N3rdhbN3LFl+u7EriTLoYk1OtZZhlC+rOueo\n> nxl1H5SHStjrD27vE9Hv2qD5Ckrwo3zib8hZNIVs6MJjFnWUCwNtNg0nqDEvpn4=\n> =xXdY\n> -----END PGP SIGNATURE-----\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n\n-- \nI like to provide some work at no charge to prove my value. Do you need a\ntechie?\nI own Litmocracy <http://www.litmocracy.com> and Meme Racing\n<http://www.memeracing.net> (in alpha).\nI'm the webmaster for The Voluntaryist <http://www.voluntaryist.com> which\nnow accepts Bitcoin.\nI also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n\"He ought to find it more profitable to play by the rules\" - Satoshi\nNakamoto\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151113/debf1563/attachment-0001.html>"
            },
            {
                "author": "Wladimir J. van der Laan",
                "date": "2015-11-16T07:49:15",
                "message_text_only": "I'm not sure that's the right way to go about verifing gpg keys.\nCopy/pasting from webpages is going to run into padding/character set conversion issues, resulting in potential false negatives. If you want to verify mails, you have to verify the original mail, which archives don't make easy (or even possible).\n\nSo I'd do this:\n\nThe binary release signing key is signed by my normal key:\n\n$ gpg --list-sigs 36C2E964\n\n    pub   4096R/36C2E964 2015-06-24 [expires: 2017-02-13]\n    uid                  Wladimir J. van der Laan (Bitcoin Core binary release signing key) <laanwj at gmail.com>\n    sig 3        36C2E964 2015-06-24  Wladimir J. van der Laan (Bitcoin Core binary release signing key) <laanwj at gmail.com>\n    sig          2346C9A6 2015-06-24  Wladimir J. van der Laan <laanwj at visucore.com>\n\nMy normal key in turn is signed by a lot of different people.\n\n$ gpg --list-sigs 2346C9A6\n\n...\n\nAlso, both keys can be found on bitcoin.org in the list of developers, as well\nas linked on the download page:\n\nhttps://bitcoin.org/en/download\n\nWladimir\n\nOn Fri, Nov 13, 2015 at 06:10:29PM -0800, Dave Scotese via bitcoin-dev wrote:\n> I decided to try to certify Wladimir's PGP keys (the old one (2346C9A6)\n> first, and then the new one (36C2E964), since it was signed with the old\n> one).\n> \n> I visited\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-June/009045.html\n> to see that the new key was referenced in a message signed by the old one.\n> I figure it's safe to assume that if the old key actually signed that\n> message, then the core dev using <laanwj at gmail.com\n> <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>> is an\n> actual core dev (that's all I'd be worried about).  So I copied the text\n> from ------BEGIN PGP SIGNED MESSAGE----- to -----END PGP SIGNATURE----- to\n> my clipboard and asked Kleopatra (on Windows) to verify it.  It says the\n> signature is bad.  If I alter the text of the email (so the signature would\n> be have to be different to be valid), it says exactly the same thing.  So\n> maybe something is wrong with Kleopatra on Windows.\n> \n> However, the SHA256SUMS.asc file I got from the magnet link posted in the\n> email (below)  verifies just fine using the new key (36C2E964).  So I\n> figure Kleopatra is not broken.  It recognizes that the old key was used to\n> create the signature in that old email, but it says it's invalid.  Has\n> Wladimir been secretly replaced by someone who doesn't have access to the\n> private key for 2346C9A6?  Can you make a (bad) signature look like it was\n> made using a key you don't have? The whole reason for signing is so that we\n> will know if something like that happened.  So did I do something wrong?\n> (I mean, besides using Windows).\n> \n> I believe this is the expected result if someone took something Wladimir\n> signed and ripped off the signature and pasted it below this new message to\n> make everyone think the new message was genuine.  Maybe Wladimir made an\n> edit after the signature was attached.  Or maybe it got changed when it\n> went through the email system.  It would be nice to know.  Anyway, I fell\n> back on Windows security and ran the install because it said it verified\n> that the publisher was \"The Bitcoin Foundation\".\n> \n> \n> On Fri, Nov 13, 2015 at 5:13 AM, Wladimir J. van der Laan via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> > -----BEGIN PGP SIGNED MESSAGE-----\n> > Hash: SHA512\n> >\n> > Bitcoin Core version 0.11.2 is now available from:\n> >\n> >   <https://bitcoin.org/bin/bitcoin-core-0.11.2/>\n> >\n> > Alternatively, through bittorrent:\n> >\n> >\n> > magnet:?xt=urn:btih:d6d3387160f7e14f6f27dc40ae84cf566ebf631b&dn=bitcoin-core-0.11.2&tr=udp%3A%2F%\n> > 2Ftracker.openbittorrent.com%3A80%2Fannounce&tr=udp%3A%2F%\n> > 2Ftracker.publicbt.com%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.ccc.de\n> > %3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.coppersurfer.tk\n> > %3A6969&tr=udp%3A%2F%2Fopen.demonii.com\n> > %3A1337&ws=https%3A%2F%2Fbitcoin.org%2Fbin%2F\n> >\n> > This is a new minor version release, bringing bug fixes, the BIP65\n> > (CLTV) consensus change, and relay policy preparation for BIP113. It is\n> > recommended to upgrade to this version as soon as possible.\n> >\n> > Please report bugs using the issue tracker at github:\n> >\n> >   <https://github.com/bitcoin/bitcoin/issues>\n> >\n> > Upgrading and downgrading\n> > =========================\n> >\n> > How to Upgrade\n> > - --------------\n> >\n> > If you are running an older version, shut it down. Wait until it has\n> > completely\n> > shut down (which might take a few minutes for older versions), then run the\n> > installer (on Windows) or just copy over /Applications/Bitcoin-Qt (on Mac)\n> > or\n> > bitcoind/bitcoin-qt (on Linux).\n> >\n> > Downgrade warning\n> > - ------------------\n> >\n> > Because release 0.10.0 and later makes use of headers-first\n> > synchronization and\n> > parallel block download (see further), the block files and databases are\n> > not\n> > backwards-compatible with pre-0.10 versions of Bitcoin Core or other\n> > software:\n> >\n> > * Blocks will be stored on disk out of order (in the order they are\n> > received, really), which makes it incompatible with some tools or\n> > other programs. Reindexing using earlier versions will also not work\n> > anymore as a result of this.\n> >\n> > * The block index database will now hold headers for which no block is\n> > stored on disk, which earlier versions won't support.\n> >\n> > If you want to be able to downgrade smoothly, make a backup of your entire\n> > data\n> > directory. Without this your node will need start syncing (or importing\n> > from\n> > bootstrap.dat) anew afterwards. It is possible that the data from a\n> > completely\n> > synchronised 0.10 node may be usable in older versions as-is, but this is\n> > not\n> > supported and may break as soon as the older version attempts to reindex.\n> >\n> > This does not affect wallet forward or backward compatibility. There are no\n> > known problems when downgrading from 0.11.x to 0.10.x.\n> >\n> > Notable changes since 0.11.1\n> > ============================\n> >\n> > BIP65 soft fork to enforce OP_CHECKLOCKTIMEVERIFY opcode\n> > - --------------------------------------------------------\n> >\n> > This release includes several changes related to the [BIP65][] soft fork\n> > which redefines the existing OP_NOP2 opcode as OP_CHECKLOCKTIMEVERIFY\n> > (CLTV) so that a transaction output can be made unspendable until a\n> > specified point in the future.\n> >\n> > 1. This release will only relay and mine transactions spending a CLTV\n> >    output if they comply with the BIP65 rules as provided in code.\n> >\n> > 2. This release will produce version 4 blocks by default. Please see the\n> >    *notice to miners* below.\n> >\n> > 3. Once 951 out of a sequence of 1,001 blocks on the local node's best\n> > block\n> >    chain contain version 4 (or higher) blocks, this release will no\n> >    longer accept new version 3 blocks and it will only accept version 4\n> >    blocks if they comply with the BIP65 rules for CLTV.\n> >\n> > For more information about the soft-forking change, please see\n> > <https://github.com/bitcoin/bitcoin/pull/6351>\n> >\n> > Graphs showing the progress towards block version 4 adoption may be\n> > found at the URLs below:\n> >\n> > - - Block versions over the last 50,000 blocks as progress towards BIP65\n> >   consensus enforcement: <http://bitcoin.sipa.be/ver-50k.png>\n> >\n> > - - Block versions over the last 2,000 blocks showing the days to the\n> >   earliest possible BIP65 consensus-enforced block: <\n> > http://bitcoin.sipa.be/ver-2k.png>\n> >\n> > **Notice to miners:** Bitcoin Core\u2019s block templates are now for\n> > version 4 blocks only, and any mining software relying on its\n> > getblocktemplate must be updated in parallel to use libblkmaker either\n> > version 0.4.3 or any version from 0.5.2 onward.\n> >\n> > - - If you are solo mining, this will affect you the moment you upgrade\n> >   Bitcoin Core, which must be done prior to BIP65 achieving its 951/1001\n> >   status.\n> >\n> > - - If you are mining with the stratum mining protocol: this does not\n> >   affect you.\n> >\n> > - - If you are mining with the getblocktemplate protocol to a pool: this\n> >   will affect you at the pool operator\u2019s discretion, which must be no\n> >   later than BIP65 achieving its 951/1001 status.\n> >\n> > [BIP65]: https://github.com/bitcoin/bips/blob/master/bip-0065.mediawiki\n> >\n> > BIP113 mempool-only locktime enforcement using GetMedianTimePast()\n> > - ----------------------------------------------------------------\n> >\n> > Bitcoin transactions currently may specify a locktime indicating when\n> > they may be added to a valid block.  Current consensus rules require\n> > that blocks have a block header time greater than the locktime specified\n> > in any transaction in that block.\n> >\n> > Miners get to choose what time they use for their header time, with the\n> > consensus rule being that no node will accept a block whose time is more\n> > than two hours in the future.  This creates a incentive for miners to\n> > set their header times to future values in order to include locktimed\n> > transactions which weren't supposed to be included for up to two more\n> > hours.\n> >\n> > The consensus rules also specify that valid blocks may have a header\n> > time greater than that of the median of the 11 previous blocks.  This\n> > GetMedianTimePast() time has a key feature we generally associate with\n> > time: it can't go backwards.\n> >\n> > [BIP113][] specifies a soft fork (**not enforced in this release**) that\n> > weakens this perverse incentive for individual miners to use a future\n> > time by requiring that valid blocks have a computed GetMedianTimePast()\n> > greater than the locktime specified in any transaction in that block.\n> >\n> > Mempool inclusion rules currently require transactions to be valid for\n> > immediate inclusion in a block in order to be accepted into the mempool.\n> > This release begins applying the BIP113 rule to received transactions,\n> > so transaction whose time is greater than the GetMedianTimePast() will\n> > no longer be accepted into the mempool.\n> >\n> > **Implication for miners:** you will begin rejecting transactions that\n> > would not be valid under BIP113, which will prevent you from producing\n> > invalid blocks if/when BIP113 is enforced on the network. Any\n> > transactions which are valid under the current rules but not yet valid\n> > under the BIP113 rules will either be mined by other miners or delayed\n> > until they are valid under BIP113. Note, however, that time-based\n> > locktime transactions are more or less unseen on the network currently.\n> >\n> > **Implication for users:** GetMedianTimePast() always trails behind the\n> > current time, so a transaction locktime set to the present time will be\n> > rejected by nodes running this release until the median time moves\n> > forward. To compensate, subtract one hour (3,600 seconds) from your\n> > locktimes to allow those transactions to be included in mempools at\n> > approximately the expected time.\n> >\n> > [BIP113]: https://github.com/bitcoin/bips/blob/master/bip-0113.mediawiki\n> >\n> > Windows bug fix for corrupted UTXO database on unclean shutdowns\n> > - ----------------------------------------------------------------\n> >\n> > Several Windows users reported that they often need to reindex the\n> > entire blockchain after an unclean shutdown of Bitcoin Core on Windows\n> > (or an unclean shutdown of Windows itself). Although unclean shutdowns\n> > remain unsafe, this release no longer relies on memory-mapped files for\n> > the UTXO database, which significantly reduced the frequency of unclean\n> > shutdowns leading to required reindexes during testing.\n> >\n> > For more information, see: <https://github.com/bitcoin/bitcoin/pull/6917>\n> >\n> > Other fixes for database corruption on Windows are expected in the\n> > next major release.\n> >\n> > 0.11.2 Change log\n> > =================\n> >\n> > Detailed release notes follow. This overview includes changes that affect\n> > behavior, not code moves, refactors and string updates. For convenience in\n> > locating\n> > the code changes and accompanying discussion, both the pull request and\n> > git merge commit are mentioned.\n> >\n> > - - #6124 `684636b` Make CScriptNum() take nMaxNumSize as an argument\n> > - - #6124 `4fa7a04` Replace NOP2 with CHECKLOCKTIMEVERIFY (BIP65)\n> > - - #6124 `6ea5ca4` Enable CHECKLOCKTIMEVERIFY as a standard script verify\n> > flag\n> > - - #6351 `5e82e1c` Add CHECKLOCKTIMEVERIFY (BIP65) soft-fork logic\n> > - - #6353 `ba1da90` Show softfork status in getblockchaininfo\n> > - - #6351 `6af25b0` Add BIP65 to getblockchaininfo softforks list\n> > - - #6688 `01878c9` Fix locking in GetTransaction\n> > - - #6653 `b3eaa30` [Qt] Raise debug window when requested\n> > - - #6600 `1e672ae` Debian/Ubuntu: Include bitcoin-tx binary\n> > - - #6600 `2394f4d` Debian/Ubuntu: Split bitcoin-tx into its own package\n> > - - #5987 `33d6825` Bugfix: Allow mining on top of old tip blocks for\n> > testnet\n> > - - #6852 `21e58b8` build: make sure OpenSSL heeds noexecstack\n> > - - #6846 `af6edac` alias `-h` for `--help`\n> > - - #6867 `95a5039` Set TCP_NODELAY on P2P sockets.\n> > - - #6856 `dfe55bd` Do not allow blockfile pruning during reindex.\n> > - - #6566 `a1d3c6f` Add rules--presently disabled--for using\n> > GetMedianTimePast as end point for lock-time calculations\n> > - - #6566 `f720c5f` Enable policy enforcing GetMedianTimePast as the end\n> > point of lock-time constraints\n> > - - #6917 `0af5b8e` leveldb: Win32WritableFile without memory mapping\n> > - - #6948 `4e895b0` Always flush block and undo when switching to new file\n> >\n> > Credits\n> > =======\n> >\n> > Thanks to everyone who directly contributed to this release:\n> >\n> > - - Alex Morcos\n> > - - \u0e3ftcDrak\n> > - - Chris Kleeschulte\n> > - - Daniel Cousens\n> > - - Diego Viola\n> > - - Eric Lombrozo\n> > - - Esteban Ordano\n> > - - Gregory Maxwell\n> > - - Luke Dashjr\n> > - - Marco Falke\n> > - - Mark Friedenbach\n> > - - Matt Corallo\n> > - - Micha\n> > - - Mitchell Cash\n> > - - Peter Todd\n> > - - Pieter Wuille\n> > - - Wladimir J. van der Laan\n> > - - Zak Wilcox\n> >\n> > And those who contributed additional code review and/or security research.\n> >\n> > As well as everyone that helped translating on [Transifex](\n> > https://www.transifex.com/projects/p/bitcoin/).\n> >\n> > -----BEGIN PGP SIGNATURE-----\n> > Version: GnuPG v1\n> >\n> > iQEcBAEBCgAGBQJWReHOAAoJEHSBCwEjRsmmTAAH/iZQGklLHLIM6a2tTOj4d/O6\n> > xHg5bJhXGjtzO284Uy3phTzvk+e4mqBTjI8BrSr4D+Vw7mJrfWihdTLlgZYCwso3\n> > AyAk8ud1H42QanAfUvciY5uXd7cyzr8tCnCIBkvwJT5O8tI3FFhSMM5Fs86WnsP1\n> > Y10+93sxaVJUave2xm1bmgiwApFZKQ2MNU1IVgFaW8agB59fuqtPRnBdKiK/j+AO\n> > Jn1LKsObsINYhjtkAFiC66mUOBZ2N3rdhbN3LFl+u7EriTLoYk1OtZZhlC+rOueo\n> > nxl1H5SHStjrD27vE9Hv2qD5Ckrwo3zib8hZNIVs6MJjFnWUCwNtNg0nqDEvpn4=\n> > =xXdY\n> > -----END PGP SIGNATURE-----\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n> \n> \n> \n> -- \n> I like to provide some work at no charge to prove my value. Do you need a\n> techie?\n> I own Litmocracy <http://www.litmocracy.com> and Meme Racing\n> <http://www.memeracing.net> (in alpha).\n> I'm the webmaster for The Voluntaryist <http://www.voluntaryist.com> which\n> now accepts Bitcoin.\n> I also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n> \"He ought to find it more profitable to play by the rules\" - Satoshi\n> Nakamoto\n\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Matt Corallo",
                "date": "2015-11-14T04:11:01",
                "message_text_only": "Heh, though mine doesnt since I mangled the line breaks...that should\nhave been...\n\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\nStrange, the signature validates for me. If I copy the entire mail\n(including the signature and PGP armor, but not the ads) I see the hash\nof the mail as\nb3bbd0fcfcea5f4eb5b49e9c2d7ed7514259f004fbdb5930c92084d6de561238.\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v2\n\niQIcBAEBCAAGBQJWRrNYAAoJEGOJ097IOJ+hTg0P/2H5DRaG1Gd8k72VPT/DiNHP\ne8Al19f3FXIaGSiiJ2CC6Tx3d/13U8SOnbqC28vWDpCn6TR+aw7QMoLy2huyivSp\nkTuboqtTVgyt2JbwmXQHrxHIHiW70Xa/dP0sfZlQKjI47RO/gBG8ccRuIyEPgVAi\nag7bT74hL7/C1BuEB+wA9E+b8lnCjr/rFjVKp0mSzp1/5qOCnoddUatQU4zNnE6E\nWNKj+qGekqDLPzzfMH/VrE9XX0GVaQcFG2cSBSqVOL6WQHj6cqh2z7MXl1aWMkEt\nX+GYVIYJw3UUikKKsHPdNqoVRHYAmrg7OVmrYXuL4JDOneJYnihTKj7O2bFy8tBz\neDIBuqjyG8RTvNvouKCYMN89ePt1P53B0zDK9o6aQDUIkT/2a6RAdUUUencrN812\nBc5E2EEbfdEn4wFeAgLAXLZ5KFFGMlEXC8ceswQHzONnXzy6UkK0D9MexvxEZnMm\n6s3N1XBbB2Xqw04JfQ6k5r0ywV3yu1JmG0AoPuluA3xZkID2izMuSGQU2Vji/xdH\nByeeRBYMFLeTbVIIi8I5v19ThQ+j7MR7VK8A8tt3GIjNSL3grNABOlRPb7mDDIyB\noMnc48XBaRn3Rsdn3wwbmhvRGF2A5fDZ+APldVy89TNgtUXPMTlholCzY9ekiniA\nlVAHrXea2CpzbH6In7GK\n=dQCp\n-----END PGP SIGNATURE-----\n\n\n\nOn 11/14/15 04:07, Matt Corallo wrote:\n> -----BEGIN PGP SIGNED MESSAGE-----\n> Hash: SHA256\n>\n> Strange, the signature validates for me. If I copy the entire mail\n> (including the signature and PGP armor, but not the ads) I see the hash\n> of the mail as\n> b3bbd0fcfcea5f4eb5b49e9c2d7ed7514259f004fbdb5930c92084d6de561238.\n> -----BEGIN PGP SIGNATURE-----\n> Version: GnuPG v2\n> \n> iQIcBAEBCAAGBQJWRrNYAAoJEGOJ097IOJ+hTg0P/2H5DRaG1Gd8k72VPT/DiNHP\n> e8Al19f3FXIaGSiiJ2CC6Tx3d/13U8SOnbqC28vWDpCn6TR+aw7QMoLy2huyivSp\n> kTuboqtTVgyt2JbwmXQHrxHIHiW70Xa/dP0sfZlQKjI47RO/gBG8ccRuIyEPgVAi\n> ag7bT74hL7/C1BuEB+wA9E+b8lnCjr/rFjVKp0mSzp1/5qOCnoddUatQU4zNnE6E\n> WNKj+qGekqDLPzzfMH/VrE9XX0GVaQcFG2cSBSqVOL6WQHj6cqh2z7MXl1aWMkEt\n> X+GYVIYJw3UUikKKsHPdNqoVRHYAmrg7OVmrYXuL4JDOneJYnihTKj7O2bFy8tBz\n> eDIBuqjyG8RTvNvouKCYMN89ePt1P53B0zDK9o6aQDUIkT/2a6RAdUUUencrN812\n> Bc5E2EEbfdEn4wFeAgLAXLZ5KFFGMlEXC8ceswQHzONnXzy6UkK0D9MexvxEZnMm\n> 6s3N1XBbB2Xqw04JfQ6k5r0ywV3yu1JmG0AoPuluA3xZkID2izMuSGQU2Vji/xdH\n> ByeeRBYMFLeTbVIIi8I5v19ThQ+j7MR7VK8A8tt3GIjNSL3grNABOlRPb7mDDIyB\n> oMnc48XBaRn3Rsdn3wwbmhvRGF2A5fDZ+APldVy89TNgtUXPMTlholCzY9ekiniA\n> lVAHrXea2CpzbH6In7GK\n> =dQCp\n> -----END PGP SIGNATURE-----\n> \n> \n> On 11/14/15 02:10, Dave Scotese via bitcoin-dev wrote:\n>> I decided to try to certify Wladimir's PGP keys (the old one (2346C9A6)\n>> first, and then the new one (36C2E964), since it was signed with the old\n>> one).\n>>\n>> I visited\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-June/009045.html\n>> to see that the new key was referenced in a message signed by the old\n>> one.  I figure it's safe to assume that if the old key actually signed\n>> that message, then the core dev using <laanwj at gmail.com\n>> <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>> is an\n>> actual core dev (that's all I'd be worried about).  So I copied the text\n>> from ------BEGIN PGP SIGNED MESSAGE----- to -----END PGP SIGNATURE-----\n>> to my clipboard and asked Kleopatra (on Windows) to verify it.  It says\n>> the signature is bad.  If I alter the text of the email (so the\n>> signature would be have to be different to be valid), it says exactly\n>> the same thing.  So maybe something is wrong with Kleopatra on Windows.\n>>\n>> However, the SHA256SUMS.asc file I got from the magnet link posted in\n>> the email (below)  verifies just fine using the new key (36C2E964).  So\n>> I figure Kleopatra is not broken.  It recognizes that the old key was\n>> used to create the signature in that old email, but it says it's\n>> invalid.  Has Wladimir been secretly replaced by someone who doesn't\n>> have access to the private key for 2346C9A6?  Can you make a (bad)\n>> signature look like it was made using a key you don't have? The whole\n>> reason for signing is so that we will know if something like that\n>> happened.  So did I do something wrong?  (I mean, besides using Windows).\n>>\n>> I believe this is the expected result if someone took something Wladimir\n>> signed and ripped off the signature and pasted it below this new message\n>> to make everyone think the new message was genuine.  Maybe Wladimir made\n>> an edit after the signature was attached.  Or maybe it got changed when\n>> it went through the email system.  It would be nice to know.  Anyway, I\n>> fell back on Windows security and ran the install because it said it\n>> verified that the publisher was \"The Bitcoin Foundation\".\n>>\n>>\n>> On Fri, Nov 13, 2015 at 5:13 AM, Wladimir J. van der Laan via\n>> bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org\n>> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>\n>>     -----BEGIN PGP SIGNED MESSAGE-----\n>>     Hash: SHA512\n>>\n>>     Bitcoin Core version 0.11.2 is now available from:\n>>\n>>       <https://bitcoin.org/bin/bitcoin-core-0.11.2/>\n>>\n>>     Alternatively, through bittorrent:\n>>\n>>        \n>>     magnet:?xt=urn:btih:d6d3387160f7e14f6f27dc40ae84cf566ebf631b&dn=bitcoin-core-0.11.2&tr=udp%3A%2F%2Ftracker.openbittorrent.com\n>>     <http://2Ftracker.openbittorrent.com>%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.publicbt.com\n>>     <http://2Ftracker.publicbt.com>%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.ccc.de\n>>     <http://2Ftracker.ccc.de>%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.coppersurfer.tk\n>>     <http://2Ftracker.coppersurfer.tk>%3A6969&tr=udp%3A%2F%2Fopen.demonii.com\n>>     <http://2Fopen.demonii.com>%3A1337&ws=https%3A%2F%2Fbitcoin.org%2Fbin%2F\n>>\n>>     This is a new minor version release, bringing bug fixes, the BIP65\n>>     (CLTV) consensus change, and relay policy preparation for BIP113. It is\n>>     recommended to upgrade to this version as soon as possible.\n>>\n>>     Please report bugs using the issue tracker at github:\n>>\n>>       <https://github.com/bitcoin/bitcoin/issues>\n>>\n>>     Upgrading and downgrading\n>>     =========================\n>>\n>>     How to Upgrade\n>>     - --------------\n>>\n>>     If you are running an older version, shut it down. Wait until it has\n>>     completely\n>>     shut down (which might take a few minutes for older versions), then\n>>     run the\n>>     installer (on Windows) or just copy over /Applications/Bitcoin-Qt\n>>     (on Mac) or\n>>     bitcoind/bitcoin-qt (on Linux).\n>>\n>>     Downgrade warning\n>>     - ------------------\n>>\n>>     Because release 0.10.0 and later makes use of headers-first\n>>     synchronization and\n>>     parallel block download (see further), the block files and databases\n>>     are not\n>>     backwards-compatible with pre-0.10 versions of Bitcoin Core or other\n>>     software:\n>>\n>>     * Blocks will be stored on disk out of order (in the order they are\n>>     received, really), which makes it incompatible with some tools or\n>>     other programs. Reindexing using earlier versions will also not work\n>>     anymore as a result of this.\n>>\n>>     * The block index database will now hold headers for which no block is\n>>     stored on disk, which earlier versions won't support.\n>>\n>>     If you want to be able to downgrade smoothly, make a backup of your\n>>     entire data\n>>     directory. Without this your node will need start syncing (or\n>>     importing from\n>>     bootstrap.dat) anew afterwards. It is possible that the data from a\n>>     completely\n>>     synchronised 0.10 node may be usable in older versions as-is, but\n>>     this is not\n>>     supported and may break as soon as the older version attempts to\n>>     reindex.\n>>\n>>     This does not affect wallet forward or backward compatibility. There\n>>     are no\n>>     known problems when downgrading from 0.11.x to 0.10.x.\n>>\n>>     Notable changes since 0.11.1\n>>     ============================\n>>\n>>     BIP65 soft fork to enforce OP_CHECKLOCKTIMEVERIFY opcode\n>>     - --------------------------------------------------------\n>>\n>>     This release includes several changes related to the [BIP65][] soft fork\n>>     which redefines the existing OP_NOP2 opcode as OP_CHECKLOCKTIMEVERIFY\n>>     (CLTV) so that a transaction output can be made unspendable until a\n>>     specified point in the future.\n>>\n>>     1. This release will only relay and mine transactions spending a CLTV\n>>        output if they comply with the BIP65 rules as provided in code.\n>>\n>>     2. This release will produce version 4 blocks by default. Please see the\n>>        *notice to miners* below.\n>>\n>>     3. Once 951 out of a sequence of 1,001 blocks on the local node's\n>>     best block\n>>        chain contain version 4 (or higher) blocks, this release will no\n>>        longer accept new version 3 blocks and it will only accept version 4\n>>        blocks if they comply with the BIP65 rules for CLTV.\n>>\n>>     For more information about the soft-forking change, please see\n>>     <https://github.com/bitcoin/bitcoin/pull/6351>\n>>\n>>     Graphs showing the progress towards block version 4 adoption may be\n>>     found at the URLs below:\n>>\n>>     - - Block versions over the last 50,000 blocks as progress towards BIP65\n>>       consensus enforcement: <http://bitcoin.sipa.be/ver-50k.png>\n>>\n>>     - - Block versions over the last 2,000 blocks showing the days to the\n>>       earliest possible BIP65 consensus-enforced block:\n>>     <http://bitcoin.sipa.be/ver-2k.png>\n>>\n>>     **Notice to miners:** Bitcoin Core\u2019s block templates are now for\n>>     version 4 blocks only, and any mining software relying on its\n>>     getblocktemplate must be updated in parallel to use libblkmaker either\n>>     version 0.4.3 or any version from 0.5.2 onward.\n>>\n>>     - - If you are solo mining, this will affect you the moment you upgrade\n>>       Bitcoin Core, which must be done prior to BIP65 achieving its 951/1001\n>>       status.\n>>\n>>     - - If you are mining with the stratum mining protocol: this does not\n>>       affect you.\n>>\n>>     - - If you are mining with the getblocktemplate protocol to a pool: this\n>>       will affect you at the pool operator\u2019s discretion, which must be no\n>>       later than BIP65 achieving its 951/1001 status.\n>>\n>>     [BIP65]: https://github.com/bitcoin/bips/blob/master/bip-0065.mediawiki\n>>\n>>     BIP113 mempool-only locktime enforcement using GetMedianTimePast()\n>>     - ----------------------------------------------------------------\n>>\n>>     Bitcoin transactions currently may specify a locktime indicating when\n>>     they may be added to a valid block.  Current consensus rules require\n>>     that blocks have a block header time greater than the locktime specified\n>>     in any transaction in that block.\n>>\n>>     Miners get to choose what time they use for their header time, with the\n>>     consensus rule being that no node will accept a block whose time is more\n>>     than two hours in the future.  This creates a incentive for miners to\n>>     set their header times to future values in order to include locktimed\n>>     transactions which weren't supposed to be included for up to two more\n>>     hours.\n>>\n>>     The consensus rules also specify that valid blocks may have a header\n>>     time greater than that of the median of the 11 previous blocks.  This\n>>     GetMedianTimePast() time has a key feature we generally associate with\n>>     time: it can't go backwards.\n>>\n>>     [BIP113][] specifies a soft fork (**not enforced in this release**) that\n>>     weakens this perverse incentive for individual miners to use a future\n>>     time by requiring that valid blocks have a computed GetMedianTimePast()\n>>     greater than the locktime specified in any transaction in that block.\n>>\n>>     Mempool inclusion rules currently require transactions to be valid for\n>>     immediate inclusion in a block in order to be accepted into the mempool.\n>>     This release begins applying the BIP113 rule to received transactions,\n>>     so transaction whose time is greater than the GetMedianTimePast() will\n>>     no longer be accepted into the mempool.\n>>\n>>     **Implication for miners:** you will begin rejecting transactions that\n>>     would not be valid under BIP113, which will prevent you from producing\n>>     invalid blocks if/when BIP113 is enforced on the network. Any\n>>     transactions which are valid under the current rules but not yet valid\n>>     under the BIP113 rules will either be mined by other miners or delayed\n>>     until they are valid under BIP113. Note, however, that time-based\n>>     locktime transactions are more or less unseen on the network currently.\n>>\n>>     **Implication for users:** GetMedianTimePast() always trails behind the\n>>     current time, so a transaction locktime set to the present time will be\n>>     rejected by nodes running this release until the median time moves\n>>     forward. To compensate, subtract one hour (3,600 seconds) from your\n>>     locktimes to allow those transactions to be included in mempools at\n>>     approximately the expected time.\n>>\n>>     [BIP113]: https://github.com/bitcoin/bips/blob/master/bip-0113.mediawiki\n>>\n>>     Windows bug fix for corrupted UTXO database on unclean shutdowns\n>>     - ----------------------------------------------------------------\n>>\n>>     Several Windows users reported that they often need to reindex the\n>>     entire blockchain after an unclean shutdown of Bitcoin Core on Windows\n>>     (or an unclean shutdown of Windows itself). Although unclean shutdowns\n>>     remain unsafe, this release no longer relies on memory-mapped files for\n>>     the UTXO database, which significantly reduced the frequency of unclean\n>>     shutdowns leading to required reindexes during testing.\n>>\n>>     For more information, see:\n>>     <https://github.com/bitcoin/bitcoin/pull/6917>\n>>\n>>     Other fixes for database corruption on Windows are expected in the\n>>     next major release.\n>>\n>>     0.11.2 Change log\n>>     =================\n>>\n>>     Detailed release notes follow. This overview includes changes that\n>>     affect\n>>     behavior, not code moves, refactors and string updates. For\n>>     convenience in locating\n>>     the code changes and accompanying discussion, both the pull request and\n>>     git merge commit are mentioned.\n>>\n>>     - - #6124 `684636b` Make CScriptNum() take nMaxNumSize as an argument\n>>     - - #6124 `4fa7a04` Replace NOP2 with CHECKLOCKTIMEVERIFY (BIP65)\n>>     - - #6124 `6ea5ca4` Enable CHECKLOCKTIMEVERIFY as a standard script\n>>     verify flag\n>>     - - #6351 `5e82e1c` Add CHECKLOCKTIMEVERIFY (BIP65) soft-fork logic\n>>     - - #6353 `ba1da90` Show softfork status in getblockchaininfo\n>>     - - #6351 `6af25b0` Add BIP65 to getblockchaininfo softforks list\n>>     - - #6688 `01878c9` Fix locking in GetTransaction\n>>     - - #6653 `b3eaa30` [Qt] Raise debug window when requested\n>>     - - #6600 `1e672ae` Debian/Ubuntu: Include bitcoin-tx binary\n>>     - - #6600 `2394f4d` Debian/Ubuntu: Split bitcoin-tx into its own package\n>>     - - #5987 `33d6825` Bugfix: Allow mining on top of old tip blocks\n>>     for testnet\n>>     - - #6852 `21e58b8` build: make sure OpenSSL heeds noexecstack\n>>     - - #6846 `af6edac` alias `-h` for `--help`\n>>     - - #6867 `95a5039` Set TCP_NODELAY on P2P sockets.\n>>     - - #6856 `dfe55bd` Do not allow blockfile pruning during reindex.\n>>     - - #6566 `a1d3c6f` Add rules--presently disabled--for using\n>>     GetMedianTimePast as end point for lock-time calculations\n>>     - - #6566 `f720c5f` Enable policy enforcing GetMedianTimePast as the\n>>     end point of lock-time constraints\n>>     - - #6917 `0af5b8e` leveldb: Win32WritableFile without memory mapping\n>>     - - #6948 `4e895b0` Always flush block and undo when switching to\n>>     new file\n>>\n>>     Credits\n>>     =======\n>>\n>>     Thanks to everyone who directly contributed to this release:\n>>\n>>     - - Alex Morcos\n>>     - - \u0e3ftcDrak\n>>     - - Chris Kleeschulte\n>>     - - Daniel Cousens\n>>     - - Diego Viola\n>>     - - Eric Lombrozo\n>>     - - Esteban Ordano\n>>     - - Gregory Maxwell\n>>     - - Luke Dashjr\n>>     - - Marco Falke\n>>     - - Mark Friedenbach\n>>     - - Matt Corallo\n>>     - - Micha\n>>     - - Mitchell Cash\n>>     - - Peter Todd\n>>     - - Pieter Wuille\n>>     - - Wladimir J. van der Laan\n>>     - - Zak Wilcox\n>>\n>>     And those who contributed additional code review and/or security\n>>     research.\n>>\n>>     As well as everyone that helped translating on\n>>     [Transifex](https://www.transifex.com/projects/p/bitcoin/).\n>>\n>>     -----BEGIN PGP SIGNATURE-----\n>>     Version: GnuPG v1\n>>\n>>     iQEcBAEBCgAGBQJWReHOAAoJEHSBCwEjRsmmTAAH/iZQGklLHLIM6a2tTOj4d/O6\n>>     xHg5bJhXGjtzO284Uy3phTzvk+e4mqBTjI8BrSr4D+Vw7mJrfWihdTLlgZYCwso3\n>>     AyAk8ud1H42QanAfUvciY5uXd7cyzr8tCnCIBkvwJT5O8tI3FFhSMM5Fs86WnsP1\n>>     Y10+93sxaVJUave2xm1bmgiwApFZKQ2MNU1IVgFaW8agB59fuqtPRnBdKiK/j+AO\n>>     Jn1LKsObsINYhjtkAFiC66mUOBZ2N3rdhbN3LFl+u7EriTLoYk1OtZZhlC+rOueo\n>>     nxl1H5SHStjrD27vE9Hv2qD5Ckrwo3zib8hZNIVs6MJjFnWUCwNtNg0nqDEvpn4=\n>>     =xXdY\n>>     -----END PGP SIGNATURE-----\n>>     _______________________________________________\n>>     bitcoin-dev mailing list\n>>     bitcoin-dev at lists.linuxfoundation.org\n>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>>\n>>\n>> -- \n>> I like to provide some work at no charge to prove my value. Do you need\n>> a techie? \n>> I own Litmocracy <http://www.litmocracy.com> and Meme Racing\n>> <http://www.memeracing.net> (in alpha).\n>> I'm the webmaster for The Voluntaryist <http://www.voluntaryist.com>\n>> which now accepts Bitcoin.\n>> I also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n>> \"He ought to find it more profitable to play by the rules\" - Satoshi\n>> Nakamoto\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Core 0.11.2 released",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Dave Scotese",
                "Matt Corallo",
                "Wladimir J. van der Laan"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 58026
        }
    },
    {
        "title": "[bitcoin-dev] How to evaluate block size increase suggestions.",
        "thread_messages": [
            {
                "author": "Emin G\u00fcn Sirer",
                "date": "2015-11-13T16:37:51",
                "message_text_only": "By now, we have seen quite a few proposals for the block size increase.\nIt's hard not to notice that there are potentially infinitely many\nfunctions for future block size increases. One could, for instance, double\nevery N years for any rational number N, one could increase linearly, one\ncould double initially then increase linearly, one could ask the miners to\nvote on the size, one could couple the block size increase to halvings,\netc. Without judging any of these proposals on the table, one can see that\nthere are countless alternative functions one could imagine creating.\n\nI'd like to ask a question that is one notch higher: Can we enunciate what\ngrand goals a truly perfect function would achieve? That is, if we could\nlook into the future and know all the improvements to come in network\naccess technologies, see the expansion of the Bitcoin network across the\nglobe, and precisely know the placement and provisioning of all future\nnodes, what metrics would we care about as we craft a function to fit what\nis to come?\n\nTo be clear, I'd like to avoid discussing any specific block size increase\nfunction. That's very much the tangible (non-meta) block size debate, and\neveryone has their opinion and best good-faith attempt at what that\nfunction should look like. I've purposefully stayed out of that issue,\nbecause there are too many options and no metrics for evaluating proposals.\n\nInstead, I'm asking to see if there is some agreement on how to evaluate a\ngood proposal. So, the meta-question: if we were looking at the best\npossible function, how would we know? If we have N BIPs to choose from,\nwhat criteria do we look for?\n\nTo illustrate, a possible meta goal might be: \"increase the block size,\nwhile ensuring that large miners never have an advantage over small miners\nthat [they did not have in the preceding 6 months, in 2012, pick your time\nframe, or else specify the advantage in an absolute fashion].\" Or \"increase\nblock size as much as possible, subject to the constraint that 90% of the\nnodes on the network are no more than 1 minute behind one of the tails of\nthe blockchain 99% of the time.\" Or \"do not increase the blocksize until at\nleast date X.\" Or \"the increase function should be monotonic.\" And it's\nquite OK (and probably likely) to have a combination of these kinds of\nmetrics and constraints.\n\nFor disclosure, I personally do not have a horse in the block size debate,\nbesides wanting to see Bitcoin evolve and get more widely adopted. I ask\nbecause as an academic, I'd like to understand if we can use various\nsimulation and analytic techniques to examine the proposals.  A second\nreason is that it is very easy to have a proliferation of block size\nincrease proposals, and good engineering would ask that we define the\nmeta-criteria first and then pick. To do that, we need some criteria for\njudging proposals other than gut feeling.\n\nOf course, even with meta-criteria in hand, there will be room for lots of\ndisagreement because we do not actually know the future and reasonable\npeople can disagree on how things will evolve. I think this is good because\nit makes it easier to agree on meta-criteria than on an actual, specific\nfunction for increasing the block size.\n\nIt looks like some specific meta-level criteria would help more at this\npoint than new proposals all exploring a different variants of block size\nincrease schedules.\n\nBest,\n\n- egs\n\n\nP.S. This message is an off-shoot of this blog post:\n\nhttp://hackingdistributed.com/2015/11/13/suggestion-for-the-blocksize-debate/\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151113/7a88aa6c/attachment.html>"
            },
            {
                "author": "Angel Leon",
                "date": "2015-11-13T16:52:08",
                "message_text_only": "I believe in the end it's the usability of bitcoin that matters.\n\nFor instance, a goal could be that no user on the network should wait more\nthan an hour to get 3 confirmations on the blockchain so that they can\nactually have useful Bitcoins.\n\nWe can debate all we want about lots of technical aspects, but if you can't\nsend money what's the point?\n\nMy humble proposal tried to take that into consideration, but I like way\nway more what you propose with NG.\n\nhttp://twitter.com/gubatron\n\nOn Fri, Nov 13, 2015 at 11:37 AM, Emin G\u00fcn Sirer <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> By now, we have seen quite a few proposals for the block size increase.\n> It's hard not to notice that there are potentially infinitely many\n> functions for future block size increases. One could, for instance, double\n> every N years for any rational number N, one could increase linearly, one\n> could double initially then increase linearly, one could ask the miners to\n> vote on the size, one could couple the block size increase to halvings,\n> etc. Without judging any of these proposals on the table, one can see that\n> there are countless alternative functions one could imagine creating.\n>\n> I'd like to ask a question that is one notch higher: Can we enunciate what\n> grand goals a truly perfect function would achieve? That is, if we could\n> look into the future and know all the improvements to come in network\n> access technologies, see the expansion of the Bitcoin network across the\n> globe, and precisely know the placement and provisioning of all future\n> nodes, what metrics would we care about as we craft a function to fit what\n> is to come?\n>\n> To be clear, I'd like to avoid discussing any specific block size increase\n> function. That's very much the tangible (non-meta) block size debate, and\n> everyone has their opinion and best good-faith attempt at what that\n> function should look like. I've purposefully stayed out of that issue,\n> because there are too many options and no metrics for evaluating proposals.\n>\n> Instead, I'm asking to see if there is some agreement on how to evaluate a\n> good proposal. So, the meta-question: if we were looking at the best\n> possible function, how would we know? If we have N BIPs to choose from,\n> what criteria do we look for?\n>\n> To illustrate, a possible meta goal might be: \"increase the block size,\n> while ensuring that large miners never have an advantage over small miners\n> that [they did not have in the preceding 6 months, in 2012, pick your time\n> frame, or else specify the advantage in an absolute fashion].\" Or \"increase\n> block size as much as possible, subject to the constraint that 90% of the\n> nodes on the network are no more than 1 minute behind one of the tails of\n> the blockchain 99% of the time.\" Or \"do not increase the blocksize until at\n> least date X.\" Or \"the increase function should be monotonic.\" And it's\n> quite OK (and probably likely) to have a combination of these kinds of\n> metrics and constraints.\n>\n> For disclosure, I personally do not have a horse in the block size debate,\n> besides wanting to see Bitcoin evolve and get more widely adopted. I ask\n> because as an academic, I'd like to understand if we can use various\n> simulation and analytic techniques to examine the proposals.  A second\n> reason is that it is very easy to have a proliferation of block size\n> increase proposals, and good engineering would ask that we define the\n> meta-criteria first and then pick. To do that, we need some criteria for\n> judging proposals other than gut feeling.\n>\n> Of course, even with meta-criteria in hand, there will be room for lots of\n> disagreement because we do not actually know the future and reasonable\n> people can disagree on how things will evolve. I think this is good because\n> it makes it easier to agree on meta-criteria than on an actual, specific\n> function for increasing the block size.\n>\n> It looks like some specific meta-level criteria would help more at this\n> point than new proposals all exploring a different variants of block size\n> increase schedules.\n>\n> Best,\n>\n> - egs\n>\n>\n> P.S. This message is an off-shoot of this blog post:\n>\n>\n> http://hackingdistributed.com/2015/11/13/suggestion-for-the-blocksize-debate/\n>\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151113/4b303813/attachment-0001.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-14T13:48:04",
                "message_text_only": "I agree with the usefulness of at least trying to define a formal set\nof criteria.\nI'm afraid that with proposals that schedule future increases to the\nblocksize consensus maximum or leave it for miners to decide (like\nBIP100, BIP101 and BIP103) cannot be evaluated without making\nassumptions about the future (or what miners will decide in the\nfuture).\nSince limiting resource consumption and mining centralization dynamics\nare the reasons to have blocksize consensus maximum in the first\nplace, I think it would be ideal to have some simulation +\nbenchmarking software that is able to analyze a given proposal, give\nresource consumption benchmark data about average and worst cases, and\nalso give some kind of metric from \"mining centralization dynamics\nsimulations\".\nWe could start with just a metric for concrete block sizes (for\narbitrary maximum blocksizes testchains see #6382).\nNote that this is unrelated to the deployment mechanism, proposed\nactivation date and other details.\n\nOn Fri, Nov 13, 2015 at 5:52 PM, Angel Leon via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> For instance, a goal could be that no user on the network should wait more\n> than an hour to get 3 confirmations on the blockchain so that they can\n> actually have useful Bitcoins.\n\nThat depends on block space demand on a particular moment in time, the\nfee paid by the example user and local relay and mining policies in\nthe network (and how they treat transactions with the specific form of\nthe transaction example) and even the network topology.\nThere's no consensus rule that can guarantee that all transaction from\nall users will be included at most 3 blocks after they are relayed.\nFor starters, any user can create infinite transactions (without fee)\nfor free while the network will never have infinite computing\nresources.\nWhat we have is a fee estimator that observes the chain and can\nestimate the market situation to tell you the average number of blocks\nfor a given transaction with a given feerate. I know that number was\nonly 14 blocks or so for free (not a single satoshi in fees)\ntransactions, but that has probably changed with the recent attacks..."
            },
            {
                "author": "Peter R",
                "date": "2015-11-14T21:45:25",
                "message_text_only": "> It looks like some specific meta-level criteria would help more at this point than new proposals all exploring a different variants of block size increase schedules.\n\nI agree.  In fact, I\u2019ll go meta on your meta and suggest that we should first discuss how Bitcoin should be governed in the first place.  Should Bitcoin evolve from the \u201cbottom up,\u201d or from the \u201ctop down\u201d?\n\nIf one\u2019s answer is from the \u201ctop-down,\u201d then the meta-level criteria can be endlessly debated, for they all involve some sort of tradeoff, they all require some sort of compromise.  The \u201ctop down\u201d perspective holds that people might make poor choices if given the freedom to easily do so--it holds that the trade-offs must be balanced instead by experts.  \n\nHowever, if one's answer is from the \u201cbottom up,\u201d then the meta-level criteria is very easy: we do what the people wants. We allow the people to weigh the tradeoffs and then we watch as consensus emerges through a decentralized process, objectively represented by the longest proof-of-work chain.  \n\nRegarding the block size limit debate, at the end of the day it comes down to two things:\n\n1.  How big of a block will my node accept today?\n\n2.  What do I want my node to do if the longest chain includes a block larger than the limit I set?\n\nIf one concedes that Bitcoin should be governed from the \u201cbottom up,\u201d then it is already possible to empower each node operator to more easily express his free choice regarding the size of blocks he is willing to accept, while simultaneously ensuring that his node tracks consensus.\n\nBest regards,\nPeter"
            },
            {
                "author": "Johnathan Corgan",
                "date": "2015-11-15T06:04:10",
                "message_text_only": "This topic is straying from Bitcoin development into general Bitcoin\ngovernance, policy, or other meta-issues.\n\nWe have now the new bitcoin-discuss mailing list now, specifically for\nthese more free-flowing topics:\n\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-discuss\n\nPlease take further discussion of this thread to that forum.\n\nThank you,\n\nThe bitcoin-dev moderation team\n\n\nOn Sat, Nov 14, 2015 at 1:45 PM, Peter R via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> > It looks like some specific meta-level criteria would help more at this\n> point than new proposals all exploring a different variants of block size\n> increase schedules.\n>\n> I agree.  In fact, I\u2019ll go meta on your meta and suggest that we should\n> first discuss how Bitcoin should be governed in the first place.  Should\n> Bitcoin evolve from the \u201cbottom up,\u201d or from the \u201ctop down\u201d?\n>\n> If one\u2019s answer is from the \u201ctop-down,\u201d then the meta-level criteria can\n> be endlessly debated, for they all involve some sort of tradeoff, they all\n> require some sort of compromise.  The \u201ctop down\u201d perspective holds that\n> people might make poor choices if given the freedom to easily do so--it\n> holds that the trade-offs must be balanced instead by experts.\n>\n> However, if one's answer is from the \u201cbottom up,\u201d then the meta-level\n> criteria is very easy: we do what the people wants. We allow the people to\n> weigh the tradeoffs and then we watch as consensus emerges through a\n> decentralized process, objectively represented by the longest proof-of-work\n> chain.\n>\n> Regarding the block size limit debate, at the end of the day it comes down\n> to two things:\n>\n> 1.  How big of a block will my node accept today?\n>\n> 2.  What do I want my node to do if the longest chain includes a block\n> larger than the limit I set?\n>\n> If one concedes that Bitcoin should be governed from the \u201cbottom up,\u201d then\n> it is already possible to empower each node operator to more easily express\n> his free choice regarding the size of blocks he is willing to accept, while\n> simultaneously ensuring that his node tracks consensus.\n>\n> Best regards,\n> Peter\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151114/ee289deb/attachment-0001.html>"
            },
            {
                "author": "Mariusz Nowostawski",
                "date": "2015-11-14T16:08:18",
                "message_text_only": "> Date: Fri, 13 Nov 2015 11:37:51 -0500\n> From: Emin G?n Sirer <el33th4x0r at gmail.com>\n> To: bitcoin-dev at lists.linuxfoundation.org\n> Subject: [bitcoin-dev] How to evaluate block size increase\n> \tsuggestions.\n> Message-ID:\n> \t<CAPkFh0s-o6BXAEC-s9s1UmFwVfMFQKStoJaM0u2Lct9yiP5QBQ at mail.gmail.com>\n> Content-Type: text/plain; charset=\"utf-8\"\n> \n> By now, we have seen quite a few proposals for the block size increase.\n> It's hard not to notice that there are potentially infinitely many\n> functions for future block size increases. One could, for instance, double\n> every N years for any rational number N, one could increase linearly, one\n> could double initially then increase linearly, one could ask the miners to\n> vote on the size, one could couple the block size increase to halvings,\n> etc. Without judging any of these proposals on the table, one can see that\n> there are countless alternative functions one could imagine creating.\n> \n> I'd like to ask a question that is one notch higher: Can we enunciate what\n> grand goals a truly perfect function would achieve? That is, if we could\n> look into the future and know all the improvements to come in network\n> access technologies, see the expansion of the Bitcoin network across the\n> globe, and precisely know the placement and provisioning of all future\n> nodes, what metrics would we care about as we craft a function to fit what\n> is to come?\n> \n> To be clear, I'd like to avoid discussing any specific block size increase\n> function. That's very much the tangible (non-meta) block size debate, and\n> everyone has their opinion and best good-faith attempt at what that\n> function should look like. I've purposefully stayed out of that issue,\n> because there are too many options and no metrics for evaluating proposals.\n> \n> Instead, I'm asking to see if there is some agreement on how to evaluate a\n> good proposal. So, the meta-question: if we were looking at the best\n> possible function, how would we know? If we have N BIPs to choose from,\n> what criteria do we look for?\n> \n> To illustrate, a possible meta goal might be: \"increase the block size,\n> while ensuring that large miners never have an advantage over small miners\n> that [they did not have in the preceding 6 months, in 2012, pick your time\n> frame, or else specify the advantage in an absolute fashion].\" Or \"increase\n> block size as much as possible, subject to the constraint that 90% of the\n> nodes on the network are no more than 1 minute behind one of the tails of\n> the blockchain 99% of the time.\" Or \"do not increase the blocksize until at\n> least date X.\" Or \"the increase function should be monotonic.\" And it's\n> quite OK (and probably likely) to have a combination of these kinds of\n> metrics and constraints.\n> \n> For disclosure, I personally do not have a horse in the block size debate,\n> besides wanting to see Bitcoin evolve and get more widely adopted. I ask\n> because as an academic, I'd like to understand if we can use various\n> simulation and analytic techniques to examine the proposals.  A second\n> reason is that it is very easy to have a proliferation of block size\n> increase proposals, and good engineering would ask that we define the\n> meta-criteria first and then pick. To do that, we need some criteria for\n> judging proposals other than gut feeling.\n> \n> Of course, even with meta-criteria in hand, there will be room for lots of\n> disagreement because we do not actually know the future and reasonable\n> people can disagree on how things will evolve. I think this is good because\n> it makes it easier to agree on meta-criteria than on an actual, specific\n> function for increasing the block size.\n> \n> It looks like some specific meta-level criteria would help more at this\n> point than new proposals all exploring a different variants of block size\n> increase schedules.\n> \n> Best,\n> \n> - egs\n\n\n\nHi,\n\nGood point. I found it also to be important. Enumerating first exactly\nWHAT and WHY is being solved and then formulating HOW the proposed\nsolutions can be evaluated, resonates with me, probably because I'm an\nacademic. We need to be able to predict if a given proposal addresses\nthe actual problem at hand and we need to know how to evaluate the\nproposals.\n\nBut first, we need to re-evaluate the problem.  I think the original\nproblem of the increasing demands on the transaction throughput of the\nbitcoin blockchain have been derailed into a rather constrained\ndiscussion on the block size increase. This is fundamentally broken. The\ndebate should be reverted back to the actual problem: how to deal with\nthe increasing demands of the transaction throughput on the bitcoin\nblockchain, what exactly is the problem, and what possible ways exist in\ndealing with those problems? In other words, how to deal with the\nscalability of the bitcoin blockchain.\n\n\nSomewhat surprisingly, all the solutions proposals so far focused on a\n\"centralized\" model in which Bitcoin blockchain plays the central role\nin any future economy. Bitcoin has been compared to VISA and questions\nhave been asked how to handle 1000s of transactions per second - via the\nBitcoin blockchain. Should any form of electronic value transfer such as\nassets, currencies, etc be handled by THE SINGLE CHAIN? A single chain\nthat does it ALL? Is that the objective for the Bitcoin blockchain?\nThere are some contradictions: from one hand the Bitcoin blockchain\noffers transparent, distributed ledger that can be used for verification\nof transactions, which is a good thing. At the same time, it uses p2p\ntechnology, consensus, and limited transaction throughput (regardless of\nwhere the actual block size limit sits), which are bad when considering\nprocessing and validating large volumes of financial transactions such\nas currently processed by VISA.\n\nPlanning the Bitcoin blockchain to handle everything will simply never\nscale, it might turn out impossible, and also it will hinder innovation,\nand can ultimately work against the Bitcoin blockchain (e.g. by\ninadvertent and irreversible centralization of verification nodes, or\nsimply reducing the full verification nodes count).\n\n\n(Devil's advocate): limit stays on 1MB and there are more transactions\ngenerated every 10min that can potentially fit into the block. Then,\nthis follows:\n\n1. There will be a strong incentive for fees to grow.\nIs it a bad thing? Are growing fees unavoidable anyway? Miners need to\nrecover the costs of mining when the crossing-point of rewards/fees\nhappens, and that means growing fees, right?  Can this be modeled? Can\nwe predict how much the fees will actually grow to weed out all the\n\"noise\" transactions that currently get through because it is cheap to\ndo so?\n\n2. Some transactions will simply never made it to the chain.\nIs it a bad thing? Perhaps it is just a self-adaptation to weed out\n\"invaluable\" transactions from the system? Do we need to process and\ncater for ALL the transactions? Including all the NOISE that doesn't\nreally contribute to anything? Can we model this?\n\nPersonally, I think transaction fees for electronic transfers should be\nclose to ZERO, but, at the same time, I think transaction costs of\nBitcoin blockchain should be high enough to keep this chain special,\nnoise free, and compact, with large number of validating nodes working\nin p2p fashion.\n\nSo are points 1 and 2 really fundamentally BAD, or are they just a\nself-regulating anti-noise mechanism? I can pack-up thousands of\ntransactions in auxiliary systems, and validate them via a SINGLE\nbitcoin blockchain transaction, and this would scale.\n\n\n3. Companies generating large number of transactions will have to look\ninto ways of saving costs and combining multiple individual transactions\ninto larger ones to save on FEE costs.\nIs it a bad thing? No - it is a very good thing, and the sooner it\nhappens the better ;)\n\n\n4. Companies, governments and institutions would have to look into ways\nof improving their own performance and scalability OUTSIDE of the\nBitcoin blockchain. For example through client-server, extremely\nefficient centralised blockchains, Open Chain-like models, and only\nusing Bitcoin blockchain for validation/verification in a transparent\nand verifiable manner. How about running thousands of financial\ntransactions per second on open chain and only recording merkel root\nhashes for batches of transactions every 10min in a Bitcoin blockchain\nfor transparency and verification?\n\n\n\n\nSo, coming back to the original question about CRITERIA:\n\n*1* The ability to setup and run low-cost fully validating node should\nremain the same or should improve; upon deployment of a given proposal\nthere should be an increase in a number of fully validating nodes, or at\nworst, there should be no decrease.\n\n*2* The ability to include additional data into Bitcoin blockchain (e.g.\nvia OP_RETURN) should improve or, at worst, remain the same as it is now.\n\n*3* Upon deployment of a given proposal, the noise in the ledger should\nbe reduced, or at worst, remain the same.\n\n*4* A proposal should address long-term scalability, and offer the\npossibility of combining Bitcoin blockchain with well-defined auxiliary\nprotocols to offer high-transaction throughputs.\n\n\n\ncheers\nMariusz"
            }
        ],
        "thread_summary": {
            "title": "How to evaluate block size increase suggestions.",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Mariusz Nowostawski",
                "Emin G\u00fcn Sirer",
                "Angel Leon",
                "Jorge Tim\u00f3n",
                "Johnathan Corgan",
                "Peter R"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 23778
        }
    },
    {
        "title": "[bitcoin-dev] Contradiction in BIP65 text?",
        "thread_messages": [
            {
                "author": "xor",
                "date": "2015-11-13T21:48:34",
                "message_text_only": "BIP65 [1] says this:\n> Motivation\n> [...]\n> However, the nLockTime field can't prove that it is impossible to spend a\n> transaction output until some time in the future, as there is no way to\n> know if a valid signature for a different transaction spending that output\n> has been created.\n\nI'd interpret \"can't prove that it is impossible to spend\" = cannot be used \nfor freezing funds.\n\nThen later, at \"Motivation\", it says:\n> Freezing Funds\n> \n> In addition to using cold storage, hardware wallets, and P2SH multisig\n> outputs to control funds, now funds can be frozen in UTXOs directly on the\n> blockchain.\n\nThis clearly says that funds can be frozen.\nCan the BIP65-thing be used to freeze funds or can it not be?\n\nNotice: I am by no means someone who is able to read Bitcoin script. I'm \nrather an end user. So maybe I'm misinterpreting the document?\nI'm nevertheless trying to provide a \"neutral\" review from an outsider who's \ntrying to understand whats new in 0.11.2.\nYou may want to discard my opinion if you think that BIP65 is aimed at an \naudience with more experience.\n\nGreetings and thanks for your work!\n\n[1] \nhttps://github.com/bitcoin/bips/blob/d0cab0379aa50cdf4a9d1ab9e29c3366034ad77f/bip-0065.mediawiki\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 836 bytes\nDesc: This is a digitally signed message part.\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151113/81565bca/attachment.sig>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2015-11-13T21:53:57",
                "message_text_only": "On Fri, Nov 13, 2015 at 9:48 PM, xor via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> BIP65 [1] says this:\n>> Motivation\n>> [...]\n>> However, the nLockTime field can't prove that it is impossible to spend a\n>> transaction output until some time in the future, as there is no way to\n>> know if a valid signature for a different transaction spending that output\n>> has been created.\n>\n> I'd interpret \"can't prove that it is impossible to spend\" = cannot be used\n> for freezing funds.\n>\n> Then later, at \"Motivation\", it says:\n>> Freezing Funds\n>>\n>> In addition to using cold storage, hardware wallets, and P2SH multisig\n>> outputs to control funds, now funds can be frozen in UTXOs directly on the\n>> blockchain.\n>\n> This clearly says that funds can be frozen.\n> Can the BIP65-thing be used to freeze funds or can it not be?\n>\n> Notice: I am by no means someone who is able to read Bitcoin script. I'm\n> rather an end user. So maybe I'm misinterpreting the document?\n> I'm nevertheless trying to provide a \"neutral\" review from an outsider who's\n> trying to understand whats new in 0.11.2.\n> You may want to discard my opinion if you think that BIP65 is aimed at an\n> audience with more experience.\n\n\nThe first text is explaining nlocktime without BIP65 in order to\nexplain the reason for having BIP65."
            },
            {
                "author": "xor",
                "date": "2015-11-13T22:08:55",
                "message_text_only": "On Friday, November 13, 2015 09:53:57 PM Gregory Maxwell wrote:\n> The first text is explaining nlocktime without BIP65 in order to\n> explain the reason for having BIP65.\n\nThanks. I would recommend changing the BIP65 to clarify what you just said, \nthis clearly is the missing piece of information there.\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 836 bytes\nDesc: This is a digitally signed message part.\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151113/7a585341/attachment.sig>"
            },
            {
                "author": "Jeff Garzik",
                "date": "2015-11-13T23:58:07",
                "message_text_only": "On Fri, Nov 13, 2015 at 4:48 PM, xor via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> This clearly says that funds can be frozen.\n> Can the BIP65-thing be used to freeze funds or can it not be?\n>\n\n\nThis language definitely trips up or worries several folks - it's been\nmentioned a few times before.\n\nThe user _chooses_ to freeze _their own_ funds.  It is not an unwilling act\nof force, which many assume when they see the phrase \"freeze funds.\"\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151113/2a23202a/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2015-11-14T00:29:51",
                "message_text_only": "On Fri, Nov 13, 2015 at 11:58 PM, Jeff Garzik via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> On Fri, Nov 13, 2015 at 4:48 PM, xor via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> This clearly says that funds can be frozen.\n>> Can the BIP65-thing be used to freeze funds or can it not be?\n> This language definitely trips up or worries several folks - it's been\n> mentioned a few times before.\n>\n> The user _chooses_ to freeze _their own_ funds.  It is not an unwilling act\n> of force, which many assume when they see the phrase \"freeze funds.\"\n\n\nThe most frequent related point of confusion I see is that people have\na dangerously wrong mental model of how scrpitpubkeys work.\n\nIt seems people think that wallets will infer whatever they can\npossibly spend and display that.  This is not how wallets work, and if\nany wallet were ever created like that its users would immediately go\nbroke (and it's author should be taken out and shot. :) ).\n\nRather, wallets must only display funds paid to scriptpubkeys (also\naddresses) they actually generated or, at least, would have generated.\n\nOtherwise someone can just create a 1 of 2 {them, you}  multisig and\nthen claw back the coins after you think you've been paid.\n\nAs such there is no risk of anyone sneaking in CLTV locked funds for\non you except by virtue of spectacular software bugs that would likely\ncause you to destroy funds in a zillion other ways first."
            },
            {
                "author": "xor",
                "date": "2015-11-14T22:47:23",
                "message_text_only": "On Friday, November 13, 2015 06:58:07 PM Jeff Garzik wrote:\n> On Fri, Nov 13, 2015 at 4:48 PM, xor via bitcoin-dev <\n> \n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > This clearly says that funds can be frozen.\n> > Can the BIP65-thing be used to freeze funds or can it not be?\n> \n> This language definitely trips up or worries several folks - it's been\n> mentioned a few times before.\n> \n> The user _chooses_ to freeze _their own_ funds.  It is not an unwilling act\n> of force, which many assume when they see the phrase \"freeze funds.\"\n\nOh, interesting, albeit that was not subject of my question.\n\nMy question in fact was whether *I* can use it to freeze *my* funds; because I \nthink that would be an interesting feature for various purposes.\nFrom the state of BIP65 I talked about, it is not even clear whether that is \npossible.\n\nYour observation beyond that is a valid concern though.\nSo both should be addressed.\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 836 bytes\nDesc: This is a digitally signed message part.\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151114/d16fea08/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Contradiction in BIP65 text?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeff Garzik",
                "Gregory Maxwell",
                "xor"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 6773
        }
    },
    {
        "title": "[bitcoin-dev] request to use service bit 28 for testing",
        "thread_messages": [
            {
                "author": "Peter Tschipper",
                "date": "2015-11-14T23:27:49",
                "message_text_only": "I'd like to use service bit 28 for testing the block compression\nprototype unless anyone has any objections or is using it already.\n\nThanks."
            },
            {
                "author": "Peter Todd",
                "date": "2015-11-16T23:24:05",
                "message_text_only": "On Sat, Nov 14, 2015 at 03:27:49PM -0800, Peter Tschipper via bitcoin-dev wrote:\n> I'd like to use service bit 28 for testing the block compression\n> prototype unless anyone has any objections or is using it already.\n\nGo for it!\n\nAFAIK the only testing service bit in use right now is bit 26, used to\nindicate full-RBF support by my replace-by-fee branch:\n\nhttps://github.com/petertodd/bitcoin/tree/replace-by-fee-v0.11.2\n\nSpeaking of, you may find the preferential peering code in the above to\nbe useful. It's a bit of a hack, but it does work.\n\n-- \n'peter'[:-1]@petertodd.org\n000000000000000009c6356b4a0f309636e2b87e263063bee18ac22e91a57deb\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151116/bba4de27/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "request to use service bit 28 for testing",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Peter Tschipper",
                "Peter Todd"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 1059
        }
    },
    {
        "title": "[bitcoin-dev] [patch] Switching Bitcoin Core to sqlite db",
        "thread_messages": [
            {
                "author": "Peter R",
                "date": "2015-11-15T01:02:33",
                "message_text_only": "Hi Greg,\n\nLike you said, the issue with using more than one database technology is not that one node would prove that Block X is valid while the another node proves that Block X is NOT valid.  Instead, the problem is that one node might say \u201cvalid\u201d while the other node says \u201cI don\u2019t know.\u201d\n\nIt is often said that what caused the Level DB fork was that the old version determined that the triggering block was invalid while the new version determined the opposite.  This interpretation of the fork event has lead to the \u201cbug-for-bug\u201d-compatibility fear regarding multiple implementations of the protocol (or multiple database technologies).  In reality, this fear is largely unfounded.  \n\nThe old version ran out of LDB locks and couldn\u2019t execute properly.  If the software was written with the philosophy that tracking consensus was more important than bug-for-bug compatibility, it would have returned an exception rather than \u201cinvalid.\u201d  At that point, the software would have checked what decision the rest of the network came to about the block in question.   My node would have forked to the longest chain, automatically assuming that the questionable block was valid; your node may have made a different decision (it\u2019s a question of ideology at that point).      \n\nA group of us have been exploring this \u201cmeta-cognition\u201d idea with Bitcoin Unlimited.  For example, Bitcoin Unlimited can be (optionally) made to automatically fork to the longest chain if it \u201cgets stuck\u201d and can neither prove that a block is valid nor that the block is invalid.  Similarly, Bitcoin Unlimited can be (optionally) made to automatically fork to a chain that contains a block marginally bigger than its block size limit\u2014once that block is buried sufficiently in what has emerged as the longest persistent chain. \n\nThinking from this perspective might go along way towards decentralizing development, the emergence of multiple competing implementations of the protocol, and true \u201cbottom up\u201d governance.  \n\nBest regards,\nPeter\n\n\n\n> On Oct 29, 2015, at 9:28 PM, Gregory Maxwell <gmaxwell at gmail.com> wrote:\n> \n> On Fri, Oct 30, 2015 at 4:04 AM, Peter R <peter_r at gmx.com> wrote:\n>> Can you give a specific example of how nodes that used different database technologies might determine different answers to whether a given transaction is valid or invalid?  I\u2019m not a database expert, but to me it would seem that if all the unspent outputs can be found in the database, and if the relevant information about each output can be retrieved without corruption, then that\u2019s all that really matters as far as the database is concerned.\n> \n> If you add to those set of assumptions the handling of write ordering\n> is the same (e.g. multiple updates in an change end up with the same\n> entry surviving) and read/write interleave returning the same results\n> then it wouldn't.\n> \n> But databases sometimes have errors which cause them to fail to return\n> records, or to return stale data. And if those exist consistency must\n> be maintained; and \"fixing\" the bug can cause a divergence in\n> consensus state that could open users up to theft.\n> \n> Case in point, prior to leveldb's use in Bitcoin Core it had a bug\n> that, under rare conditions, could cause it to consistently return not\n> found on records that were really there (I'm running from memory so I\n> don't recall the specific cause).  Leveldb fixed this serious bug in a\n> minor update.  But deploying a fix like this in an uncontrolled manner\n> in the bitcoin network would potentially cause a fork in the consensus\n> state; so any such fix would need to be rolled out in an orderly\n> manner.\n> \n>> I\u2019d like a concrete example to help me understand why more than one implementation of something like the UTXO database would be unreasonable.\n> \n> It's not unreasonable, but great care is required around the specifics.\n> \n> Bitcoin consensus implements a mathematical function that defines the\n> operation of the system and above all else all systems must agree (or\n> else the state can diverge and permit double-spends);  if you could\n> prove that a component behaves identically under all inputs to another\n> function then it can be replaced without concern but this is something\n> that cannot be done generally for all software, and proving\n> equivalence even in special cases it is an open area of research.  The\n> case where the software itself is identical or nearly so is much\n> easier to gain confidence in the equivalence of a change through\n> testing and review.\n> \n> With that cost in mind one must then consider the other side of the\n> equation-- utxo database is an opaque compressed representation,\n> several of the posts here have been about desirability of blockchain\n> analysis interfaces, and I agree they're sometimes desirable but\n> access to the consensus utxo database is not helpful for that.\n> Similarly, other things suggested are so phenomenally slow that it's\n> unlikely that a node would catch up and stay synced even on powerful\n> hardware.  Regardless, in Bitcoin core the storage engine for this is\n> fully internally abstracted and so it is relatively straight forward\n> for someone to drop something else in to experiment with; whatever the\n> motivation.\n> \n> I think people are falling into a trap of thinking \"It's a <database>,\n> I know a <black box> for that!\"; but the application and needs are\n> very specialized here; no less than, say-- the table of pre-computed\n> EC points used for signing in the ECDSA application. It just so\n> happens that on the back of the very bitcoin specific cryptographic\n> consensus algorithim there was a slot where a pre-existing high\n> performance key-value store fit; and so we're using one and saving\n> ourselves some effort.  If, in the future, Bitcoin Core adopts a\n> merkelized commitment for the UTXO it would probably need to stop\n> using any off-the-shelf key value store entirely, in order to avoid a\n> 20+ fold write inflation from updating hash tree paths (And Bram Cohen\n> has been working on just such a thing, in fact)."
            },
            {
                "author": "Gregory Maxwell",
                "date": "2015-11-15T01:08:16",
                "message_text_only": "On Sun, Nov 15, 2015 at 1:02 AM, Peter R <peter_r at gmx.com> wrote:\n> Hi Greg,\n>\n> Like you said, the issue with using more than one database technology is not that one node would prove that Block X is valid while the another node proves that Block X is NOT valid.  Instead, the problem is that one node might say \u201cvalid\u201d while the other node says \u201cI don\u2019t know.\u201d\n\nSometimes errors are such that you can catch them (if you're super\nvigilant and know an error is even possible in that case)-- and\nindeed, in that case you can get a \"I don't know, something is\nwrong.\", other times errors are undetectable.\n\n> In reality, this fear is largely unfounded.\n\nI cited an issue in leveldb (before we used it) where it would\nsilently fail to return records.\n\n> If the software was written with the philosophy that tracking consensus was more important than bug-for-bug compatibility, it would have returned an exception rather than \u201cinvalid.\u201d\n\nThat invariant requires the software to be completely free of errors\nthat would violate it."
            },
            {
                "author": "Peter R",
                "date": "2015-11-15T01:45:03",
                "message_text_only": "> On Nov 14, 2015, at 5:08 PM, Gregory Maxwell <gmaxwell at gmail.com> wrote:\n> \n> On Sun, Nov 15, 2015 at 1:02 AM, Peter R <peter_r at gmx.com> wrote:\n>> Hi Greg,\n>> \n>> Like you said, the issue with using more than one database technology is not that one node would prove that Block X is valid while the another node proves that Block X is NOT valid.  Instead, the problem is that one node might say \u201cvalid\u201d while the other node says \u201cI don\u2019t know.\u201d\n> \n> Sometimes errors are such that you can catch them (if you're super\n> vigilant and know an error is even possible in that case)-- and\n> indeed, in that case you can get a \"I don't know, something is\n> wrong.\", other times errors are undetectable.\n\nAgreed.  There are two cases to consider:\n\nType 1.  One implementation says \u201cyes\u201d or \u201cno,\u201d while the other says \u201cI don\u2019t know\u201d, and\n\nType 2.  One implementation says \u201cyes\u201d and the other says \u201cno,\u201d because of a bug.  \n\nMy previous email described how Type 1 consensus failures can be safely dealt with.  These include many kinds of database exceptions (e.g., the LevelDB fork at block #225,430), or consensus mismatches regarding the max size of a block.  \n\nType 2 consensus failures are more severe but also less likely (I\u2019m not aware of a Type 2 consensus failure besides the 92 million bitcoin bug from August 2010).  If Core was to accept a rogue TX that created another 92 million bitcoins, I think it would be a good thing if the other implementations forked away from it (we don\u2019t want bug-for-bug compatibility here).   \n\nThis once again reveals the benefits of multiple competing implementations.  \n\nSincerely,\nPeter"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2015-11-15T02:10:43",
                "message_text_only": "On Sun, Nov 15, 2015 at 1:45 AM, Peter R <peter_r at gmx.com> wrote:\n> My previous email described how Type 1 consensus failures can be safely dealt with.  These include many kinds of database exceptions (e.g., the LevelDB fork at block #225,430), or consensus mismatches regarding the max size of a block.\n\nThe size of a block is not a type 1 failure. There is a clear, known,\nunambiguous, and easily measured rule in the system that a block is\nnot permitted to have a size over a threshold. A block that violates\nthis threshold is invalid.   The only way I can see to classify that\nas a type 1 failure is to call the violation of any known system rule\na type 1 failure.  \"Spends a coin that was already spent\" \"provides a\nsignature that doesn't verify with the pubkey\" \"creates bitcoins out\nof thin air\" -- these are not logically different than \"if size>x\nreturn false\".\n\n> Type 2 consensus failures are more severe but also less likely (I\u2019m not aware of a Type 2 consensus failure besides the 92 million bitcoin bug from August 2010).  If Core was to accept a rogue TX that created another 92 million bitcoins, I think it would be a good thing if the other implementations forked away from it (we don\u2019t want bug-for-bug compatibility here).\n\nThe only consensus consistency error we've ever that I would have\nclassified as potentially type 1 had has been the BDB locks issue.\nEvery other one, including the most recently fixed one (eliminated by\nBIP66) was a type 2, by your description. They are _much_ more common;\nbecause if the author understood the possible cases well enough to\ncreate an \"I don't know\" case, they could have gone one step further\nand fully defined it in a consistent way. The fact that an\ninconsistency was possible was due to a lack of complete knowledge.\n\nEven in the BDB locks case, I don't know that the type 1 distinction\ncompletely applies, a lower layer piece of software threw an error\nthat higher layer software didn't know was possible, and so it\ninterpreted \"I don't know\" as \"no\"-- it's not that it chose to treat I\ndon't know as no, its that it wasn't authored with the possibility of\nI don't know in mind, and that exceptions were used to handle general\nfailures (which should have been treated as no). Once you step back to\nthe boundary of the calling code (much less the whole application) the\n\"I don't know\" doesn't exist anymore; there."
            },
            {
                "author": "Peter R",
                "date": "2015-11-15T02:58:50",
                "message_text_only": "> On Nov 14, 2015, at 6:10 PM, Gregory Maxwell <gmaxwell at gmail.com> wrote:\n> \n> On Sun, Nov 15, 2015 at 1:45 AM, Peter R <peter_r at gmx.com> wrote:\n>> My previous email described how Type 1 consensus failures can be safely dealt with.  These include many kinds of database exceptions (e.g., the LevelDB fork at block #225,430), or consensus mismatches regarding the max size of a block.\n> \n> The size of a block is not a type 1 failure. There is a clear, known,\n> unambiguous, and easily measured rule in the system that a block is\n> not permitted to have a size over a threshold. A block that violates\n> this threshold is invalid.  \n\nYou are looking at the problem from a \u201ctop down\u201d governance perspective assuming you know what code is actually being run and what rules the market wants.  The reality is that you can only make estimates about these two things.  As Bitcoin evolves away from the current development monoculture, rules such as the max block size may no longer be perfectly clear.  However, we can prove that the following results will continue to hold:\n\n1. A node with a block size limit greater than the hash-power weighted median will always follow the longest chain.\n\n2. An excessive (e.g., greater than 1 MB) block will be accepted into the longest chain if it is smaller than the hash-power weighted median block size limit.\n\nAlready today, different nodes have different block size limits.  There are even some miners today that will attempt to build upon blocks larger than 1 MB if anyone dares to create one.  At some point, the majority of the hash power will support something larger than 1 MB.  When that first bigger block comes and gets buried in the longest chain, hold-out nodes (e.g., MP says he will never increase his limit) will have to make a choice: fight consensus or track consensus!  I know that I would want my node to give up on its block size limit and track consensus.  You may decide to make a different choice.  \n\nYou said that \"a block that violates this [block size limit] threshold is invalid.\u201d  I agree.  If the nodes and miners rejected the block as invalid then it would not persist as the longest chain. If the nodes and miners accepted the block and continued to build on top of it, then that chain would be Bitcoin (whether you personally agree of not).  \n\nBitcoin is ultimately a creature of the market, governed by the code people freely choose to run. Consensus is then an emergent property, objectively represented by the longest persistent chain.  Proof-of-work both enforces and defines the rules of the network.  \n\n\n>  The only way I can see to classify that\n> as a type 1 failure is to call the violation of any known system rule\n> a type 1 failure.  \"Spends a coin that was already spent\" \"provides a\n> signature that doesn't verify with the pubkey\" \"creates bitcoins out\n> of thin air\" -- these are not logically different than \"if size>x\n> return false\u201d.\n\nI think you\u2019re being intentionally obtuse here: accepting a block composed entirely of valid transactions that is 1.1 MB is entirely different than accepting a TX that creates a ten thousand bitcoins out of thin air.  The market would love the former but abhor the later.  I believe you can recognize the difference.  \n\n\n>> Type 2 consensus failures are more severe but also less likely (I\u2019m not aware of a Type 2 consensus failure besides the 92 million bitcoin bug from August 2010).  If Core was to accept a rogue TX that created another 92 million bitcoins, I think it would be a good thing if the other implementations forked away from it (we don\u2019t want bug-for-bug compatibility here).\n> \n> The only consensus consistency error we've ever that I would have\n> classified as potentially type 1 had has been the BDB locks issue.\n\nThank you for conceding on that point. \n\n> Every other one, including the most recently fixed one (eliminated by\n> BIP66) was a type 2, by your description. They are _much_ more common;\n> because if the author understood the possible cases well enough to\n> create an \"I don't know\" case, they could have gone one step further\n> and fully defined it in a consistent way. The fact that an\n> inconsistency was possible was due to a lack of complete knowledge.\n> \n> Even in the BDB locks case, I don't know that the type 1 distinction\n> completely applies, a lower layer piece of software threw an error\n> that higher layer software didn't know was possible, and so it\n> interpreted \"I don't know\" as \"no\"-- it's not that it chose to treat I\n> don't know as no, its that it wasn't authored with the possibility of\n> I don't know in mind, and that exceptions were used to handle general\n> failures (which should have been treated as no). Once you step back to\n> the boundary of the calling code (much less the whole application) the\n> \"I don't know\" doesn't exist anymore; there.\n\nPlease don\u2019t take my comments and observations as criticisms.  I think the Core Dev team has done excellent work!  What I am saying instead is that as we move forward\u2014as development becomes decentralized and multiple protocol implementations emerge\u2014development philosophies will change. Tracking consensus and the will of the market will be most important.  Personally, I hope to see design philosophies that support \u201cbottom up\u201d governance instead of the current \u201ctop down\u201d model.  \n\nBest regards,\nPeter"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2015-11-15T03:30:45",
                "message_text_only": "On Sun, Nov 15, 2015 at 2:58 AM, Peter R <peter_r at gmx.com> wrote:\n> I think you\u2019re being intentionally obtuse here: accepting a block composed entirely of valid transactions that is 1.1 MB is entirely different than accepting a TX that creates a ten thousand bitcoins out of thin air.  The market would love the former but abhor the later.  I believe you can recognize the difference.\n\nIt is not technically distinct--today; politically-- perhaps, but--\nsorry, no element of your prior message indicated that you were\ninterested in discussing politics rather than technology; on a mailing\nlist much more strongly scoped for the latter; I hope you can excuse\nme for missing your intention prior to your most recent post.\n\nThat said, I believe you are privileging your own political\npreferences in seeing the one rule of the bitcoin system as\ncategorically distinct even politically. No law of nature leaves the\nother criteria I specified less politically negotiable, and we can see\nconcrete examples all around us -- the notion that funds can be\nconfiscated via external authority (spending without the owners\nsignature) is a more or less universal property of other modern\nsystems of money, that economic controls out to exist to regulate the\nsupply of money for the good of an economy is another widely deployed\npolitical perspective. You, yourself, recently published a work on the\nstable self regulation of block sizes based on mining incentives that\ntook as its starting premise a bitcoin that was forever inflationary.\nCertainly things differ in degrees, but this is not the mailing list\nto debate the details of political inertia.\n\n> Thank you for conceding on that point.\n\nYou're welcome, but I would have preferred that you instead of your\nthanks you would have responded in kind and acknowledged my correction\nthat other consensus inconsistencies discovered in implementations\nthus far (none, that I'm aware of) could be classified as \"maybe\"; and\nin doing so retained a semblance of a connection to a the technical\npurposes of this mailing list."
            },
            {
                "author": "Peter R",
                "date": "2015-11-15T04:10:30",
                "message_text_only": "Hi Greg,\n\n>> Thank you for conceding on that point.\n> \n> You're welcome, but I would have preferred that you instead of your\n> thanks you would have responded in kind and acknowledged my correction\n> that other consensus inconsistencies discovered in implementations\n> thus far (none, that I'm aware of) could be classified as \"maybe\"; and\n> in doing so retained a semblance of a connection to a the technical\n> purposes of this mailing list.\n\nI apologize for that, Greg.  I have not read enough on the issues you brought up to comment intelligibly.  I should have conceded that you could very well be correct that those were Type 2 consensus failures.  \n\n>> I think you\u2019re being intentionally obtuse here: accepting a block composed entirely of valid transactions that is 1.1 MB is entirely different than accepting a TX that creates a ten thousand bitcoins out of thin air.  The market would love the former but abhor the later.  I believe you can recognize the difference.\n> \n> It is not technically distinct--today; politically-- perhaps, but--\n> sorry, no element of your prior message indicated that you were\n> interested in discussing politics rather than technology; on a mailing\n> list much more strongly scoped for the latter; I hope you can excuse\n> me for missing your intention prior to your most recent post.\n\nThe difference between a 1.1 MB block full of valid transactions and an invalid TX that creates 10,000 BTC out of thin air is *not* a matter of \u201cpolitics.\u201d  If people could freely award themselves coins, then Bitcoin would not be money.  It\u2019s like saying that \u201ctechnically\u201d there\u2019s no difference between picking up a penny from the sidewalk and holding up a bank teller at gunpoint.  Ask the average person: there is more than a \u201cpolitical\u201d difference between creating coins out of thin air and increasing the block size limit. \n \n> That said, I believe you are privileging your own political\n> preferences in seeing the one rule of the bitcoin system as\n> categorically distinct even politically.\n\nWhat rules does Bitcoin obey?  What is Bitcoin\u2019s nature?  This brings us to the age-old debate between Rationalism versus Empiricism.\n\nRationalism holds that some propositions are known to be true by intuition alone and that others are knowable by being deduced from intuited propositions. The Rationalist may hold the view that Bitcoin has a 21-million coin limit or a 1 MB block size limit, based on deductive reasoning from the rules enforced by the Bitcoin Core source code. Such a Rationalists might believe that the code represents some immutable truth and then his understanding of Bitcoin follows from axiomatic deductions from that premise.\n\nThe Empiricist rejects the Rationalist\u2019s intuition and deduction, believing instead that knowledge is necessarily a posteriori, dependent upon observation and sense experience. The Empiricist questions the notion that Bitcoin has a 21-million coin limit, instead observing that its money supply grew by 50 BTC per block for the first 210,000 and then 25 BTC per block ever since. The Empiricist rejects the idea that Bitcoin has any sort of block size limit, having observed previous empirical limits collapse in the face of increased demand.\n\nI am not convinced that Bitcoin even *has* a block size limit, let alone that it can enforce one against the invisible hand of the market.  \n\n> No law of nature leaves the\n> other criteria I specified less politically negotiable, and we can see\n> concrete examples all around us -- the notion that funds can be\n> confiscated via external authority (spending without the owners\n> signature) is a more or less universal property of other modern\n> systems of money, that economic controls out to exist to regulate the\n> supply of money for the good of an economy is another widely deployed\n> political perspective. You, yourself, recently published a work on the\n> stable self regulation of block sizes based on mining incentives that\n> took as its starting premise a bitcoin that was forever inflationary.\n> Certainly things differ in degrees, but this is not the mailing list\n> to debate the details of political inertia.\n\nYou were the one who just brought up politics, Greg.  Not I. \n\nBest regards,\nPeter"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-15T10:12:22",
                "message_text_only": "On Nov 15, 2015 5:10 AM, \"Peter R via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> What rules does Bitcoin obey?\n\nThanks to the worl of many people, part of the consensus rules are finally\nencapsulated in the libbitcoinconsensus library. I'm currently writing a\ndocument to complete the encapsulation of the specification of the\nconsensus rules.\n\n> I am not convinced that Bitcoin even *has* a block size limit, let alone\nthat it can enforce one against the invisible hand of the market.\n\nYou keep insisting that some consensus rules are not consensus rules while\nothers \"are clearly a very different thing\". What technical difference is\nthere between the rule that impedes me from creating transactions bigger\nthan X and the rules that prevent me frm creatin new coins (not as a miner,\nas a regular user in a transaction with more coins in the outputs than in\nthe inputs)? What about property enforcement? If the invisible hand of the\nmarket is what decides consensus rules instead of their (still incomple)\nspecification (aka libconsensus), then the market could decide to stop\nenforcing ownership.\nWill you still think that Bitcoin is a useful system when/if you\nempirically observe the invisible hand of the market taking coins out of\nyour pocket?\n\nYou also keep assuming that somehow it is a universal law that users must\neventually converge under the most-work chain. People follow the most-work\nVALID chain, but if they consciously decide to implement different rules\n(different definitions of \"valid block\") then their chains can diverge, and\nonce they do they won't converge again (unless/until one group decides to\nimplement the rules of the other exactly again), just like when the\nimplementation of the rules diverge in a unintentional consensus fork. But\nin this case they could decide to never implement the same rules.\nSee bip99 and specially the \"schism hardforks\" section for more details.\n\n> You were the one who just brought up politics, Greg.  Not I.\n\nPlease, read the thread again. I think it is pretty clear that you did.\nNothing wrong with that, just move it to the discussion ml.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151115/15c036c5/attachment.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-15T11:28:44",
                "message_text_only": "Going back on topic, I believe libconsensus shouldn't depend on any\nparticular database because assuming it will continue to be stateless\n(the current libbitcoinconsensus is stateless) end therefore has no\nstorage. I know some people disagree in various degrees.\nAt the same time, the parts of the consensus rules verification that\ndepends on storage has not been encapsulated out to\nlibbitcoinconsensus yet, and I agree that changing the database is\nunnecessarily risky at this point.\nEven when the consensus rules are encapsulated, that doesn't mean that\nBitcoin Core should be DB agnostic or that we can guarantee that it\nwill follow the longest valid chain with databases that have not been\ntested."
            },
            {
                "author": "Peter R",
                "date": "2015-11-15T15:48:35",
                "message_text_only": "> On Nov 15, 2015, at 3:28 AM, Jorge Tim\u00f3n <jtimon at jtimon.cc> wrote:\n> \n> Going back on topic, I believe libconsensus shouldn't depend on any\n> particular database because assuming it will continue to be stateless\n> (the current libbitcoinconsensus is stateless) end therefore has no\n> storage.\n\nAgreed."
            },
            {
                "author": "Peter R",
                "date": "2015-11-15T17:06:58",
                "message_text_only": "Hello Jorge:\n> > What rules does Bitcoin obey? \n> \n> Thanks to the worl of many people, part of the consensus rules are finally encapsulated in the libbitcoinconsensus library. I'm currently writing a document to complete the encapsulation of the specification of the consensus rules.\n> \nI applaud your work on the consensus library.  I think it an important step to encouraging multiple competing implementations of the protocol.\n> > I am not convinced that Bitcoin even *has* a block size limit, let alone that it can enforce one against the invisible hand of the market.\n> \n> You keep insisting that some consensus rules are not consensus rules while others \"are clearly a very different thing\". What technical difference is there between the rule that impedes me from creating transactions bigger than X and the rules that prevent me frm creatin new coins (not as a miner, as a regular user in a transaction with more coins in the outputs than in the inputs)?\n> \nWhat technical difference is there between a cat and a dog? They both have four legs and a furry coat. \n\nI think you\u2019re using the term \u201ctechnical difference\u201d to mean something very specific.  Perhaps you could clarify exactly how you are defining that term because to me it is crystal clear that creating coins out of thin air is very different than accepting a block 1.1 MB in size and full of valid TXs.  There are many technical differences between the two. For example, technically the first allows coins to be created randomly while the second doesn\u2019t.  \n> What about property enforcement? If the invisible hand of the market is what decides consensus rules instead of their (still incomple) specification (aka libconsensus), then the market could decide to stop enforcing ownership.\n> \nCorrect.  Bitcoin is an experiment and could still fail (e.g., the network could allow people to move coins without valid signatures).  For Bitcoin to be viable, the network of miners and node operators being net-econo-rational actually is probably a core axiom that must be accepted.  \n> You also keep assuming that somehow it is a universal law that users must eventually converge under the most-work chain. People follow the most-work VALID chain, but if they consciously decide to implement different rules (different definitions of \"valid block\") then their chains can diverge, and once they do they won't converge again (unless/until one group decides to implement the rules of the other exactly again)\n> \nIt is fact that two competing forks can persist for at least a short amount of time\u2014we saw this a few years ago with the LevelDB bug and again this summer with the SPV mining incident.  In both cases, there was tremendous pressure to converge back to a single chain.\n\nCould two chains persist indefinitely?  I don\u2019t know.  No one knows.  My gut feeling is that since users would have coins on both sides of the fork, there would be a fork arbitrage event (a \u201cforkbitrage\u201d) where speculators would sell the coins on the side they predict to lose in exchange for additional coins on the side they expect to win.  This could actually be facilitated by exchanges once the fork event is credible and before the fork actually occurs, or even in a futures market somehow.  I suspect that the forkbitrage would create an unstable equilibrium where coins on one side quickly devalue.  Miners would then abandon that side in favour of the other, killing the fork because difficulty would be too high to find new blocks.  Anyways, I think even *this* would be highly unlikely.  I suspect nodes and miners would get inline with consensus as soon as the fork event was credible.  \n\nCryptocurrency is a new area of interdisciplinary research.  We are all learning together and no one knows how things will unfold.  \n\nBest regards,\nPeter\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151115/864944e1/attachment.html>"
            },
            {
                "author": "Tamas Blummer",
                "date": "2015-11-17T13:54:19",
                "message_text_only": "Isolating storage from the rest of consensus code is technically desirable, but implementations using different storage will be unlikely bug-for-bug compatible,\nhence able to split the network.\n\nSuch split was disastrous on the network level if partitions were of comparable magnitude - as was the case in the March 2013 fork between versions of Bitcoin Core.\n\nThis means high level implementation diversity was great, provided we would get there without blowing up the network on the way from monoculture to true decentralization of code.\n\nLibconsensus is immensely valuable to get diversity, as it makes alternate implementations bug-for-bug compatible for a big part of the consensus code.\n\nTamas Blummer\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 496 bytes\nDesc: Message signed with OpenPGP using GPGMail\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151117/fc390dd3/attachment.sig>"
            },
            {
                "author": "Tom Harding",
                "date": "2015-11-17T15:24:42",
                "message_text_only": "On Nov 17, 2015 5:54 AM, \"Tamas Blummer via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Isolating storage from the rest of consensus code is technically\ndesirable, but implementations using different storage will be unlikely\nbug-for-bug compatible,\n> hence able to split the network.\n\nThe problem with unknown bugs is you don't know how serious they are.  A\nserious bug could itself be devastating.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151117/39c94d1d/attachment.html>"
            },
            {
                "author": "telemaco",
                "date": "2015-11-17T22:17:33",
                "message_text_only": "Shouldn't a odbc jdbc jconnect or equivalent be totally transparent for the consensus code? I mean, the client would write or store the data communicating to the driver provided by the vendor. Using the schema bitcoin suggests adapted to many different vendors (one table schema for Oracle, other for mysql, etc with their slight syntax particularities), installed in the machine with the node and from that communication to the driver  the storage would be totally controlled by the third party rdbms. \nRegarding bugs or risk of fork, does not have actual client any defense against someone forking core and slightly changing the actual database used maybe wrongly and creating a fork by themselves? \nDoes the client have any way to verify that what is stored is correct? Maybe inserting a column with a hash of what is stored in each row and another column with a incremental row by row hash composed by the hash of each row and the previous column one., so any tampering in a previous row can be verified up to where is not consistent.\nI just imagine what would be for people to be able to access easily (with the thousands of software packages already bought and licensed by ALL companies in the world that already use open standard connectivity or equivalents)., the bitcoin blockchain. \nSUBSCRIPTION: for a couple decades replication servers have allowed a publish/subscription model using replication agents. If I am a guy working on a lever in the warehouse with my pda I do not need on my pda all the company info or maybe all the blockchain. If a company., that has already licensed a rdbms package with dozens of related software packages needs one guy to suscribe to something on the bitcoin blockchain, he can either use one of the purchased methods in their company and access the company database that holds blockchain data or hire a rare bitcoin developer that will create a interfaz bitcoin for a specific need up to the millions of needs out there. \nPUBLISHING Maybe even to have a publishing daemon that would allow those companies and their software packages to write things in the bitcoin blockchain provided of couse that they fund the agent with a small bitcoin amount to send transactions and they comply with the database constraint of being the owners of the private key. The publishing agent would check for changes every X minutes on that specific address  in the db and if funded it would publish \"send\" the transaction through the bitcoin client. People would be able to publish info on the decentralized ledger from 90% of enterprise software packages.,paying ofc  and with the small delay of the publishing agent checking for changes. In fact the db would allow publishing info while the publishing agent could just take its time publishing at its own rate like a slow write cache.\nIn any case shouldn't even actual consensus be shielded from a malfunctioning or Ill forked database from core client\n\nEl 17 de noviembre de 2015 16:24:42 CET, Tom Harding <tomh at thinlink.com> escribi\u00f3:\n>On Nov 17, 2015 5:54 AM, \"Tamas Blummer via bitcoin-dev\" <\n>bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> Isolating storage from the rest of consensus code is technically\n>desirable, but implementations using different storage will be unlikely\n>bug-for-bug compatible,\n>> hence able to split the network.\n>\n>The problem with unknown bugs is you don't know how serious they are. \n>A\n>serious bug could itself be devastating.\n\n-- \nSent from my Android device with K-9 Mail. Please excuse my brevity.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151117/cf843748/attachment.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-20T14:15:20",
                "message_text_only": "On Tue, Nov 17, 2015 at 11:17 PM, telemaco via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Shouldn't a odbc jdbc jconnect or equivalent be totally transparent for the\n> consensus code?\n\nYes, but we're only testing levelDB and we couldn't assure that it\nwon't produce unintentional consensus forks with other databases\nbehind the whatever db-agnostic interface.\nI believe Bitcoin Core should officially support only one database at\na time. And if that is to change in the future, I don't think it\nshould be before a storage-agnostic libconsensus is encapsulated (and\nafter that there will still be risks and costs in officially\nsupporting several several databases simultaneously).\nAs has been said, these kind of experiments are welcomed outside of\nbitcoin/master though."
            },
            {
                "author": "Rusty Russell",
                "date": "2015-11-16T01:52:28",
                "message_text_only": "Peter R via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> writes:\n> You are looking at the problem from a \u201ctop down\u201d governance\n> perspective assuming you know what code is actually being run and what\n> rules the market wants.\n\nWe have strayed far from both the Subject line and from making progress\non bitcoin development.  Please redirect to bitcoin-discuss.\n\nI have set the moderation bits on the three contributors from here down\n(CC'd): your next post will go to moderation.\n\nThanks,\nRusty."
            },
            {
                "author": "Luke Dashjr",
                "date": "2015-11-15T03:04:33",
                "message_text_only": "On Sunday, November 15, 2015 1:02:33 AM Peter R via bitcoin-dev wrote:\n> A group of us have been exploring this \u201cmeta-cognition\u201d idea with Bitcoin\n> Unlimited.  For example, Bitcoin Unlimited can be (optionally) made to\n> automatically fork to the longest chain if it \u201cgets stuck\u201d and can neither\n> prove that a block is valid nor that the block is invalid.\n\nThis situation isn't something that can be ignored and simply moved past. If \nyou can't determine the validity of a block, you also cannot process its \nresults correctly. Taking for example the BDB/LevelDB issue, the result was \nthat BDB failed to accept further changes to the UTXO set. Unless the UTXO set \ncould be updated correctly, there is no way to even attempt to validate the \nnext block or any new transactions.\n\nLuke"
            },
            {
                "author": "Peter R",
                "date": "2015-11-15T03:17:08",
                "message_text_only": "> On Sunday, November 15, 2015 1:02:33 AM Peter R via bitcoin-dev wrote:\n>> A group of us have been exploring this \u201cmeta-cognition\u201d idea with Bitcoin\n>> Unlimited.  For example, Bitcoin Unlimited can be (optionally) made to\n>> automatically fork to the longest chain if it \u201cgets stuck\u201d and can neither\n>> prove that a block is valid nor that the block is invalid.\n> \n> This situation isn't something that can be ignored and simply moved past. If \n> you can't determine the validity of a block, you also cannot process its \n> results correctly. Taking for example the BDB/LevelDB issue, the result was \n> that BDB failed to accept further changes to the UTXO set. Unless the UTXO set \n> could be updated correctly, there is no way to even attempt to validate the \n> next block or any new transactions.\n\nGreat point, Luke! \n\nIndeed, whether the program can or cannot continue after a Type 1 consensus mismatch depends on the specifics of the situation and exactly how the code was written.  But I agree: there are cases where the program *can\u2019t* continue.  In those cases it would halt.  This would require manual intervention to fix but avoids the problem of potential double-spends during the fork event.  This would be preferable to knowingly causing a fork.  \n\nPeter"
            },
            {
                "author": "Jonathan Wilkins",
                "date": "2015-11-18T00:06:44",
                "message_text_only": "Benchmarks for various DBs under discussion:\nhttp://symas.com/mdb/microbench/\n\n\nOn Mon, Oct 26, 2015 at 11:06 AM, Douglas Roark via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On 2015/10/23 03:30, Tom Zander via bitcoin-dev wrote:\n> > On Thursday 22 Oct 2015 17:26:42 Jeff Garzik via bitcoin-dev wrote:\n> >> It was noted that leveldb is unmaintained, and this is part of\n> researching\n> >> alternatives that are maintained and reliable.\n> >\n> > Apart from it being unmaintained, any links to what are problems with\n> levelDB?\n>\n> While not exactly the most rigorous link,\n> https://en.wikipedia.org/wiki/LevelDB#Bugs_and_Reliability seems like an\n> okay place to start. One thing I can attest to is that, when Armory used\n> LevelDB (0.8 - 0.92, IIRC), quite a few users had DB corruption issues,\n> particularly on Windows. Even when a switch to LMDB occurred for 0.93,\n> loads of complaints would come in from users whose LevelDB-based Core\n> DBs would fail. I know that the guy who moved Armory over to LMDB would\n> love to have more time in the day so that he could write a Core patch\n> that does the same. It's a very sore spot for him.\n>\n> (FWIW, LMDB seems to work quite nicely, at least once you patch up the\n> source a little bit. The latest version is also compatible with Core's\n> cross-compiling scheme. I'd love to see it added to Core one day.)\n>\n> Doug\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151117/394c3283/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Switching Bitcoin Core to sqlite db",
            "categories": [
                "bitcoin-dev",
                "patch"
            ],
            "authors": [
                "Rusty Russell",
                "Tamas Blummer",
                "Jonathan Wilkins",
                "telemaco",
                "Jorge Tim\u00f3n",
                "Gregory Maxwell",
                "Luke Dashjr",
                "Peter R",
                "Tom Harding"
            ],
            "messages_count": 19,
            "total_messages_chars_count": 40423
        }
    },
    {
        "title": "[bitcoin-dev] RFC - BIP: URI scheme for Blockchain exploration",
        "thread_messages": [
            {
                "author": "Marco Pontello",
                "date": "2015-11-15T02:14:44",
                "message_text_only": "Hi!\n\nTo anyone that followed the discussion (from some time ago) about the\nproposed new URI for Blockchain references / exploration, I just wanted to\npoint out that I have collected the feedback provided, reworked the text,\nput the BIP on GitHub and created a pull request:\n\nhttps://github.com/MarcoPon/bips/blob/master/bip-MarcoPon-01.mediawiki\nhttps://github.com/bitcoin/bips/pull/202\n\nThe need for an URI for this come to mind again in the last days looking at\nEternity Wall, which IMHO provide a use case that we will see more and more\nin the (near) future: http://eternitywall.it/\nUsing that service, when you want to check for the proof that a specific\nmessage was written in the Blockchain, it let you choose from 5 different\nexplorer.\nMycelium wallet recently added the option to select one of 15 block\nexplorers.\nAnd there's the crypto_bot on reddit/r/bitcoin that detect reference to\ntransaction an add a message with links to 7 different explorers.\n\nI think that's clearly something that's needed.\n\nBye!\n\n\nOn Sat, Aug 29, 2015 at 1:48 PM, Marco Pontello <marcopon at gmail.com> wrote:\n\n> Hi!\n> My first post here, hope I'm following the right conventions.\n> I had this humble idea for a while, so I thought to go ahead and propose\n> it.\n>\n> BIP: XX\n> Title: URI scheme for Blockchain exploration\n> Author: Marco Pontello\n> Status: Draft\n> Type: Standards Track\n> Created: 29 August 2015\n>\n> Abstract\n> ========\n> This BIP propose a simple URI scheme for looking up blocks, transactions,\n> addresses on a Blockchain explorer.\n>\n> Motivation\n> ==========\n> The purpose of this URI scheme is to enable users to handle all the\n> requests for details about blocks, transactions, etc. with their preferred\n> tool (being that a web service or a local application).\n>\n> Currently a Bitcoin client usually point to an arbitrary blockchain\n> explorer when the user look for the details of a transaction (es. Bitcoin\n> Wallet use BitEasy, Mycelium or Electrum use Blockchain.info, etc.).\n> Other times resorting to cut&paste is needed.\n> The same happens with posts and messages that reference some particular\n> txs or blocks, if they provide links at all.\n>\n> Specification\n> =============\n> The URI follow this simple form:\n>\n> blockchain: <hash/string>\n>\n> Examples:\n>\n> blockchain:00000000000000001003e880d500968d51157f210c632e08a652af3576600198\n> blockchain:001949\n> blockchain:3b95a766d7a99b87188d6875c8484cb2b310b78459b7816d4dfc3f0f7e04281a\n>\n> Rationale\n> =========\n> I thought about using some more complex scheme, or adding qualifiers to\n> distinguish blocks from txs, but in the end I think that keeping it simple\n> should be practical enough. Blockchain explorers can apply the same\n> disambiguation rules they are already using to process the usual search\n> box.\n>\n> From the point of view of a wallet developer (or other tool that need to\n> show any kind of Blockchain references), using this scheme mean that he\n> can simply make it a blockchain: link and be done with it, without having\n> to worry about any specific Blockchain explorer or provide a means for the\n> user to select one.\n>\n> Blockchain explorers in turn will simply offer to handle the blockchain:\n> URI, the first time the user visit their website, or launch/install the\n> application, or even set themselves if there isn't already one.\n>\n> Users get the convenience of using always their preferred explorer, which\n> can be especially handy on mobile devices, where juggling with cut&paste\n> is far from ideal.\n>\n>\n>\n\n\n-- \nTry the Online TrID File Identifier\nhttp://mark0.net/onlinetrid.aspx\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151115/0a084af7/attachment.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-15T11:42:33",
                "message_text_only": "Thank you for incorporating the feedback, specifically thank you for\nusing the genesis block hash as the unique chain ID.\n\nI wen't through the BIP draft and left a few of comments, but I really\nlike its simplicity and focus. Good work!\n\nOn Sun, Nov 15, 2015 at 3:14 AM, Marco Pontello via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Hi!\n>\n> To anyone that followed the discussion (from some time ago) about the\n> proposed new URI for Blockchain references / exploration, I just wanted to\n> point out that I have collected the feedback provided, reworked the text,\n> put the BIP on GitHub and created a pull request:\n>\n> https://github.com/MarcoPon/bips/blob/master/bip-MarcoPon-01.mediawiki\n> https://github.com/bitcoin/bips/pull/202\n>\n> The need for an URI for this come to mind again in the last days looking at\n> Eternity Wall, which IMHO provide a use case that we will see more and more\n> in the (near) future: http://eternitywall.it/\n> Using that service, when you want to check for the proof that a specific\n> message was written in the Blockchain, it let you choose from 5 different\n> explorer.\n> Mycelium wallet recently added the option to select one of 15 block\n> explorers.\n> And there's the crypto_bot on reddit/r/bitcoin that detect reference to\n> transaction an add a message with links to 7 different explorers.\n>\n> I think that's clearly something that's needed.\n>\n> Bye!\n>\n>\n> On Sat, Aug 29, 2015 at 1:48 PM, Marco Pontello <marcopon at gmail.com> wrote:\n>>\n>> Hi!\n>> My first post here, hope I'm following the right conventions.\n>> I had this humble idea for a while, so I thought to go ahead and propose\n>> it.\n>>\n>> BIP: XX\n>> Title: URI scheme for Blockchain exploration\n>> Author: Marco Pontello\n>> Status: Draft\n>> Type: Standards Track\n>> Created: 29 August 2015\n>>\n>> Abstract\n>> ========\n>> This BIP propose a simple URI scheme for looking up blocks, transactions,\n>> addresses on a Blockchain explorer.\n>>\n>> Motivation\n>> ==========\n>> The purpose of this URI scheme is to enable users to handle all the\n>> requests for details about blocks, transactions, etc. with their preferred\n>> tool (being that a web service or a local application).\n>>\n>> Currently a Bitcoin client usually point to an arbitrary blockchain\n>> explorer when the user look for the details of a transaction (es. Bitcoin\n>> Wallet use BitEasy, Mycelium or Electrum use Blockchain.info, etc.).\n>> Other times resorting to cut&paste is needed.\n>> The same happens with posts and messages that reference some particular\n>> txs or blocks, if they provide links at all.\n>>\n>> Specification\n>> =============\n>> The URI follow this simple form:\n>>\n>> blockchain: <hash/string>\n>>\n>> Examples:\n>>\n>>\n>> blockchain:00000000000000001003e880d500968d51157f210c632e08a652af3576600198\n>> blockchain:001949\n>>\n>> blockchain:3b95a766d7a99b87188d6875c8484cb2b310b78459b7816d4dfc3f0f7e04281a\n>>\n>> Rationale\n>> =========\n>> I thought about using some more complex scheme, or adding qualifiers to\n>> distinguish blocks from txs, but in the end I think that keeping it simple\n>> should be practical enough. Blockchain explorers can apply the same\n>> disambiguation rules they are already using to process the usual search\n>> box.\n>>\n>> From the point of view of a wallet developer (or other tool that need to\n>> show any kind of Blockchain references), using this scheme mean that he\n>> can simply make it a blockchain: link and be done with it, without having\n>> to worry about any specific Blockchain explorer or provide a means for the\n>> user to select one.\n>>\n>> Blockchain explorers in turn will simply offer to handle the blockchain:\n>> URI, the first time the user visit their website, or launch/install the\n>> application, or even set themselves if there isn't already one.\n>>\n>> Users get the convenience of using always their preferred explorer, which\n>> can be especially handy on mobile devices, where juggling with cut&paste\n>> is far from ideal.\n>>\n>>\n>\n>\n>\n> --\n> Try the Online TrID File Identifier\n> http://mark0.net/onlinetrid.aspx\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Marco Pontello",
                "date": "2015-11-16T00:59:46",
                "message_text_only": "Thanks for the comments! Now I fixed the typos (hope to have got them all,\nEnglish isn't my first language), clarified the chain part a bit, and fixed\nthe link. There probably is a better way to reference that source code part\nwith the genesis blocks hashs, in a way that doesn't need to be changed,\nmaybe...\n\nNow the main change would be to put in a proper BIP number! :)\n\nOn Sun, Nov 15, 2015 at 12:42 PM, Jorge Tim\u00f3n <jtimon at jtimon.cc> wrote:\n\n> Thank you for incorporating the feedback, specifically thank you for\n> using the genesis block hash as the unique chain ID.\n>\n> I wen't through the BIP draft and left a few of comments, but I really\n> like its simplicity and focus. Good work!\n>\n> On Sun, Nov 15, 2015 at 3:14 AM, Marco Pontello via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > Hi!\n> >\n> > To anyone that followed the discussion (from some time ago) about the\n> > proposed new URI for Blockchain references / exploration, I just wanted\n> to\n> > point out that I have collected the feedback provided, reworked the text,\n> > put the BIP on GitHub and created a pull request:\n> >\n> > https://github.com/MarcoPon/bips/blob/master/bip-MarcoPon-01.mediawiki\n> > https://github.com/bitcoin/bips/pull/202\n> >\n> > The need for an URI for this come to mind again in the last days looking\n> at\n> > Eternity Wall, which IMHO provide a use case that we will see more and\n> more\n> > in the (near) future: http://eternitywall.it/\n> > Using that service, when you want to check for the proof that a specific\n> > message was written in the Blockchain, it let you choose from 5 different\n> > explorer.\n> > Mycelium wallet recently added the option to select one of 15 block\n> > explorers.\n> > And there's the crypto_bot on reddit/r/bitcoin that detect reference to\n> > transaction an add a message with links to 7 different explorers.\n> >\n> > I think that's clearly something that's needed.\n> >\n> > Bye!\n> >\n> >\n> > On Sat, Aug 29, 2015 at 1:48 PM, Marco Pontello <marcopon at gmail.com>\n> wrote:\n> >>\n> >> Hi!\n> >> My first post here, hope I'm following the right conventions.\n> >> I had this humble idea for a while, so I thought to go ahead and propose\n> >> it.\n> >>\n> >> BIP: XX\n> >> Title: URI scheme for Blockchain exploration\n> >> Author: Marco Pontello\n> >> Status: Draft\n> >> Type: Standards Track\n> >> Created: 29 August 2015\n> >>\n> >> Abstract\n> >> ========\n> >> This BIP propose a simple URI scheme for looking up blocks,\n> transactions,\n> >> addresses on a Blockchain explorer.\n> >>\n> >> Motivation\n> >> ==========\n> >> The purpose of this URI scheme is to enable users to handle all the\n> >> requests for details about blocks, transactions, etc. with their\n> preferred\n> >> tool (being that a web service or a local application).\n> >>\n> >> Currently a Bitcoin client usually point to an arbitrary blockchain\n> >> explorer when the user look for the details of a transaction (es.\n> Bitcoin\n> >> Wallet use BitEasy, Mycelium or Electrum use Blockchain.info, etc.).\n> >> Other times resorting to cut&paste is needed.\n> >> The same happens with posts and messages that reference some particular\n> >> txs or blocks, if they provide links at all.\n> >>\n> >> Specification\n> >> =============\n> >> The URI follow this simple form:\n> >>\n> >> blockchain: <hash/string>\n> >>\n> >> Examples:\n> >>\n> >>\n> >>\n> blockchain:00000000000000001003e880d500968d51157f210c632e08a652af3576600198\n> >> blockchain:001949\n> >>\n> >>\n> blockchain:3b95a766d7a99b87188d6875c8484cb2b310b78459b7816d4dfc3f0f7e04281a\n> >>\n> >> Rationale\n> >> =========\n> >> I thought about using some more complex scheme, or adding qualifiers to\n> >> distinguish blocks from txs, but in the end I think that keeping it\n> simple\n> >> should be practical enough. Blockchain explorers can apply the same\n> >> disambiguation rules they are already using to process the usual search\n> >> box.\n> >>\n> >> From the point of view of a wallet developer (or other tool that need to\n> >> show any kind of Blockchain references), using this scheme mean that he\n> >> can simply make it a blockchain: link and be done with it, without\n> having\n> >> to worry about any specific Blockchain explorer or provide a means for\n> the\n> >> user to select one.\n> >>\n> >> Blockchain explorers in turn will simply offer to handle the blockchain:\n> >> URI, the first time the user visit their website, or launch/install the\n> >> application, or even set themselves if there isn't already one.\n> >>\n> >> Users get the convenience of using always their preferred explorer,\n> which\n> >> can be especially handy on mobile devices, where juggling with cut&paste\n> >> is far from ideal.\n> >>\n> >>\n> >\n> >\n> >\n> > --\n> > Try the Online TrID File Identifier\n> > http://mark0.net/onlinetrid.aspx\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n>\n\n\n\n-- \nTry the Online TrID File Identifier\nhttp://mark0.net/onlinetrid.aspx\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151116/978ce25b/attachment-0001.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-16T14:43:44",
                "message_text_only": "Not a native english speaker myself, so I may have missed some things...\n\nYes, sorry about the link. I guess you can point to #6230 . I can\nrebase it if needed but I would close it again because I don't want to\nhave too many things from #6382 opened at the same time (is noisy and\nworse for review). My plan was to not open it independently at least\nuntil after #6907 (and actually after 0.12 assuming #6907 gets in by\n0.12). But then I would maybe open a new one and reference the old one\nrather than reopening #6230 (which tends to be confusing).\nI'm not really sure what's the best answer here...but #6382 is\ncertainly going to need rebase and the link will be broken again.\nMaybe one answer is to copy some text from #6230 or the commit and add\nit directly to the BIP instead of referencing to that commit (which\nwill be, at least until #6907 is merged, a moving target).\n\nOn Mon, Nov 16, 2015 at 1:59 AM, Marco Pontello <marcopon at gmail.com> wrote:\n> Thanks for the comments! Now I fixed the typos (hope to have got them all,\n> English isn't my first language), clarified the chain part a bit, and fixed\n> the link. There probably is a better way to reference that source code part\n> with the genesis blocks hashs, in a way that doesn't need to be changed,\n> maybe...\n>\n> Now the main change would be to put in a proper BIP number! :)\n>\n> On Sun, Nov 15, 2015 at 12:42 PM, Jorge Tim\u00f3n <jtimon at jtimon.cc> wrote:\n>>\n>> Thank you for incorporating the feedback, specifically thank you for\n>> using the genesis block hash as the unique chain ID.\n>>\n>> I wen't through the BIP draft and left a few of comments, but I really\n>> like its simplicity and focus. Good work!\n>>\n>> On Sun, Nov 15, 2015 at 3:14 AM, Marco Pontello via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> > Hi!\n>> >\n>> > To anyone that followed the discussion (from some time ago) about the\n>> > proposed new URI for Blockchain references / exploration, I just wanted\n>> > to\n>> > point out that I have collected the feedback provided, reworked the\n>> > text,\n>> > put the BIP on GitHub and created a pull request:\n>> >\n>> > https://github.com/MarcoPon/bips/blob/master/bip-MarcoPon-01.mediawiki\n>> > https://github.com/bitcoin/bips/pull/202\n>> >\n>> > The need for an URI for this come to mind again in the last days looking\n>> > at\n>> > Eternity Wall, which IMHO provide a use case that we will see more and\n>> > more\n>> > in the (near) future: http://eternitywall.it/\n>> > Using that service, when you want to check for the proof that a specific\n>> > message was written in the Blockchain, it let you choose from 5\n>> > different\n>> > explorer.\n>> > Mycelium wallet recently added the option to select one of 15 block\n>> > explorers.\n>> > And there's the crypto_bot on reddit/r/bitcoin that detect reference to\n>> > transaction an add a message with links to 7 different explorers.\n>> >\n>> > I think that's clearly something that's needed.\n>> >\n>> > Bye!\n>> >\n>> >\n>> > On Sat, Aug 29, 2015 at 1:48 PM, Marco Pontello <marcopon at gmail.com>\n>> > wrote:\n>> >>\n>> >> Hi!\n>> >> My first post here, hope I'm following the right conventions.\n>> >> I had this humble idea for a while, so I thought to go ahead and\n>> >> propose\n>> >> it.\n>> >>\n>> >> BIP: XX\n>> >> Title: URI scheme for Blockchain exploration\n>> >> Author: Marco Pontello\n>> >> Status: Draft\n>> >> Type: Standards Track\n>> >> Created: 29 August 2015\n>> >>\n>> >> Abstract\n>> >> ========\n>> >> This BIP propose a simple URI scheme for looking up blocks,\n>> >> transactions,\n>> >> addresses on a Blockchain explorer.\n>> >>\n>> >> Motivation\n>> >> ==========\n>> >> The purpose of this URI scheme is to enable users to handle all the\n>> >> requests for details about blocks, transactions, etc. with their\n>> >> preferred\n>> >> tool (being that a web service or a local application).\n>> >>\n>> >> Currently a Bitcoin client usually point to an arbitrary blockchain\n>> >> explorer when the user look for the details of a transaction (es.\n>> >> Bitcoin\n>> >> Wallet use BitEasy, Mycelium or Electrum use Blockchain.info, etc.).\n>> >> Other times resorting to cut&paste is needed.\n>> >> The same happens with posts and messages that reference some particular\n>> >> txs or blocks, if they provide links at all.\n>> >>\n>> >> Specification\n>> >> =============\n>> >> The URI follow this simple form:\n>> >>\n>> >> blockchain: <hash/string>\n>> >>\n>> >> Examples:\n>> >>\n>> >>\n>> >>\n>> >> blockchain:00000000000000001003e880d500968d51157f210c632e08a652af3576600198\n>> >> blockchain:001949\n>> >>\n>> >>\n>> >> blockchain:3b95a766d7a99b87188d6875c8484cb2b310b78459b7816d4dfc3f0f7e04281a\n>> >>\n>> >> Rationale\n>> >> =========\n>> >> I thought about using some more complex scheme, or adding qualifiers to\n>> >> distinguish blocks from txs, but in the end I think that keeping it\n>> >> simple\n>> >> should be practical enough. Blockchain explorers can apply the same\n>> >> disambiguation rules they are already using to process the usual search\n>> >> box.\n>> >>\n>> >> From the point of view of a wallet developer (or other tool that need\n>> >> to\n>> >> show any kind of Blockchain references), using this scheme mean that he\n>> >> can simply make it a blockchain: link and be done with it, without\n>> >> having\n>> >> to worry about any specific Blockchain explorer or provide a means for\n>> >> the\n>> >> user to select one.\n>> >>\n>> >> Blockchain explorers in turn will simply offer to handle the\n>> >> blockchain:\n>> >> URI, the first time the user visit their website, or launch/install the\n>> >> application, or even set themselves if there isn't already one.\n>> >>\n>> >> Users get the convenience of using always their preferred explorer,\n>> >> which\n>> >> can be especially handy on mobile devices, where juggling with\n>> >> cut&paste\n>> >> is far from ideal.\n>> >>\n>> >>\n>> >\n>> >\n>> >\n>> > --\n>> > Try the Online TrID File Identifier\n>> > http://mark0.net/onlinetrid.aspx\n>> >\n>> > _______________________________________________\n>> > bitcoin-dev mailing list\n>> > bitcoin-dev at lists.linuxfoundation.org\n>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> >\n>\n>\n>\n>\n> --\n> Try the Online TrID File Identifier\n> http://mark0.net/onlinetrid.aspx"
            },
            {
                "author": "Marco Pontello",
                "date": "2015-11-16T22:10:49",
                "message_text_only": "OK, adding the relevant code fragment is probably the simplest and direct\noption. Done.\n\nOn Mon, Nov 16, 2015 at 3:43 PM, Jorge Tim\u00f3n <jtimon at jtimon.cc> wrote:\n\n> Not a native english speaker myself, so I may have missed some things...\n>\n> Yes, sorry about the link. I guess you can point to #6230 . I can\n> rebase it if needed but I would close it again because I don't want to\n> have too many things from #6382 opened at the same time (is noisy and\n> worse for review). My plan was to not open it independently at least\n> until after #6907 (and actually after 0.12 assuming #6907 gets in by\n> 0.12). But then I would maybe open a new one and reference the old one\n> rather than reopening #6230 (which tends to be confusing).\n> I'm not really sure what's the best answer here...but #6382 is\n> certainly going to need rebase and the link will be broken again.\n> Maybe one answer is to copy some text from #6230 or the commit and add\n> it directly to the BIP instead of referencing to that commit (which\n> will be, at least until #6907 is merged, a moving target).\n>\n> On Mon, Nov 16, 2015 at 1:59 AM, Marco Pontello <marcopon at gmail.com>\n> wrote:\n> > Thanks for the comments! Now I fixed the typos (hope to have got them\n> all,\n> > English isn't my first language), clarified the chain part a bit, and\n> fixed\n> > the link. There probably is a better way to reference that source code\n> part\n> > with the genesis blocks hashs, in a way that doesn't need to be changed,\n> > maybe...\n> >\n> > Now the main change would be to put in a proper BIP number! :)\n> >\n> > On Sun, Nov 15, 2015 at 12:42 PM, Jorge Tim\u00f3n <jtimon at jtimon.cc> wrote:\n> >>\n> >> Thank you for incorporating the feedback, specifically thank you for\n> >> using the genesis block hash as the unique chain ID.\n> >>\n> >> I wen't through the BIP draft and left a few of comments, but I really\n> >> like its simplicity and focus. Good work!\n> >>\n> >> On Sun, Nov 15, 2015 at 3:14 AM, Marco Pontello via bitcoin-dev\n> >> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >> > Hi!\n> >> >\n> >> > To anyone that followed the discussion (from some time ago) about the\n> >> > proposed new URI for Blockchain references / exploration, I just\n> wanted\n> >> > to\n> >> > point out that I have collected the feedback provided, reworked the\n> >> > text,\n> >> > put the BIP on GitHub and created a pull request:\n> >> >\n> >> >\n> https://github.com/MarcoPon/bips/blob/master/bip-MarcoPon-01.mediawiki\n> >> > https://github.com/bitcoin/bips/pull/202\n> >> >\n> >> > The need for an URI for this come to mind again in the last days\n> looking\n> >> > at\n> >> > Eternity Wall, which IMHO provide a use case that we will see more and\n> >> > more\n> >> > in the (near) future: http://eternitywall.it/\n> >> > Using that service, when you want to check for the proof that a\n> specific\n> >> > message was written in the Blockchain, it let you choose from 5\n> >> > different\n> >> > explorer.\n> >> > Mycelium wallet recently added the option to select one of 15 block\n> >> > explorers.\n> >> > And there's the crypto_bot on reddit/r/bitcoin that detect reference\n> to\n> >> > transaction an add a message with links to 7 different explorers.\n> >> >\n> >> > I think that's clearly something that's needed.\n> >> >\n> >> > Bye!\n> >> >\n> >> >\n> >> > On Sat, Aug 29, 2015 at 1:48 PM, Marco Pontello <marcopon at gmail.com>\n> >> > wrote:\n> >> >>\n> >> >> Hi!\n> >> >> My first post here, hope I'm following the right conventions.\n> >> >> I had this humble idea for a while, so I thought to go ahead and\n> >> >> propose\n> >> >> it.\n> >> >>\n> >> >> BIP: XX\n> >> >> Title: URI scheme for Blockchain exploration\n> >> >> Author: Marco Pontello\n> >> >> Status: Draft\n> >> >> Type: Standards Track\n> >> >> Created: 29 August 2015\n> >> >>\n> >> >> Abstract\n> >> >> ========\n> >> >> This BIP propose a simple URI scheme for looking up blocks,\n> >> >> transactions,\n> >> >> addresses on a Blockchain explorer.\n> >> >>\n> >> >> Motivation\n> >> >> ==========\n> >> >> The purpose of this URI scheme is to enable users to handle all the\n> >> >> requests for details about blocks, transactions, etc. with their\n> >> >> preferred\n> >> >> tool (being that a web service or a local application).\n> >> >>\n> >> >> Currently a Bitcoin client usually point to an arbitrary blockchain\n> >> >> explorer when the user look for the details of a transaction (es.\n> >> >> Bitcoin\n> >> >> Wallet use BitEasy, Mycelium or Electrum use Blockchain.info, etc.).\n> >> >> Other times resorting to cut&paste is needed.\n> >> >> The same happens with posts and messages that reference some\n> particular\n> >> >> txs or blocks, if they provide links at all.\n> >> >>\n> >> >> Specification\n> >> >> =============\n> >> >> The URI follow this simple form:\n> >> >>\n> >> >> blockchain: <hash/string>\n> >> >>\n> >> >> Examples:\n> >> >>\n> >> >>\n> >> >>\n> >> >>\n> blockchain:00000000000000001003e880d500968d51157f210c632e08a652af3576600198\n> >> >> blockchain:001949\n> >> >>\n> >> >>\n> >> >>\n> blockchain:3b95a766d7a99b87188d6875c8484cb2b310b78459b7816d4dfc3f0f7e04281a\n> >> >>\n> >> >> Rationale\n> >> >> =========\n> >> >> I thought about using some more complex scheme, or adding qualifiers\n> to\n> >> >> distinguish blocks from txs, but in the end I think that keeping it\n> >> >> simple\n> >> >> should be practical enough. Blockchain explorers can apply the same\n> >> >> disambiguation rules they are already using to process the usual\n> search\n> >> >> box.\n> >> >>\n> >> >> From the point of view of a wallet developer (or other tool that need\n> >> >> to\n> >> >> show any kind of Blockchain references), using this scheme mean that\n> he\n> >> >> can simply make it a blockchain: link and be done with it, without\n> >> >> having\n> >> >> to worry about any specific Blockchain explorer or provide a means\n> for\n> >> >> the\n> >> >> user to select one.\n> >> >>\n> >> >> Blockchain explorers in turn will simply offer to handle the\n> >> >> blockchain:\n> >> >> URI, the first time the user visit their website, or launch/install\n> the\n> >> >> application, or even set themselves if there isn't already one.\n> >> >>\n> >> >> Users get the convenience of using always their preferred explorer,\n> >> >> which\n> >> >> can be especially handy on mobile devices, where juggling with\n> >> >> cut&paste\n> >> >> is far from ideal.\n> >> >>\n> >> >>\n> >> >\n> >> >\n> >> >\n> >> > --\n> >> > Try the Online TrID File Identifier\n> >> > http://mark0.net/onlinetrid.aspx\n> >> >\n> >> > _______________________________________________\n> >> > bitcoin-dev mailing list\n> >> > bitcoin-dev at lists.linuxfoundation.org\n> >> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >> >\n> >\n> >\n> >\n> >\n> > --\n> > Try the Online TrID File Identifier\n> > http://mark0.net/onlinetrid.aspx\n>\n\n\n\n-- \nTry the Online TrID File Identifier\nhttp://mark0.net/onlinetrid.aspx\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151116/88c6c760/attachment-0001.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-18T11:29:13",
                "message_text_only": "I can always link to the BIP when I reopen that commit as independent\ninstead of the other way around.\nBtw, the PR needs rebase (probably the conflict is in the README).\n\nOn Mon, Nov 16, 2015 at 11:10 PM, Marco Pontello <marcopon at gmail.com> wrote:\n> OK, adding the relevant code fragment is probably the simplest and direct\n> option. Done.\n>\n> On Mon, Nov 16, 2015 at 3:43 PM, Jorge Tim\u00f3n <jtimon at jtimon.cc> wrote:\n>>\n>> Not a native english speaker myself, so I may have missed some things...\n>>\n>> Yes, sorry about the link. I guess you can point to #6230 . I can\n>> rebase it if needed but I would close it again because I don't want to\n>> have too many things from #6382 opened at the same time (is noisy and\n>> worse for review). My plan was to not open it independently at least\n>> until after #6907 (and actually after 0.12 assuming #6907 gets in by\n>> 0.12). But then I would maybe open a new one and reference the old one\n>> rather than reopening #6230 (which tends to be confusing).\n>> I'm not really sure what's the best answer here...but #6382 is\n>> certainly going to need rebase and the link will be broken again.\n>> Maybe one answer is to copy some text from #6230 or the commit and add\n>> it directly to the BIP instead of referencing to that commit (which\n>> will be, at least until #6907 is merged, a moving target).\n>>\n>> On Mon, Nov 16, 2015 at 1:59 AM, Marco Pontello <marcopon at gmail.com>\n>> wrote:\n>> > Thanks for the comments! Now I fixed the typos (hope to have got them\n>> > all,\n>> > English isn't my first language), clarified the chain part a bit, and\n>> > fixed\n>> > the link. There probably is a better way to reference that source code\n>> > part\n>> > with the genesis blocks hashs, in a way that doesn't need to be changed,\n>> > maybe...\n>> >\n>> > Now the main change would be to put in a proper BIP number! :)\n>> >\n>> > On Sun, Nov 15, 2015 at 12:42 PM, Jorge Tim\u00f3n <jtimon at jtimon.cc> wrote:\n>> >>\n>> >> Thank you for incorporating the feedback, specifically thank you for\n>> >> using the genesis block hash as the unique chain ID.\n>> >>\n>> >> I wen't through the BIP draft and left a few of comments, but I really\n>> >> like its simplicity and focus. Good work!\n>> >>\n>> >> On Sun, Nov 15, 2015 at 3:14 AM, Marco Pontello via bitcoin-dev\n>> >> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> >> > Hi!\n>> >> >\n>> >> > To anyone that followed the discussion (from some time ago) about the\n>> >> > proposed new URI for Blockchain references / exploration, I just\n>> >> > wanted\n>> >> > to\n>> >> > point out that I have collected the feedback provided, reworked the\n>> >> > text,\n>> >> > put the BIP on GitHub and created a pull request:\n>> >> >\n>> >> >\n>> >> > https://github.com/MarcoPon/bips/blob/master/bip-MarcoPon-01.mediawiki\n>> >> > https://github.com/bitcoin/bips/pull/202\n>> >> >\n>> >> > The need for an URI for this come to mind again in the last days\n>> >> > looking\n>> >> > at\n>> >> > Eternity Wall, which IMHO provide a use case that we will see more\n>> >> > and\n>> >> > more\n>> >> > in the (near) future: http://eternitywall.it/\n>> >> > Using that service, when you want to check for the proof that a\n>> >> > specific\n>> >> > message was written in the Blockchain, it let you choose from 5\n>> >> > different\n>> >> > explorer.\n>> >> > Mycelium wallet recently added the option to select one of 15 block\n>> >> > explorers.\n>> >> > And there's the crypto_bot on reddit/r/bitcoin that detect reference\n>> >> > to\n>> >> > transaction an add a message with links to 7 different explorers.\n>> >> >\n>> >> > I think that's clearly something that's needed.\n>> >> >\n>> >> > Bye!\n>> >> >\n>> >> >\n>> >> > On Sat, Aug 29, 2015 at 1:48 PM, Marco Pontello <marcopon at gmail.com>\n>> >> > wrote:\n>> >> >>\n>> >> >> Hi!\n>> >> >> My first post here, hope I'm following the right conventions.\n>> >> >> I had this humble idea for a while, so I thought to go ahead and\n>> >> >> propose\n>> >> >> it.\n>> >> >>\n>> >> >> BIP: XX\n>> >> >> Title: URI scheme for Blockchain exploration\n>> >> >> Author: Marco Pontello\n>> >> >> Status: Draft\n>> >> >> Type: Standards Track\n>> >> >> Created: 29 August 2015\n>> >> >>\n>> >> >> Abstract\n>> >> >> ========\n>> >> >> This BIP propose a simple URI scheme for looking up blocks,\n>> >> >> transactions,\n>> >> >> addresses on a Blockchain explorer.\n>> >> >>\n>> >> >> Motivation\n>> >> >> ==========\n>> >> >> The purpose of this URI scheme is to enable users to handle all the\n>> >> >> requests for details about blocks, transactions, etc. with their\n>> >> >> preferred\n>> >> >> tool (being that a web service or a local application).\n>> >> >>\n>> >> >> Currently a Bitcoin client usually point to an arbitrary blockchain\n>> >> >> explorer when the user look for the details of a transaction (es.\n>> >> >> Bitcoin\n>> >> >> Wallet use BitEasy, Mycelium or Electrum use Blockchain.info, etc.).\n>> >> >> Other times resorting to cut&paste is needed.\n>> >> >> The same happens with posts and messages that reference some\n>> >> >> particular\n>> >> >> txs or blocks, if they provide links at all.\n>> >> >>\n>> >> >> Specification\n>> >> >> =============\n>> >> >> The URI follow this simple form:\n>> >> >>\n>> >> >> blockchain: <hash/string>\n>> >> >>\n>> >> >> Examples:\n>> >> >>\n>> >> >>\n>> >> >>\n>> >> >>\n>> >> >> blockchain:00000000000000001003e880d500968d51157f210c632e08a652af3576600198\n>> >> >> blockchain:001949\n>> >> >>\n>> >> >>\n>> >> >>\n>> >> >> blockchain:3b95a766d7a99b87188d6875c8484cb2b310b78459b7816d4dfc3f0f7e04281a\n>> >> >>\n>> >> >> Rationale\n>> >> >> =========\n>> >> >> I thought about using some more complex scheme, or adding qualifiers\n>> >> >> to\n>> >> >> distinguish blocks from txs, but in the end I think that keeping it\n>> >> >> simple\n>> >> >> should be practical enough. Blockchain explorers can apply the same\n>> >> >> disambiguation rules they are already using to process the usual\n>> >> >> search\n>> >> >> box.\n>> >> >>\n>> >> >> From the point of view of a wallet developer (or other tool that\n>> >> >> need\n>> >> >> to\n>> >> >> show any kind of Blockchain references), using this scheme mean that\n>> >> >> he\n>> >> >> can simply make it a blockchain: link and be done with it, without\n>> >> >> having\n>> >> >> to worry about any specific Blockchain explorer or provide a means\n>> >> >> for\n>> >> >> the\n>> >> >> user to select one.\n>> >> >>\n>> >> >> Blockchain explorers in turn will simply offer to handle the\n>> >> >> blockchain:\n>> >> >> URI, the first time the user visit their website, or launch/install\n>> >> >> the\n>> >> >> application, or even set themselves if there isn't already one.\n>> >> >>\n>> >> >> Users get the convenience of using always their preferred explorer,\n>> >> >> which\n>> >> >> can be especially handy on mobile devices, where juggling with\n>> >> >> cut&paste\n>> >> >> is far from ideal.\n>> >> >>\n>> >> >>\n>> >> >\n>> >> >\n>> >> >\n>> >> > --\n>> >> > Try the Online TrID File Identifier\n>> >> > http://mark0.net/onlinetrid.aspx\n>> >> >\n>> >> > _______________________________________________\n>> >> > bitcoin-dev mailing list\n>> >> > bitcoin-dev at lists.linuxfoundation.org\n>> >> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> >> >\n>> >\n>> >\n>> >\n>> >\n>> > --\n>> > Try the Online TrID File Identifier\n>> > http://mark0.net/onlinetrid.aspx\n>\n>\n>\n>\n> --\n> Try the Online TrID File Identifier\n> http://mark0.net/onlinetrid.aspx"
            },
            {
                "author": "Marco Pontello",
                "date": "2015-11-18T12:31:46",
                "message_text_only": "Right, now it should be ok. Thanks.\n\nOn Wed, Nov 18, 2015 at 12:29 PM, Jorge Tim\u00f3n <jtimon at jtimon.cc> wrote:\n\n> I can always link to the BIP when I reopen that commit as independent\n> instead of the other way around.\n> Btw, the PR needs rebase (probably the conflict is in the README).\n>\n> On Mon, Nov 16, 2015 at 11:10 PM, Marco Pontello <marcopon at gmail.com>\n> wrote:\n> > OK, adding the relevant code fragment is probably the simplest and direct\n> > option. Done.\n> >\n> > On Mon, Nov 16, 2015 at 3:43 PM, Jorge Tim\u00f3n <jtimon at jtimon.cc> wrote:\n> >>\n> >> Not a native english speaker myself, so I may have missed some things...\n> >>\n> >> Yes, sorry about the link. I guess you can point to #6230 . I can\n> >> rebase it if needed but I would close it again because I don't want to\n> >> have too many things from #6382 opened at the same time (is noisy and\n> >> worse for review). My plan was to not open it independently at least\n> >> until after #6907 (and actually after 0.12 assuming #6907 gets in by\n> >> 0.12). But then I would maybe open a new one and reference the old one\n> >> rather than reopening #6230 (which tends to be confusing).\n> >> I'm not really sure what's the best answer here...but #6382 is\n> >> certainly going to need rebase and the link will be broken again.\n> >> Maybe one answer is to copy some text from #6230 or the commit and add\n> >> it directly to the BIP instead of referencing to that commit (which\n> >> will be, at least until #6907 is merged, a moving target).\n> >>\n> >> On Mon, Nov 16, 2015 at 1:59 AM, Marco Pontello <marcopon at gmail.com>\n> >> wrote:\n> >> > Thanks for the comments! Now I fixed the typos (hope to have got them\n> >> > all,\n> >> > English isn't my first language), clarified the chain part a bit, and\n> >> > fixed\n> >> > the link. There probably is a better way to reference that source code\n> >> > part\n> >> > with the genesis blocks hashs, in a way that doesn't need to be\n> changed,\n> >> > maybe...\n> >> >\n> >> > Now the main change would be to put in a proper BIP number! :)\n> >> >\n> >> > On Sun, Nov 15, 2015 at 12:42 PM, Jorge Tim\u00f3n <jtimon at jtimon.cc>\n> wrote:\n> >> >>\n> >> >> Thank you for incorporating the feedback, specifically thank you for\n> >> >> using the genesis block hash as the unique chain ID.\n> >> >>\n> >> >> I wen't through the BIP draft and left a few of comments, but I\n> really\n> >> >> like its simplicity and focus. Good work!\n> >> >>\n> >> >> On Sun, Nov 15, 2015 at 3:14 AM, Marco Pontello via bitcoin-dev\n> >> >> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >> >> > Hi!\n> >> >> >\n> >> >> > To anyone that followed the discussion (from some time ago) about\n> the\n> >> >> > proposed new URI for Blockchain references / exploration, I just\n> >> >> > wanted\n> >> >> > to\n> >> >> > point out that I have collected the feedback provided, reworked the\n> >> >> > text,\n> >> >> > put the BIP on GitHub and created a pull request:\n> >> >> >\n> >> >> >\n> >> >> >\n> https://github.com/MarcoPon/bips/blob/master/bip-MarcoPon-01.mediawiki\n> >> >> > https://github.com/bitcoin/bips/pull/202\n> >> >> >\n> >> >> > The need for an URI for this come to mind again in the last days\n> >> >> > looking\n> >> >> > at\n> >> >> > Eternity Wall, which IMHO provide a use case that we will see more\n> >> >> > and\n> >> >> > more\n> >> >> > in the (near) future: http://eternitywall.it/\n> >> >> > Using that service, when you want to check for the proof that a\n> >> >> > specific\n> >> >> > message was written in the Blockchain, it let you choose from 5\n> >> >> > different\n> >> >> > explorer.\n> >> >> > Mycelium wallet recently added the option to select one of 15 block\n> >> >> > explorers.\n> >> >> > And there's the crypto_bot on reddit/r/bitcoin that detect\n> reference\n> >> >> > to\n> >> >> > transaction an add a message with links to 7 different explorers.\n> >> >> >\n> >> >> > I think that's clearly something that's needed.\n> >> >> >\n> >> >> > Bye!\n> >> >> >\n> >> >> >\n> >> >> > On Sat, Aug 29, 2015 at 1:48 PM, Marco Pontello <\n> marcopon at gmail.com>\n> >> >> > wrote:\n> >> >> >>\n> >> >> >> Hi!\n> >> >> >> My first post here, hope I'm following the right conventions.\n> >> >> >> I had this humble idea for a while, so I thought to go ahead and\n> >> >> >> propose\n> >> >> >> it.\n> >> >> >>\n> >> >> >> BIP: XX\n> >> >> >> Title: URI scheme for Blockchain exploration\n> >> >> >> Author: Marco Pontello\n> >> >> >> Status: Draft\n> >> >> >> Type: Standards Track\n> >> >> >> Created: 29 August 2015\n> >> >> >>\n> >> >> >> Abstract\n> >> >> >> ========\n> >> >> >> This BIP propose a simple URI scheme for looking up blocks,\n> >> >> >> transactions,\n> >> >> >> addresses on a Blockchain explorer.\n> >> >> >>\n> >> >> >> Motivation\n> >> >> >> ==========\n> >> >> >> The purpose of this URI scheme is to enable users to handle all\n> the\n> >> >> >> requests for details about blocks, transactions, etc. with their\n> >> >> >> preferred\n> >> >> >> tool (being that a web service or a local application).\n> >> >> >>\n> >> >> >> Currently a Bitcoin client usually point to an arbitrary\n> blockchain\n> >> >> >> explorer when the user look for the details of a transaction (es.\n> >> >> >> Bitcoin\n> >> >> >> Wallet use BitEasy, Mycelium or Electrum use Blockchain.info,\n> etc.).\n> >> >> >> Other times resorting to cut&paste is needed.\n> >> >> >> The same happens with posts and messages that reference some\n> >> >> >> particular\n> >> >> >> txs or blocks, if they provide links at all.\n> >> >> >>\n> >> >> >> Specification\n> >> >> >> =============\n> >> >> >> The URI follow this simple form:\n> >> >> >>\n> >> >> >> blockchain: <hash/string>\n> >> >> >>\n> >> >> >> Examples:\n> >> >> >>\n> >> >> >>\n> >> >> >>\n> >> >> >>\n> >> >> >>\n> blockchain:00000000000000001003e880d500968d51157f210c632e08a652af3576600198\n> >> >> >> blockchain:001949\n> >> >> >>\n> >> >> >>\n> >> >> >>\n> >> >> >>\n> blockchain:3b95a766d7a99b87188d6875c8484cb2b310b78459b7816d4dfc3f0f7e04281a\n> >> >> >>\n> >> >> >> Rationale\n> >> >> >> =========\n> >> >> >> I thought about using some more complex scheme, or adding\n> qualifiers\n> >> >> >> to\n> >> >> >> distinguish blocks from txs, but in the end I think that keeping\n> it\n> >> >> >> simple\n> >> >> >> should be practical enough. Blockchain explorers can apply the\n> same\n> >> >> >> disambiguation rules they are already using to process the usual\n> >> >> >> search\n> >> >> >> box.\n> >> >> >>\n> >> >> >> From the point of view of a wallet developer (or other tool that\n> >> >> >> need\n> >> >> >> to\n> >> >> >> show any kind of Blockchain references), using this scheme mean\n> that\n> >> >> >> he\n> >> >> >> can simply make it a blockchain: link and be done with it, without\n> >> >> >> having\n> >> >> >> to worry about any specific Blockchain explorer or provide a means\n> >> >> >> for\n> >> >> >> the\n> >> >> >> user to select one.\n> >> >> >>\n> >> >> >> Blockchain explorers in turn will simply offer to handle the\n> >> >> >> blockchain:\n> >> >> >> URI, the first time the user visit their website, or\n> launch/install\n> >> >> >> the\n> >> >> >> application, or even set themselves if there isn't already one.\n> >> >> >>\n> >> >> >> Users get the convenience of using always their preferred\n> explorer,\n> >> >> >> which\n> >> >> >> can be especially handy on mobile devices, where juggling with\n> >> >> >> cut&paste\n> >> >> >> is far from ideal.\n> >> >> >>\n> >> >> >>\n> >> >> >\n> >> >> >\n> >> >> >\n> >> >> > --\n> >> >> > Try the Online TrID File Identifier\n> >> >> > http://mark0.net/onlinetrid.aspx\n> >> >> >\n> >> >> > _______________________________________________\n> >> >> > bitcoin-dev mailing list\n> >> >> > bitcoin-dev at lists.linuxfoundation.org\n> >> >> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >> >> >\n> >> >\n> >> >\n> >> >\n> >> >\n> >> > --\n> >> > Try the Online TrID File Identifier\n> >> > http://mark0.net/onlinetrid.aspx\n> >\n> >\n> >\n> >\n> > --\n> > Try the Online TrID File Identifier\n> > http://mark0.net/onlinetrid.aspx\n>\n\n\n\n-- \nTry the Online TrID File Identifier\nhttp://mark0.net/onlinetrid.aspx\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151118/95640aa5/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "RFC - BIP: URI scheme for Blockchain exploration",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Marco Pontello",
                "Jorge Tim\u00f3n"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 41941
        }
    },
    {
        "title": "[bitcoin-dev] BIP99 and Schism hardforks lifecycle (was Switching Bitcoin Core to sqlite db)",
        "thread_messages": [
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-16T12:06:49",
                "message_text_only": "On Mon, Nov 16, 2015 at 2:52 AM, Rusty Russell <rusty at rustcorp.com.au> wrote:\n> We have strayed far from both the Subject line and from making progress\n> on bitcoin development.  Please redirect to bitcoin-discuss.\n>\n> I have set the moderation bits on the three contributors from here down\n> (CC'd): your next post will go to moderation.\n\nSorry for going out of topic on that thread, I have just created\nanother thread to discuss this particular point (whether schism\nhardforks can be universally predicted to collapse into a single chain\nor not), which is a fundamental part of BIP99 discussion and I believe\ntechnical enough for this list (assuming that we stay on topic). But\nthe moderation thinks it's not relevant enough for this list, we can\nmove it to the discussion mailing list or private emails.\n\nOn Sun, Nov 15, 2015 at 6:06 PM, Peter R <peter_r at gmx.com> wrote:\n>> I am not convinced that Bitcoin even *has* a block size limit, let alone\n>> that it can enforce one against the invisible hand of the market.\n>\nJorge Tim\u00f3n said:\n> You keep insisting that some consensus rules are not consensus rules while\n> others \"are clearly a very different thing\". What technical difference is\n> there between the rule that impedes me from creating transactions bigger\n> than X and the rules that prevent me frm creatin new coins (not as a miner,\n> as a regular user in a transaction with more coins in the outputs than in\n> the inputs)?\n>\n\nOn Sun, Nov 15, 2015 at 6:06 PM, Peter R <peter_r at gmx.com> wrote:\n> I think you\u2019re using the term \u201ctechnical difference\u201d to mean something very\n> specific.  Perhaps you could clarify exactly how you are defining that term\n> because to me it is crystal clear that creating coins out of thin air is\n> very different than accepting a block 1.1 MB in size and full of valid TXs.\n> There are many technical differences between the two. For example,\n> technically the first allows coins to be created randomly while the second\n> doesn\u2019t.\n\nOf course, their technical difference come from the fact they are\ntechnically different. That's not what I meant.\nThere's no technical argument that lets you predict whether\neliminating one rule or the other will be more or less acceptable to\nusers.\nThere's no technical difference that I can see in that reward.\nI think these two examples strike people as \"obviously different\" just\nbecause they are morally different, but I want to avoid moral\njudgments in BIP99.\n\n> It is fact that two competing forks can persist for at least a short amount\n> of time\u2014we saw this a few years ago with the LevelDB bug and again this\n> summer with the SPV mining incident.  In both cases, there was tremendous\n> pressure to converge back to a single chain.\n\nThose were unintentional hardforks. There's an example of a failed\nschism hardfork: when some people changed the subsidy/issuance rules\nto maintain the 50 btc block subsidy constant.\nIt didn't failed because of \"tremendous pressure\": it failed because\nthe users and miners of the alternative ruleset abandoned it. If they\nhadn't, the two incompatible chains would still grow in parallel.\n\n> Could two chains persist indefinitely?  I don\u2019t know.  No one knows.  My gut\n> feeling is that since users would have coins on both sides of the fork,\n> there would be a fork arbitrage event (a \u201cforkbitrage\u201d) where speculators\n> would sell the coins on the side they predict to lose in exchange for\n> additional coins on the side they expect to win.  This could actually be\n> facilitated by exchanges once the fork event is credible and before the fork\n> actually occurs, or even in a futures market somehow.  I suspect that the\n> forkbitrage would create an unstable equilibrium where coins on one side\n> quickly devalue.  Miners would then abandon that side in favour of the\n> other, killing the fork because difficulty would be too high to find new\n> blocks.  Anyways, I think even *this* would be highly unlikely.  I suspect\n> nodes and miners would get inline with consensus as soon as the fork event\n> was credible.\n\nYes, there could be arbitrage and speculators selling \"on both sides\"\nis also a possibility.\nAt some point we would arrive to some kind of price equilibrium,\ndifferent for each of the coins. BIP99 states that those prices are\nunpredictable (or at least there's no general method to predict the\nresult without knowing the concrete case, the market, etc) and in fact\nstates that the resulting price for both sides could be going to close\nto zero market capitalization.\nThat still doesn't say anything about one side having to \"surrender\".\nThe coin that ends up with the lowest price (and consequently, the\nlowest block reward and hashrate) can still continue, maybe even for\nlonger than the side that appeared to be \"victorious\" after the\ninitial arbitrage.\nI haven't heard any convincing arguments about schism hardforks having\nto necessarily collapse into a single chain and until I do I'm not\ngoing to adapt BIP99 to reflect that.\n\nOn Sun, Nov 15, 2015 at 11:22 PM, Corey Haddad <corey3 at gmail.com> wrote:\n> On Sun, Nov 15, 2015 at 2:12 AM, Jorge Tim\u00f3n\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>\n>>If the invisible hand of the market is what decides consensus rules instead\n>> of their (still incomple) specification (aka libconsensus), then the market\n>> could decide to stop enforcing ownership. Will you still think that Bitcoin\n>> is a useful system when/if you empirically observe the invisible hand of the\n>> market taking coins out of your pocket?\n>\n> The market, which in this instance I take to mean the economic majority,\n> could absolutely decide to stop enforcing ownership of certain coins, even\n> arbitrarily ascribing them to a different address.  That's not something any\n> of us have any control over, and that reality must be acknowledged.\n> Bitcoins have value is due to collective behavior.  We can provide tools to\n> help people reach a common understanding, but the tools cannot force people\n> to reach a certain conclusion.\n\nYes, I have control: all users (including miners) have direct control\nover the rules that software they run validates.\nYou cannot ever have your coins stolen in the longest valid chain you\nfollow if the validity rules you use enforce property ownership.\nNo majority can force you to move to the new non-ownership rules, just\nlike no majority can force you to move to any different set of rules.\nIf we accept the notion that a groups of users could resist to\ndeploying this particular rule changes and keep operating under the\nold rules, we have to accept that this can happen for any\ncontroversial hardfork, and that we cannot predict a common lifecycle\nfor all schism hardforks."
            }
        ],
        "thread_summary": {
            "title": "BIP99 and Schism hardforks lifecycle (was Switching Bitcoin Core to sqlite db)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jorge Tim\u00f3n"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 6681
        }
    },
    {
        "title": "[bitcoin-dev] Opt-in Full Replace-By-Fee (Full-RBF)",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2015-11-17T00:42:18",
                "message_text_only": "Summary\n-------\n\nOpt-In Full-RBF allows senders to opt-into full-RBF semantics for their\ntransactions in a way that allows receivers to detect if the sender has\ndone so. Existing \"first-seen\" mempool semantics are left unchanged for\ntransactions that do not opt-in.\n\nAt last week's IRC meeting(1) we decided to merge the opt-in Full-RBF\npull-req(2), pending code review and this post, so this feature will\nlikely make it into Bitcoin Core v0.12.0\n\n\nSpecification\n-------------\n\nA transaction is considered to have opted into full-RBF semantics if\nnSequence < 0xFFFFFFFF-1 on at least one input. Nodes that respect the\nopt-in will allow such opt-in transactions (and their descendents) to be\nreplaced in the mempool if they meet the economic replacement criteria.\nTransactions in blocks are of course unaffected.\n\nTo detect if a transaction may be replaced check if it or any\nunconfirmed ancestors have set nSequence < 0xFFFFFFFF-1 on any inputs.\n\n\nRational\n--------\n\nnSequence is used for opting in as it is the only \"free-form\" field\navailable for that purpose. Opt-in per output was proposed as well by\nLuke-Jr, however the CTxOut data structure simply doesn't contain any\nextra fields to use for that purpose. nSequence-based opt-in is also\ncompatible with the consensus-enforced transaction replacement semantics\nin BIP68.\n\nAllowing replacement if any input opts in vs. all inputs opting in is\nchosen to ensure that transactions authored by multiple parties aren't\nheld up by the actions of a single party. Additionally, in the\nmulti-party scenario the value of any zeroconf guarantees are especially\ndubious.\n\nReplacement is allowed even if unconfirmed children did not opt-in to\nensure receivers can't maliciously prevent a replacement by spending the\nfunds. Additionally, any reasonable attempt at determining if a\ntransaction can be double-spent has to look at all unconfirmed parents\nanyway.\n\nFeedback from wallet authors indicates that first-seen-safe RBF isn't\nvery useful in practice due to the limitations inherent in FSS rules;\nopt-in full-RBF doesn't preclude FSS-RBF from also being implemented.\n\n\nCompatibility\n-------------\n\nOpt-in RBF transactions are currently mined by 100% of the hashing\npower. Bitcoin Core has been producing transactions with non-maxint\nnSequence since v0.11.0 to discourage fee sniping(3), and currently no\nwallets are known that display such transactions yet do not display\nopt-in RBF transactions.\n\n\nDemonstrations\n--------------\n\nhttps://github.com/petertodd/replace-by-fee-tools#incremental-send-many\n\n\n1) http://lists.linuxfoundation.org/pipermail/bitcoin-discuss/2015-November/000010.html\n\n2) https://github.com/bitcoin/bitcoin/pull/6871\n\n3) https://github.com/bitcoin/bitcoin/pull/2340\n\n-- \n'peter'[:-1]@petertodd.org\n00000000000000000f30567c63f8f4f079a8ecc2ab3d380bc7dc370e792b0a3a\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151116/d33dde25/attachment.sig>"
            },
            {
                "author": "Chris",
                "date": "2015-11-30T03:32:34",
                "message_text_only": "On 11/16/2015 07:42 PM, Peter Todd via bitcoin-dev wrote:\n> Sequence is used for opting in as it is the only \"free-form\" field\n> available for that purpose. Opt-in per output was proposed as well by\n> Luke-Jr, however the CTxOut data structure simply doesn't contain any\n> extra fields to use for that purpose.\nWhat is wrong with using they same scheme as sighash_single?\n\nIf input 0 has nSequence < maxint-1 then output 0 is replaceable.\n\nFor fee bumps you would just stick the change in position zero and\nreduce the value.\n\nYou get FFS functionality without the hassle of addition other inputs.\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151129/dc16d383/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Opt-in Full Replace-By-Fee (Full-RBF)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Chris",
                "Peter Todd"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 3888
        }
    },
    {
        "title": "[bitcoin-dev] Dynamic Hierarchical Deterministic Key Trees",
        "thread_messages": [
            {
                "author": "Eric Lombrozo",
                "date": "2015-11-17T11:40:43",
                "message_text_only": "I've submitted a BIP proposal that solves the issue of needing to \npredefine HD wallet structures and not being able to arbitrarily nest \ndeeper levels. Comments appreciated.\n\nhttps://github.com/bitcoin/bips/pull/242\n\n\n- Eric\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151117/2db0574f/attachment.html>"
            },
            {
                "author": "Tamas Blummer",
                "date": "2015-11-17T13:10:17",
                "message_text_only": "Hi Eric,\n\nWould you please enumerate, or point to, arguments that discourage the use of a key both for signing and for derivation of a deeper level of the hierarchy ?\n\nTamas Blummer\n\n> On Nov 17, 2015, at 12:40, Eric Lombrozo via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> I've submitted a BIP proposal that solves the issue of needing to predefine HD wallet structures and not being able to arbitrarily nest deeper levels. Comments appreciated.\n>  \n> https://github.com/bitcoin/bips/pull/242\n>  \n>  \n> - Eric\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Eric Lombrozo",
                "date": "2015-11-21T08:45:10",
                "message_text_only": "Tamas,\n\nYou could use a key for both signing and for derivation of a deeper \nlevel (and perhaps there are some applications for this, if you think of \nany please let me know), but the use cases being considered involve \ngeneration of signing key sequences from seeds that are easy to backup \nand easy to share with others to simplify multidevice synchronization, \nkey management, account structures, etc... while also allowing for \nprivacy by making it nontrivial to associate transactions for an account \nwithout knowing the seed/chain code.\n\nAs such, we generally refer to such sequences by a path to the immediate \nparent node in the tree and reserve the children themselves for the \nsigning keys.\n\n\n- Eric\n\n\n\n------ Original Message ------\nFrom: \"Tamas Blummer\" <tamas at bitsofproof.com>\nTo: \"Eric Lombrozo\" <elombrozo at gmail.com>; \"Eric Lombrozo via \nbitcoin-dev\" <bitcoin-dev at lists.linuxfoundation.org>\nSent: 11/17/2015 5:10:17 AM\nSubject: Re: [bitcoin-dev] Dynamic Hierarchical Deterministic Key Trees\n\n>Hi Eric,\n>\n>Would you please enumerate, or point to, arguments that discourage the \n>use of a key both for signing and for derivation of a deeper level of \n>the hierarchy ?\n>\n>Tamas Blummer\n>\n>>  On Nov 17, 2015, at 12:40, Eric Lombrozo via bitcoin-dev \n>><bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>  I've submitted a BIP proposal that solves the issue of needing to \n>>predefine HD wallet structures and not being able to arbitrarily nest \n>>deeper levels. Comments appreciated.\n>>\n>>  https://github.com/bitcoin/bips/pull/242\n>>\n>>\n>>  - Eric\n>>  _______________________________________________\n>>  bitcoin-dev mailing list\n>>  bitcoin-dev at lists.linuxfoundation.org\n>>  https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            }
        ],
        "thread_summary": {
            "title": "Dynamic Hierarchical Deterministic Key Trees",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Eric Lombrozo",
                "Tamas Blummer"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 2894
        }
    },
    {
        "title": "[bitcoin-dev] Hierarchical Deterministic Script Templates",
        "thread_messages": [
            {
                "author": "Eric Lombrozo",
                "date": "2015-11-21T03:29:46",
                "message_text_only": "A while back, I started working with William Swanson on a script \ntemplate format to allow for interoperability in accounts between \ndifferent wallets. We made some progress, but both of us got pretty busy \nwith other projects and general interest was still quite low.\n\nIt seems interest has picked up again, especially in light of recent \ndevelopments (i.e. CLTV, relative CLTV, bidirectional payment channels, \nlightning), where nongeneralized script formats will not readily support \nthe rapidly advancing state-of-the-art in script design.\n\nI have started working on a draft for such a standard: \nhttps://github.com/bitcoin/bips/pull/246\n\nComments, suggestions, and collaboration are welcome.\n\n- Eric\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151121/9de14fb7/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Hierarchical Deterministic Script Templates",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Eric Lombrozo"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 887
        }
    },
    {
        "title": "[bitcoin-dev] BIP68: Relative lock-time through consensus-enforced sequence numbers (update)",
        "thread_messages": [
            {
                "author": "Btc Drak",
                "date": "2015-11-21T14:13:05",
                "message_text_only": "As I am sure you are aware, for the last 5 months work has been on-going to\ncreate a relative lock-time proposal using sequence numbers. The\nimplementation can be found at https://github.com/bitcoin/bitcoin/pull/6312.\nThe current implementation is \"mempool-only\" and the soft-fork would be\ndeployed at a later stage.\n\nOver these months there has been various discussion back and forth to\nrefine the details.\n\nI have updated the BIP text now according to the details that were\ndiscussed in mid-October[1][2] and have extensively clarified the text.\n\nTo recap, the overall picture for relative lock-time is that BIP68\nintroduces consensus rules using some of the nSequence field, while BIP112\ncreates a new opcode OP_CHECKSEQUENCEVERIFY (PR #6564) so relative\nlock-time can be verified from the Bitcoin scripting language. Ideally we\nwould soft-fork BIP68, BIP112 (CSV) and 113 (MTP) together. BIP113 has been\ndeployed in 0.11.2 as mempool policy so miners should be applying this\npolicy as they deploy version 4 blocks for the ongoing CLTV soft-fork\n(currently at 42% at the time of writing).\n\nI am writing this mail to draw your attention to the BIP68 pull-requests\nand to request final review at:\n\nBIP68 text - https://github.com/bitcoin/bips/pull/245\nBIP68 implementation - https://github.com/bitcoin/bitcoin/pull/6312\n\nDiscussion references:\n[1]\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-October/011357.html\n[2] http://bitcoinstats.com/irc/bitcoin-dev/logs/2015/10/15#l1444928045.0\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151121/af05804b/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP68: Relative lock-time through consensus-enforced sequence numbers (update)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Btc Drak"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1686
        }
    },
    {
        "title": "[bitcoin-dev] BIP68: Second-level granularity doesn't make sense",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2015-11-24T04:36:18",
                "message_text_only": "BIP68 currently represents by-height locks as a simple 16-bit integer of\nthe number of blocks - effectively giving a granularity of 600 seconds\non average - but for for by-time locks the representation is a 25-bit\ninteger with granularity of 1 second. However this granularity doesn't\nmake sense with BIP113, median time-past as endpoint for lock-time\ncalcualtions, and poses potential problems for future upgrades.\n\n\nThere's two cases to consider here:\n\n1) No competing transactions\n\nBy this we mean that the nSequence field is being used simply to delay\nwhen an output can be spent; there aren't competing transactions trying\nto spend that output and thus we're not concerned about one transaction\ngetting mined before another \"out of order\". For instance, an 2-factor\nescrow service like GreenAddress could use nSequence with\nCHECKSEQUENCEVERIFY (CSV) to guarantee that users will eventually get\ntheir funds back after some timeout.\n\nIn this use-case exact miner behavior is irrelevant. Equally given the\nlarge tolerances allowed on block times, as well as the poisson\ndistribution of blocks generated, granularity below an hour or two\ndoesn't have much practical significance.\n\n\n2) Competing transactions\n\nHere we are relying on miners prefering lower sequence numbers. For\ninstance a bidirectional payment channel can decrement nSequence for\neach change of direction; BIP68 suggests such a decrement might happen\nin increments of one day.\n\nBIP113 makes lock-time calculations use the median time-past as the\nthreshold for by-time locks. The median time past is calculated by\ntaking median time of the 11 previous blocks, which means when a miner\ncreates a block they have absolutely no control over what the median\ntime-past is; it's purely a function of the block tip they're building\nupon.\n\nThis means that granularity below a block interval will, on average,\nhave absolutely no effect at all on what transaction the miner includes\neven in the hypothetical case. In practice of course, users will want to\nuse significantly larger than 1 block interval granularity in protocols.\n\n\nThe downside of BIP68 as written is users of by-height locktimes have 14\nbits unused in nSequence, but by-time locktimes have just 5 bits unused.\nThis presents an awkward situation if we add new meanings to nSequence\nif we ever need more than 5 bits. Yet as shown above, the extra\ngranularity doesn't have a practical benefit.\n\n\nRecommendation: Change BIP68 to make by-time locks have the same number\nof bits as by-height locks, and multiply the by-time lock field by the\nblock interval.\n\n-- \n'peter'[:-1]@petertodd.org\n000000000000000001a06d85a46abce495fd793f89fe342e6da18b235ade373f\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151123/4e2a25bf/attachment.sig>"
            },
            {
                "author": "Btc Drak",
                "date": "2015-11-24T05:05:32",
                "message_text_only": "On Tue, Nov 24, 2015 at 4:36 AM, Peter Todd via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> The downside of BIP68 as written is users of by-height locktimes have 14\n> bits unused in nSequence, but by-time locktimes have just 5 bits unused.\n> This presents an awkward situation if we add new meanings to nSequence\n> if we ever need more than 5 bits. Yet as shown above, the extra\n> granularity doesn't have a practical benefit.\n>\n>\n> Recommendation: Change BIP68 to make by-time locks have the same number\n> of bits as by-height locks, and multiply the by-time lock field by the\n> block interval.\n>\n\nI think you might be referring to the old specification. I believe this was\nbrought up before and the specification was changed so the same number of\nbits were used for by-time and by-height. Please see\nhttps://github.com/bitcoin/bips/pull/245\n\nHowever, I am glad you came to the came conclusions independently because\n\"re-invention\" often confirms good ideas :)\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151124/284a4d36/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2015-11-24T05:58:40",
                "message_text_only": "On Tue, Nov 24, 2015 at 05:05:32AM +0000, Btc Drak wrote:\n> On Tue, Nov 24, 2015 at 4:36 AM, Peter Todd via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> > The downside of BIP68 as written is users of by-height locktimes have 14\n> > bits unused in nSequence, but by-time locktimes have just 5 bits unused.\n> > This presents an awkward situation if we add new meanings to nSequence\n> > if we ever need more than 5 bits. Yet as shown above, the extra\n> > granularity doesn't have a practical benefit.\n> >\n> >\n> > Recommendation: Change BIP68 to make by-time locks have the same number\n> > of bits as by-height locks, and multiply the by-time lock field by the\n> > block interval.\n> >\n> \n> I think you might be referring to the old specification. I believe this was\n> brought up before and the specification was changed so the same number of\n> bits were used for by-time and by-height. Please see\n> https://github.com/bitcoin/bips/pull/245\n> \n> However, I am glad you came to the came conclusions independently because\n> \"re-invention\" often confirms good ideas :)\n\nHa, that's awesome! Looks like we're pretty much on the same page re:\ngranularity.\n\n-- \n'peter'[:-1]@petertodd.org\n000000000000000003c0cf6b89d2a9b68a8cedbd3935962203c21663925c714b\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151124/4f0ba27e/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "BIP68: Second-level granularity doesn't make sense",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Btc Drak",
                "Peter Todd"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 5657
        }
    },
    {
        "title": "[bitcoin-dev] Alternative name for CHECKSEQUENCEVERIFY (BIP112)",
        "thread_messages": [
            {
                "author": "Btc Drak",
                "date": "2015-11-24T10:30:52",
                "message_text_only": "BIP68 introduces relative lock-time semantics to part of the nSequence\nfield leaving the majority of bits undefined for other future applications.\n\nBIP112 introduces opcode CHECKSEQUENCEVERIFY (OP_CSV) that is specifically\nlimited to verifying transaction inputs according to BIP68's relative\nlock-time[1], yet the _name_ OP_CSV is much boarder than that. We spent\nmonths limiting the number of bits used in BIP68 so they would be available\nfor future use cases, thus we have acknowledged there will be completely\ndifferent usecases that take advantage of unused nSequence bits.\n\nFor this reason I believe the BIP112 should be renamed specifically for\nit's usecase, which is verifying the time/maturity of transaction inputs\nrelative to their inclusion in a block.\n\nSuggestions:-\n\nCHECKMATURITYVERIFY\nRELATIVELOCKTIMEVERIFY\nRCHECKLOCKTIMEVERIFY\nRCLTV\n\nWe could of course softfork additional meaning into OP_CSV each time we add\nnew sequence number usecases, but that would become obscure and confusing.\nWe have already shown there is no shortage of opcodes so it makes no sense\nto cram everything into one generic opcode.\n\nTL;DR: let's give BIP112 opcode a name that reflects it's actual usecase\nrather than focusing on the bitcoin internals.\n\n[1]\nhttps://github.com/bitcoin/bitcoin/pull/6564/files#diff-be2905e2f5218ecdbe4e55637dac75f3R1223\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151124/a775f63a/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2015-11-24T12:20:40",
                "message_text_only": "On Tue, Nov 24, 2015 at 10:30:52AM +0000, Btc Drak via bitcoin-dev wrote:\n> BIP68 introduces relative lock-time semantics to part of the nSequence\n> field leaving the majority of bits undefined for other future applications.\n> \n> BIP112 introduces opcode CHECKSEQUENCEVERIFY (OP_CSV) that is specifically\n> limited to verifying transaction inputs according to BIP68's relative\n> lock-time[1], yet the _name_ OP_CSV is much boarder than that. We spent\n> months limiting the number of bits used in BIP68 so they would be available\n> for future use cases, thus we have acknowledged there will be completely\n> different usecases that take advantage of unused nSequence bits.\n> \n> For this reason I believe the BIP112 should be renamed specifically for\n> it's usecase, which is verifying the time/maturity of transaction inputs\n> relative to their inclusion in a block.\n> \n> Suggestions:-\n> \n> CHECKMATURITYVERIFY\n\nDefinitely this one.\n\nAlthough I wouldn't rush to make the change just yet - I for one am busy\nwriting some test programs to actually use BIP112, and in theory they\nmight say the more general CSV concept is better.\n\nWhatever we call it, deciding on that is a simple s/FOO/BAR/ prior to\nrelease.\n\n-- \n'peter'[:-1]@petertodd.org\n000000000000000008cd594ba6601fcc5e9e919b30630076c64657209b13c7b4\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151124/4d685b3f/attachment.sig>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-24T12:35:58",
                "message_text_only": "On Nov 24, 2015 1:21 PM, \"Peter Todd via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Whatever we call it, deciding on that is a simple s/FOO/BAR/ prior to\n> release.\n\nWhile I agree we're not in a hurry, the more we wait, the longer docs (to\nbe modified later) will accumulate making the assumption that the name is\ncsv rather than op_maturity.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151124/0212d72f/attachment.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-24T12:31:55",
                "message_text_only": "I agree, I believe the first name that an op with equivalent functionality\nhad was simply op_maturity.\nAt least I remember we discussed such an opcode when discussing pegged\nsidechains' design.\n\nI kind of dislike the check_x_verify naming pattern. We want all new\noperands to return if whatever they're checking/verifying fails, fine. Do\nwe have to repeat this redundant naming pattern forever due to that\ndiscovery?\nI hope not, but if that's the case my vote is for CMV.\nAs said before, I believe the documentation and code comments can become\nmuch more clear with this change.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151124/5b9476f9/attachment.html>"
            },
            {
                "author": "Eric Lombrozo",
                "date": "2015-11-25T01:14:55",
                "message_text_only": ">From a system developer standpoint, CHECKMATURITYVERIFY ties together \nthe semantics of this opcode with another existing feature in the system \n(coinbase maturity).\n\nHOWEVER...\n\nfrom an application developer standpoint, I think the concept of a \ntimelock is more relevant. Maturity is a concept that was introduced for \nthe sake of reducing the disruptive impact of reorgs. Miners would \nprefer to be able to spend the coins immediately, but instead they are \nforced to wait due to inherent limitations of the system. Timelocks, on \nthe other hand, are typically used to control when funds can be moved. \nIn these use cases, one or more of the parties involved explicitly want \nthere to be a delay even if there were an idealized situation in which \nconsensus is always reached instantaneously and there were never any \nreorgs.\n\nMoreover, since we already have CLTV, adding RCLTV or some variant \nthereof makes the relationship between the two more explicit.\n\nSo my vote goes to RCLTV or RCHECKLOCKTIMEVERIFY.\n\nAs for whether to explicitly use CHECK_..._VERIFY, consider that with \nsegregated witness it will be possible to add opcodes that can push \nvalues onto the stack (rather than just hard failing or NOP), so there's \nsomething to be said for naming consistency.\n\n- Eric\n\n\n\n------ Original Message ------\nFrom: \"Jorge Tim\u00f3n\" <bitcoin-dev at lists.linuxfoundation.org>\nTo: \"Btc Drak\" <btcdrak at gmail.com>\nCc: \"Bitcoin Dev\" <bitcoin-dev at lists.linuxfoundation.org>\nSent: 11/24/2015 4:31:55 AM\nSubject: Re: [bitcoin-dev] Alternative name for CHECKSEQUENCEVERIFY \n(BIP112)\n\n>I agree, I believe the first name that an op with equivalent \n>functionality had was simply op_maturity.\n>At least I remember we discussed such an opcode when discussing pegged \n>sidechains' design.\n>\n>I kind of dislike the check_x_verify naming pattern. We want all new \n>operands to return if whatever they're checking/verifying fails, fine. \n>Do we have to repeat this redundant naming pattern forever due to that \n>discovery?\n>I hope not, but if that's the case my vote is for CMV.\n>As said before, I believe the documentation and code comments can \n>become much more clear with this change.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151125/f2bded13/attachment.html>"
            },
            {
                "author": "Eric Lombrozo",
                "date": "2015-11-26T21:32:58",
                "message_text_only": "After a little more though (and some comments from aj), I realize that the opcode naming convention is actually CHECK <condition > VERIFY.\n\nTherefore, the full opcode name should be CHECKRELATIVELOCKTIMEVERIFY.\n\nHowever, this name is ridiculously long, so at least some part will require abbreviation.\n\nIn typical script example usage, most sensible seems to be to abbreviate both CLTV and CRLTV.\n\n- Eric\n\nOn November 24, 2015 5:14:55 PM PST, Eric Lombrozo <elombrozo at gmail.com> wrote:\n>From a system developer standpoint, CHECKMATURITYVERIFY ties together \n>the semantics of this opcode with another existing feature in the\n>system \n>(coinbase maturity).\n>\n>HOWEVER...\n>\n>from an application developer standpoint, I think the concept of a \n>timelock is more relevant. Maturity is a concept that was introduced\n>for \n>the sake of reducing the disruptive impact of reorgs. Miners would \n>prefer to be able to spend the coins immediately, but instead they are \n>forced to wait due to inherent limitations of the system. Timelocks, on\n>\n>the other hand, are typically used to control when funds can be moved. \n>In these use cases, one or more of the parties involved explicitly want\n>\n>there to be a delay even if there were an idealized situation in which \n>consensus is always reached instantaneously and there were never any \n>reorgs.\n>\n>Moreover, since we already have CLTV, adding RCLTV or some variant \n>thereof makes the relationship between the two more explicit.\n>\n>So my vote goes to RCLTV or RCHECKLOCKTIMEVERIFY.\n>\n>As for whether to explicitly use CHECK_..._VERIFY, consider that with \n>segregated witness it will be possible to add opcodes that can push \n>values onto the stack (rather than just hard failing or NOP), so\n>there's \n>something to be said for naming consistency.\n>\n>- Eric\n>\n>\n>\n>------ Original Message ------\n>From: \"Jorge Tim\u00f3n\" <bitcoin-dev at lists.linuxfoundation.org>\n>To: \"Btc Drak\" <btcdrak at gmail.com>\n>Cc: \"Bitcoin Dev\" <bitcoin-dev at lists.linuxfoundation.org>\n>Sent: 11/24/2015 4:31:55 AM\n>Subject: Re: [bitcoin-dev] Alternative name for CHECKSEQUENCEVERIFY \n>(BIP112)\n>\n>>I agree, I believe the first name that an op with equivalent \n>>functionality had was simply op_maturity.\n>>At least I remember we discussed such an opcode when discussing pegged\n>\n>>sidechains' design.\n>>\n>>I kind of dislike the check_x_verify naming pattern. We want all new \n>>operands to return if whatever they're checking/verifying fails, fine.\n>\n>>Do we have to repeat this redundant naming pattern forever due to that\n>\n>>discovery?\n>>I hope not, but if that's the case my vote is for CMV.\n>>As said before, I believe the documentation and code comments can \n>>become much more clear with this change.\n>>\n\n-- \nSent from my Android device with K-9 Mail. Please excuse my brevity.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151126/6326f2b7/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2015-11-26T22:25:56",
                "message_text_only": "On Thu, Nov 26, 2015 at 01:32:58PM -0800, Eric Lombrozo via bitcoin-dev wrote:\n> After a little more though (and some comments from aj), I realize that the opcode naming convention is actually CHECK <condition > VERIFY.\n> \n> Therefore, the full opcode name should be CHECKRELATIVELOCKTIMEVERIFY.\n> \n> However, this name is ridiculously long, so at least some part will require abbreviation.\n> \n> In typical script example usage, most sensible seems to be to abbreviate both CLTV and CRLTV.\n\n...and CRLTV is hard to visually distinguish from CLTV. :(\n\nYou know, calling it AGEVERIFY is short and sweet.\n\n-- \n'peter'[:-1]@petertodd.org\n00000000000000000ef246c814f8cb8c1a26bc3c6cb1286bdbc5f4140ed3fc79\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151126/47f980c2/attachment.sig>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2015-11-25T23:05:50",
                "message_text_only": "Looks like I'm the long dissenting voice here? As the originator of the\nname CHECKSEQUENCEVERIFY, perhaps I can explain why the name was\nappropriately chosen and why the proposed alternatives don't stand up.\n\nFirst, the names are purposefully chosen to illustrate what they do:\n\nWhat does CHECKLOCKTIMEVERIFY do? It verifies the range of tx.nLockTime.\nWhat does CHECKSEQUENCEVERIFY do? It verifies the range of txin.nSequence.\n\nSecond, the semantics are not limited to relative lock-time / maturity\nonly. They both leave open ranges with possible, but currently undefined\nfuture consensus-enforced behavior. We don't know what sort of future\nbehavior these values might trigger, but the associated opcodes are generic\nenough to handle them:\n\nCHECKLOCKTIMEVERIFY will pass an nSequence between 1985 and 2009, even\nthough such constraints have no meaning in Bitcoin.\nCHECKSEQUENCEVERIFY is explicitly written to permit a 5-byte push operand,\nwhile checking only 17 of the available 39 bits of both the operand and the\nnSequence. Indeed the most recent semantic change of CSV was justified in\npart because it relaxes all constraints over the values of these bits\nfreeing them for other purposes in transaction validation and/or future\nextensions of the opcode semantics.\n\nThird, single-byte opcode space is limited. There are less than 10 such\nopcodes left. Maybe space won't be so precious in a post-segwitness world,\nbut I don't want to presume that just yet.\n\n\nAs for the alternatives, they capture only the initial use case of\nnSequence. My objection would relax if nSequence were renamed, but I think\nthat would be too disruptive and unnecessary. In any case, the imagined use\ncases for CHECKSEQUENCEVERIFY has to do with sequencing execution pathways\nof script, so it's not a stretch in meaning. Previously CHECKMATURITYVERIFY\nwas a hypothicated opcode that directly checked the minimum age of inputs\nof a transaction. The indirect naming of CHECKSEQUENCEVERIFY on the other\nhand is due to its indirect behavior. RELATIVELOCKTIMEVERIFY was also a\nhypothicated opcode that would check a ficticious nRelativeLockTime field,\nwhich does not exist. Again my objection would go away if we renamed\nnSequence, but I actually think the nSequence name is better...\n\nOn Tue, Nov 24, 2015 at 2:30 AM, Btc Drak via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> BIP68 introduces relative lock-time semantics to part of the nSequence\n> field leaving the majority of bits undefined for other future applications.\n>\n> BIP112 introduces opcode CHECKSEQUENCEVERIFY (OP_CSV) that is specifically\n> limited to verifying transaction inputs according to BIP68's relative\n> lock-time[1], yet the _name_ OP_CSV is much boarder than that. We spent\n> months limiting the number of bits used in BIP68 so they would be available\n> for future use cases, thus we have acknowledged there will be completely\n> different usecases that take advantage of unused nSequence bits.\n>\n> For this reason I believe the BIP112 should be renamed specifically for\n> it's usecase, which is verifying the time/maturity of transaction inputs\n> relative to their inclusion in a block.\n>\n> Suggestions:-\n>\n> CHECKMATURITYVERIFY\n> RELATIVELOCKTIMEVERIFY\n> RCHECKLOCKTIMEVERIFY\n> RCLTV\n>\n> We could of course softfork additional meaning into OP_CSV each time we\n> add new sequence number usecases, but that would become obscure and\n> confusing. We have already shown there is no shortage of opcodes so it\n> makes no sense to cram everything into one generic opcode.\n>\n> TL;DR: let's give BIP112 opcode a name that reflects it's actual usecase\n> rather than focusing on the bitcoin internals.\n>\n> [1]\n> https://github.com/bitcoin/bitcoin/pull/6564/files#diff-be2905e2f5218ecdbe4e55637dac75f3R1223\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151125/25ab2f56/attachment-0001.html>"
            },
            {
                "author": "Eric Lombrozo",
                "date": "2015-11-25T23:41:03",
                "message_text_only": "As I said in an earlier post, a systems developer and an application \ndeveloper have very different perspectives on this. From the former's \nperspective, it is entirely sensible to name things based on basic \nfeatures of the system's design (i.e. a field in the txin or tx that \ngets checked) - but from an app developer's perspective, what matters is \nhow they will use a particular feature in an actual app.\n\nI think that part of what systems developers should strive to do is to \nabstract out the inner minutiae of the system's guts and expose to app \ndevelopers the clearest interface with which to develop apps. This is \neven more the case when the details of the inner workings are completely \nirrelevant to the application logic and there's no real gains to be had \nfrom attempting to optimize for the inner workings when designing an \napplication.\n\n>From an app developer's perspective, I think it is pretty blatantly \nclear that relative timelock is *the* critical exposed functionality \nintended here. Now, one could argue that the satoshi script is still a \nsystems level component of the system...but with the advent of overlay \nprotocols such as payment channels and the Lightning Network, it is \nclear that we now require a new abstraction layer for reasoning about \nthe higher level logic of the system that doesn't burden the protocol \ndesigner with having to know the intimate and esoteric details of the \nlower system levels. Of course, many of those who work on these higher \nlevel protocols will also be experts in the underlying system design. \nHowever, it greatly increases the learning curve and can easily \nfrustrate people looking to work on these ideas...and ultimately, \nknowing the inner details of how the nSequence field is structured and \nwhat the bits actually mean is irrelevant to someone trying to design \nscripts for such applications.\n\nWe've already deployed another opcode, CHECKLOCKTIMEVERIFY, which does \nrefer to the field name. However, in this particular situation, the \nfield name reflects *far* more closely what the app developer actually \ncares about than nSequence, which to the app developer might as well be \ncalled foo. As such, I stick with my original vote - we should call the \nopcode RCHECKLOCKTIMEVERIFY, which has the advantage of communicating \nfairly directly to developers and protocol designers the semantics they \nactually care about and also makes clear the relationship between \nabsolute and relative timelock...that's to say, the ability for the \nscript designer to lock specific coins until either a specific moment in \ntime or until a certain delay has passed since the coin output was \ncreated (added to blockchain).\n\nLet's face it - the entire motivation behind BIP68/BIP112 is relative \ntimelock. Explicitly calling the opcode RCHECKLOCKTIMEVERIFY will make \nlife easier for everyone and will help sell the idea and help it gain \ngreater acceptance more quickly; while stubbornly adhering to an \nesoteric detail that is only there for historical reasons will only \ncontinue to delay the idea's acceptance and adoptance.\n\n- Eric\n\n------ Original Message ------\nFrom: \"Mark Friedenbach via bitcoin-dev\" \n<bitcoin-dev at lists.linuxfoundation.org>\nTo: \"Btc Drak\" <btcdrak at gmail.com>\nCc: \"Bitcoin Dev\" <bitcoin-dev at lists.linuxfoundation.org>\nSent: 11/25/2015 3:05:50 PM\nSubject: Re: [bitcoin-dev] Alternative name for CHECKSEQUENCEVERIFY \n(BIP112)\n\n>Looks like I'm the long dissenting voice here? As the originator of the \n>name CHECKSEQUENCEVERIFY, perhaps I can explain why the name was \n>appropriately chosen and why the proposed alternatives don't stand up.\n>\n>First, the names are purposefully chosen to illustrate what they do:\n>\n>What does CHECKLOCKTIMEVERIFY do? It verifies the range of \n>tx.nLockTime.\n>What does CHECKSEQUENCEVERIFY do? It verifies the range of \n>txin.nSequence.\n>\n>Second, the semantics are not limited to relative lock-time / maturity \n>only. They both leave open ranges with possible, but currently \n>undefined future consensus-enforced behavior. We don't know what sort \n>of future behavior these values might trigger, but the associated \n>opcodes are generic enough to handle them:\n>\n>CHECKLOCKTIMEVERIFY will pass an nSequence between 1985 and 2009, even \n>though such constraints have no meaning in Bitcoin.\n>CHECKSEQUENCEVERIFY is explicitly written to permit a 5-byte push \n>operand, while checking only 17 of the available 39 bits of both the \n>operand and the nSequence. Indeed the most recent semantic change of \n>CSV was justified in part because it relaxes all constraints over the \n>values of these bits freeing them for other purposes in transaction \n>validation and/or future extensions of the opcode semantics.\n>\n>Third, single-byte opcode space is limited. There are less than 10 such \n>opcodes left. Maybe space won't be so precious in a post-segwitness \n>world, but I don't want to presume that just yet.\n>\n>\n>As for the alternatives, they capture only the initial use case of \n>nSequence. My objection would relax if nSequence were renamed, but I \n>think that would be too disruptive and unnecessary. In any case, the \n>imagined use cases for CHECKSEQUENCEVERIFY has to do with sequencing \n>execution pathways of script, so it's not a stretch in meaning. \n>Previously CHECKMATURITYVERIFY was a hypothicated opcode that directly \n>checked the minimum age of inputs of a transaction. The indirect naming \n>of CHECKSEQUENCEVERIFY on the other hand is due to its indirect \n>behavior. RELATIVELOCKTIMEVERIFY was also a hypothicated opcode that \n>would check a ficticious nRelativeLockTime field, which does not exist. \n>Again my objection would go away if we renamed nSequence, but I \n>actually think the nSequence name is better...\n>\n>On Tue, Nov 24, 2015 at 2:30 AM, Btc Drak via bitcoin-dev \n><bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>BIP68 introduces relative lock-time semantics to part of the nSequence \n>>field leaving the majority of bits undefined for other future \n>>applications.\n>>\n>>BIP112 introduces opcode CHECKSEQUENCEVERIFY (OP_CSV) that is \n>>specifically limited to verifying transaction inputs according to \n>>BIP68's relative lock-time[1], yet the _name_ OP_CSV is much boarder \n>>than that. We spent months limiting the number of bits used in BIP68 \n>>so they would be available for future use cases, thus we have \n>>acknowledged there will be completely different usecases that take \n>>advantage of unused nSequence bits.\n>>\n>>For this reason I believe the BIP112 should be renamed specifically \n>>for it's usecase, which is verifying the time/maturity of transaction \n>>inputs relative to their inclusion in a block.\n>>\n>>Suggestions:-\n>>\n>>CHECKMATURITYVERIFY\n>>RELATIVELOCKTIMEVERIFY\n>>RCHECKLOCKTIMEVERIFY\n>>RCLTV\n>>\n>>We could of course softfork additional meaning into OP_CSV each time \n>>we add new sequence number usecases, but that would become obscure and \n>>confusing. We have already shown there is no shortage of opcodes so it \n>>makes no sense to cram everything into one generic opcode.\n>>\n>>TL;DR: let's give BIP112 opcode a name that reflects it's actual \n>>usecase rather than focusing on the bitcoin internals.\n>>\n>>[1] \n>>https://github.com/bitcoin/bitcoin/pull/6564/files#diff-be2905e2f5218ecdbe4e55637dac75f3R1223\n>>\n>>_______________________________________________\n>>bitcoin-dev mailing list\n>>bitcoin-dev at lists.linuxfoundation.org\n>>https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151125/180fa442/attachment.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2015-11-26T22:23:38",
                "message_text_only": "Actually, with this argument I think CHECKSEQUENCEVERIFY is more appropriate. To an app developer, you're enforcing maturity by enforcing sequence. I think it's much more clear to app devs to say sequence here since it makes explicit how to create the transaction which passes the check, whereas saying maturity night be confusing.\n\nOn November 25, 2015 6:41:03 PM EST, Eric Lombrozo via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>As I said in an earlier post, a systems developer and an application \n>developer have very different perspectives on this. From the former's \n>perspective, it is entirely sensible to name things based on basic \n>features of the system's design (i.e. a field in the txin or tx that \n>gets checked) - but from an app developer's perspective, what matters\n>is \n>how they will use a particular feature in an actual app.\n>\n>I think that part of what systems developers should strive to do is to \n>abstract out the inner minutiae of the system's guts and expose to app \n>developers the clearest interface with which to develop apps. This is \n>even more the case when the details of the inner workings are\n>completely \n>irrelevant to the application logic and there's no real gains to be had\n>\n>from attempting to optimize for the inner workings when designing an \n>application.\n>\n>From an app developer's perspective, I think it is pretty blatantly \n>clear that relative timelock is *the* critical exposed functionality \n>intended here. Now, one could argue that the satoshi script is still a \n>systems level component of the system...but with the advent of overlay \n>protocols such as payment channels and the Lightning Network, it is \n>clear that we now require a new abstraction layer for reasoning about \n>the higher level logic of the system that doesn't burden the protocol \n>designer with having to know the intimate and esoteric details of the \n>lower system levels. Of course, many of those who work on these higher \n>level protocols will also be experts in the underlying system design. \n>However, it greatly increases the learning curve and can easily \n>frustrate people looking to work on these ideas...and ultimately, \n>knowing the inner details of how the nSequence field is structured and \n>what the bits actually mean is irrelevant to someone trying to design \n>scripts for such applications.\n>\n>We've already deployed another opcode, CHECKLOCKTIMEVERIFY, which does \n>refer to the field name. However, in this particular situation, the \n>field name reflects *far* more closely what the app developer actually \n>cares about than nSequence, which to the app developer might as well be\n>\n>called foo. As such, I stick with my original vote - we should call the\n>\n>opcode RCHECKLOCKTIMEVERIFY, which has the advantage of communicating \n>fairly directly to developers and protocol designers the semantics they\n>\n>actually care about and also makes clear the relationship between \n>absolute and relative timelock...that's to say, the ability for the \n>script designer to lock specific coins until either a specific moment\n>in \n>time or until a certain delay has passed since the coin output was \n>created (added to blockchain).\n>\n>Let's face it - the entire motivation behind BIP68/BIP112 is relative \n>timelock. Explicitly calling the opcode RCHECKLOCKTIMEVERIFY will make \n>life easier for everyone and will help sell the idea and help it gain \n>greater acceptance more quickly; while stubbornly adhering to an \n>esoteric detail that is only there for historical reasons will only \n>continue to delay the idea's acceptance and adoptance.\n>\n>- Eric\n>\n>------ Original Message ------\n>From: \"Mark Friedenbach via bitcoin-dev\" \n><bitcoin-dev at lists.linuxfoundation.org>\n>To: \"Btc Drak\" <btcdrak at gmail.com>\n>Cc: \"Bitcoin Dev\" <bitcoin-dev at lists.linuxfoundation.org>\n>Sent: 11/25/2015 3:05:50 PM\n>Subject: Re: [bitcoin-dev] Alternative name for CHECKSEQUENCEVERIFY \n>(BIP112)\n>\n>>Looks like I'm the long dissenting voice here? As the originator of\n>the \n>>name CHECKSEQUENCEVERIFY, perhaps I can explain why the name was \n>>appropriately chosen and why the proposed alternatives don't stand up.\n>>\n>>First, the names are purposefully chosen to illustrate what they do:\n>>\n>>What does CHECKLOCKTIMEVERIFY do? It verifies the range of \n>>tx.nLockTime.\n>>What does CHECKSEQUENCEVERIFY do? It verifies the range of \n>>txin.nSequence.\n>>\n>>Second, the semantics are not limited to relative lock-time / maturity\n>\n>>only. They both leave open ranges with possible, but currently \n>>undefined future consensus-enforced behavior. We don't know what sort \n>>of future behavior these values might trigger, but the associated \n>>opcodes are generic enough to handle them:\n>>\n>>CHECKLOCKTIMEVERIFY will pass an nSequence between 1985 and 2009, even\n>\n>>though such constraints have no meaning in Bitcoin.\n>>CHECKSEQUENCEVERIFY is explicitly written to permit a 5-byte push \n>>operand, while checking only 17 of the available 39 bits of both the \n>>operand and the nSequence. Indeed the most recent semantic change of \n>>CSV was justified in part because it relaxes all constraints over the \n>>values of these bits freeing them for other purposes in transaction \n>>validation and/or future extensions of the opcode semantics.\n>>\n>>Third, single-byte opcode space is limited. There are less than 10\n>such \n>>opcodes left. Maybe space won't be so precious in a post-segwitness \n>>world, but I don't want to presume that just yet.\n>>\n>>\n>>As for the alternatives, they capture only the initial use case of \n>>nSequence. My objection would relax if nSequence were renamed, but I \n>>think that would be too disruptive and unnecessary. In any case, the \n>>imagined use cases for CHECKSEQUENCEVERIFY has to do with sequencing \n>>execution pathways of script, so it's not a stretch in meaning. \n>>Previously CHECKMATURITYVERIFY was a hypothicated opcode that directly\n>\n>>checked the minimum age of inputs of a transaction. The indirect\n>naming \n>>of CHECKSEQUENCEVERIFY on the other hand is due to its indirect \n>>behavior. RELATIVELOCKTIMEVERIFY was also a hypothicated opcode that \n>>would check a ficticious nRelativeLockTime field, which does not\n>exist. \n>>Again my objection would go away if we renamed nSequence, but I \n>>actually think the nSequence name is better...\n>>\n>>On Tue, Nov 24, 2015 at 2:30 AM, Btc Drak via bitcoin-dev \n>><bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>BIP68 introduces relative lock-time semantics to part of the\n>nSequence \n>>>field leaving the majority of bits undefined for other future \n>>>applications.\n>>>\n>>>BIP112 introduces opcode CHECKSEQUENCEVERIFY (OP_CSV) that is \n>>>specifically limited to verifying transaction inputs according to \n>>>BIP68's relative lock-time[1], yet the _name_ OP_CSV is much boarder \n>>>than that. We spent months limiting the number of bits used in BIP68 \n>>>so they would be available for future use cases, thus we have \n>>>acknowledged there will be completely different usecases that take \n>>>advantage of unused nSequence bits.\n>>>\n>>>For this reason I believe the BIP112 should be renamed specifically \n>>>for it's usecase, which is verifying the time/maturity of transaction\n>\n>>>inputs relative to their inclusion in a block.\n>>>\n>>>Suggestions:-\n>>>\n>>>CHECKMATURITYVERIFY\n>>>RELATIVELOCKTIMEVERIFY\n>>>RCHECKLOCKTIMEVERIFY\n>>>RCLTV\n>>>\n>>>We could of course softfork additional meaning into OP_CSV each time \n>>>we add new sequence number usecases, but that would become obscure\n>and \n>>>confusing. We have already shown there is no shortage of opcodes so\n>it \n>>>makes no sense to cram everything into one generic opcode.\n>>>\n>>>TL;DR: let's give BIP112 opcode a name that reflects it's actual \n>>>usecase rather than focusing on the bitcoin internals.\n>>>\n>>>[1] \n>>>https://github.com/bitcoin/bitcoin/pull/6564/files#diff-be2905e2f5218ecdbe4e55637dac75f3R1223\n>>>\n>>>_______________________________________________\n>>>bitcoin-dev mailing list\n>>>bitcoin-dev at lists.linuxfoundation.org\n>>>https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>\n>\n>------------------------------------------------------------------------\n>\n>_______________________________________________\n>bitcoin-dev mailing list\n>bitcoin-dev at lists.linuxfoundation.org\n>https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151126/9a401bd9/attachment-0001.html>"
            },
            {
                "author": "Rusty Russell",
                "date": "2015-11-27T04:02:45",
                "message_text_only": "Eric Lombrozo via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> writes:\n>>From an app developer's perspective, I think it is pretty blatantly \n> clear that relative timelock is *the* critical exposed functionality \n> intended here.\n\nAs someone who actually developed scripts using CSV, I agree with Mark\n(and Matt).  The relative locktime stuff isn't in this opcode, it's in\nthe nSequence calculation.\n\nSo, I vote to keep CSV called as it is.\n\nThanks,\nRusty."
            },
            {
                "author": "Eric Lombrozo",
                "date": "2015-11-27T08:10:49",
                "message_text_only": "After reading Rusty's post, I admit there's something to be said for the fact that both the script and the nSequence field play a combined role, and thus, making the interaction between the two more clear in the naming make sense.\n\nIt is somewhat unfortunate that currently, we can't just have a dedicated field for the purpose of relative locktime (or minimum age) without having to repurpose the only unused 32 bits in the txin.\n\nHOWEVER...there might be ways around this issue using segwit.\n\nI've been pondering the possibility of adding an extra input vector to the prunable extra data that  comprises the witness. Witness structures can provide additional data that is used in transaction validation but does not contribute to the tx hash.\n\nCurrently, the signature checking opcodes in the script already do this implicitly for computing the hash that is signed (but not the tx hash used in block merkletrees)...and this is the principal cause of undesirable malleability issues. Clearly the signatures themselves cannot contribute to the hash they are signing. So segwit makes this separation explicit by moving the signatures to a structure external to the script. Pieter Wuille's implementation (https://github.com/sipa/bitcoin/tree/segwit) generalizes this idea using a script witness structure that is a vector of arbitrary inputs. Clearly moving the signatures into such structure is an important feature...but other types of input to the script could be placed here as well.\n\nI had considered the possibility of placing a minimum age (relative locktime) field in the input vector that could be checked for mempool acceptance without having to evaluate the script. Of course, the location of such a field would have to be known by the mempool and cannot be an arbitrary element of a generic input vector, which adds some minor but surmountable complications.\n\nGreg Maxwell pointed out, however, that signing opcodes that sign hashes discarding this data would make it trivial for anyone to change this field without signing anything. The nSequence fields of txins, being part of the tx serialization that gets hashed, is therefore always signed.\n\nThis led me to consider the possibility of adding extra opcodes to the script that can incorporate additional data in the hash that gets signed. This data would go in another structure that does not contribute to the tx hash but is outside the witness. Then we could add extra prunable data fields that the signer can commit to.\n\nIf I've missed something critical in the above analysis, someone please correct me...but it seems that such a mechanism would allow adding extra prunable signed data fields to transactions, which might ultimately remove scarcity of tx data that we can repurpose via soft forks. If this is the case, I would suggest turning the nSequence field into a dedicated min age/rlt field to simplify the semantics and avoid ugliness in trying to reclaim unused bits.\n\nI may be overlooking something important here, but unless there's a reason such data cannot be made prunable, I haven't been able to poke a hole yet.\n\n- Eric\n\n\n\nOn November 26, 2015 8:02:45 PM PST, Rusty Russell <rusty at rustcorp.com.au> wrote:\n>Eric Lombrozo via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n>writes:\n>>>From an app developer's perspective, I think it is pretty blatantly \n>> clear that relative timelock is *the* critical exposed functionality \n>> intended here.\n>\n>As someone who actually developed scripts using CSV, I agree with Mark\n>(and Matt).  The relative locktime stuff isn't in this opcode, it's in\n>the nSequence calculation.\n>\n>So, I vote to keep CSV called as it is.\n>\n>Thanks,\n>Rusty.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151127/73b49c65/attachment-0001.html>"
            },
            {
                "author": "Dave Scotese",
                "date": "2015-11-27T04:08:35",
                "message_text_only": "I was curious about there being only 10 single-byte opcodes left.  There\nare ten single-byte OP_NOPx opcodes defined, but there are 15 opcodes that\n\"simply *do not exist anymore* in the protocol\" because they are scary (had\nbugs that \"could crash any Bitcoin node if exploited\" or \"allowed anyone to\nspend anyone's bitcoins\").  There are also 66 single-byte values that are\ncurrently reserved, 186 - 252 (0xba - 0xfc).\n\nIf the name OP_CHECKSEQUENCEVERIFY should not be changed, each of us has a\nsingle best reason not to change it.  Finding other reasons suggests that\none's top reason isn't good enough.  See Nassim Taleb's book, Antifragile,\nif that claim makes you curious.  The same goes for changing it.  In any\ncase, it is 178 (0xb2) and app developers can call it whatever they want.\n\nIt seems trivial to me since the following, in script.h, would neither slow\ncompilation nor confuse anyone, but could lead the curious to explore the\nhistory and expand their knowledge:\nOP_NOP3 = 0xb2,\nOP_CHECKSEQUENCEVERIFY = OP_NOP3,\nOP_CHECKMATURITYVERIFY = OP_NOP3, // A comment defending the alternative\nname\n\nI don't know the consensus here on leaving breadcrumbs in code comments\n(and enum/variable names) for curious coders to use as inspiration for\nstudying the history, but I advocate it, since modern IDEs are fairly\nwell-equipped to make skipping or hiding comments easy.\n\n\nOn Wed, Nov 25, 2015 at 3:05 PM, Mark Friedenbach via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Looks like I'm the long dissenting voice here? As the originator of the\n> name CHECKSEQUENCEVERIFY, perhaps I can explain why the name was\n> appropriately chosen and why the proposed alternatives don't stand up.\n>\n> First, the names are purposefully chosen to illustrate what they do:\n>\n> What does CHECKLOCKTIMEVERIFY do? It verifies the range of tx.nLockTime.\n> What does CHECKSEQUENCEVERIFY do? It verifies the range of txin.nSequence.\n>\n> Second, the semantics are not limited to relative lock-time / maturity\n> only. They both leave open ranges with possible, but currently undefined\n> future consensus-enforced behavior. We don't know what sort of future\n> behavior these values might trigger, but the associated opcodes are generic\n> enough to handle them:\n>\n> CHECKLOCKTIMEVERIFY will pass an nSequence between 1985 and 2009, even\n> though such constraints have no meaning in Bitcoin.\n> CHECKSEQUENCEVERIFY is explicitly written to permit a 5-byte push operand,\n> while checking only 17 of the available 39 bits of both the operand and the\n> nSequence. Indeed the most recent semantic change of CSV was justified in\n> part because it relaxes all constraints over the values of these bits\n> freeing them for other purposes in transaction validation and/or future\n> extensions of the opcode semantics.\n>\n> Third, single-byte opcode space is limited. There are less than 10 such\n> opcodes left. Maybe space won't be so precious in a post-segwitness world,\n> but I don't want to presume that just yet.\n>\n>\n> As for the alternatives, they capture only the initial use case of\n> nSequence. My objection would relax if nSequence were renamed, but I think\n> that would be too disruptive and unnecessary. In any case, the imagined use\n> cases for CHECKSEQUENCEVERIFY has to do with sequencing execution pathways\n> of script, so it's not a stretch in meaning. Previously CHECKMATURITYVERIFY\n> was a hypothicated opcode that directly checked the minimum age of inputs\n> of a transaction. The indirect naming of CHECKSEQUENCEVERIFY on the other\n> hand is due to its indirect behavior. RELATIVELOCKTIMEVERIFY was also a\n> hypothicated opcode that would check a ficticious nRelativeLockTime field,\n> which does not exist. Again my objection would go away if we renamed\n> nSequence, but I actually think the nSequence name is better...\n>\n> On Tue, Nov 24, 2015 at 2:30 AM, Btc Drak via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> BIP68 introduces relative lock-time semantics to part of the nSequence\n>> field leaving the majority of bits undefined for other future applications.\n>>\n>> BIP112 introduces opcode CHECKSEQUENCEVERIFY (OP_CSV) that is\n>> specifically limited to verifying transaction inputs according to BIP68's\n>> relative lock-time[1], yet the _name_ OP_CSV is much boarder than that. We\n>> spent months limiting the number of bits used in BIP68 so they would be\n>> available for future use cases, thus we have acknowledged there will be\n>> completely different usecases that take advantage of unused nSequence bits.\n>>\n>> For this reason I believe the BIP112 should be renamed specifically for\n>> it's usecase, which is verifying the time/maturity of transaction inputs\n>> relative to their inclusion in a block.\n>>\n>> Suggestions:-\n>>\n>> CHECKMATURITYVERIFY\n>> RELATIVELOCKTIMEVERIFY\n>> RCHECKLOCKTIMEVERIFY\n>> RCLTV\n>>\n>> We could of course softfork additional meaning into OP_CSV each time we\n>> add new sequence number usecases, but that would become obscure and\n>> confusing. We have already shown there is no shortage of opcodes so it\n>> makes no sense to cram everything into one generic opcode.\n>>\n>> TL;DR: let's give BIP112 opcode a name that reflects it's actual usecase\n>> rather than focusing on the bitcoin internals.\n>>\n>> [1]\n>> https://github.com/bitcoin/bitcoin/pull/6564/files#diff-be2905e2f5218ecdbe4e55637dac75f3R1223\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n\n\n-- \nI like to provide some work at no charge to prove my value. Do you need a\ntechie?\nI own Litmocracy <http://www.litmocracy.com> and Meme Racing\n<http://www.memeracing.net> (in alpha).\nI'm the webmaster for The Voluntaryist <http://www.voluntaryist.com> which\nnow accepts Bitcoin.\nI also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n\"He ought to find it more profitable to play by the rules\" - Satoshi\nNakamoto\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151126/53c45125/attachment.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-27T10:14:10",
                "message_text_only": "On Nov 26, 2015 12:06 AM, \"Mark Friedenbach via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n> Again my objection would go away if we renamed nSequence, but I actually\nthink the nSequence name is better...\n\nI suggested to rename nSequence to nMaturity on this list even before the\nbips and implementations were started, probably too late now.\nBefore the implementation \"let's think about those naming details later\".\nAfter the implementation \"now it's too late, now we would need to change\nthe implementation, this renaming is now unnecessarily disruptive\".\n\nReminds me of refactors and major releases:\nAt the beginning of the release \"not now, this will disrupt development of\nfeature X\"\nAfter feature X is merged or replaced by feature Y: \"too late in the\nrelease cycle, refactors should be done only at the beginning, at the end\nis 'too risky' \".\nSigh, I hope I find the \"right time\" (not both too soon and too late like\nthis time), next time...\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151127/aae8691b/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Alternative name for CHECKSEQUENCEVERIFY (BIP112)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Rusty Russell",
                "Eric Lombrozo",
                "Peter Todd",
                "Dave Scotese",
                "Jorge Tim\u00f3n",
                "Btc Drak",
                "Matt Corallo",
                "Mark Friedenbach"
            ],
            "messages_count": 14,
            "total_messages_chars_count": 42933
        }
    },
    {
        "title": "[bitcoin-dev] OP_CHECKWILDCARDSIGVERIFY or \"Wildcard Inputs\" or \"Coalescing Transactions\"",
        "thread_messages": [
            {
                "author": "Chris Priest",
                "date": "2015-11-24T17:34:35",
                "message_text_only": "Here is the problem I'm trying to solve with this idea:\n\nLets say you create an address, publish the address on your blog, and\ntell all your readers to donate $0.05 to that address if they like\nyour blog. Lets assume you receive 10,000 donations this way. This all\nadds up to $500. The problem is that because of the way the bitcoin\npayment protocol works, a large chunk of that money will go to fees.\nIf one person sent you a single donation of $500, you would be able to\nspend most of the $500, but since you got this coin by many smaller\nUTXO's, your wallet has to use a higher tx fee when spending this\ncoin.\n\nThe technical reason for this is that you have to explicitly list each\nUTXO individually when making bitcoin transactions. There is no way to\nsay \"all the utxos\". This post describes a way to achieve this. I'm\nnot yet a bitcoin master, so there are parts of this proposal that I\nhave not yet figured out entirely, but I'm sure other people who know\nmore could help out.\n\n**OP_CHECKWILDCARDSIGVERIFY**\n\nFirst, I propose a new opcode. This opcode works exactly the same as\nOP_CHECKSIGVERIFY, except it only evaluates true if the signature is a\n\"wildcard signature\". What is a wildcard signature you ask? This is\nthe part that I have not yet 100% figured out yet. It is basically a\nsignature that was created in such a way that expresses the private\nkey owners intent to make this input a *wildcard input*\n\n** wildcard inputs **\n\nA wildcard input is defined as a input to a transaction that has been\nsigned with OP_CHECKWILDCARDSIGVERIFY. The difference between a\nwildcard input and a regular input is that the regular input respects\nthe \"value\" or \"amount\" field, while the wildcard input ignores that\nvalue, and instead uses the value of *all inputs* with a matching\nlocking script.\n\n** coalescing transaction\"\n\nA bitcoin transaction that"
            },
            {
                "author": "Gavin Andresen",
                "date": "2015-11-24T20:32:37",
                "message_text_only": "On Tue, Nov 24, 2015 at 12:34 PM, Chris Priest via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> The technical reason for this is that you have to explicitly list each\n> UTXO individually when making bitcoin transactions. There is no way to\n> say \"all the utxos\". This post describes a way to achieve this. I'm\n> not yet a bitcoin master, so there are parts of this proposal that I\n> have not yet figured out entirely, but I'm sure other people who know\n> more could help out.\n>\n\nSo every input has:\n 32-byte hash (transaction being spent)\n 4-byte output (output being spent)\n 4-byte sequence number\n... plus the scriptSig. Which is as small as about 73 bytes if you're\nspending a raw OP_CHECKSIG (which you can't do as a bitcoin address, but\ncould via the BIP70 payment protocol), and which is at least two serialized\nbytes.\n\nBest case for any scheme to coalesce scriptSigs would to somehow make\nall-but-the-first scriptSig zero-length, so the inputs would be 42 bytes\ninstead of 40+73 bytes -- the coalesce transaction would be about one-third\nthe size, so instead of paying (say) $1 in transaction fees you'd pay 37\ncents.\n\nThat's in the gray are of the \"worth doing\" threshold-- if it was a 10x\nimprovement (pay 10 cents instead of $1) it'd be in my personal \"definitely\nworth the trouble of doing\" category.\n\nRE: the scheme:  an OP_RINGSIGVERIFY is probably the right way to do this:\n  https://en.wikipedia.org/wiki/Ring_signature\n\nThe funding transactions would be:  <public key> OP_RINGSIGVERIFY\n... which might could be redeemed with <ring signature> for one input and\nthen... uhh... maybe just <index_to_input_with_signature> for the other\ninputs that are part of the same ring signature group (OP_0 if the first\ninput has the signature that is good for all the other public keys, which\nwould be the common case).\n\n-- \n--\nGavin Andresen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151124/ea951f71/attachment.html>"
            },
            {
                "author": "Chris Priest",
                "date": "2015-11-24T21:01:26",
                "message_text_only": "A coalescing transaction in my scheme is the same size as a normal\ntransaction. You only include one UTXO, the rest are implied based on\nthe presence of the OP_CHECKWILDCARDSIGVERIFY opcode.\n\nThe code that determines if a UTXO is spent or not will need to be\nmodified to include a check to see if any matching coalescing\ntransactions exist in any later block. Maybe there should be a\n\"coalescing pool\" containing all coalescing transactions that make\nsuch a check faster.\n\nThe part I'm not too sure about is the \"wildcard signature\". I'm not\ntoo versed in cryptography to know how exactly to pull this off, but I\nthink it should be simple.\nYou'd just have to some way inject a flag into the signing process\nthat can be verified later.\n\nI originally wanted the \"wildcardness\" of the transaction expressed by\nthe transaction version number.\nBasically any input that exists within a \"version 2 transaction\" is\nviewed as a wildcard input. Then I realized whats to stop someone from\nmodifying the transaction from version 1 to version 2 and stealing\nsomeones funds. The \"wildcardness\" must be expressed in the signature\nso you know that the private key holder intended all inputs to be\nincluded. Hence the need for a new opcode.\n\nbtw, this scheme is definitely in the 10x or higher gain. You could\npotentially spend an unlimited number of UTXOs this way.\n\nOn 11/24/15, Gavin Andresen <gavinandresen at gmail.com> wrote:\n> On Tue, Nov 24, 2015 at 12:34 PM, Chris Priest via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> The technical reason for this is that you have to explicitly list each\n>> UTXO individually when making bitcoin transactions. There is no way to\n>> say \"all the utxos\". This post describes a way to achieve this. I'm\n>> not yet a bitcoin master, so there are parts of this proposal that I\n>> have not yet figured out entirely, but I'm sure other people who know\n>> more could help out.\n>>\n>\n> So every input has:\n>  32-byte hash (transaction being spent)\n>  4-byte output (output being spent)\n>  4-byte sequence number\n> ... plus the scriptSig. Which is as small as about 73 bytes if you're\n> spending a raw OP_CHECKSIG (which you can't do as a bitcoin address, but\n> could via the BIP70 payment protocol), and which is at least two serialized\n> bytes.\n>\n> Best case for any scheme to coalesce scriptSigs would to somehow make\n> all-but-the-first scriptSig zero-length, so the inputs would be 42 bytes\n> instead of 40+73 bytes -- the coalesce transaction would be about one-third\n> the size, so instead of paying (say) $1 in transaction fees you'd pay 37\n> cents.\n>\n> That's in the gray are of the \"worth doing\" threshold-- if it was a 10x\n> improvement (pay 10 cents instead of $1) it'd be in my personal \"definitely\n> worth the trouble of doing\" category.\n>\n> RE: the scheme:  an OP_RINGSIGVERIFY is probably the right way to do this:\n>   https://en.wikipedia.org/wiki/Ring_signature\n>\n> The funding transactions would be:  <public key> OP_RINGSIGVERIFY\n> ... which might could be redeemed with <ring signature> for one input and\n> then... uhh... maybe just <index_to_input_with_signature> for the other\n> inputs that are part of the same ring signature group (OP_0 if the first\n> input has the signature that is good for all the other public keys, which\n> would be the common case).\n>\n> --\n> --\n> Gavin Andresen\n>"
            },
            {
                "author": "Bryan Bishop",
                "date": "2015-11-24T21:51:12",
                "message_text_only": "On Tue, Nov 24, 2015 at 11:34 AM, Chris Priest via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> **OP_CHECKWILDCARDSIGVERIFY**\n\n\nSome (minor) discussion of this idea in -wizards earlier today starting\nnear near \"09:50\" (apologies for having no anchor links):\nhttp://gnusha.org/bitcoin-wizards/2015-11-24.log\n\n- Bryan\nhttp://heybryan.org/\n1 512 203 0507\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151124/1cabe010/attachment.html>"
            },
            {
                "author": "Dave Scotese",
                "date": "2015-11-24T23:28:33",
                "message_text_only": "What is required to spend bitcoin is that input be provided to the UTXO\nscript that causes it to return true.  What Chris is proposing breaks the\nprogrammatic nature of the requirement, replacing it with a requirement\nthat the secret be known.  Granted, the secret is the only requirement in\nmost cases, but there is no built-in assumption that the script always\nrequires only that secret.\n\nThis idea could be applied by having the wildcard signature apply to all\nUTXOs that are of a standard form and paid to a particular address, and be\na signature of some kind of message to that effect.  I imagine the cost of\nre-scanning the UTXO set to find them all would justify a special extra\nmining fee for any transaction that used this opcode.\n\nPlease be blunt about any of my own misunderstandings that this email makes\nclear.\n\nOn Tue, Nov 24, 2015 at 1:51 PM, Bryan Bishop via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Tue, Nov 24, 2015 at 11:34 AM, Chris Priest via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> **OP_CHECKWILDCARDSIGVERIFY**\n>\n>\n> Some (minor) discussion of this idea in -wizards earlier today starting\n> near near \"09:50\" (apologies for having no anchor links):\n> http://gnusha.org/bitcoin-wizards/2015-11-24.log\n>\n> - Bryan\n> http://heybryan.org/\n> 1 512 203 0507\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n\n\n-- \nI like to provide some work at no charge to prove my value. Do you need a\ntechie?\nI own Litmocracy <http://www.litmocracy.com> and Meme Racing\n<http://www.memeracing.net> (in alpha).\nI'm the webmaster for The Voluntaryist <http://www.voluntaryist.com> which\nnow accepts Bitcoin.\nI also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n\"He ought to find it more profitable to play by the rules\" - Satoshi\nNakamoto\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151124/0b0a26f2/attachment.html>"
            },
            {
                "author": "Chris Priest",
                "date": "2015-11-24T23:48:16",
                "message_text_only": "> This idea could be applied by having the wildcard signature apply to all\n> UTXOs that are of a standard form and paid to a particular address, and be\n> a signature of some kind of message to that effect.\n\nI think this is true. Not *all* transactions will be able to match the\nwildcard. For instance if someone sent some crazy smart contract tx to\nyour address, the script associated with that tx will be such that it\nwill not apply to the wildcard. Most \"vanilla\" utxos that I've seen\nhave the formula: OP_DUP OP_HASH160 [a hash corresponding to your\naddress] OP_EQUALVERIFY OP_CHECKSIG\". Just UTXOs in that form could\napply to the wildcard.\n\nOn 11/24/15, Dave Scotese via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> What is required to spend bitcoin is that input be provided to the UTXO\n> script that causes it to return true.  What Chris is proposing breaks the\n> programmatic nature of the requirement, replacing it with a requirement\n> that the secret be known.  Granted, the secret is the only requirement in\n> most cases, but there is no built-in assumption that the script always\n> requires only that secret.\n>\n> This idea could be applied by having the wildcard signature apply to all\n> UTXOs that are of a standard form and paid to a particular address, and be\n> a signature of some kind of message to that effect.  I imagine the cost of\n> re-scanning the UTXO set to find them all would justify a special extra\n> mining fee for any transaction that used this opcode.\n>\n> Please be blunt about any of my own misunderstandings that this email makes\n> clear.\n>\n> On Tue, Nov 24, 2015 at 1:51 PM, Bryan Bishop via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> On Tue, Nov 24, 2015 at 11:34 AM, Chris Priest via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> **OP_CHECKWILDCARDSIGVERIFY**\n>>\n>>\n>> Some (minor) discussion of this idea in -wizards earlier today starting\n>> near near \"09:50\" (apologies for having no anchor links):\n>> http://gnusha.org/bitcoin-wizards/2015-11-24.log\n>>\n>> - Bryan\n>> http://heybryan.org/\n>> 1 512 203 0507\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>\n>\n> --\n> I like to provide some work at no charge to prove my value. Do you need a\n> techie?\n> I own Litmocracy <http://www.litmocracy.com> and Meme Racing\n> <http://www.memeracing.net> (in alpha).\n> I'm the webmaster for The Voluntaryist <http://www.voluntaryist.com> which\n> now accepts Bitcoin.\n> I also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n> \"He ought to find it more profitable to play by the rules\" - Satoshi\n> Nakamoto\n>"
            },
            {
                "author": "Jannes Faber",
                "date": "2015-11-25T00:38:02",
                "message_text_only": "Few issues I can think of:\n\n1. In its basic form this encourages address reuse. Unless the wildcard can\nbe constructed such that it can match a whole branch of an HD  wallet.\nAlthough I guess that would tie all those addresses together making HD moot\nto begin with.\n\n2. Sounds pretty dangerous during reorgs. Maybe such a transaction should\ninclude a block height which indicates the maximum block that any utxo can\nmatch. With the requirement that the specified block height is at least 100\nblocks in the past. Maybe add a minimum block height as well to prevent\nunnecessary scanning (with the requirement that at least one utxo must be\nin that minimum block).\n\n3. Seems like a nice way to the reduce utxo set. But hard to say how\neffective it would really be.\nOn 25 Nov 2015 12:48 a.m., \"Chris Priest via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> > This idea could be applied by having the wildcard signature apply to all\n> > UTXOs that are of a standard form and paid to a particular address, and\n> be\n> > a signature of some kind of message to that effect.\n>\n> I think this is true. Not *all* transactions will be able to match the\n> wildcard. For instance if someone sent some crazy smart contract tx to\n> your address, the script associated with that tx will be such that it\n> will not apply to the wildcard. Most \"vanilla\" utxos that I've seen\n> have the formula: OP_DUP OP_HASH160 [a hash corresponding to your\n> address] OP_EQUALVERIFY OP_CHECKSIG\". Just UTXOs in that form could\n> apply to the wildcard.\n>\n> On 11/24/15, Dave Scotese via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > What is required to spend bitcoin is that input be provided to the UTXO\n> > script that causes it to return true.  What Chris is proposing breaks the\n> > programmatic nature of the requirement, replacing it with a requirement\n> > that the secret be known.  Granted, the secret is the only requirement in\n> > most cases, but there is no built-in assumption that the script always\n> > requires only that secret.\n> >\n> > This idea could be applied by having the wildcard signature apply to all\n> > UTXOs that are of a standard form and paid to a particular address, and\n> be\n> > a signature of some kind of message to that effect.  I imagine the cost\n> of\n> > re-scanning the UTXO set to find them all would justify a special extra\n> > mining fee for any transaction that used this opcode.\n> >\n> > Please be blunt about any of my own misunderstandings that this email\n> makes\n> > clear.\n> >\n> > On Tue, Nov 24, 2015 at 1:51 PM, Bryan Bishop via bitcoin-dev <\n> > bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >\n> >> On Tue, Nov 24, 2015 at 11:34 AM, Chris Priest via bitcoin-dev <\n> >> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>\n> >>> **OP_CHECKWILDCARDSIGVERIFY**\n> >>\n> >>\n> >> Some (minor) discussion of this idea in -wizards earlier today starting\n> >> near near \"09:50\" (apologies for having no anchor links):\n> >> http://gnusha.org/bitcoin-wizards/2015-11-24.log\n> >>\n> >> - Bryan\n> >> http://heybryan.org/\n> >> 1 512 203 0507\n> >>\n> >> _______________________________________________\n> >> bitcoin-dev mailing list\n> >> bitcoin-dev at lists.linuxfoundation.org\n> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >>\n> >>\n> >\n> >\n> > --\n> > I like to provide some work at no charge to prove my value. Do you need a\n> > techie?\n> > I own Litmocracy <http://www.litmocracy.com> and Meme Racing\n> > <http://www.memeracing.net> (in alpha).\n> > I'm the webmaster for The Voluntaryist <http://www.voluntaryist.com>\n> which\n> > now accepts Bitcoin.\n> > I also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n> > \"He ought to find it more profitable to play by the rules\" - Satoshi\n> > Nakamoto\n> >\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151125/0140731a/attachment-0001.html>"
            },
            {
                "author": "Chris Priest",
                "date": "2015-11-25T01:26:51",
                "message_text_only": "1. Technically is it promoting address reuse, but in this case, I\nthink it's OK. The primary purpose of a coalescing transaction is to\nclear out *all* funds associated with one address and send them to\nanother address (belonging to the same owner). If you coalesce the\ninputs to the same address over and over again, you an do that, but\nyou'll run the risk of leaking your private key.\n\n2. I see these transactions being broadcast in the background when the\nuser is not planning on sending or receiving any payments. By the time\nthe wallet user wants to spend funds from the address, the coalescing\ntransaction should be sufficiently deep enough in the blockchain to\navoid re-org tomfoolery. Exchanges and payment processors who take in\npayments around the clock will probably never use these transactions,\nat least not on \"live\" addresses.\n\n3. I never thought of that, but thats a benefit too!\n\nOn 11/24/15, Jannes Faber via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Few issues I can think of:\n>\n> 1. In its basic form this encourages address reuse. Unless the wildcard can\n> be constructed such that it can match a whole branch of an HD  wallet.\n> Although I guess that would tie all those addresses together making HD moot\n> to begin with.\n>\n> 2. Sounds pretty dangerous during reorgs. Maybe such a transaction should\n> include a block height which indicates the maximum block that any utxo can\n> match. With the requirement that the specified block height is at least 100\n> blocks in the past. Maybe add a minimum block height as well to prevent\n> unnecessary scanning (with the requirement that at least one utxo must be\n> in that minimum block).\n>\n> 3. Seems like a nice way to the reduce utxo set. But hard to say how\n> effective it would really be.\n> On 25 Nov 2015 12:48 a.m., \"Chris Priest via bitcoin-dev\" <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> > This idea could be applied by having the wildcard signature apply to\n>> > all\n>> > UTXOs that are of a standard form and paid to a particular address, and\n>> be\n>> > a signature of some kind of message to that effect.\n>>\n>> I think this is true. Not *all* transactions will be able to match the\n>> wildcard. For instance if someone sent some crazy smart contract tx to\n>> your address, the script associated with that tx will be such that it\n>> will not apply to the wildcard. Most \"vanilla\" utxos that I've seen\n>> have the formula: OP_DUP OP_HASH160 [a hash corresponding to your\n>> address] OP_EQUALVERIFY OP_CHECKSIG\". Just UTXOs in that form could\n>> apply to the wildcard.\n>>\n>> On 11/24/15, Dave Scotese via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> > What is required to spend bitcoin is that input be provided to the UTXO\n>> > script that causes it to return true.  What Chris is proposing breaks\n>> > the\n>> > programmatic nature of the requirement, replacing it with a requirement\n>> > that the secret be known.  Granted, the secret is the only requirement\n>> > in\n>> > most cases, but there is no built-in assumption that the script always\n>> > requires only that secret.\n>> >\n>> > This idea could be applied by having the wildcard signature apply to\n>> > all\n>> > UTXOs that are of a standard form and paid to a particular address, and\n>> be\n>> > a signature of some kind of message to that effect.  I imagine the cost\n>> of\n>> > re-scanning the UTXO set to find them all would justify a special extra\n>> > mining fee for any transaction that used this opcode.\n>> >\n>> > Please be blunt about any of my own misunderstandings that this email\n>> makes\n>> > clear.\n>> >\n>> > On Tue, Nov 24, 2015 at 1:51 PM, Bryan Bishop via bitcoin-dev <\n>> > bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> >\n>> >> On Tue, Nov 24, 2015 at 11:34 AM, Chris Priest via bitcoin-dev <\n>> >> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> >>\n>> >>> **OP_CHECKWILDCARDSIGVERIFY**\n>> >>\n>> >>\n>> >> Some (minor) discussion of this idea in -wizards earlier today\n>> >> starting\n>> >> near near \"09:50\" (apologies for having no anchor links):\n>> >> http://gnusha.org/bitcoin-wizards/2015-11-24.log\n>> >>\n>> >> - Bryan\n>> >> http://heybryan.org/\n>> >> 1 512 203 0507\n>> >>\n>> >> _______________________________________________\n>> >> bitcoin-dev mailing list\n>> >> bitcoin-dev at lists.linuxfoundation.org\n>> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> >>\n>> >>\n>> >\n>> >\n>> > --\n>> > I like to provide some work at no charge to prove my value. Do you need\n>> > a\n>> > techie?\n>> > I own Litmocracy <http://www.litmocracy.com> and Meme Racing\n>> > <http://www.memeracing.net> (in alpha).\n>> > I'm the webmaster for The Voluntaryist <http://www.voluntaryist.com>\n>> which\n>> > now accepts Bitcoin.\n>> > I also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n>> > \"He ought to find it more profitable to play by the rules\" - Satoshi\n>> > Nakamoto\n>> >\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>"
            },
            {
                "author": "Erik",
                "date": "2015-11-25T14:16:14",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA1\n\n\nNice idea. I see it as an important feature because of several reasons:\n\nConsidering the website example, where most websites uses static\ncontent, a bitcoin address could accumulate a dozen of transactions\nbefore the webmaster changes the address to a new one.\n\nAlso consider a QR-code address printed on paper. That address is also\nprone to multiple payments, which could be several small ones.\n\nYou ask someone to pay an amount of BTC. That person would be someone\nthat want you to actually don't get any money at all, so instead of\nsending one payment, the person sends a lot of small TXes. It costs a\nlot more to achieve this, but that doesn't bother the person sending the\ntransactions. What you see is the transactions to the address you've\nagreed sum up to the amount you asked for. When you later try to spend\nit, you can't because of that the size of all UXTOs is too high to even\novercome the tx fee.\n\nIf you use a wildcard transaction to bake them together into one UXTO,\nyou will not need to pay more than just one tx fee to solve the problem\nyou've got. Also the network will benefit from this because the\nalternative is to not spend those UXTOs at all because it costs more\nthan it earns, leaving lots of UXTOs in the databases.\n\nSome problems to consider is:\n* Which addresses should be involved in a wildcard TX.\n* How to not make it repeatable or delayed so that UXTOs not intended to\nbe in that TX wouldn't be included.\n* How to make it impossible to sign an wildcard TX with a future date.\n* How to limit outputs so they not are in risk being double-spent.\n* How to guarantee that the output is actually calculated from all the\ninputs involved and not less, making insane TX fees available.\n\nI could see possible solutions to this problems:\n* Using the highest block height number of transactions to include or\nmaybe better, the UXTO of one transaction destined to that address\ninvolved in that block - that implies collecting all UXTOs in that block.\n* Using a signature that includes the date. To let it be present more\ntimes in the blockchain requires another timestamp that is newer than a\nwildcard TX already existing in the blockchain. Also make the\ntransaction invalid to put in a block if the timestamp is behind a\ncertain time or in the future.\n* Using the coinbase UXTO or the block hash from the latest block as\nproof that the transaction isn't created earlier than that. Also makes\nthe wildcard TX invalid if that block isn't part of the blockchain\nanymore. This also have a secondary effect of certifying the blockchain\nitself making it more difficult to fork it from far behind because it\nwill effectively remove all transactions depending on a UXTO including\nthis type of certification.\n* Either using a priority like way to determine what are being left to\nwildcard in a block - all transactions spending UXTOs of that address is\nremoved before the wildcard TX if they occurs in the same block. Either\nit is possible to set a rule that if a wildcard TX exists in one block,\nit is invalid to include other UXTOs that is to be be included in the\nwildcard from the same address in the same block. (Classic\ndouble-spending rule)\n* Using a special form of output specifying only one destination\naddress/script and the amount of fees to pay. If the amount of fees\ncould be payed, then the rest will be sent to the destination address.\nThis covers intentional delaying and also discourage forking the\nblockchain by miners to making the signature UXTO appear later than more\nrecent transaction in a new fork to collect the later txes as fee.\n\nThis transaction type would in fact look like a time-limited offer to\nthe network to reduce the UXTO set of an address. I guess some miners\nwill then use a logic that prefers this types of TXes even if they are\nlow-fee because, if they removes lots of UXTOs, they benefits the network.\n\nSincerely,\nErik.\n\nDen 2015-11-25 kl. 02:26, skrev Chris Priest via bitcoin-dev:\n> 1. Technically is it promoting address reuse, but in this case, I\n> think it's OK. The primary purpose of a coalescing transaction is to\n> clear out *all* funds associated with one address and send them to\n> another address (belonging to the same owner). If you coalesce the\n> inputs to the same address over and over again, you an do that, but\n> you'll run the risk of leaking your private key.\n>\n> 2. I see these transactions being broadcast in the background when the\n> user is not planning on sending or receiving any payments. By the time\n> the wallet user wants to spend funds from the address, the coalescing\n> transaction should be sufficiently deep enough in the blockchain to\n> avoid re-org tomfoolery. Exchanges and payment processors who take in\n> payments around the clock will probably never use these transactions,\n> at least not on \"live\" addresses.\n>\n> 3. I never thought of that, but thats a benefit too!\n>\n> On 11/24/15, Jannes Faber via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> Few issues I can think of:\n>>\n>> 1. In its basic form this encourages address reuse. Unless the\nwildcard can\n>> be constructed such that it can match a whole branch of an HD  wallet.\n>> Although I guess that would tie all those addresses together making\nHD moot\n>> to begin with.\n>>\n>> 2. Sounds pretty dangerous during reorgs. Maybe such a transaction should\n>> include a block height which indicates the maximum block that any\nutxo can\n>> match. With the requirement that the specified block height is at\nleast 100\n>> blocks in the past. Maybe add a minimum block height as well to prevent\n>> unnecessary scanning (with the requirement that at least one utxo must be\n>> in that minimum block).\n>>\n>> 3. Seems like a nice way to the reduce utxo set. But hard to say how\n>> effective it would really be.\n>> On 25 Nov 2015 12:48 a.m., \"Chris Priest via bitcoin-dev\" <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>>> This idea could be applied by having the wildcard signature apply to\n>>>> all\n>>>> UTXOs that are of a standard form and paid to a particular address, and\n>>> be\n>>>> a signature of some kind of message to that effect.\n>>>\n>>> I think this is true. Not *all* transactions will be able to match the\n>>> wildcard. For instance if someone sent some crazy smart contract tx to\n>>> your address, the script associated with that tx will be such that it\n>>> will not apply to the wildcard. Most \"vanilla\" utxos that I've seen\n>>> have the formula: OP_DUP OP_HASH160 [a hash corresponding to your\n>>> address] OP_EQUALVERIFY OP_CHECKSIG\". Just UTXOs in that form could\n>>> apply to the wildcard.\n>>>\n>>> On 11/24/15, Dave Scotese via bitcoin-dev\n>>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>> What is required to spend bitcoin is that input be provided to the UTXO\n>>>> script that causes it to return true.  What Chris is proposing breaks\n>>>> the\n>>>> programmatic nature of the requirement, replacing it with a requirement\n>>>> that the secret be known.  Granted, the secret is the only requirement\n>>>> in\n>>>> most cases, but there is no built-in assumption that the script always\n>>>> requires only that secret.\n>>>>\n>>>> This idea could be applied by having the wildcard signature apply to\n>>>> all\n>>>> UTXOs that are of a standard form and paid to a particular address, and\n>>> be\n>>>> a signature of some kind of message to that effect.  I imagine the cost\n>>> of\n>>>> re-scanning the UTXO set to find them all would justify a special extra\n>>>> mining fee for any transaction that used this opcode.\n>>>>\n>>>> Please be blunt about any of my own misunderstandings that this email\n>>> makes\n>>>> clear.\n>>>>\n>>>> On Tue, Nov 24, 2015 at 1:51 PM, Bryan Bishop via bitcoin-dev <\n>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>\n>>>>> On Tue, Nov 24, 2015 at 11:34 AM, Chris Priest via bitcoin-dev <\n>>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>>\n>>>>>> **OP_CHECKWILDCARDSIGVERIFY**\n>>>>>\n>>>>>\n>>>>> Some (minor) discussion of this idea in -wizards earlier today\n>>>>> starting\n>>>>> near near \"09:50\" (apologies for having no anchor links):\n>>>>> http://gnusha.org/bitcoin-wizards/2015-11-24.log\n>>>>>\n>>>>> - Bryan\n>>>>> http://heybryan.org/\n>>>>> 1 512 203 0507\n>>>>>\n>>>>> _______________________________________________\n>>>>> bitcoin-dev mailing list\n>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>\n>>>>>\n>>>>\n>>>>\n>>>> --\n>>>> I like to provide some work at no charge to prove my value. Do you need\n>>>> a\n>>>> techie?\n>>>> I own Litmocracy <http://www.litmocracy.com> and Meme Racing\n>>>> <http://www.memeracing.net> (in alpha).\n>>>> I'm the webmaster for The Voluntaryist <http://www.voluntaryist.com>\n>>> which\n>>>> now accepts Bitcoin.\n>>>> I also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n>>>> \"He ought to find it more profitable to play by the rules\" - Satoshi\n>>>> Nakamoto\n>>>>\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v2.0.22 (GNU/Linux)\n\niQIcBAEBAgAGBQJWVcKuAAoJEJ51csApon2ofiYP/15DXthFvNg9pBPOaaboGOh1\nDhN7R3SXnt4PTLygQGO3AkTRcDinQrZ0Q4GDLIgrOkaKJ4yr6FtnoEYGORQSfFkx\n946eWtqkR4+IJi7gYIIn1yOfFjWKUp9l4OOWBA8Rxsn0tZUAQPXzf2f+dxAaj0Gd\nfLrftYvK1XJ8BolhwNfonJ193RJGFynQfWqZ+XeQQMS5LW23RpQLyI26f495MPHG\nWug7M/Aq50JrJDe1OyhjnnjYxNV6Gdbg9o3YIdj2gaOsBKHzsPK+LjcLCdRqD/OI\nTBwmwiI4vrOl3HzvtucHxQqnaP43wubydVhPfmjG97tDaj2cVLjadc17e77PzCVI\n8N21oVIWDzyW6y14REoo1Zs4A9ALpHjXAGWdls71eP1NIFcfdFAJWhk2/giisw8o\nZsQTgq2mUHS+n4q3NjFEwGxS011yADE3Uf3ryjuTjp3HVQf3lZxn4E4Z7z/4gkXm\n/h/3Ln7PkjEmOqp9htgHcYW7q5goeJzV0xNDBoY9wvOlJQcAh6nTiS4SJEiFJvXU\nxVZIGZsisrdW/1CfcszOi7KFGaaV1VlAXQnuJHj1I3dJ2r68yi5TQk6voMNFprEz\n2R4zuZKjIoH79rOjDV8l6XBIU1Kh92GEzCFlTicfvnAoa853fGZt+V/77ralftJW\nE6sERK8uG8S3KdBSVQ7K\n=1xdi\n-----END PGP SIGNATURE-----"
            },
            {
                "author": "Trevin Hofmann",
                "date": "2015-11-25T15:41:01",
                "message_text_only": "> Considering the website example, where most websites uses static\ncontent, a bitcoin address could accumulate a dozen of transactions\nbefore the webmaster changes the address to a new one.\n\nWould this use case be a better match for something such as stealth\naddresses or hierarchical deterministic addresses?\n\nTrevin Hofmann\nOn Nov 25, 2015 8:16 AM, \"Erik via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> -----BEGIN PGP SIGNED MESSAGE-----\n> Hash: SHA1\n>\n>\n> Nice idea. I see it as an important feature because of several reasons:\n>\n> Considering the website example, where most websites uses static\n> content, a bitcoin address could accumulate a dozen of transactions\n> before the webmaster changes the address to a new one.\n>\n> Also consider a QR-code address printed on paper. That address is also\n> prone to multiple payments, which could be several small ones.\n>\n> You ask someone to pay an amount of BTC. That person would be someone\n> that want you to actually don't get any money at all, so instead of\n> sending one payment, the person sends a lot of small TXes. It costs a\n> lot more to achieve this, but that doesn't bother the person sending the\n> transactions. What you see is the transactions to the address you've\n> agreed sum up to the amount you asked for. When you later try to spend\n> it, you can't because of that the size of all UXTOs is too high to even\n> overcome the tx fee.\n>\n> If you use a wildcard transaction to bake them together into one UXTO,\n> you will not need to pay more than just one tx fee to solve the problem\n> you've got. Also the network will benefit from this because the\n> alternative is to not spend those UXTOs at all because it costs more\n> than it earns, leaving lots of UXTOs in the databases.\n>\n> Some problems to consider is:\n> * Which addresses should be involved in a wildcard TX.\n> * How to not make it repeatable or delayed so that UXTOs not intended to\n> be in that TX wouldn't be included.\n> * How to make it impossible to sign an wildcard TX with a future date.\n> * How to limit outputs so they not are in risk being double-spent.\n> * How to guarantee that the output is actually calculated from all the\n> inputs involved and not less, making insane TX fees available.\n>\n> I could see possible solutions to this problems:\n> * Using the highest block height number of transactions to include or\n> maybe better, the UXTO of one transaction destined to that address\n> involved in that block - that implies collecting all UXTOs in that block.\n> * Using a signature that includes the date. To let it be present more\n> times in the blockchain requires another timestamp that is newer than a\n> wildcard TX already existing in the blockchain. Also make the\n> transaction invalid to put in a block if the timestamp is behind a\n> certain time or in the future.\n> * Using the coinbase UXTO or the block hash from the latest block as\n> proof that the transaction isn't created earlier than that. Also makes\n> the wildcard TX invalid if that block isn't part of the blockchain\n> anymore. This also have a secondary effect of certifying the blockchain\n> itself making it more difficult to fork it from far behind because it\n> will effectively remove all transactions depending on a UXTO including\n> this type of certification.\n> * Either using a priority like way to determine what are being left to\n> wildcard in a block - all transactions spending UXTOs of that address is\n> removed before the wildcard TX if they occurs in the same block. Either\n> it is possible to set a rule that if a wildcard TX exists in one block,\n> it is invalid to include other UXTOs that is to be be included in the\n> wildcard from the same address in the same block. (Classic\n> double-spending rule)\n> * Using a special form of output specifying only one destination\n> address/script and the amount of fees to pay. If the amount of fees\n> could be payed, then the rest will be sent to the destination address.\n> This covers intentional delaying and also discourage forking the\n> blockchain by miners to making the signature UXTO appear later than more\n> recent transaction in a new fork to collect the later txes as fee.\n>\n> This transaction type would in fact look like a time-limited offer to\n> the network to reduce the UXTO set of an address. I guess some miners\n> will then use a logic that prefers this types of TXes even if they are\n> low-fee because, if they removes lots of UXTOs, they benefits the network.\n>\n> Sincerely,\n> Erik.\n>\n> Den 2015-11-25 kl. 02:26, skrev Chris Priest via bitcoin-dev:\n> > 1. Technically is it promoting address reuse, but in this case, I\n> > think it's OK. The primary purpose of a coalescing transaction is to\n> > clear out *all* funds associated with one address and send them to\n> > another address (belonging to the same owner). If you coalesce the\n> > inputs to the same address over and over again, you an do that, but\n> > you'll run the risk of leaking your private key.\n> >\n> > 2. I see these transactions being broadcast in the background when the\n> > user is not planning on sending or receiving any payments. By the time\n> > the wallet user wants to spend funds from the address, the coalescing\n> > transaction should be sufficiently deep enough in the blockchain to\n> > avoid re-org tomfoolery. Exchanges and payment processors who take in\n> > payments around the clock will probably never use these transactions,\n> > at least not on \"live\" addresses.\n> >\n> > 3. I never thought of that, but thats a benefit too!\n> >\n> > On 11/24/15, Jannes Faber via bitcoin-dev\n> > <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >> Few issues I can think of:\n> >>\n> >> 1. In its basic form this encourages address reuse. Unless the\n> wildcard can\n> >> be constructed such that it can match a whole branch of an HD  wallet.\n> >> Although I guess that would tie all those addresses together making\n> HD moot\n> >> to begin with.\n> >>\n> >> 2. Sounds pretty dangerous during reorgs. Maybe such a transaction\n> should\n> >> include a block height which indicates the maximum block that any\n> utxo can\n> >> match. With the requirement that the specified block height is at\n> least 100\n> >> blocks in the past. Maybe add a minimum block height as well to prevent\n> >> unnecessary scanning (with the requirement that at least one utxo must\n> be\n> >> in that minimum block).\n> >>\n> >> 3. Seems like a nice way to the reduce utxo set. But hard to say how\n> >> effective it would really be.\n> >> On 25 Nov 2015 12:48 a.m., \"Chris Priest via bitcoin-dev\" <\n> >> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>\n> >>>> This idea could be applied by having the wildcard signature apply to\n> >>>> all\n> >>>> UTXOs that are of a standard form and paid to a particular address,\n> and\n> >>> be\n> >>>> a signature of some kind of message to that effect.\n> >>>\n> >>> I think this is true. Not *all* transactions will be able to match the\n> >>> wildcard. For instance if someone sent some crazy smart contract tx to\n> >>> your address, the script associated with that tx will be such that it\n> >>> will not apply to the wildcard. Most \"vanilla\" utxos that I've seen\n> >>> have the formula: OP_DUP OP_HASH160 [a hash corresponding to your\n> >>> address] OP_EQUALVERIFY OP_CHECKSIG\". Just UTXOs in that form could\n> >>> apply to the wildcard.\n> >>>\n> >>> On 11/24/15, Dave Scotese via bitcoin-dev\n> >>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>>> What is required to spend bitcoin is that input be provided to the\n> UTXO\n> >>>> script that causes it to return true.  What Chris is proposing breaks\n> >>>> the\n> >>>> programmatic nature of the requirement, replacing it with a\n> requirement\n> >>>> that the secret be known.  Granted, the secret is the only requirement\n> >>>> in\n> >>>> most cases, but there is no built-in assumption that the script always\n> >>>> requires only that secret.\n> >>>>\n> >>>> This idea could be applied by having the wildcard signature apply to\n> >>>> all\n> >>>> UTXOs that are of a standard form and paid to a particular address,\n> and\n> >>> be\n> >>>> a signature of some kind of message to that effect.  I imagine the\n> cost\n> >>> of\n> >>>> re-scanning the UTXO set to find them all would justify a special\n> extra\n> >>>> mining fee for any transaction that used this opcode.\n> >>>>\n> >>>> Please be blunt about any of my own misunderstandings that this email\n> >>> makes\n> >>>> clear.\n> >>>>\n> >>>> On Tue, Nov 24, 2015 at 1:51 PM, Bryan Bishop via bitcoin-dev <\n> >>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>>>\n> >>>>> On Tue, Nov 24, 2015 at 11:34 AM, Chris Priest via bitcoin-dev <\n> >>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>>>>\n> >>>>>> **OP_CHECKWILDCARDSIGVERIFY**\n> >>>>>\n> >>>>>\n> >>>>> Some (minor) discussion of this idea in -wizards earlier today\n> >>>>> starting\n> >>>>> near near \"09:50\" (apologies for having no anchor links):\n> >>>>> http://gnusha.org/bitcoin-wizards/2015-11-24.log\n> >>>>>\n> >>>>> - Bryan\n> >>>>> http://heybryan.org/\n> >>>>> 1 512 203 0507\n> >>>>>\n> >>>>> _______________________________________________\n> >>>>> bitcoin-dev mailing list\n> >>>>> bitcoin-dev at lists.linuxfoundation.org\n> >>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >>>>>\n> >>>>>\n> >>>>\n> >>>>\n> >>>> --\n> >>>> I like to provide some work at no charge to prove my value. Do you\n> need\n> >>>> a\n> >>>> techie?\n> >>>> I own Litmocracy <http://www.litmocracy.com> and Meme Racing\n> >>>> <http://www.memeracing.net> (in alpha).\n> >>>> I'm the webmaster for The Voluntaryist <http://www.voluntaryist.com>\n> >>> which\n> >>>> now accepts Bitcoin.\n> >>>> I also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n> >>>> \"He ought to find it more profitable to play by the rules\" - Satoshi\n> >>>> Nakamoto\n> >>>>\n> >>> _______________________________________________\n> >>> bitcoin-dev mailing list\n> >>> bitcoin-dev at lists.linuxfoundation.org\n> >>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >>>\n> >>\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n> -----BEGIN PGP SIGNATURE-----\n> Version: GnuPG v2.0.22 (GNU/Linux)\n>\n> iQIcBAEBAgAGBQJWVcKuAAoJEJ51csApon2ofiYP/15DXthFvNg9pBPOaaboGOh1\n> DhN7R3SXnt4PTLygQGO3AkTRcDinQrZ0Q4GDLIgrOkaKJ4yr6FtnoEYGORQSfFkx\n> 946eWtqkR4+IJi7gYIIn1yOfFjWKUp9l4OOWBA8Rxsn0tZUAQPXzf2f+dxAaj0Gd\n> fLrftYvK1XJ8BolhwNfonJ193RJGFynQfWqZ+XeQQMS5LW23RpQLyI26f495MPHG\n> Wug7M/Aq50JrJDe1OyhjnnjYxNV6Gdbg9o3YIdj2gaOsBKHzsPK+LjcLCdRqD/OI\n> TBwmwiI4vrOl3HzvtucHxQqnaP43wubydVhPfmjG97tDaj2cVLjadc17e77PzCVI\n> 8N21oVIWDzyW6y14REoo1Zs4A9ALpHjXAGWdls71eP1NIFcfdFAJWhk2/giisw8o\n> ZsQTgq2mUHS+n4q3NjFEwGxS011yADE3Uf3ryjuTjp3HVQf3lZxn4E4Z7z/4gkXm\n> /h/3Ln7PkjEmOqp9htgHcYW7q5goeJzV0xNDBoY9wvOlJQcAh6nTiS4SJEiFJvXU\n> xVZIGZsisrdW/1CfcszOi7KFGaaV1VlAXQnuJHj1I3dJ2r68yi5TQk6voMNFprEz\n> 2R4zuZKjIoH79rOjDV8l6XBIU1Kh92GEzCFlTicfvnAoa853fGZt+V/77ralftJW\n> E6sERK8uG8S3KdBSVQ7K\n> =1xdi\n> -----END PGP SIGNATURE-----\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151125/5e131aec/attachment-0001.html>"
            },
            {
                "author": "Dave Scotese",
                "date": "2015-11-25T17:03:32",
                "message_text_only": "The message could specify:\n{ stib: 0x01,\n  TxnCount: (# of entries in the Indexes array)\n  Indexes: [{BLK: Block#,Txns:[TxIndex,TxIndex,...]},{BLK:\nBlock#,Txns:[...]}],\n  NewUTXO: (The script that will spend these coins)\n}\n*stib *is a Script Template Index Bitfield: Must (currently) be the byte\n0x01, to indicate the \"vanilla\" script Chris identified.  If other scripts\nappear to fit the bill in the future, they can be assigned to other bits.\n*Indexes *is a list of pairs that identify a block by its height and a list\nof indexes into the block.  This puts the onus on the transactor to\nidentify all the inputs instead of requiring the miner to scan for them.\n\nIf block heights and transaction indexes are 32-bit integers, this reduces\nthe per-input size cost by at least 100 bytes, if I did my math right.\n\n\nOn Wed, Nov 25, 2015 at 6:16 AM, Erik via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>\n> -----BEGIN PGP SIGNED MESSAGE-----\n> Hash: SHA1\n>\n>\n> Nice idea. I see it as an important feature because of several reasons:\n>\n> Considering the website example, where most websites uses static\n> content, a bitcoin address could accumulate a dozen of transactions\n> before the webmaster changes the address to a new one.\n>\n> Also consider a QR-code address printed on paper. That address is also\n> prone to multiple payments, which could be several small ones.\n>\n> You ask someone to pay an amount of BTC. That person would be someone\n> that want you to actually don't get any money at all, so instead of\n> sending one payment, the person sends a lot of small TXes. It costs a\n> lot more to achieve this, but that doesn't bother the person sending the\n> transactions. What you see is the transactions to the address you've\n> agreed sum up to the amount you asked for. When you later try to spend\n> it, you can't because of that the size of all UXTOs is too high to even\n> overcome the tx fee.\n>\n> If you use a wildcard transaction to bake them together into one UXTO,\n> you will not need to pay more than just one tx fee to solve the problem\n> you've got. Also the network will benefit from this because the\n> alternative is to not spend those UXTOs at all because it costs more\n> than it earns, leaving lots of UXTOs in the databases.\n>\n> Some problems to consider is:\n> * Which addresses should be involved in a wildcard TX.\n> * How to not make it repeatable or delayed so that UXTOs not intended to\n> be in that TX wouldn't be included.\n> * How to make it impossible to sign an wildcard TX with a future date.\n> * How to limit outputs so they not are in risk being double-spent.\n> * How to guarantee that the output is actually calculated from all the\n> inputs involved and not less, making insane TX fees available.\n>\n> I could see possible solutions to this problems:\n> * Using the highest block height number of transactions to include or\n> maybe better, the UXTO of one transaction destined to that address\n> involved in that block - that implies collecting all UXTOs in that block.\n> * Using a signature that includes the date. To let it be present more\n> times in the blockchain requires another timestamp that is newer than a\n> wildcard TX already existing in the blockchain. Also make the\n> transaction invalid to put in a block if the timestamp is behind a\n> certain time or in the future.\n> * Using the coinbase UXTO or the block hash from the latest block as\n> proof that the transaction isn't created earlier than that. Also makes\n> the wildcard TX invalid if that block isn't part of the blockchain\n> anymore. This also have a secondary effect of certifying the blockchain\n> itself making it more difficult to fork it from far behind because it\n> will effectively remove all transactions depending on a UXTO including\n> this type of certification.\n> * Either using a priority like way to determine what are being left to\n> wildcard in a block - all transactions spending UXTOs of that address is\n> removed before the wildcard TX if they occurs in the same block. Either\n> it is possible to set a rule that if a wildcard TX exists in one block,\n> it is invalid to include other UXTOs that is to be be included in the\n> wildcard from the same address in the same block. (Classic\n> double-spending rule)\n> * Using a special form of output specifying only one destination\n> address/script and the amount of fees to pay. If the amount of fees\n> could be payed, then the rest will be sent to the destination address.\n> This covers intentional delaying and also discourage forking the\n> blockchain by miners to making the signature UXTO appear later than more\n> recent transaction in a new fork to collect the later txes as fee.\n>\n> This transaction type would in fact look like a time-limited offer to\n> the network to reduce the UXTO set of an address. I guess some miners\n> will then use a logic that prefers this types of TXes even if they are\n> low-fee because, if they removes lots of UXTOs, they benefits the network.\n>\n> Sincerely,\n> Erik.\n>\n> Den 2015-11-25 kl. 02:26, skrev Chris Priest via bitcoin-dev:\n> > 1. Technically is it promoting address reuse, but in this case, I\n> > think it's OK. The primary purpose of a coalescing transaction is to\n> > clear out *all* funds associated with one address and send them to\n> > another address (belonging to the same owner). If you coalesce the\n> > inputs to the same address over and over again, you an do that, but\n> > you'll run the risk of leaking your private key.\n> >\n> > 2. I see these transactions being broadcast in the background when the\n> > user is not planning on sending or receiving any payments. By the time\n> > the wallet user wants to spend funds from the address, the coalescing\n> > transaction should be sufficiently deep enough in the blockchain to\n> > avoid re-org tomfoolery. Exchanges and payment processors who take in\n> > payments around the clock will probably never use these transactions,\n> > at least not on \"live\" addresses.\n> >\n> > 3. I never thought of that, but thats a benefit too!\n> >\n> > On 11/24/15, Jannes Faber via bitcoin-dev\n> > <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >> Few issues I can think of:\n> >>\n> >> 1. In its basic form this encourages address reuse. Unless the\n> wildcard can\n> >> be constructed such that it can match a whole branch of an HD  wallet.\n> >> Although I guess that would tie all those addresses together making\n> HD moot\n> >> to begin with.\n> >>\n> >> 2. Sounds pretty dangerous during reorgs. Maybe such a transaction\n> should\n> >> include a block height which indicates the maximum block that any\n> utxo can\n> >> match. With the requirement that the specified block height is at\n> least 100\n> >> blocks in the past. Maybe add a minimum block height as well to prevent\n> >> unnecessary scanning (with the requirement that at least one utxo must\n> be\n> >> in that minimum block).\n> >>\n> >> 3. Seems like a nice way to the reduce utxo set. But hard to say how\n> >> effective it would really be.\n> >> On 25 Nov 2015 12:48 a.m., \"Chris Priest via bitcoin-dev\" <\n> >> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>\n> >>>> This idea could be applied by having the wildcard signature apply to\n> >>>> all\n> >>>> UTXOs that are of a standard form and paid to a particular address,\n> and\n> >>> be\n> >>>> a signature of some kind of message to that effect.\n> >>>\n> >>> I think this is true. Not *all* transactions will be able to match the\n> >>> wildcard. For instance if someone sent some crazy smart contract tx to\n> >>> your address, the script associated with that tx will be such that it\n> >>> will not apply to the wildcard. Most \"vanilla\" utxos that I've seen\n> >>> have the formula: OP_DUP OP_HASH160 [a hash corresponding to your\n> >>> address] OP_EQUALVERIFY OP_CHECKSIG\". Just UTXOs in that form could\n> >>> apply to the wildcard.\n> >>>\n> >>> On 11/24/15, Dave Scotese via bitcoin-dev\n> >>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>>> What is required to spend bitcoin is that input be provided to the\n> UTXO\n> >>>> script that causes it to return true.  What Chris is proposing breaks\n> >>>> the\n> >>>> programmatic nature of the requirement, replacing it with a\n> requirement\n> >>>> that the secret be known.  Granted, the secret is the only requirement\n> >>>> in\n> >>>> most cases, but there is no built-in assumption that the script always\n> >>>> requires only that secret.\n> >>>>\n> >>>> This idea could be applied by having the wildcard signature apply to\n> >>>> all\n> >>>> UTXOs that are of a standard form and paid to a particular address,\n> and\n> >>> be\n> >>>> a signature of some kind of message to that effect.  I imagine the\n> cost\n> >>> of\n> >>>> re-scanning the UTXO set to find them all would justify a special\n> extra\n> >>>> mining fee for any transaction that used this opcode.\n> >>>>\n> >>>> Please be blunt about any of my own misunderstandings that this email\n> >>> makes\n> >>>> clear.\n> >>>>\n> >>>> On Tue, Nov 24, 2015 at 1:51 PM, Bryan Bishop via bitcoin-dev <\n> >>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>>>\n> >>>>> On Tue, Nov 24, 2015 at 11:34 AM, Chris Priest via bitcoin-dev <\n> >>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>>>>\n> >>>>>> **OP_CHECKWILDCARDSIGVERIFY**\n> >>>>>\n> >>>>>\n> >>>>> Some (minor) discussion of this idea in -wizards earlier today\n> >>>>> starting\n> >>>>> near near \"09:50\" (apologies for having no anchor links):\n> >>>>> http://gnusha.org/bitcoin-wizards/2015-11-24.log\n> >>>>>\n> >>>>> - Bryan\n> >>>>> http://heybryan.org/\n> >>>>> 1 512 203 0507\n> >>>>>\n> >>>>> _______________________________________________\n> >>>>> bitcoin-dev mailing list\n> >>>>> bitcoin-dev at lists.linuxfoundation.org\n> >>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >>>>>\n> >>>>>\n> >>>>\n> >>>>\n> >>>> --\n> >>>> I like to provide some work at no charge to prove my value. Do you\n> need\n> >>>> a\n> >>>> techie?\n> >>>> I own Litmocracy <http://www.litmocracy.com> and Meme Racing\n> >>>> <http://www.memeracing.net> (in alpha).\n> >>>> I'm the webmaster for The Voluntaryist <http://www.voluntaryist.com>\n> >>> which\n> >>>> now accepts Bitcoin.\n> >>>> I also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n> >>>> \"He ought to find it more profitable to play by the rules\" - Satoshi\n> >>>> Nakamoto\n> >>>>\n> >>> _______________________________________________\n> >>> bitcoin-dev mailing list\n> >>> bitcoin-dev at lists.linuxfoundation.org\n> >>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >>>\n> >>\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n> -----BEGIN PGP SIGNATURE-----\n> Version: GnuPG v2.0.22 (GNU/Linux)\n>\n> iQIcBAEBAgAGBQJWVcKuAAoJEJ51csApon2ofiYP/15DXthFvNg9pBPOaaboGOh1\n> DhN7R3SXnt4PTLygQGO3AkTRcDinQrZ0Q4GDLIgrOkaKJ4yr6FtnoEYGORQSfFkx\n> 946eWtqkR4+IJi7gYIIn1yOfFjWKUp9l4OOWBA8Rxsn0tZUAQPXzf2f+dxAaj0Gd\n> fLrftYvK1XJ8BolhwNfonJ193RJGFynQfWqZ+XeQQMS5LW23RpQLyI26f495MPHG\n> Wug7M/Aq50JrJDe1OyhjnnjYxNV6Gdbg9o3YIdj2gaOsBKHzsPK+LjcLCdRqD/OI\n> TBwmwiI4vrOl3HzvtucHxQqnaP43wubydVhPfmjG97tDaj2cVLjadc17e77PzCVI\n> 8N21oVIWDzyW6y14REoo1Zs4A9ALpHjXAGWdls71eP1NIFcfdFAJWhk2/giisw8o\n> ZsQTgq2mUHS+n4q3NjFEwGxS011yADE3Uf3ryjuTjp3HVQf3lZxn4E4Z7z/4gkXm\n> /h/3Ln7PkjEmOqp9htgHcYW7q5goeJzV0xNDBoY9wvOlJQcAh6nTiS4SJEiFJvXU\n> xVZIGZsisrdW/1CfcszOi7KFGaaV1VlAXQnuJHj1I3dJ2r68yi5TQk6voMNFprEz\n> 2R4zuZKjIoH79rOjDV8l6XBIU1Kh92GEzCFlTicfvnAoa853fGZt+V/77ralftJW\n> E6sERK8uG8S3KdBSVQ7K\n> =1xdi\n> -----END PGP SIGNATURE-----\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n\n-- \nI like to provide some work at no charge to prove my value. Do you need a\ntechie?\nI own Litmocracy <http://www.litmocracy.com> and Meme Racing\n<http://www.memeracing.net> (in alpha).\nI'm the webmaster for The Voluntaryist <http://www.voluntaryist.com> which\nnow accepts Bitcoin.\nI also code for The Dollar Vigilante <http://dollarvigilante.com/>.\n\"He ought to find it more profitable to play by the rules\" - Satoshi\nNakamoto\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151125/b0a18f46/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "OP_CHECKWILDCARDSIGVERIFY or \"Wildcard Inputs\" or \"Coalescing Transactions\"",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Bryan Bishop",
                "Chris Priest",
                "Trevin Hofmann",
                "Dave Scotese",
                "Erik",
                "Jannes Faber",
                "Gavin Andresen"
            ],
            "messages_count": 11,
            "total_messages_chars_count": 55947
        }
    },
    {
        "title": "[bitcoin-dev] Why sharding the blockchain is difficult",
        "thread_messages": [
            {
                "author": "Peter Todd",
                "date": "2015-11-25T21:37:47",
                "message_text_only": "https://www.reddit.com/r/Bitcoin/comments/3u1m36/why_arent_we_as_a_community_talking_about/cxbamhn?context=3\n\nThe following was originally posted to reddit; I was asked to repost it here:\n\nIn a system where everyone mostly trusts each other, sharding works great! You\njust split up the blockchain the same way you'd shard a database, assigning\nminers/validators a subset of the txid space. Transaction validation would\nassume that if you don't have the history for an input yourself, you assume\nthat history is valid. In a banking-like environment where there's a way to\nconduct audits and punish those who lie, this could certainly be made to work.\n(I myself have worked on and off on a scheme to do exactly that for a few\ndifferent clients: [Proofchains](https://github.com/proofchains))\n\nBut in a decentralized environment sharding is far, far, harder to\naccomplish... There's an old idea we've been calling \"fraud proofs\", where you\ndesign a system where for every way validation can fail, you can create a short\nproof that part of the blockchain was invalid. Upon receiving that proof your\nnode would reject the invalid part of the chain and roll back the chain. In\nfact, the original Satoshi whitepaper refers to fraud proofs, using the term\n\"alerts\", and assumed SPV nodes would use them to get better guarantees they're\nusing a valid chain. (SPV as implemented by bitcoinj is sometimes referred to\nas \"non-validating SPV\") The problem is, how do you guarantee that the fraud\nwill get detected? And How do you guarantee that fraud that is detected\nactually gets propagated around the network? And if all that fails... then\nwhat?\n\nThe nightmare scenario in that kind of system is some miner successfully gets\naway with fraud for awhile, possibly creating hundreds of millions of dollars\nworth of bitcoins out of thin air. Those fake coins could easily \"taint\" a\nsignificant fraction of the economy, making rollback impossible and shaking\nfaith in the value of the currency. Right now in Bitcoin this is pretty much\nimpossible because everyone can run a full node to validate the chain for\nthemselves, but in a sharded system that's far harder to guarantee.\n\nNow, suppose we *can* guarantee validity. zk-SNARKS are basically a way of\nmathematically proving that you ran a certain computer program on some data,\nand that program returned true. *Recursive* zk-SNARKS are simply zk-SNARKS\nwhere the program can also recursively evaluate that another zk-SNARK is true.\nWith this technology a miner could *prove* that the shard they're working on is\nvalid, solving the problem of fake coins. Unfortunately, zk-SNARKS are bleeding\nedge crypto, (if zerocoin had been deployed a the entire system would have been\ndestroyed by a recently found bug that allowed fake proofs to be created) and\nrecursive zk-SNARKS don't exist yet.\n\nThe closest thing I know of to recrusive zk-SNARKS that actually does work\nwithout \"moon-math\" is an idea I came up with for treechains called coin\nhistory linearization. Basically, if you allow transactions to have multiple\ninputs and outputs, proving that a given coin is valid requires the entire coin\nhistory, which has quasi-exponential scaling - in the Bitcoin economy coins are\nvery quickly mixed such that all coins have pretty much all other coins in\ntheir history.\n\nNow suppose that rather than proving that all inputs are valid for a\ntransaction, what if you only had to prove that *one* was valid? This would\nlinearize the coin history as you only have to prove a single branch of the\ntransaction DAG, resulting in O(n) scaling. (with n <= total length of the\nblockchain chain)\n\nLet's assume Alice is trying to pay Bob with a transaction with two inputs each\nof equal value. For each input she irrevocable records it as spent, permanently\ncommitting that input's funds to Bob. (e.g. in an irrevocable ledger!) Next she\nmakes use of a random beacon - a source of publicly known random numbers that\nno-one can influence - to chose which of the two inputs' coin history's she'll\ngive to Bob as proof that the transaction is real. (both the irrevocable ledger\nand random beacon can be implemented with treechains, for example)\n\nIf Alice is being honest and both inputs are real, there's a 100% chance that\nshe'll be able to successfully convince Bob that the funds are real. Similarly,\nif Alice is dishonest and neither input is real, it'll be impossible for her\nconvince prove to Bob that the funds are real.\n\nBut what if one of the two inputs is real and the other is actually fake? Half\nthe time the transaction will succeed - the random beacon will select the real\ninput and Bob won't know that the other input is fake. However, half the time\nthe *fake* input will be selected, and Alice won't be able to prove anything.\nYet, the real input has irrevocably been spent anyway, destroying the funds! If\nthe process by which funds are spent really is irrevocable, and Alice has\nabsolutely no way to influence the random beacon, the two cases cancel out.\nWhile she can get away with fraud, there's no economic benefit for her to do\nso. On a macro level, this means that fraud won't result in inflation of the\ncurrency. (in fact, we want a system that institutionalizes this so-called\n\"fraud\" - creating false proofs is a great way to make your coins more private)\n(FWIW the way zk-SNARKS actually work is similar to this simple linearization\nscheme, but with a lot of very clever error correction math, and the hash of\nthe data itself as the random beacon)\n\nAn actual implementation would be extended to handle multiple transaction\ninputs of different sizes by weighing the probability that an input will be\nselected by it's value - merkle-sum-trees work well for this. We still have the\nproblem that O(n) scaling kinda sucks; can we do better?\n\nYes! Remember that a genesis transaction output has no history - the coins are\ncreated out of thin air and its validity is proven by the proof of work itself.\nSo every time you make a transaction that spends a genesis output you have a\nchance of reducing the length of the coin validity proof back to zero. Better\nyet, we can design a system where every transaction is associated with a bit of\nproof-of-work, and thus every transaction has a chance of resetting the length\nof the validity proof back to zero. In such a system you might do the PoW on a\nper-transaction basis; you could outsource the task to miners with a special\noutput that only the miner can spend. Now we have O(1) scaling, with a k that\ndepends on the inflation rate. I'd have to dig up the calculations again, but\nIIRC I sketched out a design for the above that resulted in something like 10MB\nor 100MB coin validity proofs, assuming 1% inflation a year. (equally you can\ndescribe that 1% inflation as a coin security tax) Certainly not small, but\ncompared to running a full node right now that's still a *huge* reduction in\nstorage space. (recursive zk-SNARKS might reduce that proof to something like\n1kB of data)\n\nRegardless of whether you have lightweight zk-SNARKS, heavyweight linearized\ncoin history proofs, or something else entirely, the key advantage is that\nvalidation can become entirely client side. Miners don't even need to care\nwhether or not their *own* blocks are \"valid\", let alone other miners' blocks.\nInvalid transactions in the chain are just garbage data, which gets rejected by\nwallet software as invalid. So long as the protocol itself  works and is\nimplemented correctly it's impossible for fraud to go undetected and destroy\nthe economy the way it can in a sharded system.\n\nHowever we still have a problem: censorship. This one is pretty subtle, and\ngets to the heart of how these systems actually work. How do you prove that a\ncoin has validly been spent? First, prove that it hasn't already been spent!\nHow do you do that if you don't have the blockchain data? You can't, and no\namount of fancy math can change that.\n\nIn Bitcoin if everyone runs full nodes censorship can't happen: you either have\nthe full blockchain and thus can spend your money and help mine new blocks, or\nthat alternate fork might as well not exist. SPV breaks this as it allows funds\nto be spent without also having the ability to mine - with SPV a cartel of\nminers can prevent anyone else from getting access to the blockchain data\nrequired to mine, while still allowing commerce to happen. In reality, this\ntype of cartel would be more subtle, and can even happen by accident; just\ndelaying other miners getting blockchain data by a few seconds harms those\nnon-cartel miners' profitability, without being obvious censorship. Equally, so\nlong as the cartel has [>30% of hashing power it's profitable in the long run\nfor the cartel if this\nhappens](http://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg03200.html).\n\nIn sharded systems the \"full node defense\" doesn't work, at least directly. The\nwhole point is that not everyone has all the data, so you have to decide what\nhappens when it's not available.\n\nAltcoins provide one model, albeit a pretty terrible one: taken as a whole you\ncan imagine the entire space of altcoins as a series of cryptocurrency shards\nfor moving funds around. The problem is each individual shard - each altcoin -\nis weak and can be 51% attacked. Since they can be attacked so easily, if you\ndesigned a system where funds could be moved from one shard to another through\ncoin history proofs every time a chain was 51% attacked and reorged you'd be\ncreating coins out of thin air, destroying digital scarcity and risking the\nwhole economy with uncontrolled inflation. You can instead design a system\nwhere coins can't move between shards - basically what the altcoin space looks\nlike now - but that means actually paying someone on another \"shard\" requires\nyou to sell your coins and buy their coins - a inefficient and expensive\nlogistical headache. (there's a reason the Eurozone was created!)\n\nIf you want to transfer value between shards with coin history proofs, without\nrisking inflation, you need all the shards to share some type of global\nconsensus. This is the idea behind treechains: every part of the tree is linked\nto a top-level timestamp chain, which means we have global consensus on the\ncontents of all chains, and thus spending a coin really is an immutable\none-time act.\n\nLet's go into a bit more detail. So what is a coin in a treechains system?\nFirst and foremost it's a *starting point* in some part of the tree, a specific\nsubchain. When Alice wants to prove to Bob that she spent a coin, giving it to\nBob, she inserts into that subchain the data that proves that someone *could\nhave* spent that coin - a valid signature and the hash of the transaction\noutput it was spending. But the actual proof that she gives to Bob isn't just\nthat spend data, but rather proof that all the blocks in that chain between the\nstarting point and the spend did *not* have a valid spend in them. (easiest way\nto do that? give Bob those blocks) That proof must link back to the top-level\nchain; if it doesn't the proof is simply not valid.\n\nNow suppose Alice can't get that part of the subchain, perhaps because a cartel\nof miners is mining it and won't give anyone else the data, or perhaps because\neveryone with the data suffered a simultaneous harddrive crash. We'll also say\nthat higher up in the tree the data is available, at minimum the top-level\nchain. As with Bitcoin, as long as that cartel has 51% of the hashing power,\nAlice is screwed and can't spend her money.\n\nWhat's interesting is what happens after that cartel disbands: how does mining\nrestart? It's easy to design a system where the creation of a block doesn't\nrequire the knowledge of previous blocks, so new blocks can be added to extend\nthe subchain. But Alice is still screwed: she can't prove to Bob that the\nmissing blocks in the subchain didn't contain a valid spend of her coin. This\nis pretty bad, on the other hand the damage is limited to just that one\nsubchain, and the system as a whole is unaffected.\n\nThere's a tricky incentives problem here though: if a miner can extend a\nsubchain without actually having previous blocks in that chain, where's the\nincentive for that miner to give anyone else the blocks they create? Remember\nthat exclusive knowledge of a block is potentially valuable if you can extort\ncoin owners for it. (Bitcoin suffers from this problem right now with\nvalidationless \"SPV\" mining, though the fact that a block can be invalid in\nBitcoin helps limit its effects)\n\nPart of the solution could be mining reward; in Bitcoin, coinbase outputs can't\nbe spent for 100 blocks. A similar scheme could require that a spend of a\ncoinbase output in a subchain include proof that the next X blocks in that\nsubchain were in fact linked together. Secondly make block creation dependent\non actually having that data to ensure the linkage actually means something,\ne.g. by introducing some validity rules so blocks can be invalid, and/or using\na PoW function that requires hashers to have a copy of that data.\n\nUltimately though this isn't magic: like it or not lower subchains in such a\nsystem are inherently weaker and more dangerous than higher ones, and this is\nequally true of any sharded system. However a hierarchically sharded system\nlike treechains can give users options: higher subchains are safer, but\ntransactions will expensive. The hierarchy does combine the PoW security of all\nsubchains together for the thing you can easily combine: timestamping security.\n\nThere's a big problem though: holy !@#$ is the above complex compared to\nBitcoin! Even the \"kiddy\" version of sharding - my linearization scheme rather\nthan zk-SNARKS - is probably one or two orders of magnitude more complex than\nusing the Bitcoin protocol is right now, yet right now a huge % of the\ncompanies in this space seem to have thrown their hands up and used centralized\nAPI providers instead. Actually implementing the above and getting it into the\nhands of end-users won't be easy.\n\nOn the other hand, decentralization isn't cheap: using PayPal is one or two\norders of magnitude simpler than the Bitcoin protocol.\n\n-- \n'peter'[:-1]@petertodd.org\n0000000000000000061df93abb76cdc4b1617bb097b4cab90f3f1ca5ae0a0df5\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 650 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151125/7a241e01/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Why sharding the blockchain is difficult",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Peter Todd"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 14471
        }
    },
    {
        "title": "[bitcoin-dev] [BIP] OP_CHECKPRIVPUBPAIR",
        "thread_messages": [
            {
                "author": "Mats Jerratsch",
                "date": "2015-11-27T08:02:37",
                "message_text_only": "Prior discussion:\nhttp://lists.linuxfoundation.org/pipermail/lightning-dev/2015-November/000309.html\n\nGoal:\nGreatly improve security for payment networks like the 'Lightning\nNetwork' (LN) [1]\n\n---\n\nIntroduction:\nTo improve privacy while using a payment network, it is possible to\nuse onion-routing to make a payment to someone. In this context,\nonion-routing means encrypting the data about subsequent hops in a way\nthat each node only knows where it received a payment from and the\ndirect next node it should send the payment to. This way we can route\na payment over N nodes, and none of these will know\n\n(1) at which position it is within the route (first, middle, last?)\n\n(2) which node initially issued the payment (payer)\n\n(3) which node consumes the payment (payee).\n\nHowever, given the way payments in LN work, each payment is uniquely\nidentifiable by a preimage-hash pair R-H. H is included in the output\nscript of the commit transaction, such that the payment is enforceable\nif you ever get to know the preimage R.\n\nIn a payment network each node makes a promise to pay the next node,\nif they can produce R. They can pass on the payment, as they know that\nthey can enforce the payment from a previous node using the same\npreimage R. This severely damages privacy, as it lowers the amount of\nnodes an attacker has to control to gain information about payer and\npayee.\n\n---\n\nProblem:\nThe problem was inherited by using RIPEMD-160 for preimage-hash\nconstruction. For any cryptographic hash-function it is fundamentally\nunfeasible to correlate preimage and hash in such a way, that\n\nF1(R1) = R2 and\nF2(H1) = H2, while\nSHA(R1) = H1 and SHA(R2) = H2.\n\nIn other words, I cannot give a node H1 and H2 and ask it to receive\nmy payment using H1, but pass it on using H2, as the node has no way\nof verifying it can produce R1 out of the R2 it will receive. If it\ncannot produce R1, it is unable to enforce my part of the contract.\n\n---\n\nSolution:\nWhile above functions are merely impossible to construct for a\ncryptographic hash functions, they are trivial when R and H is a EC\nprivate/public key pair. The original sender can make a payment using\nH1 and pass on a random number M1, such that the node can calculate a\nnew public key\n\nH2 = H1 + M1.\n\nWhen he later receives the private key R2, he can construct\n\nR1 = R2 - M1\n\nto be able to enforce the other payment. M1 can be passed on in the\nonion object, such that each node can only see M for that hop.\nFurthermore, it is unfeasible to brute-force, given a sufficiently\nlarge number M.\n\n---\n\nExample:\n\nGiven that E wants to receive a payment from A, payable to H. (if A\ncan produce R, it can be used as a prove he made the payment and E\nreceived it)\n\nA decides to route the payment over the nodes B, C and D. A uses four\nnumbers M1...M4 to calculate H1...H4. The following payments then take\nplace\n\nA->B using H4\nB->C using H3\nC->D using H2\nD->E using H1.\n\nWhen E receives H1, he can use attached M1 to calculate R1 from it.\nThe chain will resolve itself, and A is able to calculate R using\nM1...M4. It also means that all privacy is at the sole discretion of\nthe sender, and that not even the original pair R/H is known to any of\nthe nodes.\n\nTo improve privacy, E could also be a rendezvous point chosen by the\nreal receiver of the payment, similar constructions are similar in\nthat direction as well.\n\n---\n\nCaveats:\n\nCurrently it is difficult to enforce a payment to a private-public key\npair on the blockchain. While there exists OP_HASH160 OP_EQUAL to\nenforce a payment to a hash, the same does not hold true for EC keys.\nTo make above possible we would therefore need some easy way to force\na private key, given a public key. This could be done by using one of\nthe unused OP_NOP codes, which will verify\n\n<private key> <public key> OP_CHECKPRIVPUBPAIR\n\nand fails if these are not correlated or NOP otherwise. Would need\nOP_2DROP afterwards. This would allow deployment using a softfork.\n\nAs there are requests for all sort of general crypto operations in\nscript, we can also introduce a new general OP_CRYPTO and prepend one\nbyte for the operation, so\n\n0x01 OP_CRYPTO = OP_CHECKPRIVPUBPAIR\n0x02-0xff OP_CRYPTO = OP_NOP\n\nto allow for extension at some later point.\n\n---\n\nAlternatives:\n\nIn the attached discussion there are some constructions that would\nallow breaking the signature scheme, but they are either very large in\nscript language or expensive to calculate. Given that the blocksize is\na difficult topic already, it would not be beneficial to have a 400B+\nfor each open payment in case one party breaches the contract. (or\njust disappears for a couple of days)\n\nIt is also possible to use a NIZKP - more specifically SNARK - to\nprove to one node that it is able to recover a preimage R1 = R2 XOR\nM1, given only H1, H2 and M1. However, these are expensive to\ncalculate and experimental in it's current state.\n\n---\n\nAcknowledgements:\nGregory Maxwell for pointing out addition of M1 for EC points is much\nless expensive\nPieter Wuille for helping with general understanding of EC math.\nAnthony Towns for bringing up the issue and explaining SNARKs\n\n[1]\nhttp://lightning.network/"
            },
            {
                "author": "Anthony Towns",
                "date": "2015-11-29T23:41:43",
                "message_text_only": "On Fri, Nov 27, 2015 at 09:02:37AM +0100, Mats Jerratsch via bitcoin-dev wrote:\n> <private key> <public key> OP_CHECKPRIVPUBPAIR\n> As there are requests for all sort of general crypto operations in\n> script, we can also introduce a new general OP_CRYPTO and prepend one\n> byte for the operation, so\n> 0x01 OP_CRYPTO = OP_CHECKPRIVPUBPAIR\n> 0x02-0xff OP_CRYPTO = OP_NOP\n> to allow for extension at some later point.\n\nThis wouldn't be a softfork -- a single prefixed 0x01 byte would just\npush \"OP_CRYPTO\" onto the stack... If you had OP_CRYPTO look at the top\nitem on the stack to determine what to do, you could have:\n\n  OP_[0-16] OP_CRYPTO\n  OP_PUSHDATA1 [0x11-0xFF] OP_CRYPTO\n  OP_PUSHDATA2 [0x00-0xFF] [0x01-0xFF] OP_CRYPTO\n  ...\n\nto get 17 different crypto ops in two bytes, and the next 238 in three,\nand be arbitrarily expandable from there with multibyte pushes.\n\n> Alternatives:\n> In the attached discussion there are some constructions that would\n> allow breaking the signature scheme, but they are either very large in\n> script language or expensive to calculate.\n\nI think that's good enough to try them out in prototypes though -- and\npresumably if they're demonstrably useful in prototypes that's a good\nargument for adding a dedicated op code to script?\n\nAre there any other crypto ops that might be worth adding into a BIP for\na check-verify crypto toolkit op like this? The only ones that come to mind\nas having practical uses in the near term are:\n\n Base-point multiply on secp256k1 (ie, CHECKPUBPRIVPAIR)\n Schnorr-signature of transaction with secp256k1 curve (smaller,\n   faster, more-anonymous N-of-N multisig)\n\nBut perhaps there's also uses for some of:\n\n General point addition on secp256k1\n General point multiply on secp256k1\n SHA3-256 / SHA2-512 / SHA3-512\n ECDSA/Schnorr signature of value from stack\n ...?\n\nThen again, I gather that if the segregated witness soft-fork turns out\nto be plausible, re-enabling/changing/adding *any* sort of opcode could\nbe done as a soft-fork, not just turning a NOP into CHECK_foo_VERIFY...\nSo it might be better to wait and see how that goes before putting too\nmuch time into drafting a BIP or similar?\n\nCheers,\naj"
            }
        ],
        "thread_summary": {
            "title": "OP_CHECKPRIVPUBPAIR",
            "categories": [
                "bitcoin-dev",
                "BIP"
            ],
            "authors": [
                "Anthony Towns",
                "Mats Jerratsch"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 7309
        }
    },
    {
        "title": "[bitcoin-dev] Test Results for : Datasstream Compression of Blocks and Tx's",
        "thread_messages": [
            {
                "author": "Peter Tschipper",
                "date": "2015-11-28T21:41:51",
                "message_text_only": "Hi All,\n\nHere are some final results of testing with the reference implementation\nfor compressing blocks and transactions. This implementation also\nconcatenates blocks and transactions when possible so you'll see data\nsizes in the 1-2MB ranges.\n\nResults below show the time it takes to sync the first part of the\nblockchain, comparing Zlib to the LZOx library.  (LZOf was also tried\nbut wasn't found to be as good as LZOx).  The following shows tests run\nwith and without latency.  With latency on the network, all compression\nlibraries performed much better than without compression.\n\nI don't think it's entirely obvious which is better, Zlib or LZO. \nAlthough I prefer the higher compression of Zlib, overall I would have\nto give the edge to LZO.  With LZO we have the fastest most scalable\noption when at the lowest compression setting which will be a boost in\nperformance for users that want peformance over compression, and then at\nthe high end LZO provides decent compression which approaches Zlib,\n(although at a higher cost) but good for those that want to save more\nbandwidth.\n\nUncompressed 60ms \tZlib-1 (60ms) \tZlib-6 (60ms) \tLZOx-1 (60ms) \tLZOx-999\n(60ms)\n219 \t299 \t296 \t294 \t291\n432 \t568 \t565 \t558 \t548\n652 \t835 \t836 \t819 \t811\n866 \t1106 \t1107 \t1081 \t1071\n1082 \t1372 \t1381 \t1341 \t1333\n1309 \t1644 \t1654 \t1605 \t1600\n1535 \t1917 \t1936 \t1873 \t1875\n1762 \t2191 \t2210 \t2141 \t2141\n1992 \t2463 \t2486 \t2411 \t2411\n2257 \t2748 \t2780 \t2694 \t2697\n2627 \t3034 \t3076 \t2970 \t2983\n3226 \t3416 \t3397 \t3266 \t3302\n4010 \t3983 \t3773 \t3625 \t3703\n4914 \t4503 \t4292 \t4127 \t4287\n5806 \t4928 \t4719 \t4529 \t4821\n6674 \t5249 \t5164 \t4840 \t5314\n7563 \t5603 \t5669 \t5289 \t6002\n8477 \t6054 \t6268 \t5858 \t6638\n9843 \t7085 \t7278 \t6868 \t7679\n11338 \t8215 \t8433 \t8044 \t8795\n\n\n\nThese results from testing on a highspeed wireless LAN (very small latency)\n\nResults in seconds \t\n\t\n\t\n\t\n\t\nNum blocks sync'd \tUncompressed \tZlib-1 \tZlib-6 \tLZOx-1 \tLZOx-999\n10000 \t255 \t232 \t233 \t231 \t257\n20000 \t464 \t414 \t420 \t407 \t453\n30000 \t677 \t594 \t611 \t585 \t650\n40000 \t887 \t782 \t795 \t760 \t849\n50000 \t1099 \t961 \t977 \t933 \t1048\n60000 \t1310 \t1145 \t1167 \t1110 \t1259\n70000 \t1512 \t1330 \t1362 \t1291 \t1470\n80000 \t1714 \t1519 \t1552 \t1469 \t1679\n90000 \t1917 \t1707 \t1747 \t1650 \t1882\n100000 \t2122 \t1905 \t1950 \t1843 \t2111\n110000 \t2333 \t2107 \t2151 \t2038 \t2329\n120000 \t2560 \t2333 \t2376 \t2256 \t2580\n130000 \t2835 \t2656 \t2679 \t2558 \t2921\n140000 \t3274 \t3259 \t3161 \t3051 \t3466\n150000 \t3662 \t3793 \t3547 \t3440 \t3919\n160000 \t4040 \t4172 \t3937 \t3767 \t4416\n170000 \t4425 \t4625 \t4379 \t4215 \t4958\n180000 \t4860 \t5149 \t4895 \t4781 \t5560\n190000 \t5855 \t6160 \t5898 \t5805 \t6557\n200000 \t7004 \t7234 \t7051 \t6983 \t7770\n\n\n\nThe following show the compression ratio acheived for various sizes of\ndata.  Zlib is the clear\nwinner for compressibility, with LZOx-999 coming close but at a cost.\n\nrange \tZlib-1 cmp%\n\tZlib-6 cmp% \tLZOx-1 cmp% \tLZOx-999 cmp%\n0-250b \t12.44 \t12.86 \t10.79 \t14.34\n250-500b  \t19.33 \t12.97 \t10.34 \t11.11\n600-700 \t16.72 \tn/a \t12.91 \t17.25\n700-800 \t6.37 \t7.65 \t4.83 \t8.07\n900-1KB \t6.54 \t6.95 \t5.64 \t7.9\n1KB-10KB \t25.08 \t25.65 \t21.21 \t22.65\n10KB-100KB \t19.77 \t21.57 \t14.37 \t19.02\n100KB-200KB \t21.49 \t23.56 \t15.37 \t21.55\n200KB-300KB \t23.66 \t24.18 \t16.91 \t22.76\n300KB-400KB \t23.4 \t23.7 \t16.5 \t21.38\n400KB-500KB \t24.6 \t24.85 \t17.56 \t22.43\n500KB-600KB \t25.51 \t26.55 \t18.51 \t23.4\n600KB-700KB \t27.25 \t28.41 \t19.91 \t25.46\n700KB-800KB \t27.58 \t29.18 \t20.26 \t27.17\n800KB-900KB \t27 \t29.11 \t20 \t27.4\n900KB-1MB \t28.19 \t29.38 \t21.15 \t26.43\n1MB -2MB \t27.41 \t29.46 \t21.33 \t27.73\n\n\nThe following shows the time in seconds to compress data of various\nsizes.  LZO1x is the\nfastest and as file sizes increase, LZO1x time hardly increases at all. \nIt's interesing\nto note as compression ratios increase LZOx-999 performs much worse than\nZlib.  So LZO is faster\non the low end and slower (5 to 6 times slower) on the high end.\n\nrange \tZlib-1 \tZlib-6 \tLZOx-1 \tLZOx-999 cmp%\n0-250b    \t0.001 \t0 \t0 \t0\n250-500b   \t0 \t0 \t0 \t0.001\n500-1KB     \t0 \t0 \t0 \t0.001\n1KB-10KB    \t0.001 \t0.001 \t0 \t0.002\n10KB-100KB   \t0.004 \t0.006 \t0.001 \t0.017\n100KB-200KB  \t0.012 \t0.017 \t0.002 \t0.054\n200KB-300KB  \t0.018 \t0.024 \t0.003 \t0.087\n300KB-400KB  \t0.022 \t0.03 \t0.003 \t0.121\n400KB-500KB  \t0.027 \t0.037 \t0.004 \t0.151\n500KB-600KB  \t0.031 \t0.044 \t0.004 \t0.184\n600KB-700KB  \t0.035 \t0.051 \t0.006 \t0.211\n700KB-800KB  \t0.039 \t0.057 \t0.006 \t0.243\n800KB-900KB  \t0.045 \t0.064 \t0.006 \t0.27\n900KB-1MB   \t0.049 \t0.072 \t0.006 \t0.307\n\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151128/33ab8097/attachment-0001.html>"
            },
            {
                "author": "Jeff Garzik",
                "date": "2015-11-30T16:53:39",
                "message_text_only": "Thanks for providing an in-depth, data driven analysis.\n\nIt is surprising that zlib provides better compression at the high end.  I\nwonder if that is due to our specific data patterns - many zeroes - which\nprobably puts us into the zlib dictionary fast path.\n\n\n\nOn Sat, Nov 28, 2015 at 4:41 PM, Peter Tschipper via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi All,\n>\n> Here are some final results of testing with the reference implementation\n> for compressing blocks and transactions. This implementation also\n> concatenates blocks and transactions when possible so you'll see data sizes\n> in the 1-2MB ranges.\n>\n> Results below show the time it takes to sync the first part of the\n> blockchain, comparing Zlib to the LZOx library.  (LZOf was also tried but\n> wasn't found to be as good as LZOx).  The following shows tests run with\n> and without latency.  With latency on the network, all compression\n> libraries performed much better than without compression.\n>\n> I don't think it's entirely obvious which is better, Zlib or LZO.\n> Although I prefer the higher compression of Zlib, overall I would have to\n> give the edge to LZO.  With LZO we have the fastest most scalable option\n> when at the lowest compression setting which will be a boost in performance\n> for users that want peformance over compression, and then at the high end\n> LZO provides decent compression which approaches Zlib, (although at a\n> higher cost) but good for those that want to save more bandwidth.\n>\n> Uncompressed 60ms Zlib-1 (60ms) Zlib-6 (60ms) LZOx-1 (60ms) LZOx-999\n> (60ms) 219 299 296 294 291 432 568 565 558 548 652 835 836 819 811 866\n> 1106 1107 1081 1071 1082 1372 1381 1341 1333 1309 1644 1654 1605 1600 1535\n> 1917 1936 1873 1875 1762 2191 2210 2141 2141 1992 2463 2486 2411 2411 2257\n> 2748 2780 2694 2697 2627 3034 3076 2970 2983 3226 3416 3397 3266 3302 4010\n> 3983 3773 3625 3703 4914 4503 4292 4127 4287 5806 4928 4719 4529 4821 6674\n> 5249 5164 4840 5314 7563 5603 5669 5289 6002 8477 6054 6268 5858 6638 9843\n> 7085 7278 6868 7679 11338 8215 8433 8044 8795\n>\n> These results from testing on a highspeed wireless LAN (very small latency)\n>\n> Results in seconds\n>\n>\n>\n>\n> Num blocks sync'd Uncompressed Zlib-1 Zlib-6 LZOx-1 LZOx-999 10000 255 232\n> 233 231 257 20000 464 414 420 407 453 30000 677 594 611 585 650 40000 887\n> 782 795 760 849 50000 1099 961 977 933 1048 60000 1310 1145 1167 1110 1259\n> 70000 1512 1330 1362 1291 1470 80000 1714 1519 1552 1469 1679 90000 1917\n> 1707 1747 1650 1882 100000 2122 1905 1950 1843 2111 110000 2333 2107 2151\n> 2038 2329 120000 2560 2333 2376 2256 2580 130000 2835 2656 2679 2558 2921\n> 140000 3274 3259 3161 3051 3466 150000 3662 3793 3547 3440 3919 160000\n> 4040 4172 3937 3767 4416 170000 4425 4625 4379 4215 4958 180000 4860 5149\n> 4895 4781 5560 190000 5855 6160 5898 5805 6557 200000 7004 7234 7051 6983\n> 7770\n>\n> The following show the compression ratio acheived for various sizes of\n> data.  Zlib is the clear\n> winner for compressibility, with LZOx-999 coming close but at a cost.\n>\n> range Zlib-1 cmp%\n> Zlib-6 cmp% LZOx-1 cmp% LZOx-999 cmp% 0-250b 12.44 12.86 10.79 14.34\n> 250-500b  19.33 12.97 10.34 11.11 600-700 16.72 n/a 12.91 17.25 700-800\n> 6.37 7.65 4.83 8.07 900-1KB 6.54 6.95 5.64 7.9 1KB-10KB 25.08 25.65 21.21\n> 22.65 10KB-100KB 19.77 21.57 14.37 19.02 100KB-200KB 21.49 23.56 15.37\n> 21.55 200KB-300KB 23.66 24.18 16.91 22.76 300KB-400KB 23.4 23.7 16.5 21.38\n> 400KB-500KB 24.6 24.85 17.56 22.43 500KB-600KB 25.51 26.55 18.51 23.4\n> 600KB-700KB 27.25 28.41 19.91 25.46 700KB-800KB 27.58 29.18 20.26 27.17\n> 800KB-900KB 27 29.11 20 27.4 900KB-1MB 28.19 29.38 21.15 26.43 1MB -2MB\n> 27.41 29.46 21.33 27.73\n> The following shows the time in seconds to compress data of various\n> sizes.  LZO1x is the\n> fastest and as file sizes increase, LZO1x time hardly increases at all.\n> It's interesing\n> to note as compression ratios increase LZOx-999 performs much worse than\n> Zlib.  So LZO is faster\n> on the low end and slower (5 to 6 times slower) on the high end.\n>\n> range Zlib-1 Zlib-6 LZOx-1 LZOx-999 cmp% 0-250b    0.001 0 0 0 250-500b\n> 0 0 0 0.001 500-1KB     0 0 0 0.001 1KB-10KB    0.001 0.001 0 0.002\n> 10KB-100KB   0.004 0.006 0.001 0.017 100KB-200KB  0.012 0.017 0.002 0.054\n> 200KB-300KB  0.018 0.024 0.003 0.087 300KB-400KB  0.022 0.03 0.003 0.121\n> 400KB-500KB  0.027 0.037 0.004 0.151 500KB-600KB  0.031 0.044 0.004 0.184\n> 600KB-700KB  0.035 0.051 0.006 0.211 700KB-800KB  0.039 0.057 0.006 0.243\n> 800KB-900KB  0.045 0.064 0.006 0.27 900KB-1MB   0.049 0.072 0.006 0.307\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151130/2bc11689/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Test Results for : Datasstream Compression of Blocks and Tx's",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeff Garzik",
                "Peter Tschipper"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 9522
        }
    },
    {
        "title": "[bitcoin-dev] Use CPFP as consensus critical for Full-RBF",
        "thread_messages": [
            {
                "author": "Vincent Truong",
                "date": "2015-11-29T03:50:14",
                "message_text_only": "(I haven't been following this development recently so apologies in advance\nif I've made assumptions about RBF)\n\nIf you made CPFP consensus critical for all Full-RBF transactions, RBF\nshould be safer to use. I see RBF as a necessity for users to fix mistakes\n(and not for transaction prioritisation), but we can't know for sure if\nminers are playing with this policy fairly or not. It is hard to spot a\nlegitimate RBF and a malicious one, but if the recipient signs off on the\none they know about using CPFP, there should be no problems. This might\ndepend on the CPFP implementation, because you'll need a way for the\ntransaction to mark which output is a change address and which is a payment\nto prevent the sender from signing off his own txns. (This might be bad for\nprivacy, but IMO a lot safer than allowing RBF double spending sprees... If\nyou value privacy then don't use RBF?) Or maybe let them sign it off but\nmake all outputs sign off somehow.\n\nCopy/Paste from my reddit post:\n\nhttps://www.reddit.com/r/Bitcoin/comments/3ul1kb/slug/cxgegkj\n\nGoing to chime in my opinion: opt-in RBF eliminates the trust required with\nminers. You don't know if they're secretly running RBF right now anyway.\nWhether Peter Todd invented this is irrelevant, it was going to happen\neither way either with good intentions or with malice, so better to develop\nthis with good intentions.\n\nPerhaps the solution to this problem is simple. Allow Full-RBF up to the\npoint where a recipient creates a CPFP transaction. Any transaction with\nfull RBF that hasn't been signed off with a CPFP cannot go into a block,\nand this can become a consensus rule rather than local policy thanks to the\nopt-in flags that's inside transactions.\n\n> P.S. (When I wrote this, I'm actually not sure how the flag looks like\nand am just guessing it can be used this way. I'm not familiar with the\nimplementation.)\n\nCPFP is needed so that merchants can bear the burden of fees (double\nbandwidth costs aside, and frankly if RBF is allowed bandwidth is going to\nincrease regardless anyway). That's always the way I've being seeing its\npurpose. And this makes RBF much safer to use by combining the two.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151129/36a93a2d/attachment.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2015-11-29T11:55:08",
                "message_text_only": "Both CPFP and RBF are relay/mining policy and cannot be made consensus\nrules because you cannot know which transactions have been received by a\ngivrn peer and which have not (or at what time). Consensus rules can only\nvalidate information that's in the blockchain.\nOn Nov 29, 2015 5:33 AM, \"Vincent Truong via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> (I haven't been following this development recently so apologies in\n> advance if I've made assumptions about RBF)\n>\n> If you made CPFP consensus critical for all Full-RBF transactions, RBF\n> should be safer to use. I see RBF as a necessity for users to fix mistakes\n> (and not for transaction prioritisation), but we can't know for sure if\n> miners are playing with this policy fairly or not. It is hard to spot a\n> legitimate RBF and a malicious one, but if the recipient signs off on the\n> one they know about using CPFP, there should be no problems. This might\n> depend on the CPFP implementation, because you'll need a way for the\n> transaction to mark which output is a change address and which is a payment\n> to prevent the sender from signing off his own txns. (This might be bad for\n> privacy, but IMO a lot safer than allowing RBF double spending sprees... If\n> you value privacy then don't use RBF?) Or maybe let them sign it off but\n> make all outputs sign off somehow.\n>\n> Copy/Paste from my reddit post:\n>\n> https://www.reddit.com/r/Bitcoin/comments/3ul1kb/slug/cxgegkj\n>\n> Going to chime in my opinion: opt-in RBF eliminates the trust required\n> with miners. You don't know if they're secretly running RBF right now\n> anyway. Whether Peter Todd invented this is irrelevant, it was going to\n> happen either way either with good intentions or with malice, so better to\n> develop this with good intentions.\n>\n> Perhaps the solution to this problem is simple. Allow Full-RBF up to the\n> point where a recipient creates a CPFP transaction. Any transaction with\n> full RBF that hasn't been signed off with a CPFP cannot go into a block,\n> and this can become a consensus rule rather than local policy thanks to the\n> opt-in flags that's inside transactions.\n>\n> > P.S. (When I wrote this, I'm actually not sure how the flag looks like\n> and am just guessing it can be used this way. I'm not familiar with the\n> implementation.)\n>\n> CPFP is needed so that merchants can bear the burden of fees (double\n> bandwidth costs aside, and frankly if RBF is allowed bandwidth is going to\n> increase regardless anyway). That's always the way I've being seeing its\n> purpose. And this makes RBF much safer to use by combining the two.\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20151129/2b2e39b7/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Use CPFP as consensus critical for Full-RBF",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jorge Tim\u00f3n",
                "Vincent Truong"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 5323
        }
    },
    {
        "title": "[bitcoin-dev] [BIP Draft] Datastream compression of Blocks and Transactions",
        "thread_messages": [
            {
                "author": "Peter Tschipper",
                "date": "2015-11-30T23:12:24",
                "message_text_only": "@gmaxwell Bip Editor, and the Bitcoin Dev Community,\n\nAfter several weeks of experimenting and testing with various\ncompression libraries I think there is enough evidence to show that\ncompressing blocks and transactions is not only beneficial in reducing\nnetwork bandwidth but is also provides a small performance boost when\nthere is latency on the network.\n\nThe following is a BIP Draft document for your review. \n(The alignment of the columns in the tables doesn't come out looking\nright in this email but if you cut and paste into a text document they\nare just fine)\n\n\n<pre>\n  BIP: ?\n  Title: Datastream compression of Blocks and Tx's\n  Author: Peter Tschipper <peter.tschipper at gmail.com>\n  Status: Draft\n  Type: Standards Track\n  Created: 2015-11-30\n</pre>\n\n==Abstract==\n\nTo compress blocks and transactions, and to concatenate them together\nwhen possible, before sending.\n\n==Motivation==\n\nBandwidth is an issue for users that run nodes in regions where\nbandwidth is expensive and subject to caps, in addition network latency\nin some regions can also be quite high. By compressing data we can\nreduce daily bandwidth used in a significant way while at the same time\nspeed up the transmission of data throughout the network. This should\nencourage users to keep their nodes running longer and allow for more\npeer connections with less need for bandwidth throttling and in\naddition, may also encourage users in areas of marginal internet\nconnectivity to run nodes where in the past they would not have been\nable to.\n\n==Specification==\n\nAdvertise compression using a service bit.  Both peers must have\ncompression turned on in order for data to be compressed, sent, and\ndecompressed.\n\nBlocks will be sent compressed.\n\nTransactions will be sent compressed with the exception of those less\nthan 500 bytes.\n\nBlocks will be concatenated when possible.\n\nTransactions will be concatenated when possible or when a\nMSG_FILTERED_BLOCK is requested.\n\nCompression levels to be specified in \"bitcoin.conf\".\n\nCompression and decompression can be completely turned off.\n\nAlthough unlikely, if compression should fail then data will be sent\nuncompressed.\n\nThe code for compressing and decompressing will be located in class\nCDataStream.\n\nCompression library LZO1x will be used.\n\n==Rationale==\n\nBy using a service bit, compression and decompression can be turned\non/off completely at both ends with a simple configuration setting. It\nis important to be able to easily turn off compression/decompression as\na fall back mechanism.  Using a service bit also makes the code fully\ncompatible with any node that does not currently support compression. A\nnode that do not present the correct service bit will simply receive\ndata in standard uncompressed format.\n\nAll blocks will be compressed. Even small blocks have been found to\nbenefit from compression.\n \nMultiple block requests that are in queue will be concatenated together\nwhen possible to increase compressibility of smaller blocks.\nConcatenation will happen only if there are multiple block requests from\nthe same remote peer.  For example, if peer1 is requesting two blocks\nand they are both in queue then those two blocks will be concatenated.\nHowever, if peer1 is requesting 1 block and peer2 also one block, and\nthey are both in queue, then each peer is sent only its block and no\nconcatenation will occur. Up to 16 blocks (the max blocks in flight) can\nbe concatenated but not exceeding the MAX_PROTOCOL_MESSAGE_LENGTH.\nConcatenated blocks compress better and further reduce bandwidth.\n\nTransactions below 500 bytes do not compress well and will be sent\nuncompressed unless they can be concatenated (see Table 3).\n\nMultiple transaction requests that are in queue will be concatenated\nwhen possible.  This further reduces bandwidth needs and speeds the\ntransfer of large requests for many transactions, such as with\nMSG_FILTERED_BLOCK requests, or when the system gets busy and is flooded\nwith transactions.  Concatenation happens in the same way as for blocks,\ndescribed above.\n\nBy allowing for differing compression levels which can be specified in\nthe bitcoin.conf file, a node operator can tailor their compression to a\nlevel suitable for their system.\n\nAlthough unlikely, if compression fails for any reason then blocks and\ntransactions will be sent uncompressed.  Therefore, even with\ncompression turned on, a node will be able to handle both compressed and\nuncompressed data from another peer.\n\nBy Abstracting the compression/decompression code into class\n\"CDataStream\", compression can be easily applied to any datastream.\n\nThe compression library LZO1x-1 does not compress to the extent that\nZlib does but it is clearly the better performer (particularly as file\nsizes get larger), while at the same time providing very good\ncompression (see Tables 1 and 2).  Furthermore, LZO1x-999 can provide\nand almost Zlib like compression for those who wish to have more\ncompression, although at a cost.\n\n==Test Results==\n\nWith the LZO library, current test results show up to a 20% compression\nusing LZO1x-1 and up to 27% when using LZO1x-999.  In addition there is\na marked performance improvement when there is latency on the network.\n>From the test results, with a latency of 60ms there is an almost 30%\nimprovement in performance when comparing LZO1x-1 compressed blocks with\nuncompressed blocks (see Table 5).\n\nThe following table shows the percentage that blocks were compressed,\nusing two different Zlib and LZO1x compression level settings.\n\nTABLE 1:\nrange = data size range\nrange           Zlib-1  Zlib-6  LZO1x-1 LZO1x-999\n-----------     ------  ------  ------- --------\n0-250           12.44   12.86   10.79   14.34\n250-500         19.33   12.97   10.34   11.11   \n600-700         16.72   n/a     12.91   17.25\n700-800         6.37    7.65    4.83    8.07\n900-1KB         6.54    6.95    5.64    7.9\n1KB-10KB        25.08   25.65   21.21   22.65\n10KB-100KB      19.77   21.57   4.37    19.02\n100KB-200KB     21.49   23.56   15.37   21.55\n200KB-300KB     23.66   24.18   16.91   22.76\n300KB-400KB     23.4    23.7    16.5    21.38\n400KB-500KB     24.6    24.85   17.56   22.43\n500KB-600KB     25.51   26.55   18.51   23.4\n600KB-700KB     27.25   28.41   19.91   25.46\n700KB-800KB     27.58   29.18   20.26   27.17\n800KB-900KB     27      29.11   20      27.4\n900KB-1MB       28.19   29.38   21.15   26.43\n1MB -2MB        27.41   29.46   21.33   27.73\n\nThe following table shows the time in seconds that a block of data takes\nto compress using different compression levels.  One can clearly see\nthat LZO1x-1 is the fastest and is not as affected when data sizes get\nlarger.\n\nTABLE 2:\nrange = data size range\nrange           Zlib-1  Zlib-6  LZO1x-1 LZO1x-999\n-----------     ------  ------  ------- ---------\n0-250           0.001   0       0       0\n250-500         0       0       0       0.001\n500-1KB         0       0       0       0.001\n1KB-10KB        0.001   0.001   0       0.002\n10KB-100KB      0.004   0.006   0.001   0.017\n100KB-200KB     0.012   0.017   0.002   0.054\n200KB-300KB     0.018   0.024   0.003   0.087\n300KB-400KB     0.022   0.03    0.003   0.121\n400KB-500KB     0.027   0.037   0.004   0.151\n500KB-600KB     0.031   0.044   0.004   0.184\n600KB-700KB     0.035   0.051   0.006   0.211\n700KB-800KB     0.039   0.057   0.006   0.243\n800KB-900KB     0.045   0.064   0.006   0.27\n900KB-1MB       0.049   0.072   0.006   0.307\n\nTABLE 3:\nCompression of Transactions (without concatenation)\nrange = block size range\nubytes = average size of uncompressed transactions\ncbytes = average size of compressed transactions\ncmp% = the percentage amount that the transaction was compressed\ndatapoints = number of datapoints taken\n\nrange       ubytes    cbytes    cmp%    datapoints\n----------  ------    ------    ------  ----------    \n0-250       220       227       -3.16   23780\n250-500     356       354       0.68    20882\n500-600     534       505       5.29    2772\n600-700     653       608       6.95    1853\n700-800     757       649       14.22   578\n800-900     822       758       7.77    661\n900-1KB     954       862       9.69    906\n1KB-10KB    2698      2222      17.64   3370\n10KB-100KB  15463     12092     21.80   15429\n\nThe above table shows that transactions don't compress well below 500\nbytes but do very well beyond 1KB where there are a great deal of those\nlarge spam type transactions.   However, most transactions happen to be\nin the < 500 byte range.  So the next step was to appy concatenation for\nthose smaller transactions.  Doing that yielded some very good\ncompression results.  Some examples as follows:\n\nThe best one that was seen was when 175 transactions were concatenated\nbefore being compressed.  That yielded a 20% compression ratio, but that\ndoesn't take into account the savings from the unneeded 174 message\nheaders (24 bytes each) as well as 174 TCP ACKs of 52 bytes each which\nyields and additional 76*174 = 13224 byte savings, making for an overall\nbandwidth savings of 32%:\n\n     2015-11-18 01:09:09.002061 compressed data from 79890 to 67426\ntxcount:175\n\nHowever, that was an extreme example.  Most transaction aggregates were\nin the 2 to 10 transaction range.  Such as the following:\n\n     2015-11-17 21:08:28.469313 compressed data from 3199 to 2876 txcount:10\n\nBut even here the savings of 10% was far better than the \"nothing\" we\nwould get without concatenation, but add to that the 76 byte * 9\ntransaction savings and we have a total 20% savings in bandwidth for\ntransactions that otherwise would not be compressible.  Therefore the\nconcatenation of small transactions can also save bandwidth and speed up\nthe transmission of those transactions through the network while keeping\nnetwork and message queue chatter to a minimum.\n\n==Choice of Compression library==\n\nLZO was chosen over Zlib.  LZO is the fastest most scalable option when\nused at the lowest compression setting which will be a performance boost\nfor users that prefer performance over bandwidth savings. And at the\nhigher end, LZO provides good compression (although at a higher cost)\nwhich approaches that of Zlib.\n\nOther compression libraries investigated were Snappy, LZOf, fastZlib and\nLZ4 however none of these were found to be suitable, either because they\nwere not portable, lacked the flexibility to set compression levels or\ndid not provide a useful compression ratio.\n\nThe following two tables show results in seconds for syncing the first\n200,000 blocks. Tests were run on a high-speed wireless LAN with very\nlittle latency, and also run with a 60ms latency which was induced with\n\"Netbalancer\".\n               \nTABLE 4:\nResults shown in seconds on highspeed wireless LAN (no induced latency)\nNum blks sync'd  Uncmp  Zlib-1  Zlib-6  LZO1x-1  LZO1x-999\n---------------  -----  ------  ------  -------  ---------\n10000            255    232     233     231      257      \n20000            464    414     420     407      453      \n30000            677    594     611     585      650      \n40000            887    787     795     760      849     \n50000            1099   961     977     933      1048   \n60000            1310   1145    1167    1110     1259  \n70000            1512   1330    1362    1291     1470  \n80000            1714   1519    1552    1469     1679   \n90000            1917   1707    1747    1650     1882  \n100000           2122   1905    1950    1843     2111    \n110000           2333   2107    2151    2038     2329  \n120000           2560   2333    2376    2256     2580   \n130000           2835   2656    2679    2558     2921 \n140000           3274   3259    3161    3051     3466   \n150000           3662   3793    3547    3440     3919   \n160000           4040   4172    3937    3767     4416   \n170000           4425   4625    4379    4215     4958   \n180000           4860   5149    4895    4781     5560    \n190000           5855   6160    5898    5805     6557    \n200000           7004   7234    7051    6983     7770   \n\nTABLE 5:\nResults shown in seconds with 60ms of induced latency\nNum blks sync'd  Uncmp  Zlib-1  Zlib-6  LZO1x-1  LZO1x-999\n---------------  -----  ------  ------  -------  ---------\n10000            219    299     296     294      291\n20000            432    568     565     558      548\n30000            652    835     836     819      811\n40000            866    1106    1107    1081     1071\n50000            1082   1372    1381    1341     1333\n60000            1309   1644    1654    1605     1600\n70000            1535   1917    1936    1873     1875\n80000            1762   2191    2210    2141     2141\n90000            1992   2463    2486    2411     2411\n100000           2257   2748    2780    2694     2697\n110000           2627   3034    3076    2970     2983\n120000           3226   3416    3397    3266     3302\n130000           4010   3983    3773    3625     3703\n140000           4914   4503    4292    4127     4287\n150000           5806   4928    4719    4529     4821\n160000           6674   5249    5164    4840     5314\n170000           7563   5603    5669    5289     6002\n180000           8477   6054    6268    5858     6638\n190000           9843   7085    7278    6868     7679\n200000           11338  8215    8433    8044     8795\n\n==Backward compatibility==\n\nBeing unable to present the correct service bit, older clients will\ncontinue to receive standard uncompressed data and will be fully\ncompatible with this change.\n\n==Fallback==\n\nIt is important to be able to entirely and easily turn off compression\nand decompression as a fall back mechanism. This can be done with a\nsimple bitcoin.conf setting of \"compressionlevel=0\". Only one of the two\nconnected peers need to set compressionlevel=0 in order to turn off\ncompression and decompression completely.\n\n==Deployment==\n\nThis enhancement does not require a hard or soft fork.\n\n==Service Bit==\n\nDuring the testing of this implementation, service bit 28 was used,\nhowever this enhancement will require a permanently assigned service bit.\n\n==Implementation==\n\nThis implementation depends on the LZO compression library: lzo-2.09\n\n     https://github.com/ptschip/bitcoin/tree/compress\n\n==Copyright==\n\nThis document is placed in the public domain."
            }
        ],
        "thread_summary": {
            "title": "Datastream compression of Blocks and Transactions",
            "categories": [
                "bitcoin-dev",
                "BIP Draft"
            ],
            "authors": [
                "Peter Tschipper"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 14170
        }
    }
]