[
    {
        "title": "[bitcoin-dev] Signing CHECKSIG position in Tapscript",
        "thread_messages": [
            {
                "author": "Russell O'Connor",
                "date": "2019-12-01T16:09:54",
                "message_text_only": "On Thu, Nov 28, 2019 at 3:07 AM Anthony Towns <aj at erisian.com.au> wrote:\n\n> FWIW, there's discussion of this at\n> http://www.erisian.com.au/taproot-bip-review/log-2019-11-28.html#l-65\n>\n\nI think variants like signing the position of the enclosing\nOP_IF/OP_NOTIF/OP_ELSE of the OP_IF/OP_NOTIF/OP_ELSE block that the\nchecksig is within, or signing the byte offset instead of the opcode number\noffset are all fine.  In particular, signing the enclosing OP_IF... would\nallow sharing of the hashed signed data in a normal multisig sequence of\noperations.  Below I'll continue to refer to my proposal as signing the\nCHECKSIG position, but please take it to mean any of these proposed,\nsemantically equivalent, realizations of this idea.\n\nI also think that it is quite reasonable to have a sighash flag control\nwhether or not the signature covers the CHECKSIG position or not, with\nSIGHASH_ALL including the CHECKSIG position.\n\n\n> First, it seems like a bad idea for Alice to have put funds behind a\n> script she doesn't understand in the first place. There's plenty of\n> scripts that are analysable, so just not using ones that are too hard to\n> analyse sure seems like an option.\n>\n\nI don't think this is true in general.  When constructing a script it seems\nquite reasonable for one party to come to the table with their own custom\nscript that they want to use because they have some sort of 7-of-11 scheme\nbut in one of those cases is really a 2-of-3 and another is 5-of-6.  The\npoint is that you shouldn't need to decode their exact policy in order to\ncollaborate with them.  This notion is captured quite clearly in the MAST\naspect of taproot.  In many circumstances, it is sufficient for you to know\nthat there exists a branch that contains a particular script without need\nto know what every branch contains.  Because we include the tapleaf in the\nsignature, we already prevent this signature copying attack against\nattempts to transplant one's signature from one tapleaf to another.  My\nproposal is to simply extend this same protection to branches within a\nsingle tapscript.\n\nSecond, if there are many branches in the script, it's probably more\n> efficient to do them via different branches in the merkle tree, which\n> at least for this purpose would make them easier to analyse as well\n> (since you can analyse them independently).\n>\n\nOf course this should be done when practical.  This point isn't under\ndispute.\n\n\n> Third, if you are doing something crazy complex where a particular key\n> could appear in different CHECKSIG operators and they should have\n> independent signatures, that seems like you're at the level of\n> complexity where learning about CODESEPARATOR is a reasonable thing to\n> do.\n>\n\nSo while I agree that learning about CODESEPARATOR is a reasonable thing to\ndo, given that I haven't heard the CODESEPARATOR being proposed as\nprotection against this sort of signature-copying attack before and given\nthe subtle nature of the issue, I'm not sure people will know to use it to\nprotect themselves.  We should aim for a Script design that makes the\ncheaper default Script programming choices the safer one.\n\nOn the other hand, in a previous thread a while ago I was also arguing that\nsophisticated people are plausibly using CODESEPARATOR today, hidden away\nin unredeemed P2SH UTXOs.  So perhaps I'm right about at least one of these\ntwo points. :)\n\nI think CODESEPARATOR is a better solution to this problem anyway. In\n> particular, consider a \"leaf path root OP_MERKLEPATHVERIFY\" opcode,\n> and a script that says \"anyone in group A can spend if the preimage for\n> X is revelaed, anyone in group B can spend unconditionally\":\n>\n>  IF HASH160 x EQUALVERIFY groupa ELSE groupb ENDIF\n>  MERKLEPATHVERIFY CHECKSIG\n>\n> spendable by\n>\n>  siga keya path preimagex 1\n>\n> or\n>\n>  sigb keyb path 0\n>\n> With your proposed semantics, if my pubkey is in both groups, my signature\n> will sign for position 10, and still be valid on either path, even if\n> the signature commits to the CHECKSIG position.\n>\n> I could fix my script either by having two CHECKSIG opcodes (one for\n> each branch) and also duplicating the MERKLEPATHVERIFY; or I could\n> add a CODESEPARATOR in either IF branch.\n>\n\n> (Or I could just not reuse the exact same pubkey across groups; or I could\n> have two separate scripts: \"HASH160 x EQUALVERIFY groupa MERKLEPATHVERIFY\n> CHECKSIG\" and \"groupb MERKLEPATHVERIFY CHECKSIG\")\n>\n\nI admit my proposal doesn't automatically prevent this signature-copying\nattack against every Script template.  To be fully effective you need to be\naware of this signature-copying attack vector to ensure your scripts are\ndesigned so that your CHECKSIG operations are protected by being within the\nIF block that does the verification of the hash-preimage.  My thinking is\nthat my proposal is effective enough to save most people most of the time,\neven if it doesn't save everyone all the time, all while having no\nsignificant burden otherwise.  Therefore, I don't think your point that\nthere still exists a Script where a signature copying attack can be\nperformed is adequate by itself to dismiss my proposal.  However if you\nbelieve that if we don't save everyone all the time then there is no point\nin trying, or if you believe that signing the CHECKSIG position probably\nwill not protect most users most of the time, or if you believe the burden\non all the other cases is too great, then maybe it is better to rely on\npeople using CODESEPARATOR.\n\nGiven that MAST design of taproot greatly reduces this problem compared to\nlegacy script, I suppose you could argue that \"the burden on all the other\ncases is too great\" simply because you believe the problematic situation is\nnow extremely rare.\n\nI still think we ought to choose designs that are safer by default and\ninclude as much user intention within the signed data as we can reasonably\nget away, and use other sighash flags for those cases when we need to\nexclude data from the signature.\n\nIn particular, imagine a world where CODESEPARATOR never existed.  We have\nthis signature copying attack to deal with, and we are designing a new\nSegwit version in which we can now address the problem.  One proposal that\nsomeone comes up with is to sign the CHECKSIG position (or sign the\nenclosing OP_IF/OP_ELSE... position), maybe using a SIGHASH flag to\noptionally disable it.  Someone else comes up with a proposal to add new\n\"CODESEPARATOR\" opcode which requires adding a new piece of state to the\nScript interpreter (the only non-stack based piece of state) to track the\nlast executed CODESEPARATOR position and include that in the signature.\nWould you really prefer the CODESEPARATOR proposal?\n\n\n> > I believe that it would be safer, and less surprising to users, to\n> always sign\n> > the CHECKSIG position by default.\n>\n> > As a side benefit, we get to eliminate CODESEPARATOR, removing a fairly\n> awkward\n> > opcode from this script version.\n>\n> As it stands, ANYPREVOUTANYSCRIPT proposes to not sign the script code\n> (allowing the signature to be reused in different scripts) but does\n> continue signing the CODESEPARATOR position, allowing you to optionally\n> restrict how flexibly you can reuse signatures. That seems like a better\n> tradeoff than having ANYPREVOUTANYSCRIPT signatures commit to the CHECKSIG\n> position which would make it a fair bit harder to design scripts that\n> can share signatures, or not having any way to restrict which scripts\n> the signature could apply to other than changing the pubkey.\n>\n\nUm, I believe that signing the CODESEPERATOR position without signing the\nscript code is nonsensical.  You are talking about signing a piece of data\nwithout an interpretation of its meaning.\n\nRecall that originally CODESEPARTOR would let you sign a suffix of the\nScript program.  In the context of signing the whole script (which is\nalways signed indirectly as part of the txid in legacy signatures) signing\nthe offset into that scripts contains just as much information as signing a\nscript suffix, while being constant sized.  When you remove the Script from\nthe data being signed, signing an offset is no longer equivalent to signing\na Script suffix, and an offset into an unknown data structure is a\nmeaningless value by itself.  There is no way that you should be signing\nCODESEPARATOR position without also covering the Script with the signature.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191201/75cc9af7/attachment.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2019-12-03T08:35:38",
                "message_text_only": "On Sun, Dec 01, 2019 at 11:09:54AM -0500, Russell O'Connor wrote:\n> On Thu, Nov 28, 2019 at 3:07 AM Anthony Towns <aj at erisian.com.au> wrote:\n>     First, it seems like a bad idea for Alice to have put funds behind a\n>     script she doesn't understand in the first place. There's plenty of\n>     scripts that are analysable, so just not using ones that are too hard to\n>     analyse sure seems like an option.\n> I don't think this is true in general.\u00a0 When constructing a script it seems\n> quite reasonable for one party to come to the table with their own custom\n> script that they want to use because they have some sort of 7-of-11 scheme but\n> in one of those cases is really a 2-of-3 and another is 5-of-6.\u00a0 The point is\n> that you shouldn't need to decode their exact policy in order to collaborate\n> with them.\n\nHmm, I take the opposite lesson from your scenario -- it's only fine for\npeople to bring their own 2-of-3 or 5-of-6 or whatever and replace a\nsimple key if you've got something like miniscript where you understand\nthe script completely enough that you can be sure those changes are\nfine. \n\nFor contrast, with ECDSA and pre-miniscript, the above scenario might\nhave gone like someone proposing to change:\n\n  7 A B C1 C2 C3 C4 C5 C6 C7 C8 C9 11 CHECKMULTISIG\n\nfor something like\n\n  7\n  SWAP IF TOALT 2 A1 A2 A3 3 CHECKMULTISIGVERIFY FROMALT 1SUB ENDIF\n  SWAP IF TOALT 5 B1 B2 B3 B4 B5 B6 6 CHECKMULTISIGVERIFY FROMALT 1SUB ENDIF\n  C1 C2 C3 C4 C5 C6 C7 C8 C9 11 CHECKMULTISIG\n\nbut I think you'd want to be pretty sure you can decode those added\npolicies rather than just accepting it because your \"C4\" key is still\nthere. (In particular, any script fragment that uses an opcode that used\nto be OP_SUCCESS could have arbitrary effects on the script)\n\n[0]\n\n> This notion is captured quite clearly in the MAST aspect of\n> taproot. In many circumstances, it is sufficient for you to know that there\n> exists a branch that contains a particular script without need to know what\n> every branch contains.\n\n(I'm trying to avoid using MAST in the context of taproot, despite the\nbackronym, so please excuse the rephrasing--)\n\nI think if you're going to start using a taproot address with multiple\ntapscripts, either as a participant in a multiparty smart contract,\nor just to have different ways of spending your funds, then you do have\nto analyse all the branches to make sure there's no hidden \"all the\nmoney goes to the Lizard People\" script.\n\nOnce you've done that, you can then simplify things -- maybe some\nscripts are only useful for other participants in the contract, or maybe\nyou've got a few different hardware wallets and one only needs to know\nabout one branch, while the other only needs to know about some other\nbranch, but you still need to have done the analysis in the first place.\n\nOf course, probably most of the time that \"analysis\" is just making sure\nthe scripts match some well known, hardcoded template, as filled out\nwith various (tweaked) keys that you've checked elsewhere, but that\nstill ensures you know all the scripts do what you need them too.\n\n>     Third, if you are doing something crazy complex where a particular key\n>     could appear in different CHECKSIG operators and they should have\n>     independent signatures, that seems like you're at the level of\n>     complexity where learning about CODESEPARATOR is a reasonable thing to\n>     do.\n> So while I agree that learning about CODESEPARATOR is a reasonable thing to do,\n> given that I haven't heard the CODESEPARATOR being proposed as protection\n> against this sort of signature-copying attack before\n\nErr? The current behaviour of CODESEP with taproot was first discussed in\n[1], which summarised it as \"CODESEP -- lets you require different sigs\nfor different parts of a single script\" which seems to me like just a\ndifferent way of saying the same thing.\n\n[1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-November/016500.html\n\nI don't think tapscript's CODESEP or the current CODESEP can be used\nfor anything other than preventing a signature from being reused for a\ndifferent CHECKSIG operation on the same pubkey within the same script.\n\n> and given the subtle\n> nature of the issue, I'm not sure people will know to use it to protect\n> themselves.\u00a0 We should aim for a Script design that makes the cheaper default\n> Script programming choices the safer one.\n\nI think techniques like miniscript and having fixed templates specified\nin BIPs and BOLTs and the like are better approaches -- both let you\neasily allow a limited set of changes that can be safely made to a policy\n(maybe just substituting keys, hashes and times, maybe allowing more\ngeneral changes).\n\n> On the other hand, in a previous thread a while ago I was also arguing that\n> sophisticated people are plausibly using CODESEPARATOR today, hidden away in\n> unredeemed P2SH UTXOs.\u00a0 So perhaps I'm right about at least one of these two\n> points. :)\n\nSounds like an economics argument :)\n\n>     \u00a0IF HASH160 x EQUALVERIFY groupa ELSE groupb ENDIF\n>     \u00a0MERKLEPATHVERIFY CHECKSIG\n>     spendable by\n>     \u00a0siga keya path preimagex 1\n>     or\n>     \u00a0sigb keyb path 0\n> I admit my proposal doesn't automatically prevent this signature-copying attack\n> against every Script template.\n\nRight -- so if you're worried about this sort of attack, you need to\nanalyse your script to at least be sure that it's not one of these cases\nthat aren't covered. And if you've got to analyse the script anyway\n(which I think you do no matter what), then there's no benefit -- you're\neither doing something simple and you're using templates or miniscript\nto make the analysis easy; or you're doing something novel and complex,\nand you can probably cope with using CODESEP.\n\n(Ultimately I think there's only really two cases where you're\ncontributing a signature for a tx: either you're a party to the contract,\nand you should have fully analysed all the possible ways the utxo could\nbe spent to make sure the smart contract stuff is correctly implemented\nand you can't be cheated; or you're acting as an oracle or similar and\ndon't really care how the contract goes because you're not a party to\nit, in which case people reusing your signature as much as they like is\nfine. Hardware wallets don't need to analyse scripts they sign for, eg,\nbut that's only because for those cases where their owners have done\nthat first)\n\n> To be fully effective you need to be aware of\n> this signature-copying attack vector to ensure your scripts are designed so\n> that your CHECKSIG operations are protected by being within the IF block that\n> does the verification of the hash-preimage.\u00a0 My thinking is that my proposal is\n> effective enough to save most people most of the time, even if it doesn't save\n> everyone all the time, all while having no significant burden otherwise.\n\nI agree the burden's pretty minor; but I think having a single value\nfor the tx digest for each input for SIGHASH_ALL is kind-of nice for\nvalidation; and I think having to pass through a CHECKSIG position\neverytime you do a signature is likely to be annoying for implementors\nfor pretty much zero actual benefit.\n\n> Therefore, I don't think your point that there still exists a Script where a\n> signature copying attack can be performed is adequate by itself to dismiss my\n> proposal.\n\nI'm making two points with that example: (1) it's a case where if\nyou don't analyse the scripts somehow, you can still be vulnerable to\nthe attack with your change -- so your change doesn't let you avoid\nknowing what scripts do; but also (2) that CODESEP is a marginally more\nefficient/general fix the problem. Maybe (1) isn't too important,\nbecause even if it weren't true, I still think you need to know what all\nthe scripts do, but I think (2)'s still reelevant.\n\n> Given that MAST design of taproot greatly reduces this problem compared to\n> legacy script, I suppose you could argue that \"the burden on all the other\n> cases is too great\" simply because you believe the problematic situation is now\n> extremely rare.\n\nAs you aluded to in the previous mail; I think the problem's currently\nextremely rare and trivially avoidable because we don't really have any\nway of manipulating pubkeys -- there's no CAT, EC_ADD/EC_MUL/EC_TWEAK\nor MERKLEPATHVERIFY opcode (or actual Merkle Abstract Syntax Trees or\nOP_EXEC etc) to make it a dynamic concern rather than a static one.\n\n> In particular, imagine a world where CODESEPARATOR never existed.\u00a0 We have this\n> signature copying attack to deal with, and we are designing a new Segwit\n> version in which we can now address the problem.\u00a0 One proposal that someone\n> comes up with is to sign the CHECKSIG position (or sign the enclosing OP_IF/\n> OP_ELSE... position), maybe using a SIGHASH flag to optionally disable it.\u00a0\n> Someone else comes up with a proposal to add new \"CODESEPARATOR\" opcode which\n> requires adding a new piece of state to the Script interpreter (the only\n> non-stack based piece of state) to track the last executed CODESEPARATOR\n> position and include that in the signature.\u00a0 Would you really prefer the\n> CODESEPARATOR proposal?\n\nIf CODESEP had never existed, I think my first response would be to say\n\"well, just make sure you don't reuse pubkeys, and because each\nbip-schnorr sig commits to the pubkey, problem solved.\"\n\nThere's only two use cases I'm aware of, one is the ridiculous\nreveal-a-secret-key-by-forced-nonce-reuse script that's never actually\nbeen implemented [2] and ntumblebit's escrow script [3]. The first of\nthose requires pubkey recovery so doesn't work with bip-schnorr anyway;\nand it's not clear to me whether the second is really reason enough to\njustify a dedicated opcode/sighash/etc.\n\n[2] https://lists.linuxfoundation.org/pipermail/lightning-dev/2015-November/000363.html\n[3] https://github.com/NTumbleBit/NTumbleBit/blob/master/NTumbleBit/EscrowScriptBuilder.cs\n\nAn option would be to remove CODESEP and treat it as OP_SUCCESS -- that\nway it could be introduced later with pretty much the exact semantics\nthat are currently proposed; or with some more useful semantics. That\nway we could bring in whatever functionality was actually needed at the\nsame time as introducing CAT/EC_MUL/etc.\n\nBut my default position is to think that the way things currently work is\nmostly fine, and we should default ot just keeping the same functionality\n-- so SIGHASH_ALL doesn't do anything fancy, but CODESEP can be used to\nprevent sig reuse.\n\n>     > As a side benefit, we get to eliminate CODESEPARATOR, removing a fairly\n>     awkward\n>     > opcode from this script version.\n> \n>     As it stands, ANYPREVOUTANYSCRIPT proposes to not sign the script code\n>     (allowing the signature to be reused in different scripts) but does\n>     continue signing the CODESEPARATOR position, allowing you to optionally\n>     restrict how flexibly you can reuse signatures. That seems like a better\n>     tradeoff than having ANYPREVOUTANYSCRIPT signatures commit to the CHECKSIG\n>     position which would make it a fair bit harder to design scripts that\n>     can share signatures, or not having any way to restrict which scripts\n>     the signature could apply to other than changing the pubkey.\n\n> Recall that originally CODESEPARTOR would let you sign a suffix of the Script\n> program.\u00a0 In the context of signing the whole script (which is always signed\n> indirectly as part of the txid in legacy signatures) signing the offset into\n> that scripts contains just as much information as signing a script suffix,\n> while being constant sized.\u00a0 When you remove the Script from the data being\n> signed, signing an offset is no longer equivalent to signing a Script suffix,\n> and an offset into an unknown data structure is a meaningless value by itself.\u00a0\nThe tapscript implementation isn't intended to be equivalent to signing\na script suffix; all it does is add an index to the digest being signed\nso that signatures at different indexes are distinct. That it's\nequivalent to the current behaviour is definitely a feature, but I think\nthat's a surprising coincidence than a useful way of thinking about the\nactual usefulness of CODESEP in tapscript...\n\n[4]\n\n> Um, I believe that signing the CODESEPERATOR position without signing the\n> script code is nonsensical.\u00a0 You are talking about signing a piece of data\n> without an interpretation of its meaning.\n\nWith ANYPREVOUTANYSCRIPT, you're still differentiating signatures by\nindex, you just no longer also commit to any of the other details of\nthe script. That means you can't prevent your signature being reused in\nrandom other scripts someone else designs -- hence the \"ANYSCRIPT\" part --\nbut you can prevent any of your funds from going to those addresses, so\nthat's not really your problem anyway. What it does mean is that you can\nprevent your signature from being reused in different scripts you do know\nabout; eg you might have a UTXO with four different tapscript branches:\n\n     1) OP_1 CHECKSIG\n     2) CODESEP OP_1 CHECKSIGVERIFY HASH160 x EQUAL\n     3) n CLTV DROP CODESEP OP_1 CHECKSIGVERIFY\n     4) k CSV DROP CODESEP OP_1 CHECKSIGVERIFY\n\n(where OP_1 means using the taproot internal pubkey with support for\nANYPREVOUT*) -- that way a signature for either path (1) or (2) is only\nvalid for that path, but a signature for (3) can be reused for (4)\n(or vice-versa), but not (1) or (2); and all those signatures could\nbe reused for other corresponding scripts, for instance with different\nvalues for x,n,k if desired.\n\n> There is no way that you should be signing CODESEPARATOR position without also\n> covering the Script with the signature.\n\nSo I think it's more sensible than it seems; and still plausible enough\nto leave in. If you don't want to separate your ANYPREVOUT scripts,\nyou can just not put a CODESEP in -- or at least only put CODESEP after\nall your ANYPREVOUT CHECKSIGs; so it doesn't seem like it's creating\nany added complexity.\n\nCheers,\naj\n\n[0] For what it's worth, there's another reason not to allow replacing\n    keys in a threshold sig with different policies: if you've got say\n    30 people with a majority threshold of 16, then you could two groups\n    of 9 people form parties and each agree to all vote along party lines;\n    but if you let them replace their keys with multisig policies along\n    those lines, you're now enforcing a 10-of-30 policy instead (as long\n    as the 10 are 5 from the first party and 5 from the second party)\n    and allowing minority control instead of majority rule.\n\n[4] I wonder if it would be worth exploring whether we could do\n    something more like the original (presumed) intent of CODESEP, given\n    use of NOINPUT/ANYPREVOUT so as not to commit to the full script,\n    you could potentially have a SIGHASH that committed to a hash of\n    the script that's been executed so far, and also the witness data\n    that's been consumed so far, but it would ensure the first part of\n    the script behaved exactly as you expected, and allow the rest of\n    the script to be arbitrarily weird, and (I think) be efficiently\n    implementable. That doesn't give you delegation without the ability\n    to also have executable witness data of some sort, but maybe something\n    like it is interesting anyway?"
            },
            {
                "author": "Russell O'Connor",
                "date": "2019-12-05T20:24:46",
                "message_text_only": "After chatting with andytoshi and others, and some more thinking I've been\nconvinced that my specific concern about other users masquerading other\npeople pubkeys as their own in complex scripts is actually a non-issue.\n\nNo matter what you write in Script (today), you are limited to expressing\nsome policy that is logically equivalent to a set of conditions and\nsignatures on pubkeys that can be expressed in disjunctive normal form.  We\ncan write such a policy as\n\n(C[1] && PK[1,1] && ... && PK[1,m[1]]) || ... || (C[n] && PK[n,1] && ... &&\nPK[n,m[n]])\n\nwhere C[i] is some conjunction of conditions such as timelock constraints,\nor hash-lock constraints or any other kind of proof of publication, and\nwhere PK[i,j] is a requirement of a signature against a specific public key.\n\n>From Alice's point of view, she can divide set of clauses under the\ndisjunction into those that contain a pubkey that she considers (partially)\nunder her control and those clauses that she does not control (even though\nas we shall see those other keys might actually be under Alice's control,\nunbeknownst to her). To that end, let us consider a specific representative\npolicy.\n\n    (C[1] && APK[1]) || (C[2] && APK[2] && BPK[2]) || (C[3] && BPK[3])\n\nwhere Alice considers herself in control of APK[1] and APK[2], and where\nshe considers Bob in control of BPK[2] and BPK[3] and where C[1], C[2], and\nC[3] are different conditions, let's say three different hash-locks.  We\nwill also say that Alice has ensured that her pubkeys in different clauses\nare different (i.e. APK[1] != APK[2]), but she doesn't make any such\nassumption for Bob's keys and neither will we.\n\nWhen Alice funded this Script, or otherwise accepted it for consideration,\nshe agreed that she wouldn't control the redemption of the UTXO as long as\nthe preimage for C[3] is published.  In particular, Alice doesn't even need\nto fully decode the Script semantics for that clause beyond determining\nthat it enforces the C[3] requirement that she cares about. Even if Bob was\nmasquerading Alice's pubkey as his own (as in BPK[3] = APK[1] or BPK[3] =\nAPK[2]), and he ends up copying her signature into that clause, Alice ends\nup with C[3] published as she originally accepted as a possibility.  Bob\nmasquerading Alice's pubkey as his own only serves to hamper his own\nability to sign for his clauses (I mean, Bob might be trying to convince\nsome third party that Alice signed for something she didn't actually sign\nfor, but such misrepresentations of the meaning of digital signatures is\noutside our scope and this just serves as a reminder not to be deceived by\nBob's tricks here).\n\nAnd the same argument holds for BPK[2].  Even if BPK[2] = APK[1] and Bob\ntries to copy Alice's signature into the C[2] condition, he still needs a\ncountersignature with her APK[2], so Alice remains in control of that\nclause.  And if BPK[2] = APK[2] then Bob can only copy Alice's signature on\nthe C[2] condition, but in that case she has already authorised that\ncondition.  Again, Bob masquerading Alice's pubkey as his own only serves\nto hamper his own ability to sign for his clauses.\n\nSo what makes our potential issue here safe, versus the dangers that would\nhappen in <https://bitcoin.stackexchange.com/a/85665/49364> where Bob\nmasqurades Alice's UTXO as his own?  The key problem in the UTXO case isn't\nso much Bob masquerading Alice's pubkey as his own, as it is an issue with\nAlice reusing her pubkeys and Bob taking advantage of that.  We do, in\nfact, have exactly the same issue in Script.  If Alice were to reuse\npubkeys such that APK[1] = APK[2], then Bob could take her signature for\nC[1] and transplant it to redeem under condition C[2].  We see that it is\nimperative that Alice ensures that she doesn't reuse pubkeys that she\nconsiders under her control for different conditions when she wants her\nsignature to distinguish between them.\n\nFor various reasons, some historical, it is much harder to avoid pubkey\nreuse for different UTXOs than it is to avoid pubkey reuse within a single\nscript.  We often use Bitcoin addresses in non-interactive ways, such as\nputting them on flyers or painting them on walls and such.  Without a\nstandard for tweaking such pubkeys in a per-transaction way, we end up with\na lot of pubkey reuse between various UTXOs.  However, within a Script,\navoiding pubkey reuse ought to be easier.  Alice must communicate different\npubkeys intended for different clauses, or if Bob is constructing a whole\ncomplex script on Alice's behalf, he may need to add CODESEPARATORs if\ntweaking Alice's pubkey isn't an option.\n\nThe conversion of a policy to disjunctive normal form can involve an\nexponential blowup (see <\nhttps://en.wikipedia.org/wiki/Disjunctive_normal_form#Conversion_to_DNF>).\nFor instance, if Alice's policy (not in disjunctive normal form) is of the\nform\n\n    (C[1] || D[1]) && ... && (C[n] || D[n]) && APK\n\nwhere C[i] and D[i] are all distinct hashlocks, we require O(2^n) clauses\nto put it in disjunctive normal form.  If Alice wants to create signatures\nthat are restricted to a specific combination of C[i]'s and D[i]'s, she\nneeds to use an exponential number of pubkeys, which isn't tractable to do\nin Script.  But neither my original proposal nor CODESEPARATOR helps in\nthis case either because CODESEPARATOR can mark only the last executed\nposition.  Taproot's MAST (Merklized Alternative Script Tree per aj's\nsuggestion), can maybe provide a tractable solution to this in cases where\nit is applicable.  The MAST is always a disjunction and because the tapleaf\nis signed, it is safe to reuse pubkeys between alternative branches.\n\nThis analysis suggests that we should amend CODESEPARATORs behaviour to\nupdate an accumulator (presumably a running hash value), so that all\nexecuted CODESEPARATOR positions end up covered by the signature.  That\nwould provide a solution to the above problem for those cases where\ntaproot's MAST cannot be used.  I'm not sure if it is better to propose\nsuch an amendment to CODESEPARATOR's behaviour now, or to propose to\nsoft-fork in such optional behaviour at a later time.\n\nHowever, what I said above was even too simplified.  In general, a policy\nof the form.\n\n    (Exists w[1]. C[1](w[1]) && PK[1,1](w[1]) && ... && PK[1,m[1]](w[1]) ||\n... || (Exists w[n]. C[n](w[n]) && PK[n,1](w[n]) && ... && PK[n,m[n]](w[n]))\n\nwhere each term could possibly be parameterized by some witness value\n(though at the moment there isn't enough functionality in Script to\nparameterize the pubkeys in any reasonably way and it maybe isn't even\npossible to parameterise the conditions in any reasonable way).  In\ngeneral, you might want your signature to cover (some function of) this\nwitness value.  This suggests that we would actually want a CODESEPARATOR\nvariant that pushes a stack item into the accumulator that gets covered by\nthe signature rather than pushing the CODESEPARATOR position.  Though at\nthis point the name CODESEPARATOR is probably not suitable, even if it\nsubsumes the functionality.  Again, I'm not sure if it is better to propose\nsuch a replacement for CODESEPARATOR's behaviour now, or to propose to\nsoft-fork in such optional behaviour at a later time.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191205/5dc3e915/attachment-0001.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2019-12-06T04:51:53",
                "message_text_only": "On Thu, Dec 05, 2019 at 03:24:46PM -0500, Russell O'Connor wrote:\n\nThanks for the careful write up! That matches what I was thinking.\n\n> This analysis suggests that we should amend CODESEPARATORs behaviour to update\n> an accumulator (presumably a running hash value), so that all executed\n> CODESEPARATOR positions end up covered by the signature.\n\nOn IRC, gmaxwell suggests \"OP_BREADCRUMB\" as a name for (something like)\nthis functionality.\n\n(I think it's a barely plausible stretch to use the name \"CODESEPARATOR\"\nfor marking a position in the script -- that separates what was before\nand after, at least; anything more general seems like it warrants a\nbetter name though)\n\n> That would provide a\n> solution to the above problem for those cases where taproot's MAST cannot be\n> used.\u00a0 I'm not sure if it is better to propose such an amendment to\n> CODESEPARATOR's behaviour now, or to propose to soft-fork in such optional\n> behaviour at a later time.\n> However, what I said above was even too simplified.\u00a0 \n\nFWIW, I think it's too soon to propose this because (a) it's not clear\nthere's a practical need for it, (b) it's not clear the functionality is\nquite right (opcode vs more automatic sighash flag?), and (c) as you say,\nit's not clear it's powerful enough.\n\n> In general, a policy of the form.\n> \u00a0\u00a0\u00a0 (Exists w[1]. C[1](w[1]) && PK[1,1](w[1]) && ... && PK[1,m[1]](w[1]) || ...\n> || (Exists w[n]. C[n](w[n]) && PK[n,1](w[n]) && ... && PK[n,m[n]](w[n]))\n> where each term could possibly be parameterized by some witness value (though\n> at the moment there isn't enough functionality in Script to parameterize the\n> pubkeys in any reasonably way and it maybe isn't even possible to parameterise\n> the conditions in any reasonable way).\u00a0 In general, you might want your\n> signature to cover (some function of) this witness value.\u00a0 This suggests that\n> we would actually want a CODESEPARATOR variant that pushes a stack item into\n> the accumulator that gets covered by the signature rather than pushing the\n> CODESEPARATOR position.\u00a0 Though at this point the name CODESEPARATOR is\n> probably not suitable, even if it subsumes the functionality.\n\n> Again, I'm not\n> sure if it is better to propose such a replacement for CODESEPARATOR's\n> behaviour now, or to propose to soft-fork in such optional behaviour at a later\n> time.\n\nLast bit first, it seems pretty clear to me that this is too novel an\nidea to propose it immediately -- we should explore the problem space\nmore first to see what's the best way of doing it before coding it into\nconsensus. And (guessing) I think the tapscript upgrade methods should\nbe fine for handling this later.\n\nI think the annex is also not general enough for what you're thinking\nhere, in that it wouldn't allow for one signature to constrain the witness\ndata more than some other signature -- so you'd need to determine all\nthe constraints for all signatures to finish filling out the annex,\nand could only then start signing.\n\nI think you could conceivably do any/all of:\n\n * commit to a hash of all the witness data that hasn't been popped off\n   the stack (\"suffix\" commitment -- the data will be used by later script\n   opcodes)\n * commit to a hash of all the witness data that has been popped off the\n   stack (\"prefix\" commitment -- this is the data that's been used by\n   earlier script opcodes)\n * commit to the hash of the current stack\n\nThat would be expensive, but still doable as O(1) per opcode / stack\nelement. I think any other masking would mean you'd have potentially\nO(size of witness data) or O(size of stack) runtime per signature which\nI think would be unacceptable...\n\nI guess a general implementation to at least think about the possibilities\nmight be an \"OP_DATACOMMIT\" opcode that pops an element from the stack,\ndoes hash_\"DataCommit\"(element), and then any later signatures commit\nto that value (maybe with OP_0 OP_DATACOMMIT allowing you to get back to\nthe default state). You'd either need to write your script carefully to\ncommit to witness data you're using elsewhere, or have some other new\nopcodes to do that more conveniently...\n\nCODESEP at position \"x\" in the script is equivalent to \"<x> DATACOMMIT\"\nhere, I think. \"BREADCRUMB .. BREADCRUMB\" could be something like:\n\n   OP_0 TOALT [at start of script]\n   ..\n   FROMALT x CAT SHA256 DUP TOALT DATACOMMIT   \n   ..\n   FROMALT y CAT SHA256 DUP TOALT DATACOMMIT   \n\nif the altstack was otherwise unused, I guess; so the accumulator\nbehaviour probably warrants something better.\n\nIt also more or less gives you CHECKSIGFROMSTACK behaviour by doing\n\"SWAP OP_DATACOMMIT OP_CHECKSIG\" and a SIGHASH_NONE|ANYPREVOUTANYSCRIPT\nsignature.\n\nBut that seems like a plausible generalisation to think about?\n\nCheers,\naj"
            }
        ],
        "thread_summary": {
            "title": "Signing CHECKSIG position in Tapscript",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Russell O'Connor",
                "Anthony Towns"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 35826
        }
    },
    {
        "title": "[bitcoin-dev] Composable MuSig",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2019-12-02T02:05:01",
                "message_text_only": "Good morning Lloyd, and list,\n\n> Just a quick note: I think there is a way to commit to a point properly with Pedersen commitments. Consider the following:\n> COM(X) = (y*G + z*H, y*G\u00a0+ X)\u00a0 where y and z are random and the opening is (y,z,X).\u00a0 This seems to be a\u00a0 unconditionally hiding and computationally binding homomorphic commitment scheme to a point based on the DL problem rather than DDH.\n\nSo the Pedersen commitment commits to a tweak on `X`, which is revealed later so we can un-tweak `X`.\nAm I correct in assuming that you propose to use `X` for the contribution to `R` for a participant?\nHow is it different from using ElGamal commitments?\n\n\n-------\n\n\nSome number of people have noted, including at least one MuSig author, that in the ElGamal case it would be possible to prove your knowledge of the `q` behind `q * G`, and thus prevent the cancellation attack shown.\nWe already have a general proof-of-knowledge-of-secret-key, the Schnorr signature signing algorithm itself.\n\nThus, together with `q * G` in the ElGamal commitment, we could include a Schnorr signature using `q * G`, either of the target message itself, or any constant string.\n\nThis seems highly appropriate, yo dawg, I heard you like MuSig, so I put an aggregate in your aggregate, so you could sign (singly) while you sign (multiply).\n\nIn terms of a *composable* MuSig, e.g. MuSig(MuSig(A, B), C), both A and B will select `q[a]` and `q[b]` and will generate a shared `q[ab] * G` as the MuSig of `q[a] * G` and `q[b] * G`.\nSince they know the corresponding `q[a]` and `q[b]` they will also known the contributions they each will need to generate `q[ab] * H`, but note that there is no proof of this until they reveal `q[a]` and `q[b]`, which may lead to further attacks, this time on `q[ab] * H` instead.\nSo at least for `q` it seems not to be a good idea, though I have not put much thought into this.\n\nIndeed, it seems to me that signatures using the contributions `R[a]` and `R[b]` as public keys seems to be another way to commit to `R` while ensuring that your own `R` cannot have cancelled the other participant `R`.\nYou would have to exchange the (single) signatures of `R[a]` and `R[b]` first, however, otherwise a Wagner attack may be possible if you exchange `R[a]` and `R[b]` first (i.e. the signatures replace the `R` commitment phase of 3-phase MuSig).\n\nThe complexity of either sign-while-you-sign idea, however, is much greater.\nYour signing algorithm now requires delegating to another signing algorithm, which while at least fair in that you are now signing while you sign because you aggregated while you aggregated, is more complicated to implement practically.\n\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Lloyd Fournier",
                "date": "2019-12-02T03:30:26",
                "message_text_only": "Hi ZmnSCPxj,\n\n> > Just a quick note: I think there is a way to commit to a point properly with Pedersen commitments. Consider the following:\n> > COM(X) = (y*G + z*H, y*G + X)  where y and z are random and the opening is (y,z,X).  This seems to be a  unconditionally hiding and computationally binding homomorphic commitment scheme to a point based on the DL problem rather than DDH.\n>\n> So the Pedersen commitment commits to a tweak on `X`, which is revealed later so we can un-tweak `X`.\n> Am I correct in assuming that you propose to use `X` for the contribution to `R` for a participant?\n> How is it different from using ElGamal commitments?\n\nYes. It's not significantly different. It is unconditionally hiding\nrather than binding (ElGamal is unconditionally binding). I just\nthought of it while reading your post so I mentioned it. The real\nquestion is what properties does the commitment scheme need to be\nappropriate for MuSig R coin tossing?\nIn the security proof, the commitment hash is modelled as a random\noracle rather than as an abstract commitment scheme. I wonder if any\nMuSig author has an opinion on whether the H_com interaction can be\ngeneralised to a commitment scheme with certain properties (e.g\nequivocal, extractable). By the looks of it, the random oracle is\nnever explicitly programmed except with randomly generated values so\nmaybe there is hope that a non ROM commitment scheme can do the job. I\nguess the reduction would then be to either breaking the discrete\nlogarithm problem OR some property of the commitment scheme.\n\nCheers,\n\nLL"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-12-08T01:15:51",
                "message_text_only": "Good morning Lloyd,\n\n> The real\n> question is what properties does the commitment scheme need to be\n> appropriate for MuSig R coin tossing?\n\nIt seems to me that what is needed for a composable MuSig is to have a commitment scheme which is composable.\n\nLet me define a composable commitment scheme:\n\nGiven:\n\n* `A` and `B`, two points to be committed to.\n* `c[A]` and `c[B]`, commitments to the above points respectively.\n* `r[A]` and `r[B]`, openings of the above commitments respectively.\n\nThen a composable commitment scheme must have these operations:\n\n* `ComposeCommitments(c[A], c[B])`, which returns a commitment to the point `A + B`.\n* `ComposeOpenings(r[A], r[B])`, which returns an opening of the above commitment to the point `A + B`.\n\nMy multi-`R` proposal is a composable commitment scheme:\n\n* A commitment `c[A]` is the list `{h(A)}` where `h()` is some hash function.\n* `ComposeCommitments(c[A], c[B])` is the concatenation on lists of hashes of points.\n* An opening `r[A]` is the list `{A}`.\n* `ComposeOpenings(r[A], r[B])` is the concatenation on lists of points.\n\nThe property we want to have, is that:\n\n* There must not exist some operation `NegateCommitment(c[A])`, such that:\n  * `ComposeCommitments(ComposeCommitments(c[B], NegateCommitment(c[A])), c[A]) == c[B]`.\n\nMy multi-`R` proposal works as a composable commitment scheme appropriate for composable MuSig because there is no way to create an input to a concatenation operation such that the concatenation operation becomes a \"search and delete\" operation.\nPedersen and ElGamal commitments, I think, cannot work here, because commitments in those schemes are negatable in such a way that composing the commitments allows a commitment to be cancelled.\n\n-----\n\nLet us now turn to signature schemes.\nI conjecture that the Schnorr and ECDSA signature schemes are also commitment schemes on points.\n\nTo create a commitment `c[A]` on the point A, such that `A = a * G`, the committer:\n\n* Generates random scalars `r` and `m`.\n* Computes `R` as `r * G`.\n* Computes `s` as `r + h(R | m) * a`.\n* Gives `c[A]` as the tuple `(R, s)`.\n\nThe opening `r[A]` of the above is then the tuple `(m, A)`.\nThe verifier then validates that the commitment was indeed to the point `A` by doing the below:\n\n* Computes `S[validator]` as `R + h(R | m) * A`.\n* Validates that `S[validator] == s * G`.\n\nNow, we know that signatures can be composed in such a way that points (public keys) cannot be cancelled, i.e. preventing the creation of a `NegateCommitment()` operation.\nThus, a signature can be used as a composable commitment in composable MuSig scheme.\n\nIn summary, I conjecture that:\n\n* We need a composable commitment scheme that does not allow cancellation, and any such commitment scheme can be \"slotted\" into the 3-phase MuSig framework.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Lloyd Fournier",
                "date": "2019-12-08T06:10:00",
                "message_text_only": "Hi ZmnSCPxj,\n\nI think you're idea of allowing multiple Rs is a fine solution as it\nwould essentially mean that you were just doing a three party MuSig\nwith more specific communication structure. As you mentioned, this is\nnot quite ideal though.\n\n> It seems to me that what is needed for a composable MuSig is to have a commitment scheme which is composable.\n\nMaybe. Showing certain attacks don't work is a first step. It would\ntake some deeper analysis of the security model to figure out what\nexactly the MuSig requires of the commitment scheme.\n\n> To create a commitment `c[A]` on the point A, such that `A = a * G`, the committer:\n>\n> * Generates random scalars `r` and `m`.\n> * Computes `R` as `r * G`.\n> * Computes `s` as `r + h(R | m) * a`.\n> * Gives `c[A]` as the tuple `(R, s)`.\n\nThis doesn't look binding. It's easy to find another ((A,a),m) which\nwould validate against (R,s). Just choose m and choose a = (s - r)\nh(R||m)^-1.\n\nCheers,\n\nLL"
            }
        ],
        "thread_summary": {
            "title": "Composable MuSig",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Lloyd Fournier"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 8005
        }
    },
    {
        "title": "[bitcoin-dev] easypaysy - A layer-two protocol to send payments without addresses",
        "thread_messages": [
            {
                "author": "Jose Femenias",
                "date": "2019-12-02T14:00:57",
                "message_text_only": "An HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191202/764f28cf/attachment.html>"
            },
            {
                "author": "Tim Blokdijk",
                "date": "2019-12-02T17:27:21",
                "message_text_only": "Hello Jos\u00e9,\n\nJust a quick question, this is fully decentralized?\n\nGreetings,\n\nTim Blokdijk\n\nOp 02-12-19 om 15:00 schreef Jose Femenias via bitcoin-dev:\n> Hi,\n>\n> I have just released an early preview of easypaysy, a protocol for \n> Bitcoin, that I have been working on for the past few months.\n>\n> (In case you are wondering, easypaysy stands for EASY - PAYment- \n> SYstem...)\n>\n> Long story short, easypaysy is a layer-two protocol that allows the \n> creation of non-custodial accounts directly on the blockchain, so that \n> bitcoin addresses can fully disappear from the user experience.\n> In lieu of addresses, users send payments to permanent account IDs.\n>\n> Account IDs are implicitly assigned by the mining process, and come in \n> several flavors, like in these examples:\n>\n> Canonical ID: btc at 543847.636/577\n> Mnemonic ID: btc at cancel-mind.exhibit/motion\n> Domain ID: btc at example.com/motion-custom\n>\n> (Note: Domain IDs are optional and require extra configuration)\n>\n> The protocol allows both interactive and non interactive payments.\n> All payments are non-repudiable, and it is possible to implement \n> pull-payments as well as chargebacks.\n>\n> Most of the protocol is quite advanced, but I have refrained from \n> specifying some of the details, until the interested parties can give \n> their feedback.\n>\n> For more information, you can see the white paper and a short \n> introductory video at:\n>\n> https://www.easypaysy.org\n>\n> or directly, by following these links:\n>\n> White paper at https://www.easypaysy.org/assets/easypaysy_white_paper.pdf\n> Introductory video at https://www.youtube.com/watch?v=AOGBdyZbyoA\n>\n> You can also get in contact with me in at:\n>\n> jose.femenias at gmail.com\n>\n> or using the project's email at:\n>\n> easypaysy at gmail.com\n>\n> Best regards.\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191202/dcda1fd1/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-12-02T21:10:19",
                "message_text_only": "Good morning Tim, and Jose,\n\n> Just a quick question, this is fully decentralized?\n>\n\nIt broadcasts information over `OP_RETURN` on the blockchain layer, thus decentralized as long as the blockchain layer is decentralized.\nIt also means that to register an account, you need to either own some Bitcoins, or rent some Bitcoins to serve as signalling (and then potentially have to change your account identifier later when the lease expires).\n`OP_RETURN` does have size limits (imposed by `isStandard`), I do not remember exact numbers, and any data would need to fit.\nFinally, use of the blockchain layer is costly; given that payees must be online at any time payers wish to pay, it may do better to just use Lightning instead, which has the same requirement, but moves payments to a separate layer as well, and requires only a single onchain transaction to construct a channel (easypaysy seems to require at least 2, one to anchor the account pubkeys, the other to give the basic \"activation\" information for the account).\n\nIt may be useful to consider defiads, which does *not* use `OP_RETURN`, but instead uses pay-to-contract, and sends the advertisement data over a separate overlay network.\nThe use-case is mildly different, but ultimately defiads is about connecting potential buyers to potential sellers, and sending data about how to get paid would have to be part and parcel of how defiads ultimately works.\n\nAlso, one of the contact-information protocols supported should probably be Tor hidden services, instead of `https`.\nTor hidden services have better useability (no need for port forwarding or registering DNS from some centralized service), with privacy as a bonus.\n\nFurther it seems insufficient to only encode block and tx index.\nI think it should also encode output index, to also allow a single transaction to anchor multiple accounts.\nAlso consider using the Lightning encoding of identifying an output: 543847x636x2\n\n\nRegards,\nZmnSCPxj\n\n\n> Greetings,\n>\n> Tim Blokdijk\n>\n> Op 02-12-19 om 15:00 schreef Jose Femenias via bitcoin-dev:\n>\n> > Hi,\n> >\n> > I have just released an early preview of easypaysy, a protocol for Bitcoin, that I have been working on for the past few months.\n> >\n> > (In case you are wondering, easypaysy stands for EASY - PAYment- SYstem...)\n> >\n> > Long story short, easypaysy is a layer-two protocol that allows the creation of non-custodial accounts directly on the blockchain, so that bitcoin addresses can fully disappear from the user experience.\n> > In lieu of addresses, users send payments to permanent account IDs.\n> >\n> > Account IDs are implicitly assigned by the mining process, and come in several flavors, like in these examples:\n> >\n> > Canonical ID:\u00a0\u00a0\u00a0 btc at 543847.636/577\n> > Mnemonic ID:\u00a0\u00a0\u00a0 btc at cancel-mind.exhibit/motion\n> > Domain ID:\u00a0\u00a0\u00a0 btc at example.com/motion-custom\n> >\n> > (Note: Domain IDs are optional and require extra configuration)\n> >\n> > The protocol allows both interactive and non interactive payments.\n> > All payments are non-repudiable, and it is possible to implement pull-payments as well as chargebacks.\n> >\n> > Most of the protocol is quite advanced, but I have refrained from specifying some of the details, until the interested parties can give their feedback.\n> >\n> > For more information, you can see the white paper and a short introductory video at:\n> >\n> > https://www.easypaysy.org\n> >\n> > or directly, by following these links:\n> >\n> > White paper at https://www.easypaysy.org/assets/easypaysy_white_paper.pdf\n> > Introductory video at https://www.youtube.com/watch?v=AOGBdyZbyoA\n> >\n> > You can also get in contact with me in at:\n> >\n> > jose.femenias at gmail.com\n> >\n> > or using the project's email at:\n> >\n> > easypaysy at gmail.com\n> >\n> > Best regards.\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Jose Femen\u00edas Ca\u00f1uelo",
                "date": "2019-12-02T21:25:01",
                "message_text_only": "> Hello Jos\u00e9,\n> \n> Just a quick question, this is fully decentralized?\n> Greetings,\n> \n> Tim Blokdijk\n\n\nTim,\n\nit is fully decentralized indeed. \nEvery user is in charge of creating and maintaining his own account.\n\nRegards,\n\nJos\u00e9 Femen\u00edas\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191202/469e02ff/attachment.html>"
            },
            {
                "author": "Jose Femen\u00edas Ca\u00f1uelo",
                "date": "2019-12-05T20:00:03",
                "message_text_only": "Hi ZmnSCPxj\n\nfirst of all, excuse me for my delayed answer. \n\nI think I posted to the wrong address the first time (I\u2019m mainly a lurker in the list, so I make gotchas like that\u2026)\n\nLet me address your points.\n\n> It also means that to register an account, you need to either own some Bitcoins, or rent some Bitcoins to serve as signalling (and then potentially have to change your account identifier later when the lease expires). \n\nI don\u2019t understand what you mean by \u2018renting\u2019 Bitcoins. \nOnce you commit the account transaction, the account ID never changes.\n(Also, you don\u2019t need to own Bitcoins if you use a Master Easypaysy Account. See my comments later on).\n\n\n\n> Finally, use of the blockchain layer is costly; given that payees must be online at any time payers wish to pay, it may do better to just use Lightning instead,\n\nThat is not the case. \nWhen using non-interactive payments, the payee doesn\u2019t need to be online at all.\nEven for interactive payments, it depends on the protocol you use.\n\nFor Bitmessage, or email, or even MQTT you don\u2019t need to be online simultaneously. (The interactive protocol(s) is still open, however, those are just some hypothetical examples):\n\nAnyway, when using interactive payments, the payee has the option to specify an LN invoice and/or a bitcoin address.\n\n\n\n> which has the same requirement, but moves payments to a separate layer as well, and requires only a single onchain transaction to construct a channel (easypaysy seems to require at least 2, one to anchor the account pubkeys, the other to give the basic \"activation\" information for the account). \n\nEasypaysy accounts don\u2019t need 2 TXs. They need funding plus a TX for the account information itself.\nSo, you need an UTXO -to fund the account- and a TX. \nBut the UTXO can be one of many in the same transaction. \nSo, you could fund multiple accounts with a single TX.\n\n\n> Also, one of the contact-information protocols supported should probably be Tor hidden services, instead of `https`. Tor hidden services have better useability (no need for port forwarding or registering DNS from some centralized service), with privacy as a bonus. \nEasypaysy is protocol agnostic (for now). So, Tor is definitely a possibility.\n\n\n> Further it seems insufficient to only encode block and tx index. I think it should also encode output index, to also allow a single transaction to anchor multiple accounts. Also consider using the Lightning encoding of identifying an output: 543847x636x2 \nThere is really no need to specify an additional output.\nIf I am right, you can\u2019t have more than one OP_RETURN per transaction.\n\nOn the other hand, as you can see in the white paper \u201c4.2 Master accounts\u201d, these type of accounts allow for up to 2048 accounts per transaction.\n\nThe format of the ID in this case is: btc at master_idx.slave_id/checksum\n\nThe master_idx is an ordinal pointer (not positional) to the Master TX, while the slave_id points to one of the 2048 transactions within the account (whose information is stored elsewhere, protected by a Merkle root committed in the Master Tx)\n\nThere is a little bit more to it that seems appropriate to discuss here, please have a look at page 25 of the white paper.\n\nThanks for your input.\n\n\nBest regards,\n\nJos\u00e9 Femen\u00edas"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-12-06T02:53:34",
                "message_text_only": "Good morning Jose,\n\n\n> > It also means that to register an account, you need to either own some Bitcoins, or rent some Bitcoins to serve as signalling (and then potentially have to change your account identifier later when the lease expires).\n>\n> I don\u2019t understand what you mean by \u2018renting\u2019 Bitcoins.\n> Once you commit the account transaction, the account ID never changes.\n> (Also, you don\u2019t need to own Bitcoins if you use a Master Easypaysy Account. See my comments later on).\n\nIf you have 0 Bitcoins, you need to have *some* Bitcoins from somewhere else (perhaps a service provider) in order to back the initial funding transaction output.\nIf you create Master Easypaysy account by paying fiat to some service provider that then uses its Bitcoins to fund your Easypaysy account, but requires some sort of shared control over the money in it, I simply call this \"renting\" the Bitcoin, as presumably the service provider would want to get its coins back from you.\n\nIf you are referring to the use of a service provider, then the service provider at least partially controls your account and if it ceases to exist or refuses to continue doing business with you, you need to transfer your account identifier somehow (i.e. end of lease).\n\n>\n> > Finally, use of the blockchain layer is costly; given that payees must be online at any time payers wish to pay, it may do better to just use Lightning instead,\n>\n> That is not the case.\n> When using non-interactive payments, the payee doesn\u2019t need to be online at all.\n> Even for interactive payments, it depends on the protocol you use.\n>\n> For Bitmessage, or email, or even MQTT you don\u2019t need to be online simultaneously. (The interactive protocol(s) is still open, however, those are just some hypothetical examples):\n\nYou could indicate use of some kind of pay-to-contract, then have the payer send the contract text to the payee so that the payee can claim the funds later.\n\n> Anyway, when using interactive payments, the payee has the option to specify an LN invoice and/or a bitcoin address.\n>\n> > which has the same requirement, but moves payments to a separate layer as well, and requires only a single onchain transaction to construct a channel (easypaysy seems to require at least 2, one to anchor the account pubkeys, the other to give the basic \"activation\" information for the account).\n>\n> Easypaysy accounts don\u2019t need 2 TXs. They need funding plus a TX for the account information itself.\n> So, you need an UTXO -to fund the account- and a TX.\n\nYes, that is why I count it as 2 transactions: one transaction to host the funding UTXO that is referred to in the account identifier, and the other transaction is what broadcasts the account information (in particular, the funding UTXO is a P2SH and the transaction that spends it is the one that reveals the 2 pubkeys you require).\n\nIn contrast, Lightning Network requires only the funding UTXO (which requires that short channel IDs include the transaction output index, as a single funding transaction can fund multiple Lightning Network channels).\n\n> But the UTXO can be one of many in the same transaction.\n> So, you could fund multiple accounts with a single TX.\n\nSo can Lightning Network channels: multiple channels can be funded by a single funding transactions (C-Lightning supports this, but not as a single command yet, it requires some low-level fiddling).\n\n> > Also, one of the contact-information protocols supported should probably be Tor hidden services, instead of `https`. Tor hidden services have better useability (no need for port forwarding or registering DNS from some centralized service), with privacy as a bonus.\n>\n> Easypaysy is protocol agnostic (for now). So, Tor is definitely a possibility.\n\nI suggest being Tor-centric instead.\n\n>\n> > Further it seems insufficient to only encode block and tx index. I think it should also encode output index, to also allow a single transaction to anchor multiple accounts. Also consider using the Lightning encoding of identifying an output: 543847x636x2\n>\n> There is really no need to specify an additional output.\n> If I am right, you can\u2019t have more than one OP_RETURN per transaction.\n\nThis does not mesh with your earlier claim:\n\n> But the UTXO can be one of many in the same transaction.\n\nMy understanding is that the account identifier refers to the funding TXO (and funding transactions do not have an `OP_RETURN`, so I fail to see the relevance of that restriction).\nIf the funding transaction can have many UTXOs that are individually funding TXOs of multiple Easypaysy accounts, then you need to refer to *which* TXO of that funding transaction is what you are using.\n\n>\n> On the other hand, as you can see in the white paper \u201c4.2 Master accounts\u201d, these type of accounts allow for up to 2048 accounts per transaction.\n>\n> The format of the ID in this case is: btc at master_idx.slave_id/checksum\n>\n> The master_idx is an ordinal pointer (not positional) to the Master TX, while the slave_id points to one of the 2048 transactions within the account (whose information is stored elsewhere, protected by a Merkle root committed in the Master Tx)\n>\n> There is a little bit more to it that seems appropriate to discuss here, please have a look at page 25 of the white paper.\n\nWhy would it not be appropriate?\n\nIn case of such a \"Master TX\", would it be possible for each slave to be independently controlled by a different party?\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Jose Femen\u00edas Ca\u00f1uelo",
                "date": "2019-12-06T07:56:52",
                "message_text_only": "Hi ZmnSCPxj,\n\nfirst of all: do you ever sleep?    ;-)\n\n\nA few points about your reply:\n\na) The easypaysy white paper isn\u2019t a final set of specifications. \nInstead it is meant as a somewhat detailed draft of the ideas that can drive a working set of specifications.\nAs such, any qualified input -as in your case- is much welcome, since it can greatly help with the process.\n\n\n\nb) Master accounts are included in the white paper as a feature for a future release. \nThe roadmap is not set yet, but I\u2019d like to include a first release of the protocol that only covers the most basic features, to make it simpler and safer for wallet developers. \nMaster accounts aren\u2019t a priority, since they are more oriented towards scaling the proposal, and that is far from being a problem yet. \nSo, this feature is not well defined for now. However, as presented in the white paper, the \u2018service provider\u2019 has really no control over your money.\n\nHe would basically do a just a few things: \n\n- Aggregate the account info (up to 2048 individual accounts per master account).\n- Hash every account info, sort them, and calculate the Merkle root of a tree containing them all.\n- Create a JSON document containing the information of all the sub-accounts included in the pack.\n- Make that JSON document publicly available, probably with a https: URL (That\u2019s called an Authoritative server)\n- Finally, create and publish a TX that contains a pointer to the Authoritative server, and the Merkle root of the set of accounts.\n\nThe service provider would have NO control whatsoever of your funds, nor can he block payments, etc.\nThere is some sort of delegation, but no trust involved here. The Merkle root protects agains any attempt of tampering with the account data.\n\nThe account\u2019s TX won\u2019t ever disappear from the blockchain, so your account info will always be there.\nWorst case scenario, the service provider disappears and users can\u2019t download the Json document containing your account information.\n\nTo mitigate this issue, the white paper suggests the creation of mirror servers.\n\nPage 27\n---------\n'The risk that the authoritative server designated within the EASYPAYSY_MASTER_ACCOUNT_DESCRIPTOR could become unavailable can be mitigated with the use of mirror servers.\u2019\n...\n'It is conceivable that the mirror could charge for this service, perhaps requiring a small LN payment per request, so there will be an economic incentive to preserve the information associated with every master account ever published into the blockchain.\u2019\n\n\n\nc) I am a BIG fan of the Lightning network (see the example before). I wouldn\u2019t like to sound as easypaysy promotes on-chain payments vs LN payments.\nI still think there is room for both. I guess and hope that LN payments will grow exponentially in the future. \nHowever, some large transactions and a few other uses cases will probably make more sense on-chain.\n\n\n\nd) Regarding your comments on the possibility of adding the output index in the account ID, I still don\u2019t see the need for the use case of easypaysy (since, by definition, easypaysy accounts must have exactly one input and two outputs).\n*** However ***, your idea is sound and I can see some use cases for both pointing to the input and output of a TX.\nIn fact, the seed for easypaysy is some work I did previously, called \u2018Bitcoin pointers\u2019 (you can search the dev list for the link).\nIn there, I proposed a fuller set of features for a TX-ID, including both pointing to the input and the output of a TX.\n\nThis is an excerpt from the document on canonical pointers:\n\n'It is also possible to refer to an input: and/or  :output within a transaction. \nIn our example, the canonical pointers that point to the first input and the second output of that  transaction are, respectively:\n\n\tbtc at 0:170.1/028-588-872 and btc at 170.1:1/413-851-608'\n\nAdditionally, the specs allow for the use of attributes; quoting again:\n\n'btc at 170.1:1/179_address should return 12cbQLTFMXRnSzktFkuoG3eHoMeFtpTu3S, which is the address of the second output of that transaction\u2019.\n\n\n\ne) The white paper barely touches the implications the easypaysy protocol could have for the Lightning Network, other than citing the possibility of receiving an LN invoice within the Payment reply document.\nI didn\u2019t really have neither the time, nor the expertise required to explore further applicability for LN, although I can imagine some use cases.\nI know you are quite the expert on LN issues, so if you would like to contribute your suggestions on how to shape the protocol in this regard, I will very much welcome your contributions.\n\nIf you are interested, please contact me, preferably privately since I wouldn\u2019t want to become much too off topic in this dev-list\n\nThanks again for your comments.\n\nRegards,\n\n\nJose Femenias\n\njose.femenias at gmail.com\nwww.easypaysy.org\n\n\n\n> On 6 Dec 2019, at 03:53, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n> \n> Good morning Jose,\n> \n> \n>>> It also means that to register an account, you need to either own some Bitcoins, or rent some Bitcoins to serve as signalling (and then potentially have to change your account identifier later when the lease expires).\n>> \n>> I don\u2019t understand what you mean by \u2018renting\u2019 Bitcoins.\n>> Once you commit the account transaction, the account ID never changes.\n>> (Also, you don\u2019t need to own Bitcoins if you use a Master Easypaysy Account. See my comments later on).\n> \n> If you have 0 Bitcoins, you need to have *some* Bitcoins from somewhere else (perhaps a service provider) in order to back the initial funding transaction output.\n> If you create Master Easypaysy account by paying fiat to some service provider that then uses its Bitcoins to fund your Easypaysy account, but requires some sort of shared control over the money in it, I simply call this \"renting\" the Bitcoin, as presumably the service provider would want to get its coins back from you.\n> \n> If you are referring to the use of a service provider, then the service provider at least partially controls your account and if it ceases to exist or refuses to continue doing business with you, you need to transfer your account identifier somehow (i.e. end of lease).\n> \n>> \n>>> Finally, use of the blockchain layer is costly; given that payees must be online at any time payers wish to pay, it may do better to just use Lightning instead,\n>> \n>> That is not the case.\n>> When using non-interactive payments, the payee doesn\u2019t need to be online at all.\n>> Even for interactive payments, it depends on the protocol you use.\n>> \n>> For Bitmessage, or email, or even MQTT you don\u2019t need to be online simultaneously. (The interactive protocol(s) is still open, however, those are just some hypothetical examples):\n> \n> You could indicate use of some kind of pay-to-contract, then have the payer send the contract text to the payee so that the payee can claim the funds later.\n> \n>> Anyway, when using interactive payments, the payee has the option to specify an LN invoice and/or a bitcoin address.\n>> \n>>> which has the same requirement, but moves payments to a separate layer as well, and requires only a single onchain transaction to construct a channel (easypaysy seems to require at least 2, one to anchor the account pubkeys, the other to give the basic \"activation\" information for the account).\n>> \n>> Easypaysy accounts don\u2019t need 2 TXs. They need funding plus a TX for the account information itself.\n>> So, you need an UTXO -to fund the account- and a TX.\n> \n> Yes, that is why I count it as 2 transactions: one transaction to host the funding UTXO that is referred to in the account identifier, and the other transaction is what broadcasts the account information (in particular, the funding UTXO is a P2SH and the transaction that spends it is the one that reveals the 2 pubkeys you require).\n> \n> In contrast, Lightning Network requires only the funding UTXO (which requires that short channel IDs include the transaction output index, as a single funding transaction can fund multiple Lightning Network channels).\n> \n>> But the UTXO can be one of many in the same transaction.\n>> So, you could fund multiple accounts with a single TX.\n> \n> So can Lightning Network channels: multiple channels can be funded by a single funding transactions (C-Lightning supports this, but not as a single command yet, it requires some low-level fiddling).\n> \n>>> Also, one of the contact-information protocols supported should probably be Tor hidden services, instead of `https`. Tor hidden services have better useability (no need for port forwarding or registering DNS from some centralized service), with privacy as a bonus.\n>> \n>> Easypaysy is protocol agnostic (for now). So, Tor is definitely a possibility.\n> \n> I suggest being Tor-centric instead.\n> \n>> \n>>> Further it seems insufficient to only encode block and tx index. I think it should also encode output index, to also allow a single transaction to anchor multiple accounts. Also consider using the Lightning encoding of identifying an output: 543847x636x2\n>> \n>> There is really no need to specify an additional output.\n>> If I am right, you can\u2019t have more than one OP_RETURN per transaction.\n> \n> This does not mesh with your earlier claim:\n> \n>> But the UTXO can be one of many in the same transaction.\n> \n> My understanding is that the account identifier refers to the funding TXO (and funding transactions do not have an `OP_RETURN`, so I fail to see the relevance of that restriction).\n> If the funding transaction can have many UTXOs that are individually funding TXOs of multiple Easypaysy accounts, then you need to refer to *which* TXO of that funding transaction is what you are using.\n> \n>> \n>> On the other hand, as you can see in the white paper \u201c4.2 Master accounts\u201d, these type of accounts allow for up to 2048 accounts per transaction.\n>> \n>> The format of the ID in this case is: btc at master_idx.slave_id/checksum\n>> \n>> The master_idx is an ordinal pointer (not positional) to the Master TX, while the slave_id points to one of the 2048 transactions within the account (whose information is stored elsewhere, protected by a Merkle root committed in the Master Tx)\n>> \n>> There is a little bit more to it that seems appropriate to discuss here, please have a look at page 25 of the white paper.\n> \n> Why would it not be appropriate?\n> \n> In case of such a \"Master TX\", would it be possible for each slave to be independently controlled by a different party?\n> \n> \n> Regards,\n> ZmnSCPxj"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-12-06T17:16:44",
                "message_text_only": "Good morning Jose,\n\n> Hi ZmnSCPxj,\n>\n> first of all: do you ever sleep? ;-)\n\nIt seems possible, that, I do not.\n\n\n> b) Master accounts are included in the white paper as a feature for a future release.\n> The roadmap is not set yet, but I\u2019d like to include a first release of the protocol that only covers the most basic features, to make it simpler and safer for wallet developers.\n> Master accounts aren\u2019t a priority, since they are more oriented towards scaling the proposal, and that is far from being a problem yet.\n> So, this feature is not well defined for now. However, as presented in the white paper, the \u2018service provider\u2019 has really no control over your money.\n>\n> He would basically do a just a few things:\n>\n> -   Aggregate the account info (up to 2048 individual accounts per master account).\n> -   Hash every account info, sort them, and calculate the Merkle root of a tree containing them all.\n> -   Create a JSON document containing the information of all the sub-accounts included in the pack.\n> -   Make that JSON document publicly available, probably with a https: URL (That\u2019s called an Authoritative server)\n> -   Finally, create and publish a TX that contains a pointer to the Authoritative server, and the Merkle root of the set of accounts.\n>\n>     The service provider would have NO control whatsoever of your funds, nor can he block payments, etc.\n>     There is some sort of delegation, but no trust involved here. The Merkle root protects agains any attempt of tampering with the account data.\n\nThis does not seem to mesh well with the other non-Master parts of the protocol, where further updates on the single account backed by a funding TXO are performed by spending the funding TXO and creating a transaction with `OP_RETURN`.\n\nIn addition, I would like to suggest as well that instead of `OP_RETURN`, you could instead use \"sign-to-contract\".\n\nSign-to-contract is simply that, when signing, instead of selecting a random `r` and computing `R` as `R = r * G`, you select a random `r` and a contract or other message `c`, and compute `R` as `R = r * G + h((r * G) | c) * G`.\nThen the user can provide the message `c` independently of the signature, via another mechanism, and reveal `r * G` and `c` and point to the signature as a commitment to the message `c`.\nAlthough, it does have the drawback that using sign-to-contract require a different layer / overlay network to broadcast messages `c`, but it does reduce the cost on the blockchain layer, which is always a good thing.\nSimilar issues are faced by the RGB project, for instance, and defiads explicitly uses a separate overlay network when transmitting advertisements (both RGB and defiads use the opposite pay-to-contract, which tweaks the pubkey rather than the ephemeral `R`).\n\n>\n>     The account\u2019s TX won\u2019t ever disappear from the blockchain, so your account info will always be there.\n>     Worst case scenario, the service provider disappears and users can\u2019t download the Json document containing your account information.\n>\n>     To mitigate this issue, the white paper suggests the creation of mirror servers.\n\nHow about control transactions on top of the funding txo?\nWho is able to make further control transactions?\nIf the service provider gives the user full control of the control transactions on top of the funding txo, then it outright loses the money it put in the funding txo and might as well operate as a full exchange.\nIf the service provider retains even partial control, then it can refuse to cooperate with the user and the user will be unable to update his or her account.\n\nThis is not fixable by the use of mirror servers.\n\n\n> d) Regarding your comments on the possibility of adding the output index in the account ID, I still don\u2019t see the need for the use case of easypaysy (since, by definition, easypaysy accounts must have exactly one input and two outputs).\n\nDo you mean, that if the user makes a control transaction to change the details of the account, then the user is forced to change the easypaysy identifier?\n\nMy initial reading of your whitepaper is that the easypaysy identifier refers to the funding txo that roots the further control transactions.\nIf so, the funding txo is not necessarily a one-input two-output transaction.\nIf not, then each time a control transaction changes the details of the easypaysy identifier, the identifier itself is changed.0\n\n\n> If you are interested, please contact me, preferably privately since I wouldn\u2019t want to become much too off topic in this dev-list\n\nI still do not see why it would be off-topic to the devlist.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Jose Femen\u00edas Ca\u00f1uelo",
                "date": "2019-12-06T18:47:38",
                "message_text_only": "Hi ZmnSCPxj,\n\n\n>> It seems possible, that, I do not.\n\nHaha, I\u2019am starting to believe that\u2019s not a joke ...\n\n\n>> \n>> This does not seem to mesh well with the other non-Master parts of the protocol, where further updates on the single account backed by a funding TXO are performed by spending the funding TXO and creating a transaction with `OP_RETURN`.\n>> \n>> \n\n\nYou are right. The lifecycle of a regular easypaysy account states that you spend its TXO circularly as many times as you want, specifying changes in its OP_RETURN (you can\u2019t change the Identity or Value key).\nWhen you want to revoke an account, you simply spend its last update (if any) to a different address (not the one it was funded originally with).\n\n\n> How about control transactions on top of the funding txo?\n> Who is able to make further control transactions?\n> If the service provider gives the user full control of the control transactions on top of the funding txo, then it outright loses the money it put in the funding txo and might as well operate as a full exchange.\n\nNope, he will keep control of the TXO keys.\n\n\n> If the service provider retains even partial control, then it can refuse to cooperate with the user and the user will be unable to update his or her account.\n> \n> This is not fixable by the use of mirror servers.\n\nYou are right about that too\u2026 (I wonder if some kind of MAST smart contract could fix this, maybe you have a suggestion for this; I am thinking K of M users can override the service provider if he misbehaves)\n\nWhat I have in mind, but haven\u2019t completely figured out, in case of an uncooperative service provider -or just because one user decides to fly solo- is the possibility for a sub-account to \u2018detach\u2019 itself from the master account.\n\nThe sub-account holder would do so by:\n\na) Funding the multisig 2-of-2 address composed of his Id_key + Value_key, included in the common JSON file, not the Master TX. (And yes, in this event he will need to buy some btc, because life is hard...)\nb) Publishing his own update, much like a regular easypaysy account does.\n\nIn any case, the account ID never changes, it would always keep pointing to the original place where it appeared on the blockchain. \nUser wallets would have to query for the multisig address of a particular account to check whether the account is detached or not.\n\nAs as side note, I expect most easypaysy accounts to choose only non-interactive payments, since they have fewer requirements than their interactive counterparts; so -in most cases- the majority of users won\u2019t ever have to update their accounts.\n\nSo, even if the \u2018service provider\u2019 goes away or becomes uncooperative, it is just business as usual for the sub-account owners, and they can work just fine with the mirrors.\n\n(Again, all of these is speculative for now. I hope scalability will become an issue for easypaysy one day, but I think we\u2019ll have time to work out the best solution by then)\n\n\n\n>> In addition, I would like to suggest as well that instead of `OP_RETURN`, you could instead use \"sign-to-contract\u201d\u2026.\n\nI really need to study this further before I can express an informed opinion on your suggestion.\n\nOn the other hand, for Master accounts I don\u2019t think cost or space should be a problem, since both can be shared among up to 2048 sub-accounts.\nFor regular accounts, it could be.\n\nBut, based on the private feedback I am having from two prominent figures in the space, making sure the protocol is easy to implement for SPV wallets is essential to encourage wallet adoption.\nA separate transport layer doesn\u2019t fit well with this. \n\nSo, maybe your suggestion will become more applicable in future iterations of the protocol. I may request your help for further clarification about this issue, if you are so kind (as you always are).\n\n\n>> d) Regarding your comments on the possibility of adding the output index in the account ID, I still don\u2019t see the need for the use case of easypaysy (since, by definition, easypaysy accounts must have exactly one input and two outputs).\n> \n> Do you mean, that if the user makes a control transaction to change the details of the account, then the user is forced to change the easypaysy identifier?\n> \n> My initial reading of your whitepaper is that the easypaysy identifier refers to the funding txo that roots the further control transactions.\n> If so, the funding txo is not necessarily a one-input two-output transaction.\n> \n\nThe easypaysy identifier doesn\u2019t point to the funding TXO. Instead it points to the first transaction that spends the funding TXO (the TX with the OP_RETURN containing the \u2018Rendezvous descriptor\u2019)\nSo, you are right in that the funding TXO doesn\u2019t need to be a one-input, two-output transaction.\n\n> If not, then each time a control transaction changes the details of the easypaysy identifier, the identifier itself is changed.\n\nNope. The easypaysy identifier always points the placement in the blockchain of the first transaction that spends the funding TXO, not the TXO itself (please read page 3, \u20182.3 Account ID\u2019).\nFurther updates (performed by spending its single non-zero output to the same address) must be verified by wallets (by asking for the payment history of the funding address; but they never change the account ID, by convention).\n\nSo, for example, (I\u2019m following the example in page 13 of the white paper):\n\na) TX #3b00367\u20264af, in block 859253, that has j outputs and k outputs, has an output (k) that sends funds to the 2-of-2 multisig address \u20183NhgE9\u2026bqs\u2019. \n   This is the address that the Identity_key + Value_key can spend.\n\nb) Several blocks later, TX #2a01fe\u2026aab2, in its single input, spends the TXO with another TXO the same address \u20183NhgE9\u2026bqs\u2019. \n   It sends all of the funds (minus the fee) in its first output (the 2nd is the OP_RETURN).\n   This TX (called the ep_root_tx in the protocol) appears in block 859368 at, let\u2019s say position 349. So its permanent ID will be (obviating the checksum): \n   \n   btc at 859368.349\n\n   This is the ID you share with your potential payers. Whenever they want to send funds to you, they will look up the 349th transaction at block 859368. \n   They don\u2019t need to check the funding TX at all. They only have to check the signature of the ep_root_tx, because that\u2019s the part of the TX where they can find both the Identity_key and the Value_key.\n   Since this TX, by definition of the protocol, can only have a single input, there will be a single signature in it, so there is no need for its easypaysy ID to include a pointer to the input in the TX.\n\n\nc) A few more blocks later, appears TX #72f1ed\u2026bade8 a similar 1-input 2-output TX, that updates its OP_RETURN with a new \u2018Rendezvous descriptor\u2019 (in the example, it changes the email endpoint)\nd) Finally, the user revokes the account by spending the output in c) to a different address (17He...A45n).\n\n\n>> If you are interested, please contact me, preferably privately since I wouldn\u2019t want to become much too off topic in this dev-list\n> \n> I still do not see why it would be off-topic to the devlist.\n\nSince the easypaysy proposal is about a layer-2 protocol, I am not sure the developers in this list want to see this much detail about something that maybe doesn\u2019t affect them at all.\nHopefully I am wrong and this is relevant for many of the list subscribers.\n\nAgain, thanks for your time and contributions.\n\nBest regards,\n\nJose\n\n\n> On 6 Dec 2019, at 18:16, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n> \n> Good morning Jose,\n> \n>> Hi ZmnSCPxj,\n>> \n>> first of all: do you ever sleep? ;-)\n> \n> It seems possible, that, I do not.\n> \n> \n>> b) Master accounts are included in the white paper as a feature for a future release.\n>> The roadmap is not set yet, but I\u2019d like to include a first release of the protocol that only covers the most basic features, to make it simpler and safer for wallet developers.\n>> Master accounts aren\u2019t a priority, since they are more oriented towards scaling the proposal, and that is far from being a problem yet.\n>> So, this feature is not well defined for now. However, as presented in the white paper, the \u2018service provider\u2019 has really no control over your money.\n>> \n>> He would basically do a just a few things:\n>> \n>> -   Aggregate the account info (up to 2048 individual accounts per master account).\n>> -   Hash every account info, sort them, and calculate the Merkle root of a tree containing them all.\n>> -   Create a JSON document containing the information of all the sub-accounts included in the pack.\n>> -   Make that JSON document publicly available, probably with a https: URL (That\u2019s called an Authoritative server)\n>> -   Finally, create and publish a TX that contains a pointer to the Authoritative server, and the Merkle root of the set of accounts.\n>> \n>>    The service provider would have NO control whatsoever of your funds, nor can he block payments, etc.\n>>    There is some sort of delegation, but no trust involved here. The Merkle root protects agains any attempt of tampering with the account data.\n> \n> This does not seem to mesh well with the other non-Master parts of the protocol, where further updates on the single account backed by a funding TXO are performed by spending the funding TXO and creating a transaction with `OP_RETURN`.\n> \n> In addition, I would like to suggest as well that instead of `OP_RETURN`, you could instead use \"sign-to-contract\".\n> \n> Sign-to-contract is simply that, when signing, instead of selecting a random `r` and computing `R` as `R = r * G`, you select a random `r` and a contract or other message `c`, and compute `R` as `R = r * G + h((r * G) | c) * G`.\n> Then the user can provide the message `c` independently of the signature, via another mechanism, and reveal `r * G` and `c` and point to the signature as a commitment to the message `c`.\n> Although, it does have the drawback that using sign-to-contract require a different layer / overlay network to broadcast messages `c`, but it does reduce the cost on the blockchain layer, which is always a good thing.\n> Similar issues are faced by the RGB project, for instance, and defiads explicitly uses a separate overlay network when transmitting advertisements (both RGB and defiads use the opposite pay-to-contract, which tweaks the pubkey rather than the ephemeral `R`).\n> \n>> \n>>    The account\u2019s TX won\u2019t ever disappear from the blockchain, so your account info will always be there.\n>>    Worst case scenario, the service provider disappears and users can\u2019t download the Json document containing your account information.\n>> \n>>    To mitigate this issue, the white paper suggests the creation of mirror servers.\n> \n> How about control transactions on top of the funding txo?\n> Who is able to make further control transactions?\n> If the service provider gives the user full control of the control transactions on top of the funding txo, then it outright loses the money it put in the funding txo and might as well operate as a full exchange.\n> If the service provider retains even partial control, then it can refuse to cooperate with the user and the user will be unable to update his or her account.\n> \n> This is not fixable by the use of mirror servers.\n> \n> \n>> d) Regarding your comments on the possibility of adding the output index in the account ID, I still don\u2019t see the need for the use case of easypaysy (since, by definition, easypaysy accounts must have exactly one input and two outputs).\n> \n> Do you mean, that if the user makes a control transaction to change the details of the account, then the user is forced to change the easypaysy identifier?\n> \n> My initial reading of your whitepaper is that the easypaysy identifier refers to the funding txo that roots the further control transactions.\n> If so, the funding txo is not necessarily a one-input two-output transaction.\n> If not, then each time a control transaction changes the details of the easypaysy identifier, the identifier itself is changed.0\n> \n> \n>> If you are interested, please contact me, preferably privately since I wouldn\u2019t want to become much too off topic in this dev-list\n> \n> I still do not see why it would be off-topic to the devlist.\n> \n> Regards,\n> ZmnSCPxj\n\n\n\n> On 6 Dec 2019, at 18:16, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n> \n> Good morning Jose,\n> \n>> Hi ZmnSCPxj,\n>> \n>> first of all: do you ever sleep? ;-)\n> \n> It seems possible, that, I do not.\n> \n> \n>> b) Master accounts are included in the white paper as a feature for a future release.\n>> The roadmap is not set yet, but I\u2019d like to include a first release of the protocol that only covers the most basic features, to make it simpler and safer for wallet developers.\n>> Master accounts aren\u2019t a priority, since they are more oriented towards scaling the proposal, and that is far from being a problem yet.\n>> So, this feature is not well defined for now. However, as presented in the white paper, the \u2018service provider\u2019 has really no control over your money.\n>> \n>> He would basically do a just a few things:\n>> \n>> -   Aggregate the account info (up to 2048 individual accounts per master account).\n>> -   Hash every account info, sort them, and calculate the Merkle root of a tree containing them all.\n>> -   Create a JSON document containing the information of all the sub-accounts included in the pack.\n>> -   Make that JSON document publicly available, probably with a https: URL (That\u2019s called an Authoritative server)\n>> -   Finally, create and publish a TX that contains a pointer to the Authoritative server, and the Merkle root of the set of accounts.\n>> \n>>    The service provider would have NO control whatsoever of your funds, nor can he block payments, etc.\n>>    There is some sort of delegation, but no trust involved here. The Merkle root protects agains any attempt of tampering with the account data.\n> \n> This does not seem to mesh well with the other non-Master parts of the protocol, where further updates on the single account backed by a funding TXO are performed by spending the funding TXO and creating a transaction with `OP_RETURN`.\n> \n> In addition, I would like to suggest as well that instead of `OP_RETURN`, you could instead use \"sign-to-contract\".\n> \n> Sign-to-contract is simply that, when signing, instead of selecting a random `r` and computing `R` as `R = r * G`, you select a random `r` and a contract or other message `c`, and compute `R` as `R = r * G + h((r * G) | c) * G`.\n> Then the user can provide the message `c` independently of the signature, via another mechanism, and reveal `r * G` and `c` and point to the signature as a commitment to the message `c`.\n> Although, it does have the drawback that using sign-to-contract require a different layer / overlay network to broadcast messages `c`, but it does reduce the cost on the blockchain layer, which is always a good thing.\n> Similar issues are faced by the RGB project, for instance, and defiads explicitly uses a separate overlay network when transmitting advertisements (both RGB and defiads use the opposite pay-to-contract, which tweaks the pubkey rather than the ephemeral `R`).\n> \n>> \n>>    The account\u2019s TX won\u2019t ever disappear from the blockchain, so your account info will always be there.\n>>    Worst case scenario, the service provider disappears and users can\u2019t download the Json document containing your account information.\n>> \n>>    To mitigate this issue, the white paper suggests the creation of mirror servers.\n> \n> How about control transactions on top of the funding txo?\n> Who is able to make further control transactions?\n> If the service provider gives the user full control of the control transactions on top of the funding txo, then it outright loses the money it put in the funding txo and might as well operate as a full exchange.\n> If the service provider retains even partial control, then it can refuse to cooperate with the user and the user will be unable to update his or her account.\n> \n> This is not fixable by the use of mirror servers.\n> \n> \n>> d) Regarding your comments on the possibility of adding the output index in the account ID, I still don\u2019t see the need for the use case of easypaysy (since, by definition, easypaysy accounts must have exactly one input and two outputs).\n> \n> Do you mean, that if the user makes a control transaction to change the details of the account, then the user is forced to change the easypaysy identifier?\n> \n> My initial reading of your whitepaper is that the easypaysy identifier refers to the funding txo that roots the further control transactions.\n> If so, the funding txo is not necessarily a one-input two-output transaction.\n> If not, then each time a control transaction changes the details of the easypaysy identifier, the identifier itself is changed.0\n> \n> \n>> If you are interested, please contact me, preferably privately since I wouldn\u2019t want to become much too off topic in this dev-list\n> \n> I still do not see why it would be off-topic to the devlist.\n> \n> Regards,\n> ZmnSCPxj\n>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-12-07T04:09:52",
                "message_text_only": "Good morning Jose,\n\n\n\n\n> > If the service provider retains even partial control, then it can refuse to cooperate with the user and the user will be unable to update his or her account.\n> > This is not fixable by the use of mirror servers.\n>\n> You are right about that too\u2026 (I wonder if some kind of MAST smart contract could fix this, maybe you have a suggestion for this; I am thinking K of M users can override the service provider if he misbehaves)\n\nSybils are trivial, and a \"quorum\" of K users can always be manufactured for a targeted attack.\nFar better to use an n-of-n, with the service provider as one of the n, and use pre-signed transactions like in Lightning Network to allow unilateral ending of the agreement.\n\n> What I have in mind, but haven\u2019t completely figured out, in case of an uncooperative service provider -or just because one user decides to fly solo- is the possibility for a sub-account to \u2018detach\u2019 itself from the master account.\n\nA \"graftroot transform\" can be done, at the cost of moving data offchain and thus requiring easypaysy to have its own overlay network.\nBasically, one commits onchain (via `OP_RETURN`, sign-to-contract, pay-to-contract, or even just using P2PKH) some public key and a series of `R` values.\nThen, control messages are authorized by signatures validated with the public key, and use up individual `R`s in the series of `R` values.\n(Alternately we commit just to the public key and a \"next\" `R` value, and each control message indicates a new public key and next `R` value that is signed with the current public key and \"current\" `R` value, to form a chain of off-blockchain control messages.)\n\nHaving a precommitted series of `R` values ensures that the signer can only safely use an `R` once and thus cannot otherwise attack the network by giving half of it one control message and the other half a conflicting control message: if someone does so, the `R` must be reused between both conflicting control messages and this allows trivial revelation of the private key (i.e. a form of single-use-seal).\nPresumably the private key is valuable by itself somehow.\n\n> But, based on the private feedback I am having from two prominent figures in the space, making sure the protocol is easy to implement for SPV wallets is essential to encourage wallet adoption.\n> A separate transport layer doesn\u2019t fit well with this.\n\nIndeed.\n\n>\n> So, maybe your suggestion will become more applicable in future iterations of the protocol. I may request your help for further clarification about this issue, if you are so kind (as you always are).\n>\n> > > d) Regarding your comments on the possibility of adding the output index in the account ID, I still don\u2019t see the need for the use case of easypaysy (since, by definition, easypaysy accounts must have exactly one input and two outputs).\n> >\n> > Do you mean, that if the user makes a control transaction to change the details of the account, then the user is forced to change the easypaysy identifier?\n> > My initial reading of your whitepaper is that the easypaysy identifier refers to the funding txo that roots the further control transactions.\n> > If so, the funding txo is not necessarily a one-input two-output transaction.\n>\n> The easypaysy identifier doesn\u2019t point to the funding TXO. Instead it points to the first transaction that spends the funding TXO (the TX with the OP_RETURN containing the \u2018Rendezvous descriptor\u2019)\n\nAh, I see my misunderstanding now.\n\nRegards,\nZmnSCPXj"
            }
        ],
        "thread_summary": {
            "title": "easypaysy - A layer-two protocol to send payments without addresses",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Tim Blokdijk",
                "Jose Femenias",
                "Jose Femen\u00edas Ca\u00f1uelo",
                "ZmnSCPxj"
            ],
            "messages_count": 10,
            "total_messages_chars_count": 50838
        }
    },
    {
        "title": "[bitcoin-dev] Reducing energy consumption and increasing security at the same time",
        "thread_messages": [
            {
                "author": "Cheng Wang",
                "date": "2019-12-08T10:43:49",
                "message_text_only": "Hi Everyone,\n\nI would like to share my serious work on reducing the energy consumption of\nPoW without sacrificing security. My new type of algorithm is called PoLW.\nFor a practical system where mining is profitable, PoLW could actually\nimprove the security of the system.\n\nThe idea is to shift part of the external cost of mining in the physical\nworld (mainly energy consumption) to the internal cost of the network. In\nPoLW, the miners are able to give up part of the coinbase reward so as to\nget weight (> 1) for the block hash they produce. The total cost of\ngenerating a new block would still be equal to maximal coinbase reward in\nequilibrium.\n\nI analyzed two algorithms in the paper: linear PoLW and exponential PoLW.\nLinear PoLW could reduce energy consumption by a factor close to 1/2 in\nequilibrium, while exponential PoLW could reduce energy consumption by an\narbitrary factor in equilibrium.\n\nIn a practical system, mining is usually (if not always) profitable. If we\ntransition from PoW to PoLW, the external costs of mining would decrease\nand the internal costs will increase. However, the decrease in external\ncosts would be less than the increase in internal costs since mining is\nprofitable. The total cost of block generation would get higher, therefore,\nthe security will increase.\n\nOf course, we could not decrease the external costs of any existing system\nby a factor close to zero immediately. There is a section in my paper\ndiscussing this particularly. The principle of applying PoLW is that\nkeeping the absolute external cost increasing all the time, but the\npercentage of external cost in the total cost gets lower eventually.\n\nThis work is based on solid math calculation, and I am looking forward to\nfeedback and discussions. My paper is available at:\nhttps://github.com/alephium/research/raw/master/polw.pdf\n\nIt's inspired by the recent great paper of Itay, Alexander, and Ittay:\nhttps://arxiv.org/abs/1911.04124\n\nBest,\nCheng Wang\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191208/023a43f6/attachment-0001.html>"
            },
            {
                "author": "Runchao Han",
                "date": "2019-12-09T00:45:27",
                "message_text_only": "Hi Cheng,\n\nThis is an interesting proposal!\nWhile the incentive analysis is sound, I have two concerns:\n\n## What if a guy keeps mining easy blocks to launch 51% attacks?\n\nWith PoLW, a miner can sacrifice the coinbase reward as much as possible to mine blocks faster.\nIf the blockchain follows the longest chain rule, PoLW may make 51% attacks much easier.\nAn easy way of fixing this is to choose the chain with most work rather than most blocks.\n\n## What if the coinbase tx is no longer the majority of mining reward, but the fx fee?\n\nThis might happen in the future.\nA possible solution is to limit the number of txs for easy blocks.\nFor example, if a miner chooses to mine blocks N times easier, he can only include txs of which the total size is <= (block_size - metadata_size) / N.\n\nBest regards,\nRunchao\n\n> Date: Sun, 8 Dec 2019 11:43:49 +0100\n> From: Cheng Wang <cheng at alephium.org>\n> To: bitcoin-dev at lists.linuxfoundation.org\n> Subject: [bitcoin-dev] Reducing energy consumption and increasing\n> \tsecurity\tat the same time\n> Message-ID:\n> \t<CAJgZxF4G_BjJ=OhuzhjfZtkePnEc2hz8DMZzFzWKBNh17XhBeQ at mail.gmail.com>\n> Content-Type: text/plain; charset=\"utf-8\"\n> \n> Hi Everyone,\n> \n> I would like to share my serious work on reducing the energy consumption of\n> PoW without sacrificing security. My new type of algorithm is called PoLW.\n> For a practical system where mining is profitable, PoLW could actually\n> improve the security of the system.\n> \n> The idea is to shift part of the external cost of mining in the physical\n> world (mainly energy consumption) to the internal cost of the network. In\n> PoLW, the miners are able to give up part of the coinbase reward so as to\n> get weight (> 1) for the block hash they produce. The total cost of\n> generating a new block would still be equal to maximal coinbase reward in\n> equilibrium.\n> \n> I analyzed two algorithms in the paper: linear PoLW and exponential PoLW.\n> Linear PoLW could reduce energy consumption by a factor close to 1/2 in\n> equilibrium, while exponential PoLW could reduce energy consumption by an\n> arbitrary factor in equilibrium.\n> \n> In a practical system, mining is usually (if not always) profitable. If we\n> transition from PoW to PoLW, the external costs of mining would decrease\n> and the internal costs will increase. However, the decrease in external\n> costs would be less than the increase in internal costs since mining is\n> profitable. The total cost of block generation would get higher, therefore,\n> the security will increase.\n> \n> Of course, we could not decrease the external costs of any existing system\n> by a factor close to zero immediately. There is a section in my paper\n> discussing this particularly. The principle of applying PoLW is that\n> keeping the absolute external cost increasing all the time, but the\n> percentage of external cost in the total cost gets lower eventually.\n> \n> This work is based on solid math calculation, and I am looking forward to\n> feedback and discussions. My paper is available at:\n> https://github.com/alephium/research/raw/master/polw.pdf\n> \n> It's inspired by the recent great paper of Itay, Alexander, and Ittay:\n> https://arxiv.org/abs/1911.04124\n> \n> Best,\n> Cheng Wang\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191209/b61d37f6/attachment.html>"
            },
            {
                "author": "Cheng Wang",
                "date": "2019-12-09T09:47:49",
                "message_text_only": "Hi Runchao,\n\n- 1st question regarding double spending:\n\nWe won't allow a miner to sacrifice coinbase reward as much as possible for\na practical system. This will be achieved by setting a dynamic upper bound\nfor the number of rewards the miner could sacrifice. The upper bound would\nbe related to the actual mining difficulty (not the weighted one) of the\nrecent mining epoch.\n\nIn Section 8 of the paper, I discussed quite a lot about how to select\nsystem parameters and how to transition the current PoW systems to PoLW.\nJust for an example, for Bitcoin, we might transition from giving up 0\ncoinbase reward to giving up maximal 10% coinbase reward. In the long term,\nif the value of Bitcoin goes as comparable to gold, we could allow the\nminers to give up more rewards. The network could adjust these bounds\nsolely based on the internal state (i.e. the actual mining difficulty).\n\nIn short, PoLW could reduce the energy consumption of Bitcoin in\nequilibrium from coinbase reward to even sub-linear. Still, the absolute\nenergy consumption would be kept at a sufficiently high level.\n\n- 2nd question regarding tx fees:\n\nWe could simply reduce this problem to purely coinbase reward by adding tx\nfees into the maximal coinbase reward. When the tx fees dominant miner's\nprofits, we could simply allow negative coinbase reward (i.e. miners spend\ncoins for the coinbase transaction).\n\nNote that, using PoLW, we could remove the halving mechanism, as PoLW is\nadaptive already.\n\nBest, Cheng!\n\nOn Mon, Dec 9, 2019 at 1:45 AM Runchao Han <runchao.han at monash.edu> wrote:\n\n> Hi Cheng,\n>\n> This is an interesting proposal!\n> While the incentive analysis is sound, I have two concerns:\n>\n> ## What if a guy keeps mining easy blocks to launch 51% attacks?\n>\n> With PoLW, a miner can sacrifice the coinbase reward as much as possible\n> to mine blocks faster.\n> If the blockchain follows the longest chain rule, PoLW may make\n> 51% attacks much easier.\n> An easy way of fixing this is to choose the chain with most work rather\n> than most blocks.\n>\n> ## What if the coinbase tx is no longer the majority of mining reward, but\n> the fx fee?\n>\n> This might happen in the future.\n> A possible solution is to limit the number of txs for easy blocks.\n> For example, if a miner chooses to mine blocks N times easier, he can only\n> include txs of which the total size is <= (block_size - metadata_size) / N.\n>\n> Best regards,\n> Runchao\n>\n> Date: Sun, 8 Dec 2019 11:43:49 +0100\n> From: Cheng Wang <cheng at alephium.org>\n> To: bitcoin-dev at lists.linuxfoundation.org\n> Subject: [bitcoin-dev] Reducing energy consumption and increasing\n> security at the same time\n> Message-ID:\n> <CAJgZxF4G_BjJ=OhuzhjfZtkePnEc2hz8DMZzFzWKBNh17XhBeQ at mail.gmail.com>\n> Content-Type: text/plain; charset=\"utf-8\"\n>\n> Hi Everyone,\n>\n> I would like to share my serious work on reducing the energy consumption of\n> PoW without sacrificing security. My new type of algorithm is called PoLW.\n> For a practical system where mining is profitable, PoLW could actually\n> improve the security of the system.\n>\n> The idea is to shift part of the external cost of mining in the physical\n> world (mainly energy consumption) to the internal cost of the network. In\n> PoLW, the miners are able to give up part of the coinbase reward so as to\n> get weight (> 1) for the block hash they produce. The total cost of\n> generating a new block would still be equal to maximal coinbase reward in\n> equilibrium.\n>\n> I analyzed two algorithms in the paper: linear PoLW and exponential PoLW.\n> Linear PoLW could reduce energy consumption by a factor close to 1/2 in\n> equilibrium, while exponential PoLW could reduce energy consumption by an\n> arbitrary factor in equilibrium.\n>\n> In a practical system, mining is usually (if not always) profitable. If we\n> transition from PoW to PoLW, the external costs of mining would decrease\n> and the internal costs will increase. However, the decrease in external\n> costs would be less than the increase in internal costs since mining is\n> profitable. The total cost of block generation would get higher, therefore,\n> the security will increase.\n>\n> Of course, we could not decrease the external costs of any existing system\n> by a factor close to zero immediately. There is a section in my paper\n> discussing this particularly. The principle of applying PoLW is that\n> keeping the absolute external cost increasing all the time, but the\n> percentage of external cost in the total cost gets lower eventually.\n>\n> This work is based on solid math calculation, and I am looking forward to\n> feedback and discussions. My paper is available at:\n> https://github.com/alephium/research/raw/master/polw.pdf\n>\n> It's inspired by the recent great paper of Itay, Alexander, and Ittay:\n> https://arxiv.org/abs/1911.04124\n>\n> Best,\n> Cheng Wang\n>\n>\n>\n\n-- \nCheng Wang\n# Love math and coding\n# Founder of Alephium; Proposed BlockFlow algorithm\n# Proposed the first linear-time asynchronous Byzantine consensus algorithm\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191209/b39d6158/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Reducing energy consumption and increasing security at the same time",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Runchao Han",
                "Cheng Wang"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 10707
        }
    },
    {
        "title": "[bitcoin-dev] Analysis of Bech32 swap/insert/delete detection and next steps",
        "thread_messages": [
            {
                "author": "Pieter Wuille",
                "date": "2019-12-09T22:31:13",
                "message_text_only": "Hi all,\n\nI've made a writeup on Bech32's detection abilities, analysing how it\nbehaves in the presence of not just substitution errors, but also\nswapping of characters, and insertions and deletions:\nhttps://gist.github.com/sipa/a9845b37c1b298a7301c33a04090b2eb\n\nIt shows that the \"insert or delete a 'q' right before a final 'p'\" is\nin fact the only deviation from the expected at-most-1-in-a-billion\nfailure to detect chance, at least when restricted to the classes of\nerrors analyzed with various uniformity assumptions. There is some\nfuture work left, such as analyzing combinations of insertions and\nsubstitutions, but I would be surprising if additional weaknesses\nexist there.\n\nIt also shows that changing one constant in Bech32 would resolve this\nissue, while not affecting the error detection properties for other\nclasses of errors.\n\nSo my suggestion for the next steps are:\n* Update BIP173 to include the insertion weakness as an erratum, and\nthe results of this analysis.\n* Amend segwit addresses (either by amending BIP173, or by writing a\nshort updated BIP to modify it) to be restricted to only length 20 or\n32 (as fixed-length strings are unaffected by the insertion issue, and\nI don't think inserting 20 characters is an interesting error class).\n* Define a variant of Bech32 with the modified constant, so that\nnon-BIP173 uses of Bech32 can choose a non-impacted version if they\nworry about this class of errors.\n* Later, if and when we expect a need for non-32-byte witness programs\nin the medium term, define an updated segwit address scheme that uses\nthe modified Bech32 variant.\n\nI believe that the impact on production systems will be minimal using\nthe above, as many wallets already do not accept unknown witness\nversions in outputs, and it gives us probably years to adapt.\n\nWhat do people think?\n\nCheers,\n\n-- \nPieter"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-12-10T01:50:38",
                "message_text_only": "Good morning Pieter,\n\n> Hi all,\n>\n> I've made a writeup on Bech32's detection abilities, analysing how it\n> behaves in the presence of not just substitution errors, but also\n> swapping of characters, and insertions and deletions:\n> https://gist.github.com/sipa/a9845b37c1b298a7301c33a04090b2eb\n>\n> It shows that the \"insert or delete a 'q' right before a final 'p'\" is\n> in fact the only deviation from the expected at-most-1-in-a-billion\n> failure to detect chance, at least when restricted to the classes of\n> errors analyzed with various uniformity assumptions. There is some\n> future work left, such as analyzing combinations of insertions and\n> substitutions, but I would be surprising if additional weaknesses\n> exist there.\n>\n> It also shows that changing one constant in Bech32 would resolve this\n> issue, while not affecting the error detection properties for other\n> classes of errors.\n>\n> So my suggestion for the next steps are:\n>\n> -   Update BIP173 to include the insertion weakness as an erratum, and\n>     the results of this analysis.\n>\n\nTo clarify, this step does not modify anything about the implementation of BIP173, only adds this as an additional erratum section?\n\n> -   Amend segwit addresses (either by amending BIP173, or by writing a\n>     short updated BIP to modify it) to be restricted to only length 20 or\n>     32 (as fixed-length strings are unaffected by the insertion issue, and\n>     I don't think inserting 20 characters is an interesting error class).\n\nTo clarify, this refers to all SegWit address versions from 1 to 15, as this restriction exists for SegWit address v0?\n\n>\n> -   Define a variant of Bech32 with the modified constant, so that\n>     non-BIP173 uses of Bech32 can choose a non-impacted version if they\n>     worry about this class of errors.\n>\n\nOkay, this probably needs to be raised in lightning-dev as well, for invoice formats, as well as planned offers feature.\n\nBy my understanding, best practice for readers of Bech32-based formats would be something like the below:\n\n1.  Define two variants of checksum, the current Bech32 checksum and the modified Bech32 checksum.\n2.  Support both variants (software tries one first, then tries the other if it fails).\n3.  Flag or signal some deprecation warning if current Bech32 checksum was detected.\n4.  At some undefined point in the future, drop support for the current Bech32 checksum.\n\n> -   Later, if and when we expect a need for non-32-byte witness programs\n>     in the medium term, define an updated segwit address scheme that uses\n>     the modified Bech32 variant.\n\n\nOkay, so we will only use the modified Bech32 if and only if we expect to need a non-32-byte witness program for a particular non-0 SegWit version.\n\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Pieter Wuille",
                "date": "2019-12-10T06:36:20",
                "message_text_only": "> > So my suggestion for the next steps are:\n> >\n> > -   Update BIP173 to include the insertion weakness as an erratum, and\n> >     the results of this analysis.\n> >\n>\n> To clarify, this step does not modify anything about the implementation of BIP173, only adds this as an additional erratum section?\n\nCorrect - just documenting the issue.\n\n> > -   Amend segwit addresses (either by amending BIP173, or by writing a\n> >     short updated BIP to modify it) to be restricted to only length 20 or\n> >     32 (as fixed-length strings are unaffected by the insertion issue, and\n> >     I don't think inserting 20 characters is an interesting error class).\n>\n> To clarify, this refers to all SegWit address versions from 1 to 15, as this restriction exists for SegWit address v0?\n\nRight, for v0 there is an inherent restriction to size 20 or 32\nalready, so this would only semantically change anything for version 1\nthrough 16 (not 15).\n\n> > -   Define a variant of Bech32 with the modified constant, so that\n> >     non-BIP173 uses of Bech32 can choose a non-impacted version if they\n> >     worry about this class of errors.\n> >\n>\n> Okay, this probably needs to be raised in lightning-dev as well, for invoice formats, as well as planned offers feature.\n\nIt seems BOLT11 already doesn't care very much about the error\ndetection properties, as it's using Bech32 outside its design\nparameters (max length 90 characters).\n\n> By my understanding, best practice for readers of Bech32-based formats would be something like the below:\n>\n> 1.  Define two variants of checksum, the current Bech32 checksum and the modified Bech32 checksum.\n> 2.  Support both variants (software tries one first, then tries the other if it fails).\n> 3.  Flag or signal some deprecation warning if current Bech32 checksum was detected.\n> 4.  At some undefined point in the future, drop support for the current Bech32 checksum.\n\nI think it depends on the application and their tolerance to this sort\nof errors. In some cases, these insertions may be detected already\nwith high probability (e.g. because of length restrictions, or the\nfact that it adds random unstructured symbols at the end of the data\npart).\n\n> > -   Later, if and when we expect a need for non-32-byte witness programs\n> >     in the medium term, define an updated segwit address scheme that uses\n> >     the modified Bech32 variant.\n>\n> Okay, so we will only use the modified Bech32 if and only if we expect to need a non-32-byte witness program for a particular non-0 SegWit version.\n\nExactly.\n\n-- \nPieter"
            }
        ],
        "thread_summary": {
            "title": "Analysis of Bech32 swap/insert/delete detection and next steps",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj",
                "Pieter Wuille"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 7129
        }
    },
    {
        "title": "[bitcoin-dev] Human readable format for private keys",
        "thread_messages": [
            {
                "author": "JW Weatherman",
                "date": "2019-12-10T02:11:10",
                "message_text_only": "I now have a live demo of using the NATO alphabet and checksums every 4 words.\n\nIt does seem remove the stress of attempting to write unambiguous characters  and I think the demo shows it\u2019s actually easier to type with autocomplete when the word dictionary is not involved.\n\nhttps://youtu.be/kpZcXtww8Us\n\n-JW\n\nOn Sat, Oct 5, 2019 at 6:51 PM, JW Weatherman via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hey Guys,\n>\n> I\u2019d like to propose a feature to bitcoin to solve the following problems:\n>\n> - When people read or write private keys it is very easy to mistake a letter or number.\n> - When entering a private key a mistake isn\u2019t identified until the entire key is entered.\n> - When an error is made in providing a private key the location of the error isn\u2019t indicated within the private key.\n> - Private keys stored on paper can be lost if a single character is damaged or poorly transcribed.\n>\n> The solution I\u2019m proposing has two parts.\n>\n> First provide an option to use to the NATO phonetic alphabet when displaying or entertaining private keys. To indicate lower case the word should not be capitalized. Capital letters and numbers should be capitalized.\n>\n> The nato phonetic alphabet is a long-standing international standard (as international as the use of letters and numbers already used in base58) and has been designed to make each letter easily distinguishable when spoken and written.\n>\n> By using whole words, that are easily distinguishable and from a very short word database (58 well known words that are either the English numbers or words that begin with the letter indicated) the likelihood of errors in recovery are reduced.\n>\n> The second part of the solution is to insert checksum letters. If every 5th word is actually a checksum for the previous 4 words, you end up with 13 sentences such as:\n>\n> ALFA tango THREE SIX bravo\n>\n> In this case bravo is actually a checksum for the previous 4 words and can be calculated and verified as the private key is entered. If the user accidentally trumped BRAVO instead of bravo the checksum would immediately indicate an error within these 5 words (in most cases) making for a greatly improved user experience.\n>\n> An additional side effect of this is that even if an entire word is lost on multiple lines, the  checksum would probably make guessing the correct words relatively easy.\n>\n> I realize some of these issues have been discussed in relation to bip39, but I hope this is more likely to be adopted by bitcoin core as it uses existing private keys, has no impact on keygen, does not require a standardized and well known word list for every language, and is essential just a display format that hopefully wouldn\u2019t require invasive code changes.\n>\n> Thanks in advance for your feedback.\n>\n> -JW\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191210/948917d1/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Human readable format for private keys",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "JW Weatherman"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2973
        }
    },
    {
        "title": "[bitcoin-dev] BIP OP_CHECKTEMPLATEVERIFY",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2019-12-11T00:37:59",
                "message_text_only": "Three changes I would like to make to the OP_CTV draft. I think this should\nput the draft in a very good place w.r.t. outstanding feedback.\n\nThe changes can all be considered/merged independently, though, they are\nwritten below assuming all of them are reasonable.\n\n\n1) *Make the hash commit to the INPUT_INDEX of the executing scriptPubKey.*\n\n*Motivation:* As previously specified, a CTV template constructed\nspecifying a transaction with two or more inputs has a \"half-spend\" issue\nwhereby if the template script is paid to more than once (a form of\nkey-reuse), they can be joined in a single transaction leading to half of\nthe intended outputs being created.\n*Example:*\nSuppose I have a UTXO with a CTV requiring two inputs. The first is set to\nbe the CTV template, and the input has enough money to pay for all the\noutputs. The second input is added to allow the adding of a fee-only utxo.\nNow suppose someone creates an similar UTXO with this same CTV (even within\nthe same transaction).\n\n\nTxA {vin: [/*elided...*/], vout: [TxOut{1 BTC, <TxB template hash> CTV},\nTxOut {1 BTC, <TxB template hash> CTV}]}\n\n*Intended Behavior:*\n    TxB0 {vin: [Outpoint{TxA.hash(), 0}, /*arbitrary fee utxo*/], vout :\n[TxOut {1 BTC, /* arbitrary scriptPubKey */}]\n    TxB1 {vin: [Outpoint{TxA.hash(), 1}, /*arbitrary fee utxo*/], vout :\n[TxOut {1 BTC, /* arbitrary scriptPubKey */}]\n*Possible Unintended Behaviors:*\n*    Half-Spend:*\n        TxB {vin: [Outpoint{TxA.hash(), 1}, Outpoint{TxA.hash(), 0}], vout\n: [TxOut {1 BTC, /* arbitrary scriptPubKey */}]\n    *Order-malleation:*\n        TxB0 {vin: [/*arbitrary fee utxo*/, Outpoint{TxA.hash(), 0}], vout\n: [TxOut {1 BTC, /* arbitrary scriptPubKey */}]\n        TxB1 {vin: [Outpoint{TxA.hash(), 1}, /*arbitrary fee utxo*/], vout\n: [TxOut {1 BTC, /* arbitrary scriptPubKey */}]\n\nWith the new rule, the CTV commits to the index in the vin array that it\nwill appear. This prevents both the half-spend issue and the\norder-malleation issue.\n\nThus, the only execution possible is:\n\n*Intended Behavior:*\n    TxB0 {vin: [Outpoint{TxA.hash(), 0}, /*arbitrary fee utxo*/], vout :\n[TxOut {1 BTC, /* arbitrary scriptPubKey */}]\n    TxB1 {vin: [Outpoint{TxA.hash(), 1}, /*arbitrary fee utxo*/], vout :\n[TxOut {1 BTC, /* arbitrary scriptPubKey */}]\n\n*Impact of Change:*\nThis behavior change is minor -- in most cases we are expecting templates\nwith a single input, so committing the input index has no effect.\n\nOnly when we do specify multiple inputs, committing the INPUT_INDEX has the\nside effect of making reused-keys not susceptible to the \"half-spend\" issue.\n\nThis change doesn't limit the technical capabilities of OP_CTV by much\nbecause cases where the half-spend construct is desired can be specified by\nselecting the correct inputs for the constituent transactions for the\ntransaction-program. In the future, Taproot can make it easier to express\ncontracts where the input can appear at any index by committing to a tree\nof positions.\n\nThis change also has the benefit of reducing the miner-caused TXID\nmalleability in certain applications (e.g., in a wallet vault you can\nreduce malleability from your deposit flow, preventing an exponential\nblow-up). However in such constructions the TXIDs are still malleable if\nsomeone decides to pay you Bitcoin that wasn't previously yours through a\nwithdrawal path (a recoverable error, and on the bright side, someone paid\nyou Bitcoin to do it).\n\nThis change also has a minor impact on the cacheability of OP_CTV. In the\nreference implementation we currently precompute and store single hash for\nthe StandardTemplateHash of the entire transaction. Making the hash vary\nper-input means that we would need to precompute one hash per-input, which\nis impractical. Given that we expect the 0-index to be the exceedingly\ncommon case, and it's not horribly expensive if we aren't cached (a\nconstant sized SHA-256), the spec will be updated to precompute and cache\nonly the hash for the 0th index. (The hash is also changed slightly to make\nit more efficient for un-cached values, as noted in change 3).\n\n\n*2) Remove Constexpr restriction*\n*Changes:*\nCurrently it is checked that the template hash argument was not 'computed',\nbut came from a preceding push. Remove all this logic and accept any\nargument.\n*Motivation:*\nI've had numerous conversations with Bitcoin developers (see above, see\n#bitcoin-wizards on Nov 28th 2019, in person at local meetups, and in\nprivate chats with ecosystem developers) about the constexpr restriction in\nOP_CTV. There have been a lot of folks asking to remove template constexpr\nrestriction, for a few reasons:\n\na) Parsing Simplification / no need for special-casing in optimizers like\nminiscript\nb) The types of script it disables aren't dangerous\nc) There are exciting things you can do were it not there and other\nfeatures were enabled (OP_CAT)\nd) Without other features (like OP_CAT), there's not really too much you\ncan do\n\nNo one has expressed any strong justification to keep it.\n\nThe main motivation for the constexpr restriction was to keep the CTV\nproposal very conservative in scope, increasing the likelihood that it is\nan acceptable change. It was also designed to be able to be easily lifted\nin a future soft-fork. There isn't a *specific* behavior the constexpr\nrestriction is attempting to prevent, it's just a belt-and-suspenders\nmeasure to limit how creatively CTV could be used now or in the future.\n\nFuture OpCodes + OP_CTV may introduce a broader set of functionality than\npossible if OP_CTV were to retain the constexpr rule. But I think given\nthat these future op-codes will likely be introduced intentionally to\nintroduce broader functionalities, we shouldn't limit the functionality of\nOP_CTV today.\n\n*Impact of Changes:*\n\nThe only mildly interesting thing that could be done with this change (with\nno additional changes; that I could think of) would be to write a script\nlike:\n\n<serialization of transaction fields according to hash spec> SHA256 OP_CTV\n\nwhich would be a \"self-describing\" covenant (for no space savings). This\ncould be useful in some protocols where \"the public\" should be able to\nexecute some step with only chain-data.\n\nN.B. This cannot enable a case where the CTV is in the scriptSig like:\n\nscriptPubKey: <key> CHECKSIG\nscriptSig: <serialization of transaction details> OP_SHA256 CTV <sig>\n\nbecause the serialization of the transaction contains a commitment to\nnon-null scriptSigs, a self-reference/hash cycle.\n\n\n*3) Modify the template digest to be easier to cache and work with in\nscript.*\n*Changes:*\nThe current hash is:\n\n    uint256 GetStandardTemplateHash(const CTransaction& tx) {\n        auto h =  TaggedHash(\"StandardTemplateHash\")\n            << tx.nVersion << tx.nLockTime\n            << GetOutputsSHA256(tx) << GetSequenceSHA256(tx)\n            << uint64_t(tx.vin.size());\n        for (const auto& in : tx.vin) h << in.scriptSig;\n        return h.GetSHA256();\n    }\n\nI propose changing it to:\n\n    uint256 GetStandardTemplateHash(const CTransaction& tx, uint32_t\ninput_index) {\n\n        uint256 scriptSig_hash{};\n\n        bool hash_scriptSigs = std::count(tx.vin.begin(),\ntx.vin.begin(), CScript()) != tx.vin().size();\n\n        if (hash_scriptSigs) {\n            auto h =  CHashWriter()\n            for (const auto& in : tx.vin) h << in.scriptSig;\n\n            scriptSig_hash = h.GetSHA256();\n\n        }\n        auto h =  CHashWriter()\n            << tx.nVersion\n            << tx.nLockTime;\n\n            if (hash_scriptSigs) h << scriptSig_hash;\n\n            h << uint64_t(tx.vin.size())\n\n            << GetSequenceSHA256(tx)\n\n            << uint32_t(tx.vout.size())\n\n            << GetOutputsSHA256(tx)\n\n            << input_index;\n\n        return h.GetSHA256();\n    }\n\nThis changes a few things:\n1) Getting rid of the TaggedHash use\n\n2) Re-ordering to put input_index last\n\n3) Re-ordering to put Outputs SHA256 second-to-last\n\n4) Only computing scriptSig_hash if any scriptSig is non-null\n\n5) Making scriptSig data hashed in it's own hash-buffer\n\n6) explicitly committing to the vout.size()\n7) Casting vout.size() but not vin.size() to uint32_t (vout is capped\nby COutpoint indicies to 32 bits, vin is not)\n\n*Motivation:*\nThe current digest algorithm is relatively arbitrarily ordered and set up.\nModifying it makes it easier to cache (given the input index change) and\nmakes it easier to construct templates in script (once OP_CAT, or\nOP_SUBSTR, or OP_STREAMSHA256 are added to core).\n\n*Impact of Changes:*\n\n*1) Getting rid of the TaggedHash use*\n\nLow-impact. TaggedHash didn't add any security to the template hashes,\nbut did make it harder to \"confuse\" a StandardTemplateHash for a hash\nof another type.\n\nHowever, the tagged hash makes it slightly more difficult/costly to\nconstruct (with OP_CAT enabled) a template hash within script, so it\nis removed.\n\n*2) Re-ordering to put input_index last*\n\nThe input index should be put last because this makes it easy to cache\nthe intermediate hash state *just before* hashing the index, which\nmakes recomputing for different indexes cheaper.\n\nIt also allows (with OP_CAT or STREAMSHA256) to easily allow setting\nthe accepted indexes from script.\n\n*3) Re-ordering to put Outputs SHA256 second-to-last*\n\nIn the future, with OP_CAT/SHA256STREAM or similar, changing the\noutputs in the covenant is the most likely change. Placing it near the\nend simplifies this operation.\n\n\n*4) Only computing scriptSig_hash if any scriptSig is non-null*\n\nThere is no need to hash the scriptSig data at all if they are all\nnull. This is in most cases true, so we avoid extra hashing.\n\nBut the bigger win is for scripted construction of templates, which\ncan just completely ignore the scriptSig hashing if it is known to be\nusing all bare CTV/non-p2sh segwit inputs (which should be the common\ncase).\n\n\n*5) Making scriptSig data hashed in it's own hash-buffer, when hash is\nincluded.*\n\nThis implies that there are two possible sizes for the hashed data,\n+/- 1 hash (for scripSig_hash). This eliminates concerns that directly\nhashing elements into the template hash buffer might expose some\nlength extension issue when constructing a template in script.\n\n\n*6) explicitly committing to the vout.size()*\n\nThis makes it easier, when OP_CAT or similar is added, to write\nrestrictions that guarantee a limit on the number of inputs that may\nbe created.\n\n\n*7) Casting vout.size() but not vin.size() to uint32_t (vout is capped\nby COutpoint indicies to 32 bits, vin is not)*\n\nThis is just kind of annoying, but technically you can have more inputs in\na transaction than outputs because more than 32-bits of outputs breaks the\nCOutpoint class invariants.\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Thu, Nov 28, 2019 at 11:59 AM Jeremy <jlrubin at mit.edu> wrote:\n\n> Thanks for the feedback Russell, now and early. It deeply informed the\n> version I'm proposing here.\n>\n> I weighed carefully when selecting this design that I thought it would be\n> an acceptable tradeoff after our discussion, but I recognize this isn't\n> exactly what you had argued for.\n>\n> First off, with respect to the 'global state' issue, I figured it was\n> reasonable with this choice of constexpr rule given that a reasonable tail\n> recursive parser might look something like:\n>\n> parse (code : rest) stack alt_stack just_pushed =\n>     match code with\n>         OP_PUSH => parse rest (x:stack) alt_stack True\n>         OP_DUP => parse rest (x:stack) alt_stack False\n>         // ...\n>\n> So we're only adding one parameter which is a bool, and we only need to\n> ever set it to an exact value based on the current code path, no\n> complicated rules. I'm sensitive to the complexity added when formally\n> modeling script, but I think because it is only ever a literal, you could\n> re-write it as co-recursive:\n>\n> parse_non_constexpr (code : rest) stack alt_stack =\n>     match code with\n>         OP_PUSH => parse_constexpr rest (x:stack) alt_stack\n>         OP_DUP => parse_non_constexpr rest (x:stack) alt_stack\n>         // ...\n>\n> parse_constexpr (code : rest) stack alt_stack  =\n>     match code with\n>         OP_CTV => ...\n>         _ => parese_non_constexpr (code : rest) stack alt_stack\n>\n>\n> If I recall, this should help a bit with the proof automatability as it's\n> easier in the case by case breakdown to see the unconditional code paths.\n>\n>\n> In terms of upgrade-ability, one of the other reasons I liked this design\n> is that if we do enable OP_CTV for non-constexpr arguments, the issue\n> basically goes away and the OP becomes \"pure\" without any state tracking.\n> (I think the switching on argument size is much less a concern because we\n> already use similar upgrade mechanisms elsewhere, and it doesn't add\n> parsing context).\n>\n>\n> It's also possible, as I think *should be done* for tooling to treat an\n> unbalanced OP_CTV as a parsing error. This will always produce\n> consensus-valid scripts! However by keeping the consensus rules more\n> relaxed we keep our upgrade-ability paths open for OP_CTV, which as I\n> understand from speaking with other users is quite desirable.\n>\n>\n> Best (and happy thanksgiving to those celebrating),\n>\n> Jeremy\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n>\n>\n> On Thu, Nov 28, 2019 at 6:33 AM Russell O'Connor <roconnor at blockstream.io>\n> wrote:\n>\n>> Thanks for this work Jeremy.\n>>\n>> I know we've discussed this before, but I'll restate my concerns with\n>> adding a new \"global\" state variable to the Script interpreter for tracking\n>> whether the previous opcode was a push-data operation or not.  While it\n>> isn't so hard to implement this in Bitcoin Core's Script interpreter,\n>> adding a new global state variable adds that much more complexity to anyone\n>> trying to formally model Script semantics.  Perhaps one can argue that\n>> there is already (non-stack) state in Script, e.g. to deal with\n>> CODESEPARATOR, so why not add more?  But I'd argue that we should avoid\n>> making bad problems worse.\n>>\n>> If we instead make the CHECKTEMPLATEVERIFY operation fail if it isn't\n>> preceded by (or alternatively followed by) an appropriate sized\n>> (canonical?) PUSHDATA constant, even in an unexecuted IF branch, then we\n>> can model the Script semantics by considering the\n>> PUSHDATA-CHECKTEMPLATEVERIFY pair as a single operation.  This allows\n>> implementations to consider improper use of CHECKTEMPLATEVERIFY as a\n>> parsing error (just as today unbalanced IF-ENDIF pairs can be modeled as a\n>> parsing error, even though that isn't how it is implemented in Bitcoin\n>> Core).\n>>\n>> I admit we would lose your soft-fork upgrade path to reading values off\n>> the stack; however, in my opinion, this is a reasonable tradeoff.  When we\n>> are ready to add programmable covenants to Script, we'll do so by adding\n>> CAT and operations to push transaction data right onto the stack, rather\n>> than posting a preimage to this template hash.\n>>\n>> Pleased to announce refinements to the BIP draft for\n>>> OP_CHECKTEMPLATEVERIFY (replaces previous OP_SECURETHEBAG BIP). Primarily:\n>>>\n>>> 1) Changed the name to something more fitting and acceptable to the\n>>> community\n>>> 2) Changed the opcode specification to use the argument off of the stack\n>>> with a primitive constexpr/literal tracker rather than script lookahead\n>>> 3) Permits future soft-fork updates to loosen or remove \"constexpr\"\n>>> restrictions\n>>> 4) More detailed comparison to alternatives in the BIP, and why\n>>> OP_CHECKTEMPLATEVERIFY should be favored even if a future technique may\n>>> make it semi-redundant.\n>>>\n>>> Please see:\n>>> BIP: https://github.com/JeremyRubin/bips/blob/ctv/bip-ctv.mediawiki\n>>> Reference Implementation:\n>>> https://github.com/JeremyRubin/bitcoin/tree/checktemplateverify\n>>>\n>>> I believe this addresses all outstanding feedback on the design of this\n>>> opcode, unless there are any new concerns with these changes.\n>>>\n>>> I'm also planning to host a review workshop in Q1 2020, most likely in\n>>> San Francisco. Please fill out the form here\n>>> https://forms.gle/pkevHNj2pXH9MGee9 if you're interested in\n>>> participating (even if you can't physically attend).\n>>>\n>>> And as a \"but wait, there's more\":\n>>>\n>>> 1) RPC functions are under preliminary development, to aid in testing\n>>> and evaluation of OP_CHECKTEMPLATEVERIFY. The new command\n>>> `sendmanycompacted` shows one way to use OP_CHECKTEMPLATEVERIFY. See:\n>>> https://github.com/JeremyRubin/bitcoin/tree/checktemplateverify-rpcs.\n>>> `sendmanycompacted` is still under early design. Standard practices for\n>>> using OP_CHECKTEMPLATEVERIFY & wallet behaviors may be codified into a\n>>> separate BIP. This work generalizes even if an alternative strategy is used\n>>> to achieve the scalability techniques of OP_CHECKTEMPLATEVERIFY.\n>>> 2) Also under development are improvements to the mempool which will, in\n>>> conjunction with improvements like package relay, help make it safe to lift\n>>> some of the mempool's restrictions on longchains specifically for\n>>> OP_CHECKTEMPLATEVERIFY output trees. See: https://github.com/bitcoin/bitcoin/pull/17268\n>>> This work offers an improvement irrespective of OP_CHECKTEMPLATEVERIFY's\n>>> fate.\n>>>\n>>>\n>>> Neither of these are blockers for proceeding with the BIP, as they are\n>>> ergonomics and usability improvements needed once/if the BIP is activated.\n>>>\n>>> See prior mailing list discussions here:\n>>>\n>>> *\n>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-May/016934.html\n>>> *\n>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-June/016997.html\n>>>\n>>> Thanks to the many developers who have provided feedback on iterations\n>>> of this design.\n>>>\n>>> Best,\n>>>\n>>> Jeremy\n>>>\n>>> --\n>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191210/f3b59f34/attachment-0001.html>"
            },
            {
                "author": "Jeremy",
                "date": "2019-12-13T23:06:59",
                "message_text_only": "I've prepared a draft of the changes noted above (some small additional\nmodifications on the StandardTemplateHash described in the BIP), but have\nnot yet updated the main branches for the BIP to leave time for any further\nfeedback.\n\nSee below:\n\nBIP: https://github.com/JeremyRubin/bips/blob/ctv-v2/bip-ctv.mediawiki\nImplementation:\nhttps://github.com/JeremyRubin/bitcoin/tree/checktemplateverify-v2\n\nThank you for your feedback,\n\nJeremy\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191213/be6af5e4/attachment.html>"
            },
            {
                "author": "Jeremy",
                "date": "2019-12-19T20:08:03",
                "message_text_only": "I've updated the main branch (ctv) to match ctv-v2, and pushed branches\nctv-v1 which points at the prior versions.\n\nThanks to Dmitry Petukhov for helping me fix several typos and errors.\n\nI also wanted to share some some \"non-technical\" tax analysis covering the\nuse of OP_CTV for batched payments. See here:\nhttps://utxos.org/analysis/taxes/\n\nAs an aside, the site https://utxos.org/ generally is a repository of\ninformation & material on OP_CTV, it's design, applications, and analysis.\nIf you're interested in contributing any content please let me know!\n\nBest,\n\nJeremy\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Fri, Dec 13, 2019 at 3:06 PM Jeremy <jlrubin at mit.edu> wrote:\n\n> I've prepared a draft of the changes noted above (some small additional\n> modifications on the StandardTemplateHash described in the BIP), but have\n> not yet updated the main branches for the BIP to leave time for any further\n> feedback.\n>\n> See below:\n>\n> BIP: https://github.com/JeremyRubin/bips/blob/ctv-v2/bip-ctv.mediawiki\n> Implementation:\n> https://github.com/JeremyRubin/bitcoin/tree/checktemplateverify-v2\n>\n> Thank you for your feedback,\n>\n> Jeremy\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191219/5500674a/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP OP_CHECKTEMPLATEVERIFY",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 20149
        }
    },
    {
        "title": "[bitcoin-dev] [New BIP]: Universal Addresses",
        "thread_messages": [
            {
                "author": "Ty Everett",
                "date": "2019-12-24T03:20:15",
                "message_text_only": "I\u2019d like to propose a new BIP for universal, multi-currency addresses. Until a BIP number is assigned, we can substitute it with ${BIPNUM} wherever it is used. In the examples, I\u2019ll use 3301 as the value for ${BIPNUM} when required to demonstrate BIP32 derivation.\n\n```\nBIP: ${BIPNUM}\nLayer: Applications\nTitle: Universal Addresses\nAuthor: Ty Everett <ty at rubix.io>\nStatus: Draft\nType: Informational\nCreated: 2019-12-23\nLicense: BSD-2-Clause\nRequires: 32, 43, 44\n```\n\nAbstract\n\nA universally recognized and accepted cryptocurrency address format would allow merchants, exchanges and users to more easily coordinate transactions and conduct business. I propose a new address format not specific to any cryptocurrency that provides strong cryptographic security while maintaining or improving the level of transactional privacy specific to each underlying currency. BIP32 derivation permits compatibility with existing HD wallets, reducing implementational friction across the ecosystem. BIP44 numberings at the coin-selection level allow new coins to be used with the same Universal Addresses, while URL-style query parameters dictate which currencies a user prefers to receive.\n\nAs the Bitcoin and wider cryptocurrency community has matured, numerous address formats have been devised. Some projects use their own format, while others use base-58 or hex-encoded strings. Some even have identical addresses, creating confusion for users and a potential for the loss of funds. While each format has its unique set of advantages and disadvantages, they all have one thing in common: they are specific to a single currency and not to the user, who may or may not use and accept a great many currencies. I propose the use of BIP32 extended public key nodes as a Universal Address format, because no cryptocurrency project exists in a vacuum.\n\nCopyright\n\nThis BIP is licensed under the BSD 2-Clause License.\n\nSpecification\n\nPre-requisite Knowledge\n\nThis BIP draws on concepts from BIP32, BIP43 and BIP44. The reader is encouraged to familiarize themselves with those BIPs before attempting to read and understand this BIP.\n\nA Note on Annotations and Rationale in this BIP\n\nDesign decisions have been made with regard to many respects of this BIP. Where appropriate, annotations[1] have been added. Justifications can be found in the \u201cRationale\u201d section, along with a few explanatory Q&A-style points about potential implementation concerns.\n\nA Note on Terminology Used In This BIP\n\nThe key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \u201cSHALL NOT\", \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\",  \"MAY\", and \"OPTIONAL\" in this document are to be interpreted as described in RFC 2119.\n\nDerivation Path Levels for Universal Addresses\n\nImplementers of BIP${BIPNUM} MUST use the below BIP32 derivation path levels for Universal Addresses; apostrophe denotes hardened BIP32 derivation:\n\n```\nm / ${BIPNUM}\u2019 / entity / coin / shield\n```\n\nLevel 1: Denotes Use with Universal Addresses\n\nThe top-level derivation simply denotes the use of this node with Universal Addresses. Primarily, it\u2019s purpose is to isolate this use-case from other uses of the same BIP32 node (notably BIP44 wallets).\n\nLevel 2: Recipient Determines Index of Address to Share\n\nThis is the level at which the Universal Addresses allocated by a recipient's wallet are to be split off; one for each sender to whom the recipient has given an address. Starting at index 1 (0 is reserved for future use), each Universal Address SHOULD be generated canonically. The keys generated at this level are the ones to be shared from the sender to the recipient. The recipient may then derive a level 3 key based on this key and the currency they wish to send. There is no need for the sender to obtain a new Universal Address from the recipient for each of their subsequent transactions.\n\nLevel 3: Sender Selects and Derives Address for the Currency They Wish to Send\n\nThe sender receives the level 2 key from the recipient formatted as a Universal Address (see Serialization Format section below). Based on the BIP44 coin assignment number for the coin the sender would like to send (maintained by Satoshi Labs as SLIP44), the sender makes the appropriate derivation at this level.\n\nLevel 4: Sender Increments Shield Counter to Improve Privacy (\u201cEnhanced Privacy Mode\u201d)\n\nThe shield counter starts at child #1 (#0 is reserved for future use). If a higher level of privacy is desired, the sender MAY increment the shield counter once per transaction. In this way, individual addresses are not re-used. Additionally, the sender MAY split a payment into multiple separate transactions, each destined for a different blockchain-level address[2]. If the sender does not increment the shield counter for every transaction, the sender MUST always use child #1 as the public key component of the blockchain-level address.\n\nReservation of ${BIPNUM} as a BIP43 Purpose\n\nI define that the first level of BIP32 derivation to be used in Universal Address allocation from the root BIP32 node SHALL be ${BIPNUM}, which conforms to the BIP43 recommendation that top-level derivations be based on the number assigned to a BIP. The BIP43 purpose for this BIP is \u201cUniversal Addresses.\u201d\n\nSerialization Format\n\nThe serialized address format for BIP${BIPNUM} Universal Addresses SHALL be the same format described in the \u201cSerialization Format\u201d subsection of the \u201cSpecification: key derivation\u201d section of BIP32, subject to the following considerations:\n\n- Implementers of BIP${BIPNUM} Universal Addresses MUST encode Universal Addresses using the same base58 format as current extended public keys for interoperability with existing software.\n\n- For additional privacy, implementers of BIP${BIPNUM} Universal Addresses SHOULD substitute the 32-bit \u201cparent key fingerprint\u201d with 0x00000000 before disclosing the Universal Address to the sender. In these cases, the recipient has the sole responsibility of keeping track of the true parent key fingerprint if they find it useful.\n\n- For additional privacy, implementers of BIP${BIPNUM} Universal Addresses SHOULD substitute the 32-bit \u201cchild number\u201d with 0x00000000 before disclosing the Universal Address to the sender. In these cases, the recipient has the sole responsibility of keeping track of the true child number if they find it useful.\n\nURL-Style Query Parameters for Denotability of Recipient-Specified Currency Acceptance Preferences\n\nWhen the recipient wishes to specify which currencies it prefers to receive, a URL-style query parameter MAY be appended to the end of the Universal Address. If provided, the query parameter MUST have the property of lowercase \u201caccept\u201d and its value MUST be a comma-delimited list of one or more SLIP44 currency symbols. Future BIPs MAY propose new query parameters that can also be appended. All such parameters are strictly OPTIONAL in this specification. Universal addresses with no appended query parameters MUST be regarded as valid.\n\nWhen a sender wallet encounters a Universal Address with an appended \u201caccept\u201d URL-style query parameter, it SHOULD show a list of currencies in its user interface that correspond to the ones denoted by the value of the parameter. The sending wallet SHOULD also remove currencies from the list that it does not support.\n\nThe sender wallet MAY auto-select a currency for the sender if there is only one common currency between the \u201caccept\u201d list and the \u201csupported currencies\u201d list of the sender wallet. Auto-selection based on the sender\u2019s balance or other factors MAY also be performed.\n\nFuture Possibilities for Backwards-Compatible Improvements to Universal Addresses\n\nA future BIP MAY specify a URI-style format (e.g. \u201cpay:\u2026\u201d) and, if a URI-style format for Universal Addresses is proposed, the proposing BIP SHOULD consider removing unnecessary fields (version bytes, depth, parent key fingerprint and child index) from the base58-encoded string. However, to reduce the friction for adoption of Universal Addresses by the community and to promote compatibility with existing software, those changes are not proposed as part of this BIP. BIP${BIPNUM} Universal Addresses can be converted to a new, shorter format in the future[6]. Libraries, wallets and BIPs building on top of and claiming support for BIP${BIPNUM} Universal Addresses MUST maintain seamless backwards-compatible support for the use of standard BIP32-serialized extended public keys as BIP${BIPNUM} Universal Addresses.\n\nBIP${BIPNUM} Universal Address Validity Checks\n\nA serialized BIP32 extended public key string that is encoded in base58 format with a valid 32-bit checksum SHALL be regarded as a valid BIP${BIPNUM} Universal Address if the following are true:\n1). The string meets the BIP32 requirement that the specified point lies on the secp256k1 curve, and is otherwise representative of a valid BIP32 public node.\n2). The version bytes are equal to 0x0488B21E for the key[3].\n3). The depth byte is equal to 0x02.\n4). Notwithstanding the above, validity assertions SHALL NOT take into account the contents of the 32-bit parent key fingerprint or the 32-bit child number, except that these fields MUST be present in some form and that the final double-sha256 checksum MUST be correct.\n\nImplementation Notes\n\nBIP44-compliant wallet Implementers SHOULD use the same BIP32 root node as is presently in use for each of their users. This generally reduces complexity and maintains compatibility with existing software.\n\nThis BIP mandates that it is absolutely REQUIRED that the community agree on SLIP44 designations for each coin. Project leaders MUST apply for SLIP44 allocations if they have yet to do so and want their projects to be compatible with this BIP[4].\n\nUniversal Address Sharing\n\nUniversal Addresses SHOULD be viewed as having two possible security models: they can be fully public or they can be kept secret between the recipient and exactly one sender. Fully public addresses are OK, because Universal Addresses do not claim to provide confidentiality about the amounts and currencies received by the recipient. Fully private addresses, where the recipient allocates a new address for every sender (such that each sender has their own designated Universal Address for the recipient, but no sender may learn the Universal Address of any other senders to the recipient) are also secure and have other benefits[2]. However, other security models have inherent weaknesses[5] and SHOULD definitely be avoided.\n\nBalance Calculation Algorithm\n\nSimilar to current extended public key-based wallets, inquiring about the balance of a Universal Address involves querying for transactions related to the blockchain-level addresses derived from the root node. The only difference with Universal Addresses is that wallets SHOULD query all blockchains for which a known balance is desired. Higher zero-use gap toleration decreases the likelihood of missing coins. Wallets SHOULD keep track of the Universal Addresses they allocate.\n\nExamples\n\nThree situations that utilize Universal Addresses will be described; the first from the perspective of a recipient and the second two from the perspective of senders.\n\nExample 1: Recipient Usage\n\nA user generates a BIP32 private root node and wants to give out a Universal Address:\n\n```\nxprv9s21ZrQH143K2eR2vYd9i6YvrFUojaL3ecK2hY4zfabMgu6okTk2s6WxnQmPYA45apCKWiUnHrQsdvh6ER4Leaaa7ehDx5KZtDUbAcgfGBy\n```\n\nThe user will perform a hardened level 1 derivation to find private child #${BIPNUM} of their root node:\n\n```\nxprv9umttUfc6MFTxANAkz8fWE4hHN99xra5GwiP9Er91M69mBso9hAhAgYu2tXfvXaAs5AHWAPwZCSUT4SzkgBqtuNYdHLcp1tSsPDGmAg9ugW\n```\n\nThe user will perform a public derivation to arrive at the #1 child, as this is their first Universal Address:\n\n```\nxpub6A6MPF2tU1tML7JJa98pzmSgDr7V8JuaKCrYu4tjgq4ZLFKTvF4eW7y3c28ye3db9nk3XVvPBTwDA7VB7hch4aj1aQKrCj7FoW78vTJw8zj\n```\n\nThis is the Universal Address. Assuming the user is OK with accepting any SLIP44 cryptocurrency, they can share the Universal Address with any sender or publish it online.\n\nOptionally, they can append URL-style query parameters to denote one or more currencies they prefer to accept with this address. Other query string parameters may be proposed by future BIPs. This BIP only reserves the \u201caccept\u201d parameter for use as a comma-delimited list of SLIP44 currency symbols, as defined in the \u201cURL-Style Query Parameters for Denotability of Recipient-Specified Currency Acceptance Preferences\u201d subsection of the \u201cSpecification\u201d section above.\n\nExample 2: Multi-currency Wallet\n\nA user sees a BIP${BIPNUM} Universal Address on a website:\n\n```\nxpub6A6MPF2tU1tMQXuhyAAXLDWKMuw3GRwZEFUAXXwHuykZoUcyUn24gN7RPuy5xZXj6zSqWXFcVjTJEnnX5Qh4pjJMnGbjZkuXHFKFy4U22AX?accept=BTC,LTC\n```\n\nThe user\u2019s wallet notices that the address indicates a preference for either Bitcoin or Litecoin, so the UI presents a choice. The user selects Litecoin, so the wallet searches for LTC in the SLIP44 currency list and therefore derives the #2 child node of the Universal Address:\n\n```\nxpub6D76wrzT2eTJH5EaMdcK8Wkej36nBakXFwMr79HLJMxga4giaehK8RLFiCTiAkBt9W8saivsX4n2ot9reUt4ePbSUhEFHK1NGkKiPhWhQZH\n```\n\nThis particular wallet does not support \"Enhanced Privacy Mode\", so it will simply derive the #1 child of the Litecoin node instead of calculating the correct shield value:\n\n```\nxpub6E9man3MPJXdrgjHDqhkJuSjG3j9TBfESbxppRA1fF5pq9KEDCQegPfa76e9BT3Nnhwpy9krXrLTRsYx8ccFXrMKTuz6hH2ZEanhG1tC59a\n```\n\nThe Litecoin address corresponding to the derived node is:\n\n```\nLXDxiYDVosUg3hKwJ4yP24EfdkRuNumLs5\n```\n\nThe user completes their transaction with Litecoin.\n\nExample 3: \"Enhanced Privacy Mode\" and Universal Address Reuse\n\nIn a (semi)-private chat, a user receives a Universal Address:\n\n```\nxpub6AJUhNSZRaZS7d9eJ2jyyuNMbkMWQgHNEgDt9rC3WJfkXvQDAKu9LZLhMhVkeot66EtEtBJK48Ca3qNfrjBH1otkBc2CNPwaTMeHSh3TvL1\n```\n\nThe user received this particular Universal Address some months ago[7], and has used to for 17 previous Bitcoin transactions and 2 Litecoin transactions to this recipient.\n\nThe user wants to send 2 BTC to the recipient. The user\u2019s wallet has two unspent outputs in different places; the first for 1.5 BTC and the second for 1 BTC.\n\nThe wallet notices that the recipient\u2019s Universal Address indicates no preference for which currency to receive. Thus, the UI presents a list of all supported currencies for which the sender has a balance. The sender selects Bitcoin, so the wallet searches for BTC in the SLIP44 currency list and therefore derives the #0 child node of the Universal Address:\n\n```\nxpub6CUu5jU1UVXsB3zstbr6MDZcmZy9SAEfsTtm81iR2foAtRZ34cb9jnr4D1jcQxKG9y9fMhVeqYy9kC3j4jidyhbrRuX6nXiYgSdQSwZmzVi\n```\n\nSince the sender\u2019s wallet supports \"Enhanced Privacy Mode\", it will increment the Bitcoin shield counter starting at child #1 and querying the blockchain for each shielded address to see if it has ever been used[8]. The wallet sees that the shield counter is at #17[9]. Since the wallet uses \u201cEnhanced Privacy Mode\u201d, it MUST NOT use shielded children less than child #18. For privacy, the wallet MAY also split the payment into two or more transactions[11]. The wallet will now derive the #18 and #19 children of the Bitcoin node:\n\n```\nxpub6EvkmcciNXPHVoiSP4sV21mgAWi3MAzJtvwRFXoNuUusADN1KU9eZ9REkuD7PgtRDR1ggKRSvci8L6uhegmcoNwSP8QDfSqRH66iC6oGYWs -> 1F2idiEsCTBN6ZrzkLE7JTddaJPubYet5m\n```\n\nand\n\n```\nxpub6EvkmcciNXPHWR7ZLh8XJz74CZh8NDszKBzEBMS7xFDgTB7aoLbJwtzwV1CdKM6JvwrGowU1FoMpf1uZuUfBqX4BpHqMGQocTPev98qZ3Wf -> 1PpcyFv46NvqJusLwfrv6dkw3K9z434hJV\n```\n\nThe wallet will now spend the first of its outputs (1.5 BTC) entirely to child #18, and 0.5 BTC from the second output will be spent to child #19. The remaining 0.5 BTC from the second output will be sent back to a change address. In this way, it is impossible for an observer to correlate that the two outputs originally belonged to the same sender or were part of the same payment[10].\n\nMotivation\n\nAddresses are a tedious part of living in the cryptocurrency-enabled world. With hundreds of contacts and dozens of popular currencies, keeping track of which people provided which addresses for which coins makes life all the more difficult. Widespread adoption of a Universal Addressing format would allow users to share one address and accept many cryptocurrencies in the same wallet. As merchants and exchanges support and use new currencies, new addresses do not need to be exchanged among users. When sender wallets support \u201cEnhanced Privacy Mode\u201d, a substantial gain in transactional privacy is also obtained by the use of Universal Addresses.\n\nRationale\n\nReferences from the above text:\n\n[1]: This is the example annotation appearing in the \u201cA Note on Annotations and Rationale in this BIP\u201d subsection of the \u201cSpecification\u201d section.\n\n[2]: For certain blockchains that do not implement transactional \u201cinputs and outputs\u201d, this permits transactions to be made in a way that permits single-use addressing. For these coins, when the original recipient wishes to spend the received coins which are in multiple addresses, they may do so in one of two ways:\n1). If the original recipient wishes to send all received coins out as one blockchain-level transaction and from one blockchain-level address, they may first create many blockchain-level transactions collecting the coins into a single \u201cchange address\u201d and then spend the coins all at once from that address to the next recipient.\n2). If the original recipient wishes to spend using multiple addresses (i.e. the next recipient also uses Universal Addresses), the original recipient may simply empty each of the addresses they would like to spend from; the original recipient may either choose to forward all coins in a given address to the next recipient, or to forward some of the coins to the next recipient and the rest to a new \u201cchange address.\u201d This same model can apply to Bitcoin. In any case, the advantage is that it makes for better privacy because multi-transactional payments do not permit correlation of any of the outputs to any single user. It is also possible to send one transaction on blockchain A and another transaction on blockchain B as part of the same payment.\n\n[3]: Private keys are never used, and since the Bitcoin Testnet (normally 0x043587CF) is covered by level 3 SLIP44 derivation, no other version prefixes are needed.\n\n[4]: Not all cryptocurrency projects will be initially compatible with BIP${BIPNUM} Universal Addresses out of the box. Does that make these addresses non-universal? How non-universal is UPnP? This BIP defines a standard that works for most use-cases and most currencies most of the time. If enough people adopt it, non-compliant projects MAY find a way to join the standard.\n\n[5]: In particular, situations where a group of entities know a single Universal Address for a member, and where the transactions of the members of the group which involve the known Universal Address are not intended to be public should be avoided. By publishing the known Universal Address, a single member of the group can compromise the privacy of the transactions of all group members involving the known Universal Address. Each recipient SHOULD take care to allocate new Universal Addresses for each entity with whom they intend to transact business; even if an allocated address never gets used by a sender, a completely new address SHOULD be allocated by the recipient for each potential sender when privacy is strictly required because the previously-designated sender can learn the transactional activity between the newly-designated sender and the recipient if addresses are reused.\n\n[6]: Conversion can occur by simply deserializing the string, removing the unnecessary fields and re-serializing to the new format.\n\n[7]: Since Universal Addresses can be reused, the user\u2019s wallet could keep an associative list mapping names to Universal Addresses. Wallets MAY consider making this look like an address book, where the user can add their associates as contacts.\n\n[8]: Wallets MAY use a binary search-style querying strategy to speed up this process as opposed to a linear search of the blockchain. The wallet MAY also cache the highest known-to-be-used shield counter for each previously-checked currency of each Universal Address it has seen in the past.\n\n[9]: Wallets SHOULD always check shield counters even if cached data exists, because a publicly-known Universal Address could have been used by another sender. However, caching speeds up future checks because the wallet knows that the shield value is not less than the cached value.\n\n[10]: In typical Bitcoin transactions, such correlations are possible and are widely used for \u201cblockchain forensics.\u201d This new mode of wallet operation represents a substantial privacy improvement for Bitcoin and for all compliant[4] SLIP44 cryptocurrencies.\n\n[11]: It is also possible for the sender to conduct a multi-blockchain payment. For example, the sender might send one Bitcoin transaction and two Litecoin transactions. The sender SHOULD only attempt this with communication and coordination with the recipient to avoid confusion. The sender always has an incentive to ensure the recipient properly receives the payment.\n\nOther considerations:\n\nThe final set of design decisions made with regard to this BIP are documented below in a Q&A/interview-style format:\n\nQ: Will it be easy to lose coins since an address is no longer associated with a single cryptocurrency?\n\nA: This is a valid concern, but there are quite a large number of projects without unique address formats. Specifically, ERC20 coins use hex strings while Bitcoin SV and Bitcoin both use base58. Universal Addresses will be a net benefit because each project gets its own pool of address space. Additionally, the \u201caccept\u201d parameter might only contain a single SLIP44 symbol, making Universal Addresses the de facto address format for many projects.\n\nWallets implementing Universal Addresses SHOULD append the \u201caccept\u201d parameter, and senders SHOULD NOT send coins that are not listed by the \u201caccept\u201d header when specified. Also, the money wouldn't actually be lost in these situations. Assuming the root private node is safe, derivation of the right path will make recovering coins fairly straightforward. Additionally, high quality multi-currency wallet implementations should consider scanning popular blockchains for transactions even if those chains are otherwise unsupported. This can alert the user in cases where unsupported coins were received.\n\nQ: For split transaction payments, no single TXID exists. This makes accounting harder.\n\nA: In the vast majority of cases, the sender should get the recipient to simply come up with an invoice number or \u201cpayment ID\u201d that can be communicated to the sender for their records. Listing all relevant TXIDs is another possible solution. Calculating the bitwise XOR of all relevant TXIDs to create a single \u201cMTXID\u201d is also possible and could be the subject for a future BIP. In any case, it is a valid concern that \u201cEnhanced Privacy Mode\u201d deviates from the standard transactional model. If a single TXID is strictly required, a multi-transactional payment should not be used.\n\nQ: It is the sender\u2019s choice whether to use a split payment or \u201cEnhanced Privacy Mode\u201d. If they choose not to do so, can\u2019t the recipient\u2019s privacy be harmed?\n\nA: In existing implementations, the sender can breach their own privacy in many ways by revealing participation in a transaction. The onus is always on the sender of a transaction to ensure that their privacy is protected since the recipient does not control whether the sender uses \u201cEnhanced Privacy Mode.\" With Universal Addresses, each sender makes their own choice about privacy and their decision does not effect the privacy of the recipient or any other senders. In any case, future BIPs might also propose recipient-controlled preferences for privacy modes using additional URL-like query parameters.\n\nQ: Can\u2019t a sender publish the recipient\u2019s non-public Universal Address to compromise the recipient's privacy?\n\nA: Recipients should only share the same non-public Universal Address with one sender. Thus, the impact of such a disclosure is limited to transactions strictly involving this particular sender. Refer to the \u201cUniversal Address Sharing\u201c subsection of the \u201cSpecification\u201d section and [5] for further details. It is also worth noting that by revealing the non-public Universal Address, the sender explicitly notifies the recipient that they have breached the recipient's implicit trust relationship. Since the recipient gave the non-public Universal Address solely to this sender and since the recipient knows that they were not the one to have published it, the recipient can be certain that the sender published the address. The sender will lose the implicit trust of the recipient to maintain privacy.\n\nQ: Suppose a recipient publishes their own previously-undisclosed non-public Universal Address. Would this reveal that two or more spent outputs were from the same sender?\n\nA: Even if the Universal Address is publicly revealed, it does not prove that any two transactions sent from different source addresses are part of the same payment or even that they came from the same sender. Notwithstanding the above, the sender should understand that their privacy is determined by their own actions, not the actions of the recipient. If the sender failed to re-use addresses and then the recipient published the Universal Address revealing a pattern of the sender\u2019s single-address activity, the recipient is not liable for the sender\u2019s negligence.\n\nQ: Universal Addresses are long. What can be done to shorten them?\n\nA: Elimination of version bytes, parent fingerprint, child number and node depth in combination with the creation of a URI prefix would decrease length and would also make for another great BIP.\n\nQ: Is it likely that people will get Universal Addresses mixed up with normal BIP32 extended public keys?\n\nA: As they are currently used, extended keys are generally distributed at the root level. People may attempt to differentiate them because the node depth will always be 2 for Universal Addresses. Additionally, an extended public key is probably a Universal Address if its parent fingerprint and child index have been zeroed, but Universal Addresses may also exist with these values populated. A future BIP proposing a URI-denoted identifier (\u201cpay:\u2026\u201d) would also solve this problem. Ideally such a BIP would also reduce the length of Universal Addresses. In any case, the likelihood for mistakes is small considering that BIP32 extended public keys are typically only used by advanced users.\n\nQ: Should the version bytes defined in BIP32 be removed or changed for use with this BIP?\n\nA: BIP43 recommends that version bytes do not change across use-cases. If a new URI scheme is proposed for Universal Addresses in a future BIP, the effective result would be that such an identifier could replace the version bytes, because it would serve to identify the resource as a Universal Address. Version bytes are maintained by this BIP to create full backwards-compatibility with BIP32 extended public keys.\n\nQ: XYZCoin is incompatible with this BIP because BIP32 derivation will not work with Ed25519 or some other cryptography\n\nA: BIP${BIPNUM} Universal Addresses were designed to work well for most people and most cryptocurrency projects most of the time. Since anyone is free to start a new project, it is entirely possible that existing or future projects are non-compliant with this BIP. Consideration should be given to past projects which existed before this BIP\u2019s publication, since they could not have known about this BIP at the time of their inception. However, the benefits to users and the wider cryptocurrency ecosystem in implementing a standard address format MUST NOT be underestimated.\n\nReferences\n\n- BIP32\n- BIP43\n- BIP44\n- SLIP44\n- RFC-2119"
            }
        ],
        "thread_summary": {
            "title": ": Universal Addresses",
            "categories": [
                "bitcoin-dev",
                "New BIP"
            ],
            "authors": [
                "Ty Everett"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 27859
        }
    },
    {
        "title": "[bitcoin-dev] Base64-encoded descriptors",
        "thread_messages": [
            {
                "author": "Chris Belcher",
                "date": "2019-12-24T17:06:01",
                "message_text_only": "I've recently been playing around with descriptors, and they are very\nnice to work with. They should become the standard for master public\nkeys IMO.\n\nOne downside is that users cant easily copypaste them to-and-fro to make\nwatch-only wallet. The descriptors contain parenthesis and commas which\nstop highlighting by double-clicking. Also the syntax might look scary\nto newbs.\n\nAn obvious solution is to base64 encode the descriptors. Then users\nwould get a text blog as the master public key without any extra details\nto bother them, and developers can easily base64 decode for developing\nwith them.\n\nA complication might be the descriptor checksum. If there's a typo in\nthe base64 text then that could decode into multiple character errors in\nthe descriptor, which might be problematic for the checksum. Maybe the\ndescriptor could be base64 encoded without the checksum, then attach the\nchecksum to the end of the base64 text.\n\nThoughts?\n\nI didn't come up with these ideas, they came from discussions with achow101."
            },
            {
                "author": "Spencer Dupre`",
                "date": "2019-12-24T19:09:33",
                "message_text_only": "Sounds like a good UX improvement, but do we really need to introduce a new\nencoding? Perhaps bech32 could be used instead.\n\nOn Tue, Dec 24, 2019, 12:07 PM Chris Belcher via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I've recently been playing around with descriptors, and they are very\n> nice to work with. They should become the standard for master public\n> keys IMO.\n>\n> One downside is that users cant easily copypaste them to-and-fro to make\n> watch-only wallet. The descriptors contain parenthesis and commas which\n> stop highlighting by double-clicking. Also the syntax might look scary\n> to newbs.\n>\n> An obvious solution is to base64 encode the descriptors. Then users\n> would get a text blog as the master public key without any extra details\n> to bother them, and developers can easily base64 decode for developing\n> with them.\n>\n> A complication might be the descriptor checksum. If there's a typo in\n> the base64 text then that could decode into multiple character errors in\n> the descriptor, which might be problematic for the checksum. Maybe the\n> descriptor could be base64 encoded without the checksum, then attach the\n> checksum to the end of the base64 text.\n>\n> Thoughts?\n>\n> I didn't come up with these ideas, they came from discussions with\n> achow101.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191224/4255cd9f/attachment.html>"
            },
            {
                "author": "Trey Del Bonis",
                "date": "2019-12-25T01:02:09",
                "message_text_only": "Part of the aversion to using bech32 may be that the BCH code used in\nbech32 for error detection doesn't hold up for messages longer than some\nlength (that I can't remember off the top of my head).  It still encodes\nand decodes perfectly well but a decoder won't be guaranteed to detect\npotential errors, so that's somewhat wasted there.  Maybe someone should\ndefine a derivatives of bech32 that retains error detection properties for\nlonger message lengths, such as those used in lightning invoices.\n\nQR codes (as Pavol mentioned) have built-in error detection (using its own\nBCH code scheme), somewhat mitigate this when used there.  Although\npersonally I'm skeptical of how useful payment descriptors are for the\nkinds of quick transactions that QR codes work well for.\n\n-Trey\n\nOn Tue, Dec 24, 2019, 6:55 PM Spencer Dupre` via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Sounds like a good UX improvement, but do we really need to introduce a\n> new encoding? Perhaps bech32 could be used instead.\n>\n> On Tue, Dec 24, 2019, 12:07 PM Chris Belcher via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> I've recently been playing around with descriptors, and they are very\n>> nice to work with. They should become the standard for master public\n>> keys IMO.\n>>\n>> One downside is that users cant easily copypaste them to-and-fro to make\n>> watch-only wallet. The descriptors contain parenthesis and commas which\n>> stop highlighting by double-clicking. Also the syntax might look scary\n>> to newbs.\n>>\n>> An obvious solution is to base64 encode the descriptors. Then users\n>> would get a text blog as the master public key without any extra details\n>> to bother them, and developers can easily base64 decode for developing\n>> with them.\n>>\n>> A complication might be the descriptor checksum. If there's a typo in\n>> the base64 text then that could decode into multiple character errors in\n>> the descriptor, which might be problematic for the checksum. Maybe the\n>> descriptor could be base64 encoded without the checksum, then attach the\n>> checksum to the end of the base64 text.\n>>\n>> Thoughts?\n>>\n>> I didn't come up with these ideas, they came from discussions with\n>> achow101.\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191224/ad21c428/attachment-0001.html>"
            },
            {
                "author": "Pavol Rusnak",
                "date": "2019-12-24T19:25:02",
                "message_text_only": "I'd rather see something using Base58 or even better Bech32. Base64 is not\nURL/QR code friendly.\n\nOn Tue, Dec 24, 2019, 18:06 Chris Belcher via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I've recently been playing around with descriptors, and they are very\n> nice to work with. They should become the standard for master public\n> keys IMO.\n>\n> One downside is that users cant easily copypaste them to-and-fro to make\n> watch-only wallet. The descriptors contain parenthesis and commas which\n> stop highlighting by double-clicking. Also the syntax might look scary\n> to newbs.\n>\n> An obvious solution is to base64 encode the descriptors. Then users\n> would get a text blog as the master public key without any extra details\n> to bother them, and developers can easily base64 decode for developing\n> with them.\n>\n> A complication might be the descriptor checksum. If there's a typo in\n> the base64 text then that could decode into multiple character errors in\n> the descriptor, which might be problematic for the checksum. Maybe the\n> descriptor could be base64 encoded without the checksum, then attach the\n> checksum to the end of the base64 text.\n>\n> Thoughts?\n>\n> I didn't come up with these ideas, they came from discussions with\n> achow101.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191224/8cbce0ca/attachment.html>"
            },
            {
                "author": "William Casarin",
                "date": "2019-12-25T17:17:18",
                "message_text_only": "Hey Chris,\n\nChris Belcher via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> writes:\n> I've recently been playing around with descriptors, and they are very\n> nice to work with. They should become the standard for master public\n> keys IMO.\n>\n> One downside is that users cant easily copypaste them to-and-fro to make\n> watch-only wallet. The descriptors contain parenthesis and commas which\n> stop highlighting by double-clicking. Also the syntax might look scary\n> to newbs.\n>\n> An obvious solution is to base64 encode the descriptors. Then users\n> would get a text blog as the master public key without any extra details\n> to bother them, and developers can easily base64 decode for developing\n> with them.\n\nI don't think encoding descriptors is a good idea. Encoding makes more\nsense if it's non-human-readable binary data that you want transfer over\na plaintext channel.\n\nDescriptors aren't binary data, and have a wealth of useful information\nthat you can view at a glance. Obfuscating this information just to gain\nthe ability to copy-paste doesn't seem like a good idea.\n\n> I didn't come up with these ideas, they came from discussions with achow101.\n\nI suggested base58 or base62 +hrp for PSBT in id:87zhzlbfq5.fsf at jb55.com\n[1] for the reasons that you mentioned, so I'm a bit sad that base64 was\nchosen. base64 isn't really good for double-click copy-pasting, it\ncontains characters such as +/= which aren't always included when\ndouble-clicking. I prefer bech32, base58 or base62. In this case,\nencoding of any kind doesn't make much sense IMO.\n\nCheers,\nWill\n\n[1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-June/016151.html\n\n\n-- \nhttps://jb55.com"
            },
            {
                "author": "Andrew Chow",
                "date": "2019-12-26T05:18:00",
                "message_text_only": "Hi All,\n\nJust a few comments about choosing an encoding and why this is even\nbeing proposed.\n\n\nOn Wednesday, December 25, 2019 12:17 PM, William Casarin via\nbitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I don't think encoding descriptors is a good idea. Encoding makes more\n> sense if it's non-human-readable binary data that you want transfer\n> over\n> a plaintext channel.\n>\n> Descriptors aren't binary data, and have a wealth of useful\n> information\n> that you can view at a glance. Obfuscating this information just to\n> gain\n> the ability to copy-paste doesn't seem like a good idea.\n\nThe main reasons this was proposed in the first place is because of\nconcerns that users will be unwilling to use or be confused by descriptors.\nThere is a concern that users will not understand the commas,\nparentheses, brackets, etc. syntax of descriptors and thus only copy\npart of it.\nThere is also the concern that users will see this code-like syntax and\nbe intimidated by it so they will not want to handle them.\n\nSo my (offhanded) suggestion was to encode it in some way to just make\nit look like some magic string that they need to handle as one unit.\n\n\n> so I'm a bit sad that base64 was\n> chosen. base64 isn't really good for double-click copy-pasting, it\n> contains characters such as +/= which aren't always included when\n> double-clicking. I prefer bech32, base58 or base62.\n\nOn Tuesday, December 24, 2019 2:09 PM, Spencer Dupre` via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Sounds like a good UX improvement, but do we really need to introduce\na new encoding? Perhaps bech32 could be used instead.\n\nOn Tuesday, December 24, 2019 2:25 PM, Pavol Rusnak via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I'd rather see something using Base58 or even better Bech32. Base64 is\nnot URL/QR code friendly.\n\nA different encoding scheme could certainly be used. Base64 was\nsuggested in my comments to Chris and others as it is a well known\nencoding scheme that doesn't already define its own checksum as Base58\nand Bech32 do. This is an important detail because descriptors *also*\nhave their own checksum scheme.\n\nWhile other encoding methods could be used, I do want to point out that\nit would be nice to stick to things that already exist. We could use a\nbech32-like encoding, just with the different BCH code that descriptors\nuse instead of the bech32 code, but calling that bech32 would be a bit\nconfusing. And I don't think we should use Base58 at all.\n\nOn Tuesday, December 24, 2019 8:02 PM, Trey Del Bonis via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Part of the aversion to using bech32 may be that the BCH code used in\n> bech32 for error detection doesn't hold up for messages longer than\n> some length (that I can't remember off the top of my head).  It still\n> encodes and decodes perfectly well but a decoder won't be guaranteed\n> to detect potential errors, so that's somewhat wasted there.  Maybe\n> someone should define a derivatives of bech32 that retains error\n> detection properties for longer message lengths, such as those used in\n> lightning invoices.\n\nDescriptors already have their own BCH code for descriptor checksums\noptimized for their length and character rset. This can be repurposed to\nbe used with whatever encoding scheme is chosen so long as the\nencoding's character set is covered by the descriptor checksum character\nset. The checksum's character set is fairly large and covers all(?)\ncharacters on a standard keyboard so that descriptors could be expanded\nwith other features in the future. Thus it should cover any encoding\nscheme that is suggested.\n\nMore information about the descriptor checksum can be found at\nhttps://github.com/bitcoin/bitcoin/blob/master/src/script/descriptor.cpp#L26"
            }
        ],
        "thread_summary": {
            "title": "Base64-encoded descriptors",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Chris Belcher",
                "Trey Del Bonis",
                "William Casarin",
                "Pavol Rusnak",
                "Spencer Dupre`",
                "Andrew Chow"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 12601
        }
    },
    {
        "title": "[bitcoin-dev] Blind Merged Mining with covenants ( sighash_anyprevout / op_ctv )",
        "thread_messages": [
            {
                "author": "Ruben Somsen",
                "date": "2019-12-26T02:23:10",
                "message_text_only": "Blind Merged Mining (BMM) is the idea of committing the hash of another\nblockchain into a unique location on the Bitcoin blockchain, and paying a\nBitcoin fee to miners for the privilege of deciding this hash and capturing\nthe fees inside the other blockchain. Since miners don\u2019t have to know what\nthe hash represents and are simply incentivized to choose the highest\nbidder, it requires no extra validation on their part (\u201cblind\u201d). This idea\nwas originally conceived of by Paul Sztorc, but required a specific soft\nfork. [0]\n\nIn essence, BMM is a mechanism that allows external blockchains (altcoins,\ntokens) to outsource their mining to the Bitcoin blockchain. Instead of\nburning electricity with ASICs, they pay bitcoins to miners, who in turn\nwill perform Proof-of-Work (PoW) for the privilege of obtaining this\npayment. This increases the total PoW on the Bitcoin blockchain, which adds\nto the security of the Bitcoin network. It's an easy consensus mechanism to\nimplement, and simple to mine, only requiring full node software for both\nchains and some bitcoins.\n\nWhile it may be hard to justify this as a soft fork, it turns out that the\ninclusion of sighash_anyprevout (previously sighash_noinput) into Bitcoin\nis sufficient to make BMM work, because, as noted by Anthony Towns [1],\nsighash_anyprevout allows for the creation of op_checktemplateverify\n(op_ctv, previously op_securethebag) style covenants [2]. With that, we can\ngenerate the following without any trusted setup:\n\n- A long string of sighash_anyprevout transactions, each only spendable by\nthe next (the spending signature is placed in the output script, making it\na covenant)\n- RBF enabled and signed with sighash flags single, anyonecanpay, and\nanyprevout, allowing the addition of inputs and outputs in order to pay\nfees (similar to fees in eltoo [3])\n- A relative locktime of one block, ensuring only one transaction gets\nmined per block\n\nA complete transaction flow diagram can be found here:\nhttps://gist.github.com/RubenSomsen/5e4be6d18e5fa526b17d8b34906b16a5#file-bmm-svg\n\n(Note that op_ctv instead of sighash_anyprevout would require the use of\nCPFP, because all outputs need to be pre-defined.)\n\nThis setup generates a unique location for the hash, which can be freely\ncompeted for by anyone with the help of RBF. The hash can be committed into\nthe fee paying output via taproot. If the block corresponding to the hash\nis not revealed or invalid, then the BMM block simply gets orphaned, just\nlike in Sztorc\u2019s proposal.\n\nWhile the Bitcoin blockchain will be unaware of the BMM chain, the opposite\ndoes not have to be true. This enables some interesting possibilities. For\ninstance, you could make a conditional BMM token transfer that only goes\nthrough if a specific Bitcoin transaction occurs within a certain period of\ntime, thus enabling atomic swaps (especially useful when combined with\nasset issuance/colored coins/pegged tokens). It would also be possible to\ncreate contracts based on Bitcoin\u2019s hashrate and such.\n\nIt seems inevitable that this chain will need some kind of native token in\norder to pay for fees. This makes me uneasy. The fairest and least\nspeculation-inducing method I can think of is a perpetual one-way peg,\nwhere at any time 1 BTC can be burned for 1 token, essentially preserving\nthe 21M coin limit. Coins that are burned will never return, benefiting all\nBTC holders equally. Holding BTC will always be preferable, because the\noption to move is always open to you. This should disincentivize\nspeculation -- it only makes sense to move coins if they serve an immediate\npurpose.\n\nGiven the lack of a block subsidy, there may not be enough impetus to move\nthe chain forward instead of enacting a reorg. However, BMM reorgs are\nsomewhat unique in that they will have to compete for the same unique\nlocation that the original chain is using. A 10-block reorg would take 100\nminutes on average to catch up, during which the original chain won\u2019t move\nforward. If fee pressure of new transactions is targeted exclusively\ntowards the original chain during this time [4], there would be forward\npressure that makes reorgs more expensive. Whether this mitigation is\nsufficient is an open question.\n\nFinally, it is worth asking whether BMM interferes too much with the\nexisting incentive structure of Bitcoin. I don\u2019t have a clear answer, but\nit should be noted that a much more inefficient version of BMM is already\npossible today. One could simply use up lots of block space instead of\nspecifying a unique location for the hash, as demonstrated by Veriblock\n[5]. I therefore believe that the same argument as adding data via\nop_return applies here -- if it\u2019s not supported, more wasteful methods may\nbe utilized instead.\n\nSome technical details (thanks to Anthony Towns for providing his insights):\n\n- Since the exact signature is committed to ahead of time, private key\nsecurity is actually irrelevant. You can simply use G to replace both R and\nP instead of the usual s = r + e*p. This means anyone can easily\npre-compute all the sighash_anyprevout signatures with s = 1 + e.\n\n- Assuming taproot, the spending script will be inside a taproot leaf,\nmeaning there is a key spend path which should be made unusable in order to\nenforce the covenant. This can be achieved with a NUMS such as\nhashToCurve(G) =  H, which can then be used as the internal taproot key T =\nH + hash(H||bmm_hash)*G.\n\n-- Ruben Somsen\n\n\n[0] https://github.com/bitcoin/bips/blob/master/bip-0301.mediawiki\n\n[1]\nhttps://www.mail-archive.com/bitcoin-dev@lists.linuxfoundation.org/msg08075.html\n\n[2] https://github.com/JeremyRubin/bips/blob/ctv-v2/bip-ctv.mediawiki\n\n[3] https://blockstream.com/eltoo.pdf\n\n[4]\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-September/016352.html\n\n[5] https://twitter.com/lopp/status/1081558829454802945\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191226/fdba0ee1/attachment.html>"
            },
            {
                "author": "Nick Gregory",
                "date": "2019-12-26T12:32:26",
                "message_text_only": "This not similar to MainStay?\n\nhttps://commerceblock.readthedocs.io/en/latest/mainstay/index.html\n\nhttps://mainstay.xyz\n\n\nOn Thu, Dec 26, 2019 at 2:25 AM Ruben Somsen via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Blind Merged Mining (BMM) is the idea of committing the hash of another\n> blockchain into a unique location on the Bitcoin blockchain, and paying a\n> Bitcoin fee to miners for the privilege of deciding this hash and capturing\n> the fees inside the other blockchain. Since miners don\u2019t have to know what\n> the hash represents and are simply incentivized to choose the highest\n> bidder, it requires no extra validation on their part (\u201cblind\u201d). This idea\n> was originally conceived of by Paul Sztorc, but required a specific soft\n> fork. [0]\n>\n> In essence, BMM is a mechanism that allows external blockchains (altcoins,\n> tokens) to outsource their mining to the Bitcoin blockchain. Instead of\n> burning electricity with ASICs, they pay bitcoins to miners, who in turn\n> will perform Proof-of-Work (PoW) for the privilege of obtaining this\n> payment. This increases the total PoW on the Bitcoin blockchain, which adds\n> to the security of the Bitcoin network. It's an easy consensus mechanism to\n> implement, and simple to mine, only requiring full node software for both\n> chains and some bitcoins.\n>\n> While it may be hard to justify this as a soft fork, it turns out that the\n> inclusion of sighash_anyprevout (previously sighash_noinput) into Bitcoin\n> is sufficient to make BMM work, because, as noted by Anthony Towns [1],\n> sighash_anyprevout allows for the creation of op_checktemplateverify\n> (op_ctv, previously op_securethebag) style covenants [2]. With that, we can\n> generate the following without any trusted setup:\n>\n> - A long string of sighash_anyprevout transactions, each only spendable by\n> the next (the spending signature is placed in the output script, making it\n> a covenant)\n> - RBF enabled and signed with sighash flags single, anyonecanpay, and\n> anyprevout, allowing the addition of inputs and outputs in order to pay\n> fees (similar to fees in eltoo [3])\n> - A relative locktime of one block, ensuring only one transaction gets\n> mined per block\n>\n> A complete transaction flow diagram can be found here:\n>\n> https://gist.github.com/RubenSomsen/5e4be6d18e5fa526b17d8b34906b16a5#file-bmm-svg\n>\n> (Note that op_ctv instead of sighash_anyprevout would require the use of\n> CPFP, because all outputs need to be pre-defined.)\n>\n> This setup generates a unique location for the hash, which can be freely\n> competed for by anyone with the help of RBF. The hash can be committed into\n> the fee paying output via taproot. If the block corresponding to the hash\n> is not revealed or invalid, then the BMM block simply gets orphaned, just\n> like in Sztorc\u2019s proposal.\n>\n> While the Bitcoin blockchain will be unaware of the BMM chain, the\n> opposite does not have to be true. This enables some interesting\n> possibilities. For instance, you could make a conditional BMM token\n> transfer that only goes through if a specific Bitcoin transaction occurs\n> within a certain period of time, thus enabling atomic swaps (especially\n> useful when combined with asset issuance/colored coins/pegged tokens). It\n> would also be possible to create contracts based on Bitcoin\u2019s hashrate and\n> such.\n>\n> It seems inevitable that this chain will need some kind of native token in\n> order to pay for fees. This makes me uneasy. The fairest and least\n> speculation-inducing method I can think of is a perpetual one-way peg,\n> where at any time 1 BTC can be burned for 1 token, essentially preserving\n> the 21M coin limit. Coins that are burned will never return, benefiting all\n> BTC holders equally. Holding BTC will always be preferable, because the\n> option to move is always open to you. This should disincentivize\n> speculation -- it only makes sense to move coins if they serve an immediate\n> purpose.\n>\n> Given the lack of a block subsidy, there may not be enough impetus to move\n> the chain forward instead of enacting a reorg. However, BMM reorgs are\n> somewhat unique in that they will have to compete for the same unique\n> location that the original chain is using. A 10-block reorg would take 100\n> minutes on average to catch up, during which the original chain won\u2019t move\n> forward. If fee pressure of new transactions is targeted exclusively\n> towards the original chain during this time [4], there would be forward\n> pressure that makes reorgs more expensive. Whether this mitigation is\n> sufficient is an open question.\n>\n> Finally, it is worth asking whether BMM interferes too much with the\n> existing incentive structure of Bitcoin. I don\u2019t have a clear answer, but\n> it should be noted that a much more inefficient version of BMM is already\n> possible today. One could simply use up lots of block space instead of\n> specifying a unique location for the hash, as demonstrated by Veriblock\n> [5]. I therefore believe that the same argument as adding data via\n> op_return applies here -- if it\u2019s not supported, more wasteful methods may\n> be utilized instead.\n>\n> Some technical details (thanks to Anthony Towns for providing his\n> insights):\n>\n> - Since the exact signature is committed to ahead of time, private key\n> security is actually irrelevant. You can simply use G to replace both R and\n> P instead of the usual s = r + e*p. This means anyone can easily\n> pre-compute all the sighash_anyprevout signatures with s = 1 + e.\n>\n> - Assuming taproot, the spending script will be inside a taproot leaf,\n> meaning there is a key spend path which should be made unusable in order to\n> enforce the covenant. This can be achieved with a NUMS such as\n> hashToCurve(G) =  H, which can then be used as the internal taproot key T =\n> H + hash(H||bmm_hash)*G.\n>\n> -- Ruben Somsen\n>\n>\n> [0] https://github.com/bitcoin/bips/blob/master/bip-0301.mediawiki\n>\n> [1]\n> https://www.mail-archive.com/bitcoin-dev@lists.linuxfoundation.org/msg08075.html\n>\n> [2] https://github.com/JeremyRubin/bips/blob/ctv-v2/bip-ctv.mediawiki\n>\n> [3] https://blockstream.com/eltoo.pdf\n>\n> [4]\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-September/016352.html\n>\n> [5] https://twitter.com/lopp/status/1081558829454802945\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191226/8a3166d9/attachment.html>"
            },
            {
                "author": "Ruben Somsen",
                "date": "2019-12-26T16:52:43",
                "message_text_only": "Hello Nick,\n\nThank you for your interest.\n\nIt is quite different. Unlike MainStay, BMM isn't federation controlled.\nIt's a decentralized consensus mechanism that can function entirely without\na federation. BMM blocks are chosen by the highest bidder, which can be\nanyone.\n\nNote that it would be entirely possible for federations to issue two-way\npegged tokens on this decentralized chain, but keep in mind you'll have two\nchains to worry about in terms of reorg potential (i.e. slow peg-outs).\n\nCheers,\nRuben\n\nOn Thu, Dec 26, 2019 at 1:32 PM Nick Gregory <nico.gregory at gmail.com> wrote:\n\n> This not similar to MainStay?\n>\n> https://commerceblock.readthedocs.io/en/latest/mainstay/index.html\n>\n> https://mainstay.xyz\n>\n>\n> On Thu, Dec 26, 2019 at 2:25 AM Ruben Somsen via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Blind Merged Mining (BMM) is the idea of committing the hash of another\n>> blockchain into a unique location on the Bitcoin blockchain, and paying a\n>> Bitcoin fee to miners for the privilege of deciding this hash and capturing\n>> the fees inside the other blockchain. Since miners don\u2019t have to know what\n>> the hash represents and are simply incentivized to choose the highest\n>> bidder, it requires no extra validation on their part (\u201cblind\u201d). This idea\n>> was originally conceived of by Paul Sztorc, but required a specific soft\n>> fork. [0]\n>>\n>> In essence, BMM is a mechanism that allows external blockchains\n>> (altcoins, tokens) to outsource their mining to the Bitcoin blockchain.\n>> Instead of burning electricity with ASICs, they pay bitcoins to miners, who\n>> in turn will perform Proof-of-Work (PoW) for the privilege of obtaining\n>> this payment. This increases the total PoW on the Bitcoin blockchain, which\n>> adds to the security of the Bitcoin network. It's an easy consensus\n>> mechanism to implement, and simple to mine, only requiring full node\n>> software for both chains and some bitcoins.\n>>\n>> While it may be hard to justify this as a soft fork, it turns out that\n>> the inclusion of sighash_anyprevout (previously sighash_noinput) into\n>> Bitcoin is sufficient to make BMM work, because, as noted by Anthony Towns\n>> [1], sighash_anyprevout allows for the creation of op_checktemplateverify\n>> (op_ctv, previously op_securethebag) style covenants [2]. With that, we can\n>> generate the following without any trusted setup:\n>>\n>> - A long string of sighash_anyprevout transactions, each only spendable\n>> by the next (the spending signature is placed in the output script, making\n>> it a covenant)\n>> - RBF enabled and signed with sighash flags single, anyonecanpay, and\n>> anyprevout, allowing the addition of inputs and outputs in order to pay\n>> fees (similar to fees in eltoo [3])\n>> - A relative locktime of one block, ensuring only one transaction gets\n>> mined per block\n>>\n>> A complete transaction flow diagram can be found here:\n>>\n>> https://gist.github.com/RubenSomsen/5e4be6d18e5fa526b17d8b34906b16a5#file-bmm-svg\n>>\n>> (Note that op_ctv instead of sighash_anyprevout would require the use of\n>> CPFP, because all outputs need to be pre-defined.)\n>>\n>> This setup generates a unique location for the hash, which can be freely\n>> competed for by anyone with the help of RBF. The hash can be committed into\n>> the fee paying output via taproot. If the block corresponding to the hash\n>> is not revealed or invalid, then the BMM block simply gets orphaned, just\n>> like in Sztorc\u2019s proposal.\n>>\n>> While the Bitcoin blockchain will be unaware of the BMM chain, the\n>> opposite does not have to be true. This enables some interesting\n>> possibilities. For instance, you could make a conditional BMM token\n>> transfer that only goes through if a specific Bitcoin transaction occurs\n>> within a certain period of time, thus enabling atomic swaps (especially\n>> useful when combined with asset issuance/colored coins/pegged tokens). It\n>> would also be possible to create contracts based on Bitcoin\u2019s hashrate and\n>> such.\n>>\n>> It seems inevitable that this chain will need some kind of native token\n>> in order to pay for fees. This makes me uneasy. The fairest and least\n>> speculation-inducing method I can think of is a perpetual one-way peg,\n>> where at any time 1 BTC can be burned for 1 token, essentially preserving\n>> the 21M coin limit. Coins that are burned will never return, benefiting all\n>> BTC holders equally. Holding BTC will always be preferable, because the\n>> option to move is always open to you. This should disincentivize\n>> speculation -- it only makes sense to move coins if they serve an immediate\n>> purpose.\n>>\n>> Given the lack of a block subsidy, there may not be enough impetus to\n>> move the chain forward instead of enacting a reorg. However, BMM reorgs are\n>> somewhat unique in that they will have to compete for the same unique\n>> location that the original chain is using. A 10-block reorg would take 100\n>> minutes on average to catch up, during which the original chain won\u2019t move\n>> forward. If fee pressure of new transactions is targeted exclusively\n>> towards the original chain during this time [4], there would be forward\n>> pressure that makes reorgs more expensive. Whether this mitigation is\n>> sufficient is an open question.\n>>\n>> Finally, it is worth asking whether BMM interferes too much with the\n>> existing incentive structure of Bitcoin. I don\u2019t have a clear answer, but\n>> it should be noted that a much more inefficient version of BMM is already\n>> possible today. One could simply use up lots of block space instead of\n>> specifying a unique location for the hash, as demonstrated by Veriblock\n>> [5]. I therefore believe that the same argument as adding data via\n>> op_return applies here -- if it\u2019s not supported, more wasteful methods may\n>> be utilized instead.\n>>\n>> Some technical details (thanks to Anthony Towns for providing his\n>> insights):\n>>\n>> - Since the exact signature is committed to ahead of time, private key\n>> security is actually irrelevant. You can simply use G to replace both R and\n>> P instead of the usual s = r + e*p. This means anyone can easily\n>> pre-compute all the sighash_anyprevout signatures with s = 1 + e.\n>>\n>> - Assuming taproot, the spending script will be inside a taproot leaf,\n>> meaning there is a key spend path which should be made unusable in order to\n>> enforce the covenant. This can be achieved with a NUMS such as\n>> hashToCurve(G) =  H, which can then be used as the internal taproot key T =\n>> H + hash(H||bmm_hash)*G.\n>>\n>> -- Ruben Somsen\n>>\n>>\n>> [0] https://github.com/bitcoin/bips/blob/master/bip-0301.mediawiki\n>>\n>> [1]\n>> https://www.mail-archive.com/bitcoin-dev@lists.linuxfoundation.org/msg08075.html\n>>\n>> [2] https://github.com/JeremyRubin/bips/blob/ctv-v2/bip-ctv.mediawiki\n>>\n>> [3] https://blockstream.com/eltoo.pdf\n>>\n>> [4]\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-September/016352.html\n>>\n>> [5] https://twitter.com/lopp/status/1081558829454802945\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191226/3e453af7/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Blind Merged Mining with covenants ( sighash_anyprevout / op_ctv )",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Nick Gregory",
                "Ruben Somsen"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 19992
        }
    },
    {
        "title": "[bitcoin-dev] Non-equal value CoinJoins. Opinions.",
        "thread_messages": [
            {
                "author": "nopara73",
                "date": "2019-12-27T18:03:49",
                "message_text_only": "The CashFusion research came out of the Bitcoin Cash camp, thus this\nprobably went under the radar of many of you. I would like to ask your\nopinions on the research's claim that, if non-equal value coinjoins can be\nreally relied on for privacy or not.\n\n(Btw, there were also similar ideas in the Knapsack paper in 2017:\nhttps://www.comsys.rwth-aachen.de/fileadmin/papers/2017/2017-maurer-trustcom-coinjoin.pdf\n )\n\nhttps://github.com/cashshuffle/spec/blob/master/CASHFUSION.md#avoiding-amount-linkages-through-combinatorics\n\n\nI copy the most relevant paragraphs here:\n\n  ---------BEGIN QUOTE ---------\n\n\nConsider a transaction where 10 people have each brought 10 inputs of\narbitary amounts in the neighborhood of ~0.1 BCH. One input might be\n0.03771049 BCH; the next might be 0.24881232 BCH, etc. All parties have\nchosen to consolidate their coins, so the transaction has 10 outputs of\naround 1 BCH. So the transaction has 100 inputs, and 10 outputs. The first\noutput might be 0.91128495, the next could be 1.79783710, etc.\n\nNow, there are 100!/(10!)^10 ~= 10^92 ways to partition the inputs into a\nlist of 10 sets of 10 inputs, but only a tiny fraction of these partitions\nwill produce the precise output list. So, how many ways produce this exact\noutput list? We can estimate with some napkin math. First, recognize that\nfor each partitioning, each output will typically land in a range of ~10^8\ndiscrete possibilities (around 1 BCH wide, with a 0.00000001 BCH\nresolution). The first 9 outputs all have this range of possibilities, and\nthe last will be constrained by the others. So, the 10^92 possibilies will\nland somewhere within a 9-dimensional grid that cointains (10^8)^9=10^72\npossible distinct sites, one site which is our actual output list. Since we\nare stuffing 10^92 possibilties into a grid that contains only 10^72 sites,\nthen this means on average, each site will have 10^20 possibilities.\n\nBased on the example above, we can see that not only are there a huge\nnumber of partitions, but that even with a fast algorithm that could find\nmatching partitions, it would produce around 10^20 possible valid\nconfigurations. With 10^20 possibilities, there is essentially no linkage.\nThe Cash Fusion scheme actually extends this obfuscation even further. Not\nonly can players bring many inputs, they can also have multiple outputs.\n---------END QUOTE ---------\n-- \nBest,\n\u00c1d\u00e1m\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191227/6b744205/attachment.html>"
            },
            {
                "author": "Ethan Heilman",
                "date": "2019-12-28T17:38:11",
                "message_text_only": "I'm only going to talk about cashfusion and not the knapsack paper.\n\nThe language they use to describe the cashfusion protocol is very\nbroad and could describe many things. Because it is hard so vague I\ndon't want to dismiss the cashfusion approach out of hand. For\ninstance they say: \"inputs of arbitary amounts in the neighborhood of\n~0.1 BCH\" what exactly does this mean?\n\nAttack 1:\nIf we assume arbitrary means any precision then a trivial attack is\npossible. Consider the case where one of the inputs has more precision\nthan any other input. This allows an attacker to trivially break the\nprivacy of that input:\n\nLets look at a toy example that takes 12 inputs and creates 3 outputs\ninputs:\n0.1525\n0.1225\n0.1145\n0.1443\n0.1144111\n0.1001\n0.1124\n0.1093\n0.1113\n0.1134\n0.1029\n0.1206\n\nOutputs:\n0.4648111\n0.5185\n0.4349\n\nClearly output output 0.4648111 contains input 0.1144111.\n\nAttack 2:\nLet's say you attempt to address this problem this by limiting the\nprecision of inputs to two decimal places i.e. 0.1X where 0<=X<=9.\nConsider the case of 10 users where each user is always joining sets\nof 10 inputs to create 1 output. Thus in total you would have 100\ninputs and 10 outputs in the coinjoin. If one of those outputs is 2\nthen you know its inputs must all be 0.2. Using this method you can\nstart eliminate input output pairs far faster brute force. How much\nfaster is hard to say without adding additional assumptions for\ninstance are these inputs amounts drawn from a uniform distribution?\n\nI want to be clear. I'm not saying cashfusion is broken or that this\nmore inputs than outputs technique is a dead end. However the\ndescription given is vague and could be interpreted to describe a\nbroken protocol. Is this actively being used?\n\nOn Fri, Dec 27, 2019 at 8:29 PM nopara73 via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> The CashFusion research came out of the Bitcoin Cash camp, thus this probably went under the radar of many of you. I would like to ask your opinions on the research's claim that, if non-equal value coinjoins can be really relied on for privacy or not.\n>\n> (Btw, there were also similar ideas in the Knapsack paper in 2017: https://www.comsys.rwth-aachen.de/fileadmin/papers/2017/2017-maurer-trustcom-coinjoin.pdf )\n>\n> https://github.com/cashshuffle/spec/blob/master/CASHFUSION.md#avoiding-amount-linkages-through-combinatorics\n>\n> I copy the most relevant paragraphs here:\n>\n>   ---------BEGIN QUOTE ---------\n>\n>\n> Consider a transaction where 10 people have each brought 10 inputs of arbitary amounts in the neighborhood of ~0.1 BCH. One input might be 0.03771049 BCH; the next might be 0.24881232 BCH, etc. All parties have chosen to consolidate their coins, so the transaction has 10 outputs of around 1 BCH. So the transaction has 100 inputs, and 10 outputs. The first output might be 0.91128495, the next could be 1.79783710, etc.\n>\n> Now, there are 100!/(10!)^10 ~= 10^92 ways to partition the inputs into a list of 10 sets of 10 inputs, but only a tiny fraction of these partitions will produce the precise output list. So, how many ways produce this exact output list? We can estimate with some napkin math. First, recognize that for each partitioning, each output will typically land in a range of ~10^8 discrete possibilities (around 1 BCH wide, with a 0.00000001 BCH resolution). The first 9 outputs all have this range of possibilities, and the last will be constrained by the others. So, the 10^92 possibilies will land somewhere within a 9-dimensional grid that cointains (10^8)^9=10^72 possible distinct sites, one site which is our actual output list. Since we are stuffing 10^92 possibilties into a grid that contains only 10^72 sites, then this means on average, each site will have 10^20 possibilities.\n>\n> Based on the example above, we can see that not only are there a huge number of partitions, but that even with a fast algorithm that could find matching partitions, it would produce around 10^20 possible valid configurations. With 10^20 possibilities, there is essentially no linkage. The Cash Fusion scheme actually extends this obfuscation even further. Not only can players bring many inputs, they can also have multiple outputs.\n>\n> ---------END QUOTE ---------\n> --\n> Best,\n> \u00c1d\u00e1m\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-12-28T23:25:07",
                "message_text_only": "Good morning Adam,\n\n> The CashFusion research came out of the Bitcoin Cash camp, thus this probably went under the radar of many of you. I would like to ask your opinions on the research's claim that, if non-equal value coinjoins can be really relied on for privacy or not.\n>\n> (Btw, there were also similar ideas in the Knapsack paper in 2017:\u00a0https://www.comsys.rwth-aachen.de/fileadmin/papers/2017/2017-maurer-trustcom-coinjoin.pdf\u00a0)\u00a0\n>\n> https://github.com/cashshuffle/spec/blob/master/CASHFUSION.md#avoiding-amount-linkages-through-combinatorics\u00a0\u00a0\n>\n> I copy the most relevant paragraphs here:\n>\n> \u00a0 ---------BEGIN QUOTE ---------\u00a0\n> \u00a0\n>\n> Consider a transaction where 10 people have each brought 10 inputs of arbitary amounts in the neighborhood of ~0.1 BCH. One input might be 0.03771049 BCH; the next might be 0.24881232 BCH, etc. All parties have chosen to consolidate their coins, so the transaction has 10 outputs of around 1 BCH. So the transaction has 100 inputs, and 10 outputs. The first output might be 0.91128495, the next could be 1.79783710, etc.\n>\n> Now, there are 100!/(10!)^10 ~= 10^92 ways to partition the inputs into a list of 10 sets of 10 inputs, but only a tiny fraction of these partitions will produce the precise output list. So, how many ways produce this exact output list? We can estimate with some napkin math. First, recognize that for each partitioning, each output will typically land in a range of ~10^8 discrete possibilities (around 1 BCH wide, with a 0.00000001 BCH resolution). The first 9 outputs all have this range of possibilities, and the last will be constrained by the others. So, the 10^92 possibilies will land somewhere within a 9-dimensional grid that cointains (10^8)^9=10^72 possible distinct sites, one site which is our actual output list. Since we are stuffing 10^92 possibilties into a grid that contains only 10^72 sites, then this means on average, each site will have 10^20 possibilities.\n>\n> Based on the example above, we can see that not only are there a huge number of partitions, but that even with a fast algorithm that could find matching partitions, it would produce around 10^20 possible valid configurations. With 10^20 possibilities, there is essentially no linkage. The Cash Fusion scheme actually extends this obfuscation even further. Not only can players bring many inputs, they can also have multiple outputs.\n>\n> ---------END QUOTE ---------\n> --\n\n\nIt seems to me that most users will not have nearly the same output of \"around 1 BTC\" anyway if you deploy this on a real live mainnet, and if your math requires that you have \"around 1 BTC\" outputs per user. you might as well just use equal-valued CoinJoins, where the equal-valued outputs at least are completely unlinked from the inputs.\n\nIndeed, the change outputs of an equal-valued CoinJoin would have similar analyses to CashFusion, since the same analysis \"around 1 BTC\" can be performed with the CoinJoin change outputs \"around 0 BTC\".\n\n* You can always transform a CashFusion transaction whose outputs are \"around 1 BTC\" to a CoinJoin transaction with equal-valued outputs and some change outputs, with the equal-valued outputs having equal value to the smallest CashFusion output.\n * e.g. if you have a CashFusion transaction with outputs 1.0, 1.1, 0.99, you could transform that to a CoinJoin with 0.99, 0.99, 0.99, 0.01, 0.11 outputs.\n* Conversely, you can transform an equal-valued CoinJoin transaction to a CashFusion transaction using the same technique.\n* That implies that the change outputs of an equal-valued CoinJoin have the same linkability as the outputs of the equivalent CashFusion transaction.\n* At least with equal-valued CoinJoin, the equal-valued outputs have 0 linkability with inputs (at least with only that transaction in isolation).\n  The same cannot be said of CashFusion, because the value involved is just in a single UTXO.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Yuval Kogman",
                "date": "2019-12-29T03:31:48",
                "message_text_only": "Hi,\n\nOn Sat, 28 Dec 2019 at 01:29, nopara73 via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\nI haven't read the whole thing in detail (and fwiw, I don't think I will by\nthis point), but I do want to respond to section about the combinatorics as\nwell as the proof, since both the premises and the implications don't seem\nvery solid to me, especially in light of the other replies in this thread.\n\nIt appears to be a step up from the Knapsack paper in terms of the\nspecificity of a concrete mixing protocol (which again, I did not\nscrutinize, but see below), but a regression in terms of privacy (see other\nreplies), which even in the Knapsack paper's approach raises some concerns:\n\nNow, there are 100!/(10!)^10 ~= 10^92 ways to partition the inputs into a\n> list of 10 sets of 10 inputs, but only a tiny fraction of these partitions\n> will produce the precise output list.\n>\nIn the equal amount case, the search space of possible interpretations with\nn = # inputs + # indistinguishable outputs is proportional to the nth Bell\nnumber, i.e. it's exponential in the size of the transaction, which is an\ninviting intuition. But this is an *upper* bound on the difficulty of\ndeanonymization, given no additional information.\n\nThis quantitative framing is potentially misleading because:\n\n1. attributing inputs/outputs (sub-transactions in the Knapsack paper's\nterminology) is arguably not a search problem, but an optimization problem,\nsince approximate results are still partly useful to the adversary\n2. there are many computational strategies, heuristics, etc that in\npractice can make this more efficient than brute force[1], so framing it\nthat as a security parameter doesn't sit right with me\n3. as individual sub-transactions are identified (for example using out of\nband information), the computational challenge also *drops* exponentially\nfast\n\nAdditionally (though is a broader criticism of CoinJoin based privacy and\nnot specific to unequal amounts, and in particular refers to ZmnSCPxj's\nassertion of 0 linkability) I am very worried that perspectives that focus\non linkability information revealed by a single coinjoin transaction in\nisolation. This problem was alluded in the document, to but I don't see\nthat it was addressed. Naively the post/pre mix transaction graph would\nseem to present a computationally much harder problem when looking at the\ncombinatorics through the same lens, but reality it can also be used to\nplace many constraints on valid partitions/sub-transaction assignments for\na single transaction with equal amounts. The trivial example is post mix\nlinking of outputs, but there are many other ways to draw inferences or\neliminate possible interpretations of a single transaction based on its\nwider context, which in turn may be used to attack other transactions.\n\n\n> Based on the example above, we can see that not only are there a huge\n> number of partitions, but that even with a fast algorithm that could find\n> matching partitions, it would produce around 10^20 possible valid\n> configurations. With 10^20 possibilities, there is essentially no linkage.\n>\nThis is a better framing, but still doesn't address my third bullet, since\n\"Attacks always get better; they never get worse.\" In other words\n\"essentially no linkage\" due to multiple possible interpretation is still\nstrictly more meaningful if you can add constraints out of band.\n\nTo be fair in equal amount CoinJoins this is also the case, but it's a much\nsimpler model to consider in the context of other privacy leak vectors\n(e.g. transaction graph connectivity beyond a single coinjoin, wallet\nfingerprinting, temporal patterns, network privacy leaks, etc etc), since\nanalyzing your level of exposure is *also* complicated by unequal amounts,\nin other words higher chance of privacy leaks due to misuse, or ignorance\nof some of the implications under intended use. Thinking through these\nimplications is much easier when the information content in the amounts is\nminimized.\n\nThe Cash Fusion scheme actually extends this obfuscation even further. Not\n> only can players bring many inputs, they can also have multiple outputs\n>\nAnd, quoting another section:\n\nUnfortunately, the production of equal-amount coins is impractical for\n> various reasons. Foremost, it has a \"toxic waste\"\n>\n\nI'm still cautiously optimistic about the potential of multiple\ninputs/outputs per user (c.f. 3-phase chaumian CoinJoin ideas we've\npreviously discussed in the context of Wasabi, though I don't recall any\npublic discussion I can link to, sorry list), but with the additional\nassumption of amounts with small popcounts/Hamming weights (e.g. only\namounts that are 2^n sat in size, or based on 1-2-5 series, and for a\nrationale see Ethan's reply).\n\nUnfortunately this trades off that \"toxic waste\" problem for a very large\non chain footprint (e.g. if the popcount of the amount of a wallet is\nlimited to 1, the number of inputs and change outputs required in the worst\ncase is proportional to log of the payment amount) and significant UTXO\nbloat (several mixed outputs per magnitude for transaction size to scale as\nthe popcount(payment amount) instead of the log(payment amount))\n\nHowever, with OP_CHECKTEMPLATEVERIFY and Taproot, this overhead could\npotentially be mitigated (something more like TumbleBit's privacy model,\nbut with an on chain footprint similar to multiparty payment channels as\ndescribed in the OP_CTV BIP draft) since the safety guaranteed by\nCoinJoins' atomicity can be preserved without requiring atomicity of the\nmixing itself, which can extend over multiple transactions and long time\nintervals, while still providing the liquidity and finality and unilateral\nexit option of payment channels. By moving such low hamming weight amount\noutputs off chain, and allowing them to be mixed (with equal amounts),\nsplit and merged off chain. The simpler analysis of equal amount outputs\ncould still be assumed which makes analysis easier and assumptions about\nadversary weaker, and furthermore this approach would better align the\nincentives for batching and privacy, which is why I think it's very\npromising.\n\nFinally, the proof as well as its applicability seems suspect to me, since\nseems to involve trusting the server:\n\"Since the distinct list [...] [is] kept on the server and not shared with\nthe players\"\n\"The server knows the linkages of the commitments but does not participate\nas a verifier \"\n\"If there is a problem [...] each component is assigned to another player\nat random for verification\"\nthese 3 statements together seems to suggest the server is trusted to not\nuse sybils in order the compromise privacy by participating in the\nverification process?\n\n(also, and although this is nitpicking, also does not seem to be\ndemonstrating \"soundness\" in any sense that I am familiar with - wouldn't\nbreak in soundness only imply DoS vector?)\n\n[1] btw, although I still owe you (nopara73) some consistently working\nlinear programming code to attribute change outputs in Wasabi (sorry! i\nsuck...), but anecdotally, in the special cases I did manage to solve even\ntransactions with tens of inputs do not present a challenge even to\nsupposedly slow/inefficient solvers compared to the state of the art. Even\nthough it's just anecdotal and in the context of the easier problem of\nattributing change, which can still be ambiguous in Wasabi transactions, i\nstill think this puts into question the privacy of mixing based on a\ndubious hardness assumption and a computationally bounded adversary, as\nopposed to something which (in the scope of a single mixing transaction) is\nperfectly hiding.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191229/9b2cd993/attachment-0001.html>"
            },
            {
                "author": "Yuval Kogman",
                "date": "2019-12-29T09:57:48",
                "message_text_only": "On Sun, 29 Dec 2019, 05:31 Yuval Kogman, <nothingmuch at woobling.org> wrote:\n\n> n = # inputs + # indistinguishable outputs\n>\n\nsorry, this is really wrong (although of no consequence to my arguments) -\nn is the smaller of these two numbers, not their sum.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191229/190287fb/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2019-12-29T10:23:39",
                "message_text_only": "Good morning Yuval,\n\n\n> Additionally (though is a broader criticism of CoinJoin based privacy and not specific to unequal amounts, and in particular refers to ZmnSCPxj's assertion of 0 linkability) I am very worried that perspectives that focus on linkability information revealed by a single coinjoin transaction in isolation. This problem was alluded in the document, to but I don't see that it was addressed. Naively the post/pre mix transaction graph would seem to present a computationally much harder problem when looking at the combinatorics through the same lens, but reality it can also be used to place many constraints on valid partitions/sub-transaction assignments for a single transaction with equal amounts. The trivial example is post mix linking of outputs, but there are many other ways to draw inferences or eliminate possible interpretations of a single transaction based on its wider context, which in turn may be used to attack other transactions.\n\nIndeed, this is a problem still of equal-valued CoinJoin.\nIn theory the ZeroLink protocol fixes this by strongly constraining user behavior, but ZeroLink is not \"purely\" implemented in e.g. Wasabi: Wasabi still allows spending pre- and post-mix coins in the same tx (ZeroLink disallows this) and any mix change should be considered as still linked to the inputs (though could be unlinked from the equal-valued output), i.e. returned to pre-mix wallet.\n\n> Finally, the proof as well as its applicability seems suspect to me, since seems to involve trusting the server:\n> \"Since the distinct list [...] [is] kept on the server and not shared with the players\"\n> \"The server knows the linkages of the commitments but does not participate as a verifier \"\n> \"If there is a problem [...] each component is assigned to another player at random for verification\"\n> these 3 statements together seems to suggest the server is trusted to not use sybils in order the compromise privacy by participating in the verification process?\n\nEqual-valued CoinJoins fix this by using a Chaumian bank, which constrains value transfers to specific fixed amounts.\nSince an equal-valued CoinJoin uses a single fixed amount anyway, it is not an additional restriction.\nCashFusion cannot use the same technique without dropping into something very much like an equal-valued CoinJoin.\n\nRegards,\nZmnSCPxj"
            },
            {
                "author": "Yuval Kogman",
                "date": "2019-12-29T17:48:38",
                "message_text_only": "Hi,\n\nOn Sun, 29 Dec 2019 at 10:23, ZmnSCPxj <ZmnSCPxj at protonmail.com> wrote:\n\n>\n> Indeed, this is a problem still of equal-valued CoinJoin.\n> In theory the ZeroLink protocol fixes this by strongly constraining user\n> behavior, but ZeroLink is not \"purely\" implemented in e.g. Wasabi: Wasabi\n> still allows spending pre- and post-mix coins in the same tx (ZeroLink\n> disallows this) and any mix change should be considered as still linked to\n> the inputs (though could be unlinked from the equal-valued output), i.e.\n> returned to pre-mix wallet.\n>\n\nYes, although since the base denomination size is pretty large this can be\nvery limiting, possibly forcing these change outputs to be linked to each\nother or, worse, with unmixed inputs which is still a serious linkage\nconcern. This is further complicated due to variability of the denomination\n(which makes remixing possible due to the fee structure, but see below)\nalso leaks some information or requires linking of mixed outputs in\naddition (although this resets its notion of anonymity set size, so I don't\nconsider this unsafe or misleading, just wasteful) or in change being\ndonated to the coordinator due to not meeting the threshold, depending on\nthe \"phase angle\" between a user's past mixes and the coordinator's current\ndenomination.\n\n>\n> Equal-valued CoinJoins fix this by using a Chaumian bank, which constrains\n> value transfers to specific fixed amounts.\n> Since an equal-valued CoinJoin uses a single fixed amount anyway, it is\n> not an additional restriction.\n> CashFusion cannot use the same technique without dropping into something\n> very much like an equal-valued CoinJoin.\n>\n\nI concur.\n\nI need to write a proper account of what I alluded to in my last email, but\nhere's a summary (allowing myself to keep it in this thread as the subject\nwas unequal amounts and opinions ;-)\n\n1. introduce another stage between the input/output phases - at input\nregistration you would receive chaumian reissuable/redenominatable tokens\nafter deduction of per input fees, which you can then \"spend\" to create\noutputs (instead of the chaumian token itself being an output script)\n\n2. replace the current notion of a mixing round into several sub-types:\n  - \"decompose\" - take an arbitrary amount and produce\npopcount(amount-fees) outputs with popcount = 1 (anon set size assumed to\nbe 1)\n  - \"mix\" - mix popcount == 1 amounts with equal sized outputs - this is\nthe only round type that can increase anon set size\n  - \"optimize\" - convert mixed, popcount == 1 (e.g. { 2^n} <-> { 2^(n-1),\n2^(n-1) } ) - it's not clear to me to what anon set size should be\nconsidered after this, probably reset to somewhere between 1 and the\nminimum size of the inputs, depending on degree of linkage\n  - \"combine\" - spend popcount == 1 outputs to produce arbitrary amounts\n\nNote that simultaneous rounds can be merged by the server during the\nsigning phase, such so that for example a \"decompose\" output may benefit\nfrom inhabiting the same CoinJoin transaction as a mixing round with the\nsame denomination, but the coordinator would still be able to categorically\ndistinguish between these, so this should not be thought of as a robust\nprivacy improvement (but it does make some other adversary's job harder\ngiven only public data).\n\nIn order to preserve the exact denomination size for mixing transactions,\nsuch rounds would need to have their mining fees subsidized - this can be\naccomplished by such merging, with the coordinator discounting or\nsubsidizing input/output registration fees depending on the degree of\nmixing (a la Samourai/Whirlpool's mechanism design), or using some sort of\nprepaid mechanism (e.g. as part of a mixing round instead of a registered\noutput you might elect to receive long lived - as in not per round -\nchaumian tokens that can be redeemed for fee-less, round denomination\nmixing, which can be reissued if the signing phase fails). In both cases\nI'm assuming the coordinator includes an input to cover the mining fees.\n\nI find the privacy aspects much easier to think about in this model, and it\naddresses many things of zerolink's weaknesses:\n\n1. allows unequal amounts but retains many of the advantages of fixed\ndenomination - the number of separate mixing pools would be at most\nlog(2.1e13), with their sizes corresponding to actual amount distribution\nbeing used (for mining & coordination fees too, but more generally any\namounts used for any Bitcoin payment)\n\n2. it can potentially eliminate post mix change (if I want to spend some\namount x = \\sum{i=1..~40} a_i*2^i, and i have exactly the combination\nspecified by the a_i's) which the server can also enforce by restricting\n\"combine\" rounds to require \"optimize\" rounds before them\n\n3. increases privacy benefit of remixing while still removing Wasabi's\nround denomination decreases, especially over long time intervals\n\nThe main issue, which I stress is significant, is the bloat - many such\nrounds are required, with many inputs and outputs per user per round, and\nmany UTXOs per user on average. This can be alleviated to a certain degree\nby batching. Although this leaks information about payment linkage post mix\nwhich can be attacked by partitioning, the risk is still mitigated since\nthe amounts themselves are low hamming weight and since consolidations\nstill happen in mixing rounds. Since the intra-round tokens are reissuable,\nthey are transferable as well, so this effectively makes everything into a\npayment hub protocol (e.g. if Alice wants to pay Bob and Carol, registers\nan input receiving tokens, splits those as necessary to accommodate the\npayment & change amounts, and transfers some subsets to Bob and Carol, who\nare free to register their own output(s). Payment is finalized if the\nmixing succeeds and the transaction is mined). That in turn led to thinking\nof how payment channels or multiparty payment might be used in a Chaumian\nCoinJoin protocol (see also our private correspondence of some months ago),\nbut naively this approach makes many tradeoffs like a slight departure from\nCoinJoin's notion of trustless mixing or requiring interaction between\nparticipants post-mix (which introduces new privacy concerns, or at least\nsignificant complexity). Since covenants were re-raised, and specifically\nOP_STB/CTV's approach to congestion control and multiparty payment channels\nin the context of Taproot & SIGHASH_NOINPUT/ANYPREVOUT etc. I believe that\nthis approach can actually made to be size efficient by just keeping the\nlow hamming weight outputs virtual, but I still haven't worked this out in\ndetail (still overwhelmed by the size of this design space).\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191229/d2ab40f3/attachment-0001.html>"
            },
            {
                "author": "Lucas Ontivero",
                "date": "2019-12-30T01:14:19",
                "message_text_only": "This idea is not similar to the one in the knapsack paper because this one\nis based only in the computational complexity of finding partitions that\nmatch the outputs. However, and except in rare cases, there is only one\nvalid partition (solution) for each output, it doesn't introduce any\nambiguity. Knapsack, on the other hand, splits the original outputs in such\na way that there are many partitions (solutions) that match the a selected\ngroup of outputs. For example, imagine 7 people decide to participate in a\ncoinjoin transaction with an arbitrary number of inputs (no more than 7\ninputs each), imagine this is not a pay to yourself cj tx but a pay to\nsomeone else cjtx instead such that there are at most 2 outputs for\nparticipants (payment output and change output) in this case, configuring\nthe partitions search algorithm to restrict the search space to sets of 7\ninputs maximum and 4 outputs maximum it found 14,599 valid transactions in\n42mins 18secs\nhttps://raw.githubusercontent.com/lontivero/Knapsack/master/data/knapsack-7-participants.txt\n\nThe same simulation with 8 participants under the same conditions found\n35,781 valid transactions in about 4 hours. Finally, with 9 participants I\nlet it running all the day and it didn't finished. The point is that the\nnumber of valid transactions grows so incredible fast that with 100\nparticipants even if you find a way to find all the partitions that matches\na set of outputs (something near to impossible), there are no way to know\nwhich of those are the real ones.\n\nAlso, the attacks on this mechanism look so simple that generate doubts.\nFinally, I think the numbers in this proposal look weird because the\nexample is using 10 inputs and the amounts are in the \"neighborhood of\n~0.1btc\" (what the heck does that mean?) and the sum of those are around\n1btc. That means that it could work in a very specific scenario. Knapsack\nis a general solution with good math behind and backtested against\nhistorical data extracted from the bitcoin's blockchain.\n\nIn summary, in unequal inputs/outputs coinjoins knapsack is the best we\nhave at the moment (btw, it is not as effective as equal-outputs\ntransactions). This proposal is imo inferior and it is not supported by\ngood math.\n\n\nEl vie., 27 dic. 2019 a las 22:29, nopara73 via bitcoin-dev (<\nbitcoin-dev at lists.linuxfoundation.org>) escribi\u00f3:\n\n> The CashFusion research came out of the Bitcoin Cash camp, thus this\n> probably went under the radar of many of you. I would like to ask your\n> opinions on the research's claim that, if non-equal value coinjoins can be\n> really relied on for privacy or not.\n>\n> (Btw, there were also similar ideas in the Knapsack paper in 2017:\n> https://www.comsys.rwth-aachen.de/fileadmin/papers/2017/2017-maurer-trustcom-coinjoin.pdf\n>  )\n>\n>\n> https://github.com/cashshuffle/spec/blob/master/CASHFUSION.md#avoiding-amount-linkages-through-combinatorics\n>\n>\n> I copy the most relevant paragraphs here:\n>\n>   ---------BEGIN QUOTE ---------\n>\n>\n> Consider a transaction where 10 people have each brought 10 inputs of\n> arbitary amounts in the neighborhood of ~0.1 BCH. One input might be\n> 0.03771049 BCH; the next might be 0.24881232 BCH, etc. All parties have\n> chosen to consolidate their coins, so the transaction has 10 outputs of\n> around 1 BCH. So the transaction has 100 inputs, and 10 outputs. The first\n> output might be 0.91128495, the next could be 1.79783710, etc.\n>\n> Now, there are 100!/(10!)^10 ~= 10^92 ways to partition the inputs into a\n> list of 10 sets of 10 inputs, but only a tiny fraction of these partitions\n> will produce the precise output list. So, how many ways produce this exact\n> output list? We can estimate with some napkin math. First, recognize that\n> for each partitioning, each output will typically land in a range of ~10^8\n> discrete possibilities (around 1 BCH wide, with a 0.00000001 BCH\n> resolution). The first 9 outputs all have this range of possibilities, and\n> the last will be constrained by the others. So, the 10^92 possibilies will\n> land somewhere within a 9-dimensional grid that cointains (10^8)^9=10^72\n> possible distinct sites, one site which is our actual output list. Since we\n> are stuffing 10^92 possibilties into a grid that contains only 10^72 sites,\n> then this means on average, each site will have 10^20 possibilities.\n>\n> Based on the example above, we can see that not only are there a huge\n> number of partitions, but that even with a fast algorithm that could find\n> matching partitions, it would produce around 10^20 possible valid\n> configurations. With 10^20 possibilities, there is essentially no linkage.\n> The Cash Fusion scheme actually extends this obfuscation even further. Not\n> only can players bring many inputs, they can also have multiple outputs.\n> ---------END QUOTE ---------\n> --\n> Best,\n> \u00c1d\u00e1m\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20191229/87d4973c/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Non-equal value CoinJoins. Opinions.",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Lucas Ontivero",
                "Yuval Kogman",
                "ZmnSCPxj",
                "Ethan Heilman",
                "nopara73"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 33496
        }
    }
]