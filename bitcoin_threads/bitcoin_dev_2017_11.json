[
    {
        "title": "[bitcoin-dev] Simplicity: An alternative to Script",
        "thread_messages": [
            {
                "author": "Mark Friedenbach",
                "date": "2017-11-01T01:46:54",
                "message_text_only": "I don\u2019t think you need to set an order of operations, just treat the jet as TRUE, but don\u2019t stop validation. Order of operations doesn\u2019t matter. Either way it\u2019ll execute both branches and terminate of the understood conditions don\u2019t hold.\n\nBut maybe I\u2019m missing something here. \n\n> On Oct 31, 2017, at 2:01 PM, Russell O'Connor <roconnor at blockstream.io> wrote:\n> \n> That approach is worth considering.  However there is a wrinkle that Simplicity's denotational semantics doesn't imply an order of operations.  For example, if one half of a pair contains a assertion failure (fail-closed), and the other half contains a unknown jet (fail-open), then does the program succeed or fail?\n> \n> This could be solved by providing an order of operations; however I fear that will complicate formal reasoning about Simplicity expressions.  Formal reasoning is hard enough as is and I hesitate to complicate the semantics in ways that make formal reasoning harder still.\n> \n> \n> On Oct 31, 2017 15:47, \"Mark Friedenbach\" <mark at friedenbach.org> wrote:\n> Nit, but if you go down that specific path I would suggest making just\n> the jet itself fail-open. That way you are not so limited in requiring\n> validation of the full contract -- one party can verify simply that\n> whatever condition they care about holds on reaching that part of the\n> contract. E.g. maybe their signature is needed at the top level, and\n> then they don't care what further restrictions are placed.\n> \n> On Tue, Oct 31, 2017 at 1:38 PM, Russell O'Connor via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> > (sorry, I forgot to reply-all earlier)\n> >\n> > The very short answer to this question is that I plan on using Luke's\n> > fail-success-on-unknown-operation in Simplicity.  This is something that\n> > isn't detailed at all in the paper.\n> >\n> > The plan is that discounted jets will be explicitly labeled as jets in the\n> > commitment.  If you can provide a Merkle path from the root to a node that\n> > is an explicit jet, but that jet isn't among the finite number of known\n> > discounted jets, then the script is automatically successful (making it\n> > anyone-can-spend).  When new jets are wanted they can be soft-forked into\n> > the protocol (for example if we get a suitable quantum-resistant digital\n> > signature scheme) and the list of known discounted jets grows.  Old nodes\n> > get a merkle path to the new jet, which they view as an unknown jet, and\n> > allow the transaction as a anyone-can-spend transaction.  New nodes see a\n> > regular Simplicity redemption.  (I haven't worked out the details of how the\n> > P2P protocol will negotiate with old nodes, but I don't forsee any\n> > problems.)\n> >\n> > Note that this implies that you should never participate in any Simplicity\n> > contract where you don't get access to the entire source code of all\n> > branches to check that it doesn't have an unknown jet.\n> >\n> > On Mon, Oct 30, 2017 at 5:42 PM, Matt Corallo <lf-lists at mattcorallo.com>\n> > wrote:\n> >>\n> >> I admittedly haven't had a chance to read the paper in full details, but I\n> >> was curious how you propose dealing with \"jets\" in something like Bitcoin.\n> >> AFAIU, other similar systems are left doing hard-forks to reduce the\n> >> sigops/weight/fee-cost of transactions every time they want to add useful\n> >> optimized drop-ins. For obvious reasons, this seems rather impractical and a\n> >> potentially critical barrier to adoption of such optimized drop-ins, which I\n> >> imagine would be required to do any new cryptographic algorithms due to the\n> >> significant fee cost of interpreting such things.\n> >>\n> >> Is there some insight I'm missing here?\n> >>\n> >> Matt\n> >>\n> >>\n> >> On October 30, 2017 11:22:20 AM EDT, Russell O'Connor via bitcoin-dev\n> >> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>>\n> >>> I've been working on the design and implementation of an alternative to\n> >>> Bitcoin Script, which I call Simplicity.  Today, I am presenting my design\n> >>> at the PLAS 2017 Workshop on Programming Languages and Analysis for\n> >>> Security.  You find a copy of my Simplicity paper at\n> >>> https://blockstream.com/simplicity.pdf\n> >>>\n> >>> Simplicity is a low-level, typed, functional, native MAST language where\n> >>> programs are built from basic combinators.  Like Bitcoin Script, Simplicity\n> >>> is designed to operate at the consensus layer.  While one can write\n> >>> Simplicity by hand, it is expected to be the target of one, or multiple,\n> >>> front-end languages.\n> >>>\n> >>> Simplicity comes with formal denotational semantics (i.e. semantics of\n> >>> what programs compute) and formal operational semantics (i.e. semantics of\n> >>> how programs compute). These are both formalized in the Coq proof assistant\n> >>> and proven equivalent.\n> >>>\n> >>> Formal denotational semantics are of limited value unless one can use\n> >>> them in practice to reason about programs. I've used Simplicity's formal\n> >>> semantics to prove correct an implementation of the SHA-256 compression\n> >>> function written in Simplicity.  I have also implemented a variant of ECDSA\n> >>> signature verification in Simplicity, and plan to formally validate its\n> >>> correctness along with the associated elliptic curve operations.\n> >>>\n> >>> Simplicity comes with easy to compute static analyses that can compute\n> >>> bounds on the space and time resources needed for evaluation.  This is\n> >>> important for both node operators, so that the costs are knows before\n> >>> evaluation, and for designing Simplicity programs, so that smart-contract\n> >>> participants can know the costs of their contract before committing to it.\n> >>>\n> >>> As a native MAST language, unused branches of Simplicity programs are\n> >>> pruned at redemption time.  This enhances privacy, reduces the block weight\n> >>> used, and can reduce space and time resource costs needed for evaluation.\n> >>>\n> >>> To make Simplicity practical, jets replace common Simplicity expressions\n> >>> (identified by their MAST root) and directly implement them with C code.  I\n> >>> anticipate developing a broad set of useful jets covering arithmetic\n> >>> operations, elliptic curve operations, and cryptographic operations\n> >>> including hashing and digital signature validation.\n> >>>\n> >>> The paper I am presenting at PLAS describes only the foundation of the\n> >>> Simplicity language.  The final design includes extensions not covered in\n> >>> the paper, including\n> >>>\n> >>> - full convent support, allowing access to all transaction data.\n> >>> - support for signature aggregation.\n> >>> - support for delegation.\n> >>>\n> >>> Simplicity is still in a research and development phase.  I'm working to\n> >>> produce a bare-bones SDK that will include\n> >>>\n> >>> - the formal semantics and correctness proofs in Coq\n> >>> - a Haskell implementation for constructing Simplicity programs\n> >>> - and a C interpreter for Simplicity.\n> >>>\n> >>> After an SDK is complete the next step will be making Simplicity\n> >>> available in the Elements project so that anyone can start experimenting\n> >>> with Simplicity in sidechains. Only after extensive vetting would it be\n> >>> suitable to consider Simplicity for inclusion in Bitcoin.\n> >>>\n> >>> Simplicity has a long ways to go still, and this work is not intended to\n> >>> delay consideration of the various Merkelized Script proposals that are\n> >>> currently ongoing.\n> >\n> >\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >\n> \n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171031/d72ca20a/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Simplicity: An alternative to Script",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Mark Friedenbach"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 7814
        }
    },
    {
        "title": "[bitcoin-dev] Mempool optimized fees, etc. (Scaling Bitcoin)",
        "thread_messages": [
            {
                "author": "Karl Johan Alm",
                "date": "2017-11-01T03:36:07",
                "message_text_only": "This is the paper detailing the research behind my talk \"Optimizing\nfee estimation via the mempool state\" (the presentation only covers\npart of the paper) at Scaling Stanford (this coming Sunday). Feedback\nwelcome.\n\nhttps://bc-2.jp/mempool.pdf"
            }
        ],
        "thread_summary": {
            "title": "Mempool optimized fees, etc. (Scaling Bitcoin)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Karl Johan Alm"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 243
        }
    },
    {
        "title": "[bitcoin-dev] Introducing a POW through a soft-fork",
        "thread_messages": [
            {
                "author": "Devrandom",
                "date": "2017-11-01T05:48:27",
                "message_text_only": "Hi all,\n\nFeedback is welcome on the draft below.  In particular, I want to see if\nthere is interest in further development of the idea and also interested in\nany attack vectors or undesirable dynamics.\n\n(Formatted version available here:\nhttps://github.com/devrandom/btc-papers/blob/master/aux-pow.md )\n\n# Soft-fork Introduction of a New POW\n\n## Motivation:\n\n- Mitigate mining centralization pressures by introducing a POW that does\nnot have economies of scale\n- Introduce an intermediary confirmation point, reducing the impact of\nmining power fluctuations\n\nNote however that choice of a suitable POW will require deep analysis.\nSome pitfalls include: botnet mining, POWs that seem ASIC resistant but are\nnot, unexpected/covert optimization.\n\nIn particular, unexpected/covert optimizations, such as ASCIBOOST, present\na potential centralizing and destabilizing force.\n\n## Design\n\n### Aux POW intermediate block\n\nAuxiliary POW blocks are introduced between normal blocks - i.e. the chain\nalternates between the two POWs.\nEach aux-POW block points to the previous normal block and contains\ntransactions just like a normal block.\nEach normal block points to the previous aux-POW block and must contain all\ntransactions from the aux-POW block.\nBlock space is not increased.\n\nThe new intermediate block and the pointers are introduced via a soft-fork\nrestriction.\n\n### Reward for aux POW miners\n\nThe reward for the aux POW smoothly increases from zero to a target value\n(e.g. 1/2 of the total reward) over time.\nThe reward is transferred via a soft-fork restriction requiring a coinbase\noutput to an address published in the\naux-POW block.\n\n### Aux POW difficulty adjustment\n\nDifficulty adjustments remain independent for the two POWs.\n\nThe difficulty of the aux POW is adjusted based on the average time between\nnormal block found\nto aux block found.\n\nFurther details are dependent on the specific POW.\n\n### Heaviest chain rule change\n\nThis is a semi-hard change, because non-upgraded nodes can get on the wrong\nchain in case of attack.  However,\nit might be possible to construct an alert system that notifies\nnon-upgraded nodes of an upcoming rule change.\nAll blocks are still valid, so this is not a hardforking change.\n\nThe heaviest chain definition changes from sum of `difficulty` to sum of:\n\n    mainDifficulty ^ x * auxDifficulty ^ y\n\nwhere we start at:\n\n    x = 1; y = 0\n\nand end at values of x and y that are related to the target relative\nrewards.  For example, if the target rewards\nare equally distributed, we will want ot end up at:\n\n    x = 1/2; y = 1/2\n\nso that both POWs have equal weight.  If the aux POW is to become dominant,\nx should end small relative to y.\n\n\n## Questions and Answers\n\n- What should be the parameters if we want the aux POW to have equal\nweight? A: 1/2 of the reward should be transferred\nto aux miners and x = 1/2, y = 1/2.\n\n- What should be the parameters if we want to deprecate the main POW?  A:\nmost of the reward should be transferred to\naux miners and x = 0, y = 1.  The main difficulty will tend to zero, and\naux miners will just trivially generate the\nmain block immediately after finding an aux block, with identical content.\n\n- Wasted bandwidth to transfer transactions twice?  A: this can be\noptimized by skipping transactions already\ntransferred.\n\n- Why would miners agree to soft-fork away some of their reward?  A: they\nwould agree if they believe that\nthe coins will increase in value due to improved security properties.\n\n## Open Questions\n\n- After a block of one type is found, we can naively assume that POW will\nbecome idle while a block of the other type is being mined.  In practice,\nthe spare capacity can be used to find alternative (\"attacking\") blocks or\nmine other coins.  Is that a problem?\n- Is selfish mining amplified by this scheme for miners that have both\ntypes of hardware?\n\n## POW candidates\n\n- SHA256 (i.e. use same POW, but introduce an intermediate block for faster\nconfirmation)\n- Proof of Space and Time (Bram Cohen)\n- Equihash\n- Ethash\n\n## Next Steps\n\n- evaluate POW candidates\n- evaluate difficulty adjustment rules\n- simulate miner behavior to identify if there are incentives for\ndetrimental behavior patterns (e.g. block withholding / selfish mining)\n- Protocol details\n\n## Credits\n\nBram Cohen came up with a similar idea back in March:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-March/013744.html\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171101/9dc7ba4e/attachment.html>"
            },
            {
                "author": "Tao Effect",
                "date": "2017-11-02T23:55:55",
                "message_text_only": "Just going to throw in my support for a POW change, not any particular implementation, but the idea.\n\nBitcoin is technically owned by China now. That's not acceptable.\n\n- Greg\n\n--\nPlease do not email me anything that you are not comfortable also sharing with the NSA.\n\n> On Oct 31, 2017, at 10:48 PM, Devrandom via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> \n> Hi all,\n> \n> Feedback is welcome on the draft below.  In particular, I want to see if there is interest in further development of the idea and also interested in any attack vectors or undesirable dynamics.\n> \n> (Formatted version available here: https://github.com/devrandom/btc-papers/blob/master/aux-pow.md <https://github.com/devrandom/btc-papers/blob/master/aux-pow.md> )\n> \n> # Soft-fork Introduction of a New POW\n> \n> ## Motivation:\n> \n> - Mitigate mining centralization pressures by introducing a POW that does not have economies of scale\n> - Introduce an intermediary confirmation point, reducing the impact of mining power fluctuations\n> \n> Note however that choice of a suitable POW will require deep analysis.  Some pitfalls include: botnet mining, POWs that seem ASIC resistant but are not, unexpected/covert optimization.\n> \n> In particular, unexpected/covert optimizations, such as ASCIBOOST, present a potential centralizing and destabilizing force.\n> \n> ## Design\n> \n> ### Aux POW intermediate block\n> \n> Auxiliary POW blocks are introduced between normal blocks - i.e. the chain alternates between the two POWs.\n> Each aux-POW block points to the previous normal block and contains transactions just like a normal block.\n> Each normal block points to the previous aux-POW block and must contain all transactions from the aux-POW block.\n> Block space is not increased.\n> \n> The new intermediate block and the pointers are introduced via a soft-fork restriction.\n> \n> ### Reward for aux POW miners\n> \n> The reward for the aux POW smoothly increases from zero to a target value (e.g. 1/2 of the total reward) over time.\n> The reward is transferred via a soft-fork restriction requiring a coinbase output to an address published in the\n> aux-POW block.\n> \n> ### Aux POW difficulty adjustment\n> \n> Difficulty adjustments remain independent for the two POWs.\n> \n> The difficulty of the aux POW is adjusted based on the average time between normal block found\n> to aux block found.\n> \n> Further details are dependent on the specific POW.\n> \n> ### Heaviest chain rule change\n> \n> This is a semi-hard change, because non-upgraded nodes can get on the wrong chain in case of attack.  However,\n> it might be possible to construct an alert system that notifies non-upgraded nodes of an upcoming rule change.\n> All blocks are still valid, so this is not a hardforking change.\n> \n> The heaviest chain definition changes from sum of `difficulty` to sum of:\n> \n>     mainDifficulty ^ x * auxDifficulty ^ y\n> \n> where we start at:\n> \n>     x = 1; y = 0\n> \n> and end at values of x and y that are related to the target relative rewards.  For example, if the target rewards\n> are equally distributed, we will want ot end up at:\n> \n>     x = 1/2; y = 1/2\n> \n> so that both POWs have equal weight.  If the aux POW is to become dominant, x should end small relative to y.\n> \n> \n> ## Questions and Answers\n> \n> - What should be the parameters if we want the aux POW to have equal weight? A: 1/2 of the reward should be transferred\n> to aux miners and x = 1/2, y = 1/2.\n> \n> - What should be the parameters if we want to deprecate the main POW?  A: most of the reward should be transferred to\n> aux miners and x = 0, y = 1.  The main difficulty will tend to zero, and aux miners will just trivially generate the\n> main block immediately after finding an aux block, with identical content.\n> \n> - Wasted bandwidth to transfer transactions twice?  A: this can be optimized by skipping transactions already\n> transferred.\n> \n> - Why would miners agree to soft-fork away some of their reward?  A: they would agree if they believe that\n> the coins will increase in value due to improved security properties.\n> \n> ## Open Questions\n> \n> - After a block of one type is found, we can naively assume that POW will become idle while a block of the other type is being mined.  In practice, the spare capacity can be used to find alternative (\"attacking\") blocks or mine other coins.  Is that a problem?\n> - Is selfish mining amplified by this scheme for miners that have both types of hardware?\n> \n> ## POW candidates\n> \n> - SHA256 (i.e. use same POW, but introduce an intermediate block for faster confirmation)\n> - Proof of Space and Time (Bram Cohen)\n> - Equihash\n> - Ethash\n> \n> ## Next Steps\n> \n> - evaluate POW candidates\n> - evaluate difficulty adjustment rules\n> - simulate miner behavior to identify if there are incentives for detrimental behavior patterns (e.g. block withholding / selfish mining)\n> - Protocol details\n> \n> ## Credits\n> \n> Bram Cohen came up with a similar idea back in March:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-March/013744.html <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-March/013744.html>_______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171102/7d5311c6/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171102/7d5311c6/attachment-0001.sig>"
            },
            {
                "author": "Devrandom",
                "date": "2017-11-03T01:02:25",
                "message_text_only": "I am also concerned.  However, this proposal allows two POWs to coexist and\nallows for gradual transitions. This is hopefully a less disruptive\napproach since it allows cooperative miners to migrate over time.  And of\ncourse, as a soft-fork it keeps backwards compatibility with existing\nsoftware.\n\nOn Thu, Nov 2, 2017 at 4:55 PM Tao Effect <contact at taoeffect.com> wrote:\n\n> Just going to throw in my support for a POW change, not any particular\n> implementation, but the idea.\n>\n> Bitcoin is technically owned by China now. That's not acceptable.\n>\n> - Greg\n>\n> --\n> Please do not email me anything that you are not comfortable also sharing with\n> the NSA.\n>\n> On Oct 31, 2017, at 10:48 PM, Devrandom via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Hi all,\n>\n> Feedback is welcome on the draft below.  In particular, I want to see if\n> there is interest in further development of the idea and also interested in\n> any attack vectors or undesirable dynamics.\n>\n> (Formatted version available here:\n> https://github.com/devrandom/btc-papers/blob/master/aux-pow.md )\n>\n> # Soft-fork Introduction of a New POW\n>\n> ## Motivation:\n>\n> - Mitigate mining centralization pressures by introducing a POW that does\n> not have economies of scale\n> - Introduce an intermediary confirmation point, reducing the impact of\n> mining power fluctuations\n>\n> Note however that choice of a suitable POW will require deep analysis.\n> Some pitfalls include: botnet mining, POWs that seem ASIC resistant but are\n> not, unexpected/covert optimization.\n>\n> In particular, unexpected/covert optimizations, such as ASCIBOOST, present\n> a potential centralizing and destabilizing force.\n>\n> ## Design\n>\n> ### Aux POW intermediate block\n>\n> Auxiliary POW blocks are introduced between normal blocks - i.e. the chain\n> alternates between the two POWs.\n> Each aux-POW block points to the previous normal block and contains\n> transactions just like a normal block.\n> Each normal block points to the previous aux-POW block and must contain\n> all transactions from the aux-POW block.\n> Block space is not increased.\n>\n> The new intermediate block and the pointers are introduced via a soft-fork\n> restriction.\n>\n> ### Reward for aux POW miners\n>\n> The reward for the aux POW smoothly increases from zero to a target value\n> (e.g. 1/2 of the total reward) over time.\n> The reward is transferred via a soft-fork restriction requiring a coinbase\n> output to an address published in the\n> aux-POW block.\n>\n> ### Aux POW difficulty adjustment\n>\n> Difficulty adjustments remain independent for the two POWs.\n>\n> The difficulty of the aux POW is adjusted based on the average time\n> between normal block found\n> to aux block found.\n>\n> Further details are dependent on the specific POW.\n>\n> ### Heaviest chain rule change\n>\n> This is a semi-hard change, because non-upgraded nodes can get on the\n> wrong chain in case of attack.  However,\n> it might be possible to construct an alert system that notifies\n> non-upgraded nodes of an upcoming rule change.\n> All blocks are still valid, so this is not a hardforking change.\n>\n> The heaviest chain definition changes from sum of `difficulty` to sum of:\n>\n>     mainDifficulty ^ x * auxDifficulty ^ y\n>\n> where we start at:\n>\n>     x = 1; y = 0\n>\n> and end at values of x and y that are related to the target relative\n> rewards.  For example, if the target rewards\n> are equally distributed, we will want ot end up at:\n>\n>     x = 1/2; y = 1/2\n>\n> so that both POWs have equal weight.  If the aux POW is to become\n> dominant, x should end small relative to y.\n>\n>\n> ## Questions and Answers\n>\n> - What should be the parameters if we want the aux POW to have equal\n> weight? A: 1/2 of the reward should be transferred\n> to aux miners and x = 1/2, y = 1/2.\n>\n> - What should be the parameters if we want to deprecate the main POW?  A:\n> most of the reward should be transferred to\n> aux miners and x = 0, y = 1.  The main difficulty will tend to zero, and\n> aux miners will just trivially generate the\n> main block immediately after finding an aux block, with identical content.\n>\n> - Wasted bandwidth to transfer transactions twice?  A: this can be\n> optimized by skipping transactions already\n> transferred.\n>\n> - Why would miners agree to soft-fork away some of their reward?  A: they\n> would agree if they believe that\n> the coins will increase in value due to improved security properties.\n>\n> ## Open Questions\n>\n> - After a block of one type is found, we can naively assume that POW will\n> become idle while a block of the other type is being mined.  In practice,\n> the spare capacity can be used to find alternative (\"attacking\") blocks or\n> mine other coins.  Is that a problem?\n> - Is selfish mining amplified by this scheme for miners that have both\n> types of hardware?\n>\n> ## POW candidates\n>\n> - SHA256 (i.e. use same POW, but introduce an intermediate block for\n> faster confirmation)\n> - Proof of Space and Time (Bram Cohen)\n> - Equihash\n> - Ethash\n>\n> ## Next Steps\n>\n> - evaluate POW candidates\n> - evaluate difficulty adjustment rules\n> - simulate miner behavior to identify if there are incentives for\n> detrimental behavior patterns (e.g. block withholding / selfish mining)\n> - Protocol details\n>\n> ## Credits\n>\n> Bram Cohen came up with a similar idea back in March:\n>\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-March/013744.html\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171103/d8fa3100/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2017-11-06T19:50:00",
                "message_text_only": "On Wed, Nov 01, 2017 at 05:48:27AM +0000, Devrandom via bitcoin-dev wrote:\n\nSome quick thoughts...\n\n> Hi all,\n> \n> Feedback is welcome on the draft below.  In particular, I want to see if\n> there is interest in further development of the idea and also interested in\n> any attack vectors or undesirable dynamics.\n> \n> (Formatted version available here:\n> https://github.com/devrandom/btc-papers/blob/master/aux-pow.md )\n> \n> # Soft-fork Introduction of a New POW\n\nFirst of all, I don't think you can really call this a soft-fork; I'd call it a\n\"pseudo-soft-fork\"\n\nMy reasoning being that after implementation, a chain with less total work than\nthe main chain - but more total SHA256^2 work than the main chain - might be\nfollowed by non-supporting clients. It's got some properties of a soft-fork,\nbut it's security model is definitely different.\n\n> ### Aux POW intermediate block\n> \n> Auxiliary POW blocks are introduced between normal blocks - i.e. the chain\n> alternates between the two POWs.\n> Each aux-POW block points to the previous normal block and contains\n> transactions just like a normal block.\n> Each normal block points to the previous aux-POW block and must contain all\n> transactions from the aux-POW block.\n\nNote how you're basically proposing for the block interval to be decreased,\nwhich has security implications due to increased orphan rates.\n\n> ### Heaviest chain rule change\n> \n> This is a semi-hard change, because non-upgraded nodes can get on the wrong\n> chain in case of attack.  However,\n\nExactly! Not really a soft-fork.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 488 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171106/daf2333b/attachment-0001.sig>"
            },
            {
                "author": "Paul Sztorc",
                "date": "2017-11-06T20:30:30",
                "message_text_only": "+1 to all of Peter Todd's comments\n\nOn Nov 6, 2017 11:50 AM, \"Peter Todd via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Wed, Nov 01, 2017 at 05:48:27AM +0000, Devrandom via bitcoin-dev wrote:\n>\n> Some quick thoughts...\n>\n> > Hi all,\n> >\n> > Feedback is welcome on the draft below.  In particular, I want to see if\n> > there is interest in further development of the idea and also interested\n> in\n> > any attack vectors or undesirable dynamics.\n> >\n> > (Formatted version available here:\n> > https://github.com/devrandom/btc-papers/blob/master/aux-pow.md )\n> >\n> > # Soft-fork Introduction of a New POW\n>\n> First of all, I don't think you can really call this a soft-fork; I'd call\n> it a\n> \"pseudo-soft-fork\"\n>\n> My reasoning being that after implementation, a chain with less total work\n> than\n> the main chain - but more total SHA256^2 work than the main chain - might\n> be\n> followed by non-supporting clients. It's got some properties of a\n> soft-fork,\n> but it's security model is definitely different.\n>\n> > ### Aux POW intermediate block\n> >\n> > Auxiliary POW blocks are introduced between normal blocks - i.e. the\n> chain\n> > alternates between the two POWs.\n> > Each aux-POW block points to the previous normal block and contains\n> > transactions just like a normal block.\n> > Each normal block points to the previous aux-POW block and must contain\n> all\n> > transactions from the aux-POW block.\n>\n> Note how you're basically proposing for the block interval to be decreased,\n> which has security implications due to increased orphan rates.\n>\n> > ### Heaviest chain rule change\n> >\n> > This is a semi-hard change, because non-upgraded nodes can get on the\n> wrong\n> > chain in case of attack.  However,\n>\n> Exactly! Not really a soft-fork.\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171106/4c91278d/attachment.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2017-11-06T20:55:29",
                "message_text_only": "If a block that would be discarded under previous rules becomes accepted after a rule addition, there is no reason to not simply call the new rule a hard fork. IOW it's perfectly rational to consider a weaker block as \"invalid\" relative to the strong chain. As such I don't see any reason to qualify the term, it's a hard fork. But Peter's observation (the specific behavior) is ultimately what matters.\n\ne\n\n> On Nov 6, 2017, at 12:30, Paul Sztorc via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> +1 to all of Peter Todd's comments\n> \n>> On Nov 6, 2017 11:50 AM, \"Peter Todd via bitcoin-dev\" <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> On Wed, Nov 01, 2017 at 05:48:27AM +0000, Devrandom via bitcoin-dev wrote:\n>> \n>> Some quick thoughts...\n>> \n>> > Hi all,\n>> >\n>> > Feedback is welcome on the draft below.  In particular, I want to see if\n>> > there is interest in further development of the idea and also interested in\n>> > any attack vectors or undesirable dynamics.\n>> >\n>> > (Formatted version available here:\n>> > https://github.com/devrandom/btc-papers/blob/master/aux-pow.md )\n>> >\n>> > # Soft-fork Introduction of a New POW\n>> \n>> First of all, I don't think you can really call this a soft-fork; I'd call it a\n>> \"pseudo-soft-fork\"\n>> \n>> My reasoning being that after implementation, a chain with less total work than\n>> the main chain - but more total SHA256^2 work than the main chain - might be\n>> followed by non-supporting clients. It's got some properties of a soft-fork,\n>> but it's security model is definitely different.\n>> \n>> > ### Aux POW intermediate block\n>> >\n>> > Auxiliary POW blocks are introduced between normal blocks - i.e. the chain\n>> > alternates between the two POWs.\n>> > Each aux-POW block points to the previous normal block and contains\n>> > transactions just like a normal block.\n>> > Each normal block points to the previous aux-POW block and must contain all\n>> > transactions from the aux-POW block.\n>> \n>> Note how you're basically proposing for the block interval to be decreased,\n>> which has security implications due to increased orphan rates.\n>> \n>> > ### Heaviest chain rule change\n>> >\n>> > This is a semi-hard change, because non-upgraded nodes can get on the wrong\n>> > chain in case of attack.  However,\n>> \n>> Exactly! Not really a soft-fork.\n>> \n>> --\n>> https://petertodd.org 'peter'[:-1]@petertodd.org\n>> \n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171106/08da67fe/attachment-0001.html>"
            },
            {
                "author": "Devrandom",
                "date": "2017-11-07T04:38:51",
                "message_text_only": "A hard-fork is a situation where non-upgraded nodes reject a block mined\nand relayed by upgraded nodes.  This creates a fork that cannot heal\nregardless of what follows.\n\nThis proposal is not a hard-fork, because the non-upgraded node *will heal*\nif the attack has less than 1/2 of the original-POW power in the long term.\n\nThe cost of such an attack is the cost of a normal \"51%\" attack, multiplied\nby the fractional weight of the original POW (e.g. 0.75 or 0.5).\n\nSo rather than saying this is a hard-fork, I would say that this is a\nsoft-fork with reduced security for non-upgraded nodes. I would also say\nthat the reduction in security is proportional to the reduction in weight\nof the original POW at the time of attack.\n\nAs mentioned before, the original-POW weight starts at 1.0 and is reduced\nover a long period of time.  I would set up the transition curve so that\nall nodes upgrade by the time the weight is, say, 0.75.  In reality, nodes\nprotecting high economic value would upgrade early.\n\nOn Mon, Nov 6, 2017 at 3:55 PM Eric Voskuil via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> If a block that would be discarded under previous rules becomes accepted\n> after a rule addition, there is no reason to not simply call the new rule a\n> hard fork. IOW it's perfectly rational to consider a weaker block as\n> \"invalid\" relative to the strong chain. As such I don't see any reason to\n> qualify the term, it's a hard fork. But Peter's observation (the specific\n> behavior) is ultimately what matters.\n>\n> e\n>\n> On Nov 6, 2017, at 12:30, Paul Sztorc via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> +1 to all of Peter Todd's comments\n>\n> On Nov 6, 2017 11:50 AM, \"Peter Todd via bitcoin-dev\" <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> On Wed, Nov 01, 2017 at 05:48:27AM +0000, Devrandom via bitcoin-dev wrote:\n>>\n>> Some quick thoughts...\n>>\n>> > Hi all,\n>> >\n>> > Feedback is welcome on the draft below.  In particular, I want to see if\n>> > there is interest in further development of the idea and also\n>> interested in\n>> > any attack vectors or undesirable dynamics.\n>> >\n>> > (Formatted version available here:\n>> > https://github.com/devrandom/btc-papers/blob/master/aux-pow.md )\n>> >\n>> > # Soft-fork Introduction of a New POW\n>>\n>> First of all, I don't think you can really call this a soft-fork; I'd\n>> call it a\n>> \"pseudo-soft-fork\"\n>>\n>> My reasoning being that after implementation, a chain with less total\n>> work than\n>> the main chain - but more total SHA256^2 work than the main chain - might\n>> be\n>> followed by non-supporting clients. It's got some properties of a\n>> soft-fork,\n>> but it's security model is definitely different.\n>>\n>> > ### Aux POW intermediate block\n>> >\n>> > Auxiliary POW blocks are introduced between normal blocks - i.e. the\n>> chain\n>> > alternates between the two POWs.\n>> > Each aux-POW block points to the previous normal block and contains\n>> > transactions just like a normal block.\n>> > Each normal block points to the previous aux-POW block and must contain\n>> all\n>> > transactions from the aux-POW block.\n>>\n>> Note how you're basically proposing for the block interval to be\n>> decreased,\n>> which has security implications due to increased orphan rates.\n>>\n>> > ### Heaviest chain rule change\n>> >\n>> > This is a semi-hard change, because non-upgraded nodes can get on the\n>> wrong\n>> > chain in case of attack.  However,\n>>\n>> Exactly! Not really a soft-fork.\n>>\n>> --\n>> https://petertodd.org 'peter'[:-1]@petertodd.org\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171107/81f53507/attachment.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2017-11-11T19:51:04",
                "message_text_only": "> On Nov 6, 2017, at 20:38, Devrandom <c1.bitcoin at niftybox.net> wrote:\n> \n> A hard-fork is a situation where non-upgraded nodes reject a block mined and relayed by upgraded nodes.\n\nAs Peter pointed out, that is the case here.\n\n> This creates a fork that cannot heal regardless of what follows.\n\nThat is not a condition of the hard fork concept.\n\nhttps://github.com/bitcoin/bips/blob/master/bip-0099.mediawiki\nSoftfork\nA consensus fork wherein everything that was previously invalid remains invalid while blocks that would have previously considered valid become invalid. A hashrate majority of miners can impose the new rules. They have some deployment advantages like backward compatibility.\nHardfork\nA consensus fork that makes previously invalid blocks valid. Hardforks require all users to upgrade.\n\nThe essential element of a hard fork is that the new rule may cause rejection of blocks that are not rejected by old rules (thereby requiring that all users adopt the new rule in order to avoid a split). The reason a hard fork is interesting is that it can create a chain split even if it is enforced by majority hash power.\n\nThat is not the case with a soft fork and it is not the case here. A split can occur. The fact that it is possible for the split to also eventually orphan the old nodes does not make it a soft fork. A soft fork requires that a hash power majority can impose the rule. However, under the proposed new rule the hash power majority (according to the new rule) cannot impose the rule on existing nodes.\n\n> This proposal is not a hard-fork, because the non-upgraded node *will heal* if the attack has less than 1/2 of the original-POW power in the long term.\n\nNothing about this proposal implies an attack. From the Motivation section:\n\nMitigate centralization pressures by introducing a POW that does not have economies of scale\nIntroduce an intermediary confirmation point, reducing the impact of mining power fluctuations\n\n> The cost of such an attack is the cost of a normal \"51%\" attack, multiplied by the fractional weight of the original POW (e.g. 0.75 or 0.5).\n> \n> So rather than saying this is a hard-fork, I would say that this is a soft-fork with reduced security for non-upgraded nodes.\n\nPresumably this preference exists because it implies the new rule would not cause a chain split, making it more acceptable to a risk-averse economy. This is precisely why it should be described correctly.\n\n> I would also say that the reduction in security is proportional to the reduction in weight of the original POW at the time of attack.\n> \n> As mentioned before, the original-POW weight starts at 1.0 and is reduced over a long period of time.  I would set up the transition curve so that all nodes upgrade by the time the weight is, say, 0.75.  In reality, nodes protecting high economic value would upgrade early.\n\nIn reality you have no way to know if/when people would adopt this rule. What matters in the proposal is that people who do adopt it are well aware of its ability to split them from the existing economy.\n\ne\n\n>> On Mon, Nov 6, 2017 at 3:55 PM Eric Voskuil via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> If a block that would be discarded under previous rules becomes accepted after a rule addition, there is no reason to not simply call the new rule a hard fork. IOW it's perfectly rational to consider a weaker block as \"invalid\" relative to the strong chain. As such I don't see any reason to qualify the term, it's a hard fork. But Peter's observation (the specific behavior) is ultimately what matters.\n>> \n>> e\n>> \n>>> On Nov 6, 2017, at 12:30, Paul Sztorc via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> \n>>> +1 to all of Peter Todd's comments\n>>> \n>>>> On Nov 6, 2017 11:50 AM, \"Peter Todd via bitcoin-dev\" <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>> On Wed, Nov 01, 2017 at 05:48:27AM +0000, Devrandom via bitcoin-dev wrote:\n>>>> \n>>>> Some quick thoughts...\n>>>> \n>>>> > Hi all,\n>>>> >\n>>>> > Feedback is welcome on the draft below.  In particular, I want to see if\n>>>> > there is interest in further development of the idea and also interested in\n>>>> > any attack vectors or undesirable dynamics.\n>>>> >\n>>>> > (Formatted version available here:\n>>>> > https://github.com/devrandom/btc-papers/blob/master/aux-pow.md )\n>>>> >\n>>>> > # Soft-fork Introduction of a New POW\n>>>> \n>>>> First of all, I don't think you can really call this a soft-fork; I'd call it a\n>>>> \"pseudo-soft-fork\"\n>>>> \n>>>> My reasoning being that after implementation, a chain with less total work than\n>>>> the main chain - but more total SHA256^2 work than the main chain - might be\n>>>> followed by non-supporting clients. It's got some properties of a soft-fork,\n>>>> but it's security model is definitely different.\n>>>> \n>>>> > ### Aux POW intermediate block\n>>>> >\n>>>> > Auxiliary POW blocks are introduced between normal blocks - i.e. the chain\n>>>> > alternates between the two POWs.\n>>>> > Each aux-POW block points to the previous normal block and contains\n>>>> > transactions just like a normal block.\n>>>> > Each normal block points to the previous aux-POW block and must contain all\n>>>> > transactions from the aux-POW block.\n>>>> \n>>>> Note how you're basically proposing for the block interval to be decreased,\n>>>> which has security implications due to increased orphan rates.\n>>>> \n>>>> > ### Heaviest chain rule change\n>>>> >\n>>>> > This is a semi-hard change, because non-upgraded nodes can get on the wrong\n>>>> > chain in case of attack.  However,\n>>>> \n>>>> Exactly! Not really a soft-fork.\n>>>> \n>>>> --\n>>>> https://petertodd.org 'peter'[:-1]@petertodd.org\n>>>> \n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171111/1ce6f87b/attachment.html>"
            },
            {
                "author": "Devrandom",
                "date": "2017-11-06T22:39:02",
                "message_text_only": "Hi Peter, thank you for the review.  See below\n\nOn Mon, Nov 6, 2017 at 11:50 AM Peter Todd <pete at petertodd.org> wrote:\n\n> On Wed, Nov 01, 2017 at 05:48:27AM +0000, Devrandom via bitcoin-dev wrote:\n>\n> Some quick thoughts...\n>\n> > Hi all,\n> >\n> > Feedback is welcome on the draft below.  In particular, I want to see if\n> > there is interest in further development of the idea and also interested\n> in\n> > any attack vectors or undesirable dynamics.\n> >\n> > (Formatted version available here:\n> > https://github.com/devrandom/btc-papers/blob/master/aux-pow.md )\n> >\n> > # Soft-fork Introduction of a New POW\n>\n> First of all, I don't think you can really call this a soft-fork; I'd call\n> it a\n> \"pseudo-soft-fork\"\n>\n> My reasoning being that after implementation, a chain with less total work\n> than\n> the main chain - but more total SHA256^2 work than the main chain - might\n> be\n> followed by non-supporting clients. It's got some properties of a\n> soft-fork,\n> but it's security model is definitely different.\n>\n\nThe interesting thing is that the cost of attack varies smoothly as you\nvary the POW weights.\nTo attack non-upgraded nodes, you still have to \"51%\" the original POW.\nThe reward going to that POW will vary smoothly between 1.0 * block_reward\nand whatever\ntarget value (e.g. 0.5 * block_reward) and the difficulty of attack will\ntend to be proportional to that.\n\nIn a real hard-fork, your software just breaks at the fork point.  In this\ncase, it's just the non-upgraded\nnode security level declining from 100% to 50% over a long period of time.\n\nI envision the transition of POW weights will be over 1-3 years, which\nleaves plenty of time to\nupgrade after the fork activates.\n\n\n>\n> > ### Aux POW intermediate block\n> >\n> > Auxiliary POW blocks are introduced between normal blocks - i.e. the\n> chain\n> > alternates between the two POWs.\n> > Each aux-POW block points to the previous normal block and contains\n> > transactions just like a normal block.\n> > Each normal block points to the previous aux-POW block and must contain\n> all\n> > transactions from the aux-POW block.\n>\n> Note how you're basically proposing for the block interval to be decreased,\n> which has security implications due to increased orphan rates.\n>\n\nNote that the total transaction rate and block size don't materially\nchange, so I don't\nsee why the orphan rate will change.  Normal blocks are constrained to have\nall of the txs of the aux blocks, so propagation time should stay the\nsame.  Am I missing\nsomething?\n\n\n>\n> > ### Heaviest chain rule change\n> >\n> > This is a semi-hard change, because non-upgraded nodes can get on the\n> wrong\n> > chain in case of attack.  However,\n>\n> Exactly! Not really a soft-fork.\n>\n\n\"smooth-fork\" perhaps? :)\n\n\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171106/69e6bc4e/attachment.html>"
            },
            {
                "author": "Devrandom",
                "date": "2017-11-06T23:38:20",
                "message_text_only": ">\n> Note how you're basically proposing for the block interval to be decreased,\n>> which has security implications due to increased orphan rates.\n>>\n>\n> Note that the total transaction rate and block size don't materially\n> change, so I don't\n> see why the orphan rate will change.  Normal blocks are constrained to have\n> all of the txs of the aux blocks, so propagation time should stay the\n> same.  Am I missing\n> something?\n>\n\nAh, yes, I'm missing that the expected time to find each type of block is\nhalved, so the orphan rate doubles.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171106/ebea9284/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Introducing a POW through a soft-fork",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Eric Voskuil",
                "Peter Todd",
                "Devrandom",
                "Paul Sztorc",
                "Tao Effect"
            ],
            "messages_count": 10,
            "total_messages_chars_count": 37746
        }
    },
    {
        "title": "[bitcoin-dev] Merkle branch verification & tail-call semantics for generalized MAST",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2017-11-01T08:43:48",
                "message_text_only": "Mark,\n\nI think I have found an improvement that can be made.\n\nAs you recall, a downside to this approach is that one must make two \ncommitments: first, to the particular \"membership-checking script\"; and then \nin that script, to the particular merkle root of possible scripts.\n\nWould there be any harm in, instead of checking membership, *calculating* the \nroot? If not, then we could define that instead of the witness program \ncommitting to H(membership-check script), it rather commits to H(membership-\ncalculation script | data added by an OP_ADDTOSCRIPTHASH). This would, I \nbelieve, securely reduce the commitment of both to a single hash.\n\nIt also doesn't reduce flexibility, since one could omit OP_ADDTOSCRIPTHASH \nfrom their \"membership-calculation\" script to get the previous membership-\ncheck behaviour, and use <hash> OP_EQUAL in its place.\n\nWhat do you think?\n\nLuke\n\n\nOn Saturday 28 October 2017 4:40:01 AM Mark Friedenbach wrote:\n> I have completed updating the three BIPs with all the feedback that I have\n> received so far. In short summary, here is an incomplete list of the\n> changes that were made:\n> \n> * Modified the hashing function fast-SHA256 so that an internal node cannot\n> be interpreted simultaneously as a leaf. * Changed MERKLEBRANCHVERIFY to\n> verify a configurable number of elements from the tree, instead of just\n> one. * Changed MERKLEBRANCHVERIFY to have two modes: one where the inputs\n> are assumed to be hashes, and one where they are run through double-SHA256\n> first. * Made tail-call eval compatible with BIP141\u2019s CLEANSTACK consensus\n> rule by allowing parameters to be passed on the alt-stack. * Restricted\n> tail-call eval to segwit scripts only, so that checking sigop and opcode\n> limits of the policy script would not be necessary.\n> \n> There were a bunch of other small modifications, typo fixes, and\n> optimizations that were made as well.\n> \n> I am now ready to submit these BIPs as a PR against the bitcoin/bips repo,\n> and I request that the BIP editor assign numbers.\n> \n> Thank you,\n> Mark Friedenbach\n> \n> > On Sep 6, 2017, at 5:38 PM, Mark Friedenbach <mark at friedenbach.org>\n> > wrote:\n> > \n> > I would like to propose two new script features to be added to the\n> > bitcoin protocol by means of soft-fork activation. These features are\n> > a new opcode, MERKLE-BRANCH-VERIFY (MBV) and tail-call execution\n> > semantics.\n> > \n> > In brief summary, MERKLE-BRANCH-VERIFY allows script authors to force\n> > redemption to use values selected from a pre-determined set committed\n> > to in the scriptPubKey, but without requiring revelation of unused\n> > elements in the set for both enhanced privacy and smaller script\n> > sizes. Tail-call execution semantics allows a single level of\n> > recursion into a subscript, providing properties similar to P2SH while\n> > at the same time more flexible.\n> > \n> > These two features together are enough to enable a range of\n> > applications such as tree signatures (minus Schnorr aggregation) as\n> > described by Pieter Wuille [1], and a generalized MAST useful for\n> > constructing private smart contracts. It also brings privacy and\n> > fungibility improvements to users of counter-signing wallet/vault\n> > services as unique redemption policies need only be revealed if/when\n> > exceptional circumstances demand it, leaving most transactions looking\n> > the same as any other MAST-enabled multi-sig script.\n> > \n> > I believe that the implementation of these features is simple enough,\n> > and the use cases compelling enough that we could BIP 8/9 rollout of\n> > these features in relatively short order, perhaps before the end of\n> > the year.\n> > \n> > I have written three BIPs to describe these features, and their\n> > associated implementation, for which I now invite public review and\n> > discussion:\n> > \n> > Fast Merkle Trees\n> > BIP: https://gist.github.com/maaku/41b0054de0731321d23e9da90ba4ee0a\n> > Code: https://github.com/maaku/bitcoin/tree/fast-merkle-tree\n> > \n> > MERKLEBRANCHVERIFY\n> > BIP: https://gist.github.com/maaku/bcf63a208880bbf8135e453994c0e431\n> > Code: https://github.com/maaku/bitcoin/tree/merkle-branch-verify\n> > \n> > Tail-call execution semantics\n> > BIP: https://gist.github.com/maaku/f7b2e710c53f601279549aa74eeb5368\n> > Code: https://github.com/maaku/bitcoin/tree/tail-call-semantics\n> > \n> > Note: I have circulated this idea privately among a few people, and I\n> > will note that there is one piece of feedback which I agree with but\n> > is not incorporated yet: there should be a multi-element MBV opcode\n> > that allows verifying multiple items are extracted from a single\n> > tree. It is not obvious how MBV could be modified to support this\n> > without sacrificing important properties, or whether should be a\n> > separate multi-MBV opcode instead.\n> > \n> > Kind regards,\n> > Mark Friedenbach"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-11-01T15:08:46",
                "message_text_only": "Yes, if you use a witness script version you can save about 40 witness bytes by templating the MBV script, which I think is equivalent to what you are suggesting. 32 bytes from the saved hash, plus another 8 bytes or so from script templates and more efficient serialization.\n\nI believe the conservatively correct approach is to do this in stages, however. First roll out MBV and tail call to witness v0. Then once there is experience with people using it in production, design and deploy a hashing template for script v1. It might be that we learn more and think of something better in the meantime.\n\n> On Nov 1, 2017, at 1:43 AM, Luke Dashjr <luke at dashjr.org> wrote:\n> \n> Mark,\n> \n> I think I have found an improvement that can be made.\n> \n> As you recall, a downside to this approach is that one must make two \n> commitments: first, to the particular \"membership-checking script\"; and then \n> in that script, to the particular merkle root of possible scripts.\n> \n> Would there be any harm in, instead of checking membership, *calculating* the \n> root? If not, then we could define that instead of the witness program \n> committing to H(membership-check script), it rather commits to H(membership-\n> calculation script | data added by an OP_ADDTOSCRIPTHASH). This would, I \n> believe, securely reduce the commitment of both to a single hash.\n> \n> It also doesn't reduce flexibility, since one could omit OP_ADDTOSCRIPTHASH \n> from their \"membership-calculation\" script to get the previous membership-\n> check behaviour, and use <hash> OP_EQUAL in its place.\n> \n> What do you think?\n> \n> Luke\n> \n> \n>> On Saturday 28 October 2017 4:40:01 AM Mark Friedenbach wrote:\n>> I have completed updating the three BIPs with all the feedback that I have\n>> received so far. In short summary, here is an incomplete list of the\n>> changes that were made:\n>> \n>> * Modified the hashing function fast-SHA256 so that an internal node cannot\n>> be interpreted simultaneously as a leaf. * Changed MERKLEBRANCHVERIFY to\n>> verify a configurable number of elements from the tree, instead of just\n>> one. * Changed MERKLEBRANCHVERIFY to have two modes: one where the inputs\n>> are assumed to be hashes, and one where they are run through double-SHA256\n>> first. * Made tail-call eval compatible with BIP141\u2019s CLEANSTACK consensus\n>> rule by allowing parameters to be passed on the alt-stack. * Restricted\n>> tail-call eval to segwit scripts only, so that checking sigop and opcode\n>> limits of the policy script would not be necessary.\n>> \n>> There were a bunch of other small modifications, typo fixes, and\n>> optimizations that were made as well.\n>> \n>> I am now ready to submit these BIPs as a PR against the bitcoin/bips repo,\n>> and I request that the BIP editor assign numbers.\n>> \n>> Thank you,\n>> Mark Friedenbach\n>> \n>>> On Sep 6, 2017, at 5:38 PM, Mark Friedenbach <mark at friedenbach.org>\n>>> wrote:\n>>> \n>>> I would like to propose two new script features to be added to the\n>>> bitcoin protocol by means of soft-fork activation. These features are\n>>> a new opcode, MERKLE-BRANCH-VERIFY (MBV) and tail-call execution\n>>> semantics.\n>>> \n>>> In brief summary, MERKLE-BRANCH-VERIFY allows script authors to force\n>>> redemption to use values selected from a pre-determined set committed\n>>> to in the scriptPubKey, but without requiring revelation of unused\n>>> elements in the set for both enhanced privacy and smaller script\n>>> sizes. Tail-call execution semantics allows a single level of\n>>> recursion into a subscript, providing properties similar to P2SH while\n>>> at the same time more flexible.\n>>> \n>>> These two features together are enough to enable a range of\n>>> applications such as tree signatures (minus Schnorr aggregation) as\n>>> described by Pieter Wuille [1], and a generalized MAST useful for\n>>> constructing private smart contracts. It also brings privacy and\n>>> fungibility improvements to users of counter-signing wallet/vault\n>>> services as unique redemption policies need only be revealed if/when\n>>> exceptional circumstances demand it, leaving most transactions looking\n>>> the same as any other MAST-enabled multi-sig script.\n>>> \n>>> I believe that the implementation of these features is simple enough,\n>>> and the use cases compelling enough that we could BIP 8/9 rollout of\n>>> these features in relatively short order, perhaps before the end of\n>>> the year.\n>>> \n>>> I have written three BIPs to describe these features, and their\n>>> associated implementation, for which I now invite public review and\n>>> discussion:\n>>> \n>>> Fast Merkle Trees\n>>> BIP: https://gist.github.com/maaku/41b0054de0731321d23e9da90ba4ee0a\n>>> Code: https://github.com/maaku/bitcoin/tree/fast-merkle-tree\n>>> \n>>> MERKLEBRANCHVERIFY\n>>> BIP: https://gist.github.com/maaku/bcf63a208880bbf8135e453994c0e431\n>>> Code: https://github.com/maaku/bitcoin/tree/merkle-branch-verify\n>>> \n>>> Tail-call execution semantics\n>>> BIP: https://gist.github.com/maaku/f7b2e710c53f601279549aa74eeb5368\n>>> Code: https://github.com/maaku/bitcoin/tree/tail-call-semantics\n>>> \n>>> Note: I have circulated this idea privately among a few people, and I\n>>> will note that there is one piece of feedback which I agree with but\n>>> is not incorporated yet: there should be a multi-element MBV opcode\n>>> that allows verifying multiple items are extracted from a single\n>>> tree. It is not obvious how MBV could be modified to support this\n>>> without sacrificing important properties, or whether should be a\n>>> separate multi-MBV opcode instead.\n>>> \n>>> Kind regards,\n>>> Mark Friedenbach"
            },
            {
                "author": "Luke Dashjr",
                "date": "2017-11-04T07:59:07",
                "message_text_only": "How about using for the first stage, `<...> OP_CALCMERKLEROOT <root> OP_EQUAL` \ninstead of `<root...> OP_CHECKMERKLEBRANCH`? There's maybe 1 or 2 bytes extra, \nbut it seems more future-proof (since there could more easily be alternatives \nto `<root> OP_EQUAL` in future script versions).\n\nOTOH, OP_ADDTOSCRIPTHASH may be fatally incompatible with script versioning... \nOld nodes won't know how to check the witness program, which means an \nundefined version could be used to bypass the correct script entirely.\nNeed to think more on this still.\n\nLuke\n\n\nOn Wednesday 01 November 2017 3:08:46 PM Mark Friedenbach wrote:\n> Yes, if you use a witness script version you can save about 40 witness\n> bytes by templating the MBV script, which I think is equivalent to what\n> you are suggesting. 32 bytes from the saved hash, plus another 8 bytes or\n> so from script templates and more efficient serialization.\n> \n> I believe the conservatively correct approach is to do this in stages,\n> however. First roll out MBV and tail call to witness v0. Then once there\n> is experience with people using it in production, design and deploy a\n> hashing template for script v1. It might be that we learn more and think\n> of something better in the meantime.\n> \n> > On Nov 1, 2017, at 1:43 AM, Luke Dashjr <luke at dashjr.org> wrote:\n> > \n> > Mark,\n> > \n> > I think I have found an improvement that can be made.\n> > \n> > As you recall, a downside to this approach is that one must make two\n> > commitments: first, to the particular \"membership-checking script\"; and\n> > then in that script, to the particular merkle root of possible scripts.\n> > \n> > Would there be any harm in, instead of checking membership, *calculating*\n> > the root? If not, then we could define that instead of the witness\n> > program committing to H(membership-check script), it rather commits to\n> > H(membership- calculation script | data added by an OP_ADDTOSCRIPTHASH).\n> > This would, I believe, securely reduce the commitment of both to a\n> > single hash.\n> > \n> > It also doesn't reduce flexibility, since one could omit\n> > OP_ADDTOSCRIPTHASH from their \"membership-calculation\" script to get the\n> > previous membership- check behaviour, and use <hash> OP_EQUAL in its\n> > place.\n> > \n> > What do you think?\n> > \n> > Luke\n> > \n> >> On Saturday 28 October 2017 4:40:01 AM Mark Friedenbach wrote:\n> >> I have completed updating the three BIPs with all the feedback that I\n> >> have received so far. In short summary, here is an incomplete list of\n> >> the changes that were made:\n> >> \n> >> * Modified the hashing function fast-SHA256 so that an internal node\n> >> cannot be interpreted simultaneously as a leaf. * Changed\n> >> MERKLEBRANCHVERIFY to verify a configurable number of elements from the\n> >> tree, instead of just one. * Changed MERKLEBRANCHVERIFY to have two\n> >> modes: one where the inputs are assumed to be hashes, and one where\n> >> they are run through double-SHA256 first. * Made tail-call eval\n> >> compatible with BIP141\u2019s CLEANSTACK consensus rule by allowing\n> >> parameters to be passed on the alt-stack. * Restricted tail-call eval\n> >> to segwit scripts only, so that checking sigop and opcode limits of the\n> >> policy script would not be necessary.\n> >> \n> >> There were a bunch of other small modifications, typo fixes, and\n> >> optimizations that were made as well.\n> >> \n> >> I am now ready to submit these BIPs as a PR against the bitcoin/bips\n> >> repo, and I request that the BIP editor assign numbers.\n> >> \n> >> Thank you,\n> >> Mark Friedenbach\n> >> \n> >>> On Sep 6, 2017, at 5:38 PM, Mark Friedenbach <mark at friedenbach.org>\n> >>> wrote:\n> >>> \n> >>> I would like to propose two new script features to be added to the\n> >>> bitcoin protocol by means of soft-fork activation. These features are\n> >>> a new opcode, MERKLE-BRANCH-VERIFY (MBV) and tail-call execution\n> >>> semantics.\n> >>> \n> >>> In brief summary, MERKLE-BRANCH-VERIFY allows script authors to force\n> >>> redemption to use values selected from a pre-determined set committed\n> >>> to in the scriptPubKey, but without requiring revelation of unused\n> >>> elements in the set for both enhanced privacy and smaller script\n> >>> sizes. Tail-call execution semantics allows a single level of\n> >>> recursion into a subscript, providing properties similar to P2SH while\n> >>> at the same time more flexible.\n> >>> \n> >>> These two features together are enough to enable a range of\n> >>> applications such as tree signatures (minus Schnorr aggregation) as\n> >>> described by Pieter Wuille [1], and a generalized MAST useful for\n> >>> constructing private smart contracts. It also brings privacy and\n> >>> fungibility improvements to users of counter-signing wallet/vault\n> >>> services as unique redemption policies need only be revealed if/when\n> >>> exceptional circumstances demand it, leaving most transactions looking\n> >>> the same as any other MAST-enabled multi-sig script.\n> >>> \n> >>> I believe that the implementation of these features is simple enough,\n> >>> and the use cases compelling enough that we could BIP 8/9 rollout of\n> >>> these features in relatively short order, perhaps before the end of\n> >>> the year.\n> >>> \n> >>> I have written three BIPs to describe these features, and their\n> >>> associated implementation, for which I now invite public review and\n> >>> discussion:\n> >>> \n> >>> Fast Merkle Trees\n> >>> BIP: https://gist.github.com/maaku/41b0054de0731321d23e9da90ba4ee0a\n> >>> Code: https://github.com/maaku/bitcoin/tree/fast-merkle-tree\n> >>> \n> >>> MERKLEBRANCHVERIFY\n> >>> BIP: https://gist.github.com/maaku/bcf63a208880bbf8135e453994c0e431\n> >>> Code: https://github.com/maaku/bitcoin/tree/merkle-branch-verify\n> >>> \n> >>> Tail-call execution semantics\n> >>> BIP: https://gist.github.com/maaku/f7b2e710c53f601279549aa74eeb5368\n> >>> Code: https://github.com/maaku/bitcoin/tree/tail-call-semantics\n> >>> \n> >>> Note: I have circulated this idea privately among a few people, and I\n> >>> will note that there is one piece of feedback which I agree with but\n> >>> is not incorporated yet: there should be a multi-element MBV opcode\n> >>> that allows verifying multiple items are extracted from a single\n> >>> tree. It is not obvious how MBV could be modified to support this\n> >>> without sacrificing important properties, or whether should be a\n> >>> separate multi-MBV opcode instead.\n> >>> \n> >>> Kind regards,\n> >>> Mark Friedenbach"
            }
        ],
        "thread_summary": {
            "title": "Merkle branch verification & tail-call semantics for generalized MAST",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Luke Dashjr",
                "Mark Friedenbach"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 16842
        }
    },
    {
        "title": "[bitcoin-dev] Simplicity proposal - Jets?",
        "thread_messages": [
            {
                "author": "JOSE FEMENIAS CA\u00d1UELO",
                "date": "2017-11-01T10:34:40",
                "message_text_only": "Hi,\n\nI am trying to follow this Simplicity proposal and I am seeing all over references to \u2018jets\u2019, but I haven\u2019t been able to find any good reference to it.\nCan anyone give me a brief explanation and or a link pointing to this feature?\nThanks\n\n> On 31 Oct 2017, at 22:01, bitcoin-dev-request at lists.linuxfoundation.org wrote:\n> \n> The plan is that discounted jets will be explicitly labeled as jets in the\n> commitment.  If you can provide a Merkle path from the root to a node that\n> is an explicit jet, but that jet isn't among the finite number of known\n> discounted jets,\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171101/ab3d6aa3/attachment.html>"
            },
            {
                "author": "Ad\u00e1n S\u00e1nchez de Pedro Crespo",
                "date": "2017-11-03T00:45:40",
                "message_text_only": "Hi everyone,\n\nI agree that the paper could use some more details on the rationale\nbehind \"jets\". After a couple of reads, I think I can \"ELI5 them\":\n\nAs far as I understand, jets are a smart optimization that makes complex\nSimplicity contracts way cheaper to compute (ideally, comparable to\nScript or EVM).\n\nFor this purpose, jets leverage the most important element of the\nSimplicity Bit Machine: the frames stack.\n\nIn a Simplicity program, every expression or sub-expression can be\nthought of as a pure function that when applied on a certain initial\nread frame, results in the active write frame having a different value.\nThis happens deterministically and without any side effects.\n\nSo, if the Simplicity interpreter finds some expression whose result\nwhen applied upon a certain read frame is already known (because it has\nalready been executed or it was somehow precomputed), it doesn't need to\nexecute such expression step-by-step once again. Instead, it just need\nto write the known result to the active write frame.\n\nThe paper suggests that at all times the interpreter knows the result of\napplying many common operations on all possible combinations of inputs\nin the range of 8 to 256 bits. In other words, the interpreter won't\nneed to calculate \"123 + 321\" or compare \"456 > 654 because the results\nof those expressions will be already known to it. These are stupid\nexamples, but the savings are real for hash functions internals,\nelliptic curve calculations or even validation of signatures.\n\nAs said before, this can help making Simplicity programs lighter on CPU\nusage, but it has many other benefits too:\n\n+ Jets can replicate the behavior of complex chunks of Simplicity code\nwith the guarantee that they can't introduce side effects.\n\n+ Interpreter-bundled jets are formally proven. The more a Simplicity\nprogram relies on jets, the more it benefits from their safety. When\nproving the soundness of your program, you can just ignore the jets,\nassume they are valid and focus on your own logic.\n\nThe paper also suggests that different sets of jets could make up\ndifferent single purpose dialects, just like domain-specific languages\nbring richer vocabulary and semantics to the bare syntax and grammar of\ngeneral-purpose languages.\n\nI hope Russel or Mark can correct me if I got something totally wrong. I\nmust admit I really like this proposal and hereby declare myself a huge\nfan of their work :)\n\n-- \nAd\u00e1n S\u00e1nchez de Pedro Crespo\nCTO, Stampery Inc.\nSan Francisco - Madrid"
            },
            {
                "author": "Russell O'Connor",
                "date": "2017-11-03T01:10:42",
                "message_text_only": "Hi Jose,\n\nJets are briefly discussed in section 3.4 of\nhttps://blockstream.com/simplicity.pdf\n\nThe idea is that we can recognize some set of popular Simplicity\nexpressions, and when the Simplicity interpreter encounters one of these\nexpressions it can skip over the Simplicity interpreter and instead\ndirectly evaluate the function using specialized C or assembly code.\n\nFor example, when the Simplicity interpreter encounters the Simplicity\nexpression for ECDSA verification, it might directly call into libsecp\nrather than continuing the ECDSA verification using interpreted Simplicity.\n\nHTH.\n\n\nOn Nov 2, 2017 18:35, \"JOSE FEMENIAS CA\u00d1UELO via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\nHi,\n\nI am trying to follow this Simplicity proposal and I am seeing all over\nreferences to \u2018jets\u2019, but I haven\u2019t been able to find any good reference to\nit.\nCan anyone give me a brief explanation and or a link pointing to this\nfeature?\nThanks\n\nOn 31 Oct 2017, at 22:01, bitcoin-dev-request at lists.linuxfoundation.org\nwrote:\n\nThe plan is that discounted jets will be explicitly labeled as jets in the\ncommitment.  If you can provide a Merkle path from the root to a node that\nis an explicit jet, but that jet isn't among the finite number of known\ndiscounted jets,\n\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171102/47a8dfe5/attachment.html>"
            },
            {
                "author": "Ad\u00e1n S\u00e1nchez de Pedro Crespo",
                "date": "2017-11-03T08:46:16",
                "message_text_only": "Oops. That makes much more sense than what I said. Thanks a lot for the\nclarification.\n\nOn 03.11.2017 02:10, Russell O'Connor via bitcoin-dev wrote:\n> Hi Jose,\n> \n> Jets are briefly discussed in section 3.4 of\n> https://blockstream.com/simplicity.pdf\n> \n> The idea is that we can recognize some set of popular Simplicity\n> expressions, and when the Simplicity interpreter encounters one of these\n> expressions it can skip over the Simplicity interpreter and instead\n> directly evaluate the function using specialized C or assembly code.\n> \n> For example, when the Simplicity interpreter encounters the Simplicity\n> expression for ECDSA verification, it might directly call into libsecp\n> rather than continuing the ECDSA verification using interpreted Simplicity.\n> \n> HTH.\n> \n> \n> On Nov 2, 2017 18:35, \"JOSE FEMENIAS CA\u00d1UELO via bitcoin-dev\"\n> <bitcoin-dev at lists.linuxfoundation.org\n> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> \n>     Hi,\n> \n>     I am trying to follow this Simplicity proposal and I am seeing all\n>     over references to \u2018jets\u2019, but I haven\u2019t been able to find any good\n>     reference to it.\n>     Can anyone give me a brief explanation and or a link pointing to\n>     this feature?\n>     Thanks\n> \n>>     On 31 Oct 2017, at 22:01,\n>>     bitcoin-dev-request at lists.linuxfoundation.org\n>>     <mailto:bitcoin-dev-request at lists.linuxfoundation.org> wrote:\n>>\n>>     The plan is that discounted jets will be explicitly labeled as\n>>     jets in the\n>>     commitment.\u00a0 If you can provide a Merkle path from the root to a\n>>     node that\n>>     is an explicit jet, but that jet isn't among the finite number of\n>>     known\n>>     discounted jets,\n> \n> \n>     _______________________________________________\n>     bitcoin-dev mailing list\n>     bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n> \n> \n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n\n-- \nAd\u00e1n S\u00e1nchez de Pedro Crespo\nCTO, Stampery Inc.\nSan Francisco - Madrid"
            },
            {
                "author": "Hampus Sj\u00f6berg",
                "date": "2017-11-03T12:59:46",
                "message_text_only": "Thank you for your answer, Russel.\n\nWhen a code path takes advantage of a jet, does the Simplicity code still\nneed to be publicly available/visible in the blockchain? I imagine that for\nbig algorithms (say for example EDCA verification/SHA256 hashing etc), it\nwould take up a lot of space in the blockchain.\nIs there any way to mitigate this?\n\nI guess in a softfork for a jet, the Simplicity code for a jet could be\ndefined as \"consensus\", instead of needed to be provided within every\nscript output.\nWhen the Simplicity interpretor encounters an expression that has a jet, it\nwould run the C/Assembly code instead of interpreting the Simplicity code.\nBy formal verification we would be sure they match.\n\nGreetings\nHampus\n\n2017-11-03 2:10 GMT+01:00 Russell O'Connor via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org>:\n\n> Hi Jose,\n>\n> Jets are briefly discussed in section 3.4 of https://blockstream.com/\n> simplicity.pdf\n>\n> The idea is that we can recognize some set of popular Simplicity\n> expressions, and when the Simplicity interpreter encounters one of these\n> expressions it can skip over the Simplicity interpreter and instead\n> directly evaluate the function using specialized C or assembly code.\n>\n> For example, when the Simplicity interpreter encounters the Simplicity\n> expression for ECDSA verification, it might directly call into libsecp\n> rather than continuing the ECDSA verification using interpreted Simplicity.\n>\n> HTH.\n>\n>\n> On Nov 2, 2017 18:35, \"JOSE FEMENIAS CA\u00d1UELO via bitcoin-dev\" <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Hi,\n>\n> I am trying to follow this Simplicity proposal and I am seeing all over\n> references to \u2018jets\u2019, but I haven\u2019t been able to find any good reference to\n> it.\n> Can anyone give me a brief explanation and or a link pointing to this\n> feature?\n> Thanks\n>\n> On 31 Oct 2017, at 22:01, bitcoin-dev-request at lists.linuxfoundation.org\n> wrote:\n>\n> The plan is that discounted jets will be explicitly labeled as jets in the\n> commitment.  If you can provide a Merkle path from the root to a node that\n> is an explicit jet, but that jet isn't among the finite number of known\n> discounted jets,\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171103/e9a5e8b1/attachment-0001.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-11-03T16:19:39",
                "message_text_only": "To reiterate, none of the current work focuses on Bitcoin integration, and many architectures are possible.\n\nHowever the Jets would have to be specified and agreed to upfront for costing reasons, and so they would be known to all validators. There would be no reason to include anything more then the identifying hash in any contract using the jet.\n\n> On Nov 3, 2017, at 5:59 AM, Hampus Sj\u00f6berg via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Thank you for your answer, Russel.\n> \n> When a code path takes advantage of a jet, does the Simplicity code still need to be publicly available/visible in the blockchain? I imagine that for big algorithms (say for example EDCA verification/SHA256 hashing etc), it would take up a lot of space in the blockchain.\n> Is there any way to mitigate this?\n> \n> I guess in a softfork for a jet, the Simplicity code for a jet could be defined as \"consensus\", instead of needed to be provided within every script output.\n> When the Simplicity interpretor encounters an expression that has a jet, it would run the C/Assembly code instead of interpreting the Simplicity code. By formal verification we would be sure they match.\n> \n> Greetings\n> Hampus\n> \n> 2017-11-03 2:10 GMT+01:00 Russell O'Connor via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>:\n>> Hi Jose,\n>> \n>> Jets are briefly discussed in section 3.4 of https://blockstream.com/simplicity.pdf\n>> \n>> The idea is that we can recognize some set of popular Simplicity expressions, and when the Simplicity interpreter encounters one of these expressions it can skip over the Simplicity interpreter and instead directly evaluate the function using specialized C or assembly code.\n>> \n>> For example, when the Simplicity interpreter encounters the Simplicity expression for ECDSA verification, it might directly call into libsecp rather than continuing the ECDSA verification using interpreted Simplicity.\n>> \n>> HTH.\n>> \n>> \n>> On Nov 2, 2017 18:35, \"JOSE FEMENIAS CA\u00d1UELO via bitcoin-dev\" <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> Hi,\n>> \n>> I am trying to follow this Simplicity proposal and I am seeing all over references to \u2018jets\u2019, but I haven\u2019t been able to find any good reference to it.\n>> Can anyone give me a brief explanation and or a link pointing to this feature?\n>> Thanks\n>> \n>>> On 31 Oct 2017, at 22:01, bitcoin-dev-request at lists.linuxfoundation.org wrote:\n>>> \n>>> The plan is that discounted jets will be explicitly labeled as jets in the\n>>> commitment.  If you can provide a Merkle path from the root to a node that\n>>> is an explicit jet, but that jet isn't among the finite number of known\n>>> discounted jets,\n>> \n>> \n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> \n>> \n>> \n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171103/cffee143/attachment.html>"
            },
            {
                "author": "Ad\u00e1n S\u00e1nchez de Pedro Crespo",
                "date": "2017-11-03T16:42:38",
                "message_text_only": "If I did understand it right, you don't need to publish the Simplicity\ncode for the \"jetable\" expression.\n\nThat's the whole point of MAST. Each Simplicity expression can be\nidentified by its MAST root (the Merkle root of all branches in its\nAbstract Syntax Tree).\n\nImagine you want to write a Simplicity script that is roughly equivalent\nto P2PKH. Regardless of directly writing such script or using a higher\nlevel smart contract language, you won't likely write for yourself the\npart in which you compute the hash of the public key. Instead, you are\nexpected to include some external library providing hash functions or at\nleast copy and paste such function into your code.\n\nAs everyone is expected to use the same, let's say, RIPEMD160\nimplementation, it doesn't matter how you included such function in your\nprogram. The point is that once you build the MAST for your program,\nsuch function will be completely replaced by its MAST root---which is\nnothing but a hash.\n\nThis way, when the Simplicity interpreter (the BitMachine) bumps into\nthe hash, it can look for it in a predefined jets dictionary and find\nthe binary for a precompiled, formally proven implementation of a\nfunction that is perfectly equivalent to the original Simplicity code.\n\n\nOn 03.11.2017 13:59, Hampus Sj\u00f6berg via bitcoin-dev wrote:\n> Thank you for your answer, Russel.\n> \n> When a code path takes advantage of a jet, does the Simplicity code\n> still need to be publicly available/visible in the blockchain? I imagine\n> that for big algorithms (say for example EDCA verification/SHA256\n> hashing etc), it would take up a lot of space in the blockchain.\n> Is there any way to mitigate this?\n> \n> I guess in a softfork for a jet, the Simplicity code for a jet could be\n> defined as \"consensus\", instead of needed to be provided within every\n> script output.\n> When the Simplicity interpretor encounters an expression that has a jet,\n> it would run the C/Assembly code instead of interpreting the Simplicity\n> code. By formal verification we would be sure they match.\n> \n> Greetings\n> Hampus\n> \n> 2017-11-03 2:10 GMT+01:00 Russell O'Connor via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org\n> <mailto:bitcoin-dev at lists.linuxfoundation.org>>:\n> \n>     Hi Jose,\n> \n>     Jets are briefly discussed in section 3.4 of\n>     https://blockstream.com/simplicity.pdf\n>     <https://blockstream.com/simplicity.pdf>\n> \n>     The idea is that we can recognize some set of popular Simplicity\n>     expressions, and when the Simplicity interpreter encounters one of\n>     these expressions it can skip over the Simplicity interpreter and\n>     instead directly evaluate the function using specialized C or\n>     assembly code.\n> \n>     For example, when the Simplicity interpreter encounters the\n>     Simplicity expression for ECDSA verification, it might directly call\n>     into libsecp rather than continuing the ECDSA verification using\n>     interpreted Simplicity.\n> \n>     HTH.\n> \n> \n>     On Nov 2, 2017 18:35, \"JOSE FEMENIAS CA\u00d1UELO via bitcoin-dev\"\n>     <bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> \n>         Hi,\n> \n>         I am trying to follow this Simplicity proposal and I am seeing\n>         all over references to \u2018jets\u2019, but I haven\u2019t been able to find\n>         any good reference to it.\n>         Can anyone give me a brief explanation and or a link pointing to\n>         this feature?\n>         Thanks\n> \n>>         On 31 Oct 2017, at 22:01,\n>>         bitcoin-dev-request at lists.linuxfoundation.org\n>>         <mailto:bitcoin-dev-request at lists.linuxfoundation.org> wrote:\n>>\n>>         The plan is that discounted jets will be explicitly labeled as\n>>         jets in the\n>>         commitment.\u00a0 If you can provide a Merkle path from the root to\n>>         a node that\n>>         is an explicit jet, but that jet isn't among the finite number\n>>         of known\n>>         discounted jets,\n> \n> \n>         _______________________________________________\n>         bitcoin-dev mailing list\n>         bitcoin-dev at lists.linuxfoundation.org\n>         <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>         https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>         <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n> \n> \n> \n>     _______________________________________________\n>     bitcoin-dev mailing list\n>     bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n> \n> \n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n\n-- \nAd\u00e1n S\u00e1nchez de Pedro Crespo\nCTO, Stampery Inc.\nSan Francisco - Madrid"
            }
        ],
        "thread_summary": {
            "title": "Simplicity proposal - Jets?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "JOSE FEMENIAS CA\u00d1UELO",
                "Ad\u00e1n S\u00e1nchez de Pedro Crespo",
                "Hampus Sj\u00f6berg",
                "Russell O'Connor",
                "Mark Friedenbach"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 18300
        }
    },
    {
        "title": "[bitcoin-dev] Electrum 3.0 release",
        "thread_messages": [
            {
                "author": "Thomas Voegtlin",
                "date": "2017-11-02T09:56:15",
                "message_text_only": "Electrum 3.0 was tagged and released yesterday night.\n\nRelease notes:\n\n# Release 3.0 - Uncanny Valley (November 1st, 2017)\n\n  * The project was migrated to Python3 and Qt5. Python2 is no longer\n    supported. If you cloned the source repository, you will need to\n    run \"python3 setup.py install\" in order to install the new\n    dependencies.\n\n  * Segwit support:\n\n    - Native segwit scripts are supported using a new type of\n      seed. The version number for segwit seeds is 0x100. The install\n      wizard will not create segwit seeds by default; users must\n      opt-in with the segwit option.\n\n    - Native segwit scripts are represented using bech32 addresses,\n      following BIP173. Please note that BIP173 is still in draft\n      status, and that other wallets/websites may not support\n      it. Thus, you should keep a non-segwit wallet in order to be\n      able to receive bitcoins during the transition period. If BIP173\n      ends up being rejected or substantially modified, your wallet\n      may have to be restored from seed. This will not affect funds\n      sent to bech32 addresses, and it will not affect the capacity of\n      Electrum to spend these funds.\n\n    - Segwit scripts embedded in p2sh are supported with hardware\n      wallets or bip39 seeds. To create a segwit-in-p2sh wallet,\n      trezor/ledger users will need to enter a BIP49 derivation path.\n\n    - The BIP32 master keys of segwit wallets are serialized using new\n      version numbers. The new version numbers encode the script type,\n      and they result in the following prefixes:\n\n         * xpub/xprv : p2pkh or p2sh\n         * ypub/yprv : p2wpkh-in-p2sh\n         * Ypub/Yprv : p2wsh-in-p2sh\n         * zpub/zprv : p2wpkh\n         * Zpub/Zprv : p2wsh\n\n      These values are identical for mainnet and testnet; tpub/tprv\n      prefixes are no longer used in testnet wallets.\n\n    - The Wallet Import Format (WIF) is similarly extended for segwit\n      scripts. After a base58-encoded key is decoded to binary, its\n      first byte encodes the script type:\n\n         * 128 + 0: p2pkh\n         * 128 + 1: p2wpkh\n         * 128 + 2: p2wpkh-in-p2sh\n         * 128 + 5: p2sh\n         * 128 + 6: p2wsh\n         * 128 + 7: p2wsh-in-p2sh\n\n      The distinction between p2sh and p2pkh in private key means that\n      it is not possible to import a p2sh private key and associate it\n      to a p2pkh address.\n\n  * A new version of the Electrum protocol is required by the client\n    (version 1.1). Servers using older versions of the protocol will\n    not be displayed in the GUI.\n\n  * By default, transactions are time-locked to the height of the\n    current block. Other values of locktime may be passed using the\n    command line.\n\n\n\n\n\n-- \nElectrum Technologies GmbH / Waldemarstr 37a / 10999 Berlin / Germany\nSitz, Registergericht: Berlin, Amtsgericht Charlottenburg, HRB 164636\nGesch\u00e4ftsf\u00fchrer: Thomas Voegtlin"
            }
        ],
        "thread_summary": {
            "title": "Electrum 3.0 release",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Thomas Voegtlin"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2898
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Cash's new difficulty algorithm",
        "thread_messages": [
            {
                "author": "Scott Roberts",
                "date": "2017-11-02T23:31:55",
                "message_text_only": "Bitcoin cash will hard fork on Nov 13 to implement a new difficulty\nalgorithm.  Bitcoin itself might need to hard fork to employ a similar\nalgorithm. It's about as good as they come because it followed the\n\"simplest is best\" route. Their averaging window is probably\nsignificantly too long (N=144). It's:\n\nnext_D = sum (past 144 D's) * T / sum(past 144 solvetimes)\n\nThey correctly did not use max(timestamp) - min(timestamp) in the\ndenominator like others do.\n\nThey've written the code and they're about to use it live, so Bitcoin\nwill have a clear, simple, and tested path if it suddenly needs to\nhard fork due to having 20x delays for the next 2000 blocks (taking it\na year to get unstuck).\n\nDetails on it and the decision process:\nhttps://www.bitcoinabc.org/november\n\nIt uses a nice median of 3 for the beginning and end of the window to\nhelp alleviate bad timestamp problems. It's nice, helps a little, but\nwill also slow its response by 1 block.  They also have 2x and 1/2\nlimits on the adjustment per block, which is a lot more than they will\never need.\n\nI recommend bitcoin consider using it and making it N=50 instead of 144.\n\nI have seen that any attempts to modify the above with things like a\nlow pass filter, starting the window at MTP, or preventing negative\ntimestamps will only reduce its effectiveness. Bitcoin's +12 and -6\nlimits on the timestamps are sufficient and well chosen, although\nsomething a bit smaller than the +12 might have been better.\n\nOne of the contenders to the above is new and actually better, devised\nby Degnr8 and they call it D622 or wt-144.It's a little better than\nthey realize. It's the only real improvement in difficulty algorithms\nsince the rolling average.  It gives a linearly higher weight to the\nmore recent timestamps. Otherwise it is the same. Others have probably\ncome across it, but there is too much noise in difficulty algorithms\nto find the good ones.\n\n# Degnr8's D622 difficulty algorithm\n# T=TargetTime, S=Solvetime\n# modified by zawy\nfor i = 1 to N  (from oldest to most recent block)\n    t += T[i] / D[i] * i\n    j += i\nnext i\nnext_D = j / t * T\n\nI believe any modification to the above strict mathematical weighted\naverage will reduce it's effectiveness. It does not oscillate anymore\nthan regular algos and rises faster and drops faster, when needed."
            },
            {
                "author": "Gregory Maxwell",
                "date": "2017-11-02T23:37:29",
                "message_text_only": "On Thu, Nov 2, 2017 at 11:31 PM, Scott Roberts via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Bitcoin cash will hard fork on Nov 13 to implement a new difficulty\n> algorithm.  Bitcoin itself might need to hard fork to employ a similar\n> algorithm. It's about as good as they come because it followed the\n\nThis is the bitcoin development mailing list, not the \"give free\nreview to the obviously defective proposals of adversarial competing\nsystems\" mailing list. Your posting is off-topic."
            },
            {
                "author": "Scott Roberts",
                "date": "2017-11-02T23:53:25",
                "message_text_only": "Whatever their failings from their previous code or their adversarial\nnature, they got this code right and I'm only presenting it as a real and\nexcellent solution for the impending threat to bitcoin. As a big core fan,\nI really wanted to delete the word Cash from my post because I was afraid\nsomeone would turn this technical discussion into a political football.\n\nOn Nov 2, 2017 7:37 PM, \"Gregory Maxwell\" <greg at xiph.org> wrote:\n\nOn Thu, Nov 2, 2017 at 11:31 PM, Scott Roberts via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Bitcoin cash will hard fork on Nov 13 to implement a new difficulty\n> algorithm.  Bitcoin itself might need to hard fork to employ a similar\n> algorithm. It's about as good as they come because it followed the\n\nThis is the bitcoin development mailing list, not the \"give free\nreview to the obviously defective proposals of adversarial competing\nsystems\" mailing list. Your posting is off-topic.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171102/64dbe338/attachment.html>"
            },
            {
                "author": "gb",
                "date": "2017-11-03T00:47:27",
                "message_text_only": "You launched the political football by coming here with a verbose\n'recommendation'. Without a code submission in form of pull request to\nthe core repo on github this was never a technical discussion.\n\nOn Thu, 2017-11-02 at 19:53 -0400, Scott Roberts via bitcoin-dev wrote:\n> Whatever their failings from their previous code or their adversarial\n> nature, they got this code right and I'm only presenting it as a real\n> and excellent solution for the impending threat to bitcoin. As a big\n> core fan, I really wanted to delete the word Cash from my post because\n> I was afraid someone would turn this technical discussion into a\n> political football.\n> \n> On Nov 2, 2017 7:37 PM, \"Gregory Maxwell\" <greg at xiph.org> wrote:\n>         On Thu, Nov 2, 2017 at 11:31 PM, Scott Roberts via bitcoin-dev\n>         <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>         > Bitcoin cash will hard fork on Nov 13 to implement a new\n>         difficulty\n>         > algorithm.  Bitcoin itself might need to hard fork to employ\n>         a similar\n>         > algorithm. It's about as good as they come because it\n>         followed the\n>         \n>         \n>         This is the bitcoin development mailing list, not the \"give\n>         free\n>         review to the obviously defective proposals of adversarial\n>         competing\n>         systems\" mailing list. Your posting is off-topic.\n> \n> \n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "CryptAxe",
                "date": "2017-11-02T23:39:41",
                "message_text_only": "Is there an issue with the current difficulty adjustment algorithm? It's\nworked very well as far as I can tell. Introducing a new one seems pretty\nrisky, what would the benefit be?\n\nOn Nov 2, 2017 4:34 PM, \"Scott Roberts via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Bitcoin cash will hard fork on Nov 13 to implement a new difficulty\n> algorithm.  Bitcoin itself might need to hard fork to employ a similar\n> algorithm. It's about as good as they come because it followed the\n> \"simplest is best\" route. Their averaging window is probably\n> significantly too long (N=144). It's:\n>\n> next_D = sum (past 144 D's) * T / sum(past 144 solvetimes)\n>\n> They correctly did not use max(timestamp) - min(timestamp) in the\n> denominator like others do.\n>\n> They've written the code and they're about to use it live, so Bitcoin\n> will have a clear, simple, and tested path if it suddenly needs to\n> hard fork due to having 20x delays for the next 2000 blocks (taking it\n> a year to get unstuck).\n>\n> Details on it and the decision process:\n> https://www.bitcoinabc.org/november\n>\n> It uses a nice median of 3 for the beginning and end of the window to\n> help alleviate bad timestamp problems. It's nice, helps a little, but\n> will also slow its response by 1 block.  They also have 2x and 1/2\n> limits on the adjustment per block, which is a lot more than they will\n> ever need.\n>\n> I recommend bitcoin consider using it and making it N=50 instead of 144.\n>\n> I have seen that any attempts to modify the above with things like a\n> low pass filter, starting the window at MTP, or preventing negative\n> timestamps will only reduce its effectiveness. Bitcoin's +12 and -6\n> limits on the timestamps are sufficient and well chosen, although\n> something a bit smaller than the +12 might have been better.\n>\n> One of the contenders to the above is new and actually better, devised\n> by Degnr8 and they call it D622 or wt-144.It's a little better than\n> they realize. It's the only real improvement in difficulty algorithms\n> since the rolling average.  It gives a linearly higher weight to the\n> more recent timestamps. Otherwise it is the same. Others have probably\n> come across it, but there is too much noise in difficulty algorithms\n> to find the good ones.\n>\n> # Degnr8's D622 difficulty algorithm\n> # T=TargetTime, S=Solvetime\n> # modified by zawy\n> for i = 1 to N  (from oldest to most recent block)\n>     t += T[i] / D[i] * i\n>     j += i\n> next i\n> next_D = j / t * T\n>\n> I believe any modification to the above strict mathematical weighted\n> average will reduce it's effectiveness. It does not oscillate anymore\n> than regular algos and rises faster and drops faster, when needed.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171102/080f5543/attachment.html>"
            },
            {
                "author": "Scott Roberts",
                "date": "2017-11-03T01:59:47",
                "message_text_only": "The current DA is only sufficient if the coin has the highest\nhashpower. It's also just really slow.  If miners somehow stick with\nSegWit2x despite the higher rewards in defecting back to bitcoin, then\nbitcoin will have long block delays. High transaction fees will\nprobably help them defect back to us. But if SegWit2x manages to be\nmore comparable in price than BCH (despite the futures), hashpower\ncould very well oscillate back and forth between the two coins,\ncausing delays in both of them. The first one to hard fork to fix the\ndifficulty problem will have a large advantage, as evidenced by what\nhappens in alts.   In any event someday BTC may not be the biggest kid\non the block and will need a difficulty algorithm that alts would find\nacceptable. Few alts use anything like BTC's because they are not able\nto survive the resulting long delays.   I am recommending BTC\ndevelopers watch what happens as BCH goes live with a much better\nalgorithm, in case BTC needs to hard fork for the same reason and\nneeds a similar fix. Ignore the trolls.\n\nOn Thu, Nov 2, 2017 at 7:39 PM, CryptAxe <cryptaxe at gmail.com> wrote:\n> Is there an issue with the current difficulty adjustment algorithm? It's\n> worked very well as far as I can tell. Introducing a new one seems pretty\n> risky, what would the benefit be?\n>\n> On Nov 2, 2017 4:34 PM, \"Scott Roberts via bitcoin-dev\"\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> Bitcoin cash will hard fork on Nov 13 to implement a new difficulty\n>> algorithm.  Bitcoin itself might need to hard fork to employ a similar\n>> algorithm. It's about as good as they come because it followed the\n>> \"simplest is best\" route. Their averaging window is probably\n>> significantly too long (N=144). It's:\n>>\n>> next_D = sum (past 144 D's) * T / sum(past 144 solvetimes)\n>>\n>> They correctly did not use max(timestamp) - min(timestamp) in the\n>> denominator like others do.\n>>\n>> They've written the code and they're about to use it live, so Bitcoin\n>> will have a clear, simple, and tested path if it suddenly needs to\n>> hard fork due to having 20x delays for the next 2000 blocks (taking it\n>> a year to get unstuck).\n>>\n>> Details on it and the decision process:\n>> https://www.bitcoinabc.org/november\n>>\n>> It uses a nice median of 3 for the beginning and end of the window to\n>> help alleviate bad timestamp problems. It's nice, helps a little, but\n>> will also slow its response by 1 block.  They also have 2x and 1/2\n>> limits on the adjustment per block, which is a lot more than they will\n>> ever need.\n>>\n>> I recommend bitcoin consider using it and making it N=50 instead of 144.\n>>\n>> I have seen that any attempts to modify the above with things like a\n>> low pass filter, starting the window at MTP, or preventing negative\n>> timestamps will only reduce its effectiveness. Bitcoin's +12 and -6\n>> limits on the timestamps are sufficient and well chosen, although\n>> something a bit smaller than the +12 might have been better.\n>>\n>> One of the contenders to the above is new and actually better, devised\n>> by Degnr8 and they call it D622 or wt-144.It's a little better than\n>> they realize. It's the only real improvement in difficulty algorithms\n>> since the rolling average.  It gives a linearly higher weight to the\n>> more recent timestamps. Otherwise it is the same. Others have probably\n>> come across it, but there is too much noise in difficulty algorithms\n>> to find the good ones.\n>>\n>> # Degnr8's D622 difficulty algorithm\n>> # T=TargetTime, S=Solvetime\n>> # modified by zawy\n>> for i = 1 to N  (from oldest to most recent block)\n>>     t += T[i] / D[i] * i\n>>     j += i\n>> next i\n>> next_D = j / t * T\n>>\n>> I believe any modification to the above strict mathematical weighted\n>> average will reduce it's effectiveness. It does not oscillate anymore\n>> than regular algos and rises faster and drops faster, when needed.\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Jacob Eliosoff",
                "date": "2017-11-04T03:37:06",
                "message_text_only": "I'm no BCH fan, but I agree with Scott that changes to the DAA may be of\nmore than purely theoretical interest for BTC.  Anyway just for those\ninterested, below is an algo I've been playing with that adjusts difficulty\nevery block, based only on the previous block's time and difficulty.  I\ntested it a bit and it seems to adapt to hashrate swings pretty well.\n\nweight_n = 1 - e^-(blocktime_n / 1 hr)    # 1 hr = exp moving avg window -\ntoo short?\nadj_n = (10 min / blocktime_n) - 1\ndifficulty_(n+1) = difficulty_n * (1 + weight_n * adj_n)\n\nIt could also be tweaked to make the *historical* avg block time ~exactly\n10 minutes, ie, to target > 10 min if past blocks were < 10 min.  This\nwould, eg, make mapping future block numbers to calendar times much more\nexact.\n\n\nOn Nov 3, 2017 7:24 AM, \"Scott Roberts via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> The current DA is only sufficient if the coin has the highest\n> hashpower. It's also just really slow.  If miners somehow stick with\n> SegWit2x despite the higher rewards in defecting back to bitcoin, then\n> bitcoin will have long block delays. High transaction fees will\n> probably help them defect back to us. But if SegWit2x manages to be\n> more comparable in price than BCH (despite the futures), hashpower\n> could very well oscillate back and forth between the two coins,\n> causing delays in both of them. The first one to hard fork to fix the\n> difficulty problem will have a large advantage, as evidenced by what\n> happens in alts.   In any event someday BTC may not be the biggest kid\n> on the block and will need a difficulty algorithm that alts would find\n> acceptable. Few alts use anything like BTC's because they are not able\n> to survive the resulting long delays.   I am recommending BTC\n> developers watch what happens as BCH goes live with a much better\n> algorithm, in case BTC needs to hard fork for the same reason and\n> needs a similar fix. Ignore the trolls.\n>\n> On Thu, Nov 2, 2017 at 7:39 PM, CryptAxe <cryptaxe at gmail.com> wrote:\n> > Is there an issue with the current difficulty adjustment algorithm? It's\n> > worked very well as far as I can tell. Introducing a new one seems pretty\n> > risky, what would the benefit be?\n> >\n> > On Nov 2, 2017 4:34 PM, \"Scott Roberts via bitcoin-dev\"\n> > <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>\n> >> Bitcoin cash will hard fork on Nov 13 to implement a new difficulty\n> >> algorithm.  Bitcoin itself might need to hard fork to employ a similar\n> >> algorithm. It's about as good as they come because it followed the\n> >> \"simplest is best\" route. Their averaging window is probably\n> >> significantly too long (N=144). It's:\n> >>\n> >> next_D = sum (past 144 D's) * T / sum(past 144 solvetimes)\n> >>\n> >> They correctly did not use max(timestamp) - min(timestamp) in the\n> >> denominator like others do.\n> >>\n> >> They've written the code and they're about to use it live, so Bitcoin\n> >> will have a clear, simple, and tested path if it suddenly needs to\n> >> hard fork due to having 20x delays for the next 2000 blocks (taking it\n> >> a year to get unstuck).\n> >>\n> >> Details on it and the decision process:\n> >> https://www.bitcoinabc.org/november\n> >>\n> >> It uses a nice median of 3 for the beginning and end of the window to\n> >> help alleviate bad timestamp problems. It's nice, helps a little, but\n> >> will also slow its response by 1 block.  They also have 2x and 1/2\n> >> limits on the adjustment per block, which is a lot more than they will\n> >> ever need.\n> >>\n> >> I recommend bitcoin consider using it and making it N=50 instead of 144.\n> >>\n> >> I have seen that any attempts to modify the above with things like a\n> >> low pass filter, starting the window at MTP, or preventing negative\n> >> timestamps will only reduce its effectiveness. Bitcoin's +12 and -6\n> >> limits on the timestamps are sufficient and well chosen, although\n> >> something a bit smaller than the +12 might have been better.\n> >>\n> >> One of the contenders to the above is new and actually better, devised\n> >> by Degnr8 and they call it D622 or wt-144.It's a little better than\n> >> they realize. It's the only real improvement in difficulty algorithms\n> >> since the rolling average.  It gives a linearly higher weight to the\n> >> more recent timestamps. Otherwise it is the same. Others have probably\n> >> come across it, but there is too much noise in difficulty algorithms\n> >> to find the good ones.\n> >>\n> >> # Degnr8's D622 difficulty algorithm\n> >> # T=TargetTime, S=Solvetime\n> >> # modified by zawy\n> >> for i = 1 to N  (from oldest to most recent block)\n> >>     t += T[i] / D[i] * i\n> >>     j += i\n> >> next i\n> >> next_D = j / t * T\n> >>\n> >> I believe any modification to the above strict mathematical weighted\n> >> average will reduce it's effectiveness. It does not oscillate anymore\n> >> than regular algos and rises faster and drops faster, when needed.\n> >> _______________________________________________\n> >> bitcoin-dev mailing list\n> >> bitcoin-dev at lists.linuxfoundation.org\n> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171103/2e7123e2/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2017-11-03T00:00:07",
                "message_text_only": "On Thu, Nov 2, 2017 at 11:53 PM, Scott Roberts <wordsgalore at gmail.com> wrote:\n> Whatever their failings from their previous code or their adversarial\n> nature, they got this code right and I'm only presenting it as a real and\n> excellent solution for the impending threat to bitcoin. As a big core fan, I\n> really wanted to delete the word Cash from my post because I was afraid\n> someone would turn this technical discussion into a political football.\n\nI urge my colleagues here to not fall for the obvious xkcd386 bait.\n\nThe competitive advantage of prudence and competence is diminished if\ncompetitors are able to divert our efforts into reviewing their\nproposals."
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Cash's new difficulty algorithm",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "CryptAxe",
                "Scott Roberts",
                "Gregory Maxwell",
                "Jacob Eliosoff",
                "gb"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 18831
        }
    },
    {
        "title": "[bitcoin-dev] Proposal: allocate Github issue instead of wiki page to BIP discussion",
        "thread_messages": [
            {
                "author": "Sjors Provoost",
                "date": "2017-11-03T09:50:15",
                "message_text_only": "I often find myself wanting to leave relatively small comments on BIP's that are IMO not worth bothering this list.\n\nBy default each BIP has a wiki page for discussion, e.g. https://github.com/bitcoin/bips/wiki/Comments:BIP-0150\nThis is linked to from the Comments-URI field in the BIP.\n\nIn order to leave a comment, you have to edit the wiki page. This process seems a bit clunky.\n\nI think it would be better to use Github issues, with one Github issue for each BIP.\n\nOne concern might be that the ease of use of Github issues would move discussion away from this list. The issue could be temporarily locked to prevent that. The issue description could contain a standard text explaining what should be discussed there and what would be more appropriate to post on the mailinglist.\n\nAnother concern might be confusing between PR's which create and update a BIP, and the discussion issue.\n\nIf people think this a good idea, would the next step be to propose a change to the process here?\nhttps://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki#BIP_comments\n\nOr would this be a new BIP?\n\nSjors\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171103/fdb12e98/attachment.sig>"
            },
            {
                "author": "Aymeric Vitte",
                "date": "2017-11-03T18:15:10",
                "message_text_only": "+10k\n\nIndeed, as any project Github issues should be enabled for BIPs,\nwondering too since some time why this is not the case, and then if an\nissue is worth discussing here it can be redirected to the list\n\n\nLe 03/11/2017 \u00e0 10:50, Sjors Provoost via bitcoin-dev a \u00e9crit\u00a0:\n> I often find myself wanting to leave relatively small comments on BIP's that are IMO not worth bothering this list.\n>\n> By default each BIP has a wiki page for discussion, e.g. https://github.com/bitcoin/bips/wiki/Comments:BIP-0150\n> This is linked to from the Comments-URI field in the BIP.\n>\n> In order to leave a comment, you have to edit the wiki page. This process seems a bit clunky.\n>\n> I think it would be better to use Github issues, with one Github issue for each BIP.\n>\n> One concern might be that the ease of use of Github issues would move discussion away from this list. The issue could be temporarily locked to prevent that. The issue description could contain a standard text explaining what should be discussed there and what would be more appropriate to post on the mailinglist.\n>\n> Another concern might be confusing between PR's which create and update a BIP, and the discussion issue.\n>\n> If people think this a good idea, would the next step be to propose a change to the process here?\n> https://github.com/bitcoin/bips/blob/master/bip-0002.mediawiki#BIP_comments\n>\n> Or would this be a new BIP?\n>\n> Sjors\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-- \nZcash wallets made simple: https://github.com/Ayms/zcash-wallets\nBitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets\nGet the torrent dynamic blocklist: http://peersm.com/getblocklist\nCheck the 10 M passwords list: http://peersm.com/findmyass\nAnti-spies and private torrents, dynamic blocklist: http://torrent-live.org\nPeersm : http://www.peersm.com\ntorrent-live: https://github.com/Ayms/torrent-live\nnode-Tor : https://www.github.com/Ayms/node-Tor\nGitHub : https://www.github.com/Ayms\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171103/d53bc45e/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Proposal: allocate Github issue instead of wiki page to BIP discussion",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Sjors Provoost",
                "Aymeric Vitte"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 3672
        }
    },
    {
        "title": "[bitcoin-dev] \"Changes without unanimous consent\" talk at Scaling Bitcoin",
        "thread_messages": [
            {
                "author": "Anthony Towns",
                "date": "2017-11-05T17:50:33",
                "message_text_only": "Hi,\n\nPaper (and slides) for my talk in the Consensus stream of Scaling Bitcoin\nthis morning are at:\n\n   https://github.com/ajtowns/sc-btc-2017/releases\n\nSome analysis for split-related consensus changes, and (code-less)\nproposals for generic replay protection (a la BIP 115) and providing a\nbetter level of price discovery for proposals that could cause splits.\n\nCheers,\naj"
            }
        ],
        "thread_summary": {
            "title": "\"Changes without unanimous consent\" talk at Scaling Bitcoin",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Anthony Towns"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 373
        }
    },
    {
        "title": "[bitcoin-dev] Generalised Replay Protection for Future Hard Forks",
        "thread_messages": [
            {
                "author": "Mats Jerratsch",
                "date": "2017-11-05T23:48:43",
                "message_text_only": "Presented is a generalised way of providing replay protection for future hard forks. On top of replay protection, this schema also allows for fork-distinct addresses and potentially a way to opt-out of replay protection of any fork, where deemed necessary (can be beneficial for some L2 applications).\n\n## Rationale\n\nCurrently when a hard fork happens, there is ad-hoc replay protection built within days with little review at best, or no replay protection at all. Often this is either resource problem, where not enough time and developers are available to sufficiently address replay protection, or the idea that not breaking compatibility is favourable. Furthermore, this is potentially a recurring problem with no generally accepted solution yet. Services that want to deal in multiple forks are expected to closely follow all projects. Since there is no standard, the solutions differ for each project, requiring custom code for every fork. By integrating replay protection into the protocol, we advocate the notion of non-hostile forks.\n\nUsers are protected against accidentally sending coins on the wrong chain through the introduction of a fork-specific incompatible address space. The coin/token type is encoded in the address itself, removing some of the importance around the question _What is Bitcoin?_. By giving someone an address, it is explicitly stated _I will only honour a payment of token X_, enforcing the idea of validating the payment under the rules chosen by the payee.\n\n## Iterative Forks\n\nIn this schema, any hard fork is given an incremented id, `nForkId`. `nForkId` starts at `1`, with `0` being reserved as a wildcard. When project X decides to make an incompatible change to the protocol, it will get assigned a new unique `nForkId` for this fork. A similar approach like for BIP43 can be taken here. Potentially `nForkId` can be reused if a project has not gained any amount of traction.\n\nWhen preparing the transaction for signing or validation, `nForkId` is appended to the final template as a 4B integer (similar to [1]). Amending BIP143, this would result in\n\n```\n Double SHA256 of the serialization of:\n     1. nVersion of the transaction (4-byte little endian)\n     2. hashPrevouts (32-byte hash)\n     3. hashSequence (32-byte hash)\n     4. outpoint (32-byte hash + 4-byte little endian)\n     5. scriptCode of the input (serialized as scripts inside CTxOuts)\n     6. value of the output spent by this input (8-byte little endian)\n     7. nSequence of the input (4-byte little endian)\n     8. hashOutputs (32-byte hash)\n     9. nLocktime of the transaction (4-byte little endian)\n    10. sighash type of the signature (4-byte little endian)\n    11. nForkId (4-byte little endian)\n```\n\n\nFor `nForkId=0` this step is ommitted. This will immediately invalidate signatures for any other branch of the blockchain than this specific fork. To distinguish between `nForkId=0` and `nForkId` hardcoded into the software, another bit has to be set in the 1B SigHashId present at the end of signatures.\n\nTo make this approach more generic, payment addresses will contain the fork id, depending on which tokens a payee expects payments in. This would require a change on bech32 addresses, maybe to use a similar format used in lightning-rfc [2]. A wallet will parse the address, it will extract `nForkId`, and it displays which token the user is about to spend. When signing the transaction, it will use `nForkId`, such that the transaction is only valid for this specific token. This can be generalised in software to the point where replay protection *and* a new address space can be introduced for forks without breaking existing clients.\n\nFor light clients, this can be extended by enforcing the coinbase/block header to contain the `nForkId` of the block. Then the client can distinguish between different chains and tokens it received on each. Alternatively, a new P2P message type for sending transactions could be introduced, where prevOut and `nForkId` is transmitted, such that the lite client can check for himself, which token he received.\n\nAllowing signatures with `nForkId=1` can be achieved with a soft fork by incrementing the script version of SegWit, making this a fully backwards compatible change.\n\n[1]\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-February/013542.html <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-February/013542.html>\n[2]\nhttps://github.com/lightningnetwork/lightning-rfc/blob/master/11-payment-encoding.md <https://github.com/lightningnetwork/lightning-rfc/blob/master/11-payment-encoding.md>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171105/41f5276f/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 842 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171105/41f5276f/attachment.sig>"
            },
            {
                "author": "Jacob Eliosoff",
                "date": "2017-11-06T19:21:28",
                "message_text_only": "Thanks Mats, this proposal makes sense to me (especially the idea of\nfork-specific addresses).  It prevents replay across forks, and makes it\neasy for client software, and thus potentially users, to specify which fork\na tx is for.  But, like other (rougher) past proposals I've seen, it does\nlittle to prevent users from accidentally sending on the wrong fork.\n\nTake the specific and common case of non-upgraded wallet software.  Suppose\na HF happens, and becomes the network used by 90% of users.  Will old\nwallets still default to the old nForkId (10% legacy chain)?  If so, I'd\nexpect a lot of accidental mis-sends on that chain.\n\nThis is just a gap in your proposal, not a flaw, but it's worth thinking\nabout less hazard-prone ways wallets could default nForkId.  Perhaps they\ncould listen to all forks, and default to the one whose last (recent) block\nhad the highest difficulty?  Or just check those blocks to see if multiple\nforks are (nontrivially) active, and if so warn the user and force them to\nconfirm?  Something like that.\n\n\nOn Nov 6, 2017 7:05 AM, \"Mats Jerratsch via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n\nPresented is a generalised way of providing replay protection for future\nhard forks. On top of replay protection, this schema also allows for\nfork-distinct addresses and potentially a way to opt-out of replay\nprotection of any fork, where deemed necessary (can be beneficial for some\nL2 applications).\n\n## Rationale\n\nCurrently when a hard fork happens, there is ad-hoc replay protection built\nwithin days with little review at best, or no replay protection at all.\nOften this is either resource problem, where not enough time and developers\nare available to sufficiently address replay protection, or the idea that\nnot breaking compatibility is favourable. Furthermore, this is potentially\na recurring problem with no generally accepted solution yet. Services that\nwant to deal in multiple forks are expected to closely follow all projects.\nSince there is no standard, the solutions differ for each project,\nrequiring custom code for every fork. By integrating replay protection into\nthe protocol, we advocate the notion of non-hostile forks.\n\nUsers are protected against accidentally sending coins on the wrong chain\nthrough the introduction of a fork-specific incompatible address space. The\ncoin/token type is encoded in the address itself, removing some of the\nimportance around the question _What is Bitcoin?_. By giving someone an\naddress, it is explicitly stated _I will only honour a payment of token X_,\nenforcing the idea of validating the payment under the rules chosen by the\npayee.\n\n## Iterative Forks\n\nIn this schema, any hard fork is given an incremented id, `nForkId`.\n`nForkId` starts at `1`, with `0` being reserved as a wildcard. When\nproject X decides to make an incompatible change to the protocol, it will\nget assigned a new unique `nForkId` for this fork. A similar approach like\nfor BIP43 can be taken here. Potentially `nForkId` can be reused if a\nproject has not gained any amount of traction.\n\nWhen preparing the transaction for signing or validation, `nForkId` is\nappended to the final template as a 4B integer (similar to [1]). Amending\nBIP143, this would result in\n\n```\nDouble SHA256 of the serialization of:\n    1. nVersion of the transaction (4-byte little endian)\n    2. hashPrevouts (32-byte hash)\n    3. hashSequence (32-byte hash)\n    4. outpoint (32-byte hash + 4-byte little endian)\n    5. scriptCode of the input (serialized as scripts inside CTxOuts)\n    6. value of the output spent by this input (8-byte little endian)\n    7. nSequence of the input (4-byte little endian)\n    8. hashOutputs (32-byte hash)\n    9. nLocktime of the transaction (4-byte little endian)\n   10. sighash type of the signature (4-byte little endian)\n   11. nForkId (4-byte little endian)\n```\n\n\nFor `nForkId=0` this step is ommitted. This will immediately invalidate\nsignatures for any other branch of the blockchain than this specific fork.\nTo distinguish between `nForkId=0` and `nForkId` hardcoded into the\nsoftware, another bit has to be set in the 1B SigHashId present at the end\nof signatures.\n\nTo make this approach more generic, payment addresses will contain the fork\nid, depending on which tokens a payee expects payments in. This would\nrequire a change on bech32 addresses, maybe to use a similar format used in\nlightning-rfc [2]. A wallet will parse the address, it will extract\n`nForkId`, and it displays which token the user is about to spend. When\nsigning the transaction, it will use `nForkId`, such that the transaction\nis only valid for this specific token. This can be generalised in software\nto the point where replay protection *and* a new address space can be\nintroduced for forks without breaking existing clients.\n\nFor light clients, this can be extended by enforcing the coinbase/block\nheader to contain the `nForkId` of the block. Then the client can\ndistinguish between different chains and tokens it received on each.\nAlternatively, a new P2P message type for sending transactions could be\nintroduced, where prevOut and `nForkId` is transmitted, such that the lite\nclient can check for himself, which token he received.\n\nAllowing signatures with `nForkId=1` can be achieved with a soft fork by\nincrementing the script version of SegWit, making this a fully backwards\ncompatible change.\n\n[1]\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/\n2017-February/013542.html\n\n[2]\nhttps://github.com/lightningnetwork/lightning-rfc/blob/master/11-payment-\nencoding.md\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171106/91e3799f/attachment.html>"
            },
            {
                "author": "Mats Jerratsch",
                "date": "2017-11-08T16:45:01",
                "message_text_only": "Hey Jacob!\n\n> Take the specific and common case of non-upgraded wallet software.  Suppose a HF happens, and becomes the network used by 90% of users.  Will old wallets still default to the old nForkId (10% legacy chain)?  If so, I'd expect a lot of accidental mis-sends on that chain.\n\nWith this proposal implemented, a 'mis-send' is fundamentally impossible. The address contains the identifier of the token that should be sent.\n\nIf anything, it's possible to 'mis-receive'.\nThat is, the receiving wallet was not aware of a newer chain, and the receiver actually wanted to receive the newer token, but instead his wallet created an address for the old token. It is the responsibility of the receiver to write a correct invoice. This is the case everywhere else in the world too, so this seems like a reasonable trade-off.\n\nI would even argue that this should hold in a legal case, where the receiver cannot claim that he was expecting a payment in another token (contrary to how it is today, like when users send BTC to a BCH address, losing their funds with potentially no legal right for reimbursement). If I sent someone an invoice over 100\u20ac, I cannot later proclaim that I actually expected $100.\n\nWith this proposal, wallets are finally able to distinguish between different tokens. With this ability, I expect to see different implementations, some wallets which advertise staying conservative, following a strict ruleset, and other wallets being more experimental, following hashing rate or other metrics.\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 842 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171108/eef251dc/attachment.sig>"
            },
            {
                "author": "Jacob Eliosoff",
                "date": "2017-11-09T20:45:43",
                "message_text_only": "OK, I see.  On the whole this is the best replay protection solution I've\nseen.  In particular, I hope developers of Bech32 and other new address\nformats will take a close look at incorporating a fork ID this way.\n\nAs I understand you, a private key in cold storage would (of course) remain\nvalid across HFs, but an *address* would be valid only for the nForkId it\nwas generated for.  There may be cold-storage-type cases where it's\nimportant for an address to be valid across all chains, ie, to\nintentionally allow replay?  But I guess this could just be a special\nnForkId value, say -1?\n\n\nOn Nov 8, 2017 9:45 AM, \"Mats Jerratsch\" <mats at blockchain.com> wrote:\n\n> Hey Jacob!\n>\n> > Take the specific and common case of non-upgraded wallet software.\n> Suppose a HF happens, and becomes the network used by 90% of users.  Will\n> old wallets still default to the old nForkId (10% legacy chain)?  If so,\n> I'd expect a lot of accidental mis-sends on that chain.\n>\n> With this proposal implemented, a 'mis-send' is fundamentally impossible.\n> The address contains the identifier of the token that should be sent.\n>\n> If anything, it's possible to 'mis-receive'.\n> That is, the receiving wallet was not aware of a newer chain, and the\n> receiver actually wanted to receive the newer token, but instead his wallet\n> created an address for the old token. It is the responsibility of the\n> receiver to write a correct invoice. This is the case everywhere else in\n> the world too, so this seems like a reasonable trade-off.\n>\n> I would even argue that this should hold in a legal case, where the\n> receiver cannot claim that he was expecting a payment in another token\n> (contrary to how it is today, like when users send BTC to a BCH address,\n> losing their funds with potentially no legal right for reimbursement). If I\n> sent someone an invoice over 100\u20ac, I cannot later proclaim that I actually\n> expected $100.\n>\n> With this proposal, wallets are finally able to distinguish between\n> different tokens. With this ability, I expect to see different\n> implementations, some wallets which advertise staying conservative,\n> following a strict ruleset, and other wallets being more experimental,\n> following hashing rate or other metrics.\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171109/b20d9108/attachment.html>"
            },
            {
                "author": "Sjors Provoost",
                "date": "2017-11-09T21:01:10",
                "message_text_only": "> Op 9 nov. 2017, om 21:45 heeft Jacob Eliosoff via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:\n> \n> As I understand you, a private key in cold storage would (of course) remain valid across HFs, but an address would be valid only for the nForkId it was generated for.  There may be cold-storage-type cases where it's important for an address to be valid across all chains, ie, to intentionally allow replay?  But I guess this could just be a special nForkId value, say -1?\n\nIf I understand the proposal correctly, you can always spend coins; it's the next transaction that is replay protected.\n\nI like the idea of specifying the fork in bech32 [0]. On the other hand, the standard already has a human readable part. Perhaps the human readable part can be used as the fork id?\n\nNote that in your currently proposal nForkId is only in the transaction signature pre-image. It's not in the serialized transaction, so a node would just have to try to see if the signature is valid. I don't know if that's a problem.\n\nCan you clarify what you mean with:\n> Allowing signatures with `nForkId=1` can be achieved with a soft fork by incrementing the script version of SegWit, making this a fully backwards compatible change.\n\nWhat's the purpose of nForkId 1?\n\n>  potentially a way to opt-out of replay protection of any fork, where deemed necessary (can be beneficial for some L2 applications).\n\nCan you give an example of where this opt-out would be useful? Why wouldn't it be enough to just sign one transaction for each fork?\n\nIn Spoonnet, the version number is added to the SIGHASH_TYPE in the pre-image. Your solution of just adding another field seems easier, but maybe there's a downside?\n\nSjors\n\n[0] https://github.com/bitcoin/bips/blob/master/bip-0173.mediawiki#Bech32\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171109/e5a52b05/attachment.sig>"
            },
            {
                "author": "Mats Jerratsch",
                "date": "2017-11-10T11:28:06",
                "message_text_only": "I guess I wasn't clear on the wildcard, `nForkId=0`\n\nThis proposal puts Bitcoin at `nForkId=1`, with the purpose of having `nForkId=0` valid on *all* future forks. This means you can create a `nLockTime` transaction, delete the private key and still be assured to not lose potential future tokens.\n\nIn theory `nForkId=0` could be used for an address too, the sending wallet should display a warning message about unknown side effects though. This address would be future-safe, and you can put it into a safe-deposit box (even though I see little reason to back up an _address_. You would always back up a _private key_, which translates into funds on any fork.)\n\nFurthermore, `nForkId=0` can be used for L2 applications. Let's say Alice and Bob open a payment channel. One week later, project X decides to fork the network into a new token, implementing a custom way of providing strong two-way replay protection. The protocol Alice and Bob use for the payment channel has not implemented this new form of replay protection. Alice and Bob now have to make a choice:\n\n(1) Ignore this new token. This comes with an evaluation of how much this new token could be worth in the future. They will continue normal channel operation, knowing that their funds on the other branch will be locked up until eternity. When they close their payment channel, the closing transaction will get rejected from the other network, because it's not following the format for replay protected transactions.\n\n(2) Close the payment channel before the fork. The transaction, which closes the payment channel has to be mined before the fork, potentially paying a higher-than-normal fee.\n\nWith this proposal implemented, there are two additional choices\n\n(3) Create the commitment transactions with `nForkId=0`. This ensures that when the channel gets closed, funds on other chains are released accordingly. This also means that after the fork, payments on the channel move both, the original token and the new token. Potentially, Alice and Bob want to wait before further transacting on the channel, to see if the token has substantial value. If it has, they can *then* close the channel and open a new channel again. (Note: The funding transaction can use a specific `nForkId`, preventing you from locking up multiple coins when funding the channel, but you can choose to settle with `nForkId=0` to not lock up future coins)\n\n(4) Make the protocol aware of different `nForkId`. After the fork, the participants can chose to *only* close the payment channel on the new token, making the payment channel Bitcoin-only again. This is the preferred option, as it means no disruption to the original network.\n\n> I like the idea of specifying the fork in bech32 [0]. On the other hand, the standard already has a human readable part. Perhaps the human readable part can be used as the fork id?\n\nI was considering this too. On the other hand, it's only _human readable_ because thy bytes used currently encode 'bc'. For future forks, this would just be two random letters than, but potentially acceptable.\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171110/ada18c4a/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 842 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171110/ada18c4a/attachment-0001.sig>"
            },
            {
                "author": "Jacob Eliosoff",
                "date": "2017-11-11T05:18:11",
                "message_text_only": "OK, so nForkId 0 is exactly the \"valid on all chains\" specifier I was\nasking about, cool.  And your LN example (and nLockTime txs in general)\nillustrate why it's preferable to implement a generic replay protection\nscheme like yours *in advance*, rather than before each fork: all ad hoc RP\nschemes I know of break old txs on one of the chains, even when that's not\ndesirable - ie, they offer no wildcard like nForkId 0.\n\nOne comment on your LN example: users would have to take note that nForkId\n0 txs would be valid not only on future forks, but on *past* forks too.\nEg, if BCH had been deployed with nForkId 2, then a user setting up BTC LN\ntxs now with nForkId 0 would have to be aware that those txs would be valid\nfor BCH too.  Of course the user could avoid this by funding from a\nBTC-only address, but it is a potential minor pitfall of nForkId 0.  (Which\nI don't see any clean way around.)\n\n\nOn Fri, Nov 10, 2017 at 6:28 AM, Mats Jerratsch <mats at blockchain.com> wrote:\n\n> I guess I wasn't clear on the wildcard, `nForkId=0`\n>\n> This proposal puts Bitcoin at `nForkId=1`, with the purpose of having\n> `nForkId=0` valid on *all* future forks. This means you can create a\n> `nLockTime` transaction, delete the private key and still be assured to not\n> lose potential future tokens.\n>\n> In theory `nForkId=0` could be used for an address too, the sending wallet\n> should display a warning message about unknown side effects though. This\n> address would be future-safe, and you can put it into a safe-deposit box\n> (even though I see little reason to back up an _address_. You would always\n> back up a _private key_, which translates into funds on any fork.)\n>\n> Furthermore, `nForkId=0` can be used for L2 applications. Let's say Alice\n> and Bob open a payment channel. One week later, project X decides to fork\n> the network into a new token, implementing a custom way of providing strong\n> two-way replay protection. The protocol Alice and Bob use for the payment\n> channel has not implemented this new form of replay protection. Alice and\n> Bob now have to make a choice:\n>\n> (1) Ignore this new token. This comes with an evaluation of how much this\n> new token could be worth in the future. They will continue normal channel\n> operation, knowing that their funds on the other branch will be locked up\n> until eternity. When they close their payment channel, the closing\n> transaction will get rejected from the other network, because it's not\n> following the format for replay protected transactions.\n>\n> (2) Close the payment channel before the fork. The transaction, which\n> closes the payment channel has to be mined before the fork, potentially\n> paying a higher-than-normal fee.\n>\n> With this proposal implemented, there are two additional choices\n>\n> (3) Create the commitment transactions with `nForkId=0`. This ensures that\n> when the channel gets closed, funds on other chains are released\n> accordingly. This also means that after the fork, payments on the channel\n> move both, the original token and the new token. Potentially, Alice and Bob\n> want to wait before further transacting on the channel, to see if the token\n> has substantial value. If it has, they can *then* close the channel and\n> open a new channel again. (Note: The funding transaction can use a specific\n> `nForkId`, preventing you from locking up multiple coins when funding the\n> channel, but you can choose to settle with `nForkId=0` to not lock up\n> future coins)\n>\n> (4) Make the protocol aware of different `nForkId`. After the fork, the\n> participants can chose to *only* close the payment channel on the new\n> token, making the payment channel Bitcoin-only again. This is the preferred\n> option, as it means no disruption to the original network.\n>\n> > I like the idea of specifying the fork in bech32 [0]. On the other hand,\n> the standard already has a human readable part. Perhaps the human readable\n> part can be used as the fork id?\n>\n> I was considering this too. On the other hand, it's only _human readable_\n> because thy bytes used currently encode 'bc'. For future forks, this would\n> just be two random letters than, but potentially acceptable.\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171111/9fb7d5ba/attachment-0001.html>"
            },
            {
                "author": "Mats Jerratsch",
                "date": "2017-11-13T10:03:04",
                "message_text_only": "> OK, so nForkId 0 is exactly the \"valid on all chains\" specifier I was asking about, cool.  And your LN example (and nLockTime txs in general) illustrate why it's preferable to implement a generic replay protection scheme like yours in advance, rather than before each fork: all ad hoc RP schemes I know of break old txs on one of the chains, even when that's not desirable - ie, they offer no wildcard like nForkId 0.\n\nExactly!\n\n> One comment on your LN example: users would have to take note that nForkId 0 txs would be valid not only on future forks, but on past forks too.  Eg, if BCH had been deployed with nForkId 2, then a user setting up BTC LN txs now with nForkId 0 would have to be aware that those txs would be valid for BCH too.  Of course the user could avoid this by funding from a BTC-only address, but it is a potential minor pitfall of nForkId 0.  (Which I don't see any clean way around.)\n\nThis is actually incorrect. There are two transactions involved in LN. The funding transaction, which opens a payment channel, and a commitment transaction, which closes the channel when broadcasted to the network (the cooperative closing transaction can be considered a commitment transaction in a loose sense).\n\nNow you want to protect the funding transaction, as otherwise you would be subject to a replay-attack on all *past* forks. So you will set `nForkId>=1` for the funding transaction, making this payment channel non-existent on any *past* forks. However, if during the lifetime of the payment channel another fork happens, the payment channel exists for both tokens. So for the commitment transaction, you will have `nForkId=0`, making it valid on both of these chains. While this `nForkId` is valid on all chains, the parent transaction it tries to spend (the funding transaction) does only exist on two chains, the original one you created the channel for and the one that forked away.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171113/6fca842c/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 842 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171113/6fca842c/attachment.sig>"
            },
            {
                "author": "Jacob Eliosoff",
                "date": "2017-11-13T15:31:55",
                "message_text_only": ">\n> This is actually incorrect. There are two transactions involved in LN. The\n> funding transaction, which opens a payment channel, and a commitment\n> transaction, which closes the channel when broadcasted to the network (the\n> cooperative closing transaction can be considered a commitment transaction\n> in a loose sense).\n>\n> Now you want to protect the funding transaction, as otherwise you would be\n> subject to a replay-attack on all *past* forks. So you will set\n> `nForkId>=1` for the funding transaction, making this payment channel\n> non-existent on any *past* forks. However, if during the lifetime of the\n> payment channel another fork happens, the payment channel exists for both\n> tokens. So for the commitment transaction, you will have `nForkId=0`,\n> making it valid on both of these chains. While this `nForkId` is valid on\n> all chains, the parent transaction it tries to spend (the funding\n> transaction) does only exist on two chains, the original one you created\n> the channel for and the one that forked away.\n>\n\nThanks for the clarification.  How would a tx specify a constraint like\n\"nForkId>=1\"?  I was thinking of it just as a number set on the tx.\n\nAlso note that since forks form a partial order, but IDs (numbers) form a\ntotal order, \">=\" will miss some cases.  Eg, suppose BCH had forked with\nnForkId 2, and then you set up a LN funding tx on BCH with nForkId>=2, and\nthen Segwit2x forked (from BTC!) with nForkId 3.  The BCH funding tx would\nbe valid on Segwit2x.  This is more of a fundamental problem than a bug -\nto avoid it you'd have to get into stuff like making each fork reference\nits parent-fork's first block or something, someone has written about\nthis...\n\n\nOn Mon, Nov 13, 2017 at 5:03 AM, Mats Jerratsch <mats at blockchain.com> wrote:\n\n>\n> OK, so nForkId 0 is exactly the \"valid on all chains\" specifier I was\n> asking about, cool.  And your LN example (and nLockTime txs in general)\n> illustrate why it's preferable to implement a generic replay protection\n> scheme like yours *in advance*, rather than before each fork: all ad hoc\n> RP schemes I know of break old txs on one of the chains, even when that's\n> not desirable - ie, they offer no wildcard like nForkId 0.\n>\n>\n> Exactly!\n>\n> One comment on your LN example: users would have to take note that nForkId\n> 0 txs would be valid not only on future forks, but on *past* forks too.\n> Eg, if BCH had been deployed with nForkId 2, then a user setting up BTC LN\n> txs now with nForkId 0 would have to be aware that those txs would be valid\n> for BCH too.  Of course the user could avoid this by funding from a\n> BTC-only address, but it is a potential minor pitfall of nForkId 0.  (Which\n> I don't see any clean way around.)\n>\n>\n> This is actually incorrect. There are two transactions involved in LN. The\n> funding transaction, which opens a payment channel, and a commitment\n> transaction, which closes the channel when broadcasted to the network (the\n> cooperative closing transaction can be considered a commitment transaction\n> in a loose sense).\n>\n> Now you want to protect the funding transaction, as otherwise you would be\n> subject to a replay-attack on all *past* forks. So you will set\n> `nForkId>=1` for the funding transaction, making this payment channel\n> non-existent on any *past* forks. However, if during the lifetime of the\n> payment channel another fork happens, the payment channel exists for both\n> tokens. So for the commitment transaction, you will have `nForkId=0`,\n> making it valid on both of these chains. While this `nForkId` is valid on\n> all chains, the parent transaction it tries to spend (the funding\n> transaction) does only exist on two chains, the original one you created\n> the channel for and the one that forked away.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171113/ae5bea73/attachment-0001.html>"
            },
            {
                "author": "Spartacus Rex",
                "date": "2017-11-13T17:02:07",
                "message_text_only": "Totally agree something like this required..\n\nI've been burned.\n\nBut I like the 'old' idea of putting the hash of a block that MUST be on\nthe chain that this txn can eventually be added to. If the hash is not a\nvalid block on the chain, the txn can't be added.\n\nIt means you can choose exactly which forks you want to allow your txn on,\npre-fork for both, post-fork for only one, and gets round the issue of who\ngets to decide the nForkid value.. since you don't need one. Also, all the\nold outputs work fine, and LN not an issue.\n\nI'm missing why this scheme would be better ?\n\n\nOn Nov 13, 2017 15:35, \"Jacob Eliosoff via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> This is actually incorrect. There are two transactions involved in LN. The\n>> funding transaction, which opens a payment channel, and a commitment\n>> transaction, which closes the channel when broadcasted to the network (the\n>> cooperative closing transaction can be considered a commitment transaction\n>> in a loose sense).\n>>\n>> Now you want to protect the funding transaction, as otherwise you would\n>> be subject to a replay-attack on all *past* forks. So you will set\n>> `nForkId>=1` for the funding transaction, making this payment channel\n>> non-existent on any *past* forks. However, if during the lifetime of the\n>> payment channel another fork happens, the payment channel exists for both\n>> tokens. So for the commitment transaction, you will have `nForkId=0`,\n>> making it valid on both of these chains. While this `nForkId` is valid on\n>> all chains, the parent transaction it tries to spend (the funding\n>> transaction) does only exist on two chains, the original one you created\n>> the channel for and the one that forked away.\n>>\n>\n> Thanks for the clarification.  How would a tx specify a constraint like\n> \"nForkId>=1\"?  I was thinking of it just as a number set on the tx.\n>\n> Also note that since forks form a partial order, but IDs (numbers) form a\n> total order, \">=\" will miss some cases.  Eg, suppose BCH had forked with\n> nForkId 2, and then you set up a LN funding tx on BCH with nForkId>=2, and\n> then Segwit2x forked (from BTC!) with nForkId 3.  The BCH funding tx would\n> be valid on Segwit2x.  This is more of a fundamental problem than a bug -\n> to avoid it you'd have to get into stuff like making each fork reference\n> its parent-fork's first block or something, someone has written about\n> this...\n>\n>\n> On Mon, Nov 13, 2017 at 5:03 AM, Mats Jerratsch <mats at blockchain.com>\n> wrote:\n>\n>>\n>> OK, so nForkId 0 is exactly the \"valid on all chains\" specifier I was\n>> asking about, cool.  And your LN example (and nLockTime txs in general)\n>> illustrate why it's preferable to implement a generic replay protection\n>> scheme like yours *in advance*, rather than before each fork: all ad hoc\n>> RP schemes I know of break old txs on one of the chains, even when that's\n>> not desirable - ie, they offer no wildcard like nForkId 0.\n>>\n>>\n>> Exactly!\n>>\n>> One comment on your LN example: users would have to take note that\n>> nForkId 0 txs would be valid not only on future forks, but on *past*\n>> forks too.  Eg, if BCH had been deployed with nForkId 2, then a user\n>> setting up BTC LN txs now with nForkId 0 would have to be aware that those\n>> txs would be valid for BCH too.  Of course the user could avoid this by\n>> funding from a BTC-only address, but it is a potential minor pitfall of\n>> nForkId 0.  (Which I don't see any clean way around.)\n>>\n>>\n>> This is actually incorrect. There are two transactions involved in LN.\n>> The funding transaction, which opens a payment channel, and a commitment\n>> transaction, which closes the channel when broadcasted to the network (the\n>> cooperative closing transaction can be considered a commitment transaction\n>> in a loose sense).\n>>\n>> Now you want to protect the funding transaction, as otherwise you would\n>> be subject to a replay-attack on all *past* forks. So you will set\n>> `nForkId>=1` for the funding transaction, making this payment channel\n>> non-existent on any *past* forks. However, if during the lifetime of the\n>> payment channel another fork happens, the payment channel exists for both\n>> tokens. So for the commitment transaction, you will have `nForkId=0`,\n>> making it valid on both of these chains. While this `nForkId` is valid on\n>> all chains, the parent transaction it tries to spend (the funding\n>> transaction) does only exist on two chains, the original one you created\n>> the channel for and the one that forked away.\n>>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171113/452ebe4c/attachment-0001.html>"
            },
            {
                "author": "Mats Jerratsch",
                "date": "2017-11-14T13:49:56",
                "message_text_only": "> But I like the 'old' idea of putting the hash of a block that MUST be on the chain that this txn can eventually be added to. If the hash is not a valid block on the chain, the txn can't be added.\n> \n> It means you can choose exactly which forks you want to allow your txn on, pre-fork for both, post-fork for only one, and gets round the issue of who gets to decide the nForkid value.. since you don't need one. Also, all the old outputs work fine, and LN not an issue.\n> \n> I'm missing why this scheme would be better ?\n\nI do agree that solutions like `SIGHASH_BLOCKCOMMIT` are superior in the sense that they are very difficult to circumvent. However, a fork could also follow the original chain in SPV mode and allow transactions protected with these mechanism. Since it's fundamentally impossible to disallow transactions in future projects, the goal shouldn't be to make this overly complicated.\n\nFurthermore, this schema is not just adding replay protection. It makes transacting safer overall (due to a dedicated address format per fork) and allows light clients to differentiate between multiple forks. In the past three months, at least $600k has been lost by users sending BCH to a BTC address [1].\n\n> Thanks for the clarification.  How would a tx specify a constraint like \"nForkId>=1\"?  I was thinking of it just as a number set on the tx.\n\nWhether the transaction is replay protected or not is specified by setting a bit in the `SigHashId`. If this bit is set, then the signature *preimage* MUST have `nForkId` appended. `nForkId` is not part of the final transaction, someone who wants to verify the transaction must know which `nForkId` it was created with.\n\nIf the bit isn't set, it means `nForkId=0`, which allows other forks to validate the signature.\n\n> Also note that since forks form a partial order, but IDs (numbers) form a total order, \">=\" will miss some cases.  Eg, suppose BCH had forked with nForkId 2, and then you set up a LN funding tx on BCH with nForkId>=2, and then Segwit2x forked (from BTC!) with nForkId 3.  The BCH funding tx would be valid on Segwit2x.  This is more of a fundamental problem than a bug - to avoid it you'd have to get into stuff like making each fork reference its parent-fork's first block or something, someone has written about this...\n\nSorry, I was careless with the use of `>=` there. You are correct, forks form a tree. For this proposal, every leaf must be assigned a unique `nForkId`. The relationship between `nForkId` is irrelevant (e.g. which number is bigger), as long as they are unique. Transactions are only valid IFF `nForkId` matches exactly the `nForkId` of the software validating it. As described above, the transaction doesn't even contain `nForkId`, and the node surely is not starting to guess which one it could be.\n\n[1]\nhttps://twitter.com/khannib/status/930223617744437253 <https://twitter.com/khannib/status/930223617744437253>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171114/8a6b0269/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 842 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171114/8a6b0269/attachment.sig>"
            },
            {
                "author": "Jacob Eliosoff",
                "date": "2017-11-15T05:02:48",
                "message_text_only": ">\n> Sorry, I was careless with the use of `>=` there. You are correct, forks\n> form a tree. For this proposal, every leaf must be assigned a unique\n> `nForkId`. The relationship between `nForkId` is irrelevant (e.g. which\n> number is bigger), as long as they are unique. Transactions are only valid\n> IFF `nForkId` matches exactly the `nForkId` of the software validating it.\n> As described above, the transaction doesn't even contain `nForkId`, and the\n> node surely is not starting to guess which one it could be.\n>\n\nOK, but then it seems to me you have a dilemma for, eg, your LN commitment\ntx.  You either give it the specific nForkId of the fork it's created on -\nmaking it invalid on *all* other forks (eg, any future \"non-contentious\nupgrade\" HF that replaces that fork).  Or you give it nForkId 0 - which has\nthe \"BCH tx valid on Segwit2x (& vice versa)\" flaw.\n\nIt may make sense to revise your proposal to incorporate Luke's\nOP_CHECKBLOCKATHEIGHT\n<https://github.com/bitcoin/bips/blob/master/bip-0115.mediawiki>, and make\nthe fork ID a (block height, hash) pair rather than just a number.  But I\nstill think the idea of fork-specific addresses is a keeper!\n\n\nOn Tue, Nov 14, 2017 at 8:49 AM, Mats Jerratsch <mats at blockchain.com> wrote:\n\n>\n> But I like the 'old' idea of putting the hash of a block that MUST be on\n> the chain that this txn can eventually be added to. If the hash is not a\n> valid block on the chain, the txn can't be added.\n>\n> It means you can choose exactly which forks you want to allow your txn on,\n> pre-fork for both, post-fork for only one, and gets round the issue of who\n> gets to decide the nForkid value.. since you don't need one. Also, all the\n> old outputs work fine, and LN not an issue.\n>\n> I'm missing why this scheme would be better ?\n>\n>\n> I do agree that solutions like `SIGHASH_BLOCKCOMMIT` are superior in the\n> sense that they are very difficult to circumvent. However, a fork could\n> also follow the original chain in SPV mode and allow transactions protected\n> with these mechanism. Since it's fundamentally impossible to disallow\n> transactions in future projects, the goal shouldn't be to make this overly\n> complicated.\n>\n> Furthermore, this schema is not just adding replay protection. It makes\n> transacting safer overall (due to a dedicated address format per fork) and\n> allows light clients to differentiate between multiple forks. In the past\n> three months, at least $600k has been lost by users sending BCH to a BTC\n> address [1].\n>\n> Thanks for the clarification.  How would a tx specify a constraint like\n>> \"nForkId>=1\"?  I was thinking of it just as a number set on the tx.\n>>\n>\n> Whether the transaction is replay protected or not is specified by setting\n> a bit in the `SigHashId`. If this bit is set, then the signature *preimage*\n> MUST have `nForkId` appended. `nForkId` is not part of the final\n> transaction, someone who wants to verify the transaction must know which\n> `nForkId` it was created with.\n>\n> If the bit isn't set, it means `nForkId=0`, which allows other forks to\n> validate the signature.\n>\n> Also note that since forks form a partial order, but IDs (numbers) form a\n>> total order, \">=\" will miss some cases.  Eg, suppose BCH had forked with\n>> nForkId 2, and then you set up a LN funding tx on BCH with nForkId>=2, and\n>> then Segwit2x forked (from BTC!) with nForkId 3.  The BCH funding tx would\n>> be valid on Segwit2x.  This is more of a fundamental problem than a bug -\n>> to avoid it you'd have to get into stuff like making each fork reference\n>> its parent-fork's first block or something, someone has written about\n>> this...\n>>\n>\n> Sorry, I was careless with the use of `>=` there. You are correct, forks\n> form a tree. For this proposal, every leaf must be assigned a unique\n> `nForkId`. The relationship between `nForkId` is irrelevant (e.g. which\n> number is bigger), as long as they are unique. Transactions are only valid\n> IFF `nForkId` matches exactly the `nForkId` of the software validating it.\n> As described above, the transaction doesn't even contain `nForkId`, and the\n> node surely is not starting to guess which one it could be.\n>\n> [1]\n> https://twitter.com/khannib/status/930223617744437253\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171115/83057847/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Generalised Replay Protection for Future Hard Forks",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jacob Eliosoff",
                "Sjors Provoost",
                "Spartacus Rex",
                "Mats Jerratsch"
            ],
            "messages_count": 12,
            "total_messages_chars_count": 44189
        }
    },
    {
        "title": "[bitcoin-dev] Centralizing mining by force",
        "thread_messages": [
            {
                "author": "Robert Taylor",
                "date": "2017-11-07T03:55:59",
                "message_text_only": "Forgive me if this has been asked elsewhere before, but I am trying to\nunderstand a potential failure mode of Bitcoin mining.\n\nA majority of miners can decide which valid blocks extend the chain. But\nwhat would happen if a majority of miners, in the form of a cartel decided\nto validly orphan any blocks made by miners outside of their group? For\nexample, they could soft fork a new rule where the block number is signed\nby set of keys known only to the cartel, and that signature placed in the\ncoinbase. Miners outside of the cartel would not be able to extend the\nchain.\n\nIt would be immediately obvious but still valid under the consensus rules.\nWhat are the disincentives for such behavior and what countermeasures could\nbe done to stop it and ensure mining remained permissionless? I think this\nis a valid concern because while it may not be feasible for one actor to\ngain a majority of hash alone, it is certainly possible with collusion.\n\nRobert\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171107/aff7454b/attachment-0001.html>"
            },
            {
                "author": "Marc Bevand",
                "date": "2017-11-08T05:04:07",
                "message_text_only": "What you describe is an example of a majority attack (\"51% attack\"). No\ntechnical mechanism in Bitcoin prevents this. However in practice, miners\nare not incentivized to perform this attack as it would destroy confidence\nin Bitcoin, and would ultimately impact their revenues.\n\n-Marc\n\nOn Mon, Nov 6, 2017, 22:32 Robert Taylor via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Forgive me if this has been asked elsewhere before, but I am trying to\n> understand a potential failure mode of Bitcoin mining.\n>\n> A majority of miners can decide which valid blocks extend the chain. But\n> what would happen if a majority of miners, in the form of a cartel decided\n> to validly orphan any blocks made by miners outside of their group? For\n> example, they could soft fork a new rule where the block number is signed\n> by set of keys known only to the cartel, and that signature placed in the\n> coinbase. Miners outside of the cartel would not be able to extend the\n> chain.\n>\n> It would be immediately obvious but still valid under the consensus rules.\n> What are the disincentives for such behavior and what countermeasures could\n> be done to stop it and ensure mining remained permissionless? I think this\n> is a valid concern because while it may not be feasible for one actor to\n> gain a majority of hash alone, it is certainly possible with collusion.\n>\n> Robert\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171108/46545fe7/attachment.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2017-11-09T18:18:17",
                "message_text_only": "It is not the case in practice that there exists no incentive to disrupt the market for transaction confirmation. Statism is profitable, and a primary source of revenue is seigniorage. Given Bitcoin's threat to that privilege, its destruction presents a hefty incentive.\n\nThe security model of Bitcoin is not based on balancing power between miners (those who confirm) and merchants (those who validate). It is based on these parties defending their mutually-beneficial market from the state.\n\nNeither technology nor incentives resolve this conflict. People must be willing to defend their mines and their economic nodes. This requires personal risk. The risk to each individual is mitigated by broad decentralization, but remains nonetheless.\n\nEven in a highly-decentralized system, overpowering taxpayer-funded disruption of the confirmation market will require that merchants pay aggregate fees exceeding the mining subsidy expended by the taxpayer to disrupt it. Who prevails in that tug of war is unclear, but working on Bitcoin implies one believes it is possible for individuals to do so.\n\ne\n\n> On Nov 7, 2017, at 21:04, Marc Bevand via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> What you describe is an example of a majority attack (\"51% attack\"). No technical mechanism in Bitcoin prevents this. However in practice, miners are not incentivized to perform this attack as it would destroy confidence in Bitcoin, and would ultimately impact their revenues.\n> \n> -Marc\n> \n> \n>> On Mon, Nov 6, 2017, 22:32 Robert Taylor via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> Forgive me if this has been asked elsewhere before, but I am trying to understand a potential failure mode of Bitcoin mining.\n>> \n>> A majority of miners can decide which valid blocks extend the chain. But what would happen if a majority of miners, in the form of a cartel decided to validly orphan any blocks made by miners outside of their group? For example, they could soft fork a new rule where the block number is signed by set of keys known only to the cartel, and that signature placed in the coinbase. Miners outside of the cartel would not be able to extend the chain.\n>> \n>> It would be immediately obvious but still valid under the consensus rules. What are the disincentives for such behavior and what countermeasures could be done to stop it and ensure mining remained permissionless? I think this is a valid concern because while it may not be feasible for one actor to gain a majority of hash alone, it is certainly possible with collusion.\n>> \n>> Robert\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171109/176bab43/attachment.html>"
            },
            {
                "author": "ZmnSCPxj",
                "date": "2017-11-08T05:37:39",
                "message_text_only": "Good morning Robert,\n\nWhat you describe is precisely one possible result of a 51% attack.\n\nAt below the 50% threshold, miners outside the cartel will on average outrace miners inside the cartel, so fullnodes which do not follow cartel rules will reject them as per Nakamoto Consensus.  At some point, the chain split becomes permanent, with miners outside the cartel pulling above the cartel miners.\n\nHowever, above the 50% threshold, miners outside the cartel will be unable to keep up with the cartel and be unable to build on top of the cartel chain (as presumably they are not valid signatories).  Outside-cartel miners, however, may institute an opposing cartel, or an anti-cartel (blocks must have a fixed, invalid with high probability, 00000 signature).\n\nIn the end, what matters is what fullnodes accept.  If fullnodes do not care, then the group of miners that is larger wins.  If fullnodes do check one or the other set of rules, then that set of rules will win.\n\nGiven current politics, it is likely that fullnodes will institute an anti-cartel rule in this case, and reject the cartel and suffer low hashrate.  Eventually, the cartel will be betrayed by one of its members mining the anti-cartel chain in return for fees and valuable block rewards.\n\nRegards,\nZmnSCPxj\n\nSent with [ProtonMail](https://protonmail.com) Secure Email.\n\n> -------- Original Message --------\n> Subject: [bitcoin-dev] Centralizing mining by force\n> Local Time: November 7, 2017 11:55 AM\n> UTC Time: November 7, 2017 3:55 AM\n> From: bitcoin-dev at lists.linuxfoundation.org\n> To: bitcoin-dev at lists.linuxfoundation.org\n>\n> Forgive me if this has been asked elsewhere before, but I am trying to understand a potential failure mode of Bitcoin mining.\n>\n> A majority of miners can decide which valid blocks extend the chain. But what would happen if a majority of miners, in the form of a cartel decided to validly orphan any blocks made by miners outside of their group? For example, they could soft fork a new rule where the block number is signed by set of keys known only to the cartel, and that signature placed in the coinbase. Miners outside of the cartel would not be able to extend the chain.\n>\n> It would be immediately obvious but still valid under the consensus rules. What are the disincentives for such behavior and what countermeasures could be done to stop it and ensure mining remained permissionless? I think this is a valid concern because while it may not be feasible for one actor to gain a majority of hash alone, it is certainly possible with collusion.\n>\n> Robert\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171108/e5c30ecd/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Centralizing mining by force",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Robert Taylor",
                "Eric Voskuil",
                "ZmnSCPxj",
                "Marc Bevand"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 8790
        }
    },
    {
        "title": "[bitcoin-dev] BIP Proposal: Compact Client Side Filtering for Light Clients",
        "thread_messages": [
            {
                "author": "Olaoluwa Osuntokun",
                "date": "2017-11-09T23:44:07",
                "message_text_only": "Hi y'all,\n\nSince my last email we've made a number of changes to the BIP. The changes\nmade\nwere driven by the feedback we've received so far in this thread, and also\nas a\nresult of real-world testing using this new proposal as the basis for our\nlight\nweight LN node which powers the demo Lightning desktop application we\nrecently\nreleased.\n\nA highlight of the changes made between this version and the last follows:\n\n  * We've removed the modulus operation in the inner loop when constructing\n    filters. This has been replaced with an alternative, more efficient\n    mapping[1] as suggested by gmaxwell and sipa. In our implementation, we\n    perform the operation in a piece-wise fashion by hand. Alternative\n    implementations can take advantage of 128-bit arithmetic extensions on\n    supporting CPU's.\n\n  * The txid has been moved from the extended filter to the regular filter.\n    During out testing of the new light client with our LN node\nimplementation,\n    we found that we were able to reduce network traffic as we only need the\n    extended filter for rare on-chain events.\n\n  * We now use the 6th service bit. We realized that the bit we had chosen\n    prior was already being used to signal support of x-thin block syncing.\nTo\n    select this bit number, we ran a scanner on the addrman of our nodes and\n    also the network to fin da bit that wasn't used widely.\n\n  * An error in the BIP that didn't include the public key script of\ncoinbase\n    transactions in the filter has been fixed.\n\n  * An error in the BIP when constructing the initial \"genesis\" filter has\nbeen\n    fixed.\n\n  * We no longer use the ProtocolVersion field in the getcfheaders message\nor\n    its response.\n\n  * The specification of several newly defined messages were incorrect and\nhave\n    been fixed.\n\n  * A number of typos spotted by several reviewers have been fixed.\n\nThe full commit history of the BIP draft can be found here:\nhttps://github.com/Roasbeef/bips/commits/gcs-bip-draft\n\nAt this point, we're ready to make a PR against the official BIP repo and to\nrequest a number to be assigned to our proposal. Thanks to all those that\nhave\nreviewed, and contributed to the proposal!\n\n[1]:\nhttps://lemire.me/blog/2016/06/27/a-fast-alternative-to-the-modulo-reduction/\n\n-- Laolu\n\n\nOn Thu, Jun 8, 2017 at 8:59 PM Olaoluwa Osuntokun <laolu32 at gmail.com> wrote:\n\n> Hi y'all,\n>\n> Thanks for all the comments so far!\n>\n> I've pushed a series of updates to the text of the BIP repo linked in the\n> OP.\n> The fixes include: typos, components of the specification which were\n> incorrect\n> (N is the total number of items, NOT the number of txns in the block), and\n> a\n> few sections have been clarified.\n>\n> The latest version also includes a set of test vectors (as CSV files),\n> which\n> for a series of fp rates (1/2 to 1/2^32) includes (for 6 testnet blocks,\n> one of\n> which generates a \"null\" filter):\n>\n>    * The block height\n>    * The block hash\n>    * The raw block itself\n>    * The previous basic+extended filter header\n>    * The basic+extended filter header for the block\n>    * The basic+extended filter for the block\n>\n> The size of the test vectors was too large to include in-line within the\n> document, so we put them temporarily in a distinct folder [1]. The code\n> used to\n> generate the test vectors has also been included.\n>\n> -- Laolu\n>\n> [1]: https://github.com/Roasbeef/bips/tree/master/gcs_light_client\n>\n>\n> On Thu, Jun 1, 2017 at 9:49 PM Olaoluwa Osuntokun <laolu32 at gmail.com>\n> wrote:\n>\n>> > In order to consider the average+median filter sizes in a world worth\n>> larger\n>> > blocks, I also ran the index for testnet:\n>> >\n>> >     * total size:  2753238530\n>> >     * total avg:  5918.95736054141\n>> >     * total median:  60202\n>> >     * total max:  74983\n>> >     * regular size:  1165148878\n>> >     * regular avg:  2504.856172982827\n>> >     * regular median:  24812\n>> >     * regular max:  64554\n>> >     * extended size:  1588089652\n>> >     * extended avg:  3414.1011875585823\n>> >     * extended median:  35260\n>> >     * extended max:  41731\n>> >\n>>\n>> Oops, realized I made a mistake. These are the stats for Feb 2016 until\n>> about a\n>> month ago (since height 400k iirc).\n>>\n>> -- Laolu\n>>\n>>\n>> On Thu, Jun 1, 2017 at 12:01 PM Olaoluwa Osuntokun <laolu32 at gmail.com>\n>> wrote:\n>>\n>>> Hi y'all,\n>>>\n>>> Alex Akselrod and I would like to propose a new light client BIP for\n>>> consideration:\n>>>    *\n>>> https://github.com/Roasbeef/bips/blob/master/gcs_light_client.mediawiki\n>>>\n>>> This BIP proposal describes a concrete specification (along with a\n>>> reference implementations[1][2][3]) for the much discussed client-side\n>>> filtering reversal of BIP-37. The precise details are described in the\n>>> BIP, but as a summary: we've implemented a new light-client mode that\n>>> uses\n>>> client-side filtering based off of Golomb-Rice coded sets. Full-nodes\n>>> maintain an additional index of the chain, and serve this compact filter\n>>> (the index) to light clients which request them. Light clients then fetch\n>>> these filters, query the locally and _maybe_ fetch the block if a\n>>> relevant\n>>> item matches. The cool part is that blocks can be fetched from _any_\n>>> source, once the light client deems it necessary. Our primary motivation\n>>> for this work was enabling a light client mode for lnd[4] in order to\n>>> support a more light-weight back end paving the way for the usage of\n>>> Lightning on mobile phones and other devices. We've integrated neutrino\n>>> as a back end for lnd, and will be making the updated code public very\n>>> soon.\n>>>\n>>> One specific area we'd like feedback on is the parameter selection.\n>>> Unlike\n>>> BIP-37 which allows clients to dynamically tune their false positive\n>>> rate,\n>>> our proposal uses a _fixed_ false-positive. Within the document, it's\n>>> currently specified as P = 1/2^20. We've done a bit of analysis and\n>>> optimization attempting to optimize the following sum:\n>>> filter_download_bandwidth + expected_block_false_positive_bandwidth. Alex\n>>> has made a JS calculator that allows y'all to explore the affect of\n>>> tweaking the false positive rate in addition to the following variables:\n>>> the number of items the wallet is scanning for, the size of the blocks,\n>>> number of blocks fetched, and the size of the filters themselves. The\n>>> calculator calculates the expected bandwidth utilization using the CDF of\n>>> the Geometric Distribution. The calculator can be found here:\n>>> https://aakselrod.github.io/gcs_calc.html. Alex also has an empirical\n>>> script he's been running on actual data, and the results seem to match up\n>>> rather nicely.\n>>>\n>>> We we're excited to see that Karl Johan Alm (kallewoof) has done some\n>>> (rather extensive!) analysis of his own, focusing on a distinct encoding\n>>> type [5]. I haven't had the time yet to dig into his report yet, but I\n>>> think I've read enough to extract the key difference in our encodings:\n>>> his\n>>> filters use a binomial encoding _directly_ on the filter contents, will\n>>> we\n>>> instead create a Golomb-Coded set with the contents being _hashes_ (we\n>>> use\n>>> siphash) of the filter items.\n>>>\n>>> Using a fixed fp=20, I have some stats detailing the total index size, as\n>>> well as averages for both mainnet and testnet. For mainnet, using the\n>>> filter contents as currently described in the BIP (basic + extended), the\n>>> total size of the index comes out to 6.9GB. The break down is as follows:\n>>>\n>>>     * total size:  6976047156\n>>>     * total avg:  14997.220622758816\n>>>     * total median:  3801\n>>>     * total max:  79155\n>>>     * regular size:  3117183743\n>>>     * regular avg:  6701.372750217131\n>>>     * regular median:  1734\n>>>     * regular max:  67533\n>>>     * extended size:  3858863413 <(385)%20886-3413>\n>>>     * extended avg:  8295.847872541684\n>>>     * extended median:  2041\n>>>     * extended max:  52508\n>>>\n>>> In order to consider the average+median filter sizes in a world worth\n>>> larger blocks, I also ran the index for testnet:\n>>>\n>>>     * total size:  2753238530\n>>>     * total avg:  5918.95736054141\n>>>     * total median:  60202\n>>>     * total max:  74983\n>>>     * regular size:  1165148878\n>>>     * regular avg:  2504.856172982827\n>>>     * regular median:  24812\n>>>     * regular max:  64554\n>>>     * extended size:  1588089652\n>>>     * extended avg:  3414.1011875585823\n>>>     * extended median:  35260\n>>>     * extended max:  41731\n>>>\n>>> Finally, here are the testnet stats which take into account the increase\n>>> in the maximum filter size due to segwit's block-size increase. The max\n>>> filter sizes are a bit larger due to some of the habitual blocks I\n>>> created last year when testing segwit (transactions with 30k inputs, 30k\n>>> outputs, etc).\n>>>\n>>>      * total size:  585087597\n>>>      * total avg:  520.8839608674402\n>>>      * total median:  20\n>>>      * total max:  164598\n>>>      * regular size:  299325029\n>>>      * regular avg:  266.4790836307566\n>>>      * regular median:  13\n>>>      * regular max:  164583\n>>>      * extended size:  285762568\n>>>      * extended avg:  254.4048772366836\n>>>      * extended median:  7\n>>>      * extended max:  127631\n>>>\n>>> For those that are interested in the raw data, I've uploaded a CSV file\n>>> of raw data for each block (mainnet + testnet), which can be found here:\n>>>      * mainnet: (14MB):\n>>> https://www.dropbox.com/s/4yk2u8dj06njbuv/mainnet-gcs-stats.csv?dl=0\n>>>      * testnet: (25MB):\n>>> https://www.dropbox.com/s/w7dmmcbocnmjfbo/gcs-stats-testnet.csv?dl=0\n>>>\n>>>\n>>> We look forward to getting feedback from all of y'all!\n>>>\n>>> -- Laolu\n>>>\n>>>\n>>> [1]: https://github.com/lightninglabs/neutrino\n>>> [2]: https://github.com/Roasbeef/btcd/tree/segwit-cbf\n>>> [3]: https://github.com/Roasbeef/btcutil/tree/gcs/gcs\n>>> [4]: https://github.com/lightningnetwork/lnd/\n>>>\n>>> -- Laolu\n>>>\n>>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171109/9c95b929/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP Proposal: Compact Client Side Filtering for Light Clients",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Olaoluwa Osuntokun"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 10107
        }
    },
    {
        "title": "[bitcoin-dev] Covenants through merkelized txids.",
        "thread_messages": [
            {
                "author": "Rusty Russell",
                "date": "2017-11-10T01:31:14",
                "message_text_only": "Hi all,\n\n        This is an alternative to jl2012's BIPZZZ (OP_PUSHTXDATA[1]).\nIt riffs on the (ab)use of OP_CHECKSIGFROMSTACK that Russell[2]\nused to implement covenants[3].  I've been talking about it to random\npeople for a while, but haven't taken time to write it up.\n\nThe idea is to provide a OP_TXMERKLEVERIFY that compares the top stack\nelement against a merkle tree of the current tx constructed like so[4]:\n\n        TXMERKLE = merkle(nVersion | nLockTime | fee, inputs & outputs)\n        inputs & outputs = merkle(inputmerkle, outputmerkle)\n        input = merkle(prevoutpoint, nSequence | inputAmount)\n        output = merkle(nValue, scriptPubkey)\n\nMany variants are possible, but if we have OP_CAT, this makes it fairly\neasy to test a particular tx property.  A dedicated OP_MERKLE would make\nit even easier, of course.\n\nIf we one day HF and add merklized TXIDs[5], we could also use this method\nto inspect the tx *being spent* (which was what I was originally trying to\ndo).\n\nThanks for reading!\nRusty.\n\n[1] https://github.com/jl2012/bips/blob/vault/bip-0ZZZ.mediawiki\n[2] Aka Dr. \"Not Rusty\" O'Connor.  Of course both of us in the same thread will\n    probably break the internet.\n[3] https://blockstream.com/2016/11/02/covenants-in-elements-alpha.html\n[4] You could put every element in a leaf, but that's less compact to\n    use: cheaper to supply the missing parts with OP_CAT than add another level.\n[5] Eg. use the high nVersion bit to say \"make my txid a merkle\"."
            }
        ],
        "thread_summary": {
            "title": "Covenants through merkelized txids.",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Rusty Russell"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1482
        }
    },
    {
        "title": "[bitcoin-dev] OP_CHECKHARDFORKVERIFY - replay protection and fork futures on off-chain payment channels",
        "thread_messages": [
            {
                "author": "ZmnSCPxj",
                "date": "2017-11-10T23:33:31",
                "message_text_only": "Good morning list,\n\nI would like to speculate on the addition of an opcode which would provide replay protection and allow chain-backed trustless creation of hardfork futures payment channels.\n\nNote however that in order to work, the hardfork must \"cooperate\" by changing the operation of OP_CHECKHARDFORKVERIFY in the hardfork.\n\nThe opcode is simple.  If the top stack is not the exact value 1, it fails.\n\nThe intent is that a hardfork must \"cooperate\" by also changing OP_CHECKHARDFORKVERIFY so that the top stack must be some other, non-1 value after the hardfork date.  This is a consensus break, but as a hardfork is defined by the fact that it is a consensus break, this is deliberate.\n\n--\n\nIn the below, I assume the creation of a future hardfork with a new \"consensus version\" value (<hardforkVersion>, the value required by OP_CHECKHARDFORKVERIFY) and a fork height (<hardforkHeight>, the block height at which the hardfork will diverge from legacy).\n\nIt should be noted, that an \"uncooperative\" hardfork would not change its consensus version, and in that regard, OP_CHECKBLOCKATHEIGHTVERIFY is superior.\n\n--\n\nIn order to prepare my funds for splitting.  I pay to the below P2SH/P2WSH script:\n\nOP_IF\n  1 OP_CHECKHARDFORKVERIFY OP_DROP <myPubKey1> OP_CHECKSIG\nOP_ELSE\n  <hardforkVersion> OP_CHECKHARDFORKVERIFY OP_DROP <myPubKey2> OP_CHECKSIG\nOP_END\n\nIn the above, I can then create transactions that spend the first branch on legacy chain post fork, and create transactions that spend the second branch on the hardfork chain post fork.  In addition, if I suddenly need to access the fund before the fork date, I can use the first branch to recover my funds before the fork date.\n\n--\n\nSuppose I wish to make a bet with another randomly generated Internet person, MX06fRH.  I am of the opinion, that the hardfork will not have economic consensus, whereas MX06fRH is of the opinion that it will.  We resolve to each bet 1 BTC.\n\nWe create a transaction spending our funds and paying a single combined output to the below P2SH/P2WSH:\n\nOP_DUP\nOP_IF\n  1 OP_EQUAL\n  OP_IF\n    <hardforkHeight> OP_CHECKLOCKTIMEVERIFY OP_DROP\n    1 OP_CHECKHARDFORKVERIFY OP_DROP\n    <ZmnSCPxjWinPubKey> OP_CHECKSIG\n  OP_ELSE\n    <hardforkVersion> OP_CHECKHARDFORKVERIFY OP_DROP\n    <MRX06fRHWinPubKey> OP_CHECKSIG\n  OP_ENDIF\nOP_ELSE\n  OP_DROP\n  2 <ZmnSCPxjExitPubKey> <MX06fRHExitPubKey> 2 OP_CHECKMULTISIG\nOP_ENDIF\n\nIn the above, I can use <ZmnSCPxjWinPubKey> and an nLockTime transaction after the fork date to claim my legacy coin, if the legacy coin has value, wheres MRX06fRH can use <MRX06fRHWinPubKey> on the hardfork chain if it has value.  Alternatively, we can both agree to cancel the bet.\n\n--\n\nWhile the above is workable, it does not form a market where price discovery of legacy and hardfork future coins can be performed to determine consensus.  For that, we will need to use payment channel techniques.\n\nI and MRX06fRH can form a payment channel that can trade fork futures by creating an anchor transaction paying to:\n\nOP_DUP\nOP_IF\n  1 OP_EQUAL\n  OP_IF\n    <hardforkHeight> OP_CHECKLOCKTIMEVERIFY OP_DROP\n    1 OP_CHECKHARDFORKVERIFY OP_DROP\n    2 <ZmnSCPxjLegacyPubKey> <MX06fRHLegacyPubKey> 2 OP_CHECKMULTISIG\n  OP_ELSE\n    <hardforkVersion> OP_CHECKHARDFORKVERIFY OP_DROP\n    2 <ZmnSCPxjHardforkPubKey> <MX06fRHHardforkPubKey> 2 OP_CHECKMULTISIG\n  OP_ENDIF\nOP_ELSE\n  OP_DROP\n  2 <ZmnSCPxjExitPubKey> <MX06fRHExitPubKey> 2 OP_CHECKMULTISIG\nOP_ENDIF\n\nOf course, before the anchor transaction is signed, we should create commitment transactions first.  For a Poon-Drjya channel, we should create two commitment transactions, one for me and one for MX06fRH, but in fact we should create two versions of both, one for the legacy token and one for the hardfork token (four commitment transactions).  The contracts are differentiated by which branch of the above we activate.  Commitment transactions can only be claimed after the fork, but we can update them continuously using normal Poon-Dryja channel operations.\n\nIf I have the same amount of legacy and hardfork tokens, then MX06fRH also has equal legacy and hardfork tokens, so we can agree to exit.\n\n--\n\nUnfortunately this can only reach up to payment channels.  To create a futures market we should have a payment channel network.  For Lightning we use HTLCs to create atomic swaps of coins in different payment channels.  However, the difference here is that commitment transactions can only be claimed after the fork, so any HTLCs on top of that will have expired before the commitment transactions can be claimed and the HTLCs enforced.  Unfortunately, I know of no other construction that would allow creation of a payment channel network on top of a payment channel primitive.  So much for OP_CHECKHARDFORKVERIFY.\n\nRegards,\nZmnSCPxj\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171110/58bf0a84/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "OP_CHECKHARDFORKVERIFY - replay protection and fork futures on off-chain payment channels",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "ZmnSCPxj"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4980
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Core 0.15.1 released",
        "thread_messages": [
            {
                "author": "Wladimir J. van der Laan",
                "date": "2017-11-11T14:35:19",
                "message_text_only": "-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nBitcoin Core version *0.15.1* is now available from:\n\n  <https://bitcoincore.org/bin/bitcoin-core-0.15.1/>\n\nor\n\n  <https://bitcoin.org/bin/bitcoin-core-0.15.1/>\n\nOr through bittorrent:\n\n  magnet:?xt=urn:btih:e83dfdfca54def4e29f5355e8c3f9a7aa45ecbaf&dn=bitcoin-core-0.15.1&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969&tr=udp%3A%2F%2Ftracker.leechers-paradise.org%3A6969&tr=udp%3A%2F%2Fzer0day.ch%3A1337&tr=udp%3A%2F%2Fexplodie.org%3A6969\n\nThis is a new minor version release, including various bugfixes and\nperformance improvements, as well as updated translations.\n\nPlease report bugs using the issue tracker at GitHub:\n\n  <https://github.com/bitcoin/bitcoin/issues>\n\nTo receive security and update notifications, please subscribe to:\n\n  <https://bitcoincore.org/en/list/announcements/join/>\n\nHow to Upgrade\n==============\n\nIf you are running an older version, shut it down. Wait until it has completely\nshut down (which might take a few minutes for older versions), then run the \ninstaller (on Windows) or just copy over `/Applications/Bitcoin-Qt` (on Mac)\nor `bitcoind`/`bitcoin-qt` (on Linux).\n\nThe first time you run version 0.15.0 or higher, your chainstate database will\nbe converted to a new format, which will take anywhere from a few minutes to\nhalf an hour, depending on the speed of your machine.\n\nThe file format of `fee_estimates.dat` changed in version 0.15.0. Hence, a\ndowngrade from version 0.15 or upgrade to version 0.15 will cause all fee\nestimates to be discarded.\n\nNote that the block database format also changed in version 0.8.0 and there is no\nautomatic upgrade code from before version 0.8 to version 0.15.0. Upgrading\ndirectly from 0.7.x and earlier without redownloading the blockchain is not supported.\nHowever, as usual, old wallet versions are still supported.\n\nDowngrading warning\n- -------------------\n\nThe chainstate database for this release is not compatible with previous\nreleases, so if you run 0.15 and then decide to switch back to any\nolder version, you will need to run the old release with the `-reindex-chainstate`\noption to rebuild the chainstate data structures in the old format.\n\nIf your node has pruning enabled, this will entail re-downloading and\nprocessing the entire blockchain.\n\nCompatibility\n==============\n\nBitcoin Core is extensively tested on multiple operating systems using\nthe Linux kernel, macOS 10.8+, and Windows Vista and later. Windows XP is not supported.\n\nBitcoin Core should also work on most other Unix-like systems but is not\nfrequently tested on them.\n\n\nNotable changes\n===============\n\nNetwork fork safety enhancements\n- --------------------------------\n\nA number of changes to the way Bitcoin Core deals with peer connections and invalid blocks\nhave been made, as a safety precaution against blockchain forks and misbehaving peers.\n\n- - Unrequested blocks with less work than the minimum-chain-work are now no longer processed even\nif they have more work than the tip (a potential issue during IBD where the tip may have low-work).\nThis prevents peers wasting the resources of a node. \n\n- - Peers which provide a chain with less work than the minimum-chain-work during IBD will now be disconnected.\n\n- - For a given outbound peer, we now check whether their best known block has at least as much work as our tip. If it\ndoesn't, and if we still haven't heard about a block with sufficient work after a 20 minute timeout, then we send\na single getheaders message, and wait 2 more minutes. If after two minutes their best known block has insufficient\nwork, we disconnect that peer. We protect 4 of our outbound peers from being disconnected by this logic to prevent\nexcessive network topology changes as a result of this algorithm, while still ensuring that we have a reasonable\nnumber of nodes not known to be on bogus chains.\n\n- - Outbound (non-manual) peers that serve us block headers that are already known to be invalid (other than compact\nblock announcements, because BIP 152 explicitly permits nodes to relay compact blocks before fully validating them)\nwill now be disconnected.\n\n- - If the chain tip has not been advanced for over 30 minutes, we now assume the tip may be stale and will try to connect\nto an additional outbound peer. A periodic check ensures that if this extra peer connection is in use, we will disconnect\nthe peer that least recently announced a new block.\n\n- - The set of all known invalid-themselves blocks (i.e. blocks which we attempted to connect but which were found to be\ninvalid) are now tracked and used to check if new headers build on an invalid chain. This ensures that everything that\ndescends from an invalid block is marked as such.\n\n\nMiner block size limiting deprecated\n- ------------------------------------\n\nThough blockmaxweight has been preferred for limiting the size of blocks returned by\ngetblocktemplate since 0.13.0, blockmaxsize remained as an option for those who wished\nto limit their block size directly. Using this option resulted in a few UI issues as\nwell as non-optimal fee selection and ever-so-slightly worse performance, and has thus\nnow been deprecated. Further, the blockmaxsize option is now used only to calculate an\nimplied blockmaxweight, instead of limiting block size directly. Any miners who wish\nto limit their blocks by size, instead of by weight, will have to do so manually by\nremoving transactions from their block template directly.\n\n\nGUI settings backed up on reset\n- -------------------------------\n\nThe GUI settings will now be written to `guisettings.ini.bak` in the data directory before wiping them when\nthe `-resetguisettings` argument is used. This can be used to retroactively troubleshoot issues due to the\nGUI settings.\n\n\nDuplicate wallets disallowed\n- ----------------------------\n\nPreviously, it was possible to open the same wallet twice by manually copying the wallet file, causing\nissues when both were opened simultaneously. It is no longer possible to open copies of the same wallet.\n\n\nDebug `-minimumchainwork` argument added\n- ----------------------------------------\n\nA hidden debug argument `-minimumchainwork` has been added to allow a custom minimum work value to be used\nwhen validating a chain.\n\n\nLow-level RPC changes\n- ----------------------\n\n- - The \"currentblocksize\" value in getmininginfo has been removed.\n\n- - `dumpwallet` no longer allows overwriting files. This is a security measure\n  as well as prevents dangerous user mistakes.\n\n- - `backupwallet` will now fail when attempting to backup to source file, rather than\n  destroying the wallet.\n\n- - `listsinceblock` will now throw an error if an unknown `blockhash` argument\n  value is passed, instead of returning a list of all wallet transactions since\n  the genesis block. The behaviour is unchanged when an empty string is provided.\n\n0.15.1 Change log\n=================\n\n### Mining\n- - #11100 `7871a7d` Fix confusing blockmax{size,weight} options, dont default to throwing away money (TheBlueMatt)\n\n### RPC and other APIs\n- - #10859 `2a5d099` gettxout: Slightly improve doc and tests (jtimon)\n- - #11267 `b1a6c94` update cli for estimate\\*fee argument rename (laanwj)\n- - #11483 `20cdc2b` Fix importmulti bug when importing an already imported key (pedrobranco)\n- - #9937 `a43be5b` Prevent `dumpwallet` from overwriting files (laanwj)\n- - #11465 `405e069` Update named args documentation for importprivkey (dusty-wil)\n- - #11131 `b278a43` Write authcookie atomically (laanwj)\n- - #11565 `7d4546f` Make listsinceblock refuse unknown block hash (ryanofsky)\n- - #11593 `8195cb0` Work-around an upstream libevent bug (theuni)\n\n### P2P protocol and network code\n- - #11397 `27e861a` Improve and document SOCKS code (laanwj)\n- - #11252 `0fe2a9a` When clearing addrman clear mapInfo and mapAddr (instagibbs)\n- - #11527 `a2bd86a` Remove my testnet DNS seed (schildbach)\n- - #10756 `0a5477c` net processing: swap out signals for an interface class (theuni)\n- - #11531 `55b7abf` Check that new headers are not a descendant of an invalid block (more effeciently) (TheBlueMatt)\n- - #11560 `49bf090` Connect to a new outbound peer if our tip is stale (sdaftuar)\n- - #11568 `fc966bb` Disconnect outbound peers on invalid chains (sdaftuar)\n- - #11578 `ec8dedf` Add missing lock in ProcessHeadersMessage(...) (practicalswift)\n- - #11456 `6f27965` Replace relevant services logic with a function suite (TheBlueMatt)\n- - #11490 `bf191a7` Disconnect from outbound peers with bad headers chains (sdaftuar)\n\n### Validation\n- - #10357 `da4908c` Allow setting nMinimumChainWork on command line (sdaftuar)\n- - #11458 `2df65ee` Don't process unrequested, low-work blocks (sdaftuar)\n\n### Build system\n- - #11440 `b6c0209` Fix validationinterface build on super old boost/clang (TheBlueMatt)\n- - #11530 `265bb21` Add share/rpcuser to dist. source code archive (MarcoFalke)\n\n### GUI\n- - #11334 `19d63e8` Remove custom fee radio group and remove nCustomFeeRadio setting (achow101)\n- - #11198 `7310f1f` Fix display of package name on 'open config file' tooltip (esotericnonsense)\n- - #11015 `6642558` Add delay before filtering transactions (lclc)\n- - #11338 `6a62c74` Backup former GUI settings on `-resetguisettings` (laanwj)\n- - #11335 `8d13b42` Replace save|restoreWindowGeometry with Qt functions (MeshCollider)\n- - #11237 `2e31b1d` Fixing division by zero in time remaining (MeshCollider)\n- - #11247 `47c02a8` Use IsMine to validate custom change address (MarcoFalke)\n\n### Wallet\n- - #11017 `9e8aae3` Close DB on error (kallewoof)\n- - #11225 `6b4d9f2` Update stored witness in AddToWallet (sdaftuar)\n- - #11126 `2cb720a` Acquire cs_main lock before cs_wallet during wallet initialization (ryanofsky)\n- - #11476 `9c8006d` Avoid opening copied wallet databases simultaneously (ryanofsky)\n- - #11492 `de7053f` Fix leak in CDB constructor (promag)\n- - #11376 `fd79ed6` Ensure backupwallet fails when attempting to backup to source file (tomasvdw)\n- - #11326 `d570aa4` Fix crash on shutdown with invalid wallet (MeshCollider)\n\n### Tests and QA\n- - #11399 `a825d4a` Fix bip68-sequence rpc test (jl2012)\n- - #11150 `847c75e` Add getmininginfo test (mess110)\n- - #11407 `806c78f` add functional test for mempoolreplacement command line arg (instagibbs)\n- - #11433 `e169349` Restore bitcoin-util-test py2 compatibility (MarcoFalke)\n- - #11308 `2e1ac70` zapwallettxes: Wait up to 3s for mempool reload (MarcoFalke)\n- - #10798 `716066d` test bitcoin-cli (jnewbery)\n- - #11443 `019c492` Allow \"make cov\" out-of-tree; Fix rpc mapping check (MarcoFalke)\n- - #11445 `51bad91` 0.15.1 Backports (MarcoFalke)\n- - #11319 `2f0b30a` Fix error introduced into p2p-segwit.py, and prevent future similar errors (sdaftuar)\n- - #10552 `e4605d9` Tests for zmqpubrawtx and zmqpubrawblock (achow101)\n- - #11067 `eeb24a3` TestNode: Add wait_until_stopped helper method (MarcoFalke)\n- - #11068 `5398f20` Move wait_until to util (MarcoFalke)\n- - #11125 `812c870` Add bitcoin-cli -stdin and -stdinrpcpass functional tests (promag)\n- - #11077 `1d80d1e` fix timeout issues from TestNode (jnewbery)\n- - #11078 `f1ced0d` Make p2p-leaktests.py more robust (jnewbery)\n- - #11210 `f3f7891` Stop test_bitcoin-qt touching ~/.bitcoin (MeshCollider)\n- - #11234 `f0b6795` Remove redundant testutil.cpp|h files (MeshCollider)\n- - #11215 `cef0319` fixups from set_test_params() (jnewbery)\n- - #11345 `f9cf7b5` Check connectivity before sending in assumevalid.py (jnewbery)\n- - #11091 `c276c1e` Increase initial RPC timeout to 60 seconds (laanwj)\n- - #10711 `fc2aa09` Introduce TestNode (jnewbery)\n- - #11230 `d8dd8e7` Fixup dbcrash interaction with add_nodes() (jnewbery)\n- - #11241 `4424176` Improve signmessages functional test (mess110)\n- - #11116 `2c4ff35` Unit tests for script/standard and IsMine functions (jimpo)\n- - #11422 `a36f332` Verify DBWrapper iterators are taking snapshots (TheBlueMatt)\n- - #11121 `bb5e7cb` TestNode tidyups (jnewbery)\n- - #11521 `ca0f3f7` travis: move back to the minimal image (theuni)\n- - #11538 `adbc9d1` Fix race condition failures in replace-by-fee.py, sendheaders.py (sdaftuar)\n- - #11472 `4108879` Make tmpdir option an absolute path, misc cleanup (MarcoFalke)\n- - #10853 `5b728c8` Fix RPC failure testing (again) (jnewbery)\n- - #11310 `b6468d3` Test listwallets RPC (mess110)\n\n### Miscellaneous\n- - #11377 `75997c3` Disallow uncompressed pubkeys in bitcoin-tx [multisig] output adds (TheBlueMatt)\n- - #11437 `dea3b87` [Docs] Update Windows build instructions for using WSL and Ubuntu 17.04 (fanquake)\n- - #11318 `8b61aee` Put back inadvertently removed copyright notices (gmaxwell)\n- - #11442 `cf18f42` [Docs] Update OpenBSD Build Instructions for OpenBSD 6.2 (fanquake)\n- - #10957 `50bd3f6` Avoid returning a BIP9Stats object with uninitialized values (practicalswift)\n- - #11539 `01223a0` [verify-commits] Allow revoked keys to expire (TheBlueMatt)\n\n\nCredits\n=======\n\nThanks to everyone who directly contributed to this release:\n\n- - Andreas Schildbach\n- - Andrew Chow\n- - Chris Moore\n- - Cory Fields\n- - Cristian Mircea Messel\n- - Daniel Edgecumbe\n- - Donal OConnor\n- - Dusty Williams\n- - fanquake\n- - Gregory Sanders\n- - Jim Posen\n- - John Newbery\n- - Johnson Lau\n- - Jo\u00e3o Barbosa\n- - Jorge Tim\u00f3n\n- - Karl-Johan Alm\n- - Lucas Betschart\n- - MarcoFalke\n- - Matt Corallo\n- - Paul Berg\n- - Pedro Branco\n- - Pieter Wuille\n- - practicalswift\n- - Russell Yanofsky\n- - Samuel Dobson\n- - Suhas Daftuar\n- - Tomas van der Wansem\n- - Wladimir J. van der Laan\n\nAs well as everyone that helped translating on [Transifex](https://www.transifex.com/projects/p/bitcoin/).\n\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v2\n\niQEcBAEBCgAGBQJaBwnSAAoJEB5K7WKYbNJdAhIIAL6y/9IM1cdvt6Wob9yDMawv\nit2iL5pS0HIWbcqXTfnf+52JMw9SNmTX356U8B9q9l6V8EiFKMN8y1wu/A921kKb\nn1BREmVKD0JtawK368LiFt9x0eYV3q0MTww9dOCPp5HoIEt8TTLGFIOwzAvscxNi\nIQMZRE5ejtm9Yjs0VHeKBrAXNA9zt8BKzmuwGi/JHoWda8nUnAhnaL/asAaYQ1zB\nIpqZHJo4k7GxxXUFIm1hiQkqT7uDZ5iehT706Su3qY7ATtaByPq8aHsPDEZFfUJO\nPoW7nqzCzkyTofIIE7+ejviBruL7EYFZiq+oUzOt4byGJvgaRyBXo8rn+druvEI=\n=8PAn\n-----END PGP SIGNATURE-----"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Core 0.15.1 released",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Wladimir J. van der Laan"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 14087
        }
    },
    {
        "title": "[bitcoin-dev] Intersection of file system work based on Mandelbrot with Bitcoin Block Chain.",
        "thread_messages": [
            {
                "author": "Vance Turner",
                "date": "2017-11-13T05:57:42",
                "message_text_only": "I have been working on filesystem based on Mandelbrots formula, and it seems\nthat it is a prime candidate for extending the bitcoin algorithm.\n\n \n\nWould like to run some of this by you folks. \n\n \n\nThe key is that the Mandelbrot workers could help to modify the verification\nwork so that the brute force work in the current hash.\n\n \n\nIt would allow the hash results to reign in the next iteration.\n\n \n\nAlso the hash results could help to build a fast lookup table of future\nvariations of the block chain.\n\n \n\n \n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171112/50b2924f/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Intersection of file system work based on Mandelbrot with Bitcoin Block Chain.",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Vance Turner"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 693
        }
    },
    {
        "title": "[bitcoin-dev] Updates on Confidential Transactions efficiency",
        "thread_messages": [
            {
                "author": "Gregory Maxwell",
                "date": "2017-11-14T01:21:14",
                "message_text_only": "Jump to \"New things here\" if you're already up to speed on CT and just\nwant the big news.\n\nBack in 2013 Adam Back proposed that Bitcoin and related systems could\nuse additive homomorphic commitments instead of explicit amounts in\nplace of values in transactions for improved privacy.     (\nhttps://bitcointalk.org/index.php?topic=305791.0 )\n\nWe've since adopted the name 'confidential transactions' for this\nparticular approach to transaction privacy.\n\nThis approach makes transaction amounts private--known only to the\nsender, the receiver, and whichever parties they choose to share the\ninformation with through sharing watching keys or through revealing\nsingle transactions. While that, combined with pseudonymous addresses,\nis a pretty nice privacy improvement in itself, it turns out that\nthese blinded commitments also perfectly complement CoinJoin (\nhttps://bitcointalk.org/index.php?topic=279249.0 ) by avoiding the\nissue of joins being decoded due to different amounts being used. Tim\nRuffing and Pedro Moreno-Sanchez went on to show that CJ can be\ndropped into distributed private protocols for CoinJoin (\nhttp://fc17.ifca.ai/bitcoin/papers/bitcoin17-final6.pdf ) which\nachieve the property where no participant learns which output\ncorresponds to which other participant.\n\nThe primary advantage of this approach is that it can be constructed\nwithout any substantial new cryptographic assumptions (e.g., only\ndiscrete log security in our existing curve), that it can be high\nperformance compared to alternatives, that it has no trusted setup,\nand that it doesn't involve the creation of any forever-growing\nunprunable accumulators.  All major alternative schemes fail multiple\nof these criteria (e.g., arguably Zcash's scheme fails every one of\nthem).\n\nI made an informal write-up that gives an overview of how CT works\nwithout assuming much crypto background:\nhttps://people.xiph.org/~greg/confidential_values.txt\n\nThe main sticking point with confidential transactions is that each\nconfidential output usually requires a witness which shows that the\noutput value is in range.  Prior to our work, the smallest range\nproofs without trusted setup for the 0-51 bit proofs needed for values\nin Bitcoin would take up 160 bytes per bit of range proved, or 8160\nbytes needed for 51 bits--something like a 60x increase in transaction\nsize for a typical transaction usage.\n\nI took Adam's suggestion and invented a number of new optimizations,\nand created a high performance implementation. (\nhttps://github.com/ElementsProject/secp256k1-zkp/tree/secp256k1-zkp/src/modules/rangeproof\n). With these optimizations the size is reduced to 128 bytes per two\nbits plus 32 bytes; about 40% of the prior size.  My approach also\nallowed a public exponent and minimum value so that you could use a\nsmaller range (e.g., 32 bits) and have it cover a useful range of\nvalues (though with a little privacy trade-off). The result could give\nproof sizes of about 2.5KB per output under realistic usage.  But this\nis still a 20x increase in transaction size under typical usage--\nthough some in the Bitcoin space seem to believe that 20x larger\nblocks would be no big deal, this isn't a view well supported by the\nevidence in my view.\n\nSubsequent work has been focused on reducing the range proof size further.\n\nIn our recent publication on confidential assets (\nhttps://blockstream.com/bitcoin17-final41.pdf ) we reduce the size to\n96*log3(2)*bits + 32, which still leaves us at ~16x size for typical\nusage. (The same optimizations support proofs whose soundness doesn't\neven depend on the discrete log assumption with the same size as the\noriginal CT publication).\n\n-- New things here --\n\nThe exciting recent update is that Benedikt B\u00fcnz at Standford was able\nto apply and optimize the inner product argument of Jonathan Bootle to\nachieve an aggregate range proof for CT with size 64 * (log2(bits *\nnum_outputs)) + 288, which is ~736 bytes for the 64-bit 2-output case.\n\nThis cuts the bloat factor down to ~3x for today's traffic patterns.\nSince the scaling of this approach is logarithmic with the number of\noutputs, use of CoinJoin can make the bloat factor arbitrarily small.\nE.g., combining 64 transactions still only results in a proof under\n1.1KB, so in that case the space overhead from the range proof is\nbasically negligible.\n\nThe log scaling in the number of range-bits also means that unlike the\nprior construction there is little reason to be skimpy with the number\nof bits of range at the potential expense of privacy: covering the\nfull range of possible values takes only slightly longer proofs than\ncovering a short range. This scheme also has a straightforward and\nefficient method for multi-party computation, which means that the\naggregates can be used in all-party-private coinjoins like the value\nshuffle work mentioned above.\n\nUnlike prior optimizations, verification in this new work requires\ncomputation which is more than linear in the size of the proof (the\nwork is linear in the size of the statement being proved).  So it's\nlikely that in spite of the small proofs the verification will be\nsimilar in speed to the prior version, and likely that computation\nwill be the bottleneck.  Andrew, Pieter, Jonas Nick, and I are working\non an optimized implementation based on libsecp256k1 so we'll know\nmore precise performance numbers soon.\n\nThis work also allows arbitrarily complex conditions to be proven in\nthe values, not just simple ranges, with proofs logarithmic in the\nsize of the arithmetic circuit representing the conditions being\nproved--and still with no trusted setup. As a result it potentially\nopens up many other interesting applications as well.\n\nThe pre-print on this new work is available at https://eprint.iacr.org/2017/1066"
            },
            {
                "author": "Peter Todd",
                "date": "2017-11-14T09:11:23",
                "message_text_only": "On Tue, Nov 14, 2017 at 01:21:14AM +0000, Gregory Maxwell via bitcoin-dev wrote:\n> Jump to \"New things here\" if you're already up to speed on CT and just\n> want the big news.\n\n<snip>\n\n> This work also allows arbitrarily complex conditions to be proven in\n> the values, not just simple ranges, with proofs logarithmic in the\n> size of the arithmetic circuit representing the conditions being\n> proved--and still with no trusted setup. As a result it potentially\n> opens up many other interesting applications as well.\n> \n> The pre-print on this new work is available at https://eprint.iacr.org/2017/1066\n\nRe: section 4.6, \"For cryptocurrencies, the binding property is more important\nthan the hiding property. An adversary that can break the binding property of\nthe commitment scheme or the soundness of the proof system can generate coins\nout of thin air and thus create uncontrolled but undetectable inflation\nrendering the currency useless.  Giving up the privacy of a transaction is much\nless harmful as the sender of the transaction or the owner of an account is\nharmed at worst.\"\n\nI _strongly_ disagree with this statement and urge you to remove it from the\npaper.\n\nThe worst-case risk of undetected inflation leading to the destruction of a\ncurrency is an easily quantified risk: at worst any given participant loses\nwhatever they have invested in that currency. While unfortunate, this isn't a\nunique or unexpected risk: cryptocurrencies regularly lose 50% - or even 90% -\nof their value due to fickle markets alone. But cryptocurrency owners shrug\nthese risks off. After all, it's just money, and diversification is an easy way\nto mitigate that risk.\n\nBut a privacy break? For many users _that_ threatens their very freedom,\nsomething that's difficult to even put a price on.\n\nFurthermore, the risk of inflation is a risk that's easily avoided: at a\npersonal level, sell your holdings in exchange for a less risky system; at a\nsystem-wide level, upgrade the crypto.\n\nBut a privacy leak? Once I publish a transaction to the world, there's no easy\nway to undo that act. I've committed myself to trusting the crypto\nindefinitely, without even a sure knowledge of what kind of world I'll live in\nten years down the road. Sure, my donation to Planned Parenthood or the NRA\nmight be legal now, but will it come back to haunt me in ten years?\n\n\nFortunately, as section 4.6 goes on to note, Bulletproofs *are* perfectly\nhiding. But that's a feature we should celebrate! The fact that quantum\ncomputing may force us to give up that essential privacy is just another\nexample of quantum computing ruining everything, nothing more.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171114/8a02b949/attachment.sig>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2017-11-14T10:38:33",
                "message_text_only": "On Tue, Nov 14, 2017 at 9:11 AM, Peter Todd <pete at petertodd.org> wrote:\n> I _strongly_ disagree with this statement and urge you to remove it from the\n> paper.\n\nI very strongly disagree with your strong disagreement.\n\n> The worst-case risk of undetected inflation leading to the destruction of a\n> currency is an easily quantified risk: at worst any given participant loses\n> whatever they have invested in that currency. While unfortunate, this isn't a\n> unique or unexpected risk: cryptocurrencies regularly lose 50% - or even 90% -\n> of their value due to fickle markets alone. But cryptocurrency owners shrug\n> these risks off. After all, it's just money, and diversification is an easy way\n> to mitigate that risk.\n>\n> But a privacy break? For many users _that_ threatens their very freedom,\n> something that's difficult to even put a price on.\n\nIts important that people know and understand what properties a system has.\n\nPerhaps one distinction you miss is that perfectly hiding systems\ndon't even exist in practice: I would take a bet that no software on\nyour system that you can use with other people actually implements a\nperfectly hiding protocol (much less find on most other people's\nsystem system :)).\n\nIn the case of practical use with CT perfect hiding is destroyed by\nscalability-- the obvious construction is a stealth address like one\nwhere a DH public key is in the address and that is used to scan for\nyour payments against a nonce pubkey in the transactions.   The\nexistence of that mechanism destroys perfect hiding.  No scheme that\ncan be scanned using an asymmetric key is going to provide perfect\nhiding.\n\nNow, perhaps what you'd like is a system which is not perfect hiding\nbut where the hiding rests on less \"risky\" assumptions.  That is\nsomething that can plausibly be constructed, but it's not itself\nincompatible with unconditional soundness.\n\nAs referenced in the paper, there is also the possibility of having a\nyour cake and eating it too-- switch commitments for example allow\nhaving computational-hiding-depending-on-the-hardness-of-inverting-hashes\n (which I would argue is functionally as good as perfect hiding, esp\nsince hiding is ultimately limited by the asymmetric crypto used for\ndiscovery)  and yet it retains an option to upgrade or block spending\nvia unsound mechanisms in the event of a crypto break.\n\n> Furthermore, the risk of inflation is a risk that's easily avoided:\n\nSounds like you are assuming that you know when there is a problem, if\nyou do then the switch commitments scheme works and doesn't require\nany selling of anything. Selling also has the problem that everyone\nwould want to do it at once if there was a concern; this would not\nhave good effects. :) Without switch commitments though, you are just\nhosed.  And you cannot have something like switch commitments without\nabandoning perfect hiding ( though you get hiding which is good enough\n(tm), as mentioned above).\n\nOn Tue, Nov 14, 2017 at 10:07 AM, Peter Todd <pete at petertodd.org> wrote:\n> Re: the unprunable accumulators, that doesn't need to be an inherent property\n> of Zcash/Monero style systems.\n>\n> It'd be quite feasible to use accumulator epochs and either make unspent coins\n> in a previous epoch unspendable after some expiry time is reached - allowing\n\nMiners to reduce coin supply, enhancing the value of their own\nholdings, by simply not letting near-expiry ones get spent...\n(This can be partially mediated by constructing proofs to hide if a\ncoins in near expiration or not.)\n\n> or make use of a merkelized key-value scheme with transaction provided proofs to shift the costs of\n> maintaining the accumulator to wallets.\n\nYes, that they can do-- though with the trade-offs inherent in that.\nIt is worse than what you were imagining in the Bitcoin case because\nyou cannot use one or two time-ordered trees, the spent coins list\nneeds search-insertion; so maintaining it over time is harder. :(  The\nsingle time ordered tree trick doesn't work because you can't mutate\nthe entries without blowing anonymity.\n\nI think it's still fair to say that ring-in and tree-in approaches\n(monero, and zcash) are fundamentally less scalable than\nCT+valueshuffle, but more private-- though given observations of Zcash\nbehavior perhaps not that much more private.  With the right smart\ntricks the scalablity loss might be more inconvenient than fatal, but\nthey're still a loss even if they're one that makes for a good\ntradeoff.\n\nAs an aside, you shouldn't see Monero as entirely distinct now that\nwe're talking about a framework which is fully general:  Extending\nthis to a traceable 1 of N input for monero is simple-- and will add\nsize log() in the number of ring inputs with good constant factors.\nOne could also store inputs in a hash tree, and then have a\nbulletproof that verified membership in the tree.  This would provide\ntree-in style transactions with proofs that grow with the log() of the\nsize of the tree (and a spent coins accumulator); the challenge there\nwould be choosing a hash function that had a compact representation in\nthe arithmetic circuit so that the constant factors aren't terrible.\nEffectively that's what bulletproofs does:   It takes a general scheme\nfor ZKP of arbitrary computation, which could implement a range proof\nby opening the commitments (e.g. a circuit for EC point scalar\nmultiply) and checking the value, and optimizes it to handle the\ncommitments more directly. If you're free to choose the hash function\nthere may be a way to make a hash tree check ultra efficient inside\nthe proof, in which case this work could implement a tree-in scheme\nlike zcash-- but with larger proofs and slower verification in\nexchange for much better crypto assumptions and no trusted setup.\nThis is part of what I meant by it opening up \"many other interesting\napplications\".\n\nBut as above, I think that the interactive-sparse-in (CJ) has its own\nattractiveness, even though it is not the strongest for privacy."
            },
            {
                "author": "Gregory Maxwell",
                "date": "2017-11-14T10:51:13",
                "message_text_only": "On Tue, Nov 14, 2017 at 10:38 AM, Gregory Maxwell <greg at xiph.org> wrote:\n> I think it's still fair to say that ring-in and tree-in approaches\n> (monero, and zcash) are fundamentally less scalable than\n> CT+valueshuffle, but more private-- though given observations of Zcash\n\nWhile I'm enumerating private transaction topologies there is fourth\none I'm aware of (most closely related to ring-in):\n\ntake N inputs,  write >= N outputs,  where some coins are spent and\nreplaced with a new output, or an encrypted dummy... and other coins\nare simply reencrypted in a way that their owner can still decode.\nProvide a proof that shows you did this faithfully. So this one avoids\nthe spent coins list by being able to malleiate the inputs.\n\nWe never previously found an efficient way to construct that one in a\nplain DL setting, but it's probably possible w/ bulletproofs, at least\nfor some definition of efficient."
            },
            {
                "author": "Peter Todd",
                "date": "2017-11-14T10:07:28",
                "message_text_only": "On Tue, Nov 14, 2017 at 01:21:14AM +0000, Gregory Maxwell via bitcoin-dev wrote:\n> The primary advantage of this approach is that it can be constructed\n> without any substantial new cryptographic assumptions (e.g., only\n> discrete log security in our existing curve), that it can be high\n> performance compared to alternatives, that it has no trusted setup,\n> and that it doesn't involve the creation of any forever-growing\n> unprunable accumulators.  All major alternative schemes fail multiple\n> of these criteria (e.g., arguably Zcash's scheme fails every one of\n> them).\n\nRe: the unprunable accumulators, that doesn't need to be an inherent property\nof Zcash/Monero style systems.\n\nIt'd be quite feasible to use accumulator epochs and either make unspent coins\nin a previous epoch unspendable after some expiry time is reached - allowing\nthe spent coin accumulator data to be discarded - or make use of a merkelized\nkey-value scheme with transaction provided proofs to shift the costs of\nmaintaining the accumulator to wallets.\n\nThe disadvantage of epoch schemes is of course a reduced k-anonymity set, but\nif I understand the Confidential Transactions proposals correctly, they already\nhave a significantly reduced k-anonymity set per transaction than Zcash\ntheoretically could (modulo it's in practice low anonymity set due to lack of\nactual usage). In that respect, epoch size is simply a tradeoff between state\nsize and k-anonymity set size.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171114/cef7d4fb/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Updates on Confidential Transactions efficiency",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Gregory Maxwell",
                "Peter Todd"
            ],
            "messages_count": 5,
            "total_messages_chars_count": 17358
        }
    },
    {
        "title": "[bitcoin-dev] Con-peg sidechain model",
        "thread_messages": [
            {
                "author": "creighto at sdf.org",
                "date": "2017-11-15T02:13:31",
                "message_text_only": "I posted the following on bitcointalk.org and slack bitcoinunlimited. \nThis isn't a technical paper, just fleshing out my thoughts and hoping for\nsome help & feedback.  I understand bitcoin as well as any non-programer\nrealisticly could, but I am not a programmer, so if this isn't feasible,\nsomeone please let me know why.\n\n-MoonShadow\n\nCon-Peg Sidechain Model\n\nI know that this is going to sound similar to the Fed-Peg model, so don't\nwhine about that. It's not the Fed-Peg model, not quite, and the\ndifferences are critical, I believe.\n\nEvery proposal that I've seen so far require some kind of soft or hard\nfork to the current bitcoin model, but I think that I've come up with a\nway to make a sidechain work without new modifications to the running\nbitcoin protocol.\n\nI think I will call it the Confederation-Peg model.\n\nImagine a confederation of large corporations, all of which would benefit\nfrom the ability to process a large number of bitcoin transactions for net\nzero or near zero transaction fees.\nThese corporations would, most likely, have to have the following\ncharacteristics...\n\n1) Multi-national in scope, with employee bases in several different\nnations using several different fiat currencies.\n2) Have a rather large employee base.\n3) Not in direct competition with each other\n4) and not dependent upon any particular government.\nWith just a bit of google-fu, I will use the following corporations in\nthis example...\n\nWal-Mart, with more than 2 million employees worldwide.\nVolkswagon, with more than half a million employees worldwide.\nGeneral Electric, with about 300K employees worldwide.\nand Johnson & Johnson, with More than 100K.\n\nLet's call these corporations the confederation sponsors. These sponsors\nwould decide most of the sidechain's rules by consensus amongst\nthemselves, but let me lay out, in general, how I think that such a\nsidechain can be set up so that the sidechain is secure while also\ncontributing to the overall security of the main blockchain.\n\nFirst, these sponsors agree upon a deposit/escrow amount that they will\neach commit to a multi-sig address on the main blockchain; for a round\nnumber, let's say they all contribute 10 BTC to the cause. Next, they all\nagree that they must each either build or contract out bitcoin mining\ncapability of a minimum standard; high enough that the collection of\nsponsors can mine a block on a regular interval. Let's say once each day.\nBut when they mine a main blockchain block, they place into the 100 byte\nlarge \"2nd nonce\" space of the coinbase transaction the following data.\n\n1) a code that identifies the sponsor who mined this block to the other\nsponsors,\n2) the merkle tree root hash of the sidechain block that the sponsor is\nabout to release on the sidechain network.\n3) a cryptographic signing of the two prior pieces of data. (this might be\nunnecessary, I'm not sure)\n\nOnce a sponsor's mining agent releases this block to the network, and it's\naccepted as valid by the main blockchain, The sponsor then releases the\nsidechain block to the other sponsors. This block can be of an arbitrarily\nlarge size; enough to accommodate all of the transactions that all of the\nsponsors (and their clients) have produced in the past day. Since it's\nlikely that every sponsor has seen every valid transaction, this block\nmight only include the merkle tree created by the most recent mining\nsponsor.\n\nThis looks a lot like merged mining, but it's not, because the side chain\ndoesn't use proof-of-work, and doesn't require it. It uses\nproof-of-authority. Specifically, releasing a valid block onto the main\nblockchain is the proof of the authority to release the next sidechain\nblock. This achieves several things for the sponsors.\n\n1) It contributes mining power to the main blockchain, thus supporting\nmain chain security regardless of the profitability for those sponsor\nminers, since their incentive is to reduce the costs of their own\ntransactions, not win mining rewards or fees.\n2) It creates a definate timeline of the blockchain of the sidechain,\nwithout need for cryptographic proof-of-work, by tying each sidechain\nblock to a known main chain block. Thus leveraging the main chain's\nsecurity model without needing to attract miners willing to drop the main\nchain work to mine the sidechain.\n3) It establishes a definitive authority amonst the sponsors about who has\nthe right to publish the next block, as well as claim any sidechain\ntransaction fees.\n4) It allows all sponsors to keep each other honest, because if any\nsponsor were to cut back on their main chain mining responsibilities, they\nwould all be able to tell.\n5) It allows the sponsors to chose to accept as many free transactions as\nthey like, which may or may not benefit themselves,\n6) as well as keep any transaction fees that might have been issued on the\nsidechain, for which odds are high that they would have had to pay. Thus\ntransaction fees most likely travel in a circle (for the sponsors, not the\nclients)\n\nIn order to add btc to this sidechain, a main chain bitcoiner would have\nto send funds to one of the sponsors, after acquiring their agreement to\nissue sidechain coins using a special sidechain coinbase transaction\nthat...\n\n1) creates or destroys sidechain bitcoins\n2) references the main chain transaction that would permit it\n3) and identifies the sponsor creating the sidechain funds\n\nIn this way, bitcoins can flow into the sidechain, and each of the\nsponsors can watch the other sponsors to make certain that they aren't\ncreating more sidechain funds than their main chain holding would permit.\nI would imagine that the rule would be that a sponsor can't issue more\nside chain bitcoins than it has in it's public main chain addresses, and\nif that were to be violated, the other sponsors would automatically ignore\ntheir (otherwise valid) sidechain blocks.\n\nThis security model requires more trust than the trustless model of the\nmain blockchain, but permits the sidechain to structure itself in any way\nnecessary to permit safe referencing of unconfirmed transactions, thereby\npermitting nearly instant follow-up transactions. Sponsors could also\ndetect, and potentially punish, double spend attemps. Any other rapid\ntransaction model, such as the Lightening Network, could be permitted to\nwork on the sidechain; but I doubt they would be necessary.\nSponsors could attract \"clients\" by a number of incentives. For example,\nWal-mart could offer free sidechain transactions to any paying customer,\nas well as a limited number of main chain transactions to their own\nemployees; whereas Johnson & Johnson might only offer free transactions to\ntheir employees and associated businesses. I can even imagine a deposit &\n(fully BTC reserve backed) sidechain credit system, complete with interest\nrates.\n\nPaid for transaction fees could be based upon whatever the sponsors agree\nto, including a transaction fee based upon a percentage of the transfer\nvalue instead of the byte-size of a transaction. This would make the fee\nmodel much closer to how current day credit card transfer fees work, but\nwould almost certainly be less.\n\nGetting BTC back out of the sidechain (via the main chain) would work like\na sponsor's coinbase transaction with a negative value, also referencing a\nvalid transaction (which may or may not be confirmed yet) that can be seen\non the main bitcoin network. Alternatively, in a world where several such\nsidechains exist, sponsors of one sidechain could be clients on another,\npotentially permitting value to transfer from one sidechain directly to\nanother without creating a main blockchain transaction at all. The details\nof the rules of both sidechains would matter in this possibility.\n\nSince declaring weeknesses of one's own ideas is a convention in the\ncryptocurrency world, let me begin...\n\nSince this is a some-trust model; i.e. individuals have to trust an\ninstitution, at least a little bit, in order to get onto the sidechain.\nIt's possible that a sponsor might take your main chain BTC and claim you\nnever sent them, but you'd still have the transaction you produced, so\nyou'd still have recourse through traditional courts.\n\nMoving funds in the other direction, it's possible for your leaving\ntransaction to be blocked, but only if all of the sponsors refuse to deal\nwith you. Likewise, as a client, your ability to transact on the sidechain\ncould be hindered or blocked by the sponsors, but only if all of them\nblacklist you. But that only risks the possibility that you can't spend\nyour bitcoins on the sidechain, not that the sponsors could take them from\nyou without your participation.\n\nThis is a move towards some centralization, yes; but not for bitcoin as a\nwhole. For the most part, \"clients\" choose whether the lower transaction\ncosts & convenience at these institutions is worth the re-addition of\ntrust to some portion of their bitcoin activities. Perhaps employees don't\nget a choice about being a client on this sidechain, but they still get to\nchoose if they work for a sponsor.\n\nThis low-trust model depends upon the idea that the sponsors don't\nentirely trust one another, and will keep an eye on each other for bad\nbehavior; much in the same way that the banks of the free banking era\nwould occasionally challenge one another to produce the gold for the\ncurrencies they issued, either driving them out of business or harming\ntheir businesses should they misbehave. It also depends upon the idea\nthat, for the \"clients\", no one on the sidechain has more to lose from\ngetting caught defrauding a client than the sponsors themselves, because\nthe integrity of the sidechain and of their own reputations are of great\nvalue to the sponsors. It's possible that all sponsors turn to the dark\nside at once, crash the sidechain & steal all of the main chain bitcoins\nin their reserve addresses. Since this isn't one trusted authority, but\nmany in a trust-distrust relationship (and in different industries) this\npossibility seems remote to me.\n\nI could also imagine sidechains that were explicitly not worldwide in\nscope, such as those limited to a particular nation or economic block.\n\nI.E., there might be a Eurozone specific sidechain, a United States\nspecific sidechain (but would that be redundant?) and a Francophone\nsidechain. There might be a sidechain for Portuguese speaking nations\naround the world, or a sidechain just for nations in South America that\ndon't speak Portuguese.\n\nThere could be a sidechain that exists entirely on Tor, using high\nanonymity rules; or a sidechain sponsored by governments for the expressed\npurpose of paying taxes (but who would join this voluntarily?)\n\nMany people have complained that Bitcoin isn't anonymous, because the\nentire transaction history is visible. Sidechains would fix that\nimmediately, even without improved anonymity rules.\n\nFor that matter, since the extra-nonce space available in the coinbase\ntransaction is 100 bytes, that's enough to record an entire sidechain\nblock header anyway, so there might not be any reason to record the\nheaders anyplace else."
            }
        ],
        "thread_summary": {
            "title": "Con-peg sidechain model",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "creighto at sdf.org"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 11032
        }
    },
    {
        "title": "[bitcoin-dev] Making OP_CODESEPARATOR and FindAndDelete in non-segwit scripts non-standard",
        "thread_messages": [
            {
                "author": "Johnson Lau",
                "date": "2017-11-15T18:02:48",
                "message_text_only": "In https://github.com/bitcoin/bitcoin/pull/11423 <https://github.com/bitcoin/bitcoin/pull/11423> I propose to make OP_CODESEPARATOR and FindAndDelete in non-segwit scripts non-standard\n\nI think FindAndDelete() is one of the most useless and complicated functions in the script language. It is omitted from segwit (BIP143), but we still need to support it in non-segwit scripts. Actually, FindAndDelete() would only be triggered in some weird edge cases like using out-of-range SIGHASH_SINGLE.\n\nNon-segwit scripts also use a FindAndDelete()-like function to remove OP_CODESEPARATOR from scriptCode. Note that in BIP143, only executed OP_CODESEPARATOR are removed so it doesn\u2019t have the FindAndDelete()-like function. OP_CODESEPARATOR in segwit scripts are useful for Tumblebit so it is not disabled in this proposal\n\nBy disabling both, it guarantees that scriptCode serialized inside SignatureHash() must be constant\n\nIf we use a softfork to remove FindAndDelete() and OP_CODESEPARATOR from non-segwit scripts, we could completely remove FindAndDelete() from the consensus code later by whitelisting all blocks before the softfork block. The first step is to make them non-standard in the next release.\n\n\n \n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171116/2af44e77/attachment.html>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-11-15T19:54:17",
                "message_text_only": "As good of an idea as it may or may not be to remove this feature from the code base, actually doing so would be crossing a boundary that we have not previously been willing to do except under extraordinary duress. The nature of bitcoin is such that we do not know and cannot know what transactions exist out there pre-signed and making use of these features.\n\nIt may be a good idea to make these features non standard to further discourage their use, but I object to doing so with the justification of eventually disabling them for all transactions. Taking that step has the potential of destroying value and is something that we have only done in the past either because we didn\u2019t understand forks and best practices very well, or because the features (now disabled) were fundamentally insecure and resulted in other people\u2019s coins being vulnerable. This latter concern does not apply here as far as I\u2019m aware.\n\n> On Nov 15, 2017, at 8:02 AM, Johnson Lau via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> In https://github.com/bitcoin/bitcoin/pull/11423 I propose to make OP_CODESEPARATOR and FindAndDelete in non-segwit scripts non-standard\n> \n> I think FindAndDelete() is one of the most useless and complicated functions in the script language. It is omitted from segwit (BIP143), but we still need to support it in non-segwit scripts. Actually, FindAndDelete() would only be triggered in some weird edge cases like using out-of-range SIGHASH_SINGLE.\n> \n> Non-segwit scripts also use a FindAndDelete()-like function to remove OP_CODESEPARATOR from scriptCode. Note that in BIP143, only executed OP_CODESEPARATOR are removed so it doesn\u2019t have the FindAndDelete()-like function. OP_CODESEPARATOR in segwit scripts are useful for Tumblebit so it is not disabled in this proposal\n> \n> By disabling both, it guarantees that scriptCode serialized inside SignatureHash() must be constant\n> \n> If we use a softfork to remove FindAndDelete() and OP_CODESEPARATOR from non-segwit scripts, we could completely remove FindAndDelete() from the consensus code later by whitelisting all blocks before the softfork block. The first step is to make them non-standard in the next release.\n> \n> \n>  \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171115/04190c4f/attachment.html>"
            },
            {
                "author": "Sjors Provoost",
                "date": "2017-11-16T09:27:18",
                "message_text_only": "Can you clarify what you mean by \"whitelisting all blocks before the softfork block\"?\n\nThe most conservative approach could be to leave the code in place until the very last non-segwit P2SH UTXO from before the soft fork block has been spent. But this would never happen if even a single private key is lost.\n\nAfter making these transactions non-standard and removing the code, transactions containing these OP-codes could be considered valid (perhaps still checking the signature, etc). Some miners would still run the code and mine those transactions, but others wouldn't verify them. This is strictly less bad than losing those funds forever, but doesn't seem acceptable either.\n\nIs there a variant of the above scenario where a miner puts up some very large deposit (e.g. 10x the size of the UTXO) if they mine such a legacy transaction, and can lose that if someone else runs the code and finds the transaction invalid?\n\nSjors\n\n> Op 15 nov. 2017, om 20:54 heeft Mark Friedenbach via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> het volgende geschreven:\n> \n> As good of an idea as it may or may not be to remove this feature from the code base, actually doing so would be crossing a boundary that we have not previously been willing to do except under extraordinary duress. The nature of bitcoin is such that we do not know and cannot know what transactions exist out there pre-signed and making use of these features.\n> \n> It may be a good idea to make these features non standard to further discourage their use, but I object to doing so with the justification of eventually disabling them for all transactions. Taking that step has the potential of destroying value and is something that we have only done in the past either because we didn\u2019t understand forks and best practices very well, or because the features (now disabled) were fundamentally insecure and resulted in other people\u2019s coins being vulnerable. This latter concern does not apply here as far as I\u2019m aware.\n> \n> On Nov 15, 2017, at 8:02 AM, Johnson Lau via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> \n>> In https://github.com/bitcoin/bitcoin/pull/11423 <https://github.com/bitcoin/bitcoin/pull/11423> I propose to make OP_CODESEPARATOR and FindAndDelete in non-segwit scripts non-standard\n>> \n>> I think FindAndDelete() is one of the most useless and complicated functions in the script language. It is omitted from segwit (BIP143), but we still need to support it in non-segwit scripts. Actually, FindAndDelete() would only be triggered in some weird edge cases like using out-of-range SIGHASH_SINGLE.\n>> \n>> Non-segwit scripts also use a FindAndDelete()-like function to remove OP_CODESEPARATOR from scriptCode. Note that in BIP143, only executed OP_CODESEPARATOR are removed so it doesn\u2019t have the FindAndDelete()-like function. OP_CODESEPARATOR in segwit scripts are useful for Tumblebit so it is not disabled in this proposal\n>> \n>> By disabling both, it guarantees that scriptCode serialized inside SignatureHash() must be constant\n>> \n>> If we use a softfork to remove FindAndDelete() and OP_CODESEPARATOR from non-segwit scripts, we could completely remove FindAndDelete() from the consensus code later by whitelisting all blocks before the softfork block. The first step is to make them non-standard in the next release.\n>> \n>> \n>> \n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171116/c69edb2d/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171116/c69edb2d/attachment.sig>"
            },
            {
                "author": "Matt Corallo",
                "date": "2017-11-27T16:33:07",
                "message_text_only": "I strongly disagree here - we don't only soft-fork out transactions that\nare \"fundamentally insecure\", that would be significantly too\nrestrictive. We have generally been willing to soft-fork out things\nwhich clearly fall outside of best-practices, especially rather\n\"useless\" fields in the protocol eg soft-forking behavior into OP_NOPs,\nsoft-forking behavior into nSequence, etc.\n\nAs a part of setting clear best-practices, making things non-standard is\nthe obvious step, though there has been active discussion of\nsoft-forking out FindAndDelete and OP_CODESEPARATOR for years now. I\nobviously do not claim that we should be proposing a soft-fork to\nblacklist FindAndDelete and OP_CODESEPARATOR usage any time soon, and\nassume that it would take at least a year or three from when it was made\nnon-standard to when a soft-fork to finally remove them was proposed.\nThis should be more than sufficient time for folks using such weird (and\nlargely useless) parts of the protocol to object, which should be\nsufficient to reconsider such a soft-fork.\n\nIndependently, making them non-standard is a good change on its own, and\nif nothing else should better inform discussion about the possibility of\nanyone using these things.\n\nMatt\n\nOn 11/15/17 14:54, Mark Friedenbach via bitcoin-dev wrote:\n> As good of an idea as it may or may not be to remove this feature from\n> the code base, actually doing so\u00a0would be crossing a boundary that we\n> have not previously been willing to do except under extraordinary\n> duress. The nature of bitcoin is such that we do not know and cannot\n> know what transactions exist out there pre-signed and making use of\n> these features.\n> \n> It may be a good idea to make these features non standard to further\n> discourage their use, but I object to doing so with the justification of\n> eventually disabling them for all transactions. Taking that step has the\n> potential of destroying value and is something that we have only done in\n> the past either because we didn\u2019t understand forks and best practices\n> very well, or because the features (now disabled) were fundamentally\n> insecure and resulted in other people\u2019s coins being vulnerable. This\n> latter concern does not apply here as far as I\u2019m aware.\n> \n> On Nov 15, 2017, at 8:02 AM, Johnson Lau via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org\n> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> \n>> In\u00a0https://github.com/bitcoin/bitcoin/pull/11423\u00a0I propose to\n>> make\u00a0OP_CODESEPARATOR and FindAndDelete in non-segwit scripts non-standard\n>>\n>> I think FindAndDelete() is one of the most useless and complicated\n>> functions in the script language. It is omitted from segwit (BIP143),\n>> but we still need to support it in non-segwit scripts. Actually,\n>> FindAndDelete() would only be triggered in some weird edge cases like\n>> using out-of-range SIGHASH_SINGLE.\n>>\n>> Non-segwit scripts also use a FindAndDelete()-like function to remove\n>> OP_CODESEPARATOR from scriptCode. Note that in BIP143, only executed\n>> OP_CODESEPARATOR are removed so it doesn\u2019t have the\n>> FindAndDelete()-like function. OP_CODESEPARATOR in segwit scripts are\n>> useful for Tumblebit so it is not disabled in this proposal\n>>\n>> By disabling both, it guarantees that scriptCode serialized inside\n>> SignatureHash() must be constant\n>>\n>> If we use a softfork to remove FindAndDelete() and OP_CODESEPARATOR\n>> from non-segwit scripts, we could completely remove FindAndDelete()\n>> from the consensus code later by whitelisting all blocks before the\n>> softfork block. The first step is to make them non-standard in the\n>> next release.\n>>\n>>\n>> \u00a0\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Mark Friedenbach",
                "date": "2017-11-27T21:06:35",
                "message_text_only": "It is relevant to note that BIP 117 makes an insecure form of CODESEPARATOR delegation possible, which could be made secure if some sort of CHECKSIGFROMSTACK opcode is added at a later point in time. It is not IMHO a very elegant way to achieve delegation, however, so I hope that one way or another this could be resolved quickly so it doesn\u2019t hold up either one of those valuable additions.\n\nI have no objections to making them nonstandard, or even to make them invalid if someone with a better grasp of history can attest that CODESEPARATOR was known to be entirely useless before the introduction of P2SH\u2014not the same as saying it was useless, but that it was widely known to not accomplish what a early-days script author might think it was doing\u2014and the UTXO set contains no scriptPubKeys making use of the opcode, even from the early days. Although a small handful could be special cased, if they exist.\n\n> On Nov 27, 2017, at 8:33 AM, Matt Corallo <lf-lists at mattcorallo.com> wrote:\n> \n> I strongly disagree here - we don't only soft-fork out transactions that\n> are \"fundamentally insecure\", that would be significantly too\n> restrictive. We have generally been willing to soft-fork out things\n> which clearly fall outside of best-practices, especially rather\n> \"useless\" fields in the protocol eg soft-forking behavior into OP_NOPs,\n> soft-forking behavior into nSequence, etc.\n> \n> As a part of setting clear best-practices, making things non-standard is\n> the obvious step, though there has been active discussion of\n> soft-forking out FindAndDelete and OP_CODESEPARATOR for years now. I\n> obviously do not claim that we should be proposing a soft-fork to\n> blacklist FindAndDelete and OP_CODESEPARATOR usage any time soon, and\n> assume that it would take at least a year or three from when it was made\n> non-standard to when a soft-fork to finally remove them was proposed.\n> This should be more than sufficient time for folks using such weird (and\n> largely useless) parts of the protocol to object, which should be\n> sufficient to reconsider such a soft-fork.\n> \n> Independently, making them non-standard is a good change on its own, and\n> if nothing else should better inform discussion about the possibility of\n> anyone using these things.\n> \n> Matt\n> \n> On 11/15/17 14:54, Mark Friedenbach via bitcoin-dev wrote:\n>> As good of an idea as it may or may not be to remove this feature from\n>> the code base, actually doing so would be crossing a boundary that we\n>> have not previously been willing to do except under extraordinary\n>> duress. The nature of bitcoin is such that we do not know and cannot\n>> know what transactions exist out there pre-signed and making use of\n>> these features.\n>> \n>> It may be a good idea to make these features non standard to further\n>> discourage their use, but I object to doing so with the justification of\n>> eventually disabling them for all transactions. Taking that step has the\n>> potential of destroying value and is something that we have only done in\n>> the past either because we didn\u2019t understand forks and best practices\n>> very well, or because the features (now disabled) were fundamentally\n>> insecure and resulted in other people\u2019s coins being vulnerable. This\n>> latter concern does not apply here as far as I\u2019m aware.\n>> \n>> On Nov 15, 2017, at 8:02 AM, Johnson Lau via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org\n>> <mailto:bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>>> wrote:\n>> \n>>> In https://github.com/bitcoin/bitcoin/pull/11423 I propose to\n>>> make OP_CODESEPARATOR and FindAndDelete in non-segwit scripts non-standard\n>>> \n>>> I think FindAndDelete() is one of the most useless and complicated\n>>> functions in the script language. It is omitted from segwit (BIP143),\n>>> but we still need to support it in non-segwit scripts. Actually,\n>>> FindAndDelete() would only be triggered in some weird edge cases like\n>>> using out-of-range SIGHASH_SINGLE.\n>>> \n>>> Non-segwit scripts also use a FindAndDelete()-like function to remove\n>>> OP_CODESEPARATOR from scriptCode. Note that in BIP143, only executed\n>>> OP_CODESEPARATOR are removed so it doesn\u2019t have the\n>>> FindAndDelete()-like function. OP_CODESEPARATOR in segwit scripts are\n>>> useful for Tumblebit so it is not disabled in this proposal\n>>> \n>>> By disabling both, it guarantees that scriptCode serialized inside\n>>> SignatureHash() must be constant\n>>> \n>>> If we use a softfork to remove FindAndDelete() and OP_CODESEPARATOR\n>>> from non-segwit scripts, we could completely remove FindAndDelete()\n>>> from the consensus code later by whitelisting all blocks before the\n>>> softfork block. The first step is to make them non-standard in the\n>>> next release.\n>>> \n>>> \n>>>  \n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>> <mailto:bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>>\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>> \n>> \n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171127/8b6a2008/attachment-0001.html>"
            },
            {
                "author": "Matt Corallo",
                "date": "2017-11-27T21:33:37",
                "message_text_only": "Indeed, the PR in question does *not* change the semantics of\nOP_CODESEPARATOR within SegWit redeemScripts, where it is still allowed\n(and Nicolas Dorier pointed out that he was using it in TumbleBit), so\nthere are still ways to use it, but only in places, like SegWit, where\nthe potential validation complexity blowup is massively reduced.\n\nI am not sure that OP_CODESEPARATOR is entirely useless in pre-SegWit\nscripts (I believe Nicolas' construction may still be relevant\npre-SegWit), though I strongly believe FindAndDelete is.\n\nI don't think CODESEPARATOR rises to the threshold of it being \"widely\nknown to be useless\", but certainly the historical use of it (to\nseparate the scriptSig and the scriptPubKey in the scriptCode, which was\nrun as a single concatenated thing in the original design is no longer\nrelevant). FindAndDelete is equally irrelevant if not significantly more\nirrelevant.\n\nMatt\n\nOn 11/27/17 16:06, Mark Friedenbach wrote:\n> It is relevant to note that BIP 117 makes an insecure form of\n> CODESEPARATOR delegation possible, which could be made secure if some\n> sort of CHECKSIGFROMSTACK opcode is added at a later point in time. It\n> is not IMHO a very elegant way to achieve delegation, however, so I hope\n> that one way or another this could be resolved quickly so it doesn\u2019t\n> hold up either one of those valuable additions.\n> \n> I have no objections to making them nonstandard, or even to make them\n> invalid if someone with a better grasp of history can attest that\n> CODESEPARATOR was known to be entirely useless before the introduction\n> of P2SH\u2014not the same as saying it was useless, but that it was widely\n> known to not accomplish what a early-days script author might think it\n> was doing\u2014and the UTXO set contains no scriptPubKeys making use of the\n> opcode, even from the early days. Although a small handful could be\n> special cased, if they exist.\n> \n>> On Nov 27, 2017, at 8:33 AM, Matt Corallo <lf-lists at mattcorallo.com\n>> <mailto:lf-lists at mattcorallo.com>> wrote:\n>>\n>> I strongly disagree here - we don't only soft-fork out transactions that\n>> are \"fundamentally insecure\", that would be significantly too\n>> restrictive. We have generally been willing to soft-fork out things\n>> which clearly fall outside of best-practices, especially rather\n>> \"useless\" fields in the protocol eg soft-forking behavior into OP_NOPs,\n>> soft-forking behavior into nSequence, etc.\n>>\n>> As a part of setting clear best-practices, making things non-standard is\n>> the obvious step, though there has been active discussion of\n>> soft-forking out FindAndDelete and OP_CODESEPARATOR for years now. I\n>> obviously do not claim that we should be proposing a soft-fork to\n>> blacklist FindAndDelete and OP_CODESEPARATOR usage any time soon, and\n>> assume that it would take at least a year or three from when it was made\n>> non-standard to when a soft-fork to finally remove them was proposed.\n>> This should be more than sufficient time for folks using such weird (and\n>> largely useless) parts of the protocol to object, which should be\n>> sufficient to reconsider such a soft-fork.\n>>\n>> Independently, making them non-standard is a good change on its own, and\n>> if nothing else should better inform discussion about the possibility of\n>> anyone using these things.\n>>\n>> Matt\n>>\n>> On 11/15/17 14:54, Mark Friedenbach via bitcoin-dev wrote:\n>>> As good of an idea as it may or may not be to remove this feature from\n>>> the code base, actually doing so\u00a0would be crossing a boundary that we\n>>> have not previously been willing to do except under extraordinary\n>>> duress. The nature of bitcoin is such that we do not know and cannot\n>>> know what transactions exist out there pre-signed and making use of\n>>> these features.\n>>>\n>>> It may be a good idea to make these features non standard to further\n>>> discourage their use, but I object to doing so with the justification of\n>>> eventually disabling them for all transactions. Taking that step has the\n>>> potential of destroying value and is something that we have only done in\n>>> the past either because we didn\u2019t understand forks and best practices\n>>> very well, or because the features (now disabled) were fundamentally\n>>> insecure and resulted in other people\u2019s coins being vulnerable. This\n>>> latter concern does not apply here as far as I\u2019m aware.\n>>>\n>>> On Nov 15, 2017, at 8:02 AM, Johnson Lau via bitcoin-dev\n>>> <bitcoin-dev at lists.linuxfoundation.org\n>>> <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>>\n>>>> In\u00a0https://github.com/bitcoin/bitcoin/pull/11423\u00a0I propose to\n>>>> make\u00a0OP_CODESEPARATOR and FindAndDelete in non-segwit scripts\n>>>> non-standard\n>>>>\n>>>> I think FindAndDelete() is one of the most useless and complicated\n>>>> functions in the script language. It is omitted from segwit (BIP143),\n>>>> but we still need to support it in non-segwit scripts. Actually,\n>>>> FindAndDelete() would only be triggered in some weird edge cases like\n>>>> using out-of-range SIGHASH_SINGLE.\n>>>>\n>>>> Non-segwit scripts also use a FindAndDelete()-like function to remove\n>>>> OP_CODESEPARATOR from scriptCode. Note that in BIP143, only executed\n>>>> OP_CODESEPARATOR are removed so it doesn\u2019t have the\n>>>> FindAndDelete()-like function. OP_CODESEPARATOR in segwit scripts are\n>>>> useful for Tumblebit so it is not disabled in this proposal\n>>>>\n>>>> By disabling both, it guarantees that scriptCode serialized inside\n>>>> SignatureHash() must be constant\n>>>>\n>>>> If we use a softfork to remove FindAndDelete() and OP_CODESEPARATOR\n>>>> from non-segwit scripts, we could completely remove FindAndDelete()\n>>>> from the consensus code later by whitelisting all blocks before the\n>>>> softfork block. The first step is to make them non-standard in the\n>>>> next release.\n>>>>\n>>>>\n>>>> \u00a0\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>>> <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>>\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            }
        ],
        "thread_summary": {
            "title": "Making OP_CODESEPARATOR and FindAndDelete in non-segwit scripts non-standard",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Matt Corallo",
                "Sjors Provoost",
                "Johnson Lau",
                "Mark Friedenbach"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 24497
        }
    },
    {
        "title": "[bitcoin-dev] POW - Miner's choice?",
        "thread_messages": [
            {
                "author": "Stikkan83",
                "date": "2017-11-15T19:59:45",
                "message_text_only": "hello list,\n\nwould it be possible to have two available POW mining algorithms (like\nfor example \"Double-SHA256\" and \"Cuckoo Cycle\"), and let the miner\nchoose which one to use for POW?\n\nthe two algorithms would have independent difficulties, and after each\ndifficulty period, the difficulty would be adjusted to aim for 50/50\ndistribution of the two algorithms (in addition to aim for 10 minutes\nblock time).\n\nthis could be done by only adjusting up difficulty for the algorithm\nused in most blocks last period, or only adjusting down difficulty for\nthe algorithm with the least number of blocks last period (depending\non whether the combined difficulty was to be adjusted up or down).  or\nmaybe a more sophisticated variant, where both difficulties are\nadjusted, based on the relative difference of the number of blocks\nwhere they are used.\n\nthe main motivation for this would be:\n\n- increase mining distribution\n- continue mining even when one type of miners suddenly jump to mine a\n  more profitable altcoin.\n\nnot sure if this has been proposed (and rejected) before, but I can't\nremember seeing it discussed.\n\nwould probably require a hard fork.\n\nSA\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171115/e66394e8/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "POW - Miner's choice?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Stikkan83"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1335
        }
    },
    {
        "title": "[bitcoin-dev] Protocol-Level Pruning",
        "thread_messages": [
            {
                "author": "Marc Bevand",
                "date": "2017-11-16T16:56:46",
                "message_text_only": "It occurred to me that we could push the classic concept of pruning even\nfurther: we could significantly shrink the blockchain as well as reduce the\namount of network traffic during initial block download by doing something\nI would call protocol-level pruning. This would, as of today, reduce the\nsize of the blockchain by a factor of 50, hence enabling massive on-chain\nscaling.\n\nThe idea behind PLP is to serialize the UTXO set in a standardized way, and\npublish a hash of it in the block header so that the blockchain commits to\nit. Since hashing and verifying it is a moderately intensive operation,\nperhaps the UTXO set hash should be published only once every 576 blocks (4\ndays).\n\nWhen a new Bitcoin node joins the network, it would download the block\nheaders only (not the block data), it would identify the most recent block\ncontaining the UTXO set hash, and download the UTXO set from peers. From\nthat point on, it downloads and verifies all blocks as normal.\n\nEvery 576 blocks, nodes serialize and verify that their UTXO set hash\nmatches the one published in the blockchain. Doing so becomes a new part of\nconsensus rules. The last 576 blocks could then be permanently discarded as\nthey are no longer useful.\n\nToday the serialized UTXO set is about 3GB and the blockchain is about\n150GB. Therefore PLP would cut down the amount of data stored by full nodes\nby a factor of ~50 as they would have to store only the UTXO set plus at\nmost 576 blocks.\n\nOne trivial optimization is possible: to avoid hashing the entire UTXO set\nevery 576 blocks (which would take multiple seconds even on a fast\nmachine), the UTXO set serialization could be a sparse merkle tree\n<https://eprint.iacr.org/2016/683.pdf> which would allow on-the fly\nrecomputation of the hash as new blocks are mined: when a UTXO is added to\n(or removed from) the tree, only a small number of hash operations are\nneeded to recalculate the UTXO set merkle tree root hash.\n\nMaybe we don't even need sparse merkle trees, but a regular merkle tree\nwould suffice: the tree leaves would be small groups of UTXOs (some bits in\nthe ID/hash of a UTXO would determine which leaf it belongs to.)\n\nUnlike classic pruning mode, *ALL* full nodes on the network could switch\nto PLP. There is no need for any node to archive the entire blockchain any\nmore.\n\nI can think of one downside of PLP: nodes would no longer be able to handle\nreorgs that go further back than the last UTXO set hash published on the\nchain (since previous blocks have been discarded). So, perhaps keeping\naround the last N*576 blocks (N=10?) would be a sufficient workaround.\n\nThoughts?\n\n-Marc\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171116/aa078a42/attachment-0001.html>"
            },
            {
                "author": "Bryan Bishop",
                "date": "2017-11-16T17:14:47",
                "message_text_only": "It's not clear to me if you are have looked at the previous UTXO set\ncommitment proposals.\n\nsome utxo set commitment bookmarks (a little old)\nhttp://diyhpl.us/~bryan/irc/bitcoin/utxo-commitments-or-fraud-proofs.stdout.txt\n\nTXO bitfields\nhttp://diyhpl.us/wiki/transcripts/sf-bitcoin-meetup/2017-07-08-bram-cohen-merkle-sets/\n\ndelayed TXO commitments\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-May/012715.html\n\nTXO commitments do not need a soft-fork to be useful\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-February/013591.html\n\nrolling UTXO set hashes\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/014337.html\n\nlotta other resources available, including source code proposals..\n\n- Bryan\nhttp://heybryan.org/\n1 512 203 0507\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171116/a4eb94c8/attachment.html>"
            },
            {
                "author": "Marc Bevand",
                "date": "2017-11-16T17:19:13",
                "message_text_only": "Ah, thanks, I suspected the idea was too simple and must have been\ndiscussed before, but somehow I missed these proposals. I've got some\nreading to do.\n\n-Marc\n\nOn Thu, Nov 16, 2017 at 11:14 AM, Bryan Bishop <kanzure at gmail.com> wrote:\n\n> It's not clear to me if you are have looked at the previous UTXO set\n> commitment proposals.\n>\n> some utxo set commitment bookmarks (a little old)\n> http://diyhpl.us/~bryan/irc/bitcoin/utxo-commitments-or-\n> fraud-proofs.stdout.txt\n>\n> TXO bitfields\n> http://diyhpl.us/wiki/transcripts/sf-bitcoin-meetup/\n> 2017-07-08-bram-cohen-merkle-sets/\n>\n> delayed TXO commitments\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/\n> 2016-May/012715.html\n>\n> TXO commitments do not need a soft-fork to be useful\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/\n> 2017-February/013591.html\n>\n> rolling UTXO set hashes\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/\n> 2017-May/014337.html\n>\n> lotta other resources available, including source code proposals..\n>\n> - Bryan\n> http://heybryan.org/\n> 1 512 203 0507 <(512)%20203-0507>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171116/c700c912/attachment.html>"
            },
            {
                "author": "William Casarin",
                "date": "2017-11-17T19:07:04",
                "message_text_only": "Bryan Bishop via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nwrites:\n\n> It's not clear to me if you are have looked at the previous UTXO set\n> commitment proposals.\n>\n> some utxo set commitment bookmarks (a little old)\n> http://diyhpl.us/~bryan/irc/bitcoin/utxo-commitments-or-fraud-proofs.stdout.txt\n>\n> TXO bitfields\n> http://diyhpl.us/wiki/transcripts/sf-bitcoin-meetup/2017-07-08-bram-cohen-merkle-sets/\n>\n> delayed TXO commitments\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2016-May/012715.html\n>\n> TXO commitments do not need a soft-fork to be useful\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-February/013591.html\n>\n> rolling UTXO set hashes\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/014337.html\n>\n> lotta other resources available, including source code proposals..\n\nThanks!\n\nHas anyone categoried list discussions by topic like this? It seems a\nlot of this stuff is scattered between mailing lists, irc conversations,\netc and can be hard to know whats floating out there.\n\n-- \nhttps://jb55.com"
            }
        ],
        "thread_summary": {
            "title": "Protocol-Level Pruning",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Bryan Bishop",
                "William Casarin",
                "Marc Bevand"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 6111
        }
    },
    {
        "title": "[bitcoin-dev] Why SegWit Anyway?",
        "thread_messages": [
            {
                "author": "Praveen Baratam",
                "date": "2017-11-20T17:24:33",
                "message_text_only": "Bitcoin Noob here. Please forgive my ignorance.\n\n>From what I understand, in SegWit, the transaction needs to be serialized\ninto a data structure that is different from the current one where\nsignatures are separated from the rest of the transaction data.\n\nWhy change the format at all? Why cant we just compute the Transaction ID\nthe same way the hash for signing the transaction is computed?\n\n-- \nDr. Praveen Baratam\n\nabout.me <http://about.me/praveen.baratam>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171120/2fc6d1a3/attachment.html>"
            },
            {
                "author": "Ariel Lorenzo-Luaces",
                "date": "2017-11-20T17:39:11",
                "message_text_only": "Hello Praveen\n\nYou're absolutely right. We could refer to transactions by the hash that gets signed.\n\nHowever the way that bitcoin transactions reference each other has already been established to be hash of transaction+signature. Changing this would require a hard fork.\n\nSegwit is the realization that this could be done as a soft fork if we simply extract the signature outside of what the old client considers a transaction. And into a new transaction format where we do exactly what you're describing.\n\nIn my opinion the way it originally worked with the sig inside the transaction was simply an oversight by satoshi. No different than a bug.\n\nCheers\nAriel Lorenzo-Luaces\n\n\nOn Nov 20, 2017, 9:29 AM, at 9:29 AM, Praveen Baratam via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>Bitcoin Noob here. Please forgive my ignorance.\n>\n>From what I understand, in SegWit, the transaction needs to be\n>serialized\n>into a data structure that is different from the current one where\n>signatures are separated from the rest of the transaction data.\n>\n>Why change the format at all? Why cant we just compute the Transaction\n>ID\n>the same way the hash for signing the transaction is computed?\n>\n>-- \n>Dr. Praveen Baratam\n>\n>about.me <http://about.me/praveen.baratam>\n>\n>\n>------------------------------------------------------------------------\n>\n>_______________________________________________\n>bitcoin-dev mailing list\n>bitcoin-dev at lists.linuxfoundation.org\n>https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171120/292a25d9/attachment.html>"
            },
            {
                "author": "Johnson Lau",
                "date": "2017-11-20T17:45:18",
                "message_text_only": "We can\u2019t \u201cjust compute the Transaction ID the same way the hash for signing the transaction is computed\u201d because with different SIGHASH flags, there are 6 (actually 256) ways to hash a transaction.\n\nAlso, changing the definition of TxID is a hardfork change, i.e. everyone are required to upgrade or a chain split will happen.\n\nIt is possible to use \u201cnormalised TxID\u201d (BIP140) to fix malleability issue. As a softfork, BIP140 doesn\u2019t change the definition of TxID. Instead, the normalised txid (i.e. txid with scriptSig removed) is used when making signature. Comparing with segwit (BIP141), BIP140 does not have the side-effect of block size increase, and doesn\u2019t provide any incentive to control the size of UTXO set. Also, BIP140 makes the UTXO set permanently bigger, as the database needs to store both txid and normalised txid\n\n> On 21 Nov 2017, at 1:24 AM, Praveen Baratam via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Bitcoin Noob here. Please forgive my ignorance.\n> \n> From what I understand, in SegWit, the transaction needs to be serialized into a data structure that is different from the current one where signatures are separated from the rest of the transaction data.\n> \n> Why change the format at all? Why cant we just compute the Transaction ID the same way the hash for signing the transaction is computed?\n> \n> -- \n> Dr. Praveen Baratam\n> \n> about.me <http://about.me/praveen.baratam>_______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171121/f53f93f9/attachment.html>"
            },
            {
                "author": "Praveen Baratam",
                "date": "2017-11-20T18:07:40",
                "message_text_only": "BIP 140 looks like it solves Tx Malleability with least impact on current\npractices. It is still a soft fork though.\n\nFinally, if we were to create an alternative cyptocurrency similar to\nBitcoin, a Normalized Tx ID approach would be a better choice if I get it\nright!\n\u1427\n\nOn Mon, Nov 20, 2017 at 11:15 PM, Johnson Lau <jl2012 at xbt.hk> wrote:\n\n> We can\u2019t \u201cjust compute the Transaction ID the same way the hash for\n> signing the transaction is computed\u201d because with different SIGHASH flags,\n> there are 6 (actually 256) ways to hash a transaction.\n>\n> Also, changing the definition of TxID is a hardfork change, i.e. everyone\n> are required to upgrade or a chain split will happen.\n>\n> It is possible to use \u201cnormalised TxID\u201d (BIP140) to fix malleability\n> issue. As a softfork, BIP140 doesn\u2019t change the definition of TxID.\n> Instead, the normalised txid (i.e. txid with scriptSig removed) is used\n> when making signature. Comparing with segwit (BIP141), BIP140 does not have\n> the side-effect of block size increase, and doesn\u2019t provide any incentive\n> to control the size of UTXO set. Also, BIP140 makes the UTXO set\n> permanently bigger, as the database needs to store both txid and normalised\n> txid\n>\n> On 21 Nov 2017, at 1:24 AM, Praveen Baratam via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Bitcoin Noob here. Please forgive my ignorance.\n>\n> From what I understand, in SegWit, the transaction needs to be serialized\n> into a data structure that is different from the current one where\n> signatures are separated from the rest of the transaction data.\n>\n> Why change the format at all? Why cant we just compute the Transaction ID\n> the same way the hash for signing the transaction is computed?\n>\n> --\n> Dr. Praveen Baratam\n>\n> about.me <http://about.me/praveen.baratam>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n\n\n-- \nDr. Praveen Baratam\n\nabout.me <http://about.me/praveen.baratam>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171120/35d7fb17/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2017-11-20T18:59:34",
                "message_text_only": "On Mon, Nov 20, 2017 at 5:24 PM, Praveen Baratam via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Bitcoin Noob here. Please forgive my ignorance.\n>\n> From what I understand, in SegWit, the transaction needs to be serialized\n> into a data structure that is different from the current one where\n> signatures are separated from the rest of the transaction data.\n>\n> Why change the format at all? Why cant we just compute the Transaction ID\n> the same way the hash for signing the transaction is computed?\n\nThat is effectively what segwit does, upto engineering minutia and\ncompatibility details.\n\nSegwit does not serialize transactions in to a data structure where\nsignatures are separated from the rest of the transaction data; this\nis a misunderstanding.  The \"segregated\" refers to them being excluded\nfrom the TXID.   The serialization of segwit on the p2p network in\ntransactions and in blocks encodes the witness field inside the\ntransactions, immediately prior to the nlocktime field."
            },
            {
                "author": "Dan Bryant",
                "date": "2017-11-20T18:04:09",
                "message_text_only": "Is there any incentive for miners to pick segwit transactions over\nnon-segwit transaction.  Do they require less, equal, or more compute to\nprocess?\n\nOn Nov 20, 2017 11:46 AM, \"Johnson Lau via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\nWe can\u2019t \u201cjust compute the Transaction ID the same way the hash for signing\nthe transaction is computed\u201d because with different SIGHASH flags, there\nare 6 (actually 256) ways to hash a transaction.\n\nAlso, changing the definition of TxID is a hardfork change, i.e. everyone\nare required to upgrade or a chain split will happen.\n\nIt is possible to use \u201cnormalised TxID\u201d (BIP140) to fix malleability issue.\nAs a softfork, BIP140 doesn\u2019t change the definition of TxID. Instead, the\nnormalised txid (i.e. txid with scriptSig removed) is used when making\nsignature. Comparing with segwit (BIP141), BIP140 does not have the\nside-effect of block size increase, and doesn\u2019t provide any incentive to\ncontrol the size of UTXO set. Also, BIP140 makes the UTXO set permanently\nbigger, as the database needs to store both txid and normalised txid\n\nOn 21 Nov 2017, at 1:24 AM, Praveen Baratam via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\nBitcoin Noob here. Please forgive my ignorance.\n\n>From what I understand, in SegWit, the transaction needs to be serialized\ninto a data structure that is different from the current one where\nsignatures are separated from the rest of the transaction data.\n\nWhy change the format at all? Why cant we just compute the Transaction ID\nthe same way the hash for signing the transaction is computed?\n\n-- \nDr. Praveen Baratam\n\nabout.me <http://about.me/praveen.baratam>\n_______________________________________________\n\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171120/7fe1e946/attachment.html>"
            },
            {
                "author": "Steve Shadders",
                "date": "2017-11-21T13:10:28",
                "message_text_only": "There is incentive because of artificially distorted block weight rules. It\nis favourable for a miner to choose a segwit tx over a non segwit tx as\nthey can fit more of them into a block and earn more fees.\n\nOn Nov 21, 2017 11:06 PM, \"Dan Bryant via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Is there any incentive for miners to pick segwit transactions over\n> non-segwit transaction.  Do they require less, equal, or more compute to\n> process?\n>\n> On Nov 20, 2017 11:46 AM, \"Johnson Lau via bitcoin-dev\" <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> We can\u2019t \u201cjust compute the Transaction ID the same way the hash for\n> signing the transaction is computed\u201d because with different SIGHASH flags,\n> there are 6 (actually 256) ways to hash a transaction.\n>\n> Also, changing the definition of TxID is a hardfork change, i.e. everyone\n> are required to upgrade or a chain split will happen.\n>\n> It is possible to use \u201cnormalised TxID\u201d (BIP140) to fix malleability\n> issue. As a softfork, BIP140 doesn\u2019t change the definition of TxID.\n> Instead, the normalised txid (i.e. txid with scriptSig removed) is used\n> when making signature. Comparing with segwit (BIP141), BIP140 does not have\n> the side-effect of block size increase, and doesn\u2019t provide any incentive\n> to control the size of UTXO set. Also, BIP140 makes the UTXO set\n> permanently bigger, as the database needs to store both txid and normalised\n> txid\n>\n> On 21 Nov 2017, at 1:24 AM, Praveen Baratam via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Bitcoin Noob here. Please forgive my ignorance.\n>\n> From what I understand, in SegWit, the transaction needs to be serialized\n> into a data structure that is different from the current one where\n> signatures are separated from the rest of the transaction data.\n>\n> Why change the format at all? Why cant we just compute the Transaction ID\n> the same way the hash for signing the transaction is computed?\n>\n> --\n> Dr. Praveen Baratam\n>\n> about.me <http://about.me/praveen.baratam>\n> _______________________________________________\n>\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171121/27e2b472/attachment-0001.html>"
            },
            {
                "author": "Ad\u00e1n S\u00e1nchez de Pedro Crespo",
                "date": "2017-11-21T13:16:48",
                "message_text_only": "Yes.\n\n1. SegWit transactions spend less \"weight\", which is limited for every\nblock. Base transaction data weights as much as 4x the witness data.\n\n2. SegWit signatures can be cheaper to verify (linear instead of\nquadratic). Prior to this, DoS attacks were possible by using forged\ntransactions including signatures which could take several minutes to\nverify.\n\nThe immediate result of this is that miners can fit more transactions\ninto a block and at the same time spend less power building the blocks.\n\nOn 20.11.2017 19:04, Dan Bryant via bitcoin-dev wrote:\n> Is there any incentive for miners to pick segwit transactions over\n> non-segwit transaction.\u00a0 Do they require less, equal, or more compute to\n> process?\n> \n> On Nov 20, 2017 11:46 AM, \"Johnson Lau via bitcoin-dev\"\n> <bitcoin-dev at lists.linuxfoundation.org\n> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> \n>     We can\u2019t \u201cjust compute the Transaction ID the same way the hash for\n>     signing the transaction is computed\u201d because with different SIGHASH\n>     flags, there are 6 (actually 256) ways to hash a transaction.\n> \n>     Also, changing the definition of TxID is a hardfork change, i.e.\n>     everyone are required to upgrade or a chain split will happen.\n> \n>     It is possible to use \u201cnormalised TxID\u201d (BIP140) to fix malleability\n>     issue. As a softfork, BIP140 doesn\u2019t change the definition of TxID.\n>     Instead, the normalised txid (i.e. txid with scriptSig removed) is\n>     used when making signature. Comparing with segwit (BIP141), BIP140\n>     does not have the side-effect of block size increase, and doesn\u2019t\n>     provide any incentive to control the size of UTXO set. Also, BIP140\n>     makes the UTXO set permanently bigger, as the database needs to\n>     store both txid and normalised txid\n> \n>>     On 21 Nov 2017, at 1:24 AM, Praveen Baratam via bitcoin-dev\n>>     <bitcoin-dev at lists.linuxfoundation.org\n>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>\n>>     Bitcoin Noob here. Please forgive my ignorance.\n>>\n>>     From what I understand, in SegWit, the transaction needs to be\n>>     serialized into a data structure that is different from the\n>>     current one where signatures are separated from the rest of the\n>>     transaction data.\n>>\n>>     Why change the format at all? Why cant we just compute the\n>>     Transaction ID the same way the hash for signing the transaction\n>>     is computed?\n>>\n>>     -- \n>>     Dr. Praveen Baratam\n>>\n>>     about.me <http://about.me/praveen.baratam>\n>>     _______________________________________________\n>>\n>>     bitcoin-dev mailing list\n>>     bitcoin-dev at lists.linuxfoundation.org\n>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n> \n> \n>     _______________________________________________\n>     bitcoin-dev mailing list\n>     bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n> \n> \n> \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n\n-- \nAd\u00e1n S\u00e1nchez de Pedro Crespo\nCTO, Stampery Inc.\nSan Francisco - Madrid"
            },
            {
                "author": "CANNON",
                "date": "2017-11-25T15:41:44",
                "message_text_only": "On 11/21/2017 01:16 PM, Ad\u00e1n S\u00e1nchez de Pedro Crespo via bitcoin-dev wrote:\n> 2. SegWit signatures can be cheaper to verify (linear instead of\n> quadratic). Prior to this, DoS attacks were possible by using forged\n> transactions including signatures which could take several minutes to\n> verify.\n\nWhere can I find more resources on this described DoS attack?\nAnd how does SegWit prevent this if using SegWit transactions are not enforced?\n\nThanks"
            },
            {
                "author": "Johnson Lau",
                "date": "2017-11-20T19:58:57",
                "message_text_only": "Not really. BIP140 might be easier to implement, but in longterm the UTXO overhead is significant and unnecessary. There are also other benefits of segwit written in BIP141. Some of those are applicable even if you are making a new coin.\n\n> On 21 Nov 2017, at 2:07 AM, Praveen Baratam <praveen.baratam at gmail.com> wrote:\n> \n> BIP 140 looks like it solves Tx Malleability with least impact on current practices. It is still a soft fork though.\n> \n> Finally, if we were to create an alternative cyptocurrency similar to Bitcoin, a Normalized Tx ID approach would be a better choice if I get it right!\n> \u1427\n> \n> On Mon, Nov 20, 2017 at 11:15 PM, Johnson Lau <jl2012 at xbt.hk <mailto:jl2012 at xbt.hk>> wrote:\n> We can\u2019t \u201cjust compute the Transaction ID the same way the hash for signing the transaction is computed\u201d because with different SIGHASH flags, there are 6 (actually 256) ways to hash a transaction.\n> \n> Also, changing the definition of TxID is a hardfork change, i.e. everyone are required to upgrade or a chain split will happen.\n> \n> It is possible to use \u201cnormalised TxID\u201d (BIP140) to fix malleability issue. As a softfork, BIP140 doesn\u2019t change the definition of TxID. Instead, the normalised txid (i.e. txid with scriptSig removed) is used when making signature. Comparing with segwit (BIP141), BIP140 does not have the side-effect of block size increase, and doesn\u2019t provide any incentive to control the size of UTXO set. Also, BIP140 makes the UTXO set permanently bigger, as the database needs to store both txid and normalised txid\n> \n>> On 21 Nov 2017, at 1:24 AM, Praveen Baratam via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>> \n>> Bitcoin Noob here. Please forgive my ignorance.\n>> \n>> From what I understand, in SegWit, the transaction needs to be serialized into a data structure that is different from the current one where signatures are separated from the rest of the transaction data.\n>> \n>> Why change the format at all? Why cant we just compute the Transaction ID the same way the hash for signing the transaction is computed?\n>> \n>> -- \n>> Dr. Praveen Baratam\n>> \n>> about.me <http://about.me/praveen.baratam>_______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n> \n> \n> \n> \n> -- \n> Dr. Praveen Baratam\n> \n> about.me <http://about.me/praveen.baratam>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171121/27d81473/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Why SegWit Anyway?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Steve Shadders",
                "Praveen Baratam",
                "Dan Bryant",
                "Ariel Lorenzo-Luaces",
                "Ad\u00e1n S\u00e1nchez de Pedro Crespo",
                "Johnson Lau",
                "Gregory Maxwell",
                "CANNON"
            ],
            "messages_count": 10,
            "total_messages_chars_count": 19135
        }
    },
    {
        "title": "[bitcoin-dev] BIP159 - NODE_NETWORK_LIMITED service bits, extendability",
        "thread_messages": [
            {
                "author": "Sjors Provoost",
                "date": "2017-11-21T14:03:46",
                "message_text_only": "I came across the proposed Bitcoin Core implementation of BIP159 [0] in this PR [1]. The goal is to allow pruned nodes to \"serve a limited number of historical blocks\" (as opposed to none at all).\n\nIt contains a counter-measure for peer fingerprinting. I'm trying to understand how that impacts extendibility.\n\n> Peers may have different prune depths (depending on the peers configuration,\n> disk space, etc.) which can result in a fingerprinting weakness (finding the\n> prune depth through getdata requests). NODE_NETWORK_LIMITED\n> supporting peers SHOULD avoid leaking the prune depth and therefore\n> not serve blocks deeper then the signaled NODE_NETWORK_LIMITED\n> thresholds.\n\nThis means pruned nodes can only serve the last 288 blocks:\n\n> If signaled, the peer MUST be capable of serving at least the last 288 blocks (~2 day\n\nAs the blockchain keeps growing there will be ever more pruned nodes (perhaps offset by new nodes with more storage).  Although a strict improvement over todays situation, it seems a bit wasteful to have a node with 10-100 GB of storage only be able to share the most recent 288 blocks.\n\nIt would be nice if a future extension of this BIP allows more flexibility. To limit the ability to fingerprint nodes, we could limit the number of choices to e.g. 288 + 1000 * 2^n. That yields only 8 possibilities at the current chain size. A slightly better formula could take into account typical hard drive size increments, leaving enough space for the OS and other data. Node operators could opt-in to this if they think the increased fingerprint risk outweighs their desire to share archived blocks.\n\nI can also imagine - but not implement :-) - a future scenario where nodes prune a random subset of their chain, meaning that even nodes with little storage can be of help during Initial Blockchain Download (IBD) of other nodes.\n\n\nHow would such extension be signaled for? Would we need a whole new version bit?\n\nWould upgraded nodes need a new message type to communicate the chosen prune depth? Or can that information tag along some existing message?\n\nJonas Schnelli pointed out on the Github discussion that waiting for BIP150 would be appropriate. Can you explain how this is related? Although I can see why whitelisted peers can be exempted from the anti-fingerprinting measure, I would not want to restrict it to just those.\n\n\nSome minor suggestions for improving the BIP itself:\n* add link to mailinglist discussion(s) in reference section\n* explain that 288 is not just the minimum limit for Bitcoin Core, but also the bulk of traffic (as I understand from earlier discussion [2])\n\nCheers,\n\nSjors\n\n[0] https://github.com/bitcoin/bips/blob/master/bip-0159.mediawiki\n[1] https://github.com/bitcoin/bitcoin/pull/10387\n[2] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/thread.html#14315\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171121/0bd335ba/attachment.sig>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2017-11-21T18:45:33",
                "message_text_only": "With the way pruning works today my expirence is that virtually no one\nsets any parameter other than the minimum, though even with that set a\nfew more blocks can be available.\n\nIn the future we would set further pruning identifying bits, with\nthose set node would (obviously) answer for their blocks.  An earlier\nversion of this BIP had such a bit defined but it appeared that we\nlacked sufficient experience from practice to usefully specify what\nheight it should mean exactly and the proposals sounded like they\nwould likely interact poorly with other future proposals, so we\nthought it better to delay defining any additional levels for the\ntime.\n\nPart of your concern is mooted by the logistics of actually fetching\nthose additional blocks.  At least in the network today we have a\nsuperabundance of nodes that serve anything, to handle them being rare\nwill require very different approaches than we have now.  We have no\nreason to believe that \"like the pruning thing but more blocks\" is\nactually all that useful-- and some reason to expect that its not:\nonce you go back more than a handful of weeks the probably of fetching\nget pretty close to uniform, those fetches are only be newly\ninitializing nodes that need all the blocks.\n\n\n\nOn Tue, Nov 21, 2017 at 2:03 PM, Sjors Provoost via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> I came across the proposed Bitcoin Core implementation of BIP159 [0] in this PR [1]. The goal is to allow pruned nodes to \"serve a limited number of historical blocks\" (as opposed to none at all).\n>\n> It contains a counter-measure for peer fingerprinting. I'm trying to understand how that impacts extendibility.\n>\n>> Peers may have different prune depths (depending on the peers configuration,\n>> disk space, etc.) which can result in a fingerprinting weakness (finding the\n>> prune depth through getdata requests). NODE_NETWORK_LIMITED\n>> supporting peers SHOULD avoid leaking the prune depth and therefore\n>> not serve blocks deeper then the signaled NODE_NETWORK_LIMITED\n>> thresholds.\n>\n> This means pruned nodes can only serve the last 288 blocks:\n>\n>> If signaled, the peer MUST be capable of serving at least the last 288 blocks (~2 day\n>\n> As the blockchain keeps growing there will be ever more pruned nodes (perhaps offset by new nodes with more storage).  Although a strict improvement over todays situation, it seems a bit wasteful to have a node with 10-100 GB of storage only be able to share the most recent 288 blocks.\n>\n> It would be nice if a future extension of this BIP allows more flexibility. To limit the ability to fingerprint nodes, we could limit the number of choices to e.g. 288 + 1000 * 2^n. That yields only 8 possibilities at the current chain size. A slightly better formula could take into account typical hard drive size increments, leaving enough space for the OS and other data. Node operators could opt-in to this if they think the increased fingerprint risk outweighs their desire to share archived blocks.\n>\n> I can also imagine - but not implement :-) - a future scenario where nodes prune a random subset of their chain, meaning that even nodes with little storage can be of help during Initial Blockchain Download (IBD) of other nodes.\n>\n>\n> How would such extension be signaled for? Would we need a whole new version bit?\n>\n> Would upgraded nodes need a new message type to communicate the chosen prune depth? Or can that information tag along some existing message?\n>\n> Jonas Schnelli pointed out on the Github discussion that waiting for BIP150 would be appropriate. Can you explain how this is related? Although I can see why whitelisted peers can be exempted from the anti-fingerprinting measure, I would not want to restrict it to just those.\n>\n>\n> Some minor suggestions for improving the BIP itself:\n> * add link to mailinglist discussion(s) in reference section\n> * explain that 288 is not just the minimum limit for Bitcoin Core, but also the bulk of traffic (as I understand from earlier discussion [2])\n>\n> Cheers,\n>\n> Sjors\n>\n> [0] https://github.com/bitcoin/bips/blob/master/bip-0159.mediawiki\n> [1] https://github.com/bitcoin/bitcoin/pull/10387\n> [2] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/thread.html#14315\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Peter Todd",
                "date": "2017-11-28T10:48:28",
                "message_text_only": "On Tue, Nov 21, 2017 at 06:45:33PM +0000, Gregory Maxwell via bitcoin-dev wrote:\n> With the way pruning works today my expirence is that virtually no one\n> sets any parameter other than the minimum, though even with that set a\n> few more blocks can be available.\n\nFWIW, I run all my pruned nodes with the prune parameter set to about a month\nworth of blocks (a few GB). And come to think of it, I should bump that up even\nhigher now that segwit has increased the blocksize.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 488 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171128/a581cf3a/attachment.sig>"
            },
            {
                "author": "Jonas Schnelli",
                "date": "2017-11-21T19:00:21",
                "message_text_only": "Hi Sjors\n\nThanks for picking this up.\n\nThere where some previous discussions about this [1] [2].\nInitially, the idea was to have two service bits to signal (up to three) states.\nBut, since it is not clear what use-cases the bits signalling >288 blocks would fulfil, I have limited BIP159 to a single 288blocks-available signalling.\n\nTherefore, BIP159 aims to improve the block relay state around the tip (24h) which seems to be the most significant request peak (peers out of IBD).\nAlso, it takes an acceptable transition for pruned node operators into account. Once BIP159 gets active on the network, pruned peer operators may see an increase in CPU and bandwidth usage.\n\nSPV peers may also connect to BIP159 nodes, scan the mempool and wait for unconfirmed transactions (they don\u2019t do this now because pruned nodes don't signal any service).\n\nFuture extensions are possible. Maybe a p2p command that could tell more infos about the pruning state would be useful.\n\nBIP159 also recommends to fix the fingerprinting weakness by fix limiting it to 288 blocks, making it impossible for an attacker to fingerprint your peer by scanning how deep the peer can serve blocks. This may be a reduction for possible use cases with todays pruned peers and an idea would be to relax this limit for whitelisted peers (or peers connecting via BIP150 [not implemented], and this is the only connection between BIP150 and BIP159).\n\nHowever, I think the scope of BIP159 should be kept as it is. More flexibility can be added later when we have gathered more information during BIP159 deployment.\nAlso, the implementations is an advanced stage [3][4]\n\n\u2014\n</jonas>\n\n[1] https://botbot.me/freenode/bitcoin-core-dev/2017-04-27/?msg=84827228&page=3\n[2] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/thread.html#14314\n[3] https://github.com/bitcoin/bitcoin/pull/10387\n[4] https://github.com/bitcoin/bitcoin/pull/11740\n\n\n> Am 21.11.2017 um 04:03 schrieb Sjors Provoost via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>:\n> \n> I came across the proposed Bitcoin Core implementation of BIP159 [0] in this PR [1]. The goal is to allow pruned nodes to \"serve a limited number of historical blocks\" (as opposed to none at all).\n> \n> It contains a counter-measure for peer fingerprinting. I'm trying to understand how that impacts extendibility.\n> \n>> Peers may have different prune depths (depending on the peers configuration,\n>> disk space, etc.) which can result in a fingerprinting weakness (finding the\n>> prune depth through getdata requests). NODE_NETWORK_LIMITED\n>> supporting peers SHOULD avoid leaking the prune depth and therefore\n>> not serve blocks deeper then the signaled NODE_NETWORK_LIMITED\n>> thresholds.\n> \n> This means pruned nodes can only serve the last 288 blocks:\n> \n>> If signaled, the peer MUST be capable of serving at least the last 288 blocks (~2 day\n> \n> As the blockchain keeps growing there will be ever more pruned nodes (perhaps offset by new nodes with more storage).  Although a strict improvement over todays situation, it seems a bit wasteful to have a node with 10-100 GB of storage only be able to share the most recent 288 blocks.\n> \n> It would be nice if a future extension of this BIP allows more flexibility. To limit the ability to fingerprint nodes, we could limit the number of choices to e.g. 288 + 1000 * 2^n. That yields only 8 possibilities at the current chain size. A slightly better formula could take into account typical hard drive size increments, leaving enough space for the OS and other data. Node operators could opt-in to this if they think the increased fingerprint risk outweighs their desire to share archived blocks.\n> \n> I can also imagine - but not implement :-) - a future scenario where nodes prune a random subset of their chain, meaning that even nodes with little storage can be of help during Initial Blockchain Download (IBD) of other nodes.\n> \n> \n> How would such extension be signaled for? Would we need a whole new version bit?\n> \n> Would upgraded nodes need a new message type to communicate the chosen prune depth? Or can that information tag along some existing message?\n> \n> Jonas Schnelli pointed out on the Github discussion that waiting for BIP150 would be appropriate. Can you explain how this is related? Although I can see why whitelisted peers can be exempted from the anti-fingerprinting measure, I would not want to restrict it to just those.\n> \n> \n> Some minor suggestions for improving the BIP itself:\n> * add link to mailinglist discussion(s) in reference section\n> * explain that 288 is not just the minimum limit for Bitcoin Core, but also the bulk of traffic (as I understand from earlier discussion [2])\n> \n> Cheers,\n> \n> Sjors\n> \n> [0] https://github.com/bitcoin/bips/blob/master/bip-0159.mediawiki\n> [1] https://github.com/bitcoin/bitcoin/pull/10387\n> [2] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-May/thread.html#14315\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171121/31852331/attachment-0001.sig>"
            }
        ],
        "thread_summary": {
            "title": "BIP159 - NODE_NETWORK_LIMITED service bits, extendability",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Peter Todd",
                "Jonas Schnelli",
                "Sjors Provoost",
                "Gregory Maxwell"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 13775
        }
    },
    {
        "title": "[bitcoin-dev] pubkey or not pubkey?",
        "thread_messages": [
            {
                "author": "Aymeric Vitte",
                "date": "2017-11-24T15:13:04",
                "message_text_only": "I released https://github.com/Ayms/bitcoin-transactions\n\nAs you can see the restart of this project (started one year ago) was\nmotivated by the epic launch of bitcoin gold and many people still\ndesperately trying to sync, not understanding there was no need to\n'transfer' their bitcoins to btg, getting robbed, etc, but there is more\nsome long term intent\n\nThis is somewhere bitcoin-cli outside of bitcoin-qt with a non\nsynced/outside wallet (where https://github.com/Ayms/bitcoin-wallets can\nbe used), not only for btg but for any network based on bitcoin\n\nWhile implementing BIP143 I noticed during the tests/doublechecks with\ncli that scriptSig was <signature>< pubkey>\n\nThis was not the case one year ago, scriptSig was <signature> since you\ncan get the <pubkey> from the signature, that's what I did thinking of\nsome lack of optimization in the bgold client, but this behavior is very\nthe same for bitcoin core\n\nThen my first transactions did not include the pubkey and I was\nimmediately banned by my own node (who btw did not realize that it was\nbanning itself...), I got a reject message stating that OP_EQUALVERIFY\nfailed\n\nSo, the questions are: for basic p2pkh transactions why is pubkey back,\nsince when and why txs without it are rejected?\n\nAt this time where everything is made to reduce the tx's size while the\nfees/byte are quite high, this adds 34 useless bytes in each input\n\n-- \nBitcoin transactions made simple: https://github.com/Ayms/bitcoin-transactions\nZcash wallets made simple: https://github.com/Ayms/zcash-wallets\nBitcoin wallets made simple: https://github.com/Ayms/bitcoin-wallets\nGet the torrent dynamic blocklist: http://peersm.com/getblocklist\nCheck the 10 M passwords list: http://peersm.com/findmyass\nAnti-spies and private torrents, dynamic blocklist: http://torrent-live.org\nPeersm : http://www.peersm.com\ntorrent-live: https://github.com/Ayms/torrent-live\nnode-Tor : https://www.github.com/Ayms/node-Tor\nGitHub : https://www.github.com/Ayms"
            }
        ],
        "thread_summary": {
            "title": "pubkey or not pubkey?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Aymeric Vitte"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1976
        }
    },
    {
        "title": "[bitcoin-dev] Fwd: [Lightning-dev] General question on routing difficulties",
        "thread_messages": [
            {
                "author": "Bryan Bishop",
                "date": "2017-11-25T19:21:55",
                "message_text_only": "---------- Forwarded message ----------\nFrom: Olaoluwa Osuntokun <laolu32 at gmail.com>\nDate: Sat, Nov 25, 2017 at 1:16 PM\nSubject: Re: [Lightning-dev] General question on routing difficulties\nTo: Pedro Moreno Sanchez <pmorenos at purdue.edu>\nCc: lightning-dev at lists.linuxfoundation.org\n\n\n(final try as the prior mail hit the size limit, sorry for the spam!)\n\nHi Pedro,\n\nI came across this paper a few weeks ago, skimmed it lightly, and noted a\nfew interesting aspects I wanted to dig into later. Your email reminded me\nto re-read the paper, so thanks for that! Before reading the paper, I\nwasn't aware of the concept of coordinate embedding, nor how that could be\nleveraged in order to provide sender+receiver privacy in a payment network\nusing a distance-vector-like routing system. Very cool technique!\n\n\nAfter reading the paper again, my current conclusion is that while the\nprotocol presents some novel traits in the design a routing system for\npayment channel based networks, it lends much better to a\nclosed-membership, credit network, such as Ripple (which is the focus of\nthe paper).\n\n\nIn Ripple, there are only a handful of gateways, and clients that seek to\ninteract with the network must chose their gateways *very* carefully,\notherwise consensus faults can occur, violating safety properties of the\nnetwork. It would appear that this gateway model nicely translates well to\nthe concept of landmarks that the protocol is strongly dependant on.\nIdeally, each gateway would be a landmark, and as there are a very small\nnumber of gateways within Ripple (as you must be admitted to be a verified\ngateway in the network), then parameter L (the total number of landmarks)\nis kept small which minimizes routing overhead, the average path-length,\netc.\n\n\nWhen we compare Ripple to LN, we find that the two networks are nearly\npolar opposites of each other. LN is an open-membership network that\nrequires zero initial configuration by central administrators(s). It more\nclosely resembles *debit* network (a series of tubes of money), as the\nfunds within channels must be pre-committed in order to establish a link\nbetween two nodes, and cannot be increased without an additional on-chain\ncontrol transaction (to add or remove funds). Additionally, AFAIK (I'm no\nexpert on Ripple of course), there's no concept of fees within the\nnetwork. While within LN, the fee structure is a critical component of the\ninventive for node operators to lift their coins onto this new layer to\nprovider payment routing services.  Finally, in LN we rely on time-locks\nin order to ensure that all transactions are atomic which adds another set\nof constraints. Ripple has no such constraint as transfers are based on\nbi-lateral trust.\n\n\nWith that said, the primary difference between this protocol is that\ncurrently we utilize a source-routed system which requires the sender to\nknow \"most\" of the path to the destination. I say \"most\" as currently,\nit's possible for the receiver of a payment to use a poor man's rendezvous\nsystem to provide the sender with a set of suffix paths form what one can\nconsider ad-hoc landmarks. The sender can then concatenate these with\ntheir own paths, and construct the Sphinx routing package which encodes\nthe full route. This itself only gives sender privacy, and the receiver\ndoesn't know the identity of the sender, but the sender learns the\nidentity of the receiver.\n\nWe have plans to achieve proper sender/receiver privacy by extending our\nSphinx usage to leverage HORNET, such that the payment descriptor (payment\nrequest containing details of the payment) also includes several paths\nfrom rendezvous nodes (Rodrigo's) to the receiver. The rendezvous route\nitself will be nested as a further Anonymous Header (AHDR) which includes\nthe information necessary to complete the onion circuit from Rodrigo to\nthe receiver. As onion routing is used, only Rodrigo can decrypt the\npayload and finalize the route. With such a structure, the only nodes that\nneed to advertise their channels are nodes which seek to actively serve as\nchannel routers. All other nodes (phones, laptops, etc), don't need to\nadvertise their channels to the greater network, reducing the size of the\nvisible network, and also the storage and validation overhead. This serves\nto extend the \"scale ceiling\" a bit.\n\n\nMy first question is: is it possible to adapt the protocol to allow each\nintermediate node to communicate their time lock and fee references to the\nsender? Currently, as the full path isn't known ahead of time, the sender\nis unable to properly craft the timelocks to ensure safety+atomicity of\nthe payment. This would mean they don't know what the total timelock\nshould be on the first outgoing link. Additionally, as they don't know the\ntotal path and the fee schedule of each intermediate node, then once\nagain, they don't know how much to send on the first out going link. It\nwould seem that one could extend the probing phase to allow backwards\ncommunication by each intermediate node back to the sender, such that they\ncan properly craft a valid HTLC. This would increase the set up costs of\nthe protocol however, and may also increase routing failures as it's\npossible incompatibilities arise at run-time between the preferences of\nintermediate nodes. Additionally, routes may fail as an intermediate node\nconsumes too many funds as their fee, causing the funds to be insufficient\nwhen it reaches the destination. One countermeasure would maybe: the\nsender always sends waaay more than necessary, and gives the receiver a\none-time payment identifier, requiring that they route the remainder of\nthe funds *back* to them.\n\n\nTo solve this issue presently, we extend the header in Sphinx to include a\nper-hop payload which allows the sender to precisely dictate the\nstructure of the route, allows the intermediate nodes to authenticate the\ninformation given to it, and also allow the intermediate node to verify\nthat their policies have properly been respected. These payloads can also\nbe utilized by applications to communicate a small-ish amount of data to\nconstruct higher-level protocols on top of the system. Examples include:\ncross-chain swaps, chance payment games, higher-level B2B protocols,\nflavors of ZKCP's, media streaming, internet access proxying, etc.\n\n\n>From my point-of-view, when extended to LN, the core component of the\nprotocol (landmarks), becomes the weakest component. From my reading,\n*all* nodes need to be ware of an *identical* set of landmarks (more or\nless similar to the desired homogeneity of Gateways), otherwise the\ncoordinate embedding scheme breaks down. Currently, there's no requirement\nthat all nodes have a globally consistent view of the network. So then an\nimportant questions arises: who choose the landmarks? A desirable property\nof a routing system for LN (IMO) is that is has close to zero required\ninitial set up by a central administrator. With this protocol, it would\nseem that all nodes much ship with a hard coded set of global landmarks\nfor the path finding to succeed.  This itself pins a hard coordination\nrequirement amongst implementers to have something like this deployed.\nEven ignoring this requirement for a minute, I see several other\ndownsides:\n\n   * As *all* payments must flow through landmarks (since nodes break up\n     their payment into L sub-flows), the landmarks must be very, very\n     well capitalized. This would cause strong consolidation of the\n     selection of landmarks, as they need extremely large channels in\n     order to facilitate transfer within the network.\n\n   * As landmarks must be globally known, this it seems this would\n     introduce fragility in the network. If most of the landmarks go down\n     (fails stop crashes) due to hardware issues, DoS, exploited bugs,\n     etc, then the network's throughput instantly becomes crippled.\n\n   * If all payment flow *must* go through landmarks, and the transfers\n     within the network are relatively uni-directional (all payment going\n     to Candy Crush Ultra: Lighting Strikes Twice), then their\n     channels would become unbalanced very quickly.\n\n\nThe last point there invokes another component of the network: passive\nchannel rebalancing. With source routing, it's possible for nodes to\npassive rebalance their channels, in order to keep the in equilibrium,\nsuch that on average they'll be able to handle a payment flow coming from\nany direction. This is possible as with source routing, it's easy for a\nnode to simply send a payment to himself incoming/outgoing from the pair\nof channels they wish to adjust the available flow of. With\ndistance-vector-like protocols, this doesn't seem possible, as the node\ndoesn't have any control of the incoming channel that the payment will\narrive on.\n\n\nFinally, the notion of value privacy within the scheme seems a bit weak.\n>From this definition, any protocol that didn't broadcast intents to send\npayments to the world would achieve this trait. The base Bitcoin\nblockchain doesn't mask the values of transfers (yet), but even if it did\nunconditionally maintaining value privacy of channel doesn't seem\ncompatible with multi-hop payment networks (nodes can simply perform\nprobing/tagging attacks to ascertain a range of the size of a channel). A\npossible mitigation would be for nodes to probabilistically drop incoming\npayments, with all nodes sampling from the same distribution. However,\nthis would dramatically increase routing failures by senders, removing the\n\"low-latency\" trait of payment networks that many find desirable.\n\n\nPersonally, I've very excited to see additional research on the front of\nrouting within the network! Excellent work by all authors.\n\n\nIn the end, I don't think it'll be a one-size fits all solution, as each\nrouting protocol delivers with it a set of tradeoffs that should be\nweighed depending on target characteristics, and use-cases. There's no\nstrong requirement that the network as a whole uses a *single* routing\nprotocol. Instead several distinct protocols can be deployed based on\nuse-case requirements, as we only need to share a single end-to-end\nconstruct: the HTLC. I could see a future in a few years where we have\nseveral deployed protocols, similar to the wide array of existing routing\nprotocols deployed on the Internet. What we have currently gets us from\nZero to One. We'll definitely need to experiment with additional\napproaches as the size of the network grows, and the true economic flow\npatterns emerge after we all deploy to mainnet.\n\n\n-- Laolu\n\n\n_______________________________________________\nLightning-dev mailing list\nLightning-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/lightning-dev\n\n\n\n\n-- \n- Bryan\nhttp://heybryan.org/\n1 512 203 0507\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171125/19c39055/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Fwd: General question on routing difficulties",
            "categories": [
                "bitcoin-dev",
                "Lightning-dev"
            ],
            "authors": [
                "Bryan Bishop"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 10914
        }
    },
    {
        "title": "[bitcoin-dev] Block compression",
        "thread_messages": [
            {
                "author": "Jeff Johnson",
                "date": "2017-11-27T02:11:27",
                "message_text_only": "I'm new to this mailing list and apologize if this has been suggested\nbefore. I was directed from the Bitcoin core github to this mailing list\nfor suggestions.\n\nI'd just like to post a possible solution that increases the amount of data\nin a block without actually increasing the size on disk or the size in\nmemory or the size transmitted over the Internet. Simply applying various\ncompression algorithms, I was able to achieve about a 50% compression\nratio. Here are my findings on a recent Bitcoin block using max compression\nfor all methods:\n\nRaw block\n998,198 bytes\n\nGzip\n521,212 bytes (52% ratio)\n(needs 2MB to decompress).\n\nLZMA\n415,308 bytes (41% ratio)\n(1MB dictionary, needs 3MB to decompress)\n\n- ZStandard: 469,179 bytes (47% ratio)\n(1MB memory to decompress)\n\n- LZ4: 641,063 bytes (64% ratio)\n(32-64K to decompress)\n\nThe compression time on my modest laptop (2 years old) was \"instant\". I ran\nall from the command line and did not notice any lag as I pressed enter to\ndo the compression, so easily less than a second. But compression time\ndoesn't matter, decompression time is what matters as blocks will be\ndecompressed billions of times more than they will be compressed.\nDecompression speed for LZ4 is the fastest of the above methods, at 3.3GB /\nsecond, slightly less than half the speed of memcpy, see char at (\nhttps://github.com/lz4/lz4).\n\nIf decompression speed, CPU and memory usage is a concern, LZ4 is a no\nbrainer. You basically get a 33% larger block size for \"free\". But\nZStandard, in my opinion, makes the most sense as it offers greater than\n50% compression ratio with a very good decompression ratio of 900MB /\nsecond.\n\nIf this were implemented in the Bitcoin protocol, there would need to be a\nplace to specify the compression type in a set of bits somewhere, so that\nfuture compression algorithms could potentially be added.\n\nMiners could do nothing and keep sending blocks as is, and these blocks\nwould have \"no compression\" as the type of compression, just as today. Or\nthey could opt in to compress blocks and choose how many transactions they\nwant to stuff into the block, keeping the compressed size under the limit.\n\nThe bitcoin client code would also need to be able to handle the\nappropriate compression bits, and limits of signature data, etc. modified\nto deal with the compression.\n\nI understand schnorr signatures are on the roadmap as a 25% compression\ngain which is great, I suspect that schnorr signatures would compress even\nfurther when compressed with the above compression methods.\n\nHere is a link to the block that I compressed:\nhttps://mega.nz/#!YPIF2KTa!4FxxLvqzjqIftrkhXwSC2h4G4Dolk8dLteNUolEtq98\n\nThanks for reading, best wishes to all.\n\n-- Jeff Johnson\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171126/41009558/attachment.html>"
            },
            {
                "author": "Marco Pontello",
                "date": "2017-11-27T12:08:05",
                "message_text_only": "Hi Jeff!\n\n\nOn Mon, Nov 27, 2017 at 3:11 AM, Jeff Johnson via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n\n> Raw block\n> 998,198 bytes\n>\n> Gzip\n> 521,212 bytes (52% ratio)\n> (needs 2MB to decompress).\n>\n\nI don't know how you got that raw block, but it seems a bit odd.\nIf you look at it in an hex editor, you'll notice that every odd byte is 0,\nand that explain the unusual high compression ratio.\n\nBye!\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171127/4d19aa95/attachment.html>"
            },
            {
                "author": "Jonas Schnelli",
                "date": "2017-11-27T20:49:07",
                "message_text_only": "Hi Jeff\n\nThere where previous discussions about similar approaches [1] [2].\n\nI\u2019m not sure if compression should be built into the protocol.\nMy humble understanding of it, is, that it should be built into different layers.\n\nIf bandwidth is a concern, then on the fly gzip compression like apaches mod_deflate could be something. But I expect fast propagation is often more important then a ~30% bandwidth reduction.\nBandwidth may be a concern for historical blocks transmission. If you continue the proposal, I think you should focus on historical blocks.\n\nIf disk space is a concern, then the database layer should handle the compression.\n\nThanks\n\u2014\n</jonas>\n\n\n[1] https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-November/011692.html <https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-November/011692.html>\n[2] https://github.com/bitcoin/bitcoin/pull/6973 <https://github.com/bitcoin/bitcoin/pull/6973>\n\n\n\n> Am 26.11.2017 um 16:11 schrieb Jeff Johnson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>:\n> \n> I'm new to this mailing list and apologize if this has been suggested before. I was directed from the Bitcoin core github to this mailing list for suggestions.\n> \n> I'd just like to post a possible solution that increases the amount of data in a block without actually increasing the size on disk or the size in memory or the size transmitted over the Internet. Simply applying various compression algorithms, I was able to achieve about a 50% compression ratio. Here are my findings on a recent Bitcoin block using max compression for all methods:\n> \n> Raw block\n> 998,198 bytes\n> \n> Gzip\n> 521,212 bytes (52% ratio)\n> (needs 2MB to decompress).\n> \n> LZMA\n> 415,308 bytes (41% ratio)\n> (1MB dictionary, needs 3MB to decompress)\n> \n> - ZStandard: 469,179 bytes (47% ratio)\n> (1MB memory to decompress)\n> \n> - LZ4: 641,063 bytes (64% ratio)\n> (32-64K to decompress)\n> \n> The compression time on my modest laptop (2 years old) was \"instant\". I ran all from the command line and did not notice any lag as I pressed enter to do the compression, so easily less than a second. But compression time doesn't matter, decompression time is what matters as blocks will be decompressed billions of times more than they will be compressed. Decompression speed for LZ4 is the fastest of the above methods, at 3.3GB / second, slightly less than half the speed of memcpy, see char at (https://github.com/lz4/lz4 <https://github.com/lz4/lz4>).\n> \n> If decompression speed, CPU and memory usage is a concern, LZ4 is a no brainer. You basically get a 33% larger block size for \"free\". But ZStandard, in my opinion, makes the most sense as it offers greater than 50% compression ratio with a very good decompression ratio of 900MB / second.\n> \n> If this were implemented in the Bitcoin protocol, there would need to be a place to specify the compression type in a set of bits somewhere, so that future compression algorithms could potentially be added.\n> \n> Miners could do nothing and keep sending blocks as is, and these blocks would have \"no compression\" as the type of compression, just as today. Or they could opt in to compress blocks and choose how many transactions they want to stuff into the block, keeping the compressed size under the limit.\n> \n> The bitcoin client code would also need to be able to handle the appropriate compression bits, and limits of signature data, etc. modified to deal with the compression.\n> \n> I understand schnorr signatures are on the roadmap as a 25% compression gain which is great, I suspect that schnorr signatures would compress even further when compressed with the above compression methods.\n> \n> Here is a link to the block that I compressed: https://mega.nz/#!YPIF2KTa!4FxxLvqzjqIftrkhXwSC2h4G4Dolk8dLteNUolEtq98 <https://mega.nz/#!YPIF2KTa!4FxxLvqzjqIftrkhXwSC2h4G4Dolk8dLteNUolEtq98>\n> \n> Thanks for reading, best wishes to all.\n> \n> -- Jeff Johnson\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171127/59a99830/attachment.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: Message signed with OpenPGP\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171127/59a99830/attachment.sig>"
            }
        ],
        "thread_summary": {
            "title": "Block compression",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Marco Pontello",
                "Jonas Schnelli",
                "Jeff Johnson"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 8071
        }
    },
    {
        "title": "[bitcoin-dev] \u7b54\u590d:  Block compression",
        "thread_messages": [
            {
                "author": "lonsdale aseaday",
                "date": "2017-11-27T02:32:04",
                "message_text_only": "Hi, Block compression brings some problems witch need to check and you can visit:\nhttps://bitcointalk.org/index.php?topic=88208.0 and https://bitcointalk.org/index.php?topic=204283.0\n\n________________________________________\n\u53d1\u4ef6\u4eba: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> \u4ee3\u8868 Jeff Johnson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\n\u53d1\u9001\u65f6\u95f4: 2017\u5e7411\u670827\u65e5 10:11\n\u6536\u4ef6\u4eba: bitcoin-dev at lists.linuxfoundation.org\n\u4e3b\u9898: [bitcoin-dev] Block compression\n\nI'm new to this mailing list and apologize if this has been suggested before. I was directed from the Bitcoin core github to this mailing list for suggestions.\n\nI'd just like to post a possible solution that increases the amount of data in a block without actually increasing the size on disk or the size in memory or the size transmitted over the Internet. Simply applying various compression algorithms, I was able to achieve about a 50% compression ratio. Here are my findings on a recent Bitcoin block using max compression for all methods:\n\nRaw block\n998,198 bytes\n\nGzip\n521,212 bytes (52% ratio)\n(needs 2MB to decompress).\n\nLZMA\n415,308 bytes (41% ratio)\n(1MB dictionary, needs 3MB to decompress)\n\n- ZStandard: 469,179 bytes (47% ratio)\n(1MB memory to decompress)\n\n- LZ4: 641,063 bytes (64% ratio)\n(32-64K to decompress)\n\nThe compression time on my modest laptop (2 years old) was \"instant\". I ran all from the command line and did not notice any lag as I pressed enter to do the compression, so easily less than a second. But compression time doesn't matter, decompression time is what matters as blocks will be decompressed billions of times more than they will be compressed. Decompression speed for LZ4 is the fastest of the above methods, at 3.3GB / second, slightly less than half the speed of memcpy, see char at (https://github.com/lz4/lz4).\n\nIf decompression speed, CPU and memory usage is a concern, LZ4 is a no brainer. You basically get a 33% larger block size for \"free\". But ZStandard, in my opinion, makes the most sense as it offers greater than 50% compression ratio with a very good decompression ratio of 900MB / second.\n\nIf this were implemented in the Bitcoin protocol, there would need to be a place to specify the compression type in a set of bits somewhere, so that future compression algorithms could potentially be added.\n\nMiners could do nothing and keep sending blocks as is, and these blocks would have \"no compression\" as the type of compression, just as today. Or they could opt in to compress blocks and choose how many transactions they want to stuff into the block, keeping the compressed size under the limit.\n\nThe bitcoin client code would also need to be able to handle the appropriate compression bits, and limits of signature data, etc. modified to deal with the compression.\n\nI understand schnorr signatures are on the roadmap as a 25% compression gain which is great, I suspect that schnorr signatures would compress even further when compressed with the above compression methods.\n\nHere is a link to the block that I compressed: https://mega.nz/#!YPIF2KTa!4FxxLvqzjqIftrkhXwSC2h4G4Dolk8dLteNUolEtq98\n\nThanks for reading, best wishes to all.\n\n-- Jeff Johnson"
            }
        ],
        "thread_summary": {
            "title": "\u7b54\u590d:  Block compression",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "lonsdale aseaday"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3217
        }
    },
    {
        "title": "[bitcoin-dev] BIP Idea: Marginal Pricing",
        "thread_messages": [
            {
                "author": "William Morriss",
                "date": "2017-11-30T00:47:43",
                "message_text_only": "Comrades,\n\nLong term, tx fees must support hash power by themselves. The following is\nan economic approach to maximize total fee collection, and therefore\nhashpower.\n\n*Goals*\nMaximize total transaction fees\nReduce pending transaction time\nReduce individual transaction fees\n\n*Challenges*\nValidators must agree on the maximum block size, else miners can cheat and\ninclude extra transactions.\nAllowing too many transactions per block will increase the cost of the\nmining without collecting much income for the network.\n\n\n*Problem*\nIn the transaction market, users are the demand curve, because they will\ntransact less when fees are higher, and prefer altcoins. The block size is\nthe supply curve, because it represents miners' willingness to accept\ntransactions.\nCurrently, the supply curve is inelastic:\n\n\u200bIncreasing the block size will not affect the inelasticity for any fixed\nblock size. The downsides of a fixed block size limit are well-known:\n- Unpredictable transaction settlement time\n- Variable transaction fees depending on network congestion\n- Frequent overpay\n\n*Proposal*\n1. Miners implicitly choose the market sat/byte rate with the cheapest-fee\ntransaction included in their block. Excess transaction fees are refunded\nto the inputs.\n2. Remove the block size limit, which is no longer necessary.\n\n*Benefits*\n- Dynamic block size limit regulated by profit motive\n- Transaction fees maximized for every block\n- No overpay; all fees are fair\n\n\u200bMiners individually will make decisions to maximize their block-reward\nprofit.\nMiners are incentivized to ignore low-fee transactions because they would\nshave the profits of their other transactions and increase their hash time.\nUsers and services are free to bid higher transaction fees in order to\nreach the next block, since their excess bid will be refunded.\n\nThe block size limit was added as a spam-prevention measure, but in order\nfor an attacker to spam the network with low-fee transactions, they would\nhave to offset the marginal cost of reducing the price with their own\ntransaction fees. Anti-spam is thus built into the marginal system without\nthe need for an explicit limit.\n\nRarely, sections of the backlog would become large enough to be profitable.\nThis means every so many blocks, lower-fee transactions would be included\nen masse after having been ignored long enough. Low-fee transactions thus\ngain a liveness property not previously enjoyed: low-fee transactions will\neventually confirm. Miners targeting these transactions would be at a\nnoteworthy disadvantage because they would be hashing a larger block. I\npredict that this scheme would result in two markets: a backlog market and\na real-time market. Users targeting the backlog market would match the\nprice of the largest backlog section in order to be included in the next\nbacklog block.\n\n*Examples*\n\nScenario 1\nSat/byte Bytes Reward\n400 500000 200000000\n300 700000 210000000\n200 1000000 200000000\n100 1500000 150000000\n50 5000000 250000000\n20 10000000 200000000\nA miner would create a 5MB block and receive 0.25 BTC\n\nScenario 2\nSat/byte Bytes Reward\n400 600000 240000000\n300 700000 210000000\n200 1000000 200000000\n100 1800000 180000000\n50 4000000 200000000\n20 10000000 200000000\nA miner would create a 600KB block and receive 0.24 BTC\n\nThanks,\nWilliam Morriss\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171129/96ea6877/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: fixedblocksize.png\nType: image/png\nSize: 18199 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171129/96ea6877/attachment-0003.png>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: fixedblocksize.png\nType: image/png\nSize: 18199 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171129/96ea6877/attachment-0004.png>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: marginal.png\nType: image/png\nSize: 21403 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171129/96ea6877/attachment-0005.png>"
            },
            {
                "author": "Ben Kloester",
                "date": "2017-11-30T02:38:25",
                "message_text_only": "Something similar to this has been proposed  in this article by Ron Lavi,\nOr Sattath, and Aviv Zohar, and discussed in this bitcoin-dev thread\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-September/015093.html\n\nThey only discussed changing the fee structure, not removing the block size\nlimit, as far as I know.\n\n    \"Redesigning Bitcoin's fee market\"\n    https://arxiv.org/abs/1709.08881\n\n\n\n*Ben Kloester*\n\nOn 30 November 2017 at 11:47, William Morriss via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Comrades,\n>\n> Long term, tx fees must support hash power by themselves. The following is\n> an economic approach to maximize total fee collection, and therefore\n> hashpower.\n>\n> *Goals*\n> Maximize total transaction fees\n> Reduce pending transaction time\n> Reduce individual transaction fees\n>\n> *Challenges*\n> Validators must agree on the maximum block size, else miners can cheat and\n> include extra transactions.\n> Allowing too many transactions per block will increase the cost of the\n> mining without collecting much income for the network.\n>\n>\n> *Problem*\n> In the transaction market, users are the demand curve, because they will\n> transact less when fees are higher, and prefer altcoins. The block size is\n> the supply curve, because it represents miners' willingness to accept\n> transactions.\n> Currently, the supply curve is inelastic:\n>\n> \u200bIncreasing the block size will not affect the inelasticity for any fixed\n> block size. The downsides of a fixed block size limit are well-known:\n> - Unpredictable transaction settlement time\n> - Variable transaction fees depending on network congestion\n> - Frequent overpay\n>\n> *Proposal*\n> 1. Miners implicitly choose the market sat/byte rate with the cheapest-fee\n> transaction included in their block. Excess transaction fees are refunded\n> to the inputs.\n> 2. Remove the block size limit, which is no longer necessary.\n>\n> *Benefits*\n> - Dynamic block size limit regulated by profit motive\n> - Transaction fees maximized for every block\n> - No overpay; all fees are fair\n>\n> \u200bMiners individually will make decisions to maximize their block-reward\n> profit.\n> Miners are incentivized to ignore low-fee transactions because they would\n> shave the profits of their other transactions and increase their hash time.\n> Users and services are free to bid higher transaction fees in order to\n> reach the next block, since their excess bid will be refunded.\n>\n> The block size limit was added as a spam-prevention measure, but in order\n> for an attacker to spam the network with low-fee transactions, they would\n> have to offset the marginal cost of reducing the price with their own\n> transaction fees. Anti-spam is thus built into the marginal system without\n> the need for an explicit limit.\n>\n> Rarely, sections of the backlog would become large enough to be\n> profitable. This means every so many blocks, lower-fee transactions would\n> be included en masse after having been ignored long enough. Low-fee\n> transactions thus gain a liveness property not previously enjoyed: low-fee\n> transactions will eventually confirm. Miners targeting these transactions\n> would be at a noteworthy disadvantage because they would be hashing a\n> larger block. I predict that this scheme would result in two markets: a\n> backlog market and a real-time market. Users targeting the backlog market\n> would match the price of the largest backlog section in order to be\n> included in the next backlog block.\n>\n> *Examples*\n>\n> Scenario 1\n> Sat/byte Bytes Reward\n> 400 500000 200000000\n> 300 700000 210000000\n> 200 1000000 200000000\n> 100 1500000 150000000\n> 50 5000000 250000000\n> 20 10000000 200000000\n> A miner would create a 5MB block and receive 0.25 BTC\n>\n> Scenario 2\n> Sat/byte Bytes Reward\n> 400 600000 240000000\n> 300 700000 210000000\n> 200 1000000 200000000\n> 100 1800000 180000000\n> 50 4000000 200000000\n> 20 10000000 200000000\n> A miner would create a 600KB block and receive 0.24 BTC\n>\n> Thanks,\n> William Morriss\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/a56fd415/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: fixedblocksize.png\nType: image/png\nSize: 18199 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/a56fd415/attachment-0003.png>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: marginal.png\nType: image/png\nSize: 21403 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/a56fd415/attachment-0004.png>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: fixedblocksize.png\nType: image/png\nSize: 18199 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/a56fd415/attachment-0005.png>"
            },
            {
                "author": "William Morriss",
                "date": "2017-11-30T06:13:15",
                "message_text_only": "On Wed, Nov 29, 2017 at 6:38 PM, Ben Kloester <benkloester at gmail.com> wrote:\n\n> Something similar to this has been proposed  in this article by Ron Lavi,\n> Or Sattath, and Aviv Zohar, and discussed in this bitcoin-dev thread\n> https://lists.linuxfoundation.org/pipermail/bitcoin-\n> dev/2017-September/015093.html\n>\n> They only discussed changing the fee structure, not removing the block\n> size limit, as far as I know.\n>\n>     \"Redesigning Bitcoin's fee market\"\n>     https://arxiv.org/abs/1709.08881\n>\n> *Ben Kloester*\n>\n\nThanks. Marginal pricing is equivalent to the \"Monopolistic Price\nMechanism\" discussed in https://arxiv.org/abs/1709.08881. The mechanism is\nthe same, including the block size adjustment, but as you noted the prior\ndiscussion only concerns the fee structure.\n\nIt looks like the prior proposal broke down because of Peter Todd's concern\nwith out-of-band payments (https://lists.linuxfoundation.org/pipermail/\nbitcoin-dev/2017-September/015103.html). Restated, miners can circumvent\nthe system through out of band payments. Mark Friedenbach argues that\nout-of-band payments are penalized in part because the end-user could have\njust as easily bid higher instead of paying OOB. Peter Todd argues that a\nminer could mine only out-of-band transactions. Such transactions could\nhave no on-chain fees and thus be disregarded by other miners.\n\nI believe this OOB scenario is imaginary. Either it would be more\nprofitable for a miner to mine fairly, or cheaper for the end-user to pay\nthe fee in-band. Consider MINFEE to the the effective fee paid for the\nblock mined by the OOB-incentivized miner. Consider MARKFEE to the the\nmarket fee collected by non-OOB-incentivized miners. Call the OOB effective\ntx fee OOB. Then,\nFor a user to prefer OOB: MINFEE+OOB<MARKFEE\nFor a miner to prefer OOB: MINFEE+OOB>MARKFEE\nIt is impossible for both scenarios to be true. As previously argued by\nMark Friedenbach, the system disincentivizes OOB tx fees.\n\nI don't think there is any more centralization pressure with marginal fees\nthan before. What prevents miners from colluding to move tx fees OOB is the\nvalue of the on-band pending tx fees. The hashpower of individual miners is\nnot impressive compared to the entire network, so individual miners could\nnot offer a service to speed up confirmation that would be superior to\nsimply doing a RBP. OOB fees are perhaps a symptom of the current setup,\nwherein there is no penalty for arbitrarily favoring individual\ntransactions with lower fees.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171129/e53585b8/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2017-11-30T11:40:54",
                "message_text_only": "On Thu, Nov 30, 2017 at 6:13 AM, William Morriss via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> I believe this OOB scenario is imaginary. Either it would be more profitable\n\nOut of band fees are a reality even today-- and have for most of\nBitcoin's life--, without a system that has any particular incentive\nfor them.\n\n> for a miner to mine fairly, or cheaper for the end-user to pay the fee\n> in-band. Consider MINFEE to the the effective fee paid for the block mined\n> by the OOB-incentivized miner. Consider MARKFEE to the the market fee\n> collected by non-OOB-incentivized miners. Call the OOB effective tx fee OOB.\n> Then,\n> For a user to prefer OOB: MINFEE+OOB<MARKFEE\n> For a miner to prefer OOB: MINFEE+OOB>MARKFEE\n> It is impossible for both scenarios to be true. As previously argued by Mark\n> Friedenbach, the system disincentivizes OOB tx fees.\n\nThis kind of analysis seems to imagine that a single decision maker is\nmaking a globally optimal decision and that also people are somehow\nforced to only make one choice. Both are untrue in this case (and most\nother economic circumstances). Instead, participants can take the best\nof multiple choices and will often act locally for their own best\ninterest even when it reduces revenue for their industry in total.\n\nConcretely: as a user with competent wallet software, I would be\nautomatically drafting two transactions-- one paying OOB and one\npaying min fee, at equivalent expected rates.  Miners would construct\nblocks which locally maximized their revenue.   It is far from clear\nthat use of the minfee scheme is an equilibrium-- in fact I think it\nis clearly not an equilibrium: a user that writes both transactions\nwill always pay equal or less fees for the transactions where they do\nboth (even if all users doing this causes users collectively to pay\nhigher fees), a miner who considers both will always make equal or\ngreater fee income on a block by block basis (even if it lowers miner\nincome collectively when all do this).\n\n(If it were in fact preferred by users and miners alike: why doesn't\nit already exist?  Since the existence of OOB fees cannot be\neliminated, as far as we know, any use of MINFEE would be inherently\nvoluntary-- so in one sense we already 'have' voluntary minfee, but no\none uses it.)\n\n\nIgnoring the possibility of evasion, there are some other concerns\nthat you might want to consider:\n\nI believe the idea converts variance in fee willingness into variance\nin capacity for the network.  If rich uncle bill wants to waste money\nwith uneconomically high fees, with a constant flow of transactions,\nhe'll effectively knock out a large number of participants.  You could\nargue that bill could spend those same fees in spam to displace the\nsame amount of transactions while also using more capacity; but I\nUncleBill isn't trying to attack the capacity of the system. It's just\ncollateral damage.  I worry also about related strategies that arise\nin that world: For example, lets imagine that world consisted of a\ncouple unclebill who will pay high fees, and the unwashed masses that\nwill not and pay a much lower consistent feerate.   Honest conformance\nwith your protocol would result in miners either processing only the\nUncleBill txn or processing all of them at the lower rate, whichever\nis more profitable.  Super-rational behavior might be for a majority\nof hashpower to collude to only permit high fee-rate transactions\nevery other block and only permit low feerate in the others, and then\nthe network processes all unclebills in one block (at full rate), and\nall the unwashed in the others.  From a fee perspective it arguably\nisn't any worse than today, but I believe it significantly handicaps\nyour capacity limiting argument.\n\n> wherein there is no penalty for arbitrarily favoring individual transactions with lower fees\n\nNor does a MINFEE system; since the user can near costlessly construct\nas many variations of their transaction as they like.\n\n> The hashpower of individual miners is not impressive compared to the entire network,\n\nThat is unfortunately not the reality of Bitcoin today."
            },
            {
                "author": "Eric Voskuil",
                "date": "2017-11-30T12:03:30",
                "message_text_only": "On 11/29/2017 10:13 PM, William Morriss via bitcoin-dev wrote:\n> On Wed, Nov 29, 2017 at 6:38 PM, Ben Kloester <benkloester at gmail.com\n> <mailto:benkloester at gmail.com>> wrote:\n> \n>     Something similar to this has been proposed  in this article by Ron\n>     Lavi, Or Sattath, and Aviv Zohar, and discussed in this bitcoin-dev\n>     thread https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-September/015093.html\n> \n>     They only discussed changing the fee structure, not removing the\n>     block size limit, as far as I know.\n> \n>         \"Redesigning Bitcoin's fee market\"\n>         https://arxiv.org/abs/1709.08881 <https://arxiv.org/abs/1709.08881>\n> \n>     *Ben Kloester*\n> \n> Thanks. Marginal pricing is equivalent to the \"Monopolistic Price\n> Mechanism\" discussed in https://arxiv.org/abs/1709.08881\n> The mechanism is the same, including\n> the block size adjustment, but as you noted the prior discussion only\n> concerns the fee structure.\n> \n> It looks like the prior proposal broke down because of Peter Todd's\n> concern with out-of-band payments\n> (https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-September/015103.html).\n> Restated, miners can circumvent the system through out of band payments.\n> Mark Friedenbach argues that out-of-band payments are penalized in part\n> because the end-user could have just as easily bid higher instead of\n> paying OOB. Peter Todd argues that a miner could mine only out-of-band\n> transactions. Such transactions could have no on-chain fees and thus be\n> disregarded by other miners.\n> \n> I believe this OOB scenario is imaginary. Either it would be more\n> profitable for a miner to mine fairly, or cheaper for the end-user to\n> pay the fee in-band. \n> Consider MINFEE to the the effective fee paid for\n> the block mined by the OOB-incentivized miner. Consider MARKFEE to the\n> the market fee collected by non-OOB-incentivized miners. Call the OOB\n> effective tx fee OOB. Then,\n> For a user to prefer OOB: MINFEE+OOB<MARKFEE\n> For a miner to prefer OOB: MINFEE+OOB>MARKFEE\n> It is impossible for both scenarios to be true. As previously argued by\n> Mark Friedenbach, the system disincentivizes OOB tx fees.\n\nBitcoin is neutral on how miners are paid. The benefit of on-chain fee\npayment is that a fee can be paid with no communication between the\nminer and the merchant, preserving anonymity. It also serves as a\nconvenience that anonymous fees are published, as it provides a basis\nfor anonymous fee estimation. There is no centralization pressure that\narises from side fees.\n\nhttps://github.com/libbitcoin/libbitcoin/wiki/Side-Fee-Fallacy\n\n> I don't think there is any more centralization pressure with marginal\n> fees than before. What prevents miners from colluding to move tx fees\n> OOB is the value of the on-band pending tx fees. The hashpower of\n> individual miners is not impressive compared to the entire network, so\n> individual miners could not offer a service to speed up confirmation\n> that would be superior to simply doing a RBP. OOB fees are perhaps a\n> symptom of the current setup, wherein there is no penalty for\n> arbitrarily favoring individual transactions with lower fees.\n\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/2e64e116/attachment.sig>"
            },
            {
                "author": "Federico Tenga",
                "date": "2017-11-30T09:37:57",
                "message_text_only": "The main issue that I see with this proposal is that miners can still spam\nthe network for free even with high sat/byte fee levels. They can first\nchoose the sat/byte rate that maximize their profit, and then include a lot\nof spam transactions at that rate that will only pay fees to themselves,\neffectively spamming the chain for free and increasing the cost of running\na node.\n\nOn 30 Nov 2017 03:40, \"Ben Kloester via bitcoin-dev\" <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\nSomething similar to this has been proposed  in this article by Ron Lavi,\nOr Sattath, and Aviv Zohar, and discussed in this bitcoin-dev thread\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-September/\n015093.html\n\nThey only discussed changing the fee structure, not removing the block size\nlimit, as far as I know.\n\n    \"Redesigning Bitcoin's fee market\"\n    https://arxiv.org/abs/1709.08881\n\n\n\n*Ben Kloester*\n\nOn 30 November 2017 at 11:47, William Morriss via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Comrades,\n>\n> Long term, tx fees must support hash power by themselves. The following is\n> an economic approach to maximize total fee collection, and therefore\n> hashpower.\n>\n> *Goals*\n> Maximize total transaction fees\n> Reduce pending transaction time\n> Reduce individual transaction fees\n>\n> *Challenges*\n> Validators must agree on the maximum block size, else miners can cheat and\n> include extra transactions.\n> Allowing too many transactions per block will increase the cost of the\n> mining without collecting much income for the network.\n>\n>\n> *Problem*\n> In the transaction market, users are the demand curve, because they will\n> transact less when fees are higher, and prefer altcoins. The block size is\n> the supply curve, because it represents miners' willingness to accept\n> transactions.\n> Currently, the supply curve is inelastic:\n>\n> \u200bIncreasing the block size will not affect the inelasticity for any fixed\n> block size. The downsides of a fixed block size limit are well-known:\n> - Unpredictable transaction settlement time\n> - Variable transaction fees depending on network congestion\n> - Frequent overpay\n>\n> *Proposal*\n> 1. Miners implicitly choose the market sat/byte rate with the cheapest-fee\n> transaction included in their block. Excess transaction fees are refunded\n> to the inputs.\n> 2. Remove the block size limit, which is no longer necessary.\n>\n> *Benefits*\n> - Dynamic block size limit regulated by profit motive\n> - Transaction fees maximized for every block\n> - No overpay; all fees are fair\n>\n> \u200bMiners individually will make decisions to maximize their block-reward\n> profit.\n> Miners are incentivized to ignore low-fee transactions because they would\n> shave the profits of their other transactions and increase their hash time.\n> Users and services are free to bid higher transaction fees in order to\n> reach the next block, since their excess bid will be refunded.\n>\n> The block size limit was added as a spam-prevention measure, but in order\n> for an attacker to spam the network with low-fee transactions, they would\n> have to offset the marginal cost of reducing the price with their own\n> transaction fees. Anti-spam is thus built into the marginal system without\n> the need for an explicit limit.\n>\n> Rarely, sections of the backlog would become large enough to be\n> profitable. This means every so many blocks, lower-fee transactions would\n> be included en masse after having been ignored long enough. Low-fee\n> transactions thus gain a liveness property not previously enjoyed: low-fee\n> transactions will eventually confirm. Miners targeting these transactions\n> would be at a noteworthy disadvantage because they would be hashing a\n> larger block. I predict that this scheme would result in two markets: a\n> backlog market and a real-time market. Users targeting the backlog market\n> would match the price of the largest backlog section in order to be\n> included in the next backlog block.\n>\n> *Examples*\n>\n> Scenario 1\n> Sat/byte Bytes Reward\n> 400 500000 200000000\n> 300 700000 210000000\n> 200 1000000 200000000\n> 100 1500000 150000000\n> 50 5000000 250000000\n> 20 10000000 200000000\n> A miner would create a 5MB block and receive 0.25 BTC\n>\n> Scenario 2\n> Sat/byte Bytes Reward\n> 400 600000 240000000\n> 300 700000 210000000\n> 200 1000000 200000000\n> 100 1800000 180000000\n> 50 4000000 200000000\n> 20 10000000 200000000\n> A miner would create a 600KB block and receive 0.24 BTC\n>\n> Thanks,\n> William Morriss\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/f185452e/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: fixedblocksize.png\nType: image/png\nSize: 18199 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/f185452e/attachment-0003.png>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: fixedblocksize.png\nType: image/png\nSize: 18199 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/f185452e/attachment-0004.png>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: marginal.png\nType: image/png\nSize: 21403 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/f185452e/attachment-0005.png>"
            },
            {
                "author": "Chenxi Cai",
                "date": "2017-11-30T05:52:24",
                "message_text_only": "Hi All,\n\n\nAuction theory is a well-studied problem in the economics literature. Currently what bitcoin has is Generalized first-price auction, where winning bidders pay their full bids. Alternatively, two approaches are potentially viable, which are Generalized second-price auction and Vickrey\u2013Clarke\u2013Groves auction. Generalized second-price auction, where winning bidders pay their next highest bids, reduces (but not eliminate) the need for bidders to strategize by allowing them to bid closer to their reservation price. Vickrey\u2013Clarke\u2013Groves auction, a more sophisticated system that considers all bids in relation to one another, elicit truthful bids from bidders, but may not maximize miners' fees as the other two systems will.\n\n\nDue to one result called Revenue Equivalence, the choice of fee design will not impact miners' fees unless the outcomes of the auction changes (i.e, the highest bidders do not always win). In addition, the sole benefit of second-price auction over first-price auction is to spare people's mental troubles from strategizing, rather than actually saving mining fees, because in equilibrium the fees bidders pay remain the same. Therefore, in balance, I do not see substantial material benefits arising from switching to a different fee schedule.\n\n\nBest,\n\nChenxi Cai\n\n\n________________________________\nFrom: bitcoin-dev-bounces at lists.linuxfoundation.org <bitcoin-dev-bounces at lists.linuxfoundation.org> on behalf of William Morriss via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org>\nSent: Wednesday, November 29, 2017 5:47 PM\nTo: bitcoin-dev at lists.linuxfoundation.org\nSubject: [bitcoin-dev] BIP Idea: Marginal Pricing\n\nComrades,\n\nLong term, tx fees must support hash power by themselves. The following is an economic approach to maximize total fee collection, and therefore hashpower.\n\nGoals\nMaximize total transaction fees\nReduce pending transaction time\nReduce individual transaction fees\n\nChallenges\nValidators must agree on the maximum block size, else miners can cheat and include extra transactions.\nAllowing too many transactions per block will increase the cost of the mining without collecting much income for the network.\n\nProblem\nIn the transaction market, users are the demand curve, because they will transact less when fees are higher, and prefer altcoins. The block size is the supply curve, because it represents miners' willingness to accept transactions.\nCurrently, the supply curve is inelastic:\n[cid:ii_jalpxsnl1_1600a3d9def1eaff]\nIncreasing the block size will not affect the inelasticity for any fixed block size. The downsides of a fixed block size limit are well-known:\n- Unpredictable transaction settlement time\n- Variable transaction fees depending on network congestion\n- Frequent overpay\n\nProposal\n1. Miners implicitly choose the market sat/byte rate with the cheapest-fee transaction included in their block. Excess transaction fees are refunded to the inputs.\n2. Remove the block size limit, which is no longer necessary.\n\nBenefits\n- Dynamic block size limit regulated by profit motive\n- Transaction fees maximized for every block\n- No overpay; all fees are fair\n[cid:ii_jalqir4g2_1600a4c89811347a]\nMiners individually will make decisions to maximize their block-reward profit.\nMiners are incentivized to ignore low-fee transactions because they would shave the profits of their other transactions and increase their hash time.\nUsers and services are free to bid higher transaction fees in order to reach the next block, since their excess bid will be refunded.\n\nThe block size limit was added as a spam-prevention measure, but in order for an attacker to spam the network with low-fee transactions, they would have to offset the marginal cost of reducing the price with their own transaction fees. Anti-spam is thus built into the marginal system without the need for an explicit limit.\n\nRarely, sections of the backlog would become large enough to be profitable. This means every so many blocks, lower-fee transactions would be included en masse after having been ignored long enough. Low-fee transactions thus gain a liveness property not previously enjoyed: low-fee transactions will eventually confirm. Miners targeting these transactions would be at a noteworthy disadvantage because they would be hashing a larger block. I predict that this scheme would result in two markets: a backlog market and a real-time market. Users targeting the backlog market would match the price of the largest backlog section in order to be included in the next backlog block.\n\nExamples\n\nScenario 1\nSat/byte        Bytes   Reward\n400     500000  200000000\n300     700000  210000000\n200     1000000 200000000\n100     1500000 150000000\n50      5000000 250000000\n20      10000000        200000000\nA miner would create a 5MB block and receive 0.25 BTC\n\nScenario 2\nSat/byte        Bytes   Reward\n400     600000  240000000\n300     700000  210000000\n200     1000000 200000000\n100     1800000 180000000\n50      4000000 200000000\n20      10000000        200000000\nA miner would create a 600KB block and receive 0.24 BTC\n\nThanks,\nWilliam Morriss\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/1134178c/attachment-0001.html>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: fixedblocksize.png\nType: image/png\nSize: 18199 bytes\nDesc: fixedblocksize.png\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/1134178c/attachment-0003.png>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: fixedblocksize.png\nType: image/png\nSize: 18199 bytes\nDesc: fixedblocksize.png\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/1134178c/attachment-0004.png>\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: marginal.png\nType: image/png\nSize: 21403 bytes\nDesc: marginal.png\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/1134178c/attachment-0005.png>"
            },
            {
                "author": "William Morriss",
                "date": "2017-11-30T06:05:02",
                "message_text_only": "On Wed, Nov 29, 2017 at 9:52 PM, Chenxi Cai <Chenxi_Cai at live.com> wrote:\n\n> Hi All,\n>\n>\n> Auction theory is a well-studied problem in the economics literature.\n> Currently what bitcoin has is Generalized first-price auction, where\n> winning bidders pay their full bids. Alternatively, two approaches are\n> potentially viable, which are Generalized second-price auction and Vickrey\u2013Clarke\u2013Groves\n> auction. Generalized second-price auction, where winning bidders pay their\n> next highest bids, reduces (but not eliminate) the need for bidders to\n> strategize by allowing them to bid closer to their reservation\n> price. Vickrey\u2013Clarke\u2013Groves auction, a more sophisticated system that\n> considers all bids in relation to one another, elicit truthful bids from\n> bidders, but may not maximize miners' fees as the other two systems will.\n>\n>\n> Due to one result called Revenue Equivalence, the choice of fee design\n> will not impact miners' fees unless the outcomes of the auction changes\n> (i.e, the highest bidders do not always win). In addition, the sole benefit\n> of second-price auction over first-price auction is to spare people's\n> mental troubles from strategizing, rather than actually saving mining fees,\n> because in equilibrium the fees bidders pay remain the same. Therefore, in\n> balance, I do not see substantial material benefits arising from switching\n> to a different fee schedule.\n>\n>\n> Best,\n>\n> Chenxi Cai\n>\n>\nChanging the bidding system to the marginal price allows us to supersede\nthe block size limit, which changes the outcome of the auction, as\ndifferent transactions are included.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171129/e5fd0f84/attachment.html>"
            },
            {
                "author": "Gregory Maxwell",
                "date": "2017-11-30T09:12:48",
                "message_text_only": "This idea presumes that the protocol has any ability to regulate fees. I\nbelieve the locally optimal strategy for both miners and payers alike is to\naccept (pay) zero fees natively in the protocol and instead accept (pay)\ntheir actual fees out-of-band or via OP_TRUE outputs which the miner can\nsimply collect.  Then the miner sets the fee threshold to ~0 and selects\ntransactions on the basis of out of band fees.\n\nMiners today already accept out-of-band fees, and as far back as at least\n2011 there were miners that would also accept fees in the form of\nadditional transaction outputs which they were able to spend.\n\nOn Thu, Nov 30, 2017 at 9:11 AM, Gregory Maxwell <gmaxwell at gmail.com> wrote:\n\n>\n>\n> This idea presumes that the protocol has any ability to regulate fees. I\n> believe the locally optimal strategy for both miners and payers alike is to\n> accept (pay) zero fees natively in the protocol and instead accept (pay)\n> their actual fees out-of-band or via OP_TRUE outputs which the miner can\n> simply collect.  Then the miner sets the fee threshold to ~0 and selects\n> transactions on the basis of out of band fees.\n>\n> Miners today already accept out-of-band fees, and as far back as at least\n> 2011 there were miners that would also accept fees in the form of\n> additional transaction outputs which they were able to spend.\n>\n>\n>\n> On Thu, Nov 30, 2017 at 12:47 AM, William Morriss via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Comrades,\n>>\n>> Long term, tx fees must support hash power by themselves. The following\n>> is an economic approach to maximize total fee collection, and therefore\n>> hashpower.\n>>\n>> *Goals*\n>> Maximize total transaction fees\n>> Reduce pending transaction time\n>> Reduce individual transaction fees\n>>\n>> *Challenges*\n>> Validators must agree on the maximum block size, else miners can cheat\n>> and include extra transactions.\n>> Allowing too many transactions per block will increase the cost of the\n>> mining without collecting much income for the network.\n>>\n>>\n>> *Problem*\n>> In the transaction market, users are the demand curve, because they will\n>> transact less when fees are higher, and prefer altcoins. The block size is\n>> the supply curve, because it represents miners' willingness to accept\n>> transactions.\n>> Currently, the supply curve is inelastic:\n>>\n>> \u200bIncreasing the block size will not affect the inelasticity for any\n>> fixed block size. The downsides of a fixed block size limit are well-known:\n>> - Unpredictable transaction settlement time\n>> - Variable transaction fees depending on network congestion\n>> - Frequent overpay\n>>\n>> *Proposal*\n>> 1. Miners implicitly choose the market sat/byte rate with the\n>> cheapest-fee transaction included in their block. Excess transaction fees\n>> are refunded to the inputs.\n>> 2. Remove the block size limit, which is no longer necessary.\n>>\n>> *Benefits*\n>> - Dynamic block size limit regulated by profit motive\n>> - Transaction fees maximized for every block\n>> - No overpay; all fees are fair\n>>\n>> \u200bMiners individually will make decisions to maximize their block-reward\n>> profit.\n>> Miners are incentivized to ignore low-fee transactions because they would\n>> shave the profits of their other transactions and increase their hash time.\n>> Users and services are free to bid higher transaction fees in order to\n>> reach the next block, since their excess bid will be refunded.\n>>\n>> The block size limit was added as a spam-prevention measure, but in order\n>> for an attacker to spam the network with low-fee transactions, they would\n>> have to offset the marginal cost of reducing the price with their own\n>> transaction fees. Anti-spam is thus built into the marginal system without\n>> the need for an explicit limit.\n>>\n>> Rarely, sections of the backlog would become large enough to be\n>> profitable. This means every so many blocks, lower-fee transactions would\n>> be included en masse after having been ignored long enough. Low-fee\n>> transactions thus gain a liveness property not previously enjoyed: low-fee\n>> transactions will eventually confirm. Miners targeting these transactions\n>> would be at a noteworthy disadvantage because they would be hashing a\n>> larger block. I predict that this scheme would result in two markets: a\n>> backlog market and a real-time market. Users targeting the backlog market\n>> would match the price of the largest backlog section in order to be\n>> included in the next backlog block.\n>>\n>> *Examples*\n>>\n>> Scenario 1\n>> Sat/byte Bytes Reward\n>> 400 500000 200000000\n>> 300 700000 210000000\n>> 200 1000000 200000000\n>> 100 1500000 150000000\n>> 50 5000000 250000000\n>> 20 10000000 200000000\n>> A miner would create a 5MB block and receive 0.25 BTC\n>>\n>> Scenario 2\n>> Sat/byte Bytes Reward\n>> 400 600000 240000000\n>> 300 700000 210000000\n>> 200 1000000 200000000\n>> 100 1800000 180000000\n>> 50 4000000 200000000\n>> 20 10000000 200000000\n>> A miner would create a 600KB block and receive 0.24 BTC\n>>\n>> Thanks,\n>> William Morriss\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/b113f2f5/attachment.html>"
            },
            {
                "author": "Chenxi Cai",
                "date": "2017-11-30T16:15:01",
                "message_text_only": "It is clear that charging min fee won't maximize total miner's fees because it ignores heterogeneity in willingness to pay among bidders within the same block. Also, spamming can still occur by setting a large number of transactions to the min fee. Competition between spammers might drive up the min fee, which is really where the positive effect comes from in this model.\n\n\nA two-part pricing scheme involving a fixed fee per transaction plus variable fee per byte is likely to work much better. The fixed fee component raises the cost of micro-transactions substantially and deters spamming of the mempool.  Also, revenue is not lost from people with higher willingness to pay.\n\n\nChenxi\n\n________________________________\nFrom: William Morriss <wjmelements at gmail.com>\nSent: Wednesday, November 29, 2017 11:05 PM\nTo: Chenxi Cai\nCc: Bitcoin Protocol Discussion\nSubject: Re: [bitcoin-dev] BIP Idea: Marginal Pricing\n\nOn Wed, Nov 29, 2017 at 9:52 PM, Chenxi Cai <Chenxi_Cai at live.com<mailto:Chenxi_Cai at live.com>> wrote:\n\nHi All,\n\n\nAuction theory is a well-studied problem in the economics literature. Currently what bitcoin has is Generalized first-price auction, where winning bidders pay their full bids. Alternatively, two approaches are potentially viable, which are Generalized second-price auction and Vickrey\u2013Clarke\u2013Groves auction. Generalized second-price auction, where winning bidders pay their next highest bids, reduces (but not eliminate) the need for bidders to strategize by allowing them to bid closer to their reservation price. Vickrey\u2013Clarke\u2013Groves auction, a more sophisticated system that considers all bids in relation to one another, elicit truthful bids from bidders, but may not maximize miners' fees as the other two systems will.\n\n\nDue to one result called Revenue Equivalence, the choice of fee design will not impact miners' fees unless the outcomes of the auction changes (i.e, the highest bidders do not always win). In addition, the sole benefit of second-price auction over first-price auction is to spare people's mental troubles from strategizing, rather than actually saving mining fees, because in equilibrium the fees bidders pay remain the same. Therefore, in balance, I do not see substantial material benefits arising from switching to a different fee schedule.\n\n\nBest,\n\nChenxi Cai\n\n\nChanging the bidding system to the marginal price allows us to supersede the block size limit, which changes the outcome of the auction, as different transactions are included.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/e0abb4a7/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP Idea: Marginal Pricing",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Eric Voskuil",
                "Federico Tenga",
                "Ben Kloester",
                "William Morriss",
                "Chenxi Cai",
                "Gregory Maxwell"
            ],
            "messages_count": 10,
            "total_messages_chars_count": 41528
        }
    },
    {
        "title": "[bitcoin-dev] A DNS-like decentralized mapping for wallet addresses?",
        "thread_messages": [
            {
                "author": "mandar mulherkar",
                "date": "2017-11-30T22:20:10",
                "message_text_only": "Hello,\n\nI am new, so apologies if this has been asked before.\n\nHere are a few questions to start with -\n\nI was wondering in terms of mass adoption, instead of long wallet\naddresses, maybe there should be a DNS-like decentralized mapping service\nto provide a user at crypto address?\n\nThis address translation can happen with confirmations from the network. So\ninstead of providing a long string, or a QR code that needs an app, you\nsimply type in a human readable address, and the wallet software converts\nit to a wallet address.\n\nPlease let me know where I can research this more - if there already is\nliterature about this somewhere.\n\nthanks!\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20171130/29177e88/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "A DNS-like decentralized mapping for wallet addresses?",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "mandar mulherkar"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 826
        }
    }
]