[
    {
        "title": "[bitcoin-dev] On the regularity of soft forks",
        "thread_messages": [
            {
                "author": "vjudeu at gazeta.pl",
                "date": "2022-01-01T15:45:11",
                "message_text_only": "> If you don't like the reduction of the block subsidy, well that's a much bigger problem.\nIt is reversible, because you can also increase the block subsidy by using another kind of soft-fork. For example, you can create spendable outputs with zero satoshis. In this way, old nodes will accept that silently, but new nodes can check something more, because you can specify somewhere else, what is the \"real\" amount. Finally, if all nodes will upgrade, you will end up in a network, where all transactions spend zero satoshi inputs, create zero satoshi outputs and have zero fee. Old nodes would accept all of that, but new nodes would really see, what is going on, and they will check that all rules are met, and the new subsidy is for example increased x1000 (that could lead to the same situation as moving from satoshis to millisatoshis with some hard-fork, but doing that kind of change with a soft-fork is safer).\nOn 2021-12-31 10:35:06 user Keagan McClelland via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\u00a0\u00a0But whether or not it is a basic principle of general software engineering kind of misses the point. Security critical software clearly isn't engineered in the same way as a new social media app. Bugs are easily reverted in a new social media app.On top of that we aren't just dealing with security critical software. One of the most important objectives is to keep all the nodes on the network in consensus. Introducing a consensus change before we are comfortable there is community consensus for it is a massive effective bug in itself. The network can split in multiple ways e.g. part of the network disagrees on whether to activate the consensus change, part of the network disagrees on how to resist that consensus change, part of the network disagrees on how to activate that consensus change etc\n\u00a0\n>\u00a0\u00a0A consensus change is extremely hard to revert and probably requires a hard fork, a level of central coordination we generally attempt to avoid and a speed of deployment that we also attempt to avoid.\n\u00a0\nThis seems to assert the idea that soft forks are all the same: they are not. For instance a soft fork, lowering the block subsidy is completely different than changing the semantics of an OP_NOP to have semantics that may reject a subset of the witnesses that attest to the transactions permissibility. As a result, reversion means two entirely different things in these contexts. While a strict reversion of both soft forks is by definition a hard fork, the requirement of reversion as a result of undesired behavior is not the same. In the case of opcodes, there is almost never a requirement to revert it. If you don't like the way the opcodes behave, then you just don't use them. If you don't like the reduction of the block subsidy, well that's a much bigger problem.\n\u00a0\nI make this point to elucidate the idea that we cannot treat SoftForks\u2122 as a single monolithic idea. Perhaps we need to come up with better terminology to be specific about what each fork actually is. The soft vs. hard distinction is a critical one but it is not enough and treating soft forks that are noninvasive such as OP_NOP tightenings. This has been proposed before [1], and while I do not necessarily think the terms cited are necessarily complete, they admit the low resolution of our current terminology.\n\u00a0\n> Soft fork features can (and should) obviously be tested thoroughly on testnet, signet, custom signets, sidechains etc on a standalone basis and a bundled basis.\n\u00a0\nI vehemently disagree that any consensus changes should be bundled, especially when it comes to activation parameters. When we start to bundle things, we amplify the community resources needed to do review, not reduce them. I suspect your opinion here is largely informed by your frustration with the Taproot Activation procedure that you underwent earlier this year. This is understandable. However, let me present the alternative case. If we start to bundle features, the review of the features gets significantly harder. As the Bitcoin project scales, the ability of any one developer to understand the entire codebase declines. Bundling changes reduces the number of people who are qualified to review a particular proposal, and even worse, intimidates people who may be willing and able to review logically distinct portions of the proposal, resulting in lower amounts of review overall. This will likely have the opposite effect of what you seem to desire. BIP8 and BIP9 give us the ability to have multiple independent soft forks in flight at once. Choosing to bundle them instead makes little sense when we do not have to. Bundling them will inevitably degenerate into political horse trading and everyone will be worse off for it.\n\u00a0\n> part of the network disagrees on whether to activate the consensus change, part of the network disagrees on how to resist that consensus change, part of the network disagrees on how to activate that consensus change etc\n\u00a0\nDisagreements, and by extension, forks are a part of Bitcoin. What is important is that they are well defined and clean. This is the reason why the mandatory signaling period exists in BIP8/9, so that clients that intend to reject the soft fork change have a very easy means of doing so in a clean break where consensus is clearly divergent. In accordance with this, consensus changes should be sequenced so that people can decide which sides of the forks they want to follow and that the economic reality can reorganize around that. If choose to bundle them, you have one of two outcomes: either consensus atomizes into a mist where people have different ideas of which subsets of a soft fork bundle they want to adopt, or what likely comes after is a reconvergence on the old client with none of the soft fork rules in place. This will lead to significantly more confusion as well given that with sufficient miner consensus some of the rules may stick anyway even if the rest of the user base reconverges on the old client.\n\u00a0\nIt is quite likely less damaging to consensus to have frequent but strictly sequenced soft forks so that if one of the new rules is contentious the break can happen cleanly. That said, if Core or any other client wishes to cut a release of the software with the parameters bundled into a single release, that is a significantly\u00a0more palatable state of affairs, as you can still pipeline signaling and activation. However, the protocol itself adopting a tendency to activate unrelated proposals in bundles is a recipe for disaster.\n\u00a0\n\u00a0\nRespectfully,\nKeagan\n\u00a0\n\u00a0\n[1]\u00a0https://www.truthcoin.info/blog/protocol-upgrade-terminology\nOn Sat, Oct 16, 2021 at 12:57 PM Michael Folkson via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> Interesting discussion.\u00a0Correct me if I'm wrong: but putting too many features together in one shot just can't make things harder to debug in production if something very unexpected happens.\u00a0It's a basic principle of software engineering.\n\u00a0\nSoft fork features can (and should) obviously be tested thoroughly on testnet, signet, custom signets, sidechains etc on a standalone basis and a bundled basis. But whether or not it is a basic principle of general software engineering kind of misses the point. Security critical software clearly isn't engineered in the same way as a new social media app. Bugs are easily reverted in a new social media app. A consensus change is extremely hard to revert and probably requires a hard fork, a level of central coordination we generally attempt to avoid and a speed of deployment that we also attempt to avoid. On top of that we aren't just dealing with security critical software. One of the most important objectives is to keep all the nodes on the network in consensus. Introducing a consensus change before we are comfortable there is community consensus for it is a massive effective bug in itself. The network can split in multiple ways e.g. part of the network disagrees on whether to activate the consensus change, part of the network disagrees on how to resist that consensus change, part of the network disagrees on how to activate that consensus change etc\n\u00a0\nIn addition, a social media app can experiment in production whether Feature A works, whether Feature B works or whether Feature A and B work best together. In Bitcoin if we activate consensus Feature A, later decide we want consensus Feature B but find out that by previously activating Feature A we can't have Feature B (it is now unsafe to activate it) or its design now has to be suboptimal because we have to ensure it can safely work in the presence of Feature A we have made a mistake by activating Feature A in the first place. Decentralized security critical consensus changes are an emerging field in itself and really can't be treated like any other software project. This will become universally understood I'm sure over time.\n\u00a0\n\u00a0\n-- Michael Folkson Email: michaelfolkson at protonmail.com Keybase: michaelfolkson PGP:\u00a043ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n\u00a0\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Friday, October 15th, 2021 at 1:43 AM, Felipe Micaroni Lalli via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\nInteresting discussion. Correct me if I'm wrong: but putting too many features together in one shot just can't make things harder to debug in production if something very unexpected happens. It's a basic principle of software engineering.\n\u00a0\nChange. Deploy. Nothing bad happened? Change it a little more. Deployment.\nOr: Change, change, change. Deploy. Did something bad happen? What change caused the problem?\nOn Thu, Oct 14, 2021 at 8:53 PM Anthony Towns via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\nOn Mon, Oct 11, 2021 at 12:12:58PM -0700, Jeremy via bitcoin-dev wrote:\n> > ...\u00a0in this post I will argue against frequent soft forks with a single or\n> minimal\n> > set of features and instead argue for infrequent soft forks with batches\n> > of features.\n> I think this type of development has been discussed in the past and has been\n> rejected.\n> AJ:\u00a0- improvements: changes might not make everyone better off, but we\n> \u00a0 \u00a0don't want changes to screw anyone over either -- pareto\n> \u00a0 \u00a0improvements in economics, \"first, do no harm\", etc. (if we get this\n> \u00a0 \u00a0right, there's no need to make compromises and bundle multiple\n> \u00a0 \u00a0flawed proposals so that everyone's an equal mix of happy and\n> \u00a0 \u00a0miserable)\nI don't think your conclusion above matches my opinion, for what it's\nworth.\nIf you've got two features, A and B, where the game theory is:\n\u00a0If A happens, I'm +100, You're -50\n\u00a0If B happens, I'm -50, You're +100\nthen even though A+B is +50, +50, then I do think the answer should\ngenerally be \"think harder and come up with better proposals\" rather than\n\"implement A+B as a bundle that makes us both +50\".\n_But_ if the two features are more like:\n\u00a0 If C happens, I'm +100, You're +/- 0\n\u00a0 If D happens, I'm +/- 0, You're +100\nthen I don't have a problem with bundling them together as a single\nsimultaneous activation of both C and D.\nAlso, you can have situations where things are better together,\nthat is:\n\u00a0 If E happens, we're both at +100\n\u00a0 If F happens, we're both at +50\n\u00a0 If E+F both happen, we're both at +9000\nIn general, I think combining proposals when the combination is better\nthan the individual proposals were is obviously good; and combining\nrelated proposals into a single activation can be good if it is easier\nto think about the ideas as a set.\nIt's only when you'd be rejecting the proposal on its own merits that\nI think combining it with others is a bad idea in principle.\nFor specific examples, we bundled schnorr, Taproot, MAST, OP_SUCCESSx\nand CHECKSIGADD together because they do have synergies like that; we\ndidn't bundle ANYPREVOUT and graftroot despite the potential synergies\nbecause those features needed substantially more study.\nThe nulldummy soft-fork (bip 147) was deployed concurrently with\nthe segwit soft-fork (bip 141, 143), but I don't think there was any\nparticular synergy or need for those things to be combined, it just\nreduced the overhead of two sets of activation signalling to one.\nNote that the implementation code for nulldummy had already been merged\nand were applied as relay policy well before activation parameters were\ndefined (May 2014 via PR#3843 vs Sep 2016 for PR#8636) let alone becoming\nan active soft fork.\nCheers,\naj\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220101/b88be538/attachment-0001.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-01-18T16:00:06",
                "message_text_only": "I agree with you Michael, there is a risk to soft forks and we shouldn't do\nthem too often. We should do them as infrequently as practical. We should\nstrive to one day get to a point where the bitcoin consensus isn't updating\nat all.\n\nPerhaps we should come to a consensus as a consensus as a community what\nthe minimum time between soft forks should be, and just as importantly,\nwhat the minimum time between finalized consensus-change implementation and\nwhen we decide community consensus has been achieved.\n\nHow long do you think these minimums should be? I'm curious to know\neveryone's answer to this. I would think of these like I think about\nchanges to how I think national law should be changed: slowly and\ncarefully. There should be sufficient time for everyone to have a chance in\ntheir busy lives to take the time to look at it, if they care, so they can\nraise objections. I think the minimum time between a soft fork\nimplementation finalization and determining consensus should be maybe a\nyear. And the minimum time between soft forks should probably be something\nlike 5 years. This would mean that people only have to worry about paying\nattention to what might happen with bitcoin consensus once every 5 years,\nand would get a year-long window to do it. And if there isn't sufficient\nconsensus, or people bring up objections at the last minute, that should be\nacceptable and it should further delay the deployment.\n\nI think a lot of folks on here are rightly concerned about compromise\nbundles where multiple mediocre proposals are put together\nto basically incentivize some people to accept something they don't want\nin order to receive something they do want (eg what Jeremy quoted Matt\nCorallo about). But I don't think that's what Michael was suggesting at\nall. That kind of compromise happens in the *decision making process*. My\nunderstanding of what Michael was saying is that releasing a soft fork\nshould *not* be within the decision making process at all. The decision\nmaking process should have already happened.\n\nIf you have consensus changes A and B, Michael was saying that each\nconsensus change proposal should go through a community vetting process\nthat determines that there is widespread supermajority support for it\n*before* it is even merged into the code (ie master, or some equivalent\nthis-will-be-deployed branch). It should have a final implementation that\nhas been tested at all levels *before* its merged to master. And only then\nshould it potentially be bundled. After all testing has already been done,\nafter sufficient consensus has already been determined.\n\n@Keagan\n> When we start to bundle things, we amplify the community resources needed\nto do review, not reduce them.\n\nI think my above 2 paragraphs address this. I agree we don't want to review\nthese proposals together, they should be reviewed separately. And I don't\nthink Michael was suggesting otherwise.\n\n> the protocol itself adopting a tendency to activate unrelated proposals\nin bundles is a recipe for disaster.\n\nActivating multiple consensus changes in a bundle is far safer than having\nmultiple separate in-flight soft forks at once. With multiple in-flight\nsoft forks, you have many combinations of what might happen (and therefore\nwhat needs to be tested beforehand). Just 3 in-flight soft forks means 9\ncases: nine orders of what might happen. All those combinations must be\nexhaustively tested as all consensus changes must be. This is far more\nwork, more complicated, and more error prone than bundling them together in\none soft fork.\n\n@Prayank\n> However I am sure there are lot of people who still think miners vote\nduring signaling. ... I could not think of any solution to solve this\nproblem.\n\nOne solution is that we could be a lot more direct about how decisions are\nmade. There's been a lot of rhetoric around UASF and how the economic\nmajority is really who's running the show. If that's the case, why not make\nthat explicitly? Why not actually ask users to sign a petition saying they\nsupport a particular consensus change? This could be done with actual\nsignatures by keys connected to UTXOs so we can see the economic weight of\nthe petition. We would probably need to have a new address format to\nprevent problems related to public key exposure (eg by having addresses\ncontaining two public keys: `hash(hash(spendingkey)+hash(votingkey))` where\nyou can expose the voting key without exposing your spending key). Perhaps\nthis could be another tapleaf.\n\nDoing this could make it very clear how much of the bitcoin world supports\na particular change without needing to put anything extra on chain. This\nclarity would also help the actual miner activation of the software in\ncases where miners might have incentives not to activate. If it were clear\nthat an overwhelming supermajority wants it activated, miners would be less\nlikely to play games that play off uncertainty. It would also dispel the\nidea that miners or developers decide how bitcoin changes.\n\n\nOn Sat, Jan 1, 2022 at 10:00 AM vjudeu via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> > If you don't like the reduction of the block subsidy, well that's a much\n> bigger problem.\n>\n> It is reversible, because you can also increase the block subsidy by using\n> another kind of soft-fork. For example, you can create spendable outputs\n> with zero satoshis. In this way, old nodes will accept that silently, but\n> new nodes can check something more, because you can specify somewhere else,\n> what is the \"real\" amount. Finally, if all nodes will upgrade, you will end\n> up in a network, where all transactions spend zero satoshi inputs, create\n> zero satoshi outputs and have zero fee. Old nodes would accept all of that,\n> but new nodes would really see, what is going on, and they will check that\n> all rules are met, and the new subsidy is for example increased x1000 (that\n> could lead to the same situation as moving from satoshis to millisatoshis\n> with some hard-fork, but doing that kind of change with a soft-fork is\n> safer).\n>\n> On 2021-12-31 10:35:06 user Keagan McClelland via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> >  But whether or not it is a basic principle of general software\n> engineering kind of misses the point. Security critical software clearly\n> isn't engineered in the same way as a new social media app. Bugs are easily\n> reverted in a new social media app.On top of that we aren't just dealing\n> with security critical software. One of the most important objectives is to\n> keep all the nodes on the network in consensus. Introducing a consensus\n> change before we are comfortable there is community consensus for it is a\n> massive effective bug in itself. The network can split in multiple ways\n> e.g. part of the network disagrees on whether to activate the consensus\n> change, part of the network disagrees on how to resist that consensus\n> change, part of the network disagrees on how to activate that consensus\n> change etc\n>\n> >  A consensus change is extremely hard to revert and probably requires a\n> hard fork, a level of central coordination we generally attempt to avoid\n> and a speed of deployment that we also attempt to avoid.\n>\n> This seems to assert the idea that soft forks are all the same: they are\n> not. For instance a soft fork, lowering the block subsidy is completely\n> different than changing the semantics of an OP_NOP to have semantics that\n> may reject a subset of the witnesses that attest to the transactions\n> permissibility. As a result, reversion means two entirely different things\n> in these contexts. While a strict reversion of both soft forks is by\n> definition a hard fork, the requirement of reversion as a result of\n> undesired behavior is not the same. In the case of opcodes, there is almost\n> never a requirement to revert it. If you don't like the way the opcodes\n> behave, then you just don't use them. If you don't like the reduction of\n> the block subsidy, well that's a much bigger problem.\n>\n> I make this point to elucidate the idea that we cannot treat SoftForks\u2122 as\n> a single monolithic idea. Perhaps we need to come up with better\n> terminology to be specific about what each fork actually is. The soft vs.\n> hard distinction is a critical one but it is not enough and treating soft\n> forks that are noninvasive such as OP_NOP tightenings. This has been\n> proposed before [1], and while I do not necessarily think the terms cited\n> are necessarily complete, they admit the low resolution of our current\n> terminology.\n>\n> > Soft fork features can (and should) obviously be tested thoroughly on\n> testnet, signet, custom signets, sidechains etc on a standalone basis and a\n> bundled basis.\n>\n> I vehemently disagree that any consensus changes should be bundled,\n> especially when it comes to activation parameters. When we start to bundle\n> things, we amplify the community resources needed to do review, not reduce\n> them. I suspect your opinion here is largely informed by your frustration\n> with the Taproot Activation procedure that you underwent earlier this year.\n> This is understandable. However, let me present the alternative case. If we\n> start to bundle features, the review of the features gets significantly\n> harder. As the Bitcoin project scales, the ability of any one developer to\n> understand the entire codebase declines. Bundling changes reduces the\n> number of people who are qualified to review a particular proposal, and\n> even worse, intimidates people who may be willing and able to review\n> logically distinct portions of the proposal, resulting in lower amounts of\n> review overall. This will likely have the opposite effect of what you seem\n> to desire. BIP8 and BIP9 give us the ability to have multiple independent\n> soft forks in flight at once. Choosing to bundle them instead makes little\n> sense when we do not have to. Bundling them will inevitably degenerate into\n> political horse trading and everyone will be worse off for it.\n>\n> > part of the network disagrees on whether to activate the consensus\n> change, part of the network disagrees on how to resist that consensus\n> change, part of the network disagrees on how to activate that consensus\n> change etc\n>\n> Disagreements, and by extension, forks are a part of Bitcoin. What is\n> important is that they are well defined and clean. This is the reason why\n> the mandatory signaling period exists in BIP8/9, so that clients that\n> intend to reject the soft fork change have a very easy means of doing so in\n> a clean break where consensus is clearly divergent. In accordance with\n> this, consensus changes should be sequenced so that people can decide which\n> sides of the forks they want to follow and that the economic reality can\n> reorganize around that. If choose to bundle them, you have one of two\n> outcomes: either consensus atomizes into a mist where people have different\n> ideas of which subsets of a soft fork bundle they want to adopt, or what\n> likely comes after is a reconvergence on the old client with none of the\n> soft fork rules in place. This will lead to significantly more confusion as\n> well given that with sufficient miner consensus some of the rules may stick\n> anyway even if the rest of the user base reconverges on the old client.\n>\n> It is quite likely less damaging to consensus to have frequent but\n> strictly sequenced soft forks so that if one of the new rules is\n> contentious the break can happen cleanly. That said, if Core or any other\n> client wishes to cut a release of the software with the parameters bundled\n> into a single release, that is a significantly more palatable state of\n> affairs, as you can still pipeline signaling and activation. However, the\n> protocol itself adopting a tendency to activate unrelated proposals in\n> bundles is a recipe for disaster.\n>\n>\n> Respectfully,\n> Keagan\n>\n>\n> [1] https://www.truthcoin.info/blog/protocol-upgrade-terminology\n>\n> On Sat, Oct 16, 2021 at 12:57 PM Michael Folkson via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org\n> <http://../NowaWiadomosc/Do/QlIkBFQ6QUFhIVRZX192dnQBeCtCchE6GhA5LFpLCUc7EVZQVl9dQRIXXR8NCBMbCwIGChJXQFxcXEgcFh8UVVVDEyBdVkE9JVRdEwFhYXVlblhVIkosEAszLR5BQVV7U0MID0BAQUgIGh0RHgAMGAMXBQJfW1sdXRQUQUoDQlAiBFY8>>\n> wrote:\n>\n>> > Interesting discussion. Correct me if I'm wrong: but putting too many\n>> features together in one shot just can't make things harder to debug in\n>> production if something very unexpected happens. It's a basic principle\n>> of software engineering.\n>>\n>> Soft fork features can (and should) obviously be tested thoroughly on\n>> testnet, signet, custom signets, sidechains etc on a standalone basis and a\n>> bundled basis. But whether or not it is a basic principle of general\n>> software engineering kind of misses the point. Security critical software\n>> clearly isn't engineered in the same way as a new social media app. Bugs\n>> are easily reverted in a new social media app. A consensus change is\n>> extremely hard to revert and probably requires a hard fork, a level of\n>> central coordination we generally attempt to avoid and a speed of\n>> deployment that we also attempt to avoid. On top of that we aren't just\n>> dealing with security critical software. One of the most important\n>> objectives is to keep all the nodes on the network in consensus.\n>> Introducing a consensus change before we are comfortable there is community\n>> consensus for it is a massive effective bug in itself. The network can\n>> split in multiple ways e.g. part of the network disagrees on whether to\n>> activate the consensus change, part of the network disagrees on how to\n>> resist that consensus change, part of the network disagrees on how to\n>> activate that consensus change etc\n>>\n>> In addition, a social media app can experiment in production whether\n>> Feature A works, whether Feature B works or whether Feature A and B work\n>> best together. In Bitcoin if we activate consensus Feature A, later decide\n>> we want consensus Feature B but find out that by previously activating\n>> Feature A we can't have Feature B (it is now unsafe to activate it) or its\n>> design now has to be suboptimal because we have to ensure it can safely\n>> work in the presence of Feature A we have made a mistake by activating\n>> Feature A in the first place. Decentralized security critical consensus\n>> changes are an emerging field in itself and really can't be treated like\n>> any other software project. This will become universally understood I'm\n>> sure over time.\n>>\n>>\n>>\n>> --Michael Folkson\n>> Email: michaelfolkson at protonmail.com\n>> Keybase: michaelfolkson\n>> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>>\n>>\n>> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>> On Friday, October 15th, 2021 at 1:43 AM, Felipe Micaroni Lalli via\n>> bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org\n>> <http://../NowaWiadomosc/Do/QlIkBFQ6QUFhIVRZX192dnQBeCtCchE6GhA5LFpLCUc7EVZQVl9dQRIXXR8NCBMbCwIGChJXQFxcXEgcFh8UVVVDEyBdVkE9JVRdEwFhYXVlblhVIkosEAszLR5BQVV7U0MID0BAQUgIGh0RHgAMGAMXBQJfW1sdXRQUQUoDQlAiBFY8>>\n>> wrote:\n>>\n>> Interesting discussion. Correct me if I'm wrong: but putting too many\n>> features together in one shot just can't make things harder to debug in\n>> production if something very unexpected happens. It's a basic principle\n>> of software engineering.\n>>\n>> Change. Deploy. Nothing bad happened? Change it a little more. Deployment.\n>> Or: Change, change, change. Deploy. Did something bad happen? What change\n>> caused the problem?\n>>\n>> On Thu, Oct 14, 2021 at 8:53 PM Anthony Towns via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org\n>> <http://../NowaWiadomosc/Do/QlIkBFQ6QUFhIVRZX192dnQBeCtCchE6GhA5LFpLCUc7EVZQVl9dQRIXXR8NCBMbCwIGChJXQFxcXEgcFh8UVVVDEyBdVkE9JVRdEwFhYXVlblhVIkosEAszLR5BQVV7U0MID0BAQUgIGh0RHgAMGAMXBQJfW1sdXRQUQUoDQlAiBFY8>>\n>> wrote:\n>>\n>>> On Mon, Oct 11, 2021 at 12:12:58PM -0700, Jeremy via bitcoin-dev wrote:\n>>> > > ... in this post I will argue against frequent soft forks with a\n>>> single or\n>>> > minimal\n>>> > > set of features and instead argue for infrequent soft forks with\n>>> batches\n>>> > > of features.\n>>> > I think this type of development has been discussed in the past and\n>>> has been\n>>> > rejected.\n>>>\n>>> > AJ: - improvements: changes might not make everyone better off, but we\n>>> >    don't want changes to screw anyone over either -- pareto\n>>> >    improvements in economics, \"first, do no harm\", etc. (if we get this\n>>> >    right, there's no need to make compromises and bundle multiple\n>>> >    flawed proposals so that everyone's an equal mix of happy and\n>>> >    miserable)\n>>>\n>>> I don't think your conclusion above matches my opinion, for what it's\n>>> worth.\n>>>\n>>> If you've got two features, A and B, where the game theory is:\n>>>\n>>>  If A happens, I'm +100, You're -50\n>>>  If B happens, I'm -50, You're +100\n>>>\n>>> then even though A+B is +50, +50, then I do think the answer should\n>>> generally be \"think harder and come up with better proposals\" rather than\n>>> \"implement A+B as a bundle that makes us both +50\".\n>>>\n>>> _But_ if the two features are more like:\n>>>\n>>>   If C happens, I'm +100, You're +/- 0\n>>>   If D happens, I'm +/- 0, You're +100\n>>>\n>>> then I don't have a problem with bundling them together as a single\n>>> simultaneous activation of both C and D.\n>>>\n>>> Also, you can have situations where things are better together,\n>>> that is:\n>>>\n>>>   If E happens, we're both at +100\n>>>   If F happens, we're both at +50\n>>>   If E+F both happen, we're both at +9000\n>>>\n>>> In general, I think combining proposals when the combination is better\n>>> than the individual proposals were is obviously good; and combining\n>>> related proposals into a single activation can be good if it is easier\n>>> to think about the ideas as a set.\n>>>\n>>> It's only when you'd be rejecting the proposal on its own merits that\n>>> I think combining it with others is a bad idea in principle.\n>>>\n>>> For specific examples, we bundled schnorr, Taproot, MAST, OP_SUCCESSx\n>>> and CHECKSIGADD together because they do have synergies like that; we\n>>> didn't bundle ANYPREVOUT and graftroot despite the potential synergies\n>>> because those features needed substantially more study.\n>>>\n>>> The nulldummy soft-fork (bip 147) was deployed concurrently with\n>>> the segwit soft-fork (bip 141, 143), but I don't think there was any\n>>> particular synergy or need for those things to be combined, it just\n>>> reduced the overhead of two sets of activation signalling to one.\n>>>\n>>> Note that the implementation code for nulldummy had already been merged\n>>> and were applied as relay policy well before activation parameters were\n>>> defined (May 2014 via PR#3843 vs Sep 2016 for PR#8636) let alone becoming\n>>> an active soft fork.\n>>>\n>>> Cheers,\n>>> aj\n>>>\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> <http://../NowaWiadomosc/Do/QlIkBFQ6QUFhIVRZX192dnQBeCtCchE6GhA5LFpLCUc7EVZQVl9dQRIXXR8NCBMbCwIGChJXQFxcXEgcFh8UVVVDEyBdVkE9JVRdEwFhYXVlblhVIkosEAszLR5BQVV7U0MID0BAQUgIGh0RHgAMGAMXBQJfW1sdXRQUQUoDQlAiBFY8>\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> <http://../NowaWiadomosc/Do/QlIkBFQ6QUFhIVRZX192dnQBeCtCchE6GhA5LFpLCUc7EVZQVl9dQRIXXR8NCBMbCwIGChJXQFxcXEgcFh8UVVVDEyBdVkE9JVRdEwFhYXVlblhVIkosEAszLR5BQVV7U0MID0BAQUgIGh0RHgAMGAMXBQJfW1sdXRQUQUoDQlAiBFY8>\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/6380a1e7/attachment-0001.html>"
            },
            {
                "author": "Prayank",
                "date": "2022-01-18T17:22:05",
                "message_text_only": "> We should strive to one day get to a point where the bitcoin consensus isn't updating at all.\n\nThat day is nowhere near IMO and maybe we won't see it in my lifetime.\n\n> Perhaps we should come to a consensus as a consensus as a community what the minimum time between soft forks should be, and just as importantly, what the minimum time between finalized consensus-change implementation and when we decide community consensus has been achieved.\n\nThis is not possible in a decentralized network like Bitcoin and makes no sense. Soft forks can/should be done as and when required. This does not mean we do them often but if a change makes sense, looks ready, got enough consensus, reviewed properly etc. then timing doesn't really matter in every case.\n\n> Activating multiple consensus changes in a bundle is far safer than having multiple separate in-flight soft forks at once.\n\nThis is not true. More changes bundled require more review and still more probability to have bugs. Security is always about keeping things simple.\n\n> One solution is that we could be a lot more direct about how decisions are made. There's been a lot of rhetoric around UASF and how the economic majority is really who's running the show.\n\nBIP 8 with LOT=TRUE was a better activation mechanism option in Taproot but some influential developers wrote its misleading, unsafe etc. on social media so you can call me negative at this moment however I have realized the truth is really sad and we can't blindly follow some people. There are lot of people who will tell you bad things about UASF and how speedy trial is the best thing Bitcoin has ever experienced.\n\nMichael Folkson also had some opinion in activation mechanism IIRC,\n\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/839b7bfc/attachment.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-01-19T02:26:12",
                "message_text_only": ">  That day is nowhere near IMO and maybe we won't see it in my lifetime.\n\nI think there is a reasonable argument to be made that maybe bitcoin needs\nto move faster now than it should in the future, and the cost of having the\ncommunity remain vigilant against harmful changes is worth the extra speed.\nThe question then becomes, does doing soft forks more often make things go\nfaster? Its not clear to me that the answer is yes.\n\n> This is not possible in a decentralized network like Bitcoin and makes no\nsense.\n\nWhy do you think that its not possible? I completely disagree. The bitcoin\ncommunity has already come up with cultural norms like this, like the idea\nof doing soft forks instead of hardforks wherever possible. Its impossible\nto prevent others from doing otherwise, but its completely possible and\ndesirable for the bitcoin community to adopt standards that we attempt to\nadhere to.\n\n> More changes bundled require more review and still more probability to\nhave bugs.\n\nI already addressed this in my previous email. Why do you think there is\nmore to review in a soft fork with two bundled changes than in two separate\nconcurrent soft-fork activations using BIP8 or BIP9? Both require both\nchanges to be in the software and both require testing to ensure that the\nchanges interact appropriately. The difference is that in the second case,\nyou have to test all combinations of which order the proposals activate in.\n\nAnd let's consider the easiest case of change A, then soft fork 1, then\nchange B, and soft fork 2. Change A needs to be tested all on its own, and\nchange B when it comes along also then needs to be tested on code that\nalready has change A. If the changes are bundled, the same procedure needs\nto happen. You just avoid having to do soft fork 1.\n\n> BIP 8 with LOT=TRUE was a better activation mechanism\n\nI completely disagree, but that's not relevant to this topic.\n\nOn Tue, Jan 18, 2022 at 11:22 AM Prayank <prayank at tutanota.de> wrote:\n\n> > We should strive to one day get to a point where the bitcoin consensus\n> isn't updating at all.\n>\n> That day is nowhere near IMO and maybe we won't see it in my lifetime.\n>\n> > Perhaps we should come to a consensus as a consensus as a community what\n> the minimum time between soft forks should be, and just as importantly,\n> what the minimum time between finalized consensus-change implementation and\n> when we decide community consensus has been achieved.\n>\n> This is not possible in a decentralized network like Bitcoin and makes no\n> sense. Soft forks can/should be done as and when required. This does not\n> mean we do them often but if a change makes sense, looks ready, got enough\n> consensus, reviewed properly etc. then timing doesn't really matter in\n> every case.\n>\n> > Activating multiple consensus changes in a bundle is far safer than\n> having multiple separate in-flight soft forks at once.\n>\n> This is not true. More changes bundled require more review and still more\n> probability to have bugs. Security is always about keeping things simple.\n>\n> > One solution is that we could be a lot more direct about how decisions\n> are made. There's been a lot of rhetoric around UASF and how the economic\n> majority is really who's running the show.\n>\n> BIP 8 with LOT=TRUE was a better activation mechanism option in Taproot\n> but some influential developers wrote its misleading, unsafe etc. on social\n> media so you can call me negative at this moment however I have realized\n> the truth is really sad and we can't blindly follow some people. There are\n> lot of people who will tell you bad things about UASF and how speedy trial\n> is the best thing Bitcoin has ever experienced.\n>\n> Michael Folkson also had some opinion in activation mechanism IIRC,\n>\n>\n> --\n> Prayank\n>\n> A3B1 E430 2298 178F\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/29a2fa78/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "On the regularity of soft forks",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "vjudeu at gazeta.pl",
                "Prayank",
                "Billy Tetrud"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 38802
        }
    },
    {
        "title": "[bitcoin-dev] [Pre-BIP] Fee Accounts",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2022-01-01T20:04:00",
                "message_text_only": "Happy new years devs,\n\nI figured I would share some thoughts for conceptual review that have been\nbouncing around my head as an opportunity to clean up the fee paying\nsemantics in bitcoin \"for good\". The design space is very wide on the\napproach I'll share, so below is just a sketch of how it could work which\nI'm sure could be improved greatly.\n\nTransaction fees are an integral part of bitcoin.\n\nHowever, due to quirks of Bitcoin's transaction design, fees are a part of\nthe transactions that they occur in.\n\nWhile this works in a \"Bitcoin 1.0\" world, where all transactions are\nsimple on-chain transfers, real world use of Bitcoin requires support for\nthings like Fee Bumping stuck transactions, DoS resistant Payment Channels,\nand other long lived Smart Contracts that can't predict future fee rates.\nHaving the fees paid in band makes writing these contracts much more\ndifficult as you can't merely express the logic you want for the\ntransaction, but also the fees.\n\nPreviously, I proposed a special type of transaction called a \"Sponsor\"\nwhich has some special consensus + mempool rules to allow arbitrarily\nappending fees to a transaction to bump it up in the mempool.\n\nAs an alternative, we could establish an account system in Bitcoin as an\n\"extension block\".\n\n*Here's how it might work:*\n\n1. Define a special anyone can spend output type that is a \"fee account\"\n(e.g. segwit V2). Such outputs have a redeeming key and an amount\nassociated with them, but are overall anyone can spend.\n2. All deposits to these outputs get stored in a separate UTXO database for\nfee accounts\n3. Fee accounts can sign only two kinds of transaction: A: a fee amount and\na TXID (or Outpoint?); B: a withdraw amount, a fee, and an address\n4. These transactions are committed in an extension block merkle tree.\nWhile the actual signature must cover the TXID/Outpoint, the committed data\nneed only cover the index in the block of the transaction. The public key\nfor account lookup can be recovered from the message + signature.\n5. In any block, any of the fee account deposits can be: released into fees\nif there is a corresponding tx; consolidated together to reduce the number\nof utxos (this can be just an OP_TRUE no metadata needed); or released into\nfees *and paid back* into the requested withdrawal key (encumbering a 100\nblock timeout). Signatures must be unique in a block.\n6. Mempool logic is updated to allow attaching of account fee spends to\ntransactions, the mempool can restrict that an account is not allowed more\nspend more than it's balance.\n\n*But aren't accounts \"bad\"?*\n\nYes, accounts are bad. But these accounts are not bad, because any funds\nwithdrawn from the fee extension are fundamentally locked for 100 blocks as\na coinbase output, so there should be no issues with any series of reorgs.\nFurther, since there is no \"rich state\" for these accounts, the state\nupdates can always be applied in a conflict-free way in any order.\n\n\n*Improving the privacy of this design:*\n\nThis design could likely be modified to implement something like\nTornado.cash or something else so that the fee account paying can be\nunlinked from the transaction being paid for, improving privacy at the\nexpense of being a bit more expensive.\n\nOther operations could be added to allow a trustless mixing to be done by\nminers automatically where groups of accounts with similar values are\ntrustlessly  split into a common denominator and change, and keys are\nderived via a verifiable stealth address like protocol (so fee balances can\nbe discovered by tracing the updates posted). These updates could also be\nproduced by individuals rather than miners, and miners could simply honor\nthem with better privacy. While a miner generating an update would be able\nto deanonymize their mixes, if you have your account mixed several times by\nindependent miners that could potentially add sufficient privacy.\n\nThe LN can also be used with PTLCs to, in theory, have another individual\npaid to sponsor a transaction on your behalf only if they reveal a valid\nsig from their fee paying account, although under this model it's hard to\nensure that the owner doesn't pay a fee and then 'cancel' by withdrawing\nthe rest. However, this could be partly solved by using reputable fee\naccounts (reputation could be measured somewhat decentralized-ly by\nlongevity of the account and transactions paid for historically).\n\n*Scalability*\n\nThis design is fundamentally 'decent' for scalability because adding fees\nto a transaction does not require adding inputs or outputs and does not\nrequire tracking substantial amounts of new state.\n\nPaying someone else to pay for you via the LN also helps make this more\nefficient if the withdrawal issues can be fixed.\n\n*Lightning:*\n\nThis type of design works really well for channels because the addition of\nfees to e.g. a channel state does not require any sort of pre-planning\n(e.g. anchors) or transaction flexibility (SIGHASH flags). This sort of\ndesign is naturally immune to pinning issues since you could offer to pay a\nfee for any TXID and the number of fee adding offers does not need to be\nrestricted in the same way the descendant transactions would need to be.\n\n*Without a fork?*\n\nThis type of design could be done as a federated network that bribes miners\n-- potentially even retroactively after a block is formed. That might be\nsufficient to prove the concept works before a consensus upgrade is\ndeployed, but such an approach does mean there is a centralizing layer\ninterfering with normal mining.\n\n\nHappy new year!!\n\nJeremy\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220101/4cd5c38b/attachment.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-01-18T16:12:36",
                "message_text_only": "Do you have any back-of-the-napkin math on quantifying how much this would\nimprove the situation vs existing methods (eg cpfp)?\n\n\n\nOn Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Happy new years devs,\n>\n> I figured I would share some thoughts for conceptual review that have been\n> bouncing around my head as an opportunity to clean up the fee paying\n> semantics in bitcoin \"for good\". The design space is very wide on the\n> approach I'll share, so below is just a sketch of how it could work which\n> I'm sure could be improved greatly.\n>\n> Transaction fees are an integral part of bitcoin.\n>\n> However, due to quirks of Bitcoin's transaction design, fees are a part of\n> the transactions that they occur in.\n>\n> While this works in a \"Bitcoin 1.0\" world, where all transactions are\n> simple on-chain transfers, real world use of Bitcoin requires support for\n> things like Fee Bumping stuck transactions, DoS resistant Payment Channels,\n> and other long lived Smart Contracts that can't predict future fee rates.\n> Having the fees paid in band makes writing these contracts much more\n> difficult as you can't merely express the logic you want for the\n> transaction, but also the fees.\n>\n> Previously, I proposed a special type of transaction called a \"Sponsor\"\n> which has some special consensus + mempool rules to allow arbitrarily\n> appending fees to a transaction to bump it up in the mempool.\n>\n> As an alternative, we could establish an account system in Bitcoin as an\n> \"extension block\".\n>\n> *Here's how it might work:*\n>\n> 1. Define a special anyone can spend output type that is a \"fee account\"\n> (e.g. segwit V2). Such outputs have a redeeming key and an amount\n> associated with them, but are overall anyone can spend.\n> 2. All deposits to these outputs get stored in a separate UTXO database\n> for fee accounts\n> 3. Fee accounts can sign only two kinds of transaction: A: a fee amount\n> and a TXID (or Outpoint?); B: a withdraw amount, a fee, and an address\n> 4. These transactions are committed in an extension block merkle tree.\n> While the actual signature must cover the TXID/Outpoint, the committed data\n> need only cover the index in the block of the transaction. The public key\n> for account lookup can be recovered from the message + signature.\n> 5. In any block, any of the fee account deposits can be: released into\n> fees if there is a corresponding tx; consolidated together to reduce the\n> number of utxos (this can be just an OP_TRUE no metadata needed); or\n> released into fees *and paid back* into the requested withdrawal key\n> (encumbering a 100 block timeout). Signatures must be unique in a block.\n> 6. Mempool logic is updated to allow attaching of account fee spends to\n> transactions, the mempool can restrict that an account is not allowed more\n> spend more than it's balance.\n>\n> *But aren't accounts \"bad\"?*\n>\n> Yes, accounts are bad. But these accounts are not bad, because any funds\n> withdrawn from the fee extension are fundamentally locked for 100 blocks as\n> a coinbase output, so there should be no issues with any series of reorgs.\n> Further, since there is no \"rich state\" for these accounts, the state\n> updates can always be applied in a conflict-free way in any order.\n>\n>\n> *Improving the privacy of this design:*\n>\n> This design could likely be modified to implement something like\n> Tornado.cash or something else so that the fee account paying can be\n> unlinked from the transaction being paid for, improving privacy at the\n> expense of being a bit more expensive.\n>\n> Other operations could be added to allow a trustless mixing to be done by\n> miners automatically where groups of accounts with similar values are\n> trustlessly  split into a common denominator and change, and keys are\n> derived via a verifiable stealth address like protocol (so fee balances can\n> be discovered by tracing the updates posted). These updates could also be\n> produced by individuals rather than miners, and miners could simply honor\n> them with better privacy. While a miner generating an update would be able\n> to deanonymize their mixes, if you have your account mixed several times by\n> independent miners that could potentially add sufficient privacy.\n>\n> The LN can also be used with PTLCs to, in theory, have another individual\n> paid to sponsor a transaction on your behalf only if they reveal a valid\n> sig from their fee paying account, although under this model it's hard to\n> ensure that the owner doesn't pay a fee and then 'cancel' by withdrawing\n> the rest. However, this could be partly solved by using reputable fee\n> accounts (reputation could be measured somewhat decentralized-ly by\n> longevity of the account and transactions paid for historically).\n>\n> *Scalability*\n>\n> This design is fundamentally 'decent' for scalability because adding fees\n> to a transaction does not require adding inputs or outputs and does not\n> require tracking substantial amounts of new state.\n>\n> Paying someone else to pay for you via the LN also helps make this more\n> efficient if the withdrawal issues can be fixed.\n>\n> *Lightning:*\n>\n> This type of design works really well for channels because the addition of\n> fees to e.g. a channel state does not require any sort of pre-planning\n> (e.g. anchors) or transaction flexibility (SIGHASH flags). This sort of\n> design is naturally immune to pinning issues since you could offer to pay a\n> fee for any TXID and the number of fee adding offers does not need to be\n> restricted in the same way the descendant transactions would need to be.\n>\n> *Without a fork?*\n>\n> This type of design could be done as a federated network that bribes\n> miners -- potentially even retroactively after a block is formed. That\n> might be sufficient to prove the concept works before a consensus upgrade\n> is deployed, but such an approach does mean there is a centralizing layer\n> interfering with normal mining.\n>\n>\n> Happy new year!!\n>\n> Jeremy\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/655b3d36/attachment.html>"
            },
            {
                "author": "Jeremy",
                "date": "2022-01-18T17:43:07",
                "message_text_only": "Can you clarify what you mean by \"improve the situation\"?\n\nThere's a potential mild bytes savings, but the bigger deal is that the API\nshould be much less vulnerable to pinning issues, fix dust leakage for\neltoo like protocols, and just generally allow protocol designs to be fully\nabstracted from paying fees. You can't easily mathematically quantify API\nimprovements like that.\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Tue, Jan 18, 2022 at 8:13 AM Billy Tetrud <billy.tetrud at gmail.com> wrote:\n\n> Do you have any back-of-the-napkin math on quantifying how much this would\n> improve the situation vs existing methods (eg cpfp)?\n>\n>\n>\n> On Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Happy new years devs,\n>>\n>> I figured I would share some thoughts for conceptual review that have\n>> been bouncing around my head as an opportunity to clean up the fee paying\n>> semantics in bitcoin \"for good\". The design space is very wide on the\n>> approach I'll share, so below is just a sketch of how it could work which\n>> I'm sure could be improved greatly.\n>>\n>> Transaction fees are an integral part of bitcoin.\n>>\n>> However, due to quirks of Bitcoin's transaction design, fees are a part\n>> of the transactions that they occur in.\n>>\n>> While this works in a \"Bitcoin 1.0\" world, where all transactions are\n>> simple on-chain transfers, real world use of Bitcoin requires support for\n>> things like Fee Bumping stuck transactions, DoS resistant Payment Channels,\n>> and other long lived Smart Contracts that can't predict future fee rates.\n>> Having the fees paid in band makes writing these contracts much more\n>> difficult as you can't merely express the logic you want for the\n>> transaction, but also the fees.\n>>\n>> Previously, I proposed a special type of transaction called a \"Sponsor\"\n>> which has some special consensus + mempool rules to allow arbitrarily\n>> appending fees to a transaction to bump it up in the mempool.\n>>\n>> As an alternative, we could establish an account system in Bitcoin as an\n>> \"extension block\".\n>>\n>> *Here's how it might work:*\n>>\n>> 1. Define a special anyone can spend output type that is a \"fee account\"\n>> (e.g. segwit V2). Such outputs have a redeeming key and an amount\n>> associated with them, but are overall anyone can spend.\n>> 2. All deposits to these outputs get stored in a separate UTXO database\n>> for fee accounts\n>> 3. Fee accounts can sign only two kinds of transaction: A: a fee amount\n>> and a TXID (or Outpoint?); B: a withdraw amount, a fee, and an address\n>> 4. These transactions are committed in an extension block merkle tree.\n>> While the actual signature must cover the TXID/Outpoint, the committed data\n>> need only cover the index in the block of the transaction. The public key\n>> for account lookup can be recovered from the message + signature.\n>> 5. In any block, any of the fee account deposits can be: released into\n>> fees if there is a corresponding tx; consolidated together to reduce the\n>> number of utxos (this can be just an OP_TRUE no metadata needed); or\n>> released into fees *and paid back* into the requested withdrawal key\n>> (encumbering a 100 block timeout). Signatures must be unique in a block.\n>> 6. Mempool logic is updated to allow attaching of account fee spends to\n>> transactions, the mempool can restrict that an account is not allowed more\n>> spend more than it's balance.\n>>\n>> *But aren't accounts \"bad\"?*\n>>\n>> Yes, accounts are bad. But these accounts are not bad, because any funds\n>> withdrawn from the fee extension are fundamentally locked for 100 blocks as\n>> a coinbase output, so there should be no issues with any series of reorgs.\n>> Further, since there is no \"rich state\" for these accounts, the state\n>> updates can always be applied in a conflict-free way in any order.\n>>\n>>\n>> *Improving the privacy of this design:*\n>>\n>> This design could likely be modified to implement something like\n>> Tornado.cash or something else so that the fee account paying can be\n>> unlinked from the transaction being paid for, improving privacy at the\n>> expense of being a bit more expensive.\n>>\n>> Other operations could be added to allow a trustless mixing to be done by\n>> miners automatically where groups of accounts with similar values are\n>> trustlessly  split into a common denominator and change, and keys are\n>> derived via a verifiable stealth address like protocol (so fee balances can\n>> be discovered by tracing the updates posted). These updates could also be\n>> produced by individuals rather than miners, and miners could simply honor\n>> them with better privacy. While a miner generating an update would be able\n>> to deanonymize their mixes, if you have your account mixed several times by\n>> independent miners that could potentially add sufficient privacy.\n>>\n>> The LN can also be used with PTLCs to, in theory, have another individual\n>> paid to sponsor a transaction on your behalf only if they reveal a valid\n>> sig from their fee paying account, although under this model it's hard to\n>> ensure that the owner doesn't pay a fee and then 'cancel' by withdrawing\n>> the rest. However, this could be partly solved by using reputable fee\n>> accounts (reputation could be measured somewhat decentralized-ly by\n>> longevity of the account and transactions paid for historically).\n>>\n>> *Scalability*\n>>\n>> This design is fundamentally 'decent' for scalability because adding fees\n>> to a transaction does not require adding inputs or outputs and does not\n>> require tracking substantial amounts of new state.\n>>\n>> Paying someone else to pay for you via the LN also helps make this more\n>> efficient if the withdrawal issues can be fixed.\n>>\n>> *Lightning:*\n>>\n>> This type of design works really well for channels because the addition\n>> of fees to e.g. a channel state does not require any sort of pre-planning\n>> (e.g. anchors) or transaction flexibility (SIGHASH flags). This sort of\n>> design is naturally immune to pinning issues since you could offer to pay a\n>> fee for any TXID and the number of fee adding offers does not need to be\n>> restricted in the same way the descendant transactions would need to be.\n>>\n>> *Without a fork?*\n>>\n>> This type of design could be done as a federated network that bribes\n>> miners -- potentially even retroactively after a block is formed. That\n>> might be sufficient to prove the concept works before a consensus upgrade\n>> is deployed, but such an approach does mean there is a centralizing layer\n>> interfering with normal mining.\n>>\n>>\n>> Happy new year!!\n>>\n>> Jeremy\n>>\n>> --\n>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>> <https://twitter.com/JeremyRubin>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/d8324802/attachment.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-01-19T02:37:39",
                "message_text_only": "I see, its not primarily to make it cheaper to append fees, but also allows\nappending fees in cases that aren't possible now. Is that right? I can\ncertainly see the benefit of a more general way to add a fee to any\ntransaction, regardless of whether you're related to that transaction or\nnot.\n\nHow would you compare the pros and cons of your account-based approach to\nsomething like a new sighash flag? Eg a sighash flag that says \"I'm signing\nthis transaction, but the signature is only valid if mined in the same\nblock as transaction X (or maybe transactions LIST)\". This could be named\nSIGHASH_EXTERNAL. Doing this would be a lot more similar to other bitcoin\ntransactions, and no special account would need to be created. Any\ntransaction could specify this. At least that's the first thought I would\nhave in designing a way to arbitrarily bump fees. Have you compared your\nsolution to something more familiar like that?\n\nOn Tue, Jan 18, 2022 at 11:43 AM Jeremy <jlrubin at mit.edu> wrote:\n\n> Can you clarify what you mean by \"improve the situation\"?\n>\n> There's a potential mild bytes savings, but the bigger deal is that the\n> API should be much less vulnerable to pinning issues, fix dust leakage for\n> eltoo like protocols, and just generally allow protocol designs to be fully\n> abstracted from paying fees. You can't easily mathematically quantify API\n> improvements like that.\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n>\n>\n> On Tue, Jan 18, 2022 at 8:13 AM Billy Tetrud <billy.tetrud at gmail.com>\n> wrote:\n>\n>> Do you have any back-of-the-napkin math on quantifying how much this\n>> would improve the situation vs existing methods (eg cpfp)?\n>>\n>>\n>>\n>> On Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Happy new years devs,\n>>>\n>>> I figured I would share some thoughts for conceptual review that have\n>>> been bouncing around my head as an opportunity to clean up the fee paying\n>>> semantics in bitcoin \"for good\". The design space is very wide on the\n>>> approach I'll share, so below is just a sketch of how it could work which\n>>> I'm sure could be improved greatly.\n>>>\n>>> Transaction fees are an integral part of bitcoin.\n>>>\n>>> However, due to quirks of Bitcoin's transaction design, fees are a part\n>>> of the transactions that they occur in.\n>>>\n>>> While this works in a \"Bitcoin 1.0\" world, where all transactions are\n>>> simple on-chain transfers, real world use of Bitcoin requires support for\n>>> things like Fee Bumping stuck transactions, DoS resistant Payment Channels,\n>>> and other long lived Smart Contracts that can't predict future fee rates.\n>>> Having the fees paid in band makes writing these contracts much more\n>>> difficult as you can't merely express the logic you want for the\n>>> transaction, but also the fees.\n>>>\n>>> Previously, I proposed a special type of transaction called a \"Sponsor\"\n>>> which has some special consensus + mempool rules to allow arbitrarily\n>>> appending fees to a transaction to bump it up in the mempool.\n>>>\n>>> As an alternative, we could establish an account system in Bitcoin as an\n>>> \"extension block\".\n>>>\n>>> *Here's how it might work:*\n>>>\n>>> 1. Define a special anyone can spend output type that is a \"fee account\"\n>>> (e.g. segwit V2). Such outputs have a redeeming key and an amount\n>>> associated with them, but are overall anyone can spend.\n>>> 2. All deposits to these outputs get stored in a separate UTXO database\n>>> for fee accounts\n>>> 3. Fee accounts can sign only two kinds of transaction: A: a fee amount\n>>> and a TXID (or Outpoint?); B: a withdraw amount, a fee, and an address\n>>> 4. These transactions are committed in an extension block merkle tree.\n>>> While the actual signature must cover the TXID/Outpoint, the committed data\n>>> need only cover the index in the block of the transaction. The public key\n>>> for account lookup can be recovered from the message + signature.\n>>> 5. In any block, any of the fee account deposits can be: released into\n>>> fees if there is a corresponding tx; consolidated together to reduce the\n>>> number of utxos (this can be just an OP_TRUE no metadata needed); or\n>>> released into fees *and paid back* into the requested withdrawal key\n>>> (encumbering a 100 block timeout). Signatures must be unique in a block.\n>>> 6. Mempool logic is updated to allow attaching of account fee spends to\n>>> transactions, the mempool can restrict that an account is not allowed more\n>>> spend more than it's balance.\n>>>\n>>> *But aren't accounts \"bad\"?*\n>>>\n>>> Yes, accounts are bad. But these accounts are not bad, because any funds\n>>> withdrawn from the fee extension are fundamentally locked for 100 blocks as\n>>> a coinbase output, so there should be no issues with any series of reorgs.\n>>> Further, since there is no \"rich state\" for these accounts, the state\n>>> updates can always be applied in a conflict-free way in any order.\n>>>\n>>>\n>>> *Improving the privacy of this design:*\n>>>\n>>> This design could likely be modified to implement something like\n>>> Tornado.cash or something else so that the fee account paying can be\n>>> unlinked from the transaction being paid for, improving privacy at the\n>>> expense of being a bit more expensive.\n>>>\n>>> Other operations could be added to allow a trustless mixing to be done\n>>> by miners automatically where groups of accounts with similar values are\n>>> trustlessly  split into a common denominator and change, and keys are\n>>> derived via a verifiable stealth address like protocol (so fee balances can\n>>> be discovered by tracing the updates posted). These updates could also be\n>>> produced by individuals rather than miners, and miners could simply honor\n>>> them with better privacy. While a miner generating an update would be able\n>>> to deanonymize their mixes, if you have your account mixed several times by\n>>> independent miners that could potentially add sufficient privacy.\n>>>\n>>> The LN can also be used with PTLCs to, in theory, have another\n>>> individual paid to sponsor a transaction on your behalf only if they reveal\n>>> a valid sig from their fee paying account, although under this model it's\n>>> hard to ensure that the owner doesn't pay a fee and then 'cancel' by\n>>> withdrawing the rest. However, this could be partly solved by using\n>>> reputable fee accounts (reputation could be measured somewhat\n>>> decentralized-ly by longevity of the account and transactions paid for\n>>> historically).\n>>>\n>>> *Scalability*\n>>>\n>>> This design is fundamentally 'decent' for scalability because adding\n>>> fees to a transaction does not require adding inputs or outputs and does\n>>> not require tracking substantial amounts of new state.\n>>>\n>>> Paying someone else to pay for you via the LN also helps make this more\n>>> efficient if the withdrawal issues can be fixed.\n>>>\n>>> *Lightning:*\n>>>\n>>> This type of design works really well for channels because the addition\n>>> of fees to e.g. a channel state does not require any sort of pre-planning\n>>> (e.g. anchors) or transaction flexibility (SIGHASH flags). This sort of\n>>> design is naturally immune to pinning issues since you could offer to pay a\n>>> fee for any TXID and the number of fee adding offers does not need to be\n>>> restricted in the same way the descendant transactions would need to be.\n>>>\n>>> *Without a fork?*\n>>>\n>>> This type of design could be done as a federated network that bribes\n>>> miners -- potentially even retroactively after a block is formed. That\n>>> might be sufficient to prove the concept works before a consensus upgrade\n>>> is deployed, but such an approach does mean there is a centralizing layer\n>>> interfering with normal mining.\n>>>\n>>>\n>>> Happy new year!!\n>>>\n>>> Jeremy\n>>>\n>>> --\n>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>> <https://twitter.com/JeremyRubin>\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/3c72c1c7/attachment-0001.html>"
            },
            {
                "author": "Jeremy",
                "date": "2022-01-19T02:51:42",
                "message_text_only": "The issue with sighash flags is that because you make transactions third\nparty malleable it becomes possible to bundle and unbundle transactions.\n\nThis means there are circumstances where an attacker could e.g. see your\ntxn, and then add a lot of junk change/inputs + 25 descendants and strongly\nanchor your transaction to the bottom of the mempool.\n\nbecause of rbf rules requiring more fee and feerate, this means you have to\nbump across the whole package and that can get really messy.\n\nmore generally speaking, you could imagine a future where mempools track\nmany alternative things that might want to be in a transaction.\n\nsuppose there are N inputs each with a weight and an amount of fee being\nadded and the sighash flags let me pick any subset of them. However, for a\ntxn to be standard it must be < 100k bytes and for it to be consensus <\n1mb. Now it is possible you have to solve a knapsack problem in order to\nrationally bundle this transaction out of all possibilities.\n\nThis problem can get even thornier, suppose that the inputs I'm adding\nthemselves are the outputs of another txn in the mempool, now i have to\ntrack and propagate the feerates of that child back up to the parent txn\nand track all these dependencies.\n\nperhaps with very careful engineering these issues can be tamed. however it\nseems with sponsors or fee accounts, by separating the pays-for from the\nparticipates-in concerns we can greatly simplify it to something like:\ncompute effective feerate for a txn, including all sponsors that pay more\nthan the feerate of the base txn. Mine that txn and it's subsidies using\nthe normal algo. If you run out of space, all subsidies are same-sized so\njust take the ones that pay the highest amount up until the added marginal\nfeerate is less than the next eligible txn.\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Tue, Jan 18, 2022 at 6:38 PM Billy Tetrud <billy.tetrud at gmail.com> wrote:\n\n> I see, its not primarily to make it cheaper to append fees, but also\n> allows appending fees in cases that aren't possible now. Is that right? I\n> can certainly see the benefit of a more general way to add a fee to any\n> transaction, regardless of whether you're related to that transaction or\n> not.\n>\n> How would you compare the pros and cons of your account-based approach to\n> something like a new sighash flag? Eg a sighash flag that says \"I'm signing\n> this transaction, but the signature is only valid if mined in the same\n> block as transaction X (or maybe transactions LIST)\". This could be named\n> SIGHASH_EXTERNAL. Doing this would be a lot more similar to other bitcoin\n> transactions, and no special account would need to be created. Any\n> transaction could specify this. At least that's the first thought I would\n> have in designing a way to arbitrarily bump fees. Have you compared your\n> solution to something more familiar like that?\n>\n> On Tue, Jan 18, 2022 at 11:43 AM Jeremy <jlrubin at mit.edu> wrote:\n>\n>> Can you clarify what you mean by \"improve the situation\"?\n>>\n>> There's a potential mild bytes savings, but the bigger deal is that the\n>> API should be much less vulnerable to pinning issues, fix dust leakage for\n>> eltoo like protocols, and just generally allow protocol designs to be fully\n>> abstracted from paying fees. You can't easily mathematically quantify API\n>> improvements like that.\n>> --\n>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>> <https://twitter.com/JeremyRubin>\n>>\n>>\n>> On Tue, Jan 18, 2022 at 8:13 AM Billy Tetrud <billy.tetrud at gmail.com>\n>> wrote:\n>>\n>>> Do you have any back-of-the-napkin math on quantifying how much this\n>>> would improve the situation vs existing methods (eg cpfp)?\n>>>\n>>>\n>>>\n>>> On Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <\n>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> Happy new years devs,\n>>>>\n>>>> I figured I would share some thoughts for conceptual review that have\n>>>> been bouncing around my head as an opportunity to clean up the fee paying\n>>>> semantics in bitcoin \"for good\". The design space is very wide on the\n>>>> approach I'll share, so below is just a sketch of how it could work which\n>>>> I'm sure could be improved greatly.\n>>>>\n>>>> Transaction fees are an integral part of bitcoin.\n>>>>\n>>>> However, due to quirks of Bitcoin's transaction design, fees are a part\n>>>> of the transactions that they occur in.\n>>>>\n>>>> While this works in a \"Bitcoin 1.0\" world, where all transactions are\n>>>> simple on-chain transfers, real world use of Bitcoin requires support for\n>>>> things like Fee Bumping stuck transactions, DoS resistant Payment Channels,\n>>>> and other long lived Smart Contracts that can't predict future fee rates.\n>>>> Having the fees paid in band makes writing these contracts much more\n>>>> difficult as you can't merely express the logic you want for the\n>>>> transaction, but also the fees.\n>>>>\n>>>> Previously, I proposed a special type of transaction called a \"Sponsor\"\n>>>> which has some special consensus + mempool rules to allow arbitrarily\n>>>> appending fees to a transaction to bump it up in the mempool.\n>>>>\n>>>> As an alternative, we could establish an account system in Bitcoin as\n>>>> an \"extension block\".\n>>>>\n>>>> *Here's how it might work:*\n>>>>\n>>>> 1. Define a special anyone can spend output type that is a \"fee\n>>>> account\" (e.g. segwit V2). Such outputs have a redeeming key and an amount\n>>>> associated with them, but are overall anyone can spend.\n>>>> 2. All deposits to these outputs get stored in a separate UTXO database\n>>>> for fee accounts\n>>>> 3. Fee accounts can sign only two kinds of transaction: A: a fee amount\n>>>> and a TXID (or Outpoint?); B: a withdraw amount, a fee, and an address\n>>>> 4. These transactions are committed in an extension block merkle tree.\n>>>> While the actual signature must cover the TXID/Outpoint, the committed data\n>>>> need only cover the index in the block of the transaction. The public key\n>>>> for account lookup can be recovered from the message + signature.\n>>>> 5. In any block, any of the fee account deposits can be: released into\n>>>> fees if there is a corresponding tx; consolidated together to reduce the\n>>>> number of utxos (this can be just an OP_TRUE no metadata needed); or\n>>>> released into fees *and paid back* into the requested withdrawal key\n>>>> (encumbering a 100 block timeout). Signatures must be unique in a block.\n>>>> 6. Mempool logic is updated to allow attaching of account fee spends to\n>>>> transactions, the mempool can restrict that an account is not allowed more\n>>>> spend more than it's balance.\n>>>>\n>>>> *But aren't accounts \"bad\"?*\n>>>>\n>>>> Yes, accounts are bad. But these accounts are not bad, because any\n>>>> funds withdrawn from the fee extension are fundamentally locked for 100\n>>>> blocks as a coinbase output, so there should be no issues with any series\n>>>> of reorgs. Further, since there is no \"rich state\" for these accounts, the\n>>>> state updates can always be applied in a conflict-free way in any order.\n>>>>\n>>>>\n>>>> *Improving the privacy of this design:*\n>>>>\n>>>> This design could likely be modified to implement something like\n>>>> Tornado.cash or something else so that the fee account paying can be\n>>>> unlinked from the transaction being paid for, improving privacy at the\n>>>> expense of being a bit more expensive.\n>>>>\n>>>> Other operations could be added to allow a trustless mixing to be done\n>>>> by miners automatically where groups of accounts with similar values are\n>>>> trustlessly  split into a common denominator and change, and keys are\n>>>> derived via a verifiable stealth address like protocol (so fee balances can\n>>>> be discovered by tracing the updates posted). These updates could also be\n>>>> produced by individuals rather than miners, and miners could simply honor\n>>>> them with better privacy. While a miner generating an update would be able\n>>>> to deanonymize their mixes, if you have your account mixed several times by\n>>>> independent miners that could potentially add sufficient privacy.\n>>>>\n>>>> The LN can also be used with PTLCs to, in theory, have another\n>>>> individual paid to sponsor a transaction on your behalf only if they reveal\n>>>> a valid sig from their fee paying account, although under this model it's\n>>>> hard to ensure that the owner doesn't pay a fee and then 'cancel' by\n>>>> withdrawing the rest. However, this could be partly solved by using\n>>>> reputable fee accounts (reputation could be measured somewhat\n>>>> decentralized-ly by longevity of the account and transactions paid for\n>>>> historically).\n>>>>\n>>>> *Scalability*\n>>>>\n>>>> This design is fundamentally 'decent' for scalability because adding\n>>>> fees to a transaction does not require adding inputs or outputs and does\n>>>> not require tracking substantial amounts of new state.\n>>>>\n>>>> Paying someone else to pay for you via the LN also helps make this more\n>>>> efficient if the withdrawal issues can be fixed.\n>>>>\n>>>> *Lightning:*\n>>>>\n>>>> This type of design works really well for channels because the addition\n>>>> of fees to e.g. a channel state does not require any sort of pre-planning\n>>>> (e.g. anchors) or transaction flexibility (SIGHASH flags). This sort of\n>>>> design is naturally immune to pinning issues since you could offer to pay a\n>>>> fee for any TXID and the number of fee adding offers does not need to be\n>>>> restricted in the same way the descendant transactions would need to be.\n>>>>\n>>>> *Without a fork?*\n>>>>\n>>>> This type of design could be done as a federated network that bribes\n>>>> miners -- potentially even retroactively after a block is formed. That\n>>>> might be sufficient to prove the concept works before a consensus upgrade\n>>>> is deployed, but such an approach does mean there is a centralizing layer\n>>>> interfering with normal mining.\n>>>>\n>>>>\n>>>> Happy new year!!\n>>>>\n>>>> Jeremy\n>>>>\n>>>> --\n>>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>>> <https://twitter.com/JeremyRubin>\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>\n>>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/bde037b2/attachment-0001.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-01-19T04:53:21",
                "message_text_only": ">  because you make transactions third party malleable it becomes possible\nto bundle and unbundle transactions.\n\nWhat I was suggesting doesn't make it possible to malleate someone else's\ntransaction. I guess maybe my proposal of using a sighash flag might have\nbeen unclear. Imagine it as a script opcode that just says \"this\ntransaction must be mined with this other transaction\" - the only\ndifference being that you can use any output with any encumberance as an\ninput for fee bumping. It doesn't prevent the original transaction from\nbeing mined on its own. So adding junk inputs would be no more of a problem\nthan dust attacks already are. It would be used exactly like cpfp, except\nit doesn't spend the parent.\n\nI don't think what I was suggesting is as different from your proposal. All\nthe problems of fee revenue optimization and feerate rules that you\nmentioned seem like they'd also exist for your proposal, or for cpfp. Let\nme know if I should clarify further.\n\nOn Tue, Jan 18, 2022 at 8:51 PM Jeremy <jlrubin at mit.edu> wrote:\n\n> The issue with sighash flags is that because you make transactions third\n> party malleable it becomes possible to bundle and unbundle transactions.\n>\n> This means there are circumstances where an attacker could e.g. see your\n> txn, and then add a lot of junk change/inputs + 25 descendants and strongly\n> anchor your transaction to the bottom of the mempool.\n>\n> because of rbf rules requiring more fee and feerate, this means you have\n> to bump across the whole package and that can get really messy.\n>\n> more generally speaking, you could imagine a future where mempools track\n> many alternative things that might want to be in a transaction.\n>\n> suppose there are N inputs each with a weight and an amount of fee being\n> added and the sighash flags let me pick any subset of them. However, for a\n> txn to be standard it must be < 100k bytes and for it to be consensus <\n> 1mb. Now it is possible you have to solve a knapsack problem in order to\n> rationally bundle this transaction out of all possibilities.\n>\n> This problem can get even thornier, suppose that the inputs I'm adding\n> themselves are the outputs of another txn in the mempool, now i have to\n> track and propagate the feerates of that child back up to the parent txn\n> and track all these dependencies.\n>\n> perhaps with very careful engineering these issues can be tamed. however\n> it seems with sponsors or fee accounts, by separating the pays-for from the\n> participates-in concerns we can greatly simplify it to something like:\n> compute effective feerate for a txn, including all sponsors that pay more\n> than the feerate of the base txn. Mine that txn and it's subsidies using\n> the normal algo. If you run out of space, all subsidies are same-sized so\n> just take the ones that pay the highest amount up until the added marginal\n> feerate is less than the next eligible txn.\n>\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n>\n>\n> On Tue, Jan 18, 2022 at 6:38 PM Billy Tetrud <billy.tetrud at gmail.com>\n> wrote:\n>\n>> I see, its not primarily to make it cheaper to append fees, but also\n>> allows appending fees in cases that aren't possible now. Is that right? I\n>> can certainly see the benefit of a more general way to add a fee to any\n>> transaction, regardless of whether you're related to that transaction or\n>> not.\n>>\n>> How would you compare the pros and cons of your account-based approach to\n>> something like a new sighash flag? Eg a sighash flag that says \"I'm signing\n>> this transaction, but the signature is only valid if mined in the same\n>> block as transaction X (or maybe transactions LIST)\". This could be named\n>> SIGHASH_EXTERNAL. Doing this would be a lot more similar to other bitcoin\n>> transactions, and no special account would need to be created. Any\n>> transaction could specify this. At least that's the first thought I would\n>> have in designing a way to arbitrarily bump fees. Have you compared your\n>> solution to something more familiar like that?\n>>\n>> On Tue, Jan 18, 2022 at 11:43 AM Jeremy <jlrubin at mit.edu> wrote:\n>>\n>>> Can you clarify what you mean by \"improve the situation\"?\n>>>\n>>> There's a potential mild bytes savings, but the bigger deal is that the\n>>> API should be much less vulnerable to pinning issues, fix dust leakage for\n>>> eltoo like protocols, and just generally allow protocol designs to be fully\n>>> abstracted from paying fees. You can't easily mathematically quantify API\n>>> improvements like that.\n>>> --\n>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>> <https://twitter.com/JeremyRubin>\n>>>\n>>>\n>>> On Tue, Jan 18, 2022 at 8:13 AM Billy Tetrud <billy.tetrud at gmail.com>\n>>> wrote:\n>>>\n>>>> Do you have any back-of-the-napkin math on quantifying how much this\n>>>> would improve the situation vs existing methods (eg cpfp)?\n>>>>\n>>>>\n>>>>\n>>>> On Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <\n>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>\n>>>>> Happy new years devs,\n>>>>>\n>>>>> I figured I would share some thoughts for conceptual review that have\n>>>>> been bouncing around my head as an opportunity to clean up the fee paying\n>>>>> semantics in bitcoin \"for good\". The design space is very wide on the\n>>>>> approach I'll share, so below is just a sketch of how it could work which\n>>>>> I'm sure could be improved greatly.\n>>>>>\n>>>>> Transaction fees are an integral part of bitcoin.\n>>>>>\n>>>>> However, due to quirks of Bitcoin's transaction design, fees are a\n>>>>> part of the transactions that they occur in.\n>>>>>\n>>>>> While this works in a \"Bitcoin 1.0\" world, where all transactions are\n>>>>> simple on-chain transfers, real world use of Bitcoin requires support for\n>>>>> things like Fee Bumping stuck transactions, DoS resistant Payment Channels,\n>>>>> and other long lived Smart Contracts that can't predict future fee rates.\n>>>>> Having the fees paid in band makes writing these contracts much more\n>>>>> difficult as you can't merely express the logic you want for the\n>>>>> transaction, but also the fees.\n>>>>>\n>>>>> Previously, I proposed a special type of transaction called a\n>>>>> \"Sponsor\" which has some special consensus + mempool rules to allow\n>>>>> arbitrarily appending fees to a transaction to bump it up in the mempool.\n>>>>>\n>>>>> As an alternative, we could establish an account system in Bitcoin as\n>>>>> an \"extension block\".\n>>>>>\n>>>>> *Here's how it might work:*\n>>>>>\n>>>>> 1. Define a special anyone can spend output type that is a \"fee\n>>>>> account\" (e.g. segwit V2). Such outputs have a redeeming key and an amount\n>>>>> associated with them, but are overall anyone can spend.\n>>>>> 2. All deposits to these outputs get stored in a separate UTXO\n>>>>> database for fee accounts\n>>>>> 3. Fee accounts can sign only two kinds of transaction: A: a fee\n>>>>> amount and a TXID (or Outpoint?); B: a withdraw amount, a fee, and\n>>>>> an address\n>>>>> 4. These transactions are committed in an extension block merkle tree.\n>>>>> While the actual signature must cover the TXID/Outpoint, the committed data\n>>>>> need only cover the index in the block of the transaction. The public key\n>>>>> for account lookup can be recovered from the message + signature.\n>>>>> 5. In any block, any of the fee account deposits can be: released into\n>>>>> fees if there is a corresponding tx; consolidated together to reduce the\n>>>>> number of utxos (this can be just an OP_TRUE no metadata needed); or\n>>>>> released into fees *and paid back* into the requested withdrawal key\n>>>>> (encumbering a 100 block timeout). Signatures must be unique in a block.\n>>>>> 6. Mempool logic is updated to allow attaching of account fee spends\n>>>>> to transactions, the mempool can restrict that an account is not allowed\n>>>>> more spend more than it's balance.\n>>>>>\n>>>>> *But aren't accounts \"bad\"?*\n>>>>>\n>>>>> Yes, accounts are bad. But these accounts are not bad, because any\n>>>>> funds withdrawn from the fee extension are fundamentally locked for 100\n>>>>> blocks as a coinbase output, so there should be no issues with any series\n>>>>> of reorgs. Further, since there is no \"rich state\" for these accounts, the\n>>>>> state updates can always be applied in a conflict-free way in any order.\n>>>>>\n>>>>>\n>>>>> *Improving the privacy of this design:*\n>>>>>\n>>>>> This design could likely be modified to implement something like\n>>>>> Tornado.cash or something else so that the fee account paying can be\n>>>>> unlinked from the transaction being paid for, improving privacy at the\n>>>>> expense of being a bit more expensive.\n>>>>>\n>>>>> Other operations could be added to allow a trustless mixing to be done\n>>>>> by miners automatically where groups of accounts with similar values are\n>>>>> trustlessly  split into a common denominator and change, and keys are\n>>>>> derived via a verifiable stealth address like protocol (so fee balances can\n>>>>> be discovered by tracing the updates posted). These updates could also be\n>>>>> produced by individuals rather than miners, and miners could simply honor\n>>>>> them with better privacy. While a miner generating an update would be able\n>>>>> to deanonymize their mixes, if you have your account mixed several times by\n>>>>> independent miners that could potentially add sufficient privacy.\n>>>>>\n>>>>> The LN can also be used with PTLCs to, in theory, have another\n>>>>> individual paid to sponsor a transaction on your behalf only if they reveal\n>>>>> a valid sig from their fee paying account, although under this model it's\n>>>>> hard to ensure that the owner doesn't pay a fee and then 'cancel' by\n>>>>> withdrawing the rest. However, this could be partly solved by using\n>>>>> reputable fee accounts (reputation could be measured somewhat\n>>>>> decentralized-ly by longevity of the account and transactions paid for\n>>>>> historically).\n>>>>>\n>>>>> *Scalability*\n>>>>>\n>>>>> This design is fundamentally 'decent' for scalability because adding\n>>>>> fees to a transaction does not require adding inputs or outputs and does\n>>>>> not require tracking substantial amounts of new state.\n>>>>>\n>>>>> Paying someone else to pay for you via the LN also helps make this\n>>>>> more efficient if the withdrawal issues can be fixed.\n>>>>>\n>>>>> *Lightning:*\n>>>>>\n>>>>> This type of design works really well for channels because the\n>>>>> addition of fees to e.g. a channel state does not require any sort of\n>>>>> pre-planning (e.g. anchors) or transaction flexibility (SIGHASH flags).\n>>>>> This sort of design is naturally immune to pinning issues since you could\n>>>>> offer to pay a fee for any TXID and the number of fee adding offers does\n>>>>> not need to be restricted in the same way the descendant transactions would\n>>>>> need to be.\n>>>>>\n>>>>> *Without a fork?*\n>>>>>\n>>>>> This type of design could be done as a federated network that bribes\n>>>>> miners -- potentially even retroactively after a block is formed. That\n>>>>> might be sufficient to prove the concept works before a consensus upgrade\n>>>>> is deployed, but such an approach does mean there is a centralizing layer\n>>>>> interfering with normal mining.\n>>>>>\n>>>>>\n>>>>> Happy new year!!\n>>>>>\n>>>>> Jeremy\n>>>>>\n>>>>> --\n>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>>>> <https://twitter.com/JeremyRubin>\n>>>>> _______________________________________________\n>>>>> bitcoin-dev mailing list\n>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>\n>>>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/59a75bc9/attachment-0001.html>"
            },
            {
                "author": "Jeremy",
                "date": "2022-01-19T07:32:36",
                "message_text_only": "Ah my bad i misread what you were saying as being about SIGHASH_BUNDLE like\nproposals.\n\nFor what you're discussing, I previously proposed\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-September/018168.html\nwhich is similar.\n\nThe benefit of the OP_VER output is that SIGHASH_EXTERNAL has the issue\nthat unless you're binding a WTXID (which is maybe too specific?) then you\ncan have fee bumping cycles. Doing OP_VER output w/ TXID guarantees that\nyou are acyclic.\n\nThe difference between a fee account and this approach basically boils down\nto the impact on e.g. reorg stability, where the deposit/withdraw mechanism\nis a bit more \"robust\" for reorderings in reorgs than the in-band\ntransaction approach, although they are very similar.\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Tue, Jan 18, 2022 at 8:53 PM Billy Tetrud <billy.tetrud at gmail.com> wrote:\n\n> >  because you make transactions third party malleable it becomes\n> possible to bundle and unbundle transactions.\n>\n> What I was suggesting doesn't make it possible to malleate someone else's\n> transaction. I guess maybe my proposal of using a sighash flag might have\n> been unclear. Imagine it as a script opcode that just says \"this\n> transaction must be mined with this other transaction\" - the only\n> difference being that you can use any output with any encumberance as an\n> input for fee bumping. It doesn't prevent the original transaction from\n> being mined on its own. So adding junk inputs would be no more of a problem\n> than dust attacks already are. It would be used exactly like cpfp, except\n> it doesn't spend the parent.\n>\n> I don't think what I was suggesting is as different from your proposal.\n> All the problems of fee revenue optimization and feerate rules that you\n> mentioned seem like they'd also exist for your proposal, or for cpfp. Let\n> me know if I should clarify further.\n>\n> On Tue, Jan 18, 2022 at 8:51 PM Jeremy <jlrubin at mit.edu> wrote:\n>\n>> The issue with sighash flags is that because you make transactions third\n>> party malleable it becomes possible to bundle and unbundle transactions.\n>>\n>> This means there are circumstances where an attacker could e.g. see your\n>> txn, and then add a lot of junk change/inputs + 25 descendants and strongly\n>> anchor your transaction to the bottom of the mempool.\n>>\n>> because of rbf rules requiring more fee and feerate, this means you have\n>> to bump across the whole package and that can get really messy.\n>>\n>> more generally speaking, you could imagine a future where mempools track\n>> many alternative things that might want to be in a transaction.\n>>\n>> suppose there are N inputs each with a weight and an amount of fee being\n>> added and the sighash flags let me pick any subset of them. However, for a\n>> txn to be standard it must be < 100k bytes and for it to be consensus <\n>> 1mb. Now it is possible you have to solve a knapsack problem in order to\n>> rationally bundle this transaction out of all possibilities.\n>>\n>> This problem can get even thornier, suppose that the inputs I'm adding\n>> themselves are the outputs of another txn in the mempool, now i have to\n>> track and propagate the feerates of that child back up to the parent txn\n>> and track all these dependencies.\n>>\n>> perhaps with very careful engineering these issues can be tamed. however\n>> it seems with sponsors or fee accounts, by separating the pays-for from the\n>> participates-in concerns we can greatly simplify it to something like:\n>> compute effective feerate for a txn, including all sponsors that pay more\n>> than the feerate of the base txn. Mine that txn and it's subsidies using\n>> the normal algo. If you run out of space, all subsidies are same-sized so\n>> just take the ones that pay the highest amount up until the added marginal\n>> feerate is less than the next eligible txn.\n>>\n>>\n>> --\n>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>> <https://twitter.com/JeremyRubin>\n>>\n>>\n>> On Tue, Jan 18, 2022 at 6:38 PM Billy Tetrud <billy.tetrud at gmail.com>\n>> wrote:\n>>\n>>> I see, its not primarily to make it cheaper to append fees, but also\n>>> allows appending fees in cases that aren't possible now. Is that right? I\n>>> can certainly see the benefit of a more general way to add a fee to any\n>>> transaction, regardless of whether you're related to that transaction or\n>>> not.\n>>>\n>>> How would you compare the pros and cons of your account-based approach\n>>> to something like a new sighash flag? Eg a sighash flag that says \"I'm\n>>> signing this transaction, but the signature is only valid if mined in the\n>>> same block as transaction X (or maybe transactions LIST)\". This could be\n>>> named SIGHASH_EXTERNAL. Doing this would be a lot more similar to other\n>>> bitcoin transactions, and no special account would need to be created. Any\n>>> transaction could specify this. At least that's the first thought I would\n>>> have in designing a way to arbitrarily bump fees. Have you compared your\n>>> solution to something more familiar like that?\n>>>\n>>> On Tue, Jan 18, 2022 at 11:43 AM Jeremy <jlrubin at mit.edu> wrote:\n>>>\n>>>> Can you clarify what you mean by \"improve the situation\"?\n>>>>\n>>>> There's a potential mild bytes savings, but the bigger deal is that the\n>>>> API should be much less vulnerable to pinning issues, fix dust leakage for\n>>>> eltoo like protocols, and just generally allow protocol designs to be fully\n>>>> abstracted from paying fees. You can't easily mathematically quantify API\n>>>> improvements like that.\n>>>> --\n>>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>>> <https://twitter.com/JeremyRubin>\n>>>>\n>>>>\n>>>> On Tue, Jan 18, 2022 at 8:13 AM Billy Tetrud <billy.tetrud at gmail.com>\n>>>> wrote:\n>>>>\n>>>>> Do you have any back-of-the-napkin math on quantifying how much this\n>>>>> would improve the situation vs existing methods (eg cpfp)?\n>>>>>\n>>>>>\n>>>>>\n>>>>> On Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <\n>>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>>\n>>>>>> Happy new years devs,\n>>>>>>\n>>>>>> I figured I would share some thoughts for conceptual review that have\n>>>>>> been bouncing around my head as an opportunity to clean up the fee paying\n>>>>>> semantics in bitcoin \"for good\". The design space is very wide on the\n>>>>>> approach I'll share, so below is just a sketch of how it could work which\n>>>>>> I'm sure could be improved greatly.\n>>>>>>\n>>>>>> Transaction fees are an integral part of bitcoin.\n>>>>>>\n>>>>>> However, due to quirks of Bitcoin's transaction design, fees are a\n>>>>>> part of the transactions that they occur in.\n>>>>>>\n>>>>>> While this works in a \"Bitcoin 1.0\" world, where all transactions are\n>>>>>> simple on-chain transfers, real world use of Bitcoin requires support for\n>>>>>> things like Fee Bumping stuck transactions, DoS resistant Payment Channels,\n>>>>>> and other long lived Smart Contracts that can't predict future fee rates.\n>>>>>> Having the fees paid in band makes writing these contracts much more\n>>>>>> difficult as you can't merely express the logic you want for the\n>>>>>> transaction, but also the fees.\n>>>>>>\n>>>>>> Previously, I proposed a special type of transaction called a\n>>>>>> \"Sponsor\" which has some special consensus + mempool rules to allow\n>>>>>> arbitrarily appending fees to a transaction to bump it up in the mempool.\n>>>>>>\n>>>>>> As an alternative, we could establish an account system in Bitcoin as\n>>>>>> an \"extension block\".\n>>>>>>\n>>>>>> *Here's how it might work:*\n>>>>>>\n>>>>>> 1. Define a special anyone can spend output type that is a \"fee\n>>>>>> account\" (e.g. segwit V2). Such outputs have a redeeming key and an amount\n>>>>>> associated with them, but are overall anyone can spend.\n>>>>>> 2. All deposits to these outputs get stored in a separate UTXO\n>>>>>> database for fee accounts\n>>>>>> 3. Fee accounts can sign only two kinds of transaction: A: a fee\n>>>>>> amount and a TXID (or Outpoint?); B: a withdraw amount, a fee, and\n>>>>>> an address\n>>>>>> 4. These transactions are committed in an extension block merkle\n>>>>>> tree. While the actual signature must cover the TXID/Outpoint, the\n>>>>>> committed data need only cover the index in the block of the transaction.\n>>>>>> The public key for account lookup can be recovered from the message +\n>>>>>> signature.\n>>>>>> 5. In any block, any of the fee account deposits can be: released\n>>>>>> into fees if there is a corresponding tx; consolidated together to reduce\n>>>>>> the number of utxos (this can be just an OP_TRUE no metadata needed); or\n>>>>>> released into fees *and paid back* into the requested withdrawal key\n>>>>>> (encumbering a 100 block timeout). Signatures must be unique in a block.\n>>>>>> 6. Mempool logic is updated to allow attaching of account fee spends\n>>>>>> to transactions, the mempool can restrict that an account is not allowed\n>>>>>> more spend more than it's balance.\n>>>>>>\n>>>>>> *But aren't accounts \"bad\"?*\n>>>>>>\n>>>>>> Yes, accounts are bad. But these accounts are not bad, because any\n>>>>>> funds withdrawn from the fee extension are fundamentally locked for 100\n>>>>>> blocks as a coinbase output, so there should be no issues with any series\n>>>>>> of reorgs. Further, since there is no \"rich state\" for these accounts, the\n>>>>>> state updates can always be applied in a conflict-free way in any order.\n>>>>>>\n>>>>>>\n>>>>>> *Improving the privacy of this design:*\n>>>>>>\n>>>>>> This design could likely be modified to implement something like\n>>>>>> Tornado.cash or something else so that the fee account paying can be\n>>>>>> unlinked from the transaction being paid for, improving privacy at the\n>>>>>> expense of being a bit more expensive.\n>>>>>>\n>>>>>> Other operations could be added to allow a trustless mixing to be\n>>>>>> done by miners automatically where groups of accounts with similar values\n>>>>>> are trustlessly  split into a common denominator and change, and keys are\n>>>>>> derived via a verifiable stealth address like protocol (so fee balances can\n>>>>>> be discovered by tracing the updates posted). These updates could also be\n>>>>>> produced by individuals rather than miners, and miners could simply honor\n>>>>>> them with better privacy. While a miner generating an update would be able\n>>>>>> to deanonymize their mixes, if you have your account mixed several times by\n>>>>>> independent miners that could potentially add sufficient privacy.\n>>>>>>\n>>>>>> The LN can also be used with PTLCs to, in theory, have another\n>>>>>> individual paid to sponsor a transaction on your behalf only if they reveal\n>>>>>> a valid sig from their fee paying account, although under this model it's\n>>>>>> hard to ensure that the owner doesn't pay a fee and then 'cancel' by\n>>>>>> withdrawing the rest. However, this could be partly solved by using\n>>>>>> reputable fee accounts (reputation could be measured somewhat\n>>>>>> decentralized-ly by longevity of the account and transactions paid for\n>>>>>> historically).\n>>>>>>\n>>>>>> *Scalability*\n>>>>>>\n>>>>>> This design is fundamentally 'decent' for scalability because adding\n>>>>>> fees to a transaction does not require adding inputs or outputs and does\n>>>>>> not require tracking substantial amounts of new state.\n>>>>>>\n>>>>>> Paying someone else to pay for you via the LN also helps make this\n>>>>>> more efficient if the withdrawal issues can be fixed.\n>>>>>>\n>>>>>> *Lightning:*\n>>>>>>\n>>>>>> This type of design works really well for channels because the\n>>>>>> addition of fees to e.g. a channel state does not require any sort of\n>>>>>> pre-planning (e.g. anchors) or transaction flexibility (SIGHASH flags).\n>>>>>> This sort of design is naturally immune to pinning issues since you could\n>>>>>> offer to pay a fee for any TXID and the number of fee adding offers does\n>>>>>> not need to be restricted in the same way the descendant transactions would\n>>>>>> need to be.\n>>>>>>\n>>>>>> *Without a fork?*\n>>>>>>\n>>>>>> This type of design could be done as a federated network that bribes\n>>>>>> miners -- potentially even retroactively after a block is formed. That\n>>>>>> might be sufficient to prove the concept works before a consensus upgrade\n>>>>>> is deployed, but such an approach does mean there is a centralizing layer\n>>>>>> interfering with normal mining.\n>>>>>>\n>>>>>>\n>>>>>> Happy new year!!\n>>>>>>\n>>>>>> Jeremy\n>>>>>>\n>>>>>> --\n>>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>>>>> <https://twitter.com/JeremyRubin>\n>>>>>> _______________________________________________\n>>>>>> bitcoin-dev mailing list\n>>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>>\n>>>>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/862ed586/attachment-0001.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-01-19T16:51:48",
                "message_text_only": "Hmm, I don't know anything about  SIGHASH_BUNDLE. The only references\nonline I can find are just mentions (mostly from you). What is\nSIGHASH_BUNDLE?\n\n> unless you're binding a WTXID\n\nThat could work, but it would exclude cases where you have a transaction\nthat has already been partially signed and someone wants to, say, only sign\nthat transaction if some 3rd party signs a transaction paying part of the\nfee for it. Kind of a niche use case, but it would be nice to support it if\npossible. If the transaction hasn't been signed at all yet, a new\ntransaction can just be created that includes the prospective fee-payer,\nand if the transaction is fully signed then it has a WTXID to use.\n\n> then you can have fee bumping cycles\n\nWhat kind of cycles do you mean? You're saying these cycles would make it\nless robust to reorgs?\n\n> OP_VER\n\nI assume you mean something other than pushing the version onto the stack\n<https://bitcoin.stackexchange.com/questions/97258/given-op-ver-was-never-used-is-disabled-and-not-considered-useful-can-its-meani>?\nIs that related to your fee account idea?\n\n\nOn Wed, Jan 19, 2022 at 1:32 AM Jeremy <jlrubin at mit.edu> wrote:\n\n> Ah my bad i misread what you were saying as being about SIGHASH_BUNDLE\n> like proposals.\n>\n> For what you're discussing, I previously proposed\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-September/018168.html\n> which is similar.\n>\n> The benefit of the OP_VER output is that SIGHASH_EXTERNAL has the issue\n> that unless you're binding a WTXID (which is maybe too specific?) then you\n> can have fee bumping cycles. Doing OP_VER output w/ TXID guarantees that\n> you are acyclic.\n>\n> The difference between a fee account and this approach basically boils\n> down to the impact on e.g. reorg stability, where the deposit/withdraw\n> mechanism is a bit more \"robust\" for reorderings in reorgs than the in-band\n> transaction approach, although they are very similar.\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n>\n>\n> On Tue, Jan 18, 2022 at 8:53 PM Billy Tetrud <billy.tetrud at gmail.com>\n> wrote:\n>\n>> >  because you make transactions third party malleable it becomes\n>> possible to bundle and unbundle transactions.\n>>\n>> What I was suggesting doesn't make it possible to malleate someone else's\n>> transaction. I guess maybe my proposal of using a sighash flag might\n>> have been unclear. Imagine it as a script opcode that just says \"this\n>> transaction must be mined with this other transaction\" - the only\n>> difference being that you can use any output with any encumberance as an\n>> input for fee bumping. It doesn't prevent the original transaction from\n>> being mined on its own. So adding junk inputs would be no more of a problem\n>> than dust attacks already are. It would be used exactly like cpfp, except\n>> it doesn't spend the parent.\n>>\n>> I don't think what I was suggesting is as different from your proposal.\n>> All the problems of fee revenue optimization and feerate rules that you\n>> mentioned seem like they'd also exist for your proposal, or for cpfp. Let\n>> me know if I should clarify further.\n>>\n>> On Tue, Jan 18, 2022 at 8:51 PM Jeremy <jlrubin at mit.edu> wrote:\n>>\n>>> The issue with sighash flags is that because you make transactions third\n>>> party malleable it becomes possible to bundle and unbundle transactions.\n>>>\n>>> This means there are circumstances where an attacker could e.g. see your\n>>> txn, and then add a lot of junk change/inputs + 25 descendants and strongly\n>>> anchor your transaction to the bottom of the mempool.\n>>>\n>>> because of rbf rules requiring more fee and feerate, this means you have\n>>> to bump across the whole package and that can get really messy.\n>>>\n>>> more generally speaking, you could imagine a future where mempools track\n>>> many alternative things that might want to be in a transaction.\n>>>\n>>> suppose there are N inputs each with a weight and an amount of fee being\n>>> added and the sighash flags let me pick any subset of them. However, for a\n>>> txn to be standard it must be < 100k bytes and for it to be consensus <\n>>> 1mb. Now it is possible you have to solve a knapsack problem in order to\n>>> rationally bundle this transaction out of all possibilities.\n>>>\n>>> This problem can get even thornier, suppose that the inputs I'm adding\n>>> themselves are the outputs of another txn in the mempool, now i have to\n>>> track and propagate the feerates of that child back up to the parent txn\n>>> and track all these dependencies.\n>>>\n>>> perhaps with very careful engineering these issues can be tamed. however\n>>> it seems with sponsors or fee accounts, by separating the pays-for from the\n>>> participates-in concerns we can greatly simplify it to something like:\n>>> compute effective feerate for a txn, including all sponsors that pay more\n>>> than the feerate of the base txn. Mine that txn and it's subsidies using\n>>> the normal algo. If you run out of space, all subsidies are same-sized so\n>>> just take the ones that pay the highest amount up until the added marginal\n>>> feerate is less than the next eligible txn.\n>>>\n>>>\n>>> --\n>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>> <https://twitter.com/JeremyRubin>\n>>>\n>>>\n>>> On Tue, Jan 18, 2022 at 6:38 PM Billy Tetrud <billy.tetrud at gmail.com>\n>>> wrote:\n>>>\n>>>> I see, its not primarily to make it cheaper to append fees, but also\n>>>> allows appending fees in cases that aren't possible now. Is that right? I\n>>>> can certainly see the benefit of a more general way to add a fee to any\n>>>> transaction, regardless of whether you're related to that transaction or\n>>>> not.\n>>>>\n>>>> How would you compare the pros and cons of your account-based approach\n>>>> to something like a new sighash flag? Eg a sighash flag that says \"I'm\n>>>> signing this transaction, but the signature is only valid if mined in the\n>>>> same block as transaction X (or maybe transactions LIST)\". This could be\n>>>> named SIGHASH_EXTERNAL. Doing this would be a lot more similar to other\n>>>> bitcoin transactions, and no special account would need to be created. Any\n>>>> transaction could specify this. At least that's the first thought I would\n>>>> have in designing a way to arbitrarily bump fees. Have you compared your\n>>>> solution to something more familiar like that?\n>>>>\n>>>> On Tue, Jan 18, 2022 at 11:43 AM Jeremy <jlrubin at mit.edu> wrote:\n>>>>\n>>>>> Can you clarify what you mean by \"improve the situation\"?\n>>>>>\n>>>>> There's a potential mild bytes savings, but the bigger deal is that\n>>>>> the API should be much less vulnerable to pinning issues, fix dust leakage\n>>>>> for eltoo like protocols, and just generally allow protocol designs to be\n>>>>> fully abstracted from paying fees. You can't easily mathematically\n>>>>> quantify API improvements like that.\n>>>>> --\n>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>>>> <https://twitter.com/JeremyRubin>\n>>>>>\n>>>>>\n>>>>> On Tue, Jan 18, 2022 at 8:13 AM Billy Tetrud <billy.tetrud at gmail.com>\n>>>>> wrote:\n>>>>>\n>>>>>> Do you have any back-of-the-napkin math on quantifying how much this\n>>>>>> would improve the situation vs existing methods (eg cpfp)?\n>>>>>>\n>>>>>>\n>>>>>>\n>>>>>> On Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <\n>>>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>>>\n>>>>>>> Happy new years devs,\n>>>>>>>\n>>>>>>> I figured I would share some thoughts for conceptual review that\n>>>>>>> have been bouncing around my head as an opportunity to clean up the fee\n>>>>>>> paying semantics in bitcoin \"for good\". The design space is very wide on\n>>>>>>> the approach I'll share, so below is just a sketch of how it could work\n>>>>>>> which I'm sure could be improved greatly.\n>>>>>>>\n>>>>>>> Transaction fees are an integral part of bitcoin.\n>>>>>>>\n>>>>>>> However, due to quirks of Bitcoin's transaction design, fees are a\n>>>>>>> part of the transactions that they occur in.\n>>>>>>>\n>>>>>>> While this works in a \"Bitcoin 1.0\" world, where all transactions\n>>>>>>> are simple on-chain transfers, real world use of Bitcoin requires support\n>>>>>>> for things like Fee Bumping stuck transactions, DoS resistant Payment\n>>>>>>> Channels, and other long lived Smart Contracts that can't predict future\n>>>>>>> fee rates. Having the fees paid in band makes writing these contracts much\n>>>>>>> more difficult as you can't merely express the logic you want for the\n>>>>>>> transaction, but also the fees.\n>>>>>>>\n>>>>>>> Previously, I proposed a special type of transaction called a\n>>>>>>> \"Sponsor\" which has some special consensus + mempool rules to allow\n>>>>>>> arbitrarily appending fees to a transaction to bump it up in the mempool.\n>>>>>>>\n>>>>>>> As an alternative, we could establish an account system in Bitcoin\n>>>>>>> as an \"extension block\".\n>>>>>>>\n>>>>>>> *Here's how it might work:*\n>>>>>>>\n>>>>>>> 1. Define a special anyone can spend output type that is a \"fee\n>>>>>>> account\" (e.g. segwit V2). Such outputs have a redeeming key and an amount\n>>>>>>> associated with them, but are overall anyone can spend.\n>>>>>>> 2. All deposits to these outputs get stored in a separate UTXO\n>>>>>>> database for fee accounts\n>>>>>>> 3. Fee accounts can sign only two kinds of transaction: A: a fee\n>>>>>>> amount and a TXID (or Outpoint?); B: a withdraw amount, a fee, and\n>>>>>>> an address\n>>>>>>> 4. These transactions are committed in an extension block merkle\n>>>>>>> tree. While the actual signature must cover the TXID/Outpoint, the\n>>>>>>> committed data need only cover the index in the block of the transaction.\n>>>>>>> The public key for account lookup can be recovered from the message +\n>>>>>>> signature.\n>>>>>>> 5. In any block, any of the fee account deposits can be: released\n>>>>>>> into fees if there is a corresponding tx; consolidated together to reduce\n>>>>>>> the number of utxos (this can be just an OP_TRUE no metadata needed); or\n>>>>>>> released into fees *and paid back* into the requested withdrawal key\n>>>>>>> (encumbering a 100 block timeout). Signatures must be unique in a block.\n>>>>>>> 6. Mempool logic is updated to allow attaching of account fee spends\n>>>>>>> to transactions, the mempool can restrict that an account is not allowed\n>>>>>>> more spend more than it's balance.\n>>>>>>>\n>>>>>>> *But aren't accounts \"bad\"?*\n>>>>>>>\n>>>>>>> Yes, accounts are bad. But these accounts are not bad, because any\n>>>>>>> funds withdrawn from the fee extension are fundamentally locked for 100\n>>>>>>> blocks as a coinbase output, so there should be no issues with any series\n>>>>>>> of reorgs. Further, since there is no \"rich state\" for these accounts, the\n>>>>>>> state updates can always be applied in a conflict-free way in any order.\n>>>>>>>\n>>>>>>>\n>>>>>>> *Improving the privacy of this design:*\n>>>>>>>\n>>>>>>> This design could likely be modified to implement something like\n>>>>>>> Tornado.cash or something else so that the fee account paying can be\n>>>>>>> unlinked from the transaction being paid for, improving privacy at the\n>>>>>>> expense of being a bit more expensive.\n>>>>>>>\n>>>>>>> Other operations could be added to allow a trustless mixing to be\n>>>>>>> done by miners automatically where groups of accounts with similar values\n>>>>>>> are trustlessly  split into a common denominator and change, and keys are\n>>>>>>> derived via a verifiable stealth address like protocol (so fee balances can\n>>>>>>> be discovered by tracing the updates posted). These updates could also be\n>>>>>>> produced by individuals rather than miners, and miners could simply honor\n>>>>>>> them with better privacy. While a miner generating an update would be able\n>>>>>>> to deanonymize their mixes, if you have your account mixed several times by\n>>>>>>> independent miners that could potentially add sufficient privacy.\n>>>>>>>\n>>>>>>> The LN can also be used with PTLCs to, in theory, have another\n>>>>>>> individual paid to sponsor a transaction on your behalf only if they reveal\n>>>>>>> a valid sig from their fee paying account, although under this model it's\n>>>>>>> hard to ensure that the owner doesn't pay a fee and then 'cancel' by\n>>>>>>> withdrawing the rest. However, this could be partly solved by using\n>>>>>>> reputable fee accounts (reputation could be measured somewhat\n>>>>>>> decentralized-ly by longevity of the account and transactions paid for\n>>>>>>> historically).\n>>>>>>>\n>>>>>>> *Scalability*\n>>>>>>>\n>>>>>>> This design is fundamentally 'decent' for scalability because adding\n>>>>>>> fees to a transaction does not require adding inputs or outputs and does\n>>>>>>> not require tracking substantial amounts of new state.\n>>>>>>>\n>>>>>>> Paying someone else to pay for you via the LN also helps make this\n>>>>>>> more efficient if the withdrawal issues can be fixed.\n>>>>>>>\n>>>>>>> *Lightning:*\n>>>>>>>\n>>>>>>> This type of design works really well for channels because the\n>>>>>>> addition of fees to e.g. a channel state does not require any sort of\n>>>>>>> pre-planning (e.g. anchors) or transaction flexibility (SIGHASH flags).\n>>>>>>> This sort of design is naturally immune to pinning issues since you could\n>>>>>>> offer to pay a fee for any TXID and the number of fee adding offers does\n>>>>>>> not need to be restricted in the same way the descendant transactions would\n>>>>>>> need to be.\n>>>>>>>\n>>>>>>> *Without a fork?*\n>>>>>>>\n>>>>>>> This type of design could be done as a federated network that bribes\n>>>>>>> miners -- potentially even retroactively after a block is formed. That\n>>>>>>> might be sufficient to prove the concept works before a consensus upgrade\n>>>>>>> is deployed, but such an approach does mean there is a centralizing layer\n>>>>>>> interfering with normal mining.\n>>>>>>>\n>>>>>>>\n>>>>>>> Happy new year!!\n>>>>>>>\n>>>>>>> Jeremy\n>>>>>>>\n>>>>>>> --\n>>>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>>>>>> <https://twitter.com/JeremyRubin>\n>>>>>>> _______________________________________________\n>>>>>>> bitcoin-dev mailing list\n>>>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>>>\n>>>>>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220119/c587953e/attachment-0001.html>"
            },
            {
                "author": "Jeremy",
                "date": "2022-01-19T20:08:23",
                "message_text_only": "SIGHASH_BUNDLE\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-April/015862.html\n\nBy cycles I meant that if you commit to the sponsors by TXID from the\nwitness, you could \"sponsor yourself\" directly or through a cycle involving\n> 1 txn.\n\nWith OP_VER I was talking about the proposal I linked here\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-September/018168.html\nwhich used OP_VER to indicate a txn sponsoring txn. Because the OP_VER is\nin the output space, and uses TXIDs, it is cycle-free.\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Wed, Jan 19, 2022 at 8:52 AM Billy Tetrud <billy.tetrud at gmail.com> wrote:\n\n> Hmm, I don't know anything about  SIGHASH_BUNDLE. The only references\n> online I can find are just mentions (mostly from you). What is\n> SIGHASH_BUNDLE?\n>\n> > unless you're binding a WTXID\n>\n> That could work, but it would exclude cases where you have a transaction\n> that has already been partially signed and someone wants to, say, only sign\n> that transaction if some 3rd party signs a transaction paying part of the\n> fee for it. Kind of a niche use case, but it would be nice to support it if\n> possible. If the transaction hasn't been signed at all yet, a new\n> transaction can just be created that includes the prospective fee-payer,\n> and if the transaction is fully signed then it has a WTXID to use.\n>\n> > then you can have fee bumping cycles\n>\n> What kind of cycles do you mean? You're saying these cycles would make it\n> less robust to reorgs?\n>\n> > OP_VER\n>\n> I assume you mean something other than pushing the version onto the stack\n> <https://bitcoin.stackexchange.com/questions/97258/given-op-ver-was-never-used-is-disabled-and-not-considered-useful-can-its-meani>?\n> Is that related to your fee account idea?\n>\n>\n> On Wed, Jan 19, 2022 at 1:32 AM Jeremy <jlrubin at mit.edu> wrote:\n>\n>> Ah my bad i misread what you were saying as being about SIGHASH_BUNDLE\n>> like proposals.\n>>\n>> For what you're discussing, I previously proposed\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-September/018168.html\n>> which is similar.\n>>\n>> The benefit of the OP_VER output is that SIGHASH_EXTERNAL has the issue\n>> that unless you're binding a WTXID (which is maybe too specific?) then you\n>> can have fee bumping cycles. Doing OP_VER output w/ TXID guarantees that\n>> you are acyclic.\n>>\n>> The difference between a fee account and this approach basically boils\n>> down to the impact on e.g. reorg stability, where the deposit/withdraw\n>> mechanism is a bit more \"robust\" for reorderings in reorgs than the in-band\n>> transaction approach, although they are very similar.\n>>\n>> --\n>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>> <https://twitter.com/JeremyRubin>\n>>\n>>\n>> On Tue, Jan 18, 2022 at 8:53 PM Billy Tetrud <billy.tetrud at gmail.com>\n>> wrote:\n>>\n>>> >  because you make transactions third party malleable it becomes\n>>> possible to bundle and unbundle transactions.\n>>>\n>>> What I was suggesting doesn't make it possible to malleate someone\n>>> else's transaction. I guess maybe my proposal of using a sighash flag\n>>> might have been unclear. Imagine it as a script opcode that just says \"this\n>>> transaction must be mined with this other transaction\" - the only\n>>> difference being that you can use any output with any encumberance as an\n>>> input for fee bumping. It doesn't prevent the original transaction from\n>>> being mined on its own. So adding junk inputs would be no more of a problem\n>>> than dust attacks already are. It would be used exactly like cpfp, except\n>>> it doesn't spend the parent.\n>>>\n>>> I don't think what I was suggesting is as different from your proposal.\n>>> All the problems of fee revenue optimization and feerate rules that you\n>>> mentioned seem like they'd also exist for your proposal, or for cpfp. Let\n>>> me know if I should clarify further.\n>>>\n>>> On Tue, Jan 18, 2022 at 8:51 PM Jeremy <jlrubin at mit.edu> wrote:\n>>>\n>>>> The issue with sighash flags is that because you make transactions\n>>>> third party malleable it becomes possible to bundle and unbundle\n>>>> transactions.\n>>>>\n>>>> This means there are circumstances where an attacker could e.g. see\n>>>> your txn, and then add a lot of junk change/inputs + 25 descendants and\n>>>> strongly anchor your transaction to the bottom of the mempool.\n>>>>\n>>>> because of rbf rules requiring more fee and feerate, this means you\n>>>> have to bump across the whole package and that can get really messy.\n>>>>\n>>>> more generally speaking, you could imagine a future where mempools\n>>>> track many alternative things that might want to be in a transaction.\n>>>>\n>>>> suppose there are N inputs each with a weight and an amount of fee\n>>>> being added and the sighash flags let me pick any subset of them. However,\n>>>> for a txn to be standard it must be < 100k bytes and for it to be consensus\n>>>> < 1mb. Now it is possible you have to solve a knapsack problem in order to\n>>>> rationally bundle this transaction out of all possibilities.\n>>>>\n>>>> This problem can get even thornier, suppose that the inputs I'm adding\n>>>> themselves are the outputs of another txn in the mempool, now i have to\n>>>> track and propagate the feerates of that child back up to the parent txn\n>>>> and track all these dependencies.\n>>>>\n>>>> perhaps with very careful engineering these issues can be tamed.\n>>>> however it seems with sponsors or fee accounts, by separating the pays-for\n>>>> from the participates-in concerns we can greatly simplify it to something\n>>>> like: compute effective feerate for a txn, including all sponsors that pay\n>>>> more than the feerate of the base txn. Mine that txn and it's subsidies\n>>>> using the normal algo. If you run out of space, all subsidies are\n>>>> same-sized so just take the ones that pay the highest amount up until the\n>>>> added marginal feerate is less than the next eligible txn.\n>>>>\n>>>>\n>>>> --\n>>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>>> <https://twitter.com/JeremyRubin>\n>>>>\n>>>>\n>>>> On Tue, Jan 18, 2022 at 6:38 PM Billy Tetrud <billy.tetrud at gmail.com>\n>>>> wrote:\n>>>>\n>>>>> I see, its not primarily to make it cheaper to append fees, but also\n>>>>> allows appending fees in cases that aren't possible now. Is that right? I\n>>>>> can certainly see the benefit of a more general way to add a fee to any\n>>>>> transaction, regardless of whether you're related to that transaction or\n>>>>> not.\n>>>>>\n>>>>> How would you compare the pros and cons of your account-based approach\n>>>>> to something like a new sighash flag? Eg a sighash flag that says \"I'm\n>>>>> signing this transaction, but the signature is only valid if mined in the\n>>>>> same block as transaction X (or maybe transactions LIST)\". This could be\n>>>>> named SIGHASH_EXTERNAL. Doing this would be a lot more similar to other\n>>>>> bitcoin transactions, and no special account would need to be created. Any\n>>>>> transaction could specify this. At least that's the first thought I would\n>>>>> have in designing a way to arbitrarily bump fees. Have you compared your\n>>>>> solution to something more familiar like that?\n>>>>>\n>>>>> On Tue, Jan 18, 2022 at 11:43 AM Jeremy <jlrubin at mit.edu> wrote:\n>>>>>\n>>>>>> Can you clarify what you mean by \"improve the situation\"?\n>>>>>>\n>>>>>> There's a potential mild bytes savings, but the bigger deal is that\n>>>>>> the API should be much less vulnerable to pinning issues, fix dust leakage\n>>>>>> for eltoo like protocols, and just generally allow protocol designs to be\n>>>>>> fully abstracted from paying fees. You can't easily mathematically\n>>>>>> quantify API improvements like that.\n>>>>>> --\n>>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>>>>> <https://twitter.com/JeremyRubin>\n>>>>>>\n>>>>>>\n>>>>>> On Tue, Jan 18, 2022 at 8:13 AM Billy Tetrud <billy.tetrud at gmail.com>\n>>>>>> wrote:\n>>>>>>\n>>>>>>> Do you have any back-of-the-napkin math on quantifying how much this\n>>>>>>> would improve the situation vs existing methods (eg cpfp)?\n>>>>>>>\n>>>>>>>\n>>>>>>>\n>>>>>>> On Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <\n>>>>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>>>>\n>>>>>>>> Happy new years devs,\n>>>>>>>>\n>>>>>>>> I figured I would share some thoughts for conceptual review that\n>>>>>>>> have been bouncing around my head as an opportunity to clean up the fee\n>>>>>>>> paying semantics in bitcoin \"for good\". The design space is very wide on\n>>>>>>>> the approach I'll share, so below is just a sketch of how it could work\n>>>>>>>> which I'm sure could be improved greatly.\n>>>>>>>>\n>>>>>>>> Transaction fees are an integral part of bitcoin.\n>>>>>>>>\n>>>>>>>> However, due to quirks of Bitcoin's transaction design, fees are a\n>>>>>>>> part of the transactions that they occur in.\n>>>>>>>>\n>>>>>>>> While this works in a \"Bitcoin 1.0\" world, where all transactions\n>>>>>>>> are simple on-chain transfers, real world use of Bitcoin requires support\n>>>>>>>> for things like Fee Bumping stuck transactions, DoS resistant Payment\n>>>>>>>> Channels, and other long lived Smart Contracts that can't predict future\n>>>>>>>> fee rates. Having the fees paid in band makes writing these contracts much\n>>>>>>>> more difficult as you can't merely express the logic you want for the\n>>>>>>>> transaction, but also the fees.\n>>>>>>>>\n>>>>>>>> Previously, I proposed a special type of transaction called a\n>>>>>>>> \"Sponsor\" which has some special consensus + mempool rules to allow\n>>>>>>>> arbitrarily appending fees to a transaction to bump it up in the mempool.\n>>>>>>>>\n>>>>>>>> As an alternative, we could establish an account system in Bitcoin\n>>>>>>>> as an \"extension block\".\n>>>>>>>>\n>>>>>>>> *Here's how it might work:*\n>>>>>>>>\n>>>>>>>> 1. Define a special anyone can spend output type that is a \"fee\n>>>>>>>> account\" (e.g. segwit V2). Such outputs have a redeeming key and an amount\n>>>>>>>> associated with them, but are overall anyone can spend.\n>>>>>>>> 2. All deposits to these outputs get stored in a separate UTXO\n>>>>>>>> database for fee accounts\n>>>>>>>> 3. Fee accounts can sign only two kinds of transaction: A: a fee\n>>>>>>>> amount and a TXID (or Outpoint?); B: a withdraw amount, a fee, and\n>>>>>>>> an address\n>>>>>>>> 4. These transactions are committed in an extension block merkle\n>>>>>>>> tree. While the actual signature must cover the TXID/Outpoint, the\n>>>>>>>> committed data need only cover the index in the block of the transaction.\n>>>>>>>> The public key for account lookup can be recovered from the message +\n>>>>>>>> signature.\n>>>>>>>> 5. In any block, any of the fee account deposits can be: released\n>>>>>>>> into fees if there is a corresponding tx; consolidated together to reduce\n>>>>>>>> the number of utxos (this can be just an OP_TRUE no metadata needed); or\n>>>>>>>> released into fees *and paid back* into the requested withdrawal key\n>>>>>>>> (encumbering a 100 block timeout). Signatures must be unique in a block.\n>>>>>>>> 6. Mempool logic is updated to allow attaching of account fee\n>>>>>>>> spends to transactions, the mempool can restrict that an account is not\n>>>>>>>> allowed more spend more than it's balance.\n>>>>>>>>\n>>>>>>>> *But aren't accounts \"bad\"?*\n>>>>>>>>\n>>>>>>>> Yes, accounts are bad. But these accounts are not bad, because any\n>>>>>>>> funds withdrawn from the fee extension are fundamentally locked for 100\n>>>>>>>> blocks as a coinbase output, so there should be no issues with any series\n>>>>>>>> of reorgs. Further, since there is no \"rich state\" for these accounts, the\n>>>>>>>> state updates can always be applied in a conflict-free way in any order.\n>>>>>>>>\n>>>>>>>>\n>>>>>>>> *Improving the privacy of this design:*\n>>>>>>>>\n>>>>>>>> This design could likely be modified to implement something like\n>>>>>>>> Tornado.cash or something else so that the fee account paying can be\n>>>>>>>> unlinked from the transaction being paid for, improving privacy at the\n>>>>>>>> expense of being a bit more expensive.\n>>>>>>>>\n>>>>>>>> Other operations could be added to allow a trustless mixing to be\n>>>>>>>> done by miners automatically where groups of accounts with similar values\n>>>>>>>> are trustlessly  split into a common denominator and change, and keys are\n>>>>>>>> derived via a verifiable stealth address like protocol (so fee balances can\n>>>>>>>> be discovered by tracing the updates posted). These updates could also be\n>>>>>>>> produced by individuals rather than miners, and miners could simply honor\n>>>>>>>> them with better privacy. While a miner generating an update would be able\n>>>>>>>> to deanonymize their mixes, if you have your account mixed several times by\n>>>>>>>> independent miners that could potentially add sufficient privacy.\n>>>>>>>>\n>>>>>>>> The LN can also be used with PTLCs to, in theory, have another\n>>>>>>>> individual paid to sponsor a transaction on your behalf only if they reveal\n>>>>>>>> a valid sig from their fee paying account, although under this model it's\n>>>>>>>> hard to ensure that the owner doesn't pay a fee and then 'cancel' by\n>>>>>>>> withdrawing the rest. However, this could be partly solved by using\n>>>>>>>> reputable fee accounts (reputation could be measured somewhat\n>>>>>>>> decentralized-ly by longevity of the account and transactions paid for\n>>>>>>>> historically).\n>>>>>>>>\n>>>>>>>> *Scalability*\n>>>>>>>>\n>>>>>>>> This design is fundamentally 'decent' for scalability because\n>>>>>>>> adding fees to a transaction does not require adding inputs or outputs and\n>>>>>>>> does not require tracking substantial amounts of new state.\n>>>>>>>>\n>>>>>>>> Paying someone else to pay for you via the LN also helps make this\n>>>>>>>> more efficient if the withdrawal issues can be fixed.\n>>>>>>>>\n>>>>>>>> *Lightning:*\n>>>>>>>>\n>>>>>>>> This type of design works really well for channels because the\n>>>>>>>> addition of fees to e.g. a channel state does not require any sort of\n>>>>>>>> pre-planning (e.g. anchors) or transaction flexibility (SIGHASH flags).\n>>>>>>>> This sort of design is naturally immune to pinning issues since you could\n>>>>>>>> offer to pay a fee for any TXID and the number of fee adding offers does\n>>>>>>>> not need to be restricted in the same way the descendant transactions would\n>>>>>>>> need to be.\n>>>>>>>>\n>>>>>>>> *Without a fork?*\n>>>>>>>>\n>>>>>>>> This type of design could be done as a federated network that\n>>>>>>>> bribes miners -- potentially even retroactively after a block is formed.\n>>>>>>>> That might be sufficient to prove the concept works before a consensus\n>>>>>>>> upgrade is deployed, but such an approach does mean there is a centralizing\n>>>>>>>> layer interfering with normal mining.\n>>>>>>>>\n>>>>>>>>\n>>>>>>>> Happy new year!!\n>>>>>>>>\n>>>>>>>> Jeremy\n>>>>>>>>\n>>>>>>>> --\n>>>>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>>>>>>> <https://twitter.com/JeremyRubin>\n>>>>>>>> _______________________________________________\n>>>>>>>> bitcoin-dev mailing list\n>>>>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>>>>\n>>>>>>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220119/3457bd53/attachment-0001.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-01-20T05:23:12",
                "message_text_only": "Thanks for the info.\n\n> you could \"sponsor yourself\" directly or through a cycle involving > 1\ntxn.\n\nAh I see, because the sighash flags aren't used to create the TXID. I don't\nreally see the problem with cycles tho. Could a cycle cause problems for\nanyone? Seems like it would be a harmless waste of bytes. The\nfee-sponsoring OP_VER looks good too tho.\n\nOn Wed, Jan 19, 2022 at 2:08 PM Jeremy <jlrubin at mit.edu> wrote:\n\n> SIGHASH_BUNDLE\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-April/015862.html\n>\n> By cycles I meant that if you commit to the sponsors by TXID from the\n> witness, you could \"sponsor yourself\" directly or through a cycle involving\n> > 1 txn.\n>\n> With OP_VER I was talking about the proposal I linked here\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-September/018168.html\n> which used OP_VER to indicate a txn sponsoring txn. Because the OP_VER is\n> in the output space, and uses TXIDs, it is cycle-free.\n>\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n>\n>\n> On Wed, Jan 19, 2022 at 8:52 AM Billy Tetrud <billy.tetrud at gmail.com>\n> wrote:\n>\n>> Hmm, I don't know anything about  SIGHASH_BUNDLE. The only references\n>> online I can find are just mentions (mostly from you). What is\n>> SIGHASH_BUNDLE?\n>>\n>> > unless you're binding a WTXID\n>>\n>> That could work, but it would exclude cases where you have a transaction\n>> that has already been partially signed and someone wants to, say, only sign\n>> that transaction if some 3rd party signs a transaction paying part of the\n>> fee for it. Kind of a niche use case, but it would be nice to support it if\n>> possible. If the transaction hasn't been signed at all yet, a new\n>> transaction can just be created that includes the prospective fee-payer,\n>> and if the transaction is fully signed then it has a WTXID to use.\n>>\n>> > then you can have fee bumping cycles\n>>\n>> What kind of cycles do you mean? You're saying these cycles would make it\n>> less robust to reorgs?\n>>\n>> > OP_VER\n>>\n>> I assume you mean something other than pushing the version onto the stack\n>> <https://bitcoin.stackexchange.com/questions/97258/given-op-ver-was-never-used-is-disabled-and-not-considered-useful-can-its-meani>?\n>> Is that related to your fee account idea?\n>>\n>>\n>> On Wed, Jan 19, 2022 at 1:32 AM Jeremy <jlrubin at mit.edu> wrote:\n>>\n>>> Ah my bad i misread what you were saying as being about SIGHASH_BUNDLE\n>>> like proposals.\n>>>\n>>> For what you're discussing, I previously proposed\n>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-September/018168.html\n>>> which is similar.\n>>>\n>>> The benefit of the OP_VER output is that SIGHASH_EXTERNAL has the issue\n>>> that unless you're binding a WTXID (which is maybe too specific?) then you\n>>> can have fee bumping cycles. Doing OP_VER output w/ TXID guarantees that\n>>> you are acyclic.\n>>>\n>>> The difference between a fee account and this approach basically boils\n>>> down to the impact on e.g. reorg stability, where the deposit/withdraw\n>>> mechanism is a bit more \"robust\" for reorderings in reorgs than the in-band\n>>> transaction approach, although they are very similar.\n>>>\n>>> --\n>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>> <https://twitter.com/JeremyRubin>\n>>>\n>>>\n>>> On Tue, Jan 18, 2022 at 8:53 PM Billy Tetrud <billy.tetrud at gmail.com>\n>>> wrote:\n>>>\n>>>> >  because you make transactions third party malleable it becomes\n>>>> possible to bundle and unbundle transactions.\n>>>>\n>>>> What I was suggesting doesn't make it possible to malleate someone\n>>>> else's transaction. I guess maybe my proposal of using a sighash flag\n>>>> might have been unclear. Imagine it as a script opcode that just says \"this\n>>>> transaction must be mined with this other transaction\" - the only\n>>>> difference being that you can use any output with any encumberance as an\n>>>> input for fee bumping. It doesn't prevent the original transaction from\n>>>> being mined on its own. So adding junk inputs would be no more of a problem\n>>>> than dust attacks already are. It would be used exactly like cpfp, except\n>>>> it doesn't spend the parent.\n>>>>\n>>>> I don't think what I was suggesting is as different from your proposal.\n>>>> All the problems of fee revenue optimization and feerate rules that you\n>>>> mentioned seem like they'd also exist for your proposal, or for cpfp. Let\n>>>> me know if I should clarify further.\n>>>>\n>>>> On Tue, Jan 18, 2022 at 8:51 PM Jeremy <jlrubin at mit.edu> wrote:\n>>>>\n>>>>> The issue with sighash flags is that because you make transactions\n>>>>> third party malleable it becomes possible to bundle and unbundle\n>>>>> transactions.\n>>>>>\n>>>>> This means there are circumstances where an attacker could e.g. see\n>>>>> your txn, and then add a lot of junk change/inputs + 25 descendants and\n>>>>> strongly anchor your transaction to the bottom of the mempool.\n>>>>>\n>>>>> because of rbf rules requiring more fee and feerate, this means you\n>>>>> have to bump across the whole package and that can get really messy.\n>>>>>\n>>>>> more generally speaking, you could imagine a future where mempools\n>>>>> track many alternative things that might want to be in a transaction.\n>>>>>\n>>>>> suppose there are N inputs each with a weight and an amount of fee\n>>>>> being added and the sighash flags let me pick any subset of them. However,\n>>>>> for a txn to be standard it must be < 100k bytes and for it to be consensus\n>>>>> < 1mb. Now it is possible you have to solve a knapsack problem in order to\n>>>>> rationally bundle this transaction out of all possibilities.\n>>>>>\n>>>>> This problem can get even thornier, suppose that the inputs I'm adding\n>>>>> themselves are the outputs of another txn in the mempool, now i have to\n>>>>> track and propagate the feerates of that child back up to the parent txn\n>>>>> and track all these dependencies.\n>>>>>\n>>>>> perhaps with very careful engineering these issues can be tamed.\n>>>>> however it seems with sponsors or fee accounts, by separating the pays-for\n>>>>> from the participates-in concerns we can greatly simplify it to something\n>>>>> like: compute effective feerate for a txn, including all sponsors that pay\n>>>>> more than the feerate of the base txn. Mine that txn and it's subsidies\n>>>>> using the normal algo. If you run out of space, all subsidies are\n>>>>> same-sized so just take the ones that pay the highest amount up until the\n>>>>> added marginal feerate is less than the next eligible txn.\n>>>>>\n>>>>>\n>>>>> --\n>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>>>> <https://twitter.com/JeremyRubin>\n>>>>>\n>>>>>\n>>>>> On Tue, Jan 18, 2022 at 6:38 PM Billy Tetrud <billy.tetrud at gmail.com>\n>>>>> wrote:\n>>>>>\n>>>>>> I see, its not primarily to make it cheaper to append fees, but also\n>>>>>> allows appending fees in cases that aren't possible now. Is that right? I\n>>>>>> can certainly see the benefit of a more general way to add a fee to any\n>>>>>> transaction, regardless of whether you're related to that transaction or\n>>>>>> not.\n>>>>>>\n>>>>>> How would you compare the pros and cons of your account-based\n>>>>>> approach to something like a new sighash flag? Eg a sighash flag that says\n>>>>>> \"I'm signing this transaction, but the signature is only valid if mined in\n>>>>>> the same block as transaction X (or maybe transactions LIST)\". This could\n>>>>>> be named SIGHASH_EXTERNAL. Doing this would be a lot more similar to other\n>>>>>> bitcoin transactions, and no special account would need to be created. Any\n>>>>>> transaction could specify this. At least that's the first thought I would\n>>>>>> have in designing a way to arbitrarily bump fees. Have you compared your\n>>>>>> solution to something more familiar like that?\n>>>>>>\n>>>>>> On Tue, Jan 18, 2022 at 11:43 AM Jeremy <jlrubin at mit.edu> wrote:\n>>>>>>\n>>>>>>> Can you clarify what you mean by \"improve the situation\"?\n>>>>>>>\n>>>>>>> There's a potential mild bytes savings, but the bigger deal is that\n>>>>>>> the API should be much less vulnerable to pinning issues, fix dust leakage\n>>>>>>> for eltoo like protocols, and just generally allow protocol designs to be\n>>>>>>> fully abstracted from paying fees. You can't easily mathematically\n>>>>>>> quantify API improvements like that.\n>>>>>>> --\n>>>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>>>>>> <https://twitter.com/JeremyRubin>\n>>>>>>>\n>>>>>>>\n>>>>>>> On Tue, Jan 18, 2022 at 8:13 AM Billy Tetrud <billy.tetrud at gmail.com>\n>>>>>>> wrote:\n>>>>>>>\n>>>>>>>> Do you have any back-of-the-napkin math on quantifying how much\n>>>>>>>> this would improve the situation vs existing methods (eg cpfp)?\n>>>>>>>>\n>>>>>>>>\n>>>>>>>>\n>>>>>>>> On Sat, Jan 1, 2022 at 2:04 PM Jeremy via bitcoin-dev <\n>>>>>>>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>>>>>>\n>>>>>>>>> Happy new years devs,\n>>>>>>>>>\n>>>>>>>>> I figured I would share some thoughts for conceptual review that\n>>>>>>>>> have been bouncing around my head as an opportunity to clean up the fee\n>>>>>>>>> paying semantics in bitcoin \"for good\". The design space is very wide on\n>>>>>>>>> the approach I'll share, so below is just a sketch of how it could work\n>>>>>>>>> which I'm sure could be improved greatly.\n>>>>>>>>>\n>>>>>>>>> Transaction fees are an integral part of bitcoin.\n>>>>>>>>>\n>>>>>>>>> However, due to quirks of Bitcoin's transaction design, fees are a\n>>>>>>>>> part of the transactions that they occur in.\n>>>>>>>>>\n>>>>>>>>> While this works in a \"Bitcoin 1.0\" world, where all transactions\n>>>>>>>>> are simple on-chain transfers, real world use of Bitcoin requires support\n>>>>>>>>> for things like Fee Bumping stuck transactions, DoS resistant Payment\n>>>>>>>>> Channels, and other long lived Smart Contracts that can't predict future\n>>>>>>>>> fee rates. Having the fees paid in band makes writing these contracts much\n>>>>>>>>> more difficult as you can't merely express the logic you want for the\n>>>>>>>>> transaction, but also the fees.\n>>>>>>>>>\n>>>>>>>>> Previously, I proposed a special type of transaction called a\n>>>>>>>>> \"Sponsor\" which has some special consensus + mempool rules to allow\n>>>>>>>>> arbitrarily appending fees to a transaction to bump it up in the mempool.\n>>>>>>>>>\n>>>>>>>>> As an alternative, we could establish an account system in Bitcoin\n>>>>>>>>> as an \"extension block\".\n>>>>>>>>>\n>>>>>>>>> *Here's how it might work:*\n>>>>>>>>>\n>>>>>>>>> 1. Define a special anyone can spend output type that is a \"fee\n>>>>>>>>> account\" (e.g. segwit V2). Such outputs have a redeeming key and an amount\n>>>>>>>>> associated with them, but are overall anyone can spend.\n>>>>>>>>> 2. All deposits to these outputs get stored in a separate UTXO\n>>>>>>>>> database for fee accounts\n>>>>>>>>> 3. Fee accounts can sign only two kinds of transaction: A: a fee\n>>>>>>>>> amount and a TXID (or Outpoint?); B: a withdraw amount, a fee, and\n>>>>>>>>> an address\n>>>>>>>>> 4. These transactions are committed in an extension block merkle\n>>>>>>>>> tree. While the actual signature must cover the TXID/Outpoint, the\n>>>>>>>>> committed data need only cover the index in the block of the transaction.\n>>>>>>>>> The public key for account lookup can be recovered from the message +\n>>>>>>>>> signature.\n>>>>>>>>> 5. In any block, any of the fee account deposits can be: released\n>>>>>>>>> into fees if there is a corresponding tx; consolidated together to reduce\n>>>>>>>>> the number of utxos (this can be just an OP_TRUE no metadata needed); or\n>>>>>>>>> released into fees *and paid back* into the requested withdrawal key\n>>>>>>>>> (encumbering a 100 block timeout). Signatures must be unique in a block.\n>>>>>>>>> 6. Mempool logic is updated to allow attaching of account fee\n>>>>>>>>> spends to transactions, the mempool can restrict that an account is not\n>>>>>>>>> allowed more spend more than it's balance.\n>>>>>>>>>\n>>>>>>>>> *But aren't accounts \"bad\"?*\n>>>>>>>>>\n>>>>>>>>> Yes, accounts are bad. But these accounts are not bad, because any\n>>>>>>>>> funds withdrawn from the fee extension are fundamentally locked for 100\n>>>>>>>>> blocks as a coinbase output, so there should be no issues with any series\n>>>>>>>>> of reorgs. Further, since there is no \"rich state\" for these accounts, the\n>>>>>>>>> state updates can always be applied in a conflict-free way in any order.\n>>>>>>>>>\n>>>>>>>>>\n>>>>>>>>> *Improving the privacy of this design:*\n>>>>>>>>>\n>>>>>>>>> This design could likely be modified to implement something like\n>>>>>>>>> Tornado.cash or something else so that the fee account paying can be\n>>>>>>>>> unlinked from the transaction being paid for, improving privacy at the\n>>>>>>>>> expense of being a bit more expensive.\n>>>>>>>>>\n>>>>>>>>> Other operations could be added to allow a trustless mixing to be\n>>>>>>>>> done by miners automatically where groups of accounts with similar values\n>>>>>>>>> are trustlessly  split into a common denominator and change, and keys are\n>>>>>>>>> derived via a verifiable stealth address like protocol (so fee balances can\n>>>>>>>>> be discovered by tracing the updates posted). These updates could also be\n>>>>>>>>> produced by individuals rather than miners, and miners could simply honor\n>>>>>>>>> them with better privacy. While a miner generating an update would be able\n>>>>>>>>> to deanonymize their mixes, if you have your account mixed several times by\n>>>>>>>>> independent miners that could potentially add sufficient privacy.\n>>>>>>>>>\n>>>>>>>>> The LN can also be used with PTLCs to, in theory, have another\n>>>>>>>>> individual paid to sponsor a transaction on your behalf only if they reveal\n>>>>>>>>> a valid sig from their fee paying account, although under this model it's\n>>>>>>>>> hard to ensure that the owner doesn't pay a fee and then 'cancel' by\n>>>>>>>>> withdrawing the rest. However, this could be partly solved by using\n>>>>>>>>> reputable fee accounts (reputation could be measured somewhat\n>>>>>>>>> decentralized-ly by longevity of the account and transactions paid for\n>>>>>>>>> historically).\n>>>>>>>>>\n>>>>>>>>> *Scalability*\n>>>>>>>>>\n>>>>>>>>> This design is fundamentally 'decent' for scalability because\n>>>>>>>>> adding fees to a transaction does not require adding inputs or outputs and\n>>>>>>>>> does not require tracking substantial amounts of new state.\n>>>>>>>>>\n>>>>>>>>> Paying someone else to pay for you via the LN also helps make this\n>>>>>>>>> more efficient if the withdrawal issues can be fixed.\n>>>>>>>>>\n>>>>>>>>> *Lightning:*\n>>>>>>>>>\n>>>>>>>>> This type of design works really well for channels because the\n>>>>>>>>> addition of fees to e.g. a channel state does not require any sort of\n>>>>>>>>> pre-planning (e.g. anchors) or transaction flexibility (SIGHASH flags).\n>>>>>>>>> This sort of design is naturally immune to pinning issues since you could\n>>>>>>>>> offer to pay a fee for any TXID and the number of fee adding offers does\n>>>>>>>>> not need to be restricted in the same way the descendant transactions would\n>>>>>>>>> need to be.\n>>>>>>>>>\n>>>>>>>>> *Without a fork?*\n>>>>>>>>>\n>>>>>>>>> This type of design could be done as a federated network that\n>>>>>>>>> bribes miners -- potentially even retroactively after a block is formed.\n>>>>>>>>> That might be sufficient to prove the concept works before a consensus\n>>>>>>>>> upgrade is deployed, but such an approach does mean there is a centralizing\n>>>>>>>>> layer interfering with normal mining.\n>>>>>>>>>\n>>>>>>>>>\n>>>>>>>>> Happy new year!!\n>>>>>>>>>\n>>>>>>>>> Jeremy\n>>>>>>>>>\n>>>>>>>>> --\n>>>>>>>>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>>>>>>>>> <https://twitter.com/JeremyRubin>\n>>>>>>>>> _______________________________________________\n>>>>>>>>> bitcoin-dev mailing list\n>>>>>>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>>>>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>>>>>>>\n>>>>>>>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220119/1724e2e9/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Fee Accounts",
            "categories": [
                "bitcoin-dev",
                "Pre-BIP"
            ],
            "authors": [
                "Jeremy",
                "Billy Tetrud"
            ],
            "messages_count": 10,
            "total_messages_chars_count": 108378
        }
    },
    {
        "title": "[bitcoin-dev] Nuke *notify options from Bitcoin Core",
        "thread_messages": [
            {
                "author": "Prayank",
                "date": "2022-01-01T21:03:11",
                "message_text_only": "Hello World,\n\nWhat?\n\nRemove all *notify options from Bitcoin Core (full node implementation used by 99% nodes)\n\nOr one of the below:\n\nnotifications.dat\nnot use system() in runCommand()\nUse a new setting in settings.json file, notifypolicy which is 0 by default (restricted) and can be set to 1 (unrestricted)\n\nWhy?\n\nThey can help attackers in doing almost anything on machines running Bitcoin Core with some social engineering.\n\nHow?\n\nEverything is explained several times in different issues, PRs etc. to different people including few reviewers who even NACKed a PR that would help in adding such options but with some documentation. I won't comment much about the reviewers but some of them were clueless about issue and how things work.\n\nExample: Calling something misleading and ludicrous when you don't even know what works in Windows shortcut and could not share one example of financial application https://github.com/bitcoin/bitcoin/issues/23412#issuecomment-1003496126\n\nTL;DR\n\nhttps://github.com/bitcoin/bitcoin/pull/23395#issuecomment-956353035\n\nhttps://github.com/bitcoin/bitcoin/issues/23412#issuecomment-970480769\n\nTo be honest, neither I have energy left to highlight the importance of these issues nor most of the people look interested in this space to address it. This email is a part of my efforts to share things with everyone which I even tried with documentation. There is something seriously wrong if few people including maintainers acknowledge the issues with *notify options but nobody wants to fix it or document it, I will leave it for people to form their own opinions about it.\n\nLast but not least I was even asked to not review and comment in https://github.com/bitcoin/bitcoin/pull/23395 when I was just responding to others. \n\nThis will be helpful in my security project which was already shared in mailing list to highlight what users expect from developers and future of money, review process etc. and what is the ground reality.\n\nHappy New Year\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220101/f8eafc5e/attachment-0001.html>"
            },
            {
                "author": "Daniel Edgecumbe",
                "date": "2022-01-01T22:57:57",
                "message_text_only": "I've looked at these PR's and they seem, frankly, bizarre.\n\nYou've essentially noticed that if an attacker can run commands on your system, they can run commands on your system.\n\nIf you can convince someone to run arbitrary commands, which is what a desktop shortcut or a command argument _is_ at a fundamental level, you own their system. I fail to see how this has anything to do with Core at all.\n\nDaniel Edgecumbe | esotericnonsense\nemail at esotericnonsense.com | https://esotericnonsense.com\n\nOn Sat, Jan 1, 2022, at 21:03, Prayank via bitcoin-dev wrote:\n> Hello World,\n>\n> What?\n>\n> Remove all *notify options from Bitcoin Core (full node implementation \n> used by 99% nodes)\n>\n> Or one of the below:\n>\n> notifications.dat\n> not use system() in runCommand()\n> Use a new setting in settings.json file, notifypolicy which is 0 by \n> default (restricted) and can be set to 1 (unrestricted)\n>\n> Why?\n>\n> They can help attackers in doing almost anything on machines running \n> Bitcoin Core with some social engineering.\n>\n> How?\n>\n> Everything is explained several times in different issues, PRs etc. to \n> different people including few reviewers who even NACKed a PR that \n> would help in adding such options but with some documentation. I won't \n> comment much about the reviewers but some of them were clueless about \n> issue and how things work.\n>\n> Example: Calling something misleading and ludicrous when you don't even \n> know what works in Windows shortcut and could not share one example of \n> financial application \n> https://github.com/bitcoin/bitcoin/issues/23412#issuecomment-1003496126\n>\n> TL;DR\n>\n> https://github.com/bitcoin/bitcoin/pull/23395#issuecomment-956353035\n>\n> https://github.com/bitcoin/bitcoin/issues/23412#issuecomment-970480769\n>\n> To be honest, neither I have energy left to highlight the importance of \n> these issues nor most of the people look interested in this space to \n> address it. This email is a part of my efforts to share things with \n> everyone which I even tried with documentation. There is something \n> seriously wrong if few people including maintainers acknowledge the \n> issues with *notify options but nobody wants to fix it or document it, \n> I will leave it for people to form their own opinions about it.\n>\n> Last but not least I was even asked to not review and comment in \n> https://github.com/bitcoin/bitcoin/pull/23395 when I was just \n> responding to others. \n>\n> This will be helpful in my security project which was already shared in \n> mailing list to highlight what users expect from developers and future \n> of money, review process etc. and what is the ground reality.\n>\n> Happy New Year\n>\n> -- \n> Prayank\n>\n> A3B1 E430 2298 178F\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Prayank",
                "date": "2022-01-01T23:29:15",
                "message_text_only": "Hi Daniel,\n\nNot sure which PRs are you talking about, maybe you missed these points based on your understanding:\n\nLot of fancy things won't work in windows shortcut target\n\nIt is more suspicious even if you try, compared to something wrapped in *notify options provided by bitcoin core\n\nThis will not provide me option to run a command based on events like received transaction in wallet\n\n*notify options provide some options that every malware is looking for\n\nThere is enough time to research more about the issue and respond with something new or that helps in documentation.\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220102/9873c9f6/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Nuke *notify options from Bitcoin Core",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Prayank",
                "Daniel Edgecumbe"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 5878
        }
    },
    {
        "title": "[bitcoin-dev] Stumbling into a contentious soft fork activation attempt",
        "thread_messages": [
            {
                "author": "Michael Folkson",
                "date": "2022-01-03T02:05:20",
                "message_text_only": "I have already expressed my arguments on the regularity of soft forks [0]. Having spent months of my time on Taproot activation last year attempting to get at least rough community consensus on the activation method it seems crazy to me that some want to do that again so soon after Taproot activation and somehow this time it will be plain sailing. (Spoiler: it won\u2019t. Although Taproot safely activated there remain outstanding views ranging on whether BIP 8 or 9 variants of Speedy Trial should be used in future to Speedy Trial only being a short term stopgap that should not be repeated.) If OP_CTV is ready to go now and has overwhelming community support (I don\u2019t think either is true) it should surely have been included in the Taproot soft fork (perhaps delayed) rather than going through the months of activation wrangling and community outreach twice.\n\nI stated in that post:\n\n\u201cA contentious or disputed soft fork can be merged into a Bitcoin implementation at any time but doing this is opening the door to the schism, disruption and waste of developer hours that we saw in 2017. Personally I think we\u2019ll see an attempt to activate a contentious soft fork at some point in the long term future (Murphy\u2019s Law) but any attempt to do so should be strongly discouraged. It should be made clear to any individual(s) that attempt this of the knock on impacts and potential short term damage they are inflicting on the entire ecosystem. Longer term I have confidence in Bitcoin\u2019s ability to survive whatever happens but allocating significant community resources to resist an unnecessary contentious soft fork (or even regular contentious soft forks) is not an optimal use of those resources.\u201d\n\nI am getting increasingly concerned that we are stumbling into this scenario three months after I wrote that post. One of many future soft fork proposals (as many will know) is BIP 119 [1] which is the enabling of a new opcode OP_CHECKTEMPLATEVERIFY (OP_CTV). It seems to me like the author and primary promoter of this proposal (Jeremy Rubin) is pushing for an imminent attempted activation of a soft fork containing exclusively OP_CTV [2]. To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren\u2019t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4]. Similar work has not been done for any of the speculated use cases of OP_CTV. Instead Jeremy is encouraging people to \u201csoft signal\u201d for soft fork activation of OP_CTV presumably in the hope that the building out and testing of use cases can be completed post activation.\n\nThis is totally irresponsible in my view. A long list of speculated use cases means nothing on its own. I can propose a new opcode OP_MAGIC and claim it will cure cancer with no potential downsides and hence we should have a soft fork activating it as soon as possible. I would hope there would be sufficient skepticism that this proposal wouldn\u2019t see the light of day. It is true that Jeremy has some rudimentary proofs of concept built but as any software engineer will tell you the vast majority of the challenges are encountered once you attempt to build out that proof of concept. Once you do you may realize that the tool (or opcode) you are using isn\u2019t the right one for the job. Unlike adjusting a feature on a social media app adjusting a consensus change once it has been activated is trickier to put it mildly.\n\nThere are a number of other more interesting technical discussions to be had later (what kind of covenants we want and are able to enable safely on Bitcoin etc, how CTV compares to other covenant enabling proposals, to what extent activating CTV would impact future proposals) but I feel the top priority is to bring some attention to the danger of us stumbling into an attempted contentious soft fork activation attempt.\n\nJeremy has put up this site (https://utxos.org/signals/) which is collecting so-called \u201csoft signals\u201d. I very much doubt anyone has a problem with Jeremy engaging with the community on his proposal and receiving feedback. However, the site currently states:\n\n\u201cThe following organizations, individuals, or pools have communicated preference for and intent to support a BIP-119 activation attempt using reasonable parameters. These \u201csoft signals\u201d are non-binding until an actual concrete proposal has been formed, but are useful for measuring community consensus.\u201d\n\nThere have been a number of \u201csoft signals\u201d, many expressing enthusiasm for the speculated use cases of OP_CTV. Personally I share that enthusiasm like I do with the prospect of curing cancer. But these soft signals seem as if they are going to be used to attempt to justify an imminent contentious soft fork attempt. The devil is in the details both with regards to wording like \u201creasonable parameters\u201d and the utility and safety of a new opcode. Indeed if you share my concerns that there has not been sufficient scrutiny and research on the long implications of this proposal I encourage you to register a soft signal of \u201cNo\u201d on the site like I have. You can always change it to \u201cYes\u201d if and when you support an imminent soft fork activation attempt containing exclusively OP_CTV. Enabling covenants on Bitcoin is a big step change with barely any existing research on the topic and attempting to rush it through by the back door so soon after Taproot activation should be resisted. To look at the ~200 lines of code for the opcode exclusively (of course this should be done too) in a vacuum without considering the broader implications is also incredibly shortsighted. The only thing stopping a descent into Ethereum style seat of our pants consensus changes is community vigilance. If we ever lose that we lose the foundation of this industry.\n\n[0]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-October/019535.html\n\n[1]: https://github.com/bitcoin/bips/blob/master/bip-0119.mediawiki\n\n[2]: https://rubin.io/bitcoin/2021/12/24/advent-27/\n\n[3]: https://github.com/bitcoin/bips/blob/master/bip-0118.mediawiki\n\n[4]: https://yakshaver.org/bitcoin/#anyprevout\n\n--\n\nMichael Folkson\nEmail: michaelfolkson at protonmail.com\nKeybase: michaelfolkson\nPGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220103/bccea39a/attachment.html>"
            },
            {
                "author": "Prayank",
                "date": "2022-01-04T11:53:32",
                "message_text_only": "Hi Michael,\n\n> If OP_CTV is ready to go now and has overwhelming community support (I don\u2019t think either is true) it should surely have been included in the Taproot soft fork (perhaps delayed) rather than going through the months of activation wrangling and community outreach twice.\n\nIt should be ready to go in a few months IMO and makes no sense to bundle everything with Taproot soft fork. Things can remain separate and still considered good enough based on the changes proposed.\n\n\n> It should be made clear to any individual(s) that attempt this of the knock on impacts and potential short term damage they are inflicting on the entire ecosystem.\n\nI don't see any damage with a soft fork that is being discussed since years, documented properly, includes code for implementation and examples, recently got crowdfunding to incentivize review process and improve security.\n\n\n> It seems to me like the author and primary promoter of this proposal (Jeremy Rubin) is pushing for an imminent attempted activation of a soft fork containing exclusively OP_CTV [2].\n\nHe is doing nothing unexpected and got reasons to support OP_CTV being implemented soon.\n\n\n> To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren\u2019t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].\n\nBecause its not ready?\n\n\n> Similar work has not been done for any of the speculated use cases of OP_CTV.\n\nThere is no comparison between the two. If someone has worked on one of the speculated uses cases, it makes no difference.\n\nIf we still compare something because of our bias, maybe Sapio is something that would be more helpful for Bitcoin developers.\n\n\n> Instead Jeremy is encouraging people to \u201csoft signal\u201d for soft fork activation of OP_CTV presumably in the hope that the building out and testing of use cases can be completed post activation.\n\nWe had soft signals from mining pools for Taproot as well and still waiting for projects to use Taproot. Even miners signaling with speedy trial was not a guarantee they would follow new consensus rules later. I don't see anything wrong in looking for people who support a proposal and documenting it.\n\n\n> This is totally irresponsible in my view. A long list of speculated use cases means nothing on its own. I can propose a new opcode OP_MAGIC and claim it will cure cancer with no potential downsides and hence we should have a soft fork activating it as soon as possible.\n\nIf I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.\n\n\n> I would hope there would be sufficient skepticism that this proposal wouldn\u2019t see the light of day.\n\nI am confident this proposal will be used by lot of Bitcoin projects and improve privacy, security, decentralization, demand for block space etc.\n\n\n> I feel the top priority is to bring some attention to the danger of us stumbling into an attempted contentious soft fork activation attempt.\n\nI feel the danger is a few people able to stop soft forks that improve Bitcoin because of their bias and opinions which are mostly non-technical.\n\n\n> Enabling covenants on Bitcoin is a big step change with barely any existing research on the topic and attempting to rush it through by the back door so soon after Taproot activation should be resisted.\n\nNobody has stopped anyone from doing research. There is no backdoor and everything is public. So soon? I am not sure if there are any issues with a soft fork in next few months if its ready.\n\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220104/4987e2a4/attachment.html>"
            },
            {
                "author": "Michael Folkson",
                "date": "2022-01-04T14:15:04",
                "message_text_only": "> It should be ready to go in a few months IMO\n\nWhat is this assessment based on? I am assuming you haven't done a code review of the opcode, you haven't coded up a real world use case of OP_CTV (or even a primitive proof of concept), you haven't thought about alternative proposals for any particular use case (vaults for example have multiple current alternative proposals and most likely many future ones). A new programming language (Sapio) sounds great but do you you need it for your use case rather than an alternative high level language like Minsc? Sapio makes use of Miniscript which hasn't been finalized yet or updated for Taproot. Surely that needs to be done first otherwise Sapio is built on top of something that isn't ready? When you make the claims such as a consensus change is ready to go the burden is on you to convince me and other skeptics why. The status quo is the default. \"I think it is ready or will be ready\" doesn't mean much unless you have done the work.\n\nYou are well aware of the review process in Core for non-consensus changes. For consensus changes you really should be digging even deeper, the bar should be higher and all questions you and others have should be explored in depth. It is not enough for one individual to say it is ready to be activated, anyone who is expressing that view should understand why the opcode has been designed in the way it has and why it is so important that we should dedicate months of community time to getting a single opcode activated this year.\n\nI have more sympathy for those who don't follow Bitcoin Core development and Bitcoin Core review on an ongoing basis (note as I said that the bar for consensus changes should be significantly higher than a non-consensus PR). The use cases sound cool and the work is genuinely interesting. But honestly for someone who has followed Bitcoin Core development, review for a while now you really should know better than bandy around statements like \"it should be ready to go in a few months\" when you currently haven't scratched the surface on the utility and safety of this opcode. You regularly NACK Core PRs yet you seem willing to wave a consensus change through with no outstanding questions and zero skepticism.\n\n> If I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.\n\nMultiple proven built out use cases, sure. Multiple is better than single when you have done the work to ensure they are actually the right tool for those multiple use cases. This work hasn't been done on any of these use cases. The curing cancer analogy was used to elucidate the point that claims should be deeply explored rather than just accepted as true.\n\n>> To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren\u2019t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].\n\n> Because its not ready?\n\nAs I said it is not ready because the ANYPREVOUT contributors are building out and testing a use case. The high bar on readiness should be applied to all proposals not merely the ones where the authors/contributors decide to impose a high bar themselves.\n\nI don't really want to spend my year imploring people to dig deeper on this before indicating they support an imminent activation attempt. Some people don't have the understanding to dig deeper, some people don't have the time and some don't have either. However, if an activation of OP_CTV is attempted this year I am sure it will be contentious [0]. Anyone who cares about Bitcoin development and the ongoing technical work in a multitude of areas should be strongly against a contentious soft fork activation attempt wasting the time of developers and the entire ecosystem even if they don't have the understanding or time to appreciate the reasons why it is contentious.\n\nAs I understand there are IRC workshops next week on BIP 119 [1] that I'd encourage you to join so you can start getting into a position where you can engage with the skeptics on technical concerns. Regrettably (as I said I find this work interesting) I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point. In my view activation should not even be speculated upon until it is clear there is overwhelming community support for a soft fork being activated.\n\n[0]: https://gist.github.com/michaelfolkson/352a503f4f9fc5de89af528d86a1b718\n[1]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-December/019719.html\n\n--\n\nMichael Folkson\nEmail: michaelfolkson at protonmail.com\nKeybase: michaelfolkson\nPGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Tuesday, January 4th, 2022 at 11:53 AM, Prayank via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Michael,\n>\n>> If OP_CTV is ready to go now and has overwhelming community support (I don\u2019t think either is true) it should surely have been included in the Taproot soft fork (perhaps delayed) rather than going through the months of activation wrangling and community outreach twice.\n>\n> It should be ready to go in a few months IMO and makes no sense to bundle everything with Taproot soft fork. Things can remain separate and still considered good enough based on the changes proposed.\n>\n>> It should be made clear to any individual(s) that attempt this of the knock on impacts and potential short term damage they are inflicting on the entire ecosystem.\n>\n> I don't see any damage with a soft fork that is being discussed since years, documented properly, includes code for implementation and examples, recently got crowdfunding to incentivize review process and improve security.\n>\n>> It seems to me like the author and primary promoter of this proposal (Jeremy Rubin) is pushing for an imminent attempted activation of a soft fork containing exclusively OP_CTV [2].\n>\n> He is doing nothing unexpected and got reasons to support OP_CTV being implemented soon.\n>\n>> To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren\u2019t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].\n>\n> Because its not ready?\n>\n>> Similar work has not been done for any of the speculated use cases of OP_CTV.\n>\n> There is no comparison between the two. If someone has worked on one of the speculated uses cases, it makes no difference.\n>\n> If we still compare something because of our bias, maybe Sapio is something that would be more helpful for Bitcoin developers.\n>\n>> Instead Jeremy is encouraging people to \u201csoft signal\u201d for soft fork activation of OP_CTV presumably in the hope that the building out and testing of use cases can be completed post activation.\n>\n> We had soft signals from mining pools for Taproot as well and still waiting for projects to use Taproot. Even miners signaling with speedy trial was not a guarantee they would follow new consensus rules later. I don't see anything wrong in looking for people who support a proposal and documenting it.\n>\n>> This is totally irresponsible in my view. A long list of speculated use cases means nothing on its own. I can propose a new opcode OP_MAGIC and claim it will cure cancer with no potential downsides and hence we should have a soft fork activating it as soon as possible.\n>\n> If I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.\n>\n>> I would hope there would be sufficient skepticism that this proposal wouldn\u2019t see the light of day.\n>\n> I am confident this proposal will be used by lot of Bitcoin projects and improve privacy, security, decentralization, demand for block space etc.\n>\n>> I feel the top priority is to bring some attention to the danger of us stumbling into an attempted contentious soft fork activation attempt.\n>\n> I feel the danger is a few people able to stop soft forks that improve Bitcoin because of their bias and opinions which are mostly non-technical.\n>\n>> Enabling covenants on Bitcoin is a big step change with barely any existing research on the topic and attempting to rush it through by the back door so soon after Taproot activation should be resisted.\n>\n> Nobody has stopped anyone from doing research. There is no backdoor and everything is public. So soon? I am not sure if there are any issues with a soft fork in next few months if its ready.\n>\n> --\n> Prayank\n>\n> A3B1 E430 2298 178F\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220104/f5766936/attachment-0001.html>"
            },
            {
                "author": "Prayank",
                "date": "2022-01-04T15:06:28",
                "message_text_only": "What I have done related to OP_CTV?\n\nhttps://twitter.com/prayankgahlot/status/1456643891885592579\n\nWhat am I currently working on that is not shared publicly and will do in next few weeks?\n\nReview pull request 21702 and write contracts using Sapio based on few ideas that I already have.\n\nWhat is this assessment based on?\n\nA few months are enough for the recent bounty to find bugs if possible and other things pending to be completed.\n\n> you haven't thought about alternative proposals for any particular use case (vaults for example have multiple current alternative proposals and most likely many future ones)\n\nI have read enough about alternative proposals and some of them don't even compete with OP_CTV, they can all be implemented and complement each other. Vaults is not the only thing that I care about and it would be better if we don't assume about research done by others.\n\n> A new programming language (Sapio) sounds great but do you you need it for your use case rather than an alternative high level language like Minsc? Sapio makes use of Miniscript which hasn't been finalized yet or updated for Taproot. Surely that needs to be done first otherwise Sapio is built on top of something that isn't ready? When you make the claims such as a consensus change is ready to go the burden is on you to convince me and other skeptics why. The status quo is the default. \"I think it is ready or will be ready\" doesn't mean much unless you have done the work.\n\nTBH I am not against Miniscript and still waiting for its support in Core which might take another few years. I would love to have multiple programming languages so that application developers can decide what works best for them.\n\nI don't understand what work are you expecting me to do in this case to share my opinion about a soft fork.\n\n> It is not enough for one individual to say it is ready to be activated, anyone who is expressing that view should understand why the opcode has been designed in the way it has and why it is so important that we should dedicate months of community time to getting a single opcode activated this year.\n\nI have dedicated enough time reading everything related to OP_CTV and discuss things that were posted earlier here by Jeremy Rubin. Not sure how many skeptics did the same or even tried to discuss anything until recent bounty was announced.\n\n> You regularly NACK Core PRs yet you seem willing to wave a consensus change through with no outstanding questions and zero skepticism.\n\nI would NACK and write the reasons in this pull request as well if I find any issues and PR author is not addressing them. I had lots of questions at conceptual level which have been answered on different platforms and I cannot document each conversation. Its a Concept ACK from me and none of the contributors could find any issues with PR right now so I don't want to stop people from improving Bitcoin.\n\n> As I understand there are IRC workshops next week on BIP 119 [1] that I'd encourage you to join so you can start getting into a position where you can engage with the skeptics on technical concerns. Regrettably (as I said I find this work interesting) I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point. In my view activation should not even be speculated upon until it is clear there is overwhelming community support for a soft fork being activated.\n\nI would be attending the workshops and had even requested Jeremy to use Twitch because it would help more people understand things with audio, screen sharing etc. I would love to see skeptics participate and discuss technical things.\n\n> I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point.\n\nIf you don't participate in the workshops you might miss few things. However, either Jeremy or one of the participants will ensure they share the summary here or even logs would be available.\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n\n\n\nJan 4, 2022, 19:45 by michaelfolkson at protonmail.com:\n\n> >\u00a0> It should be ready to go in a few months IMO\n>\n> What is this assessment based on? I am assuming you haven't done a code review of the opcode, you haven't coded up a real world use case of OP_CTV (or even a primitive proof of concept), you haven't thought about alternative proposals for any particular use case (vaults for example have multiple current alternative proposals and most likely many future ones). A new programming language (Sapio) sounds great but do you you need it for your use case rather than an alternative high level language like Minsc? Sapio makes use of Miniscript which hasn't been finalized yet or updated for Taproot. Surely that needs to be done first otherwise Sapio is built on top of something that isn't ready? When you make the claims such as a consensus change is ready to go the burden is on you to convince me and other skeptics why. The status quo is the default. \"I think it is ready or will be ready\" doesn't mean much unless you have done the work.\n>\n> You are well aware of the review process in Core for non-consensus changes. For consensus changes you really should be digging even deeper, the bar should be higher and all questions you and others have should be explored in depth. It is not enough for one individual to say it is ready to be activated, anyone who is expressing that view should understand why the opcode has been designed in the way it has and why it is so important that we should dedicate months of community time to getting a single opcode activated this year.\n>\n> I have more sympathy for those who don't follow Bitcoin Core development and Bitcoin Core review on an ongoing basis (note as I said that the bar for consensus changes should be significantly higher than a non-consensus PR). The use cases sound cool and the work is genuinely interesting. But honestly for someone who has followed Bitcoin Core development, review for a while now you really should know better than bandy around statements like \"it should be ready to go in a few months\" when you currently haven't scratched the surface on the utility and safety of this opcode. You regularly NACK Core PRs yet you seem willing to wave a consensus change through with no outstanding questions and zero skepticism.\n>\n> >\u00a0If I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.\n>\n> Multiple proven built out use cases, sure. Multiple is better than single when you have done the work to ensure they are actually the right tool for those multiple use cases. This work hasn't been done on any of these use cases. The curing cancer analogy was used to elucidate the point that claims should be deeply explored rather than just accepted as true.\n>\n> >> To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren\u2019t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].\n>\n> > Because its not ready?\n>\n> As I said it is not ready because the ANYPREVOUT contributors are building out and testing a use case. The high bar on readiness should be applied to all proposals not merely the ones where the authors/contributors decide to impose a high bar themselves.\n>\n> I don't really want to spend my year imploring people to dig deeper on this before indicating they support an imminent activation attempt. Some people don't have the understanding to dig deeper, some people don't have the time and some don't have either. However, if an activation of OP_CTV is attempted this year I am sure it will be contentious [0]. Anyone who cares about Bitcoin development and the ongoing technical work in a multitude of areas should be strongly against a contentious soft fork activation attempt wasting the time of developers and the entire ecosystem even if they don't have the understanding or time to appreciate the reasons why it is contentious.\n>\n> As I understand there are IRC workshops next week on BIP 119 [1] that I'd encourage you to join so you can start getting into a position where you can engage with the skeptics on technical concerns. Regrettably (as I said I find this work interesting) I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point. In my view activation should not even be speculated upon until it is clear there is overwhelming community support for a soft fork being activated.\n>\n> [0]:\u00a0> https://gist.github.com/michaelfolkson/352a503f4f9fc5de89af528d86a1b718\n> [1]:\u00a0> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-December/019719.html\n>\n> --> Michael FolksonEmail: michaelfolkson at protonmail.comKeybase: michaelfolksonPGP:\u00a043ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>  On Tuesday, January 4th, 2022 at 11:53 AM, Prayank via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>  \n>\n>> Hi Michael,\n>>\n>> > If OP_CTV is ready to go now and has overwhelming community support (I don\u2019t think either is true) it should surely have been included in the Taproot soft fork (perhaps delayed) rather than going through the months of activation wrangling and community outreach twice.\n>>\n>> It should be ready to go in a few months IMO and makes no sense to bundle everything with Taproot soft fork. Things can remain separate and still considered good enough based on the changes proposed.\n>>\n>>\n>> > It should be made clear to any individual(s) that attempt this of the knock on impacts and potential short term damage they are inflicting on the entire ecosystem.\n>>\n>> I don't see any damage with a soft fork that is being discussed since years, documented properly, includes code for implementation and examples, recently got crowdfunding to incentivize review process and improve security.\n>>\n>>\n>> > It seems to me like the author and primary promoter of this proposal (Jeremy Rubin) is pushing for an imminent attempted activation of a soft fork containing exclusively OP_CTV [2].\n>>\n>> He is doing nothing unexpected and got reasons to support OP_CTV being implemented soon.\n>>\n>>\n>> > To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren\u2019t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].\n>>\n>> Because its not ready?\n>>\n>>\n>> > Similar work has not been done for any of the speculated use cases of OP_CTV.\n>>\n>> There is no comparison between the two. If someone has worked on one of the speculated uses cases, it makes no difference.\n>>\n>> If we still compare something because of our bias, maybe Sapio is something that would be more helpful for Bitcoin developers.\n>>\n>>\n>> > Instead Jeremy is encouraging people to \u201csoft signal\u201d for soft fork activation of OP_CTV presumably in the hope that the building out and testing of use cases can be completed post activation.\n>>\n>> We had soft signals from mining pools for Taproot as well and still waiting for projects to use Taproot. Even miners signaling with speedy trial was not a guarantee they would follow new consensus rules later. I don't see anything wrong in looking for people who support a proposal and documenting it.\n>>\n>>\n>> > This is totally irresponsible in my view. A long list of speculated use cases means nothing on its own. I can propose a new opcode OP_MAGIC and claim it will cure cancer with no potential downsides and hence we should have a soft fork activating it as soon as possible.\n>>\n>> If I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.\n>>\n>>\n>> > I would hope there would be sufficient skepticism that this proposal wouldn\u2019t see the light of day.\n>>\n>> I am confident this proposal will be used by lot of Bitcoin projects and improve privacy, security, decentralization, demand for block space etc.\n>>\n>>\n>> > I feel the top priority is to bring some attention to the danger of us stumbling into an attempted contentious soft fork activation attempt.\n>>\n>> I feel the danger is a few people able to stop soft forks that improve Bitcoin because of their bias and opinions which are mostly non-technical.\n>>\n>>\n>> > Enabling covenants on Bitcoin is a big step change with barely any existing research on the topic and attempting to rush it through by the back door so soon after Taproot activation should be resisted.\n>>\n>> Nobody has stopped anyone from doing research. There is no backdoor and everything is public. So soon? I am not sure if there are any issues with a soft fork in next few months if its ready.\n>>\n>>\n>> -- \n>> Prayank\n>>\n>> A3B1 E430 2298 178F\n>>\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220104/837014b9/attachment-0001.html>"
            },
            {
                "author": "Michael Folkson",
                "date": "2022-01-04T16:48:08",
                "message_text_only": "You are working on a use case of OP_CTV now? Cool, you only recently announced you were working on Bitcoin Knots (and I think Wasabi before that) so I'm losing track of all the announcements. Regardless stick with it and build out more than a rudimentary proof of concept. That is one of the things that is severely lacking at this point for OP_CTV.\n\n> TBH I am not against Miniscript and still waiting for its support in Core which might take another few years. I would love to have multiple programming languages so that application developers can decide what works best for them.\n\nI would hope you weren't against Miniscript because Sapio is built on top of it :) But whatever have fun, I can't do this all day.\n\n--\n\nMichael Folkson\nEmail: michaelfolkson at protonmail.com\nKeybase: michaelfolkson\nPGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Tuesday, January 4th, 2022 at 3:06 PM, Prayank <prayank at tutanota.de> wrote:\n\n> What I have done related to OP_CTV?\n>\n> https://twitter.com/prayankgahlot/status/1456643891885592579\n>\n> What am I currently working on that is not shared publicly and will do in next few weeks?\n>\n> Review pull request 21702 and write contracts using Sapio based on few ideas that I already have.\n>\n> What is this assessment based on?\n>\n> A few months are enough for the recent bounty to find bugs if possible and other things pending to be completed.\n>\n>> you haven't thought about alternative proposals for any particular use case (vaults for example have multiple current alternative proposals and most likely many future ones)\n>\n> I have read enough about alternative proposals and some of them don't even compete with OP_CTV, they can all be implemented and complement each other. Vaults is not the only thing that I care about and it would be better if we don't assume about research done by others.\n>\n>> A new programming language (Sapio) sounds great but do you you need it for your use case rather than an alternative high level language like Minsc? Sapio makes use of Miniscript which hasn't been finalized yet or updated for Taproot. Surely that needs to be done first otherwise Sapio is built on top of something that isn't ready? When you make the claims such as a consensus change is ready to go the burden is on you to convince me and other skeptics why. The status quo is the default. \"I think it is ready or will be ready\" doesn't mean much unless you have done the work.\n>\n> TBH I am not against Miniscript and still waiting for its support in Core which might take another few years. I would love to have multiple programming languages so that application developers can decide what works best for them.\n>\n> I don't understand what work are you expecting me to do in this case to share my opinion about a soft fork.\n>\n>> It is not enough for one individual to say it is ready to be activated, anyone who is expressing that view should understand why the opcode has been designed in the way it has and why it is so important that we should dedicate months of community time to getting a single opcode activated this year.\n>\n> I have dedicated enough time reading everything related to OP_CTV and discuss things that were posted earlier here by Jeremy Rubin. Not sure how many skeptics did the same or even tried to discuss anything until recent bounty was announced.\n>\n>> You regularly NACK Core PRs yet you seem willing to wave a consensus change through with no outstanding questions and zero skepticism.\n>\n> I would NACK and write the reasons in this pull request as well if I find any issues and PR author is not addressing them. I had lots of questions at conceptual level which have been answered on different platforms and I cannot document each conversation. Its a Concept ACK from me and none of the contributors could find any issues with PR right now so I don't want to stop people from improving Bitcoin.\n>\n>> As I understand there are IRC workshops next week on BIP 119 [1] that I'd encourage you to join so you can start getting into a position where you can engage with the skeptics on technical concerns. Regrettably (as I said I find this work interesting) I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point. In my view activation should not even be speculated upon until it is clear there is overwhelming community support for a soft fork being activated.\n>\n> I would be attending the workshops and had even requested Jeremy to use Twitch because it would help more people understand things with audio, screen sharing etc. I would love to see skeptics participate and discuss technical things.\n>\n>> I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point.\n>\n> If you don't participate in the workshops you might miss few things. However, either Jeremy or one of the participants will ensure they share the summary here or even logs would be available.\n>\n> --\n> Prayank\n>\n> A3B1 E430 2298 178F\n>\n> Jan 4, 2022, 19:45 by michaelfolkson at protonmail.com:\n>\n>>> It should be ready to go in a few months IMO\n>>\n>> What is this assessment based on? I am assuming you haven't done a code review of the opcode, you haven't coded up a real world use case of OP_CTV (or even a primitive proof of concept), you haven't thought about alternative proposals for any particular use case (vaults for example have multiple current alternative proposals and most likely many future ones). A new programming language (Sapio) sounds great but do you you need it for your use case rather than an alternative high level language like Minsc? Sapio makes use of Miniscript which hasn't been finalized yet or updated for Taproot. Surely that needs to be done first otherwise Sapio is built on top of something that isn't ready? When you make the claims such as a consensus change is ready to go the burden is on you to convince me and other skeptics why. The status quo is the default. \"I think it is ready or will be ready\" doesn't mean much unless you have done the work.\n>>\n>> You are well aware of the review process in Core for non-consensus changes. For consensus changes you really should be digging even deeper, the bar should be higher and all questions you and others have should be explored in depth. It is not enough for one individual to say it is ready to be activated, anyone who is expressing that view should understand why the opcode has been designed in the way it has and why it is so important that we should dedicate months of community time to getting a single opcode activated this year.\n>>\n>> I have more sympathy for those who don't follow Bitcoin Core development and Bitcoin Core review on an ongoing basis (note as I said that the bar for consensus changes should be significantly higher than a non-consensus PR). The use cases sound cool and the work is genuinely interesting. But honestly for someone who has followed Bitcoin Core development, review for a while now you really should know better than bandy around statements like \"it should be ready to go in a few months\" when you currently haven't scratched the surface on the utility and safety of this opcode. You regularly NACK Core PRs yet you seem willing to wave a consensus change through with no outstanding questions and zero skepticism.\n>>\n>>> If I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.\n>>\n>> Multiple proven built out use cases, sure. Multiple is better than single when you have done the work to ensure they are actually the right tool for those multiple use cases. This work hasn't been done on any of these use cases. The curing cancer analogy was used to elucidate the point that claims should be deeply explored rather than just accepted as true.\n>>\n>>>> To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren\u2019t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].\n>>\n>>> Because its not ready?\n>>\n>> As I said it is not ready because the ANYPREVOUT contributors are building out and testing a use case. The high bar on readiness should be applied to all proposals not merely the ones where the authors/contributors decide to impose a high bar themselves.\n>>\n>> I don't really want to spend my year imploring people to dig deeper on this before indicating they support an imminent activation attempt. Some people don't have the understanding to dig deeper, some people don't have the time and some don't have either. However, if an activation of OP_CTV is attempted this year I am sure it will be contentious [0]. Anyone who cares about Bitcoin development and the ongoing technical work in a multitude of areas should be strongly against a contentious soft fork activation attempt wasting the time of developers and the entire ecosystem even if they don't have the understanding or time to appreciate the reasons why it is contentious.\n>>\n>> As I understand there are IRC workshops next week on BIP 119 [1] that I'd encourage you to join so you can start getting into a position where you can engage with the skeptics on technical concerns. Regrettably (as I said I find this work interesting) I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point. In my view activation should not even be speculated upon until it is clear there is overwhelming community support for a soft fork being activated.\n>>\n>> [0]: https://gist.github.com/michaelfolkson/352a503f4f9fc5de89af528d86a1b718\n>> [1]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-December/019719.html\n>>\n>> --\n>>\n>> Michael Folkson\n>> Email: michaelfolkson at protonmail.com\n>> Keybase: michaelfolkson\n>> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>>\n>> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>> On Tuesday, January 4th, 2022 at 11:53 AM, Prayank via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Hi Michael,\n>>>\n>>>> If OP_CTV is ready to go now and has overwhelming community support (I don\u2019t think either is true) it should surely have been included in the Taproot soft fork (perhaps delayed) rather than going through the months of activation wrangling and community outreach twice.\n>>>\n>>> It should be ready to go in a few months IMO and makes no sense to bundle everything with Taproot soft fork. Things can remain separate and still considered good enough based on the changes proposed.\n>>>\n>>>> It should be made clear to any individual(s) that attempt this of the knock on impacts and potential short term damage they are inflicting on the entire ecosystem.\n>>>\n>>> I don't see any damage with a soft fork that is being discussed since years, documented properly, includes code for implementation and examples, recently got crowdfunding to incentivize review process and improve security.\n>>>\n>>>> It seems to me like the author and primary promoter of this proposal (Jeremy Rubin) is pushing for an imminent attempted activation of a soft fork containing exclusively OP_CTV [2].\n>>>\n>>> He is doing nothing unexpected and got reasons to support OP_CTV being implemented soon.\n>>>\n>>>> To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren\u2019t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].\n>>>\n>>> Because its not ready?\n>>>\n>>>> Similar work has not been done for any of the speculated use cases of OP_CTV.\n>>>\n>>> There is no comparison between the two. If someone has worked on one of the speculated uses cases, it makes no difference.\n>>>\n>>> If we still compare something because of our bias, maybe Sapio is something that would be more helpful for Bitcoin developers.\n>>>\n>>>> Instead Jeremy is encouraging people to \u201csoft signal\u201d for soft fork activation of OP_CTV presumably in the hope that the building out and testing of use cases can be completed post activation.\n>>>\n>>> We had soft signals from mining pools for Taproot as well and still waiting for projects to use Taproot. Even miners signaling with speedy trial was not a guarantee they would follow new consensus rules later. I don't see anything wrong in looking for people who support a proposal and documenting it.\n>>>\n>>>> This is totally irresponsible in my view. A long list of speculated use cases means nothing on its own. I can propose a new opcode OP_MAGIC and claim it will cure cancer with no potential downsides and hence we should have a soft fork activating it as soon as possible.\n>>>\n>>> If I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.\n>>>\n>>>> I would hope there would be sufficient skepticism that this proposal wouldn\u2019t see the light of day.\n>>>\n>>> I am confident this proposal will be used by lot of Bitcoin projects and improve privacy, security, decentralization, demand for block space etc.\n>>>\n>>>> I feel the top priority is to bring some attention to the danger of us stumbling into an attempted contentious soft fork activation attempt.\n>>>\n>>> I feel the danger is a few people able to stop soft forks that improve Bitcoin because of their bias and opinions which are mostly non-technical.\n>>>\n>>>> Enabling covenants on Bitcoin is a big step change with barely any existing research on the topic and attempting to rush it through by the back door so soon after Taproot activation should be resisted.\n>>>\n>>> Nobody has stopped anyone from doing research. There is no backdoor and everything is public. So soon? I am not sure if there are any issues with a soft fork in next few months if its ready.\n>>>\n>>> --\n>>> Prayank\n>>>\n>>> A3B1 E430 2298 178F\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220104/db180a35/attachment-0001.html>"
            },
            {
                "author": "Prayank",
                "date": "2022-01-04T17:07:34",
                "message_text_only": "> You are working on a use case of OP_CTV now?\n\nI think I mentioned clearly what I would be doing: 1. Review pull request 2. Create contracts with Sapio. This would help me review OP_CTV and learn new things.\n\n> Cool, you only recently announced you were working on Bitcoin Knots (and I think Wasabi before that) so I'm losing track of all the announcements.\n\nYou can read more about my involvement in Bitcoin Knots here: https://github.com/bitcoinknots/bitcoin/discussions/39\n\nI started working for zkSNACKs Wasabi 2 months back which can be confirmed with the team.\n\nThere are no announcements and humans can work on multiple things. You might want to check my next project which involves discreet log contracts as I have learnt a few things in bitcoin-s slack as well: https://gok.one/\n\nFor my involvement in other projects you can email me privately and I can share my resume.\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n\n\n\nJan 4, 2022, 22:18 by michaelfolkson at protonmail.com:\n\n> You are working on a use case of OP_CTV now? Cool, you only recently announced you were working on Bitcoin Knots (and I think Wasabi before that) so I'm losing track of all the announcements. Regardless stick with it and build out more than a rudimentary proof of concept. That is one of the things that is severely lacking at this point for OP_CTV.\n>\n> >\u00a0TBH I am not against Miniscript and still waiting for its support in Core which might take another few years. I would love to have multiple programming languages so that application developers can decide what works best for them.\n>\n> I would hope you weren't against Miniscript because Sapio is built on top of it :) But whatever have fun, I can't do this all day.\n>\n>\n> --> Michael FolksonEmail: michaelfolkson at protonmail.comKeybase: michaelfolksonPGP:\u00a043ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>  On Tuesday, January 4th, 2022 at 3:06 PM, Prayank <prayank at tutanota.de> wrote:\n>  \n>\n>> What I have done related to OP_CTV?\n>>\n>> https://twitter.com/prayankgahlot/status/1456643891885592579\n>>\n>> What am I currently working on that is not shared publicly and will do in next few weeks?\n>>\n>> Review pull request 21702 and write contracts using Sapio based on few ideas that I already have.\n>>\n>> What is this assessment based on?\n>>\n>> A few months are enough for the recent bounty to find bugs if possible and other things pending to be completed.\n>>\n>> > you haven't thought about alternative proposals for any particular use case (vaults for example have multiple current alternative proposals and most likely many future ones)\n>>\n>> I have read enough about alternative proposals and some of them don't even compete with OP_CTV, they can all be implemented and complement each other. Vaults is not the only thing that I care about and it would be better if we don't assume about research done by others.\n>>\n>> > A new programming language (Sapio) sounds great but do you you need it for your use case rather than an alternative high level language like Minsc? Sapio makes use of Miniscript which hasn't been finalized yet or updated for Taproot. Surely that needs to be done first otherwise Sapio is built on top of something that isn't ready? When you make the claims such as a consensus change is ready to go the burden is on you to convince me and other skeptics why. The status quo is the default. \"I think it is ready or will be ready\" doesn't mean much unless you have done the work.\n>>\n>> TBH I am not against Miniscript and still waiting for its support in Core which might take another few years. I would love to have multiple programming languages so that application developers can decide what works best for them.\n>>\n>> I don't understand what work are you expecting me to do in this case to share my opinion about a soft fork.\n>>\n>> > It is not enough for one individual to say it is ready to be activated, anyone who is expressing that view should understand why the opcode has been designed in the way it has and why it is so important that we should dedicate months of community time to getting a single opcode activated this year.\n>>\n>> I have dedicated enough time reading everything related to OP_CTV and discuss things that were posted earlier here by Jeremy Rubin. Not sure how many skeptics did the same or even tried to discuss anything until recent bounty was announced.\n>>\n>> > You regularly NACK Core PRs yet you seem willing to wave a consensus change through with no outstanding questions and zero skepticism.\n>>\n>> I would NACK and write the reasons in this pull request as well if I find any issues and PR author is not addressing them. I had lots of questions at conceptual level which have been answered on different platforms and I cannot document each conversation. Its a Concept ACK from me and none of the contributors could find any issues with PR right now so I don't want to stop people from improving Bitcoin.\n>>\n>> > As I understand there are IRC workshops next week on BIP 119 [1] that I'd encourage you to join so you can start getting into a position where you can engage with the skeptics on technical concerns. Regrettably (as I said I find this work interesting) I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point. In my view activation should not even be speculated upon until it is clear there is overwhelming community support for a soft fork being activated.\n>>\n>> I would be attending the workshops and had even requested Jeremy to use Twitch because it would help more people understand things with audio, screen sharing etc. I would love to see skeptics participate and discuss technical things.\n>>\n>> > I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point.\n>>\n>> If you don't participate in the workshops you might miss few things. However, either Jeremy or one of the participants will ensure they share the summary here or even logs would be available.\n>>\n>> -- \n>> Prayank\n>>\n>> A3B1 E430 2298 178F\n>>\n>>\n>>\n>> Jan 4, 2022, 19:45 by michaelfolkson at protonmail.com:\n>>\n>>> >\u00a0>>> It should be ready to go in a few months IMO\n>>>\n>>> What is this assessment based on? I am assuming you haven't done a code review of the opcode, you haven't coded up a real world use case of OP_CTV (or even a primitive proof of concept), you haven't thought about alternative proposals for any particular use case (vaults for example have multiple current alternative proposals and most likely many future ones). A new programming language (Sapio) sounds great but do you you need it for your use case rather than an alternative high level language like Minsc? Sapio makes use of Miniscript which hasn't been finalized yet or updated for Taproot. Surely that needs to be done first otherwise Sapio is built on top of something that isn't ready? When you make the claims such as a consensus change is ready to go the burden is on you to convince me and other skeptics why. The status quo is the default. \"I think it is ready or will be ready\" doesn't mean much unless you have done the work.\n>>>\n>>> You are well aware of the review process in Core for non-consensus changes. For consensus changes you really should be digging even deeper, the bar should be higher and all questions you and others have should be explored in depth. It is not enough for one individual to say it is ready to be activated, anyone who is expressing that view should understand why the opcode has been designed in the way it has and why it is so important that we should dedicate months of community time to getting a single opcode activated this year.\n>>>\n>>> I have more sympathy for those who don't follow Bitcoin Core development and Bitcoin Core review on an ongoing basis (note as I said that the bar for consensus changes should be significantly higher than a non-consensus PR). The use cases sound cool and the work is genuinely interesting. But honestly for someone who has followed Bitcoin Core development, review for a while now you really should know better than bandy around statements like \"it should be ready to go in a few months\" when you currently haven't scratched the surface on the utility and safety of this opcode. You regularly NACK Core PRs yet you seem willing to wave a consensus change through with no outstanding questions and zero skepticism.\n>>>\n>>> >\u00a0If I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.\n>>>\n>>> Multiple proven built out use cases, sure. Multiple is better than single when you have done the work to ensure they are actually the right tool for those multiple use cases. This work hasn't been done on any of these use cases. The curing cancer analogy was used to elucidate the point that claims should be deeply explored rather than just accepted as true.\n>>>\n>>> >> To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren\u2019t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].\n>>>\n>>> > Because its not ready?\n>>>\n>>> As I said it is not ready because the ANYPREVOUT contributors are building out and testing a use case. The high bar on readiness should be applied to all proposals not merely the ones where the authors/contributors decide to impose a high bar themselves.\n>>>\n>>> I don't really want to spend my year imploring people to dig deeper on this before indicating they support an imminent activation attempt. Some people don't have the understanding to dig deeper, some people don't have the time and some don't have either. However, if an activation of OP_CTV is attempted this year I am sure it will be contentious [0]. Anyone who cares about Bitcoin development and the ongoing technical work in a multitude of areas should be strongly against a contentious soft fork activation attempt wasting the time of developers and the entire ecosystem even if they don't have the understanding or time to appreciate the reasons why it is contentious.\n>>>\n>>> As I understand there are IRC workshops next week on BIP 119 [1] that I'd encourage you to join so you can start getting into a position where you can engage with the skeptics on technical concerns. Regrettably (as I said I find this work interesting) I don't feel like I can participate because deployment and activation is being included and I think it is irresponsible to be discussing those at this point. In my view activation should not even be speculated upon until it is clear there is overwhelming community support for a soft fork being activated.\n>>>\n>>> [0]:\u00a0>>> https://gist.github.com/michaelfolkson/352a503f4f9fc5de89af528d86a1b718\n>>> [1]:\u00a0>>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-December/019719.html\n>>>\n>>> -->>> Michael FolksonEmail: michaelfolkson at protonmail.comKeybase: michaelfolksonPGP:\u00a043ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>>>\n>>> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>>> On Tuesday, January 4th, 2022 at 11:53 AM, Prayank via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>\n>>>> Hi Michael,\n>>>>\n>>>> > If OP_CTV is ready to go now and has overwhelming community support (I don\u2019t think either is true) it should surely have been included in the Taproot soft fork (perhaps delayed) rather than going through the months of activation wrangling and community outreach twice.\n>>>>\n>>>> It should be ready to go in a few months IMO and makes no sense to bundle everything with Taproot soft fork. Things can remain separate and still considered good enough based on the changes proposed.\n>>>>\n>>>>\n>>>> > It should be made clear to any individual(s) that attempt this of the knock on impacts and potential short term damage they are inflicting on the entire ecosystem.\n>>>>\n>>>> I don't see any damage with a soft fork that is being discussed since years, documented properly, includes code for implementation and examples, recently got crowdfunding to incentivize review process and improve security.\n>>>>\n>>>>\n>>>> > It seems to me like the author and primary promoter of this proposal (Jeremy Rubin) is pushing for an imminent attempted activation of a soft fork containing exclusively OP_CTV [2].\n>>>>\n>>>> He is doing nothing unexpected and got reasons to support OP_CTV being implemented soon.\n>>>>\n>>>>\n>>>> > To contrast with his approach, the authors and contributors of another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT) aren\u2019t promoting an imminent soft fork activation attempt and instead are building out and testing one of the speculated use cases, eltoo payment channels [4].\n>>>>\n>>>> Because its not ready?\n>>>>\n>>>>\n>>>> > Similar work has not been done for any of the speculated use cases of OP_CTV.\n>>>>\n>>>> There is no comparison between the two. If someone has worked on one of the speculated uses cases, it makes no difference.\n>>>>\n>>>> If we still compare something because of our bias, maybe Sapio is something that would be more helpful for Bitcoin developers.\n>>>>\n>>>>\n>>>> > Instead Jeremy is encouraging people to \u201csoft signal\u201d for soft fork activation of OP_CTV presumably in the hope that the building out and testing of use cases can be completed post activation.\n>>>>\n>>>> We had soft signals from mining pools for Taproot as well and still waiting for projects to use Taproot. Even miners signaling with speedy trial was not a guarantee they would follow new consensus rules later. I don't see anything wrong in looking for people who support a proposal and documenting it.\n>>>>\n>>>>\n>>>> > This is totally irresponsible in my view. A long list of speculated use cases means nothing on its own. I can propose a new opcode OP_MAGIC and claim it will cure cancer with no potential downsides and hence we should have a soft fork activating it as soon as possible.\n>>>>\n>>>> If I had to select between a soft fork without any use cases and one with use cases, I would go with the one that has some use cases with code, documentation etc. You should propose a new opcode but OP_CTV is not claiming to cure cancer.\n>>>>\n>>>>\n>>>> > I would hope there would be sufficient skepticism that this proposal wouldn\u2019t see the light of day.\n>>>>\n>>>> I am confident this proposal will be used by lot of Bitcoin projects and improve privacy, security, decentralization, demand for block space etc.\n>>>>\n>>>>\n>>>> > I feel the top priority is to bring some attention to the danger of us stumbling into an attempted contentious soft fork activation attempt.\n>>>>\n>>>> I feel the danger is a few people able to stop soft forks that improve Bitcoin because of their bias and opinions which are mostly non-technical.\n>>>>\n>>>>\n>>>> > Enabling covenants on Bitcoin is a big step change with barely any existing research on the topic and attempting to rush it through by the back door so soon after Taproot activation should be resisted.\n>>>>\n>>>> Nobody has stopped anyone from doing research. There is no backdoor and everything is public. So soon? I am not sure if there are any issues with a soft fork in next few months if its ready.\n>>>>\n>>>>\n>>>> -- \n>>>> Prayank\n>>>>\n>>>> A3B1 E430 2298 178F\n>>>>\n>>\n>>\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220104/5a1f5ce4/attachment-0001.html>"
            },
            {
                "author": "Christian Decker",
                "date": "2022-01-04T14:42:28",
                "message_text_only": "Prayank via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> writes:\n>> To contrast with his approach, the authors and contributors of\n>> another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT)\n>> aren\u2019t promoting an imminent soft fork activation attempt and instead\n>> are building out and testing one of the speculated use cases, eltoo\n>> payment channels [4].\n>\n> Because its not ready?\n\nCould you elaborate on this point? I keep seeing people mentioning this,\nbut I, as BIP co-author, have not seen any real pushback. For context\nBIP118 was initially called `sighash_noinput` and it was mentioned at\nleast as far back as 2015 when Joseph and Tadje wrote about its\napplications in the LN protocol. While writing eltoo we stumbled over an\nalternative use, and decided to draft the formal proposal.\n\nOnce we saw that Taproot is likely to activate next, AJ started adapting\nit to integrate nicely with Taproot, and renamed it to anyprevout.\n\nI'd like to point out that the original noinput could be implemented\nwith as little as 3-5 lines of code in Bitcoin Core, and there are\nexperimental branches implementing APO, which isn't significantly more\ncomplex than the original proposal.\n\nIn addition Richard Myers has implemented a PoC of eltoo on top of one\nof these experimental branches. So with all this I don't see how APO\ncould be considered \"not ready\".\n\nThe reason that neither noinput nor APO have a section on activation is\nthat we want to allow bundling with other soft-forks, and we want to\nminimize the surface for potential conflicts. Also as the Taproot\nactivation has shown activation is a whole another discussion, that is\nmostly unrelated to the soft-fork being activated.\n\nWhy aren't we yelling about the advantages of APO over other soft-forks\nor asking for immediate activation? Because we want to be respectful of\neveryone's time. We know review capacity is very limited, and developer\ntime expensive. By now most devs will be aware of the many improvements\n(on LN, eltoo, MPC, channel factories, statechains, spacechains, etc)\nanyprevout would enable, so there is little point in annoying everyone\nby constantly talking about it. The people interested in exploring this\nvenue are already working on it, and we just need to wait for an\nopportune moment to start the activation discussion with other\nsoft-forks.\n\nI also see people comparing OP_CTV with APO, which may or may not work\nout in the end. It seems possible to emulate APO using OP_CTV, but at\nwhat cost? APO does not have any overhead in the transaction size, which\nis not the case for OP_CTV, and I therefore consider the two proposals\ncomplementary, and not competing (APO does best what APO does best,\nwhile OP_CTV enables use-cases beyond APO's scope). While I'd prefer APO\nfor eltoo, due to its lack of overhead, I'm also happy to go wih OP_CTV\nif only one gets activated (But then why would we? We've done much more\nobscure things to save bytes in a TX).\n\nFinally I see people mentioning that APO is insufficient to get\neltoo. That's also not true, since in fact we can implement a poor-man's\nversion of eltoo right now:\n\n - When updating:\n   - Iterate through all prior update TXs\n   - Bind the new update TX to each of the prior ones\n   - Sign using `sighash_all`\n   - Collect all sinatures and send to peer (message size O(n), but\n     semantics are preserved, while APO enable O(1) making it actually\n     reasonable to implement).\n\nThere may be some extensions, such as layered commitments that may be\nadded at a later stage, but they are not required to get the first\nversions off the ground. Pretending that they're required would be like\nsaying that the protocol in the LN paper hasn't changed since it was\nfirst written (definitely not the case).\n\nOverall I agree with Michael's sentiment that soft-fork activations have\nto be carefully planned, and kept at a reasonable pace. This is in order\nto ensure that the activated features will work as expected (building\nPoCs is important here) and that review time is kept efficient (bundling\nmay help here). For these reasons we omitted the activation discussion\nin BIP118 and have trimmed the proposal to the bare minimum.\n\nSorry for the longish rant, but I felt I needed to clarify this\nsituation a bit.\n\nCheers,\nChristian"
            },
            {
                "author": "Prayank",
                "date": "2022-01-04T15:45:11",
                "message_text_only": "Hi Christian,\n\nA few things are mentioned in these threads including unsolved research issues in which you were tagged and Richard Myers had even replied so I am assuming this is known:\n\nhttps://twitter.com/JeremyRubin/status/1460349481518465025\n\nhttps://twitter.com/ajtowns/status/1477586002252238850\n\n> I also see people comparing OP_CTV with APO, which may or may not work\nout in the end.\n\nMichael Folkson did in the first email for this thread: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019728.html\n\n> I therefore consider the two proposals complementary\n\nAgree\n\n> I'm also happy to go wih OP_CTV if only one gets activated (But then why would we? We've done much more obscure things to save bytes in a TX).\n\nMaybe we can activate one that does more than just eltoo and see how things work. If APO is still required for eltoo, there would be clear consensus for APO.\n\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n\n\n\nJan 4, 2022, 20:12 by decker.christian at gmail.com:\n\n> Prayank via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> writes:\n>\n>>> To contrast with his approach, the authors and contributors of\n>>> another future soft fork proposal (BIP 118 [3], SIGHASH_ANYPREVOUT)\n>>> aren\u2019t promoting an imminent soft fork activation attempt and instead\n>>> are building out and testing one of the speculated use cases, eltoo\n>>> payment channels [4].\n>>>\n>>\n>> Because its not ready?\n>>\n>\n> Could you elaborate on this point? I keep seeing people mentioning this,\n> but I, as BIP co-author, have not seen any real pushback. For context\n> BIP118 was initially called `sighash_noinput` and it was mentioned at\n> least as far back as 2015 when Joseph and Tadje wrote about its\n> applications in the LN protocol. While writing eltoo we stumbled over an\n> alternative use, and decided to draft the formal proposal.\n>\n> Once we saw that Taproot is likely to activate next, AJ started adapting\n> it to integrate nicely with Taproot, and renamed it to anyprevout.\n>\n> I'd like to point out that the original noinput could be implemented\n> with as little as 3-5 lines of code in Bitcoin Core, and there are\n> experimental branches implementing APO, which isn't significantly more\n> complex than the original proposal.\n>\n> In addition Richard Myers has implemented a PoC of eltoo on top of one\n> of these experimental branches. So with all this I don't see how APO\n> could be considered \"not ready\".\n>\n> The reason that neither noinput nor APO have a section on activation is\n> that we want to allow bundling with other soft-forks, and we want to\n> minimize the surface for potential conflicts. Also as the Taproot\n> activation has shown activation is a whole another discussion, that is\n> mostly unrelated to the soft-fork being activated.\n>\n> Why aren't we yelling about the advantages of APO over other soft-forks\n> or asking for immediate activation? Because we want to be respectful of\n> everyone's time. We know review capacity is very limited, and developer\n> time expensive. By now most devs will be aware of the many improvements\n> (on LN, eltoo, MPC, channel factories, statechains, spacechains, etc)\n> anyprevout would enable, so there is little point in annoying everyone\n> by constantly talking about it. The people interested in exploring this\n> venue are already working on it, and we just need to wait for an\n> opportune moment to start the activation discussion with other\n> soft-forks.\n>\n> I also see people comparing OP_CTV with APO, which may or may not work\n> out in the end. It seems possible to emulate APO using OP_CTV, but at\n> what cost? APO does not have any overhead in the transaction size, which\n> is not the case for OP_CTV, and I therefore consider the two proposals\n> complementary, and not competing (APO does best what APO does best,\n> while OP_CTV enables use-cases beyond APO's scope). While I'd prefer APO\n> for eltoo, due to its lack of overhead, I'm also happy to go wih OP_CTV\n> if only one gets activated (But then why would we? We've done much more\n> obscure things to save bytes in a TX).\n>\n> Finally I see people mentioning that APO is insufficient to get\n> eltoo. That's also not true, since in fact we can implement a poor-man's\n> version of eltoo right now:\n>\n>  - When updating:\n>  - Iterate through all prior update TXs\n>  - Bind the new update TX to each of the prior ones\n>  - Sign using `sighash_all`\n>  - Collect all sinatures and send to peer (message size O(n), but\n>  semantics are preserved, while APO enable O(1) making it actually\n>  reasonable to implement).\n>\n> There may be some extensions, such as layered commitments that may be\n> added at a later stage, but they are not required to get the first\n> versions off the ground. Pretending that they're required would be like\n> saying that the protocol in the LN paper hasn't changed since it was\n> first written (definitely not the case).\n>\n> Overall I agree with Michael's sentiment that soft-fork activations have\n> to be carefully planned, and kept at a reasonable pace. This is in order\n> to ensure that the activated features will work as expected (building\n> PoCs is important here) and that review time is kept efficient (bundling\n> may help here). For these reasons we omitted the activation discussion\n> in BIP118 and have trimmed the proposal to the bare minimum.\n>\n> Sorry for the longish rant, but I felt I needed to clarify this\n> situation a bit.\n>\n> Cheers,\n> Christian\n>\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220104/033290d3/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2022-01-09T11:38:15",
                "message_text_only": "On Mon, Jan 03, 2022 at 02:05:20AM +0000, Michael Folkson via bitcoin-dev wrote:\n> There have been a number of \u201csoft signals\u201d, many expressing enthusiasm for the speculated use cases of OP_CTV. Personally I share that enthusiasm like I do with the prospect of curing cancer. But these soft signals seem as if they are going to be used to attempt to justify an imminent contentious soft fork attempt. The devil is in the details both with regards to wording like \u201creasonable parameters\u201d and the utility and safety of a new opcode. Indeed if you share my concerns that there has not been sufficient scrutiny and research on the long implications of this proposal I encourage you to register a soft signal of \u201cNo\u201d on the site like I have. You can always change it to \u201cYes\u201d if and when you support an imminent soft fork activation attempt containing exclusively OP_CTV. Enabling covenants on Bitcoin is a big step change with barely any existing research on the topic and attempting to rush it through by the back door so soon after Taproot activation should be resisted. To look at the ~200 lines of code for the opcode exclusively (of course this should be done too) in a vacuum without considering the broader implications is also incredibly shortsighted. The only thing stopping a descent into Ethereum style seat of our pants consensus changes is community vigilance. If we ever lose that we lose the foundation of this industry.\n\nI have to second your objections.\n\nI spent a bit of time over the past week looking at the current state of\nOP_CTV/BIP-0119, and I too think it's a premature idea with an insufficient BIP\nand reference implementation, that current lacks compelling use-cases clearly\nbeneficial to all users.\n\nRemember that Bitcoin is a nearly $1 trillion network with tens of millions of\nusers that has gotten to that point with careful, conservative engineering.\nEvery change to the protocol poses risks to those users. Previous feature\nupgrades to the Bitcoin protocol have always been done with the intent of\nimproving the protocol for everyone: CSV/segwit benefit all users via\nLightning, because we can reasonably all users to directly take advantage of\nthose features. We expect _everyone_ to benefit from Taproot via improved\nprivacy. I don't think CTV in its current form makes that case sufficiently,\nand the technical details are lacking.\n\n\n\nAs for some more detailed thoughts, for clarify, I'm referring to:\n\nhttps://github.com/bitcoin/bips/blob/3693cdfd192dacdac89cd742f68cd1bb96bf7f7e/bip-0119.mediawiki\nhttps://github.com/JeremyRubin/bitcoin/tree/8f313d292e426a74d9ce28e5130bbf0cd48f867e\n\nBy no means is this a complete list of issues:\n\n# DoS Attacks\n\nNote how above I cited the git hashes to make it clear what exactly I'm\nreferring too: the fact that the reference implementation is listed as\nhttps://github.com/JeremyRubin/bitcoin/tree/checktemplateverify in the BIP is\nan immediate problem, as it's not clear what exactly is the specification.\n\nThis in turn matters quite a lot, because the BIP itself glosses over the quite\nserious DoS attack issues involved in adding more ways that opcodes can hash\ntxs. Strong resistance to DoS attacks is a _mandatory_ aspect of all Bitcoin\nscript proposals, so leaving those details to a mostly uncommented reference\nimplementation without a clear discussion of those trade-offs is insufficient.\n\n\n# Use Cases\n\nAs Folkson notes, these are barely fleshed out:\n\n## Congestion Controlled Transactions\n\nWhile this section appears somewhat fleshed out, with even a simulation, it\ncompletely ignores the numerous practical issues like the need for\ncommunication channels between wallets to inform them of the existence of these\nbatches. It also raises an important question: who needs this? On-chain\ntransactions are clearly not the future of Bitcoin and this use-case will\nlikely impact a small % of users.\n\n\n## Wallet Vaults\n\nThis use-case can be easily tested, even in production, right now with\nadditional \"oracle\" signers that simply verify the CTV rules have been\nfollowed.\n\n\n## Payment Channels\n\nThese use-cases sound promising. But they all need to be clearly fleshed out as\nactually taking advantage of them is quite complex.\n\n\n## CoinJoin\n\n> because participants agree on a single output which pays all participants,\n> which will be lower fee than before\n\nIt is not clear how the fee will be lower, given that taking advantage of CTV\nmeans there are more transactions, not less.\n\n\n# Covenant Design Trade-Offs and Risks\n\n> Covenants have historically been controversial given their potential for\n> fungibility risks -- coins could be minted which have a permanent restriction\n> on how they may or may not be spent or required to propagate metadata.\n\nIndeed, this is a significant risk with the potential to harm all Bitcoin\nusers.\n\n> In the CHECKTEMPLATEVERIFY approach, the covenants are severely restricted to\n> simple templates. The structure of CHECKTEMPLATEVERIFY template is such that\n> the outputs must be known exactly at the time of construction. Based on a\n> destructuring argument, it is only possible to create templates which expand\n> in a finite number of steps. Thus templated transactions are in theory as\n> safe as transactions which create all the inputs directly in this regard.\n\nThe \"finite\" number of steps could be millions of transactions - \"infinitely\nlong\" for any practical purpose.\n\n\n# Test Vectors\n\nCurrently the testing is poorly documented, without clear goals as to what edge\ncases are actually being tested:\nhttps://github.com/JeremyRubin/bitcoin/commit/e026bae28a774d91effc32862d0246286c114c24\n\nAlso, we really need test _vectors_ rather than a Python test: for consenus,\nyou want to write down explicitly the *data* in the form of serialized\ntransactions that is being fed into the consensus engine, to avoid mistakes in\ntest coverage due to broken test harnesses.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220109/73c067be/attachment.sig>"
            },
            {
                "author": "Jeremy",
                "date": "2022-01-11T03:42:50",
                "message_text_only": "Hi Peter,\n\nThank you for your review and feedback.\n\nApologies for the difficulties in reviewing. The branch linked from the BIP\nis not the latest, the branch in the PR is what should be considered\nhttps://github.com/bitcoin/bitcoin/pull/21702 for review and has more\nthorough well documented tests and test vectors. The version you reviewed\nshould still be compatible with the current branch as there have not been\nany spec changes, though.\n\nI'm not sure what best practice is w.r.t. linking to BIPs and\nimplementations given need to rebase and respond to feedback with changes.\nAppreciate any pointers on how to better solve this. For the time being, I\nwill suggest an edit to point it to the PR, although I recognize this is\nnot ideal. I understand your preference for a commit hash and can do one if\nit helps. For what it's worth, the taproot BIPs do not link to a reference\nimplementation of Taproot so I'm not sure what best practice is considered\nthese days.\n\nOne note that is unfortunate in your review is that there is a\ndiscrepancy between the BIP and the implementation (the original reference\nor the current PR either) in that caching and DoS is not addressed. This\nwas an explicit design goal of CTV and for it not to be mentioned in the\nBIP (and just the reference) is an oversight on my part to not aid\nreviewers more explicitly. Compounding this, I accepted a third-party PR to\nmake the BIP more clear as to what is required to implement it that does\nnot have caching (functional correctness), that exposes the issue if\nimplemented by the BIP directly and not by the reference implementation. I\nhave explained this in a review last year to pyskell\n<https://github.com/bitcoin/bitcoin/pull/21702#discussion_r616853690> on\nthe PR that caching is required for non-DoS. I will add a note to the BIP\nabout the importance of caching to avoid DoS as that should make third\nparty implementers aware of the issue.\n\nThat said, this is not a mis-considered part of CTV. The reference\nimplementation is specifically designed to not have quadratic hashing and\nCTV is designed to be friendly to caching to avoid denial of service. It's\njust a part of the BIP that can be more clear. I will make a PR to more\nclearly describe how that should happen.\n\n------\nuse cases\n------\n\nOne thing that's not clear to me is the amount of work a BIP needs to do\nwithin itself to fully describe all applications and use cases. I don't\nthink it's appropriate for most BIPs to do so, but in some cases it is a\ngood idea. However, for CTV the applications actually are relatively\nfleshed out, just outside the BIP. Further, the availability of generic\ntooling through Sapio and it's examples has demonstrated how one might\nbuild a variety of applications. See rubin.io/advent21 for numerous worked\nexamples.\n\n\n## Congestion Controlled Transactions\n\nGenerally, the existence of these transactions can be tracked using\nexisting wallets if the transaction is seen in the mempool, it will be\nmarked as \"mine\" and can even be marked as \"trusted\". See\nhttps://utxos.org/analysis/taxes/ which covers the legal obligations of\nsenders with respect to payees under congestion control. Generally, a\nlegally identifiable party such as an exchange sending a congestion control\npayment must retain and serve it to the user to prove that they made\npayment to the user. Users of said exchanges can either download a list of\ntheir transactions at the time of withdrawal or they can wait to see it\ne.g. in the mempool. This was also discussed at\nhttps://diyhpl.us/wiki/transcripts/ctv-bip-review-workshop/ where you can\nsee notes/videos of what was discussed if the notes are hard to parse.\n\nLightning specific wallets such as Muun and LND particularly plan to use\nCTV to batch-open a multitude of channels for users, using both congestion\ncontrol and non-interactive batching. Channels have to be opened on-chain\nand if channels are to be the future so will on-chain opening of them.\nThese wallets can be built out to track and receive these opening proofs.\n\n## Wallet Vaults\n\nThere exists at least 3 implementations of Vaults using CTV (one by me in\nC++, one by me in Sapio, another by Bryan Bishop in python), and there\nexist oracles as you mention for emulating it.\n\n## Payment Channels\n\nActually taking advantage of them is quite simple and has been discussed\nand reviewed with a number of independent lightning developers.\n\nYou can see here a rudimentary implementation and description of how it can\nwork https://rubin.io/bitcoin/2021/12/11/advent-14/.\n\nThis is composable with any `impl Revokable` channel update specification\nso generalizes to Lightning.\n\nOf course, making it production grade requires a lot of work, but the\nconcept is sound.\n\n\n## CoinJoin\n\n\nCTV trees may mean more transactions, not less, but if feerates are not\nmonotonic and CTV allows you to defer the utilization of chainspace.\n\nCTV CoinJoins also open the opportunity to cooperation through payment\npools (which can be opened via a coinjoin), which saves further space.\n\nThe opportunity to use embedded non-interactive channels (technically, this\nis a part of payment pools) also further decreases the urgency of getting a\nUTXO out.\n\nLastly, while it is a slight privacy leak, CTV also allows coin-joiners of\ndifferent fee-priority levels to batch together where previously they would\nnot have incentive to (see https://utxos.org/analysis/batching_sim/). This\ndoes use overall less chainspace total than if it is not incentive\ncompatible to batch together. While this is a slight privacy leak, it is\nnot that large since the batches would otherwise be unable to join together\n(worse) and priority is still unlinked from the inputs. Further, priority\nalready leaks through the observability of coins being spent anyways.\n\n\n# Covenant Design Trade-Offs and Risks\n\nThe important part is the the covenant -- regardless of its length -- must\nbe entirely known in advance. CTV is a fully enumerated non-recursive\nvalidation-only non-dynamic state covenant. This limits the types of issues\nthat can arise.\n\nUseful links:\nhttps://medium.com/block-digest-mempool/my-worries-about-too-generalized-covenants-5eff33affbb6\nhttps://rubin.io/bitcoin/2021/12/04/advent-7/\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Mon, Jan 10, 2022 at 10:31 AM Peter Todd via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Mon, Jan 03, 2022 at 02:05:20AM +0000, Michael Folkson via bitcoin-dev\n> wrote:\n> > There have been a number of \u201csoft signals\u201d, many expressing enthusiasm\n> for the speculated use cases of OP_CTV. Personally I share that enthusiasm\n> like I do with the prospect of curing cancer. But these soft signals seem\n> as if they are going to be used to attempt to justify an imminent\n> contentious soft fork attempt. The devil is in the details both with\n> regards to wording like \u201creasonable parameters\u201d and the utility and safety\n> of a new opcode. Indeed if you share my concerns that there has not been\n> sufficient scrutiny and research on the long implications of this proposal\n> I encourage you to register a soft signal of \u201cNo\u201d on the site like I have.\n> You can always change it to \u201cYes\u201d if and when you support an imminent soft\n> fork activation attempt containing exclusively OP_CTV. Enabling covenants\n> on Bitcoin is a big step change with barely any existing research on the\n> topic and attempting to rush it through by the back door so soon after\n> Taproot activation should be resisted. To look at the ~200 lines of code\n> for the opcode exclusively (of course this should be done too) in a vacuum\n> without considering the broader implications is also incredibly\n> shortsighted. The only thing stopping a descent into Ethereum style seat of\n> our pants consensus changes is community vigilance. If we ever lose that we\n> lose the foundation of this industry.\n>\n> I have to second your objections.\n>\n> I spent a bit of time over the past week looking at the current state of\n> OP_CTV/BIP-0119, and I too think it's a premature idea with an\n> insufficient BIP\n> and reference implementation, that current lacks compelling use-cases\n> clearly\n> beneficial to all users.\n>\n> Remember that Bitcoin is a nearly $1 trillion network with tens of\n> millions of\n> users that has gotten to that point with careful, conservative engineering.\n> Every change to the protocol poses risks to those users. Previous feature\n> upgrades to the Bitcoin protocol have always been done with the intent of\n> improving the protocol for everyone: CSV/segwit benefit all users via\n> Lightning, because we can reasonably all users to directly take advantage\n> of\n> those features. We expect _everyone_ to benefit from Taproot via improved\n> privacy. I don't think CTV in its current form makes that case\n> sufficiently,\n> and the technical details are lacking.\n>\n>\n>\n> As for some more detailed thoughts, for clarify, I'm referring to:\n>\n>\n> https://github.com/bitcoin/bips/blob/3693cdfd192dacdac89cd742f68cd1bb96bf7f7e/bip-0119.mediawiki\n>\n> https://github.com/JeremyRubin/bitcoin/tree/8f313d292e426a74d9ce28e5130bbf0cd48f867e\n>\n> By no means is this a complete list of issues:\n>\n> # DoS Attacks\n>\n> Note how above I cited the git hashes to make it clear what exactly I'm\n> referring too: the fact that the reference implementation is listed as\n> https://github.com/JeremyRubin/bitcoin/tree/checktemplateverify in the\n> BIP is\n> an immediate problem, as it's not clear what exactly is the specification.\n>\n> This in turn matters quite a lot, because the BIP itself glosses over the\n> quite\n> serious DoS attack issues involved in adding more ways that opcodes can\n> hash\n> txs. Strong resistance to DoS attacks is a _mandatory_ aspect of all\n> Bitcoin\n> script proposals, so leaving those details to a mostly uncommented\n> reference\n> implementation without a clear discussion of those trade-offs is\n> insufficient.\n>\n>\n> # Use Cases\n>\n> As Folkson notes, these are barely fleshed out:\n>\n> ## Congestion Controlled Transactions\n>\n> While this section appears somewhat fleshed out, with even a simulation, it\n> completely ignores the numerous practical issues like the need for\n> communication channels between wallets to inform them of the existence of\n> these\n> batches. It also raises an important question: who needs this? On-chain\n> transactions are clearly not the future of Bitcoin and this use-case will\n> likely impact a small % of users.\n>\n>\n> ## Wallet Vaults\n>\n> This use-case can be easily tested, even in production, right now with\n> additional \"oracle\" signers that simply verify the CTV rules have been\n> followed.\n>\n>\n> ## Payment Channels\n>\n> These use-cases sound promising. But they all need to be clearly fleshed\n> out as\n> actually taking advantage of them is quite complex.\n>\n>\n> ## CoinJoin\n>\n> > because participants agree on a single output which pays all\n> participants,\n> > which will be lower fee than before\n>\n> It is not clear how the fee will be lower, given that taking advantage of\n> CTV\n> means there are more transactions, not less.\n>\n>\n> # Covenant Design Trade-Offs and Risks\n>\n> > Covenants have historically been controversial given their potential for\n> > fungibility risks -- coins could be minted which have a permanent\n> restriction\n> > on how they may or may not be spent or required to propagate metadata.\n>\n> Indeed, this is a significant risk with the potential to harm all Bitcoin\n> users.\n>\n> > In the CHECKTEMPLATEVERIFY approach, the covenants are severely\n> restricted to\n> > simple templates. The structure of CHECKTEMPLATEVERIFY template is such\n> that\n> > the outputs must be known exactly at the time of construction. Based on a\n> > destructuring argument, it is only possible to create templates which\n> expand\n> > in a finite number of steps. Thus templated transactions are in theory as\n> > safe as transactions which create all the inputs directly in this regard.\n>\n> The \"finite\" number of steps could be millions of transactions -\n> \"infinitely\n> long\" for any practical purpose.\n>\n>\n> # Test Vectors\n>\n> Currently the testing is poorly documented, without clear goals as to what\n> edge\n> cases are actually being tested:\n>\n> https://github.com/JeremyRubin/bitcoin/commit/e026bae28a774d91effc32862d0246286c114c24\n>\n> Also, we really need test _vectors_ rather than a Python test: for\n> consenus,\n> you want to write down explicitly the *data* in the form of serialized\n> transactions that is being fed into the consensus engine, to avoid\n> mistakes in\n> test coverage due to broken test harnesses.\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220110/563cc209/attachment-0001.html>"
            },
            {
                "author": "Jeremy",
                "date": "2022-01-11T04:38:42",
                "message_text_only": "Please see the following bips PRs which are follow ups to the concrete\nactionables raised by Peter. Thanks for bringing these up, it certainly\nimproves the reviewability of the BIP.\n\nhttps://github.com/bitcoin/bips/pull/1271\nhttps://github.com/bitcoin/bips/pull/1272\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Mon, Jan 10, 2022 at 7:42 PM Jeremy <jlrubin at mit.edu> wrote:\n\n> Hi Peter,\n>\n> Thank you for your review and feedback.\n>\n> Apologies for the difficulties in reviewing. The branch linked from the\n> BIP is not the latest, the branch in the PR is what should be considered\n> https://github.com/bitcoin/bitcoin/pull/21702 for review and has more\n> thorough well documented tests and test vectors. The version you reviewed\n> should still be compatible with the current branch as there have not been\n> any spec changes, though.\n>\n> I'm not sure what best practice is w.r.t. linking to BIPs and\n> implementations given need to rebase and respond to feedback with changes.\n> Appreciate any pointers on how to better solve this. For the time being, I\n> will suggest an edit to point it to the PR, although I recognize this is\n> not ideal. I understand your preference for a commit hash and can do one\n> if it helps. For what it's worth, the taproot BIPs do not link to a\n> reference implementation of Taproot so I'm not sure what best practice is\n> considered these days.\n>\n> One note that is unfortunate in your review is that there is a\n> discrepancy between the BIP and the implementation (the original reference\n> or the current PR either) in that caching and DoS is not addressed. This\n> was an explicit design goal of CTV and for it not to be mentioned in the\n> BIP (and just the reference) is an oversight on my part to not aid\n> reviewers more explicitly. Compounding this, I accepted a third-party PR to\n> make the BIP more clear as to what is required to implement it that does\n> not have caching (functional correctness), that exposes the issue if\n> implemented by the BIP directly and not by the reference implementation. I\n> have explained this in a review last year to pyskell\n> <https://github.com/bitcoin/bitcoin/pull/21702#discussion_r616853690> on\n> the PR that caching is required for non-DoS. I will add a note to the BIP\n> about the importance of caching to avoid DoS as that should make third\n> party implementers aware of the issue.\n>\n> That said, this is not a mis-considered part of CTV. The reference\n> implementation is specifically designed to not have quadratic hashing and\n> CTV is designed to be friendly to caching to avoid denial of service. It's\n> just a part of the BIP that can be more clear. I will make a PR to more\n> clearly describe how that should happen.\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220110/409e4fae/attachment.html>"
            },
            {
                "author": "Prayank",
                "date": "2022-01-18T01:57:30",
                "message_text_only": "Hi Peter,\n\n> that current lacks compelling use-cases clearly beneficial to all users\n\nAll the use cases shared in below links look compelling enough to me and we can do anything that a programmer could think of using such restrictions:\n\n https://utxos.org/uses/\n\nhttps://rubin.io/archive/\n\n> I don't think CTV in its current form makes that case sufficiently, and the technical details are lacking.\nCTV cannot be compared to segwit or taproot. We are expecting different things in that case. CTV is trying to do add basic covenants in Bitcoin that would help all Bitcoin users. Most important thing missing in lot of conversations is the low demand for block space which affects everyone who understands importance of fees in long term. Right now fee rates only spike during peak bull markets which indicate the only use case is speculation and this can be improved if developers could do better things with Bitcoin smart contracts.\n\nThis would also ensure that we don't end up with something really contentious in future that changes supply.\n\n> DoS Attacks\n\nI think this was already answered by Jeremy and pull request to add related information is also merged:\n\nhttps://github.com/bitcoin/bips/pull/1272\n\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/47c8c867/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Stumbling into a contentious soft fork activation attempt",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy",
                "Michael Folkson",
                "Peter Todd",
                "Prayank",
                "Christian Decker"
            ],
            "messages_count": 12,
            "total_messages_chars_count": 96676
        }
    },
    {
        "title": "[bitcoin-dev] Why CTV, why now? Was RE: Stumbling into a contentious soft fork activation attempt",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2022-01-05T22:44:54",
                "message_text_only": "Hi Devs,\n\nThere's a lot of noise in the other thread and it's hard to parse out what\nmerits a response or not without getting into a messy quagmire, so I\nfigured a separate email with high level points was the best way to respond.\n\nCovenants are an important part of Bitcoin's future, not for \"adding use\ncases\" but for making the fundamental pillars underlying Bitcoin more\nrobust. For example, covenants play a central role in privacy, scalability,\nself custody, and decentralization (as I attempted to show in\nhttps://rubin.io/advent21).\n\nBitcoin researchers have known about covenants conceptually for a long\ntime, but the implications and problems with them led to them being viewed\nwith heavy skepticism and concern for many years.\n\nCTV was an output of my personal \"research program\" on how to make simple\ncovenant types without undue validation burdens. It is designed to be the\nsimplest and least risky covenant specification you can do that still\ndelivers sufficient flexibility and power to build many useful applications.\n\nCTV has been under development for multiple years and the spec has been\nessentially unmodified for 2 years (since the BIP was assigned a number).\n\nCTV's specification is highly design specific to being a pre-committed\ntransaction. It'd be difficult to engineer an alternative for what it does\nin a substantially different way.\n\nCTV composes with potential future upgrades, such as OP_AMOUNT, CAT, CSFS,\nTLUV. (See https://rubin.io/blog/2021/07/02/covenants/ and\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019423.html\n)\n\nCTV is non-rival (that means \"both can happen\") with any other upgrade\n(e.g. APO, TLUV).\n\nDuring the last 2 years, CTV has been reviewed by a wide range of folks and\nthere have not been (any?) conceptual or concrete NACKs for CTV to have or\nintroduce any risk or vulnerability to Bitcoin.\n\nThe main complaints about CTV are that we might come up with something\nbetter eventually, a better system of things, or that CTV is not flexible\nor general enough to make interesting applications, and it would be\nunfortunate to go through with using up the 32 byte argument version of an\nOP_NOP and the pains of any soft fork for something that we may eventually\nknow how to do better, replacing CTV.\n\nMore general approaches (e.g., based on CAT+CSFS) while more capability\npowerful, have limitations given large script sizes and difficulty in\nmanipulating transactions and their outputs (e.g., Taproot outs requires\nsome OP_TWEAK as well), and are harder to reason about given higher degrees\nof malleability.\n\nDuring the last 2 years, while some other interesting concepts have arisen\n(such as IIDs or TLUV), nothing in particular has fully overlapped CTV's\nfunctionality, the closest being APO and they would both be valuable tools\nto have independently.\n\nDuring the last 2 years, no other proposal has reached the level of\n\"technical maturity\" as CTV in terms of spec, implementation, testing,\ntooling (rust miniscript integration, Sapio, python-vaults), and the\nvariety of applications demonstrated possible. As the saying goes, one in\nthe hand is worth two in the bush.\n\nMany current users (not just end users, but businesses and protocol\ndevelopers as well) see CTV as delivering useful functionality for existing\napplications despite its limitations (and some of those limitations emerge\nas strengths). In particular, CTV is helpful for Lightning Network\ncompanies to deliver non-custodial channels to more users and generally\nimproving wallet vault custody software.\n\nApplications that are improved/enabled by CTV and not used today, like\nPayment Pools, deliver strong privacy benefits. Privacy is something that\nthe longer we exist in a worse state, the harder it becomes to improve.\nThis is unlike e.g. scalability or self custody where improvements can be\nmade independent of previous activity. On the other hand, information leaks\nfrom records of transactions are forever. There is more benefit from\nreducing privacy leaks sooner than later. In other words, privacy is a path\ndependent property not immediately upgradable to whatever current\ntechnology provides.\n\nSoftware Development is also path dependent. Many have remarked that there\nis not great alternative research on other covenant proposals, but not many\napplication builders or protocol researchers are investing deep time and\nexpertise on producing alternative paths to covenants either. Accepting an\nupgrade for limited covenants, like CTV, will give rise to many application\nbuilders including covenants in their stack (e.g. for batching or vaults or\nother applications) and will encourage more developers to contribute to\ngeneric tooling (Sapio can be improved!) and also to -- via market\nprocesses -- determine what other types of covenant would be safe and high\nvalue for those already using CTV.\n\nIn my advocacy, I published the essay \"Roadmap or Load o' Crap\" (\nhttps://rubin.io/bitcoin/2021/12/24/advent-27/), which presents a\nhypothetical path for 'completing' BIP-119 this year and analyzes some\npossible future work as well as the timeline viability of some alternatives\nbased on my best understandings. In this essay, I say very plainly:\n\n*More \u201cregular contributors\u201d would need to spend time reviewing the code\n> and BIP to assure themselves of correctness and safety. Nothing can move\n> forward without, no matter the count of casual contributors. Many regular\n> contributors don\u2019t want to \u2018get political\u2019 and look at forks. Fortunately,\n> while all consensus changes are complex, CTV is a very tiny and easy to\n> review change in comparison with SegWit or Taproot (more similar to\n> CheckLockTimeVerify \u2013 a couple hundred lines of consensus code, a couple\n> hundred lines of non consensus code, and a couple thousand lines of tests,\n> no cryptographic primitives). NOTE: This is a big if! Every contributor has\n> the right to review, and ACK or provide a reasoned NACK. Even if everyone\n> else is excited about something doesn\u2019t mean there isn\u2019t space for new\n> thought-through dissent. At the end of the article, I discuss some concrete\n> next steps to ensure more developer review occurs.*\n\n\nNowhere have I called for an imminent contentious soft fork attempt. All I\nam doing is agitating for other developers to perform reviews. I recognize\nthat developers have limited time and individual priorities that may lead\nthem to prefer to spend time on improving Bitcoin in other ways, and I\nwould not call the soft fork process to bear for an upgrade that I did not\nbelieve would yield large cross cutting benefits across a multitude of\ninterest areas. I've also plainly described that while \"*there could be a\nUASF for it, since there is strong user demand for CTV, ... I wouldn\u2019t\npersonally lead the charge on that**...*\". In no way am I endeavoring to\ncause the community to take sides.\n\nLastly, and finally, I would like to close this email with a quote from my\nTwitter from April '21\nhttps://twitter.com/JeremyRubin/status/1384689155465089025\n\nworth clarifying: I don't give a single fuck if BIP-119 CTV specifically is\n> activated or not.\n\n\n\nI want the functionality, in whatever form (eg noinput), to fix critical\n> gaps in #Bitcoin's armor:\n\n\n\nDecentralization.\n> Scaling.\n> Self Custody.\n> Privacy.\n\n\n\nlet's. fucking. go.\n\n\nThis isn't an ego driven journey about getting in a feature I worked hard\non.\n\nI couldn't care less.\n\nThis is about finding a pragmatic and low risk path to reinforcing\nBitcoin's fundamentals for the coming year.\n\nThis is about not resting on our laurels while we see properties critical\nto Bitcoin erode.\n\nAgree or disagree with CTV as the right next step, but we are all united in\nwanting Bitcoin to be the best that it can be.\n\nBest,\n\nJeremy\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220105/29613da2/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Why CTV, why now? Was RE: Stumbling into a contentious soft fork activation attempt",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 8005
        }
    },
    {
        "title": "[bitcoin-dev] BIP-119 Meeting Reminder and Prelim Agenda",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2022-01-10T07:59:18",
                "message_text_only": "Hi all,\n\nAs a reminder the first meeting for CTV will be this Tuesday at 12:00PM PT.\n\nBased on feedback, I have included a preliminary agenda and time allocation\nfor the meeting at the end of this email. The main part of the meeting will\nrun for 1.5 hours, and will be followed by a post meeting discussion of\nlength 30 minutes for discussing broader next steps and consensus seeking\nprocesses (this is separate to break up the technical review from the\nmetaphysics of consensus discussion and allow those who do not wish to\ndiscuss a polite exit).\n\nThe agenda does not thoroughly cover motivations or use cases for CTV, such\nas congestion control, vaults, payment pools, or non-interactive contract\nopenings. Those can be found in a multitude of sources (such as\nhttps://rubin.io/advent21, https://learn.sapio-lang.org, https://utxos.org,\nor https://github.com/kanzure/python-vaults/tree/master/vaults). Specific\napplications built on CTV will be best reviewed in follow up meetings as\ntechnical evaluation of how well CTV works for use cases requires a deep\nunderstanding of how the CTV primitive works.\n\nFor similar reasons, this agenda does not do a deep dive into alternatives\nto CTV. That discussion can be best had following a thorough review of CTV\nitself. Helpful links for depthening understanding on covenant properties,\nproposals, and varieties included below in a (loosely) recommended reading\norder:\nhttps://rubin.io/bitcoin/2021/12/04/advent-7/\nhttps://rubin.io/bitcoin/2021/12/05/advent-8/\nhttps://rubin.io/blog/2021/07/02/covenants/\nhttps://utxos.org/alternatives/\nhttps://arxiv.org/abs/2006.16714\nhttps://rubin.io/bitcoin/2021/12/24/advent-27/\nhttps://github.com/bitcoin/bips/blob/master/bip-0119.mediawiki#feature-redundancy\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019424.html\n\n\nIf you feel particular topics important to you are not represented in this\nagenda or if I can make any improvements otherwise, please drop me a note\nand I will endeavor to ensure they are either slotted into this meeting or\nincluded in a second meeting.\n\nThat the meeting is tightly scheduled is by design: I want to respect\neveryone's time and ensure that the meeting is highly productive. There is\nalways room for follow ups or further exploration at future meetings or as\nmailing list follow ups.\n\nLooking forward to discussing with you on tuesday,\n\nJeremy\n\n\n\n\n*#topic Overview of BIP & Q&A (40 Mins)*\n#subtopic what does CTV do? (5 minutes)\n\n#subtopic which fields are in the digest? (5 minutes)\n\n#subtopic the order / structure of fields in the digest? (5 minutes)\n\n#subtopic the half-spend problem/solution? (5 minutes)\n\n#subtopic using a NOP v.s. successX / legacy script types? (5 minutes)\n\n#subtopic using sha256 v.s. Ripemd160 (5 minutes)\n\n#subtopic general q&a (10 minutes)\n\n\n*#topic Overview of Implementation & Testing (30 Minutes)*\n#subtopic implementation walkthrough (15 minutes)\n\n#subsubtopic validation burdens & caching (5 minutes)\n\n#subtopic vectors: tx_valid.json + tx_invalid.json + transaction hashes\nchecking (2 minutes)\n\n#subtopic functional test walkthrough (8 minutes)\n\n*#topic Proposed Timeline Technical Feasibility (not advisibility) (10\nminutes)*\n\n\n*#topic Feedback on how to Structure Bounty Program (10 minutes)*\n#post-meeting\n\n\n*#topic open-ended feedback (is this meeting helpful, what could be better,\netc) (10 minutes)#topic What's required to get consensus / next steps? (20\nminutes)*\n#subtopic Discussion of \"soft signals\" utxos.org/signals (10 minutes)\n#subtopic Discussion of activation mechanisms (10 minutes)\n\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220109/35bb8366/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP-119 Meeting Reminder and Prelim Agenda",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3850
        }
    },
    {
        "title": "[bitcoin-dev] Bitcoin Legal Defense Fund",
        "thread_messages": [
            {
                "author": "jack",
                "date": "2022-01-12T00:13:45",
                "message_text_only": "To Bitcoin Developers:\n\nThe Bitcoin community is currently the subject of multi-front litigation. Litigation and continued threats are having their intended effect; individual defendants have chosen to capitulate in the absence of legal support. Open-source developers, who are often independent, are especially susceptible to legal pressure. In response, we propose a coordinated and formalized response to help defend developers. The Bitcoin Legal Defense Fund is a nonprofit entity that aims to minimize legal headaches that discourage software developers from actively developing Bitcoin and related projects such as the Lightning Network, Bitcoin privacy protocols, and the like.\n\nThe main purpose of this Fund is to defend developers from lawsuits regarding their activities in the Bitcoin ecosystem, including finding and retaining defense counsel, developing litigation strategy, and paying legal bills. This is a free and voluntary option for developers to take advantage of if they so wish. The Fund will start with a corps of volunteer and part-time lawyers. The board of the Fund will be responsible for determining which lawsuits and defendants it will help defend.\n\nThe Fund\u2019s first activities will be to take over coordination of the existing defense of the Tulip Trading lawsuit against certain developers alleging breach of fiduciary duty and provide the source of funding for outside counsel. At this time, the Fund is not seeking to raise additional money for its operations but will do so at the direction of the board if needed for further legal action or to pay for staff.\n\nIf you have questions or concerns, you can email info at bitcoindefensefund.org. Will share more information in the near future.\n\nSincerely,\nJack Dorsey, Alex Morcos, and Martin White\n(Bitcoin Legal Defense Fund Board)"
            },
            {
                "author": "Ren\u00e9 Pickhardt",
                "date": "2022-01-12T00:47:41",
                "message_text_only": "jack via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> schrieb am\nMi., 12. Jan. 2022, 01:35:\n\n> To Bitcoin Developers:\n>\n> Open-source developers, who are often independent, are especially\n> susceptible to legal pressure.\n\n\nWill the fund eventually also help to educate developers about the risks\nthey are facing and which measures can be taken to reduce such risks so\nthat legal pressure might not even arise in the first place?\n\nThe main purpose of this Fund is to defend developers from lawsuits\n> regarding their activities in the Bitcoin ecosystem, including finding and\n> retaining defense counsel, developing litigation strategy, and paying legal\n> bills. This is a free and voluntary option for developers to take advantage\n> of if they so wish.\n\n\nThank you!\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220112/f8dc7cf8/attachment.html>"
            },
            {
                "author": "Christopher Allen",
                "date": "2022-01-12T01:42:57",
                "message_text_only": "On Tue, Jan 11, 2022 at 5:02 PM Ren\u00e9 Pickhardt via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Will the fund eventually also help to educate developers about the risks\n> they are facing and which measures can be taken to reduce such risks so\n> that legal pressure might not even arise in the first place?\n>\n\nWe (Blockchain Commons) have also started a project to document\nbest-practices of pseudonymous development. A work-in-progress but an\nimportant part of our 2022 roadmap. Led by Namcios & myself, but we welcome\nissues, review & contributions!\n\nhttps://github.com/BlockchainCommons/Pseudonymity-Guide\n\n\u2014 Christopher Allen\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220111/6b0006d4/attachment.html>"
            },
            {
                "author": "Alex Morcos",
                "date": "2022-01-13T19:25:48",
                "message_text_only": "To belatedly answer Rene's question:\n\nYes, we hope so. To start, the Fund will focus on the defense of the\npending litigation and new litigation that may arise. However, we intend to\nbuild up the capacity to provide competent third-party advice to developers\non strategies to reduce their liability.\n\nOn Tue, Jan 11, 2022 at 7:47 PM Ren\u00e9 Pickhardt <r.pickhardt at googlemail.com>\nwrote:\n\n>\n>\n> jack via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> schrieb am\n> Mi., 12. Jan. 2022, 01:35:\n>\n>> To Bitcoin Developers:\n>>\n>> Open-source developers, who are often independent, are especially\n>> susceptible to legal pressure.\n>\n>\n> Will the fund eventually also help to educate developers about the risks\n> they are facing and which measures can be taken to reduce such risks so\n> that legal pressure might not even arise in the first place?\n>\n> The main purpose of this Fund is to defend developers from lawsuits\n>> regarding their activities in the Bitcoin ecosystem, including finding and\n>> retaining defense counsel, developing litigation strategy, and paying legal\n>> bills. This is a free and voluntary option for developers to take advantage\n>> of if they so wish.\n>\n>\n> Thank you!\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220113/2ed1b619/attachment-0001.html>"
            },
            {
                "author": "SatoshiSingh",
                "date": "2022-01-12T09:59:07",
                "message_text_only": "> The main purpose of this Fund is to defend developers from lawsuits regarding their activities in the Bitcoin ecosystem, including finding and retaining defense counsel, developing litigation strategy, and paying legal bills.\n\nHere in India we have the Internet Freedom Foundation that does something similar but for digital freedom and privacy. They've been supportive to bitcoin and it would be cool if we can include them in this.\n\nhttps://internetfreedom.in/\n\nSent with [ProtonMail](https://protonmail.com/) Secure Email.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220112/067e06e6/attachment.html>"
            },
            {
                "author": "Prayank",
                "date": "2022-01-13T10:13:11",
                "message_text_only": "Hi Jack,\n\n\n>\u00a0The main purpose of this Fund is to defend developers from lawsuits regarding their activities in the Bitcoin ecosystem, including finding and retaining defense counsel, developing litigation strategy, and paying legal bills. This is a free and voluntary option for developers to take advantage of if they so wish. The Fund will start with a corps of volunteer and part-time lawyers. The board of the Fund will be responsible for determining which lawsuits and defendants it will help defend.\n\nThanks for helping the developers in legal issues. Appreciate your efforts and I understand your intentions are to help Bitcoin in every possible way.\n\n\nPositives that I see in this initiative:\n\n1.Developers don't need to worry about rich scammers and can focus on development.\n\n2.Financial help for developers as legal issues can end up in wasting lot of time and money.\n\n3.People who have misused courts to affect bitcoin developers will get better response that they deserve.\n\n\nI had few suggestions and feel free to ignore them if they do not make sense:\n\n1.Name of this fund could be anything and 'The Bitcoin Legal Defense Fund' can be confusing or misleading for newbies. There is nothing official in Bitcoin however people believe things written in news articles and some of them might consider it as an official bitcoin legal fund.\n\n2.It would be better if people involved in such important funds do not comment/influence soft fork related discussions. Example: Alex Morcos had some opinions about activation mechanism during Taproot soft fork IIRC.\n\n\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220113/17a38cb8/attachment.html>"
            },
            {
                "author": "jack",
                "date": "2022-01-13T18:20:40",
                "message_text_only": "Hi Prayank,\n\n> On 13 Jan 2022, at 10:13, Prayank <prayank at tutanota.de> wrote:\n> I had few suggestions and feel free to ignore them if they do not make sense:\n> \n> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense Fund' can be confusing or misleading for newbies. There is nothing official in Bitcoin however people believe things written in news articles and some of them might consider it as an official bitcoin legal fund.\n\nExcellent point. Will come up with a better name.\n\n> 2.It would be better if people involved in such important funds do not comment/influence soft fork related discussions. Example: Alex Morcos had some opinions about activation mechanism during Taproot soft fork IIRC.\n\nYes. Will think through this and board operating principles we can share publicly, which would probably include criteria for how cases are chosen, to protect against this board and fund influencing direction.\n\nOpen to ideas and suggestions on all.\n\njack"
            },
            {
                "author": "Aymeric Vitte",
                "date": "2022-01-14T13:21:42",
                "message_text_only": "(P2P?) Electronic Cash (Defense?) Fund or Electronic Cash Foundation ?\nMore neutral, potentially covering others than Bitcoin, mimicking a bit\nEFF (even if as stated US is not the only target), referring to\nSatoshi's paper where everything started\n\nMaybe I am not up to date but it would be good to know what are the\ncurrent procedures with the Tulip thing\n\nAymeric\n\n\nLe 13/01/2022 \u00e0 19:20, jack via bitcoin-dev a \u00e9crit :\n> Hi Prayank,\n>\n>> On 13 Jan 2022, at 10:13, Prayank <prayank at tutanota.de> wrote:\n>> I had few suggestions and feel free to ignore them if they do not make sense:\n>>\n>> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense Fund' can be confusing or misleading for newbies. There is nothing official in Bitcoin however people believe things written in news articles and some of them might consider it as an official bitcoin legal fund.\n> Excellent point. Will come up with a better name.\n>\n>> 2.It would be better if people involved in such important funds do not comment/influence soft fork related discussions. Example: Alex Morcos had some opinions about activation mechanism during Taproot soft fork IIRC.\n> Yes. Will think through this and board operating principles we can share publicly, which would probably include criteria for how cases are chosen, to protect against this board and fund influencing direction.\n>\n> Open to ideas and suggestions on all.\n>\n> jack\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "qmccormick13",
                "date": "2022-01-14T18:18:40",
                "message_text_only": "I very much hope the fund will not finance lawsuits irrelevant to bitcoin.\n\nOn Fri, Jan 14, 2022 at 5:23 PM Aymeric Vitte via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> (P2P?) Electronic Cash (Defense?) Fund or Electronic Cash Foundation ?\n> More neutral, potentially covering others than Bitcoin, mimicking a bit\n> EFF (even if as stated US is not the only target), referring to\n> Satoshi's paper where everything started\n>\n> Maybe I am not up to date but it would be good to know what are the\n> current procedures with the Tulip thing\n>\n> Aymeric\n>\n>\n> Le 13/01/2022 \u00e0 19:20, jack via bitcoin-dev a \u00e9crit :\n> > Hi Prayank,\n> >\n> >> On 13 Jan 2022, at 10:13, Prayank <prayank at tutanota.de> wrote:\n> >> I had few suggestions and feel free to ignore them if they do not make\n> sense:\n> >>\n> >> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense\n> Fund' can be confusing or misleading for newbies. There is nothing official\n> in Bitcoin however people believe things written in news articles and some\n> of them might consider it as an official bitcoin legal fund.\n> > Excellent point. Will come up with a better name.\n> >\n> >> 2.It would be better if people involved in such important funds do not\n> comment/influence soft fork related discussions. Example: Alex Morcos had\n> some opinions about activation mechanism during Taproot soft fork IIRC.\n> > Yes. Will think through this and board operating principles we can share\n> publicly, which would probably include criteria for how cases are chosen,\n> to protect against this board and fund influencing direction.\n> >\n> > Open to ideas and suggestions on all.\n> >\n> > jack\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220114/a0a62882/attachment.html>"
            },
            {
                "author": "Jeremy",
                "date": "2022-01-14T18:34:45",
                "message_text_only": "If I understand the intent of your message correctly, that's unfortunately\nnot how the law works.\n\nIf there is a case that is precedent setting, whether it directly involves\nbitcoin or not, a bitcoin focused legal fund might want to either offer\nrepresentation or file an amicus brief to guide the court to making a\ndecision beneficial to Bitcoin Developers.\n\nMore than likely, some of these cases would involve developers of\nalternative projects (as they might be \"ahead of the curve\" on legal\nproblems) and heading off a strong precedent for other communities would be\nprotective for Bitcoiners in general. As an example, were the developers\nbuilding Rollups on Ethereum to face a legal threat, since we might one day\nwant similar software for Bitcoin, ensuring a good outcome for them helps\nBitcoin.\n\nThat said, all organizations must at some point have a defined scope, and\nit seems the BLDF is primarily focused for now on things impacting the\ndevelopers of Bitcoin or software for bitcoin specifically. I \"trust\" the\nlegal team behind BLDF will form a coherent strategy around what is\nrelevant to Bitcoin defense, even if the particulars of a case are not\ndirectly about Bitcoin.\n\ncheers,\n\nJeremy\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Fri, Jan 14, 2022 at 10:25 AM qmccormick13 via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I very much hope the fund will not finance lawsuits irrelevant to bitcoin.\n>\n> On Fri, Jan 14, 2022 at 5:23 PM Aymeric Vitte via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> (P2P?) Electronic Cash (Defense?) Fund or Electronic Cash Foundation ?\n>> More neutral, potentially covering others than Bitcoin, mimicking a bit\n>> EFF (even if as stated US is not the only target), referring to\n>> Satoshi's paper where everything started\n>>\n>> Maybe I am not up to date but it would be good to know what are the\n>> current procedures with the Tulip thing\n>>\n>> Aymeric\n>>\n>>\n>> Le 13/01/2022 \u00e0 19:20, jack via bitcoin-dev a \u00e9crit :\n>> > Hi Prayank,\n>> >\n>> >> On 13 Jan 2022, at 10:13, Prayank <prayank at tutanota.de> wrote:\n>> >> I had few suggestions and feel free to ignore them if they do not make\n>> sense:\n>> >>\n>> >> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense\n>> Fund' can be confusing or misleading for newbies. There is nothing official\n>> in Bitcoin however people believe things written in news articles and some\n>> of them might consider it as an official bitcoin legal fund.\n>> > Excellent point. Will come up with a better name.\n>> >\n>> >> 2.It would be better if people involved in such important funds do not\n>> comment/influence soft fork related discussions. Example: Alex Morcos had\n>> some opinions about activation mechanism during Taproot soft fork IIRC.\n>> > Yes. Will think through this and board operating principles we can\n>> share publicly, which would probably include criteria for how cases are\n>> chosen, to protect against this board and fund influencing direction.\n>> >\n>> > Open to ideas and suggestions on all.\n>> >\n>> > jack\n>> > _______________________________________________\n>> > bitcoin-dev mailing list\n>> > bitcoin-dev at lists.linuxfoundation.org\n>> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220114/bbca9866/attachment-0001.html>"
            },
            {
                "author": "Zac Greenwood",
                "date": "2022-01-21T14:36:10",
                "message_text_only": "The name of the fund should ideally unambiguously clarify its scope, i.e.,\nBitcoin & development. So maybe \u201cBitcoin Developers Community LDF\u201d. Or\nperhaps \u201cBitcoin Technical Community LDF\u201d which nicely abbreviates to\nBTCLDF.\n\nZac\n\n\nOn Thu, 13 Jan 2022 at 19:49, jack via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Prayank,\n>\n> > On 13 Jan 2022, at 10:13, Prayank <prayank at tutanota.de> wrote:\n> > I had few suggestions and feel free to ignore them if they do not make\n> sense:\n> >\n> > 1.Name of this fund could be anything and 'The Bitcoin Legal Defense\n> Fund' can be confusing or misleading for newbies. There is nothing official\n> in Bitcoin however people believe things written in news articles and some\n> of them might consider it as an official bitcoin legal fund.\n>\n> Excellent point. Will come up with a better name.\n>\n> Open to ideas and suggestions on all.\n>\n> jack\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220121/c16855a6/attachment.html>"
            },
            {
                "author": "Steve Lee",
                "date": "2022-01-13T18:28:18",
                "message_text_only": "I think the word \"The\" is important. The title of the email and the name of\nthe fund is Bitcoin Legal Defense Fund. It is \"a\" legal defense fund; not\nTHE Bitcoin Legal Defense Fund. There is room for other funds and\nstrategies and anyone is welcome to create alternatives.\n\nI also don't see why Alex or anyone should be denied the opportunity to\ncomment on future soft forks or anything about bitcoin. Alex should have no\nmore or less right to participate and his comments should be judged on\ntheir merit, just like yours and mine.\n\nOn Thu, Jan 13, 2022 at 9:37 AM Prayank via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Jack,\n>\n>\n> > The main purpose of this Fund is to defend developers from lawsuits\n> regarding their activities in the Bitcoin ecosystem, including finding and\n> retaining defense counsel, developing litigation strategy, and paying legal\n> bills. This is a free and voluntary option for developers to take advantage\n> of if they so wish. The Fund will start with a corps of volunteer and\n> part-time lawyers. The board of the Fund will be responsible for\n> determining which lawsuits and defendants it will help defend.\n>\n> Thanks for helping the developers in legal issues. Appreciate your efforts\n> and I understand your intentions are to help Bitcoin in every possible way.\n>\n>\n> Positives that I see in this initiative:\n>\n> 1.Developers don't need to worry about rich scammers and can focus on\n> development.\n>\n> 2.Financial help for developers as legal issues can end up in wasting lot\n> of time and money.\n>\n> 3.People who have misused courts to affect bitcoin developers will get\n> better response that they deserve.\n>\n>\n> I had few suggestions and feel free to ignore them if they do not make\n> sense:\n>\n> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense Fund'\n> can be confusing or misleading for newbies. There is nothing official in\n> Bitcoin however people believe things written in news articles and some of\n> them might consider it as an official bitcoin legal fund.\n>\n> 2.It would be better if people involved in such important funds do not\n> comment/influence soft fork related discussions. Example: Alex Morcos had\n> some opinions about activation mechanism during Taproot soft fork IIRC.\n>\n>\n>\n> --\n> Prayank\n>\n> A3B1 E430 2298 178F\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220113/bd8698a1/attachment.html>"
            },
            {
                "author": "Alex Schoof",
                "date": "2022-01-13T18:54:35",
                "message_text_only": "> I also don't see why Alex or anyone should be denied the opportunity to\ncomment on future soft forks or anything about bitcoin. Alex should have no\nmore or less right to participate and his comments should be judged on\ntheir merit, just like yours and mine.\n\nI think the concern is something like: \"I disagree with a board member of\nthe defense fund about [insert contentious issue]. If I disagree with them\npublicly (especially if there are clear economic implications in that\ndisagreement), am I putting myself at risk in the future where I won't be\nable to get support from the fund because I spoke out against a board\nmember?\" That kind of concern can be mitigated through policy and\ngovernance, but is the kind of thing you want to tackle before it becomes\nan issue.\n\nCheers,\n\n(a different) Alex\n\nOn Thu, Jan 13, 2022 at 1:49 PM Steve Lee via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I think the word \"The\" is important. The title of the email and the name\n> of the fund is Bitcoin Legal Defense Fund. It is \"a\" legal defense fund;\n> not THE Bitcoin Legal Defense Fund. There is room for other funds and\n> strategies and anyone is welcome to create alternatives.\n>\n> I also don't see why Alex or anyone should be denied the opportunity to\n> comment on future soft forks or anything about bitcoin. Alex should have no\n> more or less right to participate and his comments should be judged on\n> their merit, just like yours and mine.\n>\n> On Thu, Jan 13, 2022 at 9:37 AM Prayank via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi Jack,\n>>\n>>\n>> > The main purpose of this Fund is to defend developers from lawsuits\n>> regarding their activities in the Bitcoin ecosystem, including finding and\n>> retaining defense counsel, developing litigation strategy, and paying legal\n>> bills. This is a free and voluntary option for developers to take advantage\n>> of if they so wish. The Fund will start with a corps of volunteer and\n>> part-time lawyers. The board of the Fund will be responsible for\n>> determining which lawsuits and defendants it will help defend.\n>>\n>> Thanks for helping the developers in legal issues. Appreciate your\n>> efforts and I understand your intentions are to help Bitcoin in every\n>> possible way.\n>>\n>>\n>> Positives that I see in this initiative:\n>>\n>> 1.Developers don't need to worry about rich scammers and can focus on\n>> development.\n>>\n>> 2.Financial help for developers as legal issues can end up in wasting lot\n>> of time and money.\n>>\n>> 3.People who have misused courts to affect bitcoin developers will get\n>> better response that they deserve.\n>>\n>>\n>> I had few suggestions and feel free to ignore them if they do not make\n>> sense:\n>>\n>> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense\n>> Fund' can be confusing or misleading for newbies. There is nothing official\n>> in Bitcoin however people believe things written in news articles and some\n>> of them might consider it as an official bitcoin legal fund.\n>>\n>> 2.It would be better if people involved in such important funds do not\n>> comment/influence soft fork related discussions. Example: Alex Morcos had\n>> some opinions about activation mechanism during Taproot soft fork IIRC.\n>>\n>>\n>>\n>> --\n>> Prayank\n>>\n>> A3B1 E430 2298 178F\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n-- \n\n\nAlex Schoof\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220113/dbfb6d62/attachment.html>"
            },
            {
                "author": "Steve Lee",
                "date": "2022-01-13T19:28:32",
                "message_text_only": "That's a good point. Agree!\n\nOn Thu, Jan 13, 2022 at 10:54 AM Alex Schoof <alex.schoof at gmail.com> wrote:\n\n> > I also don't see why Alex or anyone should be denied the opportunity to\n> comment on future soft forks or anything about bitcoin. Alex should have no\n> more or less right to participate and his comments should be judged on\n> their merit, just like yours and mine.\n>\n> I think the concern is something like: \"I disagree with a board member of\n> the defense fund about [insert contentious issue]. If I disagree with them\n> publicly (especially if there are clear economic implications in that\n> disagreement), am I putting myself at risk in the future where I won't be\n> able to get support from the fund because I spoke out against a board\n> member?\" That kind of concern can be mitigated through policy and\n> governance, but is the kind of thing you want to tackle before it becomes\n> an issue.\n>\n> Cheers,\n>\n> (a different) Alex\n>\n> On Thu, Jan 13, 2022 at 1:49 PM Steve Lee via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> I think the word \"The\" is important. The title of the email and the name\n>> of the fund is Bitcoin Legal Defense Fund. It is \"a\" legal defense fund;\n>> not THE Bitcoin Legal Defense Fund. There is room for other funds and\n>> strategies and anyone is welcome to create alternatives.\n>>\n>> I also don't see why Alex or anyone should be denied the opportunity to\n>> comment on future soft forks or anything about bitcoin. Alex should have no\n>> more or less right to participate and his comments should be judged on\n>> their merit, just like yours and mine.\n>>\n>> On Thu, Jan 13, 2022 at 9:37 AM Prayank via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Hi Jack,\n>>>\n>>>\n>>> > The main purpose of this Fund is to defend developers from lawsuits\n>>> regarding their activities in the Bitcoin ecosystem, including finding and\n>>> retaining defense counsel, developing litigation strategy, and paying legal\n>>> bills. This is a free and voluntary option for developers to take advantage\n>>> of if they so wish. The Fund will start with a corps of volunteer and\n>>> part-time lawyers. The board of the Fund will be responsible for\n>>> determining which lawsuits and defendants it will help defend.\n>>>\n>>> Thanks for helping the developers in legal issues. Appreciate your\n>>> efforts and I understand your intentions are to help Bitcoin in every\n>>> possible way.\n>>>\n>>>\n>>> Positives that I see in this initiative:\n>>>\n>>> 1.Developers don't need to worry about rich scammers and can focus on\n>>> development.\n>>>\n>>> 2.Financial help for developers as legal issues can end up in wasting\n>>> lot of time and money.\n>>>\n>>> 3.People who have misused courts to affect bitcoin developers will get\n>>> better response that they deserve.\n>>>\n>>>\n>>> I had few suggestions and feel free to ignore them if they do not make\n>>> sense:\n>>>\n>>> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense\n>>> Fund' can be confusing or misleading for newbies. There is nothing official\n>>> in Bitcoin however people believe things written in news articles and some\n>>> of them might consider it as an official bitcoin legal fund.\n>>>\n>>> 2.It would be better if people involved in such important funds do not\n>>> comment/influence soft fork related discussions. Example: Alex Morcos had\n>>> some opinions about activation mechanism during Taproot soft fork IIRC.\n>>>\n>>>\n>>>\n>>> --\n>>> Prayank\n>>>\n>>> A3B1 E430 2298 178F\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n>\n> --\n>\n>\n> Alex Schoof\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220113/269236cd/attachment-0001.html>"
            },
            {
                "author": "Jeremy",
                "date": "2022-01-13T19:05:42",
                "message_text_only": "A further point -- were it to be a norm if a contributor to something like\nthis be denied their full capacity for \"free speech\" by social convention,\nit would either encourage anonymous funding (less accountable) or would\ndisincentivize creating such initiatives in the future.\n\nBoth of those outcomes would be potentially bad, so I don't see limiting\nspeech on an unrelated topic as a valid action.\n\nHowever, I think the inverse could have merit -- perhaps funders can\nsomehow commit to 'abstracting' themselves from involvement in cases / the\nprocess of accepting prospective clients. As neither Alex nor Jack are\nlawyers (afaict?), this should already be true to an extent as the legal\ncounsel would be bound to attorney client privilege.\n\nOf course we live in a free country and however Jack and Alex determine\nthey should spend their own money is their god-given right, as much as it\nis unfortunately the right of anyone to sue a developer for some alleged\ninfringement. I'm personally glad that Jack and Alex are using their money\nto help developers and not harass them -- many thanks for that!\n\nOne question I have is how you might describe the differences between what\nBLDF can accomplish and what e.g. EFF can accomplish. Having been\nrepresented by the EFF on more than one occasion, they are fantastic. Do\nyou feel that the Bitcoin-specific focus of BLDF outweighs the more general\n(but deeper experience/track record) of an organization like the EFF (or\nothers, like Berkman Cyberlaw Clinic, etc)? My main opinion is \"the more\nthe merrier\", so don't consider it a critique, more a question so that you\nhave the opportunity to highlight the unique strengths of this approach.\n\nBest,\n\nJeremy\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Thu, Jan 13, 2022 at 10:50 AM Steve Lee via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I think the word \"The\" is important. The title of the email and the name\n> of the fund is Bitcoin Legal Defense Fund. It is \"a\" legal defense fund;\n> not THE Bitcoin Legal Defense Fund. There is room for other funds and\n> strategies and anyone is welcome to create alternatives.\n>\n> I also don't see why Alex or anyone should be denied the opportunity to\n> comment on future soft forks or anything about bitcoin. Alex should have no\n> more or less right to participate and his comments should be judged on\n> their merit, just like yours and mine.\n>\n> On Thu, Jan 13, 2022 at 9:37 AM Prayank via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi Jack,\n>>\n>>\n>> > The main purpose of this Fund is to defend developers from lawsuits\n>> regarding their activities in the Bitcoin ecosystem, including finding and\n>> retaining defense counsel, developing litigation strategy, and paying legal\n>> bills. This is a free and voluntary option for developers to take advantage\n>> of if they so wish. The Fund will start with a corps of volunteer and\n>> part-time lawyers. The board of the Fund will be responsible for\n>> determining which lawsuits and defendants it will help defend.\n>>\n>> Thanks for helping the developers in legal issues. Appreciate your\n>> efforts and I understand your intentions are to help Bitcoin in every\n>> possible way.\n>>\n>>\n>> Positives that I see in this initiative:\n>>\n>> 1.Developers don't need to worry about rich scammers and can focus on\n>> development.\n>>\n>> 2.Financial help for developers as legal issues can end up in wasting lot\n>> of time and money.\n>>\n>> 3.People who have misused courts to affect bitcoin developers will get\n>> better response that they deserve.\n>>\n>>\n>> I had few suggestions and feel free to ignore them if they do not make\n>> sense:\n>>\n>> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense\n>> Fund' can be confusing or misleading for newbies. There is nothing official\n>> in Bitcoin however people believe things written in news articles and some\n>> of them might consider it as an official bitcoin legal fund.\n>>\n>> 2.It would be better if people involved in such important funds do not\n>> comment/influence soft fork related discussions. Example: Alex Morcos had\n>> some opinions about activation mechanism during Taproot soft fork IIRC.\n>>\n>>\n>>\n>> --\n>> Prayank\n>>\n>> A3B1 E430 2298 178F\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220113/aafa20a6/attachment-0001.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-01-13T20:50:08",
                "message_text_only": "> One question I have is how you might describe the differences between\nwhat BLDF can accomplish and what e.g. EFF can accomplish. Having been\nrepresented by the EFF on more than one occasion, they are fantastic. Do\nyou feel that the Bitcoin-specific focus of BLDF outweighs the more general\n(but deeper experience/track record) of an organization like the EFF (or\nothers, like Berkman Cyberlaw Clinic, etc)? My main opinion is \"the more\nthe merrier\", so don't consider it a critique, more a question so that you\nhave the opportunity to highlight the unique strengths of this approach.\n\nI think one opportunity could be building legal assistance in a diversity\nof jurisdictions, beyond the US one.\n\nI join the kudos about the EFF, though you won't find the institutional\nequivalent in term of subjects expertise/readiness-to-assist in most of the\nother countries.\nEspecially considering the growing number of developers located outside\nUS/Europe and a lot of great ecosystem initiatives nurturing that trend.\n\nCheers,\nAntoine\n\nLe jeu. 13 janv. 2022 \u00e0 14:06, Jeremy via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n> A further point -- were it to be a norm if a contributor to something like\n> this be denied their full capacity for \"free speech\" by social convention,\n> it would either encourage anonymous funding (less accountable) or would\n> disincentivize creating such initiatives in the future.\n>\n> Both of those outcomes would be potentially bad, so I don't see limiting\n> speech on an unrelated topic as a valid action.\n>\n> However, I think the inverse could have merit -- perhaps funders can\n> somehow commit to 'abstracting' themselves from involvement in cases / the\n> process of accepting prospective clients. As neither Alex nor Jack are\n> lawyers (afaict?), this should already be true to an extent as the legal\n> counsel would be bound to attorney client privilege.\n>\n> Of course we live in a free country and however Jack and Alex determine\n> they should spend their own money is their god-given right, as much as it\n> is unfortunately the right of anyone to sue a developer for some alleged\n> infringement. I'm personally glad that Jack and Alex are using their money\n> to help developers and not harass them -- many thanks for that!\n>\n> One question I have is how you might describe the differences between what\n> BLDF can accomplish and what e.g. EFF can accomplish. Having been\n> represented by the EFF on more than one occasion, they are fantastic. Do\n> you feel that the Bitcoin-specific focus of BLDF outweighs the more general\n> (but deeper experience/track record) of an organization like the EFF (or\n> others, like Berkman Cyberlaw Clinic, etc)? My main opinion is \"the more\n> the merrier\", so don't consider it a critique, more a question so that you\n> have the opportunity to highlight the unique strengths of this approach.\n>\n> Best,\n>\n> Jeremy\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n>\n>\n> On Thu, Jan 13, 2022 at 10:50 AM Steve Lee via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> I think the word \"The\" is important. The title of the email and the name\n>> of the fund is Bitcoin Legal Defense Fund. It is \"a\" legal defense fund;\n>> not THE Bitcoin Legal Defense Fund. There is room for other funds and\n>> strategies and anyone is welcome to create alternatives.\n>>\n>> I also don't see why Alex or anyone should be denied the opportunity to\n>> comment on future soft forks or anything about bitcoin. Alex should have no\n>> more or less right to participate and his comments should be judged on\n>> their merit, just like yours and mine.\n>>\n>> On Thu, Jan 13, 2022 at 9:37 AM Prayank via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Hi Jack,\n>>>\n>>>\n>>> > The main purpose of this Fund is to defend developers from lawsuits\n>>> regarding their activities in the Bitcoin ecosystem, including finding and\n>>> retaining defense counsel, developing litigation strategy, and paying legal\n>>> bills. This is a free and voluntary option for developers to take advantage\n>>> of if they so wish. The Fund will start with a corps of volunteer and\n>>> part-time lawyers. The board of the Fund will be responsible for\n>>> determining which lawsuits and defendants it will help defend.\n>>>\n>>> Thanks for helping the developers in legal issues. Appreciate your\n>>> efforts and I understand your intentions are to help Bitcoin in every\n>>> possible way.\n>>>\n>>>\n>>> Positives that I see in this initiative:\n>>>\n>>> 1.Developers don't need to worry about rich scammers and can focus on\n>>> development.\n>>>\n>>> 2.Financial help for developers as legal issues can end up in wasting\n>>> lot of time and money.\n>>>\n>>> 3.People who have misused courts to affect bitcoin developers will get\n>>> better response that they deserve.\n>>>\n>>>\n>>> I had few suggestions and feel free to ignore them if they do not make\n>>> sense:\n>>>\n>>> 1.Name of this fund could be anything and 'The Bitcoin Legal Defense\n>>> Fund' can be confusing or misleading for newbies. There is nothing official\n>>> in Bitcoin however people believe things written in news articles and some\n>>> of them might consider it as an official bitcoin legal fund.\n>>>\n>>> 2.It would be better if people involved in such important funds do not\n>>> comment/influence soft fork related discussions. Example: Alex Morcos had\n>>> some opinions about activation mechanism during Taproot soft fork IIRC.\n>>>\n>>>\n>>>\n>>> --\n>>> Prayank\n>>>\n>>> A3B1 E430 2298 178F\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220113/53040768/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Bitcoin Legal Defense Fund",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Steve Lee",
                "qmccormick13",
                "Jeremy",
                "Christopher Allen",
                "Antoine Riard",
                "SatoshiSingh",
                "jack",
                "Aymeric Vitte",
                "Alex Morcos",
                "Ren\u00e9 Pickhardt",
                "Zac Greenwood",
                "Prayank",
                "Alex Schoof"
            ],
            "messages_count": 16,
            "total_messages_chars_count": 39271
        }
    },
    {
        "title": "[bitcoin-dev] Summary of BIP-119 Meeting #1 Tuesday January 11th",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2022-01-12T08:23:19",
                "message_text_only": "Hi Devs,\n\nBelow you'll find my summary of the BIP-119 Meeting held earlier today.\n\nOverall the meeting was pleasant although fast paced. Thank you all for\nattending and participating. I look forward to seeing (more of) you next\ntime!\n\nMeeting notes available here:\nhttps://gnusha.org/ctv-bip-review/2022-01-11.log, please check my work that\nI've accurately reflected the opinions expressed. You'll also find the\nnotes instructive to peruse if you wish to use it as a guide for reviewing\nthe BIP.\n\nCheers,\n\nJeremy\n\n*In brief:*\n- CTV's design seems relatively uncontroversial/easy to comprehend.\n- The desirability / suitability of CTV for its use cases still seemed\nuncertain to participants.\n- Among participants, there seemed to be sentiment that if we are to stick\nto taproot speedy-trial like timelines, Springtime ('22, '23, ...) seems to\nmake sense.\n- For the next meeting, the sessions will focus more heavily on\napplications and will be slower paced.\n\n*Detailed summary:*\n\n*First participants noted what they were excited for CTV to do.*\n\nAmong participants in the meeting:\nThere was strong interest expressed in the Vaults use case by a number of\nindividuals.\nThere was lighter interest in non-interactive channels and payment pools.\nThere was strong skepticism expressed about congestion control; it was\nnoted that non-interactive channels+congestion control was a strong\nmotivator.\n\n*Then, BIP review began:*\n\nWhile reviewing the BIP:\nQuadratic hashing during validation, and how CTV should be immune to it via\ncaching, was reviewed.\nThe costs and lifetime of PrecomputedData caching was reviewed.\nA question was asked as to why the witness data was not in the CTV hash,\nwhich was explained that it could prevent signatures from being used with\nCTV.\nThe half-spend problem was explained and CTV's mitigations against it were\nreviewed.\n\nCTV's usage of a NOP was reviewed; after CTV 6 upgradable NOPs would\nremain, it was pointed out that multibyte <version number> NOP10 could\nextend the NOP space indefinitely (since CTV only uses 32-byte arguments,\nCTV's NOP is only partly used).\nOnly adding CTV to tapscript (and not segwit v0, bare script, p2sh) was\ndiscussed; no one expressed strongly that presence in legacy script was\nproblematic if there was a use for it -- i.e., let the market decide (since\nsome scripts are cheapest in bare script), although there seemed to be\nagreement that you'd usually want Taproot.\n\nIt was clearly preferred that CTV use SHA256 and not RIPEMD160.\n\nHow big interactive protocols can get without DoS was discussed. CTV makes\nnon-interactive protocols possible, open question of if it matters. The\nbulk of the benefit of a batch is in the first 10 participants (90%),\nadditional may not matter as much. It was agreed upon that CTV did at least\nseem to make protocols asynchronous and non-interactive, once participants\nagreed on what that terminology meant. A desire was expressed to see more\nbatched openings done in Lightning to see if/how CTV might help. *bonus:\nAlex tweeted after the meeting about currently operational LN batched\nopens, without congestion control\n**https://twitter.com/alexbosworth/status/1481104624085917699\n<https://twitter.com/alexbosworth/status/1481104624085917699>.*\n\n*Then, Code Review began.*\n\nFirst, the \"main\" BIP functionality commits were reviewed.\n\nThe current state of code coverage was discussed & improvements on that.\nHandleMissingData remains difficult to code cover.\nCTV's policy discouraging rules before activation were discussed, and how\nthis improves on prior soft forks not discouraging spends.\nThe TODO in the caching heuristic was discussed. The history of the\nPrecomputedData caching heuristics was discussed, and how they became more\naggressive under taproot and that this might be a minor regression. It was\nexplained by the author that \"TODO\" meant someone could do something in the\nfuture, not that something must be done now.\n\nThe bare CTV script type was discussed. The difference between legacy\nscript validation and standardness was discussed.\nBare CTV script does not (yet?) get it's own address type, but a standard\noutput type is still needed for relaying from internal services.\nThat it could be removed and added later was discussed, but that it causes\ndifficulty for testing was also mentioned.\n\nTests and test vectors were discussed.\nA non blocking action item was raised to make our hex json test vectors\n(for all Bitcoin) human readable was raised (otherwise, how do we know what\nthey do?).\n\n*Then, discussion of the bug bounty began.*\n\nAn offer was made to make the administration of the program through a tax\ndeductible 501c3, Lincoln Network.\nDifficulties were discussed in practical administration of the program\nfunds.\nDesire was expressed to reward more than just 'showstopping' bugs, but also\nstrong reviews/minor issues/longer term maintenance.\nDesire was expressed for a covenants-only Scaling Bitcoin like event.\nSome discussion was had about bounties based around mutation testing, but\nit was not clear how that might work for CTV specifically.\n\n\n*Then, discussion of a release timelines began.*\n\n*this discussion was disclaimed to be about what might be feasible, less so\nthe advisability of CTV in general.*\n\nDiscussion was had around either merging unactivated consensus code for CTV\nahead of the next feature freeze, delaying the next feature freeze slightly\nif that is too tight, or delaying CTV.\nThe importance of backporting and relationship to merging unactivated code\nwas discussed.\nDiscussion was had around 'launch windows', and how, presupposing something\nlike ST, late spring release, summer signaling, and early Nov activation\nseemed to be ideal. Such that if it cannot be done for this year, it might\nentail waiting +1 year to fit nicely with release schedules and major\nholidays.\nA preference for late spring/early summer signaling, similar to taproot,\nseemed uncontroversial.\n\n\n*Then, the main meeting ended. And the post-meeting began:*\n\nSome developers shared what their personal next steps were.\nA review of current tested ACKs was done.\nKanzure forgot he implemented CTV Vaults 2 years ago :p\nA review of literature / resources to learn about alternative covenants.\n\nActivation mechanisms were discussed:\nUpdates to BIP-119 make clear that deployment is through whatever has\nconsensus, not necessarily ST.\nParticipants during the meeting quite like UASF as an option, but not as a\nfirst option as it can be done in a follow-up release.\n\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220112/6f3ddc64/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Summary of BIP-119 Meeting #1 Tuesday January 11th",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 6750
        }
    },
    {
        "title": "[bitcoin-dev] OP_PUSH_KEY_* & BIP-118 0x01 Pun",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2022-01-13T00:35:19",
                "message_text_only": "Hi Devs,\n\nTwo small transaction introspection opcodes that are worth considering are\nOP_PUSH_KEY_INTERNAL or OP_PUSH_KEY_EXTERNAL which can return the taproot\nkey for the current input.\n\nWhile the internal key could be included in the tree already, and this is\njust a performance improvement, the external key creates a hash cycle and\nis not possible to include directly.\n\nThis came up as a potential nicety while looking at how BIP-118 \"puns\" a\nsingle 0x01 byte as a key argument to refer to the Internal key for\ncompactness. It would be more general if instead of 0x01, there were an\nopcode that actually put the Internal key on the stack.\n\nThere is a small incompatibility with BIP-118 with this approach, which is\nthat keys are not tagged for APO-enablement. Thus, there should either be a\nversion of this opcode for APO tagged or not, or, APO should instead define\nsome CheckSig2 which has APO if tagging is still desired. (Or we could\nabandon tagging keys too...)\n\nIt might be worth pursuing simplifying APO to use these OP_PUSH_KEY opcodes\nbecause future plans for more generalized covenant might benefit from being\nable to get the current key off the stack. For example, TLUV might be able\nto be decomposed into simpler (RISC) opcodes for getting the internal key,\ngetting the current merkel path, and then manipulating it, then tweaking\nthe internal key.\n\nThe internal key might be useful for signing in a path not just for APO,\nbut also because you might want to sign e.g. a transaction that is\ncontingent on a HTLC scriptcode being satisfied. Because it is cheaper to\nuse the 0x01 CHECKSIG than doing a separate key (<pk> CHECKSIG), it also\ncauses an unintended side effect from APO of incentivizing not using a\nunique key per branch (privacy loss) and incentivizing enabling an APO\ntagged key where one is not required (unless 0x00, as I've noted elsewhere\nis added to the 118 spec as a pun for an untagged key).\n\nPushing the external key's use is less obvious, but with the development of\nfuture opcodes it would be helpful for some recursive covenants.\n\nBoth opcodes are very design specific -- there's only one choice of what\ndata they could push.\n\nOf course, we could keep 118 spec'd as is, and add these PUSH_KEYs later if\never desired redundantly with the Checksig puns.\n\nCheers,\n\nJeremy\n\n\n\n\n\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220112/8cfdab01/attachment.html>"
            },
            {
                "author": "Jeremy",
                "date": "2022-01-13T01:45:30",
                "message_text_only": "Note:\n\nBIP-118 as-is enables something similar to OP_PUSH_KEY_INTERNAL_TAGGED via\nthe following script fragment:\n\nwitness: <internal pk> <sig>\nprogram: DUP 0x01 CHECKSIG SWAP DUP TOALTSTACK CHECKSIG FROMALTSTACK\n\n\nIt's unclear how useful this might be, since the signature already covers\nthe transaction.\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Wed, Jan 12, 2022 at 4:35 PM Jeremy <jlrubin at mit.edu> wrote:\n\n> Hi Devs,\n>\n> Two small transaction introspection opcodes that are worth considering are\n> OP_PUSH_KEY_INTERNAL or OP_PUSH_KEY_EXTERNAL which can return the taproot\n> key for the current input.\n>\n> While the internal key could be included in the tree already, and this is\n> just a performance improvement, the external key creates a hash cycle and\n> is not possible to include directly.\n>\n> This came up as a potential nicety while looking at how BIP-118 \"puns\" a\n> single 0x01 byte as a key argument to refer to the Internal key for\n> compactness. It would be more general if instead of 0x01, there were an\n> opcode that actually put the Internal key on the stack.\n>\n> There is a small incompatibility with BIP-118 with this approach, which is\n> that keys are not tagged for APO-enablement. Thus, there should either be a\n> version of this opcode for APO tagged or not, or, APO should instead define\n> some CheckSig2 which has APO if tagging is still desired. (Or we could\n> abandon tagging keys too...)\n>\n> It might be worth pursuing simplifying APO to use these OP_PUSH_KEY\n> opcodes because future plans for more generalized covenant might benefit\n> from being able to get the current key off the stack. For example, TLUV\n> might be able to be decomposed into simpler (RISC) opcodes for getting the\n> internal key, getting the current merkel path, and then manipulating it,\n> then tweaking the internal key.\n>\n> The internal key might be useful for signing in a path not just for APO,\n> but also because you might want to sign e.g. a transaction that is\n> contingent on a HTLC scriptcode being satisfied. Because it is cheaper to\n> use the 0x01 CHECKSIG than doing a separate key (<pk> CHECKSIG), it also\n> causes an unintended side effect from APO of incentivizing not using a\n> unique key per branch (privacy loss) and incentivizing enabling an APO\n> tagged key where one is not required (unless 0x00, as I've noted elsewhere\n> is added to the 118 spec as a pun for an untagged key).\n>\n> Pushing the external key's use is less obvious, but with the development\n> of future opcodes it would be helpful for some recursive covenants.\n>\n> Both opcodes are very design specific -- there's only one choice of what\n> data they could push.\n>\n> Of course, we could keep 118 spec'd as is, and add these PUSH_KEYs later\n> if ever desired redundantly with the Checksig puns.\n>\n> Cheers,\n>\n> Jeremy\n>\n>\n>\n>\n>\n>\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220112/edd033c7/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "OP_PUSH_KEY_* & BIP-118 0x01 Pun",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 5725
        }
    },
    {
        "title": "[bitcoin-dev] Documenting the lifetime of a transaction during mempool congestion from the perspective of a rational user",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2022-01-13T21:06:37",
                "message_text_only": "Devs,\n\nThis email is primarily about existing wallet behaviors and user\npreferences, and not about CTV. However, towards the end I will describe\nthe relevance of CTV, but the email is worth reading even if you have no\ninterest in CTV as the problems described exist today.\n\nOne point of confusion I've seen while discussing CTV based congestion\ncontrol is that it requires a bunch of new wallet software.\n\nMost of the software requirements that would make CTV work well are things\nthat either already exist in Bitcoin Core, or are 'bugs' (where bug is\ndefined as deviation from rational utility maximizing behavior) that should\nbe fixed *whether or not CTV exists.*\n\nIn this post, I am going to walk through what I expect rational behavior to\nbe for a not unlikely circumstance.\n\nFirst, let's define what rational behavior for a wallet is. A rational\nwallet should have a few goals:\n\n1) Maximize 'fully trusted' balance (fully confirmed + unconfirmed change\noutputs from our own txns)\n2) Process payments requested by the owner within the \"urgency budget\"\nrequested by the user.\n3) Maximize \"privacy\" (this is a vague goal, so we'll largely ignore it\nhere.).\n\nRational wallet behavior may not be possible without metadata. For example,\na rational wallet might prompt the user for things like \"how much do you\ntrust the sender of this payment to not RBF this transaction?\", or \"how\nmuch do you trust this sender to not double spend you?\". For example, a\nself-transfer from cold wallet to hot wallet could have a trust score of 1,\nwhereas a payment from an anonymous source would have a trust score of 0.\nExchanges where you have a legal agreement to not RBF might sit somewhere\nin between. Other pieces of exogenous information that could inform wallet\nbehavior include \"has hashrate decreased recently, making longer reorgs\nlikely\".\n\nIn the model above, a user does not request transactions, they request\npayments. The rational wallet serves as an agent to assist the user in\ncompleting these payments. For example, if I have a wallet with a single\nunconfirmed output, and I spend from it to pay Alice, if the unconfirmed\ngets replaced, my wallet should track that it was replaced and prompt me to\nre-sign a new transaction. Rational wallets that maximize balance should be\ncareful to ensure that replaced payments are exclusive, guaranteed either\nthrough sufficient confirmations or 'impossibility proofs' by reusing an\ninput (preventing double-send behavior).\n\n-----------------------------\n\nNow that we've sketched out a basic framework for what a rational wallet\nshould be doing, we can describe what the process of receiving a payment is.\n\nSuppose I have a wallet with a bevy of fully confirmed coins such that for\nmy future payments I am sufficiently funded.\n\nThen, I receive a payment from a highly trusted source (e.g., self\ntransfer) that is unconfirmed.\n\nI then seek to make an outgoing payment. I should have no preference\ntowards or against spending the unconfirmed transfer, I should simply\naccount for it's cost in coin selection of CPFP-ing the parent transaction.\nIf fees are presently historically low, I may have a preference to spend it\nso as to not have a higher fee later (consolidation).\n\nLater, I receive payment from an untrusted source (e.g., an anonymous\ndonation to me). I have no reason to trust this won't be double spent.\nPerhaps I can even observe that this output has been RBF'd many times\npreviously. I do not count on this money arriving. The feerate on the\ntransaction suggests it won't be confirmed immediately.\n\nIn order to maximize balance, I should prioritize spending from this output\n(even if I don't have a payment I desire to make) in order to CPFP it to\nthe top of the mempool and guarantee I am paid. This is inherently \"free\"\nsince my cost to CPFP would be checked to be lower than the funds I am\nreceiving, and I have no expected value to receive the payment if it is not\nconfirmed. If I do have a transaction I desire to do, I should prioritize\nspending this output at that time. If not, I would do a CPFP just in favor\nof balance maximizing. Perhaps I can piggyback something useful, like\nspeculatively opening a lightning channel.\n\nIf I just self-spend to CPFP, it is very simple since the only party set up\nfor disappointment is myself (note: I patched the behavior in this case to\naccurately *not* count this as a trusted balance in\nhttps://github.com/bitcoin/bitcoin/pull/16766, since a parent could disrupt\nthis). However, if I try to make a payment, my wallet agent must somehow\nprompt me to re-sign or automatically sign an alternative payment once it\nis proven (e.g. 6 blocks) I won't receive the output, or to re-sign on a\nmutually exclusive output (e.g., fee bumping RBF) such that issuing two\npayments will not causes a double-send error. This adds complexity to both\nthe user story and logic, but is still rational.\n\nNow, suppose that I receive a new payment from  a **trusted** source that\nis a part of a \"long chain\". A long chain is a series of transactions that\nare all unconfirmed in the mempool. This long-chain is in the bottom of the\nmempool, and is not expected to confirm any time soon.\n\nMy wallet should be configured such that it saves not only all ancestors of\nthe transaction paying me, but also all descendants of the root unconfirmed\ntransaction paying me. If I do not save all ancestor transactions, then it\nwould be impossible for me to claim this payment at a future date, and\nwould violate balance maximization. But why save descendants, if they do\nnot concern me? Descendant transactions are critical for balance\nmaximization. Someone else's spend of an output is a \"free\" CPFP subsidy\nfor driving my transaction to completion (perhaps \"descendants that\nincrease the feerate of any parent\" is the correct thing to save).\nTherefore if I want to maximize balance, I would rather keep these\ntransactions around should I ever need to rebroadcast the transactions as\nit should be cheaper than having to CPFP by myself.\n\nNow, suppose that I receive a similar payment in a longchain from a series\nof untrusted sources. The same arguments apply, but now I may have even\nhigher incentive to prioritize spending this coin since, if sender's trust\nscores are independent, my total trust in that payment is decomposed\nworst-case geometrically. It may not be a good assumption that trust scores\nare independent, since a long chain might be generated as e.g. a series of\nbatch payments from one service provider.\n\nBriefly mentioned above is rebroadcasting. This is sort of an orthogonal\nbehavior to the above, but it is \"simple\" to explain. Wallet agents should\nretransmit txns to the network if they believe other nodes are not aware of\nthem and they are likely to go into a block. This encapsulates personal\ntransactions as well as arbitrary transactions from third parties. There\nare many privacy implications of rebroadcasting that are out of scope for\nthis post.\n\n-----------------\n\nAll of the behaviors documented above are things that should happen today\nif you would like to have a rational wallet that maximizes your balance and\nmakes payments.\n\nThe reasons we don't do some of these things are, as far as I can tell:\n\n1) Engineering Complexity\n2) UX Complexity (simpler to make unconfirmed outputs \"unspendable\" to\nminimize transaction reissuing)\n3) Mempool backlog is low, things are confirmed quickly if a sender pays a\nrelatively low fee\n\nCertain wallets already have parts of this functionality baked in to an\nextent. For example, in Lightning Channels, you will drive payments to\ncompletion to prevent HTLC timeouts during contested closes (HTLCs == low\ntrust score payments).\n\nShould Bitcoin see development of a more robust fee market, it is highly\nlikely the rational behaviors described above would be emergent among all\nbitcoin wallets (who would want to use a Bitcoin wallet that gets you less\nmoney over time?). This email is not just a \"Bitcoin Core\" thing, hence not\nbeing an issue on Bitcoin Core where there are currently deviations from\nthe above behaviors.\n\n-----------------\n\nWhat's CTV got to do with it?\n\nA common critique of congestion control using CTV is that it complicates\nwallet behavior because congestion control is designed to be useful in the\ncircumstances above. CTV and congestion control do not cause these\nconditions. These conditions already exist whether or not we have\ncongestion control.\n\nWhere congestion control helps is that, in a world with a full mempool, you\nhave fewer payments that are *actually* unconfirmed because exchanges that\nbatch can fully confirm a constant sized root transaction and the sub-trees\nof transactions locked in by CTV can be treated as fully trusted. This\nhelps reduce the need for the (rational) behavior of CPFP bumping your own\npayments on receipt from lower trust senders. Further, the expansion of the\ntransaction tree can be done by other users receiving, so you have an\nincentive to wait for funds to mature as someone else might pay for\nexpansion. These two factors mean that CTV congestion control can exert a\ndramatic back pressure on transaction urgency by unbundling the blockspace\ndemand for spending and receiving coins. There are other synergies -- such\nas non-interactive channel opens -- that further improve the amount of\nreduction of time-preference in full on-chain resolution.\n\nI hope this email helps clarify why CTV Congestion Control isn't\nparticularly creating a wallet architecture problem, it's helping to solve\nan existing one.\n\nBest,\n\nJeremy\n\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220113/0cad9c8d/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Documenting the lifetime of a transaction during mempool congestion from the perspective of a rational user",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 9793
        }
    },
    {
        "title": "[bitcoin-dev] CTV and ANYPREVOUT vault designs",
        "thread_messages": [
            {
                "author": "Prayank",
                "date": "2022-01-15T17:19:36",
                "message_text_only": "Everything shared in this email was earlier posted by Michael Folkson on Bitcoin Stackexchange (a site that allows people to close opinion based questions), cross posting here so that more developers could discuss and in a better way. I have just removed one paragraph.\n\nAt the time of writing (January 2022) there seems to be very little research with direct comparisons on the utility and safety of different ways to enable the construction of various vault designs. Indeed the covenant opcode TAPLEAF_UPDATE_VERIFY was only [proposed][1] to the bitcoin-dev mailing list in September 2021 and there are no implementations of it as yet let alone detailed analyses of how it compares to constructing vaults using SIGHASH_ANYPREVOUT or OP_CHECKTEMPLATEVERIFY. The mailing list post did suggest that it enables a vault design that matches a previous [vault design][2] of Bryan Bishop with additional benefits:\n\n> It's fully recursive, allows withdrawals to vary rather than be the\n> fixed amount L (due to not relying on pre-signed transactions), and\n> generally seems a bit simpler to work with.\n\nJeremy Rubin initially [described][4] OP_CHECKOUTPUTSHASHVERIFY (which became OP_CHECKTEMPLATEVERIFY) as a \"rudimentary, limited form of covenant which does not bear the same technical and social risks of prior covenant designs\". This suggests that for vaults specifically the design space may be more limited using OP_CHECKTEMPLATEVERIFY.\n\nAndrew Poelstra has blogged on how to use OP_CAT and OP_CHECKSIGFROMSTACK to construct covenants and vaults ([1][5], [2][3]). These would enable more generalized covenants than OP_CHECKTEMPLATEVERIFY potentially increasing the design space for vaults but with the downsides of being less efficient and arguably riskier. There does seem to be a direct risk/reward trade-off here when attempting to broaden the design space for vaults and it is difficult to assess where on the spectrum is the potential optimum given how few vault prototypes there are let alone fully built out implementations of those prototypes.\u00a0\n\nThe solitary [paper][6] that has compared building vaults using OP_CHECKTEMPLATEVERIFY and SIGHASH_ANYPREVOUT at the time of writing is **Bitcoin Covenants: Three Ways to Control the Future**.\n\nThis paper discussed three categories of vault design: deleted key (no consensus changes required but inferior security model), recovered key (requires BIP 118 consensus change, superior security model) and script based (requires BIP 119 consensus change, superior security model).\n\n[![Bitcoin Covenants Paper][7]][7]\n\nIt stated:\n\n> Recovered-key and script-based covenants are mostly functionally equivalent and\nso the advantages that recovered-key covenants have over deleted-key covenants also applies to Script-based covenants. If\neither were enabled by their required soft-fork upgrade then a new domain of practical covenant-based protocols could emerge.\nUnderstanding precisely what utility is gained from such upgrades is key to their progress.\n\nThe paper concluded by stating:\n\n> Bitcoin is a complex adaptive system with many interacting parts and\n> there are systemic risks with every modification of bitcoin\u2019s\n> code-base and protocol. It is difficult to analyze those risks and it\n> would be hubris to claim that there are no unknown risks being\n> introduced.\n\n\u00a0 [1]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019419.html\n\u00a0 [2]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-August/017231.html\n\u00a0 [3]: https://www.wpsoftware.net/andrew/blog/cat-and-schnorr-tricks-ii.html\n\u00a0 [4]: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-May/016934.html\n\u00a0 [5]: https://www.wpsoftware.net/andrew/blog/cat-and-schnorr-tricks-i.html\n\u00a0 [6]: https://arxiv.org/pdf/2006.16714.pdf\n\u00a0 [7]: https://i.stack.imgur.com/Udey1.png\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220115/01a82955/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "CTV and ANYPREVOUT vault designs",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Prayank"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4038
        }
    },
    {
        "title": "[bitcoin-dev] BIP proposal: Pay-to-contract tweak fields for PSBT (bip-psbt-p2c)",
        "thread_messages": [
            {
                "author": "Dr Maxim Orlovsky",
                "date": "2022-01-16T17:41:22",
                "message_text_only": "Dear Bictoin dev community,\n\n\nIn Mar 2019 Andrew Poelstra sent to bitcoin dev mail list a proposal\nfor extending existing PSBT standard [6], which among other was suggesting adding a field for P2C tweaks:\n\n> (c) a map from public keys to 32-byte \"tweaks\" that are used in the\n>     pay-to-contract construction. Selfishly I'd like this to be a\n>     variable-length bytestring with the semantics that (a) the first\n>     33 bytes represent an untweaked pubkey; (b) the HMAC-SHA256 of\n>     the whole thing, when multiplied by G and added to the untweaked\n>     pubkey, result in the target key. This matches the algorithm in\n>     [3] which is deployed in Blockstream's Liquid, but I'd be happy\n>     with a more efficient scheme which e.g. used SHA256 rather than\n>     HMAC-SHA256.\n\nThis BIP proposal is an attempt to structure that idea into a more\nuniversal and standard form, following a discussion happened in https://github.com/bitcoin/bips/pull/1239. Specifically, it adds a PSBT input field for inputs spending UTXOs with previously created pay-to-contract (P2C) public key tweaks.\n\n\n-----------------------------------------------------------------------\n\n<pre>\n  BIP: ?\n  Layer: Applications\n  Title: Pay-to-contract tweak fields for PSBT\n  Author: Maxim Orlovsky <orlovsky at lnp-bp.org>,\n          Andrew Poelstra <apoelstra at wpsoftware.net>\n  Discussions-To: <bitcoin-dev at lists.linuxfoundation.org>\n  Comments-URI: <to be assigned>\n  Status: Draft\n  Type: Standards Track\n  Created: 2022-01-16\n  License: BSD-2-Clause\n  Requires: BIP-174\n</pre>\n\n==Introduction==\n\n===Abstract===\n\nThis document proposes additional fields for BIP 174 PSBTv0 and BIP 370 PSBTv2\nthat allow for pay-to-contract key tweaking data data to be included in a PSBT\nof any version. These will represent an extra-transaction information required\nfor the signer to produce valid signatures spending previous outputs.\n\n===Copyright===\n\nThis BIP is licensed under the 2-clause BSD license.\n\n===Background===\n\nKey tweaking is a procedure for creating a cryptographic commitment to some\nmessage using elliptic curve properties. The procedure uses the discrete log\nproblem (DLP) to commit to an extra-transaction message. This is done by adding\nto a public key (for which the output owner knows the corresponding private key)\na hash of the message multiplied on the generator point G of the elliptic curve.\nThis produces a tweaked public key, containing the commitment. Later, in order\nto spend an output containing P2C commitment, the same commitment should be\nadded to the corresponding private key.\n\nThis type of commitment was originally proposed as a part of the pay to contract\nconcept by Ilja Gerhardt and Timo Hanke in [1] and later used by Eternity Wall\n[2] for the same purpose. Since that time multiple different protocols for P2C\nhas been developed, including OpenTimeStamps [3], Elements sidechain P2C tweaks\n[4] and LNPBP-1 [5], used in for constructing Peter Todd's single-use-seals [6]\nin client-side-validation protocols like RGB.\n\n===Motivation===\n\nP2C outputs can be detected onchain and spent only if the output owner\nnot just knowns the corresponding original private key, but also is aware about\nP2C tweak applied to the public key. In order to produce a valid signature, the\nsame tweak value must be added (modulo group order) to the original private key\nby a signer device. This represents a channelge for external signers, which may\nnot have any information about such commitment. This proposal addresses this\nissue by adding relevant fields to the PSBT input information.\n\nThe proposal abstracts details of specific P2C protocols and provides universal\nmethod for spending previous outpus containing P2C tweaks, applied to the public\nkey contained within any standard form of the <tt>scriptPubkey</tt>, including\nbare scripts and P2PK, P2PKH, P2SH, witness v0 P2WPKH, P2WSH, nested witness v0\nP2WPKH-P2SH, P2WSH-P2SH and witness v1 P2TR outputs.\n\n\n==Design==\n\nP2C-tweaked public keys are already exposed in the\n<tt>PSBT_IN_REDEEM_SCRIPT</tt>, <tt>PSBT_IN_WITNESS_SCRIPT</tt>,\n<tt>PSBT_IN_TAP_INTERNAL_KEY</tt> and <tt>PSBT_IN_TAP_LEAF_SCRIPT</tt> fields;\nthe only information signer is needed to recognize which keys it should sign\nwith is from which of the original keys they were generated. This is achieved by\nintroducing new `PSBT_IN_P2C_TWEAK` field which has the original key as a field\nkey and the tweak as a field value. The signer will recognize the keys which are\navailable to it, apply the tweak to them and see in which scripts it was used --\nand use this information to apply tweaks for the corresponding private keys and\nproduce valid signatures.\n\n\n==Specification==\n\nThe new per-input type is defined as follows:\n\n{|\n! Name\n! <tt><keytype></tt>\n! <tt><keydata></tt>\n! <tt><keydata></tt> Description\n! <tt><valuedata></tt>\n! <tt><valuedata></tt> Description\n! Versions Requiring Inclusion\n! Versions Requiring Exclusion\n! Versions Allowing Inclusion\n|-\n| P2C Key Tweak\n| <tt>PSBT_IN_P2C_TWEAK = 0x19</tt>\n| <tt><pubkey></tt>\n| 33 bytes of compact public key serialization specifying to which of keys the\nP2C tweak may be applied (i.e. this MUST be a value of a public key before the\ntweak is applied). BIP-340 keys are serialized by appending `02`\nbyte.<ref>'''Why compressed public keys are not distinguished from BIP-340\npublic keys'''We follow the logic of BIP32 key derivation which does not\nperforms that distinguishment. The type of the key is defined by the input type,\nand adding additional PSBT field type will just create the need for handling\nerrors when the input type does not match the provided key type.</ref>\n| <tt><tweak></tt>\n| The 32 byte value which MUST be added to a private key to produce correct\nECDSA and/or Schnorr signature (\"key tweak\"). Signers SHOULD remove this field\nafter <tt>PSBT_IN_PARTIAL_SIG</tt> is constructed.\n|\n|\n| 0, 2\n| BIP-P2C\n|}\n\n\n==Security considerations==\n\nThe scope of this proposal is deliberately kept narrow; it addresses\nonly spending of transaction outputs containing P2C tweaks - and does not addresses construction of a new P2C commitments or transactions containing them in their outputs.<ref>'''Why only spending of P2C tweaked outputs is covered'''P2C tweaks commit to external data, some of which may represent certain value (like in some sidechains, single-use-seal applications like RGB etc). Creation of such outputs much allow hardware devices to understand the structure of such extra-transaction data, which may be in different formats and constantly involve. Thus, this should be addresses with a separate standards (or be a vendor-based). The current proposal only touches the question of spending an output which contained previously created P2C commitment, which does not creates a new commitment and does not provides that kind of risk of extra-blockchain value loses.</ref>\n\n\n==Rationale==\n\n<references/>\n\n\n==Compatibility==\n\nThe proposal is compatible with the existing consensus rules and does not\nrequire any of their modifications.\n\nThe proposed P2C PSBT fields provides sufficient information for creating a\nvalid signatures for spendings of the following output types containing tweaked\npublic keys:\n- bare scripts,\n- P2PK,\n- P2PKH,\n- P2SH,\n- witness v0 P2WPKH and P2WSH,\n- nested witness v0 P2WPKH-P2SH and P2WSH-P2SH,\n- witness v1 P2TR outputs.\n\nPossible future witness versions, including witness v1 non-taproot outputs may\nnot be supported or covered by this BIP and may require addition of new fields\nto the PSBT inputs.\n\n\n==Reference implementation==\n\nWIP\n\n\n==Acknowledgements==\n\nTBD\n\n\n==Test vectors==\n\nTBD\n\n\n==References==\n\n[1] Ilja Gerhardt, Timo Hanke. Homomorphic Payment Addresses and the\n    Pay-to-Contract Protocol. arXiv:1212.3257 \\[cs.CR\\]\n    <https://arxiv.org/pdf/1212.3257.pdf>\n[2] Eternity Wall's \"sign-to-contract\" article.\n    <https://blog.eternitywall.com/2018/04/13/sign-to-contract/>\n[3] Peter Todd. OpenTimestamps: Scalable, Trust-Minimized, Distributed\n    Timestamping with Bitcoin.\n    <https://petertodd.org/2016/opentimestamps-announcement>\n[4] Adam Back, Matt Corallo, Luke Dashjr, et al. Enabling Blockchain\n    Innovations with Pegged Sidechains (commit5620e43). Appenxix A.\n    <https://blockstream.com/sidechains.pdf>;.\n[5] Maxim Orlovsky, Rene Pickhardt, Federico Tenga, et al. Key\n    tweaking: collision- resistant elliptic curve-based commitments.\n    LNPBP-1 Standard.\n    <https://github.com/LNP-BP/LNPBPs/blob/master/lnpbp-0001.md>\n[6] Peter Todd. Single-use-seals. LNPBP-8 Standard.\n    <https://github.com/LNP-BP/LNPBPs/blob/master/lnpbp-0008.md>\n\n--\nMaxim Orlovsky\norlovsky at protonmail.com\nGitHub: @dr-orlovsky\nTwitter: @dr_orlovsky\n\nLNP/BP Standards Association\norlovsky at lnp-bp.org\ngithub.com/LNP-BP"
            },
            {
                "author": "Jeremy",
                "date": "2022-01-17T05:55:00",
                "message_text_only": "High level feedback:\n\nIt would be nice if this field was not distinct from BIP32 derivation\ndescriptors so that you could have a single representation for the Extended\nKey that doesn't need some additional field only in PSBT.\n\nIf I understood correctly, and this is just an arbitrary hash being\nprovably added (but has not direct cryptographic function), this can also\nbe done with no changes to BIP32 as I did in\nhttps://github.com/sapio-lang/sapio/blob/master/ctv_emulators/src/lib.rs.\n\nBest,\n\nJeremy\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Sun, Jan 16, 2022 at 1:00 PM Dr Maxim Orlovsky via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Dear Bictoin dev community,\n>\n>\n> In Mar 2019 Andrew Poelstra sent to bitcoin dev mail list a proposal\n> for extending existing PSBT standard [6], which among other was suggesting\n> adding a field for P2C tweaks:\n>\n> > (c) a map from public keys to 32-byte \"tweaks\" that are used in the\n> >     pay-to-contract construction. Selfishly I'd like this to be a\n> >     variable-length bytestring with the semantics that (a) the first\n> >     33 bytes represent an untweaked pubkey; (b) the HMAC-SHA256 of\n> >     the whole thing, when multiplied by G and added to the untweaked\n> >     pubkey, result in the target key. This matches the algorithm in\n> >     [3] which is deployed in Blockstream's Liquid, but I'd be happy\n> >     with a more efficient scheme which e.g. used SHA256 rather than\n> >     HMAC-SHA256.\n>\n> This BIP proposal is an attempt to structure that idea into a more\n> universal and standard form, following a discussion happened in\n> https://github.com/bitcoin/bips/pull/1239. Specifically, it adds a PSBT\n> input field for inputs spending UTXOs with previously created\n> pay-to-contract (P2C) public key tweaks.\n>\n>\n> -----------------------------------------------------------------------\n>\n> <pre>\n>   BIP: ?\n>   Layer: Applications\n>   Title: Pay-to-contract tweak fields for PSBT\n>   Author: Maxim Orlovsky <orlovsky at lnp-bp.org>,\n>           Andrew Poelstra <apoelstra at wpsoftware.net>\n>   Discussions-To: <bitcoin-dev at lists.linuxfoundation.org>\n>   Comments-URI: <to be assigned>\n>   Status: Draft\n>   Type: Standards Track\n>   Created: 2022-01-16\n>   License: BSD-2-Clause\n>   Requires: BIP-174\n> </pre>\n>\n> ==Introduction==\n>\n> ===Abstract===\n>\n> This document proposes additional fields for BIP 174 PSBTv0 and BIP 370\n> PSBTv2\n> that allow for pay-to-contract key tweaking data data to be included in a\n> PSBT\n> of any version. These will represent an extra-transaction information\n> required\n> for the signer to produce valid signatures spending previous outputs.\n>\n> ===Copyright===\n>\n> This BIP is licensed under the 2-clause BSD license.\n>\n> ===Background===\n>\n> Key tweaking is a procedure for creating a cryptographic commitment to some\n> message using elliptic curve properties. The procedure uses the discrete\n> log\n> problem (DLP) to commit to an extra-transaction message. This is done by\n> adding\n> to a public key (for which the output owner knows the corresponding\n> private key)\n> a hash of the message multiplied on the generator point G of the elliptic\n> curve.\n> This produces a tweaked public key, containing the commitment. Later, in\n> order\n> to spend an output containing P2C commitment, the same commitment should be\n> added to the corresponding private key.\n>\n> This type of commitment was originally proposed as a part of the pay to\n> contract\n> concept by Ilja Gerhardt and Timo Hanke in [1] and later used by Eternity\n> Wall\n> [2] for the same purpose. Since that time multiple different protocols for\n> P2C\n> has been developed, including OpenTimeStamps [3], Elements sidechain P2C\n> tweaks\n> [4] and LNPBP-1 [5], used in for constructing Peter Todd's\n> single-use-seals [6]\n> in client-side-validation protocols like RGB.\n>\n> ===Motivation===\n>\n> P2C outputs can be detected onchain and spent only if the output owner\n> not just knowns the corresponding original private key, but also is aware\n> about\n> P2C tweak applied to the public key. In order to produce a valid\n> signature, the\n> same tweak value must be added (modulo group order) to the original\n> private key\n> by a signer device. This represents a channelge for external signers,\n> which may\n> not have any information about such commitment. This proposal addresses\n> this\n> issue by adding relevant fields to the PSBT input information.\n>\n> The proposal abstracts details of specific P2C protocols and provides\n> universal\n> method for spending previous outpus containing P2C tweaks, applied to the\n> public\n> key contained within any standard form of the <tt>scriptPubkey</tt>,\n> including\n> bare scripts and P2PK, P2PKH, P2SH, witness v0 P2WPKH, P2WSH, nested\n> witness v0\n> P2WPKH-P2SH, P2WSH-P2SH and witness v1 P2TR outputs.\n>\n>\n> ==Design==\n>\n> P2C-tweaked public keys are already exposed in the\n> <tt>PSBT_IN_REDEEM_SCRIPT</tt>, <tt>PSBT_IN_WITNESS_SCRIPT</tt>,\n> <tt>PSBT_IN_TAP_INTERNAL_KEY</tt> and <tt>PSBT_IN_TAP_LEAF_SCRIPT</tt>\n> fields;\n> the only information signer is needed to recognize which keys it should\n> sign\n> with is from which of the original keys they were generated. This is\n> achieved by\n> introducing new `PSBT_IN_P2C_TWEAK` field which has the original key as a\n> field\n> key and the tweak as a field value. The signer will recognize the keys\n> which are\n> available to it, apply the tweak to them and see in which scripts it was\n> used --\n> and use this information to apply tweaks for the corresponding private\n> keys and\n> produce valid signatures.\n>\n>\n> ==Specification==\n>\n> The new per-input type is defined as follows:\n>\n> {|\n> ! Name\n> ! <tt><keytype></tt>\n> ! <tt><keydata></tt>\n> ! <tt><keydata></tt> Description\n> ! <tt><valuedata></tt>\n> ! <tt><valuedata></tt> Description\n> ! Versions Requiring Inclusion\n> ! Versions Requiring Exclusion\n> ! Versions Allowing Inclusion\n> |-\n> | P2C Key Tweak\n> | <tt>PSBT_IN_P2C_TWEAK = 0x19</tt>\n> | <tt><pubkey></tt>\n> | 33 bytes of compact public key serialization specifying to which of keys\n> the\n> P2C tweak may be applied (i.e. this MUST be a value of a public key before\n> the\n> tweak is applied). BIP-340 keys are serialized by appending `02`\n> byte.<ref>'''Why compressed public keys are not distinguished from BIP-340\n> public keys'''We follow the logic of BIP32 key derivation which does not\n> performs that distinguishment. The type of the key is defined by the input\n> type,\n> and adding additional PSBT field type will just create the need for\n> handling\n> errors when the input type does not match the provided key type.</ref>\n> | <tt><tweak></tt>\n> | The 32 byte value which MUST be added to a private key to produce correct\n> ECDSA and/or Schnorr signature (\"key tweak\"). Signers SHOULD remove this\n> field\n> after <tt>PSBT_IN_PARTIAL_SIG</tt> is constructed.\n> |\n> |\n> | 0, 2\n> | BIP-P2C\n> |}\n>\n>\n> ==Security considerations==\n>\n> The scope of this proposal is deliberately kept narrow; it addresses\n> only spending of transaction outputs containing P2C tweaks - and does not\n> addresses construction of a new P2C commitments or transactions containing\n> them in their outputs.<ref>'''Why only spending of P2C tweaked outputs is\n> covered'''P2C tweaks commit to external data, some of which may represent\n> certain value (like in some sidechains, single-use-seal applications like\n> RGB etc). Creation of such outputs much allow hardware devices to\n> understand the structure of such extra-transaction data, which may be in\n> different formats and constantly involve. Thus, this should be addresses\n> with a separate standards (or be a vendor-based). The current proposal only\n> touches the question of spending an output which contained previously\n> created P2C commitment, which does not creates a new commitment and does\n> not provides that kind of risk of extra-blockchain value loses.</ref>\n>\n>\n> ==Rationale==\n>\n> <references/>\n>\n>\n> ==Compatibility==\n>\n> The proposal is compatible with the existing consensus rules and does not\n> require any of their modifications.\n>\n> The proposed P2C PSBT fields provides sufficient information for creating a\n> valid signatures for spendings of the following output types containing\n> tweaked\n> public keys:\n> - bare scripts,\n> - P2PK,\n> - P2PKH,\n> - P2SH,\n> - witness v0 P2WPKH and P2WSH,\n> - nested witness v0 P2WPKH-P2SH and P2WSH-P2SH,\n> - witness v1 P2TR outputs.\n>\n> Possible future witness versions, including witness v1 non-taproot outputs\n> may\n> not be supported or covered by this BIP and may require addition of new\n> fields\n> to the PSBT inputs.\n>\n>\n> ==Reference implementation==\n>\n> WIP\n>\n>\n> ==Acknowledgements==\n>\n> TBD\n>\n>\n> ==Test vectors==\n>\n> TBD\n>\n>\n> ==References==\n>\n> [1] Ilja Gerhardt, Timo Hanke. Homomorphic Payment Addresses and the\n>     Pay-to-Contract Protocol. arXiv:1212.3257 \\[cs.CR\\]\n>     <https://arxiv.org/pdf/1212.3257.pdf>\n> [2] Eternity Wall's \"sign-to-contract\" article.\n>     <https://blog.eternitywall.com/2018/04/13/sign-to-contract/>\n> [3] Peter Todd. OpenTimestamps: Scalable, Trust-Minimized, Distributed\n>     Timestamping with Bitcoin.\n>     <https://petertodd.org/2016/opentimestamps-announcement>\n> [4] Adam Back, Matt Corallo, Luke Dashjr, et al. Enabling Blockchain\n>     Innovations with Pegged Sidechains (commit5620e43). Appenxix A.\n>     <https://blockstream.com/sidechains.pdf>;.\n> [5] Maxim Orlovsky, Rene Pickhardt, Federico Tenga, et al. Key\n>     tweaking: collision- resistant elliptic curve-based commitments.\n>     LNPBP-1 Standard.\n>     <https://github.com/LNP-BP/LNPBPs/blob/master/lnpbp-0001.md>\n> [6] Peter Todd. Single-use-seals. LNPBP-8 Standard.\n>     <https://github.com/LNP-BP/LNPBPs/blob/master/lnpbp-0008.md>\n>\n> --\n> Maxim Orlovsky\n> orlovsky at protonmail.com\n> GitHub: @dr-orlovsky\n> Twitter: @dr_orlovsky\n>\n> LNP/BP Standards Association\n> orlovsky at lnp-bp.org\n> github.com/LNP-BP\n>\n>\n>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220116/f4204300/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP proposal: Pay-to-contract tweak fields for PSBT (bip-psbt-p2c)",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy",
                "Dr Maxim Orlovsky"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 19084
        }
    },
    {
        "title": "[bitcoin-dev] bip39",
        "thread_messages": [
            {
                "author": "Erik Aronesty",
                "date": "2022-01-17T21:51:55",
                "message_text_only": "really don't like that art, work, and artwork are 3 different words\n\nwould be nice to clean up adjacent ambiguity\n\nit's not a big deal, but it can lead to confusion when writing things down\n\n\ndup: ('canal', 'arm') ('can', 'alarm')\ndup: ('canal', 'one') ('can', 'alone')\ndup: ('canal', 'ready') ('can', 'already')\ndup: ('card', 'anger') ('car', 'danger')\ndup: ('card', 'ice') ('car', 'dice')\ndup: ('card', 'inner') ('car', 'dinner')\ndup: ('card', 'raw') ('car', 'draw')\ndup: ('cart', 'able') ('car', 'table')\ndup: ('cart', 'ask') ('car', 'task')\ndup: ('cart', 'hat') ('car', 'that')\ndup: ('cart', 'hen') ('car', 'then')\ndup: ('cart', 'issue') ('car', 'tissue')\ndup: ('cart', 'one') ('car', 'tone')\ndup: ('cart', 'own') ('car', 'town')\ndup: ('cart', 'rack') ('car', 'track')\ndup: ('cart', 'rain') ('car', 'train')\ndup: ('cart', 'win') ('car', 'twin')\ndup: ('catch', 'air') ('cat', 'chair')\ndup: ('erase', 'arch') ('era', 'search')\ndup: ('fatal', 'arm') ('fat', 'alarm')\ndup: ('fatal', 'one') ('fat', 'alone')\ndup: ('fatal', 'ready') ('fat', 'already')\ndup: ('feed', 'anger') ('fee', 'danger')\ndup: ('feed', 'ice') ('fee', 'dice')\ndup: ('feed', 'inner') ('fee', 'dinner')\ndup: ('feed', 'raw') ('fee', 'draw')\ndup: ('feel', 'earn') ('fee', 'learn')\ndup: ('feel', 'end') ('fee', 'lend')\ndup: ('gasp', 'act') ('gas', 'pact')\ndup: ('gasp', 'age') ('gas', 'page')\ndup: ('gasp', 'air') ('gas', 'pair')\ndup: ('gasp', 'ill') ('gas', 'pill')\ndup: ('gasp', 'raise') ('gas', 'praise')\ndup: ('gasp', 'rice') ('gas', 'price')\ndup: ('gasp', 'ride') ('gas', 'pride')\ndup: ('gasp', 'roof') ('gas', 'proof')\ndup: ('kite', 'merge') ('kit', 'emerge')\ndup: ('kite', 'motion') ('kit', 'emotion')\ndup: ('kite', 'state') ('kit', 'estate')\ndup: ('lawn', 'arrow') ('law', 'narrow')\ndup: ('lawn', 'either') ('law', 'neither')\ndup: ('lawn', 'ice') ('law', 'nice')\ndup: ('legal', 'arm') ('leg', 'alarm')\ndup: ('legal', 'one') ('leg', 'alone')\ndup: ('legal', 'ready') ('leg', 'already')\ndup: ('seat', 'able') ('sea', 'table')\ndup: ('seat', 'ask') ('sea', 'task')\ndup: ('seat', 'hat') ('sea', 'that')\ndup: ('seat', 'hen') ('sea', 'then')\ndup: ('seat', 'issue') ('sea', 'tissue')\ndup: ('seat', 'one') ('sea', 'tone')\ndup: ('seat', 'own') ('sea', 'town')\ndup: ('seat', 'rack') ('sea', 'track')\ndup: ('seat', 'rain') ('sea', 'train')\ndup: ('seat', 'win') ('sea', 'twin')\ndup: ('skin', 'arrow') ('ski', 'narrow')\ndup: ('skin', 'either') ('ski', 'neither')\ndup: ('skin', 'ice') ('ski', 'nice')\ndup: ('tent', 'able') ('ten', 'table')\ndup: ('tent', 'ask') ('ten', 'task')\ndup: ('tent', 'hat') ('ten', 'that')\ndup: ('tent', 'hen') ('ten', 'then')\ndup: ('tent', 'issue') ('ten', 'tissue')\ndup: ('tent', 'one') ('ten', 'tone')\ndup: ('tent', 'own') ('ten', 'town')\ndup: ('tent', 'rack') ('ten', 'track')\ndup: ('tent', 'rain') ('ten', 'train')\ndup: ('tent', 'win') ('ten', 'twin')\ndup: ('used', 'anger') ('use', 'danger')\ndup: ('used', 'ice') ('use', 'dice')\ndup: ('used', 'inner') ('use', 'dinner')\ndup: ('used', 'raw') ('use', 'draw')\ndup: ('wine', 'merge') ('win', 'emerge')\ndup: ('wine', 'motion') ('win', 'emotion')\ndup: ('wine', 'state') ('win', 'estate')\ndup: ('wing', 'host') ('win', 'ghost')\ndup: ('wing', 'love') ('win', 'glove')\ndup: ('wing', 'old') ('win', 'gold')\ndup: ('wing', 'own') ('win', 'gown')\ndup: ('wing', 'race') ('win', 'grace')\ndup: ('wing', 'rain') ('win', 'grain')\ndup: ('wink', 'now') ('win', 'know')\ndup: ('youth', 'under') ('you', 'thunder')"
            },
            {
                "author": "Jeremy",
                "date": "2022-01-17T22:38:12",
                "message_text_only": "This is a good point, but can be addressed by having a non-void whitespace\ncharacter (e.g., win x estate).\n\nchanging BIP39 would be hard since software expects a standard list; it\nwould also be possible to rejection sample for seeds that do not contain\nthese pairs, unclear how much entropy would be lost from that.\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Mon, Jan 17, 2022 at 2:26 PM Erik Aronesty via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> really don't like that art, work, and artwork are 3 different words\n>\n> would be nice to clean up adjacent ambiguity\n>\n> it's not a big deal, but it can lead to confusion when writing things down\n>\n>\n> dup: ('canal', 'arm') ('can', 'alarm')\n> dup: ('canal', 'one') ('can', 'alone')\n> dup: ('canal', 'ready') ('can', 'already')\n> dup: ('card', 'anger') ('car', 'danger')\n> dup: ('card', 'ice') ('car', 'dice')\n> dup: ('card', 'inner') ('car', 'dinner')\n> dup: ('card', 'raw') ('car', 'draw')\n> dup: ('cart', 'able') ('car', 'table')\n> dup: ('cart', 'ask') ('car', 'task')\n> dup: ('cart', 'hat') ('car', 'that')\n> dup: ('cart', 'hen') ('car', 'then')\n> dup: ('cart', 'issue') ('car', 'tissue')\n> dup: ('cart', 'one') ('car', 'tone')\n> dup: ('cart', 'own') ('car', 'town')\n> dup: ('cart', 'rack') ('car', 'track')\n> dup: ('cart', 'rain') ('car', 'train')\n> dup: ('cart', 'win') ('car', 'twin')\n> dup: ('catch', 'air') ('cat', 'chair')\n> dup: ('erase', 'arch') ('era', 'search')\n> dup: ('fatal', 'arm') ('fat', 'alarm')\n> dup: ('fatal', 'one') ('fat', 'alone')\n> dup: ('fatal', 'ready') ('fat', 'already')\n> dup: ('feed', 'anger') ('fee', 'danger')\n> dup: ('feed', 'ice') ('fee', 'dice')\n> dup: ('feed', 'inner') ('fee', 'dinner')\n> dup: ('feed', 'raw') ('fee', 'draw')\n> dup: ('feel', 'earn') ('fee', 'learn')\n> dup: ('feel', 'end') ('fee', 'lend')\n> dup: ('gasp', 'act') ('gas', 'pact')\n> dup: ('gasp', 'age') ('gas', 'page')\n> dup: ('gasp', 'air') ('gas', 'pair')\n> dup: ('gasp', 'ill') ('gas', 'pill')\n> dup: ('gasp', 'raise') ('gas', 'praise')\n> dup: ('gasp', 'rice') ('gas', 'price')\n> dup: ('gasp', 'ride') ('gas', 'pride')\n> dup: ('gasp', 'roof') ('gas', 'proof')\n> dup: ('kite', 'merge') ('kit', 'emerge')\n> dup: ('kite', 'motion') ('kit', 'emotion')\n> dup: ('kite', 'state') ('kit', 'estate')\n> dup: ('lawn', 'arrow') ('law', 'narrow')\n> dup: ('lawn', 'either') ('law', 'neither')\n> dup: ('lawn', 'ice') ('law', 'nice')\n> dup: ('legal', 'arm') ('leg', 'alarm')\n> dup: ('legal', 'one') ('leg', 'alone')\n> dup: ('legal', 'ready') ('leg', 'already')\n> dup: ('seat', 'able') ('sea', 'table')\n> dup: ('seat', 'ask') ('sea', 'task')\n> dup: ('seat', 'hat') ('sea', 'that')\n> dup: ('seat', 'hen') ('sea', 'then')\n> dup: ('seat', 'issue') ('sea', 'tissue')\n> dup: ('seat', 'one') ('sea', 'tone')\n> dup: ('seat', 'own') ('sea', 'town')\n> dup: ('seat', 'rack') ('sea', 'track')\n> dup: ('seat', 'rain') ('sea', 'train')\n> dup: ('seat', 'win') ('sea', 'twin')\n> dup: ('skin', 'arrow') ('ski', 'narrow')\n> dup: ('skin', 'either') ('ski', 'neither')\n> dup: ('skin', 'ice') ('ski', 'nice')\n> dup: ('tent', 'able') ('ten', 'table')\n> dup: ('tent', 'ask') ('ten', 'task')\n> dup: ('tent', 'hat') ('ten', 'that')\n> dup: ('tent', 'hen') ('ten', 'then')\n> dup: ('tent', 'issue') ('ten', 'tissue')\n> dup: ('tent', 'one') ('ten', 'tone')\n> dup: ('tent', 'own') ('ten', 'town')\n> dup: ('tent', 'rack') ('ten', 'track')\n> dup: ('tent', 'rain') ('ten', 'train')\n> dup: ('tent', 'win') ('ten', 'twin')\n> dup: ('used', 'anger') ('use', 'danger')\n> dup: ('used', 'ice') ('use', 'dice')\n> dup: ('used', 'inner') ('use', 'dinner')\n> dup: ('used', 'raw') ('use', 'draw')\n> dup: ('wine', 'merge') ('win', 'emerge')\n> dup: ('wine', 'motion') ('win', 'emotion')\n> dup: ('wine', 'state') ('win', 'estate')\n> dup: ('wing', 'host') ('win', 'ghost')\n> dup: ('wing', 'love') ('win', 'glove')\n> dup: ('wing', 'old') ('win', 'gold')\n> dup: ('wing', 'own') ('win', 'gown')\n> dup: ('wing', 'race') ('win', 'grace')\n> dup: ('wing', 'rain') ('win', 'grain')\n> dup: ('wink', 'now') ('win', 'know')\n> dup: ('youth', 'under') ('you', 'thunder')\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220117/2bbe5f2e/attachment.html>"
            },
            {
                "author": "Pavol Rusnak",
                "date": "2022-01-17T22:45:20",
                "message_text_only": "Trezor recovery cards look like this what addresses the issue:\n\nhttps://wiki.trezor.io/images/Seed_card_example.jpg\n\n1. Each word has a box around it.\n2. You write the words one under the other, not next to each other.\n\n\nOn Mon, 17 Jan 2022 at 23:38, Jeremy via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> This is a good point, but can be addressed by having a non-void whitespace\n> character (e.g., win x estate).\n>\n> changing BIP39 would be hard since software expects a standard list; it\n> would also be possible to rejection sample for seeds that do not contain\n> these pairs, unclear how much entropy would be lost from that.\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n>\n>\n> On Mon, Jan 17, 2022 at 2:26 PM Erik Aronesty via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> really don't like that art, work, and artwork are 3 different words\n>>\n>> would be nice to clean up adjacent ambiguity\n>>\n>> it's not a big deal, but it can lead to confusion when writing things down\n>>\n>>\n>> dup: ('canal', 'arm') ('can', 'alarm')\n>> dup: ('canal', 'one') ('can', 'alone')\n>> dup: ('canal', 'ready') ('can', 'already')\n>> dup: ('card', 'anger') ('car', 'danger')\n>> dup: ('card', 'ice') ('car', 'dice')\n>> dup: ('card', 'inner') ('car', 'dinner')\n>> dup: ('card', 'raw') ('car', 'draw')\n>> dup: ('cart', 'able') ('car', 'table')\n>> dup: ('cart', 'ask') ('car', 'task')\n>> dup: ('cart', 'hat') ('car', 'that')\n>> dup: ('cart', 'hen') ('car', 'then')\n>> dup: ('cart', 'issue') ('car', 'tissue')\n>> dup: ('cart', 'one') ('car', 'tone')\n>> dup: ('cart', 'own') ('car', 'town')\n>> dup: ('cart', 'rack') ('car', 'track')\n>> dup: ('cart', 'rain') ('car', 'train')\n>> dup: ('cart', 'win') ('car', 'twin')\n>> dup: ('catch', 'air') ('cat', 'chair')\n>> dup: ('erase', 'arch') ('era', 'search')\n>> dup: ('fatal', 'arm') ('fat', 'alarm')\n>> dup: ('fatal', 'one') ('fat', 'alone')\n>> dup: ('fatal', 'ready') ('fat', 'already')\n>> dup: ('feed', 'anger') ('fee', 'danger')\n>> dup: ('feed', 'ice') ('fee', 'dice')\n>> dup: ('feed', 'inner') ('fee', 'dinner')\n>> dup: ('feed', 'raw') ('fee', 'draw')\n>> dup: ('feel', 'earn') ('fee', 'learn')\n>> dup: ('feel', 'end') ('fee', 'lend')\n>> dup: ('gasp', 'act') ('gas', 'pact')\n>> dup: ('gasp', 'age') ('gas', 'page')\n>> dup: ('gasp', 'air') ('gas', 'pair')\n>> dup: ('gasp', 'ill') ('gas', 'pill')\n>> dup: ('gasp', 'raise') ('gas', 'praise')\n>> dup: ('gasp', 'rice') ('gas', 'price')\n>> dup: ('gasp', 'ride') ('gas', 'pride')\n>> dup: ('gasp', 'roof') ('gas', 'proof')\n>> dup: ('kite', 'merge') ('kit', 'emerge')\n>> dup: ('kite', 'motion') ('kit', 'emotion')\n>> dup: ('kite', 'state') ('kit', 'estate')\n>> dup: ('lawn', 'arrow') ('law', 'narrow')\n>> dup: ('lawn', 'either') ('law', 'neither')\n>> dup: ('lawn', 'ice') ('law', 'nice')\n>> dup: ('legal', 'arm') ('leg', 'alarm')\n>> dup: ('legal', 'one') ('leg', 'alone')\n>> dup: ('legal', 'ready') ('leg', 'already')\n>> dup: ('seat', 'able') ('sea', 'table')\n>> dup: ('seat', 'ask') ('sea', 'task')\n>> dup: ('seat', 'hat') ('sea', 'that')\n>> dup: ('seat', 'hen') ('sea', 'then')\n>> dup: ('seat', 'issue') ('sea', 'tissue')\n>> dup: ('seat', 'one') ('sea', 'tone')\n>> dup: ('seat', 'own') ('sea', 'town')\n>> dup: ('seat', 'rack') ('sea', 'track')\n>> dup: ('seat', 'rain') ('sea', 'train')\n>> dup: ('seat', 'win') ('sea', 'twin')\n>> dup: ('skin', 'arrow') ('ski', 'narrow')\n>> dup: ('skin', 'either') ('ski', 'neither')\n>> dup: ('skin', 'ice') ('ski', 'nice')\n>> dup: ('tent', 'able') ('ten', 'table')\n>> dup: ('tent', 'ask') ('ten', 'task')\n>> dup: ('tent', 'hat') ('ten', 'that')\n>> dup: ('tent', 'hen') ('ten', 'then')\n>> dup: ('tent', 'issue') ('ten', 'tissue')\n>> dup: ('tent', 'one') ('ten', 'tone')\n>> dup: ('tent', 'own') ('ten', 'town')\n>> dup: ('tent', 'rack') ('ten', 'track')\n>> dup: ('tent', 'rain') ('ten', 'train')\n>> dup: ('tent', 'win') ('ten', 'twin')\n>> dup: ('used', 'anger') ('use', 'danger')\n>> dup: ('used', 'ice') ('use', 'dice')\n>> dup: ('used', 'inner') ('use', 'dinner')\n>> dup: ('used', 'raw') ('use', 'draw')\n>> dup: ('wine', 'merge') ('win', 'emerge')\n>> dup: ('wine', 'motion') ('win', 'emotion')\n>> dup: ('wine', 'state') ('win', 'estate')\n>> dup: ('wing', 'host') ('win', 'ghost')\n>> dup: ('wing', 'love') ('win', 'glove')\n>> dup: ('wing', 'old') ('win', 'gold')\n>> dup: ('wing', 'own') ('win', 'gown')\n>> dup: ('wing', 'race') ('win', 'grace')\n>> dup: ('wing', 'rain') ('win', 'grain')\n>> dup: ('wink', 'now') ('win', 'know')\n>> dup: ('youth', 'under') ('you', 'thunder')\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n-- \nBest Regards / S pozdravom,\n\nPavol \"stick\" Rusnak\nCo-Founder, SatoshiLabs\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220117/76b742a6/attachment-0001.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-01-18T16:33:04",
                "message_text_only": "I agree removing any ambiguity would be good. I'd also like to see removal\nof words that are a strict subset of another word. Words like add (which is\na subset of addict and address).\n\nAs far as entropy loss, I think even with an 1000 word list and a 12 word\nseed, it would be unlikely in a time far longer than the age of the\nuniverse to expect to come across one duplicate randomly generated seed.\nEven if every person on the planet generated 1000 seeds per second. So I\ndon't really see this as a concern.\n\nOn Mon, Jan 17, 2022 at 4:45 PM Pavol Rusnak via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Trezor recovery cards look like this what addresses the issue:\n>\n> https://wiki.trezor.io/images/Seed_card_example.jpg\n>\n> 1. Each word has a box around it.\n> 2. You write the words one under the other, not next to each other.\n>\n>\n> On Mon, 17 Jan 2022 at 23:38, Jeremy via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> This is a good point, but can be addressed by having a non-void\n>> whitespace character (e.g., win x estate).\n>>\n>> changing BIP39 would be hard since software expects a standard list; it\n>> would also be possible to rejection sample for seeds that do not contain\n>> these pairs, unclear how much entropy would be lost from that.\n>> --\n>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>> <https://twitter.com/JeremyRubin>\n>>\n>>\n>> On Mon, Jan 17, 2022 at 2:26 PM Erik Aronesty via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> really don't like that art, work, and artwork are 3 different words\n>>>\n>>> would be nice to clean up adjacent ambiguity\n>>>\n>>> it's not a big deal, but it can lead to confusion when writing things\n>>> down\n>>>\n>>>\n>>> dup: ('canal', 'arm') ('can', 'alarm')\n>>> dup: ('canal', 'one') ('can', 'alone')\n>>> dup: ('canal', 'ready') ('can', 'already')\n>>> dup: ('card', 'anger') ('car', 'danger')\n>>> dup: ('card', 'ice') ('car', 'dice')\n>>> dup: ('card', 'inner') ('car', 'dinner')\n>>> dup: ('card', 'raw') ('car', 'draw')\n>>> dup: ('cart', 'able') ('car', 'table')\n>>> dup: ('cart', 'ask') ('car', 'task')\n>>> dup: ('cart', 'hat') ('car', 'that')\n>>> dup: ('cart', 'hen') ('car', 'then')\n>>> dup: ('cart', 'issue') ('car', 'tissue')\n>>> dup: ('cart', 'one') ('car', 'tone')\n>>> dup: ('cart', 'own') ('car', 'town')\n>>> dup: ('cart', 'rack') ('car', 'track')\n>>> dup: ('cart', 'rain') ('car', 'train')\n>>> dup: ('cart', 'win') ('car', 'twin')\n>>> dup: ('catch', 'air') ('cat', 'chair')\n>>> dup: ('erase', 'arch') ('era', 'search')\n>>> dup: ('fatal', 'arm') ('fat', 'alarm')\n>>> dup: ('fatal', 'one') ('fat', 'alone')\n>>> dup: ('fatal', 'ready') ('fat', 'already')\n>>> dup: ('feed', 'anger') ('fee', 'danger')\n>>> dup: ('feed', 'ice') ('fee', 'dice')\n>>> dup: ('feed', 'inner') ('fee', 'dinner')\n>>> dup: ('feed', 'raw') ('fee', 'draw')\n>>> dup: ('feel', 'earn') ('fee', 'learn')\n>>> dup: ('feel', 'end') ('fee', 'lend')\n>>> dup: ('gasp', 'act') ('gas', 'pact')\n>>> dup: ('gasp', 'age') ('gas', 'page')\n>>> dup: ('gasp', 'air') ('gas', 'pair')\n>>> dup: ('gasp', 'ill') ('gas', 'pill')\n>>> dup: ('gasp', 'raise') ('gas', 'praise')\n>>> dup: ('gasp', 'rice') ('gas', 'price')\n>>> dup: ('gasp', 'ride') ('gas', 'pride')\n>>> dup: ('gasp', 'roof') ('gas', 'proof')\n>>> dup: ('kite', 'merge') ('kit', 'emerge')\n>>> dup: ('kite', 'motion') ('kit', 'emotion')\n>>> dup: ('kite', 'state') ('kit', 'estate')\n>>> dup: ('lawn', 'arrow') ('law', 'narrow')\n>>> dup: ('lawn', 'either') ('law', 'neither')\n>>> dup: ('lawn', 'ice') ('law', 'nice')\n>>> dup: ('legal', 'arm') ('leg', 'alarm')\n>>> dup: ('legal', 'one') ('leg', 'alone')\n>>> dup: ('legal', 'ready') ('leg', 'already')\n>>> dup: ('seat', 'able') ('sea', 'table')\n>>> dup: ('seat', 'ask') ('sea', 'task')\n>>> dup: ('seat', 'hat') ('sea', 'that')\n>>> dup: ('seat', 'hen') ('sea', 'then')\n>>> dup: ('seat', 'issue') ('sea', 'tissue')\n>>> dup: ('seat', 'one') ('sea', 'tone')\n>>> dup: ('seat', 'own') ('sea', 'town')\n>>> dup: ('seat', 'rack') ('sea', 'track')\n>>> dup: ('seat', 'rain') ('sea', 'train')\n>>> dup: ('seat', 'win') ('sea', 'twin')\n>>> dup: ('skin', 'arrow') ('ski', 'narrow')\n>>> dup: ('skin', 'either') ('ski', 'neither')\n>>> dup: ('skin', 'ice') ('ski', 'nice')\n>>> dup: ('tent', 'able') ('ten', 'table')\n>>> dup: ('tent', 'ask') ('ten', 'task')\n>>> dup: ('tent', 'hat') ('ten', 'that')\n>>> dup: ('tent', 'hen') ('ten', 'then')\n>>> dup: ('tent', 'issue') ('ten', 'tissue')\n>>> dup: ('tent', 'one') ('ten', 'tone')\n>>> dup: ('tent', 'own') ('ten', 'town')\n>>> dup: ('tent', 'rack') ('ten', 'track')\n>>> dup: ('tent', 'rain') ('ten', 'train')\n>>> dup: ('tent', 'win') ('ten', 'twin')\n>>> dup: ('used', 'anger') ('use', 'danger')\n>>> dup: ('used', 'ice') ('use', 'dice')\n>>> dup: ('used', 'inner') ('use', 'dinner')\n>>> dup: ('used', 'raw') ('use', 'draw')\n>>> dup: ('wine', 'merge') ('win', 'emerge')\n>>> dup: ('wine', 'motion') ('win', 'emotion')\n>>> dup: ('wine', 'state') ('win', 'estate')\n>>> dup: ('wing', 'host') ('win', 'ghost')\n>>> dup: ('wing', 'love') ('win', 'glove')\n>>> dup: ('wing', 'old') ('win', 'gold')\n>>> dup: ('wing', 'own') ('win', 'gown')\n>>> dup: ('wing', 'race') ('win', 'grace')\n>>> dup: ('wing', 'rain') ('win', 'grain')\n>>> dup: ('wink', 'now') ('win', 'know')\n>>> dup: ('youth', 'under') ('you', 'thunder')\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n>\n> --\n> Best Regards / S pozdravom,\n>\n> Pavol \"stick\" Rusnak\n> Co-Founder, SatoshiLabs\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/e738bc94/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "bip39",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Billy Tetrud",
                "Pavol Rusnak",
                "Jeremy",
                "Erik Aronesty"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 19279
        }
    },
    {
        "title": "[bitcoin-dev] SASE Invoices",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2022-01-18T01:48:38",
                "message_text_only": "Devs,\n\nI was recently speaking with Casey R about some of the infrastructural\nproblems with addresses and felt it would be worth summarizing some notes\nfrom that conversation for y'all to consider more broadly.\n\nCurrently, when you generate (e.g., a Taproot address):\n\n- The key may or may not be a NUMS point\n- Script paths might still be required for safety (e.g. a backup federation)\n- There may be single use constructs (e.g. HTLC)\n- The amount required to be sent might be specific (e.g., HTLC or a vault)\n\nThese issues exist in other address types as well, and covenants (such as\nthe kinds enabled by TLUV, APO, or CTV) make exact amounts also important.\n\nAs such, it may make sense to specify a new type of Invoice that's a bit\nlike a SASE, a \"Self Addressed Stamped Envelope\". SASEs simplify mail\nprocessing because the processor just puts whatever was requested in the\nexact envelope you provided, and that's \"self authenticated\".\n\nA SASE Invoice for Bitcoin might look like an address *plus* a signature\ncovering that address and any metadata required for the payment to be\nconsidered valid. For example, I might make a TR key and specify that it is\nmy hot wallet and therefore permitted for only between 0 to 1 Bitcoin. Or I\nmight specify for a covenant containing address it should only have 0.1234\nBitcoin exactly. Other use cases might include \"good for one payment only\"\nor \"please do not use after xxxx date, contact to renew\". Some of these\nmight be perilous, so it's worth careful thought on what acceptable SASE\npolicies might be.\n\nBusinesses making payments might receive a SASE Invoice and save the SASE.\nThen, in the future, a SASE can be used e.g. in dispute mediation to show\nthat the payment sent corresponded to the one requested by that address.\nBusinesses could even give users unique codes to put into their SASE\ngenerator to bind the address for their own use / to ensure the usage right\nof the address isn't transferrable.\n\nif the top-level TR key is a NUMS point, and no signature can be produced\n(as might happen for a covenant), then it could be a NUMS point derived\nfrom the hash-to-curve of the SASE Invoice policy.\n\nSuch SASE Invoice standards would also go a long way towards\ncombating address reuse. If standard software does not produce reusable\nSASE Invoices, then it would be clear to users that they should generate a\nSASE with the expected amount per requested payment.\n\nA well designed SASE spec could also cover things like EPKs and derivation\npaths as well.\n\nPreviously, https://github.com/bitcoin/bips/blob/master/bip-0070.mediawiki\nwas designed in a similar problem space. A big part of SASE invoices would\nbe for it to be focused on generating fixed payment codes rather than\ninitiating an online protocol / complicated handshaking.\n\nCheers,\n\nJeremy\n\np.s.:\n\nThere's something that looks even *more* like a single use SASE where you\nmight use one of your existing UTXOs with anyonecanpay and single to pay to\nan output which has the funds requested + the funds in the output. a payer\npaying this transaction has no choice but to pay you the correct\namount/fees for the specific txn, and it clearly cannot be reused. This is\nquite bizarre though, but is noted here if anyone wants something even\ncloser to a physical SASE.\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220117/3ad89367/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "SASE Invoices",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 3538
        }
    },
    {
        "title": "[bitcoin-dev] Covenants and capabilities in the UTXO model",
        "thread_messages": [
            {
                "author": "Billy Tetrud",
                "date": "2022-01-18T15:10:33",
                "message_text_only": ">  Since scriptpubkeys/scriptsigs continue to run ephemerally at validation\ntime full turing completeness is much less dangerous than people fear.\n\nThe covenant proposals I've seen that might give bitcoin turing\ncompleteness require a turing complete process to be stepped such that each\nstep is a transaction paid for with a usual fee. This fact I think makes\nthe turing completeness a lot less scary. No single transaction would be\nturing complete, while a sequence of them could be. But importantly, each\ntransaction has a strictly limited runtime and every script could continue\nto have a calculable number of maximum runtime steps.\n\n> The main thing missing from what's expressed in transactions themselves\nis a coherent notion of a single parent of each output instead of the\nall-inputs-lead-to-all-outputs approach of transactions currently.\n\nI'm curious to hear more about specifically what you mean by this. I think\nthere are covenant proposals that do that. TLUV has the concept of\nspecifying which output should have a script that's \"modified\" in a\nparticular way. CTV basically specifies a specific output set. My own\nOP_CONSTRAINDESTINATION\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/cd/bip-constraindestination.md>\nalso specifies what outputs the value of the input is transferred to. Is\nthis what you mean?\n\n> It would also probably be a good idea to add in a bunch of special\npurpose opcodes for making coherent statements about transactions since in\nBitcoin they're a very complex and hard to parse format.\n\nWhat are some examples you're thinking of?\n\n> Once you start implementing complex general purpose functionality it\ntends to get very expensive very fast and is likely impractical unless\nthere's a way to compress or at least de-duplicate snippets of code which\nare repeated on chain.\n\nI like this idea. If there was a way to dedupe scripts in some way, it\ncould save a lot of bandwidth which would help bitcoin scale better. One\nthing we could do is have a specific set of pre-ordained script snippets\nthat are given a shorthand that's stored in the software and explicitly\nshouldn't be transmitted long-hand. That would help for very standard\nwidespread things. We could even add in a consensus rule where short-handed\nscripts pay for their expanded vbytes, not the vbytes of the compressed\nversion. This would mean the incentives wouldn't be changed by this\napproach.\n\nWe could also imagine a more dynamic approach, where nodes keep an index of\nscripts or script snippets in some way, and keep around ones that it sees\nmost often. I'm not sure how this would work, since a script can contain a\nlot of unique values and there's no clear way to split a script into\npieces. Perhaps script segments could be committed to the chain and nodes\ncould attempt to only store and reuse these paid-for segments, maybe only\nthe X most paid-for scripts (the scripts committed with the largest fee,\npotentially across multiple explicit standalone commitments). However, this\ndynamic approach would also have some scalability benefits, tho it would be\na bit more chaotic. Any node transmitting transactions would only need to\nsend the script segments when the node they're transmitting to requests\nthem. However, the extra script references also take up space, and so if\nthe ratio of how often the node has a script segment to how often they\ndon't is bad enough, this could a net negative scalability wise.\n\n> For a payment to someone to come with a rider where they could accept it\nand think their system was working properly for a while until you exercised\nsome kind of retroactive veto on new action or even clawback would\nobviously be unacceptable behavior.\n\nI definitely agree. A payment's covenant should be completely knowable to\nthe recipient, and recipients shouldn't accept random covenants they\nhaven't explicitly accepted on their own.\n\n> for payments to come with covenants but the recipient not even be able to\nparse them unless they're fully buying into that behavior is much more\nreasonable.\n\nThe recipient not being able to parse them? Couldn't that result in exactly\nthe situation above you said was not acceptable? The recipient must be able\nto know all the possibilities of the covenant or there might be some secret\nretroactive clawback in there waiting to bite them.\n\n\n\nOn Fri, Dec 31, 2021 at 6:41 PM Bram Cohen via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> There are a few different approaches to adding covenants and capabilities\n> to the UTXO model with varying tradeoffs. It turns out that it can be done\n> while making very few but not quite zero compromises to practices Bitcoin\n> has been following so far.\n>\n> First, the good news: Full support for both capabilities and covenants can\n> be added without changing the UTXO model whatsoever by adding some more\n> programmatic capabilities to the language and doing some programmatic\n> tricks. Since scriptpubkeys/scriptsigs continue to run ephemerally at\n> validation time full turing completeness is much less dangerous than people\n> fear. The main thing missing from what's expressed in transactions\n> themselves is a coherent notion of a single parent of each output instead\n> of the all-inputs-lead-to-all-outputs approach of transactions currently.\n> It would also probably be a good idea to add in a bunch of special purpose\n> opcodes for making coherent statements about transactions since in Bitcoin\n> they're a very complex and hard to parse format.\n>\n> Now for the controversial stuff. Once you start implementing complex\n> general purpose functionality it tends to get very expensive very fast and\n> is likely impractical unless there's a way to compress or at least\n> de-duplicate snippets of code which are repeated on chain. Currently\n> Bitcoin has a strong policy that deciding which transactions to let into a\n> block for maximum fee is a strictly linear optimization problem and while\n> it's possible to keep things mostly that way making it completely strict is\n> unlikely to workable. About as close as you can get is to make it so that\n> each block can reference code snippets in previous blocks for\n> deduplication, so at least the optimization is linear for each block by\n> itself.\n>\n> Having covenants and capabilities at all is controversial in and of\n> itself. With covenants the main issue is whether they're opt-in or opt-out.\n> For a payment to someone to come with a rider where they could accept it\n> and think their system was working properly for a while until you exercised\n> some kind of retroactive veto on new action or even clawback would\n> obviously be unacceptable behavior. But for payments to come with covenants\n> but the recipient not even be able to parse them unless they're fully\n> buying into that behavior is much more reasonable.\n>\n> The main issue which people have raised with capabilities is that if you\n> were to have colored coins whose value was substantially greater than the\n> chain they were tokenized on then that could potentially create a business\n> model for attacking the underlying chain. While this is a real concern\n> tokenized assets have been out for a while now and have never come close to\n> causing this to happen, so maybe people aren't so worried about it now.\n>\n> Given all the above caveats it turns out one weird trick is all you need\n> to support general purpose capabilities: for a UTXO to have a capability\n> its scriptpubkey asserts that its parent must either be the originator of\n> that capability or also conform to the same parent-asserting format. More\n> complex functionality such as supporting on-chain verifiable colored coins\n> can also be done but it follows the same pattern: Capabilities are\n> implemented as backwards pointing covenants.\n>\n> If you'd like to see a fleshed out implementation of these ideas (albeit\n> in a slightly different model) there's quite a bit of stuff on\n> chialisp.com\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/ac735de0/attachment-0001.html>"
            },
            {
                "author": "Bram Cohen",
                "date": "2022-01-18T17:16:25",
                "message_text_only": "On Tue, Jan 18, 2022 at 7:10 AM Billy Tetrud <billy.tetrud at gmail.com> wrote:\n\n> >  Since scriptpubkeys/scriptsigs continue to run ephemerally at\n> validation time full turing completeness is much less dangerous than people\n> fear.\n>\n> The covenant proposals I've seen that might give bitcoin turing\n> completeness require a turing complete process to be stepped such that each\n> step is a transaction paid for with a usual fee. This fact I think makes\n> the turing completeness a lot less scary. No single transaction would be\n> turing complete, while a sequence of them could be. But importantly, each\n> transaction has a strictly limited runtime and every script could continue\n> to have a calculable number of maximum runtime steps.\n>\n\nThis flows naturally out of the UTXO model. In ETH you don't know how much\ntransactions will cost in advance because things don't declare their state\nup front, but with all dependencies declared up front execution can be made\ncompletely deterministic.\n\n > It would also probably be a good idea to add in a bunch of special\npurpose opcodes for making coherent statements about transactions since in\nBitcoin they're a very complex and hard to parse format.\n\n>\n> What are some examples you're thinking of?\n>\n\nWhat's needed from a programming perspective is the ability to say 'assert\nthat my parent has a scriptpubkey of X'. That way you can, for example,\nhave a UTXO which only allows itself to be absorbed by a transaction also\ninvolving a UTXO with a particular capability ('pay to singleton' is a term\nfor this) and that capability can be enforced by the scriptpubkey asserting\nthat either its parent is the originator of it or that its parent also has\nthe same type of scriptpubkey. This allows capabilities to be added without\ngunking up on chain state with things other than UTXOs.\n\n\n\n>\n> > Once you start implementing complex general purpose functionality it\n> tends to get very expensive very fast and is likely impractical unless\n> there's a way to compress or at least de-duplicate snippets of code which\n> are repeated on chain.\n>\n> I like this idea. If there was a way to dedupe scripts in some way, it\n> could save a lot of bandwidth which would help bitcoin scale better. One\n> thing we could do is have a specific set of pre-ordained script snippets\n> that are given a shorthand that's stored in the software and explicitly\n> shouldn't be transmitted long-hand. That would help for very standard\n> widespread things. We could even add in a consensus rule where short-handed\n> scripts pay for their expanded vbytes, not the vbytes of the compressed\n> version. This would mean the incentives wouldn't be changed by this\n> approach.\n>\n\nOne approach is to allow references to old blocks so code snippets can be\npulled out of them. That avoids having to define the 'common sections' up\nfront. Charging for virtual vbytes unfortunately keeps smart functionality\nvery expensive and the point is to make it not so expensive.\n\n\n> > For a payment to someone to come with a rider where they could accept it\n> and think their system was working properly for a while until you exercised\n> some kind of retroactive veto on new action or even clawback would\n> obviously be unacceptable behavior.\n>\n> I definitely agree. A payment's covenant should be completely knowable to\n> the recipient, and recipients shouldn't accept random covenants they\n> haven't explicitly accepted on their own.\n>\n> > for payments to come with covenants but the recipient not even be able\n> to parse them unless they're fully buying into that behavior is much more\n> reasonable.\n>\n> The recipient not being able to parse them? Couldn't that result in\n> exactly the situation above you said was not acceptable? The recipient must\n> be able to know all the possibilities of the covenant or there might be\n> some secret retroactive clawback in there waiting to bite them.\n>\n\nNot sure what you're saying. If the recipient can't parse a UTXO the\ndefined behavior should be that they assume it's bricked.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/5d93153e/attachment-0001.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-01-19T02:24:47",
                "message_text_only": "> 'assert that my parent has a scriptpubkey of X'... That way you can, for\nexample, have a UTXO which only allows itself to be absorbed by a\ntransaction also involving a UTXO with a particular capability\n\nI'm not sure I fully follow. I usually think about covenants as having the\nreverse form, that a parent would assert \"my children must have a script of\nthe form XYZ\". Are you saying you want to be able to specify that a UTXO\ncan only be spent if the resulting outputs of that transaction all share\nthe same script? I see this page\n<https://chialisp.com/docs/puzzles/singletons/> but i don't understand how\nthose concepts relate to covenants.\n\n>  allow references to old blocks so code snippets can be pulled out of them\n\nNodes currently aren't required to keep around the whole blockchain, but\nyour proposal sounds like it would require them to. I think this could be\npretty detrimental to future scalability. Monero, for example, has a\nsituation where its UTXO set is the whole blockchain because you can't\ngenerally know what has been spent and what hasn't been. Allowing\nreferences to old blocks would pull in all this old block data into the\nUTXO set. So unless you're very careful about how or when you can reference\nold blocks, this could cause issues.\n\n> If the recipient can't parse a UTXO the defined behavior should be that\nthey assume it's bricked.\n\nI must have misunderstood you. I think that's the appropriate response: if\nyou don't know everything about how a UTXO sent \"to you\" can be spent, you\ncan't really treat it as yours.\n\n\nOn Tue, Jan 18, 2022 at 11:16 AM Bram Cohen <bram at chia.net> wrote:\n\n> On Tue, Jan 18, 2022 at 7:10 AM Billy Tetrud <billy.tetrud at gmail.com>\n> wrote:\n>\n>> >  Since scriptpubkeys/scriptsigs continue to run ephemerally at\n>> validation time full turing completeness is much less dangerous than people\n>> fear.\n>>\n>> The covenant proposals I've seen that might give bitcoin turing\n>> completeness require a turing complete process to be stepped such that each\n>> step is a transaction paid for with a usual fee. This fact I think makes\n>> the turing completeness a lot less scary. No single transaction would be\n>> turing complete, while a sequence of them could be. But importantly, each\n>> transaction has a strictly limited runtime and every script could continue\n>> to have a calculable number of maximum runtime steps.\n>>\n>\n> This flows naturally out of the UTXO model. In ETH you don't know how much\n> transactions will cost in advance because things don't declare their state\n> up front, but with all dependencies declared up front execution can be made\n> completely deterministic.\n>\n>  > It would also probably be a good idea to add in a bunch of special\n> purpose opcodes for making coherent statements about transactions since in\n> Bitcoin they're a very complex and hard to parse format.\n>\n>>\n>> What are some examples you're thinking of?\n>>\n>\n> What's needed from a programming perspective is the ability to say 'assert\n> that my parent has a scriptpubkey of X'. That way you can, for example,\n> have a UTXO which only allows itself to be absorbed by a transaction also\n> involving a UTXO with a particular capability ('pay to singleton' is a term\n> for this) and that capability can be enforced by the scriptpubkey asserting\n> that either its parent is the originator of it or that its parent also has\n> the same type of scriptpubkey. This allows capabilities to be added without\n> gunking up on chain state with things other than UTXOs.\n>\n>\n>\n>>\n>> > Once you start implementing complex general purpose functionality it\n>> tends to get very expensive very fast and is likely impractical unless\n>> there's a way to compress or at least de-duplicate snippets of code which\n>> are repeated on chain.\n>>\n>> I like this idea. If there was a way to dedupe scripts in some way, it\n>> could save a lot of bandwidth which would help bitcoin scale better. One\n>> thing we could do is have a specific set of pre-ordained script snippets\n>> that are given a shorthand that's stored in the software and explicitly\n>> shouldn't be transmitted long-hand. That would help for very standard\n>> widespread things. We could even add in a consensus rule where short-handed\n>> scripts pay for their expanded vbytes, not the vbytes of the compressed\n>> version. This would mean the incentives wouldn't be changed by this\n>> approach.\n>>\n>\n> One approach is to allow references to old blocks so code snippets can be\n> pulled out of them. That avoids having to define the 'common sections' up\n> front. Charging for virtual vbytes unfortunately keeps smart functionality\n> very expensive and the point is to make it not so expensive.\n>\n>\n>> > For a payment to someone to come with a rider where they could accept\n>> it and think their system was working properly for a while until you\n>> exercised some kind of retroactive veto on new action or even clawback\n>> would obviously be unacceptable behavior.\n>>\n>> I definitely agree. A payment's covenant should be completely knowable to\n>> the recipient, and recipients shouldn't accept random covenants they\n>> haven't explicitly accepted on their own.\n>>\n>> > for payments to come with covenants but the recipient not even be able\n>> to parse them unless they're fully buying into that behavior is much more\n>> reasonable.\n>>\n>> The recipient not being able to parse them? Couldn't that result in\n>> exactly the situation above you said was not acceptable? The recipient must\n>> be able to know all the possibilities of the covenant or there might be\n>> some secret retroactive clawback in there waiting to bite them.\n>>\n>\n> Not sure what you're saying. If the recipient can't parse a UTXO the\n> defined behavior should be that they assume it's bricked.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/b4029e1a/attachment-0001.html>"
            },
            {
                "author": "Bram Cohen",
                "date": "2022-01-20T19:23:30",
                "message_text_only": "On Tue, Jan 18, 2022 at 6:25 PM Billy Tetrud <billy.tetrud at gmail.com> wrote:\n\n> > 'assert that my parent has a scriptpubkey of X'... That way you can, for\n> example, have a UTXO which only allows itself to be absorbed by a\n> transaction also involving a UTXO with a particular capability\n>\n> I'm not sure I fully follow. I usually think about covenants as having the\n> reverse form, that a parent would assert \"my children must have a script of\n> the form XYZ\". Are you saying you want to be able to specify that a UTXO\n> can only be spent if the resulting outputs of that transaction all share\n> the same script? I see this page\n> <https://chialisp.com/docs/puzzles/singletons/> but i don't understand\n> how those concepts relate to covenants.\n>\n\nTwo concepts here. First of all Bitcoin doesn't have a strong single\nconcept of a 'parent', it just has transactions where all the parents lead\nto all the children. For this sort of trickery to work more information\nneeds to be added to specify which of the inputs is the parent of each of\nthe outputs.\n\nSecond what in practice happens is that a coin can check what its own id\nis, then verify the secure hash chain from its parent to itself so that it\nknows what the parent looked like. For a Singleton it can then rely on the\nfact that its ancestors enforced that they each only had one child to know\nthat it's the only descendant. In some sense this is like covenants which\npoint backwards in time although that information is already there in\nprinciple because of the secure hash chain but hard to parse.\n\n\n>\n> >  allow references to old blocks so code snippets can be pulled out of\n> them\n>\n> Nodes currently aren't required to keep around the whole blockchain, but\n> your proposal sounds like it would require them to. I think this could be\n> pretty detrimental to future scalability. Monero, for example, has a\n> situation where its UTXO set is the whole blockchain because you can't\n> generally know what has been spent and what hasn't been. Allowing\n> references to old blocks would pull in all this old block data into the\n> UTXO set. So unless you're very careful about how or when you can reference\n> old blocks, this could cause issues.\n>\n\nDon't full nodes by definition have to have the whole chain? This does make\npruned nodes difficult, but it could also have rules like you can only\npoint back so far.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220120/a3cb9768/attachment.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2022-01-21T02:22:15",
                "message_text_only": "On Thu, Jan 20, 2022 at 11:23:30AM -0800, Bram Cohen via bitcoin-dev wrote:\n> > Nodes currently aren't required to keep around the whole blockchain, but\n> > your proposal sounds like it would require them to. I think this could be\n> > pretty detrimental to future scalability. Monero, for example, has a\n> > situation where its UTXO set is the whole blockchain because you can't\n> > generally know what has been spent and what hasn't been. Allowing\n> > references to old blocks would pull in all this old block data into the\n> > UTXO set. So unless you're very careful about how or when you can reference\n> > old blocks, this could cause issues.\n> >\n> \n> Don't full nodes by definition have to have the whole chain? This does make\n> pruned nodes difficult, but it could also have rules like you can only\n> point back so far.\n\n\"you can only point back so far\" leads to transactions becoming invalid, which\nis something we've always strictly avoided because it can result in huge\nproblems during reorgs with transactions being unable to be included in a new\nchange. That's exactly why transaction expiry proposals have been shot down\nover and over again.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 833 bytes\nDesc: not available\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220120/33980dcf/attachment-0001.sig>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-01-21T17:32:27",
                "message_text_only": "> Bitcoin doesn't have a strong single concept of a 'parent'\n\nI'm using the term \"parent\" loosely in context here to mean a relationship\nwhere an input has constraints applied to an output (or outputs).\n\n>   verify the secure hash chain from its parent to itself so that it knows\nwhat the parent looked like\n\nI guess I just don't understand why you would want to do it this way. If\nyou send to an address that has such a reverse-looking script, you could\nbrick funds that came from the wrong parent. With the reverse mechanism,\nthe transaction creating the child, you can prevent this from happening by\ndefining the transaction creating such a child as invalid unless the child\nmatches the covenant in the parent.\n\n> \"you can only point back so far\" leads to transactions becoming invalid,\nwhich is something we've always strictly avoided because it can result in\nhuge problems during reorgs\n\nI'm surprised to hear you say that. I have tried to learn why valid\ntransactions that can become invalid is seen as such a problem. I've been\nunsuccessful in finding much information about this. I tried to document\nthe full extent of my understanding in my proposal here\n<https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/bbv/bip-beforeblockverify.md#reorg-safety>\nwhere\nI actually have a quote from you where you said you don't think this is a\nvalid concern. Did something change your mind? Or did I misinterpret you?\nWhat am I missing from that section I linked to?\n\nOn Thu, Jan 20, 2022 at 8:22 PM Peter Todd <pete at petertodd.org> wrote:\n\n> On Thu, Jan 20, 2022 at 11:23:30AM -0800, Bram Cohen via bitcoin-dev wrote:\n> > > Nodes currently aren't required to keep around the whole blockchain,\n> but\n> > > your proposal sounds like it would require them to. I think this could\n> be\n> > > pretty detrimental to future scalability. Monero, for example, has a\n> > > situation where its UTXO set is the whole blockchain because you can't\n> > > generally know what has been spent and what hasn't been. Allowing\n> > > references to old blocks would pull in all this old block data into the\n> > > UTXO set. So unless you're very careful about how or when you can\n> reference\n> > > old blocks, this could cause issues.\n> > >\n> >\n> > Don't full nodes by definition have to have the whole chain? This does\n> make\n> > pruned nodes difficult, but it could also have rules like you can only\n> > point back so far.\n>\n> \"you can only point back so far\" leads to transactions becoming invalid,\n> which\n> is something we've always strictly avoided because it can result in huge\n> problems during reorgs with transactions being unable to be included in a\n> new\n> change. That's exactly why transaction expiry proposals have been shot down\n> over and over again.\n>\n> --\n> https://petertodd.org 'peter'[:-1]@petertodd.org\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220121/cd11d734/attachment-0001.html>"
            },
            {
                "author": "Bram Cohen",
                "date": "2022-01-22T00:19:07",
                "message_text_only": "On Fri, Jan 21, 2022 at 9:32 AM Billy Tetrud <billy.tetrud at gmail.com> wrote:\n\n> > Bitcoin doesn't have a strong single concept of a 'parent'\n>\n> I'm using the term \"parent\" loosely in context here to mean a relationship\n> where an input has constraints applied to an output (or outputs).\n>\n\nYes and I'm using it more specifically to mean a single parent because the\ntricks for implementing capabilities I'm talking about don't work if you\ndon't have a way of talking about 'my parent' as an unambiguously defined\nsingle UTXO.\n\n\n>\n> >   verify the secure hash chain from its parent to itself so that it\n> knows what the parent looked like\n>\n> I guess I just don't understand why you would want to do it this way.\n>\n\nThe idea here is to optimize for adding as little to the UXTO model as\npossible and doing everything with Bitcoin script additions. Some optional\nmappings of inputs to outputs in a transaction seem to be necessary but\nbeyond that the current model can remain unchanged.\n\n\n> If you send to an address that has such a reverse-looking script, you\n> could brick funds that came from the wrong parent. With the reverse\n> mechanism, the transaction creating the child, you can prevent this from\n> happening by defining the transaction creating such a child as invalid\n> unless the child matches the covenant in the parent.\n>\n\nIf you want to pay to a singleton you don't do it by paying to some\nscriptpubkey which represents that singleton, you pay to a scriptpubkey\nwhich says 'I can be spent in any transaction which includes singleton X'\nand it does the validation of that other UTXO being the current incarnation\nof the singleton using the capabilities validation tricks I mentioned\nbefore.\n\n\n>\n> > \"you can only point back so far\" leads to transactions becoming invalid,\n> which is something we've always strictly avoided because it can result in\n> huge problems during reorgs\n>\n> I'm surprised to hear you say that. I have tried to learn why valid\n> transactions that can become invalid is seen as such a problem. I've been\n> unsuccessful in finding much information about this. I tried to document\n> the full extent of my understanding in my proposal here\n> <https://github.com/fresheneesz/bip-efficient-bitcoin-vaults/blob/main/bbv/bip-beforeblockverify.md#reorg-safety> where\n> I actually have a quote from you where you said you don't think this is a\n> valid concern. Did something change your mind? Or did I misinterpret you?\n> What am I missing from that section I linked to?\n>\n\nIt can be made so that if it goes past the time when the backpointer works\nthen the transaction is still valid but its vbytes goes up because the\nreferenced string needs to be repeated on the chain.\n\nI too am a bit on the fence about whether strict transaction\nmonotinicity is absolutely necessary. The most plausible violation of it to\nadd would be some kind of max height/age condition to go with the current\nmin height/age restrictions. What scares me about that isn't so much the\nability to replay reorgs getting messed up (those can be derailed by double\nspends anyway) but that either an intentional DOS or just a spike in\ntransaction fees could cause a deadline to be passed and something to be\nbricked for completely technical reasons having nothing to do with its\nintended logic. The same type of functionality can be hacked by having an\nallowed spend whose only condition is a min height/age so that if the time\nhas passed as long as someone isn't asleep at the wheel the transaction\nwill switch to a new state which disallows whatever it is that was supposed\nto be disallowed at that time.\n\nSince there isn't any compelling bit of functionality which needs to\nviolate monotinicity to be implemented I don't see any need to call for an\nend to it as a principle. It certainly makes mempool logic a lot simpler\nand more reliable.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220121/84c724d7/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Covenants and capabilities in the UTXO model",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Bram Cohen",
                "Billy Tetrud",
                "Peter Todd"
            ],
            "messages_count": 7,
            "total_messages_chars_count": 29504
        }
    },
    {
        "title": "[bitcoin-dev] [Bitcoin Advent Calendar] Decentralized Coordination Free Mining Pools",
        "thread_messages": [
            {
                "author": "Billy Tetrud",
                "date": "2022-01-18T18:15:15",
                "message_text_only": "@vjudeu\n>  If you introduce signing into mining, then you will have cases, where\nsomeone is powerful enough to produce blocks, but cannot, because signing\nis needed..  your consensus is no longer \"the heaviest chain\"\n\nYou've misunderstood my suggestion. This would not be possible with what I\nsuggested. Why do you think of the signature as some kind of barrier? What\nI was suggesting was that, when a miner participating in this protocol\nmines a valid bitcoin block, they then sign a superblock with a public key\nthat can be verified alongside the coinbase output (eg say with data in the\nfirst tapleaf of the output address). The block is still connected to\nsomething secured by PoW. You really made a lot of incorrect assumptions\nabout what I suggested.\n\nOn Thu, Dec 23, 2021 at 1:05 PM Jeremy <jlrubin at mit.edu> wrote:\n\n> If you introduce signing into mining, then you will have cases, where\n>> someone is powerful enough to produce blocks, but cannot, because signing\n>> is needed. Then, your consensus is no longer \"the heaviest chain\", but \"the\n>> heaviest signed chain\". That means, your computing power is no longer\n>> enough by itself (as today), because to make a block, you also need some\n>> kind of \"permission to mine\", because first you sign things (like in\n>> signet) and then you mine them. That kind of being \"reliably unreliable\"\n>> may be ok for testing, but not for the main network.\n>\n>\n> this is a really great point worth underscoring. this is the 'key\n> ingredient' for DCFMP, which is that there is no signing or other network\n> system that is 'in the way' of normal bitcoin mining, just an opt-in set of\n> rules for sharing the bounties of your block in exchange for future shares.\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/99bfa566/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Decentralized Coordination Free Mining Pools",
            "categories": [
                "bitcoin-dev",
                "Bitcoin Advent Calendar"
            ],
            "authors": [
                "Billy Tetrud"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1895
        }
    },
    {
        "title": "[bitcoin-dev] CTV BIP review",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2022-01-18T21:19:02",
                "message_text_only": "tl;dr: I don't think CTV is ready yet (but probably close), and in any case \ndefinitely not worth reviving BIP 9 with its known flaws and vulnerability.\n\nMy review here is based solely on the BIP, with no outside context (aside from \ncurrent consensus rules, of course). In particular, I have _not_ looked at \nthe CTV code proposed for Bitcoin Core yet.\n\n>Covenants are restrictions on how a coin may be spent beyond key ownership. \n\nnit: Poorly phrased. Even simple scripts can do that already.\n\n>A few examples are described below, which should be the subject of future \nnon-consensus standardization efforts.\n\nI would ideally like to see fully implemented BIPs for at least one of these \n(preferably the claimed CoinJoin improvements) before we move toward \nactivation.\n\n>Congestion Controlled Transactions\n\nI think this use case hasn't been fully thought through yet. It seems like it \nwould be desirable for this purpose, to allow any of the recipients to claim \ntheir portion of the payment without footing the fee for every other payment \nincluded in the batch. This is still a covenant-type solution, but one that \nBIP 119 cannot support as-is.\n\n(I realise this may be a known and accepted limitation, but I think it should \nbe addressed in the BIP)\n\n>Payment Channels\n\nWhy batch mere channel creation? Seems like the spending transaction should \nreally be the channel closing.\n\n>CHECKTEMPLATEVERIFY makes it much easier to set up trustless CoinJoins than \npreviously because participants agree on a single output which pays all \nparticipants, which will be lower fee than before.\n\nI don't see how. They still have to agree in advance on the outputs, and the \ntotal fees will logically be higher than not using CTV...?\n\n>Further Each participant doesn't need to know the totality of the outputs \ncommitted to by that output, they only have to verify their own sub-tree will \npay them.\n\nI don't see any way to do this with the provided implementation.\n\n>Deployment could be done via BIP 9 VersionBits deployed through Speedy Trial.\n\nHard NACK on this. BIP 9 at this point represents developers attempting to \ndisregard and impose their will over community consensus, as well as an \nattempt to force a miner veto backdoor/vulnerability on deployment. It should \nnever be used again.\n\nSpeedy Trial implemented with BIP 8 made sense* as a possible neutral \ncompromise between LOT=True and LOT=False (which could be deployed prior to \nor in parallel), but using BIP 9 would destroy this.\n\nAs with Taproot, any future deployments should use BIP 8 again, until a better \nsolution is developed. Reverting back to a known flawed and vulnerable \nactivation method should not be done, and it would be better not to deploy \nCTV at all at such an expense.\n\nThe fact that certain developers attempted to deploy a BIP 9 alternative \nactivation for Taproot against community consensus, and that even managed to \nget released as \"Bitcoin Core\", makes it all the more important that the \ncommunity firmly rejects any further action to force this regression.\n\n* it is my opinion a BIP 8 ST would be an okay compromise under those \ncircumstances; others do disagree that ST is acceptable at all\n\n> This ensures that for a given known input, the TXIDs can also be known ahead \nof time. Otherwise, CHECKTEMPLATEVERIFY would not be usable for Batched \nChannel Creation constructions as the redemption TXID could be malleated and \npre-signed transactions invalidated, unless the channels are built using an \nEltoo-like protocol.\n\nWhy is it a problem for them to use an Eltoo-like protocol?\n\nWhy not just commit to the txid itself if that's the goal?\n\n>P2SH is incompatible with CHECKTEMPLATEVERIFY \n\nMaybe the CTV opcode should only be defined/enforced within witness scripts?\n\n>nLockTime should generally be fixed to 0 (in the case of a payment tree, only \nthe *first* lock time is needed to prevent fee-sniping the root)\n\nYour \"Congestion Controlled Transactions\" example would only make sense with \nthe spending transaction much later than the \"root\", and so could benefit \nfrom fee sniping malleability. (In fact, in that example, it would be better \nnot to commit to locktime at all.)\n\n>In the CHECKTEMPLATEVERIFY approach, the covenants are severely restricted to \nsimple templates. The structure of CHECKTEMPLATEVERIFY template is such that \nthe outputs must be known exactly at the time of construction. Based on a \ndestructuring argument, it is only possible to create templates which expand \nin a finite number of steps.\n\nIt's not clear to me that this holds if OP_CAT or OP_SHA256STREAM get added.\n\n>For example, a exchange's hot wallet might use an address which can \nautomatically be moved to a cold storage address after a relative timeout.\n\nWouldn't it make more sense to just have a UTXO both cold+hot can spend, then \nthrow away the hot key?\n\n>In contrast to previous forks, OP_CHECKTEMPLATEVERIFY will not make scripts \nvalid for policy until the new rule is active.\n\nPolicy isn't validity, and cannot be dictated by BIPs (or anyone/anything, for \nthat matter).\n\nLuke"
            },
            {
                "author": "eric at voskuil.org",
                "date": "2022-01-18T22:02:24",
                "message_text_only": "I won't comment on CTV at this point, but these comments on BIP9 and BIP8\ndeserve a response, given the intense obfuscation below.\n\nThe only material distinction between BIP9 and BIP8 is that the latter may\nactivate without signaled support of hash power enforcement.\n\nAs unenforced soft forks are not \"backward compatible\" they produce a chain\nsplit. It was for this reason alone that BIP8 never gained sufficient\nsupport.\n\nTaproot activation was in no way a compromise between enforced and\nunenforced activation. Unenforced activation was wholly rejected.\n\n> BIP 9 at this point represents developers attempting to disregard and\nimpose their will over community consensus, as well as an attempt to force a\nminer veto backdoor/vulnerability on deployment. It should never be used\nagain.\"\n\nThis appears to be the start of another marketing campaign, an attempt to\nreclaim Taproot activation as some sort of \"win\" over the \"miner backdoor\".\nThe same sort of misleading campaign was waged in the wake of segwit, and\nled directly to the conflict around Taproot activation.\n\nThe differences between ST and BIP9 are inconsequential in this regard. The\ncriticism you are making of BIP9 above applies equally to ST.\n\n> As with Taproot, any future deployments should use BIP 8 again\n\nThis is one of the most misleading statements I've seen here. It's not\ntechnically a lie, because it states what \"should\" happen. But it is clearly\nintended to lead people to believe that BIP8 was actually used (\"again\") -\nit was not. ST was some technical tweaks to BIP9.\n\nI am making no statement whatsoever on what \"should\" happen. My interest is\nin providing accurate information so that people can make informed\ndecisions.\n\nThe outright deception around this one topic has led to significant\nunnecessary conflict in the community. Make your argument, but make it\nhonestly.\n\ne\n\n> -----Original Message-----\n> From: bitcoin-dev <bitcoin-dev-bounces at lists.linuxfoundation.org> On\nBehalf\n> Of Luke Dashjr via bitcoin-dev\n> Sent: Tuesday, January 18, 2022 1:19 PM\n> To: bitcoin-dev at lists.linuxfoundation.org\n> Subject: [bitcoin-dev] CTV BIP review\n> \n> tl;dr: I don't think CTV is ready yet (but probably close), and in any\ncase\n> definitely not worth reviving BIP 9 with its known flaws and\nvulnerability.\n...\n> >Deployment could be done via BIP 9 VersionBits deployed through Speedy\n> Trial.\n> \n> Hard NACK on this. BIP 9 at this point represents developers attempting to\n> disregard and impose their will over community consensus, as well as an\n> attempt to force a miner veto backdoor/vulnerability on deployment. It\n> should never be used again.\n> \n> Speedy Trial implemented with BIP 8 made sense* as a possible neutral\n> compromise between LOT=True and LOT=False (which could be deployed\n> prior to or in parallel), but using BIP 9 would destroy this.\n> \n> As with Taproot, any future deployments should use BIP 8 again, until a\nbetter\n> solution is developed. Reverting back to a known flawed and vulnerable\n> activation method should not be done, and it would be better not to deploy\n> CTV at all at such an expense.\n> \n> The fact that certain developers attempted to deploy a BIP 9 alternative\n> activation for Taproot against community consensus, and that even managed\n> to get released as \"Bitcoin Core\", makes it all the more important that\nthe\n> community firmly rejects any further action to force this regression.\n> \n> * it is my opinion a BIP 8 ST would be an okay compromise under those\n> circumstances; others do disagree that ST is acceptable at all"
            },
            {
                "author": "Luke Dashjr",
                "date": "2022-01-18T22:09:45",
                "message_text_only": "On Tuesday 18 January 2022 22:02:24 eric at voskuil.org wrote:\n> The only material distinction between BIP9 and BIP8 is that the latter may\n> activate without signaled support of hash power enforcement.\n>\n> As unenforced soft forks are not \"backward compatible\" they produce a chain\n> split.\n\nEnforcement of the Bitcoin consensus protocol is by users, not miners.\n\nSoftforks never produce a chain split. Miners can, and might try to do it to \ncause disruption in retaliation, but the softfork itself does not.\n\n> It was for this reason alone that BIP8 never gained sufficient \n> support.\n\nBIP 8 in fact achieved consensus for Taproot activation.\n\n> This is one of the most misleading statements I've seen here. It's not\n> technically a lie, because it states what \"should\" happen. But it is\n> clearly intended to lead people to believe that BIP8 was actually used\n> (\"again\") - it was not. ST was some technical tweaks to BIP9.\n\nBIP 8 was used to activate Taproot.\n\n> The outright deception around this one topic has led to significant\n> unnecessary conflict in the community. Make your argument, but make it\n> honestly.\n\nYou are the one attempting to deceive here.\n\nLuke"
            },
            {
                "author": "eric at voskuil.org",
                "date": "2022-01-18T23:00:27",
                "message_text_only": "> -----Original Message-----\n> From: Luke Dashjr <luke at dashjr.org>\n> Sent: Tuesday, January 18, 2022 2:10 PM\n> To: eric at voskuil.org\n> Cc: 'Bitcoin Protocol Discussion' <bitcoin-dev at lists.linuxfoundation.org>\n> Subject: Re: [bitcoin-dev] CTV BIP review\n> \n> On Tuesday 18 January 2022 22:02:24 eric at voskuil.org wrote:\n> > The only material distinction between BIP9 and BIP8 is that the latter\n> > may activate without signaled support of hash power enforcement.\n> >\n> > As unenforced soft forks are not \"backward compatible\" they produce a\n> > chain split.\n> \n> Enforcement of the Bitcoin consensus protocol is by users, not miners.\n\nGiven that I stated \"hash power enforcement\" it is quite clear that this is\nin fact only produced by mining. You are misrepresenting my statement to\nmake an emotional appeal. Without \"hash power enforcement\", a soft fork is\nNOT backward compatible.\n\n\"[enforcement of] consensus protocol\" is of course by merchants, but that is\nnot the question at hand. The question is explicitly compatibility. Anyone\ncan activate a soft fork at any time, but without \"hash power enforcement\"\nsoft forks are NOT backward compatible.\n\n> Softforks never produce a chain split. Miners can, and might try to do it\nto cause disruption in retaliation, but the softfork itself does not.\n\nMaybe you are trying to split hairs given the fact that blocks are produced\nonly by miners, so only miners can \"cause\" a split.\n\nBut through not intention (\"disruption in retaliation\") whatsoever by\nmining, a soft fork will result in those activating the rule being split off\nthe original chain unless majority hash power enforces the rule. The fact\nthat doing nothing apart from deploying the rule will result in a split is\nthe very definition of NOT compatible.\n\nI assume you will argue that the original chain is not \"valid\" and therefore\nirrelevant (as if no chain split occurred). But again the point is about\ncompatibility. The appearance of multiple chains, which appear valid\naccording to either the previous or new rules, is obviously the\nincompatibility.\n\nI shouldn't have to point this out, but observed chain splits have occurred\nin more the one large scale soft fork deployment. These splits have only\nbeen resolved through hash power enforcement. In 2010 it took 51 blocks\nbefore the current chain took the lead. In 2012 minority chains persisted\nfor months. The deployment of soft forks caused these splits, NOT the\nactions of miners. And unless majority hash power eventually enforces it,\nthe soft fork branch necessarily dies.\n\n> > It was for this reason alone that BIP8 never gained sufficient\n> > support.\n> \n> BIP 8 in fact achieved consensus for Taproot activation.\n\nPlease define \"achieved consensus\", because by any definition I can imagine,\nthis is simply untrue.\n\n> > This is one of the most misleading statements I've seen here. It's not\n> > technically a lie, because it states what \"should\" happen. But it is\n> > clearly intended to lead people to believe that BIP8 was actually used\n> > (\"again\") - it was not. ST was some technical tweaks to BIP9.\n> \n> BIP 8 was used to activate Taproot.\n\nNo, it wasn't. I find it hard to imaging how you rationalize such grossly\nmisleading statements.\n\n> > The outright deception around this one topic has led to significant\n> > unnecessary conflict in the community. Make your argument, but make it\n> > honestly.\n> \n> You are the one attempting to deceive here.\n\nThat is for others to decide. I appreciate your responses above, since they\ncertainly help clarify what is happening here.\n\ne"
            },
            {
                "author": "Michael Folkson",
                "date": "2022-01-19T12:02:18",
                "message_text_only": "Eric, Luke\n\nCan I request that you don't discuss activation methods for future soft forks on a thread for CTV BIP review? I (and a number of others [0]) do not support an upcoming activation attempt of standalone OP_CTV. If you want to discuss activation methods for soft forks generally it would be much better if you set up a separate thread. OP_CTV is not the only current soft fork proposal and there will likely be more.\n\nThe activation discussion for Taproot was deliberately kept separate from the review of the Taproot BIPs and implementation. It only commenced once there was overwhelming community consensus for the soft fork to be activated (months after in fact). Though you are free to discuss whatever topics you wish (obviously) discussing soft fork activation methods on a OP_CTV thread might give the mistaken impression that OP_CTV is the next soft fork to be activated which is mere speculation at this point. In an ideal world the promoters of OP_CTV would follow the strong precedent set by the authors and contributors to the Taproot BIPs but regrettably that seems to have gone out the window at this point.\n\nThanks\nMichael\n\n[0]: https://gist.github.com/michaelfolkson/352a503f4f9fc5de89af528d86a1b718\n--\nMichael Folkson\nEmail: michaelfolkson at protonmail.com\nKeybase: michaelfolkson\nPGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n\nOn Tuesday, January 18th, 2022 at 11:00 PM, Eric Voskuil via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> -----Original Message-----\n>\n> From: Luke Dashjr luke at dashjr.org\n>\n> Sent: Tuesday, January 18, 2022 2:10 PM\n>\n> To: eric at voskuil.org\n>\n> Cc: 'Bitcoin Protocol Discussion' bitcoin-dev at lists.linuxfoundation.org\n>\n> Subject: Re: [bitcoin-dev] CTV BIP review\n>\n> On Tuesday 18 January 2022 22:02:24 eric at voskuil.org wrote:\n>\n> > The only material distinction between BIP9 and BIP8 is that the latter\n> >\n> > may activate without signaled support of hash power enforcement.\n> >\n> > As unenforced soft forks are not \"backward compatible\" they produce a\n> >\n> > chain split.\n>\n> Enforcement of the Bitcoin consensus protocol is by users, not miners.\n\nGiven that I stated \"hash power enforcement\" it is quite clear that this is\n\nin fact only produced by mining. You are misrepresenting my statement to\n\nmake an emotional appeal. Without \"hash power enforcement\", a soft fork is\n\nNOT backward compatible.\n\n\"[enforcement of] consensus protocol\" is of course by merchants, but that is\n\nnot the question at hand. The question is explicitly compatibility. Anyone\n\ncan activate a soft fork at any time, but without \"hash power enforcement\"\n\nsoft forks are NOT backward compatible.\n\n> Softforks never produce a chain split. Miners can, and might try to do it\n\nto cause disruption in retaliation, but the softfork itself does not.\n\nMaybe you are trying to split hairs given the fact that blocks are produced\n\nonly by miners, so only miners can \"cause\" a split.\n\nBut through not intention (\"disruption in retaliation\") whatsoever by\n\nmining, a soft fork will result in those activating the rule being split off\n\nthe original chain unless majority hash power enforces the rule. The fact\n\nthat doing nothing apart from deploying the rule will result in a split is\n\nthe very definition of NOT compatible.\n\nI assume you will argue that the original chain is not \"valid\" and therefore\n\nirrelevant (as if no chain split occurred). But again the point is about\n\ncompatibility. The appearance of multiple chains, which appear valid\n\naccording to either the previous or new rules, is obviously the\n\nincompatibility.\n\nI shouldn't have to point this out, but observed chain splits have occurred\n\nin more the one large scale soft fork deployment. These splits have only\n\nbeen resolved through hash power enforcement. In 2010 it took 51 blocks\n\nbefore the current chain took the lead. In 2012 minority chains persisted\n\nfor months. The deployment of soft forks caused these splits, NOT the\n\nactions of miners. And unless majority hash power eventually enforces it,\n\nthe soft fork branch necessarily dies.\n\n> > It was for this reason alone that BIP8 never gained sufficient\n> >\n> > support.\n>\n> BIP 8 in fact achieved consensus for Taproot activation.\n\nPlease define \"achieved consensus\", because by any definition I can imagine,\n\nthis is simply untrue.\n\n> > This is one of the most misleading statements I've seen here. It's not\n> >\n> > technically a lie, because it states what \"should\" happen. But it is\n> >\n> > clearly intended to lead people to believe that BIP8 was actually used\n> >\n> > (\"again\") - it was not. ST was some technical tweaks to BIP9.\n>\n> BIP 8 was used to activate Taproot.\n\nNo, it wasn't. I find it hard to imaging how you rationalize such grossly\n\nmisleading statements.\n\n> > The outright deception around this one topic has led to significant\n> >\n> > unnecessary conflict in the community. Make your argument, but make it\n> >\n> > honestly.\n>\n> You are the one attempting to deceive here.\n\nThat is for others to decide. I appreciate your responses above, since they\n\ncertainly help clarify what is happening here.\n\ne\n\nbitcoin-dev mailing list\n\nbitcoin-dev at lists.linuxfoundation.org\n\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-01-20T15:23:09",
                "message_text_only": "I'm curious to hear clarification on most of Luke's non-activation related\ncomments.\n\n> I would ideally like to see fully implemented BIPs for at least one of\nthese\n\nWhile that would be interesting, I think that's a heavy burden to be placed\non this BIP. More in depth exploration would be helpful, but a fully\nimplemented BIP I think is more than necessary.\n\n> Why is it a problem for them to use an Eltoo-like protocol?\n\nI think he was saying it is a problem *unless* its an eltoo-like protocol.\nWhy I'm not sure. Maybe you can clarify Jeremy?\n\n> It's not clear to me that this holds if OP_CAT or OP_SHA256STREAM get\nadded.\n\nEven were these opcodes to be implemented in bitcoin, a script writer could\nchoose to not use them, making it still possible to use CTV to create\ncovenant chains with a finite number of steps.\n\n>  w.r.t. the language cleanups... the legal definition of covenant ... I\ndo think things like CLTV/CSV are covenants\n\nMaybe it would be useful to specify that these are \"child covenants\" or\n\"inherited covenants\" or something like that, since unlike things like\nCLTV, CTV and similar proposed opcodes place restrictions on the child\noutput of the output containing the opcode call, which is the interesting\nunique behavior. Tho I don't think we need to be bound to the legal or\ndictionary definition in usage of the word covenant in the realm of bitcoin\n- its gonna have its own definition in this context anyway.\n\nThank you Eric for pointing out the factual errors in LukeJr's mention and\nimplications around BIP8. The fact is that the ST pull request was\ndescribed as \"BIP9-based\" <https://github.com/bitcoin/bitcoin/pull/21377>.\nTBH BIP8 is also BIP9 based, and ST is its own thing that's neither BIP8\nnor BIP9, so characterization one way or another is moot IMO. In any case,\nI also agree with Michael that this isn't the place to have a long\ndiscussion about activation method. That discussion should be kept\nseparate. I'd go so far to say that BIPs should not advocate for any\nparticular activation method, but should only go so far as to mention what\ntypes of activation methods are possible (if some types aren't possible for\nsome reason). Separation of concerns would be very useful on that front\nto reduce noise in conversations.\n\nThanks,\nBT\n\n\nOn Wed, Jan 19, 2022 at 6:37 AM Michael Folkson via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Eric, Luke\n>\n> Can I request that you don't discuss activation methods for future soft\n> forks on a thread for CTV BIP review? I (and a number of others [0]) do not\n> support an upcoming activation attempt of standalone OP_CTV. If you want to\n> discuss activation methods for soft forks generally it would be much better\n> if you set up a separate thread. OP_CTV is not the only current soft fork\n> proposal and there will likely be more.\n>\n> The activation discussion for Taproot was deliberately kept separate from\n> the review of the Taproot BIPs and implementation. It only commenced once\n> there was overwhelming community consensus for the soft fork to be\n> activated (months after in fact). Though you are free to discuss whatever\n> topics you wish (obviously) discussing soft fork activation methods on a\n> OP_CTV thread might give the mistaken impression that OP_CTV is the next\n> soft fork to be activated which is mere speculation at this point. In an\n> ideal world the promoters of OP_CTV would follow the strong precedent set\n> by the authors and contributors to the Taproot BIPs but regrettably that\n> seems to have gone out the window at this point.\n>\n> Thanks\n> Michael\n>\n> [0]:\n> https://gist.github.com/michaelfolkson/352a503f4f9fc5de89af528d86a1b718\n> --\n> Michael Folkson\n> Email: michaelfolkson at protonmail.com\n> Keybase: michaelfolkson\n> PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>\n> On Tuesday, January 18th, 2022 at 11:00 PM, Eric Voskuil via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> > -----Original Message-----\n> >\n> > From: Luke Dashjr luke at dashjr.org\n> >\n> > Sent: Tuesday, January 18, 2022 2:10 PM\n> >\n> > To: eric at voskuil.org\n> >\n> > Cc: 'Bitcoin Protocol Discussion' bitcoin-dev at lists.linuxfoundation.org\n> >\n> > Subject: Re: [bitcoin-dev] CTV BIP review\n> >\n> > On Tuesday 18 January 2022 22:02:24 eric at voskuil.org wrote:\n> >\n> > > The only material distinction between BIP9 and BIP8 is that the latter\n> > >\n> > > may activate without signaled support of hash power enforcement.\n> > >\n> > > As unenforced soft forks are not \"backward compatible\" they produce a\n> > >\n> > > chain split.\n> >\n> > Enforcement of the Bitcoin consensus protocol is by users, not miners.\n>\n> Given that I stated \"hash power enforcement\" it is quite clear that this is\n>\n> in fact only produced by mining. You are misrepresenting my statement to\n>\n> make an emotional appeal. Without \"hash power enforcement\", a soft fork is\n>\n> NOT backward compatible.\n>\n> \"[enforcement of] consensus protocol\" is of course by merchants, but that\n> is\n>\n> not the question at hand. The question is explicitly compatibility. Anyone\n>\n> can activate a soft fork at any time, but without \"hash power enforcement\"\n>\n> soft forks are NOT backward compatible.\n>\n> > Softforks never produce a chain split. Miners can, and might try to do it\n>\n> to cause disruption in retaliation, but the softfork itself does not.\n>\n> Maybe you are trying to split hairs given the fact that blocks are produced\n>\n> only by miners, so only miners can \"cause\" a split.\n>\n> But through not intention (\"disruption in retaliation\") whatsoever by\n>\n> mining, a soft fork will result in those activating the rule being split\n> off\n>\n> the original chain unless majority hash power enforces the rule. The fact\n>\n> that doing nothing apart from deploying the rule will result in a split is\n>\n> the very definition of NOT compatible.\n>\n> I assume you will argue that the original chain is not \"valid\" and\n> therefore\n>\n> irrelevant (as if no chain split occurred). But again the point is about\n>\n> compatibility. The appearance of multiple chains, which appear valid\n>\n> according to either the previous or new rules, is obviously the\n>\n> incompatibility.\n>\n> I shouldn't have to point this out, but observed chain splits have occurred\n>\n> in more the one large scale soft fork deployment. These splits have only\n>\n> been resolved through hash power enforcement. In 2010 it took 51 blocks\n>\n> before the current chain took the lead. In 2012 minority chains persisted\n>\n> for months. The deployment of soft forks caused these splits, NOT the\n>\n> actions of miners. And unless majority hash power eventually enforces it,\n>\n> the soft fork branch necessarily dies.\n>\n> > > It was for this reason alone that BIP8 never gained sufficient\n> > >\n> > > support.\n> >\n> > BIP 8 in fact achieved consensus for Taproot activation.\n>\n> Please define \"achieved consensus\", because by any definition I can\n> imagine,\n>\n> this is simply untrue.\n>\n> > > This is one of the most misleading statements I've seen here. It's not\n> > >\n> > > technically a lie, because it states what \"should\" happen. But it is\n> > >\n> > > clearly intended to lead people to believe that BIP8 was actually used\n> > >\n> > > (\"again\") - it was not. ST was some technical tweaks to BIP9.\n> >\n> > BIP 8 was used to activate Taproot.\n>\n> No, it wasn't. I find it hard to imaging how you rationalize such grossly\n>\n> misleading statements.\n>\n> > > The outright deception around this one topic has led to significant\n> > >\n> > > unnecessary conflict in the community. Make your argument, but make it\n> > >\n> > > honestly.\n> >\n> > You are the one attempting to deceive here.\n>\n> That is for others to decide. I appreciate your responses above, since they\n>\n> certainly help clarify what is happening here.\n>\n> e\n>\n> bitcoin-dev mailing list\n>\n> bitcoin-dev at lists.linuxfoundation.org\n>\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220120/0a497b07/attachment-0001.html>"
            },
            {
                "author": "eric at voskuil.org",
                "date": "2022-01-20T22:03:14",
                "message_text_only": "> BIP8 is also BIP9 based, and ST is its own thing that's neither BIP8 nor BIP9, so characterization one way or another is moot IMO.\n\n \n\nFor a selective definition of \u201cbased\u201d you can draw any conclusion you desire. However I was very clear, as was Luke, and the history on this issue is equally clear, that the *only* material distinction (and the one that we are discussing) is activation with or without majority hash power support. BIP9/ST requires this support, BIP8 does not. The characterization is not moot. It is the central issue and always has been. There was no compromise on this question made in Taproot.\n\n \n\ne\n\n \n\nFrom: Billy Tetrud <billy.tetrud at gmail.com> \nSent: Thursday, January 20, 2022 7:23 AM\n\n\n\nThank you Eric for pointing out the factual errors in LukeJr's mention and implications around BIP8. The fact is that the ST pull request was described as  <https://github.com/bitcoin/bitcoin/pull/21377> \"BIP9-based\". TBH BIP8 is also BIP9 based, and ST is its own thing that's neither BIP8 nor BIP9, so characterization one way or another is moot IMO. In any case, I also agree with Michael that this isn't the place to have a long discussion about activation method. That discussion should be kept separate. I'd go so far to say that BIPs should not advocate for any particular activation method, but should only go so far as to mention what types of activation methods are possible (if some types aren't possible for some reason). Separation of concerns would be very useful on that front to reduce noise in conversations.\n\n \n\nThanks,\n\nBT\n\n \n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220120/05477ab0/attachment.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-01-21T17:36:13",
                "message_text_only": ">  the **only** material distinction (and the one that we are discussing)\nis activation with or without majority hash power support\n\nI agree that characterization specifically is not moot. But its also\northogonal to the topic of the CTV opcode itself.\n\nOn Thu, Jan 20, 2022 at 4:03 PM <eric at voskuil.org> wrote:\n\n> > BIP8 is also BIP9 based, and ST is its own thing that's neither BIP8\n> nor BIP9, so characterization one way or another is moot IMO.\n>\n>\n>\n> For a selective definition of \u201cbased\u201d you can draw any conclusion you\n> desire. However I was very clear, as was Luke, and the history on this\n> issue is equally clear, that the **only** material distinction (and the\n> one that we are discussing) is activation with or without majority hash\n> power support. BIP9/ST requires this support, BIP8 does not. The\n> characterization is not moot. It is the central issue and always has been.\n> There was no compromise on this question made in Taproot.\n>\n>\n>\n> e\n>\n>\n>\n> *From:* Billy Tetrud <billy.tetrud at gmail.com>\n> *Sent:* Thursday, January 20, 2022 7:23 AM\n>\n> Thank you Eric for pointing out the factual errors in LukeJr's mention and\n> implications around BIP8. The fact is that the ST pull request was\n> described as \"BIP9-based\" <https://github.com/bitcoin/bitcoin/pull/21377>.\n> TBH BIP8 is also BIP9 based, and ST is its own thing that's neither BIP8\n> nor BIP9, so characterization one way or another is moot IMO. In any case,\n> I also agree with Michael that this isn't the place to have a long\n> discussion about activation method. That discussion should be kept\n> separate. I'd go so far to say that BIPs should not advocate for any\n> particular activation method, but should only go so far as to mention what\n> types of activation methods are possible (if some types aren't possible for\n> some reason). Separation of concerns would be very useful on that front\n> to reduce noise in conversations.\n>\n>\n>\n> Thanks,\n>\n> BT\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220121/67f2c1ed/attachment-0001.html>"
            },
            {
                "author": "Prayank",
                "date": "2022-01-18T22:20:45",
                "message_text_only": "Hi Luke,\n\nThis is the first competent review for CTV based on my understanding. I would not mention controversial things in this email but nobody cares about scammers and we will review everything irrespective of personal or legal attacks on developers because some people are prepared for it and capable, competent and healthy.\n\n> nit: Poorly phrased. Even simple scripts can do that already.\n\nAgree\n\n> I would ideally like to see fully implemented BIPs for at least one of these (preferably the claimed CoinJoin improvements) before we move toward activation.\n\nAgree\n\n> Hard NACK on this. BIP 9 at this point represents developers attempting to disregard and impose their will over community consensus, as well as an attempt to force a miner veto backdoor/vulnerability on deployment. It should never be used again.\n\nAgree\n\nOther technical comments on BIP are appreciated however they would be better answered by Jeremy at this point or other as I am still researching and not confident to comment.\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/47a7823e/attachment.html>"
            },
            {
                "author": "Jeremy",
                "date": "2022-01-18T23:54:21",
                "message_text_only": "Thanks for the detailed review.\n\nI'll withhold comment around activation logic and leave that for others to\ndiscuss.\n\nw.r.t. the language cleanups I'll make a PR that (I hope) clears up the\nsmall nits later today or tomorrow. Some of it's kind of annoying because\nthe legal definition of covenant is \"A formal agreement or promise, usually\nincluded in a contract or deed, to do or not do a particular act; a compact\nor stipulation made in writing or by parol.\" so I do think things like\nCLTV/CSV are covenants since it's a binding promise to not spend before a\ncertain time... it might be out of scope for the BIP to fully define these\nterms because it doesn't really matter what a covenant could be as much as\nit matters what CTV is specifically.\n\nOn the topic of drafting BIPs for specific use cases, I agree that would be\nvaluable and can consider it.\n\nHowever, I'm a bit skeptical of that approach overall as I don't\nnecessarily think that the applications *must be* standard, and I view BIPs\nas primarily for standardization whereas part of the flexibility of\nCTV/Sapio allows users to figure out how they want to use it.\n\nE.g., we do not yet have a BIP for MuSig or even Multisig in Taproot,\nalthough there are some papers and example implementations but nothing\nformal yet\nhttps://bitcoin.stackexchange.com/questions/111666/support-for-taproot-multisig-descriptors).\nPerhaps this is an opportunity for CTV to lead on the amount of formal\napplication designs available before 'release'.\n\nAs a starting point, maybe you could review some of the application focused\nposts in rubin.io/advent21 and let me know where they seem deficient?\n\nAlso a BIP describing how to build something like Sapio (and less so Sapio\nitself, since it's still early days for that) might help for folks to be\nable to think through how to compile to CTV contracts? But again, I'm\nskeptical of the value of a BIP v.s. the documentation and examples\navailable in the code and https://learn.sapio-lang.org.\n\nI think it's an interesting discussion too because as we've just seen the\nLN ecosystem start the BLIP standards, would an example of non-interactive\nchannels be best written up as a BIP, a BLIP, or a descriptive blog/mailing\nlist post?\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Tue, Jan 18, 2022 at 1:19 PM Luke Dashjr via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> tl;dr: I don't think CTV is ready yet (but probably close), and in any\n> case\n> definitely not worth reviving BIP 9 with its known flaws and vulnerability.\n>\n> My review here is based solely on the BIP, with no outside context (aside\n> from\n> current consensus rules, of course). In particular, I have _not_ looked at\n> the CTV code proposed for Bitcoin Core yet.\n>\n> >Covenants are restrictions on how a coin may be spent beyond key\n> ownership.\n>\n> nit: Poorly phrased. Even simple scripts can do that already.\n>\n> >A few examples are described below, which should be the subject of future\n> non-consensus standardization efforts.\n>\n> I would ideally like to see fully implemented BIPs for at least one of\n> these\n> (preferably the claimed CoinJoin improvements) before we move toward\n> activation.\n>\n> >Congestion Controlled Transactions\n>\n> I think this use case hasn't been fully thought through yet. It seems like\n> it\n> would be desirable for this purpose, to allow any of the recipients to\n> claim\n> their portion of the payment without footing the fee for every other\n> payment\n> included in the batch. This is still a covenant-type solution, but one\n> that\n> BIP 119 cannot support as-is.\n>\n> (I realise this may be a known and accepted limitation, but I think it\n> should\n> be addressed in the BIP)\n>\n> >Payment Channels\n>\n> Why batch mere channel creation? Seems like the spending transaction\n> should\n> really be the channel closing.\n>\n> >CHECKTEMPLATEVERIFY makes it much easier to set up trustless CoinJoins\n> than\n> previously because participants agree on a single output which pays all\n> participants, which will be lower fee than before.\n>\n> I don't see how. They still have to agree in advance on the outputs, and\n> the\n> total fees will logically be higher than not using CTV...?\n>\n> >Further Each participant doesn't need to know the totality of the outputs\n> committed to by that output, they only have to verify their own sub-tree\n> will\n> pay them.\n>\n> I don't see any way to do this with the provided implementation.\n>\n> >Deployment could be done via BIP 9 VersionBits deployed through Speedy\n> Trial.\n>\n> Hard NACK on this. BIP 9 at this point represents developers attempting to\n> disregard and impose their will over community consensus, as well as an\n> attempt to force a miner veto backdoor/vulnerability on deployment. It\n> should\n> never be used again.\n>\n> Speedy Trial implemented with BIP 8 made sense* as a possible neutral\n> compromise between LOT=True and LOT=False (which could be deployed prior\n> to\n> or in parallel), but using BIP 9 would destroy this.\n>\n> As with Taproot, any future deployments should use BIP 8 again, until a\n> better\n> solution is developed. Reverting back to a known flawed and vulnerable\n> activation method should not be done, and it would be better not to deploy\n> CTV at all at such an expense.\n>\n> The fact that certain developers attempted to deploy a BIP 9 alternative\n> activation for Taproot against community consensus, and that even managed\n> to\n> get released as \"Bitcoin Core\", makes it all the more important that the\n> community firmly rejects any further action to force this regression.\n>\n> * it is my opinion a BIP 8 ST would be an okay compromise under those\n> circumstances; others do disagree that ST is acceptable at all\n>\n> > This ensures that for a given known input, the TXIDs can also be known\n> ahead\n> of time. Otherwise, CHECKTEMPLATEVERIFY would not be usable for Batched\n> Channel Creation constructions as the redemption TXID could be malleated\n> and\n> pre-signed transactions invalidated, unless the channels are built using\n> an\n> Eltoo-like protocol.\n>\n> Why is it a problem for them to use an Eltoo-like protocol?\n>\n> Why not just commit to the txid itself if that's the goal?\n>\n> >P2SH is incompatible with CHECKTEMPLATEVERIFY\n>\n> Maybe the CTV opcode should only be defined/enforced within witness\n> scripts?\n>\n> >nLockTime should generally be fixed to 0 (in the case of a payment tree,\n> only\n> the *first* lock time is needed to prevent fee-sniping the root)\n>\n> Your \"Congestion Controlled Transactions\" example would only make sense\n> with\n> the spending transaction much later than the \"root\", and so could benefit\n> from fee sniping malleability. (In fact, in that example, it would be\n> better\n> not to commit to locktime at all.)\n>\n> >In the CHECKTEMPLATEVERIFY approach, the covenants are severely\n> restricted to\n> simple templates. The structure of CHECKTEMPLATEVERIFY template is such\n> that\n> the outputs must be known exactly at the time of construction. Based on a\n> destructuring argument, it is only possible to create templates which\n> expand\n> in a finite number of steps.\n>\n> It's not clear to me that this holds if OP_CAT or OP_SHA256STREAM get\n> added.\n>\n> >For example, a exchange's hot wallet might use an address which can\n> automatically be moved to a cold storage address after a relative timeout.\n>\n> Wouldn't it make more sense to just have a UTXO both cold+hot can spend,\n> then\n> throw away the hot key?\n>\n> >In contrast to previous forks, OP_CHECKTEMPLATEVERIFY will not make\n> scripts\n> valid for policy until the new rule is active.\n>\n> Policy isn't validity, and cannot be dictated by BIPs (or anyone/anything,\n> for\n> that matter).\n>\n> Luke\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/84498a7e/attachment-0001.html>"
            },
            {
                "author": "Alex Schoof",
                "date": "2022-01-19T00:37:02",
                "message_text_only": "Hey Jeremy,\n\n> On the topic of drafting BIPs for specific use cases, I agree that would\nbe valuable and can consider it.\n> However, I'm a bit skeptical of that approach overall as I don't\nnecessarily think that the applications *must be* standard, and I view BIPs\nas primarily for standardization whereas part of the flexibility of\nCTV/Sapio allows users to figure out how they want to use it.\n\nElectronic components (think an integrated circuit or a capacitor) usually\nhave both a \"data sheet\" and a set of \"application notes\". The data sheet\nis like a spec or the formal documentation: how the thing works (or is\nintended to work), precise dimensions and tolerances, etc. On the other\nhand, the Application Notes are either a separate document or an appendix\nto the data sheet with specific details about using that component in a\nspecific application: things like schematics for an example implementation,\nthings to watch out for (edge cases or unexpected application-specific\nbehavior, etc.). I appreciate the balance you're trying to strike between\nhaving the BIP for CTV have enough details about how you think it might be\nused and having it exclusively be a spec to help drive standardization.\nMaybe the solution here is to have some explicit application notes that\nhave enough details to give people a sense of how these uses could be built\nout, but still have it be clear that they are a use of, not a part of CTV\nitself by having it either in a linked document or an appendix or\nsomething.\n\nJust a suggestion.\n\nCheers,\n\nAlex\n\nOn Tue, Jan 18, 2022 at 6:54 PM Jeremy via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Thanks for the detailed review.\n>\n> I'll withhold comment around activation logic and leave that for others to\n> discuss.\n>\n> w.r.t. the language cleanups I'll make a PR that (I hope) clears up the\n> small nits later today or tomorrow. Some of it's kind of annoying because\n> the legal definition of covenant is \"A formal agreement or promise,\n> usually included in a contract or deed, to do or not do a particular act; a\n> compact or stipulation made in writing or by parol.\" so I do think things\n> like CLTV/CSV are covenants since it's a binding promise to not spend\n> before a certain time... it might be out of scope for the BIP to fully\n> define these terms because it doesn't really matter what a covenant could\n> be as much as it matters what CTV is specifically.\n>\n> On the topic of drafting BIPs for specific use cases, I agree that would\n> be valuable and can consider it.\n>\n> However, I'm a bit skeptical of that approach overall as I don't\n> necessarily think that the applications *must be* standard, and I view BIPs\n> as primarily for standardization whereas part of the flexibility of\n> CTV/Sapio allows users to figure out how they want to use it.\n>\n> E.g., we do not yet have a BIP for MuSig or even Multisig in Taproot,\n> although there are some papers and example implementations but nothing\n> formal yet\n> https://bitcoin.stackexchange.com/questions/111666/support-for-taproot-multisig-descriptors).\n> Perhaps this is an opportunity for CTV to lead on the amount of formal\n> application designs available before 'release'.\n>\n> As a starting point, maybe you could review some of the application\n> focused posts in rubin.io/advent21 and let me know where they seem\n> deficient?\n>\n> Also a BIP describing how to build something like Sapio (and less so Sapio\n> itself, since it's still early days for that) might help for folks to be\n> able to think through how to compile to CTV contracts? But again, I'm\n> skeptical of the value of a BIP v.s. the documentation and examples\n> available in the code and https://learn.sapio-lang.org.\n>\n> I think it's an interesting discussion too because as we've just seen the\n> LN ecosystem start the BLIP standards, would an example of non-interactive\n> channels be best written up as a BIP, a BLIP, or a descriptive blog/mailing\n> list post?\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n>\n>\n> On Tue, Jan 18, 2022 at 1:19 PM Luke Dashjr via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> tl;dr: I don't think CTV is ready yet (but probably close), and in any\n>> case\n>> definitely not worth reviving BIP 9 with its known flaws and\n>> vulnerability.\n>>\n>> My review here is based solely on the BIP, with no outside context (aside\n>> from\n>> current consensus rules, of course). In particular, I have _not_ looked\n>> at\n>> the CTV code proposed for Bitcoin Core yet.\n>>\n>> >Covenants are restrictions on how a coin may be spent beyond key\n>> ownership.\n>>\n>> nit: Poorly phrased. Even simple scripts can do that already.\n>>\n>> >A few examples are described below, which should be the subject of\n>> future\n>> non-consensus standardization efforts.\n>>\n>> I would ideally like to see fully implemented BIPs for at least one of\n>> these\n>> (preferably the claimed CoinJoin improvements) before we move toward\n>> activation.\n>>\n>> >Congestion Controlled Transactions\n>>\n>> I think this use case hasn't been fully thought through yet. It seems\n>> like it\n>> would be desirable for this purpose, to allow any of the recipients to\n>> claim\n>> their portion of the payment without footing the fee for every other\n>> payment\n>> included in the batch. This is still a covenant-type solution, but one\n>> that\n>> BIP 119 cannot support as-is.\n>>\n>> (I realise this may be a known and accepted limitation, but I think it\n>> should\n>> be addressed in the BIP)\n>>\n>> >Payment Channels\n>>\n>> Why batch mere channel creation? Seems like the spending transaction\n>> should\n>> really be the channel closing.\n>>\n>> >CHECKTEMPLATEVERIFY makes it much easier to set up trustless CoinJoins\n>> than\n>> previously because participants agree on a single output which pays all\n>> participants, which will be lower fee than before.\n>>\n>> I don't see how. They still have to agree in advance on the outputs, and\n>> the\n>> total fees will logically be higher than not using CTV...?\n>>\n>> >Further Each participant doesn't need to know the totality of the\n>> outputs\n>> committed to by that output, they only have to verify their own sub-tree\n>> will\n>> pay them.\n>>\n>> I don't see any way to do this with the provided implementation.\n>>\n>> >Deployment could be done via BIP 9 VersionBits deployed through Speedy\n>> Trial.\n>>\n>> Hard NACK on this. BIP 9 at this point represents developers attempting\n>> to\n>> disregard and impose their will over community consensus, as well as an\n>> attempt to force a miner veto backdoor/vulnerability on deployment. It\n>> should\n>> never be used again.\n>>\n>> Speedy Trial implemented with BIP 8 made sense* as a possible neutral\n>> compromise between LOT=True and LOT=False (which could be deployed prior\n>> to\n>> or in parallel), but using BIP 9 would destroy this.\n>>\n>> As with Taproot, any future deployments should use BIP 8 again, until a\n>> better\n>> solution is developed. Reverting back to a known flawed and vulnerable\n>> activation method should not be done, and it would be better not to\n>> deploy\n>> CTV at all at such an expense.\n>>\n>> The fact that certain developers attempted to deploy a BIP 9 alternative\n>> activation for Taproot against community consensus, and that even managed\n>> to\n>> get released as \"Bitcoin Core\", makes it all the more important that the\n>> community firmly rejects any further action to force this regression.\n>>\n>> * it is my opinion a BIP 8 ST would be an okay compromise under those\n>> circumstances; others do disagree that ST is acceptable at all\n>>\n>> > This ensures that for a given known input, the TXIDs can also be known\n>> ahead\n>> of time. Otherwise, CHECKTEMPLATEVERIFY would not be usable for Batched\n>> Channel Creation constructions as the redemption TXID could be malleated\n>> and\n>> pre-signed transactions invalidated, unless the channels are built using\n>> an\n>> Eltoo-like protocol.\n>>\n>> Why is it a problem for them to use an Eltoo-like protocol?\n>>\n>> Why not just commit to the txid itself if that's the goal?\n>>\n>> >P2SH is incompatible with CHECKTEMPLATEVERIFY\n>>\n>> Maybe the CTV opcode should only be defined/enforced within witness\n>> scripts?\n>>\n>> >nLockTime should generally be fixed to 0 (in the case of a payment tree,\n>> only\n>> the *first* lock time is needed to prevent fee-sniping the root)\n>>\n>> Your \"Congestion Controlled Transactions\" example would only make sense\n>> with\n>> the spending transaction much later than the \"root\", and so could benefit\n>> from fee sniping malleability. (In fact, in that example, it would be\n>> better\n>> not to commit to locktime at all.)\n>>\n>> >In the CHECKTEMPLATEVERIFY approach, the covenants are severely\n>> restricted to\n>> simple templates. The structure of CHECKTEMPLATEVERIFY template is such\n>> that\n>> the outputs must be known exactly at the time of construction. Based on a\n>> destructuring argument, it is only possible to create templates which\n>> expand\n>> in a finite number of steps.\n>>\n>> It's not clear to me that this holds if OP_CAT or OP_SHA256STREAM get\n>> added.\n>>\n>> >For example, a exchange's hot wallet might use an address which can\n>> automatically be moved to a cold storage address after a relative timeout.\n>>\n>> Wouldn't it make more sense to just have a UTXO both cold+hot can spend,\n>> then\n>> throw away the hot key?\n>>\n>> >In contrast to previous forks, OP_CHECKTEMPLATEVERIFY will not make\n>> scripts\n>> valid for policy until the new rule is active.\n>>\n>> Policy isn't validity, and cannot be dictated by BIPs (or\n>> anyone/anything, for\n>> that matter).\n>>\n>> Luke\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n-- \n\n\nAlex Schoof\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220118/942a40cd/attachment.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2022-01-20T18:38:22",
                "message_text_only": "On Tue, Jan 18, 2022 at 03:54:21PM -0800, Jeremy via bitcoin-dev wrote:\n> Some of it's kind of annoying because\n> the legal definition of covenant is [...]\n> so I do think things like CLTV/CSV are covenants\n\nI think that in the context of Bitcoin, the most useful definition of\ncovenant is that it's when the scriptPubKey of a utxo restricts the\nscriptPubKey in the output(s) of a tx spending that utxo.\n\nCTV, TLUV, etc do that; CSV, CLTV don't. (\"checksig\" per se doesn't\neither, though of course the signature that checksig uses does -- if that\nsignature is in the scriptPubKey rather than the scriptSig or witness,\nthat potentially becomes a covenant too)\n\nCheers,\naj"
            }
        ],
        "thread_summary": {
            "title": "CTV BIP review",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Prayank",
                "Jeremy",
                "Michael Folkson",
                "Anthony Towns",
                "eric at voskuil.org",
                "Luke Dashjr",
                "Billy Tetrud",
                "Alex Schoof"
            ],
            "messages_count": 12,
            "total_messages_chars_count": 50984
        }
    },
    {
        "title": "[bitcoin-dev] Highlighting Taproot implementation gotchas",
        "thread_messages": [
            {
                "author": "Michael Folkson",
                "date": "2022-01-20T12:58:24",
                "message_text_only": "Hi\n\nI'd just like to bring some attention to this blog post from the Suredbits team who when implementing Taproot in bitcoin-s found a mainnet output that did not conform to the BIP 340 specification [0] (invalid x coordinate) and hence were burned.\n\nhttps://suredbits.com/taproot-funds-burned-on-the-bitcoin-blockchain/\n\nTo be clear this is was an error made by an unknown developer rather than a bug in the Taproot BIPs or Core implementation.\n\nI'd certainly encourage the community to share with this list mistakes they make or things they find confusing (i.e. stump them for long periods of time) when re-implementing Taproot or supporting Taproot in wallets. I suspect things like eliminating the key path [1] or eliminating the script path [2] will end up being common sources of confusion for wallets.\n\nI'm also open to ideas on how there can be greater information sharing so Taproot implementers don't end up making the same mistakes or spending hours confused over the same things.\n\nI've heard some feedback on a number of occasions now that the Taproot BIPs although thorough and exhaustive aren't geared directly towards implementers and adopters. We discussed this at an online Socratic last year [3] with Craig Raw an early Taproot adopter with Sparrow Wallet. The transcript of that links to a bunch of existing resources (StackExchange posts, the Optech series \"Preparing for Taproot\", Optech workshop etc) that may be useful for implementers.\n\nwumpus also suggested that a new informational BIP might be a good idea as a first port of call for Taproot implementers who find BIP 340-342 dense and difficult to parse. This is certainly something we can do once it becomes clearer what that informational BIP should contain.\n\nOf course the Libera IRC channels #bitcoin-dev (for general Bitcoin development) and #bitcoin-core-dev (for Core related development) are there for discussion and questions. And as many will already know Murch is tracking P2TR support on the Bitcoin wiki [4].\n\nThanks\nMichael\n\n[0]: https://github.com/bitcoin/bips/blob/master/bip-0340.mediawiki#design\n[1]: https://bitcoin.stackexchange.com/questions/99722/taproot-eliminating-key-path\n[2]: https://bitcoin.stackexchange.com/questions/99325/how-do-i-construct-a-p2tr-address-if-i-just-want-to-use-the-key-path\n[3]: https://btctranscripts.com/london-bitcoin-devs/2021-07-20-socratic-seminar-taproot-rollout/\n[4]: https://en.bitcoin.it/wiki/Bech32_adoption\n\n-- Michael Folkson Email: michaelfolkson at [protonmail.com](http://protonmail.com/)\nKeybase: michaelfolkson PGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220120/3e6a6d5a/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Highlighting Taproot implementation gotchas",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Michael Folkson"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2792
        }
    },
    {
        "title": "[bitcoin-dev] Take 2: Removing the Dust Limit",
        "thread_messages": [
            {
                "author": "shymaa arafat",
                "date": "2022-01-21T12:16:35",
                "message_text_only": "Dear Sir,\nRegarding your message\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-December/019636.html\nSpecifically the part\n*\"Right now, lightning anchor outputs use a 330 sats amount. Each\ncommitment*\n*transaction has two such outputs, and only one of them is spent\"*\nI was wondering *is there a way to distinguish those 2 dust UTXOs?*\nI mean does(or could) the protocol force the user to always spend the first\nnot any of them at random?\n-My point is to distinguish between them when inserted in the UTXO set to\nknow in advance which will be spent so fast in the next transaction, and\nwhich is gonna stay there for a while?\n\n-If you look at the number of addresses holding \u22641$ here (by subtracting\ntotal from >1$), you would find it doesn't change very much with days\nhttps://bitinfocharts.com/top-100-richest-bitcoin-addresses.html\n-Meaning not that just official dust value, but values \u22641$ are rarely spent\nunless one forced to. I always had the idea of storing them separately\n(along with non-standard & burned ones at least from public addresses,\nthese should be separated too as they're not expected be spent ever)\n.\nSo the answer may make a difference,\nThank you\nShymaa M Arafat\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220121/31a9ee74/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Take 2: Removing the Dust Limit",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "shymaa arafat"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 1382
        }
    },
    {
        "title": "[bitcoin-dev] Bob-Pays-For-Transaction",
        "thread_messages": [
            {
                "author": "Prayank",
                "date": "2022-01-21T23:45:34",
                "message_text_only": "I have rephrased things discussed in a [tweet thread][1] in 2020, added a few things and interested to know possible issues if we had an opt in policy based on CPFP in which recipients pay fees for transactions instead of senders or most of the wallets followed this:\n\n## Bob-Pays-For-Transaction\n\n==Motivation==\n\nCPFP is less explored, payjoin did not get enough adoption, fee market can be improved,\nrecipients paying fees for the transactions sounds interesting and it can also be used\nin projects that use market making (maker-taker model).\n\n1.Recipient cares about the urgency and the security of the payment in lot of transactions.\n2.It might affect fee market post subsidy era and resolve issues with miners revenue, security etc.\n\n===Receiving wallet===\n\nProvide easy options to use CPFP and pay fees that confirms the parent transaction.\n\n[CPFP calculator][1] by djbooth07 or effective fee rate shown in explorers like https://mempool.space can be helpful.\n\n===Spending wallet===\n\nBroadcast all transactions with 1 sat/vB\n\n==Issues==\n\nFew issues shared by Sergej Kotliar:\n\n1.Receiver can pay via CPFP, but if that\u2019s known about them it gets exploitable, senders will consolidate lot of UTXOs by sending one output to receiver.\n2.Receivers would send their unconfirmed coins onward expecting others to pay the fees until someone considers the transaction important enough to be confirmed soon.\n\nBitcoin Core does not allow you to spend [unconfirmed UTXO using GUI][2] and most of the RPC in CLI. However Kristaps made an interesting point in the linked issue that it could be allowed for transactions\n that do not signal RBF. It is not considered safe however lot of wallets allow this including Wasabi\nin which I recently found [some UI/UX issues][3] related to unconfirmed UTXO.\n\nThe part which may require changes in protocol:\n\nThe whole fee paid for such transactions wouldn't be paid to the miner confirming the transaction but\nit would be shared between the miners creating next N blocks.\n\n\u00a0 [1]: https://twitter.com/LaurentMT/status/1292100590462537733\n\u00a0 [2]: https://github.com/djbooth007/cpfp-calculator\n\u00a0 [3]: https://github.com/zkSNACKs/WalletWasabi/issues/7045\n\u00a0 [4]: https://github.com/bitcoin-core/gui/issues/242\n\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220122/bfda255d/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Bob-Pays-For-Transaction",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Prayank"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2452
        }
    },
    {
        "title": "[bitcoin-dev] Renaming full nodes",
        "thread_messages": [
            {
                "author": "James Lu",
                "date": "2022-01-23T02:44:14",
                "message_text_only": "Much of the confusion around the Bitcoin protocol is the concept that\nmining nodes 'control' the network.\n\nI suggest renaming full nodes- to something like \"validator node\" to\nemphasize that full nodes check if blocks are valid.\n\nThen we could say:\n\n\"Bitcoin is decentralized because anyone can run a validator node, even on\na low-end laptop.\"\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220122/9468fd98/attachment.html>"
            },
            {
                "author": "mm-studios",
                "date": "2022-01-23T13:06:36",
                "message_text_only": "The problem are.miners, it is pretty.innaccessible to be a miner. That's a major isuue for me.\nBlock production is pretty much in hands of the wealthy.\nAny correlation between be wealthy and run a honest node? Not any under my eyes. Skipping the part of the narrative saying 'they are honest bcs they have skin in the game'. That's not scientific to me.\nBlock validation yes, the network is pretty decentralized.\nThanks.\n\nSent from ProtonMail mobile\n\n-------- Original Message --------\nOn 23 Jan 2022, 02:44, James Lu via bitcoin-dev wrote:\n\n> Much of the confusion around the Bitcoin protocol is the concept that mining nodes 'control' the network.\n>\n> I suggest renaming full nodes- to something like \"validator node\" to emphasize that full nodes check if blocks are valid.\n>\n> Then we could say:\n>\n> \"Bitcoin is decentralized because anyone can run a validator node, even on a low-end laptop.\"\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220123/585e3257/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Renaming full nodes",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "James Lu",
                "mm-studios"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 1605
        }
    },
    {
        "title": "[bitcoin-dev] BIP-119 CTV Meeting #2 Agenda for Tuesday January 25th at 12:00 PT",
        "thread_messages": [
            {
                "author": "Jeremy",
                "date": "2022-01-24T03:36:46",
                "message_text_only": "Bitcoin Developers,\n\nThe 2nd instance of the recurring meeting is scheduled for Tuesday January\n25th at 12:00 PT in channel ##ctv-bip-review in libera.chat IRC server.\n\nThe meeting should take approximately 2 hours.\n\nThe topics proposed to be discussed are agendized below. Please review the\nagenda in advance of the meeting to make the best use of everyone's time.\n\nIf you have any feedback or proposed content changes to the agenda please\nlet me know.\n\nSee you Tuesday,\n\nJeremy\n\n- Update on Bounty Program & Feedback (10 Min)\n- Feedback Recap (20 Min)\n  - In this section we'll review any recent feedback or review of CTV.\n    To expedite the meeting, a summary is provided below of the main\nfeedback received since the last meeting and responses to them so that the\ntime allotted may be devoted to follow up questions.\n  - Luke Dashjr's feedback\n    - thread:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019776.html\n    - summary:\n        Dashjr notes that while CTV is not done, it may be nearly done.\n        Dashjr requests that some applications be made BIP-quality before\nproceeding, amongst other smaller feedbacks.\n        Dashjr also expresses his concerns about activation logic.\n        Respondents debated the activation logic, and there was a general\nsentiment to keep the discussion of CTV and activation logic somewhat\nseparate, as Activation is a general concern pertaining to all upgrades and\nnot CTV in particular.\n        Rubin responded asking if BIP-quality is required or if examples\nlike those in rubin.io/advent21 suffice.\n  - James O'Beirne's feedback\n    - Github Link:\nhttps://github.com/bitcoin/bitcoin/pull/21702#pullrequestreview-859718084\n    - summary:\n        O'Beirne tests the reindexing performance with the CTV patches and\nfinds a minor performance regression due to the cache precomputations.\n        Rubin responds with patches for an improved caching strategy that\nprecomputes the CTV hashes only when they are used, but it is a little more\ncomplex to review.\n        Rubin also points out that the tested range is not representative\nof \"current\" blocks which have a higher proportion of segwit.\n  - Peter Todd's Feedback\n    - thread:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019738.html\n    - response:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019739.html\n    - summary:\n        Todd reviewed the BIP and an (outdated) implementation and was\ndisappointed to find that the testing was insufficient, the analysis of\nvalidation resources was insufficient, and the quality of proof of concept\napplications was insufficient.\n        Rubin responded by pointing Todd to the most up to date\nimplementation which has more tests, updated the link in the BIP to the PR,\nupdated the BIP to describe resource usage, and asked what the bar is\nexpected to be for applications.\n        Rubin further responded with an analysis of current congested\nmempool behavior here:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019756.html\n.\n        Todd is yet to respond.\n- What is Sapio / How to think about Programming with CTV (15 Min)\n  - Resources to review\n    - https://learn.sapio-lang.org/ch02-00-bip-119.html\n    - https://rubin.io/bitcoin/2021/12/06/advent-9/\n    - https://rubin.io/bitcoin/2021/12/15/advent-18/\n  - Composability\n  - What's all this \"Non-Interactivity\" Business?\n- Vaults (20 Min)\n  - Resources:\n    https://rubin.io/bitcoin/2021/12/07/advent-10/\n    https://rubin.io/bitcoin/2021/12/08/advent-11/\n    https://github.com/kanzure/python-vaults\n- Congestion Control (20 Mins)\n  - Resources:\n    https://rubin.io/bitcoin/2021/12/09/advent-12/\n\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-January/019756.html\n    https://utxos.org/analysis/batching_sim/\n    https://utxos.org/analysis/bip_simulation/\n- Payment Pools (20 Mins)\n  - Resources:\n    https://rubin.io/bitcoin/2021/12/10/advent-13/\n    https://rubin.io/bitcoin/2021/12/15/advent-18/\n\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019419.html\n\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2020-June/017964.html\n- General Q&A (15 Mins)\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220123/7a55a9f4/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "BIP-119 CTV Meeting #2 Agenda for Tuesday January 25th at 12:00 PT",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 4465
        }
    },
    {
        "title": "[bitcoin-dev] CTV dramatically improves DLCs",
        "thread_messages": [
            {
                "author": "Lloyd Fournier",
                "date": "2022-01-24T08:01:17",
                "message_text_only": "Hi dlc-dev and bitcoin-dev,\n\ntl;dr OP_CTV simplifies and improves performance of DLCs by a factor of *a lot*.\n\n## Introduction\n\nDryja introduced the idea of Discreet Log Contracts (DLC) in his\nbreakthrough work[1].\nSince then (DLC) has become an umbrella term for Bitcoin protocols\nthat map oracle secret revelation to an on-chain transaction which\napportions coins accordingly.\nThe key property that each protocol iteration preserves is that the\noracle is an *oblivious trusted party* -- they do not interact with\nthe blockchain and it is not possible to tell which event or which\noracle the two parties were betting on with blockchain data alone.\n\n `OP_CHECKTEMPLATEVERIFY` (CTV) a.k.a. BIP119 [2] is a proposed\nupgrade to Bitcoin which is being actively discussed.\nCTV makes possible an optimized protocol which improves DLC\nperformance so dramatically that it solves several user experience\nconcerns and engineering difficulties.\nTo me this is the most compelling and practical application of CTV so\nI thought it's about time to share it!\n\n## Present state of DLC specification\n\nThe DLC specifications[3] use adaptor signatures to condition each\npossible payout.\nThe protocol works roughly like this:\n\n1. Oracle(s) announce events along with a nonce `R` for each event.\nLet's say each event has `N` outcomes.\n2. Two users who wish to make a bet take the `R` from the oracle\nannouncement and construct a set of attestation points `S` and their\ncorresponding payouts.\n3. Each attestation point for each of the `N` outcomes is calculated\nlike `S_i = R + H(R || X || outcome_i) * X` where `X` is the oracle's\nstatic key.\n4. The users combine the attestation points into *contract execution\ntransaction* (CET) points e.g `CET_i = S1_i + S2_i + S3_i`.\n   Here `CET_i` is the conjunction (`AND`) between the event outcomes\nrepresented by `S1_i, S2_i, S3_i`.\n5. The oracle(s) reveals the attestation `s_i` where `s_i * G = S_i`\nif the `i`th is the outcome transpired.\n6. Either of the parties takes the `s_i`s from each of the\nattestations and combines them e.g. `cet_i = s1_i + s2_i + s3_i` and\nuses `cet_i` to decrypt the CET adaptor signature encrypted by `CET_i`\nand broadcast the transaction.\n\n## Performance issues with DLCs\n\nIn the current DLC protocol both parties compute:\n  - `E * N` attestation points where `E` is the number of events you\nare combining and `N` is the number of outcomes per event. (1 mul)\n  - `C >= E * N` CET adaptor signatures and verify them. (2 mul -- or\nwith MuSig2, 3 muls).\n\nNote that the number of CETs can be much greater than the number of\nattestation points. For example,\nif an oracle decomposes the price of BTC/USD into 20 binary digits\ne.g. 0..(2^20 -1), you could have\n`E=20,N=2,C=2^20`. So the biggest concern for worst case performance\nis the adaptor signatures multiplications.\n\nIf we take a multiplication as roughly 50 microseconds computing\nMuSig2 adaptor signatures for ~6000 CETs would take around a second of\ncpu time (each) or so.\n6000 CETs is by no means sufficient if you wanted, for example, to bet\non the BTC/USD price per dollar.\nNote there may be various ways of precomputing multiplications and\nusing fast linear combination algorithms and so on but I hope this\nprovides an idea of the scale of the issue.\nThen consider that you may want to use a threshold of oracles which\nwill combinatorially increase this number (e.g. 3/5 threshold would\n10x this).\n\nYou also would end up sending data on the order of megabytes to each other.\n\n## committing to each CET in a tapleaf with CHECKTEMPLATEVERIFY\n\nWhat can we do with OP_CTV + Taproot to improve this?\n\nInstead of creating an adaptor signature for every CET, commit to the\nCET with OP_CTV in a tapleaf:\n\n```\n<CET-hash_i> CHECKTEMPLATEVERIFY <CET_i> CHECKSIG\n```\n\nWhen the oracle(s) reveals their attestations either party can combine\nthem to get the secret key\ncorresponding to `CET_i` and spend the coins to the CET (whose CTV\nhash is `CET-hash`) which\ndistributes the funds according to the contract.\n\nThis replaces all the multiplications needed for the adaptor signature\nwith a few hashes!\nYou will still need to compute the `CET_i` which will involve a point\nnormalisation but it still brings the computational cost per CET down\nfrom hundreds of microseconds to around 5 (per party).\nThere will be a bit more data on chain (and a small privacy loss) in\nthe uncooperative case but even with tens of thousands of outcomes\nit's only going to roughly double the virtual size of the transaction.\nKeep in mind the uncooperative case should hopefully be rare too esp\nwhen we are doing this in channels.\n\nThe amount of data that the parties need to exchange is also reduced\nto a small constant size.\n\n## getting rid of combinatorial complexity of oracle thresholds\n\nNow that we're using script it's very easy to do a threshold along\nwith the script. e.g. a 2/3:\n\n```\n<CET-hash> CHECKTEMPLATEVERIFY\n<attestation-point1> CHECKSIG\n<attestation-point2> CHECKSIGADD\n<attestation-point3> CHECKSIGADD\n2 EQUAL\n```\n\nThe improvement here is that the amount of computation and\ncommunication does not increase with the number of oracles in the\nthreshold.\nThe size of the witness only increases linearly in the number of\noracles and only in the un-cooperative case.\nThis also solves a security issue with the current spec because\nattestation points from different oracles are no longer summed (which\nis a problem [4]).\n\n## Getting rid of the attestation point multiplication\n\nIt's possible to get rid of the EC multiplications from the\nattestation point computation too.\nThis is optimistically a 10x improvement but in the most important\ncases it's a negligible improvement since computing the `E*N`\nattestion points is a small fraction of the total CET point\ncomputation.\n\nRecall the original Schnorr style DLC attestation point was computed like:\n\n```\nS_i = R + H(R || X || outcome_i) * X\n```\n\nSo for each outcome we have to hash it and multiply the result by the\noracle's public key.\nI don't think hashing is necessary[6].\n\nFirst note that an oracle attestation scheme is not a signature scheme:\n\n1. The users need to be able to compute the attestation point\nbeforehand (signature schemes do not require the verifier to be able\nto compute anything before hand).\n2. There is a very different concept of a forgery -- you don't care\nabout someone being able to forge signatures under the oracle's key in\ngeneral you only care about them being able to forge an attestation\ncorresponding to some previously announced event i.e. you only care\nabout forgeries of things that people are actually betting on.\n\nLong story[6] short we can get rid of the hash and do the following\ninstead for the `outcome_i`:\n\n```\nS_i = R + i * X\n```\n\nFor each `outcome_i` the oracle will reveal a different linear\ncombination of `R` and `X`.\nHowever, if we still want to preserve the ability to add attestation\npoints together to create an AND like condition for points\nattestations from the same oracle so we have to do:\n\n```\nS_i = i * R + X\n```\n\nwhich when we combine two attestations from the same oracle becomes:\n\n`S1_i + S2_j = (i*R1 + X) + (j*R2 + X) = i*R1 + j*R2 + 2*X`\n\nAs you can see the addition preserves the linear structure.\nIf you were to do the original suggestion it would be:\n\n`S1_i + S2_j = (i*X + R1 + (j*X + R2) = (i + j)*X + R1 + R2)`\n\nWhich loses the structure and creates collisions e.g. `S1_1 + S2_2 =\nS1_2 + S2_1` .\nNote that this collision problem also exists in the current spec and\noriginal paper[4,5] but requires a solving a hashing k-sum that should\nbe hard to do in practice.\n\nSo, when we compute for `i in 1..N`, `S_1 = R + X` and each subsequent\nis `S_i = S_{i-1} + R` and so we only need to do one addition for each\nattestation point.\n\n## In summary\n\nIn the worst case this improves DLC performance by ~30x compared to\nusing MuSig2 adaptor signatures because it gets rid of all\nmultiplications for both parties.\nIn the case of a 3/5 threshold performance would be improved by another 10x.\nDepending on the kind of event, removing the attestation point\nmultiplication will also help.\nCommunication complexity also becomes constant.\n\nIn other words, from the user's perspective everything can happen\npretty much instantly even on more resource constrained devices and\nbad internet connections.\n\nThe downside of the protocol is that in the un-cooperative case, the\nsize of the witness is bigger and the transaction is distinguishable\nfrom other protocols (it's not longer scriptless).\n\n## Credits\n\nSpecial thanks to:\n\n- Ruben Somsen who first made the observation that OP_CTV could be\napplied to DLCs in the way presented here.\n- Thibaut Le Guilly who did benchmarking on getting rid of the\nattestation point multiplication.\n- Nadav Cohen who pointed out that doing `R + i*X` was broken.\n\n[1]: https://adiabat.github.io/dlc.pdf\n[2]: https://github.com/bitcoin/bips/blob/master/bip-0119.mediawiki\n[3]: https://github.com/discreetlogcontracts/dlcspecs\n[4]: https://bitcoinproblems.org/problems/secure-dlcs.html\n[5]: https://mailmanlists.org/pipermail/dlc-dev/2021-March/000065.html\n[6]: https://github.com/LLFourn/dlc-sec/blob/master/main.pdf\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220124/cec80a59/attachment-0001.html>"
            },
            {
                "author": "Jeremy",
                "date": "2022-01-28T17:21:09",
                "message_text_only": "Lloyd,\n\nThis is an excellent write up, the idea and benefits are clear.\n\nIs it correct that in the case of a 3/5th threshold it is a total 10x * 30x\n= 300x improvement? Quite impressive.\n\nI have a few notes of possible added benefits / features of DLCs with CTV:\n\n1) CTV also enables a \"trustless timeout\" branch, whereby you can have a\nfailover claim that returns funds to both sides.\n\nThere are a few ways to do this:\n\nA) The simplest is just an oracle-free <STH(timeout tx)> CTV whereby the\ntimeout transaction has an absolute/relative timelock after the creation of\nthe DLC in question.\n\nB) An alternative approach I like is to have the base DLC have a branch\n`<STH(begin timeout)> CTV` which pays into a DLC that is the exact same\nexcept it removes the just-used branch and replaces it with `<STH(timeout\ntx)> CTV` which contains a relative timelock R for the desired amount of\ntime to resolve. This has the advantage of always guaranteeing at least R\namount of time since the Oracles have been claimed to be non-live to\n\"return funds\"  to parties participating\n\n\n2) CTV DLCs are non-interactive asynchronously third-party unilaterally\ncreatable.\n\nWhat I mean by this is that it is possible for a single party to create a\nDLC on behalf of another user since there is no required per-instance\npre-signing or randomly generated state. E.g., if Alice wants to create a\nDLC with Bob, and knows the contract details, oracles, and a key for Bob,\nshe can create the contract and pay to it unilaterally as a payment to Bob.\n\nThis enables use cases like pay-to-DLC addresses. Pay-to-DLC addresses can\nalso be constructed and then sent (along with a specific amount) to a third\nparty service (such as an exchange or Lightning node) to create DLCs\nwithout requiring the third party service to do anything other than make\nthe payment as requested.\n\n\n3) CTV DLCs can be composed in interesting ways\n\nOptions over DLCs open up many exciting types of instrument where Alice can\ndo things like:\nA) Create a Option expiring in 1 week where Bob can add funds to pay a\npremium and \"Open\" a DLC on an outcome closing in 1 year\nB) Create an Option expiring in 1 week where one-of-many Bobs can pay the\npremium (on-chain DEX?).\n\n See https://rubin.io/bitcoin/2021/12/20/advent-23/ for more concrete stuff\naround this.\n\nThere are also opportunities for perpetual-like contracts where you could\ncombine into one logical DLC 12 DLCs closing 1 per month that can either be\npayed out all at once at the end of the year, or profit pulled out\npartially at any time earlier.\n\n4) This satisfies (I think?) my request to make DLCs expressible as Sapio\ncontracts in https://rubin.io/bitcoin/2021/12/20/advent-23/\n\n5) An additional performance improvement can be had for iterative DLCs in\nLightning where you might trade over a fixed set of attestation points with\nvariable payout curves (e.g., just modifying some set of the CTV points).\nDefer to you on performance, but this could help enable some more HFT-y\nexperiences for DLCs in LN\n\nBest,\n\nJeremy\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Mon, Jan 24, 2022 at 3:04 AM Lloyd Fournier via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi dlc-dev and bitcoin-dev,\n>\n> tl;dr OP_CTV simplifies and improves performance of DLCs by a factor of *a lot*.\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/442b0946/attachment-0001.html>"
            },
            {
                "author": "Jeremy Rubin",
                "date": "2022-01-28T19:38:29",
                "message_text_only": "Apologies for the double post*, but I just had a follow up idea\nthat's pretty interesting to me.\n\nYou can make the close portion of a DLC be an \"optimistic\" execution with a\nchoice of justice scheme. This enables closing a DLC somewhat securely\nwithout exposing the oracles on-chain at all.\n\nAssuming honest oracles, the only cost of this mechanism over previous is\nthat you have to do a script path spend (but it can be a top-level branch,\nsince it's the \"most likely\" one).\n\n\nFor every DLC branch like:\n\n*<CET-hash-i> CHECKTEMPLATEVERIFY\n<attestation-point1> CHECKSIG\n<attestation-point2> CHECKSIGADD\n<attestation-point3> CHECKSIGADD\n2 EQUAL*\n\n\nadd a 2 branches:\n\n\n*<CET-hash-A> CHECKTEMPLATEVERIFY\n<Alice> CHECKSIG\n*\n\n*<CET-hash-B> CHECKTEMPLATEVERIFY\n<Bob> CHECKSIG*\n\n\nThis enables Alice or Bob to \"lock in\" a redemption of the contract\nthat becomes spendable by them after <period>. CET-hash-* should\ninclude a nLockTime/nSequence such that it is at the same time as the\nattestation points should be known.\n\n\nWhere CET-hash-T sends funds to a DLC that has the following conditions:\n\n\n(cooperate):\n\n*pk_internal=musig(Alice, Bob)*\n\nor (unilateral timeout)\n\n*<T> Checksig <2 weeks> CSV*\n\nor (show oracles for this outcome)\n\n*<CET-hash-i> CHECKTEMPLATEVERIFY*\n\n*<attestation-point1> CHECKSIG\n<attestation-point2> CHECKSIGADD\n<attestation-point3> CHECKSIGADD\n2 EQUAL*\n\nor (justice with no punishment), forall j !=i:\n\n*<CET-hash-j> CHECKTEMPLATEVERIFY*\n\n*<attestation-point1> CHECKSIG\n<attestation-point2> CHECKSIGADD\n<attestation-point3> CHECKSIGADD\n2 EQUAL*\n\nor (justice with punishment), forall j!=i:\n\n*<CET-hash-punish-j, send funds to not-T> CHECKTEMPLATEVERIFY*\n\n*<attestation-point1> CHECKSIG\n<attestation-point2> CHECKSIGADD\n<attestation-point3> CHECKSIGADD\n2 EQUAL*\n\n\nJustice with punishment seems to me to be the better option since T is\nactively choosing this resolution (the CTV transition is signed), but\njustice with no punishment might be better if you think the oracles\nmight screw you over and collude to steal.\n\nOne interesting question is if the justice transactions can be\n\"compressed\" to be fewer for a given outcome. I.e., if Bob has claimed\nthat the outcome is 35, and there are 100 total outcomes, do we need\n99 justice paths or is there a way to make fewer of them? Intuitively,\nit would seem so, because if we have a 8-10 threshold for picking a\npath, a 3-10 proof would be sufficient to prove Bob claimed to know\nthe 8-10 falsely. However, that then means 3-10 could collude, v.s.\nthe fraud proof requiring a full 8-10 counter. Things to think about!\n\n\nBest,\n\n\nJeremy\n\n\n* this might actually be a triple or quadruple post depending on how\nyou count, I adjusted which email was the subscriber on my mailing\nlist account and resultantly sent from the old address... sincere\napologies if you are seeing this message >1 times to those who were on\nthe CC.\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Fri, Jan 28, 2022 at 9:21 AM Jeremy <jlrubin at mit.edu> wrote:\n\n> Lloyd,\n>\n> This is an excellent write up, the idea and benefits are clear.\n>\n> Is it correct that in the case of a 3/5th threshold it is a total 10x *\n> 30x = 300x improvement? Quite impressive.\n>\n> I have a few notes of possible added benefits / features of DLCs with CTV:\n>\n> 1) CTV also enables a \"trustless timeout\" branch, whereby you can have a\n> failover claim that returns funds to both sides.\n>\n> There are a few ways to do this:\n>\n> A) The simplest is just an oracle-free <STH(timeout tx)> CTV whereby the\n> timeout transaction has an absolute/relative timelock after the creation of\n> the DLC in question.\n>\n> B) An alternative approach I like is to have the base DLC have a branch\n> `<STH(begin timeout)> CTV` which pays into a DLC that is the exact same\n> except it removes the just-used branch and replaces it with `<STH(timeout\n> tx)> CTV` which contains a relative timelock R for the desired amount of\n> time to resolve. This has the advantage of always guaranteeing at least R\n> amount of time since the Oracles have been claimed to be non-live to\n> \"return funds\"  to parties participating\n>\n>\n> 2) CTV DLCs are non-interactive asynchronously third-party unilaterally\n> creatable.\n>\n> What I mean by this is that it is possible for a single party to create a\n> DLC on behalf of another user since there is no required per-instance\n> pre-signing or randomly generated state. E.g., if Alice wants to create a\n> DLC with Bob, and knows the contract details, oracles, and a key for Bob,\n> she can create the contract and pay to it unilaterally as a payment to Bob.\n>\n> This enables use cases like pay-to-DLC addresses. Pay-to-DLC addresses can\n> also be constructed and then sent (along with a specific amount) to a third\n> party service (such as an exchange or Lightning node) to create DLCs\n> without requiring the third party service to do anything other than make\n> the payment as requested.\n>\n>\n> 3) CTV DLCs can be composed in interesting ways\n>\n> Options over DLCs open up many exciting types of instrument where Alice\n> can do things like:\n> A) Create a Option expiring in 1 week where Bob can add funds to pay a\n> premium and \"Open\" a DLC on an outcome closing in 1 year\n> B) Create an Option expiring in 1 week where one-of-many Bobs can pay the\n> premium (on-chain DEX?).\n>\n>  See https://rubin.io/bitcoin/2021/12/20/advent-23/ for more concrete\n> stuff around this.\n>\n> There are also opportunities for perpetual-like contracts where you could\n> combine into one logical DLC 12 DLCs closing 1 per month that can either be\n> payed out all at once at the end of the year, or profit pulled out\n> partially at any time earlier.\n>\n> 4) This satisfies (I think?) my request to make DLCs expressible as Sapio\n> contracts in https://rubin.io/bitcoin/2021/12/20/advent-23/\n>\n> 5) An additional performance improvement can be had for iterative DLCs in\n> Lightning where you might trade over a fixed set of attestation points with\n> variable payout curves (e.g., just modifying some set of the CTV points).\n> Defer to you on performance, but this could help enable some more HFT-y\n> experiences for DLCs in LN\n>\n> Best,\n>\n> Jeremy\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n>\n>\n> On Mon, Jan 24, 2022 at 3:04 AM Lloyd Fournier via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi dlc-dev and bitcoin-dev,\n>>\n>> tl;dr OP_CTV simplifies and improves performance of DLCs by a factor of *a lot*.\n>>\n>>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/7ec469d9/attachment.html>"
            },
            {
                "author": "Alex Schoof",
                "date": "2022-01-28T21:14:12",
                "message_text_only": "> CTV DLCs are non-interactive asynchronously third-party unilaterally\ncreatable.\n\nThis is super interesting. I think that would make it easier to do\nmulti-party DLCs. With a \"normal\" DLC, you need to have N parties\nexchanging and signing CETs and you end up with a combinatorial explosion\nof signing operations to perform. It sounds like if you did it with CTV,\nthen each party could compute all the outcomes on their own in parallel (to\nbe able to generate commitments for each tapleaf) and then just exchange\nand sign the single opening transaction for the DLC. Or for devices with\nlimited resources, you could have a coordinator compute the whole TR tree\nand publish a ZKP to the other signers.\n\nCheers,\n\nAlex\n\n\nOn Fri, Jan 28, 2022 at 12:21 PM Jeremy via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Lloyd,\n>\n> This is an excellent write up, the idea and benefits are clear.\n>\n> Is it correct that in the case of a 3/5th threshold it is a total 10x *\n> 30x = 300x improvement? Quite impressive.\n>\n> I have a few notes of possible added benefits / features of DLCs with CTV:\n>\n> 1) CTV also enables a \"trustless timeout\" branch, whereby you can have a\n> failover claim that returns funds to both sides.\n>\n> There are a few ways to do this:\n>\n> A) The simplest is just an oracle-free <STH(timeout tx)> CTV whereby the\n> timeout transaction has an absolute/relative timelock after the creation of\n> the DLC in question.\n>\n> B) An alternative approach I like is to have the base DLC have a branch\n> `<STH(begin timeout)> CTV` which pays into a DLC that is the exact same\n> except it removes the just-used branch and replaces it with `<STH(timeout\n> tx)> CTV` which contains a relative timelock R for the desired amount of\n> time to resolve. This has the advantage of always guaranteeing at least R\n> amount of time since the Oracles have been claimed to be non-live to\n> \"return funds\"  to parties participating\n>\n>\n> 2) CTV DLCs are non-interactive asynchronously third-party unilaterally\n> creatable.\n>\n> What I mean by this is that it is possible for a single party to create a\n> DLC on behalf of another user since there is no required per-instance\n> pre-signing or randomly generated state. E.g., if Alice wants to create a\n> DLC with Bob, and knows the contract details, oracles, and a key for Bob,\n> she can create the contract and pay to it unilaterally as a payment to Bob.\n>\n> This enables use cases like pay-to-DLC addresses. Pay-to-DLC addresses can\n> also be constructed and then sent (along with a specific amount) to a third\n> party service (such as an exchange or Lightning node) to create DLCs\n> without requiring the third party service to do anything other than make\n> the payment as requested.\n>\n>\n> 3) CTV DLCs can be composed in interesting ways\n>\n> Options over DLCs open up many exciting types of instrument where Alice\n> can do things like:\n> A) Create a Option expiring in 1 week where Bob can add funds to pay a\n> premium and \"Open\" a DLC on an outcome closing in 1 year\n> B) Create an Option expiring in 1 week where one-of-many Bobs can pay the\n> premium (on-chain DEX?).\n>\n>  See https://rubin.io/bitcoin/2021/12/20/advent-23/ for more concrete\n> stuff around this.\n>\n> There are also opportunities for perpetual-like contracts where you could\n> combine into one logical DLC 12 DLCs closing 1 per month that can either be\n> payed out all at once at the end of the year, or profit pulled out\n> partially at any time earlier.\n>\n> 4) This satisfies (I think?) my request to make DLCs expressible as Sapio\n> contracts in https://rubin.io/bitcoin/2021/12/20/advent-23/\n>\n> 5) An additional performance improvement can be had for iterative DLCs in\n> Lightning where you might trade over a fixed set of attestation points with\n> variable payout curves (e.g., just modifying some set of the CTV points).\n> Defer to you on performance, but this could help enable some more HFT-y\n> experiences for DLCs in LN\n>\n> Best,\n>\n> Jeremy\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n>\n>\n> On Mon, Jan 24, 2022 at 3:04 AM Lloyd Fournier via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hi dlc-dev and bitcoin-dev,\n>>\n>> tl;dr OP_CTV simplifies and improves performance of DLCs by a factor of *a lot*.\n>>\n>>\n>> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n\n\n-- \n\n\nAlex Schoof\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/95d5f0c6/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "CTV dramatically improves DLCs",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Jeremy",
                "Lloyd Fournier",
                "Alex Schoof",
                "Jeremy Rubin"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 24234
        }
    },
    {
        "title": "[bitcoin-dev] [dlc-dev] CTV dramatically improves DLCs",
        "thread_messages": [
            {
                "author": "Jonas Nick",
                "date": "2022-01-25T16:24:21",
                "message_text_only": "Thank you, that's an interesting application of OP_CTV.\n\nPerhaps worth pointing out that this does not require OP_CTV but could also be\nenabled by other covenant constructions. For example, it seems like\nANYPREVOUT-based covenants provide similar benefits. The script of the Taproot\nleaves could be set to\n\n<sig> <G> CHECKSIGVERIFY <CET_i> CHECKSIGVERIFY\n\nwhere <sig> is an ANYPREVOUTANYSCRIPT signature of the CET for public key P = G.\nWhen using nonce R = G, signature creation has negligible computational cost (s\n= 1 + H(R, P, m)). A downside compared to CTV is the additional overhead of 64\nwitness bytes (<sig>)."
            },
            {
                "author": "Thibaut Le Guilly",
                "date": "2022-01-27T00:45:12",
                "message_text_only": "Hi,\n\nLloyd, thanks for this excellent writeup. I must say that indeed using CTV\nseems like it would very much lower the complexity of the DLC protocol (and\nit seems like APO would also work, thanks Jonas for pointing that out).\nThough thinking about it, I can't help wondering if the ideal op code for\nDLC wouldn't actually be CHECKSIGFROMSTACK? It feels to me that this would\ngive the most natural way of doing things. If I'm not mistaken, this would\nenable simply requiring an oracle signature over the outcome, without any\nspecial trick, and without even needing the oracle to release a nonce in\nadvance (the oracle could sign `event_outcome + event_id` to avoid\nsignature reuse). I must say that I haven't studied covenant opcodes in\ndetail yet so is that line of thinking correct or am I missing something?\n\nCheers,\n\nThibaut\n\nOn Wed, Jan 26, 2022 at 1:27 AM Jonas Nick via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Thank you, that's an interesting application of OP_CTV.\n>\n> Perhaps worth pointing out that this does not require OP_CTV but could\n> also be\n> enabled by other covenant constructions. For example, it seems like\n> ANYPREVOUT-based covenants provide similar benefits. The script of the\n> Taproot\n> leaves could be set to\n>\n> <sig> <G> CHECKSIGVERIFY <CET_i> CHECKSIGVERIFY\n>\n> where <sig> is an ANYPREVOUTANYSCRIPT signature of the CET for public key\n> P = G.\n> When using nonce R = G, signature creation has negligible computational\n> cost (s\n> = 1 + H(R, P, m)). A downside compared to CTV is the additional overhead\n> of 64\n> witness bytes (<sig>).\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220127/6f228196/attachment-0001.html>"
            },
            {
                "author": "Jeremy",
                "date": "2022-01-28T16:53:40",
                "message_text_only": "Thibaut,\n\nCSFS might have independent benefits, but in this case CTV is not being\nused in the Oracle part of the DLC, it's being used in the user generated\nmapping of Oracle result to Transaction Outcome.\n\nSo it'd only be complimentary if you came up with something CSFS based for\nthe Oracles.\n\nBest,\n\nJeremy\n\n\nOn Thu, Jan 27, 2022 at 12:59 AM Thibaut Le Guilly via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi,\n>\n> Lloyd, thanks for this excellent writeup. I must say that indeed using CTV\n> seems like it would very much lower the complexity of the DLC protocol (and\n> it seems like APO would also work, thanks Jonas for pointing that out).\n> Though thinking about it, I can't help wondering if the ideal op code for\n> DLC wouldn't actually be CHECKSIGFROMSTACK? It feels to me that this would\n> give the most natural way of doing things. If I'm not mistaken, this would\n> enable simply requiring an oracle signature over the outcome, without any\n> special trick, and without even needing the oracle to release a nonce in\n> advance (the oracle could sign `event_outcome + event_id` to avoid\n> signature reuse). I must say that I haven't studied covenant opcodes in\n> detail yet so is that line of thinking correct or am I missing something?\n>\n> Cheers,\n>\n> Thibaut\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/e80aa4e2/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "CTV dramatically improves DLCs",
            "categories": [
                "bitcoin-dev",
                "dlc-dev"
            ],
            "authors": [
                "Thibaut Le Guilly",
                "Jonas Nick",
                "Jeremy"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 4061
        }
    },
    {
        "title": "[bitcoin-dev] PathCoin",
        "thread_messages": [
            {
                "author": "AdamISZ",
                "date": "2022-01-24T14:43:53",
                "message_text_only": "Hello list,\n\nI took the time to write up this rather out-there idea:\n\nImagine you wanted to send a coin just like email, i.e. just transfer data to the counterparty.\n\nClearly this is in general entirely impossible; but with what restrictions and assumptions could you create a toy version of it?\n\nSee this gist for a detailed build up of the idea:\n\nhttps://gist.github.com/AdamISZ/b462838cbc8cc06aae0c15610502e4da\n\nBasically: using signature adaptors and CTV or a similar covenant, you could create a fully trustless transfer of control of a utxo from one party to another with no interaction with the rest of the group, at the time of transfer (modulo of course lots and lots of one-time setup).\n\nThe limitations are extreme and as you'd imagine. In the gist I feel like I got round one of them, but not the others.\n\n(I very briefly mention comparison to e.g. statechains or payment pools; they are making other tradeoffs against the 'digital cash' type of goal. There is no claim that this 'pathcoin' idea is even viable yet, let alone better than those ideas).\n\nPublishing this because I feel like it's the kind of thing imaginative minds like the ones here, may be able to develop further. Possibly!\n\n\nwaxwing / AdamISZ"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-01-25T11:53:36",
                "message_text_only": "There was a protocol someone mentioned a while back called Sabu that had\nthe same goals. As i recall, it had some pretty promising constructs, but\nwould have a critical vulnerability that could be exploited by miners. This\nis the write up:\n\nhttps://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n\nPerhaps some of the techniques there could be combined with your ideas to\nget closer to a solution.\n\nOn Mon, Jan 24, 2022, 08:51 AdamISZ via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hello list,\n>\n> I took the time to write up this rather out-there idea:\n>\n> Imagine you wanted to send a coin just like email, i.e. just transfer data\n> to the counterparty.\n>\n> Clearly this is in general entirely impossible; but with what restrictions\n> and assumptions could you create a toy version of it?\n>\n> See this gist for a detailed build up of the idea:\n>\n> https://gist.github.com/AdamISZ/b462838cbc8cc06aae0c15610502e4da\n>\n> Basically: using signature adaptors and CTV or a similar covenant, you\n> could create a fully trustless transfer of control of a utxo from one party\n> to another with no interaction with the rest of the group, at the time of\n> transfer (modulo of course lots and lots of one-time setup).\n>\n> The limitations are extreme and as you'd imagine. In the gist I feel like\n> I got round one of them, but not the others.\n>\n> (I very briefly mention comparison to e.g. statechains or payment pools;\n> they are making other tradeoffs against the 'digital cash' type of goal.\n> There is no claim that this 'pathcoin' idea is even viable yet, let alone\n> better than those ideas).\n>\n> Publishing this because I feel like it's the kind of thing imaginative\n> minds like the ones here, may be able to develop further. Possibly!\n>\n>\n> waxwing / AdamISZ\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220125/a599352b/attachment.html>"
            },
            {
                "author": "AdamISZ",
                "date": "2022-01-25T12:50:32",
                "message_text_only": "Hi Billy,\nI read through the description. I think systems like this *mostly* fail due to game theory.\n\nWith punishment-by-burn you have various issues that make it to my mind pretty unstable, too unstable to use for any serious system. To be fair, this isn't cut-and-dried. So let me unpack:\n\n(I briefly touched on why I dismissed penalties via burn in my gist, section: \"Not feeling the burn\".)\n\nThere is a distinction between penalty via burn to unspendable output and penalty via burn to miner fees. The latter has an obvious problem: if your counterparties collude with (or are) miners, they may not actually be penalized at all (now to be clear, that is a problematic attack ex nihilo: nobody usually can be sure who's mining the next block, but markets have a way of solving and coordinating such things: see e.g. the various MEV discussions and initiatives in Ethereum for an example of that).\n\nBut the former (provable burn) is still imo extremely unstable: if the penalty tx destroys all the money, what is the incentive for the honest party to punish? In such a scenario even a one cent donation from the attacker to the victim might prevent the penalty from happening.\nYou can combine 'destruction of most, or some, of the funds' with a smaller payout to the aggrieved party, but then again you have to factor in the possibility of bribes. The Sabu post you linked describes it as: \"There are precise and delicate formulas for calculating the amount of loss of the issuer and the creditor, which ensures that just and true act in both parties are cost-effective in all situations.\" I agree it's delicate, but after having spent time looking into these things, my strong intuition is that it will never be properly stable.\n\nIn the PathCoin description I am specifically looking for a trustless system, with this finesse: we still count it as trustless even though we are using penalties as disincentive, because the penalty *consists of a payment directly from the attacker to the attacked, and that payment is larger than the amount stolen*. I claim that that *is* stable.\n\nNotice that Lightning has the same model (in LN-Penalty), as long as 'claiming the whole channel capacity' is enough to be larger than what is stolen (see: channel reserves etc.).\n\nSent with [ProtonMail](https://protonmail.com/) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Tuesday, January 25th, 2022 at 11:53, Billy Tetrud via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> There was a protocol someone mentioned a while back called Sabu that had the same goals. As i recall, it had some pretty promising constructs, but would have a critical vulnerability that could be exploited by miners. This is the write up:\n>\n> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n>\n> Perhaps some of the techniques there could be combined with your ideas to get closer to a solution.\n>\n> On Mon, Jan 24, 2022, 08:51 AdamISZ via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hello list,\n>>\n>> I took the time to write up this rather out-there idea:\n>>\n>> Imagine you wanted to send a coin just like email, i.e. just transfer data to the counterparty.\n>>\n>> Clearly this is in general entirely impossible; but with what restrictions and assumptions could you create a toy version of it?\n>>\n>> See this gist for a detailed build up of the idea:\n>>\n>> https://gist.github.com/AdamISZ/b462838cbc8cc06aae0c15610502e4da\n>>\n>> Basically: using signature adaptors and CTV or a similar covenant, you could create a fully trustless transfer of control of a utxo from one party to another with no interaction with the rest of the group, at the time of transfer (modulo of course lots and lots of one-time setup).\n>>\n>> The limitations are extreme and as you'd imagine. In the gist I feel like I got round one of them, but not the others.\n>>\n>> (I very briefly mention comparison to e.g. statechains or payment pools; they are making other tradeoffs against the 'digital cash' type of goal. There is no claim that this 'pathcoin' idea is even viable yet, let alone better than those ideas).\n>>\n>> Publishing this because I feel like it's the kind of thing imaginative minds like the ones here, may be able to develop further. Possibly!\n>>\n>> waxwing / AdamISZ\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220125/e672234b/attachment.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-01-28T15:27:30",
                "message_text_only": "> what is the incentive for the honest party to punish?\n\nJustice. Also, there's no incentive for the honest party to not punish -\npresumably their software would automatically punish, and why go through\nany effort to stop it? A 1 cent bribe certainly wouldn't be enough. Maybe a\n$10 bribe might get someone somewhere to install hacked up software to be\nable to fulfill such a bribe, but even then i think it would be a rare\nperson that would stoop to that. Were it to become a true negotiation, the\ncheater has more to lose, and therefore the bribee has a lot of leverage.\n\n> my strong intuition is that it will never be properly stable.\n\nI'm curious what you mean by \"stable\". You had mentioned the game theory is\n\"fragile\" and I'm wondering if there's more to this than just \"what\nincentive does the honest party have to burn?\"\n\nTo be clear, I'm not advocating for Sabu and I haven't done any deep\nthinking about burn based incentives.\n\nOne thing I thought of regarding path coin, if there's ever a situation\nwhere there are multiple choices in path, whatever punishment there is\nprobably needs to be able to handle the multiple of the number of paths.\nThe only way around this i can imagine is to have some method of\ncoordination between payees, eg a place where a payee records their payment\nsuch that a payee who has been double spent on to become aware they've been\ndouble spent on and initiate the punishment. But once you have that\ncoordination mechanism it starts not looking more like an on chain\ntransaction.\n\nOn Tue, Jan 25, 2022, 06:50 AdamISZ <AdamISZ at protonmail.com> wrote:\n\n> Hi Billy,\n> I read through the description. I think systems like this *mostly* fail\n> due to game theory.\n>\n> With punishment-by-burn you have various issues that make it to my mind\n> pretty unstable, too unstable to use for any serious system. To be fair,\n> this isn't cut-and-dried. So let me unpack:\n>\n> (I briefly touched on why I dismissed penalties via burn in my gist,\n> section: \"Not feeling the burn\".)\n>\n> There is a distinction between penalty via burn to unspendable output and\n> penalty via burn to miner fees. The latter has an obvious problem: if your\n> counterparties collude with (or are) miners, they may not actually be\n> penalized at all (now to be clear, that is a problematic attack ex nihilo:\n> nobody usually can be sure who's mining the next block, but markets have a\n> way of solving and coordinating such things: see e.g. the various MEV\n> discussions and initiatives in Ethereum for an example of that).\n>\n> But the former (provable burn) is still imo extremely unstable: if the\n> penalty tx destroys all the money, what is the incentive for the honest\n> party to punish? In such a scenario even a one cent donation from the\n> attacker to the victim might prevent the penalty from happening.\n> You can combine 'destruction of most, or some, of the funds' with a\n> smaller payout to the aggrieved party, but then again you have to factor in\n> the possibility of bribes. The Sabu post you linked describes it as: \"There\n> are precise and delicate formulas for calculating the amount of loss of the\n> issuer and the creditor, which ensures that just and true act in both\n> parties are cost-effective in all situations.\" I agree it's delicate, but\n> after having spent time looking into these things, my strong intuition is\n> that it will never be properly stable.\n>\n> In the PathCoin description I am specifically looking for a trustless\n> system, with this finesse: we still count it as trustless even though we\n> are using penalties as disincentive, because the penalty *consists of a\n> payment directly from the attacker to the attacked, and that payment is\n> larger than the amount stolen*. I claim that that *is* stable.\n>\n> Notice that Lightning has the same model (in LN-Penalty), as long as\n> 'claiming the whole channel capacity' is enough to be larger than what is\n> stolen (see: channel reserves etc.).\n>\n> Sent with ProtonMail <https://protonmail.com/> Secure Email.\n>\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Tuesday, January 25th, 2022 at 11:53, Billy Tetrud via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> There was a protocol someone mentioned a while back called Sabu that had\n> the same goals. As i recall, it had some pretty promising constructs, but\n> would have a critical vulnerability that could be exploited by miners. This\n> is the write up:\n>\n>\n> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n>\n> Perhaps some of the techniques there could be combined with your ideas to\n> get closer to a solution.\n>\n> On Mon, Jan 24, 2022, 08:51 AdamISZ via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Hello list,\n>>\n>> I took the time to write up this rather out-there idea:\n>>\n>> Imagine you wanted to send a coin just like email, i.e. just transfer\n>> data to the counterparty.\n>>\n>> Clearly this is in general entirely impossible; but with what\n>> restrictions and assumptions could you create a toy version of it?\n>>\n>> See this gist for a detailed build up of the idea:\n>>\n>> https://gist.github.com/AdamISZ/b462838cbc8cc06aae0c15610502e4da\n>>\n>> Basically: using signature adaptors and CTV or a similar covenant, you\n>> could create a fully trustless transfer of control of a utxo from one party\n>> to another with no interaction with the rest of the group, at the time of\n>> transfer (modulo of course lots and lots of one-time setup).\n>>\n>> The limitations are extreme and as you'd imagine. In the gist I feel like\n>> I got round one of them, but not the others.\n>>\n>> (I very briefly mention comparison to e.g. statechains or payment pools;\n>> they are making other tradeoffs against the 'digital cash' type of goal.\n>> There is no claim that this 'pathcoin' idea is even viable yet, let alone\n>> better than those ideas).\n>>\n>> Publishing this because I feel like it's the kind of thing imaginative\n>> minds like the ones here, may be able to develop further. Possibly!\n>>\n>>\n>> waxwing / AdamISZ\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/18dd745a/attachment-0001.html>"
            },
            {
                "author": "AdamISZ",
                "date": "2022-01-29T17:16:29",
                "message_text_only": "> Justice. Also, there's no incentive for the honest party to not punish - presumably their software would automatically punish, and why go through any effort to stop it? A 1 cent bribe certainly wouldn't be enough. Maybe a $10 bribe might get someone somewhere to install hacked up software to be able to fulfill such a bribe, but even then i think it would be a rare person that would stoop to that. Were it to become a true negotiation, the cheater has more to lose, and therefore the bribee has a lot of leverage.\n\nJustice isn't a strong enough incentive, it's too context-dependent, and in particular it's not something you could rely on if there is any financial incentive pushing the other way. Especially the ordering of events: if you have a counterparty who is malicious and they *take action* to steal, then they can present you with two alternatives one of which is more favourable than the other, if there is a bribe. It isn't *just* about logic I think, though the logic definitely matters.\n\nThese arguments about whether we could use 'mutually assured destruction' approaches (burn in particular) to make contract enforcement work have been ongoing amongst Bitcoin enthusiasts for a decade, I've always felt strongly that they do not ultimately work and haven't seen anything to change my mind (I seem to remember convincing Manfred Karrer not to use it in Bitsquare in 2014/15, but there've been many other examples of people proposing it and it never really getting traction).\n\n> One thing I thought of regarding path coin, if there's ever a situation where there are multiple choices in path, whatever punishment there is probably needs to be able to handle the multiple of the number of paths.\n\nRight, I briefly alluded to setting up with multiple paths - general idea is instead of only a->b->c->d->e it's possible to setup the n-ary tree, so a can go to all of b,c,d,e etc., but the problem is the factorial blowup that you get even if you restrict to no-revisiting (or exponential otherwise). For the toy example of 5 participants though, it is entirely possible to build the matrix as illustrated in the gist, but it's an N^2 matrix duplicated for every change in the path, here's the simplest possible extension of the base case:\n\npath 1: A B* C* D* E*\npath 2: A B C* D* E*\npath 3: A B C* D* E*\npath 4: A B C D* E*\npath 5: A B C D E\npath 6: A C* B* D* E*\npath 7: A C B* D* E*\npath 8: A C B D* E*\npath 9: A C B D E*\npath 10: A C B D E\n\nThe * would indicate pre-signs (and this whole list is branches in the taproot output of the pathcoin); this setup *only* allows one alternate path (second C instead of second B) for the coin.\n\nIf A chooses to pay B (not C), then: instead of only giving B an adaptor on path1 and signatures on paths 2,3,4,5, A would also have to give B adaptors on paths 6-10 as well. So it's easy to see that if you kept adding branches for every possible spending path A->E with no revisits you have like n^2(n-1)! (maybe not exactly; something very similar).\n(Notice: though there are multiple paths via which A can cheat, they all reveal the same adaptor secret (and they're all the same coin) leading to the same forfeit of fidelity bond, see gist for the nice way you can always have it so that a single fidelity bond goes to the honest owner).\n\nAll of this is predicated on the idea that the participants do *not* coordinate at all after the initial setup; only a data transfer from payer to payee. A pretty massive restriction, of course.\n\nSent with [ProtonMail](https://protonmail.com/) Secure Email.\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Friday, January 28th, 2022 at 15:27, Billy Tetrud via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>> what is the incentive for the honest party to punish?\n>\n> Justice. Also, there's no incentive for the honest party to not punish - presumably their software would automatically punish, and why go through any effort to stop it? A 1 cent bribe certainly wouldn't be enough. Maybe a $10 bribe might get someone somewhere to install hacked up software to be able to fulfill such a bribe, but even then i think it would be a rare person that would stoop to that. Were it to become a true negotiation, the cheater has more to lose, and therefore the bribee has a lot of leverage.\n>\n>> my strong intuition is that it will never be properly stable.\n>\n> I'm curious what you mean by \"stable\". You had mentioned the game theory is \"fragile\" and I'm wondering if there's more to this than just \"what incentive does the honest party have to burn?\"\n>\n> To be clear, I'm not advocating for Sabu and I haven't done any deep thinking about burn based incentives.\n>\n> One thing I thought of regarding path coin, if there's ever a situation where there are multiple choices in path, whatever punishment there is probably needs to be able to handle the multiple of the number of paths. The only way around this i can imagine is to have some method of coordination between payees, eg a place where a payee records their payment such that a payee who has been double spent on to become aware they've been double spent on and initiate the punishment. But once you have that coordination mechanism it starts not looking more like an on chain transaction.\n>\n> On Tue, Jan 25, 2022, 06:50 AdamISZ <AdamISZ at protonmail.com> wrote:\n>\n>> Hi Billy,\n>> I read through the description. I think systems like this *mostly* fail due to game theory.\n>>\n>> With punishment-by-burn you have various issues that make it to my mind pretty unstable, too unstable to use for any serious system. To be fair, this isn't cut-and-dried. So let me unpack:\n>>\n>> (I briefly touched on why I dismissed penalties via burn in my gist, section: \"Not feeling the burn\".)\n>>\n>> There is a distinction between penalty via burn to unspendable output and penalty via burn to miner fees. The latter has an obvious problem: if your counterparties collude with (or are) miners, they may not actually be penalized at all (now to be clear, that is a problematic attack ex nihilo: nobody usually can be sure who's mining the next block, but markets have a way of solving and coordinating such things: see e.g. the various MEV discussions and initiatives in Ethereum for an example of that).\n>>\n>> But the former (provable burn) is still imo extremely unstable: if the penalty tx destroys all the money, what is the incentive for the honest party to punish? In such a scenario even a one cent donation from the attacker to the victim might prevent the penalty from happening.\n>> You can combine 'destruction of most, or some, of the funds' with a smaller payout to the aggrieved party, but then again you have to factor in the possibility of bribes. The Sabu post you linked describes it as: \"There are precise and delicate formulas for calculating the amount of loss of the issuer and the creditor, which ensures that just and true act in both parties are cost-effective in all situations.\" I agree it's delicate, but after having spent time looking into these things, my strong intuition is that it will never be properly stable.\n>>\n>> In the PathCoin description I am specifically looking for a trustless system, with this finesse: we still count it as trustless even though we are using penalties as disincentive, because the penalty *consists of a payment directly from the attacker to the attacked, and that payment is larger than the amount stolen*. I claim that that *is* stable.\n>>\n>> Notice that Lightning has the same model (in LN-Penalty), as long as 'claiming the whole channel capacity' is enough to be larger than what is stolen (see: channel reserves etc.).\n>>\n>> Sent with [ProtonMail](https://protonmail.com/) Secure Email.\n>>\n>> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>> On Tuesday, January 25th, 2022 at 11:53, Billy Tetrud via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> There was a protocol someone mentioned a while back called Sabu that had the same goals. As i recall, it had some pretty promising constructs, but would have a critical vulnerability that could be exploited by miners. This is the write up:\n>>>\n>>> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n>>>\n>>> Perhaps some of the techniques there could be combined with your ideas to get closer to a solution.\n>>>\n>>> On Mon, Jan 24, 2022, 08:51 AdamISZ via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> Hello list,\n>>>>\n>>>> I took the time to write up this rather out-there idea:\n>>>>\n>>>> Imagine you wanted to send a coin just like email, i.e. just transfer data to the counterparty.\n>>>>\n>>>> Clearly this is in general entirely impossible; but with what restrictions and assumptions could you create a toy version of it?\n>>>>\n>>>> See this gist for a detailed build up of the idea:\n>>>>\n>>>> https://gist.github.com/AdamISZ/b462838cbc8cc06aae0c15610502e4da\n>>>>\n>>>> Basically: using signature adaptors and CTV or a similar covenant, you could create a fully trustless transfer of control of a utxo from one party to another with no interaction with the rest of the group, at the time of transfer (modulo of course lots and lots of one-time setup).\n>>>>\n>>>> The limitations are extreme and as you'd imagine. In the gist I feel like I got round one of them, but not the others.\n>>>>\n>>>> (I very briefly mention comparison to e.g. statechains or payment pools; they are making other tradeoffs against the 'digital cash' type of goal. There is no claim that this 'pathcoin' idea is even viable yet, let alone better than those ideas).\n>>>>\n>>>> Publishing this because I feel like it's the kind of thing imaginative minds like the ones here, may be able to develop further. Possibly!\n>>>>\n>>>> waxwing / AdamISZ\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220129/ad458d2e/attachment-0001.html>"
            },
            {
                "author": "Billy Tetrud",
                "date": "2022-01-30T15:39:04",
                "message_text_only": "> if you have a counterparty who is malicious and they *take action* to\nsteal, then they can present you with two alternatives\n\nGenerally I don't think this is the case.  In this case, these are\ntime-sensitive operations. There is no time to negotiate after the\nmalicious party has taken action. The software would have already taken\ncounteraction. Negotiation would have to happen before broadcast.\n\n>  I've always felt strongly that they do not ultimately work\n\nSo you don't have any specific reasoning you can give for that gut feeling?\nI'm not pushing for burn mechanisms, but trying to understand why you're\ndismissing them.\n\n\n\nOn Sat, Jan 29, 2022 at 11:16 AM AdamISZ <AdamISZ at protonmail.com> wrote:\n\n> > Justice. Also, there's no incentive for the honest party to not punish\n> - presumably their software would automatically punish, and why go through\n> any effort to stop it? A 1 cent bribe certainly wouldn't be enough. Maybe a\n> $10 bribe might get someone somewhere to install hacked up software to be\n> able to fulfill such a bribe, but even then i think it would be a rare\n> person that would stoop to that. Were it to become a true negotiation, the\n> cheater has more to lose, and therefore the bribee has a lot of leverage.\n>\n> Justice isn't a strong enough incentive, it's too context-dependent, and\n> in particular it's not something you could rely on if there is any\n> financial incentive pushing the other way. Especially the ordering of\n> events: if you have a counterparty who is malicious and they *take action*\n> to steal, then they can present you with two alternatives one of which is\n> more favourable than the other, if there is a bribe. It isn't *just* about\n> logic I think, though the logic definitely matters.\n>\n> These arguments about whether we could use 'mutually assured destruction'\n> approaches (burn in particular) to make contract enforcement work have been\n> ongoing amongst Bitcoin enthusiasts for a decade, I've always felt strongly\n> that they do not ultimately work and haven't seen anything to change my\n> mind (I seem to remember convincing Manfred Karrer not to use it in\n> Bitsquare in 2014/15, but there've been many other examples of people\n> proposing it and it never really getting traction).\n>\n> > One thing I thought of regarding path coin, if there's ever a situation\n> where there are multiple choices in path, whatever punishment there is\n> probably needs to be able to handle the multiple of the number of paths.\n>\n> Right, I briefly alluded to setting up with multiple paths - general idea\n> is instead of only a->b->c->d->e it's possible to setup the n-ary tree, so\n> a can go to all of b,c,d,e etc., but the problem is the factorial blowup\n> that you get even if you restrict to no-revisiting (or exponential\n> otherwise). For the toy example of 5 participants though, it is entirely\n> possible to build the matrix as illustrated in the gist, but it's an N^2\n> matrix duplicated for every change in the path, here's the simplest\n> possible extension of the base case:\n>\n> path 1:  A  B* C* D* E*\n> path 2:  A  B  C* D* E*\n> path 3:  A  B  C* D* E*\n> path 4:  A  B  C  D* E*\n> path 5:  A  B  C  D  E\n> path 6:  A  C* B* D* E*\n> path 7:  A  C  B* D* E*\n> path 8:  A  C  B  D* E*\n> path 9:  A  C  B  D  E*\n> path 10: A  C  B  D  E\n>\n> The * would indicate pre-signs (and this whole list is branches in the\n> taproot output of the pathcoin); this setup *only* allows one alternate\n> path (second C instead of second B) for the coin.\n>\n> If A chooses to pay B (not C), then: instead of only giving B an adaptor\n> on path1 and signatures on paths 2,3,4,5, A would also have to give B\n> adaptors on paths 6-10 as well. So it's easy to see that if you kept adding\n> branches for every possible spending path A->E with no revisits you have\n> like n^2(n-1)! (maybe not exactly; something very similar).\n> (Notice: though there are multiple paths via which A can cheat, they all\n> reveal the same adaptor secret (and they're all the same coin) leading to\n> the same forfeit of fidelity bond, see gist for the nice way you can always\n> have it so that a single fidelity bond goes to the honest owner).\n>\n> All of this is predicated on the idea that the participants do *not*\n> coordinate at all after the initial setup; only a data transfer from payer\n> to payee. A pretty massive restriction, of course.\n>\n> Sent with ProtonMail <https://protonmail.com/> Secure Email.\n>\n> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n> On Friday, January 28th, 2022 at 15:27, Billy Tetrud via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> > what is the incentive for the honest party to punish?\n>\n> Justice. Also, there's no incentive for the honest party to not punish -\n> presumably their software would automatically punish, and why go through\n> any effort to stop it? A 1 cent bribe certainly wouldn't be enough. Maybe a\n> $10 bribe might get someone somewhere to install hacked up software to be\n> able to fulfill such a bribe, but even then i think it would be a rare\n> person that would stoop to that. Were it to become a true negotiation, the\n> cheater has more to lose, and therefore the bribee has a lot of leverage.\n>\n> > my strong intuition is that it will never be properly stable.\n>\n> I'm curious what you mean by \"stable\". You had mentioned the game theory\n> is \"fragile\" and I'm wondering if there's more to this than just \"what\n> incentive does the honest party have to burn?\"\n>\n> To be clear, I'm not advocating for Sabu and I haven't done any deep\n> thinking about burn based incentives.\n>\n> One thing I thought of regarding path coin, if there's ever a situation\n> where there are multiple choices in path, whatever punishment there is\n> probably needs to be able to handle the multiple of the number of paths.\n> The only way around this i can imagine is to have some method of\n> coordination between payees, eg a place where a payee records their payment\n> such that a payee who has been double spent on to become aware they've been\n> double spent on and initiate the punishment. But once you have that\n> coordination mechanism it starts not looking more like an on chain\n> transaction.\n>\n> On Tue, Jan 25, 2022, 06:50 AdamISZ <AdamISZ at protonmail.com> wrote:\n>\n>> Hi Billy,\n>> I read through the description. I think systems like this *mostly* fail\n>> due to game theory.\n>>\n>> With punishment-by-burn you have various issues that make it to my mind\n>> pretty unstable, too unstable to use for any serious system. To be fair,\n>> this isn't cut-and-dried. So let me unpack:\n>>\n>> (I briefly touched on why I dismissed penalties via burn in my gist,\n>> section: \"Not feeling the burn\".)\n>>\n>> There is a distinction between penalty via burn to unspendable output and\n>> penalty via burn to miner fees. The latter has an obvious problem: if your\n>> counterparties collude with (or are) miners, they may not actually be\n>> penalized at all (now to be clear, that is a problematic attack ex nihilo:\n>> nobody usually can be sure who's mining the next block, but markets have a\n>> way of solving and coordinating such things: see e.g. the various MEV\n>> discussions and initiatives in Ethereum for an example of that).\n>>\n>> But the former (provable burn) is still imo extremely unstable: if the\n>> penalty tx destroys all the money, what is the incentive for the honest\n>> party to punish? In such a scenario even a one cent donation from the\n>> attacker to the victim might prevent the penalty from happening.\n>> You can combine 'destruction of most, or some, of the funds' with a\n>> smaller payout to the aggrieved party, but then again you have to factor in\n>> the possibility of bribes. The Sabu post you linked describes it as: \"There\n>> are precise and delicate formulas for calculating the amount of loss of the\n>> issuer and the creditor, which ensures that just and true act in both\n>> parties are cost-effective in all situations.\" I agree it's delicate, but\n>> after having spent time looking into these things, my strong intuition is\n>> that it will never be properly stable.\n>>\n>> In the PathCoin description I am specifically looking for a trustless\n>> system, with this finesse: we still count it as trustless even though we\n>> are using penalties as disincentive, because the penalty *consists of a\n>> payment directly from the attacker to the attacked, and that payment is\n>> larger than the amount stolen*. I claim that that *is* stable.\n>>\n>> Notice that Lightning has the same model (in LN-Penalty), as long as\n>> 'claiming the whole channel capacity' is enough to be larger than what is\n>> stolen (see: channel reserves etc.).\n>>\n>>\n>> Sent with ProtonMail <https://protonmail.com/> Secure Email.\n>>\n>>\n>> \u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\n>> On Tuesday, January 25th, 2022 at 11:53, Billy Tetrud via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> There was a protocol someone mentioned a while back called Sabu that had\n>> the same goals. As i recall, it had some pretty promising constructs, but\n>> would have a critical vulnerability that could be exploited by miners. This\n>> is the write up:\n>>\n>>\n>> https://raymo-49157.medium.com/time-to-boost-bitcoin-circulation-million-transactions-per-second-and-privacy-1eef8568d180\n>>\n>> Perhaps some of the techniques there could be combined with your ideas to\n>> get closer to a solution.\n>>\n>> On Mon, Jan 24, 2022, 08:51 AdamISZ via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Hello list,\n>>>\n>>> I took the time to write up this rather out-there idea:\n>>>\n>>> Imagine you wanted to send a coin just like email, i.e. just transfer\n>>> data to the counterparty.\n>>>\n>>> Clearly this is in general entirely impossible; but with what\n>>> restrictions and assumptions could you create a toy version of it?\n>>>\n>>> See this gist for a detailed build up of the idea:\n>>>\n>>> https://gist.github.com/AdamISZ/b462838cbc8cc06aae0c15610502e4da\n>>>\n>>> Basically: using signature adaptors and CTV or a similar covenant, you\n>>> could create a fully trustless transfer of control of a utxo from one party\n>>> to another with no interaction with the rest of the group, at the time of\n>>> transfer (modulo of course lots and lots of one-time setup).\n>>>\n>>> The limitations are extreme and as you'd imagine. In the gist I feel\n>>> like I got round one of them, but not the others.\n>>>\n>>> (I very briefly mention comparison to e.g. statechains or payment pools;\n>>> they are making other tradeoffs against the 'digital cash' type of goal.\n>>> There is no claim that this 'pathcoin' idea is even viable yet, let alone\n>>> better than those ideas).\n>>>\n>>> Publishing this because I feel like it's the kind of thing imaginative\n>>> minds like the ones here, may be able to develop further. Possibly!\n>>>\n>>>\n>>> waxwing / AdamISZ\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>>\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220130/89f4a034/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "PathCoin",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "AdamISZ",
                "Billy Tetrud"
            ],
            "messages_count": 6,
            "total_messages_chars_count": 35949
        }
    },
    {
        "title": "[bitcoin-dev] TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV and ANYPREVOUT",
        "thread_messages": [
            {
                "author": "Russell O'Connor",
                "date": "2022-01-26T17:20:10",
                "message_text_only": "Recapping the relationship between CTV and ANYPREVOUT::\n\nIt is known that there is a significant amount of overlap in the\napplications that are enabled by the CTV and ANYPREVOUT proposals despite\nthe fact that their primary applications (congestion control for CTV and\neltoo lightning channels for ANYPREVOUT) are quite distinct.\nIn particular, ANYPREVOUT can enable most of the applications of CTV,\nalbeit with a higher cost.  The primary functionality of CTV is to allow a\nscriptPubKey to make a commitment to its spending transaction's hash with\nthe input's TXID excluded from the hash.  This exclusion is necessary\nbecause the scriptPubKey is hashed into the input's TXID, and including the\nTXID would cause a cycle of hash commitments, which is impossible to\nconstruct.  On the other hand, ANYPREVOUT defines a signature hash mode\nthat similarly excludes the inputs TXID for its purpose of rebindable\nsignatures.\n\nThis means that ANYPREVOUT can mimic most of the properties of CTV by\ncommitting both a public key along with an ANYPREVOUT signature inside\nscriptPubKey.  In fact, the only reason Bitcoin doesn't have covenants\ntoday is due to this cycle between scriptPubKeys and the TXIDs that occur\nin all the sighash modes.\n\nThe major differences between simulating CTV via ANYPREVOUT and the actual\nCTV proposal is: (1) The cost of simulating CTV.  With CTV the spending\ntransaction is committed using a hash of 32 bytes, while simulating it with\nANYPREVOUT requires 64 bytes for a signature, and 32 bytes for some public\nkey, plus a few more bytes for various flags.  Some of that cost could be\nreduced by using the inner public key (1 byte representation) and, if we\nhad CAT, maybe by assembling the signature from reusable pieces (i.e.\nsetting the nonce of the commited signature equal to the public key).\n\nThe other major difference is: (2) CTV's transaction hash covers values\nsuch as the number of inputs in the transaction and their sequence numbers,\nwhich ANYPREVOUT does not cover.  CTV's hash contains enough information so\nthat when combined with the missing TXIDs, you can compute the TXID of the\nspending transaction.  In particular if the number of inputs is committed\nto being 1, once the scriptpubkey's transaction id is known and committed\nto the blockchain, the TXID of its spending transaction is deducible.  And\nif that transaction has outputs that have CTV commitments in them, you can\ndeduce their spending TXIDs in turn.  While this is a pretty neat feature,\nsomething that ANYPREVOUT cannot mimic, the main application for it is\nlisted as using congestion control to fund lightning channels, fixing their\nTXIDs in advance of them being placed on chain.  However, if ANYPREVOUT\nwere used to mimic CTV, then likely it would be eltoo channels that would\nbe funded, and it isn't necessary to know the TXIDs of eltoo channels in\nadvance in order to use them.\n\n\n\nAn Alternative Proposal::\n\nGiven the overlap in functionality between CTV and ANYPREVOUT, I think it\nmakes sense to decompose their operations into their constituent pieces and\nreassemble their behaviour programmatically.  To this end, I'd like to\ninstead propose OP_TXHASH and OP_CHECKSIGFROMSTACKVERIFY.\n\nOP_TXHASH would pop a txhash flag from the stack and compute a (tagged)\ntxhash in accordance with that flag, and push the resulting hash onto the\nstack.\nOP_CHECKSIGFROMSTACKVERIFY would pop a pubkey, message, and signature from\nthe stack and fail if the signature does not verify on that message.\n\nCTV and TXHASH have roughly equivalent functionality.  'CTV DROP' can be\nsimulated by '<ctv_style_flag> TXHASH EQUALVERIFY'.  The reverse is also\ntrue where '<ctv_style_flag> TXHASH' can be simulated by CTV by\n'<ctv-result-from-witness-stack> CTV', however, as you can see, simulating\nTXHASH from CTV is much more expensive than the other way around, because\nthe resulting 32-byte hash result must be included as part of the witness\nstack.\n\n'<anyprevout-pubkey> CHECKSIGVERIFY can be simulated by '<apo_style_flag>\nTXHASH <pubkey> CHECKSIGFROMSTACKVERIFY'.  Here we see the advantage of\npushing the hash value onto the stack.  APO can be simulated without\nneeding to include a copy of the resulting txhash inside the witness data.\n\nIn addition to the CTV and ANYPREVOUT applications, with\nCHECKSIGFROMSTACKVERIFY we can verify signatures on arbitrary messages\nsigned by oracles for oracle applications.  This is where we see the\nbenefit of decomposing operations into primitive pieces.  By giving users\nthe ability to program their own use cases from components, we get more\napplications out of fewer op codes!\n\n\n\nCaveats::\n\nFirst, I acknowledge that replicating the behaviour of CTV and ANYPREVOUT\ndoes cost a few more bytes than using the custom purpose built proposals\nthemselves.  That is the price to be paid when we choose the ability to\nprogram solutions from pieces.  But we get to reap the advantages of being\nable to build more applications from these pieces.\n\nUnlike CTV, TXHASH is not NOP-compatable and can only be implemented within\ntapscript.  In particular, bare CTV isn't possible with this proposal.\nHowever, this proposal doesn't preclude the possibility of having CTV added\nto legacy script in while having TXHASH added to tapscript.\n\nFor similar reasons, TXHASH is not amenable to extending the set of txflags\nat a later date.  In theory, one could have TXHASH abort-with-success when\nencountering an unknown set of flags.  However, this would make analyzing\ntapscript much more difficult. Tapscripts would then be able to abort with\nsuccess or failure depending on the order script fragments are assembled\nand executed, and getting the order incorrect would be catastrophic.  This\nbehavior is manifestly different from the current batch of OP_SUCCESS\nopcodes that abort-with-success just by their mere presence, whether they\nwould be executed or not.\n\nI believe the difficulties with upgrading TXHASH can be mitigated by\ndesigning a robust set of TXHASH flags from the start.  For example having\nbits to control whether (1) the version is covered; (2) the locktime is\ncovered; (3) txids are covered; (4) sequence numbers are covered; (5) input\namounts are covered; (6) input scriptpubkeys are covered; (7) number of\ninputs is covered; (8) output amounts are covered; (9) output scriptpubkeys\nare covered; (10) number of outputs is covered; (11) the tapbranch is\ncovered; (12) the tapleaf is covered; (13) the opseparator value is\ncovered; (14) whether all, one, or no inputs are covered; (15) whether all,\none or no outputs are covered; (16) whether the one input position is\ncovered; (17) whether the one output position is covered; (18) whether the\nsighash flags are covered or not (note: whether or not the sighash flags\nare or are not covered must itself be covered).  Possibly specifying which\ninput or output position is covered in the single case and whether the\nposition is relative to the input's position or is an absolute position.\n\nThat all said, even if other txhash flag modes are needed in the future,\nadding TXHASH2 always remains an option.\n\n\n\nInteractions with potential future opcodes::\n\nWe should give some consideration on how these opcodes may interact with\nfuture opcodes such as CAT, rolling SHA256 opcodes, or how it might\ninterface with other covenant opcodes that may do things like, directly\npush input or output amounts onto the stack for computation purposes,\nopcodes which have been added to the Elements project.\n\nWith CAT and/or rolling SHA256 opcodes and/or existing SHA256 opcodes, the\nCHECKSIGFROMSTACKVERIFY could verify signatures on programmatically\nassembled messages.  Also, in combination with multiple calls to TXHASH,\ncould be used to create signatures that commit to complex subsets of\ntransaction data.\n\nIf new opcodes are added to push parts of the transaction data direction\nonto the stack, e.g. OP_INSPECTOUTPUTVALUE, there is perhaps concern that\nthey would obsolete TXHASH, since, in the presence of rolling SHA256\nopcodes, TXHASH could be simulated.  However, given that TXHASH can\ncompactly create a hash of large portions of transaction data, it seems\nunlikely that TXHASH would fall into disuse.  Also, a combination of TXHASH\nand transaction introspection opcodes can be used to build \"*subtractive\ncovenants*\".\n\nThe usual way of building a covenant, which we will call \"*additive *\n*covenants*\", is to push all the parts of the transaction data you would\nlike to fix onto the stack, hash it all together, and verify the resulting\nhash matches a fixed value.  Another way of building covenants, which we\nwill call \"*subtractive covenants*\", is to push all the parts of the\ntransaction data you would like to remain free onto the stack.  Then use\nrolling SHA256 opcodes starting from a fixed midstate that commits to a\nprefix of the transaction hash data. The free parts are hashed into that\nmidstate.  Finally, the resulting hash value is verified to match a value\nreturned by TXHASH.  The ability to nicely build subtractive covenants\ndepends on the details of how the TXHASH hash value is constructed,\nsomething that I'm told CTV has given consideration to.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220126/1f33d0b3/attachment.html>"
            },
            {
                "author": "Jeremy",
                "date": "2022-01-26T22:16:06",
                "message_text_only": "Hi Russell,\n\nThanks for this email, it's great to see this approach described.\n\nA few preliminary notes of feedback:\n\n1) a Verify approach can be made to work for OP_TXHASH (even with CTV\nas-is) E.g., suppose a semantic added for a single byte stack[-1] sighash\nflag to read the hash at stack[-2], then the hash can be passed in instead\nof put on the stack. This has the disadvantage of larger witnesses, but the\nadvantage of allowing undefined sighash flags to pass for any hash type.\n2) using the internal key for APO covenants is not an option because it\nmakes transaction construction interactive and precludes contracts with a\nNUMS point taproot key. Instead, if you want similar savings, you should\nadvocate an OP_GENERATOR which puts G on the stack. Further, an untagged\nAPO variant which has split R and S values would permit something like\n<sig> OP_GENERATOR OP_GENERATOR CHECKSIGAPO, which would be only 2 more\nbytes than CTV.\n3) I count something like 20 different flags in your proposal. As long as\nflags are under 40 bytes (and 32 assuming we want it to be easy) without\nupgrading math this should be feasible to manipulate on the stack\nprogrammatically. This is ignoring some of the more flexible additions you\nmention about picking which outputs/inputs are included. However, 20 flags\nmeans that for testing we would want comprehensive tests and understanding\nfor ~1 million different flag combos and the behaviors they expose. I think\nthis necessitates a formal model of scripting and transaction validity\nproperties. Are there any combinations that might be undesirable?\n4) Just hashing or not hashing isn't actually that flexible, because it\ndoesn't natively let you do things like (for example) TLUV. You really do\nneed tx operations for directly manipulating the data on the stack to\nconstruct the hash if you want more flexible covenants. This happens to be\ncompatible with either a Verify or Push approach, since you either\ndestructure a pushed hash or build up a hash for a verify.\n5) Flexible hashing has the potential for quadratic hashing bugs. The\nfields you propose seem to be within similar range to work you could cause\nwith a regular OP_HASH256, although you'd want to be careful with some of\nthe proposed extensions that you don't create risk of quadratic hashing,\nwhich seems possible with an output selecting opcode unless you cache\nproperly (which might be tricky to do). Overall for the fields explicitly\nmentioned, seems safe, the \"possibles\" seem to have some more complex\ninteractions. E.g., CTV with the ability to pick a subset of outputs would\nbe exposed to quadratic hashing.\n6) Missing field: covering the annex or some sub-range of the annex\n(quadratic hashing issues on the latter)\n7) It seems simpler to, for many of these fields, push values directly (as\nin OP_PUSHTXDATA from Johnson Lau) because the combo of flags to push the\nhash of a single output's amount to emulate OP_AMOUNT looks 'general but\nannoying'. It may make more sense to do the OP_PUSHTXDATA style opcode\ninstead. This also makes it simpler to think about the combinations of\nflags, since it's really N independent multi-byte opcodes.\n\n\nUltimately if we had OP_TXHASH available \"tomorrow\", I would be able to\nbuild out the use cases I care about for CTV (and more). So I don't have an\nopposition on it with regards to lack of function.\n\nHowever, if one finds the TXHASH approach acceptable, then you should also\nbe relatively fine doing APO, CTV, CSFS, TXHASH acceptable in any order\n(whenever \"ready\"), unless you are particularly sensitive to \"technical\ndebt\" and \"soft fork processes\". The only costs of doing something for CTV\nor APO given an eventual TXHASH is perhaps a wasted key version or the 32\nbyte argument of a NOP opcode and some code to maintain.\n\nAre there other costs I am missing?\n\nHowever, as it pertains to actual rollout:\n\n- OP_TXHASH+CSFSV doesn't seem to be the \"full\" set of things needed (we\nstill need e.g. OP_CAT, Upgraded >=64 bit Math, TLUV or OP_TWEAK\nOP_TAPBRANCH OP_MANIPULATETAPTREE, and more) to full realize covenanting\npower it intends to introduce.\n- What sort of timeline would it take to ready something like TXHASH (and\ndesired friends) given greater scope of testing and analysis (standalone +\ncompared to CTV)?\n- Is there opposition from the community to this degree of\ngeneral/recursive covenants?\n- Does it make \"more sense\" to invest the research and development effort\nthat would go into proving TXHASH safe, for example, into Simplicity\ninstead?\n\nOverall, *my opinion *is that:\n\n- TXHASH is an acceptable theoretical approach, and I am happy to put more\nthought into it and maybe draft a prototype of it.\n- I prefer CTV as a first step for pragmatic engineering and availability\ntimeline reasons.\n- If TXHASH were to take, optimistically, 2 years to develop and review,\nand then 1 year to activate, the \"path dependence of software\" would put\nBitcoin in a much better place were we to have CTV within 1 year and\napplications (that are to be a subset of TXHASH later) being built over the\nnext few years enhanced in the future by TXHASH's availability.\n- There is an element of expediency meritted for something like CTV insofar\nas it provides primitives to tackle time sensitive issues around privacy,\nscalability, self custody, and decentralization. The aforementioned\nproperties may be difficult to reclaim once given away (with the exception\nof perhaps scalability).\n- Bringing CTV to an implemented state of near-unanimous \"we could do this,\ntechnically\" is good for concretely driving the process of review for any\ncovenant proposals forward, irrespective of if we ultimately activate.\n(I.e., if there were a reason we could not do CTV safely, it would likely\nhave implications for any other future covenant)\n\nConcretely, I'm not going to stop advocating for CTV based on the above,\nbut I'm very happy to have something new in the mix to consider!\n\nBest,\n\nJeremy\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Wed, Jan 26, 2022 at 9:23 AM Russell O'Connor via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Recapping the relationship between CTV and ANYPREVOUT::\n>\n> It is known that there is a significant amount of overlap in the\n> applications that are enabled by the CTV and ANYPREVOUT proposals despite\n> the fact that their primary applications (congestion control for CTV and\n> eltoo lightning channels for ANYPREVOUT) are quite distinct.\n> In particular, ANYPREVOUT can enable most of the applications of CTV,\n> albeit with a higher cost.  The primary functionality of CTV is to allow a\n> scriptPubKey to make a commitment to its spending transaction's hash with\n> the input's TXID excluded from the hash.  This exclusion is necessary\n> because the scriptPubKey is hashed into the input's TXID, and including the\n> TXID would cause a cycle of hash commitments, which is impossible to\n> construct.  On the other hand, ANYPREVOUT defines a signature hash mode\n> that similarly excludes the inputs TXID for its purpose of rebindable\n> signatures.\n>\n> This means that ANYPREVOUT can mimic most of the properties of CTV by\n> committing both a public key along with an ANYPREVOUT signature inside\n> scriptPubKey.  In fact, the only reason Bitcoin doesn't have covenants\n> today is due to this cycle between scriptPubKeys and the TXIDs that occur\n> in all the sighash modes.\n>\n> The major differences between simulating CTV via ANYPREVOUT and the actual\n> CTV proposal is: (1) The cost of simulating CTV.  With CTV the spending\n> transaction is committed using a hash of 32 bytes, while simulating it with\n> ANYPREVOUT requires 64 bytes for a signature, and 32 bytes for some public\n> key, plus a few more bytes for various flags.  Some of that cost could be\n> reduced by using the inner public key (1 byte representation) and, if we\n> had CAT, maybe by assembling the signature from reusable pieces (i.e.\n> setting the nonce of the commited signature equal to the public key).\n>\n> The other major difference is: (2) CTV's transaction hash covers values\n> such as the number of inputs in the transaction and their sequence numbers,\n> which ANYPREVOUT does not cover.  CTV's hash contains enough information so\n> that when combined with the missing TXIDs, you can compute the TXID of the\n> spending transaction.  In particular if the number of inputs is committed\n> to being 1, once the scriptpubkey's transaction id is known and committed\n> to the blockchain, the TXID of its spending transaction is deducible.  And\n> if that transaction has outputs that have CTV commitments in them, you can\n> deduce their spending TXIDs in turn.  While this is a pretty neat feature,\n> something that ANYPREVOUT cannot mimic, the main application for it is\n> listed as using congestion control to fund lightning channels, fixing their\n> TXIDs in advance of them being placed on chain.  However, if ANYPREVOUT\n> were used to mimic CTV, then likely it would be eltoo channels that would\n> be funded, and it isn't necessary to know the TXIDs of eltoo channels in\n> advance in order to use them.\n>\n>\n>\n> An Alternative Proposal::\n>\n> Given the overlap in functionality between CTV and ANYPREVOUT, I think it\n> makes sense to decompose their operations into their constituent pieces and\n> reassemble their behaviour programmatically.  To this end, I'd like to\n> instead propose OP_TXHASH and OP_CHECKSIGFROMSTACKVERIFY.\n>\n> OP_TXHASH would pop a txhash flag from the stack and compute a (tagged)\n> txhash in accordance with that flag, and push the resulting hash onto the\n> stack.\n> OP_CHECKSIGFROMSTACKVERIFY would pop a pubkey, message, and signature from\n> the stack and fail if the signature does not verify on that message.\n>\n> CTV and TXHASH have roughly equivalent functionality.  'CTV DROP' can be\n> simulated by '<ctv_style_flag> TXHASH EQUALVERIFY'.  The reverse is also\n> true where '<ctv_style_flag> TXHASH' can be simulated by CTV by\n> '<ctv-result-from-witness-stack> CTV', however, as you can see, simulating\n> TXHASH from CTV is much more expensive than the other way around, because\n> the resulting 32-byte hash result must be included as part of the witness\n> stack.\n>\n> '<anyprevout-pubkey> CHECKSIGVERIFY can be simulated by '<apo_style_flag>\n> TXHASH <pubkey> CHECKSIGFROMSTACKVERIFY'.  Here we see the advantage of\n> pushing the hash value onto the stack.  APO can be simulated without\n> needing to include a copy of the resulting txhash inside the witness data.\n>\n> In addition to the CTV and ANYPREVOUT applications, with\n> CHECKSIGFROMSTACKVERIFY we can verify signatures on arbitrary messages\n> signed by oracles for oracle applications.  This is where we see the\n> benefit of decomposing operations into primitive pieces.  By giving users\n> the ability to program their own use cases from components, we get more\n> applications out of fewer op codes!\n>\n>\n>\n> Caveats::\n>\n> First, I acknowledge that replicating the behaviour of CTV and ANYPREVOUT\n> does cost a few more bytes than using the custom purpose built proposals\n> themselves.  That is the price to be paid when we choose the ability to\n> program solutions from pieces.  But we get to reap the advantages of being\n> able to build more applications from these pieces.\n>\n> Unlike CTV, TXHASH is not NOP-compatable and can only be implemented\n> within tapscript.  In particular, bare CTV isn't possible with this\n> proposal.  However, this proposal doesn't preclude the possibility of\n> having CTV added to legacy script in while having TXHASH added to tapscript.\n>\n> For similar reasons, TXHASH is not amenable to extending the set of\n> txflags at a later date.  In theory, one could have TXHASH\n> abort-with-success when encountering an unknown set of flags.  However,\n> this would make analyzing tapscript much more difficult. Tapscripts would\n> then be able to abort with success or failure depending on the order script\n> fragments are assembled and executed, and getting the order incorrect would\n> be catastrophic.  This behavior is manifestly different from the current\n> batch of OP_SUCCESS opcodes that abort-with-success just by their mere\n> presence, whether they would be executed or not.\n>\n> I believe the difficulties with upgrading TXHASH can be mitigated by\n> designing a robust set of TXHASH flags from the start.  For example having\n> bits to control whether (1) the version is covered; (2) the locktime is\n> covered; (3) txids are covered; (4) sequence numbers are covered; (5) input\n> amounts are covered; (6) input scriptpubkeys are covered; (7) number of\n> inputs is covered; (8) output amounts are covered; (9) output scriptpubkeys\n> are covered; (10) number of outputs is covered; (11) the tapbranch is\n> covered; (12) the tapleaf is covered; (13) the opseparator value is\n> covered; (14) whether all, one, or no inputs are covered; (15) whether all,\n> one or no outputs are covered; (16) whether the one input position is\n> covered; (17) whether the one output position is covered; (18) whether the\n> sighash flags are covered or not (note: whether or not the sighash flags\n> are or are not covered must itself be covered).  Possibly specifying which\n> input or output position is covered in the single case and whether the\n> position is relative to the input's position or is an absolute position.\n>\n> That all said, even if other txhash flag modes are needed in the future,\n> adding TXHASH2 always remains an option.\n>\n>\n>\n> Interactions with potential future opcodes::\n>\n> We should give some consideration on how these opcodes may interact with\n> future opcodes such as CAT, rolling SHA256 opcodes, or how it might\n> interface with other covenant opcodes that may do things like, directly\n> push input or output amounts onto the stack for computation purposes,\n> opcodes which have been added to the Elements project.\n>\n> With CAT and/or rolling SHA256 opcodes and/or existing SHA256 opcodes, the\n> CHECKSIGFROMSTACKVERIFY could verify signatures on programmatically\n> assembled messages.  Also, in combination with multiple calls to TXHASH,\n> could be used to create signatures that commit to complex subsets of\n> transaction data.\n>\n> If new opcodes are added to push parts of the transaction data direction\n> onto the stack, e.g. OP_INSPECTOUTPUTVALUE, there is perhaps concern that\n> they would obsolete TXHASH, since, in the presence of rolling SHA256\n> opcodes, TXHASH could be simulated.  However, given that TXHASH can\n> compactly create a hash of large portions of transaction data, it seems\n> unlikely that TXHASH would fall into disuse.  Also, a combination of TXHASH\n> and transaction introspection opcodes can be used to build \"*subtractive\n> covenants*\".\n>\n> The usual way of building a covenant, which we will call \"*additive *\n> *covenants*\", is to push all the parts of the transaction data you would\n> like to fix onto the stack, hash it all together, and verify the resulting\n> hash matches a fixed value.  Another way of building covenants, which we\n> will call \"*subtractive covenants*\", is to push all the parts of the\n> transaction data you would like to remain free onto the stack.  Then use\n> rolling SHA256 opcodes starting from a fixed midstate that commits to a\n> prefix of the transaction hash data. The free parts are hashed into that\n> midstate.  Finally, the resulting hash value is verified to match a value\n> returned by TXHASH.  The ability to nicely build subtractive covenants\n> depends on the details of how the TXHASH hash value is constructed,\n> something that I'm told CTV has given consideration to.\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220126/ef2eb4e7/attachment-0001.html>"
            },
            {
                "author": "James Lu",
                "date": "2022-01-27T04:20:40",
                "message_text_only": "What if OP_TXHASH is a no op except for the purpose of emulating CTV and\nAPO?\n\nOn Wed, Jan 26, 2022 at 5:16 PM Jeremy via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Hi Russell,\n>\n> Thanks for this email, it's great to see this approach described.\n>\n> A few preliminary notes of feedback:\n>\n> 1) a Verify approach can be made to work for OP_TXHASH (even with CTV\n> as-is) E.g., suppose a semantic added for a single byte stack[-1] sighash\n> flag to read the hash at stack[-2], then the hash can be passed in instead\n> of put on the stack. This has the disadvantage of larger witnesses, but the\n> advantage of allowing undefined sighash flags to pass for any hash type.\n> 2) using the internal key for APO covenants is not an option because it\n> makes transaction construction interactive and precludes contracts with a\n> NUMS point taproot key. Instead, if you want similar savings, you should\n> advocate an OP_GENERATOR which puts G on the stack. Further, an untagged\n> APO variant which has split R and S values would permit something like\n> <sig> OP_GENERATOR OP_GENERATOR CHECKSIGAPO, which would be only 2 more\n> bytes than CTV.\n> 3) I count something like 20 different flags in your proposal. As long as\n> flags are under 40 bytes (and 32 assuming we want it to be easy) without\n> upgrading math this should be feasible to manipulate on the stack\n> programmatically. This is ignoring some of the more flexible additions you\n> mention about picking which outputs/inputs are included. However, 20 flags\n> means that for testing we would want comprehensive tests and understanding\n> for ~1 million different flag combos and the behaviors they expose. I think\n> this necessitates a formal model of scripting and transaction validity\n> properties. Are there any combinations that might be undesirable?\n> 4) Just hashing or not hashing isn't actually that flexible, because it\n> doesn't natively let you do things like (for example) TLUV. You really do\n> need tx operations for directly manipulating the data on the stack to\n> construct the hash if you want more flexible covenants. This happens to be\n> compatible with either a Verify or Push approach, since you either\n> destructure a pushed hash or build up a hash for a verify.\n> 5) Flexible hashing has the potential for quadratic hashing bugs. The\n> fields you propose seem to be within similar range to work you could cause\n> with a regular OP_HASH256, although you'd want to be careful with some of\n> the proposed extensions that you don't create risk of quadratic hashing,\n> which seems possible with an output selecting opcode unless you cache\n> properly (which might be tricky to do). Overall for the fields explicitly\n> mentioned, seems safe, the \"possibles\" seem to have some more complex\n> interactions. E.g., CTV with the ability to pick a subset of outputs would\n> be exposed to quadratic hashing.\n> 6) Missing field: covering the annex or some sub-range of the annex\n> (quadratic hashing issues on the latter)\n> 7) It seems simpler to, for many of these fields, push values directly (as\n> in OP_PUSHTXDATA from Johnson Lau) because the combo of flags to push the\n> hash of a single output's amount to emulate OP_AMOUNT looks 'general but\n> annoying'. It may make more sense to do the OP_PUSHTXDATA style opcode\n> instead. This also makes it simpler to think about the combinations of\n> flags, since it's really N independent multi-byte opcodes.\n>\n>\n> Ultimately if we had OP_TXHASH available \"tomorrow\", I would be able to\n> build out the use cases I care about for CTV (and more). So I don't have an\n> opposition on it with regards to lack of function.\n>\n> However, if one finds the TXHASH approach acceptable, then you should also\n> be relatively fine doing APO, CTV, CSFS, TXHASH acceptable in any order\n> (whenever \"ready\"), unless you are particularly sensitive to \"technical\n> debt\" and \"soft fork processes\". The only costs of doing something for CTV\n> or APO given an eventual TXHASH is perhaps a wasted key version or the 32\n> byte argument of a NOP opcode and some code to maintain.\n>\n> Are there other costs I am missing?\n>\n> However, as it pertains to actual rollout:\n>\n> - OP_TXHASH+CSFSV doesn't seem to be the \"full\" set of things needed (we\n> still need e.g. OP_CAT, Upgraded >=64 bit Math, TLUV or OP_TWEAK\n> OP_TAPBRANCH OP_MANIPULATETAPTREE, and more) to full realize covenanting\n> power it intends to introduce.\n> - What sort of timeline would it take to ready something like TXHASH (and\n> desired friends) given greater scope of testing and analysis (standalone +\n> compared to CTV)?\n> - Is there opposition from the community to this degree of\n> general/recursive covenants?\n> - Does it make \"more sense\" to invest the research and development effort\n> that would go into proving TXHASH safe, for example, into Simplicity\n> instead?\n>\n> Overall, *my opinion *is that:\n>\n> - TXHASH is an acceptable theoretical approach, and I am happy to put more\n> thought into it and maybe draft a prototype of it.\n> - I prefer CTV as a first step for pragmatic engineering and availability\n> timeline reasons.\n> - If TXHASH were to take, optimistically, 2 years to develop and review,\n> and then 1 year to activate, the \"path dependence of software\" would put\n> Bitcoin in a much better place were we to have CTV within 1 year and\n> applications (that are to be a subset of TXHASH later) being built over the\n> next few years enhanced in the future by TXHASH's availability.\n> - There is an element of expediency meritted for something like CTV\n> insofar as it provides primitives to tackle time sensitive issues around\n> privacy, scalability, self custody, and decentralization. The\n> aforementioned properties may be difficult to reclaim once given away (with\n> the exception of perhaps scalability).\n> - Bringing CTV to an implemented state of near-unanimous \"we could do\n> this, technically\" is good for concretely driving the process of review for\n> any covenant proposals forward, irrespective of if we ultimately activate.\n> (I.e., if there were a reason we could not do CTV safely, it would likely\n> have implications for any other future covenant)\n>\n> Concretely, I'm not going to stop advocating for CTV based on the above,\n> but I'm very happy to have something new in the mix to consider!\n>\n> Best,\n>\n> Jeremy\n>\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n>\n>\n> On Wed, Jan 26, 2022 at 9:23 AM Russell O'Connor via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Recapping the relationship between CTV and ANYPREVOUT::\n>>\n>> It is known that there is a significant amount of overlap in the\n>> applications that are enabled by the CTV and ANYPREVOUT proposals despite\n>> the fact that their primary applications (congestion control for CTV and\n>> eltoo lightning channels for ANYPREVOUT) are quite distinct.\n>> In particular, ANYPREVOUT can enable most of the applications of CTV,\n>> albeit with a higher cost.  The primary functionality of CTV is to allow a\n>> scriptPubKey to make a commitment to its spending transaction's hash with\n>> the input's TXID excluded from the hash.  This exclusion is necessary\n>> because the scriptPubKey is hashed into the input's TXID, and including the\n>> TXID would cause a cycle of hash commitments, which is impossible to\n>> construct.  On the other hand, ANYPREVOUT defines a signature hash mode\n>> that similarly excludes the inputs TXID for its purpose of rebindable\n>> signatures.\n>>\n>> This means that ANYPREVOUT can mimic most of the properties of CTV by\n>> committing both a public key along with an ANYPREVOUT signature inside\n>> scriptPubKey.  In fact, the only reason Bitcoin doesn't have covenants\n>> today is due to this cycle between scriptPubKeys and the TXIDs that occur\n>> in all the sighash modes.\n>>\n>> The major differences between simulating CTV via ANYPREVOUT and the\n>> actual CTV proposal is: (1) The cost of simulating CTV.  With CTV the\n>> spending transaction is committed using a hash of 32 bytes, while\n>> simulating it with ANYPREVOUT requires 64 bytes for a signature, and 32\n>> bytes for some public key, plus a few more bytes for various flags.  Some\n>> of that cost could be reduced by using the inner public key (1 byte\n>> representation) and, if we had CAT, maybe by assembling the signature from\n>> reusable pieces (i.e. setting the nonce of the commited signature equal to\n>> the public key).\n>>\n>> The other major difference is: (2) CTV's transaction hash covers values\n>> such as the number of inputs in the transaction and their sequence numbers,\n>> which ANYPREVOUT does not cover.  CTV's hash contains enough information so\n>> that when combined with the missing TXIDs, you can compute the TXID of the\n>> spending transaction.  In particular if the number of inputs is committed\n>> to being 1, once the scriptpubkey's transaction id is known and committed\n>> to the blockchain, the TXID of its spending transaction is deducible.  And\n>> if that transaction has outputs that have CTV commitments in them, you can\n>> deduce their spending TXIDs in turn.  While this is a pretty neat feature,\n>> something that ANYPREVOUT cannot mimic, the main application for it is\n>> listed as using congestion control to fund lightning channels, fixing their\n>> TXIDs in advance of them being placed on chain.  However, if ANYPREVOUT\n>> were used to mimic CTV, then likely it would be eltoo channels that would\n>> be funded, and it isn't necessary to know the TXIDs of eltoo channels in\n>> advance in order to use them.\n>>\n>>\n>>\n>> An Alternative Proposal::\n>>\n>> Given the overlap in functionality between CTV and ANYPREVOUT, I think it\n>> makes sense to decompose their operations into their constituent pieces and\n>> reassemble their behaviour programmatically.  To this end, I'd like to\n>> instead propose OP_TXHASH and OP_CHECKSIGFROMSTACKVERIFY.\n>>\n>> OP_TXHASH would pop a txhash flag from the stack and compute a (tagged)\n>> txhash in accordance with that flag, and push the resulting hash onto the\n>> stack.\n>> OP_CHECKSIGFROMSTACKVERIFY would pop a pubkey, message, and signature\n>> from the stack and fail if the signature does not verify on that message.\n>>\n>> CTV and TXHASH have roughly equivalent functionality.  'CTV DROP' can be\n>> simulated by '<ctv_style_flag> TXHASH EQUALVERIFY'.  The reverse is also\n>> true where '<ctv_style_flag> TXHASH' can be simulated by CTV by\n>> '<ctv-result-from-witness-stack> CTV', however, as you can see, simulating\n>> TXHASH from CTV is much more expensive than the other way around, because\n>> the resulting 32-byte hash result must be included as part of the witness\n>> stack.\n>>\n>> '<anyprevout-pubkey> CHECKSIGVERIFY can be simulated by '<apo_style_flag>\n>> TXHASH <pubkey> CHECKSIGFROMSTACKVERIFY'.  Here we see the advantage of\n>> pushing the hash value onto the stack.  APO can be simulated without\n>> needing to include a copy of the resulting txhash inside the witness data.\n>>\n>> In addition to the CTV and ANYPREVOUT applications, with\n>> CHECKSIGFROMSTACKVERIFY we can verify signatures on arbitrary messages\n>> signed by oracles for oracle applications.  This is where we see the\n>> benefit of decomposing operations into primitive pieces.  By giving users\n>> the ability to program their own use cases from components, we get more\n>> applications out of fewer op codes!\n>>\n>>\n>>\n>> Caveats::\n>>\n>> First, I acknowledge that replicating the behaviour of CTV and ANYPREVOUT\n>> does cost a few more bytes than using the custom purpose built proposals\n>> themselves.  That is the price to be paid when we choose the ability to\n>> program solutions from pieces.  But we get to reap the advantages of being\n>> able to build more applications from these pieces.\n>>\n>> Unlike CTV, TXHASH is not NOP-compatable and can only be implemented\n>> within tapscript.  In particular, bare CTV isn't possible with this\n>> proposal.  However, this proposal doesn't preclude the possibility of\n>> having CTV added to legacy script in while having TXHASH added to tapscript.\n>>\n>> For similar reasons, TXHASH is not amenable to extending the set of\n>> txflags at a later date.  In theory, one could have TXHASH\n>> abort-with-success when encountering an unknown set of flags.  However,\n>> this would make analyzing tapscript much more difficult. Tapscripts would\n>> then be able to abort with success or failure depending on the order script\n>> fragments are assembled and executed, and getting the order incorrect would\n>> be catastrophic.  This behavior is manifestly different from the current\n>> batch of OP_SUCCESS opcodes that abort-with-success just by their mere\n>> presence, whether they would be executed or not.\n>>\n>> I believe the difficulties with upgrading TXHASH can be mitigated by\n>> designing a robust set of TXHASH flags from the start.  For example having\n>> bits to control whether (1) the version is covered; (2) the locktime is\n>> covered; (3) txids are covered; (4) sequence numbers are covered; (5) input\n>> amounts are covered; (6) input scriptpubkeys are covered; (7) number of\n>> inputs is covered; (8) output amounts are covered; (9) output scriptpubkeys\n>> are covered; (10) number of outputs is covered; (11) the tapbranch is\n>> covered; (12) the tapleaf is covered; (13) the opseparator value is\n>> covered; (14) whether all, one, or no inputs are covered; (15) whether all,\n>> one or no outputs are covered; (16) whether the one input position is\n>> covered; (17) whether the one output position is covered; (18) whether the\n>> sighash flags are covered or not (note: whether or not the sighash flags\n>> are or are not covered must itself be covered).  Possibly specifying which\n>> input or output position is covered in the single case and whether the\n>> position is relative to the input's position or is an absolute position.\n>>\n>> That all said, even if other txhash flag modes are needed in the future,\n>> adding TXHASH2 always remains an option.\n>>\n>>\n>>\n>> Interactions with potential future opcodes::\n>>\n>> We should give some consideration on how these opcodes may interact with\n>> future opcodes such as CAT, rolling SHA256 opcodes, or how it might\n>> interface with other covenant opcodes that may do things like, directly\n>> push input or output amounts onto the stack for computation purposes,\n>> opcodes which have been added to the Elements project.\n>>\n>> With CAT and/or rolling SHA256 opcodes and/or existing SHA256 opcodes,\n>> the CHECKSIGFROMSTACKVERIFY could verify signatures on programmatically\n>> assembled messages.  Also, in combination with multiple calls to TXHASH,\n>> could be used to create signatures that commit to complex subsets of\n>> transaction data.\n>>\n>> If new opcodes are added to push parts of the transaction data direction\n>> onto the stack, e.g. OP_INSPECTOUTPUTVALUE, there is perhaps concern that\n>> they would obsolete TXHASH, since, in the presence of rolling SHA256\n>> opcodes, TXHASH could be simulated.  However, given that TXHASH can\n>> compactly create a hash of large portions of transaction data, it seems\n>> unlikely that TXHASH would fall into disuse.  Also, a combination of TXHASH\n>> and transaction introspection opcodes can be used to build \"*subtractive\n>> covenants*\".\n>>\n>> The usual way of building a covenant, which we will call \"*additive *\n>> *covenants*\", is to push all the parts of the transaction data you would\n>> like to fix onto the stack, hash it all together, and verify the resulting\n>> hash matches a fixed value.  Another way of building covenants, which we\n>> will call \"*subtractive covenants*\", is to push all the parts of the\n>> transaction data you would like to remain free onto the stack.  Then use\n>> rolling SHA256 opcodes starting from a fixed midstate that commits to a\n>> prefix of the transaction hash data. The free parts are hashed into that\n>> midstate.  Finally, the resulting hash value is verified to match a value\n>> returned by TXHASH.  The ability to nicely build subtractive covenants\n>> depends on the details of how the TXHASH hash value is constructed,\n>> something that I'm told CTV has given consideration to.\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220126/5c9e6887/attachment-0001.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2022-01-27T19:16:33",
                "message_text_only": "I am sensitive to technical debt and soft fork processes, and I don't\nbelieve I'm unordinary particular about these issues.  Once implemented,\nopcodes must be supported and maintained indefinitely.  Some opcodes are\neasier to maintain than others.  These particular opcodes involve caching\nof hash computations and, for that reason, I would judge them to be of\nmoderate complexity.\n\nBut more importantly, soft-forks are inherently a risky process, so we\nshould be getting as much value out of them as we reasonably can. I don't\nthink implementing a CTV opcode that we expect to largely be obsoleted by a\nTXHASH at a later date is yielding good value from a soft fork process.\n\nThe strongest argument I can make in favour of CTV would be something like:\n\"We definitely want bare CTV and if we are going to add CTV to legacy\nscript (since we cannot use TXHASH in legacy script), then it is actually\neasier not to exclude it from tapscript, even if we plan to add TXHASH to\ntapscript as well.\"\n\nBut that argument basically rests the entire value of CTV on the shoulders\nof bare CTV.  As I understand, the argument for why we want bare CTV,\ninstead of just letting people use tapscript, involves the finer details of\nweight calculations, and I haven't really reviewed that aspect yet.  I\nthink it would need to be pretty compelling to make it worthwhile to add\nCTV for that one use case.\n\n\nRegarding \"OP_TXHASH+CSFSV doesn't seem to be the 'full' set of things\nneeded\", I totally agree we will want more things such as CAT, rolling\nSHA256 opcodes, wider arithmetic, pushing amounts onto the stack, some kind\nof tapleaf manipulation and/or TWEAKVERIFY.  For now, I only want to argue\nTXHASH+CSFSV is better than CTV+APO because it gives us more value, namely\noracle signature verification.  In particular, I want to argue that\nTXHASH's push semantics is better that CTV's verify semantics because it\ncomposes better by not needing to carry an extra 32-bytes (per instance) in\nthe witness data.  I expect that in a world of full recursive covenants,\nTXHASH would still be useful as a fast and cheap way to verify the\n\"payload\" of these covenants, i.e. that a transaction is paying a certain,\npossibly large, set of addresses certain specific amounts of money.  And\neven if not, TXHASH+CSFSV would still be the way that eltoo would be\nimplemented under this proposal.\n\nOn Wed, Jan 26, 2022 at 5:16 PM Jeremy <jlrubin at mit.edu> wrote:\n\n> Hi Russell,\n>\n> Thanks for this email, it's great to see this approach described.\n>\n> A few preliminary notes of feedback:\n>\n> 1) a Verify approach can be made to work for OP_TXHASH (even with CTV\n> as-is) E.g., suppose a semantic added for a single byte stack[-1] sighash\n> flag to read the hash at stack[-2], then the hash can be passed in instead\n> of put on the stack. This has the disadvantage of larger witnesses, but the\n> advantage of allowing undefined sighash flags to pass for any hash type.\n> 2) using the internal key for APO covenants is not an option because it\n> makes transaction construction interactive and precludes contracts with a\n> NUMS point taproot key. Instead, if you want similar savings, you should\n> advocate an OP_GENERATOR which puts G on the stack. Further, an untagged\n> APO variant which has split R and S values would permit something like\n> <sig> OP_GENERATOR OP_GENERATOR CHECKSIGAPO, which would be only 2 more\n> bytes than CTV.\n> 3) I count something like 20 different flags in your proposal. As long as\n> flags are under 40 bytes (and 32 assuming we want it to be easy) without\n> upgrading math this should be feasible to manipulate on the stack\n> programmatically. This is ignoring some of the more flexible additions you\n> mention about picking which outputs/inputs are included. However, 20 flags\n> means that for testing we would want comprehensive tests and understanding\n> for ~1 million different flag combos and the behaviors they expose. I think\n> this necessitates a formal model of scripting and transaction validity\n> properties. Are there any combinations that might be undesirable?\n> 4) Just hashing or not hashing isn't actually that flexible, because it\n> doesn't natively let you do things like (for example) TLUV. You really do\n> need tx operations for directly manipulating the data on the stack to\n> construct the hash if you want more flexible covenants. This happens to be\n> compatible with either a Verify or Push approach, since you either\n> destructure a pushed hash or build up a hash for a verify.\n> 5) Flexible hashing has the potential for quadratic hashing bugs. The\n> fields you propose seem to be within similar range to work you could cause\n> with a regular OP_HASH256, although you'd want to be careful with some of\n> the proposed extensions that you don't create risk of quadratic hashing,\n> which seems possible with an output selecting opcode unless you cache\n> properly (which might be tricky to do). Overall for the fields explicitly\n> mentioned, seems safe, the \"possibles\" seem to have some more complex\n> interactions. E.g., CTV with the ability to pick a subset of outputs would\n> be exposed to quadratic hashing.\n> 6) Missing field: covering the annex or some sub-range of the annex\n> (quadratic hashing issues on the latter)\n> 7) It seems simpler to, for many of these fields, push values directly (as\n> in OP_PUSHTXDATA from Johnson Lau) because the combo of flags to push the\n> hash of a single output's amount to emulate OP_AMOUNT looks 'general but\n> annoying'. It may make more sense to do the OP_PUSHTXDATA style opcode\n> instead. This also makes it simpler to think about the combinations of\n> flags, since it's really N independent multi-byte opcodes.\n>\n>\n> Ultimately if we had OP_TXHASH available \"tomorrow\", I would be able to\n> build out the use cases I care about for CTV (and more). So I don't have an\n> opposition on it with regards to lack of function.\n>\n> However, if one finds the TXHASH approach acceptable, then you should also\n> be relatively fine doing APO, CTV, CSFS, TXHASH acceptable in any order\n> (whenever \"ready\"), unless you are particularly sensitive to \"technical\n> debt\" and \"soft fork processes\". The only costs of doing something for CTV\n> or APO given an eventual TXHASH is perhaps a wasted key version or the 32\n> byte argument of a NOP opcode and some code to maintain.\n>\n> Are there other costs I am missing?\n>\n> However, as it pertains to actual rollout:\n>\n> - OP_TXHASH+CSFSV doesn't seem to be the \"full\" set of things needed (we\n> still need e.g. OP_CAT, Upgraded >=64 bit Math, TLUV or OP_TWEAK\n> OP_TAPBRANCH OP_MANIPULATETAPTREE, and more) to full realize covenanting\n> power it intends to introduce.\n> - What sort of timeline would it take to ready something like TXHASH (and\n> desired friends) given greater scope of testing and analysis (standalone +\n> compared to CTV)?\n> - Is there opposition from the community to this degree of\n> general/recursive covenants?\n> - Does it make \"more sense\" to invest the research and development effort\n> that would go into proving TXHASH safe, for example, into Simplicity\n> instead?\n>\n> Overall, *my opinion *is that:\n>\n> - TXHASH is an acceptable theoretical approach, and I am happy to put more\n> thought into it and maybe draft a prototype of it.\n> - I prefer CTV as a first step for pragmatic engineering and availability\n> timeline reasons.\n> - If TXHASH were to take, optimistically, 2 years to develop and review,\n> and then 1 year to activate, the \"path dependence of software\" would put\n> Bitcoin in a much better place were we to have CTV within 1 year and\n> applications (that are to be a subset of TXHASH later) being built over the\n> next few years enhanced in the future by TXHASH's availability.\n> - There is an element of expediency meritted for something like CTV\n> insofar as it provides primitives to tackle time sensitive issues around\n> privacy, scalability, self custody, and decentralization. The\n> aforementioned properties may be difficult to reclaim once given away (with\n> the exception of perhaps scalability).\n> - Bringing CTV to an implemented state of near-unanimous \"we could do\n> this, technically\" is good for concretely driving the process of review for\n> any covenant proposals forward, irrespective of if we ultimately activate.\n> (I.e., if there were a reason we could not do CTV safely, it would likely\n> have implications for any other future covenant)\n>\n> Concretely, I'm not going to stop advocating for CTV based on the above,\n> but I'm very happy to have something new in the mix to consider!\n>\n> Best,\n>\n> Jeremy\n>\n>\n> --\n> @JeremyRubin <https://twitter.com/JeremyRubin>\n> <https://twitter.com/JeremyRubin>\n>\n>\n> On Wed, Jan 26, 2022 at 9:23 AM Russell O'Connor via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Recapping the relationship between CTV and ANYPREVOUT::\n>>\n>> It is known that there is a significant amount of overlap in the\n>> applications that are enabled by the CTV and ANYPREVOUT proposals despite\n>> the fact that their primary applications (congestion control for CTV and\n>> eltoo lightning channels for ANYPREVOUT) are quite distinct.\n>> In particular, ANYPREVOUT can enable most of the applications of CTV,\n>> albeit with a higher cost.  The primary functionality of CTV is to allow a\n>> scriptPubKey to make a commitment to its spending transaction's hash with\n>> the input's TXID excluded from the hash.  This exclusion is necessary\n>> because the scriptPubKey is hashed into the input's TXID, and including the\n>> TXID would cause a cycle of hash commitments, which is impossible to\n>> construct.  On the other hand, ANYPREVOUT defines a signature hash mode\n>> that similarly excludes the inputs TXID for its purpose of rebindable\n>> signatures.\n>>\n>> This means that ANYPREVOUT can mimic most of the properties of CTV by\n>> committing both a public key along with an ANYPREVOUT signature inside\n>> scriptPubKey.  In fact, the only reason Bitcoin doesn't have covenants\n>> today is due to this cycle between scriptPubKeys and the TXIDs that occur\n>> in all the sighash modes.\n>>\n>> The major differences between simulating CTV via ANYPREVOUT and the\n>> actual CTV proposal is: (1) The cost of simulating CTV.  With CTV the\n>> spending transaction is committed using a hash of 32 bytes, while\n>> simulating it with ANYPREVOUT requires 64 bytes for a signature, and 32\n>> bytes for some public key, plus a few more bytes for various flags.  Some\n>> of that cost could be reduced by using the inner public key (1 byte\n>> representation) and, if we had CAT, maybe by assembling the signature from\n>> reusable pieces (i.e. setting the nonce of the commited signature equal to\n>> the public key).\n>>\n>> The other major difference is: (2) CTV's transaction hash covers values\n>> such as the number of inputs in the transaction and their sequence numbers,\n>> which ANYPREVOUT does not cover.  CTV's hash contains enough information so\n>> that when combined with the missing TXIDs, you can compute the TXID of the\n>> spending transaction.  In particular if the number of inputs is committed\n>> to being 1, once the scriptpubkey's transaction id is known and committed\n>> to the blockchain, the TXID of its spending transaction is deducible.  And\n>> if that transaction has outputs that have CTV commitments in them, you can\n>> deduce their spending TXIDs in turn.  While this is a pretty neat feature,\n>> something that ANYPREVOUT cannot mimic, the main application for it is\n>> listed as using congestion control to fund lightning channels, fixing their\n>> TXIDs in advance of them being placed on chain.  However, if ANYPREVOUT\n>> were used to mimic CTV, then likely it would be eltoo channels that would\n>> be funded, and it isn't necessary to know the TXIDs of eltoo channels in\n>> advance in order to use them.\n>>\n>>\n>>\n>> An Alternative Proposal::\n>>\n>> Given the overlap in functionality between CTV and ANYPREVOUT, I think it\n>> makes sense to decompose their operations into their constituent pieces and\n>> reassemble their behaviour programmatically.  To this end, I'd like to\n>> instead propose OP_TXHASH and OP_CHECKSIGFROMSTACKVERIFY.\n>>\n>> OP_TXHASH would pop a txhash flag from the stack and compute a (tagged)\n>> txhash in accordance with that flag, and push the resulting hash onto the\n>> stack.\n>> OP_CHECKSIGFROMSTACKVERIFY would pop a pubkey, message, and signature\n>> from the stack and fail if the signature does not verify on that message.\n>>\n>> CTV and TXHASH have roughly equivalent functionality.  'CTV DROP' can be\n>> simulated by '<ctv_style_flag> TXHASH EQUALVERIFY'.  The reverse is also\n>> true where '<ctv_style_flag> TXHASH' can be simulated by CTV by\n>> '<ctv-result-from-witness-stack> CTV', however, as you can see, simulating\n>> TXHASH from CTV is much more expensive than the other way around, because\n>> the resulting 32-byte hash result must be included as part of the witness\n>> stack.\n>>\n>> '<anyprevout-pubkey> CHECKSIGVERIFY can be simulated by '<apo_style_flag>\n>> TXHASH <pubkey> CHECKSIGFROMSTACKVERIFY'.  Here we see the advantage of\n>> pushing the hash value onto the stack.  APO can be simulated without\n>> needing to include a copy of the resulting txhash inside the witness data.\n>>\n>> In addition to the CTV and ANYPREVOUT applications, with\n>> CHECKSIGFROMSTACKVERIFY we can verify signatures on arbitrary messages\n>> signed by oracles for oracle applications.  This is where we see the\n>> benefit of decomposing operations into primitive pieces.  By giving users\n>> the ability to program their own use cases from components, we get more\n>> applications out of fewer op codes!\n>>\n>>\n>>\n>> Caveats::\n>>\n>> First, I acknowledge that replicating the behaviour of CTV and ANYPREVOUT\n>> does cost a few more bytes than using the custom purpose built proposals\n>> themselves.  That is the price to be paid when we choose the ability to\n>> program solutions from pieces.  But we get to reap the advantages of being\n>> able to build more applications from these pieces.\n>>\n>> Unlike CTV, TXHASH is not NOP-compatable and can only be implemented\n>> within tapscript.  In particular, bare CTV isn't possible with this\n>> proposal.  However, this proposal doesn't preclude the possibility of\n>> having CTV added to legacy script in while having TXHASH added to tapscript.\n>>\n>> For similar reasons, TXHASH is not amenable to extending the set of\n>> txflags at a later date.  In theory, one could have TXHASH\n>> abort-with-success when encountering an unknown set of flags.  However,\n>> this would make analyzing tapscript much more difficult. Tapscripts would\n>> then be able to abort with success or failure depending on the order script\n>> fragments are assembled and executed, and getting the order incorrect would\n>> be catastrophic.  This behavior is manifestly different from the current\n>> batch of OP_SUCCESS opcodes that abort-with-success just by their mere\n>> presence, whether they would be executed or not.\n>>\n>> I believe the difficulties with upgrading TXHASH can be mitigated by\n>> designing a robust set of TXHASH flags from the start.  For example having\n>> bits to control whether (1) the version is covered; (2) the locktime is\n>> covered; (3) txids are covered; (4) sequence numbers are covered; (5) input\n>> amounts are covered; (6) input scriptpubkeys are covered; (7) number of\n>> inputs is covered; (8) output amounts are covered; (9) output scriptpubkeys\n>> are covered; (10) number of outputs is covered; (11) the tapbranch is\n>> covered; (12) the tapleaf is covered; (13) the opseparator value is\n>> covered; (14) whether all, one, or no inputs are covered; (15) whether all,\n>> one or no outputs are covered; (16) whether the one input position is\n>> covered; (17) whether the one output position is covered; (18) whether the\n>> sighash flags are covered or not (note: whether or not the sighash flags\n>> are or are not covered must itself be covered).  Possibly specifying which\n>> input or output position is covered in the single case and whether the\n>> position is relative to the input's position or is an absolute position.\n>>\n>> That all said, even if other txhash flag modes are needed in the future,\n>> adding TXHASH2 always remains an option.\n>>\n>>\n>>\n>> Interactions with potential future opcodes::\n>>\n>> We should give some consideration on how these opcodes may interact with\n>> future opcodes such as CAT, rolling SHA256 opcodes, or how it might\n>> interface with other covenant opcodes that may do things like, directly\n>> push input or output amounts onto the stack for computation purposes,\n>> opcodes which have been added to the Elements project.\n>>\n>> With CAT and/or rolling SHA256 opcodes and/or existing SHA256 opcodes,\n>> the CHECKSIGFROMSTACKVERIFY could verify signatures on programmatically\n>> assembled messages.  Also, in combination with multiple calls to TXHASH,\n>> could be used to create signatures that commit to complex subsets of\n>> transaction data.\n>>\n>> If new opcodes are added to push parts of the transaction data direction\n>> onto the stack, e.g. OP_INSPECTOUTPUTVALUE, there is perhaps concern that\n>> they would obsolete TXHASH, since, in the presence of rolling SHA256\n>> opcodes, TXHASH could be simulated.  However, given that TXHASH can\n>> compactly create a hash of large portions of transaction data, it seems\n>> unlikely that TXHASH would fall into disuse.  Also, a combination of TXHASH\n>> and transaction introspection opcodes can be used to build \"*subtractive\n>> covenants*\".\n>>\n>> The usual way of building a covenant, which we will call \"*additive *\n>> *covenants*\", is to push all the parts of the transaction data you would\n>> like to fix onto the stack, hash it all together, and verify the resulting\n>> hash matches a fixed value.  Another way of building covenants, which we\n>> will call \"*subtractive covenants*\", is to push all the parts of the\n>> transaction data you would like to remain free onto the stack.  Then use\n>> rolling SHA256 opcodes starting from a fixed midstate that commits to a\n>> prefix of the transaction hash data. The free parts are hashed into that\n>> midstate.  Finally, the resulting hash value is verified to match a value\n>> returned by TXHASH.  The ability to nicely build subtractive covenants\n>> depends on the details of how the TXHASH hash value is constructed,\n>> something that I'm told CTV has given consideration to.\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220127/97b618df/attachment-0001.html>"
            },
            {
                "author": "James O'Beirne",
                "date": "2022-01-28T00:18:54",
                "message_text_only": "> I don't think implementing a CTV opcode that we expect to largely be\nobsoleted by a TXHASH at a later date is yielding good value from a soft\nfork process.\n\nThis presumes the eventual adoption of TXHASH (or something like it).\nYou're presenting a novel idea that, as far as I know, hasn't had much time\nto bake in public. Like Jeremy, I'm concerned by the combinatorial growth\nof flags and the implications that has for testing. Caching for something\nlike TXHASH looks to me like a whole different ballgame relative to CTV,\nwhich has a single kind of hash.\n\nEven if we were to adopt something like TXHASH, how long is it going to\ntake to develop, test, and release? My guess is \"a while\" - in the\nmeantime, users of Bitcoin are without a vault strategy that doesn't\nrequire either presigning transactions with ephemeral keys (operationally\ndifficult) or multisig configurations that would make Rube Goldberg blush\n(operationally difficult and precarious). The utility of vaulting seems\nunderappreciated among consensus devs and it's something I'd like to write\nabout soon in a separate post.\n\n> The strongest argument I can make in favour of CTV would be something\nlike: \"We definitely want bare CTV and if we are going to add CTV to legacy\nscript (since we cannot use TXHASH in legacy script), then it is actually\neasier not to exclude it from tapscript, even if we plan to add TXHASH to\ntapscript as well.\"\n\nAnother argument for CTV (which I find especially persuasive) is its\nsimplicity - it's relatively easy to reason about and, at this point,\npretty well understood. It seems like a low-risk change relative to some of\nthe other covenant proposals, nearly all of which elicit a good deal of\nheadscratching (at least from me) and seem to require not only larger\non-chain footprints but sizable code changes.\n\n> I am sensitive to technical debt and soft fork processes\n\nIf OP_CTV ends up being the most practical approach for vaulting - among\nother things - in terms of weight (which it seems to be at the moment) I\ndon't think \"technical debt\" is an applicable term.\n\nOn Thu, Jan 27, 2022 at 5:20 PM Russell O'Connor via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> I am sensitive to technical debt and soft fork processes, and I don't\n> believe I'm unordinary particular about these issues.  Once implemented,\n> opcodes must be supported and maintained indefinitely.  Some opcodes are\n> easier to maintain than others.  These particular opcodes involve caching\n> of hash computations and, for that reason, I would judge them to be of\n> moderate complexity.\n>\n> But more importantly, soft-forks are inherently a risky process, so we\n> should be getting as much value out of them as we reasonably can. I don't\n> think implementing a CTV opcode that we expect to largely be obsoleted by a\n> TXHASH at a later date is yielding good value from a soft fork process.\n>\n> The strongest argument I can make in favour of CTV would be something\n> like: \"We definitely want bare CTV and if we are going to add CTV to legacy\n> script (since we cannot use TXHASH in legacy script), then it is actually\n> easier not to exclude it from tapscript, even if we plan to add TXHASH to\n> tapscript as well.\"\n>\n> But that argument basically rests the entire value of CTV on the shoulders\n> of bare CTV.  As I understand, the argument for why we want bare CTV,\n> instead of just letting people use tapscript, involves the finer details of\n> weight calculations, and I haven't really reviewed that aspect yet.  I\n> think it would need to be pretty compelling to make it worthwhile to add\n> CTV for that one use case.\n>\n>\n> Regarding \"OP_TXHASH+CSFSV doesn't seem to be the 'full' set of things\n> needed\", I totally agree we will want more things such as CAT, rolling\n> SHA256 opcodes, wider arithmetic, pushing amounts onto the stack, some kind\n> of tapleaf manipulation and/or TWEAKVERIFY.  For now, I only want to argue\n> TXHASH+CSFSV is better than CTV+APO because it gives us more value, namely\n> oracle signature verification.  In particular, I want to argue that\n> TXHASH's push semantics is better that CTV's verify semantics because it\n> composes better by not needing to carry an extra 32-bytes (per instance) in\n> the witness data.  I expect that in a world of full recursive covenants,\n> TXHASH would still be useful as a fast and cheap way to verify the\n> \"payload\" of these covenants, i.e. that a transaction is paying a certain,\n> possibly large, set of addresses certain specific amounts of money.  And\n> even if not, TXHASH+CSFSV would still be the way that eltoo would be\n> implemented under this proposal.\n>\n> On Wed, Jan 26, 2022 at 5:16 PM Jeremy <jlrubin at mit.edu> wrote:\n>\n>> Hi Russell,\n>>\n>> Thanks for this email, it's great to see this approach described.\n>>\n>> A few preliminary notes of feedback:\n>>\n>> 1) a Verify approach can be made to work for OP_TXHASH (even with CTV\n>> as-is) E.g., suppose a semantic added for a single byte stack[-1] sighash\n>> flag to read the hash at stack[-2], then the hash can be passed in instead\n>> of put on the stack. This has the disadvantage of larger witnesses, but the\n>> advantage of allowing undefined sighash flags to pass for any hash type.\n>> 2) using the internal key for APO covenants is not an option because it\n>> makes transaction construction interactive and precludes contracts with a\n>> NUMS point taproot key. Instead, if you want similar savings, you should\n>> advocate an OP_GENERATOR which puts G on the stack. Further, an untagged\n>> APO variant which has split R and S values would permit something like\n>> <sig> OP_GENERATOR OP_GENERATOR CHECKSIGAPO, which would be only 2 more\n>> bytes than CTV.\n>> 3) I count something like 20 different flags in your proposal. As long as\n>> flags are under 40 bytes (and 32 assuming we want it to be easy) without\n>> upgrading math this should be feasible to manipulate on the stack\n>> programmatically. This is ignoring some of the more flexible additions you\n>> mention about picking which outputs/inputs are included. However, 20 flags\n>> means that for testing we would want comprehensive tests and understanding\n>> for ~1 million different flag combos and the behaviors they expose. I think\n>> this necessitates a formal model of scripting and transaction validity\n>> properties. Are there any combinations that might be undesirable?\n>> 4) Just hashing or not hashing isn't actually that flexible, because it\n>> doesn't natively let you do things like (for example) TLUV. You really do\n>> need tx operations for directly manipulating the data on the stack to\n>> construct the hash if you want more flexible covenants. This happens to be\n>> compatible with either a Verify or Push approach, since you either\n>> destructure a pushed hash or build up a hash for a verify.\n>> 5) Flexible hashing has the potential for quadratic hashing bugs. The\n>> fields you propose seem to be within similar range to work you could cause\n>> with a regular OP_HASH256, although you'd want to be careful with some of\n>> the proposed extensions that you don't create risk of quadratic hashing,\n>> which seems possible with an output selecting opcode unless you cache\n>> properly (which might be tricky to do). Overall for the fields explicitly\n>> mentioned, seems safe, the \"possibles\" seem to have some more complex\n>> interactions. E.g., CTV with the ability to pick a subset of outputs would\n>> be exposed to quadratic hashing.\n>> 6) Missing field: covering the annex or some sub-range of the annex\n>> (quadratic hashing issues on the latter)\n>> 7) It seems simpler to, for many of these fields, push values directly\n>> (as in OP_PUSHTXDATA from Johnson Lau) because the combo of flags to push\n>> the hash of a single output's amount to emulate OP_AMOUNT looks 'general\n>> but annoying'. It may make more sense to do the OP_PUSHTXDATA style opcode\n>> instead. This also makes it simpler to think about the combinations of\n>> flags, since it's really N independent multi-byte opcodes.\n>>\n>>\n>> Ultimately if we had OP_TXHASH available \"tomorrow\", I would be able to\n>> build out the use cases I care about for CTV (and more). So I don't have an\n>> opposition on it with regards to lack of function.\n>>\n>> However, if one finds the TXHASH approach acceptable, then you should\n>> also be relatively fine doing APO, CTV, CSFS, TXHASH acceptable in any\n>> order (whenever \"ready\"), unless you are particularly sensitive to\n>> \"technical debt\" and \"soft fork processes\". The only costs of doing\n>> something for CTV or APO given an eventual TXHASH is perhaps a wasted key\n>> version or the 32 byte argument of a NOP opcode and some code to maintain.\n>>\n>> Are there other costs I am missing?\n>>\n>> However, as it pertains to actual rollout:\n>>\n>> - OP_TXHASH+CSFSV doesn't seem to be the \"full\" set of things needed (we\n>> still need e.g. OP_CAT, Upgraded >=64 bit Math, TLUV or OP_TWEAK\n>> OP_TAPBRANCH OP_MANIPULATETAPTREE, and more) to full realize covenanting\n>> power it intends to introduce.\n>> - What sort of timeline would it take to ready something like TXHASH (and\n>> desired friends) given greater scope of testing and analysis (standalone +\n>> compared to CTV)?\n>> - Is there opposition from the community to this degree of\n>> general/recursive covenants?\n>> - Does it make \"more sense\" to invest the research and development effort\n>> that would go into proving TXHASH safe, for example, into Simplicity\n>> instead?\n>>\n>> Overall, *my opinion *is that:\n>>\n>> - TXHASH is an acceptable theoretical approach, and I am happy to put\n>> more thought into it and maybe draft a prototype of it.\n>> - I prefer CTV as a first step for pragmatic engineering and availability\n>> timeline reasons.\n>> - If TXHASH were to take, optimistically, 2 years to develop and review,\n>> and then 1 year to activate, the \"path dependence of software\" would put\n>> Bitcoin in a much better place were we to have CTV within 1 year and\n>> applications (that are to be a subset of TXHASH later) being built over the\n>> next few years enhanced in the future by TXHASH's availability.\n>> - There is an element of expediency meritted for something like CTV\n>> insofar as it provides primitives to tackle time sensitive issues around\n>> privacy, scalability, self custody, and decentralization. The\n>> aforementioned properties may be difficult to reclaim once given away (with\n>> the exception of perhaps scalability).\n>> - Bringing CTV to an implemented state of near-unanimous \"we could do\n>> this, technically\" is good for concretely driving the process of review for\n>> any covenant proposals forward, irrespective of if we ultimately activate.\n>> (I.e., if there were a reason we could not do CTV safely, it would likely\n>> have implications for any other future covenant)\n>>\n>> Concretely, I'm not going to stop advocating for CTV based on the above,\n>> but I'm very happy to have something new in the mix to consider!\n>>\n>> Best,\n>>\n>> Jeremy\n>>\n>>\n>> --\n>> @JeremyRubin <https://twitter.com/JeremyRubin>\n>> <https://twitter.com/JeremyRubin>\n>>\n>>\n>> On Wed, Jan 26, 2022 at 9:23 AM Russell O'Connor via bitcoin-dev <\n>> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>>> Recapping the relationship between CTV and ANYPREVOUT::\n>>>\n>>> It is known that there is a significant amount of overlap in the\n>>> applications that are enabled by the CTV and ANYPREVOUT proposals despite\n>>> the fact that their primary applications (congestion control for CTV and\n>>> eltoo lightning channels for ANYPREVOUT) are quite distinct.\n>>> In particular, ANYPREVOUT can enable most of the applications of CTV,\n>>> albeit with a higher cost.  The primary functionality of CTV is to allow a\n>>> scriptPubKey to make a commitment to its spending transaction's hash with\n>>> the input's TXID excluded from the hash.  This exclusion is necessary\n>>> because the scriptPubKey is hashed into the input's TXID, and including the\n>>> TXID would cause a cycle of hash commitments, which is impossible to\n>>> construct.  On the other hand, ANYPREVOUT defines a signature hash mode\n>>> that similarly excludes the inputs TXID for its purpose of rebindable\n>>> signatures.\n>>>\n>>> This means that ANYPREVOUT can mimic most of the properties of CTV by\n>>> committing both a public key along with an ANYPREVOUT signature inside\n>>> scriptPubKey.  In fact, the only reason Bitcoin doesn't have covenants\n>>> today is due to this cycle between scriptPubKeys and the TXIDs that occur\n>>> in all the sighash modes.\n>>>\n>>> The major differences between simulating CTV via ANYPREVOUT and the\n>>> actual CTV proposal is: (1) The cost of simulating CTV.  With CTV the\n>>> spending transaction is committed using a hash of 32 bytes, while\n>>> simulating it with ANYPREVOUT requires 64 bytes for a signature, and 32\n>>> bytes for some public key, plus a few more bytes for various flags.  Some\n>>> of that cost could be reduced by using the inner public key (1 byte\n>>> representation) and, if we had CAT, maybe by assembling the signature from\n>>> reusable pieces (i.e. setting the nonce of the commited signature equal to\n>>> the public key).\n>>>\n>>> The other major difference is: (2) CTV's transaction hash covers values\n>>> such as the number of inputs in the transaction and their sequence numbers,\n>>> which ANYPREVOUT does not cover.  CTV's hash contains enough information so\n>>> that when combined with the missing TXIDs, you can compute the TXID of the\n>>> spending transaction.  In particular if the number of inputs is committed\n>>> to being 1, once the scriptpubkey's transaction id is known and committed\n>>> to the blockchain, the TXID of its spending transaction is deducible.  And\n>>> if that transaction has outputs that have CTV commitments in them, you can\n>>> deduce their spending TXIDs in turn.  While this is a pretty neat feature,\n>>> something that ANYPREVOUT cannot mimic, the main application for it is\n>>> listed as using congestion control to fund lightning channels, fixing their\n>>> TXIDs in advance of them being placed on chain.  However, if ANYPREVOUT\n>>> were used to mimic CTV, then likely it would be eltoo channels that would\n>>> be funded, and it isn't necessary to know the TXIDs of eltoo channels in\n>>> advance in order to use them.\n>>>\n>>>\n>>>\n>>> An Alternative Proposal::\n>>>\n>>> Given the overlap in functionality between CTV and ANYPREVOUT, I think\n>>> it makes sense to decompose their operations into their constituent pieces\n>>> and reassemble their behaviour programmatically.  To this end, I'd like to\n>>> instead propose OP_TXHASH and OP_CHECKSIGFROMSTACKVERIFY.\n>>>\n>>> OP_TXHASH would pop a txhash flag from the stack and compute a (tagged)\n>>> txhash in accordance with that flag, and push the resulting hash onto the\n>>> stack.\n>>> OP_CHECKSIGFROMSTACKVERIFY would pop a pubkey, message, and signature\n>>> from the stack and fail if the signature does not verify on that message.\n>>>\n>>> CTV and TXHASH have roughly equivalent functionality.  'CTV DROP' can be\n>>> simulated by '<ctv_style_flag> TXHASH EQUALVERIFY'.  The reverse is also\n>>> true where '<ctv_style_flag> TXHASH' can be simulated by CTV by\n>>> '<ctv-result-from-witness-stack> CTV', however, as you can see, simulating\n>>> TXHASH from CTV is much more expensive than the other way around, because\n>>> the resulting 32-byte hash result must be included as part of the witness\n>>> stack.\n>>>\n>>> '<anyprevout-pubkey> CHECKSIGVERIFY can be simulated by\n>>> '<apo_style_flag> TXHASH <pubkey> CHECKSIGFROMSTACKVERIFY'.  Here we see\n>>> the advantage of pushing the hash value onto the stack.  APO can be\n>>> simulated without needing to include a copy of the resulting txhash inside\n>>> the witness data.\n>>>\n>>> In addition to the CTV and ANYPREVOUT applications, with\n>>> CHECKSIGFROMSTACKVERIFY we can verify signatures on arbitrary messages\n>>> signed by oracles for oracle applications.  This is where we see the\n>>> benefit of decomposing operations into primitive pieces.  By giving users\n>>> the ability to program their own use cases from components, we get more\n>>> applications out of fewer op codes!\n>>>\n>>>\n>>>\n>>> Caveats::\n>>>\n>>> First, I acknowledge that replicating the behaviour of CTV and\n>>> ANYPREVOUT does cost a few more bytes than using the custom purpose built\n>>> proposals themselves.  That is the price to be paid when we choose the\n>>> ability to program solutions from pieces.  But we get to reap the\n>>> advantages of being able to build more applications from these pieces.\n>>>\n>>> Unlike CTV, TXHASH is not NOP-compatable and can only be implemented\n>>> within tapscript.  In particular, bare CTV isn't possible with this\n>>> proposal.  However, this proposal doesn't preclude the possibility of\n>>> having CTV added to legacy script in while having TXHASH added to tapscript.\n>>>\n>>> For similar reasons, TXHASH is not amenable to extending the set of\n>>> txflags at a later date.  In theory, one could have TXHASH\n>>> abort-with-success when encountering an unknown set of flags.  However,\n>>> this would make analyzing tapscript much more difficult. Tapscripts would\n>>> then be able to abort with success or failure depending on the order script\n>>> fragments are assembled and executed, and getting the order incorrect would\n>>> be catastrophic.  This behavior is manifestly different from the current\n>>> batch of OP_SUCCESS opcodes that abort-with-success just by their mere\n>>> presence, whether they would be executed or not.\n>>>\n>>> I believe the difficulties with upgrading TXHASH can be mitigated by\n>>> designing a robust set of TXHASH flags from the start.  For example having\n>>> bits to control whether (1) the version is covered; (2) the locktime is\n>>> covered; (3) txids are covered; (4) sequence numbers are covered; (5) input\n>>> amounts are covered; (6) input scriptpubkeys are covered; (7) number of\n>>> inputs is covered; (8) output amounts are covered; (9) output scriptpubkeys\n>>> are covered; (10) number of outputs is covered; (11) the tapbranch is\n>>> covered; (12) the tapleaf is covered; (13) the opseparator value is\n>>> covered; (14) whether all, one, or no inputs are covered; (15) whether all,\n>>> one or no outputs are covered; (16) whether the one input position is\n>>> covered; (17) whether the one output position is covered; (18) whether the\n>>> sighash flags are covered or not (note: whether or not the sighash flags\n>>> are or are not covered must itself be covered).  Possibly specifying which\n>>> input or output position is covered in the single case and whether the\n>>> position is relative to the input's position or is an absolute position.\n>>>\n>>> That all said, even if other txhash flag modes are needed in the future,\n>>> adding TXHASH2 always remains an option.\n>>>\n>>>\n>>>\n>>> Interactions with potential future opcodes::\n>>>\n>>> We should give some consideration on how these opcodes may interact with\n>>> future opcodes such as CAT, rolling SHA256 opcodes, or how it might\n>>> interface with other covenant opcodes that may do things like, directly\n>>> push input or output amounts onto the stack for computation purposes,\n>>> opcodes which have been added to the Elements project.\n>>>\n>>> With CAT and/or rolling SHA256 opcodes and/or existing SHA256 opcodes,\n>>> the CHECKSIGFROMSTACKVERIFY could verify signatures on programmatically\n>>> assembled messages.  Also, in combination with multiple calls to TXHASH,\n>>> could be used to create signatures that commit to complex subsets of\n>>> transaction data.\n>>>\n>>> If new opcodes are added to push parts of the transaction data direction\n>>> onto the stack, e.g. OP_INSPECTOUTPUTVALUE, there is perhaps concern that\n>>> they would obsolete TXHASH, since, in the presence of rolling SHA256\n>>> opcodes, TXHASH could be simulated.  However, given that TXHASH can\n>>> compactly create a hash of large portions of transaction data, it seems\n>>> unlikely that TXHASH would fall into disuse.  Also, a combination of TXHASH\n>>> and transaction introspection opcodes can be used to build \"*subtractive\n>>> covenants*\".\n>>>\n>>> The usual way of building a covenant, which we will call \"*additive *\n>>> *covenants*\", is to push all the parts of the transaction data you\n>>> would like to fix onto the stack, hash it all together, and verify the\n>>> resulting hash matches a fixed value.  Another way of building covenants,\n>>> which we will call \"*subtractive covenants*\", is to push all the parts\n>>> of the transaction data you would like to remain free onto the stack.  Then\n>>> use rolling SHA256 opcodes starting from a fixed midstate that commits to a\n>>> prefix of the transaction hash data. The free parts are hashed into that\n>>> midstate.  Finally, the resulting hash value is verified to match a value\n>>> returned by TXHASH.  The ability to nicely build subtractive covenants\n>>> depends on the details of how the TXHASH hash value is constructed,\n>>> something that I'm told CTV has given consideration to.\n>>> _______________________________________________\n>>> bitcoin-dev mailing list\n>>> bitcoin-dev at lists.linuxfoundation.org\n>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>\n>> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220127/0c0eb4e2/attachment-0001.html>"
            },
            {
                "author": "Michael Folkson",
                "date": "2022-01-28T13:14:07",
                "message_text_only": "> Even if we were to adopt something like TXHASH, how long is it going to take to develop, test, and release? My guess is \"a while\" - in the meantime, users of Bitcoin are without a vault strategy that doesn't require either presigning transactions with ephemeral keys (operationally difficult) or multisig configurations that would make Rube Goldberg blush (operationally difficult and precarious).\n\nTo me this seems to be jumping ahead a number of steps from where we are at the current time. If the ecosystem was widely using all the tools available to them at the current time (MuSig(2), Taproot trees to embed complex scripts, Miniscript etc), was testing out upcoming available tools like threshold key aggregation schemes (e.g. FROST) on signets and the final missing piece was a covenant opcode to avoid the deleted key requirement then the argument for urgency would be stronger. I would still share the concerns I and many others have repeated over rushing soft forks and treating mainnet as a testbed for new use cases rather than the final destination for changes that will stand the test of time. But I would be a lot more sympathetic to that argument.\n\nThis isn't a criticism of the ecosystem or individual vault projects like Revault, it is clearly still very early. darosior (Revault) is working on getting a first version of Miniscript finalized and in Core [0] and I'm assuming will be part of the effort to get Taproot support in Miniscript assuming that initial effort succeeds. Murch is tracking basic send and receive to the P2TR addresses (not complex scripts, multisig, MuSig(2), merely single key spends) in the ecosystem [1] and there is still a long way to go there.\n\nThere are a bunch of covenant opcodes that have been enabled on Liquid [2] that I haven't heard yet of anyone building vault prototypes with. It would be good to get others (TLUV, TXHASH) in future. There is not even a custom signet with CTV (as far as I know) for those who subscribe to the view that we must rush to get CTV activated on mainnet as soon as possible with no thought to what opcodes might follow.\n\nWhen this discussion focuses on the pros and cons of various proposals and how they are being tested and used in prototypes on signets, sidechains I think it is really productive. But when it gets onto urgency (or worse activation speculation) I am just perplexed. That viewpoint seems to completely ignore where we are currently with Taproot use and tooling (on which most vault designs will presumably build) and even more perplexingly where we are with vault prototypes on signets, sidechains.\n\nI am sure at some point in the future we will have various vault prototypes on signets, sidechains making use of Taproot, Miniscript, MuSig(2), FROST etc and crying out for a covenant opcode or sighash flag to go into production on mainnet. But we seem miles away from that at the present time.\n\n[0]: https://github.com/bitcoin/bitcoin/pull/24147\n[1]: https://en.bitcoin.it/wiki/Bech32_adoption\n[2]: https://github.com/ElementsProject/elements/blob/master/doc/tapscript_opcodes.md\n\n--\nMichael Folkson\nEmail: michaelfolkson at [protonmail.com](http://protonmail.com/)\nKeybase: michaelfolkson\nPGP: 43ED C999 9F85 1D40 EAF4 9835 92D6 0159 214C FEE3\n\n\u2010\u2010\u2010\u2010\u2010\u2010\u2010 Original Message \u2010\u2010\u2010\u2010\u2010\u2010\u2010\nOn Friday, January 28th, 2022 at 12:18 AM, James O'Beirne via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n\n>> I don't think implementing a CTV opcode that we expect to largely be obsoleted by a TXHASH at a later date is yielding good value from a soft fork process.\n>\n> This presumes the eventual adoption of TXHASH (or something like it). You're presenting a novel idea that, as far as I know, hasn't had much time to bake in public. Like Jeremy, I'm concerned by the combinatorial growth of flags and the implications that has for testing. Caching for something like TXHASH looks to me like a whole different ballgame relative to CTV, which has a single kind of hash.\n>\n> Even if we were to adopt something like TXHASH, how long is it going to take to develop, test, and release? My guess is \"a while\" - in the meantime, users of Bitcoin are without a vault strategy that doesn't require either presigning transactions with ephemeral keys (operationally difficult) or multisig configurations that would make Rube Goldberg blush (operationally difficult and precarious). The utility of vaulting seems underappreciated among consensus devs and it's something I'd like to write about soon in a separate post.\n>\n>> The strongest argument I can make in favour of CTV would be something like: \"We definitely want bare CTV and if we are going to add CTV to legacy script (since we cannot use TXHASH in legacy script), then it is actually easier not to exclude it from tapscript, even if we plan to add TXHASH to tapscript as well.\"\n>\n> Another argument for CTV (which I find especially persuasive) is its simplicity - it's relatively easy to reason about and, at this point, pretty well understood. It seems like a low-risk change relative to some of the other covenant proposals, nearly all of which elicit a good deal of headscratching (at least from me) and seem to require not only larger on-chain footprints but sizable code changes.\n>\n>> I am sensitive to technical debt and soft fork processes\n>\n> If OP_CTV ends up being the most practical approach for vaulting - among other things - in terms of weight (which it seems to be at the moment) I don't think \"technical debt\" is an applicable term.\n>\n> On Thu, Jan 27, 2022 at 5:20 PM Russell O'Connor via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> I am sensitive to technical debt and soft fork processes, and I don't believe I'm unordinary particular about these issues. Once implemented, opcodes must be supported and maintained indefinitely. Some opcodes are easier to maintain than others. These particular opcodes involve caching of hash computations and, for that reason, I would judge them to be of moderate complexity.\n>>\n>> But more importantly, soft-forks are inherently a risky process, so we should be getting as much value out of them as we reasonably can. I don't think implementing a CTV opcode that we expect to largely be obsoleted by a TXHASH at a later date is yielding good value from a soft fork process.\n>>\n>> The strongest argument I can make in favour of CTV would be something like: \"We definitely want bare CTV and if we are going to add CTV to legacy script (since we cannot use TXHASH in legacy script), then it is actually easier not to exclude it from tapscript, even if we plan to add TXHASH to tapscript as well.\"\n>>\n>> But that argument basically rests the entire value of CTV on the shoulders of bare CTV. As I understand, the argument for why we want bare CTV, instead of just letting people use tapscript, involves the finer details of weight calculations, and I haven't really reviewed that aspect yet. I think it would need to be pretty compelling to make it worthwhile to add CTV for that one use case.\n>>\n>> Regarding \"OP_TXHASH+CSFSV doesn't seem to be the 'full' set of things needed\", I totally agree we will want more things such as CAT, rolling SHA256 opcodes, wider arithmetic, pushing amounts onto the stack, some kind of tapleaf manipulation and/or TWEAKVERIFY. For now, I only want to argue TXHASH+CSFSV is better than CTV+APO because it gives us more value, namely oracle signature verification. In particular, I want to argue that TXHASH's push semantics is better that CTV's verify semantics because it composes better by not needing to carry an extra 32-bytes (per instance) in the witness data. I expect that in a world of full recursive covenants, TXHASH would still be useful as a fast and cheap way to verify the \"payload\" of these covenants, i.e. that a transaction is paying a certain, possibly large, set of addresses certain specific amounts of money. And even if not, TXHASH+CSFSV would still be the way that eltoo would be implemented under this proposal.\n>>\n>> On Wed, Jan 26, 2022 at 5:16 PM Jeremy <jlrubin at mit.edu> wrote:\n>>\n>>> Hi Russell,\n>>>\n>>> Thanks for this email, it's great to see this approach described.\n>>>\n>>> A few preliminary notes of feedback:\n>>>\n>>> 1) a Verify approach can be made to work for OP_TXHASH (even with CTV as-is) E.g., suppose a semantic added for a single byte stack[-1] sighash flag to read the hash at stack[-2], then the hash can be passed in instead of put on the stack. This has the disadvantage of larger witnesses, but the advantage of allowing undefined sighash flags to pass for any hash type.\n>>> 2) using the internal key for APO covenants is not an option because it makes transaction construction interactive and precludes contracts with a NUMS point taproot key. Instead, if you want similar savings, you should advocate an OP_GENERATOR which puts G on the stack. Further, an untagged APO variant which has split R and S values would permit something like <sig> OP_GENERATOR OP_GENERATOR CHECKSIGAPO, which would be only 2 more bytes than CTV.\n>>> 3) I count something like 20 different flags in your proposal. As long as flags are under 40 bytes (and 32 assuming we want it to be easy) without upgrading math this should be feasible to manipulate on the stack programmatically. This is ignoring some of the more flexible additions you mention about picking which outputs/inputs are included. However, 20 flags means that for testing we would want comprehensive tests and understanding for ~1 million different flag combos and the behaviors they expose. I think this necessitates a formal model of scripting and transaction validity properties. Are there any combinations that might be undesirable?\n>>> 4) Just hashing or not hashing isn't actually that flexible, because it doesn't natively let you do things like (for example) TLUV. You really do need tx operations for directly manipulating the data on the stack to construct the hash if you want more flexible covenants. This happens to be compatible with either a Verify or Push approach, since you either destructure a pushed hash or build up a hash for a verify.\n>>> 5) Flexible hashing has the potential for quadratic hashing bugs. The fields you propose seem to be within similar range to work you could cause with a regular OP_HASH256, although you'd want to be careful with some of the proposed extensions that you don't create risk of quadratic hashing, which seems possible with an output selecting opcode unless you cache properly (which might be tricky to do). Overall for the fields explicitly mentioned, seems safe, the \"possibles\" seem to have some more complex interactions. E.g., CTV with the ability to pick a subset of outputs would be exposed to quadratic hashing.\n>>> 6) Missing field: covering the annex or some sub-range of the annex (quadratic hashing issues on the latter)\n>>> 7) It seems simpler to, for many of these fields, push values directly (as in OP_PUSHTXDATA from Johnson Lau) because the combo of flags to push the hash of a single output's amount to emulate OP_AMOUNT looks 'general but annoying'. It may make more sense to do the OP_PUSHTXDATA style opcode instead. This also makes it simpler to think about the combinations of flags, since it's really N independent multi-byte opcodes.\n>>>\n>>> Ultimately if we had OP_TXHASH available \"tomorrow\", I would be able to build out the use cases I care about for CTV (and more). So I don't have an opposition on it with regards to lack of function.\n>>>\n>>> However, if one finds the TXHASH approach acceptable, then you should also be relatively fine doing APO, CTV, CSFS, TXHASH acceptable in any order (whenever \"ready\"), unless you are particularly sensitive to \"technical debt\" and \"soft fork processes\". The only costs of doing something for CTV or APO given an eventual TXHASH is perhaps a wasted key version or the 32 byte argument of a NOP opcode and some code to maintain.\n>>>\n>>> Are there other costs I am missing?\n>>>\n>>> However, as it pertains to actual rollout:\n>>>\n>>> - OP_TXHASH+CSFSV doesn't seem to be the \"full\" set of things needed (we still need e.g. OP_CAT, Upgraded >=64 bit Math, TLUV or OP_TWEAK OP_TAPBRANCH OP_MANIPULATETAPTREE, and more) to full realize covenanting power it intends to introduce.\n>>> - What sort of timeline would it take to ready something like TXHASH (and desired friends) given greater scope of testing and analysis (standalone + compared to CTV)?\n>>> - Is there opposition from the community to this degree of general/recursive covenants?\n>>> - Does it make \"more sense\" to invest the research and development effort that would go into proving TXHASH safe, for example, into Simplicity instead?\n>>>\n>>> Overall, my opinion is that:\n>>>\n>>> - TXHASH is an acceptable theoretical approach, and I am happy to put more thought into it and maybe draft a prototype of it.\n>>> - I prefer CTV as a first step for pragmatic engineering and availability timeline reasons.\n>>> - If TXHASH were to take, optimistically, 2 years to develop and review, and then 1 year to activate, the \"path dependence of software\" would put Bitcoin in a much better place were we to have CTV within 1 year and applications (that are to be a subset of TXHASH later) being built over the next few years enhanced in the future by TXHASH's availability.\n>>> - There is an element of expediency meritted for something like CTV insofar as it provides primitives to tackle time sensitive issues around privacy, scalability, self custody, and decentralization. The aforementioned properties may be difficult to reclaim once given away (with the exception of perhaps scalability).\n>>> - Bringing CTV to an implemented state of near-unanimous \"we could do this, technically\" is good for concretely driving the process of review for any covenant proposals forward, irrespective of if we ultimately activate. (I.e., if there were a reason we could not do CTV safely, it would likely have implications for any other future covenant)\n>>>\n>>> Concretely, I'm not going to stop advocating for CTV based on the above, but I'm very happy to have something new in the mix to consider!\n>>>\n>>> Best,\n>>>\n>>> Jeremy\n>>>\n>>> --\n>>> [@JeremyRubin](https://twitter.com/JeremyRubin)https://twitter.com/JeremyRubin\n>>>\n>>> On Wed, Jan 26, 2022 at 9:23 AM Russell O'Connor via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>\n>>>> Recapping the relationship between CTV and ANYPREVOUT::\n>>>>\n>>>> It is known that there is a significant amount of overlap in the applications that are enabled by the CTV and ANYPREVOUT proposals despite the fact that their primary applications (congestion control for CTV and eltoo lightning channels for ANYPREVOUT) are quite distinct.\n>>>> In particular, ANYPREVOUT can enable most of the applications of CTV, albeit with a higher cost. The primary functionality of CTV is to allow a scriptPubKey to make a commitment to its spending transaction's hash with the input's TXID excluded from the hash. This exclusion is necessary because the scriptPubKey is hashed into the input's TXID, and including the TXID would cause a cycle of hash commitments, which is impossible to construct. On the other hand, ANYPREVOUT defines a signature hash mode that similarly excludes the inputs TXID for its purpose of rebindable signatures.\n>>>>\n>>>> This means that ANYPREVOUT can mimic most of the properties of CTV by committing both a public key along with an ANYPREVOUT signature inside scriptPubKey. In fact, the only reason Bitcoin doesn't have covenants today is due to this cycle between scriptPubKeys and the TXIDs that occur in all the sighash modes.\n>>>>\n>>>> The major differences between simulating CTV via ANYPREVOUT and the actual CTV proposal is: (1) The cost of simulating CTV. With CTV the spending transaction is committed using a hash of 32 bytes, while simulating it with ANYPREVOUT requires 64 bytes for a signature, and 32 bytes for some public key, plus a few more bytes for various flags. Some of that cost could be reduced by using the inner public key (1 byte representation) and, if we had CAT, maybe by assembling the signature from reusable pieces (i.e. setting the nonce of the commited signature equal to the public key).\n>>>>\n>>>> The other major difference is: (2) CTV's transaction hash covers values such as the number of inputs in the transaction and their sequence numbers, which ANYPREVOUT does not cover. CTV's hash contains enough information so that when combined with the missing TXIDs, you can compute the TXID of the spending transaction. In particular if the number of inputs is committed to being 1, once the scriptpubkey's transaction id is known and committed to the blockchain, the TXID of its spending transaction is deducible. And if that transaction has outputs that have CTV commitments in them, you can deduce their spending TXIDs in turn. While this is a pretty neat feature, something that ANYPREVOUT cannot mimic, the main application for it is listed as using congestion control to fund lightning channels, fixing their TXIDs in advance of them being placed on chain. However, if ANYPREVOUT were used to mimic CTV, then likely it would be eltoo channels that would be funded, and it isn't necessary to know the TXIDs of eltoo channels in advance in order to use them.\n>>>>\n>>>> An Alternative Proposal::\n>>>>\n>>>> Given the overlap in functionality between CTV and ANYPREVOUT, I think it makes sense to decompose their operations into their constituent pieces and reassemble their behaviour programmatically. To this end, I'd like to instead propose OP_TXHASH and OP_CHECKSIGFROMSTACKVERIFY.\n>>>>\n>>>> OP_TXHASH would pop a txhash flag from the stack and compute a (tagged) txhash in accordance with that flag, and push the resulting hash onto the stack.\n>>>> OP_CHECKSIGFROMSTACKVERIFY would pop a pubkey, message, and signature from the stack and fail if the signature does not verify on that message.\n>>>>\n>>>> CTV and TXHASH have roughly equivalent functionality. 'CTV DROP' can be simulated by '<ctv_style_flag> TXHASH EQUALVERIFY'. The reverse is also true where '<ctv_style_flag> TXHASH' can be simulated by CTV by '<ctv-result-from-witness-stack> CTV', however, as you can see, simulating TXHASH from CTV is much more expensive than the other way around, because the resulting 32-byte hash result must be included as part of the witness stack.\n>>>>\n>>>> '<anyprevout-pubkey> CHECKSIGVERIFY can be simulated by '<apo_style_flag> TXHASH <pubkey> CHECKSIGFROMSTACKVERIFY'. Here we see the advantage of pushing the hash value onto the stack. APO can be simulated without needing to include a copy of the resulting txhash inside the witness data.\n>>>>\n>>>> In addition to the CTV and ANYPREVOUT applications, with CHECKSIGFROMSTACKVERIFY we can verify signatures on arbitrary messages signed by oracles for oracle applications. This is where we see the benefit of decomposing operations into primitive pieces. By giving users the ability to program their own use cases from components, we get more applications out of fewer op codes!\n>>>>\n>>>> Caveats::\n>>>>\n>>>> First, I acknowledge that replicating the behaviour of CTV and ANYPREVOUT does cost a few more bytes than using the custom purpose built proposals themselves. That is the price to be paid when we choose the ability to program solutions from pieces. But we get to reap the advantages of being able to build more applications from these pieces.\n>>>>\n>>>> Unlike CTV, TXHASH is not NOP-compatable and can only be implemented within tapscript. In particular, bare CTV isn't possible with this proposal. However, this proposal doesn't preclude the possibility of having CTV added to legacy script in while having TXHASH added to tapscript.\n>>>>\n>>>> For similar reasons, TXHASH is not amenable to extending the set of txflags at a later date. In theory, one could have TXHASH abort-with-success when encountering an unknown set of flags. However, this would make analyzing tapscript much more difficult. Tapscripts would then be able to abort with success or failure depending on the order script fragments are assembled and executed, and getting the order incorrect would be catastrophic. This behavior is manifestly different from the current batch of OP_SUCCESS opcodes that abort-with-success just by their mere presence, whether they would be executed or not.\n>>>>\n>>>> I believe the difficulties with upgrading TXHASH can be mitigated by designing a robust set of TXHASH flags from the start. For example having bits to control whether (1) the version is covered; (2) the locktime is covered; (3) txids are covered; (4) sequence numbers are covered; (5) input amounts are covered; (6) input scriptpubkeys are covered; (7) number of inputs is covered; (8) output amounts are covered; (9) output scriptpubkeys are covered; (10) number of outputs is covered; (11) the tapbranch is covered; (12) the tapleaf is covered; (13) the opseparator value is covered; (14) whether all, one, or no inputs are covered; (15) whether all, one or no outputs are covered; (16) whether the one input position is covered; (17) whether the one output position is covered; (18) whether the sighash flags are covered or not (note: whether or not the sighash flags are or are not covered must itself be covered). Possibly specifying which input or output position is covered in the single case and whether the position is relative to the input's position or is an absolute position.\n>>>>\n>>>> That all said, even if other txhash flag modes are needed in the future, adding TXHASH2 always remains an option.\n>>>>\n>>>> Interactions with potential future opcodes::\n>>>>\n>>>> We should give some consideration on how these opcodes may interact with future opcodes such as CAT, rolling SHA256 opcodes, or how it might interface with other covenant opcodes that may do things like, directly push input or output amounts onto the stack for computation purposes, opcodes which have been added to the Elements project.\n>>>>\n>>>> With CAT and/or rolling SHA256 opcodes and/or existing SHA256 opcodes, the CHECKSIGFROMSTACKVERIFY could verify signatures on programmatically assembled messages. Also, in combination with multiple calls to TXHASH, could be used to create signatures that commit to complex subsets of transaction data.\n>>>>\n>>>> If new opcodes are added to push parts of the transaction data direction onto the stack, e.g. OP_INSPECTOUTPUTVALUE, there is perhaps concern that they would obsolete TXHASH, since, in the presence of rolling SHA256 opcodes, TXHASH could be simulated. However, given that TXHASH can compactly create a hash of large portions of transaction data, it seems unlikely that TXHASH would fall into disuse. Also, a combination of TXHASH and transaction introspection opcodes can be used to build \"subtractive covenants\".\n>>>>\n>>>> The usual way of building a covenant, which we will call \"additive covenants\", is to push all the parts of the transaction data you would like to fix onto the stack, hash it all together, and verify the resulting hash matches a fixed value. Another way of building covenants, which we will call \"subtractive covenants\", is to push all the parts of the transaction data you would like to remain free onto the stack. Then use rolling SHA256 opcodes starting from a fixed midstate that commits to a prefix of the transaction hash data. The free parts are hashed into that midstate. Finally, the resulting hash value is verified to match a value returned by TXHASH. The ability to nicely build subtractive covenants depends on the details of how the TXHASH hash value is constructed, something that I'm told CTV has given consideration to.\n>>>> _______________________________________________\n>>>> bitcoin-dev mailing list\n>>>> bitcoin-dev at lists.linuxfoundation.org\n>>>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/4df9e5b2/attachment-0001.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2022-01-28T14:17:40",
                "message_text_only": "On Fri, Jan 28, 2022 at 01:14:07PM +0000, Michael Folkson via bitcoin-dev wrote:\n> There is not even a custom signet with CTV (as far as I know) \n\nhttps://twitter.com/jeremyrubin/status/1339699281192656897\n\nsignetchallenge=512102946e8ba8eca597194e7ed90377d9bbebc5d17a9609ab3e35e706612ee882759351ae\naddnode=50.18.75.225\n\nBut I think there's only been a single coinbase consolidation tx, and no\nactual CTV transactions?\n\nCheers,\naj"
            },
            {
                "author": "Jeremy",
                "date": "2022-01-28T16:38:58",
                "message_text_only": "I probably need to reset it -- I ran into some issues with the IBD latch\nbug IIRC and had difficulty producing new blocks.\n\nI sent funds as a manual faucet to at least one person... not aware of\nanyone else finding use for the signet. In part this is due to the fact\nthat in order to run a signet, you also kind of need to run some kind of\nfaucet on it, which wasn't readily available when I launched it previously.\nI think I can use https://github.com/jsarenik/bitcoin-faucet-shell now\nthough.\n\nUsually people are using Regtest to play around with CTV less so Signet.\nThere is value in a signet, but I don't think that \"there's not a signet\nfor it\" is a blocking issue v.s. nice to have.\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\n\nOn Fri, Jan 28, 2022 at 6:18 AM Anthony Towns via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Fri, Jan 28, 2022 at 01:14:07PM +0000, Michael Folkson via bitcoin-dev\n> wrote:\n> > There is not even a custom signet with CTV (as far as I know)\n>\n> https://twitter.com/jeremyrubin/status/1339699281192656897\n>\n>\n> signetchallenge=512102946e8ba8eca597194e7ed90377d9bbebc5d17a9609ab3e35e706612ee882759351ae\n> addnode=50.18.75.225\n>\n> But I think there's only been a single coinbase consolidation tx, and no\n> actual CTV transactions?\n>\n> Cheers,\n> aj\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/e92ac17f/attachment.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2022-01-28T14:13:11",
                "message_text_only": "On Thu, Jan 27, 2022 at 7:19 PM James O'Beirne <james.obeirne at gmail.com>\nwrote:\n\n> > I don't think implementing a CTV opcode that we expect to largely be\n> obsoleted by a TXHASH at a later date is yielding good value from a soft\n> fork process.\n>\n> This presumes the eventual adoption of TXHASH (or something like it).\n> You're presenting a novel idea that, as far as I know, hasn't had much time\n> to bake in public. Like Jeremy, I'm concerned by the combinatorial growth\n> of flags and the implications that has for testing. Caching for something\n> like TXHASH looks to me like a whole different ballgame relative to CTV,\n> which has a single kind of hash.\n>\n\nLet's not overstate the concern around the combinatorics of TXHASH.   It's\nnot like there is a vast amount of cross-flag interaction we are talking\nabout here.  There are also a combinatorial number of ways of assembling\nopcodes in Bitcoin script, but we aren't required to exhaustively test\nevery single possible Script program.\n\n\n> Even if we were to adopt something like TXHASH, how long is it going to\n> take to develop, test, and release? My guess is \"a while\" - in the\n> meantime, users of Bitcoin are without a vault strategy that doesn't\n> require either presigning transactions with ephemeral keys (operationally\n> difficult) or multisig configurations that would make Rube Goldberg blush\n> (operationally difficult and precarious). The utility of vaulting seems\n> underappreciated among consensus devs and it's something I'd like to write\n> about soon in a separate post.\n>\n> > The strongest argument I can make in favour of CTV would be something\n> like: \"We definitely want bare CTV and if we are going to add CTV to legacy\n> script (since we cannot use TXHASH in legacy script), then it is actually\n> easier not to exclude it from tapscript, even if we plan to add TXHASH to\n> tapscript as well.\"\n>\n> Another argument for CTV (which I find especially persuasive) is its\n> simplicity - it's relatively easy to reason about and, at this point,\n> pretty well understood. It seems like a low-risk change relative to some of\n> the other covenant proposals, nearly all of which elicit a good deal of\n> headscratching (at least from me) and seem to require not only larger\n> on-chain footprints but sizable code changes.\n>\n\n\n> > I am sensitive to technical debt and soft fork processes\n>\n\n> If OP_CTV ends up being the most practical approach for vaulting - among\n> other things - in terms of weight (which it seems to be at the moment) I\n> don't think \"technical debt\" is an applicable term.\n>\n\nTechnical debt isn't a measure of weight of transactions.  It's a measure\nof the code complexity needed to implement, in this case, a Bitcoin Script\ninterpreter.\n\nBy itself, adding a single new hash format for CTV isn't that complex, and\nit is certainly simpler than this TXHASH proposal.  But then we need to add\nanother two slightly different hash formats for APO support.  And tomorrow\nwe will need yet another set of transaction hash formats for the next\nthing, and so on, with each instance requiring going through its own\nsoft-fork process.  It is at that point we end up with something more\ncomplicated and with more deployment risk than if we had just done\nsomething like TXHASH at the very beginning.  But unlike other programming\nenvironments, we cannot refactor our way out of such a situation.  We\ncannot make a new script version while deprecating the old one.  Our only\noption here is to be mindful of the long term implications of the design\nchoices we are making today.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/a793638a/attachment-0001.html>"
            },
            {
                "author": "James O'Beirne",
                "date": "2022-01-28T15:14:12",
                "message_text_only": "> Technical debt isn't a measure of weight of transactions.\n\nSorry, my original sentence was a little unclear. I meant to say that the\nnotion that CTV is just a subpar waypoint en route to a more general\ncovenant system may not be accurate if it is a more efficient way (in terms\nof chainstate/weight) to express highly useful patterns like vaults. In\nthat case, characterizing CTV as technical debt wouldn't be right.\n\n> Our only option here is to be mindful of the long term implications of\nthe design choices we are making today.\n\nYour points are well taken - I don't think anyone is arguing against\nthinking hard about consensus changes. But I have yet to see a proposal for\ncovenants that is as efficient on-chain and easy to reason about as CTV is.\n\nI also think there's some value in \"legging into\" covenants by deploying a\nsimple, non-recursive construction like CTV that services some very\nimportant uses, and then taking as much time as necessary to think about\nhow to solve more existential problems, like UTXO scalability, that likely\nrequire a recursive covenant construction.\n\nThere doesn't have to be mutual exclusion in the approaches, especially\nwhen the maintenance burden of CTV seems to be so low. If we end up\ndeploying something that requires a wider variety of in-script hashing, it\nseems likely that CTV's hash will be able to \"free ride\" on whatever more\ngeneral sighash cache structure we come up with.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/d4424a62/attachment-0001.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2022-01-29T15:43:13",
                "message_text_only": "On Fri, Jan 28, 2022 at 10:14 AM James O'Beirne <james.obeirne at gmail.com>\nwrote:\n\n> > Technical debt isn't a measure of weight of transactions.\n>\n> Sorry, my original sentence was a little unclear. I meant to say that the\n> notion that CTV is just a subpar waypoint en route to a more general\n> covenant system may not be accurate if it is a more efficient way (in terms\n> of chainstate/weight) to express highly useful patterns like vaults. In\n> that case, characterizing CTV as technical debt wouldn't be right.\n>\n\nIt only costs a few more weight units, on the order of 2 or 3, to use\nTXHASH in place of CTV.  Notably, the reverse, using CTV in place of\nTXHASH, is much more expensive, requiring more than 32 weight units.\n\n\n> > Our only option here is to be mindful of the long term implications of\n> the design choices we are making today.\n>\n> Your points are well taken - I don't think anyone is arguing against\n> thinking hard about consensus changes. But I have yet to see a proposal for\n> covenants that is as efficient on-chain and easy to reason about as CTV is.\n>\n> I also think there's some value in \"legging into\" covenants by deploying a\n> simple, non-recursive construction like CTV that services some very\n> important uses, and then taking as much time as necessary to think about\n> how to solve more existential problems, like UTXO scalability, that likely\n> require a recursive covenant construction.\n>\n> There doesn't have to be mutual exclusion in the approaches, especially\n> when the maintenance burden of CTV seems to be so low. If we end up\n> deploying something that requires a wider variety of in-script hashing, it\n> seems likely that CTV's hash will be able to \"free ride\" on whatever more\n> general sighash cache structure we come up with.\n>\n\nPerhaps there is some misunderstanding.  TXHASH + CSFSV doesn't allow for\ncomplex or recursive covenants.  Typically CAT is needed, at minimum, to\ncreate those sorts of things.  TXHASH still amounts to deploying a\nnon-recursive covenant construction.\n\nWith regards to CTV, in short my primary criticisms are (1) Push semantics\nis preferable to verify semantics, because simulating verify semantics from\npush is cheap, while simulating push semantics from verify is not\nparticularly cheap.\nAnd (2) given Push semantics we ought to have parameters to support both\nCTV-style hashes and APO-style hashes (which in the presence of CSFSV gives\nus APO applications), and, while we are at it, as many other style hashes\nas we can reasonably devise so we don't have to go through yet another\nsoft-fork process every time someone comes up with a new subset of\ntransaction data they would like to be hashed for their application.\n\nI understand why CTV was designed with verify semantics: it would like to\nbe NOP compatible.  That certainly made sense pre-tapscript.  I just\nhaven't (yet) found the use cases for that compatibility to be compelling\nin a post-tapscript world.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220129/cefdbd34/attachment.html>"
            },
            {
                "author": "Jeremy Rubin",
                "date": "2022-01-29T17:02:37",
                "message_text_only": "Perhaps there is some misunderstanding.  TXHASH + CSFSV doesn't allow for\ncomplex or recursive covenants.  Typically CAT is needed, at minimum, to\ncreate those sorts of things.  TXHASH still amounts to deploying a\nnon-recursive covenant construction.\n\n\nThis seems false to me.\n\n<Only hash a single input scriptpubkey> txhash <only hash a single output\nscriptpubkey> txhash equalverify\n\nIs that not a recursive covenant? With a little extra work you can also\ncontrol for amounts and stuff.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220129/57693bf7/attachment.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2022-01-29T17:14:43",
                "message_text_only": "The hash would normally also cover the hash flags in use, and would be\ndifferent in those two cases.\n\nBut yes, it seems at the last minute I did include a suggestion to disable\ncovering the flag themselves in the hash and appear to have accidentally\nallowed for recursive covenants (a common occurrence when designing\nopcodes).\n\nOn Sat, Jan 29, 2022 at 12:01 PM Jeremy Rubin <j at rubin.io> wrote:\n\n>\n>\n>\n>> Perhaps there is some misunderstanding.  TXHASH + CSFSV doesn't allow for\n>> complex or recursive covenants.  Typically CAT is needed, at minimum, to\n>> create those sorts of things.  TXHASH still amounts to deploying a\n>> non-recursive covenant construction.\n>>\n>>\n> This seems false to me.\n>\n> <Only hash a single input scriptpubkey> txhash <only hash a single output\n> scriptpubkey> txhash equalverify\n>\n> Is that not a recursive covenant? With a little extra work you can also\n> control for amounts and stuff.\n>\n>\n>\n>>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220129/a5d662ba/attachment.html>"
            },
            {
                "author": "Anthony Towns",
                "date": "2022-01-31T02:18:52",
                "message_text_only": "On Thu, Jan 27, 2022 at 07:18:54PM -0500, James O'Beirne via bitcoin-dev wrote:\n> > I don't think implementing a CTV opcode that we expect to largely be\n> > obsoleted by a TXHASH at a later date is yielding good value from a soft\n> > fork process.\n> Caching for something\n> like TXHASH looks to me like a whole different ballgame relative to CTV,\n> which has a single kind of hash.\n\nI don't think caching is a particular problem even for the plethora of\nflags Russell described: you cache each value upon use, and reuse that\ncached item if it's needed for other signatures within the tx; sharing\nwith BIP 143, 341 or 342 signatures as appropriate. Once everything's\ncached, each signature then only requires hashing about 32*17+4 = ~548\nbytes, and you're only hashing each part of the transaction once in\norder to satisfy every possible flag.\n\n> Even if we were to adopt something like TXHASH, how long is it going to\n> take to develop, test, and release?\n\nI think the work to release something like TXHASH is all in deciding:\n\n - if TXHASH or CTV or something else is the better \"UX\"\n - what is a good tx to message algorithm and how it should be\n   parametized\n - what's an appropriate upgrade path for the TXHASH/CTV/??? mechanism\n\nBIP 119 provides one answer to each of those, but you still have to do\nthe work to decide if its a *good* answer to each of them.\n\n> My guess is \"a while\" - \n\nIf we want to get a good answer to those questions, it might be true\nthat it takes a while; but even if we want to rush ahead with more of\na \"well, we're pretty sure it's not going to be a disaster\" attitude,\nwe can do that with TXHASH (almost) as easily as with CTV.\n\n> The utility of vaulting seems\n> underappreciated among consensus devs and it's something I'd like to write\n> about soon in a separate post.\n\nI think most of the opposition is just that support for CTV seems to be\ntaking the form \"something must be done; this is something, therefore\nit must be done\"...\n\nI'd be more comfortable if the support looked more like \"here are the\nalternatives to CTV, and here's the advantages and drawbacks for each,\nhere's how they interact with other ideas, and here's why we think,\non balance, we think this approach is the best one\". But mostly the\nalternatives are dismissed with \"this will take too long\" or \"this enables\nrecursive covenants which someone (we don't know who) might oppose\".\n\nCheers,\naj"
            },
            {
                "author": "Anthony Towns",
                "date": "2022-01-28T01:34:36",
                "message_text_only": "On Wed, Jan 26, 2022 at 12:20:10PM -0500, Russell O'Connor via bitcoin-dev wrote:\n> Recapping the relationship between CTV and ANYPREVOUT::\n\n> While this is a pretty neat feature,\n> something that ANYPREVOUT cannot mimic, the main application for it is\n> listed as using congestion control to fund lightning channels, fixing their\n> TXIDs in advance of them being placed on chain.  However, if ANYPREVOUT\n> were used to mimic CTV, then likely it would be eltoo channels that would\n> be funded, and it isn't necessary to know the TXIDs of eltoo channels in\n> advance in order to use them.\n\nEven if they weren't eltoo channels, they could be updated lightning penalty\nchannels signed with APO signatures so that the txid wasn't crucial. So\nI don't think this would require all the work to update to eltoo just to\nhave this feature, if APO were available without CTV per se.\n\n> An Alternative Proposal::\n>  ...\n\n> For similar reasons, TXHASH is not amenable to extending the set of txflags\n> at a later date.\n\n> I believe the difficulties with upgrading TXHASH can be mitigated by\n> designing a robust set of TXHASH flags from the start.  For example having\n> bits to control whether [...]\n\nI don't think that's really feasible -- eg, what you propose don't cover\nSIGHASH_GROUP: \n\n https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-July/019243.html\n\n> That all said, even if other txhash flag modes are needed in the future,\n> adding TXHASH2 always remains an option.\n\nI think baking this in from day 0 might be better: make TXHASH be\na multibyte opcode, so that when you decode \"0xBB\" on the stack,\nyou also decode a serialize.h:VarInt as the version number. Version 0\n(0xBB00) gives hashes corresponding to bip342, version 1 (0xBB01) gives\nhashes corresponding to bip118 (anyprevout), anything else remains as\nOP_SUCCESS behaviour, and you retain a pretty compact encoding even if\nwe somehow eventually end up needing hundreds or thousands of different\nTXHASH versions.\n\nBecause the version here is part of the opcode rather than pulled from\nthe stack, I think this preserves any benefits related to composition\nor analysis, but is otherwise still pretty general. I'm imagining that\nthe idea would be to be consistent between CHECKSIG key versions and\nTXHASH versions.\n\nSo I think just designing it this way means TXHASH *would* be \"amenable\nto extending the set of txflags at a later date.\"\n\n> '<anyprevout-pubkey> CHECKSIGVERIFY can be simulated by '<apo_style_flag> TXHASH <pubkey> CHECKSIGFROMSTACKVERIFY'. \n\nI don't think that's quite right. BIP 118 anyprevout is done by taking\nthe pubkey \"P\", marking it as \"APO-capable\" (by prefixing it with 0x01),\nand then getting a sighash and sig from the witness. Doing the same\nwith TXHASH/CSFSV would just be replacing \"<APO:P> CHECKSIGVERIFY\" with\n\"TXHASH <P> CSFSV\" with the witness providing both the signature and\ntxhash flag, just as separate elements rather than concatenated. (The\n\"APO-capable\" part is implicit in the \"TXHASH\" opcode)\n\n> In addition to the CTV and ANYPREVOUT applications, with\n> CHECKSIGFROMSTACKVERIFY we can verify signatures on arbitrary messages\n> signed by oracles for oracle applications.  This is where we see the\n> benefit of decomposing operations into primitive pieces.  By giving users\n> the ability to program their own use cases from components, we get more\n> applications out of fewer op codes!\n\nWhile I see the appeal of this from a language design perspective;\nI'm not sure it's really the goal we want. When I look at bitcoin's\nexisting script, I see a lot of basic opcodes to do simple arithmetic and\nmanipulate the stack in various ways, but the opcodes that are actually\nuseful are more \"do everything at once\" things like check(multi)sig or\nsha256. It seems like what's most useful on the blockchain is a higher\nlevel language, rather than more of blockchain assembly language made\nup of small generic pieces. I guess \"program their own use cases from\ncomponents\" seems to be coming pretty close to \"write your own crypto\nalgorithms\" here...\n\nI'm not really sure what the dividing line there is, or even which side\nTXHASH would be on. I'm not even totally convinced that the \"high level\nlanguage\" should be describing what consensus provides rather than some\nlayer on top that people compile (a la miniscript). Just trying to put\ninto words why I'm not 100% comfortable with the principle per se.\n\n\nOne thing I've thought about is an opcode like \"POP_SIGDATA\" which would\npopulate a new \"register\" called \"sigdata\", which would then be added\nto the message being signed. That's a generalisation of tapscript's\nbehaviour for \"codeseparator\" essentially. That is,\n\n   x POP_SIGDATA p CHECKSIG\n\nwould be roughly the same as\n\n   TXHASH x CAT SHA256SUM p CHECKSIGFROMSTACK\n\nI think \"POP_SIGDATA\" makes for an interesting counterpart to\n\"PUSH_ANNEXITEM\" -- we implicitly commit to all the annex items in\nsignatures, so PUSH_ANNEXITEM would give a way to use signed data that's\ngiven verbatim in the witness in further calculations; but POP_SIGDATA\nwould do the opposite, allowing you to require data that's the result\nof calculations and not explicitly spelled out in the witness be signed.\n\nYou could implement CHECKSIGFROMSTACK using that, ie:\n\n    sig x p CHECKSIGFROMSTACK\n\nis the same as:\n\n    sig' x POP_SIGDATA p CHECKSIG\n\nprovided sig' applies a new \"SIGHASH_NO_TX_DATA_AT_ALL\" sighash flag to\n\"sig\" that just does what it says.\n\nYou could likewise implement CTV as an extension to CHECKSIG -- define a\nnew pubkey type that's just the constant \"0x0000\" and have the \"signature\"\nbe valid if it's an exact match for the corresponding message hash. You\ncould bump the key to \"0x0001\" to introduce new hashes; and include a\n\"sighash\" with the \"signature\" as well perhaps. (Apart from reusing an\nexisting opcode instead of introducing a new one, and costing some\nadditional witnss bytes, I don't think that makes much difference\neithr way)\n\nI think the key tradeoff between \"x POP_SIGDATA p CHECKSIG\" and\n\"CHECKSIGFROMSTACK\" isn't so much that one approach is a couple of bytes\nmore or less or one claims two opcodes vs just one for the other, but\nwhether it's common to want to commit to some extra random data alongside\nthe tx itself, and in the cases where that's desirable, if we can have\na standard way of constructing that and assume everyone will use it; or\nif it's important that wallets can design their own way of committing to\nthe extra data more manually, because it's impotant to support different\napproaches in different circumstances.\n\n\nIf we had CTV, POP_SIGDATA, and SIGHASH_NO_TX_DATA_AT_ALL but no OP_CAT,\nare there any practical use cases that wouldn't be covered that having\nTXHASH/CAT/CHECKSIGFROMSTACK instead would allow? Or where those would\nbe significantly more convenient/efficient?\n\n(Assume \"y x POP_SIGDATA POP_SIGDATA p CHECKSIGVERIFY q CHECKSIG\"\ncommits to a vector [x,y] via p but does not commit to either via q so\nthat there's some \"CAT\"-like behaviour available)\n\n\nI think a difference between \"TXHASH EQUALVERIFY\" and \"CTV\" is that\nbecause the idea for TXHASH is to be compatible with CHECKSIGFROMSTACK,\nthen the messages it hashes should be distinct from anything else you\nmight ever sign. But for CTV that doesn't matter, because there's no\nsignature to be reused; so as a result, how the message is hashed can\nbe simpler, and that in turn may make it easier to do the \"subtractive\ncovenants\" and similar.\n\nI guess I don't find that super important -- if you're manually\nconstructing covenants in script by putting together various bits of\ndata about a tx, then I guess I think you've already lost the game, and\nhaving to have your script be a little more complicated in order to to\ntagged hashes and the like is no big deal.\n\n\nConcretely:\n\n - I think TXHASH needs to be designed to be upgradable; but I think\n   that's solvable\n\n - I think it makes sense for TXHASH and CHECKSIG to be synchronised;\n   so any message digest you can hash via txhash should be signable via\n   CHECKSIG and vice-versa. Given that, I don't think this approach\n   replaces APO, just adds to it.\n\n - I think I'd prefer having a single set of message digests shared\n   between TXHASH and CHECKSIG, than having one set of message digests\n   for CHECKSIG and a different set for CTV. But that's a design choice\n   for CTV rather than an advantage of TXHASH over CTV.\n\n - I think defining some OP_NOPx in terms of TXHASH so that it can\n   be made available without p2sh/segwit/tapscript wrapping would work\n   fine, if that optimisation is worthwhile\n\n - Even if we favoured CTV over TXHASH for consensus implementation,\n   I think \"TXHASH\" seems like a good primitive to use when talking\n   about script language design...\n\nCheers,\naj"
            },
            {
                "author": "Russell O'Connor",
                "date": "2022-01-28T13:56:25",
                "message_text_only": "On Thu, Jan 27, 2022 at 8:34 PM Anthony Towns <aj at erisian.com.au> wrote:\n\n> > An Alternative Proposal::\n> >  ...\n>\n> > For similar reasons, TXHASH is not amenable to extending the set of\n> txflags\n> > at a later date.\n>\n> > I believe the difficulties with upgrading TXHASH can be mitigated by\n> > designing a robust set of TXHASH flags from the start.  For example\n> having\n> > bits to control whether [...]\n>\n> I don't think that's really feasible -- eg, what you propose don't cover\n> SIGHASH_GROUP:\n>\n>\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-July/019243.html\n>\n\nFor more complex interactions, I was imagining combining this TXHASH\nproposal with CAT and/or rolling SHA256 opcodes.  If TXHASH ended up\nsupporting relative or absolute input/output indexes then users could\nassemble the hashes of the particular inputs and outputs they care about\ninto a single signed message.\n\n\n> > That all said, even if other txhash flag modes are needed in the future,\n> > adding TXHASH2 always remains an option.\n>\n> I think baking this in from day 0 might be better: make TXHASH be\n> a multibyte opcode, so that when you decode \"0xBB\" on the stack,\n> you also decode a serialize.h:VarInt as the version number.\n\n\nI wouldn't be opposed to this.\n\n> '<anyprevout-pubkey> CHECKSIGVERIFY can be simulated by '<apo_style_flag>\n> TXHASH <pubkey> CHECKSIGFROMSTACKVERIFY'.\n>\n> I don't think that's quite right. BIP 118 anyprevout is done by taking\n> the pubkey \"P\", marking it as \"APO-capable\" (by prefixing it with 0x01),\n> and then getting a sighash and sig from the witness. Doing the same\n> with TXHASH/CSFSV would just be replacing \"<APO:P> CHECKSIGVERIFY\" with\n> \"TXHASH <P> CSFSV\" with the witness providing both the signature and\n> txhash flag, just as separate elements rather than concatenated. (The\n> \"APO-capable\" part is implicit in the \"TXHASH\" opcode)\n>\n\nIndeed. The TXHASH variant does require splitting the signature and txhash\nflag across two stack items.  So it wouldn't be an operationally identical\ndrop in replacement.\n\n\n> > In addition to the CTV and ANYPREVOUT applications, with\n> > CHECKSIGFROMSTACKVERIFY we can verify signatures on arbitrary messages\n> > signed by oracles for oracle applications.  This is where we see the\n> > benefit of decomposing operations into primitive pieces.  By giving users\n> > the ability to program their own use cases from components, we get more\n> > applications out of fewer op codes!\n>\n> While I see the appeal of this from a language design perspective;\n> I'm not sure it's really the goal we want. When I look at bitcoin's\n> existing script, I see a lot of basic opcodes to do simple arithmetic and\n> manipulate the stack in various ways, but the opcodes that are actually\n> useful are more \"do everything at once\" things like check(multi)sig or\n> sha256. It seems like what's most useful on the blockchain is a higher\n> level language, rather than more of blockchain assembly language made\n> up of small generic pieces. I guess \"program their own use cases from\n> components\" seems to be coming pretty close to \"write your own crypto\n> algorithms\" here...\n>\n\nWhich operations in Script are actually composable today?\n\nCHECKSIG composes with nothing else (other than possibly other CHECKSIGs)\nas there are no other operations that manipulate pubkey keys or signature\ndata.\n\nCLTV and CSV in principle can be composed with addition and subtraction and\ncomparison operations.  But where are you going to get other values to add\nand subtract from?  I suppose you could compare the relative and absolute\nlocktimes to each other.\n\nWhat do the HASH functions compose with?  Without CAT you cannot construct\nmessages to hash.  You can hash the result of the arithmetic operations,\nbut you are limited to hashing 32-bit (or 33-bit if you are generous)\nstrings, which is too little entropy to have any security properties.  You\ncan hash a public key or a signature I suppose.\n\nI don't think there is much in the way of lessons to be drawn from how we\nsee Bitcoin Script used today with regards to programs built out of\nreusable components.  User's haven't been composing programs, not because\nthey don't find composition useful, but rather because the existing\nprimitives do not lend themselves to being composed at all.\n\nThere is one aspect of Bitcoin Script that is composable, which is\n(monotone) boolean combinations of the few primitive transaction conditions\nthat do exist.  The miniscript language captures nearly the entirety of\nwhat is composable in Bitcoin Script today: which amounts to conjunctions,\ndisjunctions (and thresholds) of signatures, locktimes, and revealing hash\npreimages.\n\nTXHASH + CSFSV won't be enough by itself to allow for very interesting\nprograms Bitcoin Script yet, we still need CAT and friends for that, but\nCSFSV is at least a step in that direction.  CSFSV can take arbitrary\nmessages and these messages can be fixed strings, or they can be hashes of\nstrings (that need to be revealed), or they can be hashes returned from\nTXHASH, or they can be locktime values, or they can be values that are\nadded or subtracted from locktime values, or they can be values used for\nthresholds, or they can be other pubkeys for delegation purposes, or they\ncan be other signatures ... for who knows what purpose.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220128/beac8333/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "TXHASH + CHECKSIGFROMSTACKVERIFY in lieu of CTV and ANYPREVOUT",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "James Lu",
                "Jeremy",
                "Michael Folkson",
                "Anthony Towns",
                "Russell O'Connor",
                "Jeremy Rubin",
                "James O'Beirne"
            ],
            "messages_count": 16,
            "total_messages_chars_count": 135498
        }
    },
    {
        "title": "[bitcoin-dev] Improving RBF Policy",
        "thread_messages": [
            {
                "author": "Gloria Zhao",
                "date": "2022-01-27T13:42:09",
                "message_text_only": "Hi everyone,\n\nThis post discusses limitations of current Bitcoin Core RBF policy and\nattempts to start a conversation about how we can improve it,\nsummarizing some ideas that have been discussed. Please reply if you\nhave any new input on issues to be solved and ideas for improvement!\n\nJust in case I've screwed up the text wrapping again, another copy can be\nfound here: https://gist.github.com/glozow/25d9662c52453bd08b4b4b1d3783b9ff\n\n## Background\n\nPlease feel free to skip this section if you are already familiar\nwith RBF.\n\nNodes may receive *conflicting* unconfirmed transactions, aka\n\"double spends\" of the same inputs. Instead of always keeping the\nfirst transaction, since v0.12, Bitcoin Core mempool policy has\nincluded a set of Replace-by-Fee (RBF) criteria that allows the second\ntransaction to replace the first one and any descendants it may have.\n\nBitcoin Core RBF policy was previously documented as BIP 125.\nThe current RBF policy is documented [here][1]. In summary:\n\n1. The directly conflicting transactions all signal replaceability\n   explicitly.\n\n2. The replacement transaction only includes an unconfirmed input if\n   that input was included in one of the directly conflicting\ntransactions.\n\n3. The replacement transaction pays an absolute fee of at least the\n   sum paid by the original transactions.\n\n4. The additional fees pays for the replacement transaction's\n   bandwidth at or above the rate set by the node's *incremental relay\nfeerate*.\n\n5. The sum of all directly conflicting transactions' descendant counts\n   (number of transactions inclusive of itself and its descendants)\ndoes not exceed 100.\n\nWe can split these rules into 3 categories/goals:\n\n- **Allow Opting Out**: Some applications/businesses are unable to\n  handle transactions that are replaceable (e.g. merchants that use\nzero-confirmation transactions). We (try to) help these businesses by\nhonoring BIP125 signaling; we won't replace transactions that have not\nopted in.\n\n- **Incentive Compatibility**: Ensure that our RBF policy would not\n  accept replacement transactions which would decrease fee profits\n  of a miner. In general, if our mempool policy deviates from what is\neconomically rational, it's likely that the transactions in our\nmempool will not match the ones in miners' mempools, making our\nfee estimation, compact block relay, and other mempool-dependent\nfunctions unreliable. Incentive-incompatible policy may also\nencourage transaction submission through routes other than the p2p\nnetwork, harming censorship-resistance and privacy of Bitcoin payments.\n\n- **DoS Protection**: Limit two types of DoS attacks on the node's\n  mempool: (1) the number of times a transaction can be replaced and\n(2) the volume of transactions that can be evicted during a\nreplacement.\n\nEven more abstract: our goal is to make a replacement policy that\nresults in a useful interface for users and safe policy for\nnode operators.\n\n## Motivation\n\nThere are a number of known problems with the current RBF policy.\nMany of these shortcomings exist due to mempool limitations at the\ntime RBF was implemented or result from new types of Bitcoin usage;\nthey are not criticisms of the original design.\n\n### Pinning Attacks\n\nThe most pressing concern is that attackers may take advantage of\nlimitations in RBF policy to prevent other users' transactions from\nbeing mined or getting accepted as a replacement.\n\n#### SIGHASH_ANYONECANPAY Pinning\n\nBIP125#2 can be bypassed by creating intermediary transactions to be\nreplaced together. Anyone can simply split a 1-input 1-output\ntransaction off from the replacement transaction, then broadcast the\ntransaction as is. This can always be done, and quite cheaply. More\ndetails in [this comment][2].\n\nIn general, if a transaction is signed with SIGHASH\\_ANYONECANPAY,\nanybody can just attach a low feerate parent to this transaction and\nlower its ancestor feerate.  Even if you require SIGHASH\\_ALL which\nprevents an attacker from changing any outputs, the input can be a\nvery low amount (e.g. just above the dust limit) from a low-fee\nancestor and still bring down the ancestor feerate of the transaction.\n\nTLDR: if your transaction is signed with SIGHASH\\_ANYONECANPAY and\nsignals replaceability, regardless of the feerate you broadcast at, an\nattacker can lower its mining priority by adding an ancestor.\n\n#### Absolute Fee\n\nThe restriction of requiring replacement transactions to increase the\nabsolute fee of the mempool has been described as \"bonkers.\" If the\noriginal transaction has a very large descendant that pays a large\namount of fees, even if it has a low feerate, the replacement\ntransaction must now pay those fees in order to meet Rule #3.\n\n#### Package RBF\n\nThere are a number of reasons why, in order to enable Package RBF, we\ncannot use the same criteria.\n\nFor starters, the absolute fee pinning attack is especially\nproblematic if we apply the same rules (i.e. Rule #3 and #4) in\nPackage RBF. Imagine that Alice (honest) and Bob (adversary) share a\nLN channel. The mempool is rather full, so their pre-negotiated\ncommitment transactions' feerates would not be considered high\npriority by miners.  Bob broadcasts his commitment transaction and\nattaches a very large child (100KvB with 100,000sat in fees) to his\nanchor output. Alice broadcasts her commitment transaction with a\nfee-bumping child (200vB with 50,000sat fees which is a generous\n250sat/vB), but this does not meet the absolute fee requirement. She\nwould need to add another 50,000sat to replace Bob's commitment\ntransaction.\n\nDisallowing new unconfirmed inputs (Rule #2) in Package RBF would be\nbroken for packages containing transactions already in the mempool,\nexplained [here][7].\n\nNote: I originally [proposed][6] Package RBF using the same Rule #3\nand #4 before I realized how significant this pinning attack is. I'm\nretracting that proposal, and a new set of Package RBF rules would\nfollow from whatever the new individual RBF rules end up being.\n\n#### Same Txid Different Witness\n\nTwo transactions with the same non-witness data but different\nwitnesses have the same txid but different wtxid, and the same fee but\nnot necessarily the same feerate. Currently, if we see a transaction\nthat has the same txid as one in the mempool, we reject it as a\nduplicate, even if the feerate is much higher. It's unclear to me if\nwe have a very strong reason to change this, but noting it as a\nlimitation of our current replacement policy. See [#24007][12].\n\n### User Interface\n\n#### Using Unconfirmed UTXOs to Fund Replacements\n\nThe restriction of only allowing confirmed UTXOs for funding a\nfee-bump (Rule #2) can hurt users trying to fee-bump their\ntransactions and complicate wallet implementations. If the original\ntransaction's output value isn't sufficient to fund a fee-bump and/or\nall of the user's other UTXOs are unconfirmed, they might not be able\nto fund a replacement transaction. Wallet developers also need to\ntreat self-owned unconfirmed UTXOs as unusable for fee-bumping, which\nadds complexity to wallet logic. For example, see BDK issues [#144][4]\nand [#414][5].\n\n#### Interface Not Suitable for Coin Selection\n\nCurrently, a user cannot simply create a replacement transaction\ntargeting a specific feerate or meeting a minimum fee amount and\nexpect to meet the RBF criteria. The fee amount depends on the size of\nthe replacement transaction, and feerate is almost irrelevant.\n\nBitcoin Core's `bumpfee` doesn't use the RBF rules when funding the\nreplacement. It [estimates][13] a feerate which is \"wallet incremental\nrelay fee\" (a conservative overestimation of the node's incremental\nrelay fee) higher than the original transaction, selects coins for\nthat feerate, and hopes that it meets the RBF rules. It never fails\nRule #3 and #4 because it uses all original inputs and refuses to\nbump a transaction with mempool descendants.\n\nThis is suboptimal, but is designed to work with the coin selection\nengine: select a feerate first, and then add fees to cover it.\nFollowing the exact RBF rules would require working the other way\naround: based on how much fees we've added to the transaction and its\ncurrent size, calculate the feerate to see if we meet Rule #4.\n\nWhile this isn't completely broken, and the user interface is\nsecondary to the safety of the mempool policy, we can do much better.\nA much more user-friendly interface would depend *only* on the\nfee and size of the original transactions.\n\n### Updates to Mempool and Mining\n\nSince RBF was first implemented, a number of improvements have been\nmade to mempool and mining logic. For example, we now use ancestor\nfeerates in mining (allowing CPFP), and keep track of ancestor\npackages in the mempool.\n\n## Ideas for Improvements\n\n### Goals\n\nTo summarize, these seem to be desired changes, in order of priority:\n\n1. Remove Rule #3. The replacement should not be *required* to pay\nhigher absolute fees.\n\n2. Make it impossible for a replacement transaction to have a lower\nmining score than the original transaction(s). This would eliminate\nthe `SIGHASH\\_ANYONECANPAY` pinning attack.\n\n3. Remove Rule #2. Adding new unconfirmed inputs should be allowed.\n\n4. Create a more helpful interface that helps wallet fund replacement\ntransactions that aim for a feerate and fee.\n\n### A Different Model for Fees\n\nFor incentive compatibility, I believe there are different\nformulations we should consider.  Most importantly, if we want to get\nrid of the absolute fee rule, we can no longer think of it as \"the\ntransaction needs to pay for its own bandwidth,\" since we won't always\nbe getting additional fees. That means we need a new method of\nrate-limiting replacements that doesn't require additional fees every\ntime.\n\nWhile it makes sense to think about monetary costs when launching a\nspecific type of attack, given that the fees are paid to the miner and\nnot to the mempool operators, maybe it doesn't make much sense to\nthink about \"paying for bandwidth\". Maybe we should implement\ntransaction validation rate-limiting differently, e.g. building it\ninto the P2P layer instead of the mempool policy layer.\n\nRecently, Suhas gave a [formulation][8] for incentive compatibility\nthat made sense to me: \"are the fees expected to be paid in the next\n(N?) blocks higher or lower if we process this transaction?\"\n\nI started by thinking about this where N=1 or `1 + p`.\nHere, a rational miner is looking at what fees they would\ncollect in the next block, and then some proportion `p` of the rest of\nthe blocks based on their hashrate. We're assuming `p` isn't *so high*\nthat they would be okay with lower absolute fees in the next 1 block.\nWe're also assuming `p` isn't *so low* that the miner doesn't care\nabout what's left of the mempool after this block.\n\nA tweak to this formulation is \"if we process this transaction, would\nthe fees in the next 1 block higher or lower, and is the feerate\ndensity of the rest of the mempool higher or lower?\" This is pretty\nsimilar, where N=1, but we consider the rest of the mempool by feerate\nrather than fees.\n\n### Mining Score of a Mempool Transaction\n\nWe are often interested in finding out what\nthe \"mining score\" of a transaction in the mempool is. That is, when\nthe transaction is considered in block template building, what is the\nfeerate it is considered at?\n\nObviously, it's not the transaction's individual feerate. Bitcoin Core\n[mining code sorts][14] transactions by their ancestor feerate and\nincludes them packages at a time, keeping track of how this affects the\npackage feerates of remaining transactions in the mempool.\n\n*ancestor feerate*: Ancestor feerate is easily accessible information,\nbut it's not accurate either, because it doesn't take into account the\nfact that subsets of a transaction's ancestor set can be included\nwithout it. For example, ancestors may have high feerates on their own\nor we may have [high feerate siblings][8].\n\nTLDR: *Looking at the current ancestor feerate of a transaction is\ninsufficient to tell us what feerate it will be considered at when\nbuilding a block template in the future.*\n\n*min(individual feerate, ancestor feerate)*: Another\nheuristic that is simple to calculate based on current mempool tooling\nis to use the [minimum of a transaction's individual score and its\nancestor score][10] as a conservative measure.  But this can\noverestimate as well (see the example below).\n\n*min ancestor feerate(tx + possible ancestor subsets)* We can also\ntake the minimum of every possible ancestor subset, but this can be\ncomputationally expensive since there can be lots and lots of ancestor\nsubsets.\n\n*max ancestor feerate(tx + possible descendant subsets)*: Another idea\nis to use the [maximum ancestor score of the transaction + each of its\ndescendants][9]. This doesn't work either; it has the same blindspot\nof ancestor subsets being mined on their own.\n\n#### Mining Score Example\n\nHere's an example illustrating why mining score is tricky to\nefficiently calculate for mempool transactions:\n\nLet's say you have same-size transactions A (21sat/vB), B (1sat/vB),\nC(9sat/vB), D(5sat/vB).\nThe layout is: grandparent A, parent B, and two children C and D.\n\n```\n    A\n    ^\n    B\n   ^ ^\n   C D\n```\n\nA miner using ancestor packages to build block templates will first\ninclude A with a mining score of 21. Next, the miner will include B and\nC with a mining score of 6. This leaves D, with a mining score of 5.\n\nNote: in this case, mining by ancestor feerate results in the most\nrational decisions, but [a candidate set-based approach][10] which\nmakes ancestor feerate much less relevant could\nbe more advantageous in other situations.\n\nHere is a chart showing the \"true\" mining score alongside the values\ncalculating using imperfect heuristics described above. All of them\ncan overestimate or underestimate.\n\n```\n   A     B       C     D\nmining score |   21   |   6   |   6   |   5   |\nancestor feerate   |   21   |  11   | 10.3  |   9   |\nmin(individual, ancestor) |   21   |   1   |   9   |   5   |\nmin(tx + ancestor subsets)      |   21   |   1   |   5   |   3   |\nmax(tx + descendants subsets) |   21   |   9   |   9   |   5   |\n\n```\n\nPossibly the best solution for finding the \"mining score\" of a\ntransaction is to build a block template, see what feerate each\npackage is included at. Perhaps at some cutoff, remaining mempool\ntransactions can be estimated using some heuristic that leans\n{overestimating, underestimating} depending on the situation.\n\nMining score seems to be relevant in multiple places: Murch and I\nrecently [found][3] that it would be very important in\n\"ancestor-aware\" funding of transactions (the wallet doesn't\nincorporate ancestor fees when using unconfirmed transactions in coin\nselection, which is a bug we want to fix).\n\nIn general, it would be nice to know the exact mining priority of\none's unconfirmed transaction is.  I can think of a few block/mempool\nexplorers who might want to display this information for users.\n\n### RBF Improvement Proposals\n\nAfter speaking to quite a few people, here are some suggestions\nfor improvements that I have heard:\n\n* The ancestor score of the replacement must be {5, 10, N}% higher\n  than that of every original transaction.\n\n* The ancestor score of the replacement must be 1sat/vB higher than\n  that of every original transaction.\n\n* If the original transaction is in the top {0.75MvB, 1MvB} of the\n  mempool, apply the current rules (absolute fees must increase and\npay for the replacement transaction's new bandwidth). Otherwise, use a\nfeerate-only rule.\n\n* If fees don't increase, the size of the replacement transaction must\n  decrease by at least N%.\n\n* Rate-limit how many replacements we allow per prevout.\n\n* Rate-limit transaction validation in general, per peer.\n\nPerhaps some others on the mailing list can chime in to throw other\nideas into the ring and/or combine some of these rules into a sensible\npolicy.\n\n#### Replace by Feerate Only\n\nI don't think there's going to be a single-line feerate-based\nrule that can incorporate everything we need.\nOn one hand, a feerate-only approach helps eliminate the issues\nassociated with Rule #3. On the other hand, I believe the main concern\nwith a feerate-only approach is how to rate limit replacements. We\ndon't want to enable an attack such as:\n\n1. Attacker broadcasts large, low-feerate transaction, and attaches a\nchain of descendants.\n\n2. The attacker replaces the transaction with a smaller but higher\nfeerate transaction, attaching a new chain of descendants.\n\n3. Repeat 1000 times.\n\n#### Fees in Next Block and Feerate for the Rest of the Mempool\n\nPerhaps we can look at replacements like this:\n\n1. Calculate the directly conflicting transactions and, with their\ndescendants, the original transactions. Check signaling. Limit the\ntotal volume (e.g. can't be more than 100 total or 1MvB or something).\n\n2. Find which original transactions would be in the next ~1 block. The\nreplacement must pay at least this amount + X% in absolute fees. This\nguarantees that the fees of the next block doesn't decrease.\n\n3. Find which transactions would be left in the mempool after that ~1\nblock. The replacement's feerate must be Y% higher than the maximum\nmining score of these transactions. This guarantees that you now have\nonly *better* candidates in your after-this-block mempool than you did\nbefore, even if the size and fees the transactions decrease.\n\n4. Now you have two numbers: a minimum absolute fee amount and a\nminimum feerate. Check to see if the replacement(s) meet these\nminimums. Also, a wallet would be able to ask the node \"What fee and\nfeerate would I need to put on a transaction replacing this?\" and use\nthis information to fund a replacement transaction, without needing to\nguess or overshoot.\n\nObviously, there are some magic numbers missing here. X and Y are\nTBD constants to ensure we have some kind of rate limiting for the\nnumber of replacements allowed using some set of fees.\n\nWhat should they be? We can do some arithmetic to see what happens if\nyou start with the biggest/lowest feerate transaction and do a bunch\nof replacements. Maybe we end up with values that are high enough to\nprevent abuse and make sense for applications/users that do RBF.\n\n### Mempool Changes Need for Implementation\n\nAs described in the mining score section above,\nwe may want additional tooling to more accurately assess\nthe economic gain of replacing transactions in our mempool.\n\nA few options have been discussed:\n\n* Calculate block templates on the fly when we need to consider a\n  replacement. However, since replacements are [quite common][11]\n  and the information might be useful for other things as well,\n  it may be worth it to cache a block template.\n\n* Keep a persistent block template so that we know what transactions\n  we would put in the next block. We need to remember the feerate\nat which each transaction was included in the template, because an\nancestor package may be included in the same block template in\nmultiple subsets. Transactions included earlier alter the ancestor\nfeerate of the remaining transactions in the package. We also need\nto keep track of the new feerates of transactions left over.\n\n* Divide the mempool into two layers, \"high feerate\" and \"low\n  feerate.\" The high feerate layer contains ~1 block of packages with\nthe highest ancestor feerates, and the low feerate layer contains\neverything else. At the edge of a block, we have a Knapsacky problem\nwhere the next highest ancestor feerate package might not fit, so we\nwould probably want the high feerate layer ~2MvB or something to avoid\nunderestimating the fees.\n\n## Acknowledgements\n\nThank you to everyone whose RBF-related suggestions, grievances,\ncriticisms and ideas were incorporated in this document:\nAndrew Chow, Matt Corallo, Suhas Daftuar, Christian Decker,\nMark Erhardt, Lloyd Fournier, Lisa Neigut, John Newbery,\nAntoine Poinsot, Antoine Riard, Larry Ruane,\nS3RK and Bastien Teinturier.\n\nThanks for reading!\n\nBest,\nGloria\n\n[1]:\nhttps://github.com/bitcoin/bitcoin/blob/master/doc/policy/mempool-replacements.md\n[2]: https://github.com/bitcoin/bitcoin/pull/23121#issuecomment-929475999\n[3]:\nhttps://github.com/Xekyo/bitcoin/commit/d754b0242ec69d42c570418aebf9c1335af0b8ea\n[4]: https://github.com/bitcoindevkit/bdk/issues/144\n[5]: https://github.com/bitcoindevkit/bdk/issues/414\n[6]:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html\n[7]:\nhttps://gist.github.com/glozow/dc4e9d5c5b14ade7cdfac40f43adb18a#new-unconfirmed-inputs-rule-2\n[8]: https://github.com/bitcoin/bitcoin/pull/23121#discussion_r777131366\n[9]: https://github.com/bitcoin/bitcoin/pull/22290#issuecomment-865887922\n[10]:\nhttps://gist.github.com/Xekyo/5cb413fe9f26dbce57abfd344ebbfaf2#file-candidate-set-based-block-building-md\n[11]: https://github.com/bitcoin/bitcoin/pull/22539#issuecomment-885763670\n[12]: https://github.com/bitcoin/bitcoin/pull/24007\n[13]:\nhttps://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/wallet/feebumper.cpp#L114\n[14]:\nhttps://github.com/bitcoin/bitcoin/blob/cf5bb048e80d4cde8828787b266b7f5f2e3b6d7b/src/node/miner.cpp#L310-L320\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220127/ec8ff818/attachment-0001.html>"
            },
            {
                "author": "Jeremy",
                "date": "2022-01-28T01:35:11",
                "message_text_only": "Gloria,\n\nThis is a brilliant post! Great job systematizing many of the issues. Quite\na lot to chew on & I hope other readers of this list digest the post fully.\n\nThree things come to mind as partial responses:\n\nunder:\n\n- **DoS Protection**: Limit two types of DoS attacks on the node's\n>   mempool: (1) the number of times a transaction can be replaced and\n> (2) the volume of transactions that can be evicted during a\n> replacement.\n\n\nI'd more simply put it:\n\nLimiting the amount of work that must be done to consider the replacement\n\nWe don't particularly care about goal (1) or goal (2), we care about how\nmuch it costs to do (1) or (2). And there are scenarios where the (1) or\n(2) might not be particularly high, but the total work still might be. I\ncan give you some examples to consider if needed. There are also scenarios\nwhere (1) and (2) might be high, but the cost is low overall. Therefore it\nmakes sense to be a little more general with what the anti-DoS goal is.\n\n\n\n\nAn issue I'd like to toss into the mix is that of iterative / additive\nbatching. E.g., https://bitcoinops.org/en/cardcoins-rbf-batching/\n\nThis is where an business puts a txn in the mempool that pays to N users,\nand as they see additional requests for payouts the update it to N+2,\nN+2... N+M payouts. This iterative batching can be highly efficient because\nthe number of transactions per business per 10 minutes is 1 (with variable\nnumber of outputs).\n\nOne issue with this approach today is that because of the feerate rule, if\nyou go from N to N+1 you need to pay 1 sat/byte over the whole txn. Applied\nM times, and you have to increase fees quadratically for this approach.\nTherefore the less efficient long-chain of batches model ends up being\n'rational' with respect to mempool policy and irrational with respect to\n\"optimally packing blocks with transactions\".\n\nIf the absolute fee rule is dropped, but feerate remains, one thing you\nmight see is businesses doing iterative batches with N+2M outputs whereby\nthey drop 2 outputs for every input they add, allowing the iterative batch\nto always increase the fee-rate but possibly not triggering the quadratic\nfeerate issue since the transaction gets smaller over time.\n\nAnother possible solution to this would be to allow relaying \"txdiffs\"\nwhich only require re-relay of signatures + new/modified outputs, and not\nthe entire tx.\n\nI think this iterative batching is pretty desirable to support, and so I'd\nlike to see a RBF model which doesn't make it \"unfairly\" expensive.\n\n(I'll spare everyone the details on how CTV batching also solves this, but\nfeel free to ask elsewhere.)\n\nA counterargument to additive batching is that if you instead do non\niterative batches every minute, and you have 100 txns that arrive\nuniformly, you'd end up with 10 batches of size 10 on average. The bulk of\nthe benefit under this model is in the non-batched to batched transition,\nand the iterative part only saves on space/fees marginally after that point.\n\n\n\nA final point is that a verifiable delay function could be used over, e.g.,\neach of the N COutpoints individually to rate-limit transaction\nreplacement. The VDF period can be made shorter / eliminated depending on\nthe feerate increase. E.g., always consider a much higher feerate txn\nwhenever available, for things of equal feerate only consider 1 per minute.\nA VDF is like proof-of-work that doesn't parallelize, in case you are\nunfamiliar, so no matter how many computers you have it would take about\nthe same amount of time (you could parallelize across N outputs, of course,\nbut you're still bound minimally to the time it takes to replace 1 output,\ndoing all outputs individually just is the most flexible option).\n\n\nCheers,\n\nJeremy\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220127/9ca1b277/attachment.html>"
            },
            {
                "author": "Antoine Riard",
                "date": "2022-01-30T22:53:32",
                "message_text_only": "Hi Gloria,\n\nThanks for this RBF sum up. Few thoughts and more context comments if it\ncan help other readers.\n\n> For starters, the absolute fee pinning attack is especially\n> problematic if we apply the same rules (i.e. Rule #3 and #4) in\n> Package RBF. Imagine that Alice (honest) and Bob (adversary) share a\n> LN channel. The mempool is rather full, so their pre-negotiated\n> commitment transactions' feerates would not be considered high\n> priority by miners.  Bob broadcasts his commitment transaction and\n> attaches a very large child (100KvB with 100,000sat in fees) to his\n> anchor output. Alice broadcasts her commitment transaction with a\n> fee-bumping child (200vB with 50,000sat fees which is a generous\n> 250sat/vB), but this does not meet the absolute fee requirement. She\n> would need to add another 50,000sat to replace Bob's commitment\n> transaction.\n\nSolving LN pinning attacks, what we're aiming for is enabling a fair\nfeerate bid between the  counterparties, thus either forcing the adversary\nto overbid or to disengage from the confirmation competition. If the\nreplace-by-feerate rule is adopted, there shouldn't be an incentive for Bob\nto\npick up the first option. Though if he does, that's a winning outcome for\nAlice, as one of the commitment transactions confirms and her\ntime-sensitive second-stage HTLC can be subsequently confirmed.\n\n> It's unclear to me if\n> we have a very strong reason to change this, but noting it as a\n> limitation of our current replacement policy. See [#24007][12].\n\nDeployment of Taproot opens interesting possibilities in the vaults/payment\nchannels design space, where the tapscripts can commit to different set of\ntimelocks/quorum of keys. Even if the pre-signed states stay symmetric,\nwhoever is the publisher, the feerate cost to spend can fluctuate.\n\n> While this isn't completely broken, and the user interface is\n> secondary to the safety of the mempool policy\n\nI think with L2s transaction broadcast backend, the stability and clarity\nof the RBF user interface is primary. What we could be worried about is a\ntoo-much complex interface easing the way for an attacker to trigger your\nL2 node to issue policy-invalid chain of transactions. Especially, when we\nconsider that an attacker might have leverage on chain of transactions\ncomposition (\"force broadcast of commitment A then commitment B, knowing\nthey will share a CPFP\") or even transactions size (\"overload commitment A\nwith HTLCs\").\n\n> * If the original transaction is in the top {0.75MvB, 1MvB} of the\n>   mempool, apply the current rules (absolute fees must increase and\n> pay for the replacement transaction's new bandwidth). Otherwise, use a\n> feerate-only rule.\n\nHow this new replacement rule would behave if you have a parent in the\n\"replace-by-feerate\" half but the child is in the \"replace-by-fee\" one ?\n\nIf we allow the replacement of the parent based on the feerate, we might\ndecrease the top block absolute fees.\n\nIf we block the replacement of the parent based on the feerate because the\nreplacement absolute fees aren't above the replaced package, we still\npreclude a pinning vector. The child might be low-feerate junk and even\nattached to a low ancestor-score branch.\n\nIf I'm correct on this limitation, maybe we could turn off the\n\"replace-by-fee\" behavior as soon as the mempool is fulfilled with a few\nblocks ?\n\n> * Rate-limit how many replacements we allow per prevout.\n\nDepending on how it is implemented, though I would be concerned it\nintroduces a new pinning vector in the context of shared-utxo. If it's a\nhardcoded constant, it could be exhausted by an adversary starting at the\nlowest acceptable feerate then slowly increasing while still not reaching\nthe top of the mempool. Same if it's time-based or block-based, no\nguarantee the replacement slot is honestly used by your counterparty.\n\nFurther, an above-the-average replacement frequency might just be the\nreflection of your confirmation strategy reacting to block schedule or\nmempools historical data. As long as the feerate penalty is paid, I lean to\nallow replacement.\n\n(One solution could be to associate per-user \"tag\" to the LN transactions,\nwhere each \"tag\" would have its own replacement slots, but privacy?)\n\n> * Rate-limit transaction validation in general, per peer.\n\nI think we could improve on the Core's new transaction requester logic.\nMaybe we could bind the peer announced flow based on the feerate score\n(modulo validation time) of the previously validated transactions from that\npeer ? That said, while related to RBF, it sounds to me that enhancing\nCore's rate-limiting transaction strategy is a whole discussion in itself\n[0]. Especially ensuring it's tolerant to the specific requirements of LN &\nconsorts.\n\n> What should they be? We can do some arithmetic to see what happens if\n> you start with the biggest/lowest feerate transaction and do a bunch\n> of replacements. Maybe we end up with values that are high enough to\n> prevent abuse and make sense for applications/users that do RBF.\n\nThat's a good question.\n\nOne observation is that the attacker can always renew the set of DoSy utxos\nto pursue the attack. So maybe we could pick up constants scaled on the\nblock size ? That way an attacker would have to burn fees, thus deterring\nthem from launching an attack. Even if the attackers are miners, they have\nto renounce their income to acquire new DoSy utxos. If a low-fee period, we\ncould scale up the constants ?\n\n\nOverall, I think there is the deployment issue to warn of. Moving to a new\nset of RBF rules implies for a lot of Bitcoin applications to rewrite their\nRBF logics. We might have a more-or-less long transition period during\nwhich we support both...\n\nCheers,\nAntoine\n\n[0] https://github.com/bitcoin/bitcoin/pull/21224\n\nLe jeu. 27 janv. 2022 \u00e0 09:10, Gloria Zhao via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n> Hi everyone,\n>\n> This post discusses limitations of current Bitcoin Core RBF policy and\n> attempts to start a conversation about how we can improve it,\n> summarizing some ideas that have been discussed. Please reply if you\n> have any new input on issues to be solved and ideas for improvement!\n>\n> Just in case I've screwed up the text wrapping again, another copy can be\n> found here:\n> https://gist.github.com/glozow/25d9662c52453bd08b4b4b1d3783b9ff\n>\n> ## Background\n>\n> Please feel free to skip this section if you are already familiar\n> with RBF.\n>\n> Nodes may receive *conflicting* unconfirmed transactions, aka\n> \"double spends\" of the same inputs. Instead of always keeping the\n> first transaction, since v0.12, Bitcoin Core mempool policy has\n> included a set of Replace-by-Fee (RBF) criteria that allows the second\n> transaction to replace the first one and any descendants it may have.\n>\n> Bitcoin Core RBF policy was previously documented as BIP 125.\n> The current RBF policy is documented [here][1]. In summary:\n>\n> 1. The directly conflicting transactions all signal replaceability\n>    explicitly.\n>\n> 2. The replacement transaction only includes an unconfirmed input if\n>    that input was included in one of the directly conflicting\n> transactions.\n>\n> 3. The replacement transaction pays an absolute fee of at least the\n>    sum paid by the original transactions.\n>\n> 4. The additional fees pays for the replacement transaction's\n>    bandwidth at or above the rate set by the node's *incremental relay\n> feerate*.\n>\n> 5. The sum of all directly conflicting transactions' descendant counts\n>    (number of transactions inclusive of itself and its descendants)\n> does not exceed 100.\n>\n> We can split these rules into 3 categories/goals:\n>\n> - **Allow Opting Out**: Some applications/businesses are unable to\n>   handle transactions that are replaceable (e.g. merchants that use\n> zero-confirmation transactions). We (try to) help these businesses by\n> honoring BIP125 signaling; we won't replace transactions that have not\n> opted in.\n>\n> - **Incentive Compatibility**: Ensure that our RBF policy would not\n>   accept replacement transactions which would decrease fee profits\n>   of a miner. In general, if our mempool policy deviates from what is\n> economically rational, it's likely that the transactions in our\n> mempool will not match the ones in miners' mempools, making our\n> fee estimation, compact block relay, and other mempool-dependent\n> functions unreliable. Incentive-incompatible policy may also\n> encourage transaction submission through routes other than the p2p\n> network, harming censorship-resistance and privacy of Bitcoin payments.\n>\n> - **DoS Protection**: Limit two types of DoS attacks on the node's\n>   mempool: (1) the number of times a transaction can be replaced and\n> (2) the volume of transactions that can be evicted during a\n> replacement.\n>\n> Even more abstract: our goal is to make a replacement policy that\n> results in a useful interface for users and safe policy for\n> node operators.\n>\n> ## Motivation\n>\n> There are a number of known problems with the current RBF policy.\n> Many of these shortcomings exist due to mempool limitations at the\n> time RBF was implemented or result from new types of Bitcoin usage;\n> they are not criticisms of the original design.\n>\n> ### Pinning Attacks\n>\n> The most pressing concern is that attackers may take advantage of\n> limitations in RBF policy to prevent other users' transactions from\n> being mined or getting accepted as a replacement.\n>\n> #### SIGHASH_ANYONECANPAY Pinning\n>\n> BIP125#2 can be bypassed by creating intermediary transactions to be\n> replaced together. Anyone can simply split a 1-input 1-output\n> transaction off from the replacement transaction, then broadcast the\n> transaction as is. This can always be done, and quite cheaply. More\n> details in [this comment][2].\n>\n> In general, if a transaction is signed with SIGHASH\\_ANYONECANPAY,\n> anybody can just attach a low feerate parent to this transaction and\n> lower its ancestor feerate.  Even if you require SIGHASH\\_ALL which\n> prevents an attacker from changing any outputs, the input can be a\n> very low amount (e.g. just above the dust limit) from a low-fee\n> ancestor and still bring down the ancestor feerate of the transaction.\n>\n> TLDR: if your transaction is signed with SIGHASH\\_ANYONECANPAY and\n> signals replaceability, regardless of the feerate you broadcast at, an\n> attacker can lower its mining priority by adding an ancestor.\n>\n> #### Absolute Fee\n>\n> The restriction of requiring replacement transactions to increase the\n> absolute fee of the mempool has been described as \"bonkers.\" If the\n> original transaction has a very large descendant that pays a large\n> amount of fees, even if it has a low feerate, the replacement\n> transaction must now pay those fees in order to meet Rule #3.\n>\n> #### Package RBF\n>\n> There are a number of reasons why, in order to enable Package RBF, we\n> cannot use the same criteria.\n>\n> For starters, the absolute fee pinning attack is especially\n> problematic if we apply the same rules (i.e. Rule #3 and #4) in\n> Package RBF. Imagine that Alice (honest) and Bob (adversary) share a\n> LN channel. The mempool is rather full, so their pre-negotiated\n> commitment transactions' feerates would not be considered high\n> priority by miners.  Bob broadcasts his commitment transaction and\n> attaches a very large child (100KvB with 100,000sat in fees) to his\n> anchor output. Alice broadcasts her commitment transaction with a\n> fee-bumping child (200vB with 50,000sat fees which is a generous\n> 250sat/vB), but this does not meet the absolute fee requirement. She\n> would need to add another 50,000sat to replace Bob's commitment\n> transaction.\n>\n> Disallowing new unconfirmed inputs (Rule #2) in Package RBF would be\n> broken for packages containing transactions already in the mempool,\n> explained [here][7].\n>\n> Note: I originally [proposed][6] Package RBF using the same Rule #3\n> and #4 before I realized how significant this pinning attack is. I'm\n> retracting that proposal, and a new set of Package RBF rules would\n> follow from whatever the new individual RBF rules end up being.\n>\n> #### Same Txid Different Witness\n>\n> Two transactions with the same non-witness data but different\n> witnesses have the same txid but different wtxid, and the same fee but\n> not necessarily the same feerate. Currently, if we see a transaction\n> that has the same txid as one in the mempool, we reject it as a\n> duplicate, even if the feerate is much higher. It's unclear to me if\n> we have a very strong reason to change this, but noting it as a\n> limitation of our current replacement policy. See [#24007][12].\n>\n> ### User Interface\n>\n> #### Using Unconfirmed UTXOs to Fund Replacements\n>\n> The restriction of only allowing confirmed UTXOs for funding a\n> fee-bump (Rule #2) can hurt users trying to fee-bump their\n> transactions and complicate wallet implementations. If the original\n> transaction's output value isn't sufficient to fund a fee-bump and/or\n> all of the user's other UTXOs are unconfirmed, they might not be able\n> to fund a replacement transaction. Wallet developers also need to\n> treat self-owned unconfirmed UTXOs as unusable for fee-bumping, which\n> adds complexity to wallet logic. For example, see BDK issues [#144][4]\n> and [#414][5].\n>\n> #### Interface Not Suitable for Coin Selection\n>\n> Currently, a user cannot simply create a replacement transaction\n> targeting a specific feerate or meeting a minimum fee amount and\n> expect to meet the RBF criteria. The fee amount depends on the size of\n> the replacement transaction, and feerate is almost irrelevant.\n>\n> Bitcoin Core's `bumpfee` doesn't use the RBF rules when funding the\n> replacement. It [estimates][13] a feerate which is \"wallet incremental\n> relay fee\" (a conservative overestimation of the node's incremental\n> relay fee) higher than the original transaction, selects coins for\n> that feerate, and hopes that it meets the RBF rules. It never fails\n> Rule #3 and #4 because it uses all original inputs and refuses to\n> bump a transaction with mempool descendants.\n>\n> This is suboptimal, but is designed to work with the coin selection\n> engine: select a feerate first, and then add fees to cover it.\n> Following the exact RBF rules would require working the other way\n> around: based on how much fees we've added to the transaction and its\n> current size, calculate the feerate to see if we meet Rule #4.\n>\n> While this isn't completely broken, and the user interface is\n> secondary to the safety of the mempool policy, we can do much better.\n> A much more user-friendly interface would depend *only* on the\n> fee and size of the original transactions.\n>\n> ### Updates to Mempool and Mining\n>\n> Since RBF was first implemented, a number of improvements have been\n> made to mempool and mining logic. For example, we now use ancestor\n> feerates in mining (allowing CPFP), and keep track of ancestor\n> packages in the mempool.\n>\n> ## Ideas for Improvements\n>\n> ### Goals\n>\n> To summarize, these seem to be desired changes, in order of priority:\n>\n> 1. Remove Rule #3. The replacement should not be *required* to pay\n> higher absolute fees.\n>\n> 2. Make it impossible for a replacement transaction to have a lower\n> mining score than the original transaction(s). This would eliminate\n> the `SIGHASH\\_ANYONECANPAY` pinning attack.\n>\n> 3. Remove Rule #2. Adding new unconfirmed inputs should be allowed.\n>\n> 4. Create a more helpful interface that helps wallet fund replacement\n> transactions that aim for a feerate and fee.\n>\n> ### A Different Model for Fees\n>\n> For incentive compatibility, I believe there are different\n> formulations we should consider.  Most importantly, if we want to get\n> rid of the absolute fee rule, we can no longer think of it as \"the\n> transaction needs to pay for its own bandwidth,\" since we won't always\n> be getting additional fees. That means we need a new method of\n> rate-limiting replacements that doesn't require additional fees every\n> time.\n>\n> While it makes sense to think about monetary costs when launching a\n> specific type of attack, given that the fees are paid to the miner and\n> not to the mempool operators, maybe it doesn't make much sense to\n> think about \"paying for bandwidth\". Maybe we should implement\n> transaction validation rate-limiting differently, e.g. building it\n> into the P2P layer instead of the mempool policy layer.\n>\n> Recently, Suhas gave a [formulation][8] for incentive compatibility\n> that made sense to me: \"are the fees expected to be paid in the next\n> (N?) blocks higher or lower if we process this transaction?\"\n>\n> I started by thinking about this where N=1 or `1 + p`.\n> Here, a rational miner is looking at what fees they would\n> collect in the next block, and then some proportion `p` of the rest of\n> the blocks based on their hashrate. We're assuming `p` isn't *so high*\n> that they would be okay with lower absolute fees in the next 1 block.\n> We're also assuming `p` isn't *so low* that the miner doesn't care\n> about what's left of the mempool after this block.\n>\n> A tweak to this formulation is \"if we process this transaction, would\n> the fees in the next 1 block higher or lower, and is the feerate\n> density of the rest of the mempool higher or lower?\" This is pretty\n> similar, where N=1, but we consider the rest of the mempool by feerate\n> rather than fees.\n>\n> ### Mining Score of a Mempool Transaction\n>\n> We are often interested in finding out what\n> the \"mining score\" of a transaction in the mempool is. That is, when\n> the transaction is considered in block template building, what is the\n> feerate it is considered at?\n>\n> Obviously, it's not the transaction's individual feerate. Bitcoin Core\n> [mining code sorts][14] transactions by their ancestor feerate and\n> includes them packages at a time, keeping track of how this affects the\n> package feerates of remaining transactions in the mempool.\n>\n> *ancestor feerate*: Ancestor feerate is easily accessible information,\n> but it's not accurate either, because it doesn't take into account the\n> fact that subsets of a transaction's ancestor set can be included\n> without it. For example, ancestors may have high feerates on their own\n> or we may have [high feerate siblings][8].\n>\n> TLDR: *Looking at the current ancestor feerate of a transaction is\n> insufficient to tell us what feerate it will be considered at when\n> building a block template in the future.*\n>\n> *min(individual feerate, ancestor feerate)*: Another\n> heuristic that is simple to calculate based on current mempool tooling\n> is to use the [minimum of a transaction's individual score and its\n> ancestor score][10] as a conservative measure.  But this can\n> overestimate as well (see the example below).\n>\n> *min ancestor feerate(tx + possible ancestor subsets)* We can also\n> take the minimum of every possible ancestor subset, but this can be\n> computationally expensive since there can be lots and lots of ancestor\n> subsets.\n>\n> *max ancestor feerate(tx + possible descendant subsets)*: Another idea\n> is to use the [maximum ancestor score of the transaction + each of its\n> descendants][9]. This doesn't work either; it has the same blindspot\n> of ancestor subsets being mined on their own.\n>\n> #### Mining Score Example\n>\n> Here's an example illustrating why mining score is tricky to\n> efficiently calculate for mempool transactions:\n>\n> Let's say you have same-size transactions A (21sat/vB), B (1sat/vB),\n> C(9sat/vB), D(5sat/vB).\n> The layout is: grandparent A, parent B, and two children C and D.\n>\n> ```\n>     A\n>     ^\n>     B\n>    ^ ^\n>    C D\n> ```\n>\n> A miner using ancestor packages to build block templates will first\n> include A with a mining score of 21. Next, the miner will include B and\n> C with a mining score of 6. This leaves D, with a mining score of 5.\n>\n> Note: in this case, mining by ancestor feerate results in the most\n> rational decisions, but [a candidate set-based approach][10] which\n> makes ancestor feerate much less relevant could\n> be more advantageous in other situations.\n>\n> Here is a chart showing the \"true\" mining score alongside the values\n> calculating using imperfect heuristics described above. All of them\n> can overestimate or underestimate.\n>\n> ```\n>    A     B       C     D\n> mining score |   21   |   6   |   6   |   5   |\n> ancestor feerate   |   21   |  11   | 10.3  |   9   |\n> min(individual, ancestor) |   21   |   1   |   9   |   5   |\n> min(tx + ancestor subsets)      |   21   |   1   |   5   |   3   |\n> max(tx + descendants subsets) |   21   |   9   |   9   |   5   |\n>\n> ```\n>\n> Possibly the best solution for finding the \"mining score\" of a\n> transaction is to build a block template, see what feerate each\n> package is included at. Perhaps at some cutoff, remaining mempool\n> transactions can be estimated using some heuristic that leans\n> {overestimating, underestimating} depending on the situation.\n>\n> Mining score seems to be relevant in multiple places: Murch and I\n> recently [found][3] that it would be very important in\n> \"ancestor-aware\" funding of transactions (the wallet doesn't\n> incorporate ancestor fees when using unconfirmed transactions in coin\n> selection, which is a bug we want to fix).\n>\n> In general, it would be nice to know the exact mining priority of\n> one's unconfirmed transaction is.  I can think of a few block/mempool\n> explorers who might want to display this information for users.\n>\n> ### RBF Improvement Proposals\n>\n> After speaking to quite a few people, here are some suggestions\n> for improvements that I have heard:\n>\n> * The ancestor score of the replacement must be {5, 10, N}% higher\n>   than that of every original transaction.\n>\n> * The ancestor score of the replacement must be 1sat/vB higher than\n>   that of every original transaction.\n>\n> * If the original transaction is in the top {0.75MvB, 1MvB} of the\n>   mempool, apply the current rules (absolute fees must increase and\n> pay for the replacement transaction's new bandwidth). Otherwise, use a\n> feerate-only rule.\n>\n> * If fees don't increase, the size of the replacement transaction must\n>   decrease by at least N%.\n>\n> * Rate-limit how many replacements we allow per prevout.\n>\n> * Rate-limit transaction validation in general, per peer.\n>\n> Perhaps some others on the mailing list can chime in to throw other\n> ideas into the ring and/or combine some of these rules into a sensible\n> policy.\n>\n> #### Replace by Feerate Only\n>\n> I don't think there's going to be a single-line feerate-based\n> rule that can incorporate everything we need.\n> On one hand, a feerate-only approach helps eliminate the issues\n> associated with Rule #3. On the other hand, I believe the main concern\n> with a feerate-only approach is how to rate limit replacements. We\n> don't want to enable an attack such as:\n>\n> 1. Attacker broadcasts large, low-feerate transaction, and attaches a\n> chain of descendants.\n>\n> 2. The attacker replaces the transaction with a smaller but higher\n> feerate transaction, attaching a new chain of descendants.\n>\n> 3. Repeat 1000 times.\n>\n> #### Fees in Next Block and Feerate for the Rest of the Mempool\n>\n> Perhaps we can look at replacements like this:\n>\n> 1. Calculate the directly conflicting transactions and, with their\n> descendants, the original transactions. Check signaling. Limit the\n> total volume (e.g. can't be more than 100 total or 1MvB or something).\n>\n> 2. Find which original transactions would be in the next ~1 block. The\n> replacement must pay at least this amount + X% in absolute fees. This\n> guarantees that the fees of the next block doesn't decrease.\n>\n> 3. Find which transactions would be left in the mempool after that ~1\n> block. The replacement's feerate must be Y% higher than the maximum\n> mining score of these transactions. This guarantees that you now have\n> only *better* candidates in your after-this-block mempool than you did\n> before, even if the size and fees the transactions decrease.\n>\n> 4. Now you have two numbers: a minimum absolute fee amount and a\n> minimum feerate. Check to see if the replacement(s) meet these\n> minimums. Also, a wallet would be able to ask the node \"What fee and\n> feerate would I need to put on a transaction replacing this?\" and use\n> this information to fund a replacement transaction, without needing to\n> guess or overshoot.\n>\n> Obviously, there are some magic numbers missing here. X and Y are\n> TBD constants to ensure we have some kind of rate limiting for the\n> number of replacements allowed using some set of fees.\n>\n> What should they be? We can do some arithmetic to see what happens if\n> you start with the biggest/lowest feerate transaction and do a bunch\n> of replacements. Maybe we end up with values that are high enough to\n> prevent abuse and make sense for applications/users that do RBF.\n>\n> ### Mempool Changes Need for Implementation\n>\n> As described in the mining score section above,\n> we may want additional tooling to more accurately assess\n> the economic gain of replacing transactions in our mempool.\n>\n> A few options have been discussed:\n>\n> * Calculate block templates on the fly when we need to consider a\n>   replacement. However, since replacements are [quite common][11]\n>   and the information might be useful for other things as well,\n>   it may be worth it to cache a block template.\n>\n> * Keep a persistent block template so that we know what transactions\n>   we would put in the next block. We need to remember the feerate\n> at which each transaction was included in the template, because an\n> ancestor package may be included in the same block template in\n> multiple subsets. Transactions included earlier alter the ancestor\n> feerate of the remaining transactions in the package. We also need\n> to keep track of the new feerates of transactions left over.\n>\n> * Divide the mempool into two layers, \"high feerate\" and \"low\n>   feerate.\" The high feerate layer contains ~1 block of packages with\n> the highest ancestor feerates, and the low feerate layer contains\n> everything else. At the edge of a block, we have a Knapsacky problem\n> where the next highest ancestor feerate package might not fit, so we\n> would probably want the high feerate layer ~2MvB or something to avoid\n> underestimating the fees.\n>\n> ## Acknowledgements\n>\n> Thank you to everyone whose RBF-related suggestions, grievances,\n> criticisms and ideas were incorporated in this document:\n> Andrew Chow, Matt Corallo, Suhas Daftuar, Christian Decker,\n> Mark Erhardt, Lloyd Fournier, Lisa Neigut, John Newbery,\n> Antoine Poinsot, Antoine Riard, Larry Ruane,\n> S3RK and Bastien Teinturier.\n>\n> Thanks for reading!\n>\n> Best,\n> Gloria\n>\n> [1]:\n> https://github.com/bitcoin/bitcoin/blob/master/doc/policy/mempool-replacements.md\n> [2]: https://github.com/bitcoin/bitcoin/pull/23121#issuecomment-929475999\n> [3]:\n> https://github.com/Xekyo/bitcoin/commit/d754b0242ec69d42c570418aebf9c1335af0b8ea\n> [4]: https://github.com/bitcoindevkit/bdk/issues/144\n> [5]: https://github.com/bitcoindevkit/bdk/issues/414\n> [6]:\n> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html\n> [7]:\n> https://gist.github.com/glozow/dc4e9d5c5b14ade7cdfac40f43adb18a#new-unconfirmed-inputs-rule-2\n> [8]: https://github.com/bitcoin/bitcoin/pull/23121#discussion_r777131366\n> [9]: https://github.com/bitcoin/bitcoin/pull/22290#issuecomment-865887922\n> [10]:\n> https://gist.github.com/Xekyo/5cb413fe9f26dbce57abfd344ebbfaf2#file-candidate-set-based-block-building-md\n> [11]: https://github.com/bitcoin/bitcoin/pull/22539#issuecomment-885763670\n> [12]: https://github.com/bitcoin/bitcoin/pull/24007\n> [13]:\n> https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/wallet/feebumper.cpp#L114\n> [14]:\n> https://github.com/bitcoin/bitcoin/blob/cf5bb048e80d4cde8828787b266b7f5f2e3b6d7b/src/node/miner.cpp#L310-L320\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220130/f53be2a3/attachment-0001.html>"
            },
            {
                "author": "Bastien TEINTURIER",
                "date": "2022-01-31T15:57:52",
                "message_text_only": "Hi Gloria,\n\nMany thanks for raising awareness on these issues and constantly pushing\ntowards finding a better model. This work will highly improve the\nsecurity of any multi-party contract trying to build on top of bitcoin\n(because most multi-party contracts will need to have timeout conditions\nand participants will need to make some transactions confirm before a\ntimeout happens - otherwise they may lose funds).\n\nFor starters, let me quickly explain why the current rules are hard to\nwork with in the context of lightning (but I believe most L2 protocols\nwill have the same issues). Feel free to skip this part if you are\nalready convinced.\n\n## Motivation\n\nThe biggest pain point is BIP 125 rule 2.\nIf I need to increase the fees of a time-sensitive transaction because\nthe feerate has been rising since I broadcast it, I may need to also pay\nhigh fees just to produce a confirmed utxo that I can use. I'm actually\npaying a high fee twice instead of once (and needlessly using on-chain\nspace, our scarcest asset, because we could have avoided that additional\ntransaction!).\n\nIt also has some annoying \"non-determinism\".\nImagine that my transaction has been evicted from my mempool because its\nfeerate was too low. I could think \"Great, that means I don't have to\napply BIP 125 restrictions, I can just fund this transaction as if it\nwere a new one!\". But actually I do, because my transaction could still\nbe in miner's mempools and I have no way of knowing it...this means that\nwhenever I have broadcast a transaction, I must assume that I will\nalways need to abide by whatever replacement rules the network applies.\n\nFortunately, as far as I understand it, this rule only exists because of\na previous implementation detail of bitcoin core, so there's simply no\ngood reason to keep it.\n\nThe second biggest pain point is rule 3. It prevents me from efficiently\nusing my capital while it's unconfirmed. Whenever I'm using a big utxo\nto fund a transaction, I will get a big change output, and it would\nreally be a waste to be unable to use that change output to fund other\ntransactions. In order to be capital-efficient, I will end up creating\ndescendant trees for my time-sensitive transactions. But as Gloria\nexplained, replacing all my children will cost me an absurdly large\namount of fees. So what I'm actually planning to do instead is to RBF\none of the descendants high enough to get the whole tree confirmed.\nBut if those descendants' timeouts were far in the future, that's a\nwaste, I paid a lot more fees for them than I should have. I'd like to\njust replace my transaction and republish the invalidated children\nindependently.\n\nRule 4 doesn't hurt as much as the two previous ones, I don't have too\nmuch to say about it.\n\nTo be fair to the BIP 125 authors, all of these scenarios were very hard\nto forecast at the time this BIP was created. We needed years to build\non those rules to get a better understanding of their limitations and if\nthe rationale behind them made sense in the long term.\n\n## Proposals\n\nI believe that now is a good time to re-think those, and I really like\nGloria's categorization of the design constraints.\n\nI'd like to propose a different way of looking at descendants that makes\nit easier to design the new rules. The way I understand it, limiting the\nimpact on descendant transactions is only important for DoS protection,\nnot for incentive compatibility. I would argue that after evictions,\ndescendant transactions will be submitted again (because they represent\ntransactions that people actually want to make), so evicting them does\nnot have a negative impact on mining incentives (in a world where blocks\nare full most of the time).\n\nI'm curious to hear other people's thoughts on that. If it makes sense,\nI would propose the following very simple rules:\n\n1. The transaction's ancestor absolute fees must be X% higher than the\nprevious transaction's ancestor fees\n2. The transaction's ancestor feerate must be Y% higher than the\nprevious transaction's ancestor feerate\n\nI believe it's completely ok to require increasing both the fees and\nfeerate if we don't take descendants into account, because you control\nyour ancestor set - whereas the descendant set may be completely out of\nyour control.\n\nThis is very easy to use by wallets, because the ancestor set is easy to\nobtain. And an important point is that the ancestor set is the same in\nevery mempool, whereas the descendant set is not (your mempool may have\nrejected the last descendants, while other people's mempools may still\ncontain them).\n\nBecause of that reason, I'd like to avoid having a rule that relies on\nsome size of the replaced descendant set: it may be valid in your\nmempool but invalid in someone else's, which makes it exploitable for\npinning attacks.\n\nI believe these rules are incentive compatible (again, if you accept\nthe fact that the descendants will be re-submitted and mined as well,\nso their fees aren't lost).\n\nCan we choose X and Y so that these two rules are also DoS-resistant?\nUnfortunately I'm not sure, so maybe we'll need to add a third rule to\naddress that. But before we do, can someone detail what it costs for a\nnode to evict a descendant tree? Given that bitcoin core doesn't allow\nchains of more than 25 transactions, the maximum number of transactions\nbeing replaced will be bounded by 25 * N (where N is the number of\noutputs of the transaction being replaced). If it's just O(n) pruning of\na graph, maybe that's ok? Or maybe we make X or Y depend on the number\nof outputs of the transaction being replaced (this would need very\ncareful thoughts)?\n\nIf you made it this far, thanks for reading!\nA couple of comments on the previous messages:\n\n> Currently, if we see a transaction\n> that has the same txid as one in the mempool, we reject it as a\n> duplicate, even if the feerate is much higher. It's unclear to me if\n> we have a very strong reason to change this, but noting it as a\n> limitation of our current replacement policy.\n\nI don't see a strong reason from an L2 protocol's point of view yet, but\nthere are many unkown unknowns. But from a miner incentive's point of\nview, we should keep the transaction with the higher feerate, shouldn't\nwe? In that case it's also a more efficient use of on-chain space, which\nis a win, right?\n\n> We might have a more-or-less long transition period during which we\nsupport both...\n\nYes, this is a long term thing.\nEven if bitcoin core releases a new version with updated RBF rules, as a\nwallet you'll need to keep using the old rules for a long time if you\nwant to be safe.\n\nBut it's all the more reason to try to ship this as soon as possible,\nthis way maybe our grand-children will be able to benefit from it ;)\n(just kidding on the timespan obviously).\n\nCheers,\nBastien\n\nLe lun. 31 janv. 2022 \u00e0 00:11, Antoine Riard via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n\n> Hi Gloria,\n>\n> Thanks for this RBF sum up. Few thoughts and more context comments if it\n> can help other readers.\n>\n> > For starters, the absolute fee pinning attack is especially\n> > problematic if we apply the same rules (i.e. Rule #3 and #4) in\n> > Package RBF. Imagine that Alice (honest) and Bob (adversary) share a\n> > LN channel. The mempool is rather full, so their pre-negotiated\n> > commitment transactions' feerates would not be considered high\n> > priority by miners.  Bob broadcasts his commitment transaction and\n> > attaches a very large child (100KvB with 100,000sat in fees) to his\n> > anchor output. Alice broadcasts her commitment transaction with a\n> > fee-bumping child (200vB with 50,000sat fees which is a generous\n> > 250sat/vB), but this does not meet the absolute fee requirement. She\n> > would need to add another 50,000sat to replace Bob's commitment\n> > transaction.\n>\n> Solving LN pinning attacks, what we're aiming for is enabling a fair\n> feerate bid between the  counterparties, thus either forcing the adversary\n> to overbid or to disengage from the confirmation competition. If the\n> replace-by-feerate rule is adopted, there shouldn't be an incentive for Bob\n> to\n> pick up the first option. Though if he does, that's a winning outcome for\n> Alice, as one of the commitment transactions confirms and her\n> time-sensitive second-stage HTLC can be subsequently confirmed.\n>\n> > It's unclear to me if\n> > we have a very strong reason to change this, but noting it as a\n> > limitation of our current replacement policy. See [#24007][12].\n>\n> Deployment of Taproot opens interesting possibilities in the\n> vaults/payment channels design space, where the tapscripts can commit to\n> different set of timelocks/quorum of keys. Even if the pre-signed states\n> stay symmetric, whoever is the publisher, the feerate cost to spend can\n> fluctuate.\n>\n> > While this isn't completely broken, and the user interface is\n> > secondary to the safety of the mempool policy\n>\n> I think with L2s transaction broadcast backend, the stability and clarity\n> of the RBF user interface is primary. What we could be worried about is a\n> too-much complex interface easing the way for an attacker to trigger your\n> L2 node to issue policy-invalid chain of transactions. Especially, when we\n> consider that an attacker might have leverage on chain of transactions\n> composition (\"force broadcast of commitment A then commitment B, knowing\n> they will share a CPFP\") or even transactions size (\"overload commitment A\n> with HTLCs\").\n>\n> > * If the original transaction is in the top {0.75MvB, 1MvB} of the\n> >   mempool, apply the current rules (absolute fees must increase and\n> > pay for the replacement transaction's new bandwidth). Otherwise, use a\n> > feerate-only rule.\n>\n> How this new replacement rule would behave if you have a parent in the\n> \"replace-by-feerate\" half but the child is in the \"replace-by-fee\" one ?\n>\n> If we allow the replacement of the parent based on the feerate, we might\n> decrease the top block absolute fees.\n>\n> If we block the replacement of the parent based on the feerate because the\n> replacement absolute fees aren't above the replaced package, we still\n> preclude a pinning vector. The child might be low-feerate junk and even\n> attached to a low ancestor-score branch.\n>\n> If I'm correct on this limitation, maybe we could turn off the\n> \"replace-by-fee\" behavior as soon as the mempool is fulfilled with a few\n> blocks ?\n>\n> > * Rate-limit how many replacements we allow per prevout.\n>\n> Depending on how it is implemented, though I would be concerned it\n> introduces a new pinning vector in the context of shared-utxo. If it's a\n> hardcoded constant, it could be exhausted by an adversary starting at the\n> lowest acceptable feerate then slowly increasing while still not reaching\n> the top of the mempool. Same if it's time-based or block-based, no\n> guarantee the replacement slot is honestly used by your counterparty.\n>\n> Further, an above-the-average replacement frequency might just be the\n> reflection of your confirmation strategy reacting to block schedule or\n> mempools historical data. As long as the feerate penalty is paid, I lean to\n> allow replacement.\n>\n> (One solution could be to associate per-user \"tag\" to the LN transactions,\n> where each \"tag\" would have its own replacement slots, but privacy?)\n>\n> > * Rate-limit transaction validation in general, per peer.\n>\n> I think we could improve on the Core's new transaction requester logic.\n> Maybe we could bind the peer announced flow based on the feerate score\n> (modulo validation time) of the previously validated transactions from that\n> peer ? That said, while related to RBF, it sounds to me that enhancing\n> Core's rate-limiting transaction strategy is a whole discussion in itself\n> [0]. Especially ensuring it's tolerant to the specific requirements of LN &\n> consorts.\n>\n> > What should they be? We can do some arithmetic to see what happens if\n> > you start with the biggest/lowest feerate transaction and do a bunch\n> > of replacements. Maybe we end up with values that are high enough to\n> > prevent abuse and make sense for applications/users that do RBF.\n>\n> That's a good question.\n>\n> One observation is that the attacker can always renew the set of DoSy\n> utxos to pursue the attack. So maybe we could pick up constants scaled on\n> the block size ? That way an attacker would have to burn fees, thus\n> deterring them from launching an attack. Even if the attackers are miners,\n> they have to renounce their income to acquire new DoSy utxos. If a low-fee\n> period, we could scale up the constants ?\n>\n>\n> Overall, I think there is the deployment issue to warn of. Moving to a new\n> set of RBF rules implies for a lot of Bitcoin applications to rewrite their\n> RBF logics. We might have a more-or-less long transition period during\n> which we support both...\n>\n> Cheers,\n> Antoine\n>\n> [0] https://github.com/bitcoin/bitcoin/pull/21224\n>\n> Le jeu. 27 janv. 2022 \u00e0 09:10, Gloria Zhao via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> a \u00e9crit :\n>\n>> Hi everyone,\n>>\n>> This post discusses limitations of current Bitcoin Core RBF policy and\n>> attempts to start a conversation about how we can improve it,\n>> summarizing some ideas that have been discussed. Please reply if you\n>> have any new input on issues to be solved and ideas for improvement!\n>>\n>> Just in case I've screwed up the text wrapping again, another copy can be\n>> found here:\n>> https://gist.github.com/glozow/25d9662c52453bd08b4b4b1d3783b9ff\n>>\n>> ## Background\n>>\n>> Please feel free to skip this section if you are already familiar\n>> with RBF.\n>>\n>> Nodes may receive *conflicting* unconfirmed transactions, aka\n>> \"double spends\" of the same inputs. Instead of always keeping the\n>> first transaction, since v0.12, Bitcoin Core mempool policy has\n>> included a set of Replace-by-Fee (RBF) criteria that allows the second\n>> transaction to replace the first one and any descendants it may have.\n>>\n>> Bitcoin Core RBF policy was previously documented as BIP 125.\n>> The current RBF policy is documented [here][1]. In summary:\n>>\n>> 1. The directly conflicting transactions all signal replaceability\n>>    explicitly.\n>>\n>> 2. The replacement transaction only includes an unconfirmed input if\n>>    that input was included in one of the directly conflicting\n>> transactions.\n>>\n>> 3. The replacement transaction pays an absolute fee of at least the\n>>    sum paid by the original transactions.\n>>\n>> 4. The additional fees pays for the replacement transaction's\n>>    bandwidth at or above the rate set by the node's *incremental relay\n>> feerate*.\n>>\n>> 5. The sum of all directly conflicting transactions' descendant counts\n>>    (number of transactions inclusive of itself and its descendants)\n>> does not exceed 100.\n>>\n>> We can split these rules into 3 categories/goals:\n>>\n>> - **Allow Opting Out**: Some applications/businesses are unable to\n>>   handle transactions that are replaceable (e.g. merchants that use\n>> zero-confirmation transactions). We (try to) help these businesses by\n>> honoring BIP125 signaling; we won't replace transactions that have not\n>> opted in.\n>>\n>> - **Incentive Compatibility**: Ensure that our RBF policy would not\n>>   accept replacement transactions which would decrease fee profits\n>>   of a miner. In general, if our mempool policy deviates from what is\n>> economically rational, it's likely that the transactions in our\n>> mempool will not match the ones in miners' mempools, making our\n>> fee estimation, compact block relay, and other mempool-dependent\n>> functions unreliable. Incentive-incompatible policy may also\n>> encourage transaction submission through routes other than the p2p\n>> network, harming censorship-resistance and privacy of Bitcoin payments.\n>>\n>> - **DoS Protection**: Limit two types of DoS attacks on the node's\n>>   mempool: (1) the number of times a transaction can be replaced and\n>> (2) the volume of transactions that can be evicted during a\n>> replacement.\n>>\n>> Even more abstract: our goal is to make a replacement policy that\n>> results in a useful interface for users and safe policy for\n>> node operators.\n>>\n>> ## Motivation\n>>\n>> There are a number of known problems with the current RBF policy.\n>> Many of these shortcomings exist due to mempool limitations at the\n>> time RBF was implemented or result from new types of Bitcoin usage;\n>> they are not criticisms of the original design.\n>>\n>> ### Pinning Attacks\n>>\n>> The most pressing concern is that attackers may take advantage of\n>> limitations in RBF policy to prevent other users' transactions from\n>> being mined or getting accepted as a replacement.\n>>\n>> #### SIGHASH_ANYONECANPAY Pinning\n>>\n>> BIP125#2 can be bypassed by creating intermediary transactions to be\n>> replaced together. Anyone can simply split a 1-input 1-output\n>> transaction off from the replacement transaction, then broadcast the\n>> transaction as is. This can always be done, and quite cheaply. More\n>> details in [this comment][2].\n>>\n>> In general, if a transaction is signed with SIGHASH\\_ANYONECANPAY,\n>> anybody can just attach a low feerate parent to this transaction and\n>> lower its ancestor feerate.  Even if you require SIGHASH\\_ALL which\n>> prevents an attacker from changing any outputs, the input can be a\n>> very low amount (e.g. just above the dust limit) from a low-fee\n>> ancestor and still bring down the ancestor feerate of the transaction.\n>>\n>> TLDR: if your transaction is signed with SIGHASH\\_ANYONECANPAY and\n>> signals replaceability, regardless of the feerate you broadcast at, an\n>> attacker can lower its mining priority by adding an ancestor.\n>>\n>> #### Absolute Fee\n>>\n>> The restriction of requiring replacement transactions to increase the\n>> absolute fee of the mempool has been described as \"bonkers.\" If the\n>> original transaction has a very large descendant that pays a large\n>> amount of fees, even if it has a low feerate, the replacement\n>> transaction must now pay those fees in order to meet Rule #3.\n>>\n>> #### Package RBF\n>>\n>> There are a number of reasons why, in order to enable Package RBF, we\n>> cannot use the same criteria.\n>>\n>> For starters, the absolute fee pinning attack is especially\n>> problematic if we apply the same rules (i.e. Rule #3 and #4) in\n>> Package RBF. Imagine that Alice (honest) and Bob (adversary) share a\n>> LN channel. The mempool is rather full, so their pre-negotiated\n>> commitment transactions' feerates would not be considered high\n>> priority by miners.  Bob broadcasts his commitment transaction and\n>> attaches a very large child (100KvB with 100,000sat in fees) to his\n>> anchor output. Alice broadcasts her commitment transaction with a\n>> fee-bumping child (200vB with 50,000sat fees which is a generous\n>> 250sat/vB), but this does not meet the absolute fee requirement. She\n>> would need to add another 50,000sat to replace Bob's commitment\n>> transaction.\n>>\n>> Disallowing new unconfirmed inputs (Rule #2) in Package RBF would be\n>> broken for packages containing transactions already in the mempool,\n>> explained [here][7].\n>>\n>> Note: I originally [proposed][6] Package RBF using the same Rule #3\n>> and #4 before I realized how significant this pinning attack is. I'm\n>> retracting that proposal, and a new set of Package RBF rules would\n>> follow from whatever the new individual RBF rules end up being.\n>>\n>> #### Same Txid Different Witness\n>>\n>> Two transactions with the same non-witness data but different\n>> witnesses have the same txid but different wtxid, and the same fee but\n>> not necessarily the same feerate. Currently, if we see a transaction\n>> that has the same txid as one in the mempool, we reject it as a\n>> duplicate, even if the feerate is much higher. It's unclear to me if\n>> we have a very strong reason to change this, but noting it as a\n>> limitation of our current replacement policy. See [#24007][12].\n>>\n>> ### User Interface\n>>\n>> #### Using Unconfirmed UTXOs to Fund Replacements\n>>\n>> The restriction of only allowing confirmed UTXOs for funding a\n>> fee-bump (Rule #2) can hurt users trying to fee-bump their\n>> transactions and complicate wallet implementations. If the original\n>> transaction's output value isn't sufficient to fund a fee-bump and/or\n>> all of the user's other UTXOs are unconfirmed, they might not be able\n>> to fund a replacement transaction. Wallet developers also need to\n>> treat self-owned unconfirmed UTXOs as unusable for fee-bumping, which\n>> adds complexity to wallet logic. For example, see BDK issues [#144][4]\n>> and [#414][5].\n>>\n>> #### Interface Not Suitable for Coin Selection\n>>\n>> Currently, a user cannot simply create a replacement transaction\n>> targeting a specific feerate or meeting a minimum fee amount and\n>> expect to meet the RBF criteria. The fee amount depends on the size of\n>> the replacement transaction, and feerate is almost irrelevant.\n>>\n>> Bitcoin Core's `bumpfee` doesn't use the RBF rules when funding the\n>> replacement. It [estimates][13] a feerate which is \"wallet incremental\n>> relay fee\" (a conservative overestimation of the node's incremental\n>> relay fee) higher than the original transaction, selects coins for\n>> that feerate, and hopes that it meets the RBF rules. It never fails\n>> Rule #3 and #4 because it uses all original inputs and refuses to\n>> bump a transaction with mempool descendants.\n>>\n>> This is suboptimal, but is designed to work with the coin selection\n>> engine: select a feerate first, and then add fees to cover it.\n>> Following the exact RBF rules would require working the other way\n>> around: based on how much fees we've added to the transaction and its\n>> current size, calculate the feerate to see if we meet Rule #4.\n>>\n>> While this isn't completely broken, and the user interface is\n>> secondary to the safety of the mempool policy, we can do much better.\n>> A much more user-friendly interface would depend *only* on the\n>> fee and size of the original transactions.\n>>\n>> ### Updates to Mempool and Mining\n>>\n>> Since RBF was first implemented, a number of improvements have been\n>> made to mempool and mining logic. For example, we now use ancestor\n>> feerates in mining (allowing CPFP), and keep track of ancestor\n>> packages in the mempool.\n>>\n>> ## Ideas for Improvements\n>>\n>> ### Goals\n>>\n>> To summarize, these seem to be desired changes, in order of priority:\n>>\n>> 1. Remove Rule #3. The replacement should not be *required* to pay\n>> higher absolute fees.\n>>\n>> 2. Make it impossible for a replacement transaction to have a lower\n>> mining score than the original transaction(s). This would eliminate\n>> the `SIGHASH\\_ANYONECANPAY` pinning attack.\n>>\n>> 3. Remove Rule #2. Adding new unconfirmed inputs should be allowed.\n>>\n>> 4. Create a more helpful interface that helps wallet fund replacement\n>> transactions that aim for a feerate and fee.\n>>\n>> ### A Different Model for Fees\n>>\n>> For incentive compatibility, I believe there are different\n>> formulations we should consider.  Most importantly, if we want to get\n>> rid of the absolute fee rule, we can no longer think of it as \"the\n>> transaction needs to pay for its own bandwidth,\" since we won't always\n>> be getting additional fees. That means we need a new method of\n>> rate-limiting replacements that doesn't require additional fees every\n>> time.\n>>\n>> While it makes sense to think about monetary costs when launching a\n>> specific type of attack, given that the fees are paid to the miner and\n>> not to the mempool operators, maybe it doesn't make much sense to\n>> think about \"paying for bandwidth\". Maybe we should implement\n>> transaction validation rate-limiting differently, e.g. building it\n>> into the P2P layer instead of the mempool policy layer.\n>>\n>> Recently, Suhas gave a [formulation][8] for incentive compatibility\n>> that made sense to me: \"are the fees expected to be paid in the next\n>> (N?) blocks higher or lower if we process this transaction?\"\n>>\n>> I started by thinking about this where N=1 or `1 + p`.\n>> Here, a rational miner is looking at what fees they would\n>> collect in the next block, and then some proportion `p` of the rest of\n>> the blocks based on their hashrate. We're assuming `p` isn't *so high*\n>> that they would be okay with lower absolute fees in the next 1 block.\n>> We're also assuming `p` isn't *so low* that the miner doesn't care\n>> about what's left of the mempool after this block.\n>>\n>> A tweak to this formulation is \"if we process this transaction, would\n>> the fees in the next 1 block higher or lower, and is the feerate\n>> density of the rest of the mempool higher or lower?\" This is pretty\n>> similar, where N=1, but we consider the rest of the mempool by feerate\n>> rather than fees.\n>>\n>> ### Mining Score of a Mempool Transaction\n>>\n>> We are often interested in finding out what\n>> the \"mining score\" of a transaction in the mempool is. That is, when\n>> the transaction is considered in block template building, what is the\n>> feerate it is considered at?\n>>\n>> Obviously, it's not the transaction's individual feerate. Bitcoin Core\n>> [mining code sorts][14] transactions by their ancestor feerate and\n>> includes them packages at a time, keeping track of how this affects the\n>> package feerates of remaining transactions in the mempool.\n>>\n>> *ancestor feerate*: Ancestor feerate is easily accessible information,\n>> but it's not accurate either, because it doesn't take into account the\n>> fact that subsets of a transaction's ancestor set can be included\n>> without it. For example, ancestors may have high feerates on their own\n>> or we may have [high feerate siblings][8].\n>>\n>> TLDR: *Looking at the current ancestor feerate of a transaction is\n>> insufficient to tell us what feerate it will be considered at when\n>> building a block template in the future.*\n>>\n>> *min(individual feerate, ancestor feerate)*: Another\n>> heuristic that is simple to calculate based on current mempool tooling\n>> is to use the [minimum of a transaction's individual score and its\n>> ancestor score][10] as a conservative measure.  But this can\n>> overestimate as well (see the example below).\n>>\n>> *min ancestor feerate(tx + possible ancestor subsets)* We can also\n>> take the minimum of every possible ancestor subset, but this can be\n>> computationally expensive since there can be lots and lots of ancestor\n>> subsets.\n>>\n>> *max ancestor feerate(tx + possible descendant subsets)*: Another idea\n>> is to use the [maximum ancestor score of the transaction + each of its\n>> descendants][9]. This doesn't work either; it has the same blindspot\n>> of ancestor subsets being mined on their own.\n>>\n>> #### Mining Score Example\n>>\n>> Here's an example illustrating why mining score is tricky to\n>> efficiently calculate for mempool transactions:\n>>\n>> Let's say you have same-size transactions A (21sat/vB), B (1sat/vB),\n>> C(9sat/vB), D(5sat/vB).\n>> The layout is: grandparent A, parent B, and two children C and D.\n>>\n>> ```\n>>     A\n>>     ^\n>>     B\n>>    ^ ^\n>>    C D\n>> ```\n>>\n>> A miner using ancestor packages to build block templates will first\n>> include A with a mining score of 21. Next, the miner will include B and\n>> C with a mining score of 6. This leaves D, with a mining score of 5.\n>>\n>> Note: in this case, mining by ancestor feerate results in the most\n>> rational decisions, but [a candidate set-based approach][10] which\n>> makes ancestor feerate much less relevant could\n>> be more advantageous in other situations.\n>>\n>> Here is a chart showing the \"true\" mining score alongside the values\n>> calculating using imperfect heuristics described above. All of them\n>> can overestimate or underestimate.\n>>\n>> ```\n>>    A     B       C     D\n>> mining score |   21   |   6   |   6   |   5   |\n>> ancestor feerate   |   21   |  11   | 10.3  |   9   |\n>> min(individual, ancestor) |   21   |   1   |   9   |   5   |\n>> min(tx + ancestor subsets)      |   21   |   1   |   5   |   3   |\n>> max(tx + descendants subsets) |   21   |   9   |   9   |   5   |\n>>\n>> ```\n>>\n>> Possibly the best solution for finding the \"mining score\" of a\n>> transaction is to build a block template, see what feerate each\n>> package is included at. Perhaps at some cutoff, remaining mempool\n>> transactions can be estimated using some heuristic that leans\n>> {overestimating, underestimating} depending on the situation.\n>>\n>> Mining score seems to be relevant in multiple places: Murch and I\n>> recently [found][3] that it would be very important in\n>> \"ancestor-aware\" funding of transactions (the wallet doesn't\n>> incorporate ancestor fees when using unconfirmed transactions in coin\n>> selection, which is a bug we want to fix).\n>>\n>> In general, it would be nice to know the exact mining priority of\n>> one's unconfirmed transaction is.  I can think of a few block/mempool\n>> explorers who might want to display this information for users.\n>>\n>> ### RBF Improvement Proposals\n>>\n>> After speaking to quite a few people, here are some suggestions\n>> for improvements that I have heard:\n>>\n>> * The ancestor score of the replacement must be {5, 10, N}% higher\n>>   than that of every original transaction.\n>>\n>> * The ancestor score of the replacement must be 1sat/vB higher than\n>>   that of every original transaction.\n>>\n>> * If the original transaction is in the top {0.75MvB, 1MvB} of the\n>>   mempool, apply the current rules (absolute fees must increase and\n>> pay for the replacement transaction's new bandwidth). Otherwise, use a\n>> feerate-only rule.\n>>\n>> * If fees don't increase, the size of the replacement transaction must\n>>   decrease by at least N%.\n>>\n>> * Rate-limit how many replacements we allow per prevout.\n>>\n>> * Rate-limit transaction validation in general, per peer.\n>>\n>> Perhaps some others on the mailing list can chime in to throw other\n>> ideas into the ring and/or combine some of these rules into a sensible\n>> policy.\n>>\n>> #### Replace by Feerate Only\n>>\n>> I don't think there's going to be a single-line feerate-based\n>> rule that can incorporate everything we need.\n>> On one hand, a feerate-only approach helps eliminate the issues\n>> associated with Rule #3. On the other hand, I believe the main concern\n>> with a feerate-only approach is how to rate limit replacements. We\n>> don't want to enable an attack such as:\n>>\n>> 1. Attacker broadcasts large, low-feerate transaction, and attaches a\n>> chain of descendants.\n>>\n>> 2. The attacker replaces the transaction with a smaller but higher\n>> feerate transaction, attaching a new chain of descendants.\n>>\n>> 3. Repeat 1000 times.\n>>\n>> #### Fees in Next Block and Feerate for the Rest of the Mempool\n>>\n>> Perhaps we can look at replacements like this:\n>>\n>> 1. Calculate the directly conflicting transactions and, with their\n>> descendants, the original transactions. Check signaling. Limit the\n>> total volume (e.g. can't be more than 100 total or 1MvB or something).\n>>\n>> 2. Find which original transactions would be in the next ~1 block. The\n>> replacement must pay at least this amount + X% in absolute fees. This\n>> guarantees that the fees of the next block doesn't decrease.\n>>\n>> 3. Find which transactions would be left in the mempool after that ~1\n>> block. The replacement's feerate must be Y% higher than the maximum\n>> mining score of these transactions. This guarantees that you now have\n>> only *better* candidates in your after-this-block mempool than you did\n>> before, even if the size and fees the transactions decrease.\n>>\n>> 4. Now you have two numbers: a minimum absolute fee amount and a\n>> minimum feerate. Check to see if the replacement(s) meet these\n>> minimums. Also, a wallet would be able to ask the node \"What fee and\n>> feerate would I need to put on a transaction replacing this?\" and use\n>> this information to fund a replacement transaction, without needing to\n>> guess or overshoot.\n>>\n>> Obviously, there are some magic numbers missing here. X and Y are\n>> TBD constants to ensure we have some kind of rate limiting for the\n>> number of replacements allowed using some set of fees.\n>>\n>> What should they be? We can do some arithmetic to see what happens if\n>> you start with the biggest/lowest feerate transaction and do a bunch\n>> of replacements. Maybe we end up with values that are high enough to\n>> prevent abuse and make sense for applications/users that do RBF.\n>>\n>> ### Mempool Changes Need for Implementation\n>>\n>> As described in the mining score section above,\n>> we may want additional tooling to more accurately assess\n>> the economic gain of replacing transactions in our mempool.\n>>\n>> A few options have been discussed:\n>>\n>> * Calculate block templates on the fly when we need to consider a\n>>   replacement. However, since replacements are [quite common][11]\n>>   and the information might be useful for other things as well,\n>>   it may be worth it to cache a block template.\n>>\n>> * Keep a persistent block template so that we know what transactions\n>>   we would put in the next block. We need to remember the feerate\n>> at which each transaction was included in the template, because an\n>> ancestor package may be included in the same block template in\n>> multiple subsets. Transactions included earlier alter the ancestor\n>> feerate of the remaining transactions in the package. We also need\n>> to keep track of the new feerates of transactions left over.\n>>\n>> * Divide the mempool into two layers, \"high feerate\" and \"low\n>>   feerate.\" The high feerate layer contains ~1 block of packages with\n>> the highest ancestor feerates, and the low feerate layer contains\n>> everything else. At the edge of a block, we have a Knapsacky problem\n>> where the next highest ancestor feerate package might not fit, so we\n>> would probably want the high feerate layer ~2MvB or something to avoid\n>> underestimating the fees.\n>>\n>> ## Acknowledgements\n>>\n>> Thank you to everyone whose RBF-related suggestions, grievances,\n>> criticisms and ideas were incorporated in this document:\n>> Andrew Chow, Matt Corallo, Suhas Daftuar, Christian Decker,\n>> Mark Erhardt, Lloyd Fournier, Lisa Neigut, John Newbery,\n>> Antoine Poinsot, Antoine Riard, Larry Ruane,\n>> S3RK and Bastien Teinturier.\n>>\n>> Thanks for reading!\n>>\n>> Best,\n>> Gloria\n>>\n>> [1]:\n>> https://github.com/bitcoin/bitcoin/blob/master/doc/policy/mempool-replacements.md\n>> [2]: https://github.com/bitcoin/bitcoin/pull/23121#issuecomment-929475999\n>> [3]:\n>> https://github.com/Xekyo/bitcoin/commit/d754b0242ec69d42c570418aebf9c1335af0b8ea\n>> [4]: https://github.com/bitcoindevkit/bdk/issues/144\n>> [5]: https://github.com/bitcoindevkit/bdk/issues/414\n>> [6]:\n>> https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-September/019464.html\n>> [7]:\n>> https://gist.github.com/glozow/dc4e9d5c5b14ade7cdfac40f43adb18a#new-unconfirmed-inputs-rule-2\n>> [8]: https://github.com/bitcoin/bitcoin/pull/23121#discussion_r777131366\n>> [9]: https://github.com/bitcoin/bitcoin/pull/22290#issuecomment-865887922\n>> [10]:\n>> https://gist.github.com/Xekyo/5cb413fe9f26dbce57abfd344ebbfaf2#file-candidate-set-based-block-building-md\n>> [11]:\n>> https://github.com/bitcoin/bitcoin/pull/22539#issuecomment-885763670\n>> [12]: https://github.com/bitcoin/bitcoin/pull/24007\n>> [13]:\n>> https://github.com/bitcoin/bitcoin/blob/1a369f006fd0bec373b95001ed84b480e852f191/src/wallet/feebumper.cpp#L114\n>> [14]:\n>> https://github.com/bitcoin/bitcoin/blob/cf5bb048e80d4cde8828787b266b7f5f2e3b6d7b/src/node/miner.cpp#L310-L320\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220131/bab2313a/attachment-0001.html>"
            }
        ],
        "thread_summary": {
            "title": "Improving RBF Policy",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Bastien TEINTURIER",
                "Jeremy",
                "Gloria Zhao",
                "Antoine Riard"
            ],
            "messages_count": 4,
            "total_messages_chars_count": 89260
        }
    },
    {
        "title": "[bitcoin-dev] Improving RBF policy",
        "thread_messages": [
            {
                "author": "Bram Cohen",
                "date": "2022-01-31T22:54:10",
                "message_text_only": "Gloria Zhao wrote:\n\n>\n> This post discusses limitations of current Bitcoin Core RBF policy and\n> attempts to start a conversation about how we can improve it,\n> summarizing some ideas that have been discussed. Please reply if you\n> have any new input on issues to be solved and ideas for improvement!\n>\n\nIs it still verboten to acknowledge that RBF is normal behavior and\ndisallowing it is the feature, and that feature is mostly there to appease\nsome people's delusions that zeroconf is a thing? It seems a bit overdue to\ndisrespect the RBF flag in the direction of always assuming it's on.\n\n\n> - **Incentive Compatibility**: Ensure that our RBF policy would not\n>   accept replacement transactions which would decrease fee profits\n>   of a miner. In general, if our mempool policy deviates from what is\n> economically rational, it's likely that the transactions in our\n> mempool will not match the ones in miners' mempools, making our\n> fee estimation, compact block relay, and other mempool-dependent\n> functions unreliable. Incentive-incompatible policy may also\n> encourage transaction submission through routes other than the p2p\n> network, harming censorship-resistance and privacy of Bitcoin payments.\n>\n\nThere are two different common regimes which result in different\nincentivized behavior. One of them is that there's more than a block's\nbacklog in the mempool in which case between two conflicting transactions\nthe one with the higher fee rate should win. In the other case where there\nisn't a whole block's worth of transactions the one with higher total value\nshould win. It would be nice to have consolidated logic which handles both,\nit seems the issue has to do with the slope of the supply/demand curve\nwhich in the first case is gentle enough to keep the one transaction from\nhitting the rate but in the second one is basically infinite.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220131/0d66162d/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Improving RBF policy",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Bram Cohen"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2039
        }
    },
    {
        "title": "[bitcoin-dev] non-default ports for automatic connections in Bitcoin P2P network",
        "thread_messages": [
            {
                "author": "Prayank",
                "date": "2022-01-29T22:02:24",
                "message_text_only": "## Using non-default ports for automatic connections in Bitcoin P2P network\n\n\nISPs can block default port 8333 used by Bitcoin nodes. One example:\nhttps://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-September/010798.html\n\nWhile it would still be possible for crawlers and scanners to know about bitcoin nodes listening on non-default ports using other methods, it can be helpful in lot of countries that use basic things to block: domain, port etc.\n\nIn October 2021 a [pull request][1] was merged in Bitcoin Core in which lot of contributors\nagreed to allow non default ports for automatic connections. It did not implement everything,\nwas limited to discussing the concept and allow AddrMan to support multiple ports per IP.\n\nIt was followed by another [pull request][2] in November 2021 which is still open and makes most\nof the changes required for non-default ports to work with automatic connections.\n\nI could not find any major issues with the changes however had some nits including a discussion on\nmailing list which was even requested by a few other reviewers.\n\n\n===Things that I found during my review, research and testing===\n\n1.One user had posted about issues with default port 8333 on [bitcointalk][3] in July 2010. VMWare server\nalso used port 8333 so an option was requested to change port. This option was added in [May 2011][4] by Gavin Andresen. Gavin has discussed this option and related issues in detail with others on [bitcointalk][5].\n\n2.I tried running signet for 1 hour v22.0 and 1 hour PR branch with debug=net. v22.0 had only 38333 port with different IPs in debug.log for connections. PR branch had 2 feeler connections with non-default ports 38331 and 13833.\n\nNote: Default ports used in Bitcoin Core are 8333(mainnet), 18333(testnet), 18444(regtest) and 38333(signet)\n\n3.Wrote a [PowerShell script][6] and tested it on v22.0 and PR branch which bans all peers every 100 seconds using default port. It works as expected and I could see one peer using port 3111 on signet.\n\n4.I am not sure about the 'bad ports' list in Bitcoin Core added in PR #23542\n\n\n8333 in leet becomes 'beee' in plain text. Not sure if this was considered by Satoshi to hardcode 8333 for Bitcoin.\n\n\n\u00a0 [1]: https://github.com/bitcoin/bitcoin/pull/23306\n\u00a0 [2]: https://github.com/bitcoin/bitcoin/pull/23542\n\u00a0 [3]: https://bitcointalk.org/index.php?topic=322.0\n\u00a0 [4]: https://github.com/bitcoin/bitcoin/pull/221\n\u00a0 [5]: https://bitcointalk.org/index.php?topic=589.0\n\u00a0 [6]: https://github.com/prayank23/bitcoin-ps-scripts/blob/main/Scripts/Node/ban_default_peers.ps1\n\n-- \nPrayank\n\nA3B1 E430 2298 178F\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20220129/472360b4/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "non-default ports for automatic connections in Bitcoin P2P network",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Prayank"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2789
        }
    }
]