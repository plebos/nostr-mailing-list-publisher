[
    {
        "title": "[bitcoin-dev] Implementing Covenants with OP_CHECKSIGFROMSTACKVERIFY",
        "thread_messages": [
            {
                "author": "Russell O'Connor",
                "date": "2016-11-02T17:30:12",
                "message_text_only": "Hi all,\n\nIt is possible to implement covenants using two script extensions: OP_CAT\nand OP_CHECKSIGFROMSTACKVERIFY.  Both of these op codes are already\navailable in the Elements Alpha sidechain, so it is possible to construct\ncovenants in Elements Alpha today.  I have detailed how the construction\nworks in a blog post at <\nhttps://blockstream.com/2016/11/02/covenants-in-elements-alpha.html>.  As\nan example, I've constructed scripts for the Moeser-Eyal-Sirer vault.\n\nI'm interested in collecting and implementing other useful covenants, so if\npeople have ideas, please post them.\n\nIf there are any questions, I'd be happy to answer.\n\n-- \nRussell O'Connor\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161102/7ccba370/attachment.html>"
            },
            {
                "author": "Johnson Lau",
                "date": "2016-11-03T03:35:02",
                "message_text_only": "Interesting. I have implemented OP_CHECKSIGFROMSTACKVERIFY in a different way from the Elements. Instead of hashing the data on stack, I directly put the 32 byte hash to the stack. This should be more flexible as not every system are using double-SHA256\n\nhttps://github.com/jl2012/bitcoin/commits/mast_v3_master <https://github.com/jl2012/bitcoin/commits/mast_v3_master>\n\n\n> On 3 Nov 2016, at 01:30, Russell O'Connor via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> \n> Hi all,\n> \n> It is possible to implement covenants using two script extensions: OP_CAT and OP_CHECKSIGFROMSTACKVERIFY.  Both of these op codes are already available in the Elements Alpha sidechain, so it is possible to construct covenants in Elements Alpha today.  I have detailed how the construction works in a blog post at <https://blockstream.com/2016/11/02/covenants-in-elements-alpha.html <https://blockstream.com/2016/11/02/covenants-in-elements-alpha.html>>.  As an example, I've constructed scripts for the Moeser-Eyal-Sirer vault.\n> \n> I'm interested in collecting and implementing other useful covenants, so if people have ideas, please post them.\n> \n> If there are any questions, I'd be happy to answer.  \n> \n> -- \n> Russell O'Connor\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org <mailto:bitcoin-dev at lists.linuxfoundation.org>\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161103/1ad19231/attachment.html>"
            },
            {
                "author": "Ryan Grant",
                "date": "2016-11-03T17:42:22",
                "message_text_only": "On Wed, Nov 2, 2016 at 1:30 PM, Russell O'Connor via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> I'm interested in collecting and implementing other useful covenants, so if\n> people have ideas, please post them.\n\nI know of a good business case that could benefit from two nice\nfeatures.\n\nAs an example:\n\n  Two parties have initiated a transaction designed with\n  counterparty-minimization in mind.  It uses MAST and has many\n  different payout distributions.  Both parties enter expecting to\n  gain from the transaction, but both take on risk due to external\n  factors.\n\n  Because of the risks involved, there exist possible times when one\n  party may wish to renegotiate the exit distribution, and might\n  threaten to block any exit.  Or, either party might get hit by the\n  proverbial bus.  During such times, the other party's eventual exit\n  is protected by using a multisig which includes an oracle\n  determination.  The oracle's trusted role is bound to this example's\n  unstated \"external factors\" in a very limited sense, and does not\n  include broader concerns, such as determining whether a party to the\n  transaction is of \"sound mind and body\".\n\n  The singular term \"oracle\" hides a set of entities participating in\n  m-of-n multisig, which we can name the \"oracle-set\".\n\n  Transaction terms include a CLTV lasting perhaps several years,\n  applied whenever the exit requires the oracle-set's signatures.\n\n  Both parties may mutually select and sign one of the payout\n  distributions, to exit early.\n\nThe example, as I've described it so far, doesn't need anything other\nthan MAST.  It isn't a covenant, because it doesn't impose any forward\nrestrictions when satisfied; despite the contractual complications of\nexecuting the oracle-set's signatures.  As covenant features are\nconsidered across updated instances of what is otherwise a singular\ntransaction, it's important that none carry into the final payout\ndistribution, and that this is easy to verify.\n\nFeatures desired:\n\n  - One party would like to unilaterally sell their participation in\n    the transaction, to a previously unknown recipient, before the\n    CLTV becomes valid.\n\n    The other originating party's stored MAST should either continue\n    to function, or require minimal replacements that can be\n    deterministically applied using data visible on the blockchain.\n    It should not be necessary to ask permission from - or coordinate\n    online communication with - the other originating party.\n\n    (This can also be viewed as a key rotation problem for any\n    long-lasting multisig transaction.)\n\n  - Both parties would like to mutually revoke rouge oracle-entities\n    from the oracle-set, without exposing each other to any possible\n    renegotiation of other terms.\n\nNote that these features affect each other, since if one party sells\ntheir participation after any oracle-entities have been revoked, then\nthe revocations should not reset, but rather remain in effect, until a\nproper payout executes the final agreement in the contract.\n\nOf course, if there's a way to achieve these features with less risk\nthan evaluating covenant logic, I would very much like to hear how to\ndo so."
            },
            {
                "author": "Russell O'Connor",
                "date": "2016-11-03T04:19:48",
                "message_text_only": "Right.  There are minor trade-offs to be made with regards to that design\npoint of OP_CHECKSIGFROMSTACKVERIFY.  Fortunately this covenant\nconstruction isn't sensitive to that choice and can be made to work with\neither implementation of OP_CHECKSIGFROMSTACKVERIFY.\n\nOn Wed, Nov 2, 2016 at 11:35 PM, Johnson Lau <jl2012 at xbt.hk> wrote:\n\n> Interesting. I have implemented OP_CHECKSIGFROMSTACKVERIFY in a different\n> way from the Elements. Instead of hashing the data on stack, I directly put\n> the 32 byte hash to the stack. This should be more flexible as not every\n> system are using double-SHA256\n>\n> https://github.com/jl2012/bitcoin/commits/mast_v3_master\n>\n>\n> On 3 Nov 2016, at 01:30, Russell O'Connor via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Hi all,\n>\n> It is possible to implement covenants using two script extensions: OP_CAT\n> and OP_CHECKSIGFROMSTACKVERIFY.  Both of these op codes are already\n> available in the Elements Alpha sidechain, so it is possible to construct\n> covenants in Elements Alpha today.  I have detailed how the construction\n> works in a blog post at <https://blockstream.com/2016/\n> 11/02/covenants-in-elements-alpha.html>.  As an example, I've constructed\n> scripts for the Moeser-Eyal-Sirer vault.\n>\n> I'm interested in collecting and implementing other useful covenants, so\n> if people have ideas, please post them.\n>\n> If there are any questions, I'd be happy to answer.\n>\n> --\n> Russell O'Connor\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161103/8e963659/attachment.html>"
            },
            {
                "author": "Daniel Robinson",
                "date": "2016-11-03T07:37:29",
                "message_text_only": "Really cool!\n\nHow about \"poison transactions,\" the other covenants use case proposed by\nM\u00f6ser, Eyal, and Sirer? (I think OP_CHECKSIGFROMSTACKVERIFY will also make\nit easier to check fraud proofs, the other prerequisite for poison\ntransactions.)\n\nSeems a little wasteful to do those two \"unnecessary\" signature checks, and\nto have to construct the entire transaction data structure, just to verify\na single output in the transaction. Any plans to add more flexible\nintrospection opcodes to Elements, such as OP_CHECKOUTPUTVERIFY?\n\nReally minor nit: \"Notice that we have appended 0x83 to the end of the\ntransaction data\"\u2014should this say \"to the end of the signature\"?\n\nOn Thu, Nov 3, 2016 at 12:28 AM Russell O'Connor via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\nRight.  There are minor trade-offs to be made with regards to that design\npoint of OP_CHECKSIGFROMSTACKVERIFY.  Fortunately this covenant\nconstruction isn't sensitive to that choice and can be made to work with\neither implementation of OP_CHECKSIGFROMSTACKVERIFY.\n\nOn Wed, Nov 2, 2016 at 11:35 PM, Johnson Lau <jl2012 at xbt.hk> wrote:\n\nInteresting. I have implemented OP_CHECKSIGFROMSTACKVERIFY in a different\nway from the Elements. Instead of hashing the data on stack, I directly put\nthe 32 byte hash to the stack. This should be more flexible as not every\nsystem are using double-SHA256\n\nhttps://github.com/jl2012/bitcoin/commits/mast_v3_master\n\n\nOn 3 Nov 2016, at 01:30, Russell O'Connor via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\nHi all,\n\nIt is possible to implement covenants using two script extensions: OP_CAT\nand OP_CHECKSIGFROMSTACKVERIFY.  Both of these op codes are already\navailable in the Elements Alpha sidechain, so it is possible to construct\ncovenants in Elements Alpha today.  I have detailed how the construction\nworks in a blog post at <\nhttps://blockstream.com/2016/11/02/covenants-in-elements-alpha.html>.  As\nan example, I've constructed scripts for the Moeser-Eyal-Sirer vault.\n\nI'm interested in collecting and implementing other useful covenants, so if\npeople have ideas, please post them.\n\nIf there are any questions, I'd be happy to answer.\n\n-- \nRussell O'Connor\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n_______________________________________________\nbitcoin-dev mailing list\nbitcoin-dev at lists.linuxfoundation.org\nhttps://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161103/32c6918b/attachment-0001.html>"
            },
            {
                "author": "Russell O'Connor",
                "date": "2016-11-03T20:02:33",
                "message_text_only": "On Thu, Nov 3, 2016 at 3:37 AM, Daniel Robinson <danrobinson010 at gmail.com>\nwrote:\n\n> Really cool!\n>\n> How about \"poison transactions,\" the other covenants use case proposed by\n> M\u00f6ser, Eyal, and Sirer? (I think OP_CHECKSIGFROMSTACKVERIFY will also make\n> it easier to check fraud proofs, the other prerequisite for poison\n> transactions.)\n>\n\nI admit I didn't study their poison transactions very carefully.  It seemed\nspecific to Bitcoin-NG.\n\n\n> Seems a little wasteful to do those two \"unnecessary\" signature checks,\n> and to have to construct the entire transaction data structure, just to\n> verify a single output in the transaction. Any plans to add more flexible\n> introspection opcodes to Elements, such as OP_CHECKOUTPUTVERIFY?\n>\n\nI used to be hesitant to the idea of adding transaction introspection\noperations, because the script design seemed to be deliberately avoiding\ndoing that.  One of the big takeaways from this work, for me at least, is\nthat since the transaction data is so easily recoverable anyways, adding\ntransaction introspection operations isn't really going to provide any more\npower to script; it will just save everyone a bunch of work.  There are no\nspecific plans to put transaction introspection opcodes into Elements at\nthis moment, but I feel that the door for that possibility is wide open now.\n\nReally minor nit: \"Notice that we have appended 0x83 to the end of the\n> transaction data\"\u2014should this say \"to the end of the signature\"?\n>\n\nProbably should reed \"Notice that we have appended 0x83000000 to the end of\nthe transaction data\".  I'll make an update.\n\n\n>\n> On Thu, Nov 3, 2016 at 12:28 AM Russell O'Connor via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Right.  There are minor trade-offs to be made with regards to that design\n> point of OP_CHECKSIGFROMSTACKVERIFY.  Fortunately this covenant\n> construction isn't sensitive to that choice and can be made to work with\n> either implementation of OP_CHECKSIGFROMSTACKVERIFY.\n>\n> On Wed, Nov 2, 2016 at 11:35 PM, Johnson Lau <jl2012 at xbt.hk> wrote:\n>\n> Interesting. I have implemented OP_CHECKSIGFROMSTACKVERIFY in a different\n> way from the Elements. Instead of hashing the data on stack, I directly put\n> the 32 byte hash to the stack. This should be more flexible as not every\n> system are using double-SHA256\n>\n> https://github.com/jl2012/bitcoin/commits/mast_v3_master\n>\n>\n> On 3 Nov 2016, at 01:30, Russell O'Connor via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Hi all,\n>\n> It is possible to implement covenants using two script extensions: OP_CAT\n> and OP_CHECKSIGFROMSTACKVERIFY.  Both of these op codes are already\n> available in the Elements Alpha sidechain, so it is possible to construct\n> covenants in Elements Alpha today.  I have detailed how the construction\n> works in a blog post at <https://blockstream.com/2016/\n> 11/02/covenants-in-elements-alpha.html>.  As an example, I've constructed\n> scripts for the Moeser-Eyal-Sirer vault.\n>\n> I'm interested in collecting and implementing other useful covenants, so\n> if people have ideas, please post them.\n>\n> If there are any questions, I'd be happy to answer.\n>\n> --\n> Russell O'Connor\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161103/f9640dd7/attachment.html>"
            },
            {
                "author": "Tim Ruffing",
                "date": "2016-11-04T14:35:51",
                "message_text_only": "Not a covenant but interesting nevertheless: _One_ of OP_CAT and\nOP_CHECKSIGFROMSTACKVERIFY alone is enough to implement \"opt-in miner\ntakes double-spend\" [1]:\n\nYou can create an output, which is spendable by everybody if you ever\ndouble-spend the output with two different transactions. Then the next\nminer will probably take your money (double-spending against your two\nor more contradicting transactions again).\n\nIf you spend such an output, then the recipient may be willing to\naccept a zero-conf transaction, because he knows that you'll lose the\nmoney when you attempt double-spending (unless you are the lucky\nminer). See the discussion in [1] for details. \n\nThe implementation using OP_CHECKSIGFROMSTACKVERIFY is straight-\nforward. You add a case to the script which allows spending if two\nvalid signatures on different message under the public key of the\noutput are given.\n\nWhat is less known I think:\nThe same functionality can be achieved in a simpler way just using\nOP_CAT, because it's possible to turn Bitcoin's ECDSA to an \"opt-in\none-time signature scheme\". With OP_CAT, you can create an output that\nis only spendable using a signature (r,s) with a specific already fixed\nfirst part r=x_coord(kG). Basically, the creator of this output commits\non r (and k) already when creating the output. Now, signing two\ndifferent transaction with the same r allows everybody to extract the\nsecret key from the two signatures.\n\nThe drawbacks of the implementation with OP_CAT is that\u00a0it's not\npossible to make a distinction between legitimate or illegitimate\ndouble-spends (yet to be defined) but just every double-spend is\npenalized. Also, it's somewhat hackish and the signer must store k (or\ncreate it deterministically but that's a good idea anyway).\n\n[1] https://www.mail-archive.com/bitcoin-development@lists.sourceforge.net/msg07122.html\n\nBest,\nTim\n\nOn Thu, 2016-11-03 at 07:37 +0000, Daniel Robinson via bitcoin-dev\nwrote:\n> Really cool!\n> \n> How about \"poison transactions,\" the other covenants use case\n> proposed by M\u00f6ser, Eyal, and Sirer? (I think\n> OP_CHECKSIGFROMSTACKVERIFY will also make it easier to check fraud\n> proofs, the other prerequisite for poison transactions.)\n> \n> Seems a little wasteful to do those two \"unnecessary\" signature\n> checks, and to have to construct the entire transaction data\n> structure, just to verify a single output in the transaction. Any\n> plans to add more flexible introspection opcodes to Elements, such as\n> OP_CHECKOUTPUTVERIFY?\n> \n> Really minor nit: \"Notice that we have appended 0x83 to the end of\n> the transaction data\"\u2014should this say \"to the end of the signature\"?\n> \n> On Thu, Nov 3, 2016 at 12:28 AM Russell O'Connor via bitcoin-dev <bit\n> coin-dev at lists.linuxfoundation.org> wrote:\n> > Right.\u00a0 There are minor trade-offs to be made with regards to that\n> > design point of OP_CHECKSIGFROMSTACKVERIFY.\u00a0 Fortunately this\n> > covenant construction isn't sensitive to that choice and can be\n> > made to work with either implementation of\n> > OP_CHECKSIGFROMSTACKVERIFY.\n> > \n> > On Wed, Nov 2, 2016 at 11:35 PM, Johnson Lau <jl2012 at xbt.hk> wrote:\n> > > Interesting. I have implemented\u00a0OP_CHECKSIGFROMSTACKVERIFY in a\n> > > different way from the Elements. Instead of hashing the data on\n> > > stack, I directly put the 32 byte hash to the stack. This should\n> > > be more flexible as not every system are using double-SHA256\n> > > \n> > > https://github.com/jl2012/bitcoin/commits/mast_v3_master\n> > > \n> > > \n> > > \n> > > > On 3 Nov 2016, at 01:30, Russell O'Connor via bitcoin-dev <bitc\n> > > > oin-dev at lists.linuxfoundation.org> wrote:\n> > > > \n> > > > Hi all,\n> > > > \n> > > > It is possible to implement covenants using two script\n> > > > extensions: OP_CAT and OP_CHECKSIGFROMSTACKVERIFY.\u00a0 Both of\n> > > > these op codes are already available in the Elements Alpha\n> > > > sidechain, so it is possible to construct covenants in Elements\n> > > > Alpha today.\u00a0 I have detailed how the construction works in a\n> > > > blog post at <https://blockstream.com/2016/11/02/covenants-in-e\n> > > > lements-alpha.html>.\u00a0 As an example, I've constructed scripts\n> > > > for the Moeser-Eyal-Sirer vault.\n> > > > \n> > > > I'm interested in collecting and implementing other useful\n> > > > covenants, so if people have ideas, please post them.\n> > > > \n> > > > If there are any questions, I'd be happy to answer.\u00a0\u00a0\n> > > > \n> > > > --\u00a0\n> > > > Russell O'Connor\n> > > > _______________________________________________\n> > > > bitcoin-dev mailing list\n> > > > bitcoin-dev at lists.linuxfoundation.org\n> > > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> > \n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> > \n> \n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Jeremy",
                "date": "2016-11-07T19:30:26",
                "message_text_only": "I think\n\u200bthe following implementation may be advantageous. It uses the same number\nof opcodes, without OP_CAT.\n\nAvoiding use of OP_CAT is still desirable as I think it will be difficult\nto agree on semantics for OP_CAT (given necessary measures to prevent\nmemory abuse) than for OP_LEFT. Another option I would be in support of\nwould be to have signature flags apply to OP_CHECKSIGFROMSTACK and all\nOP_CHECKSIG flags be ignored if they aren't meaningful...\n\n\u200b\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n*<signature; SIGHASH_ALL><signatureTxnData>1. <pubkey>\nOP_DUP3<pubkey><signature;\nSIGHASH_ALL><signatureTxnData><pubkey><signature;\nSIGHASH_ALL><signatureTxnData>2.\nOP_CHECKSIGVERIFY<signatureTxnData><pubkey><signature;\nSIGHASH_ALL><signatureTxnData>3. OP_SHA256 OP_ROT OP_SIZE OP_SUB1\nOP_LEFT<signature><sha256(signatureTxnData)><pubkey><signatureTxnData>4.\nOP_SWAP OP_ROT OP_CHECKSIGFROMSTACK\u200bVERIFY\u200b (with same \u200bargument order\u200b)\u200b*\n\n\n\n--\n@JeremyRubin <https://twitter.com/JeremyRubin>\n<https://twitter.com/JeremyRubin>\n\nOn Fri, Nov 4, 2016 at 7:35 AM, Tim Ruffing via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Not a covenant but interesting nevertheless: _One_ of OP_CAT and\n> OP_CHECKSIGFROMSTACKVERIFY alone is enough to implement \"opt-in miner\n> takes double-spend\" [1]:\n>\n> You can create an output, which is spendable by everybody if you ever\n> double-spend the output with two different transactions. Then the next\n> miner will probably take your money (double-spending against your two\n> or more contradicting transactions again).\n>\n> If you spend such an output, then the recipient may be willing to\n> accept a zero-conf transaction, because he knows that you'll lose the\n> money when you attempt double-spending (unless you are the lucky\n> miner). See the discussion in [1] for details.\n>\n> The implementation using OP_CHECKSIGFROMSTACKVERIFY is straight-\n> forward. You add a case to the script which allows spending if two\n> valid signatures on different message under the public key of the\n> output are given.\n>\n> What is less known I think:\n> The same functionality can be achieved in a simpler way just using\n> OP_CAT, because it's possible to turn Bitcoin's ECDSA to an \"opt-in\n> one-time signature scheme\". With OP_CAT, you can create an output that\n> is only spendable using a signature (r,s) with a specific already fixed\n> first part r=x_coord(kG). Basically, the creator of this output commits\n> on r (and k) already when creating the output. Now, signing two\n> different transaction with the same r allows everybody to extract the\n> secret key from the two signatures.\n>\n> The drawbacks of the implementation with OP_CAT is that it's not\n> possible to make a distinction between legitimate or illegitimate\n> double-spends (yet to be defined) but just every double-spend is\n> penalized. Also, it's somewhat hackish and the signer must store k (or\n> create it deterministically but that's a good idea anyway).\n>\n> [1] https://www.mail-archive.com/bitcoin-development@lists.\n> sourceforge.net/msg07122.html\n>\n> Best,\n> Tim\n>\n> On Thu, 2016-11-03 at 07:37 +0000, Daniel Robinson via bitcoin-dev\n> wrote:\n> > Really cool!\n> >\n> > How about \"poison transactions,\" the other covenants use case\n> > proposed by M\u00f6ser, Eyal, and Sirer? (I think\n> > OP_CHECKSIGFROMSTACKVERIFY will also make it easier to check fraud\n> > proofs, the other prerequisite for poison transactions.)\n> >\n> > Seems a little wasteful to do those two \"unnecessary\" signature\n> > checks, and to have to construct the entire transaction data\n> > structure, just to verify a single output in the transaction. Any\n> > plans to add more flexible introspection opcodes to Elements, such as\n> > OP_CHECKOUTPUTVERIFY?\n> >\n> > Really minor nit: \"Notice that we have appended 0x83 to the end of\n> > the transaction data\"\u2014should this say \"to the end of the signature\"?\n> >\n> > On Thu, Nov 3, 2016 at 12:28 AM Russell O'Connor via bitcoin-dev <bit\n> > coin-dev at lists.linuxfoundation.org> wrote:\n> > > Right.  There are minor trade-offs to be made with regards to that\n> > > design point of OP_CHECKSIGFROMSTACKVERIFY.  Fortunately this\n> > > covenant construction isn't sensitive to that choice and can be\n> > > made to work with either implementation of\n> > > OP_CHECKSIGFROMSTACKVERIFY.\n> > >\n> > > On Wed, Nov 2, 2016 at 11:35 PM, Johnson Lau <jl2012 at xbt.hk> wrote:\n> > > > Interesting. I have implemented OP_CHECKSIGFROMSTACKVERIFY in a\n> > > > different way from the Elements. Instead of hashing the data on\n> > > > stack, I directly put the 32 byte hash to the stack. This should\n> > > > be more flexible as not every system are using double-SHA256\n> > > >\n> > > > https://github.com/jl2012/bitcoin/commits/mast_v3_master\n> > > >\n> > > >\n> > > >\n> > > > > On 3 Nov 2016, at 01:30, Russell O'Connor via bitcoin-dev <bitc\n> > > > > oin-dev at lists.linuxfoundation.org> wrote:\n> > > > >\n> > > > > Hi all,\n> > > > >\n> > > > > It is possible to implement covenants using two script\n> > > > > extensions: OP_CAT and OP_CHECKSIGFROMSTACKVERIFY.  Both of\n> > > > > these op codes are already available in the Elements Alpha\n> > > > > sidechain, so it is possible to construct covenants in Elements\n> > > > > Alpha today.  I have detailed how the construction works in a\n> > > > > blog post at <https://blockstream.com/2016/11/02/covenants-in-e\n> > > > > lements-alpha.html>.  As an example, I've constructed scripts\n> > > > > for the Moeser-Eyal-Sirer vault.\n> > > > >\n> > > > > I'm interested in collecting and implementing other useful\n> > > > > covenants, so if people have ideas, please post them.\n> > > > >\n> > > > > If there are any questions, I'd be happy to answer.\n> > > > >\n> > > > > --\n> > > > > Russell O'Connor\n> > > > > _______________________________________________\n> > > > > bitcoin-dev mailing list\n> > > > > bitcoin-dev at lists.linuxfoundation.org\n> > > > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> > >\n> > > _______________________________________________\n> > > bitcoin-dev mailing list\n> > > bitcoin-dev at lists.linuxfoundation.org\n> > > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> > >\n> >\n> > _______________________________________________\n> > bitcoin-dev mailing list\n> > bitcoin-dev at lists.linuxfoundation.org\n> > https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161107/ead05154/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Implementing Covenants with OP_CHECKSIGFROMSTACKVERIFY",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Ryan Grant",
                "Jeremy",
                "Daniel Robinson",
                "Johnson Lau",
                "Russell O'Connor",
                "Tim Ruffing"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 25806
        }
    },
    {
        "title": "[bitcoin-dev] [BIP Proposal] Buried Deployments",
        "thread_messages": [
            {
                "author": "Suhas Daftuar",
                "date": "2016-11-14T18:17:25",
                "message_text_only": "Hi,\n\nRecently Bitcoin Core merged a simplification to the consensus rules\nsurrounding deployment of BIPs 34, 66, and 65 (\nhttps://github.com/bitcoin/bitcoin/pull/8391), and though the change is a\nminor one, I thought it was worth documenting the rationale in a BIP for\nposterity.\n\nHere's the abstract:\n\nPrior soft forks (BIP 34, BIP 65, and BIP 66) were activated via miner\nsignaling in block version numbers. Now that the chain has long since\npassed the blocks at which those consensus rules have triggered, we can (as\na simplification and optimization) replace the trigger mechanism by caching\nthe block heights at which those consensus rules became enforced.\n\nThe full draft can be found here:\n\nhttps://github.com/sdaftuar/bips/blob/buried-deployments/bip-buried-deployments.mediawiki\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161114/8b1e5b1f/attachment.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-14T18:47:35",
                "message_text_only": "NACK\n\nHorrible precedent (hardcoding rule changes based on the assumption that large forks indicate a catastrophic failure), extremely poor process (already shipped, now the discussion), and not even a material performance optimization (the checks are avoidable once activated until a sufficiently deep reorg deactivates them).\n\ne\n\n> On Nov 14, 2016, at 10:17 AM, Suhas Daftuar via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> Hi,\n> \n> Recently Bitcoin Core merged a simplification to the consensus rules surrounding deployment of BIPs 34, 66, and 65 (https://github.com/bitcoin/bitcoin/pull/8391), and though the change is a minor one, I thought it was worth documenting the rationale in a BIP for posterity.\n> \n> Here's the abstract:\n> \n> Prior soft forks (BIP 34, BIP 65, and BIP 66) were activated via miner signaling in block version numbers. Now that the chain has long since passed the blocks at which those consensus rules have triggered, we can (as a simplification and optimization) replace the trigger mechanism by caching the block heights at which those consensus rules became enforced.\n> \n> The full draft can be found here: \n> \n> https://github.com/sdaftuar/bips/blob/buried-deployments/bip-buried-deployments.mediawiki\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161114/03f1190e/attachment.html>"
            },
            {
                "author": "Suhas Daftuar",
                "date": "2016-11-15T14:42:50",
                "message_text_only": "Just want to clarify two points:\n\nThis change has not yet appeared in any released software (but I assume it\nwill be in the next release, 0.14.0).\n\nI agree that the performance optimization is not the point of this change;\nI can modify the BIP draft to de-emphasize that further (perhaps remove\nmention of it entirely).\n\nOn Mon, Nov 14, 2016 at 1:47 PM, Eric Voskuil <eric at voskuil.org> wrote:\n\n> NACK\n>\n> Horrible precedent (hardcoding rule changes based on the assumption that\n> large forks indicate a catastrophic failure), extremely poor process\n> (already shipped, now the discussion), and not even a material performance\n> optimization (the checks are avoidable once activated until a sufficiently\n> deep reorg deactivates them).\n>\n> e\n>\n> On Nov 14, 2016, at 10:17 AM, Suhas Daftuar via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Hi,\n>\n> Recently Bitcoin Core merged a simplification to the consensus rules\n> surrounding deployment of BIPs 34, 66, and 65 (https://github.com/bitcoin/\n> bitcoin/pull/8391), and though the change is a minor one, I thought it\n> was worth documenting the rationale in a BIP for posterity.\n>\n> Here's the abstract:\n>\n> Prior soft forks (BIP 34, BIP 65, and BIP 66) were activated via miner\n> signaling in block version numbers. Now that the chain has long since\n> passed the blocks at which those consensus rules have triggered, we can (as\n> a simplification and optimization) replace the trigger mechanism by caching\n> the block heights at which those consensus rules became enforced.\n>\n> The full draft can be found here:\n>\n> https://github.com/sdaftuar/bips/blob/buried-deployments/\n> bip-buried-deployments.mediawiki\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161115/7b2641ce/attachment.html>"
            },
            {
                "author": "Btc Drak",
                "date": "2016-11-15T17:45:45",
                "message_text_only": "I think this is already covered in the BIP text:-\n\n\"As of November 2016, the most recent of these changes (BIP 65,\nenforced since December 2015) has nearly 50,000 blocks built on top of\nit. The occurrence of such a reorg that would cause the activating\nblock to be disconnected would raise fundamental concerns about the\nsecurity assumptions of Bitcoin, a far bigger issue than any\nnon-backwards compatible change.\n\nSo while this proposal could theoretically result in a consensus\nsplit, it is extremely unlikely, and in particular any such\ncircumstances would be sufficiently damaging to the Bitcoin network to\ndwarf any concerns about the effects of this proposed change.\"\n\n\nOn Mon, Nov 14, 2016 at 6:47 PM, Eric Voskuil via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> NACK\n>\n> Horrible precedent (hardcoding rule changes based on the assumption that\n> large forks indicate a catastrophic failure), extremely poor process\n> (already shipped, now the discussion), and not even a material performance\n> optimization (the checks are avoidable once activated until a sufficiently\n> deep reorg deactivates them).\n>\n> e\n>\n> On Nov 14, 2016, at 10:17 AM, Suhas Daftuar via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n> Hi,\n>\n> Recently Bitcoin Core merged a simplification to the consensus rules\n> surrounding deployment of BIPs 34, 66, and 65\n> (https://github.com/bitcoin/bitcoin/pull/8391), and though the change is a\n> minor one, I thought it was worth documenting the rationale in a BIP for\n> posterity.\n>\n> Here's the abstract:\n>\n> Prior soft forks (BIP 34, BIP 65, and BIP 66) were activated via miner\n> signaling in block version numbers. Now that the chain has long since passed\n> the blocks at which those consensus rules have triggered, we can (as a\n> simplification and optimization) replace the trigger mechanism by caching\n> the block heights at which those consensus rules became enforced.\n>\n> The full draft can be found here:\n>\n> https://github.com/sdaftuar/bips/blob/buried-deployments/bip-buried-deployments.mediawiki\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-15T22:42:05",
                "message_text_only": "Actually this does nothing to provide justification for this consensus rule change. It is just an attempt to deflect criticism from the fact that it is such a change.\n\ne\n\n> On Nov 15, 2016, at 9:45 AM, Btc Drak <btcdrak at gmail.com> wrote:\n> \n> I think this is already covered in the BIP text:-\n> \n> \"As of November 2016, the most recent of these changes (BIP 65,\n> enforced since December 2015) has nearly 50,000 blocks built on top of\n> it. The occurrence of such a reorg that would cause the activating\n> block to be disconnected would raise fundamental concerns about the\n> security assumptions of Bitcoin, a far bigger issue than any\n> non-backwards compatible change.\n> \n> So while this proposal could theoretically result in a consensus\n> split, it is extremely unlikely, and in particular any such\n> circumstances would be sufficiently damaging to the Bitcoin network to\n> dwarf any concerns about the effects of this proposed change.\"\n> \n> \n> On Mon, Nov 14, 2016 at 6:47 PM, Eric Voskuil via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> NACK\n>> \n>> Horrible precedent (hardcoding rule changes based on the assumption that\n>> large forks indicate a catastrophic failure), extremely poor process\n>> (already shipped, now the discussion), and not even a material performance\n>> optimization (the checks are avoidable once activated until a sufficiently\n>> deep reorg deactivates them).\n>> \n>> e\n>> \n>> On Nov 14, 2016, at 10:17 AM, Suhas Daftuar via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> \n>> Hi,\n>> \n>> Recently Bitcoin Core merged a simplification to the consensus rules\n>> surrounding deployment of BIPs 34, 66, and 65\n>> (https://github.com/bitcoin/bitcoin/pull/8391), and though the change is a\n>> minor one, I thought it was worth documenting the rationale in a BIP for\n>> posterity.\n>> \n>> Here's the abstract:\n>> \n>> Prior soft forks (BIP 34, BIP 65, and BIP 66) were activated via miner\n>> signaling in block version numbers. Now that the chain has long since passed\n>> the blocks at which those consensus rules have triggered, we can (as a\n>> simplification and optimization) replace the trigger mechanism by caching\n>> the block heights at which those consensus rules became enforced.\n>> \n>> The full draft can be found here:\n>> \n>> https://github.com/sdaftuar/bips/blob/buried-deployments/bip-buried-deployments.mediawiki\n>> \n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> \n>> \n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>"
            },
            {
                "author": "Jameson Lopp",
                "date": "2016-11-16T13:29:41",
                "message_text_only": "Since \"buried deployments\" are specifically in reference to historical\nconsensus changes, I think the question is more one of human consensus than\nmachine consensus. Is there any disagreement amongst Bitcoin users that\nBIP34 activated at block 227931, BIP65 activated at block 388381, and BIP66\nactivated at block 363725? Somehow I doubt it.\n\nIt seems to me that this change is merely cementing into place a few\nattributes of the blockchain's history that are not in dispute.\n\n- Jameson\n\nOn Tue, Nov 15, 2016 at 5:42 PM, Eric Voskuil via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Actually this does nothing to provide justification for this consensus\n> rule change. It is just an attempt to deflect criticism from the fact that\n> it is such a change.\n>\n> e\n>\n> > On Nov 15, 2016, at 9:45 AM, Btc Drak <btcdrak at gmail.com> wrote:\n> >\n> > I think this is already covered in the BIP text:-\n> >\n> > \"As of November 2016, the most recent of these changes (BIP 65,\n> > enforced since December 2015) has nearly 50,000 blocks built on top of\n> > it. The occurrence of such a reorg that would cause the activating\n> > block to be disconnected would raise fundamental concerns about the\n> > security assumptions of Bitcoin, a far bigger issue than any\n> > non-backwards compatible change.\n> >\n> > So while this proposal could theoretically result in a consensus\n> > split, it is extremely unlikely, and in particular any such\n> > circumstances would be sufficiently damaging to the Bitcoin network to\n> > dwarf any concerns about the effects of this proposed change.\"\n> >\n> >\n> > On Mon, Nov 14, 2016 at 6:47 PM, Eric Voskuil via bitcoin-dev\n> > <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >> NACK\n> >>\n> >> Horrible precedent (hardcoding rule changes based on the assumption that\n> >> large forks indicate a catastrophic failure), extremely poor process\n> >> (already shipped, now the discussion), and not even a material\n> performance\n> >> optimization (the checks are avoidable once activated until a\n> sufficiently\n> >> deep reorg deactivates them).\n> >>\n> >> e\n> >>\n> >> On Nov 14, 2016, at 10:17 AM, Suhas Daftuar via bitcoin-dev\n> >> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >>\n> >> Hi,\n> >>\n> >> Recently Bitcoin Core merged a simplification to the consensus rules\n> >> surrounding deployment of BIPs 34, 66, and 65\n> >> (https://github.com/bitcoin/bitcoin/pull/8391), and though the change\n> is a\n> >> minor one, I thought it was worth documenting the rationale in a BIP for\n> >> posterity.\n> >>\n> >> Here's the abstract:\n> >>\n> >> Prior soft forks (BIP 34, BIP 65, and BIP 66) were activated via miner\n> >> signaling in block version numbers. Now that the chain has long since\n> passed\n> >> the blocks at which those consensus rules have triggered, we can (as a\n> >> simplification and optimization) replace the trigger mechanism by\n> caching\n> >> the block heights at which those consensus rules became enforced.\n> >>\n> >> The full draft can be found here:\n> >>\n> >> https://github.com/sdaftuar/bips/blob/buried-deployments/\n> bip-buried-deployments.mediawiki\n> >>\n> >> _______________________________________________\n> >> bitcoin-dev mailing list\n> >> bitcoin-dev at lists.linuxfoundation.org\n> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >>\n> >>\n> >> _______________________________________________\n> >> bitcoin-dev mailing list\n> >> bitcoin-dev at lists.linuxfoundation.org\n> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> >>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161116/fbdc0efa/attachment.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-16T13:58:57",
                "message_text_only": "This sort of statement represents one consequence of the aforementioned bad precedent.\n\nAre checkpoints good now? Are hard forks okay now?\n\nWhat is the maximum depth of a reorg allowed by this non-machine consensus?\n\nShouldn't we just define a max depth so that all cruft deeper than that can just be discarded on a regular basis?\n\nWhy are there activation heights defined by this hard fork if it's not possible to reorg back to them?\n\nThe \"BIP\" is neither a Proposal (it's been decided, just documenting for posterity), nor an Improvement (there is no actual benefit, just some tidying up in the notoriously obtuse satoshi code base), nor Bitcoin (a hard fork defines an alt coin, so from Aug 4 forward it has been CoreCoin).\n\ne\n\n> On Nov 16, 2016, at 5:29 AM, Jameson Lopp <jameson.lopp at gmail.com> wrote:\n> \n> Since \"buried deployments\" are specifically in reference to historical consensus changes, I think the question is more one of human consensus than machine consensus. Is there any disagreement amongst Bitcoin users that BIP34 activated at block 227931, BIP65 activated at block 388381, and BIP66 activated at block 363725? Somehow I doubt it.\n> \n> It seems to me that this change is merely cementing into place a few attributes of the blockchain's history that are not in dispute.\n> \n> - Jameson\n> \n>> On Tue, Nov 15, 2016 at 5:42 PM, Eric Voskuil via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> Actually this does nothing to provide justification for this consensus rule change. It is just an attempt to deflect criticism from the fact that it is such a change.\n>> \n>> e\n>> \n>> > On Nov 15, 2016, at 9:45 AM, Btc Drak <btcdrak at gmail.com> wrote:\n>> >\n>> > I think this is already covered in the BIP text:-\n>> >\n>> > \"As of November 2016, the most recent of these changes (BIP 65,\n>> > enforced since December 2015) has nearly 50,000 blocks built on top of\n>> > it. The occurrence of such a reorg that would cause the activating\n>> > block to be disconnected would raise fundamental concerns about the\n>> > security assumptions of Bitcoin, a far bigger issue than any\n>> > non-backwards compatible change.\n>> >\n>> > So while this proposal could theoretically result in a consensus\n>> > split, it is extremely unlikely, and in particular any such\n>> > circumstances would be sufficiently damaging to the Bitcoin network to\n>> > dwarf any concerns about the effects of this proposed change.\"\n>> >\n>> >\n>> > On Mon, Nov 14, 2016 at 6:47 PM, Eric Voskuil via bitcoin-dev\n>> > <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> >> NACK\n>> >>\n>> >> Horrible precedent (hardcoding rule changes based on the assumption that\n>> >> large forks indicate a catastrophic failure), extremely poor process\n>> >> (already shipped, now the discussion), and not even a material performance\n>> >> optimization (the checks are avoidable once activated until a sufficiently\n>> >> deep reorg deactivates them).\n>> >>\n>> >> e\n>> >>\n>> >> On Nov 14, 2016, at 10:17 AM, Suhas Daftuar via bitcoin-dev\n>> >> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> >>\n>> >> Hi,\n>> >>\n>> >> Recently Bitcoin Core merged a simplification to the consensus rules\n>> >> surrounding deployment of BIPs 34, 66, and 65\n>> >> (https://github.com/bitcoin/bitcoin/pull/8391), and though the change is a\n>> >> minor one, I thought it was worth documenting the rationale in a BIP for\n>> >> posterity.\n>> >>\n>> >> Here's the abstract:\n>> >>\n>> >> Prior soft forks (BIP 34, BIP 65, and BIP 66) were activated via miner\n>> >> signaling in block version numbers. Now that the chain has long since passed\n>> >> the blocks at which those consensus rules have triggered, we can (as a\n>> >> simplification and optimization) replace the trigger mechanism by caching\n>> >> the block heights at which those consensus rules became enforced.\n>> >>\n>> >> The full draft can be found here:\n>> >>\n>> >> https://github.com/sdaftuar/bips/blob/buried-deployments/bip-buried-deployments.mediawiki\n>> >>\n>> >> _______________________________________________\n>> >> bitcoin-dev mailing list\n>> >> bitcoin-dev at lists.linuxfoundation.org\n>> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> >>\n>> >>\n>> >> _______________________________________________\n>> >> bitcoin-dev mailing list\n>> >> bitcoin-dev at lists.linuxfoundation.org\n>> >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>> >>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161116/9709e645/attachment-0001.html>"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-11-16T14:18:44",
                "message_text_only": "On Wed, Nov 16, 2016 at 1:58 PM, Eric Voskuil via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Are checkpoints good now? Are hard forks okay now?\n>\n\nI think that at least one checkpoint should be included.  The assumption is\nthat no 50k re-orgs will happen, and that assumption should be directly\nchecked.\n\nCheckpointing only needs to happen during the headers-first part of the\ndownload.\n\nIf the block at the BIP-65 height is checkpointed, then the comparisons for\nthe other ones are automatically correct.  They are unnecessary, since the\ncheckpoint protects all earlier block, but many people would like to be\nable to verify the legacy chain.\n\nThis makes the change a soft-fork rather than a hard fork.  Chains that\ndon't go through the checkpoint are rejected but no new chains are allowed.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161116/da3702fc/attachment.html>"
            },
            {
                "author": "Alex Morcos",
                "date": "2016-11-16T14:32:24",
                "message_text_only": "I think we are misunderstanding the effect of this change.\nIt's still \"OK\" for a 50k re-org to happen.\nWe're just saying that if it does, we will now have potentially introduced\na hard fork between new client and old clients if the reorg contains\nearlier signaling for the most recent ISM soft fork and then blocks which\ndo not conform to that soft fork before the block height encoded activation.\n\nI think the argument is this doesn't substantially add to the confusion or\nusability of the system as its likely that old software won't even handle\n50k block reorgs cleanly anyway and there will clearly have to be human\ncoordination at the time of the event.  In the unlikely event that the new\nchain does cause such a hard fork, that coordination can result in everyone\nupgrading to software that supports the new rules anyway.\n\nSo no, I don't think we should add a checkpoint.  I think we should all\njust agree to a hard fork that only has a very very slim chance of any\npractical effect.\n\nIn response to Thomas' email.  I think ideally we would treat these soft\nforks the way we did BIP30 which is to say that we're just introducing a\nfurther soft fork that applies to all blocks except for the historical\nexceptions.  So then its a almost no-op soft fork with no risk of hard\nfork.   This however isn't practical with at least BIP 34 without storing\nthe hashes of all 200K blocks that don't meet the requirement.\n\n\n\nOn Wed, Nov 16, 2016 at 9:18 AM, Tier Nolan via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Wed, Nov 16, 2016 at 1:58 PM, Eric Voskuil via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> Are checkpoints good now? Are hard forks okay now?\n>>\n>\n> I think that at least one checkpoint should be included.  The assumption\n> is that no 50k re-orgs will happen, and that assumption should be directly\n> checked.\n>\n> Checkpointing only needs to happen during the headers-first part of the\n> download.\n>\n> If the block at the BIP-65 height is checkpointed, then the comparisons\n> for the other ones are automatically correct.  They are unnecessary, since\n> the checkpoint protects all earlier block, but many people would like to be\n> able to verify the legacy chain.\n>\n> This makes the change a soft-fork rather than a hard fork.  Chains that\n> don't go through the checkpoint are rejected but no new chains are allowed.\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161116/5e407283/attachment-0001.html>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-11-16T21:01:00",
                "message_text_only": "On Wed, Nov 16, 2016 at 09:32:24AM -0500, Alex Morcos via bitcoin-dev wrote:\n> I think we are misunderstanding the effect of this change.\n> It's still \"OK\" for a 50k re-org to happen.\n> We're just saying that if it does, we will now have potentially introduced\n> a hard fork between new client and old clients if the reorg contains\n> earlier signaling for the most recent ISM soft fork and then blocks which\n> do not conform to that soft fork before the block height encoded activation.\n> \n> I think the argument is this doesn't substantially add to the confusion or\n> usability of the system as its likely that old software won't even handle\n> 50k block reorgs cleanly anyway and there will clearly have to be human\n> coordination at the time of the event.  In the unlikely event that the new\n> chain does cause such a hard fork, that coordination can result in everyone\n> upgrading to software that supports the new rules anyway.\n> \n> So no, I don't think we should add a checkpoint.  I think we should all\n> just agree to a hard fork that only has a very very slim chance of any\n> practical effect.\n\nSo, conceptually, another way to deal with this is to hardcode a blockhash\nwhere we allow blocks in a chain ending with that blockhash to _not_ follow\nBIP65, up until that blockhash, and any blockchain without that blockhash must\nrespect BIP65 for all blocks in the chain.\n\nThis is a softfork: we've only added rules that made otherwise valid chains\ninvalid, and at the same time we are still accepting large reorgs (albeit under\nstricter rules than before).\n\nI'd suggest we call this a exemption hash - we've exempted a particular\nblockchains from a soft-forked rule that we would otherwise enforce.\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161116/eef4afb9/attachment.sig>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-16T22:21:53",
                "message_text_only": "I would suggest that, before discussing how best to fork the chain to meet this objective, we consider the objective.\n\nThe implementers have acknowledged that this does not represent a performance improvement. Especially given that this was apparently not initially understood, that alone is good reason for them to reconsider.\n\nThe remaining stated objective is reduction of code complexity. Let us be very clear, a proposal to change the protocol must be considered independently of any particular implementation of the protocol. While the implementation of BIP34 style activation may be hugely complex in the satoshi code, it is definitely not complex as a matter of necessity.\n\nActivation constitutes maybe a dozen lines of additional code in libbitcoin. The need to hit the chain (or cache) to obtain historical header info will remain for proof of work, so this change doesn't even accomplish some sort of beneficial isolation from blockchain history.\n\nSo, at best, we are talking about various ways to introduce a consensus fork so that a well designed implementation  can remove a tiny amount of already-written code and associated tests. In my opinion this is embarrassingly poor reasoning. It would be much more productive to reduce satoshi code complexity in ways that do not impact the protocol. There are a *huge* number of such opportunities, and in fact activation is one of them. Once that is done, we can talk about forking to reduce source code complexity.\n\nThese fork suggestions actually increase *necessary* complexity for any implantation that takes a rational approach to forks. By rational I mean *additive*. Deleting rules from Bitcoin code is simply bad design. Rules are never removed, they are added. A new rule to modify an old rule is simply a new rule. This is new and additional code. So please don't assume in this \"proposal\" that this makes development simpler for other implementations, that is not a necessary conclusion.\n\ne\n\n> On Nov 16, 2016, at 1:01 PM, Peter Todd via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n>> On Wed, Nov 16, 2016 at 09:32:24AM -0500, Alex Morcos via bitcoin-dev wrote:\n>> I think we are misunderstanding the effect of this change.\n>> It's still \"OK\" for a 50k re-org to happen.\n>> We're just saying that if it does, we will now have potentially introduced\n>> a hard fork between new client and old clients if the reorg contains\n>> earlier signaling for the most recent ISM soft fork and then blocks which\n>> do not conform to that soft fork before the block height encoded activation.\n>> \n>> I think the argument is this doesn't substantially add to the confusion or\n>> usability of the system as its likely that old software won't even handle\n>> 50k block reorgs cleanly anyway and there will clearly have to be human\n>> coordination at the time of the event.  In the unlikely event that the new\n>> chain does cause such a hard fork, that coordination can result in everyone\n>> upgrading to software that supports the new rules anyway.\n>> \n>> So no, I don't think we should add a checkpoint.  I think we should all\n>> just agree to a hard fork that only has a very very slim chance of any\n>> practical effect.\n> \n> So, conceptually, another way to deal with this is to hardcode a blockhash\n> where we allow blocks in a chain ending with that blockhash to _not_ follow\n> BIP65, up until that blockhash, and any blockchain without that blockhash must\n> respect BIP65 for all blocks in the chain.\n> \n> This is a softfork: we've only added rules that made otherwise valid chains\n> invalid, and at the same time we are still accepting large reorgs (albeit under\n> stricter rules than before).\n> \n> I'd suggest we call this a exemption hash - we've exempted a particular\n> blockchains from a soft-forked rule that we would otherwise enforce.\n> \n> -- \n> https://petertodd.org 'peter'[:-1]@petertodd.org\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev"
            },
            {
                "author": "Luke Dashjr",
                "date": "2016-11-17T03:06:01",
                "message_text_only": "On Wednesday, November 16, 2016 9:01:00 PM Peter Todd via bitcoin-dev wrote:\n> So, conceptually, another way to deal with this is to hardcode a blockhash\n> where we allow blocks in a chain ending with that blockhash to _not_ follow\n> BIP65, up until that blockhash, and any blockchain without that blockhash\n> must respect BIP65 for all blocks in the chain.\n> \n> This is a softfork: we've only added rules that made otherwise valid chains\n> invalid, and at the same time we are still accepting large reorgs (albeit\n> under stricter rules than before).\n> \n> I'd suggest we call this a exemption hash - we've exempted a particular\n> blockchains from a soft-forked rule that we would otherwise enforce.\n\nWhile this is technically a softfork, I think it may behave somewhat like a \nhardfork if we're not careful. Particularly, is the chain up to the block \nimmediately before the checkpoint itself valid on its own, or does it simply \nbecome retroactively valid when it hits that checkpoint?\n\nP.S. Your PGP signature is invalid?"
            },
            {
                "author": "Thomas Kerin",
                "date": "2016-11-16T14:18:52",
                "message_text_only": "BIP30 actually was given similar treatment after a reasonable amount of\ntime had passed.\nhttps://github.com/bitcoin/bitcoin/blob/master/src/main.cpp#L2392\n\nYou are also missing BIP50: 'March 2013 Chain For Post-Mortem', which\nneither benefited nor improved bitcoin, but did document an event for\nposterity.\n\nThis is not a hard fork. Removing ISM just means we've committed to\nthose soft-forks only locking into the chain we use now.\n\nOn 11/16/2016 01:58 PM, Eric Voskuil via bitcoin-dev wrote:\n> This sort of statement represents one consequence of the\n> aforementioned bad precedent.\n>\n> Are checkpoints good now? Are hard forks okay now?\n>\n> What is the maximum depth of a reorg allowed by this non-machine\n> consensus?\n>\n> Shouldn't we just define a max depth so that all cruft deeper than\n> that can just be discarded on a regular basis?\n>\n> Why are there activation heights defined by this hard fork if it's not\n> possible to reorg back to them?\n>\n> The \"BIP\" is neither a Proposal (it's been decided, just documenting\n> for posterity), nor an Improvement (there is no actual benefit, just\n> some tidying up in the notoriously obtuse satoshi code base), nor\n> Bitcoin (a hard fork defines an alt coin, so from Aug 4 forward it has\n> been CoreCoin).\n>\n> e\n>\n> On Nov 16, 2016, at 5:29 AM, Jameson Lopp <jameson.lopp at gmail.com\n> <mailto:jameson.lopp at gmail.com>> wrote:\n>\n>> Since \"buried deployments\" are specifically in reference to\n>> historical consensus changes, I think the question is more one of\n>> human consensus than machine consensus. Is there any disagreement\n>> amongst Bitcoin users that BIP34 activated at block 227931, BIP65\n>> activated at block 388381, and BIP66 activated at block 363725?\n>> Somehow I doubt it.\n>>\n>> It seems to me that this change is merely cementing into place a few\n>> attributes of the blockchain's history that are not in dispute.\n>>\n>> - Jameson\n>>\n>> On Tue, Nov 15, 2016 at 5:42 PM, Eric Voskuil via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org\n>> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>\n>>     Actually this does nothing to provide justification for this\n>>     consensus rule change. It is just an attempt to deflect criticism\n>>     from the fact that it is such a change.\n>>\n>>     e\n>>\n>>     > On Nov 15, 2016, at 9:45 AM, Btc Drak <btcdrak at gmail.com\n>>     <mailto:btcdrak at gmail.com>> wrote:\n>>     >\n>>     > I think this is already covered in the BIP text:-\n>>     >\n>>     > \"As of November 2016, the most recent of these changes (BIP 65,\n>>     > enforced since December 2015) has nearly 50,000 blocks built on\n>>     top of\n>>     > it. The occurrence of such a reorg that would cause the activating\n>>     > block to be disconnected would raise fundamental concerns about the\n>>     > security assumptions of Bitcoin, a far bigger issue than any\n>>     > non-backwards compatible change.\n>>     >\n>>     > So while this proposal could theoretically result in a consensus\n>>     > split, it is extremely unlikely, and in particular any such\n>>     > circumstances would be sufficiently damaging to the Bitcoin\n>>     network to\n>>     > dwarf any concerns about the effects of this proposed change.\"\n>>     >\n>>     >\n>>     > On Mon, Nov 14, 2016 at 6:47 PM, Eric Voskuil via bitcoin-dev\n>>     > <bitcoin-dev at lists.linuxfoundation.org\n>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>     >> NACK\n>>     >>\n>>     >> Horrible precedent (hardcoding rule changes based on the\n>>     assumption that\n>>     >> large forks indicate a catastrophic failure), extremely poor\n>>     process\n>>     >> (already shipped, now the discussion), and not even a material\n>>     performance\n>>     >> optimization (the checks are avoidable once activated until a\n>>     sufficiently\n>>     >> deep reorg deactivates them).\n>>     >>\n>>     >> e\n>>     >>\n>>     >> On Nov 14, 2016, at 10:17 AM, Suhas Daftuar via bitcoin-dev\n>>     >> <bitcoin-dev at lists.linuxfoundation.org\n>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>     >>\n>>     >> Hi,\n>>     >>\n>>     >> Recently Bitcoin Core merged a simplification to the consensus\n>>     rules\n>>     >> surrounding deployment of BIPs 34, 66, and 65\n>>     >> (https://github.com/bitcoin/bitcoin/pull/8391\n>>     <https://github.com/bitcoin/bitcoin/pull/8391>), and though the\n>>     change is a\n>>     >> minor one, I thought it was worth documenting the rationale in\n>>     a BIP for\n>>     >> posterity.\n>>     >>\n>>     >> Here's the abstract:\n>>     >>\n>>     >> Prior soft forks (BIP 34, BIP 65, and BIP 66) were activated\n>>     via miner\n>>     >> signaling in block version numbers. Now that the chain has\n>>     long since passed\n>>     >> the blocks at which those consensus rules have triggered, we\n>>     can (as a\n>>     >> simplification and optimization) replace the trigger mechanism\n>>     by caching\n>>     >> the block heights at which those consensus rules became enforced.\n>>     >>\n>>     >> The full draft can be found here:\n>>     >>\n>>     >>\n>>     https://github.com/sdaftuar/bips/blob/buried-deployments/bip-buried-deployments.mediawiki\n>>     <https://github.com/sdaftuar/bips/blob/buried-deployments/bip-buried-deployments.mediawiki>\n>>     >>\n>>     >> _______________________________________________\n>>     >> bitcoin-dev mailing list\n>>     >> bitcoin-dev at lists.linuxfoundation.org\n>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>     >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>>     >>\n>>     >>\n>>     >> _______________________________________________\n>>     >> bitcoin-dev mailing list\n>>     >> bitcoin-dev at lists.linuxfoundation.org\n>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>     >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>>     >>\n>>     _______________________________________________\n>>     bitcoin-dev mailing list\n>>     bitcoin-dev at lists.linuxfoundation.org\n>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>>\n>>\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161116/794ee05f/attachment.html>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2016-11-16T23:58:19",
                "message_text_only": "On Wed, Nov 16, 2016 at 3:18 PM, Thomas Kerin via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> BIP30 actually was given similar treatment after a reasonable amount of time\n> had passed.\n> https://github.com/bitcoin/bitcoin/blob/master/src/main.cpp#L2392\n\nThis is not really the same. BIP30 is not validated after BIP34 is\nactive because blocks complying with BIP34 will always necessarily\ncomply with BIP30 (ie coinbases cannot be duplicated after they\ninclude the block height)."
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-17T00:00:33",
                "message_text_only": "On 11/16/2016 03:58 PM, Jorge Tim\u00f3n via bitcoin-dev wrote:\n> On Wed, Nov 16, 2016 at 3:18 PM, Thomas Kerin via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>> BIP30 actually was given similar treatment after a reasonable amount of time\n>> had passed.\n>> https://github.com/bitcoin/bitcoin/blob/master/src/main.cpp#L2392\n> \n> This is not really the same. BIP30 is not validated after BIP34 is\n> active because blocks complying with BIP34 will always necessarily\n> comply with BIP30 (ie coinbases cannot be duplicated after they\n> include the block height).\n\nThis is a misinterpretation of BIP30. Duplicate transaction hashes can\nand will happen and are perfectly valid in Bitcoin. BIP34 does not\nprevent this.\n\ne\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161116/b8912894/attachment.sig>"
            },
            {
                "author": "Alex Morcos",
                "date": "2016-11-17T01:24:49",
                "message_text_only": "huh?\ncan you give an example of how a duplicate transaction hash (in the same\nchain) can happen given BIP34?\n\n\nOn Wed, Nov 16, 2016 at 7:00 PM, Eric Voskuil via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On 11/16/2016 03:58 PM, Jorge Tim\u00f3n via bitcoin-dev wrote:\n> > On Wed, Nov 16, 2016 at 3:18 PM, Thomas Kerin via bitcoin-dev\n> > <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> >> BIP30 actually was given similar treatment after a reasonable amount of\n> time\n> >> had passed.\n> >> https://github.com/bitcoin/bitcoin/blob/master/src/main.cpp#L2392\n> >\n> > This is not really the same. BIP30 is not validated after BIP34 is\n> > active because blocks complying with BIP34 will always necessarily\n> > comply with BIP30 (ie coinbases cannot be duplicated after they\n> > include the block height).\n>\n> This is a misinterpretation of BIP30. Duplicate transaction hashes can\n> and will happen and are perfectly valid in Bitcoin. BIP34 does not\n> prevent this.\n>\n> e\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161116/31f43652/attachment.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-17T01:41:51",
                "message_text_only": "On 11/16/2016 05:24 PM, Alex Morcos wrote:\n> huh?\n> can you give an example of how a duplicate transaction hash (in the same\n> chain) can happen given BIP34?\n\n\"The pigeonhole principle arises in computer science. For example,\ncollisions are inevitable in a hash table because the number of possible\nkeys exceeds the number of indices in the array. A hashing algorithm, no\nmatter how clever, cannot avoid these collisions.\"\n\nhttps://en.wikipedia.org/wiki/Pigeonhole_principle\n\ne\n\n> On Wed, Nov 16, 2016 at 7:00 PM, Eric Voskuil via bitcoin-dev wrote:\n> \n>     On 11/16/2016 03:58 PM, Jorge Tim\u00f3n via bitcoin-dev wrote:\n>     > On Wed, Nov 16, 2016 at 3:18 PM, Thomas Kerin via bitcoin-dev\n>     > <bitcoin-dev at lists.linuxfoundation.org\n>     <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>     >> BIP30 actually was given similar treatment after a reasonable amount of time\n>     >> had passed.\n>     >> https://github.com/bitcoin/bitcoin/blob/master/src/main.cpp#L2392\n>     <https://github.com/bitcoin/bitcoin/blob/master/src/main.cpp#L2392>\n>     >\n>     > This is not really the same. BIP30 is not validated after BIP34 is\n>     > active because blocks complying with BIP34 will always necessarily\n>     > comply with BIP30 (ie coinbases cannot be duplicated after they\n>     > include the block height).\n> \n>     This is a misinterpretation of BIP30. Duplicate transaction hashes can\n>     and will happen and are perfectly valid in Bitcoin. BIP34 does not\n>     prevent this.\n> \n>     e\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161116/1e67d9e0/attachment-0001.sig>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-17T00:13:42",
                "message_text_only": "On 11/16/2016 06:18 AM, Thomas Kerin wrote:\n> BIP30 actually was given similar treatment after a reasonable amount of\n> time had passed.\n> https://github.com/bitcoin/bitcoin/blob/master/src/main.cpp#L2392\n\nBIP30 was the resolution to a catostrophic protocol flaw that would\nimpact any block whether above or below the point where the rule was\napplied. Applying it to all future blocks, regardless of whether there\nis a reorg back to genesis, was the only option as far as I can tell. So\nthe comparison to an unnecessary fork is hardly apt.\n\n> You are also missing BIP50: 'March 2013 Chain For Post-Mortem', which\n> neither benefited nor improved bitcoin, but did document an event for\n> posterity.\n\nBIP50 documents the release of an \"unexpected\" hard fork to a large\nnumber of users. Given that Core code is considered by some to be the\n*definition* of the true protocol, this led to two \"legitimate\" Bitcoin\nchains. Leveraging the centralized state of Bitcoin mining, the\ndevelopment team was able to kill the newer chain. This was simply an\naltcoin that didn't survive because people stopped using it.\n\nAnyone can create an altcoin - the question here is specifically, why\nwould we want to do so in this case.\n\n> This is not a hard fork. Removing ISM just means we've committed to\n> those soft-forks only locking into the chain we use now.\n\nThere didn't seem to be any confusion among the implementers that it is\na hard fork.\n\nI will correct one implication I made below. The heights in the proposal\nare required in the absence of BIP34-style activation so that the soft\nfork validation rules can be properly enforced at those points (whether\nor not a deep reorg happens).\n\ne\n\n> On 11/16/2016 01:58 PM, Eric Voskuil via bitcoin-dev wrote:\n>> This sort of statement represents one consequence of the\n>> aforementioned bad precedent.\n>>\n>> Are checkpoints good now? Are hard forks okay now?\n>>\n>> What is the maximum depth of a reorg allowed by this non-machine\n>> consensus?\n>>\n>> Shouldn't we just define a max depth so that all cruft deeper than\n>> that can just be discarded on a regular basis?\n>>\n>> Why are there activation heights defined by this hard fork if it's not\n>> possible to reorg back to them?\n>>\n>> The \"BIP\" is neither a Proposal (it's been decided, just documenting\n>> for posterity), nor an Improvement (there is no actual benefit, just\n>> some tidying up in the notoriously obtuse satoshi code base), nor\n>> Bitcoin (a hard fork defines an alt coin, so from Aug 4 forward it has\n>> been CoreCoin).\n>>\n>> e\n>>\n>> On Nov 16, 2016, at 5:29 AM, Jameson Lopp <jameson.lopp at gmail.com\n>> <mailto:jameson.lopp at gmail.com>> wrote:\n>>\n>>> Since \"buried deployments\" are specifically in reference to\n>>> historical consensus changes, I think the question is more one of\n>>> human consensus than machine consensus. Is there any disagreement\n>>> amongst Bitcoin users that BIP34 activated at block 227931, BIP65\n>>> activated at block 388381, and BIP66 activated at block 363725?\n>>> Somehow I doubt it.\n>>>\n>>> It seems to me that this change is merely cementing into place a few\n>>> attributes of the blockchain's history that are not in dispute.\n>>>\n>>> - Jameson\n>>>\n>>> On Tue, Nov 15, 2016 at 5:42 PM, Eric Voskuil via bitcoin-dev\n>>> <bitcoin-dev at lists.linuxfoundation.org\n>>> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>>\n>>>     Actually this does nothing to provide justification for this\n>>>     consensus rule change. It is just an attempt to deflect criticism\n>>>     from the fact that it is such a change.\n>>>\n>>>     e\n>>>\n>>>     > On Nov 15, 2016, at 9:45 AM, Btc Drak <btcdrak at gmail.com\n>>>     <mailto:btcdrak at gmail.com>> wrote:\n>>>     >\n>>>     > I think this is already covered in the BIP text:-\n>>>     >\n>>>     > \"As of November 2016, the most recent of these changes (BIP 65,\n>>>     > enforced since December 2015) has nearly 50,000 blocks built on\n>>>     top of\n>>>     > it. The occurrence of such a reorg that would cause the activating\n>>>     > block to be disconnected would raise fundamental concerns about the\n>>>     > security assumptions of Bitcoin, a far bigger issue than any\n>>>     > non-backwards compatible change.\n>>>     >\n>>>     > So while this proposal could theoretically result in a consensus\n>>>     > split, it is extremely unlikely, and in particular any such\n>>>     > circumstances would be sufficiently damaging to the Bitcoin\n>>>     network to\n>>>     > dwarf any concerns about the effects of this proposed change.\"\n>>>     >\n>>>     >\n>>>     > On Mon, Nov 14, 2016 at 6:47 PM, Eric Voskuil via bitcoin-dev\n>>>     > <bitcoin-dev at lists.linuxfoundation.org\n>>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>>     >> NACK\n>>>     >>\n>>>     >> Horrible precedent (hardcoding rule changes based on the\n>>>     assumption that\n>>>     >> large forks indicate a catastrophic failure), extremely poor\n>>>     process\n>>>     >> (already shipped, now the discussion), and not even a material\n>>>     performance\n>>>     >> optimization (the checks are avoidable once activated until a\n>>>     sufficiently\n>>>     >> deep reorg deactivates them).\n>>>     >>\n>>>     >> e\n>>>     >>\n>>>     >> On Nov 14, 2016, at 10:17 AM, Suhas Daftuar via bitcoin-dev\n>>>     >> <bitcoin-dev at lists.linuxfoundation.org\n>>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>>     >>\n>>>     >> Hi,\n>>>     >>\n>>>     >> Recently Bitcoin Core merged a simplification to the consensus\n>>>     rules\n>>>     >> surrounding deployment of BIPs 34, 66, and 65\n>>>     >> (https://github.com/bitcoin/bitcoin/pull/8391\n>>>     <https://github.com/bitcoin/bitcoin/pull/8391>), and though the\n>>>     change is a\n>>>     >> minor one, I thought it was worth documenting the rationale in\n>>>     a BIP for\n>>>     >> posterity.\n>>>     >>\n>>>     >> Here's the abstract:\n>>>     >>\n>>>     >> Prior soft forks (BIP 34, BIP 65, and BIP 66) were activated\n>>>     via miner\n>>>     >> signaling in block version numbers. Now that the chain has\n>>>     long since passed\n>>>     >> the blocks at which those consensus rules have triggered, we\n>>>     can (as a\n>>>     >> simplification and optimization) replace the trigger mechanism\n>>>     by caching\n>>>     >> the block heights at which those consensus rules became enforced.\n>>>     >>\n>>>     >> The full draft can be found here:\n>>>     >>\n>>>     >>\n>>>     https://github.com/sdaftuar/bips/blob/buried-deployments/bip-buried-deployments.mediawiki\n>>>     <https://github.com/sdaftuar/bips/blob/buried-deployments/bip-buried-deployments.mediawiki>\n>>>     >>\n>>>     >> _______________________________________________\n>>>     >> bitcoin-dev mailing list\n>>>     >> bitcoin-dev at lists.linuxfoundation.org\n>>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>>     >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>>>     >>\n>>>     >>\n>>>     >> _______________________________________________\n>>>     >> bitcoin-dev mailing list\n>>>     >> bitcoin-dev at lists.linuxfoundation.org\n>>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>>     >> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>>>     >>\n>>>     _______________________________________________\n>>>     bitcoin-dev mailing list\n>>>     bitcoin-dev at lists.linuxfoundation.org\n>>>     <mailto:bitcoin-dev at lists.linuxfoundation.org>\n>>>     https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>>>     <https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev>\n>>>\n>>>\n>>\n>>\n>> _______________________________________________\n>> bitcoin-dev mailing list\n>> bitcoin-dev at lists.linuxfoundation.org\n>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n> \n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161116/e85b7728/attachment.sig>"
            },
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2016-11-16T23:48:02",
                "message_text_only": "On Wed, Nov 16, 2016 at 2:58 PM, Eric Voskuil via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> This sort of statement represents one consequence of the aforementioned bad\n> precedent.\n>\n> Are checkpoints good now?\n\nCheckpoints are not necessary for consensus and work is being done to\nremove them completely from Bitcoin Core in particular.\n\n> Are hard forks okay now?\n\nI personally think uncontroversial hardforks are ok.\n\n> What is the maximum depth of a reorg allowed by this non-machine consensus?\n\nGood question, specially if we plan to do this with future buried\ndeployments. What about 1 year reorg?\n\n> Shouldn't we just define a max depth so that all cruft deeper than that can\n> just be discarded on a regular basis?\n\nNot sure I understand this question.\n\n> Why are there activation heights defined by this hard fork if it's not\n> possible to reorg back to them?\n\nIf this is a hardfork, it is one that will only be visible if/when\nthere's a very deep reorg , one of the kind where we can practically\nconsider Bitcoin done (and only if some nodes keep the ISM code).\nBut I could accept that definition. Another way to see it (even though\nother said the optimization part was not important) as such an\noptimization and simplification.\nThe way I see it, ISM and BIP9 are just coordination mechanisms for\nuncontroversial rule changes.\nOnce the coordination happened and is long in the past, I really don't\nsee the problem with replacing the mechanism with a simpler height.\n\n> The \"BIP\" is neither a Proposal (it's been decided, just documenting for\n> posterity), nor an Improvement (there is no actual benefit, just some\n> tidying up in the notoriously obtuse satoshi code base), nor Bitcoin (a hard\n> fork defines an alt coin, so from Aug 4 forward it has been CoreCoin).\n\nMhmm, I disagree on the notion that any hardfork necessarily\nrepresents an altcoin.\nIt is certainly an improvement in the sense that it simplifies\nimplementations and optimizes validation. You may argue that you don't\nconsider the improvement important though.\nThese changes to Bitcoin Core could be rolled back (and obviously\nother implementations don't need to adopt them unless they want to\nbenefit from the simplification/optimization or fear such a long\nreaorg), but I really hope we don't.\n\nTrying to understand you better...\nAccepting your definition of this as a hardfork, do you oppose to it\nsimply because it is a hardfork, or because you consider this\n\"hardfork\" a bad idea for some reason I am missing?"
            },
            {
                "author": "Pieter Wuille",
                "date": "2016-11-17T01:50:53",
                "message_text_only": "On Wed, Nov 16, 2016 at 5:58 AM, Eric Voskuil via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> This sort of statement represents one consequence of the aforementioned\n> bad precedent.\n>\n> Are checkpoints good now?\n>\n\nSo far in this discussion, and in a thread that has forked off, I think 3\ncases of implementation aspects have been mentioned that under certain\ncircumstances result in the validity of chains changing:\n* Buried softforks (by simplifying the activation rules for certain rules)\n* Not verifying BIP30 after BIP34 is active (since only under a SHA256^2\ncollision a duplicate txid can occur)\n* The existence (and/or removal) of checkpoints (in one form or another).\n\nNone of these will influence the accepted main chain, however. If they ever\ndo, Bitcoin has far worse things to worry about (years-deep reorgs, or\nSHA256 collisions).\n\nIf you were trying to point out that buried softforks are similar to\ncheckpoints in this regard, I agree. So are checkpoints good now? I believe\nwe should get rid of checkpoints because they seem to be misunderstood as a\nsecurity feature rather than as an optimization. I don't think buried\nsoftforks have that problem.\n\n-- \nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161116/8b6f55ed/attachment.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-17T02:16:23",
                "message_text_only": "On 11/16/2016 05:50 PM, Pieter Wuille wrote:\n\n> If you were trying to point out that buried softforks are similar to\n> checkpoints in this regard, I agree.\n\nYes, that was my point.\n\n> So are checkpoints good now?\n> I believe we should get rid of checkpoints because they seem to be\nmisunderstood as a security feature rather than as an optimization.\n\nOr maybe because they place control of the \"true chain\" in the hands of\nthose selecting the checkpoints? It's not a great leap for the parties\ndistributing the checkpoints to become the central authority.\n\nI recommend users of our node validate the full chain without\ncheckpoints and from that chain select their own checkpoints and place\nthem into config. From that point forward they can apply the\noptimization. Checkpoints should never be hardcoded into the source.\n\n> I don't think buried softforks have that problem.\n\nI find \"buried softfork\" a curious name as you are using it. You seem to\nbe implying that this type of change is itself a softfork as opposed to\na hardfork that changes the activation of a softfork. It was my\nunderstanding that the term referred to the 3 softforks that were being\n\"buried\", or the proposal, but not the burial itself.\n\nNevertheless, this proposal shouldn't have \"that problem\" because it is\nclearly neither a security feature nor an optimization. That is the\nfirst issue that needs to be addressed.\n\ne\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161116/88257c4a/attachment.sig>"
            },
            {
                "author": "Pieter Wuille",
                "date": "2016-11-17T02:47:33",
                "message_text_only": "On Wed, Nov 16, 2016 at 6:16 PM, Eric Voskuil <eric at voskuil.org> wrote:\n\n> On 11/16/2016 05:50 PM, Pieter Wuille wrote:\n>\n\n\n> > So are checkpoints good now?\n> > I believe we should get rid of checkpoints because they seem to be\n> misunderstood as a security feature rather than as an optimization.\n>\n> Or maybe because they place control of the \"true chain\" in the hands of\n> those selecting the checkpoints? It's not a great leap for the parties\n> distributing the checkpoints to become the central authority.\n>\n\nYes, they can be used to control the \"true chain\", and this has happened\nwith various forks. But developers inevitably have this possibility, if you\nignore review. If review is good enough to catch unintended consensus\nchanges, it is certainly enough to catch the introduction of an invalid\ncheckpoint. The risk you point out is real, but the way to deal with it is\ngood review and release practices.\n\nI wish we had never used checkpoints the way we did, but here we are.\nBecause of this, I want to get rid of them. However, It's not because I\nthink they offer an excessive power to developers - but because they're\noften perceived this way (partially as a result of how they've been abused\nin other systems).\n\n\n> I recommend users of our node validate the full chain without\n> checkpoints and from that chain select their own checkpoints and place\n> them into config. From that point forward they can apply the\n> optimization. Checkpoints should never be hardcoded into the source.\n>\n\nHaving users with the discipline you suggest would be wonderful to have. I\ndon't think it's very realistic, though, and I fear that the result would\nbe that everyone copies their config from one or a few websites \"because\nthat's what everyone uses\".\n\n> I don't think buried softforks have that problem.\n>\n> I find \"buried softfork\" a curious name as you are using it. You seem to\n> be implying that this type of change is itself a softfork as opposed to\n> a hardfork that changes the activation of a softfork. It was my\n> understanding that the term referred to the 3 softforks that were being\n> \"buried\", or the proposal, but not the burial itself.\n>\n\nI do not consider the practice of \"buried softforks\" to be a fork at all.\nIt is a change that modifies the validity of a theoretically construable\nchain from invalid to valid. However, a reorganization to that theoretical\nchain itself is likely already impossible due to the vast number of blocks\nto rewind, and economic damage that is far greater than chain divergence\nitself.\n\n\n> Nevertheless, this proposal shouldn't have \"that problem\" because it is\n> clearly neither a security feature nor an optimization. That is the\n> first issue that needs to be addressed.\n\n\nIt is clearly not a security feature, agreed. But how would you propose to\navoid the ISM checks for BIP34 and BIP66 all the time? I feel this approach\nis a perfectly reasonable choice for code that likely won't ever affect the\nvalid chain again.\n\nCheers,\n\n-- \nPieter\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161116/3e3da51b/attachment.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-17T10:10:30",
                "message_text_only": "On 11/16/2016 06:47 PM, Pieter Wuille wrote:\n> On Wed, Nov 16, 2016 at 6:16 PM, Eric Voskuil <eric at voskuil.org\n> <mailto:eric at voskuil.org>> wrote:\n> \n>     On 11/16/2016 05:50 PM, Pieter Wuille wrote:\n> \n>     > So are checkpoints good now?\n>     > I believe we should get rid of checkpoints because they seem to be\n>     misunderstood as a security feature rather than as an optimization.\n> \n>     Or maybe because they place control of the \"true chain\" in the hands of\n>     those selecting the checkpoints? It's not a great leap for the parties\n>     distributing the checkpoints to become the central authority.\n> \n> Yes, they can be used to control the \"true chain\", and this has happened\n> with various forks. But developers inevitably have this possibility, if\n> you ignore review. If review is good enough to catch unintended\n> consensus changes, it is certainly enough to catch the introduction of\n> an invalid checkpoint. The risk you point out is real, but the way to\n> deal with it is good review and release practices.\n> \n> I wish we had never used checkpoints the way we did, but here we are.\n> Because of this, I want to get rid of them. However, It's not because I\n> think they offer an excessive power to developers - but because they're\n> often perceived this way (partially as a result of how they've been\n> abused in other systems).\n>  \n>     I recommend users of our node validate the full chain without\n>     checkpoints and from that chain select their own checkpoints and place\n>     them into config. From that point forward they can apply the\n>     optimization. Checkpoints should never be hardcoded into the source.\n> \n> Having users with the discipline you suggest would be wonderful to have.\n> I don't think it's very realistic, though, and I fear that the result\n> would be that everyone copies their config from one or a few websites\n> \"because that's what everyone uses\".\n\nCertainly, but embedding them in the code makes that a practical\ncertainty. People cannot be prevented from doing dumb things, but let's\nnot make it hard for them to be smart.\n\n>     > I don't think buried softforks have that problem.\n> \n>     I find \"buried softfork\" a curious name as you are using it. You seem to\n>     be implying that this type of change is itself a softfork as opposed to\n>     a hardfork that changes the activation of a softfork. It was my\n>     understanding that the term referred to the 3 softforks that were being\n>     \"buried\", or the proposal, but not the burial itself.\n\n\n> I do not consider the practice of \"buried softforks\" to be a fork at\n> all. It is a change that modifies the validity of a theoretically\n> construable chain from invalid to valid.\n\nI was out at a Bitcoin meetup when I read this and I think beer actually\ncame out of my nose.\n\n> However, a reorganization to\n> that theoretical chain itself is likely already impossible due to the\n> vast number of blocks to rewind, and economic damage that is far greater\n> than chain divergence itself.\n\nIt's either possible or it is not. If it is not there is no reason for a\nproposal - just make the change and don't bother to tell anyone. The\nreason we are having this discussion is because it is not impossible.\n\n>     Nevertheless, this proposal shouldn't have \"that problem\" because it is\n>     clearly neither a security feature nor an optimization. That is the\n>     first issue that needs to be addressed.\n> \n> It is clearly not a security feature, agreed. But how would you propose\n> to avoid the ISM checks for BIP34 and BIP66 all the time?\n\nI'll call straw man on the question. It is not important to avoid the\nactivation checks. The question is whether there is a material\nperformance optimization in eliminating them. This would have to be\nsignificant enough to rise to the level of a change to the protocol.\nHaving said that there are a few options:\n\n1. The naive approach to activation is, for each new block, to query the\nstore for the previous 1000 block headers (to the extent there are that\nmany), and just do so forever, summing up after the query. This is the\nmost straightforward but also the most costly approach.\n\n2. A slightly less costly approach is, for each new block, to reverse\niterate over the store until all decisions can be made. This would be an\nimprovement below activation in that it would take it takes as little as\n251 vs. 1000 queries to make the determinations.\n\n3. A further improvement is available by caching the height of full\nactivation of all three soft forks. Unless there is a subsequent reorg\nwith a fork point prior that height, there is never a need to make\nanother query. Once fully activated the activation height is cached to\nthe store (otherwise just query the last 1000 versions at startup to\ndetermine the state), eliminating any ongoing material cost.\n\n4. We may also be interested in optimizing initial block download. A\ncache of the last 1000 block versions can be maintained by adding each\nto a circular buffer as they are committed. This eliminates *all*\nquerying for block versions unless:\n\n(1) there is a restart prior to full activation - in which case there is\na query of up to 1000 versions to prime the cache.\n\n(2) there is a potential reorg after full activation, and the fork point\nprecedes the saved full activation height - in which case the cache must\nbe reprimed.\n\n(3) there is a potential reorg. before reaching full activation - in\nwhich case the cache must be backfilled with a query for a number of\nversions equal to the depth of the fork point.\n\nDuring initial block download potential reorgs are exceedingly rare\n(reorgs don't have potential unless they have sufficient work to\novercome the long chain) and the cost of handling them as described\nabove is trivial. The cost of priming the cache is immaterial in the\ncontext of a restart.\n\nSo even with a full chain validation one is not likely to *ever* need to\nquery the store. The memory cost of the cache is strictly 3 bits per\nblock (375 bytes total). A simpler less memory-sensitive approach is to\nuse one byte (1,000 bytes total). The computational cost is trivial.\n\nThis should already be implemented. A protocol fork (or \"change that\nmodifies the validity of a theoretically construable chain from invalid\nto valid\") to avoid doing so is not a performance optimization.\n\n> I feel this\n> approach is a perfectly reasonable choice for code that likely won't\n> ever affect the valid chain again.\n\nI find it to be completely unsupportable as there is no security,\nperformance, or feature benefit in it.\n\ne\n\n\n\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161117/22c2a137/attachment.sig>"
            },
            {
                "author": "Tom Zander",
                "date": "2016-11-16T14:38:21",
                "message_text_only": "Here is my thinking.\n\nThe BIP process is about changes to a living project which is the bitcoin \nprptocol.\nThis specific BIP got accepted and we know in the blockchain that\nthis event (the acceptance) is recorded.\nBefore a certain block the rules were one way, after they were changed.\n\nI have no problem with changing the *code* to be less complex because it \nalready knows the past. A checkpoint is the same, it is the registeration of \na past event.\nThis makes software less complex and still capable of checking the entire \nblockchain from genesis.\n\nI don\u2019t see any harm in this change. I see prudent software engineering \npractices.\n\n\nOn Monday, 14 November 2016 10:47:35 CET Eric Voskuil via bitcoin-dev wrote:\n> NACK\n> \n> Horrible precedent (hardcoding rule changes based on the assumption that\n> large forks indicate a catastrophic failure), extremely poor process\n> (already shipped, now the discussion), and not even a material\n> performance optimization (the checks are avoidable once activated until a\n> sufficiently deep reorg deactivates them).\n\n\n-- \nTom Zander\nBlog: https://zander.github.io\nVlog: https://vimeo.com/channels/tomscryptochannel"
            }
        ],
        "thread_summary": {
            "title": "Buried Deployments",
            "categories": [
                "bitcoin-dev",
                "BIP Proposal"
            ],
            "authors": [
                "Eric Voskuil",
                "Thomas Kerin",
                "Suhas Daftuar",
                "Tom Zander",
                "Peter Todd",
                "Tier Nolan",
                "Jorge Tim\u00f3n",
                "Btc Drak",
                "Alex Morcos",
                "Luke Dashjr",
                "Jameson Lopp",
                "Pieter Wuille"
            ],
            "messages_count": 24,
            "total_messages_chars_count": 65721
        }
    },
    {
        "title": "[bitcoin-dev] BIP30 and BIP34 interaction (was Re: [BIP Proposal] Buried Deployments)",
        "thread_messages": [
            {
                "author": "Jorge Tim\u00f3n",
                "date": "2016-11-17T00:06:45",
                "message_text_only": "On Thu, Nov 17, 2016 at 1:00 AM, Eric Voskuil <eric at voskuil.org> wrote:\n> This is a misinterpretation of BIP30. Duplicate transaction hashes can\n> and will happen and are perfectly valid in Bitcoin. BIP34 does not\n> prevent this.\n\nSorry for moving the topic, but isn't duplication of tx hashes\nprecisely what BIP30 prevents?\nThat was my undesrtanding but should read it again.\nSince regular txs take inputs, the collision is extremely unlikely\n(again, this is my understanding, please correct me when wrong), the\nworrying case is coinbase txs (which don't have input to take entropy\nfrom). By introducing the committed height, collisions on coinbase txs\nare prevented too.\n\nIf I'm wrong on any of this I'm more than happy to learn why."
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-17T00:10:07",
                "message_text_only": "No, BIP30 prevents duplicate tx hashes in the case where the new tx hash\nduplicates that of a preceding tx with unspent outputs.\n\nThere was one such case that had already become buried in the chain at\nthe time, so it was exempted from validation. There was another case of\na duplicate hash, but it's predecessor was spent so it complied with the\nnew rule.\n\nBoth of these cases resulted from exact duplicate txs, which BIP34 now\nprecludes. However nothing precludes different txs from having the same\nhash.\n\ne\n\nOn 11/16/2016 04:06 PM, Jorge Tim\u00f3n wrote:\n> On Thu, Nov 17, 2016 at 1:00 AM, Eric Voskuil <eric at voskuil.org> wrote:\n>> This is a misinterpretation of BIP30. Duplicate transaction hashes can\n>> and will happen and are perfectly valid in Bitcoin. BIP34 does not\n>> prevent this.\n> \n> Sorry for moving the topic, but isn't duplication of tx hashes\n> precisely what BIP30 prevents?\n> That was my undesrtanding but should read it again.\n> Since regular txs take inputs, the collision is extremely unlikely\n> (again, this is my understanding, please correct me when wrong), the\n> worrying case is coinbase txs (which don't have input to take entropy\n> from). By introducing the committed height, collisions on coinbase txs\n> are prevented too.\n> \n> If I'm wrong on any of this I'm more than happy to learn why.\n> \n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161116/417a75b2/attachment.sig>"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-11-17T00:31:02",
                "message_text_only": "On Thu, Nov 17, 2016 at 12:10 AM, Eric Voskuil via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Both of these cases resulted from exact duplicate txs, which BIP34 now\n> precludes. However nothing precludes different txs from having the same\n> hash.\n>\n\nThe only way to have two transactions have the same txid is if their\nparents are identical, since the txids of the parents are included in a\ntransaction.\n\nCoinbases have no parents, so it used to be possible for two of them to be\nidentical.\n\nDuplicate outputs weren't possible in the database, so the later coinbase\ntransaction effectively overwrote the earlier one.\n\nThe happened for two coinbases.  That is what the exceptions are for.\n\nNeither of the those coinbases were spent before the overwrite happened.  I\ndon't even think those coinbases were spent at all.\n\nThis means that every activate coinbase transaction has a unique hash and\nall new coinbases will be unique.\n\nThis means that all future transactions will have different txids.\n\nThere might not be an explicit rule that says that txids have to be unique,\nbut barring a break of the hash function, they rules do guarantee it.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161117/55cc4f6a/attachment-0001.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-17T00:43:08",
                "message_text_only": "> This means that all future transactions will have different txids...\nrules do guarantee it.\n\nNo, it means that the chance is small, there is a difference.\n\nIf there is an address collision, someone may lose some money. If there\nis a tx hash collision, and implementations handle this differently, it\nwill produce a chain split. As such this is not something that a node\ncan just dismiss. If they do they are implementing a hard fork.\n\ne\n\nOn 11/16/2016 04:31 PM, Tier Nolan via bitcoin-dev wrote:\n> \n> \n> On Thu, Nov 17, 2016 at 12:10 AM, Eric Voskuil via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org\n> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n> \n>     Both of these cases resulted from exact duplicate txs, which BIP34 now\n>     precludes. However nothing precludes different txs from having the same\n>     hash.\n> \n> \n> The only way to have two transactions have the same txid is if their\n> parents are identical, since the txids of the parents are included in a\n> transaction.\n> \n> Coinbases have no parents, so it used to be possible for two of them to\n> be identical.\n> \n> Duplicate outputs weren't possible in the database, so the later\n> coinbase transaction effectively overwrote the earlier one.\n> \n> The happened for two coinbases.  That is what the exceptions are for.\n> \n> Neither of the those coinbases were spent before the overwrite\n> happened.  I don't even think those coinbases were spent at all.\n> \n> This means that every activate coinbase transaction has a unique hash\n> and all new coinbases will be unique.\n> \n> This means that all future transactions will have different txids.\n> \n> There might not be an explicit rule that says that txids have to be\n> unique, but barring a break of the hash function, they rules do\n> guarantee it.\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161116/a04356d5/attachment.sig>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-17T00:53:45",
                "message_text_only": "Also, it's important to take note of the motivation behind not banning\nduplicate tx hashes outright. Doing so would require that spent tx\nhashes are retained forever. A pruning node will have no way of knowing\nwhether a new tx duplicates the hash of a preceding tx. Any\nimplementation that does retain such hashes and dismisses new txs on\nthat basis would fork against pruning nodes.\n\ne\n\nOn 11/16/2016 04:43 PM, Eric Voskuil wrote:\n>> This means that all future transactions will have different txids...\n> rules do guarantee it.\n> \n> No, it means that the chance is small, there is a difference.\n> \n> If there is an address collision, someone may lose some money. If there\n> is a tx hash collision, and implementations handle this differently, it\n> will produce a chain split. As such this is not something that a node\n> can just dismiss. If they do they are implementing a hard fork.\n> \n> e\n> \n> On 11/16/2016 04:31 PM, Tier Nolan via bitcoin-dev wrote:\n>>\n>>\n>> On Thu, Nov 17, 2016 at 12:10 AM, Eric Voskuil via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org\n>> <mailto:bitcoin-dev at lists.linuxfoundation.org>> wrote:\n>>\n>>     Both of these cases resulted from exact duplicate txs, which BIP34 now\n>>     precludes. However nothing precludes different txs from having the same\n>>     hash.\n>>\n>>\n>> The only way to have two transactions have the same txid is if their\n>> parents are identical, since the txids of the parents are included in a\n>> transaction.\n>>\n>> Coinbases have no parents, so it used to be possible for two of them to\n>> be identical.\n>>\n>> Duplicate outputs weren't possible in the database, so the later\n>> coinbase transaction effectively overwrote the earlier one.\n>>\n>> The happened for two coinbases.  That is what the exceptions are for.\n>>\n>> Neither of the those coinbases were spent before the overwrite\n>> happened.  I don't even think those coinbases were spent at all.\n>>\n>> This means that every activate coinbase transaction has a unique hash\n>> and all new coinbases will be unique.\n>>\n>> This means that all future transactions will have different txids.\n>>\n>> There might not be an explicit rule that says that txids have to be\n>> unique, but barring a break of the hash function, they rules do\n>> guarantee it.\n> \n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161116/d25e8219/attachment.sig>"
            },
            {
                "author": "Peter Todd",
                "date": "2016-11-17T08:44:05",
                "message_text_only": "On Wed, Nov 16, 2016 at 04:43:08PM -0800, Eric Voskuil via bitcoin-dev wrote:\n> > This means that all future transactions will have different txids...\n> rules do guarantee it.\n> \n> No, it means that the chance is small, there is a difference.\n> \n> If there is an address collision, someone may lose some money. If there\n> is a tx hash collision, and implementations handle this differently, it\n> will produce a chain split. As such this is not something that a node\n> can just dismiss. If they do they are implementing a hard fork.\n\nIf there is a tx hash collision it is almost certainly going to be because\nSHA256 has become weak through advances in cryptography, much like MD5. If that\nis the case, Bitcoin is fundementally broken because the blockchain no longer\ncan be relied upon to commit to a unique transaction history: miners would be\nable to generate blocks that have SHA256 collisions in transactions and even\nthe merkle tree itself, making it possible to simultaneously mine two (or more)\ncontradictory transaction histories at once.\n\nMeanwhile the probability of SHA256 _not_ being broken and a collision being\nfound is low enough that we should be more worried about earth-killing\nasteroids and mutant sharks, among other things.\n\nQuoting Bruce Schneier:\n\n    These numbers have nothing to do with the technology of the devices; they are\n    the maximums that thermodynamics will allow. And they strongly imply that\n    brute-force attacks against 256-bit keys will be infeasible until computers are\n    built from something other than matter and occupy something other than space.\n\n-https://www.schneier.com/blog/archives/2009/09/the_doghouse_cr.html\n\n-- \nhttps://petertodd.org 'peter'[:-1]@petertodd.org\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 455 bytes\nDesc: Digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161117/5a08a14c/attachment.sig>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-17T09:58:38",
                "message_text_only": "On 11/17/2016 12:44 AM, Peter Todd wrote:\n> On Wed, Nov 16, 2016 at 04:43:08PM -0800, Eric Voskuil via bitcoin-dev wrote:\n>>> This means that all future transactions will have different txids...\n>> rules do guarantee it.\n>>\n>> No, it means that the chance is small, there is a difference.\n>>\n>> If there is an address collision, someone may lose some money. If there\n>> is a tx hash collision, and implementations handle this differently, it\n>> will produce a chain split. As such this is not something that a node\n>> can just dismiss. If they do they are implementing a hard fork.\n> \n> If there is a tx hash collision it is almost certainly going to be because\n> SHA256 has become weak..\n\nAlmost certainly is not certainly. Hash collisions happen because of chance.\n\nBIP30 is quite explicit:\n\n> \"Fully-spent transactions are allowed to be duplicated in order not to\nhinder pruning at some point in the future. Not allowing any transaction\nto be duplicated would require evidence to be kept for each transaction\never made.\"\n\nBIP34 motivations:\n\n> \"2. Enforce block and transaction uniqueness, and assist unconnected\nblock validation.\"\n\nBut it only specifies making collisions harder, not impossible (i.e.\nexplicitly rejected by consensus).\n\nAre you proposing that we draft a new BIP that allows us all to not have\nto code for this? If we do so it will be impossible to guard against a\nchain split due to pruning, but you seem to think that's unimportant.\n\ne\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161117/e4e97aa9/attachment.sig>"
            },
            {
                "author": "Tier Nolan",
                "date": "2016-11-17T10:22:28",
                "message_text_only": "On Thu, Nov 17, 2016 at 12:43 AM, Eric Voskuil <eric at voskuil.org> wrote:\n\n> > This means that all future transactions will have different txids...\n> rules do guarantee it.\n>\n> No, it means that the chance is small, there is a difference.\n>\n\nI think we are mostly in agreement then?  It is just terminology.\n\nIn terms of discussing the BIP, barring a hash collision, it does make\nduplicate txids impossible.\n\nGiven that a hash collision is so unlikely, the qualifier should be added\nto those making claims that require hash collisions rather than those who\nassume that they aren't possible.\n\nYou could have said \"However nothing precludes different txs from having\nthe same hash, but it requires a hash collision\".\n\nThinking about it, a re-org to before the enforcement height could allow\nit.  The checkpoints protect against that though.\n\n\n> As such this is not something that a node\n> can just dismiss.\n\n\nThe security of many parts of the system is based on hash collisions not\nbeing possible.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161117/30a28347/attachment-0001.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-17T11:22:03",
                "message_text_only": "On 11/17/2016 02:22 AM, Tier Nolan via bitcoin-dev wrote:\n> On Thu, Nov 17, 2016 at 12:43 AM, Eric Voskuil <eric at voskuil.org\n> <mailto:eric at voskuil.org>> wrote:\n> \n>     > This means that all future transactions will have different txids...\n>     rules do guarantee it.\n> \n>     No, it means that the chance is small, there is a difference.\n> \n> I think we are mostly in agreement then?  It is just terminology.\n\nSure, if you accept that mostly is not fully - just as unlikely is not\nimpossible.\n\n> In terms of discussing the BIP, barring a hash collision, it does make\n> duplicate txids impossible.\n\nThat's like saying, as long as we exclude car accidents from\nconsideration, car accidents are impossible.\n\n> Given that a hash collision is so unlikely, the qualifier should be\n> added to those making claims that require hash collisions rather than\n> those who assume that they aren't possible.\n> \n> You could have said \"However nothing precludes different txs from having\n> the same hash, but it requires a hash collision\".\n\nI generally try to avoid speaking in tautologies :)\n\n> Thinking about it, a re-org to before the enforcement height could allow\n> it.  The checkpoints protect against that though.\n>  \n>     As such this is not something that a node\n>     can just dismiss. \n> \n> The security of many parts of the system is based on hash collisions not\n> being possible.\n\nThis is not the case.\n\nBlock hash duplicates within the same chain are invalid as a matter of\nconsensus, which is the opposite of assuming impossibility.\n\nTx hash collisions are explicitly allowed in the case that preceding tx\nwith the same hash is unspent. This is also not a reliance on the\nimpossibility of hash collision. Core certainly implements this distinction:\n\nhttps://github.com/bitcoin/bitcoin/blob/master/src/main.cpp#L2419-L2426\n\nAddress hashes and script hashes can collide without harming the\nsecurity of Bitcoin (although address owner(s) may experience harm).\nRare in this case is sufficient because of this distinction.\n\nCompact blocks contemplates hash collisions:\n\nhttps://github.com/bitcoin/bips/blob/master/bip-0152.mediawiki#Random_collision_probabilty\n\nCheckpoints aren't part of Bitcoin security, so even the remote\npossibility of two different potential blocks, with the same hash, at\nthe same height in the same chain, does not indicate a problem.\n\nThere is no case where the security of Bitcoin assumes that hashes never\ncollide. Consensus rules have specific handling for both block hash\ncollisions and tx hash collisions.\n\ne\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161117/a1837c8b/attachment.sig>"
            },
            {
                "author": "Alex Morcos",
                "date": "2016-11-17T11:38:12",
                "message_text_only": "I think this conversation has gone off the rails and is no longer really\nappropriate for the list.\n\nBut just to be clear to any readers.  Bitcoin Core absolutely does rely on\nthe impossibility of a hash collision for maintaining consensus.  This\nhappens in multiple places in the code but in particular we don't check\nBIP30 any more since the only way it could get violated is by a hash\ncollision.\n\n\n\n\n\nOn Thu, Nov 17, 2016 at 6:22 AM, Eric Voskuil via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On 11/17/2016 02:22 AM, Tier Nolan via bitcoin-dev wrote:\n> > On Thu, Nov 17, 2016 at 12:43 AM, Eric Voskuil <eric at voskuil.org\n> > <mailto:eric at voskuil.org>> wrote:\n> >\n> >     > This means that all future transactions will have different\n> txids...\n> >     rules do guarantee it.\n> >\n> >     No, it means that the chance is small, there is a difference.\n> >\n> > I think we are mostly in agreement then?  It is just terminology.\n>\n> Sure, if you accept that mostly is not fully - just as unlikely is not\n> impossible.\n>\n> > In terms of discussing the BIP, barring a hash collision, it does make\n> > duplicate txids impossible.\n>\n> That's like saying, as long as we exclude car accidents from\n> consideration, car accidents are impossible.\n>\n> > Given that a hash collision is so unlikely, the qualifier should be\n> > added to those making claims that require hash collisions rather than\n> > those who assume that they aren't possible.\n> >\n> > You could have said \"However nothing precludes different txs from having\n> > the same hash, but it requires a hash collision\".\n>\n> I generally try to avoid speaking in tautologies :)\n>\n> > Thinking about it, a re-org to before the enforcement height could allow\n> > it.  The checkpoints protect against that though.\n> >\n> >     As such this is not something that a node\n> >     can just dismiss.\n> >\n> > The security of many parts of the system is based on hash collisions not\n> > being possible.\n>\n> This is not the case.\n>\n> Block hash duplicates within the same chain are invalid as a matter of\n> consensus, which is the opposite of assuming impossibility.\n>\n> Tx hash collisions are explicitly allowed in the case that preceding tx\n> with the same hash is unspent. This is also not a reliance on the\n> impossibility of hash collision. Core certainly implements this\n> distinction:\n>\n> https://github.com/bitcoin/bitcoin/blob/master/src/main.cpp#L2419-L2426\n>\n> Address hashes and script hashes can collide without harming the\n> security of Bitcoin (although address owner(s) may experience harm).\n> Rare in this case is sufficient because of this distinction.\n>\n> Compact blocks contemplates hash collisions:\n>\n> https://github.com/bitcoin/bips/blob/master/bip-0152.\n> mediawiki#Random_collision_probabilty\n>\n> Checkpoints aren't part of Bitcoin security, so even the remote\n> possibility of two different potential blocks, with the same hash, at\n> the same height in the same chain, does not indicate a problem.\n>\n> There is no case where the security of Bitcoin assumes that hashes never\n> collide. Consensus rules have specific handling for both block hash\n> collisions and tx hash collisions.\n>\n> e\n>\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161117/dc2d9d3c/attachment-0001.html>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-17T12:22:09",
                "message_text_only": "On 11/17/2016 03:38 AM, Alex Morcos wrote:\n> I think this conversation has gone off the rails and is no longer really\n> appropriate for the list.\n\nIf this discussion is not appropriate for the Bitcoin Protocol\nDiscussion list then the list is pointless.\n\n> But just to be clear to any readers.  Bitcoin Core absolutely does rely\n> on the impossibility of a hash collision for maintaining consensus. \n> This happens in multiple places in the code but in particular we don't\n> check BIP30 any more since the only way it could get violated is by a\n> hash collision.\n\nSo the protocol change that I suggested to Peter an hour or so ago was\nactually implemented, a year ago, by you:\n\nhttps://github.com/bitcoin/bitcoin/commit/06d81ad516f1d136da9f03ca2ae823211c0f6988\n\nGiven that hash collisions are unquestionably possible, this is a clear\nbreak with BIP30 (irrespective of BIP34) and constitutes a hard fork. Is\nthere going to be a retroactive BIP for this one at some point as well?\n\nI'm aware that the block hash check is performed against the full chain,\nas opposed to the candidate block fork height, and as a result is\ninsufficient to guard against a block hash collision causing a chain\nsplit (though until now I assumed this was a bug).\n\nWould you care to share the other consensus critical reliances on the\nimpossibility of hash collision that you are implying?\n\ne\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161117/6edc184a/attachment.sig>"
            },
            {
                "author": "Johnson Lau",
                "date": "2016-11-17T15:40:05",
                "message_text_only": "> On 17 Nov 2016, at 20:22, Eric Voskuil via bitcoin-dev <bitcoin-dev at lists.linuxfoundation.org> wrote:\n> \n> \n> Given that hash collisions are unquestionably possible, \n\nEverything you said after this point is irrelevant.\n\nHaving hash collision is **by definition** a consensus failure, or a hardfork. You could replace the already-on-chain tx with the collision and create 2 different versions of UTXOs (if the colliding tx is valid), or make some nodes to accept a fork with less PoW (if the colliding tx is invalid, or making the block invalid, such as being to big). To put it simply, the Bitcoin protocol is broken. So with no doubt, Bitcoin Core and any implementation of the Bitcoin protocol should assume SHA256 collision is unquestionably **impossible**. If some refuse to make such assumption, they should have introduced an alternative hash algorithm and somehow run it in parallel with SHA256 to prevent the consensus failure.\n\njl2012"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-17T17:01:20",
                "message_text_only": "On 11/17/2016 07:40 AM, Johnson Lau wrote:\n>\n>> On 17 Nov 2016, at 20:22, Eric Voskuil via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>\n>> Given that hash collisions are unquestionably possible,\n>\n> Everything you said after this point is irrelevant.\n\nSo... you think hash collisions are not possible, or that it's moot\nbecause Core has broken its ability to handle them.\n\n\n> Having hash collision is **by definition** a consensus failure,\n\nI suppose if you take fairly recent un-BIPped consensus changes in Core\nto be the definition of consensus, you would be right about that.\n\n\n> or a hardfork.\n\nAnd those changes could definitely result in a chain split. So right\nabout that too.\n\n\n> You could replace the already-on-chain tx with the collision and\ncreate 2 different versions of UTXOs (if the colliding tx is valid), or\nmake some nodes to accept a fork with less PoW (if the colliding tx is\ninvalid, or making the block invalid, such as being to big).\n\n\nNot in accordance with BIP30 and not according to the implementation of\nit that existed in Core until Nov 2015. A tx was only valid as a\n\"replacement\" if it did not collide with the hash of an existing tx with\nunspent outputs. The collision would have been rejected. And an invalid\ncolliding tx would not be accepted in any case (since nodes presumably\nvalidate blocks and don't rely on checkpoints as a security measure).\n\nA transaction duplicating the hash of another and taking its place in a\nblock would not only have to collide the hash, but it would have to be\nfully valid in the context of the block you are suggesting it is\nsubstituted into. In that case it's simply a fully valid block. This is\nnot just the case of a hash collision, this is the case of a hash\ncollision where both transactions are fully valid in the context of the\nsame block parent. Even if that unlikely event did occur, it's not a\nhard fork, it's a reorg. The chain that builds on this block will be\nvalid to all nodes but necessarily deviates from the other block's valid\nchain. This is true whether the magical block is assembled via compact\nblocks or otherwise.\n\nTransaction \"replacement\" is an implementation detail of Core. Once Core\naccepted a replacement of a previously spent transaction it would be\nunable to provide the previous block/spent-tx, but that would be a\nwallet failure and an inability to provide valid historical blocks, not\na consensus/validation failure. The previously spent outputs no longer\ncontribute to validation, unless there is a reorg back to before the\noriginal tx's block, and at that point it would be moot, since neither\ntransaction is on the chain.\n\nYou are referring to the *current* behavior (\"replacement\" without\nconcern for collision). That was an unpublished hard fork, and is the\nvery source of the problems you are describing.\n\n> To put it simply, the Bitcoin protocol is broken. So with no doubt,\nBitcoin Core and any implementation of the Bitcoin protocol should\nassume SHA256 collision is unquestionably **impossible**.\n\nI'm not disagreeing with you that it is broken. I'm pointing out that it\nwas broken by code that was merged recently - an undocumented hard fork\nthat reverted the documented BIP30 behavior that was previously\nimplemented correctly, based on the assumption that hash collisions\ncannot occur, for the modest performance boost of not having to check\nfor unspent duplicates (sounds sort of familiar).\n\n> If some refuse to make such assumption, they should have introduced an\nalternative hash algorithm and somehow run it in parallel with SHA256 to\nprevent the consensus failure.\n\nNo hash algorithm can prevent hash collisions, including one that is\njust two running in parallel. A better resolution would be to fix the\nproblem.\n\nThere is no need to replace the BIP30 rule. That resolves the TX hash\ncollision problem from a consensus standpoint. In order to serve up\nwhole blocks in the circumstance requires a more robust store than I\nbelieve is exists in Core, but that has nothing to do with validity.\n\nThe block hash check and signature validation caching splits caused by\ncollision can easily be avoided, and doing so doesn't break with\nconsensus. I'm not aware of any other aspects of consensus that are\neffected by an implementation assumption of non-colliding hashes. But in\nany case I'm pretty sure there aren't any that are necessary to consensus.\n\ne\n\n\n-------------- next part --------------\nA non-text attachment was scrubbed...\nName: signature.asc\nType: application/pgp-signature\nSize: 490 bytes\nDesc: OpenPGP digital signature\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161117/755dc7aa/attachment.sig>"
            },
            {
                "author": "Johnson Lau",
                "date": "2016-11-17T17:22:56",
                "message_text_only": "I\u2019m not sure if you really understand what you and I am talking. It has nothing to do with BIP30, 34, nor any other BIPs.\n\nSay tx1 is confirmed 3 years ago in block X. An attacker finds a valid tx2 which (tx1 != tx2) and (SHA256(tx1) == SHA256(tx2)). Now he could replace tx1 with tx2 in block X and the block is still perfectly valid. Anyone trying to download the blockchain from the beginning may end up with a different ledger. The consensus is irrevocably broken as soon as tx1 or tx2 is spent.\n\nOr, alternatively, an attacker finds an invalid tx3 which (tx1 != tx3) and (SHA256(tx1) == SHA256(tx3)). Now he could replace tx1 with tx3 in block X. Anyone trying to download the blockchain from the beginning will permanently reject the hash of block X. They will instead accept a fork built on top of block X-1. The chain will be permanently forked.\n\njl2012\n\n\n> On 18 Nov 2016, at 01:01, Eric Voskuil <eric at voskuil.org> wrote:\n> \n> On 11/17/2016 07:40 AM, Johnson Lau wrote:\n>> \n>>> On 17 Nov 2016, at 20:22, Eric Voskuil via bitcoin-dev\n> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>> \n>>> Given that hash collisions are unquestionably possible,\n>> \n>> Everything you said after this point is irrelevant.\n> \n> So... you think hash collisions are not possible, or that it's moot\n> because Core has broken its ability to handle them.\n> \n> \n>> Having hash collision is **by definition** a consensus failure,\n> \n> I suppose if you take fairly recent un-BIPped consensus changes in Core\n> to be the definition of consensus, you would be right about that.\n> \n> \n>> or a hardfork.\n> \n> And those changes could definitely result in a chain split. So right\n> about that too.\n> \n> \n>> You could replace the already-on-chain tx with the collision and\n> create 2 different versions of UTXOs (if the colliding tx is valid), or\n> make some nodes to accept a fork with less PoW (if the colliding tx is\n> invalid, or making the block invalid, such as being to big).\n> \n> \n> Not in accordance with BIP30 and not according to the implementation of\n> it that existed in Core until Nov 2015. A tx was only valid as a\n> \"replacement\" if it did not collide with the hash of an existing tx with\n> unspent outputs. The collision would have been rejected. And an invalid\n> colliding tx would not be accepted in any case (since nodes presumably\n> validate blocks and don't rely on checkpoints as a security measure).\n> \n> A transaction duplicating the hash of another and taking its place in a\n> block would not only have to collide the hash, but it would have to be\n> fully valid in the context of the block you are suggesting it is\n> substituted into. In that case it's simply a fully valid block. This is\n> not just the case of a hash collision, this is the case of a hash\n> collision where both transactions are fully valid in the context of the\n> same block parent. Even if that unlikely event did occur, it's not a\n> hard fork, it's a reorg. The chain that builds on this block will be\n> valid to all nodes but necessarily deviates from the other block's valid\n> chain. This is true whether the magical block is assembled via compact\n> blocks or otherwise.\n> \n> Transaction \"replacement\" is an implementation detail of Core. Once Core\n> accepted a replacement of a previously spent transaction it would be\n> unable to provide the previous block/spent-tx, but that would be a\n> wallet failure and an inability to provide valid historical blocks, not\n> a consensus/validation failure. The previously spent outputs no longer\n> contribute to validation, unless there is a reorg back to before the\n> original tx's block, and at that point it would be moot, since neither\n> transaction is on the chain.\n> \n> You are referring to the *current* behavior (\"replacement\" without\n> concern for collision). That was an unpublished hard fork, and is the\n> very source of the problems you are describing.\n> \n>> To put it simply, the Bitcoin protocol is broken. So with no doubt,\n> Bitcoin Core and any implementation of the Bitcoin protocol should\n> assume SHA256 collision is unquestionably **impossible**.\n> \n> I'm not disagreeing with you that it is broken. I'm pointing out that it\n> was broken by code that was merged recently - an undocumented hard fork\n> that reverted the documented BIP30 behavior that was previously\n> implemented correctly, based on the assumption that hash collisions\n> cannot occur, for the modest performance boost of not having to check\n> for unspent duplicates (sounds sort of familiar).\n> \n>> If some refuse to make such assumption, they should have introduced an\n> alternative hash algorithm and somehow run it in parallel with SHA256 to\n> prevent the consensus failure.\n> \n> No hash algorithm can prevent hash collisions, including one that is\n> just two running in parallel. A better resolution would be to fix the\n> problem.\n> \n> There is no need to replace the BIP30 rule. That resolves the TX hash\n> collision problem from a consensus standpoint. In order to serve up\n> whole blocks in the circumstance requires a more robust store than I\n> believe is exists in Core, but that has nothing to do with validity.\n> \n> The block hash check and signature validation caching splits caused by\n> collision can easily be avoided, and doing so doesn't break with\n> consensus. I'm not aware of any other aspects of consensus that are\n> effected by an implementation assumption of non-colliding hashes. But in\n> any case I'm pretty sure there aren't any that are necessary to consensus.\n> \n> e\n> \n>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-17T17:49:45",
                "message_text_only": "Actually both possibilities were specifically covered in my description. Sorry if it wasn't clear.\n\nIf you create a new valid block out of an old one it's has potential to cause a reorg. The blocks that previously built on the original are still able to do so but presumably cannot build forever on the *new* block as it has a different tx. But other new blocks can. There is no chain split due to a different interpretation of valid, there are simply two valid competing chains.\n\nNote that this scenario requires not only block and tx validity with a tx hash collision, but also that the tx be valid within the block. Pretty far to reach to not even get a chain split, but it could produce a deep reorg with a very low chance of success. As I keep telling people, deep reorgs can happen, they are just unlikely, as is this scenario.\n\nIf you create a new invalid block it is discarded by everyone. That does not invalidate the hash of that block. Permanent blocking as you describe it would be a p2p protocol design choice, having nothing to do with consensus. Libbitcoin for example does not ban invalidated hashes at all. It just discards the block and drops the peer.\n\ne\n\n> On Nov 17, 2016, at 9:22 AM, Johnson Lau <jl2012 at xbt.hk> wrote:\n> \n> I\u2019m not sure if you really understand what you and I am talking. It has nothing to do with BIP30, 34, nor any other BIPs.\n> \n> Say tx1 is confirmed 3 years ago in block X. An attacker finds a valid tx2 which (tx1 != tx2) and (SHA256(tx1) == SHA256(tx2)). Now he could replace tx1 with tx2 in block X and the block is still perfectly valid. Anyone trying to download the blockchain from the beginning may end up with a different ledger. The consensus is irrevocably broken as soon as tx1 or tx2 is spent.\n> \n> Or, alternatively, an attacker finds an invalid tx3 which (tx1 != tx3) and (SHA256(tx1) == SHA256(tx3)). Now he could replace tx1 with tx3 in block X. Anyone trying to download the blockchain from the beginning will permanently reject the hash of block X. They will instead accept a fork built on top of block X-1. The chain will be permanently forked.\n> \n> jl2012\n> \n> \n>> On 18 Nov 2016, at 01:01, Eric Voskuil <eric at voskuil.org> wrote:\n>> \n>> On 11/17/2016 07:40 AM, Johnson Lau wrote:\n>>> \n>>>> On 17 Nov 2016, at 20:22, Eric Voskuil via bitcoin-dev\n>> <bitcoin-dev at lists.linuxfoundation.org> wrote:\n>>>> \n>>>> Given that hash collisions are unquestionably possible,\n>>> \n>>> Everything you said after this point is irrelevant.\n>> \n>> So... you think hash collisions are not possible, or that it's moot\n>> because Core has broken its ability to handle them.\n>> \n>> \n>>> Having hash collision is **by definition** a consensus failure,\n>> \n>> I suppose if you take fairly recent un-BIPped consensus changes in Core\n>> to be the definition of consensus, you would be right about that.\n>> \n>> \n>>> or a hardfork.\n>> \n>> And those changes could definitely result in a chain split. So right\n>> about that too.\n>> \n>> \n>>> You could replace the already-on-chain tx with the collision and\n>> create 2 different versions of UTXOs (if the colliding tx is valid), or\n>> make some nodes to accept a fork with less PoW (if the colliding tx is\n>> invalid, or making the block invalid, such as being to big).\n>> \n>> \n>> Not in accordance with BIP30 and not according to the implementation of\n>> it that existed in Core until Nov 2015. A tx was only valid as a\n>> \"replacement\" if it did not collide with the hash of an existing tx with\n>> unspent outputs. The collision would have been rejected. And an invalid\n>> colliding tx would not be accepted in any case (since nodes presumably\n>> validate blocks and don't rely on checkpoints as a security measure).\n>> \n>> A transaction duplicating the hash of another and taking its place in a\n>> block would not only have to collide the hash, but it would have to be\n>> fully valid in the context of the block you are suggesting it is\n>> substituted into. In that case it's simply a fully valid block. This is\n>> not just the case of a hash collision, this is the case of a hash\n>> collision where both transactions are fully valid in the context of the\n>> same block parent. Even if that unlikely event did occur, it's not a\n>> hard fork, it's a reorg. The chain that builds on this block will be\n>> valid to all nodes but necessarily deviates from the other block's valid\n>> chain. This is true whether the magical block is assembled via compact\n>> blocks or otherwise.\n>> \n>> Transaction \"replacement\" is an implementation detail of Core. Once Core\n>> accepted a replacement of a previously spent transaction it would be\n>> unable to provide the previous block/spent-tx, but that would be a\n>> wallet failure and an inability to provide valid historical blocks, not\n>> a consensus/validation failure. The previously spent outputs no longer\n>> contribute to validation, unless there is a reorg back to before the\n>> original tx's block, and at that point it would be moot, since neither\n>> transaction is on the chain.\n>> \n>> You are referring to the *current* behavior (\"replacement\" without\n>> concern for collision). That was an unpublished hard fork, and is the\n>> very source of the problems you are describing.\n>> \n>>> To put it simply, the Bitcoin protocol is broken. So with no doubt,\n>> Bitcoin Core and any implementation of the Bitcoin protocol should\n>> assume SHA256 collision is unquestionably **impossible**.\n>> \n>> I'm not disagreeing with you that it is broken. I'm pointing out that it\n>> was broken by code that was merged recently - an undocumented hard fork\n>> that reverted the documented BIP30 behavior that was previously\n>> implemented correctly, based on the assumption that hash collisions\n>> cannot occur, for the modest performance boost of not having to check\n>> for unspent duplicates (sounds sort of familiar).\n>> \n>>> If some refuse to make such assumption, they should have introduced an\n>> alternative hash algorithm and somehow run it in parallel with SHA256 to\n>> prevent the consensus failure.\n>> \n>> No hash algorithm can prevent hash collisions, including one that is\n>> just two running in parallel. A better resolution would be to fix the\n>> problem.\n>> \n>> There is no need to replace the BIP30 rule. That resolves the TX hash\n>> collision problem from a consensus standpoint. In order to serve up\n>> whole blocks in the circumstance requires a more robust store than I\n>> believe is exists in Core, but that has nothing to do with validity.\n>> \n>> The block hash check and signature validation caching splits caused by\n>> collision can easily be avoided, and doing so doesn't break with\n>> consensus. I'm not aware of any other aspects of consensus that are\n>> effected by an implementation assumption of non-colliding hashes. But in\n>> any case I'm pretty sure there aren't any that are necessary to consensus.\n>> \n>> e\n> \n>"
            },
            {
                "author": "Johnson Lau",
                "date": "2016-11-17T18:08:09",
                "message_text_only": "The fact that some implementations ban an invalid block hash and some do not, suggests that it\u2019s not a pure p2p protocol issue. A pure p2p split should be unified by a bridge node. However, a bridge node is not helpful in this case. Banning an invalid block hash is an implicit \u201cfirst seen\u201d consensus rule.\n\njl2012\n\n> On 18 Nov 2016, at 01:49, Eric Voskuil <eric at voskuil.org> wrote:\n> \n> Actually both possibilities were specifically covered in my description. Sorry if it wasn't clear.\n> \n> If you create a new valid block out of an old one it's has potential to cause a reorg. The blocks that previously built on the original are still able to do so but presumably cannot build forever on the *new* block as it has a different tx. But other new blocks can. There is no chain split due to a different interpretation of valid, there are simply two valid competing chains.\n> \n> Note that this scenario requires not only block and tx validity with a tx hash collision, but also that the tx be valid within the block. Pretty far to reach to not even get a chain split, but it could produce a deep reorg with a very low chance of success. As I keep telling people, deep reorgs can happen, they are just unlikely, as is this scenario.\n> \n> If you create a new invalid block it is discarded by everyone. That does not invalidate the hash of that block. Permanent blocking as you describe it would be a p2p protocol design choice, having nothing to do with consensus. Libbitcoin for example does not ban invalidated hashes at all. It just discards the block and drops the peer.\n> \n> e"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-18T03:20:52",
                "message_text_only": "You are suggesting that, since a node implements a denial of service policy that actually denies itself otherwise valid blocks, those blocks are conditionally invalid. And that, since the validity condition is based on order of arrival and therefore independently unverifiable, Bitcoin consensus is broken in the face of a hash collision.\n\nI am aware of two other hash collision scenarios that cause Core to declare blocks invalid based on ordering. The block hash duplicate check (it's not fork-point relative) and signature verification caching. Like the \"block banning\" issue above, the latter is related to an internal optimization. I would categorize the former as a simple oversight that presumably goes way back.\n\nWhat then is the consequence of validity that is unverifiable? You believe this means that Bitcoin consensus is broken. This is incorrect. First understand that it is not possible for consensus rules to invalidate blocks based on order of arrival. As such any *implementation* that invalidates blocks based on order of arrival is broken. It is an error to claim that these behaviors are part of consensus, despite being implemented in the satoshi node(s).\n\nValidity must be verifiable independent of the state of other nodes. Consensus is a function of block history and time alone. Time is presumed to be universally consistent. To be a consensus rule all nodes must be able to independently reach the same validity conclusion, given the same set of blocks, independent of order. If this is not the case the behavior is not a consensus rule, it is simply a bug. \n\nDeviating from such bugs is not a break with consensus, since such non-rules cannot be part of consensus. One node implementation can behave deterministically while others are behaving non-deterministically, with the two nodes remaining consistent from a consensus standpoint (deterministic produces a subset of non-deterministic results). But, unlike arbitrary nodes, deterministic nodes will not cause disruption on the network.\n\nYou imply that these determinism bugs are necessary, that there is no fix. This is also incorrect.\n\nThe block banning hash collision bug is avoided by not using non-chain/clock state to determine validity. Doing otherwise is clearly a bug. The hash of a block is not the block itself, a logically-correct ban would be to compare the wire serialization of the block as opposed to the hash, or not maintain the feature at all.\n\nThe signature verification caching hash collision bug is the same problem, an optimization based on an invalid assumption. A full serialization comparison (true identity), or elimination of the feature resolves the  bug.\n\nThe block hash check collision bug is trivially resolved by checking at the fork point as opposed to the tip. This prevents arbitrary (and irrational) invalidity based on conflict with irrelevant blocks that may or may not exist above the fork point.\n\nLibbitcoin is deterministic in all three cases (although the third issue is not made consistent until v3). I am not aware of any other non-determinism in Core, but I don't spend a lot of time there. There is no need to study other implementations to ensure determinism, as that can be verified independently.\n\nAny situation in which a node cannot provide deterministic validation of unordered blocks constitutes a non-consensus bug, as the behavior is not consistently verifiable by others under any conditions. Fixing/preventing these bugs is responsible development behavior, and does not require forks or BIPs, since Bitcoin doesn't inherently contain any such bugs. They are the consequence of incorrect implementation, and in two of the three cases above have resulted from supposed optimizations. But any code that creates non-determinism in exchange for speed, etc. is not an optimization, it's a bug. A node must implement its optimizations in a manner that does not alter consensus.\n\nThe BIP30 regression hard fork is not a case of non-determinism. This will produce deterministic results (apart from the impact of unrelated bugs). However the results are both a clear break from previous (and documented) consensus but also produce a very undesirable outcome - destruction of all unspent outputs in the \"replaced\" transaction for starters. So this is a distinct category, not a determinism bug but a hard fork that produces undesired consequences.\n\nThe BIP30 regression hard fork actually enables the various pathological scenarios that you were describing, where no such issues existed in Bitcoin consensus previously. It is now possible to produce a block that mutates another arbitrarily deep block, and forces a reorg all the way back to the mutated block. This was done to save microseconds per block. Despite the improbability of hash collisions, I find this deplorable and the lack of public discussion on the decision concerning.\n\nWith respect to the original post, the point at issue is the introduction of another hard fork, with some odd behaviors, but without any justification apart from tidying up the small amount of necessary code. These issues are related in that they are both consensus forks that have been introduced as supposed optimizations, with no public discussion prior to release (or at least merging to master with the presumption of shipping in the latter case). Two of the three hash collision issues above are also related in that they are bugs introduced by a desire to optimize internals.\n\nThe engineering lesson here should be clear - watch out for developers bearing optimizations. A trade against correctness is not an optimization, it's a break. Satoshi was clearly a fan of the premature optimization. FindAndDelete is a howler. So this is a tradition in Bitcoin. My intent is not to sling mud but to improve the situation.\n\nIt is very possible to produce straightforward and deterministic code that abides consensus and materially outperforms Core, without any of the above optimization breaks, even avoiding the utxo set optimization. Even the tx (memory) and block (orphan) pools are complex store denormalizations implemented as optimizations. Optimizing before producing a clean conceptual model architecture and design is a software development anti-pattern (premature optimization). The proposed fork is a premature optimization. There are much more significant opportunities to better organize code (and improve performance). I cannot support the decision to advance it.\n\nI was unaware Core had regressed BIP30. Given that the behavior is catastrophic and that it introduces the *only* hash-collision consensus misbehavior (unless we consider a deep reorg sans the otherwise necessary proof of work desirable behavior), I strongly recommend it be reverted, with a post-mortem BIP.\n\nFinally I recommend people contemplate the difference between unlikely and impossible. The chance of random collision is very small, but not zero. Colliding hashes is extremely difficult, but not impossible. But Bitcoin does not rely on impossibility for correct behavior. It relies of difficulty. This is a subtle but important distinction that people are missing.\n\nDifficulty is a knowable quantity - a function of computing power.  If hash operations remain difficult, Bitcoin is undeterred. Collisions will have no impact, even if they happen with unexpected frequency (which would still be vanishingly infrequent). If the difficulty of producing a collision is reduced to the point where people cannot rely on addresses (for example), then Bitcoin has a problem, as it has become a leaky ship (and then there's mining). But with the unnecessary problems described above, a single hash collision can be catastrophic. Unlike difficulty, which is known, nobody can know when a single collision will show up. Betting Bitcoin, and potentially the world's money, on the unknowable is poor reasoning, especially given that the cost of not doing so is so very low.\n\ne\n\n> On Nov 17, 2016, at 10:08 AM, Johnson Lau <jl2012 at xbt.hk> wrote:\n> \n> The fact that some implementations ban an invalid block hash and some do not, suggests that it\u2019s not a pure p2p protocol issue. A pure p2p split should be unified by a bridge node. However, a bridge node is not helpful in this case. Banning an invalid block hash is an implicit \u201cfirst seen\u201d consensus rule.\n> \n> jl2012\n> \n>> On 18 Nov 2016, at 01:49, Eric Voskuil <eric at voskuil.org> wrote:\n>> \n>> Actually both possibilities were specifically covered in my description. Sorry if it wasn't clear.\n>> \n>> If you create a new valid block out of an old one it's has potential to cause a reorg. The blocks that previously built on the original are still able to do so but presumably cannot build forever on the *new* block as it has a different tx. But other new blocks can. There is no chain split due to a different interpretation of valid, there are simply two valid competing chains.\n>> \n>> Note that this scenario requires not only block and tx validity with a tx hash collision, but also that the tx be valid within the block. Pretty far to reach to not even get a chain split, but it could produce a deep reorg with a very low chance of success. As I keep telling people, deep reorgs can happen, they are just unlikely, as is this scenario.\n>> \n>> If you create a new invalid block it is discarded by everyone. That does not invalidate the hash of that block. Permanent blocking as you describe it would be a p2p protocol design choice, having nothing to do with consensus. Libbitcoin for example does not ban invalidated hashes at all. It just discards the block and drops the peer.\n>> \n>> e\n> \n>"
            },
            {
                "author": "Johnson Lau",
                "date": "2016-11-18T14:43:03",
                "message_text_only": "In this case I don\u2019t understand how your implementation won\u2019t be DoS-ed. An attacker could keep sending you inv for the same block / transaction. Since you don\u2019t assume the hash is unique, each time you have to download the block/tx again before you could tell if that is the same one you have already known. Otherwise, you are implementing the \u201cfirst seen\u201d rule.\n\nAlso, you can\u2019t ban a peer just because you get an invalid tx from him, because he might be referring to a hash-colliding UTXO that you don\u2019t know. In that case you need to request for the parent tx to verify. I wonder if you are really doing that.\n\n> On 18 Nov 2016, at 11:20, Eric Voskuil <eric at voskuil.org> wrote:\n> \n> You are suggesting that, since a node implements a denial of service policy that actually denies itself otherwise valid blocks, those blocks are conditionally invalid. And that, since the validity condition is based on order of arrival and therefore independently unverifiable, Bitcoin consensus is broken in the face of a hash collision.\n> \n> I am aware of two other hash collision scenarios that cause Core to declare blocks invalid based on ordering. The block hash duplicate check (it's not fork-point relative) and signature verification caching. Like the \"block banning\" issue above, the latter is related to an internal optimization. I would categorize the former as a simple oversight that presumably goes way back.\n> \n> What then is the consequence of validity that is unverifiable? You believe this means that Bitcoin consensus is broken. This is incorrect. First understand that it is not possible for consensus rules to invalidate blocks based on order of arrival. As such any *implementation* that invalidates blocks based on order of arrival is broken. It is an error to claim that these behaviors are part of consensus, despite being implemented in the satoshi node(s).\n> \n> Validity must be verifiable independent of the state of other nodes. Consensus is a function of block history and time alone. Time is presumed to be universally consistent. To be a consensus rule all nodes must be able to independently reach the same validity conclusion, given the same set of blocks, independent of order. If this is not the case the behavior is not a consensus rule, it is simply a bug. \n> \n> Deviating from such bugs is not a break with consensus, since such non-rules cannot be part of consensus. One node implementation can behave deterministically while others are behaving non-deterministically, with the two nodes remaining consistent from a consensus standpoint (deterministic produces a subset of non-deterministic results). But, unlike arbitrary nodes, deterministic nodes will not cause disruption on the network.\n> \n> You imply that these determinism bugs are necessary, that there is no fix. This is also incorrect.\n> \n> The block banning hash collision bug is avoided by not using non-chain/clock state to determine validity. Doing otherwise is clearly a bug. The hash of a block is not the block itself, a logically-correct ban would be to compare the wire serialization of the block as opposed to the hash, or not maintain the feature at all.\n> \n> The signature verification caching hash collision bug is the same problem, an optimization based on an invalid assumption. A full serialization comparison (true identity), or elimination of the feature resolves the  bug.\n> \n> The block hash check collision bug is trivially resolved by checking at the fork point as opposed to the tip. This prevents arbitrary (and irrational) invalidity based on conflict with irrelevant blocks that may or may not exist above the fork point.\n> \n> Libbitcoin is deterministic in all three cases (although the third issue is not made consistent until v3). I am not aware of any other non-determinism in Core, but I don't spend a lot of time there. There is no need to study other implementations to ensure determinism, as that can be verified independently.\n> \n> Any situation in which a node cannot provide deterministic validation of unordered blocks constitutes a non-consensus bug, as the behavior is not consistently verifiable by others under any conditions. Fixing/preventing these bugs is responsible development behavior, and does not require forks or BIPs, since Bitcoin doesn't inherently contain any such bugs. They are the consequence of incorrect implementation, and in two of the three cases above have resulted from supposed optimizations. But any code that creates non-determinism in exchange for speed, etc. is not an optimization, it's a bug. A node must implement its optimizations in a manner that does not alter consensus.\n> \n> The BIP30 regression hard fork is not a case of non-determinism. This will produce deterministic results (apart from the impact of unrelated bugs). However the results are both a clear break from previous (and documented) consensus but also produce a very undesirable outcome - destruction of all unspent outputs in the \"replaced\" transaction for starters. So this is a distinct category, not a determinism bug but a hard fork that produces undesired consequences.\n> \n> The BIP30 regression hard fork actually enables the various pathological scenarios that you were describing, where no such issues existed in Bitcoin consensus previously. It is now possible to produce a block that mutates another arbitrarily deep block, and forces a reorg all the way back to the mutated block. This was done to save microseconds per block. Despite the improbability of hash collisions, I find this deplorable and the lack of public discussion on the decision concerning.\n> \n> With respect to the original post, the point at issue is the introduction of another hard fork, with some odd behaviors, but without any justification apart from tidying up the small amount of necessary code. These issues are related in that they are both consensus forks that have been introduced as supposed optimizations, with no public discussion prior to release (or at least merging to master with the presumption of shipping in the latter case). Two of the three hash collision issues above are also related in that they are bugs introduced by a desire to optimize internals.\n> \n> The engineering lesson here should be clear - watch out for developers bearing optimizations. A trade against correctness is not an optimization, it's a break. Satoshi was clearly a fan of the premature optimization. FindAndDelete is a howler. So this is a tradition in Bitcoin. My intent is not to sling mud but to improve the situation.\n> \n> It is very possible to produce straightforward and deterministic code that abides consensus and materially outperforms Core, without any of the above optimization breaks, even avoiding the utxo set optimization. Even the tx (memory) and block (orphan) pools are complex store denormalizations implemented as optimizations. Optimizing before producing a clean conceptual model architecture and design is a software development anti-pattern (premature optimization). The proposed fork is a premature optimization. There are much more significant opportunities to better organize code (and improve performance). I cannot support the decision to advance it.\n> \n> I was unaware Core had regressed BIP30. Given that the behavior is catastrophic and that it introduces the *only* hash-collision consensus misbehavior (unless we consider a deep reorg sans the otherwise necessary proof of work desirable behavior), I strongly recommend it be reverted, with a post-mortem BIP.\n> \n> Finally I recommend people contemplate the difference between unlikely and impossible. The chance of random collision is very small, but not zero. Colliding hashes is extremely difficult, but not impossible. But Bitcoin does not rely on impossibility for correct behavior. It relies of difficulty. This is a subtle but important distinction that people are missing.\n> \n> Difficulty is a knowable quantity - a function of computing power.  If hash operations remain difficult, Bitcoin is undeterred. Collisions will have no impact, even if they happen with unexpected frequency (which would still be vanishingly infrequent). If the difficulty of producing a collision is reduced to the point where people cannot rely on addresses (for example), then Bitcoin has a problem, as it has become a leaky ship (and then there's mining). But with the unnecessary problems described above, a single hash collision can be catastrophic. Unlike difficulty, which is known, nobody can know when a single collision will show up. Betting Bitcoin, and potentially the world's money, on the unknowable is poor reasoning, especially given that the cost of not doing so is so very low.\n> \n> e\n> \n>> On Nov 17, 2016, at 10:08 AM, Johnson Lau <jl2012 at xbt.hk> wrote:\n>> \n>> The fact that some implementations ban an invalid block hash and some do not, suggests that it\u2019s not a pure p2p protocol issue. A pure p2p split should be unified by a bridge node. However, a bridge node is not helpful in this case. Banning an invalid block hash is an implicit \u201cfirst seen\u201d consensus rule.\n>> \n>> jl2012\n>> \n>>> On 18 Nov 2016, at 01:49, Eric Voskuil <eric at voskuil.org> wrote:\n>>> \n>>> Actually both possibilities were specifically covered in my description. Sorry if it wasn't clear.\n>>> \n>>> If you create a new valid block out of an old one it's has potential to cause a reorg. The blocks that previously built on the original are still able to do so but presumably cannot build forever on the *new* block as it has a different tx. But other new blocks can. There is no chain split due to a different interpretation of valid, there are simply two valid competing chains.\n>>> \n>>> Note that this scenario requires not only block and tx validity with a tx hash collision, but also that the tx be valid within the block. Pretty far to reach to not even get a chain split, but it could produce a deep reorg with a very low chance of success. As I keep telling people, deep reorgs can happen, they are just unlikely, as is this scenario.\n>>> \n>>> If you create a new invalid block it is discarded by everyone. That does not invalidate the hash of that block. Permanent blocking as you describe it would be a p2p protocol design choice, having nothing to do with consensus. Libbitcoin for example does not ban invalidated hashes at all. It just discards the block and drops the peer.\n>>> \n>>> e\n>> \n>>"
            },
            {
                "author": "Eric Voskuil",
                "date": "2016-11-18T16:47:09",
                "message_text_only": "What is the difference between downloading a hash and comparing it to a hash vs downloading a hash and then a block and comparing it to a block?\n\nYou are talking about breaking a system in order to make it run faster. Using the hash is an non-optimization trade against correctness.\n\nThere is no \"first seen\" rule, there is only valid and invalid. Even the name exposes the error of this thinking as \"first\" requires order.\n\nCaching invalidity for DOS protection is fine. It should be quite obvious that the blockchain is nothing more than a coach of validity. If it's faster in some cases to store both validity and all invalidity that you are aware of it is fine, you are trading space for time.\n\nBut caching information that is neither validity nor invalidity, and using it to validate blocks is a break.\n\nI cannot emphasize this point enough. A technique that provides varied results based on communication history, such as this \"rule\", is an attack vector. It allows the attacker to place information into your cache and read it back later from another connection. Even optimizing correct results based on communication history exposes the node in this manner. These sort of attacks have been shown to be very effective at deanonymizing hidden nodes.\n\nThe p2p protocol actually makes this sort of attack a matter of communication standard via the sharing of address information, but this can be disabled without impacting correctness. Due to such non-optimizations as the first seen \"rule\" however, a node becomes a candy store of fingerprinting attack vectors.\n\nBitcoin provides the mechanism to reject cheaply-produced invalid blocks quickly. This is after all the fundamental principle of hash cash - force the attacker to pay to spam attack. By obtaining headers first a node can obtain proof of work and perform correct and fast validation before ever obtaining the block's transactions. This technique is probably no more time-costly than the incorrect technique of checking a cache of hashes (ironically, a \"hash cache\" is an incorrect \"hash cash\"), and avoids the extra space of a secondary cache (the blockchain is the primary cache). It also avoids the varied time response that a secondary cache creates.\n\nSo once again, premature optimization erupts from the underlying design flaw, and creates more problems than proper design. The p2p network standard didn't have headers first at one point, making correct checks more costly. That is no longer the case. But nevertheless, one cannot trade correctness for time.\n\nThe tx pool, like the orphan pool, as I mentioned previously, is an optimization. It is not a part of consensus, so it isn't relevant to a discussion about forks. It is also a design flaw that nodes are expected to hold invalid transactions. It exposes nodes to both DOS and fingerprinting attacks. Proper tx handling implies that a tx connect to a valid block. There is no \"header\" for a transaction so correctness requires that the tx be downloaded before it can be validated.\n\ne\n\n> On Nov 18, 2016, at 8:43 AM, Johnson Lau <jl2012 at xbt.hk> wrote:\n> \n> In this case I don\u2019t understand how your implementation won\u2019t be DoS-ed. An attacker could keep sending you inv for the same block / transaction. Since you don\u2019t assume the hash is unique, each time you have to download the block/tx again before you could tell if that is the same one you have already known. Otherwise, you are implementing the \u201cfirst seen\u201d rule.\n> \n> Also, you can\u2019t ban a peer just because you get an invalid tx from him, because he might be referring to a hash-colliding UTXO that you don\u2019t know. In that case you need to request for the parent tx to verify. I wonder if you are really doing that.\n> \n>> On 18 Nov 2016, at 11:20, Eric Voskuil <eric at voskuil.org> wrote:\n>> \n>> You are suggesting that, since a node implements a denial of service policy that actually denies itself otherwise valid blocks, those blocks are conditionally invalid. And that, since the validity condition is based on order of arrival and therefore independently unverifiable, Bitcoin consensus is broken in the face of a hash collision.\n>> \n>> I am aware of two other hash collision scenarios that cause Core to declare blocks invalid based on ordering. The block hash duplicate check (it's not fork-point relative) and signature verification caching. Like the \"block banning\" issue above, the latter is related to an internal optimization. I would categorize the former as a simple oversight that presumably goes way back.\n>> \n>> What then is the consequence of validity that is unverifiable? You believe this means that Bitcoin consensus is broken. This is incorrect. First understand that it is not possible for consensus rules to invalidate blocks based on order of arrival. As such any *implementation* that invalidates blocks based on order of arrival is broken. It is an error to claim that these behaviors are part of consensus, despite being implemented in the satoshi node(s).\n>> \n>> Validity must be verifiable independent of the state of other nodes. Consensus is a function of block history and time alone. Time is presumed to be universally consistent. To be a consensus rule all nodes must be able to independently reach the same validity conclusion, given the same set of blocks, independent of order. If this is not the case the behavior is not a consensus rule, it is simply a bug. \n>> \n>> Deviating from such bugs is not a break with consensus, since such non-rules cannot be part of consensus. One node implementation can behave deterministically while others are behaving non-deterministically, with the two nodes remaining consistent from a consensus standpoint (deterministic produces a subset of non-deterministic results). But, unlike arbitrary nodes, deterministic nodes will not cause disruption on the network.\n>> \n>> You imply that these determinism bugs are necessary, that there is no fix. This is also incorrect.\n>> \n>> The block banning hash collision bug is avoided by not using non-chain/clock state to determine validity. Doing otherwise is clearly a bug. The hash of a block is not the block itself, a logically-correct ban would be to compare the wire serialization of the block as opposed to the hash, or not maintain the feature at all.\n>> \n>> The signature verification caching hash collision bug is the same problem, an optimization based on an invalid assumption. A full serialization comparison (true identity), or elimination of the feature resolves the  bug.\n>> \n>> The block hash check collision bug is trivially resolved by checking at the fork point as opposed to the tip. This prevents arbitrary (and irrational) invalidity based on conflict with irrelevant blocks that may or may not exist above the fork point.\n>> \n>> Libbitcoin is deterministic in all three cases (although the third issue is not made consistent until v3). I am not aware of any other non-determinism in Core, but I don't spend a lot of time there. There is no need to study other implementations to ensure determinism, as that can be verified independently.\n>> \n>> Any situation in which a node cannot provide deterministic validation of unordered blocks constitutes a non-consensus bug, as the behavior is not consistently verifiable by others under any conditions. Fixing/preventing these bugs is responsible development behavior, and does not require forks or BIPs, since Bitcoin doesn't inherently contain any such bugs. They are the consequence of incorrect implementation, and in two of the three cases above have resulted from supposed optimizations. But any code that creates non-determinism in exchange for speed, etc. is not an optimization, it's a bug. A node must implement its optimizations in a manner that does not alter consensus.\n>> \n>> The BIP30 regression hard fork is not a case of non-determinism. This will produce deterministic results (apart from the impact of unrelated bugs). However the results are both a clear break from previous (and documented) consensus but also produce a very undesirable outcome - destruction of all unspent outputs in the \"replaced\" transaction for starters. So this is a distinct category, not a determinism bug but a hard fork that produces undesired consequences.\n>> \n>> The BIP30 regression hard fork actually enables the various pathological scenarios that you were describing, where no such issues existed in Bitcoin consensus previously. It is now possible to produce a block that mutates another arbitrarily deep block, and forces a reorg all the way back to the mutated block. This was done to save microseconds per block. Despite the improbability of hash collisions, I find this deplorable and the lack of public discussion on the decision concerning.\n>> \n>> With respect to the original post, the point at issue is the introduction of another hard fork, with some odd behaviors, but without any justification apart from tidying up the small amount of necessary code. These issues are related in that they are both consensus forks that have been introduced as supposed optimizations, with no public discussion prior to release (or at least merging to master with the presumption of shipping in the latter case). Two of the three hash collision issues above are also related in that they are bugs introduced by a desire to optimize internals.\n>> \n>> The engineering lesson here should be clear - watch out for developers bearing optimizations. A trade against correctness is not an optimization, it's a break. Satoshi was clearly a fan of the premature optimization. FindAndDelete is a howler. So this is a tradition in Bitcoin. My intent is not to sling mud but to improve the situation.\n>> \n>> It is very possible to produce straightforward and deterministic code that abides consensus and materially outperforms Core, without any of the above optimization breaks, even avoiding the utxo set optimization. Even the tx (memory) and block (orphan) pools are complex store denormalizations implemented as optimizations. Optimizing before producing a clean conceptual model architecture and design is a software development anti-pattern (premature optimization). The proposed fork is a premature optimization. There are much more significant opportunities to better organize code (and improve performance). I cannot support the decision to advance it.\n>> \n>> I was unaware Core had regressed BIP30. Given that the behavior is catastrophic and that it introduces the *only* hash-collision consensus misbehavior (unless we consider a deep reorg sans the otherwise necessary proof of work desirable behavior), I strongly recommend it be reverted, with a post-mortem BIP.\n>> \n>> Finally I recommend people contemplate the difference between unlikely and impossible. The chance of random collision is very small, but not zero. Colliding hashes is extremely difficult, but not impossible. But Bitcoin does not rely on impossibility for correct behavior. It relies of difficulty. This is a subtle but important distinction that people are missing.\n>> \n>> Difficulty is a knowable quantity - a function of computing power.  If hash operations remain difficult, Bitcoin is undeterred. Collisions will have no impact, even if they happen with unexpected frequency (which would still be vanishingly infrequent). If the difficulty of producing a collision is reduced to the point where people cannot rely on addresses (for example), then Bitcoin has a problem, as it has become a leaky ship (and then there's mining). But with the unnecessary problems described above, a single hash collision can be catastrophic. Unlike difficulty, which is known, nobody can know when a single collision will show up. Betting Bitcoin, and potentially the world's money, on the unknowable is poor reasoning, especially given that the cost of not doing so is so very low.\n>> \n>> e\n>> \n>>> On Nov 17, 2016, at 10:08 AM, Johnson Lau <jl2012 at xbt.hk> wrote:\n>>> \n>>> The fact that some implementations ban an invalid block hash and some do not, suggests that it\u2019s not a pure p2p protocol issue. A pure p2p split should be unified by a bridge node. However, a bridge node is not helpful in this case. Banning an invalid block hash is an implicit \u201cfirst seen\u201d consensus rule.\n>>> \n>>> jl2012\n>>> \n>>>> On 18 Nov 2016, at 01:49, Eric Voskuil <eric at voskuil.org> wrote:\n>>>> \n>>>> Actually both possibilities were specifically covered in my description. Sorry if it wasn't clear.\n>>>> \n>>>> If you create a new valid block out of an old one it's has potential to cause a reorg. The blocks that previously built on the original are still able to do so but presumably cannot build forever on the *new* block as it has a different tx. But other new blocks can. There is no chain split due to a different interpretation of valid, there are simply two valid competing chains.\n>>>> \n>>>> Note that this scenario requires not only block and tx validity with a tx hash collision, but also that the tx be valid within the block. Pretty far to reach to not even get a chain split, but it could produce a deep reorg with a very low chance of success. As I keep telling people, deep reorgs can happen, they are just unlikely, as is this scenario.\n>>>> \n>>>> If you create a new invalid block it is discarded by everyone. That does not invalidate the hash of that block. Permanent blocking as you describe it would be a p2p protocol design choice, having nothing to do with consensus. Libbitcoin for example does not ban invalidated hashes at all. It just discards the block and drops the peer.\n>>>> \n>>>> e\n>>> \n>>> \n> \n>"
            }
        ],
        "thread_summary": {
            "title": "BIP30 and BIP34 interaction (was Re: Buried Deployments)",
            "categories": [
                "bitcoin-dev",
                "BIP Proposal"
            ],
            "authors": [
                "Eric Voskuil",
                "Peter Todd",
                "Johnson Lau",
                "Tier Nolan",
                "Jorge Tim\u00f3n",
                "Alex Morcos"
            ],
            "messages_count": 19,
            "total_messages_chars_count": 74389
        }
    },
    {
        "title": "[bitcoin-dev] Flexible Transactions.",
        "thread_messages": [
            {
                "author": "Russell O'Connor",
                "date": "2016-11-21T15:54:19",
                "message_text_only": "Hi Tom,\n\nOn Tue, Sep 20, 2016 at 1:15 PM, Tom via bitcoin-dev <bitcoin-dev at lists.\nlinuxfoundation.org> wrote:\n\n>\n> The OP_CHECKSIG is the most well known and, as its name implies, it\n> validates a signature.\n> In the new version of 'script' (version 2) the data that is signed is\n> changed to be equivalent to the transaction-id. This is a massive\n> simplification and also the only change between version 1 and version 2 of\n> script.\n>\n\nI'm a fan of simplicity too; Unfortunately, your proposal above to change\nthe semantics of OP_CHECKSIG is too naive.\n\nThe SIGHASH data used in both the original Bitcoin script and in Segwit\nscript contains data indicating which input is being signed.  In Bitcoin\nscript, the input is being signed is indicated by the input that has a\nnon-empty scriptSig field.  In the Segwit script, the outpoint\ncorresponding to the input being signed is explicitly included in the\nsignature data. By signing only the transaction id, your proposed signature\ndoes not include the data that tells which input of the transaction is\nbeing signed.  Thus if different inputs share the same public key due to\nkey reuse, then the signatures on those different inputs will be\nidentical.  Your Flexible Transactions proposal opens up a new line of\nattack against Bitcoin that doesn't currently exist.\n\nConsider the following simple example, suppose you and I are jointly\npreparing a transaction to mix our coins, or perhaps we are jointly funding\nsome purchase.  We jointly prepare a transaction with one input from you\nand another input from me.  We each sign the transaction and hand the\nsignature data over to each other so we can produce a completed\ntransaction.  But oh no! I lied to you. I didn't use my own input to the\ntransaction.  \"My input\" was actually the outpoint from one of *your*\ntransactions; one that has the same public key as the input you have\nchosen.  Now I copy your signature you have provided in your input to cover\n\"my input\", which is really your coins.  Surprise, it turns out you are\nfunding both inputs to our \"jointly\" funded purchase.  Other protocols are\nlikely similarly broken by your Flexible Transactions proposal.\n\nI personally rate this flaw as about the same caliber as the transaction\nmalleability you are trying to fix.  Sure, with enough vigilance, perhaps\nyou can detect and avoid this trap.  However, it requires a bunch of\nunexpected work.  You must always examine every other input to a\ntransaction you are about to sign to make sure that it isn't one of your\ninputs, which means you probably need a copy of the UXTO set to lookup\noutpoints, which is a huge burden, especially if you are a hardware\nwallet.  If you are not vigilante, your funds may end up stolen. Surely it\nis better not to open this line of attack.\n\nFor the most part, the SIGHASH works the way it does in Bitcoin for a\nreason. You cannot simply throw away the parts you don't understand or\nappreciate.  You should take the time to learn why things are the way they\nare, and then, only once you are certain that some aspects are not, or no\nlonger, needed then can you propose removing them.\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161121/4af91442/attachment.html>"
            },
            {
                "author": "Tom Zander",
                "date": "2016-11-21T20:28:51",
                "message_text_only": "On Monday, 21 November 2016 10:54:19 CET Russell O'Connor wrote:\n> Hi Tom,\n> \n> On Tue, Sep 20, 2016 at 1:15 PM, Tom via bitcoin-dev <bitcoin-dev at lists.\n> \n> linuxfoundation.org> wrote:\n> > The OP_CHECKSIG is the most well known and, as its name implies, it\n> > validates a signature.\n> > In the new version of 'script' (version 2) the data that is signed is\n> > changed to be equivalent to the transaction-id. This is a massive\n> > simplification and also the only change between version 1 and version 2\n> > of script.\n> \n> I'm a fan of simplicity too; Unfortunately, your proposal above to change\n> the semantics of OP_CHECKSIG is too naive.\n\nThanks for your email, Russell.\n\nUnfortunately you waited 6 weeks with writing this and the problem you are \nseeing has been fixed quite some time ago.\n\nThanks again for reviewing, though!\n-- \nTom Zander\nBlog: https://zander.github.io\nVlog: https://vimeo.com/channels/tomscryptochannel"
            },
            {
                "author": "Russell O'Connor",
                "date": "2016-11-21T21:29:21",
                "message_text_only": "On Mon, Nov 21, 2016 at 3:28 PM, Tom Zander via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Thanks for your email, Russell.\n>\n> Unfortunately you waited 6 weeks with writing this and the problem you are\n> seeing has been fixed quite some time ago.\n>\n\nOh, that is good news!  I look forward to seeing BIP 134 updated with your\nsolution.\n\n\n> Thanks again for reviewing, though!\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161121/988a2b51/attachment.html>"
            }
        ],
        "thread_summary": {
            "title": "Flexible Transactions.",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Russell O'Connor",
                "Tom Zander"
            ],
            "messages_count": 3,
            "total_messages_chars_count": 4818
        }
    },
    {
        "title": "[bitcoin-dev] The Excessive-Block Gate: How a Bitcoin Unlimited Node Deals With Large Blocks",
        "thread_messages": [
            {
                "author": "Peter R",
                "date": "2016-11-22T16:31:50",
                "message_text_only": "Dear all,\n\nBitcoin Unlimited\u2019s market-based solution to the block-size limit is slowly winning support from node operators and miners.  With this increased attention, many people are asking for a better explanation of how Bitcoin Unlimited actually works.  The article linked below describes how Bitcoin Unlimited\u2019s excessive-block logic works from the perspective of a single node. (I\u2019m hoping to do a follow-up article that describe how this \u201cnode-scale\u201d behavior facilitates the emergence of a fluid and organic block size limit at the network scale.)\n\nhttps://medium.com/@peter_r/the-excessive-block-gate-how-a-bitcoin-unlimited-node-deals-with-large-blocks-22a4a5c322d4 <https://medium.com/@peter_r/the-excessive-block-gate-how-a-bitcoin-unlimited-node-deals-with-large-blocks-22a4a5c322d4>\n\nBest regards,\nPeter R\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161122/2f884976/attachment.html>"
            },
            {
                "author": "Sergio Demian Lerner",
                "date": "2016-11-25T01:39:05",
                "message_text_only": "Hi Peter,\n\nHow would a person or exchange decide to accept a payment in BU if it does\nnot know the gate policy of 51% of the miners?\n\nSuppose that the exchange receives B1,S2,S3,S4 (a big block at height 1,\nand 3 small blocks at height 2, 3 and 4), and an alternate chain A1,A2,A3\n(three small blocks). The first is the longest, but the second may be the\none 51% of the miners will extend.\n\nWithout knowing  the policy of at least 51% of the miners (the maximum\nacceptance depth) it's unclear if the exchange has to obey the longest\nchain or the chain with higher probability of being extended.\nIf the maximum acceptance depth of the majority of miners is higher than 6\nblocks, accepting a transaction with 6 confirmations is risky.\nSo BU would set a lower bound on the number of confirmations equal to the\nmaximum acceptance depth of the majority of miners.But miners do not\npublish their acceptance depth, so basically users are clue-less. I think\nminers should at least advertise their gate block size and acceptance depth\nin their coinbase field.\n\nIs there a game-theoretic analysis of confirmation blocks and their\nprobabilities in BU ?\nWithout a detailed analysis, unlimited block size seems a risky change to\nBitcoin, to me.\n\nRegards, Sergio.\n\n\n\nOn Tue, Nov 22, 2016 at 1:31 PM, Peter R via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> Dear all,\n>\n> Bitcoin Unlimited\u2019s market-based solution to the block-size limit is\n> slowly winning support from node operators and miners.  With this increased\n> attention, many people are asking for a better explanation of how Bitcoin\n> Unlimited actually works.  The article linked below describes how Bitcoin\n> Unlimited\u2019s excessive-block logic works from the perspective of a single\n> node. (I\u2019m hoping to do a follow-up article that describe how this\n> \u201cnode-scale\u201d behavior facilitates the emergence of a fluid and organic\n> block size limit at the network scale.)\n>\n> https://medium.com/@peter_r/the-excessive-block-gate-how-\n> a-bitcoin-unlimited-node-deals-with-large-blocks-22a4a5c322d4\n>\n> Best regards,\n> Peter R\n>\n> _______________________________________________\n> bitcoin-dev mailing list\n> bitcoin-dev at lists.linuxfoundation.org\n> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161124/7c1166cd/attachment.html>"
            },
            {
                "author": "Tom Zander",
                "date": "2016-11-25T15:25:58",
                "message_text_only": "On Thursday, 24 November 2016 22:39:05 CET Sergio Demian Lerner via bitcoin-\ndev wrote:\n> Without a detailed analysis, unlimited block size seems a risky change to\n> Bitcoin, to me.\n\nWhat exactly do you think is a \u2018change\u2019 in bitcoin here?\n\nThe concept of proof-of-work is that the longer a chain, the higher \nprobability that that one will be extended for the simple reason that \nanother chain will have to show a higher amount of proof of work to \u2018win\u2019.\n\nAs far as I understand the document from Peter, there is no change there at \nall. Only chains with more POW will win.\nOr, to answer your example, miners will prefer to extend the chain with the \nmost POW.\n\nThe other fact stays the same as well, if you protect from reorgs by \nexpecting more confirmations. Nothing changes here either. The common-sense 6 \nconfirmations for things like exchange-deposits keep having the same \nsecurity.\n\nThe basic idea that we have a 3 or 4 deep fork is a huge problem in Bitcoin. \nIt hasn\u2019t happened for ages, and we like it that way. The miners like it \nthat way too. Its disruptive.\nThe is a problem that is not created by the \u2018excessive block\u2019 concept. It \ndoes, however, provide a possible solution to this very far-fetched problem.\n\nYou should also realize that the policy of a miner is stored in the \ncoinbase.\n\nThat said, I\u2019m sure there are improvements to be made to the policy that BU \nuses. But since this is a node-local policy, the consensus rules are not \naffected by it.\n-- \nTom Zander\nBlog: https://zander.github.io\nVlog: https://vimeo.com/channels/tomscryptochannel"
            },
            {
                "author": "Sergio Demian Lerner",
                "date": "2016-11-25T22:31:22",
                "message_text_only": "On Fri, Nov 25, 2016 at 12:25 PM, Tom Zander via bitcoin-dev <\nbitcoin-dev at lists.linuxfoundation.org> wrote:\n\n> On Thursday, 24 November 2016 22:39:05 CET Sergio Demian Lerner via\n> bitcoin-\n> dev wrote:\n> > Without a detailed analysis, unlimited block size seems a risky change to\n> > Bitcoin, to me.\n>\n> What exactly do you think is a \u2018change\u2019 in bitcoin here?\n>\n> A change is anything that modifies with a HF the current state of the\nBitcoin Core implementation of the consensus protocol. Sadly (or happily,\nfor some) there is no \"abstract\" definition of Bitcoin.\n\n\n\n> The concept of proof-of-work is that the longer a chain, the higher\n> probability that that one will be extended for the simple reason that\n> another chain will have to show a higher amount of proof of work to \u2018win\u2019.\n>\n> We know what Bitcoin the protocol dictates, but if what the protocol\ndictates is not in the best interest of miners or full-nodes? then they\nwill simply choose a rule that maximizes their revenue (or any other\nmeasure of performance, such as lower latency, or less transaction reversal\nprobability).\n\n\nAs far as I understand the document from Peter, there is no change there at\n> all. Only chains with more POW will win.\n>\n\nI haven't gone to the code to check, but the video Peter sent does not say\nthat. It says that miners will mine on top of a block ONLY if the \"gate\"\nhas been opened for that block (e.g. there is additional blocks to push a\nbig block). So a miner having a preferring low block sizes will choose to\nmine on top of the A1,A2,A3 chain (3 units of work), while miners\nsupporting bigger sizes will mine on top of the chain B1,S2,S3,S4 (4 units\nof work).\n\nSaying that the chain starting with B1 is not considered by a node X does\nnot mean that the node X is blind to the information that can be extracted\nfrom the fact that there is a chain of 4 blocks starting from B1.\nIf there is more information, there may be a better local choice. If there\nare better local choices, there is probably a better global equilibrium (or\nnot equilibrium at all).\n\n\n> Or, to answer your example, miners will prefer to extend the chain with the\n> most POW.\n>\n\nClearly this is not universal: some miners will, and some other miners\nwon't, because some miners have postponed adding some blocks.\n\n\n\n>\n> The other fact stays the same as well, if you protect from reorgs by\n> expecting more confirmations. Nothing changes here either. The\n> common-sense 6\n> confirmations for things like exchange-deposits keep having the same\n> security.\n>\n\nSuppose that I provide a service that accepts payments with 2\nconfirmations, and in certain time I have the information that the network\nis at the same time considering the forks B1 S2 and A1 A2. Then the best I\ncan do is NOT to accept the 2-confirmation and wait for a resolution of the\nfork. Choosing either fork may put me at the risk of immediate reversal.\n\nThe existence of fork information changes equilibrium decision to choose\nthe longest-chain.  This is the same that happens with the GHOST protocol:\nthe information on the existence of uncles changes the local incentives to\nchoose the longest chain to some different strategy, and when all nodes\nchange their strategy, then the supposedly last equilibrium state is that\nall follow the GHOST strategy for choosing the heaviest chain.\n\n\n>\n> The basic idea that we have a 3 or 4 deep fork is a huge problem in\n> Bitcoin.\n> It hasn\u2019t happened for ages, and we like it that way. The miners like it\n> that way too. Its disruptive.\n> The is a problem that is not created by the \u2018excessive block\u2019 concept. It\n> does, however, provide a possible solution to this very far-fetched\n> problem.\n>\n> You should also realize that the policy of a miner is stored in the\n> coinbase.\n>\n> This is important, but yet the full node does not use this information\nautomatically. The amount of confirmations that a node accepts is not\naffected by the miner's policies or the size of the blocks mined, but it\nshould.\n\n\n> That said, I\u2019m sure there are improvements to be made to the policy that BU\n> uses.\n\n\nProbably a simple wise addition would be to estimate the accepted block\nsize for the majority of the miners (S), and only count block confirmations\nfor wallet transactions taking into account only blocks whose size is lower\nor equal than S. So for example, if Alice receives a transaction T in block\nB1 and it is confirmed by block B2, but size(B1)>S and size(B2)>S, then the\nwallet should tell Alice that transaction T has 0 confirmations. This local\nstrategy reduces the chances that Alice accept T but is then easily\nreversed for the opposite fork growing one block ahead.\n\nRegards,\n Sergio\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161125/677ee30f/attachment-0001.html>"
            },
            {
                "author": "Sergio Demian Lerner",
                "date": "2016-11-25T23:45:20",
                "message_text_only": "I now think my reasoning and conclusions are based on a false premise: that\nBU block size policies for miners can be heterogeneous.\n\nThere can't be short forks because forks are not in the best interest of\nthe honest miner majority. All miners need to announce and follow the same\nblock size policy to prevent short forks.\n\nThe incentives are established so that all block size negotiations will be\ncarried between miners in a off-chain manner, not by modifying the policy\nnor by announcing anything in the coinbase,\n\nIf block size negotiations are meant to be open and carried on on-chain,\nthen it's much better to let miners increase or decrease the block size\nlimit by 1% per block (such as what Ethereum does with the gas limit).\n\n\n\n\n\nOn Fri, Nov 25, 2016 at 7:31 PM, Sergio Demian Lerner <\nsergio.d.lerner at gmail.com> wrote:\n\n>\n>\n> On Fri, Nov 25, 2016 at 12:25 PM, Tom Zander via bitcoin-dev <\n> bitcoin-dev at lists.linuxfoundation.org> wrote:\n>\n>> On Thursday, 24 November 2016 22:39:05 CET Sergio Demian Lerner via\n>> bitcoin-\n>> dev wrote:\n>> > Without a detailed analysis, unlimited block size seems a risky change\n>> to\n>> > Bitcoin, to me.\n>>\n>> What exactly do you think is a \u2018change\u2019 in bitcoin here?\n>>\n>> A change is anything that modifies with a HF the current state of the\n> Bitcoin Core implementation of the consensus protocol. Sadly (or happily,\n> for some) there is no \"abstract\" definition of Bitcoin.\n>\n>\n>\n>> The concept of proof-of-work is that the longer a chain, the higher\n>> probability that that one will be extended for the simple reason that\n>> another chain will have to show a higher amount of proof of work to \u2018win\u2019.\n>>\n>> We know what Bitcoin the protocol dictates, but if what the protocol\n> dictates is not in the best interest of miners or full-nodes? then they\n> will simply choose a rule that maximizes their revenue (or any other\n> measure of performance, such as lower latency, or less transaction reversal\n> probability).\n>\n>\n> As far as I understand the document from Peter, there is no change there at\n>> all. Only chains with more POW will win.\n>>\n>\n> I haven't gone to the code to check, but the video Peter sent does not say\n> that. It says that miners will mine on top of a block ONLY if the \"gate\"\n> has been opened for that block (e.g. there is additional blocks to push a\n> big block). So a miner having a preferring low block sizes will choose to\n> mine on top of the A1,A2,A3 chain (3 units of work), while miners\n> supporting bigger sizes will mine on top of the chain B1,S2,S3,S4 (4 units\n> of work).\n>\n> Saying that the chain starting with B1 is not considered by a node X does\n> not mean that the node X is blind to the information that can be extracted\n> from the fact that there is a chain of 4 blocks starting from B1.\n> If there is more information, there may be a better local choice. If there\n> are better local choices, there is probably a better global equilibrium (or\n> not equilibrium at all).\n>\n>\n>> Or, to answer your example, miners will prefer to extend the chain with\n>> the\n>> most POW.\n>>\n>\n> Clearly this is not universal: some miners will, and some other miners\n> won't, because some miners have postponed adding some blocks.\n>\n>\n>\n>>\n>> The other fact stays the same as well, if you protect from reorgs by\n>> expecting more confirmations. Nothing changes here either. The\n>> common-sense 6\n>> confirmations for things like exchange-deposits keep having the same\n>> security.\n>>\n>\n> Suppose that I provide a service that accepts payments with 2\n> confirmations, and in certain time I have the information that the network\n> is at the same time considering the forks B1 S2 and A1 A2. Then the best I\n> can do is NOT to accept the 2-confirmation and wait for a resolution of the\n> fork. Choosing either fork may put me at the risk of immediate reversal.\n>\n> The existence of fork information changes equilibrium decision to choose\n> the longest-chain.  This is the same that happens with the GHOST protocol:\n> the information on the existence of uncles changes the local incentives to\n> choose the longest chain to some different strategy, and when all nodes\n> change their strategy, then the supposedly last equilibrium state is that\n> all follow the GHOST strategy for choosing the heaviest chain.\n>\n>\n>>\n>> The basic idea that we have a 3 or 4 deep fork is a huge problem in\n>> Bitcoin.\n>> It hasn\u2019t happened for ages, and we like it that way. The miners like it\n>> that way too. Its disruptive.\n>> The is a problem that is not created by the \u2018excessive block\u2019 concept. It\n>> does, however, provide a possible solution to this very far-fetched\n>> problem.\n>>\n>> You should also realize that the policy of a miner is stored in the\n>> coinbase.\n>>\n>> This is important, but yet the full node does not use this information\n> automatically. The amount of confirmations that a node accepts is not\n> affected by the miner's policies or the size of the blocks mined, but it\n> should.\n>\n>\n>> That said, I\u2019m sure there are improvements to be made to the policy that\n>> BU\n>> uses.\n>\n>\n> Probably a simple wise addition would be to estimate the accepted block\n> size for the majority of the miners (S), and only count block confirmations\n> for wallet transactions taking into account only blocks whose size is lower\n> or equal than S. So for example, if Alice receives a transaction T in block\n> B1 and it is confirmed by block B2, but size(B1)>S and size(B2)>S, then the\n> wallet should tell Alice that transaction T has 0 confirmations. This local\n> strategy reduces the chances that Alice accept T but is then easily\n> reversed for the opposite fork growing one block ahead.\n>\n> Regards,\n>  Sergio\n>\n>\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161125/f5679767/attachment-0001.html>"
            },
            {
                "author": "Tom Zander",
                "date": "2016-11-26T15:01:16",
                "message_text_only": "On Friday, 25 November 2016 20:45:20 CET Sergio Demian Lerner wrote:\n> I now think my reasoning and conclusions are based on a false premise:\n> that BU block size policies for miners can be heterogeneous.\n\nAgreed.\n \n> There can't be short forks because forks are not in the best interest of\n> the honest miner majority. All miners need to announce and follow the same\n> block size policy to prevent short forks.\n\nWhat you appear to want to say is that it is in everyones best interest to \navoid short forks.\nIts impossible to guarentee they can't happen, but very possible to minimize \nthem.\n \n> If block size negotiations are meant to be open and carried on on-chain,\n> then it's much better to let miners increase or decrease the block size\n> limit by 1% per block (such as what Ethereum does with the gas limit).\n\nNo, there are no block-size-negotiations on chain.\n\nThe blockchain is used here for one purpose, to state the position of \nindividual miners. But what may not be clear is that you can use this as a \ntime-stamped way to hold them to it. Which means that if they lie (by \nrejecting a block), everyone in the world will be able to individually \nverify that fact and their credibility will be affected.\n\nWhich will not help their case next time any block size negotiations will \nhappen.\n-- \nTom Zander\nBlog: https://zander.github.io\nVlog: https://vimeo.com/channels/tomscryptochannel"
            },
            {
                "author": "Peter R",
                "date": "2016-11-26T23:35:49",
                "message_text_only": "Great discussion, Sergio and Tom!\n\n> I now think my reasoning and conclusions are based on a false premise: that BU block size policies for miners can be heterogeneous.\n\n\nRight, miners who set their block size limits (BSL) above OR below the \"effective BSL\" are disadvantaged.  Imagine that we plot the distribution (by hash power) for all miners' BSLs.  We might get a chart that looks like this:\n\nhttp://imgur.com/a/tWNr6 <http://imgur.com/a/tWNr6>\n\nIn this chart, the \"effective BSL\" is defined as the largest block size that no less than half the hash power will accept.  \n\nIf a block is mined with a size Q that is less than the \"effective BSL,\" then all the hash power with BSLs between BSL_min and Q will be forked from the longest chain (until they update their software if they're running Core or until their acceptance depth is hit if they're running BU).  This wastes these miners' hash power.  \n\nHowever, if a block is mined with a size Q that is greater than the effective BSL, then all the hash power with BSLs between Q and BSL_max will temporarily be mining on a \"destined to be orphaned\" chain.  This also wastes these miners' hash power.  \n\nTherefore, it is in the best interest of miners to all set the same block size limit (and reliably signal in their coinbase TX what that limit is, as done by Bitcoin Unlimited miners).  \n\nWe have empirical evidence the miners in fact behave this way: \n\n(1) No major miner has ever set his block size limit to less than 1 MB (not even those such as Luke-Jr who think 1 MB is too big) because doing so would just waste money.  \n\n(2) After switching to Bitcoin Unlimited, both ViaBTC and the Bitcoin.com pool temporarily set their BSLs to 2 MB and 16 MB, respectively (of course keeping their _generation limit_ at 1MB).  However, both miners quickly reduced these limits back to 1 MB when they realized how it was possible to lose money in an attack scenario.  (This actually surprised me because the only way they could lose money is if some _other_ miner wasted even more money by purposely mining a destined-to-be-orphaned block.)   \n\nThe follow-up article I'm working on is about the topics we're discussing now, particularly about how Bitcoin Unlimited's \u201cnode-scale\u201d behavior facilitates the emergence of a fluid and organic block size limit at the network scale.  Happy to keep continue with this current discussion, however.\n\nBest regards\nPeter\n\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161126/765d7ba9/attachment.html>"
            },
            {
                "author": "Tom Zander",
                "date": "2016-11-27T07:47:00",
                "message_text_only": "On Saturday, 26 November 2016 15:35:49 CET Peter R via bitcoin-dev wrote:\n> Therefore, it is in the best interest of miners to all set the same block\n> size limit (and reliably signal in their coinbase TX what that limit is,\n> as done by Bitcoin Unlimited miners).\n\nAs a point of interest, last week I merged into Classic the same concept. \nClassic will now respect the EB limit and put it in the coinbase.\n\n>  (This actually surprised me because the only way they could lose money is\n>  if some _other_ miner wasted even more money by purposely mining a\n>  destined-to-be-orphaned block.)\n\nYour surprise may come from the difference in cost vs. expected earnings of \ncreating a block, which is quite significant.\n-- \nTom Zander\nBlog: https://zander.github.io\nVlog: https://vimeo.com/channels/tomscryptochannel"
            }
        ],
        "thread_summary": {
            "title": "The Excessive-Block Gate: How a Bitcoin Unlimited Node Deals With Large Blocks",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Sergio Demian Lerner",
                "Tom Zander",
                "Peter R"
            ],
            "messages_count": 8,
            "total_messages_chars_count": 20554
        }
    },
    {
        "title": "[bitcoin-dev] BIP idea: Standardised p2sh bitcoin addresses requiring an arbitrary and/or combination of keys",
        "thread_messages": [
            {
                "author": "Erland Lewin",
                "date": "2016-11-29T20:56:45",
                "message_text_only": "I would like to get community feedback on whether the following idea would\nbe reasonable to write as an informational BIP proposal:\n\n\nBoolean Addresses: Standardized p2sh addresses combining public keys,\nmultisigs and time locks with arbitrary and/or-operations\n\n\nAbstract\n========\nIt is currently straightforward to create Bitcoin addresses which can be\nredeemed by a single key or an m-of-n multi signature. It is not as\nstraight forward to create addresses that can be redeemed by, for example,\nkey A or (key B and key C).\n\nThis proposal describes a consistent way to create s type of p2sh addresses\n(\u201cBoolean addresses\u201d) which can be redeemed by an arbitrary set of keys and\nmulti signatures combined with logical and/or operations.\n\n\nExamples\n\n========\nIn the examples below, Alice has key A, Bob key B, Charles key C, etc).\n\nExample 1:\n\nA corporation has an account that can be spent by the CEO Alice or two\nboard members (of Bob, Charles, David or Eric) in union. The account should\nallow signatures by \"A or (2 of 4 of B, C, D, E)\"\n\n\nExample 2:\n\n\nAlice wants a bitcoin address that she normally signs herself. However, if\nshe has a fatal accident, she sets up a key \"B\" to be automatically mailed\nfrom a cloud service after a given time of inactivity to close relatives\nCharles, David and Eric. These relatives are also given keys written on\npaper.\n\n\nAlice's address can be redeemed by \"A or (B and 1-of-3 of C, D, E)\". This\nway, if the cloud wallet key B is compromised or paper wallets C, D or E\nare stolen, it is not sufficient to redeem the address. If Alice\u2019s key is\nlost, she can ask C, D, or E for their key and use key B to spend the\naddress to a new one with a new key for Alice.\n\n\nMotivation\n\n==========\nStandardisation of these addresses would allow interoperability for wallet\nsoftware to create, sign and share signature requests for such addresses.\n\n\nImplementation\n==============\nA Boolean address is described as a tree starting at a root node, where a\nnode can be:\n\n* An \u201cand\u201d operation, with a list of sub-nodes\n* An \u201cor\u201d operation, with a list of sub-nodes\n* A public key\n* A Multisig operation n-of-m with a list of public keys\n* A CHECKLOCKTIMEVERIFY operation\n\nThe implementation will describe a single well-defined way to generate a\nP2SH script from a given boolean address tree.\n\nIt will also define the ordering of sub-nodes for and and or operations.\n\nThe implementation will further detail how spending transactions are to be\nsigned. A signature will consist of keys required for a given path through\nthe tree. Signing an \u201cor\u201d- branch of the tree, will consist of a value\nspecifying which or-subnode is signed, followed by the signatures for that\nnode. That way, only one or-case has to be evaluated in the script.\n\nFor example, in the case of an account that can be redeemed by the example\n\"A or (B and 1-of-3 of C, D, E)\" from above, could be signed by something\nlike:\n\n0 (meaning evaluate the first sub-node of the or condition)\nA\n\nor\n\n1 (evaluate the second sub-node of the top level or condition)\nB\n1 (One key for the multisig)\nD (one of the 1-of-3 signatures)\n0 (padding required for multisig opcode)\n-------------- next part --------------\nAn HTML attachment was scrubbed...\nURL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20161129/c3ea1977/attachment.html>"
            },
            {
                "author": "Edmund Edgar",
                "date": "2016-11-30T00:00:43",
                "message_text_only": "On 30 November 2016 at 05:56, Erland Lewin via bitcoin-dev\n<bitcoin-dev at lists.linuxfoundation.org> wrote:\n> This proposal describes a consistent way to create s type of p2sh addresses\n> (\u201cBoolean addresses\u201d) which can be redeemed by an arbitrary set of keys and\n> multi signatures combined with logical and/or operations.\n\n>From our point of view at Reality Keys ( https://www.realitykeys.com )\nI can confirm that\n1) The pain point this proposal aims to fix is indeed painful.\n2) This would be very helpful, if wallet authors actually adopt it.\n3) The implementation as described so far looks sensible.\n\n-- \n-- \nEdmund Edgar\nFounder, Social Minds Inc (KK)\nTwitter: @edmundedgar\nLinked In: edmundedgar\nSkype: edmundedgar\nhttp://www.socialminds.jp\n\nReality Keys\n@realitykeys\ned at realitykeys.com\nhttps://www.realitykeys.com"
            }
        ],
        "thread_summary": {
            "title": "BIP idea: Standardised p2sh bitcoin addresses requiring an arbitrary and/or combination of keys",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Erland Lewin",
                "Edmund Edgar"
            ],
            "messages_count": 2,
            "total_messages_chars_count": 4149
        }
    },
    {
        "title": "[bitcoin-dev] BIP status updates & BIP 2 activation",
        "thread_messages": [
            {
                "author": "Luke Dashjr",
                "date": "2016-11-30T10:20:30",
                "message_text_only": "To conclude discussion on BIP 2, I have opened a pull request to implement it \nand mark it active. Note this implies activation and implementation of BIP 123 \nas well: https://github.com/bitcoin/bips/pull/478\n\nI plan to merge this on December 14th. If there are any hard objections to \nthis change, please bring it up on the bitcoin-dev mailing list before then. \nFurther reviews of the implementation are welcome in the meantime. Please \nrefrain from requesting further changes to the BIPs themselves unless it is a \nblocker/show-stopper or trivial (not changing the meaning).\n\nIn the process of implementing BIP 2, I came across a number of BIPs which \nmanaged to get into the repository without a proper license. Authors of any of \nthese BIPs should open a pull request adding the necessary Copyright section \nand License header(s). (If there are other contributors to the document in the \nBIP git logs, I will try to reach out to them to get permission. If you have \naccepted contributions from anyone not documented in git as an Author, please \nmention this in the PR explicitly.)\n\nThese BIPs need a license:\n 001  BIP Purpose and Guidelines\n 010  Multi-Sig Transaction Distribution\n 011  M-of-N Standard Transactions\n 012  OP_EVAL\n 013  Address Format for pay-to-script-hash\n 014  Protocol Version and User Agent\n 015  Aliases\n 016  Pay to Script Hash\n 021  URI Scheme\n 030  Duplicate transactions\n 031  Pong message\n 032  Hierarchical Deterministic Wallets\n 033  Stratized Nodes\n 034  Block v2, Height in Coinbase\n 035  mempool message\n 039  Mnemonic code for generating deterministic keys\n 043  Purpose Field for Deterministic Wallets\n 044  Multi-Account Hierarchy for Deterministic Wallets\n 045  Structure for Deterministic P2SH Multisignature Wallets\n 047  Reusable Payment Codes for Hierarchical Deterministic Wallets\n 061  Reject P2P message\n 062  Dealing with malleability\n 064  getutxo message\n 066  Strict DER signatures\n 067  Deterministic Pay-to-script-hash multi-signature addresses through\n          public key sorting\n 068  Relative lock-time using consensus-enforced sequence numbers\n 070  Payment Protocol\n 071  Payment Protocol MIME types\n 072  bitcoin: uri extensions for Payment Protocol\n 073  Use \"Accept\" header for response type negotiation with Payment Request\n          URLs\n 075  Out of Band Address Exchange using Payment Protocol Encryption\n 101  Increase maximum block size\n 102  Block size increase to 2MB\n 103  Block size following technological growth\n 106  Dynamically Controlled Bitcoin Block Size Max Cap\n 120  Proof of Payment\n 121  Proof of Payment URI scheme\n 123  BIP Classification\n\nThanks,\n\nLuke"
            }
        ],
        "thread_summary": {
            "title": "BIP status updates & BIP 2 activation",
            "categories": [
                "bitcoin-dev"
            ],
            "authors": [
                "Luke Dashjr"
            ],
            "messages_count": 1,
            "total_messages_chars_count": 2641
        }
    }
]